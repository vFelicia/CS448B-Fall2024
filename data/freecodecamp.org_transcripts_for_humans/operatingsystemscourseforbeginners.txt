With timestamps:

00:00 - in this massive 25-hour operating system
00:03 - course you will learn the fundamental
00:05 - and advanced operating system Concepts
00:08 - in detail the course starts with
00:11 - defining what an OS is and its various
00:13 - roles then you'll learn about topics
00:16 - like Process Management CPU scheduling
00:19 - deadlock handling strategies memory
00:21 - management and more this course will
00:24 - give you a comprehensive understanding
00:27 - of how operating systems function and
00:30 - manage resources hey there well you have
00:33 - just landed upon the most comprehensive
00:36 - operating system course on this platform
00:38 - we have gone to the depth and have
00:40 - discussed each and every important
00:42 - Concept in
00:43 - detail which is included in our us cabus
00:46 - so first let's discuss the cabus Opera
00:49 - operating system course can be divided
00:51 - into seven major parts the first one is
00:55 - Introduction and background now comes
00:58 - Process Management CPU scheding process
01:02 - synchronization or coordination then
01:04 - comes the deadlock memory management and
01:07 - then in the end file
01:09 - management I believe in certain phases
01:12 - of learning the first one is Theory we
01:15 - understand the concept with the help of
01:17 - real life examples the theory is
01:20 - completed now we comes to numericals I
01:23 - believe problem solving is the best way
01:26 - to check whether you have understood the
01:27 - concept or not
01:30 - then comes the revision my mother said
01:33 - if you fail to revise you fail to
01:35 - learn after some days when you will open
01:39 - the notes and you'll try to read from
01:41 - that everything will seem new to you it
01:44 - will feel like you have never attended
01:45 - this
01:46 - course okay revision is
01:49 - must now let me tell you what the course
01:52 - offers the course offers 25 hours of
01:56 - comprehensive
01:57 - content 400 pages of lecture notes are
02:01 - discussed here although I advise you to
02:04 - make your own short notes but if you
02:07 - want to have the same notes from which I
02:09 - teach to you then you can visit the
02:11 - website I'll paste the QR code there you
02:14 - can visit the website and download the
02:15 - notes from there now who should take
02:18 - this course this course is perfectly
02:21 - suited for University
02:23 - students for their semester exams
02:26 - perfectly suited we have taken 100 plus
02:30 - up Notch numericals all handpicked from
02:33 - the standard textbook of operating
02:34 - system like Stallings galin and Tenon
02:37 - bomb I have taken important problems
02:40 - from the gate exam course is perfectly
02:42 - suited for the University
02:44 - students the gate aspirant or anyone who
02:47 - wants their operating system fundamental
02:50 - solid anyone who is curious who is
02:52 - preparing for some job job interview
02:54 - this course is for you now one last
02:57 - thing a guideline you can cannot just
03:00 - sit back relax and watch this course as
03:02 - a Netflix series no when I discuss
03:05 - Theory you make short notes when I
03:07 - discuss numericals you pause the video
03:10 - and attempt the numerical first by your
03:13 - own see if you just directly see the
03:16 - solution of a problem the problem is
03:18 - wased for you this will not help you
03:20 - grow you will never understand the
03:22 - beauty behind the problem you will never
03:25 - understand where you could have made
03:26 - mistake and that mistake you are going
03:29 - to make in the exam
03:30 - that's why I sincerely request you pause
03:32 - the video first attempt by your own and
03:36 - the third important thing you need to
03:39 - revise let's meet in the first lecture
03:43 - bye welcome to the operating system
03:46 - course this is sh Sharma starting with
03:48 - the chapter one introduction and
03:50 - background so before starting this
03:51 - chapter I'm feeling the need to clarify
03:54 - that there are some prerequisites of
03:56 - this course so you should know or you
03:59 - should have a little bit knowledge about
04:01 - computer organization and architecture I
04:03 - mean little bit about what is computer
04:06 - it's Hardware how does it work its
04:09 - architecture little bit knowledge about
04:11 - that is required you should have a
04:14 - programming exposure with any language
04:16 - either C or Java or any language you
04:19 - prefer you should have little bit of
04:20 - programming exposure okay so these are
04:22 - the two prerequisite and if you do not
04:25 - have them there's no need to worry I
04:27 - will brush up those concepts for you
04:30 - and I will briefly explain you about
04:33 - them okay so we are starting with the
04:35 - chapter one introduction and background
04:37 - so what we will do in this chapter we'll
04:39 - start with what is operating system
04:41 - functions and goals of operating systems
04:43 - types of operating system multi-program
04:44 - operating system architecture
04:46 - requirement and so on mode shifting
04:48 - system calls folk system calls and in
04:50 - the end as I have promised in the
04:51 - preview problem solving okay so these
04:54 - are the three textbooks which I'm
04:56 - following for creation of this course
04:59 - always concepts by galin tenan bomb and
05:01 - Stallings okay so let's start so the
05:03 - first question which arises in our mind
05:05 - is what is an operating system so I'll
05:08 - give you several definitions and I'll
05:10 - explain them one by one okay so
05:12 - operating system is an interface between
05:15 - user and
05:17 - computer what is an interface now I'll
05:20 - explain them but first we should know a
05:23 - little bit about component of Hardware
05:26 - then only you will get a better idea
05:28 - about what does operating system system
05:29 - basically do okay so there are three
05:32 - components or three units of Hardware
05:35 - input output memory input
05:38 - output memory and CPU which is also
05:42 - known as
05:44 - processor so in CPU there are two units
05:47 - control unit and arithmetic logic unit
05:49 - let me change the color I think this
05:51 - will be good okay so control unit and
05:53 - arthamatic logic unit we'll study about
05:55 - what is control unit so control unit is
05:58 - the unit that have power of of
05:59 - generation timing or control signal
06:02 - clock signals you may have heard about
06:03 - it that controls the operation it has
06:06 - also widely known for sequential
06:09 - execution of micro operations now the
06:11 - question arises what are micro
06:13 - operations these are the operations that
06:15 - are carried out on data stored on
06:17 - resistors let me clarify those
06:18 - definitions so this is the high level
06:21 - program written here int ABC B is = 1
06:24 - Cal to 2 A = to B plus C okay so this is
06:27 - a high level statement a Max operation
06:30 - now when it is passed onto the compiler
06:33 - it converts into several micro
06:35 - instructions
06:36 - like load the value of B into register
06:40 - R1 load the value of B into register R1
06:44 - load the value of C into register R2 now
06:47 - add R1 and R2 and load the result into
06:50 - R1 now store the value of R1 into memory
06:53 - a so these are some micro instructions
06:58 - okay now the control unit is responsible
07:01 - for sequential execution that is first
07:03 - you have to do this then this then this
07:05 - and then in the end this who is
07:08 - responsible control unit is responsible
07:10 - okay so this was the architecture in
07:12 - which memory input output and processor
07:16 - this was the architecture proposed by V
07:18 - Newman it is most famous architecture
07:21 - okay so now we'll move down so we have
07:24 - understood what is control unit now
07:26 - let's understand what is ALU ALU is
07:28 - called functional unit unit what
07:30 - functions is perform it performs like
07:32 - arithmetic and logical functions so it's
07:34 - the main unit that carries out
07:35 - arithmetic and logical
07:37 - operations it consists of adders
07:39 - subtractors and so on now comes the
07:42 - memory
07:43 - part so we have studied in our earlier
07:46 - classes that there are two types of
07:47 - memory primary memory and secondary
07:49 - memory primary memory is also called as
07:51 - main memory and secondary memory is also
07:53 - called as auxiliary memory primary
07:55 - memory includes Ram Rome cach registers
07:58 - it's faster to access it's expensive and
08:00 - it is lower size and one most important
08:03 - thing about primary memory is it's
08:05 - volatile what does volatile mean
08:07 - volatile mean that the content vanishes
08:10 - when the power supply goes off it
08:13 - doesn't happen in the secondary
08:16 - memory secondary memory is nonvolatile
08:19 - that is content does not vanishes when
08:20 - the power supply goes off let's take an
08:22 - example you have downloaded a movie now
08:25 - you shut down your computer when you
08:26 - start again you found find the movie
08:28 - present there already
08:30 - but let's take an example of um let's
08:32 - say terminal you have written some code
08:35 - and then when you close the terminal the
08:37 - code finishes it can never be brought
08:39 - back so this is the primary memory and
08:42 - the secondary memory are these are the
08:43 - hard disk the pen drives these are the
08:46 - example of secondary
08:47 - memory so we have in the one num
08:51 - architecture we have written the three
08:53 - parts memory CPU and input output so
08:57 - which memory here I am referring to I am
08:59 - referring here here to primary memory
09:00 - CPU access only primary memory which
09:04 - memory primary that's why I have written
09:06 - P then what about secondary memory I
09:08 - have not seen secondary memory in this
09:10 - architecture where is it so that's
09:13 - that's why I have written it in form of
09:15 - question so where is secondary memory
09:17 - then so as per volum architecture
09:19 - secondary memory are the part of input
09:21 - output devices input output devices I
09:24 - hope that you must know what are input
09:26 - output devices it's like monitor
09:28 - keyboard
09:30 - printer and hard disk these are input
09:32 - output
09:33 - devices okay now an important concept
09:36 - come here how are programs executed in
09:39 - the one Newman architecture so this is
09:42 - the most important part of one num
09:44 - architecture you must pay a little more
09:47 - Focus here okay so let's take with an
09:50 - example we started with a file test. C
09:53 - so this is a C file as here it is we are
09:55 - seeing the extension do c so it's a C
09:57 - file C file is passed to the compiler
10:00 - compiler converts into the executable
10:02 - form that is in form of instruction i1
10:04 - I2 till I in let's say there are any
10:06 - instructions okay now this instruction
10:10 - this whole instruction is passed onto
10:12 - the operating system what does operating
10:15 - system do here it loads thee file into
10:19 - the main memory this is an important
10:21 - part so when a program is loaded in
10:24 - memory for execution this concept is
10:27 - known as stored program con concept this
10:29 - is an important concept so what does OS
10:31 - do it loads the exe file from hard disk
10:35 - to main memory and then from Main memory
10:38 - it is passed to the CPU and CPU do the
10:41 - sequential execution that is CPU first
10:45 - take the in instruction one i1 execute
10:47 - it then I2 then it will execute it until
10:49 - in the end I in now the question
10:53 - arises so here I have written CPU cannot
10:56 - execute the program directly from the
10:57 - hard disk why is it so
11:00 - why does CPU cannot directly access from
11:01 - the hard disk why does it require the
11:04 - main memory why does it require the
11:06 - operating system that needs that exe
11:09 - file first transferred into main memory
11:11 - and then in CPU why does it happen
11:13 - because hard diss are slow the computer
11:17 - has high and fast processing speed but
11:20 - it cannot fetch that much data from hard
11:23 - disk it requires a fast memory so CPU is
11:27 - fast hard disk is slow we need something
11:30 - that can match the speed of CPU so this
11:32 - is main memory that is RAM and it is
11:34 - fast as
11:35 - CPU okay so first operating system need
11:39 - to transfer XE file to main memory here
11:43 - which I have shown and then CPU loads
11:45 - the program from in memory itself and
11:47 - does sequential execution of the
11:49 - instructions so the instruction of the
11:51 - program are executed sequentially one
11:53 - after another that we will learn more in
11:56 - the computer organization architecture
11:57 - course so what we have learned about the
11:59 - fundamental principles of vum
12:01 - architecture we have learned about store
12:03 - program concept that is see operating
12:05 - system loads thex file from hard disk to
12:08 - CPU and then second point is then CPU
12:11 - does the sequential execution of the
12:14 - instructions any program that has to be
12:16 - executed must be stored in the main
12:18 - memory that is the Golden Rule you have
12:21 - to remember okay now you can understand
12:24 - what is an operating system so here is
12:26 - the user here is our Hardware so
12:28 - operating system act as a bridge for
12:30 - communication between user and hardware
12:33 - user talks in the high level language
12:36 - operating system system is an interface
12:38 - which converts that into machine
12:40 - language that is understandable by
12:42 - Hardware Hardware performs the execution
12:45 - then it send the result to operating
12:46 - system and then it send the result to
12:48 - user okay
12:50 - so what is this representation this
12:52 - represent that whole language of user is
12:55 - between symbols a to zed that is our
12:57 - English language and the whole language
13:00 - of the computer is between the set 0 and
13:02 - one between symbol 0 and one okay this
13:05 - is just the representation so question
13:07 - arises how does operating system perform
13:09 - so much of work how does it do this work
13:12 - so how it is done so OS consist of
13:15 - several modules it consists of modules
13:18 - like process manager memory manager file
13:20 - manager device manager and protection
13:22 - manager all this combines and become
13:25 - kernel kernel of operating system it is
13:27 - also known as core or nuclear
13:30 - is okay
13:32 - so what I have taught you till now let
13:34 - me put this all into the same
13:37 - picture this is our user this is our
13:40 - hardware and in between there is an
13:42 - interface so these are the users I have
13:44 - symbolized in the cycle form and in the
13:47 - bottom there's a hardware so operating
13:50 - system manages the
13:53 - hardware and it act as an interface so
13:56 - there are two levels of interface level
13:58 - one and level two
13:59 - level one is user OS interface that is
14:02 - like a command interpreter which consist
14:05 - of shell or GUI can be either so it's a
14:09 - user OS interface that helps in
14:11 - communication between user and the
14:14 - OS so the level one interface helps with
14:16 - communication between user and the OS
14:19 - and then OS kernel performs the
14:20 - operation that is required by the user
14:23 - with the help or with the
14:24 - management of the hardware Hardware
14:27 - consist of CPU main memory input output
14:29 - devices what are what is OS kernel OS
14:32 - kernel consist of all these module
14:33 - process manager memory manager file
14:34 - manager device manager and prodection
14:36 - manager okay so this was operating
14:39 - system definition number one now let's
14:41 - move to definition number two that is
14:43 - operating system also act as resource
14:47 - manager so which resources I'm talking
14:49 - about I'm talking about software
14:50 - resources and Hardware resources
14:53 - Hardware resources include computer
14:55 - sorry CPU monitors input output devices
14:57 - and software resources are file SEMA 4
14:59 - monitors so you don't need to worry
15:01 - there's no need to worry we'll explain
15:03 - all of them file SEMA 4 monitors in
15:06 - detail when the time will come okay and
15:10 - the second part is control program it
15:12 - act as a control program let me also
15:15 - tell you one thing in Resource
15:16 - Management operating system perform the
15:18 - allocation of resources deallocation of
15:20 - resources freeing of resources Etc
15:23 - basically it manages the resources which
15:25 - resources hardware and software
15:27 - operating system is a control program a
15:30 - program that control all the operations
15:32 - of the
15:33 - computer definition number four set of
15:36 - utilities to simplify application
15:38 - development it takes charge of Hardware
15:41 - create environment or platform that help
15:43 - us to focus on development in the high
15:46 - level mode so what OS will do OS will
15:49 - perform the work at the back of the
15:50 - stage and will
15:52 - help or will allow us to write the code
15:55 - in the high level language and rest OS
15:57 - will manage we just have to write the
15:59 - code in high level language so this is
16:03 - the power of operting system so if I
16:06 - summarize what is an operating system
16:08 - operating system is a
16:11 - government so government is not a single
16:13 - person we cannot say uh let's say Joe
16:16 - Biden is the government of America no we
16:18 - don't say it like that we say government
16:21 - consist of lots of Ministries like
16:23 - Ministry of Health Ministry of Defense
16:25 - Ministry of uh science
16:29 - so operating system is is like a
16:32 - government it consist of several
16:34 - Ministries or we can say modules which
16:37 - modules I'm talking about I'm talking
16:38 - about the modules in the kernel like
16:39 - process manager file manager Etc so
16:42 - operating system is not a single program
16:44 - operating system is a service provider
16:46 - just like the government operating
16:47 - system is the resource manager just like
16:49 - the government so who manages the
16:51 - resources in the country government who
16:53 - provides the service to the people
16:55 - government okay so government controls
16:59 - the country in the same way OS controls
17:03 - everything in the computer okay so let
17:06 - me explain you again so user it
17:09 - communicate to the application of
17:10 - program application of program goes to
17:12 - the kernel operating system kernel then
17:14 - at the lowest level it is Hardware
17:17 - memory or
17:19 - devices okay so now the question arises
17:23 - in the introduction we should also study
17:25 - what are the goals of operating system
17:28 - operating system there are several goals
17:29 - like convenience that is the primary
17:31 - goal of day-to-day operating system
17:33 - which we talk about and then efficiency
17:36 - efficiency means you should use your
17:39 - operating system make use of resources
17:42 - efficiently it should be reliable it
17:45 - means for which purpose operating system
17:48 - was designed that purpose should be
17:50 - achieved what is robustness operating
17:52 - system should be robust robust means
17:54 - strong enough to Bear errors operating
17:57 - system should be scalable operating
17:59 - system should have ability to evolve
18:01 - operating system should be portable it
18:03 - means it should have ability to work
18:05 - across different platforms Let me Give
18:08 - an
18:08 - example Windows operating system that is
18:11 - more portable than Mac operating system
18:14 - Mac operating system only works in the
18:16 - Apple devices whereas Windows operating
18:18 - system can Works in number of devices
18:20 - like Samsung Dell Etc okay so as I've
18:25 - said what is the primary goal of
18:26 - operating system the convenience
18:30 - so so there was a survey taken that
18:33 - which operating system would you prefer
18:34 - Unix or Windows most of the people have
18:37 - chosen Windows why because it was
18:40 - convenient even though Unix was more
18:42 - efficient Unix was more reliable it was
18:45 - more robust so the primary goal of
18:47 - operating system I'm not saying all
18:49 - operating system why because there are
18:52 - some different operating system like
18:54 - realtime operating system which have
18:56 - some deadline strict programs like like
18:59 - we say missile control satellite control
19:02 - nuclear
19:03 - system let's say air traffic control so
19:06 - all of these things have a strict
19:09 - deadline these are known as hard time
19:11 - real operating hard realtime operating
19:13 - system okay and the soft can be said to
19:17 - as ATM in which a deadline is strict
19:19 - deadline even if it's not met then it's
19:21 - not a big problem so in these cases here
19:25 - the main goal is reliability or
19:27 - efficiency in a missile system and is a
19:29 - missile control satellite control
19:31 - nuclear system Air Traffic Control
19:34 - efficiency and reliability are the main
19:35 - goal here convenience do not matter okay
19:39 - so it depends from operating system to
19:41 - operating system that which which is its
19:43 - primary goal either it is convenience or
19:46 - efficiency or reliability and so on what
19:48 - are the functions of operating system
19:50 - processor management these are all
19:52 - self-explanatory functions it manages
19:55 - the processor memory detects the error
19:58 - it's responsible for the security and
20:00 - file management and we'll in detail
20:04 - explain I will explain them all in
20:07 - detail when we move ahead to this module
20:10 - of processor management to memory
20:12 - management these are all chapters okay
20:15 - so these are this is the first lecture
20:19 - let us revise what we have done we
20:20 - started with what is an operating system
20:23 - it's an interface between user and
20:24 - computer components of hardware is
20:26 - memory input output and CPU CPU consist
20:29 - of two control unit and arithmetic logic
20:31 - unit control unit is responsible for
20:33 - control signals that controls the
20:34 - operation and sequential execution of
20:37 - micro operations micro operations are
20:39 - the operations that are carried out on
20:40 - data stored in registers okay we have
20:43 - taken an example and then we understood
20:45 - what is ALU and then memory the two
20:47 - types of memory we have also understood
20:51 - what where is the secondary memory in
20:52 - one architecture how program are
20:55 - executed in one architecture this is an
20:56 - important part we've learned about
20:58 - stored program concept and sequential
21:00 - execution
21:01 - concept any program that has to be
21:03 - executed we've also learned this must be
21:05 - stored in the main memory then this we
21:07 - have learned we have learned how
21:09 - operating system act as a government
21:12 - okay this is the communication how does
21:16 - it communicates the user to Hardware
21:18 - there are two level of interfaces we
21:19 - have seen we have also understood how
21:22 - operating system act as a resource
21:23 - manager what are resources which we are
21:25 - here referring to control program
21:27 - application development
21:29 - simplification it act like a government
21:31 - and then goals and functions of
21:33 - operating system so in the next lecture
21:35 - we'll study types of operating system
21:38 - hello everyone welcome to the operating
21:39 - system course lecture two in this
21:42 - lecture we are going to study mainly
21:43 - about the multiprogramming operating
21:45 - system we are not going to discuss those
21:47 - operating system which could be
21:48 - understood just by the Google search so
21:51 - our main focus is understanding
21:53 - multi-programming operating system we'll
21:54 - start with the introduction and then
21:56 - we'll move in depth okay so these
21:59 - operating system which are batch
22:01 - operating system multi program time
22:02 - sharing real time these are basic
22:05 - operating system and distributed OS and
22:08 - network os are Advanced operating system
22:10 - which has which are also known as
22:12 - multiprocessor operating system so what
22:15 - is multiprocessor and what what is
22:16 - uniprocessor we are going to learn later
22:19 - in the lecture so when the first
22:22 - generation of computer were arrived
22:24 - there were no OS in those computers in
22:26 - second generation magnetic tapes was
22:28 - introduced but then there also there was
22:32 - no operating system in third generation
22:35 - when magnetic disc was introduced which
22:37 - is hard dis or a floppy dis the
22:39 - operating system was
22:42 - introduced the operating system is
22:44 - basically divided into two parts uni
22:46 - programmed and
22:47 - multiprogrammed so the ability of
22:50 - operating system to hold a single
22:52 - program in a memory that is uni
22:55 - programming operating system okay so let
22:58 - us understood understand by the diagram
23:00 - so there are many ready to run programs
23:02 - in the hard disk and there is operating
23:04 - system also present in the hard disk at
23:05 - the time of booting operating system get
23:07 - loaded in the main memory so when
23:10 - booting occurs the operating system gets
23:12 - here in the main memory the area where
23:15 - the operating system resides is s area
23:17 - which is also known as system area and
23:19 - the area where programs get loaded are
23:21 - user area so in uni programming
23:24 - operating system only one out of these
23:27 - ready to run program s will get in the
23:29 - main memory so there is a restriction
23:32 - that only a one program from hard disk
23:36 - can be loaded in the main
23:38 - memory and when the CPU start execution
23:41 - on that program let's say in between the
23:43 - program want Services of iio devices
23:46 - input output devices let's say it is not
23:50 - present in CPU when it has went for the
23:52 - io devices then the CPU is empty and if
23:56 - CPU is empty then the proper utilization
23:59 - of CPU is not possible CPU is Idle we
24:02 - don't want that so in uni programming
24:05 - operating system the drawback is less
24:08 - efficiency less CPU utilization and less
24:11 - throughput we will see I have written
24:13 - all these things which I have said just
24:14 - now so let's understand again so there
24:17 - are various ready to run program in the
24:18 - hard disk these are the programs I'm
24:21 - talking
24:22 - about out of these program one program
24:24 - get loaded in the main memory OS can
24:27 - load only aing single program from the
24:29 - memory okay so if the single program
24:33 - that is loaded is not in the CPU let's
24:36 - say it has moved to the io devices then
24:38 - CPU becomes idle and if CPU becomes idle
24:42 - this is the situation we don't want we
24:44 - want efficient CPU utilization we want
24:47 - efficient CPU utilization because if CPU
24:51 - is idle throughput is less and
24:52 - efficiency is less what is throughput
24:54 - number of program executed per unit time
24:58 - okay so I've written that grut is number
25:00 - of programs completed in a unit
25:03 - time so let me clarify again in uni
25:06 - programming operating system the
25:08 - operating system can load only a single
25:10 - ready to run program from hard disk to
25:12 - main memory and if that program is not
25:14 - in CPU let's say it has gone for iio Io
25:18 - services so it is not in CPU there CPU
25:20 - is not uh working on that program then
25:23 - at that case CPU is Idle we don't want
25:25 - that because if CPU becomes idle
25:28 - the efficiency drops CPU zidle
25:31 - throughput drops what is throughput
25:33 - throughput is number of programs
25:34 - completed in a unit
25:36 - time okay do you know an example of uni
25:39 - programming operating system the example
25:42 - is Ms do Microsoft DOS it was there in
25:45 - the
25:45 - 1990s what is the full form Disk
25:47 - Operating System in MS DOS it was
25:50 - command based there was no GUI and only
25:52 - a single program can be loaded in the
25:54 - main memory what was the objective we
25:58 - want maximum CPU utilization so what do
26:01 - you suggest what do you suggest how can
26:04 - we maximize the CP utilization so we can
26:06 - maximize CP utilization by putting more
26:08 - and more programs there so if one
26:11 - program gets into the io devices or one
26:14 - program empty CPU for Io Services there
26:17 - should be other ready to run program for
26:20 - execution so
26:22 - if the P1 has moved to the io Services
26:25 - CPU will start executing on P2 hence CPU
26:29 - idleness
26:30 - decreases let's say even P2 went for Io
26:33 - Services then then also P3 will be there
26:36 - for CPU to work upon if three P3 went
26:39 - there will be P4 and so on so we want
26:42 - multiprogramming operating system
26:44 - multiprogramming operating system is
26:46 - operating system in which operating
26:48 - system has ability to load multiple
26:50 - program from hard disk to main
26:52 - memory okay so this is multiprogramming
26:56 - operating system operating system can
26:58 - hold hold multiple ready to run programs
27:00 - in the main memory so this is the case
27:03 - here are here is the P1 P1 went for Io
27:05 - Services now P1 the CPU is empty there
27:08 - are various program ready for execution
27:11 - the these are waiting okay so at one
27:14 - time yes this is the point I want to
27:17 - emphasize upon CPU can only execute or
27:21 - or only work upon a single program at a
27:24 - time so this I have written at a time
27:26 - only one program will run in any case in
27:29 - any case I'm talking about even
27:32 - multiprocessor operating system
27:34 - multiprocessor see the the computer
27:37 - which has multiple processor which has
27:38 - multiple CPU in that case also in one
27:41 - CPU there will be only one program that
27:45 - will be worked upon so at at at a time
27:49 - only one program only one will run in
27:51 - any case okay I hope I have clarified
27:54 - you I am absolutely sorry for my bad and
27:58 - nonfluent English because English is not
28:00 - my first language okay but I hope I'm
28:02 - able to speak that much English in which
28:04 - you understand the basic idea which I
28:06 - want to
28:07 - say okay so what we want we want maximum
28:11 - CPU utilization we want maximum
28:13 - efficiency we want maximum
28:15 - throughput so for that case
28:18 - multiprogramming operating system is a
28:19 - better choice okay because CPU idleness
28:22 - has been significantly
28:25 - decreased so multiprogramming operating
28:28 - system gives a impression of
28:30 - multiplexing because CPU is working upon
28:33 - different program first is let's say
28:34 - it's working upon P1 P1 went for iio now
28:36 - it's working on P2 now P2 has been
28:38 - executed P1 came back now it's working
28:41 - again on P1 then P2 then again P3 I hope
28:44 - you're getting the point so it's given a
28:46 - impression of
28:48 - multiplexing impression of multiplexing
28:50 - of CPU among different programs is there
28:52 - in multiprogramming operating system now
28:55 - you have also heard uh
28:58 - term named multitasking operating
29:01 - system so the multi-programming and
29:03 - multitasking operating system are
29:05 - somehow same the Unix family of people
29:08 - says program as a program and windows
29:11 - family of people says program as a task
29:13 - so program is a programming task are the
29:15 - same thing okay now you now you may have
29:19 - doubt then what is process is process
29:22 - and program different we are going to
29:24 - learn that thing in detail in very much
29:26 - detail in the upcoming sections so for
29:28 - now just
29:30 - remember a program in execution is a
29:34 - process okay now let's move ahead now
29:38 - we'll learn the schematic view of
29:39 - multiprogramming operating system so
29:42 - let's say this is secondary storage it
29:43 - was a hard disk which I was talking
29:45 - about it has multiple ready to run
29:47 - programs like P1 P2 and P3 well program
29:49 - task and jobs are same thing these are
29:51 - the same thing just a notation okay so
29:56 - various jobs are loaded in the op in
29:58 - system let's say job one went for the io
30:01 - Services now job two is in execution and
30:04 - job two is in CPU so it is in execution
30:06 - and job three and job four these are
30:09 - ready and waiting for the CPU okay so
30:11 - this is a overall view of
30:13 - multiprogramming operating system let me
30:15 - explain again so this is a secondary
30:16 - storage it has multiple ready to run
30:19 - program that are loaded here let's say
30:20 - job one job two job three and job 4 job
30:23 - one has gone to the io devices job two
30:25 - is now in execution now also the there
30:28 - are two programs waiting and are ready
30:30 - and waiting for the
30:31 - CPU okay so this is a schematic view of
30:34 - multiprogramming operating system so in
30:36 - this case CPU utilization is increased
30:39 - and idleness is
30:41 - decreased now there are two types of
30:43 - multiprogramming also the preemptive one
30:45 - and non preemptive
30:47 - one what is preemptive
30:49 - multiprogramming forceful deallocation
30:52 - from CPU so this job one or let's say
30:55 - job two is in CPU so if a high priority
30:58 - job come here let's say it is job three
31:01 - job three has come there job three is
31:04 - waiting in main memory and it has a more
31:05 - priority then job two then what
31:08 - operating system will do operating
31:09 - system will say hey job two you should
31:11 - go now because a high priority job has
31:13 - come so job three will be there and job
31:16 - two will again be sent in there this is
31:19 - so this is forceful preemption job two
31:22 - has not completed his execution there
31:24 - are instructions remaining for execution
31:27 - in job two but a high high priority
31:30 - process job 3 came so operating system
31:32 - which for will forcefully deallocate job
31:35 - two and will send job three for
31:37 - allocation so this is preemptive
31:39 - multiprogramming forceful deallocation
31:41 - from CPU it can be based either upon
31:45 - priority or time let's say job two is
31:49 - working is is is getting executed from
31:52 - so much time that job three and job four
31:55 - are getting starved these are not
31:57 - getting chance to be there with CPU so
32:01 - what operating system will say operating
32:03 - system will say hey Job 2 you it's been
32:05 - a long time you have been there in the
32:06 - CPU now it's chance for job three and
32:08 - job four to be with CPU so either
32:12 - priority or time on the base of this CPU
32:15 - will forcefully deallocate processes
32:18 - from CPU what is non preemptive
32:20 - non-preemptive is a type of
32:22 - multiprogramming in which nobody will
32:24 - force the program to leave the CPU it
32:26 - will release the CPU voluntarily in
32:29 - which cases either all the instructions
32:31 - are complete now there's no purpose of a
32:33 - job in the CPU because all all the
32:36 - instructions are now complete now why
32:39 - will job be with CPU now okay all
32:41 - instructions are completed the second
32:44 - case arises the job needs IOU job needs
32:48 - input output services so it will leave
32:49 - CPU voluntarily and the third is system
32:52 - call we will learn about this in detail
32:54 - in the later
32:55 - lecture okay so let us revise what we
32:58 - have learned till now so firstly we
33:00 - started with the types of operating
33:02 - system there are various type of
33:03 - operating system batch operating system
33:05 - multiprogramming time sharing realtime
33:06 - Network and distributed distributed and
33:08 - network are Advanced operating system
33:11 - and the rest are basic operating system
33:12 - these are basic operating system these
33:14 - are Advanced okay in the third
33:16 - generation magnetic dis was introduced a
33:18 - secondary storage was
33:20 - introduced which later gave the birth to
33:23 - different type of operating system uni
33:25 - programming and multiprogramming in uni
33:27 - programming the oper system can hold
33:28 - only a single program in the memory
33:30 - whereas in multiprogramming multiple
33:32 - program can be there or can be present
33:34 - in memory so if there is only one CPU at
33:37 - motherboard it is uniprocessor and if
33:39 - there are multiple CPUs at the
33:40 - motherboard these are multiprocessor
33:42 - operating system like I was talking
33:43 - about distributed and
33:45 - network okay so if multiple CP are
33:48 - present then is multiprocessor now let's
33:51 - talk about un programming schematic view
33:53 - so there are several there are several
33:55 - ready to run program in the hard disk
33:57 - now operating system has capability to
33:58 - load only one so P1 is loaded there P1
34:01 - went for execution now P1 is there in
34:03 - the CPU CPU is working upon P1 but P1
34:06 - wants IO services so P1 went P1 empties
34:09 - the CPU and goes to the io devices now
34:11 - CPU is empty it is not working upon any
34:14 - program it is Idle we don't want CPU
34:16 - idleness we want we want to minimize the
34:18 - CPU idess because CPU idleness decreases
34:22 - the efficiency and
34:23 - throughput so if CPU becomes idle then
34:26 - throughput and efficiency are decreased
34:29 - okay so we don't want that we want
34:32 - efficient CF utilization so there is
34:34 - example present MS DOS dis operating
34:36 - system which was introduced in the
34:38 - 1990s command based and it has no
34:41 - graphical user interface so what is our
34:43 - what was our objective to maximize CP
34:45 - utilization multiprogramming operating
34:47 - system is a better choice for that
34:49 - because o can hold multiple ready to run
34:50 - programs if a program is not present in
34:52 - the CPU let's say it's gone for Io
34:54 - Services then there are several other
34:56 - programs waiting to be there with CPU so
34:58 - CPU is never idle but there is a golden
35:01 - point at a time only one will run in the
35:04 - CPU at any case whether it is
35:05 - uniprocessor or
35:07 - multiprocessor so our objective is to
35:10 - maximize utilization maximize efficiency
35:12 - and maximize throughput multiprogramming
35:15 - operating system also gives an
35:16 - impression of multiplexing because CPU
35:18 - is working among different
35:20 - programs what is multitasking
35:22 - multitasking is the same as
35:24 - multi-programming Unix family says
35:27 - program and windows family says task for
35:29 - the same thing now we have learned the
35:31 - schematic view of multiprogramming there
35:33 - are there is a secondary storage a hard
35:35 - disk or a floppy disc anything which has
35:38 - multiple ready to run programs now OS
35:40 - loads all these program several program
35:42 - whichever is the capacity we say degree
35:45 - the amount of programs let's say four
35:48 - programs are there in the main memory so
35:51 - the degree is four operating system can
35:53 - load four programs in the main memory so
35:56 - the degree of multiprogramming is four
35:59 - okay now job one has moved to the io
36:02 - devices job two is in execution still
36:04 - there are job three and job four ready
36:05 - and waiting for the CPU so this is a
36:07 - schematic view CPU utilization is
36:09 - increased and ID is decreased now we
36:10 - have learned about types of
36:11 - multiprogramming preemptive and non-
36:13 - preemptive preemptive means forceful
36:15 - deallocation from CPU in non preemptive
36:17 - nobody will force the program to leave
36:18 - the CPU it will leave the CPU in only
36:20 - three cases either all the instructions
36:22 - are complete it needs an IO service or
36:25 - there's a system system call Okay so
36:27 - what is the drawback of multiprogramming
36:29 - operating system multi-programming
36:31 - operating system can lead to starvation
36:34 - or indefinite waiting for other
36:37 - programs lack of interactiveness and
36:39 - responsiv how these are the tropics let
36:41 - me explain you so let's say there is a
36:44 - high priority task let's say antivirus
36:48 - antivirus wants to run there so let's
36:50 - say P1 is that antivir task now there
36:52 - are several this is in the CPU people in
36:54 - the CPU now there are several the task
36:57 - which are waiting P1 has been the
37:01 - antivirus scan has been going on since 2
37:03 - hours now these tasks are starving to be
37:07 - there with CPU but this is not allowed
37:10 - this is a high priority task so response
37:13 - time for P2 P3 and P4 is significantly
37:16 - decreased interactiveness is decreased
37:18 - starvation or indefinite waiting for the
37:21 - other programs is there because P2 P3
37:24 - and P4 do not know when will P1 leave
37:26 - the CPU so so these are the drawback of
37:28 - multiprogramming operating system or
37:31 - specifically saying non- preemptive
37:33 - multiprogramming operating
37:38 - system so what do you think the recent
37:40 - operating system like Unix Linux and Mac
37:44 - operating system are they non-preemptive
37:46 - or preemptive so I hope you have guessed
37:49 - correctly these are preemptive operating
37:51 - system because non- preemptive
37:53 - introduces starvation which is
37:56 - undesirable
37:58 - so Windows 95 till Windows 11 Unix Linux
38:02 - and Mac these operating system are
38:04 - preemptive operating system because it
38:05 - improve responsiveness by forceful
38:07 - deallocation by operating system so that
38:09 - other rating program can get a chance to
38:12 - run on CPU okay so preemption is based
38:15 - on two things it's either on time or on
38:18 - priority so let's say operating system
38:19 - has given 10 seconds for
38:21 - PX NE and P and PX neither completed nor
38:25 - it went for Io so what operating system
38:27 - will say hey PX now you need to leave so
38:30 - these operating system are called as
38:32 - multiprogramming time shared operating
38:34 - system and let's move to the next part
38:37 - that is
38:38 - priority so PX was there enjoying with
38:41 - the CPU now a high priority task come
38:44 - let's say py and if priority of Y is
38:46 - greater than priority of X then OS
38:49 - remove PX from the CPU and let py enter
38:51 - the CPU because it has higher
38:53 - priority so preemption is done on two
38:55 - things time and priority if if it is
38:57 - done on time these are also known as
38:59 - time sharing operating
39:00 - system so this is a better schematic
39:03 - view of multitasking or multiprogramming
39:05 - operating system so if I say what is
39:08 - multitasking operating system then what
39:10 - is the difference between multitasking
39:11 - and multiprogramming then you can say a
39:14 - preemptive multiprogramming operating
39:16 - system is a multitasking operating
39:18 - system I hope you have understood very
39:21 - well till now so this is another
39:23 - schematic view a more detailed one so
39:25 - what happens first a job creation happen
39:27 - first and then it is moved to the ricq
39:31 - Don't Be Afraid by these names RQ IQ
39:33 - these are just uh a a way to symbolize
39:36 - things we are going to learn in detail
39:39 - in the section two Process
39:43 - Management okay so so the job is created
39:46 - first and then it has moved to the
39:48 - readyq when it is ready it stores ready
39:51 - to run program this is ready this is a
39:52 - type of data structure okay it is in the
39:55 - memory so scheduler is there which
39:58 - selects out of ready to run program
40:00 - which program should should go to the
40:02 - CPU let's say a program is there let's
40:05 - say P1 P1 is scheduled so P1 will be
40:07 - there on CPU now it will either be
40:10 - terminated so when in which cases P1
40:12 - will leave CPU P1 will leave CPU in case
40:14 - of job termination or it wants an IO
40:16 - service so this is a part where it is V
40:20 - left CPU for Io services so it will
40:23 - request for Io there will be SE there
40:25 - may be several other program which were
40:27 - already there requesting for the iio so
40:29 - it has to wait in the queue and then it
40:33 - will get the io Services then it will go
40:36 - again in the RQ and and the cycle
40:38 - continues okay so when all the
40:41 - instructions are completed the job will
40:43 - get
40:44 - terminated now the important part comes
40:47 - there must be some architectural
40:49 - requirement for implementing a
40:50 - multiprogramming operating system
40:52 - architecture means Hardware requirement
40:55 - okay so let's discuss these there are
40:56 - three hard requirements so the first is
40:59 - secondary storage device which I was
41:01 - talking about let's say hard disk or
41:03 - oper input output devices these are the
41:05 - same must be dma compatible now you must
41:09 - be wondering what is dma and what does
41:11 - it mean by being dma compatible so we
41:14 - have discussed in detail in computer
41:16 - organization architecture course if you
41:18 - want to learn deep in the if you want to
41:20 - learn about dma for now
41:23 - just get this dma is direct memory
41:27 - access okay so what's the purpose of
41:30 - being DM compatible it means secondary
41:32 - storage devices must be efficient in
41:35 - data transfer between secondary storage
41:38 - and Main memory okay so first
41:40 - requirement is the secondary storage
41:42 - devices should be dma
41:44 - compatible the second requirement is
41:47 - memory system should support address
41:50 - translation now what is this address
41:52 - translation let me clarify so there is a
41:55 - program which is running on the CPU so
41:57 - how does it work it works like it
41:59 - generates The Logical address what is
42:01 - logical address it's a type of address
42:03 - to access its instruction or data from
42:05 - Main memory okay so what is The Logical
42:08 - address let's say let's understand by
42:10 - real word
42:11 - analogy okay so you come to me and you
42:15 - say hey shage do you know John's house I
42:18 - say yes from here you just go straight
42:20 - 200 M and turn left there's the John's
42:22 - house so this is a logical address this
42:25 - is your logical address and what is a
42:28 - physical address these are the exact
42:30 - coordinate of Jon's house I hope you are
42:32 - getting the point
42:34 - so program generate a logical address to
42:37 - access its instruction or data from Main
42:41 - memory okay and physical address is
42:45 - needed to access instruction or data
42:47 - from Main memory so now there must be a
42:51 - translator in between which translates
42:53 - or convert logical address into physical
42:56 - address so yes there exist a translator
42:58 - we call as memory management unit so
43:01 - what is what is its work its work is to
43:04 - trans or convert logical address into
43:07 - physical address physical address is the
43:09 - actual address of instruction and data
43:11 - unit in the main
43:13 - memory okay so now the question arises
43:17 - what is the need of logical address and
43:19 - physical address so the thing is
43:22 - security with one address let's say only
43:24 - physical each program would directly
43:26 - access physical memory Lo
43:27 - locations so let me clarify with the
43:30 - same example which we have taken so this
43:31 - is
43:32 - me this is you and this is John's house
43:35 - I said so what I said go 200 M and take
43:39 - left so this is
43:42 - The Logical address I have given just to
43:46 - you now if I given let's say the exact
43:49 - coordinate of John's address let's say
43:52 - 200 and 200 just take an example random
43:55 - example now if someone get to know this
43:58 - this will be a big problem let's say
44:01 - what I have told you if someone get to
44:02 - know that I have said you just know to
44:05 - go 200 M straight and then take left
44:08 - suppose this information is e dropped by
44:12 - someone else let's say Alice now Alice
44:15 - Alice has location different so if Alice
44:18 - tried to do do that 200 M and then to
44:22 - left it will not reach the John's house
44:25 - so it is for the security purpose that
44:28 - only logical address is being shared not
44:30 - the physical address so let's understand
44:33 - it formally so with one address only
44:36 - physical each program would directly
44:38 - access physical memory locations a buggy
44:40 - program could overwrite memory used by
44:41 - another program corrupting data and
44:44 - causing crashes logical addresses
44:46 - prevent this by creating an abstraction
44:48 - layer program operate with logical
44:50 - addresses and the O translate them to
44:52 - the physical addresses we are talking
44:54 - about this the memory management unit it
44:56 - translates logical address to the
44:58 - physical address ensuring program do not
45:01 - interfere with with each other's memory
45:03 - space so why we need two addresses just
45:06 - for the security purpose and in the
45:09 - later part of this course we will learn
45:11 - in very detail about logical address and
45:13 - physical address its conversion paging
45:16 - so the course has a lot of things to
45:18 - offer now the third Hardware requirement
45:20 - is CPU CPU must support dual mode
45:24 - operation so what is dual mode operation
45:26 - we are talking about user mode and
45:27 - kernel mode I'm sure you have heard
45:29 - about it user mode and kernel mode so
45:32 - what are user mode and kernel mode Let's
45:34 - discuss so user mode is a non-privileged
45:37 - mode so what is the meaning of privilege
45:40 - and being non-privileged so privilege
45:42 - instructions are like let's let's take
45:44 - an example it's like an ambulance on the
45:46 - road ambulance is privileged it does not
45:49 - have to follow the traffic symbols or
45:52 - any other traffic rule it is privileged
45:54 - for that because it is a priority to
45:56 - take patient as soon as possible to the
45:57 - hospital or let's say the Convoy of
45:59 - Chief Minister chief minister do not
46:01 - have to stop at the traffic right
46:05 - traffic light so these are the
46:07 - privileged people okay who are the
46:10 - non-privileged people the Common Man
46:11 - common man is a non-privileged people in
46:13 - the same way in the same way the user
46:15 - applications like Microsoft PowerPoint
46:18 - Microsoft Chrome Microsoft Word oops I
46:21 - have said Microsoft Chrome that mistake
46:24 - the Chrome the word the PowerPoint these
46:26 - these are the user applications these
46:28 - are like the common man on the road but
46:31 - there are some OS level kernel routine
46:34 - programs just like the chief minister
46:37 - and the ambulance which are
46:40 - privileged and what is the privilege
46:43 - they are getting that they will
46:45 - atomically perform no one will stop them
46:48 - in between when they are executing they
46:50 - will perform non preemptive
46:52 - multiprogramming and the user level user
46:55 - applications
46:57 - preemptive these are just the normal
46:58 - costs so user mode
47:02 - is preemptive mode and kernel mode is
47:05 - non- preemptive mode because it is
47:08 - privileged so what are the example of
47:10 - user applications I have given Microsoft
47:12 - PowerPoint or any other random game you
47:14 - are playing these are example of user
47:15 - application what is the example of os
47:17 - level colel level routines Process
47:19 - Management file management system calls
47:21 - these are included in the privilege
47:24 - instructions so what does this signify
47:27 - the one and zero I have written besides
47:30 - user and kernel this symbolizes which
47:33 - mode we are in currently so there is
47:37 - there is a register in CPU which says
47:39 - PSW register that is processor status
47:42 - word it has a bit which we call is at
47:44 - mode bit if the mode bit is zero the
47:47 - mode is Kernel if the mode bit is one
47:49 - the mode is user
47:51 - mode okay so many times it becomes
47:54 - necessary to shift modes using user to
47:57 - Kernel or kernel to user so if some user
48:00 - application wants to Avil OS kernel
48:02 - level Services then mode shifting is
48:06 - required okay let let me read it again
48:08 - if some user application wants to Avail
48:11 - OS kernel level Services then more
48:13 - shifting is must because kernel level
48:16 - programs are privileged programs they
48:17 - run atomically and user level programs
48:20 - are non-privileged programs so if user
48:22 - applications want to Avail some
48:24 - privilege instruction or Os services
48:27 - then mode should be shifted from user to
48:29 - Kernel okay in that case mode shifting
48:32 - is
48:34 - required okay so let me read this you
48:36 - will get more idea about what are what
48:38 - is actually kernel mode and a user mode
48:40 - in kernel mode the executing code has
48:42 - complete and unrestricted access to the
48:44 - underlying Hardware so I am talking
48:47 - about this so the upper layer contain
48:50 - users and then the users have access to
48:53 - the system programs application programs
48:56 - and the user program these all run in
48:58 - user mode Library routines also run in
49:00 - the user mode and then there exists some
49:04 - OS some Services which is availed only
49:07 - when their kernel mode is activated like
49:10 - system calls operating system or
49:13 - accessing the computer hardware which
49:15 - required kernel mode so the more we go
49:18 - up the more abstraction we achieve the
49:21 - more we go less the abstraction become
49:24 - less okay so now let let's discuss what
49:27 - I was
49:28 - discussing so in kernel mode the
49:30 - executing code has a complete and
49:31 - unrestricted access to the underlying
49:33 - Hardware it can execute any CPU
49:35 - instruction and reference any memory
49:37 - address so kernel mode can do anything
49:39 - in the computer so kernel mode is
49:42 - generally reserved for the lowest level
49:44 - most trusted functions of the operating
49:46 - system so we can we here we can also see
49:48 - the kernel mode is for the lowest level
49:52 - things so the kernel mode is generally
49:54 - reserved for the lowest level most Trust
49:56 - functions of the operating system
49:58 - because crashes in the kernel mode are
50:00 - catastrophic they will halt the entire
50:03 - PC so if kernel mode get crashed the
50:07 - change will be irreversible so let's
50:10 - discuss now about the user mode in user
50:11 - mode the executing code has no ability
50:14 - to directly access the hardware or
50:15 - reference memory so a user mode has a
50:17 - scope of till this it can at Max access
50:21 - the library
50:23 - routines okay so code running in the
50:25 - user mode must delegate to the system
50:27 - apis what are the system apis we are
50:30 - going to learn in detail in the next
50:31 - lecture let me tell you a little bit
50:33 - about it system apis are the interface
50:36 - which help to Transit from user mode to
50:40 - Kernel mode to access Hardware or memory
50:42 - so code running in user mode must
50:44 - delegate to the system API to access
50:46 - Hardware or memory due to the protection
50:48 - afforded by this sort of isolation
50:51 - crashes in the user mode are always
50:53 - recoverable because if something let's
50:56 - say if Google Chrome chist the operating
50:59 - system will be preserved because it is
51:02 - isolated so the crashes in the user mode
51:06 - are always recoverable unlike kernel
51:09 - mode crashes so most of the code running
51:11 - on your computer will execute in user
51:14 - mode
51:16 - so let's revise everything because it's
51:19 - it was a long
51:21 - lecture so first we started with the
51:23 - types of operating system then we
51:25 - understood the different types of
51:27 - operating system like uni program and
51:28 - multi program operating system in uni
51:30 - program the operating system can load
51:31 - only a single program from hard disk to
51:33 - main memory this introduces CPU idleness
51:37 - and it decreases through poent
51:39 - efficiency example of uni programming is
51:41 - dis operating system by macrosoft now
51:44 - our objective was to maximize CP
51:45 - utilization hence we introduced
51:47 - multiprogramming operating system in
51:49 - which operating system can load
51:50 - different programs from hard disk to
51:52 - main memory and if a program is not
51:54 - present in the CPU there are several
51:55 - other programs waiting to be with the
51:57 - CPU a golden rule was that at a time
51:59 - only one program will run in any case so
52:03 - this increases the CPU utilization it
52:05 - increases the efficiency it increases
52:07 - the throughput and it also gives
52:09 - impression of multiplexing of CPU among
52:11 - different programs program and task is
52:13 - the same thing Unix family people say
52:16 - program and windows family say
52:18 - task now there's a schematic view of
52:20 - operating of multiprogramming operating
52:22 - system there is a secondary storage
52:24 - there is a operating system in the S
52:25 - area and there are several jobs in the
52:27 - user area so if one job has gone to the
52:30 - I devices one is being executed there
52:32 - are several other like job three and job
52:34 - four ready and waiting for the CPU CPU
52:36 - utilization is increased and idleness is
52:38 - decreased there are two type of
52:39 - multiprogramming preemptive and non-
52:41 - preemptive preemptive means forceful
52:43 - deallocation and non PR means nobody
52:45 - will force the program to leave the CPU
52:46 - it will leave CPU voluntarily in when
52:49 - what are the cases either all the
52:51 - instructions are complete the job is
52:52 - terminated or it needs an IO services or
52:55 - there's a system code we'll learn in
52:57 - detail what the system called in the
52:58 - next lecture what are the drawbacks of
52:59 - multiprogramming the drawback is it
53:01 - leads to starvation lack of
53:03 - interactiveness or
53:04 - responsiveness so the preemptive
53:07 - operating system preemptive types of
53:08 - multiprogramming improve the
53:09 - responsiveness by forceful
53:11 - deallocation the types the current
53:14 - operating system which we are using like
53:15 - Windows Linux Unix Max are preemptive
53:18 - operating
53:20 - system
53:22 - so preemption is based on time and
53:25 - priority if it is based on time then we
53:26 - say it's time sharing and if it's based
53:28 - on prty that there is no specific name
53:30 - just remember this if a high priority
53:32 - Tas come then CPU will throw the low
53:35 - priority task from the CPU so operating
53:37 - system will throw the low priority task
53:39 - from the CPU pardon me multitasking
53:41 - operating system is same as
53:43 - multiprogramming with preemption okay so
53:46 - this is another schematic view what are
53:47 - the architectural requirement the first
53:49 - is second day storage devices should be
53:51 - dma compatible what does it mean so the
53:53 - data should be transferred between
53:55 - secondary storage and memory efficiently
53:57 - memory system should support address
53:59 - translation it means logical address
54:01 - should be translated to physical address
54:03 - for the program to access instruction of
54:05 - data from the main memory why we need
54:07 - two addresses because of security
54:09 - reasons the processor should support
54:11 - dual mode what are the Dual mode user
54:13 - mode and kernel mode user mode has a
54:14 - mode bit of one and kernel mode has a
54:16 - mode bit of zero user mode have
54:19 - non-privileged instructions and kernel
54:21 - mode is privileged it is non-preemptive
54:23 - and it runs
54:25 - atomically so there is a mode bit which
54:28 - can be either zero or one Z symbolizes
54:29 - kernel mode and one symbolizes user mode
54:32 - the mode bit is in the register which
54:33 - register PSW processor status world so
54:36 - many times it becomes necessary to shift
54:38 - modes when it is necessary if a user
54:40 - application wants to Avail OS kernel
54:42 - level services so we have discussed in
54:44 - the end what is a kernel mode and user
54:46 - mode now in the next lecture we are
54:48 - going to learn how the mode shifting is
54:50 - done what is an interupt what is fork
54:52 - and then we will end the chapter one
54:55 - that is introduction background and then
54:58 - from the next to next lecture we'll
55:00 - start the new
55:02 - section Process
55:05 - Management hello everyone welcome to the
55:08 - operating system Master course problem
55:10 - solving session one of the section
55:12 - introduction and background so I have
55:14 - given you the dppp in the previous
55:15 - lecture I hope you have solved that and
55:18 - now you are seeing the solution see as I
55:21 - have said in the course preview if you
55:22 - failed to solve the DPP before and you
55:24 - are directly seeing the solution you are
55:26 - not going to appreciate the beauty
55:28 - behind the question the mistake which
55:30 - you may make and you have missed that
55:33 - okay you will fail to analyze where you
55:36 - are wrong you
55:38 - will never ever know where you are
55:40 - lagging in the
55:41 - concepts okay so I sincerely advise you
55:45 - to First solve the DPP and then see the
55:47 - solution okay so now let's move to the
55:50 - questions so the first question is
55:52 - multiple choice question it means out of
55:54 - these four choices only one is correct
55:55 - so let start consider the following
55:57 - statements operating system
55:59 - implementation has architectural
56:01 - constraints this is entirely true we
56:03 - have discussed it so many times let's
56:05 - take another example uh a a smartphone
56:09 - operating system cannot be implemented
56:11 - over a
56:12 - desktop operating system implementation
56:16 - have architectural constraints the
56:18 - second part says operating system is the
56:20 - set of utilities this is true we have
56:23 - given a definition of operating system
56:25 - based on this operating system is a set
56:27 - of utilities which simplifies
56:29 - application development I hope you
56:31 - remember that now so option C is correct
56:34 - both one and two are correct okay let's
56:36 - move to the question number two
56:38 - operating system working on strict
56:40 - deadlines are time sharing no realtime
56:43 - operating system yes this is true
56:45 - realtime operating system works on the
56:47 - strict deadlines and have time
56:49 - constraints for example like fire alarm
56:51 - system hard pacemaker missile control
56:54 - these are example of strict deadline or
56:56 - realtime operating
56:58 - system what must be the primary goal for
57:00 - a hard realtime operating system this is
57:03 - efficiency and only
57:04 - efficiency yeah it after efficiency
57:07 - reliability and robustness may come but
57:09 - the primary goal is the efficient
57:11 - convenience is not the primary goal it
57:13 - is primary goal for for some other
57:15 - operating system like mobile operating
57:17 - system or laptop operating system like
57:19 - Microsoft and Mac the convenien is
57:23 - primary goal for them but for hard
57:25 - realtime operating system like missile
57:27 - control can you afford a missile control
57:28 - to be inefficient no the consequences
57:32 - will be catastrophic then okay so the
57:35 - primary goal will be efficiency question
57:37 - number four this is a multiple select
57:39 - question it means out of these four one
57:41 - or more may be correct okay which of the
57:44 - following statement is our correct
57:45 - during booting OS is loaded into disk
57:47 - from Main memory no the opposite is true
57:50 - OS is loaded from disk to main memory
57:54 - during time of booting okay so this is
57:57 - false the area of memory where operating
57:59 - system is stored is known as the system
58:01 - area yes this is true I have said that
58:03 - this area is the system area and the
58:05 - area where programs or the process are
58:07 - stored are are user area so this was the
58:11 - system area this was the user area uni
58:13 - programming can load and execute a
58:15 - single program in a memory this is true
58:18 - yes it can load and execute only a
58:20 - single program in the memory uni
58:22 - programming suffers from idleness of the
58:24 - CPU this is also true because if a CPU
58:29 - goes for I device uh what I'm saying if
58:32 - the process leave the CPU for some IO
58:34 - Services the CPU is Idle then CPU has
58:37 - nothing to do so in uni programming CPU
58:41 - or unit programming suffers from the
58:43 - idleness of CPU in case of
58:45 - multiprogramming if one process goes for
58:47 - Io the other came for execution CPU will
58:50 - not remain as Idle as was in the uni
58:52 - programming okay so let's move to the
58:55 - question number five I hope the concept
58:57 - was clear for question number four it is
58:58 - a multiple choice question throughput is
59:02 - throughput is total number of program
59:04 - completed per unit time this is as
59:05 - simple as that this is false this is
59:07 - false this is false total number of
59:08 - program loaded now total number of
59:10 - program completed per unit time this was
59:12 - important question number six preemptive
59:15 - process have forceful deallocation this
59:17 - is true better response time yes this is
59:20 - true for example a process has been with
59:22 - the CPU with a a very long time and the
59:24 - other process which are waiting the RQ
59:26 - are starving so what OS will do OS will
59:29 - forcefully deallocate that process from
59:31 - CPU and will give other process waiting
59:34 - a chance to be with the CPU so a
59:37 - response time it's it is it has a better
59:39 - response time than non-preemptive
59:42 - processes question number seven which of
59:44 - the following statements are true
59:46 - non-preemptive process can lead to
59:47 - starvation yes this is the thing which I
59:49 - have discussed now non preemptive
59:51 - process is a good response time now
59:52 - preemptive process has a good response
59:54 - time noncp process can release CP
59:57 - voluntarily they always release CP
59:59 - voluntarily either in the case of
60:01 - execution of all instructions or some
60:04 - system call or IO call so for that for
60:06 - those reason non-preemptive process
60:09 - release the CPU they cannot be
60:11 - forcefully deallocated from the CP
60:13 - question number eight function of
60:15 - operating system include Resource
60:17 - Management yes reliability uh no
60:20 - reliability is the goal of operating
60:21 - system it is not the function security
60:24 - yes security is the function control
60:26 - over system performance yes this is the
60:28 - function so reliability is the goal it
60:30 - is not the
60:31 - function so are there any more questions
60:34 - no the dpb is over now so I hope you got
60:38 - the point you need to First solve by
60:40 - yourself and then see the solution
60:42 - whether you have Sol it correctly or not
60:44 - okay
60:51 - goodbye welcome to the operating system
60:53 - Master course lecture 3 in this lecture
60:56 - we will learn more about user mode and
60:59 - kernel mode and we will see how mode
61:01 - shifting is done between user and kernel
61:03 - mode so we used to represent user and
61:05 - kernel mode like this so this is the
61:07 - user mode the kernel mode these are some
61:09 - user applications user applications are
61:12 - those application which you use like
61:14 - Google Chrome the Microsoft PowerPoint
61:16 - any game you play these are user
61:18 - application and they run in preemptive
61:20 - fashion it means non-atomic fashion it
61:23 - means that operating system can
61:25 - forcefully de locate if a high priority
61:28 - process has come okay and there is a
61:31 - kernel mode kernel mode in kernal mode
61:34 - OS program resides these are non
61:36 - preemptive and they run atomically they
61:38 - cannot be forcefully preemptive they
61:40 - cannot be forcefully deallocated from
61:42 - CPU by operating system so in CPU we
61:45 - have seen there is a registor named
61:47 - processor status World which has a bit
61:49 - named mode bit it could be zero or one
61:52 - zero represents kernel mode and one
61:54 - represents the user mode so we have seen
61:56 - that operating system is a service
61:58 - provider and user programs are the
61:59 - service user and whenever we need some
62:02 - operating system Services we need to
62:04 - shift our mode from user mode to Kernel
62:06 - mode and when our when our motive got
62:09 - completed after the completion of that
62:11 - service we need to switch back from
62:13 - kernel mode to user mode so this is the
62:15 - main objective of our course we will
62:17 - learn how this mod shifting done how the
62:20 - mode shifting is
62:21 - done
62:23 - and why it is necessary so we have seen
62:27 - that kernel level program are privileged
62:29 - program they run they have more rights
62:32 - than user level applications so whenever
62:35 - the user application want to get
62:38 - privileged or want some more rights the
62:41 - mode is shifted from user to gal mode
62:44 - okay so that's why the mode shifting is
62:47 - necessary because if user application
62:49 - want to Avail kernel level Services it
62:52 - has to shift mode from user to Kernel
62:54 - mode now I have also written a word
62:56 - named API so what is an API let's
62:59 - understand by an example so in India
63:00 - here we have
63:02 - EAS that act as an interface between the
63:05 - common people and the government let's
63:07 - let's represent government with a
63:08 - rectangle so these are
63:12 - eitas let's say government has issued a
63:15 - service of the citizenship
63:17 - identification card here in India it is
63:19 - known as AAR card AAR card so I want to
63:22 - Avail that Adar card that citizenship
63:25 - identi ification card from the
63:27 - government so I will not go directly to
63:29 - the any Ministry and will say I want an
63:31 - AAR card I will go to the eitas that
63:33 - will help me to Avail the service of AAR
63:36 - card given by the government for the
63:38 - people so to Avail those Services I will
63:41 - go to the emitra not the government in
63:43 - the same way we'll go to the application
63:46 - programmer interface then API which will
63:48 - tell us what OS Services we can
63:51 - Avail okay so now we will learn the
63:54 - implementation of mod shifting via
63:57 - application programmer interface that is
63:58 - API or seci what is Sci I also written
64:01 - here SCI is system call interface so
64:05 - either application programmer interface
64:06 - or a system call interface we'll learn
64:09 - the implementation of mode shifting via
64:11 - them okay so let's consider a program
64:15 - main int a b c these are the Vari
64:18 - variable I have declared then B = to 1 C
64:22 - = to 2 and then A = to B plus C so user
64:25 - program prr like a c program run in
64:28 - kernel mode no run in user
64:33 - mode so a user program like a c program
64:35 - run in user
64:37 - mode okay so I by mistake I have written
64:40 - this you need to correct them in your
64:41 - notes also okay so how this is
64:45 - implemented so firstly it will go to the
64:47 - compiler the compiler will translate it
64:49 - into instructions and then the ready to
64:53 - run
64:53 - programs that is the set of instructions
64:56 - will be loaded into main memory and then
64:58 - CPU will execute the instruction one by
65:00 - one and in this way these com these
65:03 - programs are executed now let's say I
65:05 - have also included a function here I
65:08 - also included a function okay so this is
65:11 - a user defined function so user defined
65:13 - functions are always implemented in user
65:17 - mode okay so let's say in this user
65:19 - defined function I have also defined I
65:22 - have also used print statement let's say
65:24 - print f percentage D and K we are
65:27 - printing the K
65:29 - value now tell me what is print F so
65:33 - print f is a predefined function we say
65:36 - it's a buil-in function or we also say
65:38 - it's a library function now I ask you
65:42 - where is the print F defined see f is
65:44 - defined in some let's say in
65:47 - another after the main f is defined okay
65:50 - now I ask you where is the print of
65:52 - defined in C program we write hash
65:55 - include
65:59 - std. do you think the print F defined in
66:02 - this file if you think so you are wrong
66:05 - print T is not defined in The Hider
66:07 - files print T are defined in the library
66:11 - file in header file in header file like
66:13 - stdi stdi Doh this only contain the
66:17 - function declaration or we also say that
66:19 - a function
66:20 - prototype not the function
66:24 - implementation the then where is the
66:26 - print T defined print T defined in the
66:29 - library files which has extension of
66:32 - Li so you must remember this C basic
66:35 - that print f is not defined in the
66:37 - header file it is defined in the library
66:39 - files then what is the use of header
66:41 - file it is used in type checking in
66:44 - syntactic correctness and if the proper
66:46 - argument are passed or not to check this
66:49 - the header file is there the function
66:50 - declaration is there but implementation
66:52 - of print f is not present in the header
66:54 - file so the implementation is present in
66:56 - library file like do a liary file
66:59 - anyway whether it is a predefined
67:01 - function or a user defined function all
67:04 - of both or or sorry both are executed in
67:09 - user mode pardon me English is not my
67:11 - first language that's why but I can
67:13 - speak well enough to make you understand
67:16 - the basic idea what I am trying to say
67:18 - okay so anyway whether it is a
67:20 - predefined function or a user defined
67:22 - function both are executed in user mode
67:26 - okay only operating system only
67:29 - operating system kernel routines or
67:31 - operating system service
67:33 - routines service
67:35 - routines routines or system
67:38 - calls system calls are executed in
67:41 - kernel mode rest functions like
67:43 - predefined function or built-in function
67:46 - we also say
67:47 - that and user defin function both are
67:50 - executed in user mode so which functions
67:53 - are executed in kernel mode or operating
67:55 - system service routine or system
67:58 - calls I hope you have got the idea
68:01 - so so why do predefined functions and
68:05 - user defined functions are executed in
68:07 - user mode simply because they are
68:09 - written by
68:10 - users now you may argue that printf is
68:15 - not or you can argue that in stdi file
68:19 - the print F declaration is there in I
68:22 - file the printf implementation is there
68:25 - I have not written them no you have not
68:27 - written but these are present in the
68:30 - compiler then I guess if they are
68:32 - present in the compiler they should be
68:34 - run by kernel level modes no you are
68:37 - wrong because compilers are not the part
68:40 - of operating system compiler is just a
68:42 - user application program like your other
68:45 - programs or other applications like
68:47 - Microsoft Excel compiler is no different
68:49 - from Microsoft Excel in terms of user
68:52 - and kernel mode so the other programs so
68:55 - the above program didn't require any
68:57 - mode shifting it can be executed
69:00 - completely in the user
69:02 - mode okay so let's take a program which
69:05 - require mode shifting so now I have
69:08 - included a system call in our program
69:11 - that is
69:12 - fork okay so main B = to 1 Cal to 2 the
69:16 - same program was there but I have
69:18 - included now a system call so what is a
69:20 - fork and what does it do so execution of
69:24 - fork result in creating child
69:27 - processes okay so what is a fork I have
69:29 - told you it result ex its execution
69:32 - results in creation of child
69:36 - process and what does it do it's a fun
69:39 - it's a type of function it's a special
69:41 - function and that special function is
69:43 - known as system call if you are conf
69:46 - getting confused between this definition
69:48 - don't worry in the next lecture we will
69:50 - go more and more deep in this part okay
69:54 - or we will take some good examples in
69:57 - the DPP which will help you to build
70:00 - your understanding on Fork so what is a
70:03 - fork Fork execution results in creation
70:07 - of child processes and it's a type of
70:10 - function it's a special function and
70:12 - these special functions are known as
70:14 - system calls what are system calls
70:16 - system calls are those functions which
70:18 - are called to the operating system and
70:21 - Fork is defined or implemented in the OS
70:23 - kernel Fork is an operat system routine
70:26 - so it cannot be directly executed by
70:28 - user mode so to execute this program we
70:32 - need to shift our mode from user to
70:36 - Kernel mode now we will see how to Avail
70:39 - the fork services offered by the
70:41 - operating system now the main concept
70:43 - starts of mode
70:44 - shifting so I have using using some uh
70:48 - short forms like CT CT means compile
70:50 - time BSA means branch and save address
70:52 - if you are getting confused what is a
70:54 - branch and save address and what is SVC
70:56 - supervisory call don't worry we will
70:58 - learn in detail what are those in our
71:00 - computer organization and architecture
71:02 - course for this course you just need to
71:04 - know what I'm going to tell for now okay
71:08 - so this was our program main we started
71:10 - with the main then there are some lines
71:12 - which we don't have to bother about then
71:14 - there is a function which is a
71:16 - predefined function or we can say a user
71:18 - defined function so at compile time user
71:20 - defined functions get transferred or get
71:24 - converted into instructions which we see
71:28 - as branch and save address and branch
71:29 - and save address instructions are non
71:32 - privilege
71:33 - instruction so if you are getting
71:34 - confused what is BSA do not worry we
71:36 - will learn in detail in our COA
71:39 - course okay so these branches save
71:43 - instructions save address instructions
71:44 - are executed in user mode and if an OS
71:50 - routine when it is compiled it is
71:53 - converted into SVC SVC is supervisory
71:56 - call so this supervisory call is
71:59 - executed in kernel mode because the fork
72:02 - requires some additional privileges
72:04 - because it has to replicate the parent
72:08 - process it has to create child processes
72:12 - so SVC includes some privilege
72:15 - instructions so what we need what we
72:18 - need
72:20 - now we need to change our mode from user
72:23 - to Kernel mode okay so let me let me
72:26 - clarify some of the basics high level
72:28 - program when it is compiled it's
72:30 - converted into instruction in the same
72:32 - way when user defined program that is
72:34 - written in the high level language when
72:36 - compiled it is converted into BSI
72:38 - instructions which is branch and C
72:40 - instruction and these are non-privileged
72:42 - instruction so if user defined function
72:45 - is compiled it is compiled to a
72:47 - non-privileged instruction and if an OS
72:50 - routine is compiled it is converted to
72:53 - the privilege instructions or it is also
72:55 - known as soft interrupt instructions so
72:58 - what is SVC SVC is supervisory call so
73:01 - when supervisory call at runtime will
73:04 - generate an software interrupt so
73:07 - there's interrupt interrupt means
73:10 - informing the operating system of some
73:12 - activity so there are two type of
73:13 - interrupt software interrupt and
73:15 - Hardware
73:16 - interrupt so we are seeing the example
73:19 - of software interrupt now let's take the
73:21 - example of Hardware interrupt why I'm
73:22 - writing the spelling wrong again and
73:23 - again Hardware interupt let's say
73:25 - Hardware interrupt is you are playing a
73:28 - game let's say rocket League at a
73:30 - CPU at a low processor and a low Ram
73:34 - let's say 2 GB Ram you you have
73:36 - installed a rocket League game on your
73:38 - 2GB Ram computer so the computer is
73:40 - getting Hot and Hot so an interrupt is
73:43 - generated from the hardware please close
73:45 - down these programs the CPU temperature
73:48 - is rising so these are Hardware
73:50 - interrupts and what are software
73:52 - interrupts software interrupts we are
73:54 - discussing now so SVC super supervisory
73:57 - call instructions which are generated
73:59 - when an OS routine is compiled so at
74:01 - compile time the OS routines in compile
74:04 - time generates the SVC and SVC during
74:07 - run time generates a software interrupt
74:09 - what is a software interrupt it informs
74:12 - the operating system of some
74:17 - activity so every instruction has a
74:21 - routine to serve it serve O Okay so this
74:24 - is known as ISR interrupt service
74:27 - routine let me clarify the story again
74:31 - so when OS routine are compiled it is
74:33 - converted into SVC when SVC during
74:35 - runtime is convert generates a software
74:38 - interrupt and software interrupts
74:40 - generate an ISR interrupt service
74:42 - routine every interrupt has a routine
74:45 - service routine to serve the operating
74:47 - system so interrupt service routine is
74:49 - generated and what interrupt service
74:51 - routine will do it has two major work so
74:54 - first firstly it will go and change the
74:57 - mode bit in the PS W processor status
75:00 - World register in the CPU it will change
75:03 - the mode bit from 1 to zero because we
75:05 - are converting from we are transferring
75:07 - from user mode to Kernel mode user mode
75:09 - has a mode bit of one and Kel mode has a
75:11 - mod bit of zero if we have changed the
75:13 - mode bit from 1 to Zer it means we have
75:14 - shifted to Kernel mode okay so now we
75:18 - have we are in the kernel mode we are in
75:21 - the kernel mode now now the question
75:23 - arises how to find where our Fork is we
75:26 - need the address of the fork okay so
75:30 - this was the first activity done by
75:32 - interupt service routine that it has
75:34 - changed the mode bit from 1 to zero now
75:36 - the second activity is interupt service
75:38 - routine has to find the address of the
75:40 - fork so for that OS maintains a table in
75:44 - the kernel known as dispatch table
75:47 - dispatch table is a data structure in
75:48 - Ram it tells what all services OS
75:51 - provides or the address with it so this
75:54 - is a dispatch table dispatch
75:58 - table and in dispatch table there is a
76:00 - name written a fork and its address so
76:03 - the address will be accessed and will go
76:05 - to Fork there are various instructions
76:08 - the instruction will be executed
76:10 - sequentially and the last instruction
76:12 - will be executed it will go again to the
76:14 - processor status word will convert the
76:18 - mode bit from 0 to 1 you know we have to
76:20 - also change back from kernel to user
76:23 - mode why why is necessary you know for
76:26 - the security purposes we cannot always
76:28 - give a user application the admin rights
76:30 - every time we need to
76:32 - change the rights as soon as the service
76:34 - is completed okay so as soon as the last
76:39 - instruction is executed you need to
76:41 - change the bit from 0 to 1 it means
76:44 - kernel mode to user
76:46 - mode so I I guess you have understood
76:49 - let me clarify the story again so what
76:51 - happens whenever the compiler find there
76:54 - is
76:56 - us kernel level program it during
76:58 - compile time it generates SVC that is
77:00 - supervisory call these are the privilege
77:02 - instruction so at SVC at runtime
77:04 - generate software interrupt and every
77:07 - interrupt has a routine to serve it so
77:09 - there is a ISR interrupt service routine
77:12 - interrupt what ISR will do it has two
77:14 - work firstly it will change the mode bit
77:16 - from 1 to zero and secondly it will go
77:19 - to the dispatch table in the operating
77:21 - system and we'll find the address where
77:23 - the where the fork is it will find the
77:24 - add address it will go to the fork
77:26 - execute the instruction one by one
77:28 - sequentially and the last instruction is
77:30 - executed it will again go to the PSW
77:32 - processor status word register and we
77:34 - will change the kernel mode to user mode
77:36 - by changing the mode bit from 0 to 1 and
77:40 - all operating systems follow this
77:41 - Paradigm of user and kernel mode
77:44 - conversion so there are three type of
77:47 - functions we have discussed in the
77:50 - previous 5 minutes the user defined
77:52 - function and the built-in functions
77:54 - these these functions user defin the
77:56 - buil-in are executed in user mode simply
77:58 - because they are written by the user
78:00 - kernel oh sorry compiler is not the part
78:03 - of operating
78:04 - system system calls are executed by
78:08 - kernel mode so there are three type of
78:09 - function user defined builtin and system
78:11 - calls the first two are executed in user
78:13 - mode and the last one that is system
78:15 - call is executed in the kernel
78:18 - mode okay so this was all the story of
78:21 - how mode shifting is performed now I
78:23 - have a task for you what you need to do
78:25 - you need to what you need to do you need
78:28 - to write everything which I have told in
78:29 - the previous 10 to 15 minutes in form of
78:32 - a flow chart in form of a flow chart you
78:34 - have to show how mode shifting is done
78:37 - and
78:38 - then you have to pause the video write
78:41 - that in your copy and then I will show
78:42 - you the answer so three 2 and 1 so this
78:46 - is the
78:47 - answer so OS routines are accessed
78:49 - through API so it will start with a fork
78:52 - like operating system routine at compile
78:55 - time it can generated SVC supervisory
78:57 - call and then at run time it generates
78:59 - ISR and then it generates it has to work
79:02 - changing the mode bit at the PSW and a
79:04 - dispatch table and in dispatch table it
79:06 - will find the address and it will do the
79:09 - sequential Atomic execution of
79:11 - instruction I have told you the in
79:13 - kernel mode the instructions are
79:15 - executed
79:17 - atomically because they are known
79:18 - preemptive privilege instructions and
79:20 - when the last instruction is executed it
79:22 - will go back to the processor status
79:24 - word and will change the mode bit and in
79:27 - this way the thing is completed okay so
79:31 - I have told you that print F
79:33 - implementation was in library file so if
79:35 - printf want to access the device and
79:38 - device control is with the operating
79:40 - system then it has also has to change
79:43 - the mode bit from user to Kernel so
79:46 - let's say in printf implementation there
79:49 - is some user mode level programs the
79:52 - statements and then suddenly a system
79:55 - call is there that is right so Library
79:57 - function like print F can also use
79:59 - system calls and when system call is
80:01 - there mode shifting will occur okay so
80:04 - in this way I have represented this so
80:06 - there is a user process user process
80:08 - executing system call and then system
80:10 - call Will generate a trap so you must be
80:13 - wondering now what is a trap don't worry
80:14 - it's same as an interrupt interrupt and
80:16 - trap are the same thing so mode WID will
80:19 - here is zero so it will execute it will
80:21 - change the mode WID from 0 1 to 0o mode
80:25 - bit is zero now now it will execute the
80:27 - system call it will change the mode bit
80:29 - from 0 to 1 and then it will return from
80:32 - the system call in this way the mode
80:34 - shifting is
80:36 - completed so no interrupt is generated
80:38 - during kernel to users transformation so
80:41 - you have you may see here there is a no
80:43 - trap while going back from kernel to
80:45 - user mode the interrupt is generated
80:47 - only when user to Kernel shifting is
80:50 - there okay so when we need just a vage
80:54 - instruction without interrupt to switch
80:56 - from kernel to user mode so we do not
80:58 - need an interrupt from kernel to user
81:01 - mode
81:02 - shifting so I hope you have understood
81:04 - how mode shifting is done and what are
81:07 - kernel and user mode
81:09 - properly so there's a DPP which I'm
81:12 - giving you right now you have to solve
81:13 - that and in the next lecture we will
81:15 - discuss
81:17 - them welcome to the operating system
81:19 - Master course this is DPP number two
81:21 - let's start so the first question says
81:24 - it is multiple select question which of
81:26 - the following statements are allowed in
81:27 - kernel mode only only kernel mode can do
81:30 - this user mode cannot do that so the
81:32 - first says enabling and disabling
81:33 - interrupts yes this is a kernel mode
81:34 - operation So the instructions that run
81:36 - in the kernel mode are known as
81:38 - privilege instructions and privilege
81:40 - instructions can only enable and disable
81:43 - interrupts reading the system time no
81:45 - user mode can also do do this contact
81:47 - switching contact switching is the part
81:49 - which we are going to learn later it is
81:51 - a very common thing we will learn don't
81:53 - worry for now so the Contex switching is
81:55 - also a kernel mode operation just
81:56 - remember this for now contact switching
81:58 - is a kernel mode operation and cannot be
82:00 - performed by user
82:02 - mode clear the memory clear the memory
82:05 - or remove any process from the memory
82:06 - this is a kernel mode
82:08 - operation so which options are the
82:10 - correct a c and d are correct okay let's
82:14 - move down to the question number two it
82:16 - is also a multiple select question it
82:17 - says which of the following are correct
82:20 - to switch from kernel mode to user mode
82:22 - the mode WID should be changed to one so
82:24 - so the kernel mode has a mode bit of
82:27 - zero and user mode has a mode bit of one
82:29 - to switch from kernel to user we have to
82:31 - change the mode bit to one so this
82:32 - option is correct to switch from kernel
82:35 - mode to user mode the mode should be so
82:37 - this is the same thing you have to what
82:39 - remember from kernel to user change the
82:42 - mode bit to one and from K uh user to
82:46 - Kernel change the mode bit to zero so
82:47 - this is a kernel mode operation this is
82:49 - a kernel mode bit and this is a user
82:51 - mode bit
82:55 - do you can do this now okay the question
82:57 - number two I hope you can do this the
82:58 - answer is uh change to one this is
83:01 - correct this is false this is false to
83:05 - switch from user to this is true so
83:07 - option A and D is true let's move to the
83:09 - question number three it is a multiple
83:11 - choice question user mode user mode is
83:15 - atomic no user mode is a mode bit of
83:17 - Zero no user mode is privilege no user
83:19 - mode is preemptive so this is true Cal
83:21 - mode is atomic it's mode bit has zero
83:23 - and it is privilege so I hope you can do
83:24 - this now this is true move to the
83:27 - question number four it is a multiple
83:29 - choice question system call is used to
83:31 - access operating system
83:34 - functionality system call is used to
83:36 - access operating system functionality
83:37 - this is common thing I don't think it
83:39 - needs some explanation question number
83:42 - five consider the following statements
83:44 - predefined function start executing in
83:46 - kernel
83:48 - mode and the second says user defined
83:50 - function start executing user mode so
83:52 - I've already told you predefined
83:55 - function whether it is predefined
83:56 - function or user defined function they
83:58 - both execute in user mode only the
84:00 - system calls or operating system service
84:03 - routine execute in the kernel mode so
84:05 - which is
84:06 - correct only second is correct user
84:09 - defined function start execute in the
84:10 - user mode predefined function also
84:12 - execute in the user mode it doesn't
84:14 - execute in the kernel mode question
84:15 - number six so this may be a tough
84:17 - question for you so let's solve it this
84:20 - now consider the following program main
84:23 - 444 so there are three folks and then a
84:26 - print statement and then return
84:29 - zero so what do you think how many times
84:31 - G to to 2 three will be
84:34 - printed uh so I have told you that
84:37 - execution of work results in the
84:39 - creation of child process so when this
84:41 - Fork will be executed these three will
84:43 - be copied I mean it's it's like the
84:46 - duplicating let's say if this is a fork
84:49 - and then some print statement print one
84:52 - so 2 * 1 will be printed so 1 one this
84:54 - will be the output let's say there are
84:56 - fork and then print
84:59 - one so when this Fork Fork will be
85:02 - executed these two will be duplicated
85:04 - let's say like this fork and print when
85:07 - this Fork will be executed this print
85:09 - will be duplicated so one and one and
85:12 - this this four will execute one and one
85:14 - so four * 1 will be printed in the
85:17 - similar way when there are three folks
85:20 - then eight time 2023 G 2023 will be
85:23 - printed so so I hope you are not
85:26 - understanding it properly so let me
85:27 - explain you a different way let me
85:29 - explain in form of a tree so when this
85:32 - Fork will be executed these three will
85:34 - be duplicated down there in the next
85:37 - level so I will write fork for this Fork
85:41 - another fork for this fork and a print
85:44 - statement for the last print statement
85:47 - now for this when this Fork will be
85:49 - executed these two child process will
85:51 - come there so Fork
85:55 - and the print statement will go there
85:57 - when this Fork executed this print will
85:59 - be duplicated so print will come here
86:02 - now when this Fork executed this fork
86:05 - and print will go there so I will write
86:07 - let me change the color uh let's choose
86:10 - this so it will like fork and then
86:14 - print when this Fork will be executed
86:16 - the print statement this print will go
86:19 - there okay when this for will executed
86:21 - this print statement will go there so
86:23 - print
86:25 - and then uh I guess now we will execute
86:28 - this Fork the print statement this print
86:31 - will go
86:32 - there so when we'll execute this Fork
86:34 - the print statement will come so now we
86:36 - can see all the forks are executed and
86:39 - only print statements are remaining in
86:40 - the leaf nodes so 1 2 3 4 5 6 7 and 8 so
86:48 - we have seen eight times the print
86:51 - statement was there what if I include
86:53 - another 4K here how many times this will
86:55 - be printed so we have seen if a fork if
86:58 - only one fork was there it was printed
87:01 - only one time oh it was printed for two
87:03 - time like fork and print so what will
87:07 - this Fork do it will duplicate this
87:09 - print statement so print and print two
87:11 - times print are there so if one fork was
87:13 - there it was printing two times if two
87:16 - Fork was there it will print four times
87:17 - if Three Forks are there we have seen it
87:19 - will print for eight times if if four
87:21 - Forks are there then it will print for
87:23 - 16 times times how did I get 16 so
87:26 - quickly because I have created a formula
87:29 - for this let end be the time Fork is
87:34 - present then the next
87:36 - statement just below the forks let's say
87:39 - fork Fork Fork so this Fork has present
87:42 - n times Fork n times so the next
87:46 - statement will be executed 2 ra to the^
87:49 - n * here it was 2^ 1 it is 2^ 2 it is 2^
87:54 - 3 if it is n then it will be 2 power N I
87:58 - hope now it is clear for
88:00 - you so let's move to the question number
88:02 - seven mod bit is present
88:06 - in is it present in main memory no it is
88:09 - present in dis now it is present in cash
88:12 - no it is present in the register I've
88:14 - already told you it is present in the
88:16 - register named PSW processor status
88:19 - world it is in the CPU at system boot
88:23 - time the hardware starts in kernel mode
88:26 - man the in the system boot times the
88:29 - hardware starts in the kernel
88:31 - mode okay so so this was the DPP number
88:35 - two we have discussed there was a
88:37 - special concept of fork which we learned
88:39 - and a formula we learned rest was the
88:41 - easy question so you should have done at
88:44 - least six question out of these eight
88:46 - correctly okay so if you're unable do
88:48 - not worry just try to focus more during
88:50 - the lectures and then avoid silly
88:53 - mistakes and you will make it
88:55 - through hello everyone welcome to the
88:57 - section two Process Management we are
89:00 - starting with the lecture six in this
89:02 - lecture we are going to learn everything
89:04 - about what is a process so some student
89:08 - may have doubt about a program and a
89:10 - process is the process and program same
89:13 - we will clarify that in detail in this
89:16 - lecture okay we will learn about what is
89:18 - a process it several definitions like we
89:21 - did in case of operating system in
89:23 - lecture one I will give you several
89:25 - definition of a
89:27 - process I will tell you what operations
89:30 - process can perform what are the
89:31 - attributes of a process how does the
89:33 - process look like in a
89:35 - memory so are you ready for this
89:37 - interesting lecture tighten your seat
89:39 - belts and let's start so we will first
89:42 - start with a difference between a
89:44 - program and a process so let me tell you
89:48 - straightly imagine you have written a
89:50 - high level code now you have compiled it
89:52 - it will be converted into doxe file if
89:55 - this is present in the hard disk this is
89:57 - a program if this is present in the
89:59 - memory this is a process it is so simple
90:02 - to
90:03 - understand so if a program ISE file and
90:07 - it is present in the hard disk it is a
90:10 - process it is a program and if a program
90:13 - is in
90:14 - execution I mean it is in the main
90:16 - memory then it it becomes a process so
90:19 - when program is loaded from dis to main
90:21 - memory it becomes the process process is
90:24 - the instance of a program process is the
90:27 - instance of a program okay so in program
90:31 - there are two things data and
90:32 - instructions data include operant and
90:35 - variables and instruction include add
90:37 - load multiply store there are various
90:39 - like SBC and BSA supervisory call and
90:42 - the BSA branch and save address we
90:44 - studied in the last lecture okay so
90:46 - let's understand by this
90:48 - example here we have declared three
90:50 - variable a b and c b is equal to 1 C =
90:54 - to 2 and a equal to B plus C so simple
90:56 - like that now when this will be passed
90:58 - to the
90:59 - compiler it will generate a list of
91:02 - instructions and this list of
91:05 - instruction is nothing but a program and
91:08 - if this is stored in the hard disk it is
91:10 - a program if this is stored in the
91:13 - memory it is a process so what we need
91:15 - to do we need to add the value of B and
91:18 - C and store it in a so we'll first load
91:20 - the constant value in B the constant
91:23 - value in C
91:24 - now the addition is performed between
91:27 - registers so we have to load the value
91:29 - of B into register 1 and C into register
91:31 - 2 add both registers and store the value
91:34 - or the result in R1 and then the store
91:37 - the value of R1 in a and we will get a
91:40 - equal to B plus C so this is the lowle
91:42 - instructions converted from the high
91:44 - level piece of Code by the compiler and
91:47 - these instructions if it stored in the
91:48 - hard disk are program if it stored in
91:50 - the memory is process so simple so
91:54 - process is something which is Created
91:55 - from the program okay now data is of two
91:58 - types static data and dynamic data so
92:02 - this is a part from C language course
92:04 - also but I think I am feeling the need
92:07 - to also add this here in the operating
92:09 - system
92:10 - course because this will be necessary
92:13 - when I will be explaining the process as
92:16 - abstract data type or process how the
92:19 - process look in the memory okay don't
92:23 - Focus what I said Just remember data is
92:26 - of two type static and dynamic static
92:28 - means fixed size or known size dynamic
92:31 - means it is weing or it may be of the
92:33 - fixed size but it is allocated at the
92:36 - run time so if Dynamic data is allocated
92:38 - at the run time is static data allocated
92:41 - at the compile time no the answer is
92:44 - wrong so I have written that at form of
92:47 - question at what time of a program
92:48 - execution memory allocation occurs for
92:51 - static
92:52 - data compile time no compile time is
92:55 - wrong why because compile time is meant
92:57 - for checking syntactic correctness and
92:59 - generating the code which code this
93:01 - instruction code I was talking about so
93:04 - what if just imagine the scenario what
93:06 - if I just compile the program and do not
93:08 - run it this is possible uh in Unix we
93:12 - see JCC and then uh the name test. c
93:16 - this mean I have compiled
93:18 - it and a file named a.out is created or
93:24 - okay so if I have to execute I have to
93:26 - write do/ a.out and then it will be
93:31 - executed okay but in this case what I'm
93:33 - doing I am just compiling the program
93:35 - and I'm not running it it means I have
93:39 - just written this in the terminal and
93:42 - pressed enter I have not written the
93:43 - next statement of
93:45 - executing
93:46 - so memory located at compile time is a
93:49 - wastage because I have not executed this
93:51 - I have just compiled what is the point
93:54 - of allocating the memory at compile time
93:56 - what if the user do not execute it it
93:58 - means the wastage of memory occurs if
94:00 - the memory is allocated at compile time
94:03 - compiler only decides how much memory
94:07 - allocation should be there compiler only
94:10 - decides how much okay so between compile
94:15 - time and run time there is another time
94:18 - that is load time what is load time load
94:20 - time is the time when the program is
94:22 - loaded from dis to memory for execution
94:26 - so for static
94:27 - data like this in a c for static data
94:33 - the memory is allocated at load time
94:35 - neither compile time nor run time but at
94:38 - the load time for dynamic data the
94:40 - memory is allocated at runtime okay I
94:43 - hope the concept is clear let's move
94:45 - ahead so I have written like this int n
94:48 - and I have created I have declared an
94:50 - array A N I have not created it I have
94:53 - declared an AR okay now what I'm doing I
94:55 - am taking the value of n from the user I
94:58 - taking the input n is this possible in C
95:02 - or is this valid in C so the answer is
95:05 - no this is not valid in C
95:08 - language so Dynamic array are not
95:12 - created in C language like this we are
95:14 - just taking the input and then a and no
95:17 - this is not the right way but can we do
95:21 - this in C++ yes this is allowed in C++
95:24 - then if I want to implement the dynamic
95:27 - array how should I Implement in C so we
95:30 - used the term
95:32 - maloc okay if you are unaware about the
95:35 - Malo or you have heard the first heard
95:37 - the Malo for the first time this means
95:39 - you are weak in C programming so you
95:43 - must watch the C programming course
95:46 - before the operating system course
95:48 - because it is the prerequisite for the
95:49 - operating system course okay for now
95:52 - let's if you you have not don't worry
95:55 - for now I will give you enough
95:56 - information to understand the context
95:58 - which I'm here to give you for
96:01 - understanding this process thing okay so
96:04 - how we create the dynamic array of size
96:05 - n in C without by not doing this so
96:09 - alternatively we do this by Malo so we
96:13 - have created intn and declared a pointer
96:15 - and then we took the input from the user
96:18 - and then we declared a pointer which has
96:20 - created which in which is pointing the
96:23 - dynamic array of size
96:26 - n so this is how it is
96:28 - done this is how it is done so a regular
96:31 - integer is of two B so this n is of two
96:33 - B so this is declared in as a static
96:36 - form at the load time now this pointer
96:39 - is also declared the load time because
96:41 - this is also static
96:43 - now for Malo thing it means we are
96:46 - declaring a dynamic array so this
96:48 - Dynamic array will be allocating memory
96:51 - at run time so this point this pointer
96:54 - will be pointing to the dynamic array of
96:56 - size n this pointer is pointing to the
96:59 - dynamic array of size n so the address
97:01 - of the first element of the array and
97:03 - the pointer should be the
97:06 - same that is the only meaning of
97:08 - pointing it okay so this is how the
97:11 - dynamic memory location is done using
97:14 - Melo in C okay so we'll learn more about
97:17 - it in C and DSA Master
97:19 - course so as objec is to class in
97:24 - oops the same way process is to program
97:28 - object is the instance of a class in the
97:29 - same way process is the instance of a
97:32 - program okay so the first part of this
97:35 - lecture is over here which differentiate
97:39 - between a process and a program so I
97:42 - will say again what is the difference
97:43 - between process and program so high
97:45 - level code is converted intoe part by
97:49 - compiler if the XE file is in hard disk
97:53 - then
97:54 - it is a program if the XE file is in the
97:56 - memory then it is a process as simple as
97:59 - that okay so let's start with the
98:02 - process now the
98:04 - definition the representation the
98:07 - operation and the attributes this four
98:09 - thing we are going to learn about the
98:10 - process so what is the process process
98:13 - is the program in
98:15 - execution and if a program isn't
98:17 - execution it means it is using the
98:19 - computer resources program doesn't use
98:21 - the computer resources it is as good as
98:24 - dead but the process is alive it uses
98:27 - the Computer Resources it is like the
98:29 - program in
98:30 - execution so process is a program when
98:33 - it get loaded in the memory process is
98:35 - the instance of a program these three
98:37 - definitions I have already explained you
98:39 - the fourth one is process is active
98:41 - entity that is also I have explained you
98:43 - it means it using the computer resources
98:45 - program is passive it doesn't use
98:47 - resources it is dead and process is
98:49 - alive process is always in the memory
98:52 - program is always in the hard disk if
98:55 - the program is shifted from hard disk to
98:57 - memory it becomes the process process is
98:59 - the locus of control of operating system
99:02 - what does it mean it is the same as
99:05 - people are the locus of control for the
99:07 - government so people are the process and
99:09 - government is the operating
99:11 - system let me repeat locus of control of
99:14 - operating system is process in the same
99:17 - way locus of control of government is
99:19 - the
99:20 - people okay the process is the animated
99:23 - disp
99:23 - so this is a term used by an author so
99:26 - what does it represents it is
99:28 - representing that in a body there exist
99:31 - a
99:32 - soul in the same way in a program the
99:36 - soul is the
99:39 - process okay the program is dead without
99:42 - the process process is alive the soul is
99:45 - alive the body is dead the soul is alive
99:47 - the body is as good as dead if the soul
99:50 - is not
99:51 - present okay so
99:54 - I hope you understood what is the
99:56 - process its definition let me repeat
99:58 - process is nothing but a program in
100:00 - execution it is the instance of a
100:02 - program okay so when a program is
100:04 - transferred from hard disk to the memory
100:07 - it becomes the process now we have to
100:10 - learn from the developers perspective
100:11 - what is a process okay so process is an
100:14 - abstract data type or simply a data
100:17 - structure so any data structure is
100:19 - represented in four things each data
100:22 - structure have four part the definition
100:24 - the representation or we can say
100:26 - implementation third is Operation and
100:28 - fourth is attribute for example linked
100:30 - list link list is a data structure so
100:32 - what is the definition of the link list
100:34 - a link list is a linear data structure
100:35 - blah blah blah it has a definition how
100:38 - it is implemented it is implemented
100:40 - using nodes or data and reference to the
100:41 - next node what are the operation it can
100:43 - perform like insertion delion travel Etc
100:47 - what are the attributes he head tail
100:50 - size length data next null these are the
100:53 - attributes of the link
100:55 - list that's why I have told you that C+
100:58 - C or C++ and DSA and Kaa is the
101:02 - prerequisite for this course so that you
101:03 - can relate better okay so for link list
101:07 - these are the four things any data
101:09 - structure have four parts definition
101:11 - representation operation and attributes
101:13 - like link list of the four parts the
101:15 - process similarly also have four parts I
101:18 - have I have cleared the definition for
101:21 - you now we will learn
101:23 - how the process is represented in the
101:25 - memory now in the same way we need to
101:27 - Define process we have defined the
101:28 - process how does the process look like
101:30 - in the memory okay so I have cleared you
101:32 - the program consist of two things
101:34 - instruction and data data is of two type
101:36 - static and dynamic and the program
101:38 - creates the
101:39 - process okay so how does the process
101:42 - look like in the memory how does the
101:45 - program creates the process by going
101:46 - from hard dis to the memory now the
101:48 - program is in memory it is process how
101:50 - does the process look like in the memory
101:52 - so the process process look like this
101:55 - the process has four parts text Data
101:58 - Heap and the St what is this aror
102:01 - representing is representing it is not
102:02 - fixed it is shiftable it shifted as per
102:06 - the needs okay so the first thing is the
102:08 - text text means the code section the
102:11 - second thing is the data data means
102:13 - Global variable and static data static
102:15 - data it means the fixed size data of fix
102:17 - size like we have seen int X that is the
102:21 - static data
102:24 - let me clarify the data is of two type
102:26 - the static data is of two type or the
102:29 - global variables is of two type or
102:31 - simply say data consist of two parts
102:33 - initialized and uninitialized data
102:36 - initialized data is like int x equal to
102:38 - 1 I have initialized the value of x to
102:41 - be one and un uninitialized data is that
102:44 - simply int X so uninitialized data is
102:47 - stored in another compartment and
102:50 - initialized data is stored in another
102:51 - compartment
102:53 - okay so text is clear it is the code
102:56 - section data is clear it is global
102:58 - variable and static data what is Heap
103:00 - Heap is the area in memory for dynamic
103:03 - memory
103:04 - allocation okay so Heap means D dynamic
103:07 - memory allocation and for a stack what
103:09 - is stack used the stack contains the
103:12 - activation record of function calls now
103:15 - if you are weak C Concepts you may
103:17 - wonder what are activation records so
103:20 - let me clarify that for you activation
103:22 - record does not not contain the address
103:24 - of the function so does activation
103:26 - record contain the address of the
103:27 - function no what does it contain then it
103:30 - contains the information and space of
103:32 - the local variables okay so let me give
103:35 - you an example so this is a piece of
103:36 - code int X Main and then static part
103:40 - static int y int K RL these are some
103:43 - variables I have defined and then a
103:45 - function and then again some something
103:48 - and then this function is this is the
103:51 - Declaration and this is the this is
103:53 - declaration and this is the definition
103:55 - okay now the function is defined here
103:57 - the function has
103:59 - two parameters int Zed and int e these
104:03 - are the argument these are the
104:04 - parameters so the function has two
104:06 - parameters int Z and int e and some
104:09 - other variables are also declared here
104:11 - like P Q and L blah blah blah so just
104:13 - take it as as example as a random code I
104:16 - have given to explain you how the
104:18 - activation records are created so this
104:21 - is what is this let me explain you what
104:23 - is this this is the global data so where
104:26 - is the global data will be stored it is
104:27 - stored here in the data
104:30 - section okay now now comes the main part
104:34 - main is the function I have said that
104:36 - activation records of function calls are
104:38 - stored in the stack so as soon as the
104:40 - compiler will reach at this line main an
104:42 - activation record for main will be
104:44 - created here so this activation record
104:46 - is
104:46 - created now in this activation record
104:49 - what does it store activation record
104:50 - stores the information and space of the
104:53 - local variables what are local variables
104:55 - here k r l are the local variables so I
104:58 - have written K RL the local variables
105:00 - here the space of the local variables
105:03 - and its information are stored plus a
105:06 - return address is also
105:08 - stored in the activation records so it
105:12 - will keep executing it will keep
105:13 - compiling these lines and then when it
105:16 - will reach here to another function call
105:19 - it will create an another activation
105:21 - record above the main activation record
105:23 - in the stack so another activation
105:26 - record is pushed as soon as it will
105:28 - reach this line of KR okay so what does
105:32 - it will contain it will contain the
105:34 - local variables z e p q l all are the
105:39 - local variables here so all of them will
105:41 - be stored plus I have said the return
105:44 - address so the return address is C let's
105:47 - say it's is a c so when this function
105:49 - will be compiled the compiler will point
105:51 - to this line
105:53 - that is the this is the return address
105:55 - let's say C is the return address so I
105:56 - will put return address is equals to C
105:59 - that is when this will be compiled you
106:02 - have to go back to the address which I'm
106:04 - giving you that is C so the compiler
106:05 - will start compiling from this line
106:07 - onwards K = to R+L and then the
106:09 - compilation
106:11 - continues so I hope you have you have
106:14 - got the idea what activation records are
106:15 - activation records are the part in the
106:17 - system Stacks that contain the
106:20 - information and a space of local
106:22 - variables plus it also contain the
106:24 - return address of that function in main
106:26 - it contain the return address of Main
106:28 - and
106:29 - in function f activation record it
106:32 - contains the returned address of
106:33 - function f that is if function f is
106:35 - completely compiled then the compiler
106:37 - has to move to this return address that
106:39 - is C that means the next line k equal to
106:42 - r+ okay
106:44 - so when the compiler will move to this
106:46 - this activation record will be deleted
106:48 - and when compiler will compile the last
106:51 - line of main this activation record of
106:53 - main will also be completed okay
106:58 - so activation record of main function
107:00 - gets deleted when the function is
107:02 - deleted or the function is completed
107:04 - okay I should have written completed
107:06 - here instead of
107:08 - deleted okay now it is good so how does
107:13 - the process look like it consist of four
107:15 - parts text it contains the code section
107:18 - initialized data it contains the data
107:20 - like int xal to 1 un uninitialized data
107:23 - it contains the data like int X and then
107:26 - Heap Heap contains the dynamic
107:28 - dynamically allocated memory and then
107:30 - stack contains the activation record of
107:31 - the function and they can shrink and
107:33 - grow as per the
107:36 - requirement okay and now I have a
107:38 - homework for you you have to learn about
107:41 - the VSS extension that
107:44 - is block start by symbol this is the
107:47 - homework you have to learn about this
107:49 - and then you have to comment I don't
107:51 - know you can comment here on you or not
107:53 - but this is the homework we will discuss
107:55 - that in the next
107:57 - lecture so activation record that part
108:00 - is discussed now we have also completed
108:03 - this part the representation part let's
108:05 - move to the operation part we'll move to
108:07 - the operation what several operation the
108:09 - process can perform it can perform the
108:11 - create create means resource allocation
108:13 - resource allocation process get created
108:16 - by this operation memory and resources
108:19 - which are necessary for the process are
108:20 - allocated I think it is simple it
108:22 - doesn't need any more explanation what
108:24 - is create operation create operation
108:26 - means allocating resources which are
108:28 - necessary for the process and the
108:29 - process gets created what is termination
108:32 - it means resource deallocation all the
108:34 - proc all the resources which were given
108:35 - to the process are taken back from the
108:38 - process and the process is destroyed for
108:41 - create the process was created and
108:43 - terminate the process gets
108:46 - terminated
108:48 - schedule the act of selecting process to
108:50 - run on the CPU out of several
108:53 - in multiprogramming operating system
108:55 - this was the OS and there were several
108:57 - processes waiting for the CPU so
109:00 - selecting out of these three which
109:02 - process should be there with the CPU
109:04 - first so this is scheduling the act of
109:07 - selecting process to run on the CPU
109:09 - execute or run executing instruction
109:11 - from code section so this is
109:13 - self-explanatory I have no need to
109:16 - explain block and weight yes this is
109:19 - something which need explanation so
109:21 - process will get blocked when it will
109:23 - execute system call or iio operation it
109:25 - has to wait okay now the suspend part
109:29 - sometime we need to move the process
109:31 - from memory to disk so you must be
109:34 - wondering I have not explained this part
109:35 - the block and weight the suspend the
109:37 - resume so these all things are the part
109:41 - of transition diagram so process move
109:43 - from several States it starts from the
109:46 - create and then terminate in between
109:49 - there are several States like block
109:51 - ready
109:54 - running
109:56 - suspend these are the all parts of
109:58 - transition diagram of the process which
110:00 - we are about to discuss in the next
110:02 - lecture so for now just remember these
110:05 - are just the operation which process can
110:07 - perform what are those its intrig cases
110:10 - will be discussed in the next lecture
110:11 - when we will discuss the transition
110:13 - diagram of the process okay so what is
110:15 - block and weight the process will get
110:17 - blocked when it will execute system call
110:19 - or I operation suspend sometime we need
110:22 - to move the process from memory to disk
110:25 - resume if the if our motive is completed
110:28 - now we have to bring the process back
110:30 - from disk to memory this is the resume
110:32 - part and suspension means memory to disk
110:34 - resume means dis to memory okay now I
110:38 - have completed the third part of the
110:39 - process also that is the operations now
110:43 - let's come to the
110:47 - attributes so the first attribute is for
110:49 - identification type attribute that is
110:51 - the process ID the parent process ID the
110:53 - group ID
110:55 - Etc the CPU related attributes like
110:57 - program counter what is a program
110:59 - counter the program counter will always
111:01 - point to the next instruction to be
111:02 - executed so these are the attributes of
111:04 - the
111:05 - process
111:07 - priority that is the level of importance
111:09 - should be given by OS to the process the
111:13 - state which state the process is in is
111:15 - it in running State the suspended State
111:17 - the blocked State okay and the bust time
111:20 - how much time the process has spent in
111:22 - the C CPU for
111:23 - execution these all are the attributes
111:27 - CPU related okay memory related
111:30 - attributes the third
111:32 - thing it includes size limits the
111:35 - process in which area of the memory is
111:36 - present these are the things file
111:38 - related device related file related
111:40 - means list of the all files which are
111:42 - used by the process accounting related
111:45 - it means which of the following uh which
111:47 - resources are used by the process for
111:49 - execution so these all attributes
111:51 - identification related CPU related
111:53 - memory related file related device
111:55 - related accounting related Etc all the
111:57 - attributes are stored in the PCB that is
112:01 - process control
112:02 - block it is just like the ID card of the
112:05 - process it will contain the process ID
112:07 - its parent ID everything the every
112:09 - information about the process is in this
112:12 - PCB that is the process control block it
112:15 - contain the attribute of the process
112:17 - each process has its own PCB and the
112:19 - pcbs are stored in the memory
112:23 - so this was for this lecture six let's
112:25 - revise what we have done in this lecture
112:27 - so firstly we started with the
112:28 - difference between program and the
112:30 - process next we learned several C
112:32 - Concepts that were necessary to
112:35 - discuss and then next we move to the
112:37 - definition of the process and then we
112:40 - learn the process from developers
112:42 - perspective how the process is an
112:44 - abstract data type its definition it's
112:46 - representation implementation attributes
112:49 - and in the end we learned that all the
112:51 - attributes are stored in PCB the process
112:55 - control block which is stored in the
112:57 - memory each process has its own PCB now
113:00 - in the next lecture we will learn about
113:02 - the scheding cues queing diagrams the
113:04 - transition diagram which I was referring
113:06 - there and schedulers and dispatchers
113:08 - thank
113:09 - you hello everyone welcome to lecture
113:12 - eight of operating system Master course
113:14 - we'll start our discussion from process
113:16 - control block and then we will move to
113:18 - the states of the process which process
113:21 - covers from is it's beginning to end so
113:24 - during the whole process lifetime
113:26 - process covers several States process
113:28 - moves from one state to another and how
113:30 - the process moves which is represented
113:33 - through the process State transition
113:35 - diagram I'm going to guarantee you
113:38 - that the amount of depth which we are
113:40 - going to cover here in this lecture is
113:42 - unmatchable to any content on this
113:45 - platform and when I used to teach in
113:48 - classes people used to ask some common
113:50 - doubts I've also taken those doubts like
113:53 - this and their answers okay so we'll
113:56 - start our discussion now okay let's go
114:00 - so in the last lecture we have seen what
114:02 - PCB is so let's just
114:05 - revise so PCB is also known as process
114:08 - descriptor it's stored in the memory and
114:10 - the total content of the PCB is known as
114:14 - process context or process environment
114:16 - remember this I have talked about this
114:18 - in one of the DPP so context switching
114:21 - is related to this we are going to learn
114:23 - that context switching in the next next
114:25 - lecture okay so for now just remember
114:29 - the contents of the PCB is known as
114:31 - process context or process environment
114:33 - context the famous word during the
114:36 - process lifetime process goes from one
114:38 - state to another just like uh human it
114:42 - start with a child it it start with a
114:45 - infant and then
114:47 - child and then school boy adolesence and
114:51 - then youth in the end it dies old age
114:54 - and then it
114:56 - dies in the same way process also goes
114:59 - from various stages so this is the stage
115:02 - one the new in which process gets
115:05 - created resource allocation happens in
115:08 - the ready which process are in the ready
115:11 - state which are ready to run on the CPU
115:13 - so the process which are ready to run on
115:15 - the CPU belongs to the ready state in
115:17 - running State the process is actually in
115:19 - the CPU so the process is executing
115:22 - instructions on the
115:24 - CPU and then block SL weit it means it
115:29 - leave the CPU process need to perform I
115:31 - operation or execute a system call for I
115:34 - operation okay so I'm giving example
115:37 - like what is Io Io means reading
115:40 - something from the device writing
115:42 - something from writing something to the
115:44 - device I should use a proper preposition
115:47 - writing something to the device pardon
115:48 - me I'm learning the English language
115:51 - okay and then the last stage is
115:54 - terminate so the process has completed
115:57 - all of the instructions and resources
116:00 - are taken back from the process so
116:02 - resource deallocation
116:04 - happens okay so how many states are
116:06 - there new ready running block and wait
116:09 - and then terminate so we are starting
116:12 - with these five process only but as we
116:14 - move as we learn more we'll go we'll
116:16 - learn the two more stages that is
116:18 - suspend block and suspend ready okay so
116:20 - for now we will learn the process State
116:24 - transition diagram in five states only
116:27 - okay so this is the new state
116:31 - CPU oh operating system allocates the
116:34 - resource it create the process and when
116:36 - the process is created it is ready to be
116:39 - actually executed in the CPU so in this
116:42 - ready stage the process is ready for CPU
116:47 - okay now what is scheduling and what is
116:49 - dispatch scheduling means making a
116:51 - decision out out of many ready processes
116:53 - which will be chosen for the CPU I've
116:55 - told you several times that only one
116:57 - process can run on CPU at a time so out
117:01 - of several ready process out of sever I
117:04 - have let me represent out of several
117:07 - ready process I have already told you in
117:09 - in this way there are several process P1
117:10 - P2 P3 PN out of these only one will be
117:14 - with the CPU being
117:16 - executed okay so now OS has to choose
117:19 - out of these ready processes which I
117:21 - have to s to CPU so that is scheduling
117:24 - and what is dispatch dispatch means CPU
117:26 - gains the right to execute instruction
117:28 - of that process CPU gains the right to
117:31 - execute instruction of that process so
117:33 - I'm feeling the need to clarify your
117:36 - doubt we say it's just a matter of
117:39 - saying that we say the first the process
117:41 - was in hard disk and then it has moved
117:43 - to main memory here the process has
117:45 - actually moved from hard disk to main
117:47 - memory in hard disk it was a program in
117:49 - main memory we say it as a process it
117:51 - has actually moved the process has
117:54 - actually moved but when we say the
117:56 - process from Main memory has moved to
117:58 - CPU that is just a a way of saying it
118:01 - has not actually moved to CPU CPU has
118:04 - got the control to execute instructions
118:06 - of the process let's imagine like this
118:09 - okay so this was the OS and then uh
118:12 - let's say the P1 process is in the main
118:14 - memory so there are several instruction
118:15 - like i1 I2 I3 now the CPU has gained the
118:19 - rights over the instruction instu of the
118:22 - process one to execute them now CPU will
118:25 - execute instruction one and then
118:27 - instruction two and then instruction
118:28 - three the the process has not actually
118:31 - went these instruction has not actually
118:33 - went to the CPU the CPU is at its place
118:36 - the process is in main memory CPU has
118:38 - got rights
118:40 - to execute those instructions okay so
118:44 - the process Still Remains in the main
118:45 - memory CPU just gets the control to
118:47 - execute the process in the same way when
118:50 - we say the process was initially in the
118:53 - CPU let's imagine this is just a way of
118:55 - seeing and then it has moved to the io
118:58 - devices to perform some iio Services now
119:00 - CPU is empty this is just a way to
119:02 - explain a child okay you are you are
119:05 - children in context to operating system
119:08 - so this is a way to explain the process
119:10 - has not actually moved from CPU to I
119:12 - devices okay the process resides in the
119:16 - main memory process does not perform the
119:19 - I
119:21 - operation we learn this later in this
119:23 - lecture okay so the process does not
119:25 - perform the I operation it is the
119:26 - operating system which perform the I
119:28 - operation process tells the O while
119:31 - remaining in the main memory that I need
119:33 - the I services so it will make a system
119:35 - call the process will make a system call
119:38 - that OS will hear and then OS will say
119:41 - what is it the process say to OS see OS
119:45 - I require this and this IO Services the
119:47 - pro the operating system will say okay
119:49 - you wait in here in the memory I will do
119:51 - that service for you and then I will
119:53 - give you the
119:56 - results I hope you got the point so the
120:00 - process always remains in the main
120:03 - memory either it is being executed by
120:06 - the CPU or it is getting some IO
120:08 - services from the operating system it is
120:10 - in the main memory or we will learn it
120:13 - later the process either it is in the
120:15 - main memory or in the hard
120:17 - disk sometimes the process need to be
120:20 - shifted from Main memory to the hard
120:22 - disk also from till now we have learned
120:25 - that we need to shift the program from
120:29 - hard disk to main memory so that it
120:31 - becomes the process now I'm also telling
120:33 - you that operating system also feel the
120:36 - need to shift the process from Main
120:39 - memory to hard
120:40 - disk can you guess why because there is
120:43 - so much clutter in the main memory so
120:45 - that operating system feel I need to
120:47 - clear some process I have to hold some
120:50 - process I have to keep some process on
120:53 - hold so it will shift the process from
120:56 - Main memory to the hard disk so that the
121:00 - number of process in the main memory
121:01 - becomes manageable for the
121:04 - OS okay so operate the process does not
121:09 - go to the CPU or to the io devices is it
121:12 - resides either in the main memory or in
121:14 - the hard disk so this was the concept I
121:17 - felt you must be cleared with Okay so
121:20 - this concept should be crystal clear
121:22 - now let's move to our state diagram so
121:25 - we started with the new the process get
121:27 - created the resource allocation done is
121:29 - done and then the process is moved to
121:31 - the ready
121:33 - State and then out of several ready
121:36 - State CPU will choose
121:38 - one and then uh sorry operating system
121:42 - will choose one and then it will give
121:44 - rights to the CPU to execute the
121:47 - instruction of the
121:48 - processes okay so that part if the CPU
121:52 - start executing it its instruction the
121:54 - process is in running State now if all
121:57 - the instructions of the process are
121:59 - executed then the process transits from
122:01 - running to termination running to
122:04 - termination because all of the
122:06 - instructions of the process has been
122:08 - executed now let's see the process feels
122:12 - that it requires some input output
122:14 - services so it will make a system call
122:16 - for an io2 oos
122:23 - hm so it will make a system
122:25 - call Now voice will say okay you wait so
122:29 - it will take the rights of execution
122:31 - from CPU and the process is in weight
122:35 - State or the process is blocked from
122:37 - being executed by operating system so
122:41 - the process is in waight state where it
122:42 - is waiting it is waiting in the main
122:47 - memory okay so the process is in
122:50 - weightage state when the io or system
122:52 - call has been completed the process has
122:54 - got what it wanted it is again shifted
122:57 - to it is again shifted to ready state so
123:01 - let me clear you the story again so the
123:04 - process started with a new resource
123:06 - allocation happens the process is
123:07 - created it is in the ready State ready
123:09 - to be executed by the CPU out of several
123:11 - ready processes CPU is given one process
123:15 - by the operating system that choosing
123:17 - the one process out of several ready
123:18 - process is scheduling and then giving
123:21 - the op uh giving the CPU the rights to
123:24 - execute the instruction is dispatching
123:26 - if the CPU start executing the
123:28 - instruction the process is in running
123:30 - State and then if all the instructions
123:32 - of the CPU if if all the instruction has
123:35 - been executed by the CPU then the
123:36 - process isn't termination
123:39 - stage okay while
123:42 - running there is a need for input output
123:46 - Services then the operate the process
123:49 - will make a system call to the operating
123:51 - system operating system will say okay
123:53 - you wait in the main memory I'll do the
123:55 - io services for you and we'll give you
123:57 - the results the when the operating when
123:59 - the operating system give the process
124:01 - the results or the io service which it
124:04 - needed it is again sent back to ready
124:07 - stage ready to be executed the rest of
124:09 - the instructions okay suppose let's say
124:11 - the instructions are i1 I2 I3 I4 and I5
124:15 - in I3 it requires some IO services so
124:18 - the instruction one is executed by the
124:19 - CPU 2 is executed and then in the third
124:21 - stage if it needs IO then it will be the
124:26 - the operating system will take the
124:27 - rights from the CPU for ex for executing
124:29 - the instructions and the process will
124:32 - wait in the main memory and when the
124:35 - operating system completed the io
124:37 - services and give the io results to the
124:41 - process it will again be sent to the
124:44 - ready state for next instruction to be
124:46 - executed so when the scheduler will
124:50 - choose the process let's say this
124:51 - process was P1 when the Scher will
124:53 - choose P1 and send it to the running
124:56 - stage the CPU will execute its remaining
124:58 - instructions so I hope
125:01 - the story is clear to
125:03 - you okay so when will the process
125:08 - Transit from running to block State when
125:09 - it needs some IO call and when IO call
125:11 - is completed it is again sent back to
125:14 - ready state for its remaining
125:16 - instruction to be
125:17 - executed okay now there's a question
125:21 - arises by seeing this process straight
125:23 - transition diagram can you guess which
125:26 - type of operating system is it is it
125:28 - multi-programming operating system or
125:30 - uni programming operating system so we
125:34 - can here observe that there is a ready
125:35 - State Ready State contain all those
125:37 - processes which are ready to be
125:40 - scheduled for
125:43 - Execution this itself clears the point
125:46 - that there are several processes which
125:49 - OS is holding in the main memory it
125:50 - means it is multiprogramming operating
125:52 - system so due to this ready State we can
125:54 - say this is a multiprogramming operating
125:56 - system
125:59 - now my question two whether this is a
126:03 - diagram of preemptive operating system
126:06 - or non- preemptive operating system can
126:08 - you tell me yes you are correct this is
126:11 - a diagram
126:13 - of
126:15 - of non- preemptive operating system
126:17 - because the process is exiting
126:22 - the CPU only when either it is completed
126:24 - or it needs an iio service if I made a
126:30 - shift like this it becomes a preemptive
126:33 - system that the process is forcefully
126:36 - preempted from the CPU and put back to
126:38 - the ready stage
126:40 - okay so what is scheduling and
126:43 - dispatching scheduling means selecting
126:45 - and dispatching means giving control
126:48 - okay so what should be the state
126:50 - transition diagram for uni programming
126:52 - operating
126:53 - system so for uni programming operating
126:56 - system there is a no need for ready
126:59 - stage because there's only one process
127:02 - so when the process is
127:04 - created it will directly send to the
127:06 - running state if it needs some IO it
127:08 - will go to the block State and then when
127:10 - the io service is completed it will
127:11 - again come back to the running stage and
127:13 - then it is terminated so no ready stage
127:16 - because there's only a single program or
127:19 - process okay so let's move now every
127:24 - process will complete from running state
127:28 - only so you you can see there's only one
127:30 - path for termination stage that comes
127:34 - from the running stage only there is
127:36 - only one path from running state to the
127:39 - termination state so the process will
127:41 - complete from running state only you
127:44 - should remember this because it is an
127:46 - important concept so I must clarify this
127:50 - more so we will write like this exit in
127:54 - the end of the program that statement
127:56 - must be executed on CPU to terminate the
127:59 - process so it should be in the running
128:02 - State before it get
128:04 - terminated okay so I have already
128:07 - cleared this this is a diagram for non-
128:10 - preemptive and then if I do this
128:13 - transition that is forceful deallocation
128:15 - Force for deallocation now it has become
128:18 - preemptive okay so this is preemptive
128:20 - based m programming operating system
128:23 - okay so here you can see here in this
128:27 - you can see the process will leave the
128:28 - CPU voluntarily on its own when it is
128:31 - leaving the CPU either it is completed
128:33 - or it needs some I or system call so in
128:36 - this case in this
128:39 - case preemption is not occurring and
128:42 - here the preemption is there based on
128:44 - either time or either
128:46 - priority okay so let's move down here
128:49 - are some important notes that you must
128:51 - remember number either process is in a
128:53 - ready State running state or blocked
128:55 - State the process is in the main memory
128:59 - let me clarify either the process is in
129:02 - the ready State the running State or the
129:05 - blocked State the process is in the main
129:09 - memory
129:10 - okay this is the part where the process
129:13 - is entering the main memory the resource
129:16 - allocation is being occurring well this
129:20 - is a grammatical error so this is a part
129:23 - where resource allocation occurs and
129:25 - this is a part where resource
129:26 - deallocation occurs here it is entering
129:29 - the main memory here it is leaving the
129:31 - main memory in these three states that
129:34 - is ready running and block and weight
129:37 - the process is actually in the main
129:39 - memory
129:41 - okay so either process is in ready State
129:44 - running state or blocked State the
129:46 - process is in the main memory in new it
129:48 - is entering the main memory in terminate
129:50 - it is leaving the main memory
129:51 - Point number two there can be multiple
129:54 - process in ready and blocked State
129:56 - theoretically infinite process can be in
129:59 - the radiant block State there there is
130:00 - no limit there is no limit it depends
130:03 - upon the capacity of ram it depends upon
130:07 - the capacity of operating system to
130:09 - manage that much service that much
130:11 - processes okay so this is the operating
130:14 - system here let's say the hard disk it
130:17 - has theoretically
130:18 - infinite processes and this this Ram or
130:22 - main memory is theoretically infinite so
130:25 - operating system can load and manage
130:27 - theoretically infinite
130:29 - processes so how many state can be in
130:32 - the ready or blocked State theoretically
130:35 - infinite but how many process can be in
130:38 - the running state so I have told you
130:40 - several
130:41 - time that at a time CPU can work upon
130:46 - only a single process if it is a
130:49 - multiprocessor CPU let's say it has n
130:51 - CPUs then n processes can be in the
130:55 - running State let's say let's say if it
130:57 - has if the system has n CPU then end
131:00 - processes can be in the running State at
131:03 - a single time if it has one CPU if it is
131:05 - uniprocessor then only one process will
131:08 - be executed by the CPU at a time okay
131:12 - so I have written there can be at Max
131:15 - One Running process for one CPU at Max
131:18 - One Running process for one CPU if there
131:20 - are multiple CPU there can be multiple
131:23 - running process depending upon the
131:24 - number of CPUs so maximum process and
131:27 - radi blocked State can be theoretical
131:28 - infinite maximum process in the running
131:30 - State depends upon the number of CPUs
131:32 - there can be multiple process in radiant
131:34 - blocked state but there can be only one
131:37 - process running for one CPU okay so now
131:41 - the important part come that is the
131:44 - suspension so we'll learn the suspension
131:46 - part and we'll continue or the we'll
131:49 - continue the seven State transition
131:51 - diagram this part we will continue in
131:52 - the next lecture okay so now we'll
131:55 - understand what is suspension so let's
131:56 - take the example of a
131:59 - classroom suppose uh let me write in the
132:03 - this page okay suppose take this
132:06 - example this is me teaching in a
132:09 - classroom okay there are several
132:11 - students like let's say the capacity of
132:13 - classroom is 100
132:15 - students so when I came from uh my home
132:19 - to to the school
132:21 - I see there are already 150 students
132:24 - sitting in the classroom for my lecture
132:27 - so what I will say I will say hey guys
132:30 - uh why didn't you 50 guys the 50 guys
132:33 - which were standing here by disciplined
132:36 - 50 guys there are there I say why hey
132:39 - why don't you 50 guys go out in another
132:42 - classroom when I will complete my
132:44 - lecture for these 100 students I will
132:46 - call you again and I will give you the
132:49 - same lecture so the 50 I says okay sir
132:52 - no problem we are good with this so what
132:56 - I have done these 150 students are the
133:00 - process which are unmanageable by this
133:05 - OS so the students are representing the
133:08 - process and this is me the operating
133:10 - system and what does this classroom
133:12 - represent this classroom represents the
133:15 - main
133:16 - memory and what does this classroom
133:19 - represents which I have told the 50
133:20 - students to go go this represent the
133:22 - hard disk so you remember I have told
133:25 - you one time that there is a case in
133:28 - which the operating system transfer the
133:32 - process from Main memory to the
133:34 - disk what we usually do we usually
133:37 - brings the process from dis to main
133:40 - memory but here in this case we are
133:43 - transferring the process from Main
133:45 - memory to the dis why is it so why do
133:48 - you think I have sent those 50 student
133:51 - to the next class because I want to
133:54 - improve performance I don't want any
133:57 - disturbance the heat of the classroom
133:59 - will increase because there are so much
134:02 - students above capacity in the same way
134:06 - the suspension this process is
134:08 - suspension suspension of 50 50 students
134:10 - that is the 50 process the 50 processes
134:13 - should be moved from Main memory to the
134:15 - dis to improve the performance to
134:18 - improve the efficiency so the what does
134:22 - I have written here so let's say there
134:25 - are 120 ready programs ready to run
134:27 - programs in the main memory and Os can
134:29 - handle only 100 so the OS will transfer
134:31 - the rest 20 from Main memory to the hard
134:33 - disk to improve the performance this is
134:35 - suspension so I already took the example
134:38 - of a classroom now the question arises
134:40 - from which states we can suspend the
134:41 - processes we can State we can suspend
134:44 - from those we can suspend only those
134:47 - students see here we can suspend only
134:50 - those students which are already present
134:52 - in this classroom I cannot suspend the
134:55 - student which is standing outside the
134:57 - classroom I cannot suspend the student
134:59 - which is going out of this classroom
135:02 - what is the point of saying that I'm
135:03 - suspending a student which is already
135:05 - going out of a classroom so this student
135:07 - which is standing out of the classroom
135:09 - is the process in the new state and this
135:13 - student which is going out of the
135:14 - classro is the process in the
135:16 - termination
135:19 - stage so which isent students I can
135:22 - suspend I can suspend those students
135:24 - which are there in this classroom so I
135:27 - can suspend those processes operating
135:29 - system can suspend those processes which
135:31 - are in the main
135:33 - memory so which processes are in the
135:36 - main memory the process in the ready
135:37 - State the process in the running State
135:40 - and the process in the blogged
135:44 - state now can you guess which is the
135:46 - most desirable state for
135:49 - suspension the ready state is the most
135:51 - desirable State for the suspension
135:53 - because in this state the process is
135:55 - already being executed by the CPU in
135:58 - this state the process is waiting for
136:01 - operating system to complete its IO call
136:04 - so ready
136:06 - state is the most desirable state for
136:13 - suspension so I have written this ready
136:15 - state is the most desirable state for
136:19 - suspension because the there the process
136:21 - is neither running nor performing and
136:25 - input output call okay so in the next
136:27 - lecture this lecture length is going way
136:30 - high it's already half an hour so in the
136:32 - next lecture we will learn the seven
136:35 - State process transition diagram
136:45 - goodbye okay so let's continue our
136:47 - lecture so in the last lecture we
136:49 - discussed the need of suspension of the
136:51 - process because we want to improve the
136:53 - performance we've also discussed an
136:55 - example of the classroom so we can
136:57 - suspend the state from ready we can
137:00 - suspend the process from ready State
137:01 - running State and blocked State because
137:03 - these are the states in which the
137:05 - process is in memory what is a
137:07 - suspension suspension
137:09 - means Shifting the process from memory
137:12 - to the dis this is the suspension so we
137:15 - can only suspend those process which are
137:17 - in the memory we cannot suspend those
137:19 - process which are not in the memory like
137:21 - the process in the new state and the
137:23 - terminated state so which is the most
137:25 - desirable state for suspension ready
137:28 - State because there the process is
137:29 - neither running nor performing the io we
137:31 - have discussed all that in our previous
137:33 - lecture now we will see the transition
137:36 - diagram so from ready State we can
137:38 - suspend the process to the state suspend
137:41 - ready and if we want to bring the
137:45 - process back from dis to memory you will
137:46 - say it resume so suspend resume suspend
137:49 - means Shifting the process from memory
137:53 - to the disk and then resuming means
137:55 - shift Shifting the process back from
137:57 - disk to memory we can also suspend a
137:59 - process from CPU the process which is
138:03 - currently running but this is not
138:04 - desirable so I have denoted those
138:07 - transition which are possible but not
138:09 - desirable with dotted lines okay
138:13 - so we can also suspend from block State
138:16 - the process which is waiting in the
138:18 - memory for a long time we will suspend
138:20 - the process hey you can you are just
138:23 - waiting there and you are making the me
138:25 - memory messy so you can just go and wait
138:28 - in the dis because it's doing nothing
138:30 - it's just waiting so OS will say you can
138:32 - wait in the disc
138:34 - also so it will suspend the process to
138:38 - the suspended block State and well and
138:40 - when it thinks the process should be
138:43 - brought back to the memory it will
138:44 - resume so suspension
138:47 - resume okay so we have taken an example
138:50 - so this is the process Pi it was waiting
138:52 - for some IO from a long time now OS will
138:54 - say Hey you are just waiting so why
138:56 - can't you wait in the main why can't you
138:58 - wait in the disk instead of waiting the
139:01 - main memory so OS will transfer to disk
139:04 - to improve the pro efficiency it will
139:06 - transfer the process to the disk so it
139:08 - will come here Pi so it will in the
139:11 - suspended block State and when o will
139:13 - get the time to Surf this process when
139:15 - the iio operation is completed by the OS
139:18 - it won't remain in the suspended block
139:20 - state it is now ready to be brought back
139:22 - to the
139:23 - memory okay so this was the case
139:27 - suspended block state it was waiting for
139:29 - some resources now when it is ready to
139:32 - be scheduled it is in the suspended
139:34 - ready State and from suspended ready
139:35 - state it will go back to the ready State
139:39 - like
139:39 - this okay so for example if a process is
139:42 - waiting for a data from a file it will
139:44 - in the suspended block State until the
139:46 - data becomes available once the data is
139:49 - ready or IO service which it was asking
139:52 - for is completed the process transition
139:55 - to the suspended ready the process
139:57 - transition to the suspended ready State
139:59 - and can be scheduled to run by the
140:00 - operating
140:01 - system okay so so let's discuss these
140:05 - points I have written I summarized here
140:07 - let's read this process is running State
140:10 - initially the process is in running
140:11 - State execute its instructions okay now
140:15 - the process request for the io service
140:17 - or a system call the process may require
140:19 - IO service such as reading from a file
140:21 - or sending a data over the network it
140:23 - makes a system call to request the
140:24 - services this was the part two like it
140:28 - this is the thing which we are
140:29 - discussing now now the process is in the
140:31 - blocked State the process transition to
140:33 - a blocked State while waiting for the
140:34 - requested IO operation to complete while
140:37 - in this state the process is not
140:39 - actively executed instructions hence
140:41 - what the operating system will do it
140:43 - will send this process from memory to
140:46 - the disk to improve the
140:48 - efficiency now the operating Sy system
140:50 - handle the requested iio operation for
140:52 - example if the process requested to read
140:54 - data from a file the operating system
140:56 - would perform the necessary dis ey
140:57 - operation to read the data into the
140:59 - memory now the process resumes for I
141:02 - operation is complete the process
141:04 - transition back to the ready State
141:06 - indicating that it is ready to continue
141:09 - executing the operating system scheduler
141:10 - will determine when to schedule this
141:13 - this thing scheduler we will discuss in
141:14 - the next lecture what is a scheder and
141:16 - dispatcher okay in detail
141:19 - so I hope hope you are getting somewhat
141:22 - what I'm saying but to clarify it fully
141:24 - let us see the legendary seven State
141:28 - process transition diagram we'll clarify
141:30 - from the beginning to the end so the
141:32 - first the new
141:34 - state I hope you know what is a new
141:36 - state it is the state which contain the
141:39 - pcvs of the process which are ready to
141:41 - be loaded in the main memory so the
141:45 - process is created the process is
141:47 - allocated the resources in the ready
141:49 - state
141:51 - the scheduler will schedule the process
141:54 - and dispatch to the CPU so scheduling
141:56 - and dispatching is being done in the
141:59 - ready State the process transitions from
142:02 - ready to the
142:04 - Running by scheder and dispatcher and
142:07 - now three cases are there either it
142:09 - terminates or preemption happens or it
142:11 - needs an IO service from the operating
142:13 - system so if the preemption happens it
142:16 - goes back to the ready state if it's
142:18 - terminate it go to the terminate state
142:19 - it ends and if it requires some IO
142:23 - service it will go to the block
142:24 - State now if it is waiting from a long
142:28 - time the OS will say hey you're just
142:30 - waiting doing nothing in the memory
142:33 - memory is a place for the process which
142:35 - are important you are just waiting here
142:38 - so you can also wait in the dis so it
142:41 - will suspend the process and we'll move
142:44 - to the suspended block State now from
142:47 - suspended block state it can go two way
142:50 - either it will directly resume to the
142:52 - block state or it will go to the
142:55 - suspended ready and from suspended ready
142:57 - it will resume to the ready so the
142:59 - process may follow this path or may
143:02 - follow this
143:04 - path okay so here I have written when an
143:08 - application need to perform an ie
143:09 - operation such as reading or writing a
143:11 - file it make a request to the kernel
143:13 - through a system call the kernel then
143:15 - handles th operation and when the
143:16 - operation is complete it Returns the
143:18 - result to the application so this is the
143:20 - part the IE operation part which I'm
143:22 - discussing here now there is a case
143:25 - there is a new thing which I'm
143:26 - discussing for the first time this is
143:28 - the new thing suppose a process is in
143:30 - the ready State ready to be
143:32 - scheduled for Execution but suddenly OS
143:36 - says Hey process you are getting
143:40 - resources R1 R2 and R3 and I am in the
143:42 - sudden need of resource R1 so I am
143:44 - taking the resource R1 from you so the
143:46 - resource R1 is preempted by the OS now
143:49 - what will happen
143:51 - the process cannot be scheduled because
143:53 - it lacks the resources which it needed
143:55 - so it will go to the block State and
143:58 - when OS will return the resources to the
144:01 - process it will go to the r State
144:03 - again okay so
144:05 - now I have discussed completely what is
144:08 - a process State transition diagram how
144:10 - the process Transit from one state to
144:13 - another now let's address some of the
144:16 - doubts which may arise in your mind so
144:18 - why the process is moved from blogged to
144:21 - the suspended block okay so why the
144:23 - process has moved from blogged to the
144:26 - suspended block let's discuss here the
144:28 - process is moved to the suspended block
144:30 - State due to the resource management and
144:32 - multitasking needs so this is just the
144:34 - formal thing which I've told you already
144:36 - when the process is in Block state it is
144:38 - waiting for an ey operation to complete
144:41 - okay so this was the thing which Ive
144:43 - written there also it is waiting for
144:44 - some eye
144:45 - operation okay however sometime the
144:48 - operating system need to free up the
144:49 - resources like memory
144:51 - so or it might need to pause the process
144:53 - for other reasons like if the user
144:54 - searches to a different application in
144:56 - these cases the operating system can
144:59 - move the process from blogged state to
145:00 - the suspended blog State this is the
145:02 - thing from for these reason the
145:04 - operating system can move the process
145:06 - from blocked state to the suspended
145:08 - block State okay so I have summarized
145:10 - that point to just in to improve
145:14 - efficiency in suspended block State the
145:16 - process is not only waiting for an i
145:18 - operation to complete but it is also
145:19 - swept out of main memory it is in the
145:21 - disk now and placed onto the disk
145:23 - storage this frees of the system
145:25 - resources and allow the operation to
145:27 - work on active processes that's why the
145:29 - process a move from blogged state to the
145:31 - suspended blog State okay so this is the
145:34 - thing once the operation is complete the
145:36 - system resources are now available again
145:38 - the process can be moved back to the
145:39 - main memory and transition to the ready
145:40 - state where it is eligible to continue
145:42 - running on the CPU so that's the thing
145:45 - now the question number two why send to
145:48 - suspend ready instead of ready
145:51 - okay why is the need to send to suspend
145:53 - ready instead of just ready so why don't
145:57 - from this suspended block State why
145:59 - don't we can directly transfer it to the
146:02 - ready State instead of suspended ready
146:03 - State why is it so so transition from
146:06 - suspended block to suspended ready
146:08 - instead of directly to the ready state
146:10 - it is due to the way how operating
146:12 - system works it is the way of operating
146:14 - system it's due to the way operating
146:16 - system manage memory and resources so
146:19 - when a process is in supended blog state
146:21 - it is not in the main memory but it's
146:23 - swept out of the disk this is done to
146:24 - free of the main memory for active
146:26 - processes this is the same thing which
146:28 - is which I am telling you again and
146:30 - again so that you may remember it so
146:33 - when the I operation that the process
146:36 - was waiting for is complete now the I
146:38 - operation is
146:39 - complete this I operation is complete
146:43 - the process becomes ready in a logical
146:45 - sense but it is not in the main memory
146:48 - this is the thing you need to focus upon
146:49 - so when the operation is complete the
146:51 - process is ready in a logical sense but
146:54 - it is in the disk now it was in the dis
146:57 - and even when the I operation is
146:58 - complete the OS has not shifted the
147:01 - process from disc to memory it is even
147:05 - now in the disk only it is red in The
147:08 - Logical sense but it is even the but it
147:10 - is in the dis okay so it is not in the
147:14 - main memory so it is suspended ready
147:16 - State before the process can actually be
147:17 - executed move to the ready State actual
147:19 - ready state it need to be brought back
147:22 - to the main memory from the disk this
147:24 - operation is known as swapping or
147:25 - loading
147:27 - okay you need to remember this point
147:29 - swapping and loading it is important
147:31 - that's why I have put here because it
147:33 - will be an important thing in the next
147:35 - lecture we will learn about the contact
147:37 - switching okay so the decision of when
147:39 - to load the process back to the main
147:41 - memory is made by the operating system
147:43 - based on the various Vector like system
147:44 - load memory uses this is the thing okay
147:46 - now another question why resuming the
147:49 - process from suspended block to block
147:52 - instead of sending it to the suspended
147:53 - ready and then ready so now you may get
147:56 - the doubt that there are two paths from
148:00 - suspended block to reach the ready State
148:03 - path number one this path let me draw
148:05 - again this path and path number two this
148:08 - path which path it should follow in
148:12 - which cases can be the doubt
148:15 - so the process is just waiting in these
148:18 - both stages it's doing nothing nothing
148:20 - but
148:21 - waiting so if the process if the
148:23 - operating system resumes the process
148:26 - from suspended block to block state it
148:29 - we can infer that the operating system
148:31 - has enough resources to bring the
148:33 - process from disk to
148:35 - memory and when the operating system
148:38 - doesn't bring the process from dis to
148:40 - memory just it changes the stage from
148:43 - suspend block to suspend ready the
148:44 - process in both stages are in the disk
148:47 - only it suggest that the operating
148:50 - system is experiencing the lack of
148:52 - resources that's why it's keeping the
148:54 - process in disk and not bringing it to
148:56 - the memory and when the time will be
148:59 - appropriate the operating system will
149:01 - bring the process from suspend ready to
149:03 - ready States it mean when the time will
149:05 - be appropriate the operating system will
149:07 - bring the process from dis to the
149:10 - memory here in the both stages the
149:14 - process is doing nothing but waiting
149:16 - operating system has brought the process
149:18 - from dis to memory before time it means
149:21 - the operating system has enough
149:23 - resources okay so this was all the point
149:26 - let's summarize the full lecture from
149:29 - starting to the end so what was PCB PCB
149:31 - is nothing but the process descriptor we
149:34 - have seen there are several uh
149:36 - attributes pointer what is this pointer
149:38 - we will learn in the next
149:40 - lecture okay process State process
149:44 - number program counter registers
149:46 - everything so there are several stages
149:48 - like new ready running block and wait we
149:50 - have seen the process State transition
149:52 - diagram when the process Transit from
149:54 - one state to another in which cases what
149:56 - is the reason okay we have discussed
149:59 - everything in detail okay so this was
150:02 - all the thing which we have discussed
150:03 - several points and then what's the
150:06 - motive behind suspension several States
150:09 - regarding suspension uh example to
150:11 - explain the suspension
150:14 - properly and then the 7 State process
150:16 - transition diagram in the end and we
150:18 - have taken some doubts
150:20 - now okay you don't have to read this
150:23 - this was something absurd written so
150:25 - here we are ending your lecture
150:28 - goodbye hello everyone welcome to the
150:30 - lecture 10 of operating system Master
150:32 - course in the last lecture we have
150:34 - learned about the process transition
150:36 - diagrams in this lecture we will learn
150:39 - about the scheduling cues and the state
150:41 - queuing diagram okay so we'll first
150:44 - learn about what is a q so Q is a data
150:47 - structure which follows the fif
150:48 - discipline okay okay so I hope you know
150:51 - a little bit about what is a q how it is
150:53 - implemented so Q is implemented using a
150:55 - linked list okay so link list is also a
150:59 - data structure so there are two type of
151:01 - cues on memory que and on dis Q okay so
151:05 - on memory Q has another two types ready
151:08 - q and block Q This correspond to the
151:10 - states ready State and the blocked
151:13 - state so in
151:16 - ricq the
151:17 - pcbs of the process process which are
151:20 - ready to be executed are stored like P
151:23 - PJ PK these are the process which are
151:25 - ready to be executed so ricu contains
151:28 - the list of the pcbs of the ready
151:29 - process so what is a RQ it's a link list
151:33 - which follows the fif discipline okay so
151:36 - I hope you remember the image which I
151:38 - have shared of the PCB so it has the
151:39 - first block named pointer so now you
151:43 - have now you can understand what does
151:45 - that P that pointer mean so this is the
151:49 - PCB and it has a little bit a part of
151:52 - pointer which points to the next PCB
151:56 - just like the link list in link list one
151:58 - node points to the next node so this is
152:00 - the head node and this point to the next
152:03 - PCB then next then next and so on so
152:06 - nodes in this link list are the
152:08 - pcbs and this is the head pointer as we
152:11 - used to have in the linked
152:13 - list and another queue which is in the
152:17 - memory is the block Q block Q Q
152:20 - correspond corresponds to the block
152:22 - state in the process State transition
152:25 - diagram so block Q is also known as
152:27 - divice Q each input output device has
152:30 - its own Q like input output device one
152:32 - has its own device Q one two has its own
152:35 - Q three has its own queue so each device
152:39 - has its own que and it contains the list
152:43 - of the pcbs that get blogged onto that
152:46 - device okay so what does device que
152:48 - contain list of the PCB that get blogged
152:51 - onto that device those processes which
152:54 - are interested in getting the io
152:57 - Services of device one those pcbs are
153:01 - there in this device q1 okay so let me
153:04 - revise again there are two type of qes
153:06 - on memory q and on dis Q on memory Q
153:09 - contain two type of cues ready q and
153:10 - block Q ready Q contains the pcbs of
153:13 - those processes which are ready to be
153:15 - executed and device Q contains the list
153:18 - of the PCB that get blog onto that
153:20 - device for the iio services okay so
153:24 - block Q is also known as device Q these
153:26 - are the same thing device q and the
153:27 - block are the same
153:30 - thing let's now move to the on dis
153:34 - cues so on this queue contain job queue
153:38 - and suspend queue so this is similar to
153:42 - the process State transition diagram the
153:44 - job Q is corresponding to the new state
153:47 - and suspend Q is corresponding to the
153:50 - suspended block and suspended ready
153:51 - state so what does job Q contain it
153:53 - contain the program ready to be loaded
153:55 - in the
153:56 - memory okay and what does suspend que
153:59 - contain it contain the list of the
154:01 - processes that get suspended from the
154:03 - memory onto the disk this is simple to
154:05 - understand these names are
154:07 - self-explanatory
154:09 - okay so let me again revise revision is
154:12 - the important
154:13 - thing we started with the scheding cues
154:15 - cues is a data structure which follows
154:17 - the fee for discipline there are two
154:19 - type of cues on memory and on disk on
154:21 - memory que contain ready q and block Q
154:23 - ready Q corresponding to the ready state
154:25 - which contains the list of the pcps
154:26 - which are of the processes which are
154:28 - ready to be executed by the CPU and the
154:30 - block Q
154:32 - contain there the block Q have several
154:34 - devices q and each device que contain
154:36 - the list of those processes or the PCB
154:40 - of those processes which are blogged
154:42 - onto that device for the io
154:44 - Services okay and on this queue contain
154:48 - two type of cues job Que and suspend Q
154:50 - job Q is corresponding to the new state
154:52 - and suspend Q correspond to these states
154:54 - suspended block and suspended ready job
154:57 - Q contain the program that are ready to
154:59 - be loaded in the
155:00 - memory these are the this is the hard
155:03 - disk it contains several programs now
155:05 - what we have to do we have to load this
155:07 - program into the memory so these
155:10 - programs are stored in the job
155:12 - que okay so I hope I'm clear with this
155:15 - okay now let's move to the state queuing
155:18 - diagram in this diagram
155:20 - we are also showing the cues as well as
155:22 - the states which it correspond hence its
155:24 - name is State queuing diagram which you
155:26 - also written here the state queing
155:28 - diagram so the cycle starts with job
155:31 - Cube the job cube contain list of the
155:33 - pcbs which are ready to be loaded in the
155:35 - main memory out of several ready process
155:37 - the scheduler chooses a one process and
155:41 - then shift the process from or give the
155:43 - control the
155:46 - process
155:48 - okay so now we are moving forward to the
155:51 - state queing diagram topic so the thing
155:54 - is started with job Q job Q contains the
155:56 - list of the PCB which are ready to be
155:59 - loaded in the main memory out of several
156:02 - ready processes the scheduler chooses a
156:05 - process and dispatcher give control of
156:08 - that process instruction to the CPU for
156:10 - execution now there are several
156:12 - possibilities either the process has all
156:15 - its instruction executed by the CPU then
156:17 - the process will terminate and if the
156:20 - process needs some IO operation then it
156:22 - will move to the block State the process
156:24 - needs some system call then also it will
156:26 - move to the block State the process got
156:29 - interrupted by some interrupt then it
156:30 - will also go to the block state or there
156:33 - is a possibility that the time given by
156:36 - operating system to the process for
156:37 - execution in the CPU has expired now the
156:41 - time SL is expired suppose the 10 second
156:43 - was given to the process 10 second is
156:46 - over the process has still not executed
156:50 - all its instruction by the CPU so the
156:52 - operating system will say now your time
156:54 - is over you need to go out and join the
156:56 - ricq again so the time SL expired
156:58 - preemption is done on the basis of time
157:01 - it could be on the basis of some
157:02 - interrupt either a system call so this
157:05 - is the state queuing diagram so we
157:07 - started with the job queue then ready
157:09 - queue then some device queue we can
157:12 - say and then the block Q the same thing
157:17 - now you may wonder what is the fork
157:18 - system called we have also talked about
157:20 - in our previous lecture by the execution
157:22 - of fork system call it creates the child
157:24 - process we have also discussed in our
157:27 - previous dpps okay so if any
157:31 - non-completed process exits from the CPU
157:33 - will join back to the ricq eventually
157:37 - okay firstly it will it may go to the
157:38 - block State and then to the readyq or it
157:41 - may directly go to the RQ in case of
157:44 - preemption okay so this is the handmade
157:46 - diagram again so that you may remember
157:49 - it properly so let's create the state
157:50 - queing diagram we started with the job
157:52 - queue okay it's it correspond to the new
157:55 - state of the process State transition
157:58 - diagram so we started with job que then
158:01 - the program are loaded into the memory
158:03 - it becomes the process out of several
158:05 - ready process the scheduler chooses a
158:08 - one process and transfer to the
158:11 - CPU I know the Scher doesn't do that
158:14 - Scher just chooses the process the
158:16 - dispatcher is the main protagonist here
158:19 - the dispatcher give
158:21 - control to CPU for execution of the
158:25 - instructions of the process okay so
158:27 - scheduling will done out of several
158:29 - ready process one process will be
158:30 - selected and will be given to CPU for
158:33 - execution in case of
158:36 - preemption it comes back to the Rue now
158:39 - there are several possibility either it
158:41 - terminates or it move for to the blog
158:43 - state for some input output operation
158:47 - okay it is also possible that
158:49 - [Music]
158:51 - the process get suspended from ricu so
158:54 - it may get suspend or it may get resumed
158:56 - it can also be suspended from the
158:58 - running state but as we have talked in
159:01 - the previous lecture it is not
159:03 - desirable so this is the state King
159:05 - diagram okay now let's move to the topic
159:09 - schedulers and dispatchers so scheduling
159:12 - mean making a decision and dispatching
159:14 - beans we'll cover it later so first
159:16 - we'll learn about what is a scheder
159:19 - do scheduling what is scheduling making
159:22 - a decision what decision choosing a
159:24 - process out of several processes so
159:27 - where we have to make the decision we
159:29 - have to make the decision in the job
159:30 - queue ready queue suspend
159:32 - queue we have also we we we will also
159:36 - make a decision in the blog que but we
159:39 - will not focus on that we will focus on
159:42 - these three job queue readyq and the
159:43 - suspend que so what is the formal
159:47 - definition of scheduler Scher is the
159:49 - compon ENT of operating system that
159:50 - makes the decision as simple as that
159:53 - what are the three types of scheder
159:54 - long-term scheder short-term scheder and
159:56 - medium-term SCH why we say them as long
159:59 - short and medium these names are given
160:02 - on the basis of frequency of
160:05 - activation you will understand that more
160:08 - long-term Scher what does it do it
160:10 - brings the new process it brings the
160:13 - process from New State to ready
160:15 - state so from job Q to the ready que
160:18 - long long term Scher will work let me
160:21 - speak again from job queue to ready que
160:23 - long-term scheder will work what will it
160:25 - do see this is the hard disk it has
160:28 - several it has several programs that are
160:31 - ready to be loaded in the memory now we
160:33 - have to select only three programs from
160:35 - these six so scheder will choose which
160:38 - program I have to load in the memory so
160:41 - let's say long-term SCH decide this one
160:42 - this one and this one so this decision
160:45 - is made by the long-term scheder so what
160:48 - will long-term scheder do
160:52 - it will changes the state of the process
160:56 - from new to ready I hope you got the
160:58 - point now let's move to the most
161:01 - important shortterm scheder it will
161:03 - schedule the process out of several
161:05 - ready process it will schedule it will
161:08 - choose one process that need to be
161:11 - executed so it is also known as CPU Sher
161:14 - because it give it select the process
161:16 - for execution on CPU now the third
161:19 - scheduler is mid medium-term scheder so
161:22 - what is it responsible for it is
161:24 - responsible for process suspension and
161:27 - resuming so this part this part is done
161:30 - by medium-term scheduler this part is
161:32 - done by shortterm scheder and this part
161:34 - is done by long-term scheder I hope you
161:36 - are now clear with the point let me
161:38 - speak again this part of suspension and
161:41 - resuming is handled by medium-term
161:45 - scheduler this part of scheduling to the
161:47 - CPU is
161:50 - handled by short ter scheder and this
161:52 - part of loading the process from disk to
161:55 - memory is handled by long-term
161:58 - Scher okay so this is the diagram you
162:02 - may read this from job Q to RQ long-term
162:04 - SCH RQ to CPU short-term Scher and for
162:07 - suspension work medium-term scheder is
162:11 - responsible so now another question
162:14 - important
162:15 - question which scheduler controls the
162:19 - degree of
162:20 - multiprogramming now you should remember
162:22 - what is the degree of multiprogramming
162:24 - so I have told you that this is the main
162:29 - memory this is operating system now
162:31 - there are several process in
162:33 - multiprogramming operating system in M
162:35 - minority let's say P1 P2 and P3 so what
162:39 - is the degree of this operating system
162:41 - what is the degree of multiprogramming
162:42 - we will say the degree is three because
162:46 - there are three process in the main
162:47 - memory now whose work is this to choose
162:52 - how many process will go from hard disk
162:55 - to main memory long-term schedu
162:57 - responsible so long-term scheder
162:59 - controls the degree of multiprogramming
163:01 - it loads the new program in the
163:03 - memory okay now we'll move to the
163:06 - dispatcher so how many topics we have
163:08 - covered till now we learned about the
163:10 - sheding cues the state queuing diagram
163:13 - the
163:14 - dispatcher the scheduler and now we'll
163:16 - move to the dispatcher okay so what is
163:18 - the dispatcher dispatcher is responsible
163:21 - for carrying out the activity of context
163:23 - switching now you may wonder what is
163:25 - contact switching so you you you can
163:28 - remember this name from the dpb1 we have
163:30 - discussed contact switching is entirely
163:33 - a kernel mode
163:34 - operation okay so what is contact
163:36 - switching we will discuss it now so
163:39 - contact switching is the activity of
163:41 - loading and saving the process during a
163:43 - process switch on
163:45 - CPU I hope you have understood nothing
163:48 - from this
163:49 - let me explain from an
163:51 - example so this is the radue there are
163:54 - several process p a PB PC and PD lying
163:57 - in the ricq this is the CPU this is the
163:59 - block Q okay so now you are clear with
164:01 - the diagram now you are clear with the
164:03 - situation okay so first firstly the PA
164:08 - was being executed in the CPU the PA was
164:10 - being executed in the
164:12 - CPU now preemption occurs let me speak
164:17 - speak again firstly p being executed in
164:19 - the CPU suddenly preemption occurs so
164:23 - what will this dispatcher will do it
164:26 - will save the context or we can also say
164:30 - PCB it will save the PCB from PA to the
164:33 - radue and will load the PCB of the next
164:37 - process let me let me speak the
164:39 - definition again activity of loading and
164:42 - saving the process during a process
164:44 - switch what is a process switch saving
164:47 - the PCB of the CPU living process so
164:49 - what was the CPU leaving process here PA
164:51 - was the CPU leing process so saving the
164:54 - PCB saving where either in the ricq or a
164:57 - block q that depends on the situation so
165:00 - what is a process switch saving the PCB
165:02 - of the CPU leaving process and loading
165:05 - the PCV of the next
165:08 - process let me let me clarify fully now
165:12 - so at first the context of PA was active
165:15 - there in the CPU so the context of PA
165:17 - was active now suddenly either
165:19 - preemption occurs or PA wants an IO
165:22 - service so what will it do it will leave
165:24 - the CPU so saving the PCB of CPU living
165:27 - process saving where if it is the case
165:29 - of preemption then saving to the RQ if
165:31 - it is the case of IO service then saving
165:32 - to the block Q so saving the pro PCB of
165:36 - the CPU leaving process and loading the
165:40 - PCB of next process now we need to load
165:43 - the PCB because CPU can't remain idle so
165:46 - we save the PCV of CPU living process
165:49 - and we load the PCV of the next process
165:51 - this is the context switch or the
165:53 - process switch so at first the context
165:55 - of P was active now the context of PC is
165:57 - active this is the contact switch now
166:00 - the time taken by the dispatcher to do
166:03 - this this contact switching is also
166:04 - known as contact switching time or CPU
166:07 - scheduling
166:09 - overhead or dispatch latency just
166:11 - remember the names now we will discuss
166:14 - these name when the topic will come like
166:17 - in CPU scheduling we will disc discuss
166:19 - this in
166:20 - detail okay now the next Point
166:22 - dispatcher is not involved in the
166:24 - suspension of process there the MTS will
166:26 - work the important Point regarding
166:28 - dispatcher was it works only with the
166:31 - shortterm scheduler so here here only
166:34 - dispatcher will
166:36 - work in this case the schedulers are
166:39 - there
166:41 - okay so dispatcher Works only with the
166:44 - short-term Sher in case of suspension or
166:47 - loading the process from hard dis to
166:49 - main memory separate or individual
166:51 - schedulers are there like long-term
166:53 - Scher and medium-term scheder so
166:55 - dispatcher has nothing to do with the
166:56 - suspension of the
166:58 - process so let's revise the full lecture
167:00 - now we started with the scheduling cues
167:02 - and then we learned the state queuing
167:05 - diagram then we saw some diagrams the
167:08 - handwritten State King diagram and then
167:10 - we learned about the schedulers and
167:11 - dispatcher what does it do scheder
167:13 - chooses and dispatcher does the rest of
167:15 - the work and then in the end we learned
167:18 - the the we learned about the dispatcher
167:20 - in detail in the next lecture we will
167:23 - learn about CPU scheduling and our this
167:26 - process management section will be over
167:28 - or new section that is CPU Shing start
167:30 - I'm giving you a DPP now you need to
167:32 - solve and explore how the process are
167:36 - scheduled what are the criterias the
167:38 - tiebreaker rules mode of operations
167:40 - every sort of process time like arrival
167:43 - time burst time completion time
167:45 - turnaround time and their formulas the
167:47 - algorithms like FCF FS sjf srtf lrf hrnn
167:52 - round robin priority based multi level
167:54 - Qing everything will be covered in this
167:57 - section and there are so much questions
168:01 - which we will do so my sincere request
168:03 - to you all is first try the question and
168:07 - then see the answer the chances of silly
168:10 - mistakes in this section is very high
168:13 - and it is a totally numerically oriented
168:16 - section there are lots and lots of
168:19 - questions in the DPP and in the lectures
168:22 - so without wasting any more time let's
168:24 - start
168:26 - so there was a thing which I want to
168:28 - discuss uh from the last lecture so I've
168:31 - included that in a form of question so
168:33 - the question says there's a two time T1
168:35 - and T2 T1 is the time between user to
168:39 - colal mode shift and T2 is the process
168:41 - Swit time now which one is bigger so we
168:45 - can easily infer that T2 will be greater
168:47 - than T1 that is process which time will
168:49 - be greater than the user to Kernel mode
168:50 - switch time why because process switch
168:53 - or contact switch is a kernel mode
168:55 - operation itself and the default mode is
168:58 - user mode so we need to shift the mode
168:59 - from user to Kernel while switching the
169:02 - process so process switching time
169:05 - involves the mode shifting time so T2
169:08 - involves T1 so T2 must be bigger than T1
169:12 - now let's move to our main topic that is
169:14 - CPU scheduling what does CPU scheduling
169:16 - means it is nothing but
169:19 - design and implementation of shortterm
169:21 - Scher what was the work of shortterm
169:23 - Scher the work was out of several ready
169:27 - to run process schedule a process for
169:31 - execution on
169:32 - CPU now shortterm Scher must have some
169:36 - criteria to select the process okay so
169:39 - these criteria are included in the CPU
169:41 - scheduling technique so shortterm SCH
169:44 - have function and goal just like the any
169:46 - other component of operating system what
169:49 - is the function of shortterm scheder
169:50 - shortterm scheder so the function is to
169:53 - select a process from RQ to run on the
169:55 - CPU there are several process waiting in
169:58 - the ricq for CPU so selecting out of
170:00 - those waiting process for execution on
170:03 - CPU what is the goal to maximize CPU
170:07 - utilization to maximize the throughput
170:10 - to maximize the efficiency these are the
170:12 - goal and what is the other counterpart
170:15 - minimize waiting time minimize the
170:17 - turnaround time and minimize the
170:19 - response time so you must be wondering
170:21 - what are those waiting time turnaround
170:22 - time and response time you are well
170:24 - versed with CP utilization through point
170:26 - and efficiency now what are those
170:28 - waiting time response time so these are
170:30 - included in the topic process time so
170:32 - there are several we are going to look
170:35 - one by one so the first is arrival time
170:37 - or submission time this is the time at
170:39 - which the process enters the ricq for
170:41 - the first time so there was the hard
170:43 - disk and from hard disk there exist a
170:46 - program so that program will be loaded
170:48 - into main memory so this time when the
170:50 - process arrives in the main memory for
170:52 - the first time or in the ricu for the
170:54 - first time this Pro this time is known
170:56 - as arrival time and the process arrives
170:58 - from hard disk so in terms of State when
171:02 - the process come from New State to the
171:04 - ready State for the first time this is
171:05 - the arrival time why I'm saying for the
171:07 - first time because there will be several
171:09 - time when the process leaves the red EQ
171:11 - and come back again in the redu we have
171:13 - seen this in detail in our last section
171:16 - that is process transition diagram
171:19 - so from new to ready when the process
171:21 - arrives for the first time in the ricu
171:23 - this time is known as arrival time what
171:25 - is waiting time the time is spent by the
171:27 - process waiting the
171:29 - ricu I hope this is all clear so there
171:33 - is a time when the process spends in the
171:35 - ricu waiting for the execution by the
171:37 - CPU so that time will be the waiting
171:40 - time I have represented that time like
171:42 - this so it will be easy to remember what
171:44 - is the burst time the amount of time the
171:46 - process has spent in the running State
171:48 - or the time spent by the process running
171:50 - on CPU is the burst time so the burst
171:52 - time is the time which CPU takes for
171:56 - execution of the process or the time
171:58 - spent by the process running on CPU what
172:00 - is iob time the time spent by the
172:02 - process waiting for I operation in the
172:04 - blogged state so I have represented like
172:06 - this when the process is in blocked
172:07 - State waiting for IO this is the io bu
172:10 - time there's a note Ive discussed that
172:13 - already several time but for the
172:15 - revision purposes I've included that
172:16 - note in most modern operating system
172:18 - when a process initiates an IO input
172:20 - output operation it typically doesn't
172:23 - perform the actual I operation itself
172:25 - what is does instead it usually
172:27 - initiates the operation and then enters
172:29 - a blocked State waiting for the
172:31 - operation to handle the I of operation
172:32 - on its behalf waiting for the operating
172:34 - system to handle the ey operation on its
172:36 - behalf so what does it do it just
172:38 - initiates and the rest thing is handled
172:39 - by operating system okay now the fifth
172:42 - time is completion time as as the name
172:46 - suggests the time when the process
172:48 - shifts it state from running to
172:50 - terminated the time at which the process
172:52 - terminate the time at which the last
172:54 - instruction of the process is executed
172:56 - by the CPU the time at which the process
172:59 - leaves the CPU for termination stage
173:02 - okay so there is a diagram which is
173:05 - known as state timing diagram okay so
173:08 - the first when the process arrives in
173:10 - the Ric is known as arrival time and
173:11 - when the process weights in the ricu for
173:14 - the CPU that is the weight time one
173:17 - weight time one what is weight time one
173:18 - waiting for the CPU for first time and
173:21 - then the
173:21 - CPU executes then start executing the
173:25 - instruction of that process so that time
173:26 - will be the first time suddenly it
173:28 - requires some IO service so it will wait
173:30 - in the block distate that is the io wait
173:33 - and that time will be included in the
173:34 - iobs time it again goes to the
173:36 - Rue and then wait and waits for the CPU
173:40 - for the second time so this is the wait
173:42 - time to and and so on so process arrives
173:45 - in the radue arrival time process
173:47 - running on CPU burst time and process
173:49 - waiting for Io that is IO burst time so
173:51 - I hope this is clear let's move down
173:54 - what is turnaround time turn around time
173:56 - is the time spent by the process between
173:59 - the transitions in the States from new
174:02 - to terminate so it's it's like the
174:04 - lifetime of the process completion time
174:07 - minus arrival time the time which when
174:10 - it's come from hard disk to main memory
174:12 - till the time it get terminated that
174:14 - time is known as turnaround time I hope
174:17 - I am clear
174:19 - SO waiting time can also be expressed in
174:22 - form of turnaround time so this is the
174:24 - lifetime whole lifetime and this is the
174:27 - time it was being either it was being in
174:30 - the running state or it was in the
174:33 - blocked state so the time when the
174:35 - process was in ready state is total time
174:38 - minus when the process was in ready
174:40 - State and the process was in blog
174:42 - distate so I hope this is clear let me
174:44 - write it down this is the total
174:46 - time and this is the time when the
174:48 - process was in uh running
174:51 - State let me write again the running
174:54 - State and this was the time when the
174:56 - process was in log
174:57 - disted okay so waiting time can also be
175:00 - expressed like
175:02 - this let's move to the seventh part that
175:05 - is schedule
175:07 - length what is schedule length say total
175:10 - time taken to complete all n process as
175:12 - per the schedule Suppose there are n
175:14 - process in the Rue this was the Rue 1 2
175:16 - 3 till n so the total time taken by all
175:19 - these process to complete is schedule
175:25 - length Okay so what is a schedule
175:29 - schedule is the order in which the
175:31 - process gets completed like P1 P2 P3
175:34 - this was the order okay so this is a
175:36 - schedule and what is its
175:38 - length we will discuss it after a minute
175:41 - or two so first of that I want to
175:44 - discuss the number of schedule that is
175:46 - possible with n process
175:48 - suppose this is there let's just take
175:51 - this example only so there are three
175:52 - process P1 P2 and P3 how many schedules
175:55 - are possible with these three
175:59 - process think about it suppose there are
176:01 - three students student one student three
176:03 - student student one student 2 and
176:05 - student 3 in how many orders you can
176:07 - arrange the students so in three
176:09 - factorial ways this is a common peration
176:12 - and
176:13 - combination if there are n objects we
176:15 - can arrange those n objects in N fact
176:18 - factorial ways in the same way how many
176:20 - schedule are possible with n process n
176:23 - factorial so is this always true why
176:27 - because this is true only in the case of
176:29 - non preemptive scheding let's take the
176:31 - example of preemptive scheding then with
176:33 - these three P1 P2 and P3 these are the
176:35 - three processes in how many possible
176:38 - schedules or we can schedule this in how
176:41 - many possible ways okay so let's take I
176:45 - first schedule P1 and then P2
176:49 - and then P3 so this was the possible
176:51 - case one when the P1 was completely
176:53 - executed then P2 and then P3 now what I
176:56 - do I schedule let's say two instructions
176:59 - of P1 and then I preempted it now let's
177:02 - say I schedule two instructions of P2
177:04 - and then I preempted it
177:07 - now P1 came again executed it next two
177:10 - in next two instructions then P2 came
177:13 - again then P3
177:15 - came so I hope now you are getting the
177:17 - point that there is a infinite
177:19 - possibility let's start with the P2 and
177:22 - then I instruction I executed two
177:24 - instructions of P2 then P1 came now I
177:27 - executed three instructions of P1 and
177:28 - then P3 came then P1 came again then P2
177:31 - came again then P1 came again then P2
177:32 - came again then P3 came then P1 came
177:34 - then V2 G so there are so many possible
177:37 - ways in preemptive scheduling case so
177:40 - there are infinite theoretically
177:42 - infinite possible ways to schedule end
177:44 - processes if the processes are
177:47 - preemptive in non- preemptive case P1
177:50 - have to execute completely first and
177:52 - then P2 will come it will execute the
177:54 - complete first and then P3 will come
177:57 - let's take another uh case suppose P2
177:59 - came first then P1 and then P3 suppose
178:02 - P1 came first and then P3 and then P2
178:04 - let's take P2 came first and then P3 and
178:06 - then P1 let's take P1 uh P3 came first
178:10 - and then P1 and then P2 P3 came first
178:12 - and then P2 and then P1 so there are so
178:14 - many possible ways okay so is there any
178:17 - other way left P1 came first and then
178:19 - these two shifted and replaced and then
178:22 - P2 came first and then these two these
178:24 - two P1 and P3 and then P3 and P1 these
178:26 - two uh exchanged and then P3 came first
178:28 - P1 P2 and P2 P1 so only these six
178:31 - possible ways are there because in
178:34 - non-preemptive case a process has to
178:36 - complete properly only then a new
178:39 - process will come into the
178:40 - CPU it will not be preempted
178:43 - forcefully so how many schedules are
178:46 - possible with n process and torial if
178:48 - the case is non- preemptive and infinite
178:51 - if the case is
178:52 - preemptive I hope you got the point now
178:56 - we were discussing about the schedule
178:57 - length schedule length was the total
178:59 - time taken to complete all end process
179:01 - so how will you represent schedule
179:03 - length in terms of any formula is this
179:06 - sum of turnaround time is this the sum
179:08 - of life cycle of all the process no this
179:12 - is false because if you add turnaround
179:14 - time fall process it will become more
179:16 - than L that is uh I hope you get the
179:18 - feel of this if you add the life cycle
179:21 - of all the process it will be greater
179:23 - than the schedule length or if you add
179:25 - the bur time of all the process it will
179:28 - include I bur time
179:30 - too
179:31 - so what is l l is the completion time of
179:36 - last process minus arrival time of the
179:38 - first process this is the schedule
179:40 - length what was the schedule length you
179:42 - must focus on the definition total time
179:45 - taken to complete all in process as per
179:47 - schedule total time taken to complete
179:49 - all and process as per schedule so this
179:51 - is the schedule
179:53 - length so the completion time of the
179:55 - last process let's say P3 came at the
179:58 - last so the completion time of P3 where
180:00 - it goes yeah completion time of P3 minus
180:04 - arrival time of the first process that
180:05 - is P1 this is the schedule length that
180:07 - is completion time or arrival time of P1
180:11 - to the completion time of P3 completion
180:14 - time of the last process minus arrival
180:16 - time of the first process this is the
180:18 - schedule
180:18 - length Okay so maximum of CI minus
180:21 - minimum of AI what is CI completion time
180:23 - and what is AI it is arrival time I hope
180:26 - you are clear now now throughput
180:29 - throughput is number of process
180:30 - completed per unit time so let's say
180:32 - there are n process and the total time
180:35 - was schedule length and the throughput
180:38 - will be n by number of process that is n
180:41 - completed per unit Time divid by
180:43 - L now there is another thing that is
180:47 - Contex switching time or scheduling
180:48 - overhead this is also known as dispatch
180:50 - latency so contact switching time or
180:53 - scheduling overhead is Delta we are
180:55 - representing is it with Delta and
180:58 - another point to note is for Simplicity
181:00 - we are just including the loading time
181:02 - we are not including the saving time in
181:04 - this data because it will increase the
181:06 - complexity of the problems process which
181:08 - was already running in the CPU taking
181:11 - that process out of the CPU and saving
181:13 - it somewhere else let's say in the
181:14 - blocked queue that time we are not
181:16 - taking we are only taking the the time
181:18 - for the dispatcher to load the PCB of a
181:21 - process in the radue to the CPU we are
181:23 - taking only that time to be Delta we are
181:25 - not taking this time just for the
181:27 - problem solving purposes just for the
181:28 - sake of Simplicity okay so the time
181:31 - taken by the dispatcher to load the PCB
181:33 - from RQ onto the CPU is Delta that is
181:36 - seding overhead just remember
181:38 - this
181:40 - okay so let's revise what we have done
181:42 - till now so we started our lecture with
181:45 - this that there are T1 and T2 I have
181:48 - discussed that the process switching
181:49 - time involved the mod shifting time then
181:51 - we move to the CPU scheding what is CPU
181:52 - scheding it is nothing but the
181:54 - implementation of shortterm scheder
181:56 - shortterm Sher has a goal and a function
181:58 - and we discuss several process times
182:00 - arrival time the time when the process
182:02 - arrives in the reue waiting time the
182:04 - amount of time is spent by the process
182:05 - in the RQ bu time the amount of time is
182:07 - spent uh by the process running on CPU I
182:10 - time the the time spent by the process
182:12 - in the blogged state completion time the
182:15 - time at which the process
182:19 - completes this is the completion time
182:21 - turnaround time completion time minus
182:22 - arrival time it's also known as lifetime
182:24 - of the process when the process came in
182:28 - the uh when when the process was
182:30 - allocated resources till the process was
182:33 - uh the resources was deallocated from
182:34 - the process that time is turn around
182:37 - time the time is spent with the process
182:38 - between new to terminated State waiting
182:40 - time can also be represented turnaround
182:42 - time that is the total time minus time
182:45 - spent by the process in the running
182:47 - State and the blocked State this was the
182:51 - time spend of the process in the ready
182:53 - state so we can write like this the time
182:56 - spent by the process in ready State plus
182:57 - the time spent by the process in running
182:59 - State plus the time spent by the process
183:01 - in the blocked state is the turnaround
183:04 - time I hope you are clear now so we are
183:07 - not taking we are not making that it
183:09 - that complex that we are including the
183:10 - suspend time and the suspended blocked
183:12 - and no we are just making it simple we
183:16 - are just uh dealing with with the five
183:18 - State transition diagram which we have
183:20 - we have discussed in the initial part of
183:23 - the lecture of process State transition
183:24 - diagram I hope you remember that now so
183:27 - for problem solving purposes we only
183:29 - include
183:31 - that we discussed the schedule length
183:33 - then schedule length is the total time
183:35 - total time taken to complete all in
183:37 - process it is not for a single process
183:40 - the above times which you have seen like
183:41 - completion time and arrival time these
183:43 - are the property of a single process the
183:45 - schedule length is the property or uh it
183:48 - is related with the schedule that is the
183:52 - total time taken to complete all n
183:53 - process it's Collective okay uh now we
183:57 - discussed the formula schedule possible
183:59 - with n process that was n factorial in
184:01 - case of preemptive infinite May
184:03 - possible and then we discuss the formula
184:05 - of L that is the completion time of last
184:07 - process minus arrival time of the first
184:09 - process maximum of completion time minus
184:11 - arrival of uh minimum of arrival time
184:14 - what was the throughput number of
184:15 - process completed per unit time and n
184:17 - represented the number of process and L
184:19 - represented the total time okay then we
184:22 - discussed the contact switching time or
184:24 - scheduling overhead that is Delta for
184:26 - Simplicity we just took the loading time
184:28 - we ignored the saving
184:30 - time so the time taken by dispatcher to
184:32 - load the PCV from Rue onto
184:36 - CPU so we stopped our last lecture at
184:39 - this point what was the Delta it was
184:42 - dispatch latency the time taken by the
184:45 - dispatcher to load the PCB from RQ onto
184:47 - CPU this time is taken and the saving
184:50 - time is
184:51 - ignored now where we need scheduling we
184:54 - not only need scheduling when the
184:56 - process Transit from ready to running
184:58 - state but at different parts of straight
185:01 - transition like running to terminated
185:03 - running to waiting and waiting to ready
185:04 - we also need scheding but our main focus
185:07 - will be on this transition because we
185:09 - are here implementing the short-term
185:12 - scheduler okay so scheduling is of two
185:14 - type preemptive and non- preemptive in
185:16 - algorithms where the process is
185:18 - forcefully
185:19 - deallocated because of the operating
185:22 - system way of working or any time
185:24 - constraint or priority you know all this
185:28 - so that part of scheduling is preemptive
185:31 - scheduling and the rest is non-
185:32 - preemptive where the process completes
185:34 - its last execution it is it leaves the
185:37 - CPU voluntarily that is non preemptive
185:39 - and the preemptive you all know CPU
185:41 - bound process those process which
185:43 - perform a lot of computation in Long
185:45 - burst and very little IO you know what
185:48 - is birth time the time is spent by the
185:50 - process in in running state so CPU bound
185:53 - process are those process which perform
185:55 - long competitions in Long burst it means
185:57 - it take long time with the CPU and very
186:00 - little IO and IO bound process performs
186:02 - lots of IO followed by short bu of
186:04 - computation okay these are the process
186:07 - which are focused on iO and these are
186:09 - the pro process which works lot with
186:13 - CPU ideally system should be the mix of
186:16 - both to make maximize CPU and iio
186:19 - utilization let's say a process only
186:21 - works with a CPU then iio is idle and
186:24 - let's say the process perform lots of IO
186:28 - and and a very less competition than CPU
186:30 - is ID so in ideal
186:33 - case it should be a mix of both to
186:35 - maximize CPU and IO
186:38 - utilization okay so this was all the
186:41 - introduction now we will move to the
186:43 - main part of this that is the algorithms
186:46 - we will learn some algorithms so the
186:48 - first algorithm is first come first
186:50 - serve what is the selection criteria
186:53 - arrival time the process which comes
186:54 - first get scheduled first what is the
186:57 - mode of operation non- preemptive mode
186:59 - of operation conflict resolution suppose
187:02 - two process arrived at the same time
187:03 - then we will choose the process with the
187:05 - lower process ID now I want to clarify a
187:08 - point that for conflict resolution there
187:10 - is a no fixed
187:13 - criteria but the best one is choose the
187:17 - process
187:18 - for lower process idid in any algorithm
187:21 - which we are going to discuss later in
187:23 - the course choose the process with the
187:25 - lower process ID whenever a conflict on
187:28 - selection criteria occurs suppose two
187:30 - process arrive at the same time choose
187:31 - the one with lower process ID
187:34 - okay you must remember that fcfs is non
187:38 - preemptive otherwise you are going to
187:39 - make mistakes there
187:42 - okay we'll also take some assumptions
187:44 - while discussing about these algorithm
187:46 - is time is in clock text we are not
187:48 - talking about some milliseconds or
187:50 - uncond n time is in clock text okay just
187:56 - for Simplicity no IO times and
188:00 - scheduling overhead we will take it as
188:01 - zero in later part of the course we will
188:04 - take or let's say in the next lecture we
188:06 - will take iob buus also and we will also
188:09 - take some significant value of Shing
188:11 - overhead
188:12 - too okay now I hope you get the idea
188:16 - what is CFS suppose the process which
188:19 - comes or arrives first get scheduled
188:22 - first but there is a serious problem
188:24 - with fcfs scheduling so let's say this
188:27 - is the process which arrived first so it
188:29 - says we I could stay here forever anyway
188:31 - I'm not going back to the end of the
188:33 - queue okay so and the operating system
188:36 - says to the these process which which
188:38 - say hurry up I waiting for you you have
188:40 - you with the processor for ages look at
188:42 - the size of that que this is the new
188:44 - process which came which arrived at the
188:46 - last and when these process complaint
188:48 - about the first process to operating
188:49 - system he says sorry first come first
188:52 - served so this is a serious problem this
188:56 - long process causes the starvation so in
188:59 - this course we
189:00 - will uh symbolizes the process with a
189:04 - large bus time as long process and the
189:06 - process with the short bus time as short
189:08 - process okay so large Bus Time long
189:11 - process Short Bus Time short process
189:13 - okay so this is the process which have a
189:16 - large bus time it is a long process
189:19 - which has been with the CPU for ages and
189:21 - these newly arrived process are waiting
189:24 - for that for a long time okay and this
189:27 - process it it has been in a grief that
189:30 - hey there are so many already waiting
189:32 - for the CP so it is just devastated to
189:36 - see look at the size of that queue and
189:37 - operating
189:39 - system give no shits it says sorry first
189:42 - come first start so fcfs causes a
189:44 - serious problem named starvation
189:48 - you can suggest uh why does it come it
189:50 - comes due to its non- preemptive nature
189:54 - okay so this was just for additional
189:56 - information now we will practice some of
189:58 - the fcfs algorithm okay so let's
190:01 - practice the fcfs
190:03 - algorithm so we will be given with this
190:06 - type of uh table these are the process
190:09 - IDs 1 2 and three these are the process
190:12 - ID one signifies the process number one
190:14 - process number two and process number
190:15 - three 80 is the arrival time BT is the
190:18 - first time CT is the completion time
190:20 - turnaround time and waiting time so
190:22 - these are given to us that is the
190:24 - process ID arrival time and the burst
190:26 - time now we need to find the completion
190:29 - time turnaround time and waiting time
190:31 - how we are going to find that how will
190:33 - know that the process one will complete
190:35 - at which time or what is the life cycle
190:38 - time of the or turnaround time of the
190:41 - process one how we will know that for
190:43 - how much time the process waited in the
190:46 - ricu so to solve this we need to learn a
190:49 - technique of making a chart known as
190:51 - Gant chart a Gant chart okay so how we
190:55 - will make this so the first point about
190:57 - the Gant chart which you need to
190:58 - remember is it always start from zero no
191:01 - matter what
191:03 - so what does fcfs algorithm say the one
191:07 - who arrives first get scheduled first so
191:09 - who arrived first all of them arrived at
191:11 - the same point at Time Zero it means
191:14 - when we start looking at this all of the
191:16 - process were in the ricu so we will say
191:19 - the time was
191:20 - zero so all arrived at the same time now
191:24 - what we will use as the tiebreaking
191:26 - rule lower process ID will be scheduled
191:29 - first if the rest arrived at the same
191:31 - time so process number one will be
191:33 - scheduled first so process number one
191:35 - will be scheduled there for how much
191:36 - time it will run in the CPU so this Gant
191:38 - CH represent the CPU this is the CPU I
191:40 - can write here
191:42 - CPU okay so for how much time the
191:45 - process one will be with the CPU for
191:47 - four units so for four units the process
191:49 - will be P1 will be in the CPU and then
191:52 - it will be executed
191:55 - so the process P1 will be over after
191:57 - four time four units now process 2 was
192:01 - already waiting and it will be given
192:04 - more priority than process 3 because of
192:05 - its lower process ID so between P2 and
192:09 - P3 P2 will be scheduled so after P1 P2
192:11 - will be scheduled and for how much time
192:14 - it will be with the CPU for three units
192:16 - so 4 units was the time taken
192:20 - by process one and then later three
192:23 - units that is from 4 unit to S units P2
192:27 - will be with the CPU so we will write
192:29 - for 427 P2 will be there and now the P3
192:32 - will be scheduled for how much time it
192:34 - will it will be with the CPU for 5 units
192:37 - so from 7 unit to 12 unit P3 will be
192:40 - there with the CPU so these are the Bus
192:42 - Time 4 3 and 5 and this is the timeline
192:46 - so in G chart
192:47 - what we represent so this is a Gand
192:52 - chart Gand chart it represent the
192:55 - CPU in this bar we write process and
192:59 - then in the
193:01 - x-axis this
193:04 - AIS time
193:06 - elapsed okay so I hope now I'm clear in
193:09 - G chart is a way of
193:11 - representing a schedule so what is a
193:14 - schedule here
193:15 - P1 then P2 then P3 this was the schedule
193:19 - so G chart represent a
193:22 - schedule and in the x-axis time elapsed
193:25 - is the represented okay so 12 unit was
193:31 - needed to complete the schedule so
193:32 - schedule length will be from 0 to 12
193:35 - this will be the schedule length Okay so
193:39 - what will be the completion time of P1
193:41 - P1 completed at four units so completion
193:43 - time of P1 will be 4 units okay what
193:46 - will be the completion time of P2 P2
193:49 - completed at 7 so the completion time of
193:51 - P2 will be 7 what will be the completion
193:53 - time of P3 12 so 4 7 and 12 this will be
193:57 - the 4 7 and 12 will be the completion
193:59 - time now what is the turnaround time
194:02 - turn around time is completion time
194:04 - minus arrival time so here arrival time
194:06 - is zero so we can say that turnaround
194:09 - time will be equal to the completion
194:11 - time so we can write here as it is 4 7
194:13 - and 12 now we'll see waiting time okay
194:18 - so what is my tip is to you regarding
194:21 - waiting time is you should calculate
194:23 - waiting time with the
194:25 - chart instead going to the formula okay
194:29 - so what is waiting time let's let's look
194:32 - at by the chart so when P P1 arrived at
194:35 - Zer and it get scheduled at the zero so
194:38 - for how much time it waited it waited
194:40 - for 0 time units because when it arrived
194:43 - it get immediately
194:44 - scheduled okay P2 arrived at0
194:47 - when was it scheduled it arrived at Zer
194:50 - it has to wait for 4 units and then it
194:52 - was scheduled so waiting time will be 4
194:55 - and when did P3 arrived it arrived at
194:58 - zero and when it get scheduled it
195:00 - scheduled at 7 from so from 0 to 7 it
195:03 - has to wait so waiting time was 04 and 7
195:08 - I hope you are now clear with this you
195:10 - see if you want to calculate the waiting
195:13 - time with the formula you can also do
195:14 - that so what is with the waiting time
195:16 - turn around time minus bust time so
195:17 - turnaround time was nothing but
195:19 - completion time and burst time was it's
195:21 - written there so you just need to
195:23 - subtract the completion time from Bust
195:25 - time so let's do this completion timeus
195:27 - Bus Time 4 - 4 is 0 7 - 3 is 4 and 12 -
195:31 - 5 is 7 so I have taught you how to
195:34 - calculate the waiting time from either
195:36 - chart or from the formula okay so let's
195:39 - revise let's revise because the next
195:41 - question you have to do that fcfs
195:43 - algorithm first come first sir one who
195:45 - arrived first gets served first if all
195:48 - arrived at the same time then lower
195:49 - process ID will be given preference so
195:51 - here P1 will be scheduled first P1
195:53 - scheduled first it will run for how many
195:55 - units of time four units of time because
195:59 - fcfs is completely nonpreemptive the
196:02 - process will leave the CPU voluntarily
196:04 - okay so we are not talking about any IO
196:06 - here so it will be with the CPU until it
196:08 - completes so from 0 to
196:11 - 4 we will how how did we write four here
196:14 - all right because the bu time of process
196:16 - one was 4 4 so from 0 to 4 P1 will be
196:19 - the will be with the CPU and from 4 to 7
196:22 - three units P2 will be scheduled why
196:25 - because after because this is the
196:30 - priority given while checking the
196:31 - process ID P1 will be given the highest
196:33 - priority and then P2 and then P3 because
196:36 - we give more priority to the lower ID
196:39 - process okay so after uh P2 was over
196:43 - then P3 came it scheduled it was with
196:45 - the CPU for 5 units so from 7 to 12 it
196:48 - was with the CPU so from 0 to 4 P1 4 to
196:50 - 7 P2 and 7 to 12 was
196:54 - P3 okay so let's try another question it
196:58 - says so this was already given to
197:02 - us let's trite
197:05 - so two process arrived at Time Zero
197:08 - process one and process two which will
197:10 - be scheduled first process one will be
197:11 - scheduled first so we will write process
197:13 - one here and for how much time for two
197:16 - bus times so for two units P1 will be
197:18 - with the CPU okay now which will be
197:21 - scheduled P2 will be scheduled because
197:23 - it arrived
197:25 - earlier P2 will be scheduled then rest
197:27 - of the process so how for how much time
197:30 - P2 will be scheduled the bus time that
197:32 - is 1 so from 2 to three p will be there
197:34 - now this get executed completely this
197:36 - get executed now there these are the
197:38 - three process remaining who arrived
197:40 - first among the three process three
197:42 - arrived first because it arrived at two
197:45 - units okay so for how much time it will
197:47 - be executed 3 units so 3 to six 3 units
197:52 - P3 will be executed now these three are
197:55 - completed rest two are remaining who
197:57 - arrived earlier P4 arrived earlier so P4
198:01 - will be scheduled for two units so from
198:03 - 6 to 8 P4 will be there now the last one
198:07 - it gets scheduled for and for how much
198:09 - time four units so 8 to 12 4
198:12 - units so if you are facing problem
198:16 - indirectly doing this you can also make
198:19 - a time and a rue thing so it keep it
198:23 - helps you to keep track of the process
198:25 - which are in the ricq so at Time Zero P1
198:27 - and P2 were present at time two P1 was
198:30 - gone and P2 and P3 was there in the Rue
198:32 - at time two P2 and P3 were there in the
198:34 - Ric okay at time three P3 and P4 were
198:38 - there at time three at time 3 P3 and P4
198:42 - were there because it arrived at unit 2
198:46 - and it arrived at time three so at time
198:48 - three both were present in the ricu at
198:51 - Time 5 P3 P4 and P5 at time 6 P4 and P5
198:54 - so the basic purpose of uh writing this
198:57 - is time and ricu thing is you get to
199:00 - know which process are present in the
199:03 - ricq and among which process you have to
199:07 - compare the arrival time suppose at time
199:10 - Zer we saw P1 and P2 was present so we
199:12 - need to compare the arrival time of
199:14 - these two process only so we'll compare
199:16 - for these two process whose arrival time
199:18 - is more see both are same so now what we
199:20 - will do we will apply the tiebreaking
199:22 - rule that
199:23 - is lower process ID so which has lower
199:27 - process ID P1 is lower process ID right
199:30 - P1 is lower than P2 P2 is higher so we
199:32 - are talking about these numbers okay so
199:35 - so between them P1 will be scheduled
199:38 - first and then P2 so when P1 was getting
199:41 - scheduled for two units at time
199:44 - two P3 was also present and P2 was was
199:46 - also present in the ricu and P1 has went
199:49 - to running and then ex execute and then
199:51 - terminated so P1 was terminated and then
199:54 - at time two P2 and P3 were present in
199:57 - the
199:58 - ricq okay so in this way you can do this
200:02 - and now you have to compare between P2
200:04 - and P3 between P2 and P3 who arrived
200:06 - earlier P2 arrived earlier so P2 will be
200:08 - scheduled P2 will be scheduled for one
200:10 - bu time so at time three we will see P2
200:13 - was gone and P4 came so now we to
200:16 - compare between P3 and P4 so it's just a
200:19 - helping hand if you get more and more
200:22 - confused in how to apply fcfs algorithm
200:24 - it will signify significantly reduce
200:27 - your Sly mistakes let's move to the
200:29 - question number three it's again on fcfs
200:32 - algorithm so this is given to you to us
200:35 - and now we have to calculate completion
200:37 - time turnaround time and waiting time so
200:40 - I'll create the Gant chart and you have
200:42 - to fill the values by seeing the Gant
200:44 - chart so this you have to do as your
200:45 - homework okay so we will see here so
200:48 - there are four process which arrived at
200:50 - different times so the first process
200:51 - arrived at time three so now you may
200:54 - Wonder between time 0 and time three
200:56 - what will CPU do it has nothing to do it
200:59 - will remain idle so from 0 to 3 the CPU
201:02 - will remain idle now I have told you you
201:04 - must remember that in Gant chart you
201:07 - always start with zero so from 0 to
201:10 - three no one was there with the CPU so
201:12 - we will represent this part as
201:14 - Idle now at time P1 came and it get
201:19 - executed with the CPU for five units so
201:22 - from 3 to 8 P1 came at 3 and from it
201:26 - executed till 5 units so from 3 to 8 P1
201:30 - was there with the CPU the next process
201:32 - came at 10 so 8 to 10 again the CPU is
201:35 - idled and from 10 to 12 P2 get executed
201:38 - for two busts okay so for for two unit
201:41 - P2 get executed now the next process
201:43 - that is the P3 which came at time 15 so
201:46 - again from from 12 to 15 CPU is
201:48 - idled the process 3 get executed for 4
201:51 - units so from 15 to 19 P3 will be there
201:53 - with the CPU and then now no idleness
201:58 - because P4 came 1 second before or one
202:01 - unit before the P3 get completed P4 came
202:05 - one unit before P3 came completed P3
202:09 - completed at 19 and P4 came at 18 so
202:12 - there's no idess P4 will wait for one
202:15 - unit until the P3 get completed and then
202:17 - P4 will get immediately scheduled so
202:19 - from 19
202:21 - to 5 minutes more that is 24 P4 will be
202:24 - there so this is the Gant chart and it
202:26 - always start from zero so for CPU was
202:30 - idle for how many units three here two
202:32 - here and three again here so 3 and 3 6 6
202:34 - and 2 8 so CPU was idle for 8 units what
202:38 - is the schedule length what is the
202:40 - schedule length completion time of the
202:42 - last
202:44 - process to AR time of the first process
202:47 - I should speak in opposite order so the
202:49 - arrival time of first process to the
202:51 - completion time of last process this is
202:53 - the schedule length this will not be
202:54 - counted in the schedule length so there
202:58 - is an interesting concept of percentage
203:00 - CPU
203:01 - idleness so what will be the percentage
203:03 - CPU idess for this G
203:05 - chart so one thing you must remember
203:08 - about the percentage CP idess is it is
203:11 - always calculated over schedule length
203:15 - l so we will not see we will not see
203:18 - this part we will only calculate the
203:21 - percentage where CPU was idle for this
203:23 - duration only so the percentage CP idess
203:25 - is calculated over l so for how much
203:28 - time the CP was idled 2 and three so 5
203:30 - units divided by 24 to 23 is 21 so 5x 21
203:36 - into 100 this was the percentage CPU
203:38 - idleness so 5x 21 into let me divide 100
203:41 - for
203:42 - percentage we multiplied by 100 to
203:45 - calculate the percentage
203:47 - so this was the percentage CPU
203:49 - idleness now we will see one more
203:52 - question and then there's a homework for
203:55 - you you have to calculate the percentage
203:57 - CP idleness in this given question okay
204:00 - so let's do
204:02 - this so we are again given with the
204:04 - three things process number arrival time
204:07 - and the burst time okay so let me take
204:09 - this now it's
204:11 - good so we will compare the arrival time
204:15 - who arrived first
204:16 - Pro process to arrived at time three so
204:19 - between 0 to 3 it will be
204:21 - idle and for time three it arrived so P2
204:24 - will be scheduled at time three and it
204:26 - will run for 1 unit from 3 to 4 it will
204:28 - run and then the next process arrived at
204:30 - Time 5 so 4 to 5 CPU will be idle and
204:34 - then process one will be scheduled for
204:35 - two units so from 5 to 7 process one
204:38 - will be there and the next process
204:40 - arrived at time 8 so from 7: to 8 again
204:43 - the CP will be added and the process
204:45 - three will be scheduled at time 8 and it
204:47 - will run for 4 units so from 8 to
204:50 - 12 the process three will be with the
204:53 - CPU so what will be the G chart this is
204:55 - the G chart it always start with a zero
204:57 - what will be the schedule length the
204:59 - schedule length will be the completion
205:00 - time of last process to arrival time of
205:03 - the first process to 12 - 3 that is 9 is
205:07 - the schedule length Okay so in the same
205:11 - way in the same way you should try a
205:13 - question on yourself too so try this
205:16 - question
205:18 - and I have given you the answer that is
205:21 - percentage C is 4X 23 so you you should
205:24 - get get this must remember if such
205:26 - situation arise where the CPU idle for
205:29 - initial part do not include this in the
205:31 - percentage CPU ID L because it is always
205:34 - calculated over the schedule length so
205:36 - we'll only calculate this and this okay
205:38 - so try this and try to get the answer
205:41 - and do not stop until you get this 4X 23
205:45 - okay welcome to the interesting part of
205:47 - CPU scheduling in which we will include
205:50 - the Delta and IUS time too so my
205:53 - intention is not to scare you but this
205:54 - is a new variety of problems which we
205:57 - are going to see in this lecture this is
205:58 - an important lecture sit with pen and
206:01 - paper and first solve the question by
206:03 - yourself when I will say and then see
206:05 - the solution okay
206:07 - so what what is Delta what is the
206:10 - significance of Delta let me explain
206:12 - Suppose there uh suppose take the case
206:14 - in which the Delta is negligible okay P1
206:17 - was there in the RQ at time zero and it
206:19 - has a burst time of 4 units so what we
206:21 - did we used to directly schedule P1 for
206:24 - 0 to 4 we did like that but now the
206:28 - scenario has changed the dispatcher has
206:30 - took two unit of
206:33 - time before the process can start
206:35 - running so from 0 to 2 it was the time
206:38 - taken by the dispatcher to transmit or
206:41 - or Transit the process from ready to
206:43 - running so this was the time taken by
206:45 - the dispatcher and now the process will
206:47 - run
206:49 - for 4 units so initially the process was
206:52 - completing at 4 units of time now the
206:55 - process is completing at 6 unites so
206:57 - completion Time Has Changed okay
207:00 - so don't worry we we will learn about
207:03 - this when we see the problems so in
207:04 - problems we will be given with the
207:06 - process life cycle like first it was
207:08 - with the running first it was running
207:11 - and then it got to blocked State and
207:13 - then again it came uh for running so
207:15 - this is the life cycle which will be
207:17 - given burst time iob bur time and the
207:19 - bur time okay it can also be like iur
207:22 - time burst time and iob burst time that
207:24 - will be a another difficult part this
207:27 - what I'm saying this IO burst time burst
207:31 - time and I burst
207:33 - time so this is a Next Level problem
207:36 - okay so don't worry we will see them one
207:40 - by one so initially in the initial
207:42 - problems we will be given with the burst
207:44 - time IO burst time and the burst time
207:45 - and let's say Delta is one okay so this
207:49 - is we will start with just one process
207:52 - so this is process number one arrived at
207:54 - the RQ at time zero and this is the life
207:57 - cycle that is it was running in the CPU
208:00 - for 3 units then for 5 units it went for
208:02 - Io and then again two units it went it
208:05 - run on the CPU and then it terminated
208:08 - so at time Z P1 was present in the
208:12 - RQ so the load time of dispatcher that
208:15 - it loaded did the PCB of P1 in the CPU
208:19 - it took one unit of time so from 0 to 1
208:22 - the time was taken by the dispatcher and
208:25 - for three units the time was taken by
208:27 - the process to run on CPU so 1 to 4 that
208:32 - is the three unit of time taken by the
208:33 - process to run so and one unit of time
208:36 - was taken by the
208:38 - dispatcher so we have completed for four
208:41 - units we have completed this part okay
208:44 - now the process has went for Io so from
208:47 - 4 to 9 that means the five unit the
208:50 - process was with the io okay and it came
208:53 - back again
208:56 - at time 9 see if you if you directly
209:00 - jumped to the CP lecture
209:02 - without understanding the process State
209:04 - transition diagram you will never going
209:07 - to understand what is going on here see
209:10 - what the process State transition
209:11 - diagram was the process was in the ready
209:13 - State then it moved to the running State
209:15 - and then whenever process get blogged
209:17 - for
209:18 - Io it cannot go back directly here what
209:22 - it will do it will first go to the ready
209:24 - like this and then from readyq it will
209:28 - be
209:29 - scheduled and again there dispatcher
209:32 - will take the load time because what is
209:35 - the straight transition happening here
209:37 - from ready to running from ready to
209:40 - running so dispatcher will take again
209:42 - one unit of time so from 9 to 10
209:46 - let me explain again okay from 0 to 1 it
209:49 - was the time taken by dispatcher to load
209:51 - the process 1 PCB from ricq to the
209:54 - CPU and 1 to 4 was time taken by the
209:57 - process one in the CPU from 4 to 9 that
210:01 - is the five unit is taken by the process
210:03 - at IO at time 9 it came again at the RQ
210:07 - and one unit was taken by the dispatcher
210:09 - to schedule it to the
210:11 - CPU or trans transfer or load the
210:14 - process in CPU
210:16 - and for two units the process ran at the
210:18 - CPU and then it got terminated so I hope
210:23 - this thing is now clear to you
210:26 - okay let's take another
210:29 - question yeah so we did not took the
210:32 - time okay I have written this so the the
210:35 - time taken by dispatcher or the Delta
210:38 - like here one unit it was the only time
210:41 - taken to load the process the saving
210:44 - time was not in included it was
210:47 - negligible
210:48 - hence or we took it we took it as
210:51 - negligible so the time taken by
210:53 - dispatcher only to load was taken but
210:56 - saving was not taken what did dispatcher
210:59 - do it load and save the time taken to
211:01 - load was taken and save was ignored okay
211:06 - question number two okay do you want to
211:08 - try it yourself go ahead be brave and
211:11 - try now I'm giving you the answer so the
211:16 - we are doing the fcfs algorithm so we
211:20 - will compare the arrival time who
211:22 - arrived first process one arrived first
211:24 - so process one will be in the RQ at time
211:26 - zero and the scheduling uh or the
211:29 - dispatch latency is Time 1 so to load
211:33 - the process in CPU it will take one unit
211:36 - of time so to loading P1 it will take
211:38 - one unit and then P1 will run for three
211:40 - units so P1 will run for three units and
211:43 - then for seven units it will go to the
211:45 - iio so from 4 to 11 it will go to the
211:47 - iio and will and it will go back again
211:49 - to the RQ at time
211:51 - 11
211:53 - okay so at Time 4 there was no one with
211:56 - the CPU so OS will decide or scheder
211:58 - will
211:59 - decide there is no one with the CPU and
212:01 - there are there is a process arrived at
212:04 - time
212:06 - two that is ready to be scheduled so P2
212:08 - arrived at time two and no one is there
212:10 - in the CPU at time four so what OS will
212:12 - do OS will say hey P2 you can go in the
212:15 - CPU so P2 will be loaded in the CPU the
212:18 - loading time is 1 unit and P2 will load
212:20 - for 5 so from 5: to 10 P2 will be there
212:22 - with the CPU
212:25 - okay now at
212:28 - 10 at 10 no one is there with the
212:31 - CPU and P3 has arrived at Time 5 and P2
212:35 - went for the iio for two units so P2
212:37 - will return in the RQ at time 12 from 10
212:41 - to 12 from 10 to 12 it was with the io
212:43 - and at 12 it will return in the r Q so
212:47 - at time 10 no one is there with the CPU
212:50 - so what OS will decide there is a
212:51 - process which came at Time 5 is ready to
212:54 - be scheduled at the CPU so why not
212:56 - schedule process three so one unit of
212:59 - time will be taken for loading and
213:01 - then one unit of time is the bust time
213:04 - so 12 11 to 12 P3 will be there now P3
213:10 - will go for Io for till tell to 16 so at
213:13 - time 16 P3 will be there with the
213:17 - ricu so now time 11 P1 came and now at
213:21 - time 12 no one was there with the CPU so
213:23 - o will say Hey listen at time 11 P1 came
213:26 - and no one is there with the CPU hey
213:28 - scheduler why don't you schedule the
213:29 - process P1 again at the CPU so sh would
213:33 - say okay
213:35 - sir P1 will be scheduled and one unit of
213:38 - time was taken for loading and two units
213:43 - of time was taken by P1 at the CPU so
213:47 - from 13 to 15 this will be completed at
213:51 - time 15 P1 will leave the CPU and it
213:54 - will get terminated because this was
213:56 - completed this was completed and this
213:57 - was completed at time
214:00 - 15 the CPU is again empty so o will say
214:04 - hey there is a process which came to the
214:06 - r equ at time 12 why don't you schedule
214:08 - that so okay we will schedule that so at
214:11 - time 15 P2 will get scheduled so one
214:14 - unit of time will be taken for loading
214:16 - and the rest three units will be taken
214:18 - by as a bu
214:20 - time now at time 19 no one is there with
214:23 - the CPU but os's hey there's a process
214:26 - which came at time 16 why don't you
214:28 - schedule that okay sir we'll schedule P3
214:31 - so one unit of time will be taken to
214:33 - load and two units to complete so two
214:36 - units to complete so I hope everything
214:39 - is clear I hope everything is clear so
214:41 - what will be the schedule length
214:44 - completion time of the last process till
214:47 - the arrival time of the first process
214:49 - now there is a very very important thing
214:51 - I want to
214:54 - clarify this
214:56 - timing this loading timing is not a
214:59 - waiting time for the P1 let's say let's
215:03 - let's imagine
215:04 - this suppose you are the process and you
215:07 - are in the RQ and there's a CPU which is
215:09 - empty so what I'm doing
215:12 - now so this is you
215:15 - and this is CPU okay uh let's take a
215:19 - time that is uh you arrived at the
215:21 - process Q at 4:00 and the CPU became
215:24 - empty at 5:00 okay so at 5:00 I said to
215:28 - you hey come on let's go to the CPU CPU
215:30 - is empty
215:32 - now now the time taken by you to go from
215:36 - ricq to the CPU was 10
215:38 - minutes so the CPU started execution on
215:41 - you at 510 so what will be the time you
215:44 - waited
215:46 - you waited for only 1 hour this this
215:48 - time was not the waiting time try to
215:51 - understand this so so this Transit time
215:54 - is not waiting time okay now I have
215:57 - important thing to discuss that system
215:59 - has multiple IO
216:02 - devices this thing you should notice
216:04 - here so from Time 4 to 11 P1 was with
216:07 - the iio from 10 to 12 P2 was with the IU
216:12 - so at time 11 or let's say at time uh
216:16 - 10.5 both P1 and P2 was with the iio
216:19 - this is only possible when system has
216:21 - multiple iio devices and I operation can
216:24 - be concurrent if the system has a single
216:26 - device
216:28 - then P2 has to wait till 10 to 11 until
216:32 - P1 get gets it IO done at time 11 so at
216:36 - 10 to 11 P2 will wait and then from 11
216:40 - to 13 P2 will completes its IO I hope
216:44 - that's clear now
216:46 - and the CPU idleness so during the whole
216:49 - schedule length at what time CPU is Idle
216:52 - No CPU is not idle for any time this is
216:56 - the transit time CPU is not
216:58 - idle okay
217:00 - now let's let's calculate the waiting
217:03 - time so I have told you two ways to
217:05 - calculate the waiting time one from the
217:07 - G chart and from the
217:09 - formula so we'll first calculate the
217:12 - Gant chart okay so P1 was ready at Time
217:15 - Zero when when was it scheduled for the
217:18 - first time it was scheduled at time zero
217:20 - so first the time the weight was
217:24 - zero and then when it came again it came
217:28 - again at time 11 when was it scheduled
217:30 - it was scheduled at time
217:33 - 12 so from 11: to 12 1 unit of time was
217:37 - there to wait in the ricu see I have
217:41 - told you an
217:43 - example that 10 minutes was not included
217:46 - in the waiting time so we will not
217:48 - include this in the waiting time this is
217:50 - Transit time not waiting
217:51 - time will take this time as the time
217:56 - when P1 was actually scheduled okay so
217:59 - P1 only waited from time 11 to 12 when
218:02 - it was finally decided to get scheduled
218:04 - over the CPU okay so the waiting time of
218:07 - P1 was 0 and 1 0 and 1 this was the time
218:12 - P1 waited okay so 1 was the waiting time
218:15 - of of
218:16 - P1 waiting time of P2 it arrived at time
218:19 - two when was it scheduled first time it
218:22 - it was scheduled at Time 4 so two units
218:25 - of time from 2: to 4: this was the time
218:28 - P2 waited in the RQ so two units and
218:31 - when it came again it came again at time
218:33 - 12 when was it scheduled again it was
218:36 - scheduled at time
218:38 - 15 okay so see we will not include this
218:41 - time in the waiting time so it was
218:43 - scheduled at time 15 so from 15 to 12
218:45 - how much time is wa it waited for 3
218:48 - units okay now P3 when did P3 came in
218:51 - the Rue at Time 5 so P3 was there in the
218:54 - Rin Time 5 when was it scheduled it was
218:56 - scheduled at time 11 so see this was the
219:01 - mistake you can do in generally we see
219:04 - this time but now we have to take in
219:07 - account this time also so from 5 5 to 10
219:12 - it waited only we will not include this
219:15 - time time as the waiting time 5 to 10
219:18 - only 5 so 5 will be there see why I'm
219:23 - focusing on this so much that you should
219:25 - not include this time is the waiting
219:27 - time why I'm focusing on this because
219:29 - generally when we calculate waiting time
219:31 - from the chart what we see when it
219:33 - arrived and when did it get scheduled so
219:36 - we directly see like this okay we tend
219:40 - to ignore that
219:41 - part in general cases when there is no
219:44 - scheduling uh or CPU Shing overhead so
219:48 - we tend to ignore this part and we
219:49 - directly take this so this can be a
219:52 - critical mistake you may make okay so
219:55 - you have to remember this part that this
219:58 - is not waiting time you do not include
220:01 - that part in the waiting time okay so
220:04 - five was the waiting time made done by
220:08 - the process 3 at the first and then when
220:10 - it came again in the RQ it came again in
220:12 - time 16 when was it scheduled again it
220:15 - was scheduled at time 19 so from 16 to
220:17 - 19 it it waited for 3
220:19 - units so from chart we calculated the
220:22 - waiting time but you should not
220:24 - calculate the waiting
220:26 - time from formula why not formula
220:29 - because there may be some cases like in
220:32 - this case you may remember your old
220:35 - waiting time formula that is turnaround
220:38 - time minus bust time but here a special
220:41 - case has come that is this is also
220:44 - present this may change the formula that
220:46 - is the weight time as formula was
220:48 - turnaround time minus burst time so
220:51 - according to the formula 15 was the
220:52 - turnaround time 15 was the turnaround
220:55 - time the time spent by the process or
220:57 - the whole life cycle of the process so
220:58 - the turnaround time was completion time
221:00 - minus arrival time so 15 was the
221:02 - turnaround time what was the bu time
221:05 - this was The Bu time that is bus time
221:07 - and the I bu time 7 and 3 10 10 and 2 12
221:10 - so 15 - 12 is 3 so P1 should have waited
221:13 - for three units but it only waited for
221:14 - one unit
221:15 - it so where did we go wrong we ignored
221:20 - that part okay so waiting time in
221:24 - waiting time this will be the formula
221:27 - when we take account as CPU scheduling
221:29 - overhead 2 so turnaround time minus bus
221:32 - time plus I time plus n into Delta
221:35 - number of time a process get scheduled
221:36 - on the CPU so P1 was scheduled for how
221:39 - much time 1 and two so what will be the
221:43 - formula now 15
221:45 - minus this was 12 plus two time it was
221:49 - scheduled and what was the CP scheding
221:51 - overhead 2 so 2 into sorry I think the
221:54 - CP shoulding over was 1 yes one so 1 1
221:58 - into 2 that is 2 so it will come here so
222:01 - 15 - 14 is equal to 1 now the answer is
222:03 - correct so to remove all this begining
222:07 - let's always take a pledge to let's take
222:11 - a pledge to always calculate waiting
222:12 - time from the chart ignore the formula
222:15 - it may make it may let you to make
222:17 - mistake okay take this pledge you will
222:21 - always calculate the waiting time from
222:22 - the chart okay that is the Gant chart
222:24 - you will calculate waiting time from
222:25 - here not the
222:27 - formula let's move to another question
222:30 - in which iob buus time is bus time and
222:33 - then iobs time so this is a great
222:36 - question you should try your you should
222:38 - try this question on your own first and
222:40 - then see the solution so let's see the
222:43 - solution
222:48 - so there are three process which arrived
222:50 - at time zero so all three process was
222:53 - present in the radic at time 0 P1 P2 and
222:55 - P3 were present at Time
222:57 - Zero
222:59 - okay the process started with the iob
223:02 - bus time first and then the bus time
223:04 - came do you think it is possible is it
223:06 - possible for a process to directly go
223:09 - from ready state to the io no this is
223:13 - not possible
223:15 - so how can IUS time come first so this
223:20 - should have been the scenario so the
223:22 - first process go from Runing to running
223:24 - and then from running it should go to
223:26 - the block state that is the
223:27 - io so what a special thing is that when
223:31 - the process get scheduled from ready to
223:33 - running CPU scheduling overhead will
223:36 - come it will execute a single
223:39 - instruction in the CPU and then it will
223:40 - go to the
223:42 - io let me write
223:49 - and then block a process cannot directly
223:52 - go from ready to block unless the case
223:54 - of resource preemption happens but this
223:56 - that's a rare case we are just taking
223:59 - the general scenario so from ready to
224:00 - running and then block can a process
224:03 - directly go to the io no so it has to
224:05 - first go to the running State and then
224:07 - block so when the
224:09 - process Transit from running ready to
224:12 - running State data comes
224:15 - there is a time which dis dispatcher
224:17 - takes to Transit the process from ready
224:20 - to
224:20 - running so Delta will be accounted here
224:24 - okay so what I'm trying to tell you
224:26 - is so when the process P1 will be
224:30 - scheduled at the process P1 will be
224:33 - scheduled at the running and then it
224:35 - will execute a single instruction and it
224:37 - will go to the IU so Delta for P1 will
224:42 - be there one unit of time and then it
224:44 - will will go to the io from 1 to let's
224:47 - say 2 units so from 1 to 3 1 to 3 for 2
224:51 - units it will be the io now the process
224:55 - two will come it will again go to the
224:57 - running State and the time will be taken
225:00 - by the dispatcher will be 1 units so
225:02 - from 1 to 2 P2 came to the running State
225:05 - and then immediately it went for Io
225:07 - immediately went for Io for how much
225:09 - time for four units so for four units it
225:11 - was with the io it came back to the RQ
225:13 - at time six and P1 came back to the r at
225:16 - time three now P3 when did P3 came at
225:19 - time zero so P3 will be scheduled now P3
225:22 - will be scheduled for running and then
225:24 - from running state it will immediately
225:25 - transit to IO so from 3 to how much time
225:29 - six units so from 3 to six that is for 9
225:31 - units it will be the io and at time 9 it
225:33 - will again come back to the
225:36 - RQ now who is in the RQ P1 P2 and P3 are
225:40 - in the ricu at times doots 3 6 and 9
225:43 - respectively so at time three P1 will be
225:45 - scheduled in the running quebe uh what
225:48 - I'm saying P1 will be scheduled from
225:51 - ready to running State okay so again
225:53 - dispatcher will take its own time so 3
225:55 - to 4 will be the time taken by
225:57 - dispatcher for P1 and then P1 will
226:00 - perform its bu time with the CPU so from
226:02 - 4 to 11 P1 will perform its bus time and
226:05 - then from 11: to 12 it will perform its
226:07 - IO for one unit so it will perform its
226:09 - IO and then at time 12 it will come back
226:11 - to the RQ so P1 came back at time 12
226:17 - okay now now now I want to I want to uh
226:22 - tell something important about this P1
226:25 - state it has completed this this and
226:27 - this when the P1 came back at the
226:32 - RQ it has to again
226:35 - schedule to exit Okay uh let me again
226:39 - Mark the point so first the P1 was in
226:41 - the RQ it goes to the running state for
226:44 - this
226:45 - so that it can go to the block state to
226:47 - perform the io of two units it again
226:50 - performed the io of two units now when
226:52 - it performed the I of two units it came
226:54 - back to the ready State and then it was
226:56 - again scheduled to perform the bus time
226:58 - for S units okay it performed the bus
227:00 - time and then it was uh it go to the
227:03 - block state to perform the I of one unit
227:05 - okay the I of one unit is performed now
227:08 - the process has done its every part now
227:11 - the process want to terminate how can it
227:13 - terminate I have to told several times
227:15 - that process can terminate only from the
227:17 - running state so it will go again there
227:20 - at the right State get scheduled again
227:22 - and from running state it will terminate
227:25 - so this was the important point or this
227:26 - was the beauty behind this question so
227:28 - P1 will be scheduled again P1 will
227:30 - schedule again it will execute its exit
227:33 - instruction the last instruction and
227:35 - then at time 49 it will
227:38 - terminate okay so where were we in the
227:41 - diagram so P1 completed
227:45 - it came at time 12 okay so now at time
227:49 - 11 now at time 11 who is present in the
227:52 - ricu at time 11 P2 and P3 both are
227:54 - present so which we will take P2 we will
227:57 - take so P2 will get scheduled due to its
227:59 - lower process ID when P2 will be
228:01 - scheduled the dispatcher will take one
228:02 - unit of time and then P2 will take its
228:05 - 14 unit of BU time so 14 unit of BU time
228:08 - taken by P2 now the time is 26
228:12 - okay P2 will go to the I P2 will go to
228:15 - the io for time 28 so at time 28 P2 will
228:19 - go back to the RQ this is clear now at
228:22 - time 26 CPUs is ID there's no one with
228:24 - the CPU so we need to schedule a process
228:27 - for CPU so who is in
228:29 - the redq P3 and P1 are present in the RQ
228:32 - at time 26 so we will schedule P3 so one
228:35 - unit of time taken by the dispatcher and
228:38 - P3 will take 21 units of time as a burst
228:40 - time so 21 unit of time as the burst
228:42 - time has taken and then three unit as IO
228:44 - so 48 to 51 at 51 the P3 will be again
228:48 - at the RQ now at time 48 who CPU is Idle
228:52 - who will come who will come now P1 will
228:54 - get scheduled so P1 will get
228:57 - scheduled it got terminated and then who
228:59 - will be get scheduled P2 will get
229:01 - scheduled so P2 will get scheduled for
229:03 - how much time no time see see
229:06 - see no time no time no time to execute
229:10 - just a single instruction exit and then
229:12 - it will terminate
229:15 - so this was the time taken by dispatcher
229:17 - process took negligible time again the
229:19 - time taken by the dispatcher process
229:20 - took negligible time from 50 to 51 no
229:23 - one was present in the Ric Cube at time
229:26 - 51 P3 came so for 50 to 51 CPU will
229:29 - remain idle at time 51 P3 came so P3
229:33 - came at time 51 P3 will get scheduled
229:35 - one unit toen by the dispatcher and
229:37 - nothing was taken by the P3 because it
229:40 - has to execute a single instruction only
229:42 - and then it will execute so let me
229:45 - clarify the whole question
229:47 - again so at first process need to come
229:51 - to the running state so that it can go
229:53 - for
229:55 - Io and at last process need to come at
229:59 - the running state so that it can
230:03 - terminate and in between the simple uh
230:05 - thing which we were doing was the same
230:08 - so this was the part which was good
230:10 - about this question okay so let me
230:12 - clarify again so what happened here
230:17 - there were three process initially we
230:19 - scheduled the process based on the lower
230:21 - process ID Delta was the time taken by
230:23 - the dispatcher and then process executed
230:25 - or the process took its time in the
230:28 - blocked State when the OS performed its
230:30 - I operation so 1 2 3 this was the I
230:33 - operation done by the process and then
230:35 - at time three P1 will came so we did
230:38 - like this so there's one important thing
230:41 - that when the time when the time when
230:43 - the process completes IO you should
230:46 - remember to transfer that process to Rue
230:48 - and write the time above it otherwise it
230:50 - will be confusing suppose at time let's
230:52 - say 50 at time 50 if you did not write
230:55 - the time here 51 you may forgot that the
230:58 - P1 the P3 came at 51 and it there's a
231:02 - slight chance possible that you
231:05 - schu P3 at time 50 if you fail to write
231:08 - here 501 okay so what my advice to do
231:11 - such complex question is make ricu
231:15 - and
231:16 - then uh do the calculations for the Gant
231:19 - chart you have any problem understanding
231:21 - this question try to do do this on your
231:23 - own explore okay watch the video repeat
231:26 - the video
231:30 - okay so this was an important question
231:33 - to clarify your fcfs Concepts this was
231:36 - the hardest question possible in the
231:37 - fcfs okay uh another next category could
231:40 - be that there is only single I this will
231:43 - this will be the supreme god question
231:45 - for fcfs if I say the iobt comes first
231:49 - there is a CPU shiing overhead and there
231:51 - is a single iio device that will be the
231:54 - Supreme question or the hardest question
231:56 - that can be formed on fcfs okay but that
231:59 - is not required and academics level so
232:01 - we will just go with
232:03 - this
232:06 - okay so this was the important concept
232:08 - here from ready to running to go to the
232:11 - block distate from ready here the
232:12 - process want to to go to the block
232:14 - distate from ready state so it cannot
232:16 - directly go from ready to block it has
232:18 - to come to the CPU first it has to come
232:21 - to the CPU first execute a single
232:23 - instruction for iio for Io it will
232:25 - execute a system call and then the OS
232:28 - will allow the process to go to the
232:29 - blocked
232:31 - State and when the process want to
232:34 - terminate so here the process was in
232:36 - blocked State and it want to what is
232:38 - going
232:40 - on so here the process wanted to
232:42 - terminate but it cannot directly
232:44 - terminate at from blocked state so it
232:46 - has to go to the running State that's
232:48 - why these three part came okay so this
232:51 - was an really good question now here are
232:53 - the tips to solve such question always
232:55 - create time and ricu thing this is
232:58 - must okay start G chart from zero this
233:01 - is also a good tip always remember
233:04 - transition diagram if you forgot the
233:05 - transition diagram you may make a
233:06 - mistake of including of not including
233:09 - this and this part in the Gant
233:11 - chart do not include the delta in the
233:14 - waiting waiting time while including
233:16 - while calculating from the chart okay so
233:19 - these are the four tips let me read
233:20 - again always create time in ricu things
233:22 - start gting chart from zero always
233:24 - remember transition diagram and do not
233:26 - include Delta in waiting
233:28 - time we stopped our last lecture at this
233:31 - amazing
233:32 - question this was a really good question
233:35 - in which the process started with the io
233:37 - bu time and then bu time and then again
233:39 - came the iur time in this question the
233:42 - process need to go to the CPU first and
233:44 - then block Q it will execute a single
233:46 - instruction on the CPU let's say the
233:48 - system call so that it can go to the
233:50 - block que and when it came back when it
233:53 - has completed all its IO and in and it
233:56 - came back for termination it has to
233:58 - again go to the CPU to execute a single
234:00 - instruction let's say exit instruction
234:02 - to
234:04 - terminate so this
234:06 - part and this
234:09 - part people generally misses because
234:12 - they do not have a conceptual
234:14 - understanding understanding of process
234:15 - transition diagram which we have okay so
234:18 - we also seen some tips like we need to
234:21 - always create time and ricu we should
234:23 - start our G chart from Time Zero we
234:26 - should always remember the transition
234:27 - diagram okay like in this question and
234:31 - we should not include the dispatch Laten
234:33 - in waiting time okay now I have another
234:37 - question for you a simpler one so you
234:40 - need to do the same question with
234:42 - dispatch latency as zero and you need to
234:44 - find the CPU idleness and the schedule
234:47 - length the answer is this so I request
234:50 - you to solve the question first and then
234:53 - until the answer arrives you need
234:55 - to you need to fight okay so let's see
234:59 - the answer
235:01 - now so we are solving with zero dispatch
235:04 - latency okay so in the radue at time
235:06 - zero three processes process 1 2 and
235:08 - three were available so these proces are
235:10 - present at time
235:12 - zero so we'll schedule this process at
235:14 - Time Zero again the process need to go
235:18 - from ready state to block state but it
235:20 - is not possible unless the case of
235:23 - resource preemption is there so for
235:25 - ready Q to block Q it has to go to the
235:28 - running State first and then it can go
235:30 - to the block Q so it will come to the
235:32 - CPU execute a single instruction let's
235:34 - say for negligible time and then it will
235:36 - go to the io so it will perform a two
235:39 - unit of IO and then at time two it will
235:41 - again go to the
235:42 - RQ so from 0 to0 P1 was executing in the
235:46 - CPU and then for two unit it went for
235:48 - the iio and at time two it came back
235:50 - with the ricq same stories for P2 from 0
235:53 - to Z it performed the a single
235:55 - instruction at CPU it went for Io for
235:57 - four units at and at time four it came
236:00 - to the RQ similarly for B3 it came to
236:02 - the RQ at time
236:04 - six okay
236:07 - now now at time two at time two P1 was
236:13 - there but from 0 to 2 there was no one
236:17 - with the CPU so from time 0 to time 2
236:20 - the CPU will remain idle because the
236:22 - first process which came in the Rue for
236:25 - CPU came at time two so from 0 to two
236:29 - CPU was idle at time 2 P1 came for
236:31 - performing the seven unit of verst time
236:33 - so from 2 to 9 that is the seven unit P1
236:36 - will be with the
236:38 - CPU at time 9 it will go for Io so for
236:43 - one unit so it will came back to the
236:45 - ricu at time 10 so P1 was back in the
236:48 - ricu at time 10 now at time 9 who was
236:52 - who are in the readyq ready to be
236:54 - scheduled so till time 9 P2 and P3 are
236:57 - available who will be schedule now the
237:00 - process which came earlier who came
237:02 - earlier P2 came earlier so we will
237:03 - schedule P2 for how much time for 14
237:06 - unit so from 9 to 23 that is the 14 unit
237:09 - P2 will be with the CPU at time 23 it
237:13 - will go to perform IO so from 23 to 25
237:16 - it be it will be performing IO and at
237:18 - time 25 it will come back to the RQ now
237:21 - at time 23 which processes are in the
237:24 - CPU so at time 23 P3 and P1 are present
237:28 - who came earlier P3 came earlier so we
237:30 - will schedule P3
237:32 - now from time
237:34 - 23 to 44 that is the 21 units of BU time
237:38 - P3 will be there with the CPU and at
237:40 - time 44 it will go to the io so it will
237:43 - perform IO for three units of time and
237:45 - at time 47 it will come back to the
237:48 - ricq so at time 44 which processes are
237:51 - present in the ricq so P1 and P2 are
237:54 - present in the ricq so we will schedule
237:56 - P1
237:57 - now P1 will be scheduled for how much
238:00 - time see this part was completed this
238:02 - part was completed this part was
238:03 - completed too now P1 will come to the
238:06 - CPU just for performing a single
238:08 - instruction that was the exit
238:09 - instruction so it will come to the CPU
238:12 - for negligible time let's say for time
238:14 - zero so from time 44 to time 44 P1 will
238:17 - be the with the CPU performing a single
238:19 - operation and then it will end so P1
238:21 - ended and it didn't come back to the
238:23 - ricu because the process is complete now
238:25 - now we will schedule P2 according to the
238:28 - arrival time again P2 will execute a
238:30 - single instruction and then it will
238:32 - terminate now at time 44 who is present
238:35 - in the ricq see no one is present in the
238:37 - ricq these all process gets terminated
238:39 - at time 47 P3 came so from time 44 to 47
238:44 - CPU will remain idle and at time 47 P3
238:47 - will come to the CPU for executing a
238:49 - single instruction that is the exit
238:50 - instruction and then it will
238:52 - terminate so I hope thing is clear
238:56 - now if you made some mistake try to
238:59 - analyze where did you lag in your
239:01 - Concepts okay so what will be the
239:04 - schedule length completion time of the
239:06 - last process till the arrival time of
239:07 - the first process so this will be the
239:09 - schedule length that is the 47 and what
239:11 - is the CPU idleness CPU was idled for 2
239:13 - units here and three units here so total
239:16 - 5x
239:17 - 47 okay I hope it is clear uh now you
239:21 - have to calculate for part A for this
239:23 - part you have to calculate the CPU
239:24 - overhead
239:26 - activity dispatcher was working for how
239:30 - much time divided by the schedule length
239:32 - total time dispatcher time upon total
239:35 - time that will give the percentage CPU
239:37 - overhead activity so total time was
239:39 - completion time of the last process that
239:41 - is 53 till the arrival time of the first
239:43 - process process processes were ready uh
239:45 - processes arrived at the Ric time Z from
239:47 - 0 to 52 that will be the schedule length
239:50 - so from 0 to 52 52 will come at the
239:52 - denominator for schedule length and for
239:54 - how much time the dispatcher was active
239:57 - so percentage CP you overhead 1 2 3 4 5
240:01 - 6 7 8 and 9 so 9 by 52 will be the
240:04 - answer that will give the percentage CP
240:06 - over reductivity okay to calculate the
240:08 - percentage you need to multiply it by
240:10 - 100 now if I ask what will the
240:12 - percentage CPU efficient
240:14 - then total minus percentage C over
240:19 - activity plus percentage CV or you can
240:21 - calculate directly like the time when
240:24 - the CP was active efficiently working
240:27 - was this time this time and this
240:32 - time this is nothing this is nothing and
240:34 - this is nothing so you can calculate
240:35 - like this or if you have already
240:37 - calculated the percentage CP over acity
240:39 - and percentage CP ID you can directly
240:41 - subtract them by 100 and you will get
240:44 - your answer for percentage CPU
240:45 - efficiency now I have three good
240:48 - questions for homework and you must
240:50 - solve it otherwise if you just seeing
240:52 - the video and do are not solving the
240:54 - homework question which I'm giving you
240:57 - will lag behind in the end okay you'll
241:00 - eventually not make the most out of this
241:01 - course okay so you need to solve the
241:04 - question which I give to you similarly
241:06 - this question for Shing overhead equals
241:10 - to two and uh Next Level question for I
241:13 - iobt first then BT and then iobt for
241:16 - scheding over length equals to
241:18 - scheduling overhead equals to 1 now a
241:20 - third
241:21 - question try question one and two we
241:24 - need to try this question and this
241:25 - question assuming system has only one IO
241:29 - device did we discuss a question uh in
241:32 - which the system has only one I device
241:34 - this is see if you are getting scared by
241:37 - this question number three do not get
241:38 - scared it is as simple as the previous
241:40 - ones are what you need to do just take
241:43 - into account
241:45 - that just like CPU we were doing that
241:48 - there can be only one process in a CPU
241:50 - at a time in the same way you have to
241:52 - take into account that there can be only
241:54 - one process performing Io if the if
241:57 - another process want to perform IO at
241:59 - the same time then it has to wait until
242:01 - the first first process completes its IO
242:04 - so you need to take account an
242:05 - additional waiting time okay it is not
242:08 - as hard as it seems okay so you need to
242:10 - try question one and two you need to try
242:11 - this question and this question
242:14 - if the system has only one IO device if
242:16 - one process is performing the io other
242:18 - has to
242:19 - wait okay so I want you to try
242:28 - them now it is the time to discuss the
242:30 - homework question which I have given you
242:32 - for fcfs algorithm so there are three
242:35 - process available along with the arrival
242:38 - time and their lifetime it was first
242:41 - with the CPU then IO and then the CPU so
242:44 - let's start so which process is
242:46 - available at time Z P1 is available so
242:48 - P1 will be scheduled and the dispatch
242:49 - Laten is two so two unit will be taken
242:51 - by dispatcher and three unit will be
242:54 - taken by P1 now at time five which
242:57 - process are available at in the ricq P2
243:00 - is available so two unit will be taken
243:02 - by the dispatcher and two unit will be
243:05 - taken by
243:06 - the P2 now you may see there is no IO it
243:11 - means zero unit of IO performed it means
243:14 - the process didn't even go for the io
243:17 - that means the process will continue
243:19 - till completion so from 7 it will go
243:24 - till 12 at time 12 which process is
243:27 - available so P1 went for the io at Time
243:31 - 5 for 4 unit so it will return back in
243:33 - the radue at time 9 so P1 will be
243:35 - available at time 12 so we will schedule
243:38 - P1 there two unit will be taken by the
243:40 - dispatcher and two unit will be taken by
243:43 - the the P1 so 12 to 14 dispatcher and 14
243:46 - to 16 taken by the P1 now at time 16
243:49 - which process are
243:52 - available no process available P3 came
243:54 - at time 20 so from 16 to 20 CP will
243:58 - remain idle at time 20 P3 will get
244:01 - scheduled so from 20 to 22 the dispatch
244:04 - latency P3 will be scheduled and for one
244:06 - unit it will with the CPU at time 23 it
244:10 - will go for 15 unit of IO so from 23 to
244:13 - to 38 the process have gone for Io and
244:17 - no processor is available in the Radu at
244:19 - time 23 so CPU will remain idle at time
244:23 - 38 the P3 will go back in the radue so
244:27 - at time 38 P3 will be available for
244:29 - scheduling we will schedule P3 two unit
244:31 - will be taken by dispatcher and six unit
244:33 - will be taken by the P3 and then at time
244:36 - 46 all of them will end let's move to
244:39 - the question number
244:40 - two in this question there are three
244:42 - process and three uh and their arrival
244:45 - times in their life cycle is given so
244:47 - this question was the special one as we
244:49 - discussed earlier in the lecture the the
244:52 - process directly want to go to to the
244:54 - block Q from ready but this is not
244:57 - possible as you know so the process has
244:59 - to go to the running State and from
245:02 - there it can go to the block State and
245:05 - from block when it will complete its IO
245:07 - for the last time it it cannot go
245:09 - directly to exit state so first it has
245:12 - to go to the ready State and then then
245:13 - it has to go to the running State and
245:15 - then it will
245:16 - terminate so when the process will go
245:19 - from ready to running for the first time
245:21 - it will execute a single instruction
245:23 - that is the system call and when the
245:25 - process want to terminate directly from
245:26 - the Block state it has to go to the
245:28 - running State first VI ready state to
245:31 - execute a single instruction that is
245:32 - exit so we will assume that it took
245:35 - negligible time to exit to
245:38 - uh execute those instructions so we took
245:41 - 10 and one and and 11 can you see from
245:45 - 11 to 11 from 10 to 10 from 1 to 1 so
245:48 - these are the time taken to execute just
245:50 - a single instruction for the first phase
245:52 - the instruction was system call and for
245:53 - the last phase like this one
245:57 - and and this one and this one so these
246:01 - are the exit instructions so I hope you
246:03 - can do that now uh I know I have made a
246:05 - Sil mistake here I was very exhausted
246:08 - while solving these questions so I made
246:11 - a mistake that from time 0 to 3 the CPU
246:14 - will remain idle but I forgot that the
246:17 - process the first process arrived at
246:19 - time three so I started with time zero
246:21 - so you have to shift the whole timeline
246:23 - by three units but that won't work
246:26 - because there are some idle patches in
246:27 - the Gart so you have to do this question
246:30 - whole again this is wrong the
246:31 - calculation is wrong but the concept is
246:33 - correct you have to do as I have told
246:35 - you in the concepts remember the
246:36 - transition diagram and check again
246:39 - because the chances of s mistakes in
246:41 - these questions are very high let's
246:43 - solve the question number
246:45 - three so the question number three was
246:48 - you have to solve the about two question
246:49 - with
246:50 - a with assuming that there is only one
246:52 - IO why why don't we take a new question
246:55 - and we will assume that the
246:57 - non-concurrent io is present it means
246:59 - the whole system has only a single IO
247:01 - device so let's start so process 1 2 3
247:05 - arrival time is given and their life
247:07 - cycle so which process is available at
247:09 - time Z P1 is available in the rad at
247:11 - time Z so we will schedule P1 and we
247:13 - have assumed that the dispatch Laten is
247:15 - zero so we will directly schedu P1 we
247:16 - schedu P1 at Time Zero it will run for
247:18 - two units it will run for two units and
247:20 - then it will go to iio for 2 to 2 to 7
247:23 - for 5 units for 5 units it will go to
247:26 - iio so till time 7 P1 will Beck the
247:30 - io let's discuss about the CPU so at
247:34 - time 2 P1 went for the io so CPU is Idle
247:37 - now but there is a process ready to be
247:40 - scheduled in RQ that is P2 so why don't
247:43 - we P2 we scheduled P2 for three units of
247:45 - time so from 2 to 5 P2 will be the CPU
247:48 - and for 10
247:50 - units P2 went for the io so P2 went for
247:54 - the io for how much time for 10 minutes
247:55 - so from 5
247:58 - to 10 from 5 to 10 P2 has to go to the
248:02 - io but but
248:04 - but there's only a single device which
248:07 - will which is being used by the process
248:09 - 1 till time 7 so from 7 5 to 7 it has to
248:13 - wait until the I device becomes
248:15 - empty then from 7 to 17 for 10 units P2
248:20 - will work so you have to account this
248:23 - waiting time also because there is a
248:25 - single IO device so when it will be
248:27 - emptied by P1 then only P2 can go to
248:29 - that device so from unit 5 to unit 7 it
248:32 - has to wait and from 7 to 17 this will
248:35 - execute this uh or from 7 to 17 it will
248:37 - use di services for 10 minutes of time
248:40 - okay now let's discuss about the C CPU
248:42 - then at time which process is present in
248:44 - the CPU P2 and P3 both are present but
248:46 - P3 and went for the iio so P2 is went
248:49 - for the io so P3 is the only process we
248:50 - will schedu P3 for one unit of time so
248:52 - from 5 to 6 P3 will get scheduled and
248:56 - from and then it has to do three units
249:00 - of IO so it will wait until the process
249:03 - two leaves the io at time 17 at time 17
249:06 - it will do three units of IO from 17 to
249:08 - 20 it will come back in the radue at
249:10 - time 20 P2 will come back in the radue
249:12 - at time 17 and P1 will come back in the
249:14 - Rue at time 7 so from 6 to 7 there's no
249:17 - process available in Rue for scheduling
249:19 - so the CPU will remain idle at time 7 P1
249:22 - will get
249:23 - scheduled for three unit of time so from
249:27 - 7
249:28 - to what I've have
249:30 - done oh no I again made a mistake here
249:33 - you should not try this question when
249:35 - you were exhausted so from 7 to it
249:39 - should be 10 it should be 10 so it
249:40 - should be 10 so from 7 to 10 P1 will uh
249:45 - execute at rest of the bust time that is
249:47 - the three unit of time at time 17 so
249:50 - from 10 to 17 the CP will remain idle at
249:52 - time 17 P2 will come P2 will execute its
249:55 - two unit of IO so from 7 to
249:57 - 19 uh it's not I it bus time so it will
250:00 - execute two unit of its bus time so from
250:02 - 17 to 19 P2 will work
250:05 - and and at time 19 no process is present
250:08 - in the ricu the process P3 came at the
250:11 - ricu at time 20 so from 19 to 20 the CPU
250:15 - will again remain idle and at time 20 P3
250:18 - will get scheduled for the 5 unit of its
250:19 - first time remaining so at time 25 this
250:22 - will be over so I hope there is no
250:25 - confusion but I'll explain it again so
250:27 - what we have
250:29 - done what we have done this is 10 okay
250:32 - so what we have done
250:33 - now we will assume that there is only
250:35 - one IO device and if there is only one
250:37 - IO device the process has to wait until
250:40 - the previous process exits the io
250:43 - hi we completed our fcfs algorithm in
250:46 - the last lecture and from this lecture
250:48 - we will start our new algorithm that is
250:50 - the shortest job first so as the name
250:52 - suggest what you think about it in fcfs
250:55 - we scheduled that process which arrived
250:56 - first so in sgf that is the shortest job
250:59 - first we will schedule those process
251:02 - which has a less less burst time so this
251:05 - is based on the burst time the amount of
251:06 - time the process spends with the CPU if
251:08 - the process has less bus time it will be
251:11 - given higher priority than the process
251:13 - which as a large bus time so we will
251:15 - represent those process which is a high
251:16 - bus time as a long process and the
251:19 - process Which is less bus time or short
251:21 - bu time is short process so short
251:23 - process are given priority than the long
251:24 - process in shortest job first and like
251:27 - fcfs it is non preum to so a process
251:30 - cannot be forcefully
251:32 - deallocated okay so for conflict
251:34 - resolution as we did in the fcfs we will
251:36 - take the lower process ID see if P1 and
251:39 - P2 both has the same bus time then we
251:41 - will schedule P1 first okay okay so
251:44 - among the process present in the ricu
251:46 - select the process with least bust time
251:48 - and schedule it on the CPU so this is
251:49 - the line you have to remember for
251:51 - shortest job first among the process
251:53 - present in the RQ we need to select
251:55 - those process which have least bus time
251:58 - and schedule it on CPU okay let's solve
252:01 - the question so these were the processes
252:04 - and these are the arrival time and these
252:05 - are the bus time this is the thing which
252:07 - will be given to us okay
252:09 - now remember this point remember this
252:12 - point among the process present in the
252:15 - Rue among the process present in the
252:16 - radue we need to compare the bus time of
252:19 - only those process which are already
252:21 - present in the
252:23 - Rue all already remember this word
252:27 - already present in the Rue do not
252:28 - compare those process if they are not
252:31 - present in the ricu okay so a process
252:35 - arrived at time zero so P1 arrived at
252:37 - Time Zero we will schedule P1 no matter
252:40 - what because this is the only process
252:41 - present in the ricu now so we will
252:44 - schedule P1 and if P1 is scheduled in
252:46 - non preemptive algorithms then it will
252:49 - not exit CPU unless it has completed all
252:52 - its instruction or it need to perform
252:54 - the io okay so here I the case of I is
252:58 - not present so we will we will take the
253:00 - case that it will exit the CPU only if
253:03 - it will it has completed all its
253:04 - instruction so for two bust units it
253:07 - will be there with the CPU and then it
253:09 - will exit at time two which processes
253:12 - are present in the Rue at time two only
253:14 - P2 is present because P1 has exited and
253:16 - P2 is present in the RQ so we will
253:18 - schedule P2 directly without any
253:21 - comparison because this is the only
253:23 - process present in the RQ so for three
253:25 - units of time P2 will be with the CPU at
253:28 - time five which processes are present in
253:30 - the CPU so at time three P3 came and and
253:35 - time five P4 came so we will see till
253:38 - time five which process are present in
253:39 - the CPU so P3 and P4 are present in the
253:42 - ricu
253:44 - I I didn't want to use the word cvu it
253:47 - was Ru okay so P3 and P4 are present in
253:50 - the ricq at time five so we will compare
253:53 - the bu time of those process which are
253:55 - present in the Rue at the same time so
253:57 - for P3 and P4 which process has less Bus
254:00 - Time P3 has less bus time so we schedule
254:02 - P3 there we will schedule P3 and it will
254:05 - it will be with the CPU for one bu unit
254:07 - so it will be with the CPU till time 6
254:09 - and it will
254:10 - exit at time six which Pres process are
254:13 - present in the Rue so at time six no new
254:16 - process has came so we'll schedule P4
254:18 - because this is the only process present
254:20 - in the Rue P4 will be with the CPU for
254:22 - two units so from 6 to 8 P4 will be
254:24 - present with the CPU and at time P4 at
254:27 - time at time 8 P4 will exit Okay so at
254:30 - time 8 which process are present in the
254:32 - ricq at time 8 P5 is the only process in
254:35 - the Rue so we will schedule P5 without
254:37 - any thinking so from 8 to 11 for three
254:40 - bust unit P3 will be with the CPU at
254:42 - time 11 which process are present in the
254:44 - red CU process 6 it came at time 10 so
254:48 - we will schedule P6 without any thinking
254:51 - so we will schedule P6 for two units of
254:53 - time so from two units of time from 11:
254:56 - to 13 P6 will be the CPU I hope the
254:58 - point is clear why I took this question
255:01 - with this data set so as to clear the
255:04 - point that we need to compare the bus
255:06 - time of only those process which are
255:07 - present in the
255:09 - ricu and among those process select the
255:12 - process with least but time least bu
255:14 - time and schedule it on
255:16 - CPU I hope the point is clear now I have
255:20 - written there also that bus time is only
255:22 - compared with the processes in the
255:26 - r okay let's try another question so
255:29 - these are the six processes their
255:31 - arrival time and bust time are given to
255:33 - us now let's see which process are
255:36 - present in the ricu at time zero so no
255:38 - process is present in the radic at Time
255:40 - Zero the first process which came in the
255:42 - ricu was P4 at time two so from 0 to two
255:45 - CPU will be idle because no process is
255:47 - present in the ricq at time two P4 came
255:50 - so we will schedule P4 for how much time
255:52 - for three units so from 2 to 5 P4 will
255:55 - be present at time five which process
255:57 - are present in the RQ at time five P5 is
256:00 - present P6 is present and P2 is present
256:03 - so P5 P6 P2 P5 and P6 are present at
256:07 - time five so which process will be
256:10 - scheduled among the these these three
256:12 - process which are present in the r at
256:14 - same time the process which has least
256:16 - bust time which process has least bust
256:18 - time among these three process P2 P5 and
256:20 - P6 P2 P5 and P6 uh all these process
256:24 - have the same bus time so we will use
256:25 - the tiebreaking criteria that is
256:27 - schedule the process which have lower
256:30 - process ID so we schedule P2 here P2
256:33 - will be executed for two units so from 5
256:35 - to 7 P2 will be the CPU at time 7 which
256:38 - processes are present in the CPU at time
256:40 - 7 P3 a new process came
256:43 - so these process are present in the CPU
256:45 - at time seven because these two got
256:48 - executed and these three are present so
256:49 - we need to compare the bust time of
256:51 - these three process P5 P6 and P3 so P5
256:54 - P6 have bust time of two and P3 have a
256:56 - burst time of four so we will
256:58 - schedule either P5 or
257:02 - P6 now we will use the tiebreaking
257:04 - criteria P5 is a lower process ID than
257:06 - P6 so we will schedu P2 P5 so we will
257:09 - schedule P5 here P5 will get a executed
257:13 - for two units so from 7 to 9 P5 will be
257:16 - executed at time 9 which process is
257:18 - present in the
257:20 - CPU so at time 9 no new process came
257:23 - these two process are available we will
257:25 - schedule the process which has a lower
257:26 - burst time so process 6 has a lower bu
257:30 - time so we will schedule process 6 okay
257:33 - for two units so at time 11 which
257:35 - processes are available in the RQ P1
257:38 - came a new process P1 came at time 10 so
257:41 - these two process are ail avilable till
257:43 - time 11 so we will schedule the process
257:46 - which has a lower bus time which process
257:48 - has a lower Bus Time among P3 and P1 so
257:51 - P1 has a lower bust time so we'll
257:53 - schedule P1 for one bust unit so from 11
257:57 - to 12 P1 will be the CPU and at the last
257:59 - P3 will get scheduled for 4 units so
258:01 - from 12 to 16 P3 will be with the CPU
258:04 - and then the P3 will exit at time 16
258:06 - which process are present in the Rue all
258:07 - the processes has been executed so no
258:10 - new process is there we will end our
258:11 - Gant chart here
258:13 - now if I ask what is the schedule length
258:15 - the schedule length is the arrival time
258:17 - of the first process to the completion
258:19 - time of the last process so schedule
258:20 - length will be
258:22 - 14 what will be the percentage CPU
258:24 - idleness the CPU was not idle during the
258:27 - whole schedule length Okay so I hope the
258:31 - point is clear now let me revise again
258:34 - or let me give you the road map see at
258:37 - any
258:38 - time see the process which are present
258:40 - in the ricu if there are mple process
258:43 - present in the RQ see which process is a
258:45 - lesser bur time schedule this that
258:47 - process and if two process have the same
258:49 - bur time schedule the process with the
258:51 - lower process ID only compare the bus
258:54 - time of those process which are present
258:56 - in the radue at the same
258:58 - time okay so here we see at time five at
259:02 - time five P3 and P4
259:04 - represent in this sgf we do not see the
259:08 - arrival time of the process okay the
259:10 - arrival time is only seen when there is
259:12 - a single process present in the RQ
259:14 - like there it was the single process
259:17 - present so we'll schedule that without
259:19 - any thought okay so I hope the point is
259:21 - clear how the sgf works so in the last
259:25 - lecture we completed the sgf algorithm
259:27 - that is the shortest job first now we
259:30 - will learn the preemptive sgf a new type
259:33 - of sgf that is the preemptive sgf and we
259:35 - call it as srtf shortest remaining time
259:38 - first what will be the selection
259:40 - criteria of this srtf similar to g f
259:42 - that is the burst time we will schedule
259:44 - those process which have a lower burst
259:47 - time okay and the mode of operation will
259:48 - be
259:49 - preemptive and the tiebreaking rule will
259:52 - be the similar to SDF that is the lower
259:53 - process ID I have an important note for
259:55 - you preemption of running process is
259:57 - based on the availability of a strictly
259:59 - shorter process this is an important
260:00 - point I will come back to it again when
260:02 - we will see some questions then I will
260:04 - refer it again now another point that is
260:07 - out of the process present in the radue
260:09 - select the one having the least was time
260:11 - similar to sgf and we will continue to
260:13 - the run on CPU that process until a new
260:16 - process with shorter Bus Time arrives
260:18 - and I should not write here shorter we
260:20 - should I should write strictly shorter
260:22 - strictly shorter bus
260:24 - time okay so let me read it again out of
260:28 - the process this is the part which you
260:29 - need to remember
260:30 - for sgf out srtf okay in
260:35 - sgf till this part was
260:38 - correct and as it was non- preemptive so
260:42 - we will continue to the run on CPU until
260:44 - the process completes but here a new
260:45 - additional thing came that is we need to
260:48 - preempt the process if a new process
260:51 - with shorter bu time arrives okay so I
260:53 - hope the point is
260:55 - clear so let's try so we will first
260:59 - schedule the process based on the sgf
261:01 - algorithm that is the non-preemptive
261:02 - algorithm at Time Zero which process are
261:04 - present in the RQ at Time Zero only P1
261:07 - was present so we will schedule that P1
261:08 - no matter what so we will schedule that
261:10 - P1 for five best units so we P1 from 0
261:13 - to 5 at time five which processes are
261:16 - present in the ricu only P2 is present
261:18 - P1 is ended so P2 will be scheduled for
261:22 - two units so from 5 to 7 P2 will be
261:24 - scheduled so this was when the sgf case
261:27 - was there when we were talking about the
261:30 - non- preemptive case now let's take the
261:33 - case of srtf what I have said select the
261:36 - one with have least verse time so which
261:38 - process are present in the radic at time
261:41 - zero so P1 was present in the IQ so we
261:43 - will schedule the
261:44 - process P1 okay so from 0 to 2
261:49 - units we only schedule till 2 units why
261:52 - because we will continue to the run that
261:54 - process of CPU until a new process
261:57 - arrives at time to a new process arrives
261:59 - so from 0 to two we will run and a new
262:02 - process arrives so we'll see that if the
262:04 - new process has a burst time strictly
262:07 - shorter than the remaining bust time
262:09 - that is three so two is strictly shorter
262:11 - than three so we we will preempt the P1
262:13 - we will preempt the P1 and we will
262:15 - schedule P2 for two units of BU time so
262:19 - we will schedule the P2 for 2 unites of
262:21 - bus
262:22 - time so P2 completed at Time 4 and then
262:25 - we will go back to P1 P1 will be
262:28 - scheduled for 3 units of its remaining
262:30 - time so from 4: to 7: P un was scheduled
262:32 - let me clarify it again in sgf we
262:36 - directly Shu the process by just
262:38 - comparing the burst time of the process
262:41 - present in the RQ at P1 was present in
262:43 - the RQ so P1 was scheduled so from 0 to
262:47 - 5 as it was non preemptive P1 will
262:49 - completes and then after completion it
262:52 - will leave the CPU so at time five which
262:55 - process are present P2 was present so we
262:57 - schedule the P2 for 2 units that way now
263:00 - in srtf I have said we need we will
263:02 - continue to run the process on CPU until
263:05 - a new process arrives and if a new
263:07 - process AR we need to compare the burst
263:08 - time if the burst time of the new
263:10 - process is strictly less
263:13 - than the remaining time of the old
263:14 - process then we will schedule the new
263:16 - process and preempt the old
263:18 - process I hope you got the point so here
263:22 - in the case of srtf which process are
263:24 - present in the radicate time zero only
263:25 - P1 was present so we will schedule P1
263:27 - and we'll continue to the Run P1 until a
263:29 - new process arrive at time two a new
263:31 - process arrive so we will compare the
263:32 - burst time of the new process and the
263:35 - remaining time of the old process if the
263:36 - burst time of new process is strictly
263:38 - shorter than the remaining time of old
263:40 - process we will preempt the old process
263:42 - and will schedule the new process so P1
263:44 - will be preempted at time to and P2 will
263:46 - be scheduled P2 will be scheduled so no
263:49 - new process came till P2 has completed
263:51 - its instructions so at time for P2 will
263:54 - leave the CPU and the remaining process
263:56 - that is P1 will came to execute its rest
263:59 - of the instruction for three units of
264:00 - time so I hope the point is clear now I
264:03 - want to make another point that is if P2
264:05 - also is a burst time of three let's
264:07 - let's write this if P2 also has a burst
264:10 - time of three so then we will check time
264:12 - to a new process arrived yes a new
264:14 - process arrived does the new process
264:17 - have a strictly shorter burst time than
264:19 - the already running process no it is not
264:22 - strictly shorter it's it's equal so we
264:25 - will not preempt the process in that
264:27 - case I have written shorter or I should
264:30 - write strictly
264:31 - shorter okay so if P2 also has a burst
264:35 - time of three then remaining burst time
264:36 - is not strictly greater than the uh new
264:40 - process burst time so no preemption will
264:42 - be there at time two there is another
264:43 - process available in RQ which is a bu
264:45 - time is lesser than the remaining bu
264:47 - time of currently running process hence
264:48 - we preempted that in older case in this
264:51 - case if the first time would have been
264:52 - three then we should we would not have
264:54 - preempted that part okay I hope the srtf
264:58 - is clear now let's move down and we will
265:00 - see a question which algorithm has more
265:04 - context switches is it sgf or srtf we
265:07 - are given with this information P1 P2
265:09 - and 3 P3 are the process numbers this is
265:12 - the arrival time and this is the burst
265:13 - time so we'll first draw the Gant chart
265:15 - for sgf and then
265:17 - srtf so let's draw for sgf
265:21 - first so at Time Zero which process was
265:24 - present in the rigu at time Z P1 was
265:26 - present for bu time five so P will run
265:28 - in the CPU from 0 units to 5 units okay
265:32 - at time five which process are present
265:34 - in the Rue process two and process three
265:36 - are present process two came at time one
265:37 - and process three came at time two so
265:39 - till time five these two process are
265:41 - present in the ricu with this bus time
265:43 - now we will choose the process with
265:45 - lesser bus time so P3 will be chosen I
265:47 - will schedule P3 for two units so from 5
265:49 - to 7 P3 will run and for rest of the
265:51 - time for four units P2 will come so how
265:53 - many contact switches first Contact
265:55 - switch and second contact switch so it
265:58 - took two switches in sjf now let's see
266:00 - for srtf in srtf which process will be
266:04 - scheduled only P1 will be scheduled
266:07 - because it was the only process present
266:08 - in the Rue so we will schedule P1 for
266:10 - how much time we will schedule until a
266:13 - new process arrives so at at time one we
266:16 - will see and stop we will stop and then
266:19 - see whether a new process arrived yes
266:21 - new process arrived that is P2 does the
266:23 - P2 have a birst Time strictly shorter
266:28 - than
266:28 - the remaining bus time of P1 so at Time
266:32 - 1 P1 have run for one unit so the
266:35 - remaining bus time will be four now P2
266:37 - also have a bus time of four and P1 also
266:39 - have bus time of four there is no
266:40 - strictly shorter concept they are equal
266:42 - so we will
266:44 - not preempt so this will go run till P
266:49 - at time to at time to a new process
266:51 - arrived till time to P1 have run for two
266:55 - units so the remaining bus time was
266:57 - three and the bus time of new process is
267:00 - strictly shorter than the remaining bus
267:01 - time so here we will preempt the P1 and
267:04 - then P3 will be scheduled P3 will be
267:07 - scheduled for 2 units because this has
267:09 - the least best time so for 2 to 4
267:12 - P3 will be scheduled and then which will
267:16 - come P1 will come because it has a
267:18 - lesser bus time than P2 so P1 will come
267:21 - and it will run for the remaining three
267:23 - units so from 4 to 7 P will been run and
267:25 - then from 7 to 11 the remaining this
267:28 - part P2 it will run from 7 to 11 so how
267:30 - many contact switches 1 2 and three so
267:34 - three contact
267:35 - switches for srtf and two contact
267:38 - switches for sgf so it was it was an
267:41 - obvious thing because srtf was
267:43 - preemptive it was an obvious thing to
267:45 - suggest that srtf would have more
267:47 - contact switches than
267:50 - sgf okay so what is this point I have
267:53 - written check every time whenever new
267:55 - process arrives so at time one we
267:57 - checked because a new process arrived at
267:59 - time one at time two we check because a
268:01 - new process arrived at time two so we
268:03 - need to check every time whenever new
268:05 - process arrives and if the bust time of
268:08 - the new newly arrived process is
268:10 - strictly shorter than the B first time
268:12 - of remaining process or currently
268:13 - running process then we will preempt
268:15 - otherwise we will not preempt I hope the
268:17 - point is clear let's see another
268:20 - question so why don't to do it as a
268:22 - homework okay I have also given you a
268:25 - solution
268:26 - so try this as a homework and in the
268:29 - next lecture we will
268:31 - discuss so let's start with the homework
268:33 - question which I have given you so this
268:35 - is srtf question and there are six
268:38 - process given to us along with your
268:40 - arrival time and birst time so we need
268:42 - to calculate the entries in the grand
268:44 - chart for srtf
268:46 - algorithm so we can see at time 0 to2
268:49 - there is no no process available so from
268:52 - 0 to two CPU will be idle at time two we
268:54 - can see there are two processes that is
268:57 - P2 and P6 that have arrived and The Bu
269:00 - time of P6 is lesser than bu time of P2
269:03 - so we will schedule P6 first and we have
269:05 - to run P6 until a new process arrives so
269:08 - a new process arrives at time three a
269:10 - new process arrives at time 3 which is a
269:13 - burst time of 6 and the remaining burst
269:15 - time of P6 was 7 so we need to preempt
269:18 - it because you know the
269:21 - reason so at time three P6 will be
269:23 - preempted and will be sent
269:26 - back to RQ and P1 will be scheduled
269:30 - because it has a bus time lesser than
269:33 - the remaining bus time of P6 so we need
269:35 - to run P1 for how much time till a new
269:38 - process arrives so we have to keep
269:40 - running P1 until a new process arrives
269:42 - at time for a new process arrive that is
269:44 - P5 and it has a burst time lesser than
269:46 - the remaining burst time of P1 so we
269:49 - will schedule P5 we have to run P5 until
269:51 - a new process arrive at time five a new
269:53 - process arrive which is a burst time
269:55 - lesser than the burst time of remaining
269:58 - P5 so we will schedule P3 and we have to
270:02 - keep running P3 until a new process
270:03 - arrive at time six a new process arrive
270:05 - which is a burst time equal to the
270:07 - remaining bus time of P3 so we will not
270:09 - preempt P3 we preempt only in the case
270:12 - of strictly shorter I have told you this
270:14 - several times so we will not preempt P
270:17 - P3 at time six we will keep it running
270:19 - till it's completes so at time seven
270:21 - there's no new process now now I want to
270:25 - clarify an important point there that I
270:27 - should write it
270:28 - here it behaves
270:32 - like sjf
270:36 - when new
270:39 - process stops
270:44 - coming so now if the new process stops
270:47 - coming preemption will
270:49 - stop okay because the preemption only
270:52 - happens when there is a new process
270:55 - which has a shorter bu time than the
270:57 - remaining bus time of the old process so
271:00 - when new no new process is coming then
271:02 - there will be no preemption sgf become
271:04 - srtf becomes sgf so at time 8 at time 7
271:07 - also no new processor is there so now
271:11 - which which process is in the
271:13 - RQ at time seven at time 7even all of
271:16 - the process have been arrived so we will
271:17 - schedule the process which has the least
271:19 - best time that is P4 P3 is completed so
271:22 - we will schedule P4 now P4 will come
271:24 - there and it will run for one unit until
271:27 - it get completes so now how many process
271:29 - are completed P4 is completed P3 is
271:31 - completed is there any process which is
271:33 - completed no the rest are remaining now
271:37 - at time it which process will be
271:39 - scheduled the process which has a lesser
271:42 - bus time so we will see which process is
271:44 - a lesser bus time it has a five it has
271:46 - 10 it has three it has seven so three is
271:48 - a lesser bus time so we will schedule P5
271:50 - for how much time until it completes
271:54 - because on this time srtf becomes sgf so
271:58 - P5 got completed now P5 is also complete
272:01 - which
272:02 - process should be scheduled next the one
272:05 - which has a lesser bus time out of 5 10
272:08 - and 7 five is a lesser bus time so we
272:10 - will schedule P1 there and it will
272:12 - complete till 5 minutes so till 11 11 to
272:14 - 16 P1 will run now which process should
272:17 - be scheduled this is also completed
272:20 - there are two process remaining 10 and 7
272:23 - so we will schedule the seventh one that
272:24 - is P6 so we will schedule P6 16 + 7 that
272:27 - is 23 so we will schedule until 23 and
272:30 - then at time 23 the last process that is
272:32 - P2 which has the largest bu time will be
272:34 - scheduled so at 22 to 33 P2 will be
272:37 - there I think this has become easy now
272:41 - okay it it may seems difficult in the
272:43 - beginning but everything is difficult in
272:45 - the beginning okay when you were small
272:48 - when you when you used to write a b c d
272:51 - that was also difficult at that time
272:53 - everything is difficult in the beginning
272:55 - okay do not worry so this is a homework
272:57 - question for you this is a homework
272:59 - question you need to solve I have also
273:01 - given you the answer this is
273:04 - 8.25
273:06 - okay now another question three process
273:09 - arrive at Time Zero with CPU but of 16
273:12 - 20 and 10 milliseconds if the scheder
273:14 - has a prior knowledge about the length
273:16 - of the cvu bust the minimum achievable
273:19 - waiting time for these process in a non-
273:21 - preemptive Sher is how many milliseconds
273:24 - now to solve this question we need to
273:25 - learn about the performance of sgf and
273:28 - srtf so we need to learn about the
273:31 - performance of sgf that is non-
273:32 - preemptive and srtf that is preemptive
273:35 - and these two algorithm are said to be
273:37 - optimal
273:39 - algorithm so is there any problem
273:41 - regarding these
273:43 - algorithm why are they optimal because
273:47 - both of them favors the shorter process
273:49 - I I have said shorter process refers to
273:51 - those process which has a less burst
273:54 - time with respect to other process so
273:56 - what are the advantages and
273:57 - disadvantages of doing this favoring
273:59 - shorter process the disadvantages is it
274:02 - causes starvation to the longer process
274:04 - as soon as new process with shorter Bus
274:06 - Time Keeps arriving the longer process
274:08 - will never get a chance to run on CPU
274:10 - and what is the advantage an ages as
274:12 - they favor shorter process so in a fixed
274:16 - time segment more number of process can
274:18 - be completed or more jobs could be done
274:20 - in less duration it means it maximizes
274:23 - throughput minimizes the average waiting
274:25 - time and average turnaround time
274:28 - okay now is there any problem regarding
274:31 - these sgf and srtf they are good yes
274:34 - there is a problem because think about
274:36 - this they work on the burst time burst
274:39 - time is the time required by the process
274:41 - to execute all its instruction on
274:44 - CPU they work on the burst
274:47 - time their
274:49 - implementation is the problem because we
274:53 - do not know the prior bust time of the
274:54 - processes how can we how can we know for
274:57 - how much time process will run on the
275:00 - CPU that's why it needs prior bust time
275:04 - its implementation is not
275:05 - possible okay so since the bu time of
275:09 - process are not known a Priory they are
275:12 - not practically implementable if this is
275:14 - the case then why did you teach a shage
275:17 - you may ask this question then why did
275:18 - we study them because theoretically sgf
275:22 - is an optimal algorithm and we use sgf
275:25 - as a benchmark to measure the
275:26 - performance of other
275:28 - algorithms okay this is quite understand
275:31 - understandable thing so sgf can be
275:32 - implemented with predictive verst times
275:35 - what are the techniques to predict the
275:36 - best time we'll see later but let us do
275:39 - that question what was the question
275:41 - there there are three processes which
275:42 - arrive at Time Zero it means at Time
275:44 - Zero all three processes were available
275:45 - in the RQ with CPU bust off 16 20 and 10
275:48 - Mond if the scheder that's why it is
275:51 - written there it has already prior
275:53 - knowledge about the length of the CPU
275:54 - bust this is theoretical okay the
275:57 - minimum achievable average waiting time
275:58 - for these process in a non- preemptive
276:00 - mode is so which is the best algorithm
276:03 - for the least waiting time sgf and srtf
276:07 - and which one out of these two we have
276:09 - to use here the one which is non pre
276:11 - that is sgf so we will use sgf okay so
276:14 - it's a easy question you just have to
276:16 - apply sgf and calculate the waiting time
276:18 - I hope you can do that let's move to the
276:21 - next question you should try this on
276:23 - your own and then see the solution so
276:24 - there are four process P1 P2 and P3 P4
276:28 - and the buth time of P4 that is equals
276:31 - to Z is unknown to us and the thing
276:33 - which is given is total waiting time
276:35 - should be equal to 4 now solve the
276:37 - question this is a good question you
276:39 - must solve this and then see the
276:41 - solution
276:42 - otherwise you won't appreciate the
276:43 - beauty of this question okay so let's go
276:47 - so there are four process along with the
276:49 - arrival times and first time are given
276:51 - so we need to calculate the value of Zed
276:54 - okay so let's discuss the approach first
276:56 - so what we will do we will calculate the
276:58 - waiting time we will we will see that
277:00 - this process has to collectively wait
277:03 - for four unit of time okay so we will
277:06 - schedule the process in such a way that
277:08 - the waiting time equals 4 Okay so at
277:11 - time Z which process was available only
277:14 - P1 was available so P1 will get
277:16 - scheduled from 0 to 1 P1 will scheduled
277:18 - and at Time 1 a new process has arrived
277:20 - which is a burst time lesser than the
277:22 - burst time of currently running process
277:24 - so P1 will get preempted and P2 will run
277:26 - for one unit and at time
277:29 - two and at time two only P1 was present
277:33 - in the RQ these process came later after
277:35 - time to so P1 will get scheduled again
277:38 - till here let's calculate the waiting
277:40 - time let's calculate the waiting time so
277:43 - P1 has waited for how much time P1
277:44 - waited for one unit of time when P2 was
277:46 - running P2 waited for how much time P2
277:49 - waited for zero now P3 and P4 are
277:52 - remaining so let's erase all this P3 and
277:56 - P4 both has to wait three unit of time I
278:00 - hope you got this because P1 has already
278:02 - waited for one unit of time now these
278:05 - two collectively have to wait three unit
278:07 - of time okay
278:12 - P3 arrived at time three P3 arrived at
278:15 - time three so it has already waited for
278:17 - one unit of time it has already waited
278:19 - for one unit of time so we can write
278:21 - here that P3 and P4 has to wait two unit
278:24 - of
278:26 - time okay let me uh speak again P3
278:30 - arrived at this moment and the next
278:32 - schedule process the next process which
278:34 - have to be scheduled will be scheduled
278:36 - at Time 4 so P3 is already waited for
278:39 - one unit of time so these two process
278:41 - have has to now collectively wait for 2
278:42 - units of time now let's discuss the
278:45 - important part which process should be
278:47 - scheduled first out of these P3 and P4
278:51 - as we don't know the value of Z so let
278:53 - discuss the cases let's say P3 will get
278:55 - scheduled first okay let's schedule the
278:57 - P3 first if we schedule P3 first then P4
279:01 - will have to wait for how much
279:04 - time the first time of P3 when weu P3
279:08 - then it will run for 7 and then p 4 will
279:11 - get scheduled now P4 will wait for how
279:13 - much time it will wait for three units
279:15 - of time if P4 will wait for three units
279:17 - of time that is not possible that's
279:19 - already exceeding this so it is not
279:20 - possible that we scheduled P3 first it
279:23 - means we have to schedule P4 first let's
279:25 - schedule P4 first if we schedule P4
279:28 - first and for how much time P3 have to
279:33 - wait it it has to wait for Z unit of
279:36 - time so P3 has to wait for Zed unit of
279:39 - time and for how much time P4 Will Wait
279:42 - P4 had had arrived at time four and and
279:45 - it gets scheduled at time four it
279:47 - arrived at time four and it gets
279:49 - scheduled the time for so for how much
279:50 - time it has waited it has waited for
279:53 - nothing so Z + 0 = 2 it means Z = to 2
279:57 - it means the first time of process 4
279:59 - will be two now after we have found the
280:02 - value of two let's verify so let's do
280:06 - this as two now let's schedule the
280:07 - remaining process so P4 will get
280:09 - schedule first P4 will get scheduled
280:12 - first because it is a lesser first time
280:14 - so P4 will run for two units that is six
280:16 - and then P3 will be scheduled for 3
280:18 - units of time that is N9 now let's
280:20 - calculate the waiting time of all
280:21 - process for how much time P1 has waited
280:24 - P1 has waited initially nothing and then
280:26 - P1 has waited for 1 unit of time okay
280:28 - for how much time P2 waited P2 waited
280:30 - for nothing as it arrived at Time 1 and
280:32 - it get scheduled at Time 1 so P1 waited
280:34 - for nothing now for how much time P3 had
280:39 - waited P3 had waited for one unit
280:42 - here as it arrived let's let's discuss
280:45 - directly as it arrived at time three and
280:48 - it get schedule for time six so it
280:50 - waited for three units so total weight
280:53 - will be four the total weight will be
280:55 - four so the option is uh the value we
280:58 - have found is
281:00 - correct so in the previous lecture we
281:02 - somewhere discussed that sgf is the
281:04 - optimal algorithm but there is a problem
281:06 - with the sgf it's implementation we do
281:09 - not know the bur time a prior
281:11 - we can only predict them so in this
281:13 - lecture we are going to learn about some
281:15 - of the prediction techniques for CPU
281:17 - birds so there are two type of
281:18 - techniques static and dynamic in a
281:21 - static Technique we look at the total
281:23 - verst time let me give you an example so
281:27 - first is the process size there was an
281:29 - old process which is a size of 101 KB
281:32 - and it ran on the CPU for 20 seconds
281:35 - there's a new process which has a size
281:36 - of 100 KV so we can say that it will
281:39 - approximately run around 20 seconds in
281:41 - the CPU so this is how we predicted
281:43 - based on the size okay there is another
281:48 - method to predict the static burst time
281:50 - on the basis of
281:52 - type there are four let's say there are
281:54 - we have segregated these processes in
281:58 - various classes let's say the operating
282:00 - system type process interactive process
282:01 - foreground process background process OS
282:04 - process take an average burst time of 5
282:06 - Seconds interactive process average bust
282:08 - time of 10 seconds then 15 seconds and
282:10 - 30 seconds then there is a new process
282:13 - which has arrived and it has a type of
282:15 - background process so we can say it will
282:17 - approximately run around 30 seconds so
282:20 - these are the methods which we have
282:21 - predicted the static first times okay
282:25 - now the another technique is dynamic but
282:28 - what I want to tell you is while
282:30 - remaining in the radue we want to
282:32 - predict how much time will be of the
282:35 - next burst so while remaining in the NQ
282:37 - we need to predict how much time will it
282:40 - is going to take for the next burst
282:41 - while remaining The Rue we want to
282:43 - predict how much time it will take for
282:45 - the next burst while remaining The Rue I
282:47 - hope you got the
282:48 - point so these are the two predictions
282:51 - which we have already
282:52 - made now while remaining in this radue
282:56 - we want to make the predictions for this
282:59 - CPU P so how can we do
283:03 - that
283:04 - now how we will predict dynamically so
283:08 - for dynamic predictions we have a
283:09 - technique named exponential averaging
283:11 - technique or aging algorithm so this is
283:14 - the diagram which I was there referring
283:18 - to this is T1 that is the completed bus
283:22 - time so T1 will represent the this vt1
283:26 - T1 will represent the bt1 and to one
283:29 - will
283:31 - represent and T one will represent the
283:33 - time which we have predicted for the
283:36 - first bust I hope you got the point this
283:39 - was the actual and this was we predicted
283:42 - let me write again this was the time
283:44 - which we predicted and this was the time
283:46 - which actually process took so for
283:50 - this to3 will be the time which we want
283:53 - to predict and T3 will be the time which
283:55 - was actually taken by the
283:57 - process so to n + 1 represent the next
284:01 - CPU busts so here the value of n will be
284:06 - 2 what is the n signifies n signifies
284:10 - how many times the process has already
284:12 - been with the CPU so here two times the
284:14 - process has already been with the CPU
284:16 - now we want to predict for the next
284:18 - bursts see to n plus1 represent the next
284:21 - CPU bu so the formula that we
284:23 - experimentally derived that is to n +1
284:27 - is equals to Alpha TN + 1 - Alpha TN so
284:31 - what does this signify Alpha is just a
284:32 - constant which lies between 0 to 1 so
284:35 - what does this Alpha signify it
284:37 - signifies the weight so for the
284:40 - prediction of next CPU bust how much
284:43 - weightage we are giving to the already
284:46 - completed CPU
284:48 - busts plus how much weightage we are
284:50 - giving to the predicted CPU busts okay
284:55 - so to calculate the next CPU bust we are
284:57 - giving some weightage to
285:00 - the actual time taken plus we are giving
285:04 - some weightage to the pr predicted time
285:07 - I hope I am able to clarify what I want
285:10 - to say
285:13 - weightage given to the actual time taken
285:16 - weightage given to the predicted time so
285:19 - we will calculate the T n+1 in this way
285:21 - so what is it it is a recurrence
285:23 - relation so how are we going to solve
285:24 - this recurrence relation V will put the
285:27 - value of
285:30 - TN so this this method is known as back
285:32 - substitution so what does we do here we
285:35 - will find the value of TN and we'll put
285:37 - it back here okay so if the equation as
285:41 - a t n + 1 = Alpha TN + 1 - Alpha t n so
285:46 - what we will do we will just subtract 1
285:49 - so this will become t n equal to Alpha
285:52 - tnus 1 + 1 - Alpha t n minus 1 so this
285:56 - will give the value of to n this is how
285:58 - recurrence relation work so what we will
286:00 - do we will substitute back the value of
286:02 - TN now we get
286:04 - this what we will do now we will solve
286:08 - it first we'll simplify it first so we
286:10 - will get this after the substitution
286:12 - value of TN and then we will get to n
286:14 - minus one what we will do we'll again
286:16 - find the value and we will put it so we
286:18 - found the value of to n minus one and
286:20 - then we put it what we will get then we
286:22 - get this part and then we will keep
286:24 - putting the value of to then we will put
286:27 - the value of to n minus 2 and then to n
286:29 - minus 3 and we will keep putting the
286:30 - value until we reach to 1 this is to
286:34 - until we reach to
286:37 - one now now the thing now the question
286:40 - arises okay so we started with to n we
286:43 - put the value of t n minus one and then
286:45 - we put the value of t n minus 2 and at
286:47 - last we reach the value of to n what we
286:49 - will do then we have to do nothing
286:51 - because the value of to 1 will be given
286:54 - to
286:55 - us this value is known as initial
286:58 - guess so let's take the analogy of
287:01 - factorial we cannot find factorial of
287:04 - any number until we know the factorial
287:06 - of zero that is one can you find the
287:08 - factorial of five yes
287:11 - uh without 0 factorial No 5 into 4 into
287:15 - 3 into 2 into 1 into 0 factorial you can
287:19 - find the value of this but how will you
287:21 - get the value of this because in
287:23 - factorial you cannot put negative
287:25 - values so you cannot find the value of
287:28 - any factorial until the initial guess is
287:30 - given to you so here the value of T1
287:33 - will be given that is to1 will be given
287:36 - that is the initial guess so what we can
287:39 - infer given the value of L Alpha and to
287:41 - one one can predict any CPU
287:45 - bus let me clarify again so in HF the
287:49 - main problem which arised was its
287:52 - implementation we do not know the burst
287:54 - time of the process a prior so we need
287:56 - some prediction techniques to predict
287:59 - some CPU bus so there were two
288:00 - techniques static and dynamic in static
288:02 - we used the two methods of size and type
288:04 - in Dynamic what we do while remaining in
288:07 - the Rue we want to predict how much time
288:09 - it will take for the next verse
288:11 - so we derived a recurrence relation so
288:14 - this was the recurrence relation given
288:17 - what we will do we want to solve this
288:18 - recurrence relation so we found the
288:20 - value of TN and then we put the value of
288:23 - TN back in the original equation and we
288:26 - will keep on doing until we reach
288:28 - T1 and the value of T1 we know because
288:32 - it is the initial guess it is similar as
288:34 - if we know the value of 0 factorial to
288:36 - find the factorial of any number so
288:39 - given the value of T1 and
288:42 - Alpha we can predict any next CPU bu so
288:46 - let's take the question it will clarify
288:48 - you more let's solve this question now
288:50 - consider a system
288:53 - using so I hope the point is clear let's
288:56 - move to the question consider a system
288:58 - using aging algorithm to predict the
289:00 - next CPU bu given alal to 2 and to 1al
289:03 - to 10 the process Bus Time hour that is
289:06 - this is T1 this is T2 this is T3 this is
289:09 - T4 these are the actual completed burst
289:11 - time now we need to predict the next CPU
289:14 - first okay so we'll use the equation to
289:17 - n + 1 equal to Alpha TN + 1 - Alpha t
289:22 - n so we need to find the fifth bust so
289:27 - we'll predict the next CP bu four has
289:29 - already been completed so n is equal to
289:31 - 4 so we will put the value of n equal to
289:34 - 4 so T 5 = to Alpha T4 + 1 - Alpha T 4
289:39 - so we got this equation here we know the
289:41 - value of alpha T4 1 - Alpha we don't
289:45 - know the value of T4 so we'll write the
289:47 - equation for T4 what we will do we will
289:49 - put n = 3 so we will get T 4 = to
289:53 - Alpha to T3 + 1 - Alpha to 3 we don't
289:58 - know the value of to 3 we'll do this
289:59 - again uh to 3 = to Alpha T2 + 1 - Alpha
290:03 - to 2 we do this again to 2 = to Alpha T
290:05 - 1 + 1 - Alpha T
290:08 - 1 we did this we kept on putting the
290:11 - values until we reach the initial guess
290:13 - are we given the value of initial guess
290:15 - yes so this is the value which we are
290:16 - given with now we know the value of this
290:19 - this this and this so we can find the
290:22 - value of T 2 we will put the value of T2
290:24 - here we'll find the value of to 3 we
290:25 - will put the value of T 3 here we'll
290:27 - find the value of T 4 and we'll put the
290:28 - value of T 4 and we'll get the value of
290:30 - to 5 so in this way we'll get the next
290:33 - CPU burst it was an easy question
290:37 - so this is an important formula you need
290:40 - to remember this
290:41 - what does it say t n + 1 equal to Alpha
290:45 - TN + 1 - Alpha t n Alpha signifies the
290:49 - weightage okay but the problem of
290:52 - starvation is still continuing in this
290:54 - sgf whether preemptive or non preemptive
290:57 - because longer process will starve
290:59 - against the solter process this fact
291:01 - cannot be denied so how we will solve
291:03 - this
291:09 - problem yes that is the hrrn algorithm
291:13 - highest response ratio next now you may
291:16 - wonder what is response ratio so
291:18 - response ratio is this waiting time plus
291:21 - burst time divided by burst time and
291:24 - burst time is also known as service time
291:26 - so the response ratio is commonly known
291:29 - as W + S / s Well w is the waiting time
291:33 - s is the worst time and s in the
291:35 - denominator is the first time can you
291:37 - can you infer something from this
291:39 - response ratio
291:41 - can you infer
291:42 - something yes the process with the
291:45 - shorter bus time is preferred but the
291:47 - process which has been waiting for a
291:49 - long time is being given more priority
291:52 - than the shter process do not worry when
291:55 - we will see the numerical you will get a
291:57 - more understanding of this so the next
292:00 - process is to run is the one whose
292:02 - response ratio that is this part is the
292:05 - highest so the response ratio is highest
292:09 - that process will be given more priority
292:11 - longer process waiting from a long time
292:14 - will have high response ratio and that
292:16 - was the problem which got solved with
292:19 - this hrr and
292:21 - algorithm now W + S / s that means if
292:26 - waiting time increases then response
292:29 - ratio increases if burst time decreases
292:31 - then response ratio increases it means
292:33 - the shorter process is given priority
292:36 - that fact cannot be denied but the
292:38 - longer process which has been waiting
292:40 - from long time will have high response
292:43 - ratio so when waiting time increases the
292:45 - response ratio increases and that
292:48 - process will be scheduled first whose
292:50 - response ratio is high and its mode is
292:53 - non preemptive it works on a non-
292:55 - preemptive mode and the tiebreaker thing
292:57 - is again the lower process ID suppose
292:59 - two process have same response ratio
293:01 - then the process which have lower
293:03 - process ID will be favored so let's see
293:05 - a numerical and then we'll get a better
293:08 - idea of this so these are the data
293:12 - sets now let's first solve using sgf so
293:16 - which process is available at Time Zero
293:18 - process one so we will schedule process
293:19 - one for bus time three so till process 0
293:22 - till time 0 to 3 P1 will run at time
293:25 - three is there any new process which has
293:27 - arrived yes P2 has arrived so we'll
293:29 - schedule P2 for sixth bus time so from 3
293:32 - to 9 P2 will run
293:35 - now all three process has been arrived
293:37 - till P2 completes now P3 P4 and P P5 are
293:40 - present in the ricu which process has
293:43 - shorter bust time P5 has shorter bust
293:45 - time so we schedule P5 from for two bust
293:48 - units so from 9 to 12 P5 will run from 9
293:51 - to 11 P5 will run now out of them which
293:55 - process is shorter Bus Time P3 so their
293:57 - P3 will run for 4 units of time so from
294:00 - 11 to 15 P3 will run and at last for
294:02 - five units of time P4 will run so this
294:06 - part this Gant chart is based on the hgf
294:09 - algorithm what we can infer from this
294:11 - see at this point at at time 9ine at
294:15 - time 9 see at this point P3 arrived at
294:19 - Time 4 but it got scheduled at time
294:22 - 11: and P5 arrived at time 8 and it get
294:26 - immediately scheduled because it was
294:28 - shorter so this is something unfair
294:31 - being done to process the now let me
294:33 - speak again P3 arrived at Time 4 and P5
294:38 - arrived at time 8
294:40 - but still P5 got scheduled at timeline
294:44 - just because it has a shorter bus time
294:46 - this was something unfair being done to
294:48 - process 3 it arrived at Time 4 it should
294:50 - be scheduled earlier
294:53 - but P5 is favored because of a shorter
294:56 - bus time so P3 has been waiting for a
294:59 - long time this should not be the thing
295:02 - so how can this problem be solved using
295:04 - hrnn SO waiting time of P5 is 1 and
295:07 - waiting time of P3 is 7 this is unfair
295:09 - so let's solve this by using hrrn now
295:13 - what we do in hrnn let me recall so out
295:16 - of the process present in the RQ we
295:19 - calculate the waiting time and The Bu
295:21 - time and then we will do waiting time
295:24 - plus bust time divided by bust time that
295:26 - is the response ratio and we'll compare
295:28 - the response ratio between those process
295:30 - only which is present in the Radu at the
295:32 - time of scheduling and there's a special
295:34 - thing this waiting time is not the
295:36 - waiting time for the complete Gant chart
295:39 - it is the waiting time
295:41 - till the time which we are seeing when
295:44 - we'll solve the question you will get a
295:45 - better idea what I I want to say okay so
295:49 - which process is present in the radue at
295:50 - Time Zero P1 is present so we will
295:53 - schedule P1 for three units of time as I
295:55 - say it was non
295:56 - Prem for time at time 2 P2 was present
296:00 - so P2 will be scheduled because this was
296:03 - the only process we need not to think
296:05 - anything if there is only process in the
296:07 - ricu for scheduling scheder will not
296:09 - think anything and it will directly
296:11 - schedule that only process so P2 will be
296:13 - scheduled so from 3: to 9 as it is a bu
296:16 - time of 6 P2 will be there at time 9
296:19 - which processes are present in the Rue
296:21 - at time 9 P3 P4 and P5 are present so
296:24 - these processes are present in the Rue
296:26 - at time 9 now we will calculate the
296:28 - response ratio because there out of
296:30 - these three process scheder has to
296:32 - select one so it will calculate the
296:36 - response ratio for these three processes
296:39 - for P3 what is the waiting time it
296:42 - arrived at time 4: and we are seeing at
296:44 - time 9 or the short time scheduler is at
296:48 - the moment of time 9 so from 4 to 9 how
296:53 - much unit P3 waited P3 waited for 5
296:56 - units of time and what was the birth
296:58 - time of P3 4 and 4 so 5 + 4 divided 4
297:01 - that is 9 by 4 which is
297:04 - 2.25 let's calculate for P4 P4 arrived
297:07 - at time six and shortterm Sh is planning
297:10 - to schedule at time 9 so at this time
297:13 - till this time how much unit P3 P4
297:16 - waited P4 waited for 3 units of time and
297:19 - what is the first time 5 so 3 + 5 divid
297:22 - 5 that is 1.6 is the response ratio for
297:25 - P4 till time
297:27 - line now we'll see P5 so P5 P5 arrived
297:33 - at time 8 and the current time is time 9
297:36 - so tell how much time is wait it waited
297:38 - it waited for 1 unit so 1 + 2 divided 2
297:41 - that is 1.5 now out of these three
297:44 - response ratio 2.25 is the highest that
297:47 - is of P3 so we will schedule P3 here and
297:50 - it will run non preemptively for four
297:52 - units of bus time so from 9 to 13 P3
297:55 - will run at time 13 which processes are
297:58 - present in the RQ P4 and P5 now we'll
298:02 - calculate the waiting time till time 13
298:06 - so we'll calculate for P4 P4 arrived at
298:08 - time 6 till time 13 how much unit it has
298:11 - waited it waited for 7 units of time and
298:13 - The Bu time was 5 so we have written 7 +
298:16 - 5id 5 that is 2.4 is the response ratio
298:20 - for P4 now let's calculate for P5 so for
298:23 - P5 what is the arrival time it arrived
298:26 - at time 8 and the current time is 13 so
298:30 - till how much time it waited it waited
298:32 - for 5 units of time so 5 plus its bu
298:37 - time 2id 2 that is 3.5 out of these two
298:41 - which is greater 3.5 is greater so we'll
298:44 - schedule P4 P5 next and P5 will run for
298:47 - how much unit of time two units so 13 to
298:49 - 15 P5 will run and in the end the only
298:52 - process which is remaining in the ricq
298:54 - is P4 so we will schedule P4 directly so
298:57 - and P4 will run for 5 minutes of time so
298:59 - from 15 to 20 P4 will run now what we
299:02 - can see this was the longer process and
299:05 - this was the shorter process hrnn
299:07 - preferred that longer process which has
299:10 - been waiting from a long time so the
299:12 - problem of starvation
299:14 - solved so let's start our class with a
299:17 - new algorithm that is longest remaining
299:19 - time first this algorithm is exactly the
299:22 - opposite of algorithm srtf which we have
299:25 - studied earlier in srtf we used to
299:28 - schedule those process which has a
299:30 - shortest worst time among the process
299:33 - present in the ricu so here as the name
299:35 - suggest we will schedule the longest one
299:40 - but there is a
299:41 - catch that we will discuss later while
299:44 - solving the question so this algorithm
299:46 - is not easy as it seems this is a
299:48 - difficult one you have to be extra
299:50 - careful while solving these
299:52 - questions so the selection criteria is
299:55 - first time and the mode of operation is
299:57 - preemptive this make it dangerous and
300:00 - there is another thing that is the
300:02 - tiebreaker rule which was common in all
300:04 - of the algorithm which we have discussed
300:07 - if the tie if there is a need of
300:08 - tiebreaker rule we will we will take the
300:11 - lowest process ID we will prefer that
300:13 - process okay so let's start with the
300:16 - question and you will get an idea of
300:18 - what I was
300:19 - saying so at the time zero there are
300:21 - three process available in the radue so
300:24 - we will schedule the process which has a
300:26 - largest bus time so P3 has the largest
300:30 - bus time that is 8 so we will schedule
300:34 - P3 now for how much time P3 will run
300:37 - that is the main thing so in srtf what
300:40 - we used to
300:41 - say out of the several process present
300:43 - in the red EQ we will choose a process
300:46 - and we will schedule it to the
300:48 - CPU and for how much time this process
300:51 - will run this process will run until a
300:54 - new process arrives or there is a
300:56 - process present in the radue which has a
300:58 - burst time which has a burst
301:02 - time strictly shorter than the remaining
301:04 - verst time of currently running
301:07 - process so this we used to say we used
301:09 - to emphasize more upon strictly shorter
301:11 - thing as I said this algorithm is
301:14 - exactly the opposite of srtf so what we
301:16 - will do in this
301:17 - algorithm or you tell me what is the
301:21 - opposite of a strictly shorter thing the
301:24 - opposite of a strictly shorter
301:26 - is equal or
301:29 - greater equal or greater the opposite of
301:33 - strictly shorter is equal or greater so
301:36 - what we will do here we will keep P3
301:39 - running will keep P3 running until there
301:41 - is a process present in the radue which
301:44 - has a burst time of either will will
301:46 - check of either eal or greater than the
301:50 - remaining burst time of currently
301:52 - running process I mean I am saying this
301:55 - very slowly because this needs an extra
301:58 - care so we will keep P3 running until
302:02 - there's a new until there's a process
302:04 - present in the ricu that is P2 which is
302:06 - a burst time of either equal so yes
302:10 - equal thing satisfies P3 is a bus time
302:12 - of 8 and it has already run for 4 units
302:15 - so the remaining bus time will be
302:18 - 4 and four and four are equal so what we
302:22 - will do we will preempt
302:24 - P3 and we will send it back to the radue
302:27 - and we will schedule
302:28 - P2 and we will schedule P2 because this
302:31 - is the process which has a burst time
302:35 - equal or greater than the burst time of
302:38 - than the remaining burst time of
302:39 - previously running process so four and
302:42 - four were equal so what we did we
302:44 - preempted P3 see we we never used to
302:50 - preempt a process in srtf if the bur
302:53 - time were equal but in ltf we will
302:56 - preempt a process if the bus time are
302:59 - equal so at time four four and four are
303:03 - equal so what we did we preempted P3 and
303:05 - we scheduled P2 so P2 will be scheduled
303:08 - now for how much time P2 will run P2
303:10 - will run for only one unit of time
303:12 - because when P2 will run for one unit of
303:14 - time there is a process present in the
303:15 - RQ which is a bu time of greater than
303:18 - the remaining bus time of P2 so 4 is
303:20 - greater than three so we will preempt P2
303:24 - and we and we will send it back to the
303:25 - RQ and will schedule P3 now for how much
303:28 - time P3 will run P3 will also run for
303:31 - one of time only
303:33 - because when P3 will run for one unit of
303:35 - time there is a process present in the
303:37 - RQ which has a burst time equal to the
303:40 - remaining bus time of process P3 so we
303:42 - will preempt P P3 send it back to the
303:45 - radue and we will schedule P2 again now
303:48 - P2 will run for only one unit of time
303:50 - because there is a process present in
303:53 - the RQ which has a burst time greater
303:55 - than the remaining bus time of P P2 so
303:58 - we will preempt P2 and we will schedule
304:03 - P3 now P3 will also run for 1 unit of
304:06 - time
304:07 - because the remaining bus time of
304:10 - P3 is equal to the bust time of two
304:14 - processes present in the radue now out
304:16 - of these two process which we will
304:18 - choose the process with the lower bu ID
304:21 - so we will choose the process
304:23 - P1 okay now P1 will run again see have
304:28 - you seen some pattern
304:30 - here the same pattern is going to follow
304:32 - now the B time of P1 P2 and P3 is 222 so
304:36 - which will be scheduled first so they
304:38 - will
304:40 - they will be scheduled alternatively so
304:43 - first P1 will run as P1 will run its
304:46 - remaining time will become one remaining
304:48 - bu time will become one now there are
304:50 - two process present in the redq which is
304:52 - a first time greater than the remaining
304:54 - bu time of P1 so we will schedule out of
304:56 - these two process now which process we
304:58 - will choose the process with the lower
304:59 - bu lower process ID so P2 will be
305:01 - scheduled here so P1 will be send back
305:03 - to the ricq and P2 will be scheduled P2
305:07 - will be scheduled now P2 will also run
305:09 - for unit of time because there is a
305:11 - process present in the RQ which is a bu
305:13 - time greater so P3 will be scheduled now
305:15 - for how much time P3 will will run P3
305:18 - will run for only one unit of time
305:20 - because if it has run for one unit of
305:23 - time there are two process present in
305:24 - the radue which is a burst time equal to
305:26 - the bu time of remaining bu time of
305:28 - currently running process so we will
305:30 - preempt P3 and now out of these two
305:32 - process we
305:34 - will schedule a process which is a lower
305:36 - bust ID lower process ID so we will SCH
305:40 - P1 and the same thing goes goes on P3
305:44 - when when P1 will run this will become
305:46 - zero and there are two process present
305:48 - in the r which is burst time greater
305:50 - than zero so out of these two the
305:51 - process with the lower bur lower process
305:54 - ID will be preferred so P2 will be
305:56 - scheduled P2 will run for one unit of
305:58 - time and
306:00 - then there is a process present in the
306:02 - radue which is a Burge time greater than
306:04 - P2 so P2 will be preempted and P3 will
306:06 - go and in this manner all the process
306:09 - ends so this was a little bit weird
306:13 - algorithm and it and it requires an
306:16 - extra care to to solve such question
306:19 - okay so let's draw another question so
306:22 - this is the thing which we are given
306:23 - with and we have to find the average
306:25 - completion time of A and B okay so let's
306:29 - do this now there are three process
306:31 - present in the radue at time zero so we
306:34 - will schedule the process which has a
306:35 - largest bu time so now c will go there c
306:39 - will run for three units of time because
306:42 - at three unit of time there will be a
306:44 - process present in the RQ which has a
306:46 - bus time equal to the bus time of
306:47 - currently running process so six and six
306:49 - are equal so we will schedule C and we
306:51 - will so we will preempt C and we will
306:53 - schedule b b will run for how much time
306:56 - we will run for only one of time
306:59 - because there is a process present in
307:01 - the radue which has a bur time greater
307:03 - than the remaining bus time of currently
307:06 - running process so C's bust time is
307:09 - greater than than the B's bu time so 6
307:11 - is greater than 5 so we will preempt B
307:13 - and we will schedule
307:15 - C now C3 will again run for one unit
307:18 - only so this thing will goes on and on
307:20 - until they all becomes equal so c will
307:24 - go there his bus time will become five
307:27 - five and five are equal c will get
307:28 - preempted B will be get scheduled then
307:31 - B's bus time will become four now
307:33 - there's a process which has a bu time
307:35 - greater so c will again get scheduled
307:37 - now c will run for only one unit because
307:39 - there are process available which is a
307:41 - bu time equal to C so out of these two
307:43 - the one which has a lower process ID
307:44 - that is a will be scheduled so a will
307:46 - come here a will run for only one unit
307:48 - as there are process with greater bust
307:50 - time so out of these two B will be
307:52 - scheduled so B will run for three and
307:54 - there's a process with greater verst
307:55 - time then C will be scheduled c will run
307:57 - for only one unit of time because there
307:58 - are process available in the RQ which
308:00 - which has a bust time equal to the bust
308:01 - time of currently running process so
308:03 - after of these two the process with the
308:04 - lower lower process ID will get
308:06 - scheduled so a will get scheduled here a
308:09 - will run for only one unit because the
308:12 - two is shorter than two is lesser than
308:14 - three and three so after these two B
308:17 - will be scheduled as it has a lower
308:19 - process ID so B will go there b will run
308:22 - for two units because 3 is greater B
308:24 - will run for only one unit remaining
308:25 - time will be two 2 is lesser than three
308:27 - so three uh that is the c will be
308:29 - scheduled now the same thing goes and on
308:31 - until the everything ends to zero so I
308:35 - hope you got the idea so now what we
308:37 - were asked we were asked find the
308:38 - average of the completion time of A and
308:40 - B so what will the completion time of A
308:42 - and B A completed at 17 and B completed
308:46 - B completed at 18 so 17 + 18 divid 2 is
308:49 - the
308:50 - answer let's solve some other questions
308:53 - in a
308:55 - system in a system using single
308:57 - processor a new process arrives at a
308:59 - rate of 10 process per minute and each
309:02 - such process requires 5 Second of
309:03 - service time what is the percentage CP
309:05 - utilization so this this is a very easy
309:08 - question six in 60 seconds that is a new
309:11 - process arrive at at a rate of 10
309:14 - process per minute it means in 60 second
309:17 - 10 processes arrive that means in 6
309:19 - second one process
309:21 - arrives and each such process requires 5
309:24 - Second of service time so what is the CP
309:28 - utilization so there are 10 process each
309:31 - requires 5 Second of service time so 50
309:34 - seconds will be the service time of all
309:36 - these 10
309:37 - processes and
309:39 - the completion time will be the
309:42 - 60 so the percentage utilization will be
309:45 - the useful time upon the total time the
309:48 - useful time will be 50 and the total
309:50 - time was 60 so 50 divid 60 into 100 will
309:52 - be the percentage C utilization so this
309:55 - was a easy question let's move to
309:57 - another question six jobs are waiting to
309:59 - be run the expected running times are
310:01 - 975 21 so I made in this way and X
310:05 - respectively so this is X find the value
310:07 - of x using hdf algorithm so I have
310:09 - included those questions of old
310:11 - algorithm so for the revision purposes
310:14 - okay so I was thinking something about
310:16 - the dpps so I thought I should share the
310:19 - DPP with you for your practice uh I
310:22 - think I have solved enough questions in
310:24 - the lectures only uh so I will share the
310:27 - DP with
310:28 - you you solve them I will share the
310:31 - answers and the detailed solution
310:33 - detailed printed solution I will type
310:34 - them with you instead of making a whole
310:37 - video of this lengthy uh
310:39 - solving because there are at least 7 to
310:42 - eight questions per DPP and there are
310:45 - almost 5 to six dpps so it will take lot
310:47 - of time to discuss each question one by
310:49 - one and there are and they are easy
310:51 - question as compared to the question
310:53 - discussed in the
310:54 - lectures so what I was thinking I will
310:57 - share them with you if you get some
310:58 - doubt you may ask me
311:01 - and I will share the detailed solution
311:04 - with you okay so let's move to this
311:06 - question six jobs are waiting to be run
311:09 - then expected running times are this one
311:11 - find the value of x using SDF okay so
311:14 - let us
311:15 - schedule all the process are available
311:17 - at time zero so which process has the
311:20 - least bu time because this is sgf
311:22 - shortest job first and this is
311:24 - non-preemptive so P5 will be scheduled
311:27 - it will run until
311:29 - completion at time when which process
311:31 - are present all of them are present so
311:33 - P5 will be over now I have to choose the
311:36 - smallest among the among these process
311:40 - except P5 so P4 this process has the
311:43 - shortest ver time so P4 will get
311:45 - scheduled it will run until completion
311:48 - now which process now P3 P3 is the
311:52 - shortest among
311:53 - 97 and x x is the One X lies between 5
311:58 - and 7 so it will be greater than five
312:01 - hence P3 will be scheduled first P3 will
312:03 - be scheduled until 8
312:05 - now X will come because its value lies
312:09 - between 5 to 7 and these ones are
312:11 - greater than 7 so X will be sh to next
312:13 - so P6 P6 with the first time of X so 8
312:17 - to 8 + 6 will be scheduled next now P2
312:22 - for 7 so 15 + x and then P1 that is 24 +
312:26 - x so what we are given there the
312:30 - expected running times are this and this
312:33 - uh X is the range of X is given and
312:35 - average completion time is 13 so we'll
312:37 - add the completion time of all and will
312:39 - divided by six because there are six
312:40 - process that will give me the average so
312:42 - P5 completed at 1 P4 at 3 P3 at 8 P6 at
312:46 - 8+ 6 P2 15 + 6 and P1 is 24 We'll add
312:49 - all of them and divide by six as there
312:51 - are six
312:52 - process and this 13 is given to us so X
312:56 - will be equal to this part and in just
312:59 - computation so I hope you got the idea
313:00 - how to solve these type of questions in
313:02 - the next lecture we will see an
313:04 - important algorithm that is priority
313:06 - based
313:08 - scheduling let's move to the new
313:09 - algorithm named priority based Shing
313:13 - this algorithm works exactly like sgf or
313:16 - srtf that means it could be
313:18 - non-preemptive or it could be
313:20 - preemptive except that it looks for
313:23 - priority instead of BU
313:25 - time so the process with the hard
313:28 - priority will be given preference in
313:29 - terms of scheduling what is a priority
313:32 - it is a number assigned in corresponding
313:35 - to the level of importance of a process
313:37 - let's say OS processes the that is
313:39 - operating system service routine will be
313:41 - given higher preferences than the user
313:44 - process okay so the OS process will have
313:47 - higher priority it could be non-
313:50 - preemptive or preemptive and the tie
313:52 - breaker will be the same that is lower
313:55 - process ID okay so if two process with
313:58 - the same priority comes then the one
314:01 - with the lower process ID will be
314:03 - selected So based on the type size and
314:07 - the resources integer value is given to
314:10 - a process that is the priority okay so
314:13 - what is the default convention the
314:15 - default convention is higher the
314:18 - number higher the priority will be there
314:21 - higher the number higher the priority
314:24 - okay so if it is given in the question
314:26 - that 10th be the lowest priority and
314:29 - number one be the highest priority then
314:30 - you have to take accordingly okay but
314:32 - the default one is higher number higher
314:34 - priority so let's solve using both
314:36 - preemptive and non- preemptive so these
314:38 - are the process these are the priority
314:39 - of the process arrival time and the
314:41 - burst time let's solve using non
314:43 - preemptive so this is the arrival time
314:45 - P1 arrived first so we will schedule P1
314:48 - and it will run until completion because
314:51 - this is the case of non preemption so it
314:53 - will run until 4 at time four which
314:56 - processes are available process two and
314:59 - process three which has a higher
315:01 - priority process three so we will
315:02 - schedule process three until it
315:04 - completes so it will run for 5 minutes
315:06 - of time so 4 to 9
315:10 - process 3 will
315:11 - run and in the end process two will run
315:14 - for 9 to 12 so this was the case for non
315:16 - preemptive and for the preemptive
315:19 - case process will continue to run until
315:22 - a new process with the higher priority
315:24 - arrives so P1 was the first to come in
315:27 - the C in the RQ so P1 will be scheduled
315:29 - first and it will run until a new
315:32 - process the higher priority arrives so
315:34 - P2 is the new process with higher
315:36 - priority so it will run until one and
315:38 - then P1 will be preempted and P2 will be
315:40 - scheduled and P2 will run until a new
315:43 - process with high priority arrives so P2
315:45 - will run
315:47 - until one unit and P3 arrives now P3 is
315:53 - the process with the highest priority so
315:55 - it will run until completion so it is a
315:58 - worst time of 5 so it will run from 2 to
316:00 - 5 and then which processes are present
316:02 - in the ricu now P1 and P2 which is a
316:05 - higher priority P2 so we will schedule
316:07 - P2 until it completes see see in
316:12 - srtf whenever the process stopped
316:14 - arriving it behaves like sgf or the
316:18 - preemption or we do not preempt the
316:20 - process when there is no new process
316:23 - arrival okay so when new process stops
316:26 - coming will stops the preemption so here
316:29 - at time three 0 1 2
316:33 - so at time three at time three no new
316:35 - process came so after this we did not
316:39 - preempt any process before its
316:41 - completion okay so these
316:44 - process left the CPU after their
316:46 - completion only okay so I got the point
316:48 - this is similar to srtf and sgf but in
316:51 - srtf we used to focus on first time and
316:54 - here we will focus on priority this is
316:56 - as simple as that let's solve another
316:58 - question so there are six process
317:00 - available these are the priority this is
317:02 - the arrival time and this is the burst
317:03 - time so let's create Gant chart so we
317:06 - can see there is no new no process at
317:08 - Time Zero so the the first process
317:10 - arrived at time two from 0 to two the
317:13 - CPU will remain idle at time two at time
317:16 - two I can see that process 4 is
317:18 - available at time two the process 4 is
317:20 - available with priority three so I will
317:22 - schedule process 4 until a new process
317:24 - arrives at time three that is a higher
317:26 - priority than process four priority so
317:28 - six is greater than three so we will
317:29 - preempt four and we will schedule P2 now
317:33 - P2 will run until a new process arrives
317:35 - with a higher priority so after time
317:38 - time three new process arrives when a
317:42 - new process arrives at time four that is
317:44 - P1 but it Priority is lesser
317:46 - than the priority of P2 so we will
317:49 - ignore that process and then another
317:51 - process comes at P at time five which is
317:53 - a higher priority so we will preempt
317:56 - that process and we will schedule the
317:57 - process with the higher priority so P5
317:59 - will be scheduled and I can
318:02 - see that it has a second highest
318:06 - priority so it will run until the new
318:09 - process with the higher priority comes
318:11 - so after 3 units a new process with the
318:13 - high PRI but it bu time is two so it
318:15 - will complete at time 7 at time seven
318:18 - which process are available in the RQ P2
318:20 - is available with the the highest
318:25 - priority because at time five P5 got
318:29 - erased and the new process with the
318:31 - highest priority will come at time 8 so
318:34 - at time 7 P2 will be the process with
318:36 - the highest priority so we will schedule
318:38 - P2 and it will run until a process with
318:41 - the highest priority that is P3 with the
318:43 - priority 8 will come so as the process
318:45 - with the highest priority come the
318:46 - process with the lower priority that is
318:48 - six is lower with lower as compared to
318:50 - eight so this will get preempted and P3
318:52 - will be scheduled and it will run until
318:55 - it gets completed because it the highest
318:57 - priority process so till 8 to 14 it will
319:00 - run as it is a bus time of
319:02 - 6 okay now which process will
319:06 - come now which process will come P6 will
319:09 - come P6 has a priority of five and it
319:13 - has arrival time of three so P6 will be
319:15 - scheduled why not
319:18 - P2 I think P2 got completed here 3 to 5
319:22 - that is 2 unit and 1 unit so P2 was
319:25 - completed and the next highest process
319:28 - and the process with the highest
319:29 - priority after P2 and P5 was P6 so we
319:33 - will schedule P6 here so P6 will run for
319:36 - how much time P6 will run for five
319:39 - minutes of time because now new process
319:40 - has start arriving so whenever new
319:43 - process stops
319:45 - arriving the mode changes it becomes
319:47 - from preemptive to non preemptive okay
319:49 - so say the mode changes from preemptive
319:51 - to non preemptive now when the process
319:53 - get scheduled it will run until
319:55 - completion so this will run until
319:57 - completion run until completion run and
319:59 - run okay so at time 23 P4 will get over
320:02 - so what will be the schedule length
320:04 - completion time of the last process till
320:07 - the arrival time of the first process so
320:08 - from 2 to 23 that is 21 will be
320:12 - the answer for schedule
320:15 - length so let's start the part two of
320:18 - priority based
320:19 - scheduling in priority based scheding
320:21 - what we used to do we used to schedule
320:23 - the process based on the priority it is
320:25 - a number assigned to the process which
320:27 - was corresponding to the level of
320:29 - importance given to process okay so
320:31 - priority can be the static or dynamic
320:33 - static priority means fixed priority and
320:35 - dynamic means wearing can priority be
320:38 - wearing yes we will understand after
320:41 - some time so the problem will pursue
320:44 - that is the starvation to lower priority
320:46 - process because if high priority process
320:49 - keeps on coming then OS will never
320:50 - schedule a low priority process that
320:52 - will cause to the starvation to it and
320:54 - this is unfair so what we will do we
320:57 - will increase the priority so lower
320:59 - priority process will become higher
321:01 - priority process after some time that
321:04 - means the priorities are not fixed they
321:06 - are wearing they are Dynamic so Dynamic
321:08 - priorities that is based on the Aging
321:10 - algorithm will be the solution for
321:12 - starvation don't worry we will solve
321:14 - some questions on that okay so let's
321:17 - move to the question number one what
321:18 - does it say uh there's a system with
321:20 - three process P1 P2 and P3 and they have
321:23 - infinite instances of these process so
321:26 - the first instance arrival time of each
321:28 - process first instance is 1 millisecond
321:31 - what I want to say there are three
321:33 - process P1 P2 and P3 and they have
321:35 - infinite instances of them okay the
321:37 - first instance are arrived at Time 1
321:40 - millisecond the second instance of P1
321:43 - arrived at Time 4 and the third instance
321:47 - at time 7 so they have periods okay 3 7
321:49 - and 20
321:51 - 3 7 and
321:56 - 20 okay so now the question is what is
322:00 - the completion time of first instance of
322:02 - process P3 so I have said there are
322:03 - three process P1 P2 P3 there they have
322:06 - infinite instances so when the what is
322:08 - the time when this instance will get
322:10 - over okay so nothing we have to just
322:12 - schedule and there is one more Point
322:14 - given that the priority is inverse of
322:17 - the period
322:18 - so the parity of process one will be 1X
322:21 - 3 P2 will be 1X 7 and third will be 1x2
322:24 - so let's
322:25 - schedule so we will start with Time Zero
322:28 - which process is available at Time Zero
322:31 - no process was available all of them
322:33 - came at Time 1 millisecond so from 0 to
322:35 - 1 CPU will become idle at Time 1 which
322:38 - process will be scheduled the process
322:40 - with the higher priority this will be
322:42 - scheduled P1 will be scheduled for how
322:44 - much time as this is of higher priority
322:46 - it will complete
322:48 - until it will execute until completion
322:51 - so from 1 to two P1 will schedule so
322:54 - first instance of P1 completed at time
322:56 - two now who will come P2 will come P2
323:00 - will run for 2 units of time so P2 will
323:03 - run for 2 unites of time because this is
323:05 - the highest priority process among P2
323:08 - and P3 P1 was over now P2 and P3 are
323:11 - remaining so P2 will be scheduled for 2
323:13 - unites of time so from 2 to 4 P2 will
323:16 - get scheduled now which process are
323:18 - available in the ricq P3 and P1 the
323:21 - second instance of P1 came at Time 4 so
323:24 - P3 and P1 these are the two process
323:26 - present in the ricq Which is higher
323:27 - priority P1 is high priority so P1 will
323:29 - get sched for how much time for one unit
323:32 - of time it has one unit of bust time now
323:36 - at time five which processes are present
323:38 - at time five only P3 is present I guess
323:41 - yes only P3 is present so P3 will run
323:45 - for how much time until a new process
323:47 - with higher priority arrives so P3 will
323:49 - run for 2 units of time because at time
323:51 - 7 P1 came which is of higher priority so
323:54 - P3 will get preempted at time 7 and P1
323:57 - will
323:58 - come okay so from 7 to 8 it will run
324:02 - because it will run until completion as
324:04 - it is the process with the highest
324:06 - priority so it has wor time of one so it
324:08 - will run from 7 to 8 now which pluses
324:12 - are present in the RQ P2 is present
324:15 - because at time 8 the second instance of
324:17 - P2 came so P2 is present P2 will come in
324:20 - the RQ or P2 will come in the CPU and it
324:23 - will run for 2 units of time so from 8
324:25 - to 10 P2 will run now the third instance
324:29 - came from came at time
324:31 - 7 third instance I think this was all
324:35 - completed now the fourth instance of P2
324:38 - oh sorry a fourth instance of P1 will
324:40 - come at time 10 so fourth in instance
324:43 - will get
324:44 - scheduled it will run for one unit of
324:46 - time I said they have infinite instances
324:48 - they have infinite instances so the
324:50 - fourth will come at time 10 now P1 Will
324:54 - C schedu see P3 is not getting chance to
324:57 - be run after this first P1 came then P2
325:00 - came then again P1 came now P3 will give
325:03 - the chance
325:04 - because P2 is over and its next instance
325:08 - will come come at time 15 P1 is over and
325:11 - its next instance will come at time 13
325:15 - so at time 11 only P3 have have been in
325:18 - the CPU so it will run for how much time
325:20 - its remaining bu time so P3 has already
325:22 - run for 2 units here so it will run for
325:24 - 2 minutes here so what will the
325:25 - completion time of first instance of P3
325:28 - at 13 so 13 will be the time 13
325:30 - millisecond will be the
325:32 - answer now let's solve a question on
325:34 - Aging algorithm consider a system using
325:36 - preemptive priority baseding dynamically
325:38 - changing priorities the priorities are
325:41 - Dynamic on its arrival a process is
325:43 - assigned to a priority of zero so when
325:45 - the process arrives the priority is set
325:47 - to Zero running process priority
325:49 - increases at the rate of beta and the
325:52 - priority of process in ricu increases
325:55 - the rate of alpha by dynamically
325:57 - changing the values of Alpha and beta
325:59 - one can achieve different scheding
326:00 - disciplines well that is clear because
326:04 - see if the priority if the prior of the
326:09 - process in the RQ is more than the
326:10 - priority of process
326:13 - running then it will be preemptive and
326:15 - if the priority of running process is
326:18 - more than the priority of ready process
326:19 - then it will be non preemptive I hope
326:21 - you got the point so what will be the
326:24 - disciplin be followed by the following
326:25 - conditions so let's see if the process
326:27 - arrives the priority is zero process in
326:30 - ricu increases by Alpha rate and
326:32 - processes running increases by Beta
326:34 - rate so in a job queue when a new
326:37 - process arrives
326:38 - it has a priority of priority increase
326:42 - by Alpha rate so let's say at time one
326:44 - at time one what will the priority of
326:46 - ricq what will the pariy of processing
326:48 - ricq at Time 1 it will be Alpha because
326:52 - initially at Time Zero it was Zero at
326:55 - time one let's say it increased by Alpha
326:57 - so the priority of process in the ricu
326:59 - will be Alpha and what will the priority
327:02 - of process in the CPU running at Time 1
327:05 - it will be beta so now we have to
327:07 - compare Alpha and beta beta so if beta
327:10 - is greater than Alpha which I mean to
327:12 - say if the priority of process running
327:15 - is greater than priority of process in
327:17 - the ready then no ready process can ever
327:19 - preempt the running process because beta
327:21 - is greater than Alpha so it will behave
327:23 - like
327:24 - fcfs first come first serve and if if
327:29 - ready process have always greater
327:32 - priority than the running process if
327:35 - ready process have always the greater
327:37 - priority than running process process
327:39 - but
327:40 - but a newly arrived process have always
327:44 - greater priority than ready process and
327:45 - running process then what will happen
327:47 - think think if a newly ared process have
327:50 - greater priority than running process
327:53 - and ready process then the newly arrived
327:55 - process will be scheduled first which
327:57 - means the one who came at last will get
327:59 - scheduled first so last come first serve
328:02 - and here the one who came earlier will
328:05 - be scheduled first I hope you going to
328:08 - point the one who came earlier will be
328:10 - scheduled first and in this the one who
328:12 - came at last will be scheduled
328:14 - first okay so if you have some doubt
328:17 - this is an easy question think about it
328:20 - here's the question read it again think
328:22 - about it see the solution and you will
328:24 - and your doubt will clear
328:26 - automatically welcome to the new lecture
328:29 - and in this lecture we learn about the
328:30 - round robin algorithm this is the most
328:32 - famous scheduling
328:34 - technique in this roundr algorithm let's
328:37 - understand the IDE
328:39 - if the process fails to execute all its
328:41 - instruction in the given time Quantum so
328:44 - we assign a fixed time Quantum let's say
328:46 - of 4 seconds if the process gets its all
328:50 - instruction complete in the 4 second
328:52 - this is well and good otherwise the pro
328:54 - the OS will preempt that
328:56 - process and will give chance to other
328:59 - processes to be with the CPU and that
329:01 - process that preempted process will go
329:03 - to the end of the
329:05 - Rue and go to the end of the ricq so
329:07 - let's see round an algorithm this
329:09 - algorithm is used in preemptive based
329:11 - multi-programming time sharing operating
329:13 - system okay what does it do it improves
329:16 - interactiveness and responsiveness of
329:18 - the system so let's understand this by
329:20 - real life example so what we used to do
329:22 - in
329:23 - India we used to play cricket on the
329:26 - Terrace of our house okay so I I can
329:30 - recall when we were smaller when we when
329:32 - we were younger there was a big uh there
329:35 - was a big ba the big brother he used to
329:40 - play for so so far so long he used to
329:44 - play and we we the smaller kids do not
329:47 - get a chance to
329:48 - bet so we decided a rule we created a
329:52 - rule that every one of us will play only
329:55 - six balls that is in in one hour consist
329:58 - of six balls so every one of us will
330:00 - play only six balls and whether you are
330:02 - out or not you have to retire and give
330:03 - chance to other players to bet okay so
330:07 - that such things do not happen that uh a
330:11 - player who is good to a player who is
330:13 - good in cricket do not get out easily
330:15 - and we used to just ball and
330:18 - field and and in in childhood days we we
330:22 - used to think that balling and Fielding
330:24 - is boring and batting is a good thing so
330:26 - we all of us want to bat but this big
330:28 - boy doesn't let us to bat he was good in
330:31 - cricket so we decided a rule that
330:34 - whether you are out or not you have to
330:36 - leave you have to retire after after six
330:39 - balls you will go there in the fielders
330:42 - and one of us will go to B okay so the
330:46 - similar case is there the similar case
330:48 - is here in the round robin we assign a
330:51 - Time Quantum to a process whether a
330:53 - process completes its instruction in
330:55 - this time Quantum or
330:57 - not the process has to leave after that
331:00 - time Quantum and other processes who are
331:03 - waiting for the CPU will get a chance to
331:05 - be with the CPU so the criteria will be
331:07 - the arrival time plus the time Quantum
331:09 - and the mode of operation will be this
331:11 - is obvious preemptive okay so let's see
331:14 - the question first before starting the
331:17 - question I have a tip for you always
331:19 - maintain the status of
331:21 - ricu and keep cutting the processes
331:24 - which have been over from ricu see this
331:27 - is an important
331:30 - thing this is not only mandatory for
331:33 - round robin I suggest you should
331:35 - maintain ricq for any of the SCH
331:38 - algorithm this will decrease the chances
331:40 - of silly mistake which you may make but
331:43 - in case of round robin it is almost
331:46 - impossible or it is very very difficult
331:50 - to create Gant chart without the help of
331:53 - radue otherwise you may make mistake
331:56 - okay so what is my tip always maintain
331:59 - the status of ricu always and always
332:01 - maintain the status of ricu especially
332:03 - while solving the round robin questions
332:06 - and keep cutting the process from ricu
332:07 - like this way those which are completed
332:10 - keep cutting okay so let's see this
332:13 - question here the time Quantum is two
332:16 - which means a process will run for 2
332:19 - units and then it will pre automatically
332:22 - so let's
332:23 - start so P1 P2 and P3 all are available
332:27 - at time zero so which process will will
332:29 - schedule the one who arrived earlier all
332:31 - of the arrived them same time so we will
332:33 - use the tri breaker rule TI breaker rule
332:35 - that is the lower process ID so we will
332:37 - schedule P1 what is the burst time of P1
332:40 - P1 is burst time of 4 unit so we will
332:42 - schedule for two time Quantum and then
332:45 - it will preempt so P1 P2 and P3 all of
332:48 - them were available at
332:49 - Time Zero now what will
332:53 - happen till time two till time two P1
332:56 - will run and it will go to the end of
333:00 - the radue at time two see I have seen I
333:02 - have written this I have written
333:05 - this if the time Quantum expires then OS
333:08 - will preempt the process and the
333:09 - preempted process will go to the end of
333:11 - the ricu so this P1 this P1 when it will
333:15 - get preempted it will go to the end of
333:16 - Rue so this was the Rue and it will go
333:19 - there now what will happen let's
333:22 - see at time to P2 will get scheduled now
333:27 - P2 will get scheduled it will run for
333:28 - how much time it will run for 2 units of
333:30 - time so it will run for 2 minutes of
333:32 - time now the remaining bus time I have
333:35 - maintained here 5 3 and 4 two now who
333:39 - will run now P3 will run P3 will run for
333:42 - how much time it is a bu time of three
333:43 - so it will run for two units and the
333:45 - remaining will be one so it will run
333:48 - there and after at Time 4 P2 will go at
333:51 - the end of ricu and at time 6 p 3 will
333:54 - go at the end of ricu now what will
333:56 - happen see this was completed now I will
333:59 - schedule P1 so P1 will get scheduled for
334:01 - how much time for 2 units of time so
334:03 - this will get over and P1 completed if
334:06 - P1 completed there is no need to send
334:07 - back to the Rue it will go to the
334:09 - terminate stage it will end so at time 8
334:13 - P1 ended now which process is available
334:16 - P2 is available so we'll schedule P2 so
334:19 - we'll schedule P2 then the remaining
334:20 - time will be 1 unit so at time 10 P2
334:24 - will again go back to the ready
334:27 - Cube
334:29 - okay so now P2 gets over now the turn is
334:34 - of P3 so P3 will run for how much time
334:35 - the remaining bus time is one so P3 will
334:37 - run for one unit of time so from 11 P3
334:39 - will run and it will end here now P2
334:42 - will run so I will cancel it and P2 will
334:45 - go there so in this way if you just put
334:48 - a cross mark there it will be easy for
334:50 - you to remember that we have scheduled
334:52 - all the
334:54 - process which has a cross mark okay I I
334:57 - hope you got the idea so this round
335:00 - dropping is a new type of uh Shing
335:03 - technique so I suggest you
335:05 - to do this Sol this question or on your
335:09 - own now and get this G chart okay so let
335:12 - us go there and solve another
335:15 - question this is a new question this is
335:18 - a another variety of round dring
335:20 - question which you will explore see
335:22 - there are five
335:24 - processes okay each arrived at different
335:26 - time and they have the bus time also
335:28 - given the time Quantum is two so we will
335:31 - schedule process P4 as it arrived at
335:34 - time three the earliest so from 0 to 3
335:37 - CP will remain idle and at time three P4
335:39 - will get scheduled for how much time the
335:41 - time Quantum is two so out of three two
335:44 - will get over so one will remain now at
335:46 - time five at time five P4 will go at the
335:50 - back of Rue
335:53 - but at time five we can see that P1 and
335:57 - P5 are also present in the ricu so
336:01 - firstly the new process will come and
336:03 - then the preempted process will join
336:05 - them at the back
336:07 - I'll speak again P4 ran in the CPU from
336:11 - time 3 to
336:14 - 5 L A Time five I see there are two
336:17 - process already
336:18 - available that is P1 and P5 so what I
336:21 - will do I will enter these process I
336:24 - will enter this process in the ricq
336:26 - first and then the preemptive process
336:28 - will go at the back of Rue so the
336:30 - firstly the new arrived process so the
336:32 - new process will come in the RQ and then
336:34 - the preemptive process will go let me
336:37 - this week again first the new process
336:39 - and then the preemptive process the new
336:40 - process and then the preemptive process
336:42 - so I hope you got the idea now let's
336:45 - continue our discussion
336:48 - so so P4 was present in the radic time
336:51 - three so from 0 to 3 the CP will remain
336:53 - idle and at time three P4 will come P4
336:57 - will run for 2 units of time P4 will run
336:59 - for 2 units of time and the remaining
337:00 - bus time will be one at time five there
337:03 - are two new process that is P1 which
337:06 - arrived at time four and P5 which
337:08 - arrived at time five so I will schedule
337:09 - the new process in the RQ I will sent
337:11 - the new process in the RQ and then the
337:14 - preemptive preempted process will go so
337:16 - new process then preemptive process now
337:20 - I will cancel this part and then when I
337:22 - schedule P1 I will cancel this part okay
337:24 - so I have already scheduled P4 now I'm
337:27 - going to schedule P1 so I will cancel
337:28 - this P1 will get scheduled P1 is a bu
337:30 - time of four so it will run for 2 units
337:32 - of time it run for 2 units of time that
337:35 - is from 5 to 7 from 5 to 7 p Dr at time
337:39 - 7 is there a new new process no no new
337:42 - the next new process came at time 8 so
337:45 - at time 7 no new process came so I will
337:47 - directly send this P1 at the end of RQ
337:52 - this was the end of RQ then there so P4
337:55 - will go there and P1 will go at the end
337:57 - of ricu now I will schedule P5 so P5
338:00 - will come P5 is a bus time of four so
338:03 - two will be the remaining bus time so P5
338:05 - will get scheduled here now from 7 to9
338:08 - P5 will come P5 will come at time line I
338:11 - can see that there is a new process so
338:14 - the firstly the new process will come
338:16 - and then the preempted process will come
338:19 - new process will come first and then the
338:21 - preempted process so preempted process
338:23 - will go there now what I will
338:26 - do now I will schedule P4 so P4 was
338:29 - scheduled again for how much time it
338:31 - will run for one unit of the remaining
338:32 - bus time so P4 will run for one unit at
338:35 - time 10 is there any new process no the
338:37 - next new process is going to come at
338:39 - time 15 so at time 10 which process are
338:42 - available these processes are available
338:44 - so I will schedule P1 first then P3 and
338:47 - then
338:48 - P5 I can see the process which that is
338:52 - P2 came at time 15 so the new process
338:55 - will come
338:56 - first so at time 15 P2 will come and
339:00 - then the preempted process that is P3
339:03 - will go
339:05 - there okay so I hope you got the idea so
339:09 - in the same way you have to complete the
339:10 - Gant
339:14 - chart so let me revise again what we
339:17 - have done till now so round dring
339:19 - algorithm is a kind of algorithm which
339:21 - has a fixed time unit a fixed time slice
339:23 - if the time slice expires
339:26 - then the OS will preempt the process and
339:28 - then that preempted process will go at
339:31 - the end of
339:32 - RQ after the new process comes Okay so
339:37 - the tip was always maintain the status
339:39 - Rue and keep cutting from Rue so we have
339:41 - seen this
339:43 - question let us let us do let us uh
339:46 - revise this question again because this
339:48 - is an important
339:50 - question firstly 0 to 3 CP will remain
339:53 - idle at time three P4 will get scheduled
339:55 - it will run for how much time at time
339:56 - three P4 run for two unit of time
339:58 - because this is time Quantum two one
340:00 - will be remaining this one will be
340:01 - scheduled later at this moment of time
340:03 - so P4 will get completed at 10 now will
340:07 - come P1 will come so P1 will get
340:10 - scheduled at time 7 at time 7 which
340:13 - process are available in the RQ P5 and
340:16 - P4 are available so they will come first
340:18 - and then people will go behind them and
340:20 - then we will schedule accordingly P5 P4
340:22 - P1 and then the new process will come
340:25 - that is P3 and then the old process that
340:27 - is p P5 will go there now new process is
340:30 - present then it will come otherwise this
340:34 - this get over P5 P4 get over then P3
340:36 - will go there
340:37 - here new process come then P5 that is
340:41 - this part will get sheded so in the same
340:43 - way you have to keep on going this is a
340:45 - ly question I don't want to waste my
340:46 - time on this I hope I have given you the
340:49 - concept now the computition part you can
340:51 - do on your own let's see another
340:53 - question let's move to another
340:55 - question this is a smaller one so we'll
340:57 - complete this question this is a round
341:00 - robin question in this question the
341:02 - process first go to The Bu time and then
341:04 - I and then again comes okay so let's
341:06 - solve I think this is an interesting
341:07 - question so the first process arrived at
341:11 - time zero so we'll schedule process P1
341:13 - for how much time
341:15 - for two time Quantum so from 0 to 2 P1
341:19 - will be there
341:21 - and I have I have written the bu time in
341:24 - there okay so from 0 to
341:27 - two two units will be subtracted from
341:30 - three so one will remain now which will
341:32 - come at time two P2 also arrived in the
341:35 - RQ so P2 will be scheduled for how much
341:37 - time for 2 units so from five 2 units
341:39 - subtracted that this three will remain
341:42 - now at
341:44 - Time 4 which process will come P3 is
341:48 - present in the ricq
341:49 - but it came at time three and P1 came
341:53 - back to the Ric time two so P1 will come
341:56 - first so P1 will come here for how much
341:58 - time it will run for one unit of time so
342:00 - it will run for 1 unit of time it has
342:02 - completed its bus time the first phase
342:04 - of the bus time now it will go to IO at
342:06 - time then
342:07 - time from 5 to 5 from 5 to 5 that is
342:10 - time 10 so it will come back in the ricu
342:12 - at time 10 okay at time five which
342:16 - process are present in the ricu at time
342:19 - five these processes are present in the
342:21 - ricu P3 was over so P1 was over so P3
342:25 - will be there for how much time P3 will
342:27 - run P3 will run for 2 units of time so
342:29 - P3 will run for 2 units of time now the
342:31 - first phase of first phase for the first
342:34 - time of P3 was over now it will go for I
342:37 - from 7 to 9 it will go to I and then P3
342:40 - will come back to the to the Rue at
342:42 - which time at 9 so P3 will come back
342:45 - here now P2 will be scheduled for how
342:49 - much time see time Quantum was 2 unit
342:53 - and three was the remaining bus time so
342:55 - one will remain for the bus time of P2
342:57 - so two unit will be there now P3 will
343:01 - come again P3 has completed this part
343:04 - and this part now P3 will come there
343:06 - again from 9 to 11 11 P3 will end so P3
343:08 - ended at time 11 now which processes are
343:12 - present in the RQ now P2 will get
343:14 - scheduled P2 will get scheduled for how
343:17 - much time P2 will run for just one unit
343:19 - so from 11 to 12 P2 will
343:21 - run now which process will
343:24 - come P1 will come and at time 12 P2
343:29 - completed this part so it will go for Io
343:31 - till 20 till 20 okay so it will come
343:36 - back to the radic at time
343:38 - 20 now P1 P1 is a how much time
343:41 - remaining 1 so P1 will execute for how
343:43 - much
343:44 - time no no no no now we have moved to
343:47 - this part so P1 will execute for two
343:50 - units of time so two unit will be
343:52 - remaining so P will execute for two unit
343:54 - of time but there is no other process in
343:56 - the Rue so it will execute for two more
343:58 - so execute for two more so from 12 to 16
344:02 - it
344:03 - will execute now there's an important
344:05 - part which I want to emphasize upon you
344:07 - think operating system will preempt P1
344:09 - at this
344:11 - moment yes it has preempted P1 in this
344:15 - moment because so P1 will continue its
344:18 - execution preemption will obviously
344:20 - happen there at time 14 at time 16 which
344:23 - process are present in the ricu see P1
344:25 - got over P1 got over P3 got over now the
344:29 - only process which is left is P2 but
344:33 - what it is doing it is performing its IO
344:34 - till 20 so CP is nothing to do till 20
344:36 - so will wait till 20 so at this time CPU
344:39 - will remain idle at time 20 it will come
344:42 - back to the CPU to execute the one unit
344:44 - of B time so it will come back to from
344:46 - 20 to 21 P2 will come back to the CPU
344:49 - and at time 21 this will preempt or this
344:52 - will
344:54 - terminate okay so these are the some
344:57 - questions for homework so these are the
344:59 - easy questions you can do on your own
345:02 - okay so I have also shared the solution
345:06 - with you see the question the next one
345:08 - this is also homework homework question
345:12 - and in the next lecture we will learn
345:13 - about the response
345:16 - time so in the last lecture we have seen
345:19 - about round robin algorithm we have
345:21 - solved some questions on it in this
345:23 - lecture we will learn about the
345:25 - performance of round robin see the
345:27 - homework question and learn the New
345:30 - Concept of response time in the first
345:34 - lecture of CPU scheding I have talked
345:35 - about it that the goal of CPU scheding
345:38 - is to minimize the turnaround time
345:40 - waiting time and response time we have
345:42 - talked about this but this was remaining
345:45 - so in this lecture we'll clarify what is
345:48 - response time so let's start with the
345:50 - performance of round robin performance
345:53 - of round robin depends upon the time
345:55 - Quantum its value if it is taken very
345:57 - small small large and very
346:00 - large what is the consequence of that so
346:03 - if we have taken very small time
346:05 - Quantum then the efficiently will be
346:08 - nearly
346:10 - zero most of the time will be taken by
346:13 - dispatcher to schedule the task as soon
346:15 - as the task starts running on the CPU it
346:18 - will again be preempted and then a new
346:20 - process has to come dispatcher has to
346:22 - work and as soon as the new process
346:24 - start to be
346:26 - executed then that process will also get
346:28 - preempted and a new process will come so
346:30 - efficiency the net efficiency will drop
346:32 - to zero dispatcher will take the most of
346:35 - the time and the useful time what is the
346:37 - formula of efficiency useful time upon
346:40 - total time so the total time will be
346:44 - contributed most by the dispatcher and
346:47 - the useful time will be very less so
346:49 - efficiency will drop to zero if the time
346:52 - Quantum is taken small then then there
346:55 - will be more contact
346:57 - switching and there will be more
347:00 - overhead what is overhead dispatch
347:02 - latency but the responsiveness will
347:04 - increase if the time Quant is reasonably
347:07 - small then responsiveness will
347:09 - definitely increase if the time Quantum
347:12 - is reasonably large then contact
347:14 - switching will less so overhead will be
347:17 - less but interactiveness will
347:20 - decrease if I took time Quantum very
347:23 - large
347:25 - then let's say the time Quantum is is
347:29 - greater than the maximum of BU time then
347:32 - the round robin will perform like fcfs
347:36 - because none of the process will get
347:38 - preempted in between because the time
347:40 - Quantum is greater than the maximum of
347:42 - burst time so it will be least
347:44 - interactive and it will behave just like
347:46 - the fcfs algorithm what was the
347:49 - selection criteria of round robin
347:51 - arrival time plus time time Quantum and
347:54 - if time Quantum if time Quantum is
347:56 - greater than the first time of any
347:58 - process then it will behave just like
348:01 - fcfs I hope you got the idea let's
348:04 - discuss the homework question which I
348:06 - have given you it is a very nice
348:07 - question if you haven't solved this till
348:09 - now I request you I sincerely request
348:12 - you to please pause the video and solve
348:15 - this question this will teach you so
348:17 - many
348:18 - things okay so let's
348:22 - begin it is it is not a difficult
348:24 - question it is an easy question just a
348:26 - conceptual one so what this what does
348:28 - this question say we will learn consider
348:32 - a system okay with n processes arriving
348:35 - at time zero so at Time Zero all the end
348:37 - process are present in the ricu with
348:40 - substantially large bust time so bust
348:42 - time let's say each process a bust time
348:44 - of 100 the CPU scheduling overhead is s
348:48 - so the Delta is s the time Quantum is QC
348:52 - and time Quantum is Q using round robin
348:55 - scheduling what must be the value of
348:57 - time Quantum Q such that each process is
349:00 - guaranteed to gets gets a turn at time
349:03 - at the CPU exactly after T seconds in it
349:06 - subsequent run on the
349:08 - CPU okay so how we will start this
349:12 - question see every CPU scheduling
349:15 - question it starts with the creation of
349:17 - Gant chart as soon as you create Gant
349:19 - chart you'll get an idea of how to solve
349:21 - it so let us start
349:24 - so here it is written every process
349:27 - there are n process and every process
349:29 - arrived at time zero so each process was
349:31 - present in the radue at time zero and it
349:34 - has a very large ver time so we need not
349:36 - think of B
349:37 - time why this line is given this line is
349:40 - given to prevent this
349:44 - case Okay
349:46 - so if bu times are substantially large
349:50 - then it will be mandatory for for the
349:53 - process to preempt in between of its
349:56 - execution bus time is larger than the
349:59 - time Quantum okay the CPU scheduling
350:02 - overhead is s second and time Quantum is
350:03 - Q using this we have to schedule in such
350:06 - a that each process is guaranteed to
350:08 - gets its turn at CPU exactly after T
350:11 - seconds in the subsequent run so what I
350:13 - have said in round robin when the
350:15 - process gets preempted it go back and
350:18 - join the end of the queue so when all
350:21 - these process will get it turn after
350:23 - that P1 turn will come so we are asking
350:27 - this is asking just that part that we
350:31 - have to schedule in such a way that each
350:33 - process is guaranteed to get its turn
350:35 - exactly after T seconds so this should
350:38 - be the T P1 got it turned exactly after
350:42 - the 3 second so this should be
350:44 - t Okay so let's draw the G
350:47 - chart schedule P1 0 to S we have seen
350:51 - that overhead was s so 0 to S will be
350:53 - the time taken by
350:55 - dispatcher s to S + q that is Q will be
350:58 - time taken by process P1 and then again
351:02 - P2 will get scheduled so s will be the
351:04 - time taken by the dispatcher so 2 s+ Q
351:07 - will be the time taken by the dispatcher
351:08 - and Q will be the time taken by P2 so 2
351:11 - s + 2 Q will be the time taken by P2 in
351:15 - the same way if P1 completed at s+ Q P2
351:19 - completed its first turn at 2 s + 2 Q so
351:24 - PN will complete this this process will
351:26 - complete its first turn at NS + NQ P1 at
351:29 - 1 s + 1 Q P2 at 2 s + 2 Q P3 at 3 S + 3
351:33 - Q so PN at NS + NQ
351:38 - now this P1 will go and join the back of
351:40 - the que so now it is the turn for P1 to
351:43 - get scheduled s will be the time taken
351:45 - by the dispatcher now the turn
351:50 - off now after this much time P1 got it
351:55 - turn to run on CPU here it is written it
351:59 - subsequent run on CPU it subsequent run
352:01 - on CPU so after how much time P1 will
352:04 - start running so for for this case we
352:07 - will include this Delta 2 you must have
352:10 - made a mistake if you haven't read the
352:12 - question properly here it is
352:14 - written using Round Rob and scheding
352:17 - what must be the value of time Quantum Q
352:19 - such that each process is guaranteed to
352:21 - get its turn at the CPU exactly after TC
352:24 - in its subsequent run on CPU run on CPU
352:27 - is given so we will so from this part P1
352:30 - have started running so we will include
352:34 - this Delta 2 so from this this this
352:37 - moment to this moment this will be the T
352:40 - so exactly after T second P1 got a
352:43 - chance to run on CPU so now what we will
352:45 - do we'll calculate this length so what
352:47 - is this length this is s+ q and this is
352:52 - n + 1 s + Q This was NS + NQ and there
352:56 - is a additional s so it will be n + 1 s+
353:01 - Q so n + 1 s + Q minus s+ Q will give me
353:05 - this length so I have written this and
353:07 - then from this equation I have solved to
353:09 - get the value of Q easy
353:12 - peasy now there are some inferences
353:15 - which we can derive from
353:18 - this Q so if Q is equal to exactly equal
353:23 - to tus NS n minus1 tus NS nus1 then
353:28 - process P1 will get onto CPU exactly
353:31 - after T
353:33 - second if Q is less what is does it mean
353:37 - time Quantum is less
353:41 - then P2 will run less P3 will run less
353:46 - P4 will run less but the but the t is
353:49 - fix so what does this signify this
353:52 - signify that process will get onto CPU
353:54 - at least once within the time T
353:58 - if the time Quantum decreased then P2
354:01 - will run less P3 will run less P4 will
354:05 - run less but
354:06 - this this length is fixed let me right
354:10 - this length is fixed this length is
354:12 - fixed if the process between these
354:16 - lengths between this length run for
354:18 - lesser time let's say P2 run for this
354:21 - time only and get preempted P3 run for
354:23 - this time only and get pred so P1 will
354:26 - get a chance earlier than the previous
354:29 - case are you
354:30 - following let me speak
354:33 - again this length is fixed the t is
354:37 - fixed if Q is lesser which means P2 run
354:43 - less than before P3 run less than before
354:46 - P4 run less less than before PN run less
354:50 - than before
354:52 - so P1 will get a chance earlier than the
354:57 - previous
354:58 - case Okay so process will get onto CPU
355:02 - at least once within the time
355:04 - T here the proc process got onto CPU
355:07 - exactly after the time T here the
355:10 - process will get onto CPU exactly once
355:12 - within the time T and when time Quantum
355:15 - become large and when time Quantum is
355:17 - become large it means P2 has run more P3
355:21 - has run more P4 has run more so what can
355:24 - we infer we can infer process will get
355:26 - onto CPU after at least every time 10
355:30 - seconds I have also explained them more
355:34 - so what does this say signify process
355:37 - will get onto CPU after at least every
355:39 - 10 second this says if the value of Q is
355:42 - large P1 will wait either TC or more
355:45 - than T that is self-explanatory because
355:48 - if this become larger if this become
355:51 - larger then P1 has to wait either t or
355:55 - more than T if this become smaller if P2
355:59 - run lesser than the usual then P1 has to
356:03 - wait either less than t or equal 2 D I
356:07 - hope you are understanding see let me
356:10 - speak again let me speak again if this
356:12 - is exactly equal then P1 get to run on
356:15 - CPU exactly after the TC this was the
356:17 - time T
356:19 - if the time Quantum is decreased in time
356:22 - Quantum is decreased then every process
356:23 - will run lesser than the usual P2 will
356:26 - run less P3 will run less so in this
356:30 - case in this case process will get onto
356:33 - at least once within the time T So P1
356:35 - has to wait either time T second or
356:37 - lesser than time
356:39 - TC if P2 run less then P3 run less P4
356:43 - run less so all the process will over
356:46 - earlier than the previous case so P1
356:48 - will get a chance earlier that is the
356:50 - point I'm trying to make here P1 will
356:53 - get a chance earlier here P1 will get a
356:55 - chance later here P1 will get a chance
356:58 - exactly after T I hope now the point is
357:01 - clear okay so this I have mentioned so
357:05 - this was a fantastic question
357:09 - let us learn about A New Concept that is
357:11 - response time time of admitting the
357:14 - request to the time of generating its
357:16 - result there the one thing is missing
357:18 - that is first result and it is not
357:21 - end yes the right is correct so you may
357:24 - think response time as the turnaround
357:26 - time it is somewhat similar to
357:28 - turnaround time in turnaround time what
357:30 - we used to say completion time minus
357:33 - arrival
357:34 - time the time when the process was
357:36 - admitted in the ricq till the time the
357:39 - process ended that time was the
357:42 - turnaround time but here one thing got
357:46 - changed that is time of admitting the
357:49 - request to the Rue till the time of
357:51 - generating its first result so when the
357:53 - process will complete for the first time
357:55 - that time minus arrival time will be the
357:57 - response time let's take an example
357:59 - suppose there's a process P1 which
358:00 - arrived in the ricu OR got
358:03 - admitted at the time let's say 4
358:08 - so at Time 4 it was let's say sheduled
358:11 - or let's say it has to wait for 6
358:15 - unit so at time 10 it was scheduled and
358:18 - it is a bust time of total
358:20 - 20 so it has run for 5 minutes of time
358:25 - so from 10 to 15 it has run now the
358:28 - remaining ver time is
358:30 - 15 so the time when it was admitted in
358:33 - the process till the time it has
358:35 - generated its first result that is the
358:37 - response time I hope you have got the
358:39 - idea now
358:41 - so let me clarify again the difference
358:43 - between turnaround time and response
358:46 - time so the turnaround time was that was
358:48 - the total time taken to execute a
358:50 - process starting from the moment till it
358:52 - enter the system until it completes the
358:55 - execution and exits the system the
358:58 - formula of turnaround time was
358:59 - completion time minus arrival time I
359:01 - hope you remember that now what is
359:03 - response time response time is the time
359:06 - taken from a
359:08 - from response time is the time taken
359:11 - from when a request was submitted until
359:15 - the first response was produced so this
359:17 - time was the response time when the
359:19 - request was taken until the first
359:21 - response was
359:23 - produced okay so the formula of response
359:26 - time will be first response
359:30 - time minus arrival time I hope now you
359:33 - have the clear idea of what is a
359:34 - response time let's solve a question on
359:37 - this then we will end our lecture
359:39 - consider a system using round dring
359:41 - scheduling with 10 process all arriving
359:43 - at Time Zero each process is associated
359:46 - with 20 identical request each process
359:48 - request consumes 20 millisecond of CPU
359:50 - time after which it spends 10 m
359:53 - milliseconds time on iO thereafter
359:55 - initiate subsequent request assume
359:57 - scheduling CPU scheduling overhead of 2
360:00 - millisecond and time Quantum of 20
360:02 - calculate the response time of first
360:03 - request of the first process easy
360:06 - question I have told you definition try
360:09 - to solve on your own just give it a try
360:13 - okay let's see the solution so what was
360:16 - given in the question each process was
360:19 - present in the radue at time
360:21 - zero and there are 10 processes each
360:25 - process has identical request 20
360:27 - identical requests each process each
360:30 - process I has a 20 identical request and
360:33 - each request takes 20 milliseconds of
360:36 - CPU and 10 milliseconds of IO and the
360:38 - time Quantum is 20 the scheding over
360:41 - overhead is two now the question is
360:43 - asked as response time of first request
360:46 - of the first
360:47 - process so what we do in such type of
360:50 - question nothing the approach one is
360:52 - create G chart and we will automatically
360:53 - know what we have to do so we'll do the
360:57 - scheduling so what P11 represent it
360:59 - represent
361:01 - the first request of the first process
361:03 - so P11 represent the first request of
361:06 - the first process so P1 will be
361:08 - scheduled two unit taken by dispatcher
361:10 - and 20 as the bus
361:12 - time and the time Quantum is also 20 so
361:16 - it's a good coincidence so from 2 to 22
361:19 - P1 will run P11 will run and for 10
361:23 - seconds or milliseconds whatever be the
361:26 - unit 10 milliseconds it will go for iio
361:28 - at time 32 it will go again at here so
361:32 - this will be the this will be the second
361:37 - request of the process one how many pro
361:40 - how many requests are there 20 requests
361:42 - are there how many process are there 10
361:44 - process are there so I hope you got the
361:46 - point at this time P11 left the CPU for
361:51 - 10 units it was in the io and then at
361:55 - time
361:57 - 32 the second request of process one
362:01 - enters the ricu Okay so
362:06 - what is the response time of first
362:09 - request of the first process so the time
362:11 - when it was admitted till the time it
362:14 - has generated its first result that is
362:16 - from 22 to 0 that is the 22 millisecond
362:19 - will be the answer now the another
362:21 - question is calculate the response time
362:23 - of first request of the last
362:25 - process first request of the last
362:29 - process response time of first request
362:31 - of the last process what is the last
362:33 - process P1 is the last process
362:37 - so P10 is the last
362:41 - process when was P10 admitted the first
362:44 - request of P10 that is
362:47 - p101 when it was admitted they all were
362:50 - admitted at Time Zero when it got
362:52 - completed it got completed at time 220
362:55 - so from 0 to 220 this will be the
362:57 - response time so 220 will be the answer
363:00 - question number three response time of
363:02 - subsequent request of any process in
363:05 - these type of question just take the
363:06 - process one so what will the response
363:08 - time of subsequent request which means
363:10 - the request number
363:13 - two so the response
363:15 - time of request number two that is
363:19 - p12 will be the time at which it was
363:22 - admitted till the time at which it was
363:24 - completed so it were admitted at time 32
363:26 - we have seen here and when it will be
363:28 - completed it will be complet at time
363:31 - 242 so the response time will be result
363:34 - minus admission
363:36 - that is 242 - 32 which will give 210 as
363:39 - the answer so this was also a good
363:41 - question in lectures we have taken
363:44 - questions which is handpicked by me
363:47 - these are all questions which will give
363:49 - you a
363:50 - new a new thinking okay so now our
363:55 - response time topic is over round robin
363:57 - topic is over in the next lecture we'll
363:59 - start with the multi-level
364:01 - CU congratulations we are at the last
364:04 - lecture of CPU
364:08 - scheduling we will start with the
364:10 - multi-level queue and after this the CPU
364:13 - scheduling will be
364:16 - complete I have something to tell you
364:18 - that in CPU scheding
364:21 - section we have solved enough numericals
364:24 - so I don't think there is a separate
364:26 - problem solving session for each
364:28 - algorithm so even though I will give you
364:30 - a dppp with detailed answers so you can
364:33 - try them on your own and one thing I was
364:36 - planning I should make a revision video
364:39 - of whatever we have done till now let's
364:41 - revise them in let's say an half an hour
364:45 - we make a revision video okay so let's
364:48 - start with the multi-level Q
364:50 - scheduling all algorithm which we have
364:52 - read till now was based on the single
364:54 - ricq
364:56 - system isn't it
364:58 - fantastic whatever algorithm which we
365:00 - have read till now was based on single
365:02 - ricu
365:03 - system so every kind of process every
365:06 - type of process was fit in a single ricu
365:10 - whether it was OS process background
365:12 - process foreground process a user
365:14 - process every process was in a single
365:17 - ricu system and for every kind of
365:20 - process we can apply only a single
365:23 - scheduling technique could it be
365:25 - possible that for OS process we can
365:27 - apply first come first serve and for
365:29 - user process we can apply round robin
365:32 - [Music]
365:34 - algorithm no it was not possible until
365:37 - the multi-level ricu came so what were
365:40 - the drawbacks of single ricu system
365:42 - there are different type of process all
365:44 - mixed up and placed in a single ricu so
365:48 - the different process are os process
365:49 - user process user process include
365:51 - interactive process foreground process
365:53 - background process
365:55 - so when all these process are mixed up
365:58 - and placed in a single Rue the searching
366:01 - time and filtering time of these process
366:02 - will be high if I want to search a
366:04 - single process let's say a foreground
366:06 - process
366:09 - then in a single ricu where all these
366:11 - process are mixed up the searching time
366:13 - and filtering time will be high each
366:16 - process is bound to follow a single
366:18 - scheduling
366:20 - technique which I have discussed earlier
366:23 - so what is the solution for this
366:25 - multiple rues so what we will do we will
366:28 - create multiple ricu like system process
366:30 - interactive process interactive editing
366:32 - process badge process student process so
366:35 - these are the different ricu for
366:37 - different type of process this is the
366:40 - ricu for least priority process and this
366:42 - is the ricu for highest priority process
366:44 - so different radices for different type
366:46 - of process now what happens different
366:49 - scheduling algorithm can be applied to
366:51 - different Q let's say I decide to apply
366:53 - fcfs here and apply round robin here can
366:56 - it be done yes it is possible but in the
366:59 - case of single ricq it was not
367:02 - possible so Q's are now divided in the
367:05 - the based off priorities the higher
367:08 - priority process should be scheduled
367:09 - first and then only lower priority
367:12 - process can be scheduled do you know
367:14 - what I'm talking about
367:15 - it the higher priority process should be
367:17 - scheduled first and then only the lower
367:19 - priority process can be scheduled can
367:21 - youer what I'm about to
367:22 - say let's say there's a process P1 in
367:26 - the student process so this P1 can only
367:28 - be scheduled when this process when this
367:30 - Rue this Rue this radue and this ricq
367:33 - all are empty then only P1 will be
367:38 - scheduled let's say there's a process
367:40 - named PX this PX can only be scheduled
367:42 - when this and this rues are
367:45 - empty so to schedule this to schedule
367:49 - this these three should be these three
367:51 - higher priority CU should be empty
367:53 - because the higher priority Pro higher
367:56 - priority process should be scheduled
367:58 - first then only lower priority process
367:59 - can be scheduled so this is a problem
368:02 - man this student process will start
368:07 - so what could be done star of the
368:09 - process lying on the low level what
368:11 - could be done the solution is
368:13 - multi-level Q scheduling so what we will
368:17 - do see we will penalize the process that
368:20 - have been running longer we will
368:23 - penalize them we will put that process
368:26 - in the lower CU suppose the the process
368:29 - in the ricq one it is already ran for
368:32 - let's say some four units of time now
368:34 - what we will do we will shift that
368:36 - process from this queue to this queue we
368:38 - will decrease its
368:40 - priority so what we will do we will
368:42 - penalize the process penalize it in what
368:44 - terms in terms of priority so we'll
368:46 - decrease the priority of those process
368:48 - which have been running longer so what
368:50 - we will do let's say this was ricu Zero
368:52 - at the top top level this process was
368:55 - admitted dispatched it has run for time
368:58 - Quantum of three but it has not
369:00 - completed so we will transfer it to the
369:04 - RQ one that is of lower priority we will
369:06 - increase the time Quantum time Quantum
369:08 - is equals to 5 now it has gone to CPU
369:11 - again it was not completed so we will
369:13 - move to the ricq 2 which means we will
369:15 - decrease the priority we will penalize
369:17 - them for the those process which have
369:20 - been running longer now you may have a
369:23 - doubt so how can be three CPUs no it's
369:25 - not 3 CPU it's just a representation it
369:27 - is one okay so the process which have
369:30 - been running longer will keep on
369:31 - decreasing the
369:33 - priority when the process is transfer
369:35 - from readyq 0 to RQ 1 we will not
369:38 - schedule the process
369:39 - immediately we will wait until the first
369:42 - que becomes empty so I've already told
369:44 - you the student process will only be
369:46 - scheduled when these four process are
369:48 - EMP when these four ricu are empty there
369:51 - is no process in these ricu then only
369:54 - this ricu process will be scheduled so
369:57 - when the process is transferred we will
369:59 - not schedule that immediately we'll wait
370:01 - until the upper cubes become empty so
370:03 - let's solve a question on this consider
370:05 - a system which is a CPU bond process CPU
370:08 - bond process means which is no IO which
370:11 - require the burst time of 80 Seconds the
370:13 - multi-level feedback you why we say
370:16 - feedback
370:17 - feedback feedback that's why we say
370:20 - feedback the multi level feedback Q
370:22 - scheduling algorithm is used and the Q
370:24 - time Quantum is 4 second time Quantum is
370:26 - 4 second and in each level It Is
370:28 - incremented by 10 second I have said
370:30 - we'll increase the time Quantum so here
370:33 - the time Quantum is incremented by 10
370:35 - seconds how many times the process will
370:37 - be interrupted or preempted how many
370:40 - times the process will be preempted on
370:42 - which Q the process will terminate its
370:44 - execution so it's it's an easy
370:47 - problem so time Quantum was 80 this is a
370:50 - longer process it started its execution
370:53 - from q1 so at q1 the first the time
370:57 - Quantum was four so it will execute for
371:00 - four units of time and the remaining bus
371:01 - time will be 76 it will be feeded back
371:04 - to the RQ 2 which is of lower priority
371:08 - it has a Time Quantum of 14 we have said
371:11 - that time Quantum will increment by 10
371:12 - seconds so 4 to
371:15 - 14 now it will run for 14 minutes of
371:18 - time and then it will be preempted what
371:20 - is 76 - 14 that is 62 so 62 will be
371:23 - preempted to this now 10 unit will be
371:25 - increased more 62 - 24 what will be the
371:28 - answer 38 38 will be preed to this 38 -
371:31 - 34 will again increase 10 34 will be
371:34 - preempted to this this no not 34 38 - 34
371:38 - is 4 so 4 will be preempted to this and
371:41 - 44 - 4 will
371:44 - be as only four the time Quantum is 44
371:48 - and the remaining best time is only four
371:49 - so it will complete here okay so at
371:51 - which queue it got completed 1 2 3 4 and
371:54 - F on Fifth Q it was completed and how
371:56 - many times it was interrupted 1 2 3 4 it
371:59 - was not interrupted here it got
372:01 - completed so for four times it got
372:03 - interrupted and it completed at the
372:05 - fifth que so this was an easy concept of
372:08 - multi-level Q
372:10 - scheduling at this moment or CPU
372:12 - scheding lecture is completely
372:14 - over
372:22 - congratulations hello welcome to the new
372:25 - section process synchronization and
372:27 - coordination this is lecture one we we
372:29 - going to learn about how process
372:31 - communicates interprocess communication
372:33 - and processing synchronization what is
372:36 - synchronization and what is its
372:38 - need so let me give you in introduction
372:41 - about the
372:42 - section this section is different from
372:44 - CPU scheduling that was numerically
372:47 - oriented and this section is logical and
372:50 - is reasoning oriented you have to focus
372:52 - while learning okay it is not hard but
372:56 - you need to focus okay it is logical so
373:01 - let's start what is IPC IPC is
373:03 - interprocess communication
373:05 - so let's talk generally there are two
373:09 - entities person one and person two let
373:11 - let's put it here person one with a
373:13 - mobile and person two with a mobile and
373:15 - they wish to communicate in this world
373:17 - when two entities wish to communicate
373:19 - there should be a shared media in
373:20 - between there should be a shared media
373:22 - and that shared media should be
373:24 - accessible to
373:26 - both it could be Hardware or software
373:29 - Hardware include wire cables wireless
373:31 - and software include protocols so my
373:33 - main point is if two entities wish to
373:36 - communicate there should be a shared
373:37 - media and that shared media should be
373:39 - accessible to both that I want to
373:40 - explain in the same way if two process
373:43 - wish to communicate there should be a
373:45 - shared media
373:46 - too it could be a
373:49 - file so a file in memory is known as
373:52 - pipe okay so what is pipe pipe is
373:54 - equivalent of file in hard
373:57 - disk so this shared media is known as
374:00 - IPC mechanism interprocess communication
374:02 - mechanism it could be a simple Global
374:04 - variable
374:06 - so what you have to remember if two
374:07 - process wish to communicate there should
374:09 - be a shared media there should be a
374:11 - shared media okay and this communication
374:14 - can be intra process too suppose in a
374:16 - process if two entities wish to
374:19 - communicate what what can be these two
374:21 - entities these two entity can be
374:22 - function so if these two entities wish
374:25 - to communicate there should be a common
374:26 - thing too there should be a shared thing
374:29 - too so let's uh let me recall you some
374:32 - of the C Concepts how can two functions
374:34 - in a program communicate by parameter
374:36 - passing and Global variables here you
374:38 - can also see shared thing okay so
374:43 - whatever I I have spoken till now you
374:46 - have to remember just a single line if
374:48 - two entities wish to communicate there
374:50 - should be a shared media that's it okay
374:53 - now let's talk about
374:55 - processes so the process are of two type
374:58 - independent and coordinating as the name
375:00 - suggest as the name suggest independent
375:03 - means no communication between the
375:05 - processes and coordinating means they
375:07 - cooperate they communicate okay
375:09 - communication happens so these are the
375:12 - type of processes okay now let's move to
375:15 - the main part that is synchronization
375:18 - what is
375:19 - synchronization you have heard about it
375:21 - so many times what is synchronization
375:23 - let me explain you in layman terms
375:25 - synchronization is nothing but doing
375:28 - something that is agreed or performing
375:31 - that is already decided that is
375:32 - synchronization okay
375:35 - so what problems arises due to the lack
375:39 - of synchronization let's discuss them
375:41 - one by
375:42 - one so in IPC environment lack of
375:45 - synchronization lead to the following
375:47 - problem the first one is
375:48 - inconsistency how inconsistency is
375:50 - generated we commonly call it as race
375:53 - problem to process race to update a
375:55 - common variable and they produce an
375:58 - unexpected result or they produce an
376:00 - incorrect result or wrong result that is
376:04 - inconsistency
376:05 - okay data loss as the name suggest and
376:09 - the third is deadlock what is deadlock
376:11 - or lock
376:12 - up deadlock is waiting for something
376:15 - that is never going to happen deadlock
376:17 - is waiting for something that is never
376:19 - ever going to happen we also call it as
376:22 - infinite blocking of the processes
376:24 - suppose uh the traffic got accumulated
376:27 - from all the four
376:29 - sides now this part of traffic expecting
376:33 - these three of them to back off
376:35 - and this part is expecting these three
376:37 - of them to back off so in this biger
376:39 - ring they all get stuck at the same
376:41 - place and none of them is ready to move
376:44 - back so this part this this situation is
376:47 - known as dead Lock they got logged up
376:50 - for infinite time and Deadlock is the
376:52 - most undesirable situation because
376:54 - processes not only get blocked but they
376:57 - also hold up the resources so that's why
377:01 - that's why we need synchronization
377:03 - synchronization is very much
377:06 - essential okay so let me explain you
377:10 - synchronization with the help of some
377:11 - examples so what is synchronization
377:15 - agreement or understanding between the
377:17 - entities let's take the example number
377:19 - one sharing a lawn among neighbors so
377:22 - these are the two neighbors H1 and H2 H1
377:26 - is the house owner of house one and H2
377:28 - is the house own of house to they have
377:30 - pets H1 has cat and H2 has a dog now
377:34 - there should be an agreement regarding
377:36 - the timing of lawn uses otherwise you
377:38 - know the consequences this could release
377:40 - cat and this could release the dog and
377:43 - you know what will happen so there
377:45 - should be a agreement regarding the
377:48 - timing so let's say they decide that the
377:51 - morning session will be for the cat and
377:52 - evening will be for the dog
377:54 - so this agreement is known as
377:57 - synchronization and and these two
377:59 - follows the agreement then they are in
378:00 - the
378:00 - syn okay let's discuss another problem
378:03 - more milk problem I hope you know what
378:06 - is PG paying guest so let's say in a
378:09 - hostel there are three paying guests P1
378:11 - P2 and P3 okay so they have an agreement
378:14 - what is agreement if any one of us
378:16 - notices that that there is no milk in
378:18 - the fridge he should go out and buy so
378:21 - this fellow came come to the fridge and
378:23 - he notices that there is no milk in the
378:25 - fridge he goes out when he was out
378:27 - another fellow comes he notices that
378:30 - there is no milk in the fridge he also
378:31 - goes out he also do the same thing so
378:35 - they all are out at the same time and
378:38 - they all of them bring milk for each
378:41 - other also so what will be the problem
378:45 - all of them notice one by one and goes
378:46 - out to buy milk so what will be the
378:48 - problem more milk problem so what is the
378:50 - solution solution will be past it note
378:53 - suppose he goes out he paste a note that
378:55 - I'm going out and when these two will
378:58 - come and see that there is no milk in
379:00 - the fridge but P1 has go P1 has gone out
379:03 - to buy some milk so they will stay and
379:05 - wait for him so this could lead to a
379:07 - solution so what I'm basically trying
379:10 - you to explain is what is
379:12 - synchronization let's understand it
379:13 - formally now so process synchronization
379:16 - refers to the coordination and control
379:19 - of the concurrent process why concurrent
379:21 - process because if the process are not
379:23 - concurrent suppose P1
379:25 - is uh performing its action at 8: a.m.
379:29 - let's let's just take an example and P2
379:31 - is performing its uh actions on
379:35 - let's say 12: p.m. so they are working
379:39 - on different times so they are not
379:40 - concurrent so what will be the need of
379:42 - synchronization synchronization is only
379:44 - needed when the process are working
379:47 - together control of the concurrent
379:48 - process in computer system so that they
379:50 - execute properly without interfering
379:53 - with each other it involves methods and
379:56 - mechanism to manage to access to manage
379:59 - access to the shared resources such as
380:01 - data device or in that example loan loan
380:04 - was the shared
380:06 - resource preventing conflicts ensuring
380:09 - orderly execution what is orderly
380:11 - execution so in the morning session cat
380:13 - will come and in evening section dog
380:15 - will come so that is the orderly
380:18 - execution so let's discuss again what is
380:20 - process synchronization agreed upon
380:22 - protocol in IPC environment V process
380:25 - work according to the agreed upon
380:26 - protocol that is synchronization to
380:29 - avoid inconsistency data loss and
380:32 - Deadlock Okay so
380:35 - P1 and P2 they are having some shared
380:37 - resources which is accessible to both
380:39 - and there exist an agreement protocol
380:41 - between them for synchronization let's
380:44 - let's take an
380:47 - example this is process one that is the
380:49 - track one and this is process two that
380:52 - is the track two now there exist a
380:54 - shared
380:55 - resource there exist a shared resource
380:58 - so there should be a protocol for the
381:00 - uses of this shared resource by both of
381:03 - the process otherwise
381:05 - the you know the consequences that could
381:07 - be catastrophic if both the trains come
381:09 - from here at the same time let's take
381:12 - another example suppose this is device
381:14 - one device two they both issues a
381:15 - command for printing the file at the
381:17 - same time so what will happen may result
381:19 - print of two different PDFs at the same
381:21 - page okay so these are the problem that
381:25 - could arise if the process lacks
381:28 - synchronization so what could be
381:30 - solution for this problem let's talk
381:32 - about generally what could be solution
381:34 - depending upon whether the printed is
381:36 - already printer is already begin used by
381:38 - another process or not the operating
381:40 - system must decide whether to Grant the
381:42 - printing request if the printer is free
381:45 - or to deny the request and classify the
381:46 - process as waiting process until the
381:48 - printers available becomes available so
381:51 - this gives the command this also gives
381:53 - the command so operating system will
381:54 - decide you wait I will first print the
381:58 - file of this computer and then I will
381:59 - come to you so this is a general
382:02 - solution okay I hope you all know
382:05 - now let's talk about the type of
382:07 - synchronization what are the two types
382:09 - of
382:10 - synchronization listen this
382:13 - synchronization thing only happens when
382:15 - the process communicates so in
382:17 - independent
382:18 - process there is no need of
382:20 - synchronization synchronization is only
382:22 - needed in coordinating process when
382:24 - communication happens so there are two
382:26 - type of synchronization competitive and
382:30 - and the second one is
382:32 - cooperative so as the name suggest what
382:35 - is competitive process compete for the
382:38 - accessibility of a shared resource
382:40 - process compete and what is cooperative
382:43 - execution of one process affects the
382:45 - another that is dependency so I hope you
382:48 - are craving for an example of both weit
382:51 - for Cooperative process there is a
382:52 - famous example that is producer consumer
382:54 - problem I hope you have heard it before
382:56 - if you have read operating system
382:58 - already this is a very famous problem
383:00 - and we are going to look for its
383:02 - solution in many different ways
383:05 - let's first talk about the
383:07 - competitive
383:09 - synchronization for the Amazon sale
383:12 - there's an single iPhone piece available
383:15 - that is that is available at at a great
383:18 - discount so all of three buy to wants to
383:21 - buy an iPhone for a single piece of
383:23 - iPhone listed on Amazon at the same time
383:25 - so these three are competiting these are
383:28 - these are in competition for this iPhone
383:30 - so this is an example of competition
383:33 - let's take another example in terms of
383:35 - process so this is P1 and this is
383:38 - P2 and this is a shared variable that is
383:41 - variable C so P1 wants to increment the
383:45 - value of C that's C = to C + 1 and P2
383:48 - wants to decrement the value of C that
383:50 - is C minus minus so what will be the
383:53 - expected result so the expected result
383:55 - will be uh first P1 increments that is 5
383:58 - + 1 6 and P2 decrements that is five so
384:01 - the expected result is five but there
384:04 - are some cases when we get the result
384:07 - either six or
384:10 - four this could also possible that we
384:13 - can get result either six or
384:15 - four so this is the example of
384:18 - competitive synchronization example four
384:21 - people trying to book a single seat in a
384:23 - train that is example of competitive
384:25 - synchronization
384:29 - okay let's understand the producer
384:32 - consumer problem so there is a producer
384:35 - which produce an item and there is a
384:37 - consumer which consumes an item what
384:39 - item a data item okay so what does
384:42 - producer do producer attempts to place
384:44 - the data item onto buffer and consumer
384:47 - attempts to consume the data item from
384:48 - buffer so what does producer do it it
384:50 - produces and what does Consumer do it
384:52 - consumes but there is a catch they
384:55 - attempts why attempts because the buffer
384:58 - is bounded so if the buffer is full then
385:02 - producer cannot place the item into to
385:04 - the buffer and if the buffer is empty
385:07 - consumer cannot consume that's why I
385:09 - used the word attempts okay so let's say
385:13 - producer produces X and then producer
385:15 - produces y now producer want to produce
385:17 - Zed what is what is this this is a
385:20 - variable which has a data type of
385:22 - integer and what does it what does it
385:24 - store it stores the value of next empty
385:27 - slot firstly when these two were there
385:30 - the next empty slot was two and when
385:33 - producer produces this data item Z then
385:36 - the next empty slot becomes three so
385:38 - this will update the value three these
385:40 - are the slots I hope you know so this is
385:43 - the producer consumer problem so what
385:46 - will the what will be the condition if
385:48 - the buffer is full producer cannot
385:50 - produce and if the B is empty consumer
385:52 - cannot
385:54 - consume so this is an example of
385:58 - cooperating processes P1 that is process
386:03 - producer process and consumer process
386:05 - they are
386:06 - cooperating because the actions of one
386:09 - affects the actions of the other that's
386:12 - why they are in the cooperation and this
386:14 - example which we have seen that three
386:15 - people are trying to buy a single piece
386:17 - of iPhone present in the Amazon sale or
386:20 - two process want to update the value of
386:22 - of a shared variable at the same time or
386:24 - four people trying to book a single seat
386:26 - in a train that is example of
386:28 - competitive synchronization and this is
386:31 - an example of Cooperative
386:32 - synchronization when actions of the
386:34 - world affect the actions of the
386:36 - other okay so if the synchronization is
386:40 - competitive then what does the lack of
386:43 - synchronization causes is it causes
386:45 - inconsistency and data loss in case of
386:47 - Cooperative it causes data lock so can
386:50 - data lock arise in in this producer and
386:53 - consumer problem we will see later okay
386:56 - and there there is another note what
386:58 - does it say an application in IPC
387:00 - environment may involve either
387:02 - cooperation competition or both so later
387:06 - we will see that producer consumer
387:08 - problem is an example of both
387:10 - competitive and and Co Cooperative how
387:14 - competitive we'll see it later when
387:15 - we'll see the code the C code okay so
387:19 - what we have learned in this whole
387:20 - lecture we have learned that for
387:23 - communication there need a shared
387:25 - resource and that shared resource should
387:27 - be accessible to the both entities okay
387:30 - and process are of two type independent
387:32 - and coordinating independent process
387:34 - do not communicate hence they do not
387:36 - require synchronization coordinating
387:39 - process communicates hence they require
387:40 - synchronization and what does the lack
387:42 - of synchronization causes inconsistency
387:45 - that is wrong results data loss and
387:47 - Deadlock we learned a new term that is
387:48 - deadlock what is deadlock waiting for an
387:51 - event that is never going to
387:52 - happen we have seen some examples that
387:55 - is sharing a laan m Mill problem and we
387:58 - have also learned a formal definition of
388:00 - process
388:01 - synchronization okay and then in the end
388:03 - we learn learned what is competitive and
388:05 - Cooperative synchronization we have seen
388:06 - some examples and we also learned that
388:09 - application in an IPC can involve either
388:12 - cooperation or competition or
388:15 - both let's start lecture two in this
388:18 - lecture we will see a famous condition
388:21 - known as race condition in the last
388:23 - lecture we have studed about
388:25 - synchronization what is the need of
388:27 - synchronization how process communicate
388:29 - we learned about IPC its mechanism
388:31 - shared media and stuff in this lecture
388:33 - we'll start with the race
388:35 - condition so there are two process P1
388:38 - and P2 and they are in a race they are
388:41 - in a competition to update the value of
388:45 - a shared variable let's say C P1 wants
388:48 - to increment it and P2 wants to
388:50 - decrement it so what will be the high
388:53 - level code it could be Cal to C + 1 and
388:56 - the low level and the high level code
388:58 - for decrement will be Cal to cus1 and
389:01 - what will be the low LEL code
389:02 - corresponding to them the low level will
389:04 - be
389:05 - this so this will the low level will be
389:07 - generated by compiler that is the
389:09 - assembly code so the three instructions
389:11 - are there and they will be executed
389:14 - sequentially so what we will do we'll
389:16 - first load the value of C into register
389:18 - R1 we'll increment the value of register
389:20 - R1 and we will store the value of R1
389:22 - back to C so this is
389:24 - how it will be executed at low level
389:28 - similarly for
389:30 - decrement the value of C that is the
389:32 - memory will be loaded into register R2
389:35 - it will be decremented and the
389:36 - decremented value will be stored back to
389:38 - the memory so C is a
389:42 - memory
389:45 - okay this part till this part whatever
389:48 - computation is being done it is being
389:50 - done in the register at part I3 it
389:53 - changes the value at memory remember
389:56 - this till this part whatever being done
389:59 - whatever competition is being
390:02 - done is done at register level the final
390:06 - value of register is not stored until
390:08 - instruction three at instruction 3 the
390:11 - value of C is changed okay so now how we
390:16 - can get the result 6 or four when the
390:19 - expected result is five this is
390:21 - inconsistency so how inconsistency
390:23 - happen let's see suppose consider this
390:27 - scenario in RQ there are two process
390:29 - available P1 and P2 at time
390:32 - t CPU scheder decide let's schedule P1
390:36 - first so P1 will be scheduled now before
390:39 - going ahead I want to share a universal
390:42 - assumption that in user
390:47 - process they can get preempted after any
390:50 - instruction this user process can be
390:52 - preempted even before executing
390:54 - instruction one it could be preempted
390:56 - after execut instruction one before I2
391:00 - it could be preempted here it could be
391:01 - preempted here any anywhere it could be
391:03 - preempted anywhere here so user process
391:06 - can be preempted anytime anywhere after
391:08 - any instruction you have to take into
391:11 - account this
391:13 - assumption so P1 ver first scheduled
391:16 - what
391:17 - happens P1 executes instruction i1 and
391:21 - I2 what will P1 do P1 loads the value of
391:25 - register of memory P1 loads the value
391:27 - from memory into register that is value
391:29 - five and it will increment it so the
391:32 - value of R1 is 5 instruction
391:34 - I2 okay let's go back so what it will do
391:38 - it will first load the value of C into
391:40 - R1 and it's incremented so what will the
391:42 - value of R1 now the value of R1 is six
391:47 - okay this part is represented like this
391:49 - i1 and I2 that is the R1 is now have
391:53 - value six at this point it got preempted
391:56 - it it got preempted at this point I have
391:57 - said user process can be preempted at
391:59 - any time so user process gets preempted
392:02 - here so P1 gets preempted here so P
392:05 - represents preempted now it's time for
392:08 - P2 because CPU can't be added so P2 will
392:11 - be brought from ricq to the CPU and P1
392:15 - which was which was previously in the
392:17 - CPU will be sent back to the ricq
392:19 - because it has its instruction remaining
392:21 - to be executed so at time T1 let's say
392:24 - at another time P2 will start executing
392:28 - its instructions so P2 will execute i1
392:30 - I2 and I3 so it has executed all of
392:33 - three so let's go back so what it will
392:36 - do it will first load the value of C
392:38 - into R2 it has decremented the value and
392:41 - it has again loaded the value of C of R2
392:44 - into C that is it has made the final
392:47 - changes it has made the final changes
392:49 - because it has also executed its
392:51 - instruction three it has first loaded
392:53 - the
392:54 - value it has first loaded the value into
392:56 - R2 the value of C was five so five has
393:00 - loaded it has decremented the value now
393:02 - the value of al2 is four and and it has
393:04 - loaded the value of R2 back into the C
393:06 - so it has stored the value of R2 into C
393:10 - see the instruction I3 okay so the third
393:13 - instruction is the instruction in which
393:15 - final changes has been made this was
393:17 - remaining okay now P2 has completed all
393:22 - its instructions so it will leave the
393:24 - CPU it's turned for P1 to come back so
393:26 - now P1 will come back and I have I have
393:29 - told you several times that when a
393:31 - process comes back from ricu to the CPU
393:34 - it will resume it will not restart so it
393:37 - will resume from instruction I3 where it
393:39 - got preempted so what is instruction I3
393:42 - making the final changes again what is
393:45 - instruction I3 is storing the value of
393:47 - R1 what is the value of R1 the value of
393:49 - R1 was six so it will store the value of
393:53 - R1 that is 6 back into
393:56 - C now what is the final value the final
394:00 - value is six and what was the expected
394:03 - value the expected value should be five
394:05 - because P1 increments and P2 decrements
394:07 - so the result should be unchanged so it
394:09 - should be five but what we got we got
394:12 - six this is inconsistency this is race
394:16 - condition P1 and P2 are not in
394:18 - synchronization so this type of problem
394:20 - are caused now we have got value six but
394:24 - can we got value four yes the thing is
394:28 - opposite there are two ways to get four
394:30 - so the first is do the same same thing
394:33 - in opposite fashion start with the P2
394:35 - first preempt here complete the
394:38 - instruction of P1 and when P2 comes
394:41 - back make the final changes again store
394:43 - the value of R2 into the C that was four
394:45 - okay another way
394:47 - is another way is at time T1 so this was
394:50 - the time at time T P1 executed
394:53 - instruction i1 and I2 and it got
394:54 - preempted so the first case this this
394:57 - and that preempted now what is the what
395:00 - is the scenario R1 has the value of six
395:03 - the value of C is still five because no
395:05 - final changes has been made because it
395:07 - got preempted before final changes now
395:09 - what happens at time T1 P2 also gets
395:12 - preempted here P2 executes these two
395:15 - instruction and get preempted now in Ru
395:18 - there are two process now in readyq
395:20 - there are two process P1 and P2 ready to
395:23 - make the final changes now it depends
395:26 - now it depends if P1 make the changes
395:28 - first let's say P1 make the changes
395:31 - first and then P2 make the changes that
395:32 - is four so the final fin changes the
395:34 - final answer will be
395:36 - four case two P2 make the changes first
395:40 - the value of C will be four and now P1
395:42 - comes so it will change back to six so
395:45 - the value of C can be either six or can
395:48 - be either four depending which process
395:51 - updates or make the final changes first
395:54 - so what was expected the expected value
395:57 - was what was expected the expected value
396:00 - was five but what we got we got either
396:02 - six or four depending which process
396:04 - updates first so this is raise condition
396:08 - I so this is an important point I should
396:10 - I felt that I should write it in the
396:12 - notes whenever a process comes back to
396:14 - the CPU it will resume not
396:16 - restart so this above scenario is a
396:19 - clear demonstration of
396:21 - inconsistency the process to update last
396:23 - will win then what is the
396:26 - solution is it ever possible to get a
396:29 - correct value is it possible if yes then
396:31 - in which scenario
396:35 - the answer is when there is no
396:37 - preemption when there is no preemption
396:40 - what P1 does P1 executes all these three
396:43 - instruction and then when it gets
396:46 - completed it leaves the
396:48 - CPU and then P2 comes it executes all
396:51 - these three instructions so what happens
396:53 - let's
396:54 - see P1 executes all these three
396:56 - instructions so what happens this is the
396:58 - value of R1 this is the value of C that
397:01 - is five first load the value of
397:04 - C into R1 so value of C will be loaded
397:07 - into R1 c will be loaded into R1 that is
397:11 - 5 now what happens increment R1 let's
397:14 - increment R1 let's make it six now store
397:17 - the value of R1 back into the C store
397:19 - the value of R1 back into the C now the
397:21 - value will be six now the value of C
397:23 - will be
397:26 - six okay P1 has executed all its
397:30 - instruction now it's chance for P2 to
397:32 - execute P2 will come load the value of
397:35 - R2 into C sorry load the value of C into
397:38 - R2 the one which is written later that
397:41 - value will be loaded into the thing
397:43 - which is written before see if we have
397:45 - to store we will write R2 later if we
397:48 - have to load we will write R2 first okay
397:51 - so value of C will be loaded into R2 so
397:53 - what is the value of C 6 6 will be
397:55 - loaded into R2 what are decrement R2 so
397:59 - five will be the value store the value
398:01 - of R2 back into C so now the value will
398:04 - be five finally the value is five so
398:07 - this is the expected value this is the
398:09 - correct
398:10 - result when we got correct result when
398:13 - there is no preemption when we executed
398:15 - either P1 first and then P2 or either P2
398:19 - first and then P1 in both cases we will
398:21 - get correct result
398:23 - but if any of the process get preempted
398:25 - in between then it causes
398:29 - inconsistency so here I have written so
398:32 - when there is no preemption then we will
398:34 - get correct result but as an end user
398:36 - see as an end user we want a solution
398:39 - that always give me correct result why I
398:41 - should bother let's say let's say there
398:43 - is a there's a children 5-year-old
398:46 - children wants to play a game in a in a
398:49 - smartphone but it has got some problem
398:52 - problem because of risk condition why
398:54 - should the end user a 5-year-old give
398:56 -  about whether a process gets
398:58 - preempted or not he wants a correct
399:01 - solution every time he wants a correct
399:03 - result every time whether preemption
399:04 - takes place or not I do not I do not
399:07 - bother whether preemption happens or not
399:08 - as an end user I want correct
399:13 - solution let's start with the
399:14 - implementation of producer consumer
399:16 - problem there are two processes a
399:18 - producer process and a consumer process
399:20 - producer process produces an item and
399:23 - place the item into through the bounded
399:24 - buffer why bounded bounded means a fixed
399:28 - size so the size will be n and the index
399:32 - will be from 0 to n minus one I hope
399:34 - this is clear
399:36 - so process P that is the producer
399:39 - process is going to produce an item and
399:41 - place it onto the bounded buffer and
399:43 - what will consumer do it is going to
399:45 - consume an item from the bounded buffer
399:48 - producer produces consumer consumes as
399:51 - simple now now there are two pointers
399:54 - pointer in and pointer out pointer in
399:57 - refers to the pointer of next empty slot
400:00 - what is the next empty slot here
400:03 - two and out refers to the first filled
400:07 - slot what is the first filled slot you
400:09 - can see Zero that is X now producer
400:14 - produces and place it onto the
400:18 - buffer
400:20 - in I hope I'm making sense because this
400:23 - is the next empty slot producer will see
400:26 - the next empty slot and will place an
400:27 - item onto the bounded buffer what from
400:30 - where the consumer consumes it consumes
400:32 - the from buffer out what is out the
400:36 - first filled
400:39 - slot now let's move to the code part we
400:42 - are defining a global variable n what is
400:44 - n the size of the bounded buffer let's
400:46 - say it is 100 now we are also defining a
400:49 - variable named count it is also a global
400:51 - variable count what does count refer to
400:54 - it refers to the number of data items in
400:56 - the
400:56 - buffer if a producer produce and place
401:00 - the data item in the buffer the count
401:01 - will increase and if a consumer will
401:02 - consume then the count will decrease we
401:05 - are also defining a bounded buffer of
401:07 - size n so it's an array of integer type
401:10 - buffer n now we are going to write the
401:13 - producer and the consumer code so what
401:16 - are the major changes that we are going
401:18 - to make when a producer produce and when
401:21 - a consumer consumes let's discuss them
401:25 - so we are first going to check a
401:27 - producer produce only when the bounded
401:29 - buffer is not full and a consumer
401:32 - consume only when the bounded buffer is
401:34 - not empty okay
401:37 - so what will producer do first it will
401:41 - produce and place the item in a variable
401:43 - named item P let's say the produced item
401:45 - item P let me write item P so the
401:49 - producer produced and placed the item in
401:51 - this variable item P now we have to
401:54 - place the item p in the buffer where we
401:57 - will place we will place at
401:59 - buffer in
402:03 - so we'll play place it as buffer in okay
402:07 - but these all will only happen when the
402:10 - bounded buffer is speak after me bounded
402:14 - buffer
402:15 - is not full so if the bounded buffer is
402:18 - full what we have to do we have to make
402:20 - the producer busy weight until the
402:22 - consumer consumes and make a space for
402:26 - the item to be placed into the bounded
402:28 - buffer okay
402:31 - so when the item will be placed in the
402:33 - buffer in then we have to increase the
402:35 - value of count two so we will do count
402:37 - Plus+ also so let's see in the code so
402:40 - what we will do we will produce and
402:43 - place the item into the variable named
402:44 - item P so what will produce item do
402:46 - let's say the produce item is a function
402:48 - in a library already present produced
402:51 - item is placed in the variable item P
402:53 - okay now we will check we will check
402:56 - whether the bounded buffer is full or
402:57 - not so we will use while count equals to
403:01 - equals to n we will check whether count
403:03 - count equals to equals to n whether
403:04 - count is equals to n or I can directly
403:07 - say if the bounded buff is full then the
403:09 - producer cannot produce and place the
403:11 - atom it it may
403:12 - produce the producer May produce but it
403:15 - cannot place so it may produce but it
403:19 - cannot place so it has to first check
403:21 - whether the bounded buffer is full or
403:23 - not if full then it will wait until
403:26 - preemption happens and consumer takes
403:29 - the control and it consumes an item and
403:31 - makees space for the producer to place
403:33 - the item so producer May produce but it
403:36 - cannot place before checking so we'll
403:38 - first check we'll first check so the
403:40 - busy waiting thing will happen what is
403:42 - busy waiting busy waiting is testing the
403:44 - condition again and again and what is
403:46 - waiting for what it is waiting for to
403:48 - proceed
403:49 - further okay
403:52 - so let me speak again producer will
403:56 - produce and place the item into the
403:57 - variable item P now it is in the
404:00 - variable item P it is not in the buffer
404:02 - so before place before placing into the
404:04 - buffer we have to first check so we
404:06 - checked and it is not full it has some
404:09 - space available it will go down buffer
404:12 - in equals to item P we will place the
404:14 - item P what is item P item p is
404:16 - containing the produced item so we will
404:18 - place the item P into the in what is in
404:23 - the next empty slot so we plac item P
404:25 - into the buffer in now we have to
404:28 - increase the value of n because now the
404:31 - next empty slot will be the next one
404:34 - let's let's take this case what is the
404:35 - next empty slot two if the producer
404:38 - Place item let's say Z Now the next
404:39 - empty slot will be three so we have to
404:41 - increase the value of in also what does
404:43 - this circular thing say let's say the
404:46 - last here it is produced so it will go
404:49 - back and produce that and place the item
404:51 - at index 0o if the last item was at n
404:54 - minus one it will go back and place the
404:56 - item at zero I hope this point is clear
404:58 - this thing is for the circular and count
405:00 - Plus+ because item is placed into the
405:02 - buffer so the number of item will be
405:04 - increased so this was the code for
405:05 - producer item so for the producer now I
405:09 - am giving you a challenge to write the
405:10 - code for the consumer what changes you
405:13 - have to think about it so for
405:15 - Consumer the consumer consumes when the
405:18 - consumer can consume it can consume only
405:20 - when it can consume only when there
405:24 - exists some item into the buffer when
405:25 - the buffer is
405:27 - nonempty okay let's say the buffer is
405:30 - non empty what changes you have to make
405:32 - you have to make you have to decrease
405:33 - the value of count because the consumer
405:36 - has consumed an item you have to
405:38 - increase the value of out because what
405:42 - does out signify first filled slot let's
405:44 - say consumer had consumed this now the
405:46 - first filled slot is this one that is
405:48 - one so we have to increase the value of
405:49 - out two same same case for the last
405:52 - thing suppose consumer consume from this
405:55 - part now from where the next time
405:57 - consumer will consume from this so it
405:58 - has to go back so for circular thing
406:00 - will be out equals to out + 1
406:05 - modul n okay so let's see the consumer
406:08 - code vo consumer void now item C item c
406:11 - will be the item C represents the
406:14 - consumed item the item which is going to
406:16 - be consumed
406:17 - so before anything before making changes
406:21 - before any change making we have to
406:24 - check whether
406:26 - the whether the bounded buffer is empty
406:28 - or not if the bounded buffer is empty
406:30 - busy wait until the producer produce and
406:32 - place an item into the buffer
406:34 - then item c will be representing the
406:37 - item that is going to be consumed so
406:39 - which item is going to be consumed
406:40 - buffer out now we have to increase the
406:42 - value of out decrease the value of count
406:44 - and consume the item in the end see see
406:47 - there is a thing in consumer the
406:51 - condition was at the top while in
406:53 - producer the condition was at the second
406:55 - statement at B why why this is so
406:59 - because a producer can produce
407:03 - but it cannot place so this represent a
407:06 - producer can produce but it cannot place
407:09 - before placing it has to check the
407:10 - condition no statement can be made
407:12 - before checking if the bounded buffer is
407:16 - empty none of these changes will be
407:19 - made I hope I am clear so this was the
407:22 - all the implementation of producer and
407:25 - consumer in C
407:26 - language in the last lecture we
407:28 - discussed about the producer and
407:30 - consumer problem implementation
407:33 - so we are going to see some more points
407:34 - on that so the producer and consumer
407:36 - problem are involved in Cooperative
407:39 - synchronization why because they are
407:41 - getting affected by each other now this
407:43 - this point you all know but there is
407:45 - some special point that this case of
407:48 - producer and consumer problem is
407:50 - involved in both competitive and
407:52 - Cooperative
407:53 - synchronization how competitive uh let
407:56 - me tell you see if you carefully watch
407:59 - the uh if you carefully observe the code
408:02 - then
408:04 - you can see there is a shared variable
408:07 - count there's a shared variable count so
408:10 - let's say this is the producer code this
408:12 - is the consumer code the producer
408:14 - executes these four instruction and get
408:16 - preempted here and the consumer execute
408:18 - these three instruction get preempted
408:20 - here just before updating the value of
408:21 - count because they are user process and
408:23 - user process can be preempted anywhere
408:25 - at any time so they got preed here there
408:29 - this part and this part they get preed
408:31 - just before updating the value of
408:33 - now this is the
408:36 - situation producer and consumer process
408:38 - are in the ricq waiting to update the
408:41 - value of count okay so this situation
408:43 - this situation if you recall is exactly
408:46 - similar to our previous problem that
408:47 - causes inconsistency what was the
408:49 - previous problem the race
408:54 - condition so these producer and consumer
408:57 - are in a race to update the value of
408:59 - Shield variable
409:00 - count okay so let let me recall you
409:04 - there are two process producer and
409:05 - consumer producer want to increase the
409:07 - value of count consumer want to decrease
409:09 - the value of count let's say the initial
409:10 - value of count is five now the expected
409:13 - expected results are six and uh expected
409:16 - result is five but what we can get we
409:18 - can get six and four depending on which
409:20 - process updates the value of count at
409:23 - last the one which update first loses
409:25 - and the one which updated to the last
409:27 - that value of count will be the final
409:29 - value of count so this I have already
409:33 - discussed before in our previous lecture
409:36 - what point I'm here to make that
409:38 - producer and consumer is a case in which
409:41 - a process or the processes are involved
409:44 - in a cooperative and competitive
409:45 - synchronization
409:48 - both okay I hope the point is clear so
409:51 - to solve this problem we are going to
409:53 - need a synchronization tool a
409:56 - synchronization tool so that
409:58 - synchronization tool we are going to see
409:59 - in the next lecture
410:07 - in the previous lecture we saw that we
410:09 - need a synchronization tool to avoid
410:11 - some problems in this lecture we are
410:13 - going to explore
410:15 - more suppose uh let's talk about a
410:18 - disease named malaria I hope you have
410:19 - heard about it so what is the necessary
410:23 - condition for malaria to spread in a Lo
410:25 - in a locality so the necessary condition
410:28 - is stagnant water if a stagnant water is
410:31 - not present so mosquito larva won't
410:33 - breed there and mosquitoes won't be
410:35 - there so the main culprit that is the
410:37 - mosquito would not be present in that
410:39 - locality so chances of malaria spreading
410:41 - is very less so stagnant water
410:44 - mosquitoes the main culprit should be
410:45 - there and unhygienic environment so
410:48 - these are the necessary condition for
410:49 - malaria to spread in a
410:53 - locality let's talk about the
410:54 - synchronization problem so this was a
410:56 - problem these are the necessary
410:58 - condition this is the problem let's talk
411:00 - about the synchronization problems
411:02 - necessary condition condition so the
411:03 - first condition is critical section
411:05 - there should be a shared
411:06 - resource if there is no shared resource
411:09 - there won't be any synchronization
411:10 - problem we have discussed it earlier
411:12 - also okay so what is critical section
411:15 - the part of a program where shared
411:17 - resources are accessed the part of a
411:19 - program where shared resources are
411:21 - accessed okay so let's say this is a
411:23 - program it consists of two things
411:25 - non-critical section and critical
411:28 - section noncritical section consist of
411:30 - local variables which belong to that
411:32 - process only and critical section
411:35 - consist of those variables which belongs
411:37 - to both the processes let's say two
411:38 - process are there want to communicate so
411:41 - critical section is the section which
411:43 - has shared variable let's talk here uh
411:45 - in the case of producer consumer problem
411:47 - let's say item P equals to produce item
411:49 - this is a noncritical section because
411:52 - item P or produce item this belongs only
411:55 - to the producer
411:56 - process while this count this n this
412:01 - buffer this count again this and this
412:04 - belongs to both the processes producer
412:05 - and
412:06 - consumer they can be they are accessible
412:09 - to both the process so this is the
412:11 - critical section see remember the first
412:14 - class of Process Management I have said
412:17 - that not Process Management process
412:19 - synchronization I have said that for
412:21 - communication to happen between two
412:23 - entities there should be a shared media
412:25 - and that shared media should be
412:26 - accessible to both that's the same
412:29 - thing okay so that shared media is known
412:32 - as critical section so for
412:35 - synchronization problem there must
412:37 - present a critical section and the
412:39 - second condition is raise condition say
412:42 - if the processes are not in rise to
412:45 - update a update a shared variable let's
412:48 - say count if producer and consumer are
412:50 - not in Risk to update the value of count
412:51 - then there will be no problem for
412:53 - synchronization problem to occur what
412:55 - are the necessary condition the first is
412:58 - that there should be some shared
412:59 - variable there should be critical
413:01 - section and the second is for that
413:03 - shared variable processes should be in
413:05 - race to update the value okay so the
413:08 - race condition is necessary situation
413:09 - where the process are trying to access
413:11 - critical section and final result
413:13 - depends on the order they finish their
413:15 - update now here like malaria for the
413:18 - case of malaria stagnant water and
413:20 - unhygienic environment is similar as
413:22 - critical section and race condition but
413:24 - the main culprate is still missing can
413:26 - you guess the name of main culprit
413:30 - think yes the the main culprit is
413:33 - preemption which type of preemption
413:36 - premature
413:38 - preemption let let's let's see the
413:40 - situation so here are the critical
413:42 - section P1 enters the critical section
413:44 - P1 was still executing the instructions
413:48 - of the critical section but it got
413:50 - preempted
413:52 - prematurely now P2 wants to enter
413:55 - critical section P2 will enter and that
413:57 - causes problem so the premature
414:01 - preemption when a process has not
414:03 - completed the all this all its
414:06 - instructions in the critical section but
414:07 - it got preempted prematurely and some
414:10 - another process enters critical section
414:12 - that causes problem so what is the main
414:14 - culprit here preemption and which type
414:16 - of preemption premature
414:18 - preemption okay so we need some solution
414:22 - uh to solve all these problems so the
414:23 - solution is we need some synchronization
414:26 - mechanism or let's say security
414:29 - guard so can you guess the purpose of
414:32 - the security
414:35 - guard see the problem arise when two or
414:38 - more process enters critical section
414:40 - when two or more process are in the
414:42 - critical section see critical section
414:44 - and CPU are different things let's say
414:46 - here is the
414:48 - CPU these process are present in the
414:50 - ricu okay now P1 is in the CPU now P1 is
414:55 - in the CPU P1 started executing its
414:58 - instruction the critical section let's
414:59 - in between it got
415:01 - preempted P1 is still in the critical
415:04 - section this is the uh denot we denote
415:07 - it like that that P1 has not completed
415:10 - all its instruction from the critical
415:11 - section P1 got removed from the CPU it
415:15 - went back to the RQ now P2 enters P2
415:18 - enters okay so P2 is in the CPU started
415:22 - executing instructions want to enter the
415:25 - critical section but P1 has its
415:28 - unfinished work in the critical section
415:30 - so it's still lying there not executing
415:33 - any instructions further because it is
415:36 - not present in the CPU P2 is there so
415:38 - it's still lying there now the problem
415:40 - arise when P2 enters critical section
415:43 - 2 so this is the problem so we need to
415:46 - solve this problem using a security
415:49 - guard so can you guess the purpose of
415:51 - security
415:52 - guard yes you guessed
415:55 - correctly security guard will allow only
415:58 - one process enter at a time in the
416:00 - critical section let's say P1 get
416:02 - preempted in between let's say p P2 has
416:05 - P2 is in the CPU now security guard will
416:09 - prevent P2 entering the critical section
416:12 - P2 cannot enter critical section
416:14 - security guard will prevent it
416:17 - okay let's say P2 got preed again and P1
416:20 - get the chance P1 is present in the CPU
416:22 - now P1 resumed its instruction completed
416:26 - critical section get over got terminated
416:29 - now when P2 comes it is allowed to enter
416:32 - critic iCal
416:33 - section okay so this is the purpose of
416:35 - security guard not only this not only
416:38 - this security guard also notifies other
416:41 - processes when a process or the
416:43 - previously running process in the
416:45 - critical section has completed its
416:47 - instructions let's say P1 has completed
416:50 - its instruction so the security guard
416:51 - will notify other processes hey critical
416:54 - section is empty now you can go any one
416:58 - of you can go okay so there are two
417:01 - purposes of security first is and we
417:04 - have divided security guard in two entry
417:07 - section and exit section entry section
417:09 - will allow out of these three process
417:11 - only one to enter critical section and
417:14 - exit section what's the purpose of exit
417:16 - section it will notifies other process
417:19 - that the previously running process in
417:21 - the critical section has completed its
417:23 - instruction now any one of you can go
417:25 - now in the critical
417:27 - section I hope I'm clear uh let's see
417:30 - again here so P1 p P3 want to enter
417:33 - critical section so there comes the
417:35 - enter section first which allows only
417:37 - one process to access critical section
417:40 - let's say P1 entered P1 completed its
417:42 - instruction went to the exit section
417:45 - this exit section notifies other process
417:47 - P2 and P3 that critical section is empty
417:50 - now okay so when process exits the
417:53 - critical section it notifies the other
417:56 - processes so how this synchronization
417:58 - mechanism looks like first comes the
418:01 - non-critical section or the section
418:03 - which does not have any shared
418:05 - resource for critical section that is
418:08 - this is critical so we need some
418:10 - security guard up and Below enter
418:14 - section and exit section then again
418:15 - comes the non-critical section so this
418:17 - is the this is the synchronization
418:20 - mechanism okay note what is the note
418:22 - process running in user mode can get
418:25 - preempted anywhere any number of times
418:27 - after completing any instruction so this
418:29 - is a kind of assumption we will take to
418:31 - solve synchronization problem what is
418:33 - the Assumption process running in user
418:35 - mode can get preempted anywhere after
418:39 - any instructions any number of times
418:41 - okay you have to remember this in the
418:44 - next lecture we will see the
418:45 - requirements of critical section problem
418:49 - here we have seen the necessary
418:50 - condition so what is the difference
418:52 - between necessary condition and
418:53 - requirements so necessary conditions are
418:55 - the conditions which are necessary for
418:58 - problem to happen like mosquitoes are
418:59 - necessary for malaria to spread and what
419:02 - are the requirement these are the
419:04 - requirement to be fulfilled to make sure
419:06 - the solution is
419:08 - correct okay so we will discuss them in
419:10 - the next lecture let's discuss the
419:13 - requirements of critical section problem
419:15 - these are the conditions that must be
419:17 - satisfied by synchronization mechanism
419:20 - to make sure the solution is correct and
419:22 - what was necessary condition these are
419:24 - the condition necessary to
419:26 - happen necessary for problem to happen
419:29 - Okay so let's discuss the requirements
419:31 - the first is Mutual exclusion what does
419:34 - this say that there should be only a
419:36 - single process in the critical section
419:38 - at a time no two process should be
419:40 - present in the critical section at the
419:42 - same time remember this line in any
419:45 - synchronization mechanism we discuss the
419:47 - first thing which we are going to check
419:48 - is this line is there any possibility
419:51 - that two process enter critical section
419:53 - at the same time if yes then the mutual
419:56 - exclusion is not
419:58 - guaranteed so what is mutual exclusion
420:01 - no to process should be present in
420:03 - critical section at the same time as
420:04 - this diagram depicts so a process is
420:07 - already present in the critical section
420:09 - uh another process enter this is
420:12 - wrong more processor enter this is
420:16 - wrong in this critical section only
420:18 - single process there and these all
420:20 - processes are out so this is good thing
420:23 - okay so only one rest are out so mutual
420:26 - exclusion is guaranteed so repeat after
420:29 - me what is mutual
420:30 - exclusion no go to process should be in
420:33 - the critical section at the same time
420:36 - okay let's discuss the second condition
420:39 - that is
420:41 - progress okay so what does progress mean
420:45 - that a process let's say P1 P2 and P3
420:49 - these are the process P1 is not
420:52 - interested to enter critical section so
420:54 - it should not block the interested
420:57 - processes like P2 and P3 let me speak
421:00 - again non-interested process process or
421:02 - uninterested process should not block
421:04 - the entry of interested process this is
421:07 - the progress okay so P1 and P2 these two
421:12 - want to enter P3 is not interested so P3
421:15 - has no right to block the progress of
421:18 - others uninterested process should not
421:21 - block the entry of interested process
421:23 - this is progress okay now the third part
421:26 - bounded waiting listen
421:29 - carefully P1 P2 P3 these are the three
421:33 - process wants to enter critical section
421:36 - P1 first uh goes to entry section
421:40 - allowed because no other process is
421:41 - present in the critical section vents to
421:43 - critical section comes out now it goes
421:48 - again it goes again joins the queue goes
421:51 - again enter enter the entry section goes
421:54 - to critical section again goes to exit
421:56 - section now this fellow joins again see
422:00 - P1 is laughing at the face of P2 and P3
422:03 - that you fellows are waiting from so
422:04 - much time and whenever I come back I
422:06 - directly go to the critical section so
422:08 - you keep on waiting I will keep on going
422:10 - into the critical section P1 will laugh
422:12 - at the face of P2 and P3 so this is not
422:15 - correct P2 and P3 do not know for how
422:18 - much time they have to
422:20 - wait okay so this should not happen this
422:23 - should not happen this is not fair so
422:26 - this is the thing which I have
422:27 - represented P1 enters goes to critical
422:30 - section exits joins the que again enters
422:33 - again goes to critical section exits
422:36 - goes again enter this keep on happening
422:39 - and P2 and P3 are waiting so this these
422:43 - these two process P2 and P3 should not
422:45 - wait forever for their turn Okay so this
422:47 - is bounded
422:49 - waiting okay so let me erase all these
422:53 - things
422:54 - huh so I have written in form of
422:56 - statements no process has to wait to
422:59 - access critical section there should be
423:01 - a bound on number of times a process is
423:03 - allowed to enter critical section before
423:05 - other process request is
423:07 - granted let me uh revise all the
423:11 - requirements again the first was Mutual
423:13 - exclusion what does it say no two
423:15 - process should be allowed in the
423:16 - critical section at the same time What
423:18 - does progress say an uninterested
423:21 - process has no right to block the
423:23 - progress of other interested process and
423:25 - what does bounding waiting bounded
423:26 - waiting say no process has no process
423:30 - can enter critical section again in
423:31 - again while the other interested process
423:34 - are waiting forever okay so
423:37 - the weight should be bounded it should
423:39 - not be unbounded that they are starving
423:42 - for infinite time okay so these are the
423:47 - requirements if P2 and P3 are not
423:49 - interested then P1 should not be blocked
423:51 - otherwise progress will be violated if
423:53 - Mutual exclusion is not guaranteed then
423:55 - what problems that arise are
423:57 - inconsistency and loss of data if Mutual
424:00 - exclusion is not guaranteed two or more
424:02 - process can enter critical section and
424:04 - they will be in RIS condition then to
424:06 - update a value of count as we saw that
424:09 - let's say producer want to update the
424:11 - value of count by + one and consumer
424:13 - want to decrease the value of count by
424:15 - minus one and the initial value of Count
424:16 - by Five so the expected result was five
424:19 - but we got four or six so this uncon
424:22 - inconsistency happens due due to the
424:25 - reason that producer and consumer
424:26 - entered critical section at the same
424:28 - time so when Mutual exclusion is not
424:31 - guaranted inconsistency and loss of data
424:33 - happens what is
424:35 - inconsistency wrong results and this is
424:38 - self-explanatory loss of data if bounded
424:41 - waiting is not guaranted then starvation
424:43 - P2 and P3 are starving here okay and if
424:47 - progress is not guaranted then then it
424:49 - is unfair solution indefinite
424:53 - postponement let's say P3 is not
424:55 - interested and it has also blocked the
424:58 - entry of P1 and P2 so this is unfair
425:02 - so we have completed the requirements in
425:04 - the next in the next lecture we are
425:05 - going to see some synchronization
425:07 - mechanisms or simply Solutions of these
425:12 - problems now comes the synchronization
425:14 - mechanisms I'm going to take the name of
425:16 - all synchronization mechanisms that we
425:18 - are going to study later so I should not
425:21 - say synchronization mechanisms are the
425:24 - solution these are just the tries we try
425:27 - to solve the problem okay so let me give
425:30 - an example uh busy waiting and non busy
425:32 - waiting and these are subcategorized
425:34 - into software hardware and OS based that
425:36 - you can all
425:38 - read lock variables and strict
425:41 - alternation are not solution so which
425:44 - synchronization mechanism I should
425:46 - categorize them as solution the one
425:49 - which guarantees Mutual exclusion the
425:51 - one which guarantees progress and
425:53 - bounded waiting if these three are
425:55 - satisfied by a Sol by a mechanism then I
425:58 - can categorize that mechanism as
426:00 - solution
426:03 - out of all these I cannot say all of
426:06 - them are
426:07 - solution let me give you an example
426:10 - see take these two log variable
426:14 - guarantees progress but it fails to
426:16 - guarantee Mutual exclusion and bounded
426:19 - waiting these two are not guaranted
426:21 - strict alternation is
426:25 - opposite it hinders progress but it
426:28 - guarantees Mutual exclusion and bounded
426:30 - waiting which loog variable was unable
426:33 - to give and loog variable was giving
426:35 - something which was not possible for
426:38 - strict alternation to give so why don't
426:41 - we merge the good qualities of both of
426:42 - them let me let me explain loog variable
426:45 - gives Mutual exclusion uh sorry log
426:48 - variables gives progress fails to give
426:50 - Mutual exclusion and bounded waiting
426:53 - strict alternation provides Mutual
426:55 - exclusion hinders progress and provides
426:59 - bounded waiting so why don't we mer mer
427:01 - the good qualities of them and create a
427:04 - perfect
427:05 - solution that is Peterson or ders
427:07 - algorithm so we cannot categorize lock
427:10 - variable and strict alternation as
427:13 - solution sometimes we say them as
427:15 - solution but they are not in literal
427:17 - terms what is solution solution is the
427:21 - one that satisfy all the requirement
427:23 - Mutual exclusion bounded waiting and
427:25 - progress lock variables and District
427:27 - alternation are not Solutions Peterson
427:30 - and deer algorithm solution okay but
427:33 - sometime sometimes we say lock variable
427:36 - as software solution we just say we
427:38 - doesn't mean that as actual solution
427:41 - okay so let me read so synchronization
427:44 - mechanisms are of two types bounded
427:46 - waiting and non-s sorry busy waiting and
427:48 - non- busy waiting busy waiting is also
427:50 - known as spin lock and non- busy waiting
427:52 - is also known as blocking and these are
427:54 - subcategorized into software hardware
427:57 - and OS based software are user mode
427:59 - Hardware as special instructions and OS
428:02 - based or kernel mode so four these are
428:05 - the four type of software solution two
428:07 - types of Hardware solution TSL
428:09 - instruction and swap instruction and OS
428:11 - based are sleep and wake up semaphor and
428:14 - monitors I hope you have somewhere heard
428:17 - the name of semap for
428:19 - before okay so don't worry we are going
428:21 - to study them in detail in every case
428:25 - possible in each of the synchronization
428:27 - mechanisms we are going to solve lots of
428:29 - problem in these uh synchronization
428:32 - mechanisms and these problems will be
428:34 - logical okay so let's see some
428:37 - assumptions process enter critical
428:39 - section for finite amount of time this
428:41 - is the first assumption because if say
428:42 - the process enters critical section for
428:44 - infinite amount of time and we have also
428:46 - guaranteed its Mutual
428:48 - exclusion it will make other process
428:51 - starve because Mutual exclusion won't
428:53 - allow any other process to enter
428:55 - critical section and this process is not
428:57 - leaving the crital section so other
428:59 - process will Dive Dive because of
429:02 - die because of starvation so we have to
429:04 - assume that process enter critical
429:06 - section for a finite amount of time and
429:08 - come out of it it never gets stuck in
429:10 - the critical section this is the first
429:11 - assumption process can never get stuck
429:14 - in a critical section second thing is if
429:16 - a process is in entry section then it
429:19 - means it is interested in the critical
429:21 - section uh in the previous lecture I
429:24 - have discussed about process sorry
429:26 - progress what was
429:28 - progress an uninterested process should
429:31 - not block the entry of interested
429:33 - process now I should clarify what is
429:36 - interested
429:37 - process interested process the process
429:40 - who wants to enter critical
429:42 - section and if a process wants to enter
429:44 - critical section then only they will
429:47 - enter entry
429:49 - section otherwise they will never enter
429:51 - into entry section let me speak again if
429:54 - a process is interested in critical
429:56 - section or wants to go in critical
429:58 - section then only it will tries to to
430:01 - enter entry section otherwise it will
430:03 - not okay so this is the second
430:05 - assumptions we are taking the third is a
430:08 - process is said to have left the
430:11 - critical section only when it has
430:13 - executed its exit
430:15 - section and the fourth is a process can
430:19 - get preempted from CPU while executing
430:22 - either entry section or critical section
430:24 - or exit section a user process can get
430:27 - preempted anywhere after any instruction
430:32 - any number of time okay so let me read
430:34 - the assumptions again a process will
430:37 - never stuck in the critical section A
430:39 - process will enter into entry section
430:42 - only when it is inst interested in the
430:45 - critical section and the third
430:47 - is a process is said to have left
430:50 - critical section only when it has
430:51 - executed its exit section and the fourth
430:54 - is a process can get preempted from
430:57 - anywhere after any instruction any
431:00 - number of times
431:02 - let's discuss our first synchronization
431:05 - mechanism that is lock
431:07 - variable can you suggest something from
431:09 - the name lock variable a variable named
431:12 - lock which is used to represent whether
431:14 - critical section is free or in use it is
431:17 - a busy waiting solution I hope you all
431:19 - know what is busy waiting and it is a
431:21 - software solution do you remember the
431:25 - the types we discussed in the last
431:27 - lecture software solution Hardware
431:29 - solution operating system system and
431:32 - software solution are implementable at
431:33 - user mode Hardware Solutions
431:36 - are are special instructions and
431:40 - operating systems are based on kernel
431:42 - mode okay so it is a software solution
431:45 - so it is a way to say a
431:48 - solution it is not an actual solution
431:51 - okay I have discussed that thing in the
431:52 - last lecture we just say it as a
431:54 - solution but is not an actual solution
431:57 - it does not satisfy all the requirements
432:00 - to be a solution can you remember the
432:03 - requirements yes the requirements are it
432:06 - should guarantee Mutual exclusion it
432:08 - should guarantee progress and bounded
432:11 - waiting okay so let's see how does it
432:14 - work
432:15 - so in entry section we Define a variable
432:18 - named lock variable which can take two
432:20 - value either zero or one what does Z
432:23 - represent Z represent that critical
432:25 - section is
432:27 - free no process is in the critical
432:29 - section at the moment and what does one
432:32 - represent critical section is in use a
432:35 - process is already present in the
432:36 - critical section okay so let's say it is
432:40 - the beginning okay a process enters into
432:44 - entry section see that lock is zero that
432:46 - means critical section is free goes into
432:49 - critical section and changes the value
432:51 - of log to
432:53 - one it's it's similar as if uh there's a
432:56 - there's a room someone enters the room
433:00 - and lock it it from inside and when it
433:03 - is logged from inside if some other
433:05 - process see a room is logged from
433:07 - inside then it understands that someone
433:10 - is already present in the
433:13 - room so lock 0 or 1 0o means critical
433:17 - section is free and one means critical
433:18 - section is in
433:21 - use and what does exit exit section do
433:24 - when a man comes out of a room then what
433:28 - does it do it unlocks the room and goes
433:32 - out see it is similar like a like a
433:34 - bathroom situation or toilet situation
433:36 - whatever you call if a man enters into a
433:38 - toilet what does he do he locks it from
433:42 - inside suppose another man comes and see
433:45 - a toilet is locked from inside
433:47 - understand that someone is already
433:48 - present he will wait until the man
433:51 - unlocks and comes out okay same is the
433:55 - case Zero means critical section is free
433:57 - one means critical section is in use and
433:59 - when a process EX exits what does it do
434:02 - it changes the log to zero which says
434:05 - critical section is now free okay so
434:08 - this is the main idea of lock now let's
434:10 - see the implementation the entry section
434:13 - okay so we Define lock and we sets set
434:17 - it value initially to zero what does Z
434:19 - represent initially the critical section
434:21 - is free no one is in the toilet okay or
434:24 - any room let's say toilet if you feel it
434:27 - gross so let's take an example of a room
434:30 - so let's say in a room initially the
434:32 - room is open anyone can enter hence the
434:34 - lock is equals to zero void process in I
434:39 - so this is a process code now here it
434:42 - comes non-critical section and then the
434:44 - entry
434:45 - section while loog equals toal to 1 then
434:49 - busy weight what does this represent
434:52 - this represent busy weight it says if
434:54 - loog equals to 1 whether log is equals
434:56 - to
434:57 - 1 what does one say critical section is
435:00 - in use so it says if critical section is
435:03 - is in use check this condition again and
435:06 - again again and again and it busy weits
435:09 - busy in what checking the condition
435:12 - whether critical section is free or in
435:14 - use and waiting to proceed
435:17 - further okay so if critical section is
435:19 - in use it will busy
435:21 - weit and let's say critical section is
435:24 - not in use this is the initial case so
435:26 - loog is equals
435:27 - to0 while loog equals to equals to 1 no
435:30 - this is false it will go down lock
435:33 - equals to 1 it will change the value of
435:35 - lock equals to 1 and it will enters the
435:37 - critical
435:39 - section and when it has performed all
435:41 - the instructions of critical
435:43 - section the process intends to go out so
435:46 - before going out what does it do changes
435:49 - the value of lock equals to Zer it
435:50 - unlocks the
435:52 - room okay so I hope you got the idea
435:55 - just think think it it as a toilet or
435:58 - some room uh for um for couples to to go
436:01 - in okay so let's say process represent a
436:03 - couple I hope uh now you can get the
436:06 - idea let's say a process represent a
436:07 - couple a couple enters the room an open
436:09 - room uh and then locks the room from
436:13 - inside do whatever they want to do in
436:15 - the critical section and when they want
436:17 - to come out they will unlock the room
436:19 - for another couples I hope now you got
436:21 - the idea so what is the two things the
436:23 - couples do before entering into the room
436:26 - the first thing
436:28 - is the first thing is it will check it
436:31 - will
436:32 - check if someone is already present in
436:34 - the room if yes then they will wait busy
436:37 - wait if no they will
436:40 - enter lock the room perform whatever
436:43 - they want to perform and then they comes
436:45 - out by unlocking the room I hope you got
436:48 - the
436:49 - idea
436:51 - see this entry section is in the written
436:53 - in the high level code when it will be
436:56 - in the when it will pass to compiler it
436:58 - will be changed to low level code that
437:00 - is assembly good so what does it look
437:02 - like load the value of lock into some
437:05 - resistor RI compare the value of RI with
437:10 - zero jump if not zero to statement B
437:13 - again so this is
437:15 - busit and store the value of lock store
437:19 - the value of one constant one into lock
437:22 - do to get this is the same thing written
437:25 - here did you get it
437:28 - see lock the uh load the value of lock
437:31 - into RI let's say this is register RI
437:34 - and the value of lock was initial zero
437:36 - so this value will be loaded
437:37 - here compare RI with zero is the value
437:41 - of RI equals to
437:44 - Z yes it is equals to Z so what will it
437:49 - will do it will go to the next statement
437:52 - jump if not zero but it is zero so it
437:55 - will ignore this statement will go down
437:57 - store the value of constant 1 into the
438:01 - lock variable so
438:03 - now in lock in lock variable one will be
438:07 - stored now I hope you got the
438:11 - idea in the last that is exit section
438:14 - store the value of 0er into the
438:18 - loog what does this mean lock the room
438:21 - from inside what does this mean check if
438:24 - critical section is free and what does
438:27 - this mean unlock the room when you comes
438:29 - out
438:37 - in the last lecture we have seen the
438:40 - high level implementation and lowlevel
438:42 - implementation of lock
438:44 - variable let's understand from this
438:46 - diagram also there are two process P1
438:49 - and P2 available in the ricq let's say
438:51 - P1 enters in the CPU P1 got scheduled on
438:55 - the CPU P1 shows interest to enter into
438:58 - critical section so what it has to do it
439:01 - has to enter into entry section first
439:04 - and what is entry
439:06 - section check if the value of log equals
439:09 - to 1 if not then change the value of
439:12 - lock equals to 1
439:14 - so P1 enters P1 P1 want to enter
439:17 - critical section so it will check if the
439:20 - value of lock equals to one no the value
439:21 - of lock was zero so it will change the
439:23 - value of lock equals to 1 now P2 P1 is
439:27 - started executing there some
439:29 - instructions of the critical ction and
439:31 - suddenly premature preemption happens
439:33 - let's say P2 is a high priority process
439:36 - P2 comes here P2 comes in the CPU what
439:40 - it will do it has also interest to go
439:42 - into the critical section so it will go
439:44 - to the entry section first while value
439:47 - of lock equals to 1 yes the value of
439:49 - lock equals to 1 check the condition
439:52 - again does the value of lock equals to 1
439:55 - yes check the condition again is log
439:57 - equals to one yes check the condition
439:59 - again so it will keep on checking the
440:01 - condition again and again it will busy
440:03 - wait until the time slice expires now
440:07 - the P2 got preempted from the CPU P1 got
440:11 - the chance again P1 was shed on the CPU
440:13 - P1
440:14 - resumed P1 resumed completed its
440:17 - critical section when it got when it
440:20 - want to get out from the critical
440:21 - section it has to execute exit section
440:25 - and what does exit section say change
440:27 - the value of lock to zero now the value
440:30 - of loog is
440:32 - zero now P2 got chance P1 has P1 has
440:35 - been terminated now P2 got chance on the
440:38 - CPU again P2 will resume so P2 will
440:42 - check is the value of log equals to 1 so
440:46 - the value of loog loog is not equals to
440:48 - one the value of loog is zero so it will
440:51 - escape the busy V now it will change the
440:53 - value of loog equals to one so value of
440:55 - loog will be changed again to one goes
440:58 - into gral section complete the critical
441:00 - section and when it come comes out it
441:03 - will unlock the critical section so I
441:05 - hope you got the idea how does loog
441:07 - variable work so let me read it
441:10 - again when P1 was in the critical
441:13 - section lock variable will not allow P2
441:16 - enter critical section so P2 will be
441:19 - busy waiting until P1 comes back exits
441:22 - critical section by updating the lock
441:25 - variable so I hope you understand how
441:27 - does log variable works so now I a
441:30 - question for you does this law
441:32 - guarantees Mutual exclusion every time
441:35 - is there any possibility that Mutual
441:37 - exclusion get violated is there any
441:39 - possibility that P1 and P2 gets into
441:43 - critical section at the same
441:46 - time think about it see the code and
441:48 - think about it is there any possibility
441:51 - that P1 and P2 enters the critical
441:53 - section at the same
441:58 - time what I'm about to say is a Golden
442:00 - Rule for solving questions like
442:05 - that whenever you see whenever you see
442:08 - an entry section of two
442:11 - statements preempt in
442:13 - between let me speak again whenever you
442:16 - see entry section of two statements
442:18 - preempt in between if you preempt in
442:21 - between of these two statements then you
442:24 - will get some uh good results to infer
442:28 - okay so we are going to do the same
442:31 - let's preempt in between so we have to
442:34 - preempt the process in such a manner
442:37 - that two process are in the critical
442:40 - section at the same time that is mutual
442:42 - exclusion is violated we try in such a
442:44 - way so how we can do that we will
442:49 - preempt between the two statements of
442:51 - Entry section so the first statement
442:53 - consist of these three instructions and
442:55 - the second consist of this one
442:57 - instruction so we try to preempt after
442:59 - this instruction
443:01 - let's go so here let me draw the value
443:05 - of
443:07 - lock
443:08 - R1 and R2 okay now store the value or
443:14 - load the value of lock into R1 so what
443:17 - is the initial value of log initially is
443:19 - zero initially is zero so we'll load
443:21 - that value into R1 now compare the value
443:25 - of R1 with 0o is it zero yes it is zero
443:28 - so it will go to the statement three
443:30 - jump if not zero but it is zero so it
443:32 - will not go anywhere it tries to go to
443:34 - statement 4 but what we have to do we
443:37 - have to
443:38 - preempt before it can execute the
443:40 - statement 4 so it got preempted before
443:44 - the process can change the value of lock
443:46 - now process two is in the CPU process
443:49 - two starts load the value of lock into
443:51 - R2 what is the value of lock it is zero
443:54 - load it into the R2 okay compare the
443:56 - value of R2 is the value of R2 equals to
443:59 - Z yes it is z
444:01 - jump if not zero to statement B but it
444:03 - is zero so it will not jump
444:07 - anywhere now it tries to go
444:10 - to store lock equals to 1 so you can see
444:16 - preempting P2 here will give us no
444:19 - benefit
444:21 - because let me explain more
444:25 - so now P2 has executed fourth statement
444:28 - also so you have to preempt just one
444:30 - process either P1 or P2 so we have
444:32 - preempted P1 so no need to preempt P2 P2
444:36 - executed fourth instruction also that is
444:38 - store the value of one into the log so
444:41 - change the
444:42 - value 0 to 1 okay
444:47 - now what does loog equals to 1 represent
444:50 - loog equals to 1 represent that critical
444:52 - section is not free so P2 gets into
444:56 - critical section start executing
444:58 - critical section but what what happens
445:00 - premature preemption so we are
445:02 - preempting P2 here premature preemption
445:05 - happens P2 is in the critical section
445:08 - but it got preempted from the CPU now
445:11 - what will happen P1 will start its
445:14 - execution P1 will resume what P1 will do
445:18 - P1 will start from this instruction P1
445:21 - will change the value of lock 1
445:25 - to1 this instruction will executed what
445:27 - does this instruction say load the value
445:30 - or
445:30 - store the value of constant one into the
445:32 - lock so one will be stored into the lock
445:36 - now what we will do it will enter the
445:38 - critical section no one is going to stop
445:41 - P1 from entering the critical
445:43 - section so P1 will enter the critical
445:46 - section P2 was already present in the
445:48 - critical section this will cause
445:50 - inconsistency and loss of
445:52 - data so does lock guarantees Mutual
445:55 - exclusion every time no it doesn't
445:58 - guarantee Mutual exclusion if pre
446:00 - happens between the two statements of
446:02 - Entry
446:03 - section I hope you got the idea you want
446:07 - to read I have
446:08 - also written the numbers so first this
446:11 - will instruction this instruction will
446:13 - executed this one this one and then it
446:15 - will get preempted now what will happen
446:17 - P1 gets preempted P2 will start
446:19 - execution it loads the value of lock
446:21 - into R2 these things happens now it will
446:25 - change the value of lock from 0 to 1
446:29 - starts execute using the instructions of
446:31 - critical section but it gets preempted
446:33 - in between now P2 gets in P1 gets into
446:37 - the
446:38 - CPU started from where it left store the
446:41 - value of loog equals to one loog was
446:43 - already one but it will change the value
446:45 - of lock equals to 1 now it will enter
446:47 - critical section is there anyone present
446:50 - to stop P1 from entering critical
446:54 - section given that P2 is already there
446:57 - in the critical section no one is there
446:59 - so P1 and P2 will be in the critical
447:01 - section at the same time this
447:03 - is a major reason for inconsistency
447:07 - Mutual exclusion is violated so both
447:10 - process are in critical section Mutual
447:11 - exclusion is violated is progress
447:15 - guaranteed can a non-interested process
447:18 - prevent interested process from going
447:19 - into the critical section no see I have
447:23 - explained you an assumption I think the
447:26 - Assumption number two it was that if a
447:29 - process
447:30 - is
447:31 - uninterested in critical section it will
447:34 - never ever enter the entry section and
447:36 - if a uninterested process never enters
447:39 - the entry section how can it change the
447:41 - value of lock equals to
447:44 - 1 can an uninterested couple go inside
447:48 - and
447:49 - lock lock them themselves in the room so
447:51 - that other couples do not enter no this
447:54 - not happen that this does not happen so
447:56 - in the same way a process will not go
447:59 - into the intersection
448:01 - even if it is uninterested to go to
448:03 - critical section and lock the critical
448:05 - section this will not do this this won't
448:07 - be done by any process who is
448:09 - uninterested so can a non-interested
448:11 - process prevent interested
448:13 - process process prevent the interested
448:16 - process from going to the critical
448:17 - section no this doesn't happen so yes
448:19 - progress is
448:22 - guaranteed okay so I have also explained
448:25 - in this way P1 is not interested P2 is
448:27 - interested P1 will be busy here in
448:29 - non-critical SE it will never ever enter
448:31 - the entry section so lock value will
448:34 - always be zero for
448:36 - P2 for P2 critical section will be
448:40 - always free okay now the third condition
448:43 - is waiting bounded a process should not
448:46 - go into critical section when there
448:47 - exist another interested
448:49 - process
448:50 - okay so what does uh bounded waiting say
448:54 - a process should not go to critical
448:56 - section uh I should write here again
449:00 - when there is an another existing
449:03 - interested
449:05 - process so let's
449:08 - check let's check suppose P1 completes
449:11 - its critical section check if the value
449:14 - of log equals to Z yes the value of loog
449:16 - equals
449:17 - to0 changes the value of loog equals to
449:20 - 1 enters critical section when completes
449:22 - all the instruction enters exit section
449:24 - change the value of lock equals to Z
449:27 - again comes here now the value of lock
449:29 - is again Z so lock is zero it will go
449:32 - there check if the value of lock equals
449:34 - to Z no change the value of lock equals
449:35 - to 1 enters critical section changes the
449:37 - value of log to zero again goes again
449:40 - goes again goes again no one is there to
449:42 - stop P1 going again and again while P2
449:45 - is there waiting for its turn to get
449:47 - into the critical
449:49 - section so bounded
449:52 - waiting no bounded waiting is not
449:54 - guaranteed waiting can be unbounded for
449:58 - P2 so suppose p exits critical section
450:00 - make the value of log equals to zero and
450:02 - quickly joins readyq to go into the
450:04 - critical section again a process can
450:06 - successfully enter critical section
450:08 - multiple times while other process are
450:10 - waiting for their turn to ENT critical
450:12 - section so lock variable guarantees
450:16 - progress but it fails to guarantee
450:18 - Mutual exclusion and bounded
450:21 - vitting okay so let's see a this thing
450:25 - lock variable is a busy waiting solution
450:27 - leading to wastage of CPU time Cycles so
450:31 - yes it is a busy fitting solution
450:33 - because
450:36 - see this
450:39 - part can something be done like this a
450:42 - process comes to the entry section check
450:45 - if critical section is free or not let's
450:48 - say it is not free so why does it have
450:51 - to check the condition again and again
450:53 - wasting the CPU
450:55 - Cycles why does it have to check the
450:58 - condition again and again with wasting
451:00 - the CPU
451:01 - Cycles can something be done like this
451:04 - that a process check the condition that
451:07 - critical section is not free it itself
451:10 - gets blogged and when the process which
451:14 - was in the critical section comes out in
451:16 - the exit section it wake up wakes up the
451:20 - wakes up the blocked process or it's
451:21 - unblocked the sleeping process are you
451:24 - getting what I'm trying to
451:26 - say see this point
451:30 - lock variable is a busy waiting solution
451:32 - leading to the wastage of CPU time
451:34 - Cycles why does the CPU Cycles get
451:36 - wasted because a process checks the
451:38 - condition again and again can something
451:40 - be done like this that the process need
451:42 - not have to check the condition again
451:44 - and again instead what happens is
451:48 - process checks the condition once see if
451:51 - the critical section is not
451:54 - free then it itself get blocked it
451:58 - itself get blocked let's say P1 sleeps
452:01 - let's say P2 P1 was in the critical
452:04 - section P2 comes check that critical
452:06 - section not free get into the sleeping
452:08 - que let's say sleeping queue this is the
452:11 - new name sleeping
452:13 - queue now when P1 completes the critical
452:16 - section goes to the exit section now it
452:19 - is responsibility for P1 to wake up the
452:22 - sleeping process that is P2 it says Hey
452:25 - P2 wake up now I have completed the
452:27 - critical section you can go into the
452:29 - critical section if something like this
452:32 - can be happened then the wastage of CPU
452:36 - cycle can be pre
452:37 - preempted prevented
452:41 - okay so let's see what is
452:48 - this several concurrent process are
452:50 - attempting to share an iio device in an
452:52 - attempt to achieve Mutual exclusion each
452:54 - process is given a following structure
452:57 - Okay so
452:59 - code unrelated to device use that is
453:01 - non-critical section repeat until b
453:04 - equals to false b equals to True code to
453:08 - X is shared b equals to false code
453:10 - unrated to device see what happens even
453:14 - if the variable is
453:16 - changed we we thinks that is a difficult
453:18 - question it is exactly similar to the
453:20 - lock variable which have which we have
453:22 - discussed earlier so here busy is equals
453:25 - to loog false is zero and true equals to
453:28 - 1 now
453:30 - check codee unrelated to device that we
453:33 - don't bother about non-critical section
453:36 - repeat until bz equals to false that
453:39 - is lo lo equals
453:44 - to0 if lock equals to0 then go to the
453:49 - next statement b equals to 2 which means
453:52 - lock equals to 1 now so this is similar
453:55 - like while log
453:59 - so this is
454:01 - similar to what we have studied in the
454:03 - previous uh this
454:05 - code this thing this is exactly similar
454:08 - what they have done instead of lock they
454:10 - have written busy instead of one they
454:12 - have written true and instead of uh zero
454:16 - they have written false so this thing
454:19 - can also be written like that log is not
454:22 - equals to
454:23 - Z okay so they have just changed the way
454:27 - of a
454:28 - representation so this code is exactly
454:30 - similar to the lock variable code which
454:32 - we have discussed now check the
454:34 - following uh options which of the
454:37 - following are true for this approach it
454:38 - provide a reasonable solution to the
454:40 - problem of guanting mutual exclusion no
454:42 - we have discussed recently that lock
454:45 - variable does not guarantee Mutual
454:46 - exclusion because if you preempt here
454:49 - Mutual exclusion is not guaranteed it
454:51 - may consume substantial CPU time
454:53 - accessing the busy variable
454:55 - yes this thing lock variable is a busy
454:58 - betting solution it leads to wastage of
455:01 - CPU time or Cycles third it will fail to
455:04 - guarantee Mutual exclusion yes this is
455:06 - true so option option two and option
455:08 - three are
455:10 - correct in the last lecture we have seen
455:12 - log variable in this lecture we will
455:15 - move to the next synchronization
455:17 - mechanism that is strict
455:19 - alternation do you remember the problems
455:22 - which lock variable has caused the first
455:24 - was Mutual exclusion lock variable
455:27 - doesn't guarantee Mutual exclusion every
455:29 - time in which cases Mutual exclusion was
455:31 - not
455:32 - guaranteed in in entry section when
455:35 - there were two statements preempt in
455:37 - between the two statements preempt after
455:40 - one statement is executed in that case
455:42 - Mutual exclusion was not guaranteed and
455:44 - bounded waiting was also not guaranteed
455:45 - a progress can go again and again while
455:48 - some other interested process kept on
455:50 - waiting for infinite time or starving
455:53 - for unbounded time now the next
455:56 - synchronization mechanism is strict
455:58 - alternation
456:00 - let's check so the strict alternation is
456:03 - also a busy waiting solution and it is a
456:05 - software solution implementable at user
456:07 - mode similar to the lock variable and it
456:09 - is a two process solution do you
456:12 - remember the lock variable was a
456:13 - multi-process
456:15 - solution where is it so the lock
456:17 - variable was a multi-process
456:19 - solution strict alternation and Peterson
456:21 - algorithm these are
456:23 - the two process solution what does two
456:26 - process mean this solution only work
456:29 - when there are two process in
456:30 - consideration so what we do strictly on
456:33 - Alternate bi basis process takes turn to
456:36 - enter critical section so strictly on
456:38 - Alternate basis first P1 goes then P2
456:40 - then again P1 goes then P2 and in this
456:43 - way they completes the critical section
456:45 - so let's see the
456:47 - code int turn equals to random 0 or 1 so
456:51 - turn is a variable that can take two
456:53 - values either Z or 1 and we randomly
456:55 - assign the value of the variable turn it
456:59 - can can be either zero or one randomly
457:02 - so let's write the code void process Z
457:04 - here it is a problem it should be
457:06 - process one yeah void process Zer so we
457:09 - are talking about p 0 and P1 so these
457:12 - are the two processes while non-critical
457:15 - section while turn equals to 1 critical
457:18 - section turn equals to one so what does
457:21 - this say this
457:24 - says so the turn turn signifies which
457:28 - process should go in the critical
457:30 - section now if turn is zero then p 0
457:32 - should go into the critical section if
457:34 - turn is 1 then P1 should go in the
457:37 - critical section so here in the busy
457:39 - weight condition it checks while turn
457:41 - equals to 1 is it the case that turn
457:44 - equals to 1 if yes then keep on checking
457:47 - the condition busy weight if turn equals
457:49 - to 1 keep on checking the condition busy
457:51 - weight otherwise go into critical
457:54 - section after you complete the critical
457:56 - section change the value to of turn
457:59 - initially let's say the value of turn
458:01 - was Zero let's say the value of turn was
458:03 - zero so critical section
458:06 - completed condition checking turn is not
458:09 - equals to one so it will bypass it goes
458:11 - to the critical section when it
458:13 - completes the critical section now it
458:15 - has to change the value of turn to one
458:17 - because what we said strictly on
458:19 - Alternate basis so first turn value of
458:22 - turn was Zero it means p 0 went to the
458:24 - critical section now when it has
458:26 - completed its critical section then it
458:28 - has to change the value of turn equals
458:30 - to 1 which means now it is the turn of
458:33 - process one to go into the critical
458:35 - section so let's check this while P1
458:38 - similar for process one check if turn
458:40 - equals to zero then Vis it otherwise go
458:43 - into critical section and when you
458:44 - complete the critical section make sure
458:46 - to change the value of turn I hope you
458:49 - understand this solution this is easier
458:51 - than lock variable okay so is mutual
458:55 - exclusion guaranteed can you check this
458:58 - so when was Mutual exclusion not
458:59 - guaranted in lock variable when we
459:02 - preempt in between two statements of
459:04 - Entry section what is the entry section
459:06 - here just this one and exit section just
459:10 - this one so mutual exclusion will be
459:13 - guaranteed let's
459:15 - see let's see so the what does log
459:20 - variable meant if it is zero which means
459:22 - critical section is free if it is one
459:24 - which means critical section is not free
459:27 - if turn equals to I which means it is p
459:30 - is turned to enter into the critical
459:31 - section and if turn equals to J it is PJ
459:34 - is turned to enter into the critical
459:35 - section I hope this is clear now let's
459:38 - check the scenario there are two process
459:40 - p 0 and P1 in the RQ which are
459:42 - interested in going to critical section
459:45 - let's say p 0 was scheduled first on the
459:48 - CPU
459:50 - and turn equals to zero and this was
459:53 - randomly saved randomly assigned so p 0
459:56 - was executing its instructions in the
459:58 - critical section at s finally it got
459:59 - preempted so p 0 was already present in
460:03 - the critical section now let's say p 0
460:06 - is preempted from the CPU P1 comes so P1
460:11 - will
460:13 - start so the value of turn equals to 0
460:16 - because p 0 has not completed its
460:19 - critical
460:20 - section and the value of turn equals to
460:23 - one is still remaining to be executed so
460:26 - the value of turn equals to zero now
460:29 - goes to the non-critical section while
460:31 - turn equals to Z yes turn equals to Z so
460:33 - it will keep on checking the condition
460:35 - again and again until the time slice or
460:38 - the time Quantum of P1 expires when P1
460:41 - expires then P1 is preed from the CPU
460:44 - sent back to the RQ and p 0 comes back
460:47 - now p 0 will resume when p 0 complete
460:50 - this its instruction of the critical
460:52 - section then it goes to the exit section
460:55 - what is the exit section change the
460:56 - value of turn so the turn equals to one
460:57 - now now when one tries to enter critical
461:00 - section it will because it will not get
461:04 - stuck in the busy waiting condition okay
461:08 - so what is the busy waiting condition
461:10 - turn equals to equals to Z but the value
461:11 - of turn is one now because p 0 has
461:14 - completed this instruction so the value
461:17 - of turn has changed now when P1 will try
461:20 - to enter when P1 will try to execute
461:22 - this
461:23 - instruction it will not get stuck in the
461:26 - busy waiting I hope the thing is clear
461:29 - so now P1 cannot enter critical section
461:32 - until p 0 set the value of turn as one
461:34 - so is mutual exclusion guaranted yes the
461:36 - mutual exclusion is
461:38 - guaranteed can you infer more so let's
461:41 - say turn equals to random 0a 1
461:46 - see
461:48 - see there are two process p 0 and P1 and
461:52 - the value of turn is set
461:55 - randomly let's say the value of turn is
461:57 - zero here but
461:59 - p 0 is not interested to go to the
462:01 - critical
462:03 - section if p 0 is not interested to go
462:05 - to the critical section it will never
462:07 - ever enter entry section it will never
462:10 - go to this critical section and it will
462:12 - never execute this turn equals to one
462:15 - and if turn equals to 1 is never
462:16 - executed then P1 in any case cannot go
462:21 - into the critical section so p
462:24 - 0 is uninterested process is hindering
462:28 - the progress of P1 which is interested
462:30 - process let me speak again p 0 is not
462:33 - interested to go to critical section if
462:35 - it never goes to critical section which
462:36 - means it will never execute the exit
462:38 - section and what was the exit section
462:41 - change the value of turn so turn equals
462:43 - to 1 will never happen and if this never
462:46 - happen P1 cannot go to critical section
462:48 - ever so an uninterested process has
462:51 - hindered the progress of interested
462:53 - process so progress is hindered here
462:56 - which was not in the lock variable
462:59 - so this is the same thing let's say turn
463:01 - equals to random 0 1 gives one it means
463:03 - it is Pi's turn to enter critical
463:05 - section but she is not interested ENT
463:07 - the critical section if she doesn't
463:09 - enter I'm talking about the process if
463:10 - she doesn't doesn't enter in the
463:12 - critical section then she will never
463:14 - execute the exit section turn will never
463:16 - be set to zero p 0 is blocked by a
463:18 - non-interested one progress is hindered
463:20 - so it is just an
463:22 - example what I want to say Mutual
463:24 - exclusion is guaranteed progress is
463:27 - hindered because an uninterested process
463:29 - take anyone either p 0 or P1 it is just
463:32 - an example take any
463:34 - process that uninterested process will
463:37 - never change the value of turn equals to
463:40 - the other process so other process other
463:43 - interested process will never be equal
463:45 - will will never be able to enter the
463:47 - critical section so an uninterested
463:49 - process is blocking the progress of
463:51 - interested process so progress is
463:55 - hindered is the waiting bounded yes wait
463:59 - is bounded what was the meaning of
464:01 - unbounded waiting the meaning of
464:02 - unbounded waiting was P1 kept on going
464:05 - to the critical section again and again
464:07 - again and again again and again while an
464:09 - other interested process that is P1 is
464:12 - starving and p 0 is laughing at the face
464:15 - of P1 this was bounded waiting this was
464:19 - unbounded waiting now here in the case
464:23 - you
464:23 - see when p 0 enters into the critical
464:26 - section it must change the value of turn
464:29 - equals to other process which means p 0
464:31 - is giving chance to other process to
464:34 - enter to the critical section now which
464:36 - means p 0 cannot enter into the critical
464:38 - section two times in a row let me
464:41 - explain so let's say the initial value
464:43 - of turn was Zero Turn was zero this
464:47 - condition will be escaped goes to the
464:49 - critical section now turn equals to one
464:51 - try to go again now it will get stuck
464:55 - here as turn equals to one when it tries
464:57 - to go again it will get stuck in this
464:59 - Loop so bounded waiting is present as
465:03 - there is a strict
465:04 - alternation bounded waiting as there is
465:06 - a strict alternation now let's revise so
465:10 - lock variable and turn variable what is
465:11 - the difference Mutual exclusion was not
465:13 - guaranted by lock variable it was it is
465:16 - guaranteed by turn progress progress is
465:18 - guaranteed by lock variable but in turn
465:21 - an un uninterested process can block
465:23 - other interested process bounded waiting
465:26 - bounded waiting was not uh ensured in
465:30 - lock variable but it is ensured in turn
465:32 - as there is a strict alternation between
465:34 - the order of process which goes into the
465:37 - critical section busy waiting the both
465:40 - are busy waiting solution and busy
465:41 - waiting vage the CPU Cycles
465:45 - okay and last thing is number of process
465:48 - lock variable is a multiprocess solution
465:51 - while turn variable is a two process
465:53 - solution so these are the difference
465:54 - between lock variable and turn variable
465:56 - so till now we have covered two
465:58 - synchronization mechan mechm lock and
466:00 - turn okay now the last thing the value
466:04 - of turn need not to be equals to 0 or 1
466:06 - it can be any either I comma J so we are
466:09 - generalizing it is not necessary that
466:11 - only p 0 and P1 are there in the program
466:14 - it can be either process like it can be
466:17 - p8 and P9 that can also be possible so
466:20 - we are generalizing in terms of I and J
466:22 - so let's say in turn equals to random I
466:25 - comma J so we are assigning the value of
466:29 - turn randomly either I or J turn can
466:31 - take here two values I or J if it is I
466:35 - then it is the turn of process I to
466:37 - enter the critical section and if it is
466:39 - J then it is the proc it is the turn of
466:41 - process J to enter the critical section
466:44 - so simil same
466:47 - thing in process I check if it is the
466:50 - turn of process J to enter if yes then
466:53 - keep on busy waiting otherwise goes to
466:55 - the critical section and in the exit
466:57 - section change the value of turn to the
466:59 - other process same thing is happening
467:00 - here
467:03 - okay so lock and strict alternation are
467:06 - incorrect solution why because they are
467:08 - not satisfying all the requirements
467:10 - log was not log was
467:13 - not giving Mutual exclusion and bounded
467:16 - waiting and alternation is not giving
467:18 - progress so all three condition Mutual
467:20 - exclusion progress and bounding waiting
467:22 - should be satisfied but here some of the
467:24 - other is not satisfied so these are
467:26 - incorrect
467:27 - Solutions so here is a homework
467:30 - problem here's a homework problem check
467:32 - this in turn equals to random i j so
467:35 - this is a problem you have to tell is
467:37 - this guanting Mutual exclusion is this
467:39 - guanting progress and bounded waiting
467:42 - try this in the last lecture we have
467:45 - seen strict alternation which
467:48 - provides Mutual exclusion and bounded
467:51 - waiting and if you recall the middle one
467:54 - that is the progress was ensured by lock
467:57 - variable so Lo variable has ensured
467:59 - progress strict alternation in ensures
468:02 - bounded waiting and mutual exclusion why
468:04 - not we Club the good qualities of both
468:06 - and create a perfect solution we have
468:09 - done the same thing that is Peterson
468:11 - solution has been made by combining the
468:13 - good qualities of lock variable and
468:15 - strict
468:16 - alternation and it is a solution in
468:18 - literal terms it provides all the three
468:20 - matual exclusion bounded waiting and
468:22 - progress it is a busy waiting solution
468:25 - software solution implementable at user
468:27 - mode and it is a two process
468:30 - solution that means it will only work
468:33 - when there are two process into
468:35 - consideration let's say pi and PJ so we
468:37 - are defining so let me tell you what is
468:40 - the main idea of this Peterson solution
468:42 - we are using two variables flag variable
468:45 - and turn
468:47 - variable so what does flag and turn
468:50 - refer to flag variable suggest if a
468:53 - process is interested to go into
468:55 - critical section or
468:57 - not flag gives the
469:01 - interest for a process let's say for
469:03 - process I if the value of flag is zero
469:06 - which means process is not interested
469:08 - and if the value is one which means
469:10 - process is interested and turn you all
469:13 - know what is the meaning of
469:15 - turn which process should enter into the
469:18 - critical section which process so turn
469:20 - means if turn equals to I that suggest
469:23 - Pi should enter into critical section if
469:25 - turn is I which means Pi should enter
469:28 - into the critical section and if it is
469:30 - J which means PJ should enter I hope
469:33 - this is clear so what we are doing here
469:36 - is what we are
469:39 - doing initially initially we are setting
469:42 - the value of flag to false we are saying
469:45 - initially no process is interested to go
469:47 - into the critical section okay now when
469:51 - the process code will be there here
469:53 - let's check this check the intersection
469:56 - we are changing the value of flag it to
469:58 - true for process I we are changing the
470:01 - value of flag I to
470:03 - true and we are changing the value of
470:06 - turn
470:07 - to the value of the process we are
470:10 - changing the value of turn to the value
470:12 - of the process what does this mean so
470:14 - the concept of turn that is a global
470:17 - variable will be used when both of them
470:19 - are interested
470:21 - simultaneously if turn equals to zero so
470:25 - both the processes are updating the
470:26 - value of turn according to their value
470:28 - if it is process I then it will change
470:31 - the value of turn to I and if it is J
470:33 - then it will change the value of turn to
470:35 - J okay so let's say there are two
470:38 - process p 0 and P1 p 0 updated the value
470:42 - of turn to zero and what will P1 do it
470:44 - will change the value of turn to
470:46 - one now comes the important part now
470:49 - comes the important part the process to
470:52 - update the value of turn and the last
470:54 - will wait the process which will update
470:57 - the value of turn in the last Will Wait
471:00 - so we will check what is the value of
471:03 - turn if the value of turn is one it
471:06 - means that p 0 has updated it already
471:09 - and P1 has updated later and if the
471:12 - value of turn is zero which means P1 has
471:15 - already updated the value and p 0 has
471:18 - updated it in the last so we will check
471:21 - what we will
471:23 - check change the value of flag I to True
471:27 - make the process interested
471:29 - change the value of turn to the process
471:32 - value now check if other process is
471:35 - interested and the value of turn equals
471:38 - to I then busy
471:39 - weight let me explain
471:43 - again let's say p 0 and P1 both are
471:47 - interested to enter into the critical
471:49 - section both has changed the value of
471:51 - flag to True when both are interested
471:54 - they will change the value of flag to
471:56 - true now both wants to change the value
471:59 - of turn to their value so p 0 update p 0
472:03 - change the change the value of turn to
472:05 - zero and P1 changed the value of turn to
472:08 - one now when you see if the value of
472:11 - turn is zero that means P1 has updated
472:15 - first and then p 0 has updated in the
472:17 - last that's why the value of turn is
472:20 - zero you all know the process which
472:23 - updates last that value of turn will be
472:25 - saved finally let me write this the
472:28 - process which updates
472:31 - last that value of turn will eventually
472:34 - remain so if the value of turn equals to
472:37 - I that means the process I has updated
472:41 - the value of turn in the last so the the
472:43 - process which will update the value of
472:45 - turn in the last will
472:48 - wait okay so check if other process is
472:53 - interested and the value of turn equals
472:55 - to I this means that the other process
472:58 - that is the the process J has already
473:00 - changed the value of turn to J and later
473:03 - Pi I changed the value of turn to I
473:05 - that's why the value of turn is I
473:07 - eventually so which process should wait
473:10 - whose value is there in the turn so that
473:13 - process Will Wait so I hope the point is
473:16 - clear let me explain again initially
473:19 - what we are doing we are defining the
473:21 - value of n22 that is n refers to the
473:23 - number of
473:26 - process true means one and false means
473:29 - zero we are also defining
473:31 - this we are also defining an array of
473:34 - size n initialized to
473:37 - false so initi initially we are saying
473:40 - that all process are uninterested so
473:42 - let's say if there are two process then
473:43 - flag two and both are initialized to
473:47 - false that is both the process are
473:49 - uninterested in the beginning and in
473:51 - turn we are declaring a variable
473:54 - turn see here we are not initializing
473:56 - turn in the pre previous case that is of
473:59 - a strict alternation what we were saying
474:01 - we were saying Turn equals to random of
474:03 - I comma G we are not doing this here
474:07 - what we are doing we are letting the
474:08 - process change the value of turn
474:10 - accordingly according to their values
474:13 - and the process which updates the value
474:15 - of turn at the last that process has to
474:18 - wait
474:19 - because the other process has already
474:22 - updated the value of turn so that
474:25 - process should go first same concept we
474:27 - are applying here so this is the process
474:30 - code void process in I we are talking
474:33 - about process I and J refers to the
474:35 - other process what does this line means
474:37 - this line says that J is the other
474:39 - process here comes the critical section
474:42 - what we are doing changing the value of
474:44 - lag to True making the process
474:45 - interested changing the value of turn to
474:48 - I which
474:49 - means it is the turn of process I to
474:52 - enter critical section this is how
474:54 - process thinks and when it will check
474:57 - that other process is also interested
474:59 - and the value of turn is equals to my
475:02 - value which means I have updated the
475:04 - value of turn in the last and other
475:06 - process is interested too which means
475:09 - the other process should enter the
475:11 - critical section first because it has
475:13 - changed the value of turn earlier than
475:15 - me so I should wait okay so this is
475:19 - entry section and what is exit exit
475:22 - section so when the process completes
475:24 - the critical section it will make itself
475:27 - uninterested
475:29 - okay
475:31 - so let's summarize what we have
475:35 - said what a process does it change the
475:38 - flag value to True set the turn equals
475:40 - to the process ID check if other process
475:43 - is interested and I am the last one to
475:45 - update turn then I should bate so this
475:47 - is the main summary of Peterson
475:52 - solution okay so how does the process
475:55 - gets he was the last one to update if a
475:57 - process find out find out its ID and the
476:01 - value of turn is same then it is the
476:03 - last one to update so I have said said
476:06 - this thing several times I hope the
476:08 - thing is clear let me speak
476:10 - again P1 and P2 are two process P1
476:14 - should change the value of turn to one
476:16 - and P2 should change the value of turn
476:18 - to two in the end we finally see that
476:21 - the value of turn is two so which
476:24 - process do you think has updated the
476:26 - value of turn earlier p
476:29 - okay so this is clear in the next video
476:32 - we will see how this is a correct
476:35 - solution in the last lecture we have
476:37 - seen the implementation of Peterson
476:39 - solution in this lecture we will see why
476:41 - Peterson solution is a correct
476:44 - solution so initially two processes are
476:47 - in the ru p 0 and P1 and the value of
476:50 - flag is initialized to false which means
476:53 - in the beginning both the process are
476:55 - uninterested to go into the critical
476:57 - section pz is scheduled into the CPU at
476:59 - time T1 and P1 at time T2 so T1 at time
477:04 - T1 p 0 is in the CPU and I is equals to0
477:08 - and J equals to 1 which means the
477:10 - process which we are considering has the
477:13 - ID of zero and the other process has the
477:16 - ID one
477:17 - see in turn and in lock we have written
477:21 - two solutions for for p 0 different
477:24 - different code for P1 different code but
477:27 - here what we are doing we are have
477:28 - written this
477:29 - line that this is the code of whichever
477:32 - process we are considering and J is the
477:34 - other process Pi is the process which we
477:36 - are considering and J is the other
477:38 - process so in this case in this case
477:43 - which is pi p 0 and in this case which
477:47 - is Pi Pi is P1 so in this case we were
477:52 - considering p 0 and in this case we are
477:54 - considering P1 so whichever process we
477:56 - are considering I refers to that process
477:58 - ID and J is the process ID of other
478:01 - process so P0 has completed three
478:04 - sections non-critical section flag 0
478:07 - equals to True which means it has
478:10 - completed these three instructions these
478:12 - three
478:13 - instructions and it got preed here
478:16 - non-critical section changed the value
478:18 - of FL to true and turned to I which
478:20 - means zero so these three part are
478:23 - completed and it got preempted here now
478:26 - at time T2 P1 is scheduled so I = to 1 J
478:29 - = to 0 it does the similar thing
478:32 - non-critical section change the value of
478:34 - like to true and turn to
478:37 - one now you know that P1 was the last
478:42 - one to update the value of turn so it
478:44 - will
478:45 - bate check
478:48 - here when it will it has completed
478:52 - non-critical section change the flag to
478:54 - True did this turn equals to I now see
478:58 - when it will check this condition we are
479:00 - talking about the P1 when P1 will check
479:03 - this condition it will it will see that
479:05 - the other process is interested as P0
479:09 - has already completed this instruction
479:11 - so it will see the flag of P0 is true
479:15 - the flag of p 0 that is the flag of
479:17 - other process is true and the value of
479:19 - turn equals to one because this process
479:22 - has updated in the last so it will get
479:25 - stuck in this condition checking it will
479:27 - busy so which process will busy weight
479:30 - P1 will busy weit so it will be busy
479:32 - weting now at time D3 p 0 will join the
479:35 - CPU
479:36 - again now the value of I equal to 0 and
479:39 - J = to 1 I refers to the current process
479:41 - which is the current process zero so I
479:43 - will refer to the ID of the current
479:44 - process so I equals to Z and J equals to
479:46 - the other
479:47 - process what it will do
479:50 - now it will start from this p 0 will
479:54 - start from statement D because it got
479:56 - printted here and when process returns
479:59 - it will resume it will not restart so it
480:01 - will start from statement D it will
480:03 - check is the other process interested
480:06 - yes the other process is interested and
480:08 - what is the value of turn the value of
480:10 - turn is equals to J the value of turn is
480:12 - equals to J in the last turn equals to 1
480:15 - so the value of turn equals to J so it
480:17 - will not wait it will escape this
480:19 - waiting condition and enters the
480:21 - critical section enters the critical
480:25 - section okay so this is how Mutual
480:28 - exclusion is guaranteed when both
480:29 - process are interested so whichever
480:31 - process updates the value of turn in the
480:33 - last will
480:34 - beate c p 0 and P1 were both interested
480:37 - to go into the critical section and here
480:41 - we can see that one process has to busit
480:44 - so this is how Mutual exclusion is
480:45 - guaranteed when both the process are
480:48 - interested now we have a concept of flag
480:50 - if other process is not interested then
480:53 - it won't let the other process busy it
480:54 - because of her see
480:58 - busy waiting only happens when the other
481:01 - process is interested and the other
481:03 - process has updated the value of turn
481:06 - earlier than the current
481:09 - process I will speak this line again
481:12 - busy waiting only happens when the other
481:14 - process is interested and the other
481:18 - process has changed the value of turn
481:20 - earlier than the current
481:21 - process
481:23 - now in context to
481:26 - progress the other process will never
481:28 - change the value of flag to True see I
481:31 - have already said if a process is
481:33 - interested then only it will go to the
481:35 - entry section and the first statement of
481:37 - the entry section is change the value of
481:38 - true if a process is not interested it
481:40 - will never go to the entry section it
481:42 - will never change the value of flag to
481:45 - true so it will never let the other
481:47 - process busy weit so the progress is not
481:49 - hindered
481:50 - here I hope you are appreciating the
481:53 - beauty of Peterson solution so
481:57 - now we have concept of flag if other
481:59 - process is not interested then it won't
482:01 - let the other process busy because of
482:03 - it okay so non-interested process
482:07 - guaranteed progress now how the bounded
482:09 - weight is guaranteed let's say let's see
482:12 - from the
482:13 - code let's see from the code p 0 wants
482:17 - to enter critical section two times in a
482:18 - row can this happen or not let's check
482:21 - P0 completes non-critical section change
482:24 - the value of flag to True change the
482:25 - value of turn to zero now it's checks if
482:29 - flag J equals to true and turn equals to
482:32 - I initially let's
482:34 - say it escapes this condition because we
482:37 - are checking if it can enter the
482:38 - critical section two times in a row so
482:40 - let's assume it has entered first time
482:43 - completes the critical section completes
482:45 - the exit section change the value of
482:47 - flag to false now it wants to go again
482:50 - so what it will do completes the
482:52 - non-critical section change the value of
482:54 - flag to True change the value of turn to
482:56 - I so this is the critical thing change
482:59 - the value of turn to I which means
483:01 - change the value of turn to zero other
483:04 - interested process is there and the
483:06 - value of turn equals to zero which means
483:09 - it will busiate it cannot go again
483:11 - similar thing I have written here let's
483:14 - Z let's say p 0 completes critical
483:16 - section and it quickly completes its
483:18 - rest of the instruction to enter the
483:20 - critical section again while the other
483:22 - process is still waiting which means
483:24 - while the other process is interested
483:27 - okay which means the flag of other
483:29 - process is true is that possible no why
483:32 - because we have a concept of turn if p 0
483:35 - wants to go again it cannot go because
483:38 - let's say for the first time it
483:40 - completes the critical section completes
483:42 - the ex exit section now goes again to
483:47 - the entry section change the value of FL
483:49 - to True change the value of turn to
483:54 - zero you got this other process is
483:57 - interested and the value of turn is
483:58 - equals to Z see p 0 itself changed the
484:03 - value of turn to Z and in the next
484:05 - statement it checks whether the value of
484:07 - turn equals to zero or not it is zero
484:09 - and the other person is interested so it
484:11 - will buyit it cannot enter again because
484:15 - P0 was the last one to update the turn
484:17 - and the process which updates the turn
484:19 - in the last should be Z
484:21 - so did you see how intricately this is
484:24 - crafted this Peterson solution let's
484:28 - revise again so what we do in the peton
484:29 - solution we change the value of flag to
484:32 - true we change the value of turn equals
484:34 - to the idea of the process and checks if
484:36 - the other process is true if the flag of
484:39 - the other process is true which means
484:40 - other process is also interested and the
484:44 - value of turn equals to the I which
484:48 - means this process has updated the value
484:51 - of turn in the last which means this
484:52 - process should Bey okay so this is how
484:56 - Peterson solution guarant is mutual
484:58 - exclusion in the second case we have a
485:00 - concept of
485:01 - flag an uninterested process will never
485:05 - change the value of flag to True
485:07 - initially it is set to false an
485:09 - uninterested process will never go to
485:10 - the entry section and it will never
485:12 - change the value of flag to true that's
485:14 - why it will never hinder it will never
485:16 - hinder the progress of other interested
485:19 - process in the third bounded waiting we
485:22 - have a concept of turn which ensures
485:24 - that a process cannot go into the
485:26 - critical section two times in a row so
485:29 - that's why Peterson solution is a
485:31 - correct solution I hope now it is
485:40 - clear hi do you remember the problem
485:43 - which I have given you you have to tell
485:46 - whether this piece of code provides
485:47 - Mutual exclusion bounded waiting and
485:50 - progress or not so let's check line by
485:53 - line in turn equals to random I comma J
485:57 - so we are randomly assigning the value
485:59 - of turn to either I or J void process in
486:03 - I
486:05 - so this is the code of running process I
486:08 - refers to the running process and J
486:10 - refers to the process which is other
486:12 - than I J equals to not I the process
486:15 - which is not
486:16 - running while one noncritical section
486:20 - while turn is not equals to I so this
486:22 - can also be written as y turn equals to
486:24 - J so what does this line say it says if
486:27 - if it is the turn of another process
486:29 - then busy weit change the value of turn
486:33 - to J and what is J J is not I goes to
486:36 - the critical section again change the
486:38 - value of turn to J so this is the code
486:41 - now we are here to check whether this
486:43 - provide a mutual exclusion or not so do
486:45 - not have to read from this PDF I made a
486:47 - little mistake
486:48 - here read from
486:52 - this so what are the statements of the
486:55 - entry section initially the non-critical
486:58 - section then in the intersection we are
487:00 - checking if it is the turn of another
487:02 - process if yes then bate change the
487:05 - value of turn to J now I've told you
487:08 - that whenever there are Whenever there
487:09 - are two or more statements in the entry
487:12 - section then preempt in between to check
487:15 - M exclusion or deadlock or anything
487:18 - preempt in between so we are doing the
487:19 - same thing we are preempting in between
487:21 - p 0 is the process under consideration
487:24 - so the value of I equal to 0 and value
487:25 - of JAL to 1
487:28 - and we are seeing initially the value of
487:30 - turn is
487:31 - zero p 0 completes the non-critical
487:34 - section now checks the condition while
487:37 - turn is not equals to
487:39 - zero well the value of turn is equals to
487:41 - zero so this condition is false do not
487:45 - vate escapes this condition and here it
487:48 - got preempt preempt just before turn
487:51 - equals to
487:52 - one okay so whenever the process comes
487:54 - back it will start with turn equals to
487:56 - one okay
487:58 - now comes P1 so now P1 is the process
488:02 - under consideration so the value of I
488:04 - will be 1 and value of J will be zero
488:06 - completes the non-critical section tries
488:09 - to enter into the critical section so
488:11 - firstly it have to go into the entry
488:13 - section now the value of turn equals to
488:15 - Z checks while turn is not equals to 1
488:18 - yes turn is not equals to 1 it is equals
488:20 - to Z the condition is true B
488:24 - it so it is not able to enter into the
488:27 - critical section while this process can
488:32 - enter so here we can say Mutual excution
488:35 - is guaranteed but but have you checked
488:39 - the traditional way what was the
488:40 - traditional way what was the definition
488:43 - the definition is two process should not
488:46 - be into the critical section at the same
488:48 - time
488:49 - so what what are we doing we are letting
488:51 - one process enter into the critical
488:53 - section and there we are preempting it
488:56 - and we will see that if another process
488:58 - can also enter into the critical section
489:00 - or
489:01 - not so at time T1 P0 is the process in
489:06 - the consideration I = to 0 Z = to 1 turn
489:09 - equals to 0 initially completes the
489:11 - non-critical section why turn equals 2
489:13 - equal to 1 no no this is false escapes
489:16 - the busy weight change the value of turn
489:18 - to
489:19 - one goes to the critical section gets
489:22 - preempted
489:23 - here now the value of turn is 1 okay p 1
489:27 - is the process let's say at time T T2 P1
489:29 - is the process into the consideration I
489:31 - = 1 J = to 0 completes the non-critical
489:34 - section while turn equals to equals to
489:37 - zero is this true no this is false turn
489:40 - equals to one so it will not busy weight
489:42 - goes to the next statement turn equals
489:45 - to0 enters the critical
489:47 - section when p 0 is in critical section
489:50 - when p 0 is in critical section no one
489:52 - is there to stop P1 from entering so
489:56 - here we can say m Mutual exclusion is
489:58 - not guaranteed let's check for
490:01 - Progress so we are randomly initializing
490:04 - the value of I and J let's say the value
490:07 - of turn is value of turn is
490:10 - J as we can as it is randomly
490:13 - initialized so we can say we can
490:15 - initialize the value of turn to anything
490:16 - either I or J okay so let's say the turn
490:20 - turn is initialized to J which means it
490:22 - is the turn of process J to enter
490:24 - critical section but process J is not
490:28 - interested not interested to enter
490:30 - critical
490:31 - section if it is not interested it is
490:34 - never going to change the value of turn
490:36 - to another
490:39 - process so the progress is hindered
490:42 - progress now turn let's say the value of
490:46 - turn was J so pi and PJ are two process
490:48 - in the RQ PJ is the not process which is
490:51 - not interested for critical section so
490:54 - Pi will get stuck in the v loop as PJ
490:57 - will never enter into the critical
490:59 - section so the value of turn equals to I
491:01 - will never happen so the progress is
491:03 - hindered here what about bounded waiting
491:06 - can a process enters into the critical
491:08 - section two times in a row if yes then
491:11 - the waiting is
491:12 - unbounded let's see let's see p 0 is the
491:17 - process goes into critical section so
491:19 - here I equal to 0 and Jal to 1 goes into
491:21 - the non-critical section while false
491:24 - because let's say the turn equals to Z
491:27 - zero in the beginning so is it the turn
491:29 - of another process no condition becomes
491:33 - false now the value of turn is changed
491:35 - to one so what does this say it is the
491:39 - turn for another process to
491:41 - enter so when the when after completing
491:45 - all these steps when p 0 trying to enter
491:47 - again into the critical section there it
491:49 - will get stuck in the busy weight Loop
491:52 - because the value of turn has been
491:54 - changed to one so P0 cannot enter into
491:57 - the critical section so the bounded
491:59 - waiting is
492:01 - guaranteed so I hope you now know how to
492:04 - get how to infer from a piece of code
492:07 - that either bounded waiting Mutual
492:09 - exclusion or progress is guaranteed or
492:11 - not
492:13 - okay in the at the last time for the
492:15 - last time I should use better
492:17 - prepositions for the last time let's see
492:20 - the formal definitions of all these
492:21 - things all these requirements Mutual
492:24 - exclusion I'm just going to read it you
492:25 - all know the meaning of all things them
492:27 - just for the formal sake this property
492:31 - ensures that if a process is executing
492:33 - in its critical section then no other
492:35 - process can execute in their critical
492:37 - section okay this property ensure that
492:40 - if no process is executing in its
492:42 - critical section and there exist some
492:44 - process that wish to enter their
492:45 - critical section then selection of the
492:47 - process that will enter the critical
492:49 - section next cannot be postponed
492:53 - indefinitely this is progress and
492:55 - bounded waiting this property ensures
492:57 - that there exist a bound or limit on the
492:59 - number of times there exist a bound or
493:02 - limit on the number of times that other
493:05 - process are allowed to enter into their
493:07 - critical sections after a process has
493:09 - made a request to enter into critical
493:11 - section and before that request is
493:14 - granted so what does bounded waiting say
493:17 - that a process should not be allowed or
493:20 - there should be a
493:22 - limit on the number of process going
493:24 - into the critical section again and
493:26 - again if there exists some another
493:29 - interested process and what does
493:31 - progress say progress says that an
493:34 - uninterested process should not hinder
493:37 - or should not block the interested
493:40 - process and what does mutual exclusion
493:41 - say you all know there should not be two
493:43 - or more process in the critical section
493:48 - okay so in the next lecture we are going
493:49 - to start dear's
493:53 - algorithm hope you all remember Peterson
493:55 - algorithm in this Le we are going to see
493:58 - the optimized version of Peterson
493:59 - algorithm that is D's algorithm and it
494:02 - is a correct algorithm too it provides M
494:05 - exclusion bounded waiting and progress
494:08 - so how does it work let's see void
494:11 - Deckers algorithm in I so I is the
494:14 - process under consideration and J is the
494:16 - other process
494:19 - okay while one non-critical section so
494:23 - let me give you a
494:25 - situation this is u this is the other
494:28 - process you are process I and your
494:31 - friend is the process J so both are
494:33 - friends so what happens there is a TV
494:36 - screen here which gives the value of
494:38 - turn variable so what
494:41 - happens you loudly say I am interested
494:44 - to go into the critical section so what
494:47 - you do you change the value of flag I to
494:51 - true but you also check at your friend's
494:54 - face he also seems interested to go into
494:57 - the critical section so what do you
494:59 - check you check whether your friend is
495:02 - interested to go to the critical
495:07 - section if he is interested then what
495:10 - you will do you will look at the TV
495:12 - screen of
495:13 - turn if it is the turn of your friend to
495:16 - go into the critical section what you
495:18 - will do you will become a good man you
495:21 - will say okay my friend should go into
495:24 - the critical section I am an
495:26 - uninterested for now I am uninterested
495:28 - for
495:29 - now so we'll change the value of your
495:32 - flag to false and you will say I will
495:36 - wait until it's my turn to enter into
495:39 - the critical section so until the turn
495:43 - equals to equals to J you are going to
495:45 - busy wait and as soon as as soon as at
495:48 - the TV screen you say it's my turn to go
495:51 - into the critical section what you will
495:52 - do you will change your flag to
495:55 - interested or true through you'll go
495:58 - into the critical
495:59 - section and when you comes out it is
496:02 - your responsibility to say okay I have
496:05 - done my work now I am un interested to
496:07 - go into the critical section my friend
496:09 - you can go will change the value of
496:11 - false and you will say the value of turn
496:13 - will be equals to J so this is how
496:16 - Decker's algorithm
496:18 - work okay so let's read the full code
496:21 - Decker's algorithm vo Decker in i j is
496:24 - the other process I is the process under
496:25 - consideration completes the non-critical
496:27 - section you say hey I am interested but
496:30 - you will also look at your friend's face
496:32 - if he also seems interested and then you
496:35 - look at the TV screen of turn the turn
496:38 - suggest that J should go so you will
496:40 - become a good man you will say hey my
496:43 - friend you can go I am uninterested for
496:45 - now and I will wait until it's my turn
496:47 - to go into the critical section and as
496:49 - soon as your turns appear uh or your ID
496:52 - appears at the TV screen you say now I
496:54 - am interested to go into the critical
496:55 - section you goes to the critical section
496:58 - after the completion of critical section
496:59 - you say now I'm uninterested my friend
497:02 - you can go it's now your
497:05 - turn I hope dear algorithm is clear now
497:09 - now we'll see why dear algorithm is
497:11 - correct algorithm let's check for Mutual
497:13 - exclusion the algorithm uses two Boolean
497:15 - variable flag I and flag J to indicate
497:18 - if a process wants to enter critical
497:19 - section it also users turn to decide
497:22 - which process can enter critic section
497:23 - when both want to this ensure that only
497:26 - one process can enter into a critical
497:27 - section providing Mutual
497:30 - exclusion so the mutual exclusion is
497:32 - guaranteed now let's check for Progress
497:34 - if a progress doesn't want to enter the
497:35 - critical section it sets its flag as
497:38 - false this allow other process to enter
497:40 - critical section if it wants to this
497:42 - ensure that if a process GS to ENT
497:44 - critical section it eventually will
497:46 - providing progress
497:49 - see initially the value of flag is false
497:53 - for both the process and I have said
497:56 - that a process will enter into the entry
497:59 - section only when it is interested to go
498:01 - into the critical section so it will
498:03 - never change its value to
498:06 - true the value of flag will always
498:08 - remains false and if the value of flag
498:11 - will always remains false it will never
498:13 - going to bate the other process so the
498:17 - progress is guaranteed because the value
498:19 - of flag will never be set to true if a
498:22 - process doesn't enter the entry section
498:25 - and an uninterested process never ever
498:27 - enters the ENT section bounded waiting
498:30 - the turn variable ensures that the
498:32 - process alternately enter the critical
498:35 - section and they both want to enter c
498:37 - here whenever it completes the exit
498:39 - section the turn is set to J and if it
498:41 - tries to go again it will stuck here
498:45 - okay so process cannot enter the
498:48 - critical section two times in a row in
498:49 - bounded waiting okay so I hope the point
498:53 - is clear how deer algorithm is correct
498:55 - it provides Mutual exclusion progress
498:56 - and bounded waiting we have completed
498:59 - the software solution for
499:01 - synchronization the lock variable the
499:04 - turn variable that is a strict
499:05 - alternation Peterson solution and
499:08 - Decker's
499:09 - algorithm in this lecture we are going
499:12 - to start the new topic synchronization
499:15 - using Hardware but before that let's
499:17 - discuss some problems so there are two
499:20 - process P1 and P2 that need to access
499:23 - critical section of the code consider
499:25 - the following synchronization con
499:27 - used by these process and you have to
499:29 - tell whether they provide mutex progress
499:32 - mutex means Mutual exclusion progress
499:35 - bounded waiting and
499:38 - Deadlock okay
499:41 - so for the mutex let's discuss the two
499:45 - condition the first is preempt in the
499:47 - critical section and see if the other
499:49 - process is also able to enter into the
499:52 - critical section or not the other one is
499:54 - preempt in between the two state M of
499:57 - Entry section so let's check for the
499:58 - critical section first there are two
500:01 - variable want one and want two initially
500:06 - set to
500:08 - false now let's see what happens want 1
500:11 - equals to True here in this code wants 1
500:14 - equals to true so I'm going to change
500:16 - the value to
500:17 - True while wants two equals to true no
500:21 - this is false so we are not going to
500:22 - busy weit enter into the critical
500:24 - section preempt here
500:27 - let's go to the second process wants 2
500:31 - equals to true so we are changing the
500:32 - value of wants two to true
500:37 - now while want 1 equals to True is it
500:40 - true yes it is true so it is going to
500:42 - Vis it it won't be able into the it
500:45 - won't be able to enter into the critical
500:47 - section now we will check the second
500:50 - condition that is preempt here want 1
500:53 - equals to True preempt wants two equals
500:55 - to true so this is the the case
500:57 - now go here while wants to equals to
501:01 - True yes it is true so it is going to
501:04 - busy go here now while wants 1 equals to
501:07 - True yes it is true so it is also going
501:09 - to both process are busy
501:12 - waiting this is the case of dat log let
501:16 - me explain
501:17 - again first this statement wants one
501:20 - equals to true then this statements 1 to
501:23 - equals to true then this statement and
501:25 - then this so both are busy waiting both
501:28 - get blocked so this is the case of
501:30 - Deadlock so deadlock is present Mutual
501:33 - exclusion is also guaranteed now check
501:36 - for
501:38 - Progress let's see P2 is the process
501:40 - uninterested to go into the critical
501:42 - section so initially the value of want
501:44 - one and want two is set to false and P2
501:47 - is the process that is not interested to
501:49 - go into the critical
501:50 - section if P2 is not interested can it
501:54 - block P1 to go into the critical section
501:57 - if P2 is not interested it will never
501:59 - change its value to true and if the
502:02 - value of want to is never true then P1
502:06 - is never going to beate so progress is
502:09 - also guaranteed an uninterested process
502:12 - is not hindering or blocking the
502:14 - interested process to enter into the
502:16 - critical section so progress is also
502:19 - guaranteed Mutual exclusion guaranteed
502:22 - progress guaranteed deadlock also
502:23 - guaranteed check for the bounded waiting
502:26 - for bounded
502:28 - waiting see if a process can enter into
502:30 - the critical section two times in a row
502:33 - wants 1 equals to True while one two
502:36 - equals to True initially the one two is
502:39 - false so it enters into the critical
502:41 - section now want to equals to
502:45 - false
502:46 - okay now wants to equals to false it was
502:49 - initially False only so this is true
502:53 - once one has become true and this is
502:55 - false it tries to go again want one is
502:58 - true change the value to True is want to
503:00 - equals to true no it is false enters
503:03 - into the critical
503:04 - section now change the value of one two
503:06 - to false again tries to go again wants
503:09 - two equals to True yes it is true is the
503:12 - value of one 22 true no it is false so
503:14 - it enters again a process can enter
503:18 - again and again into the critical
503:19 - section while other interested process
503:21 - is waiting so bounded waiting is not
503:24 - guaranted if it was the case of strict
503:26 - alternation then bounded waiting will
503:29 - also be present and for case of a strict
503:32 - alternation they never have deadlock the
503:34 - case of Deadlock will never be present
503:36 - in the case of strict alternation okay
503:39 - let's let's see another question
503:41 - variable P equals to false variable Q
503:43 - equals to false code for process X is
503:45 - given for process Y is given you have to
503:48 - tell is there any possibility of
503:50 - Deadlock does this guarantee Mutual
503:52 - exclusion this is an homework question
503:54 - and easy one you can do this on your own
503:56 - let's move to the synchronization
503:59 - Hardware so each processor supports some
504:01 - special Hardware instructions that are
504:03 - Atomic in
504:04 - nature okay so do you mean what do you
504:07 - mean by atomic Atomic means that they
504:10 - cannot be preempted until they gets
504:12 - completed it's just like the kernel mode
504:14 - instructions okay so these
504:17 - instructions these special instructions
504:19 - are Atomic in
504:21 - nature so we are discussing about TSL
504:24 - and swap instruction
504:27 - they are also based on busy waiting and
504:29 - they can be used at user mode as a
504:31 - special instructions so they are they
504:34 - are being used as user mode only but
504:36 - they are special instructions hence
504:38 - Atomic in
504:41 - nature they belong to the hardware
504:43 - category and it is a multi-process
504:45 - solution see lock variable was a
504:48 - multiprocess solution turn variable was
504:49 - a two process solution Peterson was a
504:51 - two process solution deers was a two
504:53 - process solution this TSL and swep we
504:55 - will see it later
504:57 - later these are multiprocess solution
504:59 - this Hardware solution TSL and swap are
505:01 - multiprocess solution what are they we
505:03 - are going to see in the next lecture and
505:05 - it is a lock based solution lock based
505:09 - solution do you know the full form of
505:11 - TSL test and set lock so these are the
505:14 - lock based solution this is just an
505:16 - introduction video we are going to see
505:18 - them in detail you in this lecture we
505:20 - are going to start our first
505:22 - synchronization Hardware mechanism that
505:24 - is TSL TSL stand for test and set lock
505:29 - so what does it do let me tell in brief
505:31 - DSL takes a parameter lock m% loog that
505:35 - is the address of lock so what does TSL
505:38 - do TSL Returns the current value of lock
505:41 - let's say initially the loog
505:44 - is set to the loog is set to
505:47 - false so what does TSL will return TSL
505:50 - will return the value as false and then
505:53 - it will change the value of log to true
505:57 - so what does TSL do TSL Returns the
506:00 - current value of log and set the value
506:02 - of log to True okay so this is what I
506:04 - have written TSL M loog process
506:07 - executing TSL Returns the current value
506:10 - of log and sets the value of log always
506:13 - to true so first it will read the
506:14 - current value and write the current
506:16 - value to
506:17 - True okay so whatever be the value
506:20 - either true or false this will be
506:22 - returned and then the value of log will
506:24 - be changed to true
506:26 - so this is what TSL does now before we
506:30 - are going to see how TSL is going to
506:32 - solve the critical section problem we'll
506:34 - first see how TSL works so what is the
506:36 - function behind TSL bull TSL why bull
506:40 - because TSL returns a boan variable
506:42 - either true or false I have said first
506:44 - it will return it Returns the current
506:46 - value of loog so what does loog contain
506:48 - either true or false so firstly it will
506:51 - return so return type will be
506:54 - Boolean Bo
506:57 - esteric Target so here we have written
506:59 - m% lock and here we have written esteric
507:01 - Target so Target is a pointer pointing
507:03 - to the lock here we are using passing by
507:05 - reference so Target is a pointer
507:08 - pointing to the lock what does return
507:11 - Value Store bu return value return value
507:13 - is going to store the current value of
507:15 - lock let's say let's discuss the
507:18 - previous example which I have given so
507:21 - according to that previous example the
507:22 - return value of lock will be false
507:29 - and so let me write it again so
507:32 - initially the value of log was set to
507:35 - false okay so return value is going to
507:38 - store the value of log that is false so
507:40 - return value will store false and then
507:43 - set the value of log to true so we are
507:45 - going to set the value of log to true
507:48 - and return the return value what is the
507:50 - return return value false so what does
507:52 - it will return TSL will return false and
507:55 - will set the value of log to True okay
507:58 - so this is how TSL work now last
508:02 - statement which I am going here to made
508:03 - before we will see how this solves the
508:05 - critical section problem is these three
508:08 - instruction will execute atomically no
508:11 - preemption so it Returns the value of
508:14 - log and set it to true and this is done
508:17 - atomically okay so let's see how this
508:20 - solves the critical section
508:22 - problem initially let's set the value of
508:24 - log to false void process in I while one
508:28 - now see non-critical section is executed
508:31 - and then while TSL M percent loog is
508:35 - equals to is equals to true this is
508:37 - entry section critical section and then
508:39 - set log to false let's see how how it is
508:42 - going to solve the critical section
508:44 - problem there are two process in the RQ
508:46 - P1 and
508:48 - P2 okay P1 P1 firstly scheduled at CPU
508:53 - start executing the critical section P1
508:56 - is still in the critical section and it
508:58 - gets preempted now P2 comes now P2 is in
509:01 - the CPU let's check whether P2 can also
509:04 - enter into the critical section or not
509:07 - if it is capable to enter into the
509:09 - critical section this DSL is not going
509:11 - to provide the mutual exclusion let's
509:13 - see whether it is capable or not so
509:16 - initially when the P1 wants to enter
509:18 - critical section what it has to do it
509:20 - has to First execute the noncritical
509:22 - section it will check whether the value
509:25 - which TSL return is true or not so
509:27 - initially the value was false so what
509:29 - does TSL will do TSL will change the
509:32 - value of log to true and Returns the
509:34 - current previous value what was the
509:36 - previous value false so it will return
509:37 - false is false equals to true no it is
509:40 - not hence it will go into the critical
509:42 - section it was still in the critical
509:44 - section before it got preempted so P1 is
509:49 - still in the critical section now P2 got
509:51 - scheduled let's check whether P2 is also
509:53 - capable executes the non-critical
509:55 - section while TSL M m% log what does TSL
509:59 - do TSL Returns the current value of log
510:01 - what is the current value of log true so
510:03 - it will return true and sets the value
510:05 - of log to true so it return true is true
510:08 - equals to True yes it is true so it will
510:11 - keep on visting visting and visting
510:14 - until until P1 completes the critical
510:17 - section goes to the exit section change
510:20 - the value of log to fals so it will
510:22 - change the value of log to FS now when
510:24 - P2 will get hold of CPU when P2 will be
510:28 - in the CPU it will resume resume from
510:30 - where from here now it will see
510:33 - TSL Returns the current value of log
510:35 - what is the current value of log false
510:37 - is false equals to true no it is not now
510:40 - it can go into the critical section so I
510:42 - can make a statement P2 can go into the
510:45 - critical section only when P1 has
510:47 - completed its exit
510:50 - section so it guarantees Mutual
510:53 - exclusion does it guarantees progress
510:56 - yes it guarantees progress how because
510:59 - let's say there are two process P1 and
511:00 - P2 P1 is not interested to go to the
511:04 - critical section so a process which is
511:05 - not interested to go to the critical
511:07 - section will never ever visit the entry
511:09 - section so the value of lock will be
511:12 - never changed to true it will remain
511:15 - false so when P2 tries to enter false is
511:19 - not equals to true it will easily Escape
511:21 - The Waiting condition so P1 is not
511:23 - hindering P1 is uninterested process so
511:26 - uninterested process not hindering the
511:28 - way of interestate process hence
511:30 - progress is guaranteed non-interested
511:33 - process will never change the value of
511:34 - log to
511:36 - ro
511:37 - okay now comes the now comes the
511:41 - scenario of bounded waiting is bounded
511:44 - waiting satisfied I think it's not why
511:46 - let's see P1 completes the critical
511:49 - section goes to the TSL initially the
511:52 - value of lock was false so when this
511:55 - will be executed this DSL it will change
511:57 - the value of log to true but it will
511:59 - return the current value as false so
512:00 - false is not equals to True easily
512:02 - escapes the critical section goes to the
512:04 - ENT section it will change the value
512:06 - goes to the exit section it will change
512:08 - the value to false again try to
512:10 - go what does TSL will return it will
512:13 - return the current value that is false
512:15 - false is not equal to True will again
512:17 - Escape The Waiting condition hence P1
512:20 - can go into the critical section again
512:22 - and again while P2 is still waiting so
512:25 - P1 will l in the face of P2 but P2 can
512:29 - do nothing so bounded waiting is not
512:31 - guaranteed but I have seen in this logic
512:35 - bounded waiting is not guaranted but in
512:37 - galin textbook so which textbook
512:39 - textbook are we referring to we are
512:41 - referring to galin so in galin textbook
512:43 - they have added additional logic in TSL
512:45 - which will make it right like a round
512:47 - robin so first P1 will go it will
512:49 - execute for some time and then P2 will
512:51 - go so in this manner a a type of turn is
512:55 - introduced P1 P2 P1 P2 it's it's like a
512:58 - round robin so they have added
513:00 - additional logic and if that additional
513:03 - logic is there then it will ensure
513:05 - bounded weight but here in the basic
513:07 - logic bounded weight is not ensured P1
513:10 - can go into the critical section again
513:12 - and again so if you are interested you
513:13 - can just go to the Galvin textbook read
513:15 - the additional logic and try to
513:17 - understand okay but here in the uh the
513:20 - case which we are talking about bounded
513:22 - weight is not initialized P1 can go into
513:24 - the bounded weight is not there not
513:26 - present P1 can go into the critical
513:28 - section again and again okay so I hope
513:31 - how TSL work is clear in the next
513:33 - lecture we are going to see the swep
513:36 - mechanism let us start the swap
513:39 - mechanism this is based on lock in key
513:41 - mechanism so what does I refer here to
513:43 - we'll see later but let's first see the
513:46 - introduction part swap mechanism based
513:48 - on lock and key and it is atomic in
513:50 - nature so this web function this will
513:53 - make sure that these three instructions
513:54 - will be ex executed atomically so what
513:57 - does are the these three instruction
513:59 - these three instructions are for
514:01 - swapping the values stored in the
514:02 - variable A and B so why are we using
514:05 - here the call by reference not directly
514:07 - because we want the changes to reflect
514:09 - into the original data also we are
514:12 - changing inside a function we also want
514:16 - that original data should also be
514:17 - changed that's why we are using call by
514:19 - reference if you don't know call by
514:20 - reference it's your homework to
514:22 - understand how call by reference work
514:25 - okay
514:26 - so let's first understand how spping
514:29 - work for swapping what we have to do we
514:31 - have to use a temporary variable
514:33 - otherwise the value of one variable will
514:35 - be lost what I am saying here is let's
514:37 - see this is variable a this is variable
514:39 - B it is stored value five it store value
514:42 - 7 now I want to swap the values of A and
514:45 - B let's say I want seven here and five
514:47 - here how can this be achieved let's see
514:51 - okay I cannot directly store the value
514:53 - of a into B I cannot directly write here
514:55 - five otherwise the seven will be
514:57 - gone okay so first we have to store the
515:00 - value of s into a temporary variable
515:03 - before changing the value of B so we
515:06 - have stored the value of B into some
515:08 - temporary variable T now this can be
515:10 - overridden and here the value of T will
515:14 - be stored back to a so this is how
515:15 - swipping is done let's see
515:18 - here we are defining a temporary
515:20 - variable we store the value of a into
515:22 - the temporary variable now the value of
515:24 - a is safe I can directly store the value
515:28 - of B into a the value of a is already
515:32 - safe now the B value of B is stored in a
515:35 - and then the value of a indirectly I'm
515:39 - saying the value of a is now stored in B
515:41 - so value of B is stored in a and value
515:43 - of a is stored in B this is how swipping
515:45 - is done using a temporary
515:48 - variable now you got how spping is done
515:51 - let's
515:52 - see how this spping is useful in solving
515:55 - the critical section problem set the
515:58 - value of lock to false initially the
516:00 - value of lock that is a global variable
516:02 - is set to
516:03 - false void process in I P1 let's say P1
516:07 - is the
516:08 - process and has a value of key to True
516:12 - initially we have set the value of key2
516:15 - true P now P1 wish to enter into the
516:17 - critical section so what it will do it
516:19 - will first execute the non-critical
516:21 - section goes to statement B while key
516:24 - equals to equals to true it will check
516:26 - whether key equals to True yes it is
516:28 - true it will enter into the V Loop swap
516:30 - the value of lock in key now we have to
516:33 - exchange the value of lock and key lock
516:34 - will become
516:35 - true and key will become
516:38 - false as it is a vop it has to go check
516:41 - the condition again the value of key is
516:44 - true no the value of key is false so it
516:46 - is going to escape this while loop goes
516:48 - to the critical section now we wish to
516:52 - now we wish that this spping mechanism
516:53 - solve the critical section problem so so
516:55 - we are going to check when P1 is in the
516:58 - critical
516:59 - section does another process also enters
517:03 - is another process capable to enter into
517:04 - the critical section that we are
517:06 - checking so we will preempt in the
517:08 - critical section so P1 is still in the
517:10 - critical section P2 wish to
517:13 - enter what is the value of lock lock is
517:16 - true now P2 wish to enter so this is P2
517:21 - and I have said initially the value of
517:23 - key in process is true
517:26 - P2 completes the non-critical section is
517:28 - the value of key to is true yes it is
517:30 - true it will swap the value of key and
517:33 - lock the value of key and lock will be
517:35 - swed so true will be here and true will
517:38 - be here the value of Key and Lock is
517:41 - swapped but the keys is still true so
517:44 - when it is going to check the condition
517:46 - again it has to swap again the value of
517:49 - login key so it is going to it is just
517:51 - swipping the value again and again
517:53 - checking the condition swipping the
517:54 - value
517:56 - busy weight busy weight until the value
517:59 - of log becomes false and how can value
518:01 - of log become false when P1 completes
518:05 - the critical section executes the exit
518:07 - section now value of loog has been
518:09 - changed to
518:10 - false now if P2 wish to enter see in now
518:15 - presently no one is the no one is in the
518:16 - critical section now P2 wish to enter
518:18 - the value of lock has been changed to
518:20 - false by P1 exit section so P2 will
518:24 - start here check check does the value of
518:26 - key is equals to True yes it is equals
518:29 - to True swap the value of lock and key
518:31 - so it will swap this will become false
518:33 - and this will become true now it is
518:35 - going to check the condition again is
518:37 - the value of key true no it is false so
518:39 - it will escape now it can enter easily
518:41 - into the critical section but what a
518:44 - statement I can make here the mutual
518:46 - exclusion is
518:49 - guaranteed see here P1 completes non-
518:51 - critical section key equals to True swap
518:53 - the value now lock is true key is false
518:55 - enters critical section got preempted P2
518:58 - is to enter completes non-critical
518:59 - section key is true swap the value of
519:02 - lock in key but it has to CH it has to
519:05 - check the condition again key is true
519:07 - yes swap the value key is true yes swap
519:09 - the value key is true yes swap the value
519:11 - until P1 completes its exit section
519:13 - change the value of lock now when it
519:16 - will swap the value the key will become
519:19 - false and lock will true now when it's
519:21 - going to check the condition the key is
519:23 - false so now it can enter into the
519:25 - critical section only when P1 completes
519:28 - the critical section so we can say
519:29 - Mutual exclusion is guaranteed P2 is
519:31 - unable to enter into the critical
519:33 - section when P1 was present
519:36 - there does it guarantee progress yes
519:38 - progress is guaranteed as no
519:40 - uninterested process will change the
519:41 - value of lock not blocking the other
519:44 - process
519:46 - okay in particular the code could lead
519:48 - to the situation known as starvation if
519:50 - one process quickly finish its critical
519:52 - section and re-enters it before the
519:54 - other process it has it chance to set
519:55 - lock it could potentially keep
519:57 - re-entering the critical section
519:58 - indefinitely while the other process
519:59 - Waits unboundedly so here I can also say
520:01 - that bounded waiting is not guaranteed a
520:04 - process can enter into the critical
520:05 - section again and again again and again
520:07 - by setting the value of log to
520:09 - false okay see to enter into the
520:12 - critical section what is the major thing
520:13 - required the value of log should be
520:15 - false critical section should not be
520:19 - logged the value of log should be false
520:21 - so a process can change the value of log
520:23 - to false in its EX in it exit section
520:26 - and can enter into the critical section
520:28 - again and again while other process is
520:30 - waiting so bounded waiting is not
520:33 - guaranteed but similar to the TSL if
520:37 - additional logic is added then bounded
520:39 - waiting can be guaranteed but here in
520:41 - this case bounded waiting is not
520:42 - guaranteed so this was swap mechanism it
520:45 - guarantees Mutual exclusion progress but
520:48 - fail to guarantee bounded w
520:58 - so we have completed test and set and
521:02 - swep mechanism let's see a problem on
521:04 - this enter critical section and leave
521:07 - critical section functions are there to
521:08 - implement the critical section of a
521:09 - process and are realized using test and
521:12 - set
521:13 - instruction X is initialized to zero
521:15 - which says critical section is free so
521:18 - when test and set X will be executed it
521:20 - will return the value of x and will set
521:22 - to one which says critical section is
521:23 - busy so this is similar to the test and
521:26 - set which we have studied now based on
521:28 - this try to solve or try to guess which
521:32 - of the following four options is
521:34 - correct so the first says the about
521:37 - solution of critical section is deadlock
521:38 - free yes test and set is deadlock
521:41 - free the solution is starvation free no
521:43 - this is false because a process can
521:45 - enter into the critical section any
521:47 - number of times while some other process
521:49 - is waiting other process is starving so
521:52 - starvation free this is false starvation
521:55 - can be present the process enters
521:57 - critical section in feif folder no this
521:59 - is false there's no no restriction for
522:01 - process to enter only in folder they can
522:03 - enter in any order fourth more than one
522:06 - process can enter critical section at
522:08 - the same time no test and set log
522:10 - successfully provide Mutual exclusion so
522:12 - only option one is
522:14 - correct now an interesting problem that
522:17 - is priority inversion problem see if
522:20 - someone ask you an interview which is a
522:23 - high probability give me a best example
522:25 - of
522:27 - Deadlock give me a best example of
522:29 - Deadlock then you are going to say this
522:32 - priority inversion problem this has
522:34 - happened in one of a NASA's Mars project
522:37 - finder project so what happened
522:40 - that let me explain you in
522:43 - brief there are two process PL and pH PL
522:47 - refers to the low priority process and
522:49 - pH refers to the higher priority process
522:51 - so all correct busy waiting Solutions
522:53 - suffer from Priority inversion problem
522:55 - and this problem is only when we are
522:58 - using preemptive priority based
522:59 - scheduling I hope you all recall what is
523:01 - preemptive priority based
523:03 - scheduling so initially PL was there PL
523:07 - got to the CPU went to the entry section
523:10 - completed entry section was executing
523:12 - the instructions of critical section but
523:14 - suddenly it sees
523:16 - that there is a high priority process
523:19 - present in the ricu so it has to leave
523:21 - it has to leave CPU go back into the
523:23 - ricu now pH is entering into the CPU pH
523:27 - is in the CPU pH says I wish to enter
523:30 - into the critical section
523:31 - 2 tries to enter into the critical
523:34 - section but denied why because PL is PL
523:37 - is already present pH feels bad I am the
523:41 - process with higher priority how can pH
523:44 - remain in critical section when I am I
523:46 - want to enter PL Hey listen PL you
523:48 - should leave the critical section
523:51 - immediately PL says listen sir the thing
523:55 - is I cannot complete my instructions
523:57 - until you leave the CPU so that I can
524:00 - complet my complete my remaining
524:02 - instruction of critical section exit and
524:05 - then you can go to the critical section
524:07 - till I am in the critical section you
524:09 - cannot enter into the critical section
524:11 - PL says how dare you to talk me to talk
524:13 - to me like this I am the process with
524:15 - the higher priority I am not leaving the
524:17 - CPU PL also says okay go and try try to
524:20 - enter to critical section if you can I
524:22 - am not leaving the critical section as
524:24 - well
524:25 - so pH is waiting for PL to enter
524:27 - critical section PL is waiting for pH to
524:30 - leave CPU so that it can complete the
524:32 - remaining instructions of critical
524:33 - section pH is waiting on PL PL is
524:36 - waiting on ph deadlock perfect example
524:38 - of
524:39 - Deadlock so let me read pH is also
524:43 - interested into critical section but it
524:45 - it cannot be allowed no matter how high
524:47 - the priority is it cannot be allowed
524:50 - until there is some process present in
524:51 - the critical section so pH cannot be
524:53 - allowed to enter section until P1
524:56 - completes and for completion PL needs
525:00 - CPU pH won't leave CPU because of its
525:03 - ego so there are the they present the
525:06 - conflict of two principles the first is
525:08 - priority and the second is of mutual
525:10 - exclusion priority says a low process a
525:13 - low priority process should leave
525:14 - whenever a high priority process come
525:16 - Mutual exclusion says there should be
525:18 - only a single process into critical
525:20 - section pH cannot enter into the
525:22 - critical section until PL leaves
525:25 - both will be adment do you know the
525:27 - meaning of adment the adment means
525:31 - stubborn stubborn both are stubborn to
525:33 - leave this causes
525:36 - deadlock so I have given you if I have
525:38 - already told you if someone in the
525:40 - interview ask you example of Deadlock
525:42 - this is the best one this problem
525:43 - occurred in the NASA's Mar Mars
525:46 - Pathfinder project so what is the
525:48 - solution the solution of the problem is
525:51 - priority inheritance see the thing is
525:53 - you can drive the inter VI the way you
525:56 - speak let's say it has started with tell
526:00 - me your favorite subject and then you
526:01 - say operating system they ask what is
526:03 - deadlock you give the definition of
526:05 - Deadlock now they ask can you give me an
526:08 - example then you say yes I can give you
526:10 - an example and you give this perfect
526:12 - example this priority inversion problem
526:15 - first thing is the interview will be the
526:17 - interviewer will be very much impressed
526:20 - and the second thing is he will ask what
526:22 - is the solution then then you are going
526:24 - to say priority inheritance PL will
526:28 - inherit the priority of pH and vice
526:30 - versa for PL so what
526:33 - happens when this uh when this type of
526:35 - problem occurs then that uh a low
526:38 - priority process is present in the
526:39 - critical section and a high priority
526:41 - process has occupied CPU then we have to
526:45 - invert the
526:46 - priority PL will get the priority of pH
526:49 - so what will happen now pH will leave PL
526:53 - will come PL will execute the
526:55 - instructions and then when the critical
526:57 - section will be over it will execute the
527:00 - exit section and then it will get its
527:02 - own priority back now pH will enter into
527:06 - the CPU and then can easily enter the
527:07 - critical
527:09 - section so I hope you all you have
527:12 - understood what is priority inversion
527:14 - problem and what is the solution
527:15 - priority inherit inheritance we are
527:17 - going to exchange the priority of low
527:20 - priority and high priority
527:22 - process now
527:25 - an amazing homework question it has
527:27 - various parts and if you can do this
527:30 - give yourself a nice trate this is an
527:32 - amazing question we are going to discuss
527:33 - this in the next lecture let me explain
527:35 - you the
527:36 - problem Fetch and add X comma I is an
527:40 - atomic read modify WR instruction that
527:43 - reads the value of memory location X
527:46 - increment it by value of I and Returns
527:48 - the old value of x it is used in the
527:50 - studio code as shown below to implement
527:52 - a busy weight lock
527:55 - so this this Fetch and add L comma fun
528:00 - this could be implemented like in this
528:03 - way this is not a part of question this
528:05 - I have given you in form of a hint so
528:08 - fetch and add log int X in I these are
528:10 - the parameters taken by Fetch and adlog
528:13 - these are the
528:15 - parameters int return
528:18 - value the store the value of x into the
528:20 - return value increment the value of x by
528:22 - I and then return the return value so
528:25 - what does it do read modify write
528:27 - instruction that reads the value of
528:29 - memory location X reads the value of
528:31 - memory location X incremented by value I
528:34 - incremented by value I and Returns the
528:36 - old value of x and Returns the old value
528:37 - of x it is used in the pseudo code shown
528:40 - bu to implement a busy weight lock L is
528:42 - assigned integer unassigned integer and
528:44 - shared variable initialized to zero the
528:47 - value Z correspond to the lock being
528:49 - available if the value is zero which
528:51 - means the lock is available while any
528:54 - nonzero value correspond to the lock
528:56 - being not available non zero says the
528:59 - lock is not available Zer says lock is
529:01 - available okay so acquire lock while
529:05 - Fetch and add L comma 1 initially let's
529:08 - say the value of L is set to zero
529:10 - initially the critical section is free
529:13 - what it will do Fetch and add l so what
529:16 - is going to do L increase the value of L
529:18 - by 1 so now what will be the value of L
529:21 - the value of L will be 1 and in the next
529:24 - instruction
529:25 - it says set the value of loog to one set
529:27 - the value of loog to
529:29 - One release loog so this was the end
529:32 - entry section and this is the exit
529:34 - section so to release loog set the value
529:37 - of loog to zero so what are we doing
529:39 - here while Fetch and add it is going to
529:41 - increase the value of loog by one and
529:43 - then in the next line we are setting the
529:45 - value of loog to one
529:49 - okay so what does this entry section
529:53 - make it will make the program it will
529:57 - make the process busy weight if L is
530:00 - greater than zero so if L equals to Z CR
530:03 - section is free if L is greater than Z
530:05 - CR section is not free so if L is
530:07 - greater than Z then it will busy weate
530:09 - and why we have written Lal to 1 here
530:12 - that you have to figure it out why we
530:13 - have written Lal to 1
530:17 - so so in log while one Fetch and add and
530:21 - n% log one so this is atomic returning
530:23 - the value of log and and increasing the
530:25 - value of block by one will be done
530:27 - atomically and then L equal to 1 why are
530:31 - we doing this figure it
530:33 - out so these are the
530:37 - problems which you have to solve so the
530:39 - first problem is we have set the value
530:42 - of Lal to 1 if this would not have been
530:44 - there then the value overflow would have
530:46 - been occurred how value of overflow
530:49 - would be occurred if L is not one figure
530:52 - it out the second problem is does this
530:54 - provide Mutual exclusion does this piece
530:56 - of code provide Mutual exclusion the
530:58 - third is can it be possible after a
531:00 - moment that no one can go to the
531:02 - critical
531:02 - section can it be possible that lock is
531:05 - one and critical SE critical section is
531:08 - three what I've said in the beginning if
531:11 - lock is zero then critical section is
531:13 - free if Any number greater than zero
531:15 - then not free but is it possible that
531:18 - the value of lock is one and critical
531:20 - section is
531:21 - free starvation from some starvation for
531:24 - some process is it there so you have to
531:27 - figure out these five questions this is
531:30 - an amazing amazing
531:33 - problem give it a Time solve it and if
531:36 - you are able to solve it correctly give
531:39 - yourself a nice trck because this is a
531:41 - difficult question this requires
531:43 - presence of mind this requires logic so
531:46 - in the last lecture I've given you a
531:48 - problem to solved this was a nice and
531:50 - interesting question before solving this
531:53 - let's first revise some some of the
531:54 - synchronization mechanism properties so
531:57 - the lock variable and District
531:59 - alternation are just the opposite lock
532:01 - variable doesn't provide Mutual
532:02 - exclusion and bounded waiting while stct
532:04 - alternation provides lock variable
532:06 - provides progress but stct alternation
532:09 - doesn't p and Decker are complete TSL
532:12 - and swap they provide Mutual exclusion
532:14 - and progress but fails to provide
532:16 - bounded waiting but an additional logic
532:19 - tsln swap also provides bounded waiting
532:22 - so it depends in which context we are
532:24 - talking about so now we will move on to
532:27 - the
532:28 - question we have been given a function
532:31 - fetch an add which Returns the value of
532:33 - x and increase the value of x by I and
532:36 - this was the enter section and this was
532:38 - the exit section now the first question
532:40 - if you remember was what will happen if
532:43 - Lal to 1 wouldn't have been there
532:46 - wouldn't have been there so for that
532:48 - case let's trace
532:50 - this initially the value of log is zero
532:54 - it goes there what it will return it
532:56 - will return zero and increases the value
532:58 - of log by one so now the value of log is
533:00 - one remember this while zero it will not
533:04 - get entered into the loop it will escape
533:05 - this condition goes into the critical
533:07 - section okay now the value of lock is
533:10 - one for another process when it will go
533:12 - there while fetching at lock what it
533:15 - will return it will return one and
533:17 - increase the value of loog by 1 so
533:20 - initially the value of log was
533:22 - zero so 0 was returned and then it was
533:25 - increased to one now for the second time
533:28 - when this will come here the value of
533:30 - log is one so one will be written and it
533:33 - will be increased by 1 so now the value
533:35 - of log will
533:36 - be 2 for the third time when it will
533:39 - come two will be returned and it will be
533:41 - increased by 1
533:43 - three four
533:45 - time four will be returned and it will
533:47 - increase to I hope you are getting the
533:50 - point so this will happen only when L =
533:53 - to 1 is not set there
533:55 - okay so this will only happen when Lal
533:57 - to 1 is not present but if Lal to 1 is
534:00 - present then this overflow wouldn't have
534:02 - been there let me repeat for the first
534:05 - time lock is zero goes there what it
534:07 - will return zero escapes the condition
534:08 - goes into the critical section for the
534:10 - second process when it comes what will
534:12 - the value of lock see when the first
534:14 - time when the value of lock equals to0
534:16 - was return it was also increased by one
534:18 - so now the value of lock is one if the
534:21 - value of lock is one it will return one
534:23 - and increase the value of loog by 1 so
534:26 - now the value of loog is two and we have
534:28 - assumed that Lal to 1 is not
534:30 - present goes
534:33 - again returns two and increase the value
534:35 - of log by 1 now three goes again returns
534:38 - three increase the value of log by one
534:39 - now the value of log will be four goes
534:41 - again returns four increase the value of
534:43 - log by one the value is five so this
534:45 - cycle will keep on going on going on and
534:47 - going on until the value overflow would
534:50 - be there okay so I hope you got the
534:52 - point how Lal to 1 is saving the
534:56 - overflow now we we are taking the case
534:59 - when Lal to 1 is present then what will
535:02 - happen initially L equal to 0 it returns
535:05 - Z change the value of log to one goes
535:08 - into the critical section for this
535:10 - another process now the value of loog is
535:12 - one is returned and then the value of
535:14 - loog is increased by one so now the
535:16 - value of loog is two but it will also go
535:19 - there in the loop in the loop condition
535:22 - so Nal to 1 is set so
535:25 - value of two will be set to
535:27 - 1 so by writing this C equals to 1 it
535:30 - will keep on oscillating between 1 and
535:32 - 2 okay so I hope you got the point how
535:36 - Lal 1 is saving the Overflow if Lal 1 is
535:39 - not present the value overflow will be
535:41 - there if Lal to 1 is present the value
535:44 - of log will oscillate between 1 and two
535:46 - I hope you got the idea now the second
535:48 - question does it provide manual
535:51 - exclusion so let's check Suppose there
535:53 - are three process in the RQ P1 P2 and P3
535:56 - okay critical section initially is
535:59 - empty and the value of log equals to
536:02 - zero for the first time okay now what
536:04 - happens
536:06 - P1 at the time T1 goes try to go into
536:09 - the critical section so fa AA is the
536:12 - Fetch and add log initially the value of
536:14 - log was zero so it will return zero and
536:16 - will change the value of log to one okay
536:18 - so it has all passed the conditions now
536:21 - it can easily go into the critical
536:23 - section so it will go into the critical
536:24 - section and there it get
536:26 - preempted okay so now P1 is in the
536:29 - critical section it has not completed
536:31 - the critical section but before it got
536:33 - preempted and the value of log is one
536:35 - now at time T2 let's say P2 also want to
536:38 - enter the critical section goes to the
536:40 - fion add log what it returns it Returns
536:43 - the value of log one and changes the
536:45 - value of log to
536:46 - two and then what will happen in the v
536:49 - you you remember that we have set the
536:51 - value of log to one so the value of log
536:53 - will be set to one
536:55 - and then when it goes again to check the
536:58 - condition the value of one will be
537:00 - return return and log will be set to two
537:02 - and then again so it will busy here it
537:06 - will busy here loog will be one
537:08 - initially the loog one will be written
537:10 - the value of log will be changed to two
537:12 - and then when this statement will be
537:13 - executed the log value will be back
537:16 - changed to one goes again the value of 1
537:18 - will be returned 2 1 2 1 this will keep
537:22 - on going on so this cycle one will be
537:25 - returned increase to two again set to
537:28 - one one will be return increase to two
537:30 - so this will keep on going on it will
537:31 - busy wa now let's say at time T3 P1
537:34 - comes again completes the critical
537:36 - section and it will execute the exit
537:39 - section and what was in the exit section
537:42 - L equal to 0 so it will change the value
537:43 - of log to
537:45 - 0 at time T4 P2 wants to go again so it
537:49 - P2 goes to the Fetch and add lock so now
537:52 - the value of lock is zero so fetch and
537:53 - add lock loog will return zero increase
537:56 - the value of log by one now what is the
537:59 - value of uh log log is one and the value
538:02 - of log which was return was zero so it
538:04 - will not get stuck in the busy weight it
538:06 - can easily go into the critical section
538:08 - completes the critical section and again
538:09 - set the value of L to zero to show that
538:12 - now the critical is free so I hope you
538:14 - got the idea that overflow is not
538:17 - possible and it also guarantees Mutual
538:20 - exclusion okay it it was easy so
538:23 - question in question B was easy now
538:25 - let's check question C can it be
538:27 - possible after a moment that no one can
538:29 - go to the critical section can it be
538:31 - possible so let's see that at time T1
538:34 - let's say P1 wants to enter the critical
538:36 - section initially the value of log was
538:37 - zero so it will return zero and will
538:39 - change the value of log to one goes to
538:42 - the critical section and then get
538:44 - preempted now at time T2 P2 wants to
538:47 - enter into the critical section the
538:49 - value of log was changed to one so it
538:50 - will return one and will increase the
538:52 - value of log to
538:54 - 2 now what happens is it gets preempted
538:58 - before it could set the value of log to
538:59 - one so let
539:01 - me show it here so this was all these
539:05 - statements were executed but here it got
539:07 - preed before it can set the value of log
539:09 - to one so we are solving the question
539:11 - can it be possible after a moment that
539:13 - no one can go to the critical
539:15 - section for that case we are preempting
539:18 - before it could set L equal to 1 now
539:21 - what will happen see so here is a
539:23 - general observation Whenever there are
539:24 - two statements in entry section preempt
539:27 - after one to get good inferences so I
539:29 - have told you several times Whenever
539:31 - there are two statements in the entry
539:32 - section so there were two statements
539:34 - preempt after one preempt here to get
539:38 - good inferences and here we have got
539:39 - also so now the value of lock what is
539:42 - the value of lock now the value of lock
539:43 - is
539:44 - two okay so at time P1 at time at time
539:48 - at time T3 P1 was there in the critical
539:51 - section if you remember P1 was preempted
539:53 - while it was in the critical section so
539:55 - P1 was in the critical section what it
539:57 - do now it completes the critical section
540:00 - change the value of log to 0 and
540:02 - leaves okay P1 has done all all its work
540:06 - now at time P4 P2 comes back P2 comes
540:09 - hold of the CPU it start executing its
540:12 - instruction so which instruction it will
540:14 - execute it will execute Lal to 1 it will
540:17 - execute lals to 1 fet and now what will
540:20 - happen
540:22 - see P2 has executed this instruction so
540:26 - it will go again and check the condition
540:28 - so it will go again and check the
540:29 - condition it will go again and check the
540:31 - condition what fetch ad log will return
540:34 - it will return one and it will increase
540:36 - the value of log to two so you got the
540:39 - idea it is busy waiting now so it is
540:42 - busy waiting is there anyone in the in
540:45 - the critical section no no one is the is
540:48 - in the critical section P1 was present
540:51 - in the critical section but it has
540:53 - completed all its work work it has left
540:55 - the critical section no one is present
540:56 - in the critical section but when P2 came
540:58 - it itself changed the value of log to
541:01 - one and you should remember the value of
541:04 - log equals to 1 represent that the
541:07 - critical section is not free but in
541:09 - reality the critical section is free no
541:11 - one is present so this is something
541:15 - wrong here P2 should logically go into
541:17 - the critical section because critical
541:19 - section should be free P1 when it when
541:22 - it was leaving it has changed the Val of
541:24 - log equals to0 which imply that critical
541:26 - section is free anyone can go into it
541:28 - but what happened P2 changed the value
541:31 - of log equals to one so this is
541:33 - something like this P2 without entering
541:36 - into the critical section has said to
541:39 - everyone has has told everyone that
541:41 - critical section is logged but actually
541:43 - inside no one is in the critical section
541:45 - so P2 should logically go into the
541:47 - critical section but it failed critical
541:49 - section is free the value of log is
541:51 - oscillating between 1 and two
541:54 - but no one is able to go into the
541:56 - critical section let's let's say at
541:58 - another time P3 P3 will always busy weit
542:01 - because lock is not equals to Z
542:03 - afterward so this is something stuck see
542:07 - no now what is the situation no one can
542:10 - go into the critical section critical
542:12 - section is logged into from inside so
542:14 - this is similar to the room which is
542:16 - logged from inside and no one is present
542:17 - in there also so that similar case have
542:21 - been occurred so have you noticed
542:24 - something there will be so many
542:26 - processes which can be preempted after
542:29 - increasing the value of
542:30 - L so this this may also this may also be
542:34 - the case so what I have said preempt
542:37 - before it can set the value of log
542:38 - equals to one so this is similar like a
542:41 - process one come process one came
542:43 - increase the value of log by one and
542:45 - fail to set the value of log equals to
542:47 - one process two came increase the value
542:50 - of loog by one process three came
542:51 - increase the value of loog by one and
542:52 - all of them all of the process failed to
542:55 - set the value of lock equals to one so
542:57 - each and every process will come
542:59 - increase the value of Lock by one come
543:00 - increase the value of Lo by one come
543:01 - increase the value of log by one and
543:02 - eventually what will happen if the value
543:04 - of log will keep on increasing and
543:06 - increasing and increasing what will
543:07 - happen overflow so this is the similar
543:11 - case so here overflow will occur so
543:14 - there will be so many processes which
543:16 - can be preempted after increasing the
543:17 - value of L so overflow may happen let's
543:20 - say the let's say the integer is of two
543:22 - bytes
543:24 - we are taking the 32bit architecture so
543:27 - let's say the integer value is of 2 by
543:29 - so the maximum value possible is
543:32 - 32,767 so if the number of process are
543:34 - less than this number then this
543:37 - mechanism will work correctly but if the
543:39 - number of process are more than the size
543:40 - of integer you know what will happen
543:45 - overflow okay so this was the case
543:49 - now we have done this question this
543:51 - question and this question now uh fine a
543:54 - fine question can it be possible
543:57 - that a loog equals to 1 which means the
544:00 - critical section is logged no one can go
544:03 - into it until it is the lock is released
544:05 - so can it be possible then critic that
544:07 - critical section is logged and
544:10 - also it is free log equals to 1 and
544:14 - critical section is also free can it be
544:17 - possible so we have already seen that it
544:21 - is possible
544:24 - here in the case lock was one lock was
544:27 - one and critical section was also free
544:28 - because no one was in the critical
544:30 - section P1 has already left the critical
544:32 - section but what happened that P2 when
544:34 - it came it by mistake set the value of
544:37 - lock equals to
544:38 - 1 so this was also
544:40 - done starvation for some process does
544:43 - some process starve obviously the
544:45 - process will
544:47 - starve so now I have important note I
544:51 - have important note for you that unless
544:53 - special focus is given to exceptional
544:55 - case think generally so one of my
544:58 - student come to me and ask this question
545:00 - which of the following algorithm suffers
545:02 - from
545:03 - starvation so I told him that sgf and
545:08 - priority will be the answer but he also
545:10 - said that fcfs should also be there
545:13 - because in some rare cases fcfs also
545:16 - suffers from
545:17 - starvation
545:19 - so I have given me I have been given the
545:22 - solution Manual of of galin textbook
545:25 - exercise so what happened I show in the
545:28 - answer of the actual the authorized
545:30 - authors the galin so there it was given
545:34 - that fcfs doesn't suffer from starvation
545:37 - it inherently doesn't suffer from
545:38 - starvation except the case for infinite
545:41 - Loops so until a special focus is given
545:44 - to exceptional case we should always
545:47 - think
545:48 - generally for this question the answer
545:50 - will be sgf and priority not the fcfs
545:54 - now comes to the blocking mechanisms or
545:56 - non busy Solutions so in the entry
545:59 - section we have a while
546:01 - loop we are talking about the busy
546:03 - Solutions so why busy Solutions were not
546:05 - preferred so in the entry section we
546:07 - have a while loop so have you ever
546:10 - thought how it sus for the CPU to check
546:12 - condition again and again again and
546:13 - again even if in the one check we get an
546:15 - idea that critical section is free or
546:18 - not so this this this V condition is the
546:23 - vage of CPU time in form of Loops so the
546:26 - process in just one check it can get the
546:29 - idea whether critical section is free or
546:31 - not why it has to busy wait until the
546:33 - time Quantum expires why is it so it is
546:36 - wasting its's time so to tackle that we
546:40 - got an idea that the process should test
546:43 - the condition only
546:45 - once if the critical section is free you
546:47 - are free to enter go into the critical
546:49 - section if not it should immediately get
546:52 - blocked it should immediately release
546:54 - the CPU and should get blocked let's let
546:57 - me explain suppose P1 is present in the
547:01 - ricu P1 goes to the CPU start executing
547:05 - the ENT section in ENT section in just
547:08 - one check it get an idea that critical
547:11 - section is not free someone is already
547:13 - present there let's say P2 so what it
547:15 - will do it will immediately release the
547:18 - CPU and should get blocked so that the
547:21 - other process present in the critical
547:23 - section that is P2 should take charge of
547:25 - the CPU so the P2 comes into the CPU
547:28 - start executing its remaining
547:29 - instructions of the critical section so
547:32 - that it can quickly execute critical
547:33 - section come out execute critical
547:36 - execute the exit section and unblock the
547:39 - blogged
547:41 - process let me tell you the story again
547:44 - there were two process P1 and P2 P2 was
547:47 - already present in the critical section
547:50 - okay so P1 wants to also go there P1
547:53 - goes to the CPU start executing the
547:56 - instruction of Entry section in entry
547:58 - section in just one check it got an idea
548:00 - that critical section is not free P2 is
548:03 - already present there so what it will do
548:06 - it will immediately leave the CPU why so
548:09 - that P2 can complete it critical section
548:11 - see it is a win-win situation for both
548:13 - P1 cannot enter into the critical
548:15 - section until P2 leaves the critical
548:18 - section because only one process can be
548:21 - present in the critical section so P1
548:23 - wants to to go into the critical section
548:25 - as soon as possible but it will it can
548:27 - only be it will only happen when P2
548:30 - completes the remaining section of the
548:32 - critical section so instead of busy
548:35 - waiting again and again checking the
548:37 - condition again and again wasting the
548:38 - time of P1 and P2
548:42 - both why shouldn't it get blocked and
548:47 - let P2 get charge of the CPU so that it
548:49 - can complete its remaining instructions
548:51 - when P2 completes its remaining
548:52 - instructions
548:54 - P1 is also getting benefited
548:57 - because P1 when P2 quickly execute the
549:00 - critical section P2 will come out
549:02 - execute the exit section and will
549:04 - unblock the blocked process so P1 was
549:07 - blocked it will unblock P1 hey even now
549:10 - you can go into the critical section it
549:11 - is
549:12 - free so this is the best case for busy
549:16 - waiting we have used while and in non-
549:19 - busy waiting we will use if then else in
549:22 - while what will happen we will go again
549:23 - and again check the condition again and
549:25 - again if then else will only work once
549:27 - condition true then block if false then
549:29 - enter simple and easy so for this
549:32 - blocking mechanism we have three things
549:34 - sleep and wake up SEMA force and
549:38 - monitors so first learn about the sleep
549:41 - and wake
549:43 - up sleep and wake up it is a blocking
549:46 - construct based on the blocking
549:48 - mechanism or non- Business Solutions it
549:50 - is a multiprocess solution and it
549:52 - behaves like an primitive like system
549:55 - call which means it is non preemptive no
549:58 - one can preempt it in between it's
550:00 - Atomic so let me tell you the story when
550:03 - the process executes sleep it gets
550:05 - blogged into the Sleep que a new name
550:08 - sleep que till some other process wakes
550:10 - up so let's take this scenario P1 was
550:14 - present in the RQ goes into the CPU
550:16 - start executing the entry section but
550:18 - what happens it checks that P2 is
550:21 - present in the critical section already
550:23 - it
550:24 - goes execute the sleep function sleep
550:27 - function will put the P1 into the Sleep
550:29 - Q so P1 will release the CPU immediately
550:32 - and P2 will take the
550:33 - charge now what happens P2 is in the CPU
550:37 - it completes the remaining instruction
550:39 - of the critical
550:40 - section and exits the critical section
550:43 - now it will exit it it will complete its
550:46 - exit section in the exit section what it
550:49 - will do it will wake up P1 so from the
550:52 - Sleep Q it will put P1 back to the RQ
550:55 - now P1 can go into the
550:57 - CPU do the same thing again checks the
551:00 - ENT section now critical section is free
551:03 - it can easily go into the critical
551:04 - section so this is how sleep mechanism
551:06 - work instead of being there in the CPU
551:09 - checking the condition again and again
551:10 - wasting the time of itself and also P2
551:14 - it get
551:15 - blocked and let P2 completes its
551:17 - critical section when P2 completes goes
551:19 - to the exit section P2 will put the P1
551:22 - back to the radic from the Sleep Cube
551:25 - now in the r CU P1 can go check the
551:27 - condition critical section is free and
551:30 - P1 is free to enter critical section so
551:33 - this is how it
551:34 - work now we will see the producer
551:37 - consumer problem but with the non busy
551:39 - solution we are going to do we will
551:41 - convert the busy waiting solution into
551:43 - the non busy waiting
551:45 - solution so what we are going to do we
551:47 - will make the consumer sleep when the
551:49 - buffer is empty and make the producer
551:50 - sleep when the buffer is full okay okay
551:53 - so we are not going to check the
551:54 - condition again and again wasting the
551:55 - time what we will do we will simply
551:58 - check if the buffer is empty consumer go
552:00 - to sleep buffer is full producer go to
552:02 - sleep now it is the duty of producer and
552:06 - consumer for producer to wake up the
552:09 - consumer and for Consumer to wake up the
552:11 - producer process so producer process
552:13 - will wake up the consumer when the first
552:15 - item is placed before that it might be
552:18 - sleeping so and the consumer will wake
552:22 - up the producer when the first item will
552:24 - be consumed so consumer will wake up
552:26 - producer when an item is consumed from
552:27 - the full buffer before that it might be
552:29 - sleeping so these are the four point
552:31 - that you have to remember now let's go
552:34 - to the code so this these were the
552:35 - global variables which we have defined
552:37 - void producer producer in item P item P
552:40 - will be the produced item and initially
552:43 - in was zero so do you remember the
552:45 - producer consumer process in the
552:48 - buffer there are these are this was the
552:50 - bounded buffer and we have two pointers
552:53 - in and out in will be the index of next
552:57 - empty slot for the produced item to be
552:59 - placed and out will be the index of the
553:02 - first empty slot first filled slot the
553:06 - slot from where the consumer can consume
553:09 - so in
553:11 - Empty Out
553:14 - full in is for the producer out is for
553:16 - the consumer I hope you remember
553:19 - that item P so we'll place the produce
553:22 - item into the the item P variable if
553:25 - count equals to equals to N Sleep If
553:28 - count equals to equals to n what does it
553:30 - mean that the buffer is full if the
553:32 - buffer is full no need of producer just
553:34 - go to the
553:35 - sleep if it is not so then place the
553:39 - produced item into the buffer at the
553:42 - empty slot and increase the value of
553:44 - empty slot by one and if it is if it is
553:47 - the last slot then do the circular thing
553:50 - that's why mod n so if this is the last
553:53 - not then go there place it here okay
553:56 - increase the value of counter by
553:58 - one but why because an item is placed
554:01 - and in the end if count equals to one
554:04 - wake up the consumer see we have to wake
554:07 - up the consumer when the first item is
554:08 - placed if the count equals to one which
554:10 - means the first item is placed we have
554:12 - to wake up the consumer let me repeat
554:15 - again declare a variable item P place
554:18 - the produced item at item P if count
554:21 - equals to n which means if the buffer is
554:22 - full
554:23 - make the producer sleep if it is not
554:26 - place the produced item into the buffer
554:28 - increase the value of n by one increase
554:31 - the value of count by one and if the
554:33 - count equals to one which means the
554:35 - first item is placed then we have to
554:38 - wake up the consumer because before that
554:40 - it might be
554:41 - sleeping similarly for the consumer code
554:45 - item c will be the item that will be
554:47 - consumed so if the count equals to zero
554:50 - which means the buffer is empty then
554:52 - there's no need for Consumer to wake up
554:54 - so it just go to the sleep because
554:56 - buffer is empty it cannot consume from
554:57 - empty
554:58 - buffer if it is not then item c will be
555:02 - the item at the buffer so from the out
555:06 - it will consume an item C out will be
555:09 - increased by
555:11 - one and count will be decreased by one
555:13 - see let me uh give you a pictorial
555:15 - representation let me check if it is
555:17 - recording yes okay so let's say the
555:21 - initially the value of count is zero so
555:23 - the consumer will go to sleep producer
555:25 - produce an item and it wakes up the
555:27 - consumer consumer got waked up
555:30 - now let's say this was the item C so the
555:34 - buffer do out this was the first item
555:36 - placed by the producer consumer is now
555:38 - ready to consument so item c will be
555:41 - equals to buffer. out so this will be
555:42 - the item C now we have to increase the
555:45 - value of out plus out plus one so now
555:48 - the out will be this consumer has
555:50 - already consumed this item so we have to
555:52 - increase the value of out if it is the
555:53 - circular case just for the producer just
555:55 - like the producer we have to do the
555:57 - circular thing if it is the last uh item
556:00 - if it is the last item in the buffer
556:02 - then it has to go again to the first
556:04 - item so that's why more than and we have
556:07 - to decrease the value of count because a
556:10 - item is consumed okay so I hope you got
556:12 - the idea now last thing if count equals
556:16 - to n minus
556:18 - one from the full buffer from the full
556:21 - buffer if one item is consumed now what
556:24 - is will be the number of items n minus
556:26 - one full buffer is n items one item is
556:28 - consumed so the item will be nus one so
556:32 - if count equals to n minus1 from the
556:33 - full buffer one item is consumed we have
556:35 - to wake up the producer because before
556:37 - that it might be
556:39 - sleeping and then consume item C see
556:42 - these four things are the main make
556:44 - consumer sleep when the buffer is empty
556:46 - make producer sleep when the buffer is
556:47 - full wake up consumer when the first
556:49 - item is placed wake up producer when the
556:52 - when an item is consumed from the full
556:53 - buffer okay so this was the code now we
556:57 - will analyze it in the next
556:59 - video Let's analyze the solution which
557:01 - we have discussed in the last
557:04 - lecture I have told you so many times
557:07 - Whenever there is more than one
557:08 - statement in the
557:10 - intersection preempt after one let's say
557:13 - there are two statements preempt after
557:15 - one preempt in between that will this
557:18 - will give you so many nice inferences
557:21 - let's check here this is an very very
557:23 - very interesting case Okay so focus and
557:27 - listen there's a cooperation and
557:30 - competition both so is there any
557:32 - possibility of Deadlock or inconsistency
557:34 - let's see so this was the entry section
557:38 - I have told you to preempt here if I
557:41 - preempt here before a process can go to
557:44 - sleep what will happen let's see so I
557:47 - have taken a small buffer of three
557:49 - things of three slots 0 1 and two and
557:52 - initially the value of count is zero n
557:55 - is equal to 3 there are three slots okay
557:57 - so n equal to 3 now what happens at time
558:00 - T1 consumer comes if count equals equals
558:04 - to Z yes count equals to Z initially the
558:06 - count is zero no item is in the buffer
558:09 - so what it has to do it has to make
558:12 - itself sleep but what happens before it
558:15 - can make itself sleep it get preempted
558:17 - here so whenever it will come back it
558:18 - will go to the sleep so whenever process
558:20 - come back whenever consumer get hold of
558:22 - the CPU it will start executing from the
558:25 - next instruction and what is the next
558:26 - instruction sleep so whenever it will
558:28 - come back it will go to the sleep at
558:31 - time T2 producer comes does count equals
558:35 - to n no count is not equals to n count
558:38 - is zero and N is three so it will
558:39 - produce its first item place it in the
558:42 - buffer increment the count now count is
558:46 - one if you remember if the count is
558:49 - one the it is the duty of producer to
558:52 - wake up the consumer so if count is one
558:54 - it will wake up the
558:56 - consumer but consumer never slept so
559:00 - producer will think it has done its work
559:02 - it has done its duty of waking up the
559:03 - consumer but the consumer never slept so
559:07 - what producer will do it will goes back
559:09 - and repeats this until the buffer is
559:11 - full producer will keep on producing
559:13 - item and item and item until the buffer
559:15 - is full buffer is now
559:17 - full X Y and Z these items are produced
559:20 - now count equals to three which is
559:21 - equals to n
559:23 - so if count equals to Wi yes then go to
559:25 - sleep producer goes to the sleep now
559:28 - producer go to The Sleep producer goes
559:31 - to sleep now consumer will get hold of
559:33 - the CPU what consumer will do it will
559:36 - execute it next instruction that is
559:38 - sleep producer goes to producer is
559:40 - already in the Sleep queue consumer also
559:42 - comes in the Sleep queue see this is a
559:44 - very dangerous situation producer will
559:47 - think that consumer will wake her up
559:50 - consumer will think that producers will
559:52 - wake her up and they are both sleeping
559:54 - comfortably in the Sleep
559:55 - ke so this is the case of Deadlock so
559:59 - here I have said producer goes to the
560:01 - sleep thinking that consumer will wake
560:03 - her up as soon as she consumes an item
560:05 - but producer doesn't know that consumer
560:07 - is also going to sleep so both the
560:09 - process are sleeping comfortably with
560:10 - assumption that one will
560:12 - wake the other so this is the case of
560:15 - Deadlock so yes deadlock is there and is
560:19 - there any case of inconsistency yes
560:21 - inconsistency is also also there because
560:23 - producer and consumer tries to update
560:25 - the value of count
560:27 - simultaneously so this is similar to the
560:28 - race condition so what is the solution
560:31 - of this
560:33 - problem this is a very very nice problem
560:36 - that both have gone to the Sleep Queue
560:38 - at the same time producer will think
560:40 - consumer will wake her up consumer will
560:41 - think producer will wake her up and
560:43 - they're both sleeping this was the case
560:44 - of dead dog and and for the
560:47 - inconsistency they tries to update the
560:48 - value of count simultaneously like the
560:50 - is condition p p tries to increase so
560:53 - this is just a case let's say the value
560:55 - of count is five P tries to producer
560:57 - tries to increase it and consumer tries
560:59 - to consume it so the value should be
561:01 - five but we get the answer like six and
561:03 - four I've discussed this so many times
561:05 - this is the race condition so what is
561:07 - the solution of this the solution is
561:09 - SEMA 4 and this is what we practically
561:12 - use we are going to learn more about
561:14 - SEMA 4 in the next lecture
561:24 - let's see what is semap 4 it is a
561:26 - practical inuse tool we use it
561:29 - practically most famous blocking
561:32 - construct OS based that is component of
561:35 - operating system Cal which means the
561:36 - operations are Atomic in nature general
561:39 - purpose utility which means it is used
561:41 - to solve several problems like critical
561:43 - section problem classical IPC problems
561:45 - and concurrency
561:47 - mechanisms it is implemented as an
561:49 - abstract data type like we used to do in
561:51 - the process thing process was also
561:53 - implemented as an abstract data type
561:56 - which has its own implementation and it
561:59 - has its own operations so what are the
562:01 - operations involved in semaphore the
562:03 - first is down and the second is up the
562:06 - down operation what does it do it just
562:09 - decrease the value by one it is also
562:11 - known as weight or p and what does up
562:14 - suggest it suggest it will increase the
562:16 - value by one it's also known as signal
562:18 - or V okay so what is the definition
562:21 - definition SEMA 4 abstract data type
562:24 - that takes only integer values remember
562:27 - this it only takes integer
562:29 - values and for integer value it can be
562:32 - classified into two binary SEMA 4 and
562:35 - Counting SEMA 4 binary SEMA 4 as the
562:37 - name suggest takes only two values Z or
562:40 - one it is also known as
562:42 - MX and Counting seor takes any integer
562:45 - value and it is also known as general
562:48 - semap for so we are going to first see
562:50 - the counting semaphor that is sm4 and
562:53 - the values it take is from minus
562:55 - infinity to plus
562:58 - infinity this is how it it is
563:00 - represented typed F struct int values Q
563:05 - Type L counting sem 4 so the counting
563:07 - sem4 consist of two things the first is
563:10 - it is a structure and it is named as
563:13 - counting S 4 which has two things the
563:16 - first is the value and the second is Q
563:18 - Type L and what does this Q type contain
563:20 - it contains the list of PCV
563:23 - of those process that gets blocked while
563:25 - performing down operation
563:27 - unsuccessfully so what is unsuccessful
563:30 - down operation we are going to see in a
563:32 - few minute so this thing this is Kernel
563:36 - mode and this is user
563:37 - mode so after defining the variable we
563:42 - have to mandatorily initialize it and
563:45 - the initialize value will be it depends
563:48 - on the application whatever value we
563:51 - initialize
563:52 - similarly or accordingly it will work so
563:56 - this means will depends upon
563:59 - application so let's say we have said
564:01 - the counting semap 4 S do value is one
564:04 - so we said the value is one if we
564:06 - perform the down operation then what
564:09 - happens then again it goes to the kernel
564:11 - mode as I said the operations are Atomic
564:15 - in nature so the down operation so this
564:17 - we did the initialization or the
564:20 - Declaration kernel mode
564:23 - setting the values user mode and
564:25 - Performing the operation again on the
564:26 - kernal mode so what does down operation
564:29 - do it decrements the current value of s
564:32 - that is the SEMA 4 so this was s do
564:34 - value we declared a sem 4 accounting
564:35 - SEMA 4 S and we set the value equals to
564:39 - 1 now we are performing a down operation
564:42 - on that counting S4 s so what does a
564:44 - down operation do it decrements the
564:47 - current value of sem 4 S by 1 so what
564:50 - was the value initially it was one so s
564:53 - do Val equal to S do valus one we say
564:55 - that the result is either successful or
564:58 - unsuccessful if it is successful it goes
565:00 - to the next statement if it is
565:02 - unsuccessful it's blogged in the Q so
565:05 - this was I was talking about Q Type
565:08 - L it contains the list of pcbs of those
565:11 - process that gets blocked while
565:13 - performing down operation unsuccessfully
565:16 - so I've said while performing down
565:18 - operation two things can happen either
565:20 - it can get performed successfully or
565:22 - unsuccessfully if it is successfully
565:24 - performed we go to the next statement if
565:27 - it is unsuccessfully performed we are
565:28 - blocked in the queue which Q This Q Type
565:31 - L ql okay so this is the next thing now
565:37 - the question arises how to identify
565:39 - whether we are blocked or unblocked
565:41 - whether the operation was successful or
565:43 - unsuccessful so if S4 do value is
565:48 - negative put the process PCV in the Q
565:51 - that is the Sleep Q
565:52 - and block the process s DOL is this is
565:56 - the Q name you can see here we declared
565:58 - accounting S for S so s DOL this is the
566:02 - que so we will put the process in the
566:05 - queue and block the process which means
566:08 - it's sleeping now else return to the
566:11 - next statement okay so how we get to
566:15 - know that the operation was successful
566:17 - or unsuccessful if the value of counting
566:20 - sem4 becomes negative then it is
566:23 - unsuccessful if the value if the return
566:25 - value is positive or greater than or
566:28 - zero if it is positive or zero then it
566:30 - is successful if negative unsuccessful
566:33 - if positive or zero successful
566:36 - okay now comes the question if we set
566:40 - the value equals to
566:42 - 5 how many down operations can be
566:44 - carried out
566:45 - successfully if the value of count4 is
566:48 - set to five how many down operation can
566:50 - be performed successfully so what we did
566:53 - we start decreasing the value by one so
566:56 - at five We performed down operation
566:57 - successful four how we know it was
566:59 - successful because the value is still
567:03 - positive we decreased it one down
567:05 - operation four another down operation
567:07 - three another down operation two another
567:10 - down operation 1 now let's let's perform
567:13 - another down operation another down
567:16 - operation it is zero now is it
567:19 - successful yes what I said if it is non-
567:23 - negative then it is successful it
567:26 - doesn't depend whether it is zero or
567:27 - positive if it is non- negative
567:29 - successful so five down operations were
567:31 - successful let's perform another down
567:33 - operation now the value is minus one now
567:35 - we can say the value became negative
567:38 - hence it is
567:39 - unsuccessful
567:41 - okay now another process came and
567:44 - performed another down operation another
567:45 - down operation it becomes minus 2 again
567:48 - unsuccessful so this the process which
567:51 - perform down operation on this and the
567:54 - process which perform down operation on
567:55 - this both get blogged so the number of
567:59 - blogged process are two so there are two
568:01 - process in UL suppose another process
568:05 - which came and performed down operation
568:06 - on this so the value of s will be minus
568:09 - 3 and number of blocked process will be
568:12 - three I hope you got the idea okay so
568:16 - positive value of the SEMA 4 indicate
568:19 - that those many down operations can be
568:20 - performed successfully so what was the
568:22 - value of 74 here s = to 5 so we
568:25 - performed five down operations
568:27 - successfully and after that process
568:30 - starts getting
568:31 - blocked we can also observe another
568:34 - thing
568:35 - here let's say when the value of sem 4
568:38 - was min-2 how many processes were
568:40 - blocked two processes were blocked let's
568:43 - say another process came and performed
568:44 - down operation now the value is minus 3
568:46 - how many process are blocked now so the
568:49 - process which performed down operation
568:50 - on this did an unsuccessful down
568:52 - operation so this process will also be
568:54 - blocked so the number of blocked process
568:56 - will be three now when the value of 74
568:58 - was minus 3 so a thing we can notice
569:01 - when it was minus one then one process
569:04 - was blocked when it was min-2 two
569:05 - process were blocked when it was minus 3
569:07 - three processes were blocked so we can
569:09 - give two inferences here positive value
569:11 - of the sem 4 indicate that those many
569:13 - down operation can be performed and
569:14 - after carrying out a series of down
569:16 - operation if the value of SEMA 4 becomes
569:19 - negative then the magnitude of the
569:21 - negative value indicates get the number
569:22 - of blogged
569:23 - process so I hope the point is clear so
569:26 - the first thing says if s equal to 5
569:28 - these many down operations can be
569:30 - performed and after performing a series
569:32 - of down operation if the value of sem4
569:34 - let's say is minus 8 then we can say 8
569:36 - process 8 process are blocked eight
569:39 - process are residing in the
569:41 - ql okay so now let's
569:45 - check another
569:48 - thing so this was the radue now out of
569:52 - these ready out of these three process
569:54 - some process will enter into the entry
569:57 - section so let's say a process enters
570:00 - into the ENT section performs the uh
570:03 - instructions in the ENT section goes to
570:05 - the critical section P1 goes to the
570:07 - critical section and then completes the
570:09 - exit section and then goes out so by
570:13 - doing this what we do how does this sem4
570:16 - thing how does the sema4 provides Mutual
570:19 - exclusion we are going to see
570:20 - that so out of these three process a
570:23 - process came and performs the ENT
570:25 - section and in ENT section what we do we
570:27 - decrease the value of S 4 by one so
570:30 - initially let's say the sem4 value was X
570:33 - so X down operation can be performed
570:35 - successfully when X becomes zero then
570:38 - the number of let's say uh three down
570:40 - operations will performed so all three
570:42 - process will get
570:44 - blogged okay and let's say the value of
570:47 - initially let's say the value of x was
570:49 - three
570:50 - so 1 two three three down three down
570:53 - operations can be performed successfully
570:55 - so all three process will be successful
570:57 - in performing down operation and they
571:00 - all will enter the critical
571:02 - section are you getting the point let me
571:05 - explain more clearly so initially let's
571:08 - say the value of sem 4 was one only okay
571:11 - P1 got the chance to get hold of CPU and
571:14 - it start executing the instructions of
571:16 - Entry section what is the instruction in
571:18 - the entry section P of s which means
571:21 - down operation of on S so what is the
571:23 - value of s one so it will perform down
571:25 - operation and now the value of s will
571:26 - become
571:28 - zero nice okay it will go into the
571:31 - critical section P1 is still in the
571:32 - critical section and somehow it got
571:34 - preempted
571:35 - now let's say P2 get the chance P2 goes
571:39 - to the entry section will perform a down
571:42 - operation on S equals to0 if s equals to
571:45 - 0 then down operation will be minus one
571:48 - and I hope you remember that if the
571:50 - value of down operation after performing
571:52 - the value of down operation if the value
571:53 - of s is negative then it is an
571:56 - unsuccessful down operation and in the
571:59 - case of unsuccessful down operation we
572:01 - block the process so the process P2 will
572:04 - get blocked it will it won't be able to
572:06 - enter into the critical section same
572:08 - case for the P3 let's say P3 also attemp
572:10 - to go into the critical section so what
572:13 - was the value of s it was minus one it
572:15 - performs another down operation it
572:16 - becomes minus 2 which means two process
572:19 - now P3 is also blocked two process are
572:21 - blocked and only P1 can complete okay
572:24 - now let's see P1 was in the critical
572:26 - section P1 get again chance to get hold
572:28 - of CPU see it start executing the
572:31 - remaining instructions of critical
572:32 - section completes the critical section
572:34 - now V of s what is V of s it is the up
572:36 - operation so what P1 will do it will
572:39 - perform an up up operation so s equals
572:41 - to from minus 2 it will perform an up
572:43 - operation from -2 to
572:47 - -1 what does minus one suggest it
572:49 - suggest that only one process should be
572:51 - blocked
572:52 - so it will wake up another process let's
572:54 - say P2 is waked
572:57 - up now what will P2 do it will start
573:00 - executing from the next instruction it
573:02 - has already executed this so the next
573:04 - instruction is just the critical section
573:05 - it goes to the critical section happily
573:08 - now when it comes out it will perform
573:09 - the up operation when it will perform
573:12 - the up operation this minus one will
573:13 - become zero what does this suggest it
573:16 - means P2 will wake up P3 also P2 exits
573:19 - the exit section now it's turned for p
573:21 - P3 P3 will again resume from where from
573:24 - the next instructions so it will it has
573:27 - already completed this it will go
573:29 - directly in the critical section P3
573:32 - comes out what does it will do now it
573:34 - will increase the value of S 4 by 1 so
573:36 - one so this is how sem 4 provides Mutual
573:40 - exclusion if one process in the critical
573:42 - section is present then no other process
573:45 - will be able to go into the critical
573:47 - section if they try they will get
573:49 - blocked and they will will be awaken or
573:52 - they will uh come out of the blocked que
573:55 - only when some process completes their
573:58 - exit section so I hope you got the idea
574:00 - let's read this thing also so when P1
574:04 - was in the critical section and P2 and
574:06 - P3 tries to go into the critical section
574:08 - then they get blocked in the ql and it
574:11 - is a f4q generally so the basic
574:14 - objective of up operation is to wake up
574:16 - a sleeping
574:18 - process so s = to min-2 when the up
574:21 - operation was performed it was minus one
574:23 - so what does this suggest P3 is sleeping
574:25 - now and P2 is awake and P2 is awake then
574:28 - it will go to the Rue as you have as you
574:30 - have studied that from the blocked que
574:32 - we go to the RQ so it goes to the RQ and
574:35 - then it will start executing from the
574:36 - next instruction what is the next
574:38 - instructions go to the critical section
574:41 - okay as it has already completed its
574:43 - entry
574:44 - section so what does up operation we
574:47 - have studied the down operation what
574:49 - does up operation look like up on
574:51 - counting sem4 s increase the value by 1
574:55 - if the value is negative if the value is
574:57 - negative or equals to zero select a
574:59 - process from sleeping que and wake up
575:02 - else return so it is the duty of up
575:04 - operation that if the value is negative
575:07 - or equals to Z then it has to wake up a
575:09 - sleeping
575:10 - process okay so this is what we had done
575:13 - here when the value was increased when
575:15 - the value was increased from -2 to
575:19 - -1 up operation has awaken
575:22 - P2 and when the value was increased
575:24 - fromus 1 to 0 up operation has awaken P3
575:28 - okay so this is how it work so when P1
575:30 - is performing up operation indirectly it
575:32 - wakes up P2 and put it into the critical
575:36 - section and when P2 performs up
575:38 - operation it wakes a P3 P3 goes to the
575:40 - Ric and then critical section and then
575:42 - again it performs the operation and for
575:45 - that case for that case when performs
575:47 - the up operation the value is now one
575:50 - see
575:52 - for P3 what was the value for P3 s was
575:55 - already zero so when P3 has completed
575:57 - the exit section which means P3 will
575:59 - perform an up operation on zero so what
576:01 - will be value now one so P3 has
576:03 - performed up operation the value is now
576:05 - one is the value if the value is
576:09 - negative or equals to Z no it is
576:11 - positive so it will not perform the
576:13 - waking up of any process if s equals to
576:16 - Z and then up up operation is performed
576:18 - on it then the process will not wake any
576:21 - process
576:22 - why because there is no process in the
576:24 - slip que because the value of s equals
576:26 - to Z suggest what there is no process in
576:28 - the slip CU and this is what we had
576:31 - written here in form of condition I hope
576:34 - you got the idea so no wake up call if s
576:37 - do value is positive if s equals to Z I
576:40 - have to wake up one more process if the
576:41 - initial value of s was one so mutual
576:43 - exclusion is violated
576:46 - here are you understanding it if the
576:49 - value of su 4 was not one if the value
576:52 - of sem4 was not one see here if the
576:54 - value of sem4 was not one then Mutual
576:56 - exclusion will be violated let's say I
576:59 - put the value of S 4 S2 so what does s =
577:02 - to 2 suggest it means two process can
577:05 - now go into the critical section
577:07 - simultaneously let me show you let's say
577:10 - the value of S4 was 2 P1 comes decrease
577:13 - the value by 1 P1 goes to the critical
577:15 - section let's say P1 get preempted here
577:17 - P2 comes decrease the value by 1 now it
577:20 - is zero see
577:22 - both P1 and P2 has performed a
577:24 - successful down operation so no one is
577:26 - stopping P1 P2 also to go to the
577:28 - critical section so at the same time P1
577:30 - and P2 are both present in the critical
577:32 - section so this is how Mutual exclusion
577:34 - is violated if the value of sem4 is
577:37 - greater than
577:38 - one okay so this is how semor works this
577:42 - is how the ensures Mutual exclusion in
577:45 - the next lecture we are going to see
577:46 - some of the basic problems of uh up and
577:49 - down operation
577:51 - now let's discuss some super easy
577:53 - questions in the initial value of
577:55 - counting SEMA 4 is 8 and we have to
577:57 - perform these
577:59 - operations what will the final value
578:01 - super easy this is down operation p is
578:04 - down operation and V is up operation for
578:06 - down operation you do nothing but to
578:07 - incre to decrease the value by one and
578:10 - for up operation you increase the value
578:11 - by one so for this what can you do 8 -
578:16 - 10 + 1 -5 + 2 - 6 + 3
578:21 - what will be the value you get you get
578:23 - -7 and what does -7 signify it says that
578:27 - there are 17 process blocked in the
578:30 - Sleep
578:31 - G another question counting sem4 what
578:35 - will be the initial value of counting
578:37 - sem4 such that after performing these
578:39 - operations up and down the final value
578:41 - which I get is minus 6 super easy you
578:44 - can do this by two ways either you can
578:46 - make an equation like x - 12 + 4 - 6 + 3
578:50 - - 8 + 1 should be equal to - 6 you can
578:53 - do do like this or you can just think
578:56 - like that let's say we started with - 6
579:00 - and instead of doing down operation we
579:03 - what we did we did up operation so it's
579:07 - nothing just we started the opposite
579:09 - thing minus 6 for up operation we added
579:12 - and for down operation we subtracted so
579:14 - in this way we get the final value as 12
579:16 - you can do that from the both ways or
579:22 - directly saying this is the same thing
579:24 - which you did in the equation also okay
579:26 - so the final value which you got is 12
579:29 - which means if the initial value of sem4
579:32 - would have been 12 then after performing
579:33 - these series of down and up operation we
579:35 - get the final value as Min - 6 another
579:38 - question question consider a non-
579:39 - negative counting S 4 S the operation PS
579:42 - decrements s and vs increments s same
579:45 - thing during execution 20 PS operations
579:49 - and 12 vs operations are issued in some
579:51 - order okay the largest initial value of
579:53 - s for which at least one PS operation
579:56 - will remain blocked so for at least one
579:58 - PS operation that remain
580:01 - blocked in the end the value of SEMA 4
580:04 - in the end should be less than or equal
580:07 - to minus1 for at least we have written
580:10 - this less than or equal to minus1 for
580:14 - exactly one operation one PS operation
580:16 - to remain blocked then value should be
580:18 - minus one and for at least one then
580:20 - value should be less than equal to
580:21 - minus1 so what we did we take the
580:24 - initial value as X so X and how many
580:28 - down operation 20 so x - 20 how many up
580:31 - operation 12 + 12 = to S and that s
580:35 - should be less than equal to -1 after
580:38 - performing calculations we get the value
580:40 - of x should be less than equal to 7 so
580:43 - what will the largest value
580:45 - 7 Easy Peasy okay let's see the
580:48 - practical application of sem4 how it is
580:50 - used in Practical life Suppose there is
580:54 - a client server
580:56 - architecture there are several clients
580:59 - and server can manage only 100 request
581:01 - at a time and there are so many clients
581:04 - that they are sending 5,000 request so
581:07 - if all the 5,000 request reach at the
581:10 - server how does server is going to
581:12 - manage them so this problem can be
581:14 - solved using counting SEMA 4 which
581:17 - ensure that only 100 or th000 requests
581:20 - so whatever be the number 1,000 request
581:22 - go and rest wait so what we did we set
581:25 - the value of s equals to
581:28 - 1,000 try to set an analogy or try to
581:30 - set a connection see in the case of
581:33 - process and critical section whatever be
581:35 - the value we set that number of process
581:38 - can go into the critical section here we
581:40 - said that if s equal to 2 then P1 and P2
581:42 - both can go into the critical section if
581:44 - I said s = to 1 only then only P1 was
581:47 - able to go and rest two of them were
581:49 - blocked
581:51 - similarly think that there are 5,000
581:54 - processes and it is feasible that only
581:59 - thousand of them can go into the
582:00 - critical section so for that case what
582:02 - should be the value of s so the value of
582:05 - s should be set to th000 so this is how
582:08 - so these processes can be set as clients
582:11 - and the critical section can be sent as
582:12 - server I hope you got the idea so how to
582:16 - set that only thousand process should go
582:18 - into the
582:19 - server so this can be solved as setting
582:23 - the value of counting some of 4S th000
582:25 - so every request will perform a down
582:26 - operation on S and after it gets served
582:28 - it will perform up then so this is how
582:31 - this will work so when th000 down
582:34 - operation will be performed or when
582:35 - th000 request will go to the server for
582:38 - uh servicing then 1,1 request will be
582:42 - blocked because the value is set to, so
582:46 - this is how it works okay in the next
582:48 - lecture we are going to see binary SEMA
582:50 - 4 Counting sem4 is complete now so we
582:52 - should make a revision so how does
582:54 - counting sem4 work type def instruct
582:57 - what is the use of type def to give it a
583:00 - name so we give it a name as counting
583:01 - se4 so counting se4 is two things values
583:05 - and Q the value mean what is the initial
583:08 - value of counting sem4 let's say for the
583:10 - client server architecture the initial
583:12 - value was
583:13 - 1,000 okay so this uh declaring is done
583:17 - in the kernel mode setting up the value
583:20 - initializing is done in the user mode
583:21 - and we have to mandator initialize it
583:23 - let's say we initialize that to th000 so
583:26 - th000 process can go into the critical
583:27 - section so it has two operations the
583:29 - first is down and the second is up for
583:31 - down operation what you have to do you
583:33 - have to decrease the value by one and
583:36 - after decreasement if the value becomes
583:38 - negative then we have to put the process
583:40 - into sleep
583:42 - Q else go to the next statement and how
583:45 - we get to know that the process is
583:47 - process has performed a successful or
583:49 - unsuccessful down operation the down
583:51 - operation is successful when the value
583:54 - is non- negative and it is unsuccessful
583:57 - when the value is
583:58 - negative okay so we have seen everything
584:01 - how it is ensuring Mutual exclusion and
584:03 - then we will
584:05 - see up operation and what you have to do
584:08 - in up operation increase the value by
584:10 - one if the value is less than or equals
584:13 - to zero which means we have to select a
584:15 - process and wake it up from the sleeping
584:18 - quebe otherwise else return okay
584:21 - let's start the binary semap 4 binary
584:24 - semap 4 can takes only two value either
584:26 - zero or
584:27 - one so how it is declared type def
584:31 - struct type def for BM because we want
584:34 - to rename it and struct because it is a
584:36 - structure which contains two things just
584:39 - like the
584:40 - CM now we have to use enum why enum
584:44 - because this variable value of type enum
584:46 - can take only two values either zero or
584:47 - one it is a binary semore and it can
584:50 - take only two Val vales either 0 or 1 it
584:52 - has a sleep que similar to the counting
584:54 - semap 4 which contains the list of all
584:57 - those processes PCB which fail to
584:59 - perform perform an successful down
585:02 - operation okay so while performing down
585:04 - operation there are only two
585:06 - possibilities because the value of s can
585:08 - be either Z or 1 so when down operation
585:11 - is performed on zero the value will
585:13 - still remain zero it won't become minus
585:15 - one because it is a binary semap 4 so
585:18 - the value will still remain zero and it
585:20 - will be blocked
585:21 - but if the down oper operation is
585:24 - performed on one the value will become
585:26 - zero and success it won't get blocked
585:30 - okay so there are only two possibilities
585:31 - while performing down operation you can
585:33 - get on zero the result will be zero but
585:38 - for one case the process will be blocked
585:40 - and for another case it will be
585:44 - successful user mode binary sem4 we have
585:47 - to initialize it we can initialize it
585:50 - from either zero or one if it is
585:52 - initialized to zero which means no
585:53 - process can go into the critical section
585:55 - if it is initialized to one which means
585:57 - only one process can be in the critical
585:59 - section at a
586:01 - time okay so we have to perform down
586:03 - operation and if the down oper operation
586:06 - is successful we go to the next
586:08 - statement so what is down operation down
586:10 - on binary sem 4 S if the value of s is 1
586:15 - set the value to zero return else put
586:19 - the this process PCB in sleep q and
586:20 - block it so this is what we are doing
586:23 - while performing down operation if the
586:24 - value is one then set the value to zero
586:28 - return return where return to the next
586:30 - statement otherwise put this process PCB
586:32 - and block it what is the otherwise case
586:34 - this is the case if the value of s is
586:37 - not one which means the value will be
586:39 - zero if it is zero then block it if it
586:42 - is zero put this process PCB in the slip
586:45 - Cube while performing dou
586:47 - operation okay so it will never take
586:50 - negative values we won't know how many
586:52 - processes are blocked there okay so in
586:56 - counting semaphore when we used to do
586:58 - down operation the value of s keep on
587:01 - decreasing as I have said in the
587:03 - previous video uh in one question we get
587:06 - the value of s is minus 17 so we can
587:08 - easily identify that there are 17
587:10 - processes sleeping in the block Q or 17
587:14 - process blocked in the cing both are the
587:16 - same but here we can only see the value
587:20 - of s s either 0 or 1 if the value of s
587:23 - is z we cannot tell how many process are
587:26 - there in the sleeping queue because it
587:28 - won't take any negative values okay so
587:31 - let's see this scenario there are three
587:33 - process present in the radue and they
587:35 - are both eager to go into the critical
587:36 - section and they are all eager to go
587:38 - into the critical section let's say a
587:39 - process P1 gets a chance to get hold of
587:42 - CPU start executing the instructions of
587:45 - Entry section performs the down
587:47 - operation on S performs the down
587:49 - operation s now it becomes zero goes to
587:51 - the critical section is it still in the
587:54 - critical section but somehow it get
587:55 - preempted P2 wants to go into the
587:57 - critical section performs the down
587:59 - operation on zero and if the down
588:01 - operation is performed on zero what
588:03 - happens it get blocked so P2 is blocked
588:06 - now P3 comes what is the value of down
588:08 - what is the value of s it is still zero
588:11 - P3 comes to the entry section start
588:14 - executing this down operation but again
588:17 - when the down operation is performed on
588:19 - zero it will also get blocked so there
588:20 - are two processes blocked but the value
588:23 - of SEMA 4 is zero so by seeing the value
588:26 - of semor in this case we cannot tell how
588:28 - many process are blocked but this is
588:30 - somehow providing Mutual exclusion
588:32 - because when P1 was in the critical
588:35 - section P2 and P3 were unable to go into
588:37 - the critical section so what will happen
588:39 - P1 completes the instructions of
588:41 - critical section comes out of the
588:43 - critical section goes to the exit
588:45 - section and what and what does it will
588:47 - do it will increase the value by one so
588:50 - what is vs increase the value of sem4 by
588:52 - 1 so the value of sem 4 will be directly
588:55 - increased to one will this happen let's
588:59 - see let's see so if there is a process
589:02 - in either critical section or block Q
589:04 - the value of SEMA 4 must be zero must be
589:06 - zero if the process is in either
589:09 - critical section or block Q the value of
589:11 - S4 must be zero so how will up operation
589:14 - will be performed for up operation check
589:17 - if there is no block process then the
589:18 - value set value to one and and if there
589:21 - are block process in the block Q then
589:22 - wake up a process and send it to the
589:24 - critical section are you getting the
589:26 - point
589:28 - see let's say the value of s at some
589:31 - point is zero can you tell me by seeing
589:33 - this how many process are blocked in the
589:35 - uh sleeping queue can you can you tell
589:37 - me no it is not possible so how can you
589:39 - directly increase the value of s to one
589:42 - by performing up operation when there
589:45 - are still processes present in the
589:46 - sleeping queue you can't so we are going
589:50 - to check it first if there is no process
589:52 - in the sleeping queue what we are going
589:54 - to do we are going to just increase the
589:55 - value by one and if there are process
589:58 - present in the sleeping Q then what will
590:00 - will do we won't increase the value
590:02 - directly to
590:04 - one for up operation we will we are
590:06 - going to wake up a process from the
590:07 - sleeping key just wake up the process no
590:10 - need to increase the value of s okay so
590:13 - this is what we are doing here how will
590:14 - up operation will be performed if there
590:16 - is no block process then value of s is 1
590:19 - if there are process in the block block
590:20 - you then wake up a process and send it
590:22 - to the critical section why we are
590:24 - sending it directly to the critical
590:25 - section because when a process get
590:27 - blocked it has already completed the
590:29 - instructions of the critical section and
590:31 - when it will come again it will resume
590:34 - from the next instruction what is the
590:35 - next instruction critical section so it
590:37 - will go directly into the critical
590:38 - section so this is how up operation is
590:41 - performed up on binary sem 4 S if sleep
590:44 - Q is not empty select a process from L
590:46 - and wake up and if it is empty select
590:48 - set the value of s to one
590:51 - so for performing down operation we had
590:54 - two possibilities if the value was Zero
590:56 - block it if the value was one decrease
590:58 - the value and success go to the next
591:00 - instruction But Here If s equals to Z
591:04 - again two possibilities set it to zero
591:07 - and when when the Q is not empty and
591:10 - select a process and wake it up if Q is
591:14 - empty set the value to one and remember
591:17 - one thing whether it is a case of binary
591:20 - sem 4 or counting SEMA 4 up operation is
591:24 - always and always
591:26 - successful for the case of down
591:28 - operation the thing of success and
591:31 - unsuccess is
591:32 - defined up operation is always
591:34 - successful down operation is somewhere
591:37 - sometimes successful and sometimes not
591:39 - when successful I've already told
591:42 - you so what does s equals to one suggest
591:45 - s equals to 1 says critical section is
591:47 - free and the Q is also empty
591:51 - and what does s equal to0 suggest it
591:54 - says a process is is either in the
591:56 - critical section or in the block
591:59 - Q okay so if s = to 1 and and some say
592:05 - let's increase the value or uh perform
592:08 - an unop up operation then the value will
592:11 - remain one only because it is a binary
592:13 - S4 it can take only two values either 0o
592:15 - or one so performing an up operation on
592:18 - one will result in one only it won't
592:20 - increase it to two because it is a
592:22 - binary sem4 okay for S = to
592:26 - 0 up operation if it is the first
592:30 - operation so if it is the first
592:33 - operation then it logically means that Q
592:35 - is
592:36 - empty what I'm saying here is the value
592:39 - of s is set to zero and up operation is
592:43 - the first operation which means that the
592:46 - Q is empty because it is just the
592:47 - starting of the thing so in that case
592:50 - the value of s will be directly set to
592:52 - one and the status is Success so the up
592:56 - operation will be always successful and
592:58 - what do s equal to one suggest critical
592:59 - section is free and Q is empty s equal
593:02 - to0 says a process is in either in the
593:05 - critical section or block
593:07 - q but if we are directly saying s equals
593:10 - to 0 we are performing an oper up
593:11 - operation what will be the value we
593:13 - cannot directly
593:14 - tell if it is the first operation then
593:17 - we can directly tell s equal to 1
593:18 - because the Q will be empty and if it is
593:21 - not the first operation we have to see
593:23 - whether Q is empty or not then we will
593:24 - tell what will be the value when up
593:27 - operation is performed on zero okay you
593:30 - got the
593:31 - idea process never get blocked while
593:34 - performing up operation can get blocked
593:36 - while down whether it is counting or
593:38 - binary semop 4 I have already made this
593:41 - point this sleeping Cube which we are
593:43 - talking about here is dynamic of course
593:45 - dynamic because a process comes performs
593:47 - the down operation and get blocked
593:50 - if it is not Dynamic if it is not
593:52 - Dynamic let's say there are only two
593:53 - slots present process one came get
593:56 - blocked process two came get blocked p 0
593:58 - was already in the critical section so
594:00 - P1 came get blocked P2 came get blocked
594:02 - now what will happen if the P3 come it
594:05 - should also get blocked in the same Q so
594:06 - for that thing we have kept this
594:08 - sleeping Q as
594:10 - Dynamic
594:12 - okay let us revise and then we will
594:14 - solve the
594:16 - question so for binary semap 4 it can
594:19 - take only two Val either 0 or one if the
594:21 - value is zero if the value is zero what
594:24 - does this suggest it says that critical
594:27 - section is not free or a process is in
594:30 - the sleeping Cube okay and if it is one
594:34 - it says critical section is also free
594:36 - and there is no process in the sleeping
594:38 - okay it has two operations just like the
594:41 - counting semor down and up but
594:44 - there their working is
594:46 - different in down operation there are
594:49 - two possib ities if the value of sem4 is
594:51 - 0 or one if the value of sem4 is
594:54 - zero and we are performing a down
594:56 - operation block the process which means
595:00 - what does zero suggest appro critical
595:02 - section is not
595:03 - free so when a down operation will be
595:06 - performed on zero which means a process
595:09 - is wants to go to the critical section
595:11 - when it is being acquired by some other
595:13 - process so what we have to do we have to
595:15 - block that process if it is one what
595:18 - does that mean critical section is free
595:20 - so just decrease the value and it is
595:23 - Success
595:26 - okay and how up operation will be
595:29 - performed if there is no block
595:31 - process if the Q is
595:34 - empty if the Q is empty increase the
595:37 - value by one and what does one suggest
595:40 - critical section is free and if the Q is
595:42 - not empty wake up a process select a
595:45 - process from the que and wake it up so
595:47 - this is how down and up operations is
595:48 - get performed now now comes a question
595:51 - binary sem 4 S is set to one initially
595:54 - and there are several or there is a
595:56 - series of up and down operation 10 down
595:58 - operation 2 up 18 down 3 up 4 down five
596:01 - up okay so what will be the value of s
596:04 - now you cannot directly do this 1- 10 +
596:07 - 2 + 18 now you cannot directly do
596:09 - this we have to keep track of number of
596:12 - process in the block Q so how this will
596:16 - happen let's say s = to 1 and what we
596:19 - are doing we we are performing 10 down
596:22 - operation so what will happen there will
596:25 - be nine process in the block you see P1
596:30 - process will be able to go into the
596:31 - critical section and P2 P3 till P10 will
596:34 - be
596:36 - blocked okay now what happens two up
596:39 - operations so for two up operation this
596:41 - P2 and P3 will be waken up by the
596:45 - process so P2 and P3 will be waken up
596:48 - and we are performing 18 down operations
596:51 - again so what will be the uh status of Q
596:55 - here P4 to P10 now 18 down operation so
596:58 - P4 P5 to p28 three up operation P4 P5
597:02 - and P6 will be waken up so p7 to p28 now
597:05 - four up operations four up four down
597:07 - operations which means p7 p8 from p28
597:11 - four new process will come and join this
597:13 - sleep que so
597:15 - p32 five five operations so p7 p8 P9 P10
597:18 - P1 will be wck so from p12 to
597:23 - p32 these process will be in the
597:25 - sleeping so what will be the size of Q
597:27 - size of uh Q the size will be 21 and
597:31 - what will be the final value s = to
597:33 - 0 I hope you got the point how we are
597:36 - doing this let me explain again see we
597:40 - cannot directly do like this I hope you
597:43 - know why we can't directly do like this
597:46 - because this is a binary sem for it can
597:48 - take only two values either 0o or one
597:51 - so when s = to 1 and we have performed
597:54 - 10 down operations so P1 will be able to
597:57 - go into the critical section rest
597:59 - process will get blocked so P2 P3 and
598:01 - P10 will get blocked now we have
598:04 - performed two up operation how does up
598:06 - operation work we see whether the Q is
598:09 - empty or not Q is not empty so when Q is
598:11 - not empty the value remains zero but
598:13 - what we do we wake up the two process
598:16 - from the Sleep Q so we wake up P2 and P3
598:18 - will be waken up P2 and P3 will be
598:19 - removed from on the sleeping quebe now
598:21 - P4 P5 till P10 is in the sleeping queue
598:24 - we performed 10 down operation which
598:26 - means 18 new process came and get
598:28 - blogged so these process came and get
598:30 - blogged now what we do we perform three
598:33 - up operation what
598:36 - happens the value is zero and the Q is
598:40 - not empty so we will select three
598:42 - process and wake them up P4 P5 and P6
598:45 - will be removed and from p7 to p28 they
598:48 - will be in the sleeping queue four down
598:50 - operation four new process came and join
598:51 - this queue p32 five of operation five
598:54 - process will be removed from this queue
598:56 - p7 p8 P9 P10 P1 and from p12 to
599:00 - p32 they will remain in the Sleep C and
599:03 - what is the value zero okay and what is
599:05 - the size 21 and the value is zero so I
599:08 - hope you understand what is sem 4 how
599:11 - does it work what is counting SEMA 4 how
599:15 - up and down operation works both in
599:17 - counting and binary SEMA 4 why we cannot
599:19 - increase is the value of binary S 4 just
599:21 - like as we did in the counting S 4 so
599:24 - these were some basic things which you
599:25 - should
599:27 - know let's see if semap 4 provides
599:31 - Mutual exclusion bounded waiting in
599:33 - progress or not in the previous lecture
599:35 - we have seen that counting SEMA 4 with s
599:37 - equal to 1 or binary SEMA 4 provides
599:41 - Mutual
599:42 - exclusion
599:44 - okay
599:46 - now let's okay let's see again how does
599:49 - it provide a mutual extion just for the
599:50 - sake of revision first P1 goes to the
599:53 - critical section by changing the value
599:55 - of s from 1 to 0 okay P1 is still in the
599:58 - critical section but somehow it get
599:59 - preempted now P2 wants to go to the
600:02 - critical section so first it has to pass
600:05 - the entry section in entry section it
600:07 - has to perform down operation on S
600:09 - equals to0 the value will remain zero
600:12 - but P2 will get
600:13 - blocked similarly if P3 also wanted to
600:16 - go to the critical section it has to
600:18 - first pass the entry section and the
600:20 - value of s is still zero so when it will
600:23 - perform down operation what happens is
600:25 - P3 will also get blocked so if a process
600:29 - is already present in the critical
600:30 - section it has changed the value of s
600:32 - from 1 to zero and if some other process
600:35 - wants to go to the critical section at
600:36 - the same time then s = to0 will prevent
600:40 - them from entering because performing a
600:42 - down operation on S equal to 0 the value
600:44 - will remain zero but the process get
600:47 - blocked so this is how Mutual exclusion
600:50 - is ensured now let's talk about progress
600:53 - suppose P1 P2 and P3 were the three
600:56 - process present in the ricu P1 and P2
600:59 - were the interested process and P3 was
601:01 - not interested to go to the critical
601:03 - section so I have told you several time
601:07 - that a process who is not interested to
601:09 - go to the critical section will never
601:11 - ever enters the entry
601:14 - section so P3 will never enter the entry
601:17 - section P3 will never perform a down
601:20 - operation on S so P3 will never bother
601:23 - P1 and P2 it will not become hindrance
601:25 - in the path of P1 and
601:28 - P2 if P3 is not interested she will not
601:31 - bother about us so in that case progress
601:35 - is also
601:36 - ensured let me repeat again Mutual
601:39 - exclusion is ensured because of value of
601:42 - s equal to Z if some other process tries
601:43 - to go they will get blocked progress
601:46 - will be ensured because P3 will never
601:48 - ever enters the entry section so it will
601:50 - never bother P1 and P2 okay now comes
601:54 - the interesting part let's check if P1
601:56 - can enter into critical section again
601:58 - and again while other interested process
602:00 - are sleeping can it happen which means
602:04 - does it provide bounded waiting let's
602:07 - check so P1 P2 and P3 were the three
602:09 - process present in the ricq interested
602:12 - to go to the critical section okay P1
602:16 - initially the value of s was one P1 goes
602:19 - to the ENT section section change the
602:20 - value of s from 1 to 0 present in the
602:24 - critical section now somehow it got
602:26 - preempted here P2 attempts to go to the
602:29 - critical section by first passing from
602:31 - the entry section but what happens from
602:33 - zero value will remain zero but P2 will
602:35 - get blocked so P2 is in the sleeping Q
602:38 - now P3 also attempts so P3 also performs
602:43 - done operation the value will remain
602:45 - zero
602:46 - but P3 will get
602:48 - blocked okay okay now P1 get the chance
602:51 - of CPU again it started it execution it
602:54 - performed the remaining execution of
602:56 - critical
602:57 - section goes to the exit section and
603:00 - then in the exit section what will it
603:02 - will do it will wake up P2 and put it
603:06 - back to the ricq okay by performing the
603:11 - exit section P1 is free now but it it is
603:14 - still in the CPU so what it will attempt
603:17 - it will attempt to go to the entry
603:19 - section again again P2 is in the ricq P3
603:22 - is sleeping and P1 is in the CPU okay
603:25 - the value of s is zero now so when P1
603:28 - tries to go to the critical section by
603:31 - first passing from the entry section
603:32 - what happens the value will still remain
603:35 - zero but P1 will get blocked because the
603:37 - value of s was zero so now P1 is blocked
603:40 - what happens P3 is sleeping P2 is in the
603:43 - ricu and P1 has also joined P3 so P3 and
603:47 - P1 are in the Ric are in the sleeping q
603:50 - and P2 is in the RQ P2 will get now
603:53 - chance of the CPU will start its
603:55 - execution from the remaining instruction
603:58 - from the next instruction so what is the
604:00 - next instruction the critical section
604:02 - itself so P2 will go to the critical
604:04 - section now so this is how we have
604:06 - preent prevented pre P1 to go to the
604:09 - critical section again and again if a
604:11 - process attempts to go to the critical
604:13 - critical section again it get blocked so
604:16 - this is how bounded waiting is also
604:18 - ensured and
604:22 - semaphor we are given with two
604:23 - semaphores s and t both initialized to
604:27 - one and two process process I and
604:29 - process J in entry section we have down
604:32 - on S down on T and here in process J we
604:35 - have down on T and then down on
604:37 - S for exit section up on T upon on S
604:41 - here up on S and then up on T so the
604:44 - question is does it guarantee Mutual
604:45 - exclusion and what about
604:48 - deadlock okay
604:50 - so for that we has to preempt somewhere
604:53 - in C and I have told you several times
604:55 - that whenever there are two statements
604:58 - in the entry section preempt in between
605:00 - so you remember the note so we going to
605:02 - preempt here initially the value of s is
605:05 - one and value of T is also one so let's
605:07 - say the first process I tries to go to
605:10 - the critical section goes to entry
605:13 - section down on S the value of s is now
605:16 - zero preemption process J comes
605:21 - down on T tal to Z okay preemption now
605:25 - process I
605:26 - again down on T the value of T is
605:30 - already zero so when it perform down on
605:32 - T process I will get blocked now it is
605:34 - the chance of process J down on S the
605:37 - value of s was already
605:38 - zero P process J will also get
605:42 - blocked so if preemption occurs here in
605:45 - the both process and then the other
605:48 - process continue from the next section
605:50 - both of the process gets blocked and
605:52 - there is no one to wake them
605:54 - up because in sem force it is the duty
605:58 - of other process to wake the sleeping
606:00 - process and here both the process are
606:02 - sleeping
606:03 - comfortably who is going to wake them up
606:06 - so this is the case of Deadlock so when
606:10 - preemption happens here Pi will be
606:11 - blocked and PG will be blocked too is
606:14 - deadlock present yes deadlock is present
606:16 - now the question is does it guarantee
606:18 - Mutual exclusion let's see so first what
606:22 - happens the case is again from the
606:24 - starting s = to 1 and T = to 1 process 1
606:27 - goes to the critical
606:29 - section change the value of s to 0
606:31 - change the value of T to 0 goes to the
606:34 - critical section somehow got preempted
606:36 - before it can complete the critical
606:37 - section now it is the chance of process
606:39 - J to go to the critical section attempts
606:42 - down on T get blocked so if a process is
606:46 - already present in the critical section
606:48 - the other process can not go so does it
606:50 - does it guarantee Mutual exclusion no it
606:53 - is not possible you can preempt anywhere
606:55 - in check Mutual exclusion is present and
606:58 - Deadlock is also present so deadlock is
607:02 - there preemption between the two of the
607:03 - down
607:04 - operations now the question
607:07 - arises if I preempt between these two
607:09 - down operation deadlock happens can
607:11 - something be done that even I preempt
607:15 - after the first instruction that
607:17 - headlock is saved can something be done
607:20 - think about it pause the video think
607:22 - about it can something be done yes the
607:25 - sequence of both the process performing
607:27 - down operation should be the same in
607:30 - above question the sequence was reversed
607:32 - that was the case when deadlock was
607:34 - occuring let's
607:35 - see if the sequence of both the process
607:38 - performing down operation is same so we
607:40 - are taking the case this to thick m p of
607:45 - s p of T and here P of S and P of T not
607:50 - changing the sequence now when s = to 1
607:54 - comes to this it changes the value of s
607:56 - to0 we are preempting
607:58 - here now it is the chance of process J
608:02 - process J again start with performing a
608:04 - down operation on S the value of s was
608:06 - already zero so this process will get
608:10 - blocked I hope you are getting the point
608:13 - deadlock was occurring because the
608:15 - sequence was different if the sequence
608:17 - was same PS is PS will will perform the
608:19 - down operation on S and then process G
608:22 - when tries to do the same it gets
608:24 - blogged so this is how deadlock can be
608:26 - preempted if the sequence is
608:29 - different okay so this was a nice
608:31 - question let's move to the question
608:33 - number two byus semor s = to 1 and tal
608:37 - to 0 so now we have two sem fores s and
608:39 - t the value of s is initialized to 1 and
608:41 - T to Zer there are two process process I
608:44 - and process J okay this is the critical
608:48 - section and these are the entry section
608:50 - entry and exit section respectively
608:52 - entry and exit section respectively okay
608:54 - so the question is what is the regular
608:57 - expression that gets generated when
609:00 - these two work
609:02 - concurrently suppose firstly process I
609:05 - wants to go to the critical section p on
609:08 - T which
609:09 - means if the value of T is set to zero
609:13 - it is necessary that process J should
609:16 - start first because if process I tries
609:18 - to start first it gets blocked so
609:21 - process J will start
609:22 - first s = to 1 PS it will perform a down
609:27 - operation on S the value of s will now
609:28 - be zero goes to the critical section
609:31 - print 0o print zero okay so what does
609:35 - this suggest this suggest that the
609:37 - regular expression that will be
609:38 - generated in that regular expression
609:40 - zero will be printed
609:42 - first okay now the case can arise can I
609:47 - preempt here and start from this
609:49 - no because until the value of T is
609:53 - increased 1 cannot be pred so first two
609:56 - Z will be there okay so I have written I
610:01 - explained the same thing s = to 1 and T
610:02 - = to 0
610:04 - if tal to 0 if this tries to go there it
610:08 - get blogged so firstly we have to start
610:10 - with PJ s = to 0 both are printed now
610:14 - when the value of t equal to 1 is there
610:16 - so when this both 0 and0 will be printed
610:19 - and then the up operation will be
610:20 - performed on this SEMA 4 T when the up
610:24 - operation will be performed the value
610:25 - will be
610:27 - one okay so now we can go
610:31 - there perform down on T now the value
610:33 - will be zero then print one and then
610:37 - print
610:38 - one so now again the question arise can
610:42 - I preempt here and then from Start From
610:44 - Here Again can it be
610:47 - possible no it is not possible because
610:50 - the value of s was changed to Zero by
610:54 - this statement so 0 will not come again
610:57 - until this vs is executed let me speak
611:01 - again from the beginning so first we'll
611:03 - start from here print two
611:05 - zeros make the value of T2 1 we'll start
611:08 - from here print 2 one and then we will
611:10 - change the value of S2 again 1 okay so
611:14 - the answer will be 0 0 1 1 0 0 1 1 and
611:19 - this will keep on going on okay so 0 0 1
611:22 - 1 plus repeat so this will this is the
611:25 - regular expression that will be
611:29 - generated okay so I hope you got the
611:31 - point we are going on alternatively
611:34 - because of these in process I we are
611:38 - performing a down operation on T but up
611:40 - operation on S similarly in process J we
611:43 - are performing down operation on S but
611:44 - up operation on T so this will ensure
611:46 - the alternative printing of 0 and one so
611:49 - for Zer and then ones Zer and then ones
611:52 - and why not 1 1 0 0 1 1 0 0 why not this
611:56 - because the initial value of T was set
611:57 - to zero okay now the question arise does
612:01 - it
612:02 - ensures Mutual exclusion progress and
612:04 - bounded waiting let's
612:06 - check Mutual exclusion is ensured
612:09 - because until a process increases the
612:12 - value of t or
612:13 - s or I can say until a process completes
612:17 - its exit section other process cannot
612:19 - start to go to the critical section this
612:22 - is clear so mutual exclusion is ensured
612:25 - does it provides progress let's check
612:29 - suppose suppose PJ is uninterested to go
612:32 - to the critical section if PJ is
612:35 - uninterested can Pi can go no let me
612:40 - speak again PJ is not interested to go
612:42 - to the critical section so PJ will never
612:44 - ever go to the entry section will never
612:46 - ever go to the exit section and will not
612:48 - increase the value of T and if the value
612:51 - of T is zero then Pi can also not go to
612:54 - the critical section in this way an
612:57 - uninterested process is hindering the
612:59 - progress of interested process so
613:01 - progress is not guaranteed progress is
613:05 - not there bounded waiting can a process
613:08 - go again and again again and again again
613:09 - and again while some other interested
613:11 - process is waiting no we have seen that
613:13 - alternation is ensured first 0 0 then 1
613:16 - one then 0 0 then 1 one so yes Mutual
613:20 - exclusion ured progress not and bounded
613:21 - waiting is
613:23 - ured okay so we can say that Mutual
613:26 - exclusion there progress not there and
613:27 - Boundary diving implication of a strict
613:29 - alternation Pi cannot enter until PG
613:32 - exits from exit section so this is this
613:34 - was an also a nice question let's move
613:36 - to the question number
613:37 - three we are given an array of binary S
613:40 - 4 we name it as M and it it consist of
613:44 - five elements and all initialized to one
613:47 - so m0 initialized to one M1 initialized
613:51 - to one M2 initialized to one so in this
613:53 - way till M4 it is initialized to one so
613:55 - there are five binary s fors all
613:58 - initialized to one now there
614:01 - are five processes also from 0 to 1 so p
614:05 - 0 P1 P2 till P4 are the five
614:09 - processes involved in this question and
614:13 - we are given a code of each process also
614:15 - while
614:17 - one p of MI i p of m i + 1 mod 4
614:22 - critical section so this is the entry
614:25 - section and this is the exit section so
614:27 - we should write the code of first
614:30 - process to get a better understanding so
614:31 - we are writing the code of p 0
614:34 - here okay p 0 the first statement will
614:38 - be P of m0 which means for process0 the
614:41 - binary S
614:42 - 4 value will be decreased and for p of
614:47 - M1 which means the binary process the
614:49 - binary semaphor of process one process
614:52 - one will also be decreased to zero so if
614:56 - p 0 tries to go to the critical section
614:58 - m0 will be made zero M1 will also be
615:01 - made
615:03 - zero okay goes to the critical section
615:07 - performs an un up operation on both m0
615:10 - and M1 so this is how a process is
615:12 - working and why this percentage mode for
615:16 - for the circular thing for case for this
615:18 - case when we are writing the code of P4
615:21 - then we are thinking we are talking
615:23 - about P4 and p 0 so that's why we are
615:26 - using a mod for the circular thing okay
615:29 - so p 0 and P1 for this p 0 uh I should
615:34 - write this m0 and M1 for p 0 M1 and M2
615:38 - for P1 M2 and M3 for P2 M3 and M4 for P3
615:45 - and M4 and m0 for P4
615:49 - this is how it works okay so we are
615:51 - writing the code for P1
615:55 - also M1 M2 critical section M1 M2 I hope
615:59 - you got the idea okay so what I was
616:00 - doing I was explaining the question so
616:02 - now the question is what is the maximum
616:05 - number of process that can be in the
616:07 - critical section so what is the maximum
616:09 - number of process p 0 Let's first start
616:12 - directly P0 wants to go to the critical
616:13 - section decreases the value of m0 and M1
616:16 - is in the critical section let's say
616:18 - preemption happens here
616:19 - P1 tries to go to the critical section
616:22 - P1 will get blocked because p 0 has
616:24 - decreased the value so P1 will get
616:27 - blocked now let's talk about P2 can P2
616:31 - enter P2 can enter because it doesn't
616:34 - contain m0 or M1 so P2 can enter P2 will
616:37 - change the value of M2 and M3 to zero
616:40 - now let's check for P3 can P3 enter so
616:43 - M3 and M4 is included in P3 but P2 has
616:46 - changed the value of M3 so for this
616:49 - reason P3 will also get blocked now the
616:51 - question for P4 can P4 enter no because
616:54 - m0 was made to zero so P4 will also get
616:57 - blocked so p 0 and P2 can be in the
617:00 - critical section at the same time Mutual
617:03 - exclusion not guaranteed so the question
617:05 - was what is the maximum number of
617:07 - process that can be in the critical
617:08 - section
617:09 - two okay I think I should explain the
617:13 - question from the beginning again and
617:14 - should give you a brief idea again so
617:16 - the question was we have a array of
617:18 - binary sem4 forget about this we are
617:20 - given with m0 and M1 that will be
617:22 - included in the code of process p 0 so
617:25 - when p 0 tries to go to the critical
617:27 - section it decreases the value of two
617:30 - binary semaphores itself and the other
617:33 - one so m0 and M1 will be made to zero
617:37 - for case of P1 M1 and M2 will be made to
617:40 - zero so in this way the thing goes on
617:43 - now the question is how many processes
617:45 - can go into the critical section at the
617:46 - same time that's what we are checking so
617:49 - for case of p
617:50 - 0 it decreases the value of m0 and M1 to
617:54 - 0 when P1 tries to go due to P0 this
617:58 - Mischief P1 cannot go P1 will be blocked
618:02 - now for the case of P2 can P2 go yes
618:05 - there's no one blocking P2 M2 and M3
618:07 - will be made to zero and P2 will pass
618:09 - can P3 go to critical section no because
618:12 - P2 has made the value of M3 to0 so P3
618:14 - will also be blocked can P4 go P4 will
618:18 - also not be able to go because the value
618:19 - of m0 was made to Z by p 0 that's why P4
618:23 - cannot go to the critical section so the
618:26 - two process which can go are P2 and p 0
618:29 - and
618:30 - P2 I hope it's clear
618:33 - now or you can do like that also uh
618:36 - let's start with P1 if P1 can go to the
618:40 - critical section then apart from P1 P3
618:42 - can go and D all will be blocked okay so
618:46 - this is how this
618:47 - work now Mutual exclusion is not
618:50 - guaranteed the question number two does
618:51 - it uh suffer from deadlock let's
618:54 - see what happens
618:58 - is as there are two instructions in the
619:00 - critical section we say preempt in
619:03 - between so we preempt it from here here
619:06 - here here and
619:09 - here this is a dangerous Case C if I
619:12 - preempt it from here the value of M will
619:13 - be Chang m0 will be zero if I PRT it
619:15 - from here the value of M1 will be Zer
619:18 - and for this case M2 will also be zero
619:20 - for this case M3 will be Z and for this
619:22 - case M4 will be zero all of them are
619:24 - made to zero all of the process for
619:26 - perform their first instruction and get
619:29 - preempted and they will wait on each
619:31 - other for their second
619:32 - instruction they cannot go the c p 0
619:36 - performs the first instruction okay and
619:38 - get preempted P1 performs the first
619:40 - instruction and get preempted so the
619:42 - value of binary sem4 is now zero for all
619:45 - of the M when p 0 will start performing
619:49 - this it will get blocked when P2 will P1
619:51 - will start performing this it will get
619:52 - blocked for P2 blocked in this way P3
619:56 - and P4 will also get blogged all of the
619:58 - process are now blogged and no one is
620:00 - there to wake them up so this is a case
620:02 - of
620:04 - Deadlock let's see another interesting
620:06 - question binary semap 4 S T and z are
620:10 - given so the initial value of s is 1 and
620:12 - T and z are zero so what can you say by
620:15 - seeing this only you can say that
620:17 - whichever process which is using T and
620:19 - Zed as their semap 4 in their entry
620:22 - section those process cannot start
620:25 - first so PJ and PK cannot start first so
620:30 - Pi will be bound to start first because
620:33 - the value of s is one
620:35 - okay this is the entry section this is
620:37 - the exit section and this is the
620:38 - critical section while one which means
620:41 - Pi can run again and again PG and PK
620:43 - will run only once because they don't
620:45 - have any while loop here okay so let's
620:49 - see the flow Pi while one it will change
620:53 - the value of s20 print and star and then
620:56 - it will invoke pi and PK PG and PK so it
621:01 - will change the value of T from 0 to 1 Z
621:03 - from 0 to
621:05 - 1 enabling PJ and PK to run okay so now
621:10 - the value of T 1 T = to 1 will be
621:14 - changed to zero in this statement and
621:17 - then VSS
621:19 - so now PJ and PK PJ and PK are helping
621:22 - pi to run again and
621:24 - again okay now the question is what is
621:27 - the minimum and maximum number of stars
621:29 - that can get printed can you tell me the
621:32 - maximum and minimum number of stars see
621:35 - Pi is helping PG and PK and PG and PK
621:39 - are helping pi to print more and more
621:41 - stars
621:43 - so initially the value of s was one
621:46 - changed to zero but here the value value
621:48 - of s was again changed to one and then
621:51 - when PK will run after PJ it will
621:54 - perform an an up operation on value
621:58 - one performing an un operation up
622:00 - operation on value one is going to waste
622:03 - that up operation
622:05 - because up the value will remain the
622:08 - same so this is the main point that you
622:10 - have to focus upon that you cannot
622:13 - increase the value more than one if this
622:15 - is the case you are wasting an up
622:17 - operation here
622:19 - so why why can't you fit Pi again in
622:21 - between to get the maximum number of
622:23 - stars what I'm saying is if you perform
622:26 - like this Pi PJ and PK and then
622:30 - Pi you are getting two
622:32 - stars and but if you doing like this Pi
622:35 - PJ and then you are enabling Pi again
622:38 - here pi and then PK and then again Pi
622:42 - you are getting three stars
622:44 - here okay if you're feeling difficulty
622:46 - in it let me give you a nice explanation
622:49 - here okay initially the value was set to
622:52 - one it will go here change the value to
622:55 - zero print an star change the value of
622:59 - VT and v z to one so now the value of T
623:02 - is 1 and Zed is 1 this operation will be
623:05 - performed the value of T will become
623:06 - zero now and value of Z will become zero
623:09 - okay now vs so the value of s was
623:12 - initially zero it will change back to
623:14 - one and then if you perform directly PK
623:17 - after PJ then
623:19 - this the value was one up operation will
623:22 - performed on one the value will still
623:24 - remain one and then if you try to
623:28 - perform Pi again the value was one it
623:31 - can go again there print another
623:33 - star and then we'll change the value of
623:36 - VT and VZ back to one but even after VT
623:39 - and VZ even after T and Zed are one
623:42 - again these process cannot run because
623:45 - there is no while loop in in
623:47 - them they are destined to run only once
623:52 - so these will not run again now when p p
623:56 - tried to run
623:57 - again it cannot run the value was Zero
624:00 - okay so in this way only two stars can
624:03 - get
624:04 - printed okay but now what we are doing
624:06 - we
624:07 - have enabling Pi here also so when pi
624:12 - will be performed here let me uh give
624:14 - you an idea so we have enabled Pi here
624:18 - Pi will run first change the value of s
624:20 - to zero and then it this will run change
624:23 - the value of s to one again now if we if
624:26 - we use Pi here the value of s will be
624:28 - changed to zero and then we use PK it
624:32 - will change back to one and then we can
624:33 - use again Pi
624:35 - here by using pi in between PG and PK we
624:38 - are utilizing an up operation that was
624:41 - being wasted in the previous case so
624:44 - this is how we can get maximum and
624:46 - minimum number of stars
624:48 - let's see another variation of this
624:50 - question in which we are not using VZ
624:53 - here this is the
624:56 - question okay so here in this question
624:59 - we are not using VZ here there's no VZ
625:02 - here so what are we
625:04 - doing Pi is enabling PJ PJ is enabling
625:10 - PK and PK is again enabling Pi so in
625:13 - this case a type of cycle is being
625:16 - formed so what will happen now
625:19 - now s equals to initially was one will
625:22 - be changed to zero one star will be
625:24 - printed PJ will be enabled and then PK
625:28 - will be
625:29 - enabled Z will be changed back to zero s
625:32 - will be changed back to one again P will
625:34 - run another star will
625:37 - print and then value of T will be
625:39 - changed to one but unfortunately there's
625:43 - no while loop in P PG and
625:45 - PK so PG and PK cannot run again cannot
625:50 - increase the value of s again that's why
625:52 - two stars will be printed only in every
625:55 - case which means the maximum and minimum
625:57 - number of stars that can be printed were
625:59 - only
626:00 - two okay so this is an homework question
626:03 - what does this say consider a counting
626:06 - SEMA 4 initialized to two there are four
626:08 - concurrent process Pi PJ PK and pl the
626:11 - process pi and PJ desire to increment
626:13 - the current value of variable C by 1 so
626:15 - p i and PJ will increase the value of C
626:18 - by
626:19 - 1 whereas PK and PK PK and pl decrement
626:23 - the value of C by 1 PK and pl will
626:26 - decrement by one minus what can be the
626:30 - minimum and maximum value of C after all
626:32 - the process finish their update and
626:34 - remember the value of counting sem 4 is
626:36 - two so value of counting sem 4 was two
626:38 - pi and PJ wants to increase the value
626:41 - and PK and pl wants to decrease the
626:43 - value
626:45 - okay and a process will execute only
626:48 - once there's no while loop now you have
626:50 - to tell what is the maximum and minimum
626:52 - value of C after all the process finish
626:55 - their update okay so you can write the
626:57 - code of process like that process X
627:01 - increment decrement increment and then C
627:05 - = to C+ -1 depends on the process for I
627:07 - and J the value will be plus and for K
627:09 - and L the value will be minus and this
627:12 - is not a single operation it consists of
627:14 - three micro operation load increment
627:16 - decrement and store So based on this you
627:19 - have to think where to preempt where not
627:21 - and then you have to tell me the maximum
627:24 - and minimum possible value of C after
627:28 - all the process finished their
627:36 - update okay let's see some more
627:38 - questions consider three processes using
627:40 - four binary sem4 a b c and d in the
627:43 - order shown below which sequence is a
627:45 - deadlock free sequence Okay so so we
627:49 - need to preempt in such a manner that in
627:52 - any preemption cases even one of the XY
627:54 - Z is able to complete then it is
627:56 - deadlock free and if not then deadlock
627:58 - is present so we are given with binary
628:01 - semop fores which means they are all
628:03 - initialized to
628:04 - one initialize to one okay so we need to
628:08 - see which sequence is deadlock fore so
628:10 - let's start with option one PA a value a
628:13 - changeed to zero PB value B changed to
628:16 - zero and PC value C changed to zero okay
628:19 - now PB it will get stuck here PC will
628:22 - get stuck here and PD value changeed to
628:25 - zero PC will get stuck PD will get stuck
628:29 - and Pa will get stuck so all of them are
628:31 - stuck this sequence is not deadlock free
628:33 - so this is how you have to attempt let's
628:35 - move to option two
628:38 - PB uh change to
628:40 - zero then again PB stuck PA change to
628:43 - zero PA a stuck PC change to zero now
628:48 - again PC stuck PC stuck PD change to
628:51 - zero and then again
628:55 - stuck now what you can see all see all
628:58 - of them are not stck like in the case
629:00 - one what will happen now PD will start
629:04 - executing so the process with sem4 d
629:07 - will start executing because this
629:09 - process has not been blocked so PD is
629:12 - going to release its sem4 at some point
629:15 - so when it will release this D from
629:17 - block block state will come back and
629:20 - when this will come
629:21 - back D will be going to execute it
629:24 - coming back there at this line okay so
629:28 - this C let me use some different pen
629:30 - this C is going to be executed because
629:33 - this is not blog so it's going to
629:35 - release release its semaphor at some
629:36 - point so what will happen this C this
629:39 - blogged c will come back to life okay so
629:42 - this has this has completed this has
629:44 - completed and this has already been uh
629:47 - has never been blocked
629:48 - so all of these are completed so this
629:51 - sequence is not deadlock free you cannot
629:53 - preempt in any case which you want and
629:56 - lead to a deadlock this won't happen
629:58 - Okay so this sequence is deadlock free I
630:00 - can guaranteed say that option two is
630:02 - deadlock free let's check for some more
630:05 - options B will change to zero c will
630:08 - change to zero a will change to zero
630:10 - then
630:12 - deadlock okay so this is not deadlock
630:15 - free obviously a will change to z c will
630:18 - change to zero blogged B will change to
630:21 - Zero blogged D change to zero c blogged
630:25 - d blocked a blocked so this is again
630:29 - going to lead to deadlock so option two
630:31 - is the deadlock free sequence okay I
630:33 - have explained it here also so because
630:38 - how option two is not deadlock because
630:40 - it's going to release the resources it
630:42 - SEMA 4 at some point later so it will
630:44 - change the value back to one okay so
630:47 - this is how this is not deadlock free
630:49 - it's time for the homework
630:51 - problem so each of the set of n process
630:53 - executes the following code using two
630:55 - semaphor A and B so there are two
630:57 - semores A and B A is initialized to one
631:00 - b b is initialized to zero and there is
631:02 - a shared variable named count which is
631:04 - initialized to zero and it is not used
631:07 - in code section P so there is a code
631:09 - section P then some lines of code and
631:10 - then code section Q what does this line
631:13 - of code say perform weight on a and then
631:16 - increase the value of count
631:18 - if count equals to number of process
631:20 - then signal on B signal on a weight on B
631:23 - signal on B so let me explain you more
631:27 - uh clear way let's say there are three
631:30 - process P1 P2 and P3 okay so P1 first
631:35 - performs the code section P now it has
631:38 - to perform weight on a so it will change
631:41 - the value of a from 1 to Z the value of
631:44 - count will be increased the value of
631:45 - count will be increased and this won't
631:48 - be performed because the value of count
631:49 - is not equals to one perform signal on a
631:52 - we perform signal on a change the value
631:54 - of a to one and wait on B see the value
631:57 - of B was initially zero so this will be
632:00 - blocked another process comes let's say
632:02 - P2 comes goes to the code section P
632:06 - perform weight on a same thing goes to
632:08 - code section P perform weight on a does
632:10 - the count equals to number of process no
632:12 - increase the value of a and get blocked
632:14 - okay now another process P3 comes
632:16 - performs code section p
632:18 - P perform uh weight on a so the value of
632:23 - a will be changed back to zero does the
632:26 - count equals to the number of process
632:27 - yes now the count is equals to number of
632:29 - process change the value of uh B to 1
632:33 - signal on B We performed signal on B
632:36 - signal on a we change the value of a
632:38 - back to one and then perform weight on B
632:41 - We performed weight on B and then signal
632:43 - on B and then performed the code section
632:45 - Q So based on this you you have to
632:48 - answers you have to answer or choose
632:49 - among these of the four options the
632:51 - first option says it ensures that no
632:53 - process execute code section Q before
632:56 - every process has finished code section
632:58 - P it ensures that two process are in
633:01 - code section Q at any time it ensures
633:04 - that all the process execute code
633:06 - section P mutually
633:08 - exclusively it ensures that at most n
633:10 - minus1 process are in code section P at
633:12 - any time so out of these four options
633:14 - you have to select okay so this is a
633:16 - homework question
633:18 - now this is an interesting problem
633:20 - consider two functions increment and
633:22 - decrement increment goes like this
633:23 - weight on S increases the value of
633:25 - signal on S weight on S decreases the
633:28 - value signal on S and the initial value
633:30 - of x is given as 10 five process invoke
633:33 - increment and three process invoke
633:35 - decrement X is a shared variable
633:37 - initialized to 10 okay so there are two
633:40 - cases case one and case two case one
633:42 - says the value of s is set to one and it
633:45 - is a binary semap 4 and case two says
633:47 - the the value of s is set to two and it
633:49 - is a counting S 4 so what can you infer
633:51 - from this for case one we have to do
633:53 - sequential execution and for case two we
633:56 - can let two process enter into the
633:58 - critical
633:59 - section and for these two cases V1 and
634:02 - V2 are the values minimum possible
634:04 - values of the implementation of in i1
634:05 - and I2 then chooses for the value of x
634:09 - for V1 and V2 okay so V1 and V2 are the
634:11 - minimum possible values of X when i1 and
634:14 - I2 are implemented so we have to now
634:17 - tell the value use of V1 and V2 so how
634:19 - how are we going to approach this
634:21 - question let's say there are five
634:23 - process P1 P2 P3 P4 and P5 interested
634:26 - for the increment and three process P6
634:29 - p7 p8 interested for the
634:31 - decrement okay so the weight this is the
634:34 - increment function weight on S increases
634:36 - the value signal on S but this is not a
634:39 - single single statement this consist of
634:42 - three micro operations load increment
634:44 - and store similarly wait on S decrement
634:47 - load decrement store and signal on S so
634:50 - this is how it work and for case i1 the
634:53 - value of s is one which means we have to
634:55 - do sequential
634:57 - execution okay so P1 will come increases
635:00 - the value P6 will come and decrease the
635:02 - value so anyhow they perform in any
635:05 - order the value will remain 12 why 10
635:07 - was the initial value five process for
635:10 - incrementation and three for
635:11 - decementation the value will remain 12
635:13 - no matter how what is the order of these
635:15 - process let's say P1 and then then P6
635:18 - and then p7 and then p8 and then P2 and
635:20 - then P4 and then P3 and P5 no matter
635:23 - what be the order the value for case 1
635:26 - will be 12 the minimum value will be 12
635:28 - okay or I can say the maximum will also
635:30 - be the 12
635:32 - because no matter how the process
635:34 - executes the value will remain 12 I have
635:37 - already told you so the the minimum and
635:39 - maximum is the same for case two the
635:41 - things get interesting because now there
635:44 - are two process that can be into the
635:46 - critical section
635:48 - okay and if there are two process in the
635:50 - critical section what will happen the
635:52 - rise condition two process will raise to
635:55 - update the value of s of X and if two
635:58 - process raise to update the value of x
636:02 - we should let the decrement one win so
636:05 - that we get the minimum possible value
636:07 - of uh X so what are we doing we are
636:11 - making these process race P1 and P6 and
636:14 - let P6 win P2 and p7 and let p7 win P3
636:18 - and p8 and let p8 win and then P4 and P5
636:22 - will run but do not let them run
636:25 - individually we are going to race
636:27 - between them also for P4 and P5 we will
636:30 - let any of them one win so what will be
636:32 - the value
636:34 - 10 and then P6 win so 9 and then p7 win
636:39 - and then 8 and then p8 win and then
636:41 - seven and out of these two anyone will
636:44 - win so eight again so the final value
636:47 - should be8 so the value answer should be
636:50 - 12a 8 but don't be too don't be in too
636:55 - hurry to take the answer because this is
636:57 - wrong why it is wrong see we are going
637:01 - to we are letting two process race so
637:05 - what are we basically doing we are
637:06 - wasting P1 P2 and P3 we are
637:09 - intentionally wasting P P1 P2 and
637:12 - P3 by fighting it to P6 p7 and p8 so P1
637:16 - P2 and P3 are wasted and among them we
637:19 - have uh made any one of them win so the
637:22 - final value should be it how it is wrong
637:25 - let me tell
637:26 - you let's say initially P1 and P6 were
637:30 - in the
637:30 - fight P1 has completed its load
637:34 - increment and
637:35 - store but what happened P6 P6 has
637:40 - completed its load liement but somehow
637:43 - it has not stored its value
637:47 - in critical section the two process
637:49 - which were there in initially was P1 and
637:51 - P6 P1 has completed and changed the
637:54 - value of x from 10 to
637:56 - 11 and P6 is still in execution it has
638:01 - not executed its instruction 3 so the
638:04 - store instruction is not executed by P6
638:06 - now what will happen P1 will go out
638:11 - and P2 will come P2 will increase the
638:14 - value again from 12 but P6 has has
638:17 - intentionally not completed its third
638:19 - instruction that is
638:20 - stored okay now what will happen P2 has
638:24 - completed all these three instructions
638:25 - and then P3 will
638:27 - come P3 will change the value from 12 to
638:29 - 13 but P6 is doing some mischief and it
638:33 - is not executing its third instruction
638:36 - so store will now also not executed P3
638:39 - has changed the value to 13 now it is
638:42 - time for P4 P4 came changed the value
638:44 - from 13 to 14 P6 is still not P6 has
638:49 - still not executed in store now it's
638:51 - time for P5 P5 completed the value has
638:54 - changed to 15 now the value of x is now
638:57 - 15 but P6 has still not executed its
639:02 - instructions now what will happen when
639:04 - P5 has stored P5 is stored the value of
639:08 - 15 now P6 comes and say Hey I want to
639:11 - store the value so the OS asks P6 what
639:15 - is your value P6 says
639:18 - when I was doing my computation I did on
639:22 - like this so now the value which I want
639:24 - to store is
639:25 - nine so P6 is going to store the value
639:29 - from 15 to 9 see this uh see the
639:34 - cunningness of
639:35 - P6 from 15 it has changed back to it 9
639:38 - now p7 comes now p7 comes and then among
639:43 - p7 p8 they have made such a uh coalition
639:47 - between them that p7 says hey p8 you
639:51 - first decrements the value p p says okay
639:54 - so it's it has stored the value 8 now p7
639:57 - says now I will store
639:59 - now so the minimum value is now 7 that's
640:02 - why I have said don't be hurry to take
640:04 - the answer because 12a 8 was also
640:07 - present in the option so many of your
640:10 - students must have chosen this but the
640:11 - correct answer is 12a 7 so this was the
640:14 - question from the gate examination of
640:15 - India
640:17 - amazing
640:19 - question
640:21 - okay so this I have written everything
640:24 - in form of statement so that it would be
640:27 - easy for you to read again for revision
640:30 - purposes so initially s = to 22 process
640:32 - can be in critical section at the same
640:33 - time let them raise to update the value
640:35 - of x and then always makes makes the
640:37 - decrement one win so this was our first
640:39 - approach so among P6 and P1 and P6 we
640:41 - made P6 win P2 and p7 we made p7 win and
640:45 - then among P4 and P5 we made anyone win
640:48 - so the final value which we thought of
640:50 - is eight but this was wrong then a idea
640:54 - pop into our mind that is it necessary
640:56 - to store the decreased value of count
640:57 - after only one increment so let all P1 P
641:01 - P1 P2 P3 P4 and P5 increment it to 15
641:04 - and now P6 stores its value from that is
641:06 - X = to 9 and then p7 P had come X = to 7
641:10 - is the final answer if you want more
641:13 - clarity or another way of of proceeding
641:17 - I have written this you can read this
641:19 - same thing but uh some different way to
641:22 - uh Express okay in the next lecture we
641:25 - are going to see some classical IPC
641:26 - problems producer consumer now this now
641:29 - the correct implementation reader writer
641:31 - and dining
641:34 - philosophers okay let's discuss the
641:36 - homework problem first and then we'll
641:37 - move to the producer consumer problem
641:39 - okay so we were given with a variable C
641:42 - equals to Z initialized to zero and two
641:45 - process pi and PJ wants to increments
641:47 - the value of c and PK and pl were
641:50 - wishing to decrement the value of C we
641:52 - have seen that counting Su of 4 S = to 2
641:54 - means two process can be in the critical
641:57 - section at the same time and in this
641:59 - question we had to find the minimum and
642:01 - maximum value of C so for minimum value
642:05 - we will put these two in the critical
642:06 - section and let both them race and make
642:10 - pkin similarly we did in the last
642:13 - lecture last
642:14 - question we make them PJ and P PG and pl
642:18 - race and let PL win so the value minimum
642:21 - value will be
642:23 - min-2 okay and for incrementing part for
642:27 - the maximum value what we'll do we'll
642:29 - make pi and PJ win so the maximum value
642:31 - will be two minimum value will be min-2
642:34 - and if I say binary SEMA 4 instead of
642:37 - using counting SEMA 4 you are using
642:39 - binary sem 4 S = to 1 then what will the
642:42 - minimum and maximum value the minimum
642:45 - and maximum value will be same which
642:47 - will be C equals to
642:49 - Z see by using binary semop 4 race
642:53 - condition is eliminated so pi and PJ pi
642:56 - and
642:57 - PK only one process can be in the
643:00 - critical section at the same at the time
643:02 - so Pi will be in the critical section
643:04 - will increase PK then will come and
643:05 - decrease PJ will come and then again
643:08 - increase and pl will come and then again
643:10 - decrease so the process will execute
643:14 - sequentially that's why for binary 4 the
643:17 - value will
643:18 - be zero for minimum and maximum case
643:22 - both now comes the producer and consumer
643:24 - problem the interesting thing till now
643:26 - we have seen two implementations of
643:28 - producer consumer problem the first one
643:30 - was busy waiting the second one was
643:31 - sleep wake up busy waiting suffers from
643:34 - inconsistency and sleep wake up suffers
643:36 - from deadlock remember when producer and
643:38 - consumer both are sleeping comfortably
643:40 - in the Sleep queue thinking that other
643:42 - will other one will wake them up but
643:44 - both were
643:45 - sleeping so these were the incorrect
643:48 - implementations now we are going to see
643:50 - the correct implementation using semap
643:53 - fores so we are going to define the
643:55 - bounded buffer of size 100 okay so these
643:58 - were the global variables bounded buffer
644:00 - of size 100
644:02 - okay now instead of defining the count
644:04 - thing the count variable what are we
644:07 - doing we are defining two counting semap
644:09 - fores empty and full initially all the
644:13 - slots are empty so we are defining mtal
644:15 - to n and initially no no one was full
644:18 - all the slots were empty that's why full
644:20 - was zero and then binary S 4 MX = to 1
644:25 - used between producer and consumer to
644:26 - ensure Mutual exclusion between buffer
644:29 - and these two were used for condition
644:31 - checking okay now let's see the producer
644:34 - code item P this will be the produced
644:37 - item in equals to Z I hope you remember
644:39 - what is in in is the next empty slot for
644:42 - producer to place an
644:44 - item so initially the in will be set to
644:46 - zero
644:48 - we are going to place the produced item
644:50 - into item P this was the non-critical
644:52 - section and now we are defining the
644:55 - entry section the entry section consist
644:56 - of two down operations the first is down
644:58 - on
645:00 - empty can you tell me when the producer
645:02 - process needs to be blocked when all the
645:06 - slots are full at that case producer
645:09 - should stop that's what we are doing
645:12 - here if Mt equals to Z which means all
645:15 - the slots are full we need to to stop
645:17 - the producer that's why we are
645:18 - performing down operation on
645:22 - empty and then we are performing down
645:24 - operation on mutex so this is just for
645:27 - the mutual
645:29 - exclusion and then the intersection is
645:31 - completed now comes the critical section
645:33 - we are going to place that buffer place
645:35 - that item P that is the produced item
645:37 - into the buffer where at index in that
645:39 - is the empty slot and then we are going
645:41 - to increase the value of Mt slot after
645:43 - placing that item in equals to n+ 1% per
645:47 - n okay and now comes the exit section we
645:51 - are going to up the MX upon full y upon
645:54 - full because we have increased a value
645:58 - which value see initially the full was
646:01 - Zero we have incremented one so now the
646:04 - full will be one now comes the code of
646:07 - consumer item c will be the consumed
646:09 - item out equals to
646:11 - zero remember what out signify it
646:14 - signify the index from which cons conser
646:17 - can consume an item while one down on
646:20 - full we need to stop the consumer when
646:23 - there is no item to consume in the
646:25 - buffer so that case full equals to zero
646:30 - so we will perform down on
646:33 - full when full is zero which means there
646:35 - is no item to consume then we need to
646:37 - block the consumer and down on mutex
646:39 - just for the mutual exclusion item c
646:42 - will be the consumed item increase the
646:44 - value of out upon mutex up empty why
646:47 - upon empty because we have made another
646:52 - slot empty consumer has consumed from an
646:55 - item so the value of empty slot will
646:56 - increase that's why upon Mt and then
646:59 - consume item item C this is the
647:00 - non-critical section
647:02 - again so this is how producer and
647:04 - consumer work by the help of sem for so
647:07 - this is a correct
647:09 - implementation now the question arise
647:11 - how producer and consumer are in
647:15 - cooperation so here it is written
647:18 - this were the implementation this was
647:22 - the producer implementation and this was
647:23 - the consumer
647:26 - implementation see the producer wakes up
647:28 - the consumer here producer wakes up the
647:31 - consumer here and consumers wake up the
647:33 - producer here so this is how they are
647:35 - both in cooperation
647:38 - okay so you need to remember these Five
647:40 - Points the first is if the buffer is
647:42 - full block producer P if if buffer is
647:45 - empty block consumer see producer should
647:48 - wake up consumer when he is sleeping and
647:51 - consumer should wake up producer when he
647:52 - is sleeping and mutual exclusion should
647:55 - exist between producer and consumer so
647:56 - these are the five points that will
647:58 - ensure the correct implementation of
648:00 - semur or producer consumer problem using
648:03 - SEMA 4 I should
648:04 - say
648:07 - okay have you remembered we discussed a
648:09 - question in
648:11 - which the order the changing the order
648:13 - between the entry section was leading
648:16 - the situation to deadlock similar thing
648:19 - will happen here if the mutex is not at
648:22 - the second instructions second
648:24 - instruction of the entry section this
648:26 - will lead to deadlock or I should say if
648:28 - we change the order then this will lead
648:30 - to deadlock
648:31 - see down on Mt initially the value was n
648:34 - decreased to n minus one down on MX
648:37 - initially the value was 1 decreased to
648:39 - zero down on full the value was already
648:41 - full this will be blocked so no case of
648:45 - mutual exclusion is VI viated okay now
648:47 - comes the deadlock thing can deadlock
648:49 - occur can both the process get blocked
648:51 - no this won't get blocked both of them
648:53 - will run now to check whether deadlock
648:56 - will occur we are going to preempt here
648:58 - okay as we used to do down on Mt n minus
649:02 - one down on full Full was full was
649:04 - already zero so this will get blocked
649:07 - but this this won't so this will run
649:08 - keep on running and then after it
649:11 - completes the exit section this is going
649:13 - to wake up the consumer thing okay so
649:17 - this is how it works no case of Deadlock
649:19 - but what if I change the order down on
649:22 - empt down on mutex but what I'm doing
649:25 - here down on mutex and then down on full
649:28 - okay let's see so first we did this down
649:31 - on mutex mutex value changed to zero
649:34 - down on full get blocked the value is
649:36 - minus one and then comes here down on
649:39 - empty the value change to n minus1 and
649:41 - then down mutex the mutex is already
649:44 - zero this will get blocked so both are
649:45 - blocked here
649:47 - if both are blocked then this is the
649:49 - case of Deadlock so what you have to
649:51 - remember while writing this down newex
649:53 - will always be in the instruction two of
649:56 - the entry section when it was this at
649:58 - the second instruction it was working
650:00 - fine when the mutex value changed or the
650:03 - for one case the mutex came up in that
650:07 - case deadlock occurred so this is an un
650:10 - undesirable case that's why the order is
650:13 - important in the last lecture we have
650:15 - seen the implementation of producer
650:18 - consumer problem using
650:19 - semap in this lecture we are going to
650:22 - see some more problems on that so that
650:25 - our understanding becomes better okay
650:29 - Ive also told you to remember a fact
650:31 - that mutex should always be at the
650:34 - instruction two of the entry section if
650:36 - it is not at one case if it's come above
650:39 - then the chances of Deadlock are present
650:41 - deadlock seems to happen Okay let's
650:45 - solve this question it says consider the
650:46 - following solution to the producer
650:48 - consumer synchronization problem I
650:50 - sincerely request you to First you
650:52 - attempt this question and then we will
650:54 - discuss okay so this is just an implicit
650:57 - advice you have to follow that in each
650:59 - and every question we discuss i' I've
651:01 - told you in the beginning also that
651:04 - whenever I solve a question pause the
651:06 - video and solve yourself try to attempt
651:10 - yourself even if you fail doesn't matter
651:12 - but when you attempt you are going to
651:15 - appreciate the beauty appreciate the
651:17 - beauty behind the concept of the
651:19 - question you can appreciate where you
651:21 - had made mistake or where you can make
651:23 - mistake
651:26 - and okay so I I hope you got the
651:29 - point what is the purpose of solving the
651:32 - question first and then seeing the
651:33 - solution okay so let's solve consider
651:36 - the following solution producer consumer
651:38 - synchronization problem the shared
651:40 - buffer sizes n semap 4 R Mt full and
651:44 - mutex defined with the respective value
651:46 - of 0 n and
651:48 - one seeing something
651:50 - odd empty value is zero which means the
651:53 - buffer is already full full Valu is n
651:56 - which
651:58 - means the buffer is already full and MX
652:01 - is
652:03 - one
652:05 - see in the solution which we have
652:08 - discussed using SEMA 4 V what we have
652:10 - assumed that initially the buffer is
652:12 - empty but I think here we are using
652:14 - assuming that the buffer is initially
652:16 - full
652:17 - okay we'll go with that semop 4 empty
652:19 - denotes the number of available slots in
652:21 - the buffer for the consumer to read from
652:24 - now this is this is just the opposite
652:27 - which we have learned
652:28 - before I I got the idea behind the
652:31 - question they are just trying to confuse
652:32 - us so what are they trying to do they
652:35 - they have just changed the meaning of
652:37 - empty and full they are also they are
652:41 - also taking the empty buffer in the
652:43 - beginning I got this okay so SE empty
652:46 - denotes the number of available slots in
652:48 - the buffer for Consumer and full denotes
652:50 - it must be for the producer to write to
652:53 - yes so empty denotes available slots
652:56 - filled with the item and full denotes
652:58 - number of empty slots okay placeholder
653:02 - variables PQ and r r s and they can be
653:05 - assigned with either empty or full and
653:07 - valid sem for operations are weight and
653:09 - signal so we have to assign the value of
653:10 - pqrs in such a way
653:14 - that this code works for uh producer
653:18 - consumer problem
653:19 - okay producer consumer I have told you
653:22 - five things to remember do you
653:23 - remember the five things are when the
653:25 - buffer is full block producer when the
653:27 - buffer is empty block
653:30 - consumer producer should wake up
653:32 - consumer when he's sleeping and consumer
653:33 - should wake up producer when he's
653:34 - sleeping and mutual exclusion should be
653:36 - there we will apply the exact same
653:39 - concept producer it should be sleeping
653:42 - when the buffer is
653:45 - full okay
653:48 - and what does full denotes full denotes
653:50 - the number of empty slots if I say if
653:53 - number of empty slots in the beginning
653:55 - is zero then producer should get blocked
653:57 - so we are performing weight operation on
654:00 - full what does full represent here this
654:02 - is not that typical full it represents
654:04 - number of empty slots and if I say
654:06 - number of empty slots is zero in the
654:08 - beginning which means producer should go
654:10 - to sleep that's why we are performing
654:12 - weight operation here on the
654:14 - foot and when an item is added to the
654:17 - buffer empty SEMA 4 should be increased
654:20 - with one when an item is added empty
654:22 - sema4 should be increased with one why
654:24 - because
654:25 - empty empty symbolizes available slots
654:28 - filled with an item so when an item is
654:30 - added to the buffer available slots
654:32 - filled with an item should
654:34 - increase okay so if you're getting
654:36 - confused just see that they have just
654:40 - changed the meaning of full and empty so
654:42 - what we are going to do we are going to
654:43 - just change the assignment of full full
654:46 - and empty here so you remember we have a
654:48 - sign like this empty full full empty so
654:52 - what are we going to here do full empty
654:54 - empty full so the answer should be full
654:57 - empty empty full C so you have to
654:59 - correct them at your notes also answer
655:01 - is not D it's C okay it's just a a
655:05 - mistake to take D but the answer is full
655:08 - empty empty full how we have done that
655:10 - we have just notices that the meaning of
655:14 - full and empty has changed here so we
655:15 - will just change the assignment also so
655:18 - full empty empty full is the answer
655:20 - let's move to question number two
655:22 - consider the procedure below for
655:24 - producer consumer problem which uses
655:27 - SEMA fores okay so this is a nice
655:30 - question SEMA 4 n Nal to Z number of
655:33 - items sem 4 S = to 1 it represents the
655:36 - mutex okay there are two codes given
655:39 - producer and
655:40 - consumer what does producer do it
655:42 - produce an item apply log to the
655:45 - critical section goes to the action add
655:47 - the item to the buffer free the lock
655:49 - increase the value of n because number
655:51 - of items here are now increased with one
655:54 - void consumer while true what is
655:56 - consumer doing consumer is first
655:58 - applying log to the critical
656:00 - section Sam wait why s wait here because
656:04 - it cannot go to the critical section or
656:05 - consume from a bounded buffer until
656:08 - there is
656:09 - some item already present for there it
656:12 - to be consumed okay that's why Sam weit
656:15 - n
656:17 - if there is item present go to the
656:19 - critical section consume the item s
656:21 - signal as free the
656:23 - lock and then we are free to consume
656:27 - okay so what we have done here let me
656:29 - repeat again producer produces apply a
656:32 - lock add the item to the buffer remove
656:35 - the lock increase the value of n what
656:38 - consumer
656:39 - do apply
656:41 - lock check if there is some item present
656:44 - or not if not then get blocked remove
656:47 - the item from the
656:48 - buffer remove the lock consume the item
656:51 - okay so this is what happens now the
656:53 - question is producer will be able to add
656:55 - an item to the buffer but consumer can
656:58 - never consume
656:59 - it why is it so let's check is that is
657:03 - true or
657:04 - not so producer will be able to add an
657:06 - item to the buffer producer produces
657:08 - apply a lock add the item to the buffer
657:11 - removes the loog increase the value of
657:13 - number of items so producer is able to
657:15 - produce yes but consumer can never
657:17 - consume it why is it so let's
657:20 - see same weight on s s is changed to
657:22 - zero same weight on n n is equal to Z
657:25 - Now removes the item from the buffer s
657:27 - is set to one consumes the item so this
657:30 - statement is false because consumer is
657:32 - able to consume the item question number
657:35 - or the option b the consumer will remove
657:38 - no more than one item from the
657:40 - buffer why is it so let's say the
657:43 - producer produced 10 item consecutively
657:45 - 1 2 2 3 4 5 6 okay till 10 items Now
657:49 - consumer is free to consume no one is
657:52 - just stopping that
657:54 - see while
657:56 - true consumer can consume as many times
657:59 - same weight on S so when producer has
658:03 - produced an item or it has left the
658:04 - critical section it must have changed
658:06 - the value of S2 one so now consumer
658:08 - won't be blocked here Sam weight on N so
658:11 - this will change the value to 9 removes
658:13 - the item from the buffer change the
658:14 - value of signal s back to 1 so n should
658:16 - be n here and it can consume okay so
658:19 - this was the first cycle now it tries to
658:20 - goes again s weit on
658:22 - S it will change the value of s to zero
658:25 - s weight on N it will change the value
658:27 - of n to 8 removes item from the buffer
658:30 - change the value of s to one again and
658:31 - consumes so it has consumed more than
658:34 - one item from The Bu so this is also
658:36 - false deadlock occurs if the consumer
658:38 - succeeds in acquiring sema4 s when the
658:40 - buffer is
658:42 - empty yes this is true how let's say
658:46 - consumer tries to go Sam weight on s s
658:49 - is changed to zero Sam weight on n n is
658:53 - initially already zero so this consumer
658:56 - will get blocked now comes here same
658:58 - weight on s s was already zero so this
659:01 - is this also get blocked this also get
659:03 - blocked let me repeat again the initial
659:05 - value of s is 1 and N is Zer when
659:08 - consumer applies log to the critical
659:10 - section s is changed to zero and it gets
659:12 - blocked here because the value of n is
659:13 - zero so consumer is blocked here now now
659:16 - producer tries to go consumer has
659:17 - changed the value of H to Zer producer
659:20 - cannot also go producer will also get
659:22 - blocked so both the process are blocked
659:24 - it is the case of
659:25 - Deadlock next option the starting value
659:29 - for the sem 4 n must be one and not zero
659:31 - for deadlock free
659:32 - [Music]
659:33 - operation is that necessary let's see so
659:36 - we are given that the starting value of
659:38 - sem 4 n must be one and not zero for
659:41 - deadlock free
659:43 - operation next's check so for deadlock
659:46 - free operation what we have to do this
659:48 - instruction mxe is at instruction one so
659:50 - we have to swap for solving the deadlock
659:53 - so let's say we have S that in that case
659:56 - the deadlock can be resolved but what we
659:58 - are given here the value of n should be
660:00 - initially one and not zero for deadlock
660:02 - fre operation let's
660:04 - see so we can think of any case in which
660:08 - n is one and Deadlock can happen can you
660:10 - think of that let's see from the
660:13 - consumer side s is changed to zero n is
660:15 - changed to consumer can freely go it is
660:17 - not blocked let's say it get preed here
660:19 - tries to go from here producer tries to
660:21 - go s is already zero producer will get
660:24 - blocked consumer will now chance
660:26 - consumer will consume or consumer will
660:29 - uh change the value of n to zero again
660:30 - now it's chance for producer to go
660:33 - consumer will change the value of s also
660:35 - to one so producer can freely go now in
660:38 - that
660:39 - case either you start with the producer
660:41 - first n is initially one no one is
660:44 - stopping producer to go to the critical
660:45 - section if one process can go to the
660:47 - critical section then other will also go
660:50 - after some time when the lock is
660:52 - released so the if the starting value of
660:54 - sem for n is 1 and not zero then it is
660:56 - dead log free yes it is true so this is
660:59 - again wrong this is this is true okay so
661:03 - C and D is the answer you need to
661:05 - correct that both in your uh notes okay
661:09 - the first question answer is C and the
661:10 - second question answer is C and D in the
661:12 - next lecture we are going to see reader
661:14 - writer problem solution in the last
661:16 - lecture we have seen some problems on
661:18 - producer consumer SEMA for
661:20 - implementation in this lecture we are
661:23 - going to see the interesting reader
661:24 - writer problem and it solution using
661:28 - semor let me tell you what is reader
661:30 - writer problem Suppose there is some
661:33 - database with records okay now there are
661:36 - two process a reader and a writer both
661:39 - have access to the database and what
661:41 - does reader do it read one or more
661:44 - records from the database
661:46 - and what does writer do writes to one or
661:48 - more records from the database or to the
661:51 - database okay now the problem is reader
661:55 - and writer should not be able to access
661:57 - database at the same time this is the
662:01 - problem it should not be there that
662:03 - reader and writer both are present in
662:04 - the database because a writer may be
662:07 - writing that thing and reader May read
662:09 - the updated value or reader May read the
662:12 - old value and writer May write to the
662:14 - new value so there is some kind of of
662:16 - problem there you can feel it too so
662:19 - what we want that reader and writer
662:20 - should not be able to access database at
662:22 - the same time what is the solution just
662:26 - just use a mutex let's say there is a
662:28 - binary 7 for mutex equal to 1 down on
662:30 - mutex critical section upon mutex
662:32 - problem solved this is it no there is
662:36 - something more to the
662:37 - problem which is there are multiple
662:41 - readers and multiple
662:44 - writers so
662:46 - multiple writers multiple writers cannot
662:49 - be in the critical section at the same
662:51 - time you can feel it too a reader and a
662:54 - writer cannot be in the critical section
662:56 - at the same time but multiple readers
663:00 - can be in the critical section at the
663:02 - same time or multiple readers can be in
663:04 - the database at the same time because
663:06 - readers are causing no harm they are the
663:10 - writers because writers update the value
663:13 - so multiple writers should not be there
663:15 - a reader and writer should not be there
663:17 - multiple readers can be there so this is
663:20 - what we have to implement using
663:22 - semap see this there can be multiple
663:25 - readers and writers so the reading is
663:27 - not a problem reading plus writing will
663:29 - be a problem writing will be a problem
663:32 - so multiple writers can't be there
663:35 - multiple readers can be there a reader
663:36 - and writer can't be there so this is
663:38 - what we have to implement okay and there
663:42 - is some another problem which is
663:44 - starvation to the writers let's say this
663:47 - is our database okay I have assigned so
663:51 - there is a reader and there is a writer
663:53 - so I have told reader to go into the
663:55 - into the critical section of the
663:56 - database first so reader goes okay start
663:59 - its reading another reader comes because
664:03 - multiple readers can be in the critical
664:04 - section at the same time that's why I
664:06 - allow another reader to go to the
664:08 - critical section also then another
664:10 - reader come then another reader come so
664:13 - the readers keep on coming and the
664:16 - writer is waiting so the writer is
664:19 - waiting and readers keep on coming this
664:21 - caus starvation to the writers let's
664:23 - take another case in which writer goes
664:27 - first reader got blocked when another
664:30 - writer comes let's say writer two writer
664:32 - three and writer four all of them will
664:34 - get blocked until writer one performs
664:36 - its operation and let's say writer one
664:37 - is performing its operation for a long
664:39 - time then writer two writer three and
664:41 - writer four and every writer which will
664:43 - come after writer four or the writers
664:46 - will keep on coming and will and will
664:48 - get and will keep on getting blogged and
664:51 - blogged so this will cause a starvation
664:53 - to the writers so this is the problem
664:55 - which we have to
664:56 - solve
664:59 - okay so what can we think of
665:02 - it let me explain
665:04 - you there are two process reader and
665:06 - writer
665:08 - okay let me explain you the main idea
665:11 - what
665:12 - happens this is the database
665:17 - okay for the first case writer comes it
665:21 - will lock the database from inside
665:23 - perform its writing operation and when
665:26 - it will come out it will remove the lock
665:28 - and will go out so this is what a writer
665:30 - do as simple as that but the problem is
665:34 - with the
665:36 - readers so what a reader going to do
665:38 - let's say this is R1 this is the leader
665:41 - of the reader this is the first reader
665:44 - which has shown interest to enter into
665:46 - the
665:47 - database reader come check the database
665:51 - if it is logged from the inside let's
665:52 - say writer one is present
665:54 - already what it will do it will tell the
665:57 - other writers hey the critical section
666:00 - or the database is logged from inside
666:03 - all of us should get blogged until the
666:05 - writer perform its
666:08 - operation okay so this is how readers
666:11 - are going to cooperate but let's say
666:14 - there is no there's no writer present in
666:17 - the database so what it will do reader
666:20 - one will come lock the database from
666:23 - inside for the writers
666:25 - only for the writers
666:27 - only and will allow its fellow readers
666:31 - to enter into the database so R2 can
666:33 - easily go R3 can easily go R4 can easily
666:36 - go and when they will come out of the
666:38 - database or let's say they have
666:39 - Performance Reading so they will go out
666:41 - R1 goes out R2 goes out R3 goes out and
666:45 - now it is the the responsibility for R4
666:46 - that is the last reader to tell the
666:49 - writers that now we have performed our
666:52 - reading you can go now so R4 have the
666:55 - responsibility to remove the lock which
666:58 - the first reader that is the leader of
667:02 - the reader R1 has applied on the
667:05 - database are you getting the point let
667:08 - me repeat again and then we will move to
667:10 - the
667:12 - code see there are reader and the writer
667:15 - Pres
667:16 - if writer comes it will lock for lock
667:19 - the database from inside for everyone
667:21 - either either it be a reader or it be a
667:24 - writer writer one performs its operation
667:27 - writes the thing and before going out it
667:29 - will remove the lock and it goes out so
667:32 - this is how R do its operation and how
667:34 - reader do reader one will come and check
667:37 - if there is a lock on the database
667:40 - already for the readers which some
667:42 - writer must have been applied or or
667:45 - locked the database from inside it will
667:47 - car its fellow readers R2 R3 and R4 to
667:50 - get blocked that we all of us should get
667:52 - blogged until writer one perform its
667:54 - operation and when writer one will
667:56 - perform the operation it will go by
667:58 - removing the lock at the database so the
668:00 - lock will be removed now reader one
668:03 - comes it applies the log log for whom
668:06 - only for the
668:07 - writers reader one comes it allows other
668:11 - its fellow readers to go and read at the
668:13 - database reader one has completed its
668:16 - reading so it will leave reader two has
668:18 - completed reader two will leave reader
668:20 - three will leave but now the last reader
668:23 - the last reader that is reader 4 it is
668:26 - the responsibility for reader 4 to
668:29 - remove the lock which reader one has
668:31 - acquired at the database so that other
668:35 - writers may get to know that the now
668:38 - database is free we can go into the
668:41 - database I hope you got the idea let's
668:44 - see the implementation
668:45 - of reader and writer using SE we will
668:48 - maintain a reader count also to know
668:51 - that if that reader is the first reader
668:54 - or the last reader that's why because we
668:56 - have to take account of leaders and the
668:59 - last reader that's why we are
669:00 - maintaining a readers
669:02 - count okay so int
669:05 - RC that is the readers count that is
669:07 - number of readers present in the
669:09 - critical section okay so readers count
669:12 - is the value of uh the readers present
669:15 - in the critical section see suppose RI
669:19 - is the reader that wants to enter into
669:22 - the critical section so it will try to
669:23 - increase the value of readers count and
669:25 - RJ is the reader that has completed its
669:28 - reading so it will try to decrease the
669:30 - value of readers
669:32 - count can you see this as a race
669:35 - condition because multiple readers may
669:37 - want to access readers count for incre
669:39 - increment and decrement so this will
669:41 - cause inconsistency in some way that's
669:44 - why we are maintaining a mutex which is
669:47 - used by readers for readers count and we
669:50 - are maintaining a binary 74 database
669:54 - which is used by reader and writer to
669:55 - access database as the critical as
669:57 - access database as critical section are
669:59 - you getting the point we are maintaining
670:02 - two binary seaone the first one is mutex
670:04 - mutex is for the readers count and
670:07 - another one is the database database is
670:09 - for the critical section mutex is used
670:12 - only by the readers and database is used
670:14 - by the readers and writer to get access
670:16 - of the critical section okay now what is
670:19 - the major function of the writer it has
670:22 - to just go to the database apply the
670:26 - lock and if someone is present get
670:28 - blocked this is the uh major work and
670:31 - whenever the writing is done when it
670:34 - will go it will release the lock so this
670:35 - is what we have done here void writer
670:38 - perform down operation on database that
670:40 - is acquiring the lock performing the
670:42 - database right and releasing the lock as
670:44 - simple as that but the readers
670:48 - implementation is a bit tricky what
670:50 - readers have to do whenever a reader
670:53 - enter into the database it has to
670:56 - increase the value of readers count by
670:59 - one to prevent inconsistency we have to
671:03 - perform or the reader have to perform a
671:05 - lock or a down operation on
671:07 - mutex so that some if some another
671:10 - reader want to decrement that won't
671:12 - cause inconsistency suppose if a reader
671:16 - is incrementing the value of reader
671:18 - count and another reader comes and it
671:21 - wants to decrement the value of readers
671:23 - count let's say somewhere at this point
671:26 - then this will prevent them download
671:29 - mutex will prevent them for causing
671:32 - inconsistency okay so mutex is used by
671:35 - readers only to increment or decrement
671:38 - the readers count okay suppose reader
671:42 - one comes perform down on mutex increase
671:44 - the value of reader count initially it
671:45 - was zero so now reader count is one and
671:48 - I have told you if the reader is the
671:51 - leader or it is the first reader it has
671:55 - to check whether some writer is present
671:57 - into the critical section or not if it
671:59 - is present then other readers should
672:02 - also get
672:04 - blogged so reader one will get blogged
672:06 - where it will get blogged at the
672:09 - instruction C and let's say some reader
672:12 - two also wants to go to the critical
672:13 - section it tries to first in the value
672:15 - of readers count it won't be able to it
672:17 - will get blocked directly here so R1 R2
672:21 - and any other reader which try to go
672:23 - will get blocked so this is what happens
672:26 - mutex initially changed to zero reader
672:28 - counts changeed to one
672:30 - database let's say the DB that is the
672:33 - down on mutex is already Zero by some
672:35 - writer so a leader will be blocked at
672:37 - instruction C at this point and rest
672:41 - others will be blocked at instruction a
672:43 - at this point only I hope you are
672:44 - getting the idea okay now what happens
672:47 - let's say there is no writer present in
672:50 - the critical section so now what leader
672:52 - of the readers will do it will change
672:54 - the value of DB to Z why to prevent
672:56 - other writers entering into the critical
672:59 - section okay now as it has changed the
673:01 - value of RC to 1 it will increase the
673:04 - value of mutex or it will release the
673:05 - lock it has acquired on the readers
673:08 - count shared variable now what it will
673:11 - do it has successfully entered into the
673:13 - critical section or I can say it has
673:15 - sucessfully enter into the database so
673:16 - it will perform the read operation on
673:18 - the database and now when it has done
673:21 - when it is done with its reading then
673:23 - what will happen it should go out of the
673:27 - database so before going out of the
673:29 - database it should decrease the value of
673:31 - readers count by one so what it will do
673:34 - it will perform the down operation it
673:36 - will acquire the lock performs the
673:39 - reading or performs the decrement on the
673:42 - readers count and will release the mutex
673:45 - but here is the catch also I have told
673:47 - you if it is the last leader that is R4
673:51 - in our case then it should be a
673:53 - responsibility for R4 to tell other
673:55 - writers that database is now free so the
673:58 - last one should
673:59 - unlock so if it is the last one that is
674:02 - reader count equals to zero then it
674:03 - should unlock the database and then upon
674:05 - M Tex so this is how reader wrer problem
674:10 - is solved using 74 let me read again if
674:13 - it's the first writer it checks that
674:14 - database
674:15 - has writer already then it will get
674:17 - blocked rest all of the readers will be
674:19 - blocked and if it sees no one is there
674:21 - in the database it can go there and
674:23 - simply lock it for the writers only
674:25 - readers can enter and no need to lock
674:27 - every time so the first reader is the
674:29 - leader of all other
674:31 - readers so what are we doing here down
674:33 - mutex before accessing the reader count
674:35 - and before making it up lock if it is
674:38 - the first reader and unlock if it is the
674:39 - last one so the last one is unlocking
674:41 - and lock is performed by the first
674:43 - leader okay so this is how it work now
674:47 - let's revise what we have done in the
674:49 - readers writer problem let me repeat
674:51 - again what happens there is a database
674:54 - there are two process reader process and
674:56 - the writer process a writer process can
674:58 - go only if there is no other writer or
675:01 - reader present in the database so when a
675:03 - writer process try to go it will perform
675:05 - a down operation on DB which will
675:08 - automatically
675:09 - adjust if there's some other reader or
675:11 - other writer present then it will get
675:13 - blogged if not it will go acquire the
675:15 - lock go into the critical section if
675:18 - some other writer tries to enter it will
675:20 - get blocked now what for the reader
675:23 - let's say there are four readers R1 R2
675:25 - R3 and R4 R1 is the reader R sorry R1 is
675:28 - the first reader so it will become the
675:30 - leader first reader is the leader so
675:34 - when a reader leader tries to enter it
675:36 - will see that critical section is logged
675:38 - or not if yes it will tell other readers
675:41 - also to get blogged so all of the
675:42 - readers will get blogged and when this
675:45 - it will go out it will tell the other
675:47 - readers that c section is not free you
675:49 - can go so R1 will go R1 will go
675:56 - first R1 will go first we'll see if this
676:00 - if there is no other reader no other
676:02 - writer it will lock the database from
676:05 - inside for the writers only and other
676:08 - readers are free to go so R2 will go
676:10 - then R3 will go and R4 will go and when
676:12 - they have performed their reading
676:13 - operation R1 will go out will decrement
676:16 - the value of RC R2 will go out will
676:18 - decrement the value of RC R3 will go out
676:20 - will decrement the value of RC and when
676:22 - R4 will go out the RC will be zero
676:25 - because there is no other reader present
676:27 - in the database so RC will become zero
676:30 - and when RC will Zero it is the
676:31 - responsibility of reader 4 that is the
676:33 - last
676:35 - reader to tell other writers that
676:40 - database is now free you can go and
676:42 - write or perform your right operation so
676:44 - this is how reader writer problem works
676:48 - or this is how reader writer problem is
676:50 - solved using the semaphor I hope you
676:52 - like this uh I hope you liked
676:56 - it now let's move to the new problem
676:59 - that is dining philosophers problem it
677:01 - consists of some philosophers discussing
677:03 - on some topic and then when one
677:05 - philosopher become hungry he eats the
677:07 - meal in front of him using a knife and
677:09 - fork these knife and fork are
677:11 - shared okay so when philosopher 2 is
677:13 - eating he'll pick up the the knife pick
677:15 - up the fork and we start eating but in
677:18 - case if P1 and P3 also become hungry at
677:20 - the same time they won't be able to eat
677:22 - because they need fork and knife but
677:24 - when P3 will try to pick up the fork
677:27 - this Fork is already in use by P2 so P3
677:30 - fails to pick up this Fork hence won't
677:32 - be able to eat when P1 will try to pick
677:34 - up this knife this knife is already in
677:37 - use by P2 so P1 also fails to
677:41 - eat so these knife and fork are shared
677:43 - between these philosophers if one
677:45 - philosopher is eating then these two
677:47 - philosopher can't eat okay so this is
677:49 - what I've written here n is greater than
677:51 - two that is number of philosophers
677:52 - should be greater than equal to two
677:54 - philosophers eating noodles and using a
677:56 - knife and fork is shared between these
677:58 - two when a Philosophers become hungry
678:00 - he'll pick up the left thing that is or
678:02 - the left fork and then the right if
678:04 - successful but why I have written if
678:05 - successful because in that case in this
678:08 - case P1 is unable to pick up the right
678:10 - thing that's why I written if successful
678:12 - and if not then P1 won't be able to
678:16 - eat so a philosopher start eating only
678:18 - when he pick ups the right successful
678:20 - picks up the left successful so left and
678:23 - right are both picked up and
678:26 - successful okay now you can see this
678:29 - problem suffers severely from deadlock
678:34 - how let's say a Philosophers picks up
678:37 - the left thing and get
678:39 - preempted picks up the left thing and
678:41 - get preed suppose this philosopher picks
678:44 - up the the left knife and get preempted
678:46 - picks up the left Fork get preempted
678:48 - picks up the left knife get preempted
678:50 - picks up the left Fork get preed picks
678:52 - up the left knife gets pred picks up the
678:55 - left Fork get preed
678:58 - now each of the knife and fork is
679:00 - acquired by some philosopher and other
679:03 - philosopher is waiting for other
679:05 - philosopher to release that knife so
679:07 - this is waiting for him this is waiting
679:08 - for him waiting for him waiting for him
679:10 - so there consist a cycle in which a
679:13 - philosopher is waiting on another to
679:16 - release that lock see p 0 is waiting
679:19 - on P1 P1 is waiting on P2 P2 is waiting
679:22 - on P3 P3 is waiting on P4 P4 is waiting
679:24 - on P5 and P5 is waiting on p 0 so this
679:27 - is how deadlock occurs in this ding
679:30 - philosopher problem so how in which case
679:32 - dead log occur all of are hungry all of
679:35 - them prevents uh preempts after picking
679:37 - one
679:38 - thing they all picks up the left thing
679:40 - and get preed fork0 is acquired by p 0
679:44 - for is required by P1 2 by P3 and all of
679:47 - them p 0 is waiting on P1 P1 on P2 P3 on
679:49 - P3 P3 on P4 P4 on P5 and P5 again on p 0
679:53 - so this is a case of
679:56 - Deadlock okay so how this dining
679:59 - philosopher problem is implemented let's
680:01 - see so we have defined six philosophers
680:04 - here let N equals to 6 void philosopher
680:07 - and I while one think this is the case
680:11 - when a philosopher is thinking think I
680:15 - now it gets hungry take Fork I take Fork
680:19 - I + 1 mod n why mod n for the circular
680:22 - thing for
680:24 - this for this that's why for the
680:28 - circular thing we have written mod
680:31 - n picks up the left Fork picks up the
680:34 - Right Fork if successful eat after
680:37 - eating put back left Fork put back the
680:39 - Right Fork this is it this is how a
680:41 - philosopher work you will think suppose
680:44 - now thinking he gets hungry he takes up
680:46 - the left Fork takes up the Right Fork if
680:49 - successful then eat put back the left
680:51 - Fork put back the Right Fork this is how
680:53 - a philosopher
680:55 - work now the question arises what is the
680:58 - maximum concurrency how many
681:00 - philosophers can eat at a time without
681:02 - deadlock let's say now we change the
681:04 - number for Nal to 5 what is the maximum
681:06 - number of philosophers that can be
681:09 - eating okay let's say philosopher zero
681:12 - tries to wait picks up the left four
681:14 - picks up the Right Fork P1 tries to it
681:16 - gets blogged because F Fork one is
681:18 - already acquired by p 0 now in this case
681:21 - we are ignoring the fact that knife and
681:22 - fork are different we are just taking
681:24 - into consideration that a a philosopher
681:27 - require two Fork we are saying that
681:29 - knife and fork are the same what I'm
681:31 - saying instead of segregating between
681:33 - knife and fork we are saying they are
681:34 - just forks and a process and philosopher
681:38 - require two Fork to eat two forks to eat
681:41 - okay so this is what we are doing
681:42 - suppose we are saying p 0 requires are
681:44 - Fork 0 and Fork 1 P1 requires now Fork 1
681:47 - but it will get blocked because Fork 1
681:49 - is already required by p 0 now P2 comes
681:52 - P2 acquires 42 and Fork 3 P3 comes get
681:54 - blocked because P3 has
681:57 - acquired it wants to go to the fork 3
681:59 - but Fork 3 is already acquired with 42
682:02 - P4 comes F4 and F0 but F4 F0 is already
682:06 - acquired with p 0 so at Max two
682:09 - philosophers can it you can also see
682:10 - here
682:15 - let me go
682:16 - back yeah you can also see here in this
682:19 - case how many philosopher can eat this
682:20 - can eat freely this can eat freely and
682:24 - this can eat freely in case of six
682:25 - philosophers but if let's say I remove
682:28 - this philosopher and this knife then how
682:31 - many can eat only this can eat and this
682:33 - can
682:34 - eat
682:37 - okay so this is not a hard question what
682:40 - you have to do what you have to do just
682:42 - allocate folks to the philosopher and if
682:44 - some other philosopher wants to acquire
682:46 - the same Fork then make it blocked this
682:48 - is it p 0 wants to get Fork 0 and Fork
682:52 - one give them give him P1 wants to get
682:55 - Fork one but it is required with uh p 0
682:57 - block it P2 wants F2 and F3 give him P3
683:02 - wants F3 block him because F3 is already
683:05 - with F2 P4 wants F4 and F0 block because
683:08 - F0 is already with p 0 so this is how
683:10 - you have to
683:11 - do for n = to 3 when when there are
683:14 - three philosophers the answer will
683:17 - be and the answer should be one
683:20 - C if there are three philosophers
683:26 - and oh for Three Philosophers can it be
683:28 - three knives yes for three Three
683:31 - Philosophers three folks will be there
683:34 - at a time only one philosopher can eat
683:37 - with using this so these two will wait I
683:40 - think I must have I must want to return
683:43 - six here
683:45 - you can see for six this philosopher can
683:47 - eat freely this philosopher can eat
683:49 - freely and this philosopher can eat
683:51 - freely so for Nal to six three of the
683:53 - philosophers can act can eat freely okay
683:57 - now the question arise how to prevent
684:00 - that deadlock
684:02 - case so the first answer is semaphor
684:04 - based and the second is non- semaphor
684:07 - based okay let's discuss the first non
684:10 - semaphor based answer let's say there
684:12 - are two philosophers sitting on a table
684:15 - with two forks in between see the number
684:16 - of forks is equal to the number of
684:18 - philosopher and one philosopher require
684:21 - two forks for eating you have to
684:22 - remember this condition what I have said
684:25 - the number of forks is equal to number
684:26 - of philosophers and each Phil each
684:28 - philosopher require two forks for eating
684:31 - okay so now here two philosophers are
684:33 - sitting on a
684:34 - [Music]
684:35 - table and there are two folks present
684:37 - you can see these blue the blue ones are
684:39 - the folks so now what we have to do we
684:42 - have to make this veloc pher picks left
684:45 - first and then right and this
684:47 - philosopher should pick right first and
684:48 - then left see how this is going to solve
684:50 - the problem this philosopher what is the
684:52 - left of this philosopher this one so
684:55 - this will pick
684:56 - this what is the right of this
684:58 - philosopher this one so when this
685:01 - philosopher has already acquired this
685:04 - Fork this philosopher should also try to
685:06 - acquire the same Fork otherwise if this
685:08 - philosopher acquire this Blue Fork the
685:10 - deadlock will occur each of them has
685:12 - acquired a fork that is required by the
685:14 - other a cycle will be so this is a
685:17 - deadlock condition what we have to
685:19 - do he picks the left Fork first and then
685:22 - right make him pick the right Fork first
685:24 - and then
685:25 - left in that way deadlock won't occur
685:28 - let's see picks up the left Fork first
685:31 - he also tries to pick up the Right Fork
685:33 - first but this Fork is acquired by this
685:36 - one gets blocked now he can pick up that
685:38 - that one eat properly and then when
685:42 - after eating he will release them so
685:44 - when this will try now they can both eat
685:47 - one after another so first this it and
685:49 - then the other one so this is how non
685:52 - semop for solution
685:55 - work picks left first and then right
685:57 - picks right first and then left this
685:59 - Fork is right one to the P2 P1 left
686:01 - picks the left Fork P2 tries for the
686:04 - right one and get blocked because what
686:07 - the fork which is left to P2 is right
686:09 - for the P1 or you can say the other way
686:13 - the fork which is left to P1 1 and is
686:15 - right to P2 so both will try to pick up
686:17 - the same
686:18 - fork okay let's say P1 has acquired the
686:22 - lock first then P2 will get blocked this
686:24 - is how deadlock will be saved otherwise
686:26 - let's say this has picked this fork and
686:27 - this has picked this Fork now this
686:30 - philosopher is waiting on this
686:31 - philosopher to release the fork and this
686:33 - philosopher is waiting on this
686:34 - philosopher to release the fork this
686:36 - will be a case of Deadlock so what we
686:37 - have to do make one philosopher change
686:40 - the pattern let's say all philosophers
686:42 - are picking left first first and then
686:44 - right left first and then right left
686:45 - first and then right make one
686:47 - philosopher pick right first and then
686:49 - left in this case deadlock won't occur
686:52 - believe me deadlock won't occur make one
686:55 - philosopher choose the different way
686:57 - okay so n minus one philosophers let's
687:00 - say there are total n philosophers so n
687:02 - minus one philosophers will go first
687:05 - left and then right and N philosopher
687:08 - will choose first right and then left
687:11 - okay so let's say P1 be that n
687:13 - philosopher will first choose the right
687:15 - fork and then the left Fork so this is
687:19 - how P1
687:20 - works okay now let's uh start the thing
687:23 - P4 picks up the left Fork
687:25 - first P5 picks up the left Fork first P1
687:30 - tries to pick the right Fork first but
687:33 - Right Fork is already required will get
687:34 - blocked so P1 will is blocked
687:36 - here okay P2 picks up the left Fork
687:41 - first P3 picks up the left Fork first
687:44 - and now it's chance for P4 again P4 will
687:47 - pick the right Fork see here so after
687:51 - eating will be done off for P4 now P4
687:53 - can eat see P4 has required both these
687:55 - folks so P4 can eat when P4 will eat
687:58 - after eating P4 will release them now P5
688:01 - can eat after eating P5 can release them
688:04 - now P1 can eat so P1 tries to pick this
688:08 - get
688:10 - blocked P1 tries to pick this it can
688:13 - pick successfully but when tries to pick
688:14 - this gets blocked now what will happen
688:17 - chance for P2 P2 cannot pick this gets
688:20 - blocked chance for P3 P3 can pick this
688:23 - so P3 will eat P3 will eat after eating
688:26 - we release both of them now chance for
688:27 - P2 P2 can pick this now P2 will eat P2
688:31 - will release both of them now it chance
688:32 - for P1 P1 can pick this
688:35 - again now P1 can eat and
688:38 - will successfully release them so this
688:41 - is how deadlock is pre prevented when
688:45 - one of the philosophers is has changed
688:48 - the path all of them were moving from
688:51 - left to right and one of them was odd so
688:54 - what he choose he chose left to right so
688:57 - this is how deadlock can be saved that's
689:00 - what I'm trying to tell here
689:04 - okay okay so this was the non semap 4
689:08 - based
689:09 - solution it was semap for free it was
689:12 - deadlock free how it works out ofense n
689:14 - philosopher let N minus one go from left
689:17 - to right and then one philosopher will
689:19 - go from left right to left or you can do
689:21 - like that even number should pick first
689:23 - left then right and OD number should
689:25 - pick first right and then left you can
689:27 - do like both both the ways will save you
689:30 - from deadlock so this is how non
689:33 - semaphor based solution worked now comes
689:35 - to the semaphor based solution what are
689:37 - we what are we doing here put semaphore
689:39 - control on taking and releasing the
689:41 - fork how we'll discuss later in the
689:44 - chapters of monitor so there are some
689:46 - miscellaneous topic which I will discuss
689:48 - in the end like uh we have not discussed
689:51 - in detail about Fork system call we have
689:53 - not discussed about threading
689:54 - multi-threading we have not discussed uh
689:58 - monitors in later part of the course we
690:01 - will learn when we will learn about
690:02 - memory management we will learn
690:04 - segmented paging and inverted paging in
690:06 - the last of the course that is the
690:08 - miscellaneous topics okay so we'll
690:11 - discuss that part in the later part of
690:13 - the course that is we'll discuss when we
690:15 - will study monitors okay so this was the
690:18 - dining philosophers
690:26 - problem let's start our lecture with the
690:28 - sleeping Barber
690:30 - problem this problem is from ten and
690:33 - bomb textbook if you want to have a
690:35 - reference you can visit the
690:37 - textbook okay so the problem is there is
690:40 - a barber shop okay there's one Barber
690:42 - and and chairs for in customers as you
690:44 - can see this in the picture if there are
690:47 - no customers then the barber sits on his
690:49 - chair and sleep as Illustrated in this
690:51 - way when a new customer arrives and the
690:53 - barber is sleeping then he'll wake up
690:55 - the barber suppose a customer arrives
690:57 - and the barber is sleeping he'll wake up
690:58 - the barber when a new customer arrives
691:00 - and the barber is busy then he'll just
691:02 - sit on the waiting chairs like this and
691:06 - if there are no chairs available then
691:07 - he'll just
691:08 - leave okay so now you have to tell me
691:11 - the possibility of Deadlock how deadlock
691:14 - can arise in this
691:15 - situation let me give you a hint when a
691:19 - customer doesn't vacate the only chair
691:22 - even after the haircut in that scenario
691:25 - deadlock may arise now you have to think
691:28 - how
691:30 - okay now let's move to the our last
691:33 - topic of this section current
691:35 - concurrency versus
691:37 - sequentiality okay so see this program
691:41 - begin statement one statement 2
691:44 - statement 3 statement 4 a = B+ c d = to
691:47 - e CR F K = A+ d l = k CR D so this will
691:52 - execute sequentially okay now if we see
691:55 - this uh for this in operation if we see
691:58 - the micro instruction or micro
692:00 - operations which are instruction one
692:03 - load the value of B into register load
692:05 - the value of C into register add and
692:08 - store the value of R1 + R2 into register
692:11 - R1 and then store the value of register
692:13 - into a so after all these instructions
692:16 - this statement will be executed so this
692:19 - will go like sequential execution you
692:21 - all
692:22 - know but but I say if permissible if it
692:26 - is allowed then which statement can
692:29 - execute concurrently you know the
692:31 - meaning of concurrent execution
692:33 - parallely okay not not directly see
692:36 - there's a difference between concurr
692:38 - concurrency and
692:39 - parallelism but if you do not know the
692:42 - meaning of concurrency paral ISM can
692:44 - give you a hint
692:46 - okay so if permissible which statement
692:49 - can be executed concurrently so the
692:52 - statement which are not dependent on
692:54 - each other can be executed concurrently
692:57 - or concurrently you can say together
692:59 - okay see statement S1 a = to B+ C
693:05 - statement S2 d = e CR F these two
693:08 - statement are independent how can I say
693:11 - that which statements are dependent
693:14 - those statements are
693:16 - dependent for if one if the output of
693:20 - one statement becomes input for the
693:23 - other see like this S1 and
693:26 - S3 the output of one statement becomes
693:28 - input to the other C S3 and S4 the
693:31 - output of one statements become input
693:33 - for the other so these are dependent so
693:38 - these dependent instructions or these
693:39 - dependent statements cannot be executed
693:42 - together or concurrent ly okay now see
693:47 - this S1 and S2 they can be concurrently
693:51 - executed after this S1 and S2 you can
693:55 - execute S3 and after S3 you can execute
693:57 - S4 so this graph which I have made here
694:00 - is the Precedence graph it is also
694:03 - directed graph what does this
694:06 - show S1 and S2 should be executed first
694:10 - after that S3 after that S4
694:15 - there is there is no order or there is
694:17 - no significance of order to be followed
694:20 - while executing these S1 and S2 so this
694:22 - is what concurrency
694:24 - means why because S1 and S2 are
694:27 - independent okay let's take another
694:29 - example let's see this presidence graph
694:31 - can you tell me which statements can be
694:34 - concurrent the statements which are
694:36 - independent which statements are
694:39 - independent those statements are
694:41 - independent in which the output of
694:44 - doesn't becomes the input for the other
694:46 - okay see this can I say S1 and S2 are
694:49 - independent no because the output of S1
694:51 - will become independent the output of S1
694:54 - will become input of S2 can I say S1 and
694:57 - S3 no the same thing is there also can I
694:59 - say S2 and S3 yes they are independent
695:02 - so they can be concurrent can I say S3
695:06 - and S4 Yes because the output of S4 or
695:10 - output of S3 is not becoming input for
695:11 - the other I hope you're getting the
695:13 - point
695:15 - can I
695:15 - say S5 and S6 are independent or
695:18 - concurrent yes can I say S4 and S5 no
695:22 - because output of S4 is becoming input
695:24 - for the S5 can I say the same thing for
695:27 - S4 and S6 no can I say this S5 and S S6
695:33 - can be concurrently executed with
695:35 - S3 yes can I say S3 and
695:40 - S7 can be conr executed no because the
695:43 - output of I hope you're getting the
695:44 - point okay
695:47 - so you have to see like this this if it
695:51 - is on the other Branch then I can say
695:54 - that they can be
695:56 - concurrent okay now let's understand the
695:59 - difference between concurrency and
696:03 - parallelism concurrency let me tell you
696:05 - directly let me tell you two words which
696:07 - will make it clear concurrency means
696:10 - multi-programming and parallelism means
696:13 - multi
696:14 - processing let me repeat again
696:16 - concurrency means multiprogramming I
696:18 - hope you already remember what is
696:20 - multiprogramming we had this OS and
696:22 - there are multiple programs in the main
696:24 - memory and then CPU executes sometimes
696:27 - P1 and sometimes P2 and sometimes P3 so
696:29 - this is multiprogramming what is
696:32 - multiprocessing in one CPU P1 is being
696:35 - executed in another CPU P2 is being
696:37 - executed in another CPU P3 is being
696:40 - executed this is multiprocessing which
696:42 - include multiprocessors
696:44 - okay so let's read this a system is said
696:47 - to be concurrent if it can support two
696:50 - or more actions in progress at the same
696:53 - time
696:54 - okay same to multiprogramming a system
696:57 - is set to concurrent effec support
696:59 - support C support two or more actions in
697:01 - progress at the same
697:03 - time set analogy with that
697:05 - multi-programming two or more process
697:08 - can be supported for Progress at the
697:10 - same time parallelism a system is said
697:12 - to be parallel if it can support two or
697:15 - more actions executing see this
697:17 - executing word is important executing
697:19 - simultaneously and here progress word is
697:21 - important concurrency is about dealing
697:24 - with a lot of things at once and
697:26 - parallelism about doing lots of things
697:29 - at once okay concurrency is dealing and
697:32 - parallelism is
697:33 - doing don't worry if you are not getting
697:36 - it I have plenty of examples to solve
697:39 - this
697:40 - confusion two or more actions can go
697:42 - along together together or progress
697:44 - together okay so take this example you
697:48 - sit at a chair eating snacks watching
697:51 - lectures and listening to lufy beats in
697:53 - the
697:53 - background this is you dealing with
697:55 - multiple things at a time and what is
697:58 - parallelism in that situation
698:00 - simultaneous execution one person is
698:02 - eating snack one person is watching
698:04 - lecture one person is listening to lfy
698:06 - beads and these are happening at the
698:09 - same time so this is the difference
698:12 - between concurrency and parallelism
698:15 - concurrency leads to parallelism or I
698:16 - can say parallelism can be derived
698:18 - through concurrency okay see this this
698:22 - is sequential execution first this one
698:25 - then this one then this one then this
698:26 - one then this then this then this first
698:28 - all blue ones get executed and then the
698:31 - red ones what happens here sometimes
698:34 - blue one sometimes red one like the CPU
698:36 - do with the processes sometime this
698:38 - process sometime this process this is
698:39 - concurrent we are dealing with the blue
698:41 - ones and the red ones at the same time
698:43 - and noce parallel execution blue ones
698:46 - and red ones are being executed at the
698:48 - same time okay so this is the progress
698:52 - this is the execution okay see this
698:56 - concurrency sometime the blue processor
698:58 - sometime the green sometime blue
698:59 - sometime green here green and blue are
699:01 - being executed together take another
699:03 - analogy concurrent means two cues at one
699:06 - coffee machine sometime this one go some
699:09 - this one go then this one then this one
699:11 - and what is parallelism two Q's on
699:13 - different coffee machines here this
699:15 - coffee machine is dealing with the two
699:16 - different cues and here is the doing I
699:19 - hope you're getting uh the idea okay
699:23 - interleaved execution in
699:25 - multiprogramming this is
699:27 - concurrency you know what is the meaning
699:28 - of intered execution the CPU sometimes
699:31 - execute P1 sometimes execute P2 but it
699:34 - is the same
699:35 - CPU parallelism is possible with multi
699:38 - multiple CPUs or multi code
699:41 - okay concurrency can be segregated into
699:44 - two parts pseudo and real the real
699:47 - concurrency is actual
699:49 - parallelism and the pseudo concurrencies
699:51 - one CPU we get an impression of
699:54 - concurrency see
699:56 - this this is sudo concurrency and this
700:00 - is real
700:01 - concurrence real parallelism actually
700:04 - doing two things simultaneously and here
700:06 - we are just getting an impression of
700:07 - concurrency we are just seeing suppose
700:10 - suppose this is in a black box both of
700:12 - them are in a black box you can't see
700:13 - what is in
700:15 - there so you can see that or you can
700:19 - from the output you can say that blue
700:23 - ones are also coming and red ones are
700:25 - also coming in the output I get an
700:27 - impression that both are being
700:30 - executed at the same time but is it so
700:33 - no sometime this one sometime this one
700:35 - sometime this one sometime this one in
700:37 - this black box when you see the output
700:39 - you can also say that same thing I can
700:42 - see blue ones and R ones coming out of
700:44 - the box so I can say the same thing for
700:46 - here also that both are being executed
700:48 - but the difference is clear here we are
700:51 - just getting an impression of the
700:53 - concurrency and here is the actual
700:56 - concurrency okay this is done when there
700:59 - is a single CPU and this is done when we
701:01 - have two core CPUs because this can be
701:04 - executed on one CPU and this on the
701:05 - other here there is one CPU sometime
701:08 - this is executed and sometime this is I
701:10 - hope now the difference is clear okay
701:13 - so that that thing which we call as
701:16 - sometimes P1 sometimes P2 that is called
701:17 - as that is called as interl execution
701:20 - among
701:21 - processes okay now let me ask you a
701:23 - question Suppose there are two
701:24 - statements SI and SJ SI is AAL to B plus
701:29 - C and SJ is d = e cross
701:33 - F now tell me can they be executed
701:37 - concurrently yes they can be executed
701:39 - because the output of one statement is
701:42 - not becoming the input for the
701:44 - other they all have different variables
701:46 - so yes they can be executed concurrently
701:50 - let's see another question tell this A =
701:53 - to B plus C D = to B CR C can they be
701:55 - executed sequen concurrently yes you can
701:58 - also guess this because the output of
702:01 - one is not becoming the input for the
702:02 - other is a becoming input for this D no
702:06 - we are just reading the values so yes
702:08 - they can also be executed concurrently
702:10 - even though they have shared resources
702:12 - but they are only reading the value of B
702:14 - and
702:15 - C
702:16 - okay so if the output of one becomes
702:19 - input for the other then those two
702:20 - statements won't be concurrent here so
702:22 - you have to remember this line
702:26 - okay for every statement two sets can be
702:29 - defined the reading set and the writing
702:31 - set see above these for this can you
702:34 - define the reading set and the writing
702:35 - set yes reading set will include reading
702:38 - set of Si will include B and C and the
702:41 - writing set of Si will include a
702:43 - because the value of a is overridden or
702:46 - or overwritten and the B and C are red
702:50 - only okay so this is read set set of all
702:53 - those variable whose values are R and
702:56 - right set is all those variables whose
702:58 - values are
703:00 - updated so for this a go to B plus C B
703:03 - and C variables are in the read set and
703:06 - a will be in the right
703:09 - set suppose this statement a + = to ++ B
703:15 - cross - - c so this can be simplified to
703:18 - this a = to a + Plus+ b into-- c now can
703:24 - you tell me what is the read set and
703:26 - what is the right
703:27 - set see for a b and c you can check that
703:32 - value of all the variables are updated
703:35 - see the value of a will be updated for
703:38 - sure the value of B will be updated but
703:41 - how this Plus+ B and b++ are different
703:44 - here we will first increase the value of
703:48 - B by one and then we'll use it we'll
703:50 - first decrease the value of C by 1 and
703:52 - then we'll use it but what happens in
703:54 - the case of b++ we'll first use the
703:56 - value of B and then we'll increase
703:59 - it so a = to a +++ b cross-- c first
704:04 - increase its value by one then use so
704:06 - the value of each of the variable is
704:07 - being updated so what will the read set
704:10 - a b and c and sorry what is the right
704:12 - set a b and c and read will be
704:14 - fine okay now let me ask you an amazing
704:18 - question can you
704:20 - guess this index S3 equals to is SC F
704:25 - perc D and
704:26 - X okay so what is the statement there is
704:29 - some variable
704:31 - index and you are taking the input for
704:34 - it okay now you have to tell me scan F
704:37 - now you have to tell me the read set and
704:39 - the right set think about it pause the
704:42 - video you think about it the read set
704:44 - and the right set okay I'm showing you
704:46 - the answers now so the read set will be
704:49 - five and the right set will be X how
704:53 - this is uh did you think of the opposite
704:56 - answer maybe possible see initially when
705:00 - you just declare a variable without
705:03 - assigning any value then there is some
705:05 - garbage value stored here garbage some
705:07 - garbage value initially and when you
705:09 - take input from the user that garbage
705:11 - value let's say I pressed five on the
705:13 - keyboard for this integer so that
705:15 - garbage value will be replaced by that
705:18 - five okay so the value of x was
705:22 - initially this some garbage value and
705:23 - now it is updated to five so I can say
705:26 - the value is updated so the read set
705:28 - will be X and what is the sorry I always
705:31 - see a so the right set will be X and
705:34 - what will the read set five because we
705:37 - have not read this value so why is it
705:39 - necessary for uh why is it necessary to
705:42 - read this garbage value no it is not
705:43 - necessary so the read set will be fine
705:45 - the right side will be
705:47 - X similarly for S print X for printing
705:51 - we just read the value we do not update
705:54 - that so for print the value will be X so
705:57 - the read value will be X and the right
705:58 - will be F these are just some uh
706:01 - practice question to boost you uh when
706:03 - you can how to find a read set and right
706:06 - set
706:07 - because from this read set and right set
706:09 - I can say if two statements are
706:11 - concurrent or not
706:14 - if if between the right set of the first
706:19 - statement and the read set of the second
706:20 - statement if there is nothing common
706:23 - then the statement SI and SJ are
706:27 - concurrent if the read set and the right
706:29 - the read set of first first statement
706:31 - and the right set of another statement
706:33 - if there's nothing
706:35 - common then SI and SJ can be concurrent
706:38 - if the read if the right set of first
706:40 - first statement and the right set of
706:43 - second statement if there's nothing
706:45 - common then the SI and SJ can be
706:48 - concurrent so this is called as burn
706:50 - steam concurrency
706:54 - condition for two statements you derive
706:57 - what is read set and what is the right
706:59 - set and then see if there is something
707:01 - common in between if yes then they are
707:04 - not concurrent and if no then they can
707:06 - be concurrent okay so this is Burnstein
707:10 - concurrency condition okay now let's see
707:13 - concurrency mechanism how this
707:14 - concurrency is actually implemented and
707:16 - this is not from any textbook okay so C
707:20 - C++ Java sequential language but how can
707:23 - concurrency be applied we can apply it
707:26 - using pair begin and parent so this pair
707:31 - refers to the parallel and this Co begin
707:35 - which is the same name for pair begin
707:36 - and parent co- begin and co- end is for
707:38 - concurrent okay so uh let me tell you
707:42 - how this works begin S1 S2 S3 and end
707:45 - when you write this sequential execution
707:48 - will happen first S1 then S2 and then S3
707:51 - but if you write pair begin and pair
707:54 - end in that
707:56 - case we are allowing for concurrent
707:59 - execution see this firstly s0 s0 came as
708:03 - the root node pair begin S1 S2 and S3 so
708:06 - the they are the concurrent so I can put
708:09 - them on the same level on different
708:11 - branches and then after this block I had
708:14 - S4 so after this I had S4 so I hope you
708:17 - get the difference between how this pair
708:19 - begin and pair end are uh making the
708:22 - Precedence graph different for this only
708:25 - begin and end we did the sequential
708:27 - execution and for pair begin and Pa end
708:30 - we are allowing for concurrent execution
708:34 - okay okay see this S1 pair begin S2 S3
708:38 - S4 begin so we are now using nested
708:41 - begin and pair begin and now you have to
708:43 - do the draw the Precedence graph we
708:46 - start with the S1 so this is the root
708:47 - node we start with the S1 pair begin PA
708:50 - and and then in the end S1 so whatever
708:53 - will come here and then in the end we
708:55 - will had S11 now pair begin S2 S3 S4 so
709:00 - S2 S3 and S4 will be concurrent
709:03 - statements okay begin S5 S6 and end see
709:09 - this here we are using begin so S5 and
709:12 - S6 will be sequential I can see S5 and
709:15 - S6 are sequential begin S7 S8 S9 so S7
709:19 - S8 and S9 will be sequential S7 S8 and
709:21 - S9 are sequential and then in the end
709:24 - S10 in the end S10 see this S2 S3 S4
709:29 - this one this one and this one will be
709:31 - concurrent and this one in this one S5
709:34 - and S6 are sequential S7 S8 and S9 are
709:37 - sequential so this is how it's going to
709:38 - look if you're feeling difficulty don't
709:40 - worry I have plenty of examples
709:43 - write program now it's it's different
709:46 - now you have to go the opposite way
709:48 - write program for the graph see S1 so
709:50 - we'll write S1 here now S2 and S3 can be
709:53 - concurrently executed so I will apply
709:55 - pair begin S2 and S3 but see S2 had some
710:00 - more sequential executions like S2 after
710:04 - that S4 and then S5 and S6 so I'll first
710:06 - write S3 and then I will apply begin why
710:09 - begin because I need some sequential
710:11 - execution steps now I'll write S2 and
710:14 - then S4 so this part is covered and then
710:16 - I I should write S5 and S6 but they are
710:19 - sequential but they are concurrent so I
710:21 - can
710:22 - write S2 S4 and then this pair begin
710:25 - thing and then in the end
710:27 - end and then parent and then in the end
710:30 - S7 let me repeat again see S1 came here
710:34 - this part
710:37 - was related to concurrent execution so
710:40 - I'll write pair begin and pair end here
710:42 - okay now forget about this S3 and S2 are
710:46 - concurrent so I'll write S3 and S2 but
710:49 - you
710:50 - see S4 and S3 are also concurrent S5 S6
710:54 - and S3 are also concurrent that's why we
710:56 - are keeping the S3 outside and this
711:00 - begin and end in the one part okay so S3
711:03 - will be outside begin now we are talking
711:06 - about this
711:08 - tree okay begin S2 S2 will become the
711:11 - root node for this tree and then I need
711:13 - S4 S4 Here and Now I want concurrent
711:16 - execution for S5 and S6 that's why I've
711:18 - used pair begin here and then
711:21 - end now let's modify the question a
711:23 - little
711:24 - bit instead of S3 going straight to S7
711:28 - why don't we make like this S3 going to
711:30 - S6 now it's a homework problem we have
711:33 - to write the program just as we did here
711:36 - okay in this graph we made a little bit
711:38 - of change instead of going like this we
711:40 - changed to this okay
711:44 - let us start our discussion of final
711:45 - part with the homework problem I've
711:48 - given you a homework problem in which I
711:50 - change the Edge from this to
711:53 - this okay this is The Edge now you have
711:56 - to tell what will be the code of this
711:57 - graph so I start with S1 I start with S1
712:01 - and then I can see these two these two
712:04 - blocks are these two nodes are
712:07 - concurrent okay can I say these two are
712:09 - concurrent also no I cannot directly say
712:11 - because the statement the the section or
712:15 - I can say the
712:16 - node
712:18 - S3 is making S6 dependent on itself the
712:21 - output of S3 is the input of S6 so I
712:26 - cannot say S5 and S6 are concurrent
712:29 - always because this is from a different
712:31 - branch and this may be from a different
712:34 - branch that's why I cannot say S5 and S6
712:36 - concurrent as always like I did in the
712:39 - last question in the last question S5
712:41 - and S6 were indeed con current but now
712:43 - it is not so how we going to proceed
712:46 - with this let's see we have two cases we
712:48 - have two options we started with S1 here
712:50 - pair begin S3 and then this S2 S4 and
712:55 - also include S5 and S6 here I'm talking
712:58 - about of this block including here after
713:02 - s sport so what is the problem that may
713:04 - arise the problem is this Edge this pair
713:07 - begins is you can start with either S3
713:09 - or this or this statement you can either
713:13 - start with both of
713:15 - them so I say why I can't start with
713:18 - this so I start with this begin S2 S4
713:22 - and I said I'm including this block also
713:24 - here so S5 and then S6 but the problem
713:28 - is can you execute S6 before executing
713:32 - S3 no that's why we have to we cannot
713:35 - include this block here that's why we
713:38 - need to separate this
713:39 - block what we did in the last question
713:42 - in the in the previous lecture we
713:44 - included this block here but you cannot
713:46 - do this now why let me repeat again
713:48 - because the input of
713:51 - S6 is the output of
713:53 - S3 they are dependent on each other they
713:57 - cannot be in pair begin with different
714:00 - statements with this and this okay I
714:03 - hope you're getting the idea that's why
714:05 - I need to separate this block but
714:07 - separation also caused a problem this
714:10 - code says you need to First execute S1
714:13 - then this block then this block and then
714:17 - S7 this block includes S3 in it this
714:20 - blocks include S5 in it so the code says
714:23 - you cannot execute S5 before executing
714:27 - S3 but the graph says yes you can the
714:30 - graph says you
714:32 - can so there is some kind of
714:34 - contradiction there is some kind of
714:35 - complication in the
714:37 - solution I had only two cases either to
714:39 - include that block here or to keep it
714:41 - separate
714:42 - by keeping that block here I'm volting
714:44 - this Edge this Edge and by keeping the
714:47 - blocks separate I'm including an
714:50 - additional age so this is creating a
714:52 - problem this is complicated
714:54 - now okay so can I say about S5 and S6
714:58 - they are concurrent no sometimes they
715:00 - are and sometimes they are not because
715:02 - S6 depends on S3 and S4 both and these
715:04 - two belongs to different branches okay
715:07 - that's why I cannot say S5 and S6 are
715:08 - always
715:09 - concurrent so the program is you cannot
715:12 - complete S5 before completing S3 but the
715:14 - graph says yes the program would be okay
715:16 - if I put an edge from S3 to S5 but
715:19 - now the edge is not
715:21 - present so there is some kind of problem
715:23 - in the
715:26 - solution the answer is it is non
715:30 - implementable we cannot implement this
715:32 - with pair begin and pair end
715:35 - alone such graphs are implementable
715:38 - using semap for let's see how so we
715:41 - Define
715:43 - number of binary sem fores a b c d e FG
715:45 - and all of them are set to zero so what
715:48 - idea we are using here we are using that
715:51 - as we have defined all of the binary S4
715:54 - to zero I cannot move to a statement
715:57 - directly see
716:00 - this forget about this graph forget
716:02 - about everything here okay just see this
716:05 - in pair begin I have several statements
716:06 - here okay can I jump directly to this
716:09 - statement and start executing no because
716:12 - I would be directly blocked away because
716:14 - the value of a is initially
716:17 - zero can I directly jump here yes I can
716:19 - jump here I can start executing S1
716:22 - increased the value of a now can I go
716:24 - there yes now can I come here so what
716:27 - does this VA and Pa VA is
716:31 - increasing up operation on a and Pa is
716:34 - down operation on a so what are we doing
716:36 - we have initialized the value of binary
716:37 - S 4 all of them to zero and now we are
716:42 - making it like a condition that before
716:45 - you execute this
716:47 - statement before you execute the or I
716:49 - should say before you execute this
716:51 - statement you have to execute the above
716:53 - one because in the above one only you
716:56 - have a key to access this statement
716:59 - because if you do not do this this VA
717:02 - you are not able to go ahead with this
717:04 - statement you you won't be able to
717:06 - execute S2 you won't be ex able to
717:08 - execute S4 I hope you're getting the
717:10 - idea let me put it in a simple
717:13 - words v
717:16 - s p or I should say v s p a k suppose S
717:22 - and K are two statements so which
717:23 - statement are you going to execute first
717:26 - obviously VA because initially the value
717:28 - of a is zero if you try to directly go
717:30 - and execute a statement K you will fail
717:32 - you will be directly blocked away that's
717:33 - why it is necessary to execute a
717:35 - statement s first so VA a = to 1 s first
717:38 - will be executed now we comes to PA now
717:41 - the value of a is set to Z Z and now I
717:42 - can execute a statement K so this is how
717:45 - we are using the help of or we are
717:47 - taking the help of SEMA 4 to create a
717:50 - sequence here we have created sequence
717:52 - you need to execute first s and then K
717:54 - only here sequence is created so that's
717:56 - why we are using SEO to create a
717:58 - sequence let's see how are we going to
718:00 - use that sequence thing in in this our
718:04 - uh our question so we want S1 to be
718:06 - executed first then S2 and S3 that's
718:09 - [Music]
718:10 - why we we created a lock here and a key
718:14 - here so if someone directly try to
718:16 - execute S2 and S3 they will be directly
718:18 - blocked away so it has to First acquire
718:20 - the key where is the key here is the key
718:22 - so first execute S1 acquire the key for
718:25 - this statement acquire the key for this
718:27 - statement and then end now I have key
718:30 - for S2 and S3 both it's upon me it's or
718:34 - I can say it's my choice on which I
718:36 - should go I can either go to SD I can go
718:38 - to I can go to S2 or I can go to S3 it's
718:40 - my choice why I am given with a choice
718:43 - because these two statements are
718:47 - concurrent we were not given we were not
718:50 - given the choice for S1 we have to
718:52 - execute S1
718:53 - first because by doing all these things
718:56 - we want to create a
718:58 - sequence we need to execute S1 first now
719:01 - you get a choice to execute S2 or S3 for
719:03 - S2 you after S2 you have to execute S4
719:06 - see this after S2 you have to execute to
719:08 - S4 there's no other
719:10 - choice so in this this way we are we are
719:13 - planning to proceed or in this way we
719:14 - are going to solve this problem let's
719:17 - now see Again Begin S1 acquire key for
719:20 - this statement acquire key for this
719:21 - statement now let's say I begin with
719:23 - this PA we open the door for this
719:28 - path execute S2
719:31 - S4 now now now now what happens before
719:35 - going
719:37 - to S5 or S6 before going to S5 or S6
719:42 - I have to acquire key for S5 or S6 so I
719:45 - have to acquire key for S see this this
719:48 - is the key VC is the key for S5 so I
719:50 - acquired key for
719:52 - S5 and then I acquired key for S6 also
719:55 - see by executing S4 I acquired key for
719:59 - either S5 and then S6 and then we
720:02 - ended now I jumped to here I have key
720:06 - for S5 so I go to this
720:09 - statement executed S5 go got a key to
720:13 - execute the statement 7 got a key to
720:15 - execute the statement 7 so what I want I
720:17 - directly go there to execute the
720:19 - statement 7 but I what I found there is
720:21 - another lock here and what does this
720:23 - lock say this lock say man you need to
720:26 - execute S6 before going to before coming
720:29 - to me because S7 it is dependent on S6
720:31 - also so what I was trying to do after
720:33 - executing S5 I was directly trying to
720:35 - jump to S7 but the S7 says I have
720:38 - another lock for you and this lock will
720:40 - be opened only when S6 will be executed
720:43 - see see here this lock will be
720:45 - opened this lock will be opened after
720:48 - when S6 is executed okay so what I
720:53 - did I executed this this this got a key
720:56 - for s for the first lock of S7 and then
720:59 - remember I had also key for S6 so I
721:02 - moved here
721:05 - completed uh open the first log for S6
721:08 - see this S6 also has two logs one and
721:11 - second so the first I got for S4 and the
721:13 - second I need to get from
721:16 - S3 so the first loog I executed I I
721:19 - opened using the key which I got from
721:22 - which I got from executing S4 now I want
721:25 - second key from where I can get remember
721:27 - I had a key for S3 also by executing the
721:30 - first statement I key I got a key so I
721:33 - applied I or I used that key here opened
721:35 - the lock for S3 executed S3 and got the
721:38 - key for
721:40 - S6 now I can open the second lock for S6
721:44 - executed the S6 got a key for the second
721:46 - lock of S7 opened the second lock
721:50 - executed the S7 and then
721:52 - end for the beginning it may seem
721:55 - complicated but it is not believe me it
721:57 - is not complicated it is just like a it
722:00 - is just like uh remember we used to in
722:03 - in in childhood we used to solve that
722:05 - maze problem you go there go there and
722:07 - then we finally get out of the maze so
722:09 - this is similar to that you just go with
722:12 - the flow execute s S1 first executed S1
722:16 - first now I got a key for S2 and S3 I
722:20 - got a key for S2 and S3 it's upon me
722:23 - which uh way I I go so I decide to go on
722:26 - the S2 way I decide to go on the S2 Way
722:28 - open the log for S2 executed S2 then S4
722:32 - got a key for S5 that this VC I got a
722:35 - key for S5 because why why I written
722:39 - like this because for S5 it is necessary
722:41 - to execute S4 first that's why we
722:43 - created lock there at the before S5 and
722:46 - then this lock key is available after S4
722:49 - so I got a key for S5 and after
722:53 - executing S4 I also got a key for S6
722:56 - because the output of S4 is input for S6
723:00 - that's why a key should be given after
723:02 - executing S4 for S6 that's why I got a
723:05 - key here now what I got what I have with
723:08 - me I have the key for S3 which I got
723:11 - from EX this statement I got a key for
723:14 - S5 and I got a key for S6 so I decide to
723:18 - go with the S5 I go with the S5 open the
723:20 - door for S5 execute the statement S5 now
723:23 - you can see S7 is dependent on S5 so I
723:27 - will get a key of S7 after executing S5
723:30 - now I give got a key for S7 what I
723:33 - decide I decide directly go to the S7 I
723:35 - decide to go to the7 open the first lock
723:37 - but what I see there there is another
723:39 - lock also for this Edge
723:42 - in this and say you have to first open
723:45 - S6 so I go to the S6 I have a I have a
723:49 - key for S6 which I got from this S4 I
723:52 - open the first door for S6 now I've got
723:55 - another lock and this lock will be
723:57 - opened by S3 this lock will be opened by
724:00 - S3 so I go to the S3 execute S3 see I
724:03 - had a key for S3 executed the S3 and I
724:05 - got a key for V which is the second loog
724:08 - of S6 so I've got the second loog of S6
724:12 - executed S6 got the key for the second
724:15 - lock of S7 for the second lock of S7 exe
724:18 - open the lock and then executed S7 and
724:20 - then
724:21 - end okay so this is how we are going to
724:24 - solve this uh par begin and parent using
724:28 - semop fores okay let me tell you one
724:31 - last time this
724:34 - shortcut for S6 you need to have two
724:38 - keys for S7 you need to have two keys
724:41 - for S5 you need to have only one key for
724:43 - S4 you need to have only one key for S2
724:46 - you need to have one key for S3 you need
724:48 - to have one key so based on the edges
724:50 - there will be that number of locks see
724:52 - for S6 we had two locks for S7 we had
724:55 - two
724:57 - locks okay so this is how we will
724:59 - proceed with it I hope you understood
725:03 - how are we solving using semap and to
725:05 - check that I have a homework for you the
725:08 - homework is try writing the same program
725:10 - with less than than seven semores try
725:13 - writing the program with less than sem4
725:15 - see here we used 1 2 3 4 5 6 7 binary
725:18 - sem4 can you optimize it to use that in
725:21 - less than 7 774 try
725:24 - this let's discuss some more problems so
725:27 - we are given with a code and we have to
725:29 - draw the graph let's start S1 we made S1
725:33 - in the starting pair begin and this pair
725:36 - begin ends here so I can say S9 will be
725:39 - the last S9 will be the last now what
725:42 - comes S2 and S4 so there is a edge for
725:45 - S2 and then S4 S2 and S4 are
725:48 - sequential then this part S3 S3 will be
725:53 - the in the beginning and that S3 and
725:56 - this pair begin PA end will be
725:57 - sequential so S3 and this will be
725:59 - sequential first S3 and then this pair
726:02 - begin S5 pair begin S5 see S5 and this
726:06 - part will be concurrent S5 and this part
726:09 - is concurrent and then S6 and S8 are
726:12 - sequential S6 and S8 are sequential and
726:14 - then par end this ends now what was in
726:18 - the par begin S2
726:20 - S4 S3 in this part and S7 and S7 and
726:25 - then the end comes S9 so then in the end
726:28 - comes S9 so this is the graph easy
726:31 - question number two we are given with a
726:34 - function void p a b c void q d e Main
726:41 - pair begin p and Q and P and Q can be
726:44 - concurrently executed now we have to
726:46 - select the valid sequences okay I can
726:49 - either start with P I can start with Q I
726:52 - can go like this let me write all the
726:54 - possibility I can go like this first P
726:55 - then Q first Q then
726:57 - P for some time p and then for some time
727:01 - Q for some time q and then for some time
727:03 - P I can go with any of the way for
727:06 - sometime P for sometime Q for sometime P
727:08 - for sometime Q I can go this way also
727:12 - but in all of the sequences the order
727:15 - should be valid B cannot come before a e
727:18 - cannot come before D okay so based on
727:21 - this we have to select the valid
727:22 - sequences can this be valid a b c d e
727:25 - yes we execute first p and then q a b c
727:28 - and then d e so yes this is valid a d b
727:32 - e c is this valid a d b e c yes this is
727:36 - valid I have said we can execute P for
727:39 - some time then Q then again P then Q
727:41 - then again we can go like that there's
727:42 - no problem in that because PA
727:45 - begin d e a b c d e AB b c we can go
727:50 - like that first q and then p d c e b a d
727:56 - and then C no this cannot come because C
727:59 - cannot come before a see here you can
728:01 - see C cannot come before a so this is
728:03 - false this is
728:05 - wrong a e b d c a e no this is false
728:11 - after a even if you are going to Q then
728:13 - D should come see these are sequential
728:16 - these are sequential but these p and Q
728:18 - are
728:19 - concurrent okay so a cannot come or I
728:22 - can say C cannot come before a or E
728:25 - cannot come before D so you have to
728:27 - check that okay so out of
728:30 - these 1 2 and three are correct let's
728:34 - move to the next question this was a
728:35 - nice question in X 0 and Y is z co- Co
728:40 - is same as PA begin so it ends here this
728:43 - is co begin begin x = 1 y = x so
728:46 - whenever you are given with the code for
728:48 - better understanding you should make the
728:49 - Precedence graph so we made a precedence
728:51 - graph we started and then this part and
728:54 - this part are concurrent that's why we
728:56 - made this part and this part concurrent
728:58 - this part included this x = 1 y = y + x
729:02 - and this part include Y = 2 and then x =
729:06 - x + 3 so we have to proceed in the same
729:08 - way in the same way now final values of
729:12 - X and Y which of the following values
729:13 - are possible let's check
729:16 - that is this
729:18 - [Music]
729:20 - possible is this possible x = 1 Y = 2
729:23 - let's see so we started with X = 0 here
729:26 - is the start we started with X = 0 and Y
729:28 - = 0 so I go with this first 1 x = 1 and
729:33 - then 3 Y = 2 x = 1 y = 3 but wait the
729:38 - program is not over yet and then I come
729:40 - to two y = y + x what was y y was 2 y =
729:45 - y + x 2 + 1 = 3 so we got 3 here and
729:50 - then four x = x + 3 x = x + 3 what was x
729:53 - 1 3 so X is 4 the final values are 3 and
729:56 - 4 it is not 1 and two so I have not got
730:01 - it yet let's check for another sequence
730:03 - I started with this I go like
730:07 - this okay let's
730:09 - check 3 4 why would = 2 x = so Y = 2 2 x
730:16 - = to 3 now because initially the X was Z
730:18 - here now I go here x = 1 and y = 2 + 1 =
730:23 - 3 so the value which I got is 1 and 3 no
730:26 - it is not 1 2 3 4 if I go in another
730:31 - fashion like 1 2 3 and 4 in this way
730:34 - then does it go like that x = 1 y = y +
730:38 - x initially the Y was 0 so y will also
730:40 - be 1 now y becomes 2 Y = 2 now let's
730:43 - check for x x = 1 + 3 = 4 now the value
730:46 - which I got is 2 and
730:49 - 4 so this is not there so I can say x =
730:52 - 1 and y = 2 is not possible let's check
730:55 - for another x = 1 for this case x = 1
730:58 - and y = 3 I should go like 3 4 1 and 2
731:02 - in that case I got the value 3 4 and 1
731:04 - and 2 in that case we got x = 1 because
731:09 - the value of x was last updated here and
731:11 - y = 3 how y = to the value of y was last
731:14 - updated here 2 + 1 = 3 so this is
731:16 - correct yes can I got x = 4 and y =
731:20 - 6 let's check for that can I get so this
731:23 - was this was not true this was true can
731:26 - I get x = 4 and y = 6 Let's see we start
731:31 - with we start with one and then we two
731:34 - and then three and four are here 1 and 2
731:37 - okay so x = 1 so we go like that x = 1
731:41 - okay and Y = 2 yes and then we move down
731:44 - here x = x + 3 which is 1 + 3 = 4 now
731:50 - I'll go here so this is this way I'm
731:55 - moving now I get here the value of y was
731:58 - last updated to 2 and the value of x is
732:00 - 4 so 2 + 4 = 6 so now I got 2 + 4 = 6 so
732:04 - this is also true so the answer was
732:07 - second and third let's move to the next
732:10 - question the question says int x = 0 y =
732:13 - to 20 so initial value was 0 and
732:16 - 20 we have two binary S4 MX and NY and
732:20 - they are both set to one MX = to 1 and m
732:23 - y =
732:24 - 1 we are given with two concurrent
732:27 - blocks this block and this block and so
732:31 - we made a graph PX x = x + 1 M VX MX see
732:38 - both MX are present here MX X = to y + 1
732:41 - and
732:42 - vmx now what is the final possible
732:45 - values of
732:46 - X what is the possible values of X we
732:49 - have to get that
732:51 - so as we can see the value of MX is
732:55 - 1 I can say this is the critical
732:58 - section so I say we start with P1 first
733:03 - and then P2 so P1 first it comes here P
733:06 - = to MX now P MX so MX will be changed
733:10 - to Z
733:11 - x = x + what is the initial value of x 1
733:15 - now V
733:17 - MX MX is changed back to 1 now this
733:21 - comes MX is changed back to zero X = to
733:25 - y + 1 so the value was X was what was
733:29 - the value of x initially it was set to
733:30 - one now what happens here x = y + 1 what
733:33 - is y 20 20 + 1 = 22
733:36 - 21 so in this way I can get the final
733:39 - value of x is 21 I get the final value
733:41 - of x is
733:43 - 21 if I go opposite if I go opposite
733:46 - first this way x = y + 1 what is the
733:49 - value of x initial it was 0 so 0 or so y
733:52 - + 1 = 21 I get the value of x is 21 now
733:57 - I go here x = x + 1 21 + 1 = 22 so 22 so
734:04 - if I say you directly you can solve this
734:06 - question without even lifting a
734:08 - pen how is it possible because you can
734:11 - see we are using binary SEMA 4 here
734:14 - binary SEMA 4 with value one can't you
734:17 - remember that this implies
734:24 - sequentiality there is no such
734:26 - concurrency if we are using Mutual
734:28 - exclusion concurrency means that we are
734:30 - not using Mutual
734:32 - exclusion binary sem 4 with value 1
734:35 - implies sequentiality we have to first
734:38 - execute either this one and then this
734:40 - one or we can go like this one and then
734:42 - this one but we have to be sequential we
734:44 - have to be sequential we can execute
734:46 - either this block first and then this
734:48 - block or can do the opposite like this
734:50 - one and then this one so the final
734:51 - possible values are 21
734:54 - 22 now it's your homework question if P
734:58 - MX and vmx were not there then what will
735:00 - the value of x think on low level what
735:02 - is the meaning of low level break it
735:04 - onto the instructions like
735:06 - load increment store do like that and
735:11 - and then tell me the value of x if
735:13 - Mutual exclusion was not present okay so
735:16 - this is your homework try
735:18 - this let us start our last topic of the
735:22 - section process synchronization fork and
735:24 - join this is not that traditional Fork
735:26 - which we used to talk about it is not
735:27 - the system called and they are Atomic
735:31 - let's see the syntax of the fork is for
735:34 - l what does this fork in join
735:37 - do this the fork divides and the join
735:41 - joins let's see what does the fork
735:43 - divide execution of this Fork will
735:46 - result in starting of two competitions
735:48 - concurrently which will be the two
735:50 - competitions the first statement after
735:53 - fork and the statement at which label is
735:57 - pointing these two will
735:58 - [Music]
736:00 - be concurrently started being executed
736:03 - which two the statement right after fork
736:06 - and the statement which label is
736:08 - pointing so these two statement will be
736:11 - concurrently executed the execution of
736:13 - fork result in starting two computations
736:15 - concurrently the first one is which is
736:17 - immediately after the fork and the
736:18 - second one is which is at label L see
736:21 - this and you'll get more clarity int
736:24 - count equals to two why we have def
736:26 - defined count here for joining purposes
736:30 - this count signify how many edges are
736:32 - meeting at that point if I say count
736:34 - equals to three which which means three
736:36 - edges are meeting at the
736:38 - junction okay s one the root node now
736:43 - comes the division that's why we use
736:45 - Fork so Fork Fork
736:49 - l what does l points L points to the
736:52 - statement three S3 so S3 and what is the
736:55 - immediate next instruction after Fork S2
736:58 - so S2 and S3 will be concurrently being
737:00 - started executing so S2 and S3 are
737:02 - concurrent here now I have to join I
737:05 - have to join how can I join after S2 the
737:09 - control should go to join after S3 the
737:11 - control should go to join so that's why
737:14 - after S2 to make the control flow go to
737:18 - the join we made the label of join as X
737:21 - and then we wrote go to
737:24 - x so after S2 the control should go to
737:26 - join after S3 the control should go to
737:28 - join for S2 the join was not the next
737:31 - immediate statement that's why we
737:32 - included go to statement but for S3 the
737:36 - join was the next immediate statement
737:38 - that's why there is no need to write go
737:39 - to here it will automatically go to
737:41 - statement X without writing the go to
737:43 - because it is the next statement okay so
737:46 - we write after statement X2 go to x and
737:50 - after statement S three the x is
737:51 - automatically here so join will join two
737:56 - statements so these two are joined and
737:58 - at and they are joined at which
738:00 - node the node which is written or the
738:03 - statement which is written right after
738:04 - the join which is as4 do not worry if
738:06 - you are feeling too much of information
738:08 - overload this is an easy concept and
738:11 - you'll get it believe me so what does
738:14 - join do join in count count equals to
738:17 - count minus one if count is not zero
738:19 - then exit else return forget about this
738:23 - this is not much important but I'm
738:24 - telling you okay let's solve some more
738:27 - question you'll get the idea we'll get
738:28 - back to it we'll see some more questions
738:30 - so S1 what we want we need to Fork so S1
738:36 - Fork L and L should point to which S3 so
738:40 - the next immediately statement is S2 and
738:43 - L should point to S3 L should point to
738:45 - S3 okay now after S2 I want the control
738:49 - go to S4 control go to S4 now I want
738:52 - Fork here I want Fork here Fork K and K
738:57 - should be S6 and the next immediate
738:59 - statement is S5 so the control will be
739:02 - divided to S5 and S6 S5 and S6
739:07 - here now after S5 S6 and S6 I want to
739:11 - join them so control should go to the
739:13 - join statement so after S5 the control
739:15 - should go to join so after S5 the
739:17 - control should go to join where is the
739:19 - join join is at Zed so I made the label
739:21 - Zed so after S5 control should go to
739:23 - label Zed after S3 after S3 control
739:26 - should go to label Zed control should go
739:29 - to label Zed and after S6 the label Zed
739:32 - itself here so we did not include it go
739:34 - to and then in the end join count S7 so
739:38 - after join whichever node is present at
739:40 - that node the merging will be there okay
739:44 - I hope you got the idea how it's working
739:45 - so road map is if you are dividing
739:48 - include
739:49 - Fork the next statement and l l is S2
739:53 - okay and if you want to join join count
739:56 - and then in the end whichever node we
739:58 - are joining write that so this is how
740:00 - four can join work so let's see what was
740:02 - written here after S2 and S3 the control
740:04 - should come to join out of the one which
740:06 - complete at last going to make the count
740:08 - Z that will start as 4 easy same thing
740:11 - it's written
740:12 - here now let's see if if there are more
740:15 - questions yes there are more questions
740:16 - P1 P2 P3 and P4 okay so P1 I want to
740:20 - divide that into three parts see this is
740:22 - an interesting problem in Fork if I
740:24 - write Fork L then the immediate
740:26 - instruction after Fork let's say S1 I'll
740:29 - get S1 here and whichever instruction
740:30 - this level is pointing let's say S2
740:32 - those two will start concurrently but
740:35 - how I'm going to branch that into three
740:37 - is there any way is there any way to
740:39 - Branch them into three
740:41 - so first of all if you are planning to
740:43 - join them into one node then you should
740:45 - make the count equals to three P1 Fork L
740:50 - Fork L we divided into P2 and L is
740:52 - pointing to another
740:55 - fork and that fork is pointing to
740:57 - another thing that is p Fork so we are
740:59 - using two forks so the first fork and
741:02 - the second
741:03 - Fork are you seeing this the first fork
741:06 - and the second Fork P2 P2
741:12 - is executed and then label n is pointing
741:13 - to another Fork x n is pointing to
741:16 - another Fork X after X P3 is there after
741:18 - X P3 is there and the next statement
741:21 - that will be there is P4 so P4 is come
741:23 - here so these three will be concurrent
741:26 - and now we have to join them how are we
741:29 - going to join them after P2 the control
741:31 - should go to P5 the control should go to
741:33 - P5 and we have made a label join K so
741:36 - control should go to join K here this
741:39 - way after P3 the control should go to
741:41 - join after P3 the control should go to
741:43 - join
741:44 - X after P3 okay after P3 the control
741:47 - should go to there okay now after P4 the
741:50 - control should go to this join but it is
741:52 - already there that's why we did not
741:53 - include go to so we came here and these
741:55 - three will be joined to which node P5
741:58 - which is immediately just just after the
742:00 - join let's move to another question this
742:03 - will clarify all your doubts n and M are
742:05 - set to two n is set to two and M is set
742:08 - to two two folks are there which which
742:11 - means right just after the start the
742:14 - program will be divided into three
742:15 - branches for two folks the program will
742:17 - be divided into three branches the first
742:20 - is S1 the first is S1 the second one is
742:22 - the label L3 where is label L3 the label
742:24 - L3 yes this is here the S2 the second
742:26 - one is S2 and the third one will be
742:29 - level L4 where is level L4 here S4 the
742:31 - third one will be here S4 so the program
742:34 - right after the star divided into three
742:36 - things three
742:38 - branches after s
742:40 - [Music]
742:42 - the label comes to join n the label
742:44 - comes to join n so we have to join we
742:47 - have to join we have to join and what is
742:49 - n n is the two which means two of the
742:52 - edges are going to join and come at
742:55 - where S3 so S3 will be the point where
742:57 - two edges are joining which two edges
742:59 - are there so the first one is after S1
743:02 - the L1 which is joining statement comes
743:03 - so the first Edge will be of S1 and the
743:06 - second Edge will be of will be of the
743:09 - statement after which the control is
743:11 - shifted to the label one which statement
743:14 - after which control has been shifted to
743:16 - label one see is there any go to
743:18 - statement go to go to go to go to go to
743:22 - label one is here so after S2 I am
743:24 - finding a go to statement which is
743:26 - sending me back to join so after S2 join
743:30 - is going to
743:31 - happen see we did the same thing
743:33 - everywhere don't get
743:36 - confused whichever edges we want to join
743:40 - after that node we sent the control to
743:42 - the go to statement or the join
743:44 - statement see after P2 we want to join
743:47 - after P2 we want to join that's why we
743:48 - sent to joining statement after P3 we
743:51 - want to join after P3 we want to join
743:53 - that's why we sent to the joining
743:54 - statement after P4 the control will
743:56 - automatically go to join that's why P4
743:59 - is here to join same thing is happening
744:01 - here after S1 control automatically get
744:04 - to join that's why join after S2 the
744:08 - control has been shifted to join I use
744:10 - the help of go to statement that's why
744:12 - S2 will be there and whichever node is
744:16 - after that join statement the edges will
744:19 - be merging there that's why S3 is here
744:22 - okay after S3 after S3 join M so some
744:26 - join operation will here happen also
744:28 - okay now I have to find the go to
744:30 - statement which is sending the control
744:33 - to this label to go to statement go to
744:37 - statement go to no go to this go to what
744:39 - is sending label to join n no I want the
744:42 - control to join
744:43 - M L4 L2 see here I have found so after
744:48 - S4 the control has been sent to
744:51 - this so from S4 The Edge will come
744:54 - because after S4 the control has been
744:56 - sent to this so after S4 The Edge will
744:58 - come now what will
745:02 - happen whatever be the node after that
745:05 - join statement join will happen there so
745:08 - the join will happen at S5 see in the
745:10 - previous case whichever node after
745:12 - coming join that is S3 join will happen
745:14 - there whichever node after coming the
745:16 - join join will happen there that why
745:18 - join happened here okay now what happens
745:21 - go to next what is next this has already
745:24 - been executed already been executed
745:26 - already been executed go to already been
745:28 - executed now this thing S6 that's why we
745:32 - xess so this is how we solve the
745:35 - questions of for and join just remember
745:38 - one thing or two things I should say for
745:40 - four Fork you should remember two things
745:41 - the control will be divided at two nodes
745:45 - the first which is immediately after the
745:46 - fork and the second will be the fork
745:48 - which is it labeling to see the fork is
745:51 - labeling to L which is S3 should come so
745:53 - S3 came here for fork you have to
745:56 - remember these two things for join which
745:57 - two things you have to remember for join
745:59 - you have to
746:02 - remember after join whichever node is
746:04 - coming join will happen at that node
746:06 - merging will happen at that node and
746:09 - whichever node after which the the
746:11 - control is sent to the join statement
746:14 - that node edges will be merged at the
746:17 - node which is coming after the joining
746:19 - statement let me repeat again see after
746:22 - S5 the control has been sent to join so
746:24 - S5 Edge will be merged at S7 after S6
746:28 - the control has been sent to join so S6
746:30 - Edge will be merged at S7 after S3 the
746:34 - control has been sent to join so S3 Edge
746:36 - will be joined at S7 okay so these
746:39 - things you have to remember
746:40 - for
746:41 - for so basically here our section of
746:44 - process synchronization is over but
746:46 - before just uh making it end like that
746:49 - let's see some revision questions the
746:51 - question says consider the following C
746:53 - code where s is a sem4 initialized to
746:55 - five in line two and counters a shared
746:58 - variable initialized to zero in line one
747:00 - assume that the increment operation in
747:02 - line 7 is not Atomic are saying the
747:05 - counter is set to zero the SEMA 4 is set
747:07 - to five there is some function which
747:09 - include two two weight operation one
747:11 - increment and two signal operation it
747:14 - says if five thre execute the function
747:16 - PA of concurrently which are the
747:18 - following program or behavior is are
747:19 - possible there's a deadlock involving
747:21 - all the threads is that possible yes it
747:23 - is possible let's say there are five
747:25 - threads T1 T2 T3 T4 T5 the first one
747:28 - come execute this weight on so this
747:31 - becomes four gets preempted second one
747:33 - come execute the first operation s
747:35 - becomes three now this one comes s
747:38 - becomes two now this one comes s becomes
747:39 - one now this one comes s z now now T1
747:42 - comes again and start with this but s is
747:44 - zero will get blocked T2 come again and
747:47 - start with this s is zero T will get
747:49 - blocked will get blocked blocked blocked
747:52 - so all of them are blogged in this way
747:54 - deadlock is
747:56 - present so the question was asking which
747:58 - of the following are possible is
747:59 - deadlock possible yes preempt after one
748:02 - instruction and then execute all of them
748:05 - and then when they will come back again
748:08 - they'll get blocked okay so this is
748:10 - deadlock is possible the second question
748:11 - says the value of counter is five after
748:14 - all threads successfully complete the PA
748:16 - of instruction yes the value of counter
748:18 - will be five how let all threads execute
748:22 - sequentially in that case first T1 will
748:24 - execute and then T2 will execute and
748:26 - then T3 and then T4 and then T5 in this
748:29 - way if the sequential execution happen
748:31 - the value of counter is
748:32 - five the value of counter is one after
748:35 - all the threads successfully complete
748:36 - the execution of perrow can the value of
748:38 - counter be one yes when the counter will
748:41 - one okay see this process one P1 or the
748:45 - thread one load increment and it just
748:47 - get preempted before it can store let P2
748:50 - P3 P4 and P5 complete make the changes
748:53 - so the initially it was Zero when it
748:57 - when P3 was about to make the changes it
748:59 - gets pred P2 P4 P3 and P5 comes makes
749:03 - the changes make it to 4 and now P1 is
749:05 - storing its value as one so this is how
749:08 - the counter is one see we have have done
749:11 - so much of questions like this don't uh
749:13 - feel confused if you are feeling
749:14 - confused just go back watch some
749:16 - lectures we have solved so much of
749:18 - difficult question on that this is an
749:19 - easy one you should uh this should be a
749:21 - cake for cake work for you okay P1 and
749:25 - then in the end we store load increment
749:27 - preemption make that that these process
749:30 - complete and then P1 is come to store so
749:33 - the final value will be one yes this is
749:34 - true the value of counter is zero after
749:36 - all threads execute or successfully
749:39 - complete the execution of per no the
749:41 - value of counter can never ever be zero
749:43 - in any case after the execution of all
749:45 - these threads
749:47 - okay the value of counter can be 1 2 3 4
749:50 - 5 depends on how process executes so so
749:53 - this was an this was uh uh brainstorming
749:57 - question how can the value be one this
750:00 - this way how can value be two these two
750:03 - store later and these two comes first so
750:06 - after P3 P4 and P5 have completed the
750:08 - execution now P1 and P2 comes
750:11 - and store their value so this is how
750:14 - value can be two value can be three when
750:16 - when P4 and P5 makes the change and then
750:19 - P1 P2 and P3 sequential execute and make
750:21 - the value three so this is way things
750:23 - will go
750:24 - on okay now there is another homework
750:27 - question for
750:28 - you if we initialize the sem 4 to one
750:31 - and remove one weight and Signal here so
750:33 - what is the question now the S 4 value
750:36 - is now one and vit s count Plus+ signal
750:38 - s signal s what is the possible value of
750:40 - the count now you have to tell me this
750:42 - see if you tell this wrong I'm going to
750:46 - come at your home and give you a nice
750:47 - beating because we have done this type
750:50 - of question so many times you can even
750:52 - in a blink of eye you can you should
750:54 - tell the answer of
750:56 - this let's move to the next question
750:58 - this is a homework question solve it
750:59 - yourself let's move to the next question
751:01 - int count equals to Z while
751:05 - test let's see another similar question
751:08 - it says int Counting equal to Z void
751:11 - test and then in test there are five
751:14 - times count Plus+ par begin and then two
751:17 - times test so this is like this I can
751:20 - segregate into two count Plus+ count
751:22 - Plus+ five times here also count Plus+
751:24 - count Plus+ five times now it's asking
751:25 - what is the minimum and maximum value of
751:27 - the count see this is an amazing
751:29 - question this is a nice question you
751:31 - should give it a try for maximum you can
751:34 - directly say when the the value of count
751:36 - will be maximum when the execution is
751:38 - done sequentially first find time this
751:40 - and then five time this in that case the
751:43 - value will be 10 so the maximum value is
751:44 - 10 but can you guess the minimum value
751:47 - the minimum let me tell you something
751:48 - the minimum value is not five and the
751:50 - minimum value is not one now you have to
751:52 - tell me what will be the minimum value
751:54 - and this is a homework problem we will
751:55 - discuss it
751:56 - later okay
751:59 - so here we have officially completed our
752:02 - process synchronization section in the
752:05 - next section we will start Deadlock
752:15 - we have successfully completed our last
752:18 - section that is process synchronization
752:21 - in this section we are going to learn
752:22 - about deadlock what is deadlock how
752:24 - deadlock happen how we can prevent
752:26 - deadlock how we can recover if deadlock
752:28 - is already happened all these things we
752:30 - are going to cover in this
752:31 - section let's start with what is
752:33 - deadlock deadlock is when two or more
752:36 - processes are waiting for an event that
752:38 - is never going to happen or waiting for
752:40 - the happening of an event that is never
752:42 - going to happen Okay so let's say
752:45 - process P1 is waiting process P2 let's
752:48 - say there is a resource some resource R1
752:50 - that is hold by process P1 and there is
752:53 - some resource R2 that is hold by process
752:55 - P2 now process P1 wanted resource R2 and
752:59 - process P2 want resource
753:02 - R1 they are both waiting that they can
753:05 - get resources but P1 is saying you first
753:08 - release then I'll complete my work and
753:10 - then you will get both resources and P2
753:12 - is saying the same thing both are adant
753:15 - do you know the meaning of adant it is a
753:17 - stubborn so both are being
753:19 - stubborn I don't know spelling
753:22 - of stubborn is that the spelling
753:26 - anyway so in deadlock the process need
753:29 - to be stubborn otherwise deadlock will
753:32 - not happen
753:33 - and the process should be non-
753:36 - preemptive otherwise what will happen
753:38 - suppose P1 is a high priority process so
753:41 - what it will do it will just snatch away
753:42 - the resource R2 from process to so this
753:46 - should not also happen in a deadlock so
753:47 - what is deadlock deadlock is P1 is
753:50 - waiting for P2 to release resource R2
753:54 - and P2 is waiting for P1 to release
753:55 - resource R1 in this way they are waiting
753:58 - for such an event that is never going to
754:00 - happen why because processes are
754:01 - stubborn they are they will never ever
754:04 - release their
754:06 - resources okay so this is what deadlock
754:09 - is they waiting for an event that is
754:11 - never going to
754:13 - happen but you see they are not only
754:16 - just waiting they are also holding up
754:18 - the resources so this is the worst thing
754:23 - they do not only wait but they hold up
754:24 - the
754:26 - resources the consequences will be uh
754:29 - the throughput and efficiency drops
754:31 - ineffective utilization of resources
754:33 - therefore this deadlock thing is
754:36 - undesirable okay now we have to also
754:39 - understand the difference between what
754:40 - is deadlock and what is a starvation
754:41 - they seems similar in some way but they
754:44 - are not starvation is blocking for
754:47 - indefinite time you do not know the time
754:49 - when you'll get the chance and Deadlock
754:52 - is you have been blocked for infinite
754:55 - time you have been blocked forever and
754:57 - what is starvation blocking for
754:59 - indefinite time so you should know the
755:01 - difference between indefinite and
755:03 - infinite infinite means forever and
755:05 - indefinite means you just don't know
755:08 - okay so here are some examples of
755:10 - Deadlock this is Rachel and this is Ross
755:14 - Rachel wants to make omelette and Ross
755:15 - wants to make pancake so for omelette
755:19 - and pancake they both need a pan and an
755:21 - oil so what happens Rachel gets the oil
755:24 - to start cooking and Ross grabs the
755:28 - pan what happens now they are both
755:31 - stubborn Rachel won't release the oil
755:33 - till she get the pan and Rose won't
755:35 - leave the pan till he get the oil so in
755:38 - this way they are both both being
755:40 - stubborn so adamancy is required for
755:42 - deadlock Rachel is waiting for Ross to
755:45 - release the pen and Ross is waiting for
755:47 - Rachel to release the oil in this way
755:49 - they are both waiting and they will wait
755:51 - for forever so this is what deadlock is
755:55 - okay so we can say
755:57 - Ross uh Rachel is the process one and
755:59 - Ross is the process two let oil be the
756:02 - resource R1 and pan with the resource R2
756:05 - okay so resource R1 that is uh this o
756:10 - has been assigned to process one that is
756:12 - Rachel so resource R1 is assigned to
756:14 - process one and process one is waiting
756:16 - for resource R2 that is the pan and
756:19 - resource R2 has been assigned to process
756:20 - two that is Ross and Ross is waiting for
756:23 - resource one that is the oil so in this
756:25 - way deadlock occurs so for deadlock
756:28 - cycle is
756:29 - required okay here is another meme from
756:32 - 3 D movie if you not watched that movie
756:34 - you should watch it's a great movie so
756:38 - this is a meme from that M so
756:40 - interviewer ask the candidate explain
756:42 - deadlock and we will hire you the
756:44 - candidate replies hire me and then I'll
756:46 - explain to you so this is exactly what
756:48 - deadlock is let's discuss the salary so
756:52 - now System model what kind of system we
756:55 - are assuming for the study of
756:58 - Deadlock so n depicts the number of
757:01 - process P1 P2 till PN m m depicts the
757:04 - resources R1 R2 RM they can be the
757:08 - hardware resource or software resource
757:10 - okay and the resource can be either
757:12 - single instance or multi- instance
757:14 - resource what is multi- instance copies
757:17 - of the single instance Source okay now
757:21 - this is the process process request the
757:23 - operating system to Grant the resource
757:26 - operating system can do two things it
757:28 - can grant or it can
757:30 - deny suppose the resources granted
757:34 - process will use the resource and it
757:36 - will release and give it back to the OS
757:39 - and suppose the OS denies the process
757:41 - request then what happens process get
757:43 - blocked and it will starve and suppose
757:46 - after some time operating system feel
757:48 - pity on the process he grants the
757:51 - resources what happens then process will
757:53 - reuse the resources and then after the
757:54 - completion of work it will release the
757:56 - resources back to the operating system
757:59 - but this is a case
758:01 - that that process get blocked and
758:04 - operating system never grants that
758:07 - process it's required re resources then
758:09 - what happens it will be blocked forever
758:11 - there's no one who will wake up the
758:13 - process and say hey your resources has
758:15 - been granted you can go and do your work
758:17 - now
758:18 - no this process has been blogged forever
758:21 - and this is what exactly deadlock
758:24 - is
758:26 - okay for example SEMA 4 in One S then
758:30 - single instance in multiple s then
758:32 - multiple instance it's just the thing
758:33 - that resource can be of two types single
758:36 - instance and multi- instance multi
758:37 - instance is nothing but the copies of
758:38 - single instance this is what it's
758:40 - written here now comes the necessary
758:42 - condition for
758:44 - deadlock the first is there should be
758:46 - critical section some shared resource
758:48 - deadlock will never happen among
758:50 - independent processes see here if if
758:54 - Rachel if Rachel never wanted the pen
758:57 - and if Ross never wanted the oil do you
759:00 - think deadlock will happen no deadlock
759:03 - won't happen so deadlock never happens
759:05 - among independent process so there
759:07 - should be some critical section there
759:08 - should be some shared resources the
759:11 - second Point says process should hold
759:13 - some resource and should wait for
759:15 - another this is also the necessary
759:17 - condition for deadlock
759:18 - suppose Rael would have never hold the
759:22 - oil and is never asking for the
759:25 - pen do you think deadlock will happen no
759:28 - for deadlock hold and weight should be
759:30 - there processes holding some resources
759:32 - see here in this case also hold and
759:35 - weight is present so hold and weight is
759:37 - necessary condition for Deadlock process
759:39 - should be holding some resources and
759:41 - asking for another resource if holding
759:45 - weight
759:46 - is if hold and weight is there can I say
759:49 - it implies deadlock no it doesn't imply
759:53 - deadlock but if I say deadlock is there
759:55 - can I say hold and weight must be there
759:57 - yes hold and weight must be there see
759:59 - this suppose this is what this is uh
760:04 - process Pi process Pi has been holding
760:06 - resource R1 and requesting for R2
760:10 - and R2 has been acquired by PJ do you
760:13 - think deadlock will happen in this case
760:16 - no deadlock will not happen see here
760:19 - here Pi is holding and waiting some of
760:21 - the resources but PJ is not there PJ is
760:23 - not waiting for the for R1 which has
760:26 - been called by pi so in this case
760:29 - deadlock won't happen why see
760:32 - this Pi is just requesting for resource
760:35 - R2 and is it has not get resource R2
760:37 - delet it PJ has resource art so what it
760:42 - will do it will just use the resource
760:44 - and see here and when a process is
760:46 - granted with some resource it will use
760:47 - the resource and will release back to
760:49 - the operating system so when this PJ
760:52 - will release this this R2 it will be
760:54 - granted to Pi and Pi will do its work is
760:58 - there any case of infinite blocking
761:00 - present no so I cannot say if hold and
761:04 - weight is there see hold and weight is
761:05 - there but deadlock is present no
761:07 - deadlock is not present but but if I say
761:09 - dead log is present then hold and weight
761:11 - should be there
761:13 - yes this should be there
761:16 - see example of
761:18 - Deadlock py P1 is holding some resource
761:21 - and requesting for another P2 is holding
761:23 - some resource and requesting for the
761:24 - another if deadlock is present then hold
761:27 - and weight will be there so if I say
761:29 - hold and weight implies deadlock see
761:31 - this no it doesn't imply deadlock does
761:33 - deadlock implies hold and weight yes see
761:36 - this deadlock implies hold and weight
761:38 - okay third thing no forceful snatching
761:40 - of resource no preemption should be
761:43 - there take this scenario suppose Ross
761:47 - and Rachel are brother and sister and
761:49 - what
761:50 - happens this uh Ross is the big brother
761:53 - what happens he pushes the Rachel away
761:55 - and by force he snatches the this oil
761:59 - bottle do you think now Ross is going to
762:02 - wait for infinite time no this will not
762:04 - happen until she complain his father
762:06 - about his behavior this is one going to
762:09 - happen
762:11 - so if forceful snatching is allowed then
762:15 - deadlock will not happen I hope you are
762:17 - getting the point no forceful snatching
762:19 - of resource this is also a necessary
762:21 - condition and the fourth necessary
762:22 - condition is circular weight should be
762:24 - present circular weight should be there
762:26 - see P1 is waiting on P2 P2 is waiting on
762:29 - P3 and P3 is waiting on P1 in that case
762:33 - deadlock will happen see here no
762:35 - circular thing no deadlock circular
762:37 - thing is present Deadlock
762:40 - lock circle cycle is present deadlock
762:44 - cycle is present deadlock okay so cycle
762:47 - should be there for deadlock okay if
762:50 - these four condition are present then
762:52 - there is a possibility of Deadlock see
762:55 - see here if I say if there is critical
763:00 - section present then there will be
763:01 - deadlock can I go from necessary
763:04 - condition to deadlock no but can I go
763:07 - the opposite way yes if deadlock is
763:09 - present then these necessary condition
763:11 - must be fulfilled see if I say if I say
763:15 - critical section is present then will it
763:17 - lead to deadlock no is this a joke no
763:20 - critical section if critical section is
763:22 - present then there should be
763:24 - deadlock absolutely not and if deadlock
763:28 - is there there should be critical
763:29 - section yes it is necessary it must be
763:31 - there otherwise deadlock won't happen if
763:33 - I say hold and weight is present then
763:35 - deadlock should happen no it is not
763:37 - necessary but if I say Deadlock is there
763:39 - then Wen weight should be there yes this
763:41 - is must same thing for it if I say oh I
763:46 - can say for this thing circular weight
763:49 - if I say deadlock is there then circular
763:51 - weight must be present yes but if I say
763:53 - circular weight is there then deadlock
763:54 - will happen think about it if circular
763:57 - weight is there then deadlock will
763:58 - happen can I say for fourth condition
764:01 - that I can go both around ways can I
764:05 - say so if circular weight is present
764:09 - then deadlock will going to happen I
764:11 - cannot say this because circular weight
764:13 - is a necessary condition not the
764:15 - sufficient one consider this case uh
764:18 - John needs a screwdriver from Mar Mary
764:21 - needs pliers from Ken Ken needs a wrench
764:24 - from Lisa Lisa needs the screwdriver
764:26 - from John and now what
764:28 - happens John says hey Lisa take this
764:32 - screw driver which means they are not
764:35 - admin now so can I say circular weight
764:38 - implies that no what happens if one of
764:40 - them is not
764:42 - adment then deadlock won't be there so
764:45 - circular weight is not the sufficient
764:47 - condition for deadlock but the necessary
764:49 - one if I said deadlock is there then
764:52 - circular weight will be present yes that
764:54 - is must so if these four condition are
764:57 - present then there is a possibility of
764:59 - Deadlock and if deadlock is there then
765:02 - these four condition must be present I
765:04 - hope you got the point now okay in the
765:06 - next lecture we are going to see
765:07 - resource allocation
765:10 - graph let's start with the resource
765:12 - allocation
765:14 - graph the graph consist of vertices and
765:17 - edges in the same way resource
765:19 - allocation graph vertices of two
765:20 - different types processes and resources
765:23 - process is represented using this
765:25 - circular node with pi in between like P1
765:28 - P2 in this way processes are represented
765:31 - and resources are represented using this
765:34 - square or rectangular node it can be of
765:37 - two different types single instance and
765:38 - and multi- instance single instance has
765:41 - one dot in between and multi instance it
765:43 - has multiple dots in in this rectangular
765:46 - body but this dots represent number of
765:48 - instances suppose here are three dots
765:50 - which says there are three instances of
765:54 - resource
765:55 - RG okay now comes to the
765:58 - edge The Edge can be of three types
766:00 - claim Edge request Edge and assigned
766:03 - Edge so the claim says Pi is the process
766:08 - claiming the resource RI and RI is a
766:11 - single resource single instance
766:14 - resource request Edge PJ is a process
766:18 - requesting for multiple resources or two
766:21 - resources of or two instances of
766:24 - resource
766:25 - RG and assigned Edge
766:28 - is the opposite
766:30 - way resource RK has been assigned to the
766:33 - process PK okay let me repeat again so
766:37 - in resource allocation graph there are
766:39 - vertices and edges vertices can be
766:40 - divided into two process and resources
766:42 - resources can be of two types single
766:43 - instance and multi- instance the number
766:45 - of dots in the representation that is
766:48 - the rectangle says the number of
766:50 - instance of that resource there are
766:52 - three dots which says there are three
766:53 - instance of resource RJ now comes the
766:55 - edge claim Edge request Edge and
766:57 - assigned Edge the dotted dotted Edge is
767:00 - the claim Edge which means process Pi is
767:03 - claiming the resource RI the single
767:05 - instance of resource RI request Ed says
767:09 - process PJ is requesting for two
767:12 - resource or two instance of resource RJ
767:14 - it's not two resource it's two instance
767:16 - of resource RJ and assigned Ed single
767:20 - instance resource RK has been assigned
767:22 - to process
767:24 - PK so request and assigned is clear what
767:27 - is the claim Ed claim is the process May
767:31 - request that resource in the future and
767:33 - request as says it is actually requested
767:35 - and assigned Ed is resource all
767:38 - allocated to that process claim says may
767:40 - request in future request says it has
767:43 - already requested and assigned
767:45 - says the resource has been already
767:48 - allocated to that process okay so this
767:50 - is resource allocation
767:53 - graph so here one more thing to notice
767:56 - see I have made two arrows here this two
767:58 - arrows signifies number of instances
768:01 - that PJ is requesting suppose if if in a
768:06 - case in which there should be there will
768:08 - be two two resource of RK and that two
768:11 - resources are already allocated to PK so
768:13 - I will add an additional edge here so
768:16 - the number of edges represent how many
768:18 - instances of that resource have been
768:20 - either requested or assigned okay so
768:22 - number of request or assignment is that
768:24 - many edges okay so this is how resource
768:27 - allocation graph looks like process P1
768:31 - is requesting the resource R1 the single
768:34 - instance of resource R1 has been
768:36 - assigned to process P2 process P2 is
768:39 - requesting for R3 and single instance of
768:41 - R3 has been assigned to process P3 okay
768:45 - one instance of resource R2 has been
768:47 - assigned to P2 and another instance of
768:50 - of resource R2 has been assigned to
768:51 - process
768:53 - P1 okay and this uh one instance of
768:56 - resource R4 has been assigned to process
768:59 - P4 so this is how you have to read the
769:02 - resource allocation graph see this
769:05 - process P1 has got one instance of
769:09 - resource R2 and is requesting for R1 but
769:12 - R1 is not free or R1 is already assigned
769:16 - to process P2 so operating system is not
769:19 - able to give resource R1 directly to P1
769:21 - so in that case P1 will move to the
769:23 - block
769:24 - State same case for P2 P2 is acquiring
769:28 - resource R2 and resource R1 but is
769:30 - requesting for resource R3 but resource
769:33 - R3 has been already assigned to process
769:35 - P3 so in that case P2 will get to block
769:37 - state
769:38 - P3 but p3s will be able to run on CPU
769:42 - because it has already required that
769:44 - resource which is necessary for it to
769:47 - run on CPU so P3 will is free to run on
769:49 - CPU P3 will run on CPU P3 will after
769:52 - completion of its work it will release
769:54 - the resource R3 and that R3 will be then
769:57 - granted to P2 and after P2 complete its
769:59 - work it will release resource R1 and
770:02 - resource R2 so that R1 will be assigned
770:04 - to P1 now and P1 From the Block state
770:06 - will be wake up by the operating system
770:09 - and that R1 resource will be granted to
770:11 - P1 so this is how it's going to work
770:13 - graph G2 P1 is requesting for resource
770:16 - R1 but is has acquired resource R2 P3 is
770:21 - requesting for resource R2 but has
770:23 - acquired resource R1 P2 is requesting or
770:27 - this is an allocated so R1 is allocated
770:30 - to P2 now
770:32 - see now see P1 is holding R2 and
770:36 - requesting for R1 P3 is holding R1 and
770:39 - requesting for R2 but R2 has been
770:41 - assigned to this P4 do you think
770:43 - deadlock will occur in this case no
770:46 - deadlock won't occur what I've have said
770:48 - if all the processes are blocked by the
770:50 - operating system because the resources
770:54 - were not available at that time to give
770:56 - to the process in that case only
770:59 - deadlock will occur I have said all the
771:01 - process even if one process is free to
771:04 - run on CPU then that process see here
771:07 - that process will release its resour
771:10 - and will prevent deadlock same case is
771:12 - going to happen here R4 see this P4 is
771:15 - going to release resource R2 that R2
771:18 - will be given to P3 P3 will complete its
771:21 - work and that P3 is going to release
771:24 - resource R1 and that resource R1 will be
771:26 - eventually given to process P1 see here
771:29 - cycle is present but deadlock is not
771:31 - present so from necessary condition I
771:34 - cannot go to
771:35 - deadlock but from deadlock I can go to
771:38 - necessary Neary condition if you are
771:40 - getting confused just remember this line
771:42 - necessary condition are not the
771:44 - sufficient
771:46 - condition if deadlock is present it
771:49 - means that necessary condition must be
771:51 - fulf fulfilled then after deadlock can
771:54 - happen but necessary condition are not
771:57 - sufficient condition same case happened
771:59 - here cycle should be there for deadlock
772:02 - to happen if deadlock is present then
772:05 - cycle must have been there but if I say
772:08 - cycle is present will deadlock happen I
772:10 - cannot guarantee that see this case
772:12 - let's see an interesting case suppose if
772:14 - I add an edge here what can you tell
772:17 - about uh will deadlock occur in this
772:20 - resource allocation graph analyze and
772:23 - see P1 is holding R2 and requesting for
772:27 - R1 P2 is holding R1 and R2 and
772:29 - requesting for R3 P3 is holding R3 and
772:32 - requesting for
772:33 - R2 P1 will be blocked because R1 is not
772:37 - available as it is hold by P2 P2 will be
772:41 - blocked because R3 is not available and
772:43 - P3 will be blocked because R2 is not
772:45 - available in this way these three
772:48 - process will be blocked but see here P4
772:51 - will run completely P4 even after
772:54 - running will release the resources R4
772:56 - but can you think R4 is going to help in
772:59 - this matter no it is already isolated so
773:02 - for that case deadlock will be there in
773:05 - this resource allocation graph before
773:07 - was not blocked it was free but even
773:09 - after completing its work and releasing
773:12 - its resources R4 is not going to help in
773:14 - this matter for there I can see it is
773:17 - not required for all of the process to
773:20 - get blocked okay see firstly you have to
773:22 - check if all the process are blocked or
773:23 - not if yes then you can say directly
773:25 - deadlock is present if no then check
773:28 - those process which are not blocked
773:30 - after releasing their resources are are
773:32 - they going to help in the matter of
773:33 - solving deadlock if yes if they will
773:36 - help then deadlock won't OCC and if no
773:39 - then deadlock will occur as simple as
773:41 - that till now we have understand what is
773:44 - deadlock and what is a resource
773:46 - allocation graph how are you going to
773:48 - identify deadlock by seeing a resource
773:50 - allocation graph now we are going to see
773:52 - deadlock handling strategies the first
773:54 - one is deadlock prevention the second
773:57 - one is deadlock avoidance these two deal
773:59 - with the case when deadlock do not occur
774:01 - prevention and avoidance as the name
774:03 - suggest the third one is deadlock
774:05 - detection and Recovery the fourth one is
774:07 - deadlock ignorance so these two deal
774:09 - with the case when deadlock either have
774:11 - occurred already or will occur in future
774:13 - as the name such as deadlock
774:15 - detection can deadlock occur in future
774:18 - and Deadlock recovery if deadlock has
774:21 - already occurred then how are we going
774:23 - to recover from that the fourth one say
774:26 - is deadlock
774:27 - ignorance ostrich algorithm do you know
774:30 - what OST ostrich ostrich does it bury
774:35 - its head into the mud so this is what
774:37 - ostrich algorithm is that is no strategy
774:40 - if deadlock have occurred let it happen
774:42 - we will see the worst cases so this is
774:45 - what deadlock ignorance is okay in
774:48 - deadlock idence we are going to learn
774:49 - about Banker's algorithm this is a very
774:51 - famous algorithm by dter dter is the
774:54 - person who implemented SE 4 you have
774:56 - heard his name so many times in this
774:58 - computer science engineering so txra is
775:00 - a great man or was a great man I don't
775:03 - know dtra have done so many contribution
775:06 - in the field of CSC
775:08 - okay anyway deadlock detection in this
775:11 - we are going to see the doctor's
775:13 - algorithm and Deadlock ignorance or
775:15 - algorithm so we let start with the
775:16 - ignorance ofch algorithm which is no
775:19 - strategy algorithm so when system will
775:22 - go to the deadlock it will get hanged it
775:25 - will get hanged so in that case what we
775:27 - do we press the restart button and
775:29 - fortunately unfortunately what we say
775:31 - windows Unix Linux all uses a algorithm
775:35 - because deadlock occurs very rarely and
775:38 - the cost of prevention is high that's
775:41 - why they say if deadlock occurs just put
775:45 - your head into the mud just bu your head
775:47 - like ostrich
775:48 - do day-to-day operating system the
775:51 - deadlock occur very rarely and the cost
775:53 - of prevention high so it doesn't require
775:57 - the deadlock prevention we have to what
775:59 - we have we have to use this deadlock
776:02 - prevention in those operating system in
776:04 - which data and time are
776:05 - critical for those operating system in
776:08 - which we can afford deadlock to happen
776:11 - we don't give much much attention
776:12 - because the cost of prevention is high
776:15 - but in those operating system in which
776:18 - we cannot afford deadlock to happen in
776:20 - which data and time are
776:23 - critical in that case we have to use
776:26 - deadlock prevention strategies you
776:29 - cannot lose
776:31 - one bite of data even for 1 millisecond
776:35 - system should not be down even for a 1
776:36 - millisecond for example Air Traffic
776:38 - Control missile control satellite
776:40 - control system in these critical
776:43 - operating systems deadlock prevention
776:46 - should be acknowledged okay so now we
776:48 - are going to see deadlock prevention and
776:51 - how are we going to prevent deadlock by
776:53 - negating one or more necessary condition
776:56 - can you remember the necessary condition
776:58 - which we have studied for
776:59 - deadlock the first one was there should
777:02 - be a shared resource there should be
777:04 - critical section the second one was hold
777:06 - and waight the third one we did was no
777:09 - pre no pre preemption and the fourth one
777:11 - was circular weight so if I negate
777:14 - either of these four strategies either
777:16 - of these four conditions then deadlock
777:19 - will not happen see what I have
777:22 - said necessary condition as the name
777:25 - suggest these four condition all of
777:26 - these condition are necessary to happen
777:29 - at the same time for deadlock to occur
777:31 - and if I am able
777:34 - to negate even one of these four
777:37 - condition then deadlock will not happen
777:39 - Okay so this is what deadlock prevention
777:42 - does negating one or more of the
777:45 - necessary condition so let's see one by
777:47 - one which condition I can negate
777:49 - critical section can we remove a
777:51 - critical section well I cannot even
777:54 - imagine of a multiprogrammed operating
777:56 - system without a shared resource so
777:58 - critical section will be there it is
778:00 - almost practically impossible to remove
778:01 - critical
778:02 - section okay so this thing critical
778:05 - section condition is no dissatisfied
778:09 - viable now let's move to the second
778:11 - condition hold and
778:13 - weight instead of hold and weight can we
778:16 - adjust it to hold or weight can we do
778:18 - like that let's
778:20 - see so process must request and be
778:23 - allocated all resources prior to its
778:25 - start if we can do something like that
778:27 - in that case hold and wait thing can be
778:30 - avoided see this P1 for 30 minutes of
778:34 - phase 1 P1 wants R1 and R2 and for 20
778:37 - minutes of phase 2 P2 P P1 bonds R2 and
778:41 - R3 so generally what process do after
778:44 - the phase 1 that is after 30 minutes
778:46 - process P1 will release R1 hold R2 and
778:50 - will request for R3 because process 1
778:53 - knows that after after Phase 1 in Phase
778:55 - 2 P1 will going to need R2 so it
779:01 - releases R1 and hold R2 and request for
779:03 - R3 so this is the case of hold and
779:06 - weight but if r R3 is not available it's
779:10 - going to wait so this hold and weight we
779:11 - want to avoid how can we avoid this hold
779:14 - and weight so we have two protocols to
779:16 - avoid this hold and weight the first one
779:18 - is to avoid this case of hold and weight
779:21 - we can do like this process will ask for
779:24 - all R1 R2 and R3 before the beginning of
779:26 - phase 1 so for the whole time when
779:29 - process is going to run in the
779:32 - CPU process will prior request all the
779:35 - resources which is going to need for its
779:37 - whole phases for Phase 1 Phase 2 and
779:40 - even if in future it will go for some
779:42 - phase three then combining all these
779:46 - phases which resources process one will
779:48 - need that it should ask even before
779:51 - phase one so this is what protocol one
779:54 - says so if available hold these
779:57 - resources go on do the
779:59 - work and this will prevent the case of
780:02 - hold and vit because it has got all the
780:05 - resources which which is going to need
780:06 - so there is no waiting there so if
780:09 - available hold and if not wait see there
780:14 - is no hold and wait it's hold or wait if
780:17 - available then hold if not then wait so
780:20 - there is or between either of them will
780:22 - happen either available or not available
780:25 - but there no case of hold and wait but
780:29 - this protocol one gives some serious
780:31 - drawbacks the first one is starv Vision
780:34 - see this process one is waiting for that
780:37 - perfect chance in which R1 is also free
780:39 - R2 is also free and R3 is also free in
780:42 - that case P1 will request and will get
780:45 - these three suppose R1 and R2 P1 is
780:49 - acquired P1 is required R1 R2 but not R3
780:52 - so what it will do it will release them
780:55 - wait for that time in which R3 is also
780:57 - free request for all these things but
780:59 - what happens R3 is free now R1 is free
781:02 - now but R2 has been acquired by some
781:04 - other process P2 because it is not
781:05 - holding them
781:09 - so for finding that perfect moment R1 R2
781:13 - and R3 all of them are free this has to
781:15 - wait for a lot of time P1 has to starve
781:20 - so starvation is the obvious drawback
781:23 - the second one is inefficiency in Phase
781:25 - One why are we holding R3 for 30 minutes
781:28 - see why what protocol one says hold all
781:31 - the resources which you are going to
781:32 - need in future even before phase one so
781:35 - when phase one will start for these 30
781:38 - minutes R3 will be holded by P1 so this
781:41 - is very inefficient utilization of
781:43 - resources so to recover that or to find
781:47 - a better algorithm we had moved to
781:49 - protocol 2 what protocol 2 says process
781:52 - must release all resources before making
781:54 - a fresh or new
781:55 - request suppose this thing happens P1
782:00 - got resource R1 and R2 completed its
782:03 - phase for 30 minutes
782:05 - now phase one is completed after Phase 1
782:08 - process will releasee R1 and R2
782:10 - according to protocol 2 and will ask for
782:13 - R2 and R3 again
782:15 - see P1 has just released R2 and it
782:19 - asking for R2 again so there may be a
782:21 - chance in which when it has released R2
782:24 - suddenly it got assigned to some other
782:29 - process so it has to wait again so
782:32 - starvation is still present but
782:34 - inefficiency has been
782:36 - renoved inefficiency has been removed
782:38 - see we are not holding R3 in the phase
782:41 - one so in this case hold and weight is
782:45 - not present so for both protocol one and
782:47 - protocol 2 hold and weight has been
782:48 - avoided so out of these four condition
782:51 - first one is non diss satisfiable hold
782:53 - and weight is this satisfiable but it
782:55 - comes with serious drawbacks now comes
782:57 - to the condition three no preemption can
782:59 - we preempt can we
783:02 - preempt let's see so preent preemption
783:05 - of resources from the process can be of
783:07 - two types either forceful preemption or
783:09 - self- preemption forceful preemption
783:11 - says running process should not get
783:15 - blocked forceful preemption says running
783:17 - process should not get blocked and self-
783:19 - preemption says adopt selfless attitude
783:23 - say this allow pi to forcefully take
783:26 - away RB without bothering what will
783:28 - happen to
783:31 - pjc this is CPU process Pi is running on
783:35 - the CPU ra is already located to process
783:38 - Pi now what
783:41 - happens Pi wants a new process a new
783:45 - request uh what I'm saying Pi wants a
783:50 - new resource RB so it's requesting for a
783:52 - new resource RB but see RB is already
783:54 - allocated to
783:55 - PJ but what my protocol says forceful
783:58 - preemption says running process is of
784:00 - utmost prity running process should not
784:02 - get locked so I will snatch away the
784:03 - resource RB from PJ and will give it to
784:07 - D
784:08 - without bothering what will happen to PG
784:10 - later so running process got the right
784:13 - to snatch away the resources from ready
784:15 - process so this is forceful preemption
784:17 - and what does self preemption says
784:20 - running process Pi founds out that RB is
784:22 - not available instead of snatching RB it
784:25 - will release its resources ra thinking
784:28 - that others might be in need of my
784:29 - resource why should I hold and wait up
784:32 - why should I hold the resource and wait
784:34 - for some other resource instead I should
784:36 - release my resources
784:38 - in order that someone might be present
784:41 - there who is hoping to get the resource
784:43 - which is present with me so both these
784:47 - strategies prevent deadlock let me
784:49 - revise no preemption can it be avoided
784:53 - yes we can do preemption based on two
784:56 - protocols the first is forceful and the
784:58 - other is self what does forceful
785:00 - forceful say running process should not
785:02 - get blocked Pi is Pi already has
785:04 - resource R and is requesting for a new
785:06 - resource RB which is already allocated
785:07 - to some other ready process so what
785:09 - happens Pi snatches away RV from PJ not
785:13 - thinking of PJ what will happen to PJ it
785:15 - snatches away its resources complete its
785:16 - work it's like a selfish attitude and it
785:20 - self self preemption it adopts a
785:23 - selfless attitude Pi is running on CPU
785:27 - ra is allocated to Pi but instead of
785:29 - snatching our resources of RB what
785:31 - happens Pi release away its resources by
785:34 - seeing the hey RB is already located to
785:37 - PJ I cannot get RB from PJ so should I
785:42 - or I should release away my resources
785:44 - because someone there might be someone
785:47 - there might be present who is requesting
785:50 - resource ra so Pi is adopting a selfless
785:54 - attitude by releasing away its resources
785:57 - okay now again comes the problem of
786:00 - starvation you can guess why fourth
786:02 - condition is circular fate circular fate
786:05 - prevented by total order relation among
786:08 - processes and resources so what is this
786:09 - total order relation we will
786:12 - see so the protocol says assign unique
786:15 - number to each resource and never allow
786:17 - a process to request a lower numbered
786:19 - resource than the last one allocated see
786:23 - this so what happen we assign a unique
786:26 - number to each resource there are this
786:27 - is the list of resources I have
786:29 - allocated I have allotted a unique
786:32 - number to each resource to Resource a
786:34 - IED 10 to Resource d i alled four so
786:37 - this is this is a resource ID a unique
786:39 - number okay and now never allow a
786:42 - process to request a lower numbered
786:45 - resource then the last one allocated see
786:49 - this PR PR has been allocated see the
786:52 - resource ID was three
786:55 - now PRI can only request for those
786:58 - resources which has a resource ID
787:01 - greater than three can it a request for
787:03 - B yes 8 8 is greater than three yes now
787:07 - it can only request for those resources
787:09 - which has a resource ID greater than 8
787:11 - can it request for D no can it request
787:14 - for G no can it request for a yes
787:18 - because the resource ID of a is greater
787:19 - than the resource ID of B so what are we
787:21 - doing here basically we are removing the
787:23 - cycle and we are introducing linearity
787:26 - to avoid
787:27 - circularity okay so what does this
787:29 - algorithm say process I can only request
787:32 - for those resources which have ID
787:35 - greater than 10 now now it can only ask
787:38 - for those resources which have ID
787:39 - greater than 10 which means it can ask
787:41 - for either F or e that's it
787:46 - okay now say this if process I request
787:52 - for those resources which has a ID less
787:54 - than 10 then what happens suppose
787:57 - process I request for
788:01 - G then what will happen it has to go
788:03 - back and you can see the cycle is
788:04 - forming if request if it request for
788:07 - five then cycle condition what to do
788:09 - then resource preemption okay so you
788:11 - know what to do you have to preempt the
788:13 - resource and then Grant
788:15 - again how suppose after getting a after
788:19 - getting a resource with resource ID 10
788:22 - the process wants to get resource with
788:24 - the resource ID of five which means
788:25 - process one to get resource G now what
788:27 - will we have to do we have to snatch
788:30 - away the resource with resource ID 10 we
788:32 - have to snatch away with the resource
788:34 - with resource ID 8 and now I can give
788:37 - the proc
788:37 - with resource id5 so now 3 5 8 and 10
788:42 - now we are going to Grant it again so
788:44 - basically whatever we're doing we are
788:46 - just avoiding circularity we do not want
788:49 - circularity the first firstly the
788:51 - process got resource three then eight
788:53 - then 10 now it wants five so what I will
788:55 - do I will preempt 10 preempt eight
788:58 - assign five and then we'll Grant again 8
789:00 - and 10 so in this way the linearity is
789:02 - maintained as circularity do not come
789:04 - the resource given plus linearity is
789:07 - there now starvation is obvious
789:09 - starvation may come because when I
789:11 - preempted these resources some other
789:13 - process May request for this so I can
789:15 - give process request I can give
789:19 - process the source id5 but when it will
789:22 - request for 8 and 10 Again these were
789:25 - already allocated to some different
789:26 - process so it has to starve so this
789:29 - granting again thing is dangerous it
789:32 - invites
789:33 - starvation so after these four condition
789:35 - which conditions which we can negate so
789:38 - the first one was can we remove critical
789:41 - section no we cannot remove critical
789:43 - section second one was hold and waight
789:46 - can we avoid hold hold and weight yes we
789:48 - can avoid hold and weight by two
789:50 - protocol the first one was ask for all
789:52 - resources in the beginning the second
789:54 - one says if you made a new request you
789:56 - should release all the previously
789:57 - assigned resources the third one says no
790:00 - preemption yes we can preempt the first
790:02 - one is forceful the second one was self
790:04 - and the fourth one says circular weight
790:07 - can circular or the cycle be avoided yes
790:09 - it can be avoided by this algorithm a
790:12 - process can request only those resources
790:14 - which has a resource ID greater than the
790:16 - previously allocated resource ID okay in
790:20 - this way the cycle is preed
790:31 - prevented in our previous lectures we
790:33 - have learned about resource allocation
790:35 - graph in this lecture we are going to
790:37 - see an interesting property of resource
790:39 - allocation
790:40 - graph so if RG is a resource of multi-
790:43 - instance
790:45 - type then cycle is only a necessary
790:48 - condition focus on the word
790:49 - necessary if cycle is present there may
790:52 - or may not be deadlock but if deadlock
790:54 - is there then there must be cycle cycle
790:58 - must have been there okay but but if
791:04 - there are only single instance type
791:05 - resources in that particular area of a
791:08 - graph where cycle is forming then in
791:11 - that case cycle is necessary and
791:13 - sufficient also in that case I can see
791:15 - cycle leads to deadlock see for General
791:18 - cases I cannot see necessary condition
791:20 - leads to deadlock this is false but if
791:23 - deadlock is present then necessary
791:25 - condition must have been
791:27 - fulfilled but here in this case if only
791:30 - single instance type resources are
791:32 - present then I can say cycle leads to
791:35 - deadlock then I can say cycle leads to
791:36 - dead log is correct okay you have to
791:39 - remember this so let us summarize only
791:41 - multi instance cycle is necessary
791:43 - combination of multi and single instance
791:45 - cycle is necessary only single instance
791:47 - cycle is necessary and
791:50 - sufficient so in our last lecture we
791:52 - have learned about deadlock prevention
791:54 - in deadlock prevention what we try to do
791:57 - we try to negate one of the four
791:59 - necessary conditions in deadlock
792:01 - avoidance what are we going to learn
792:03 - let's see so deadlock avoidance can be
792:06 - divided into two parts are single
792:07 - instance and multi- instance single
792:09 - instance in which resources have a
792:12 - single copy and multi instance
792:14 - combination of single and multi instance
792:16 - a resource can have multiple
792:18 - instances
792:20 - okay so in single instance we are going
792:22 - to learn about resource allocation graph
792:24 - algorithm and for multi instance we are
792:26 - going to learn about Bankers algorithm
792:28 - you must have heard the name
792:30 - before okay so both algorithm are based
792:33 - on a prior knowledge you know meaning of
792:35 - a prior beforeand and the operating
792:38 - system should know that with that the
792:40 - process is going to need which resources
792:43 - in future while executing so that is a
792:45 - prior knowledge every process need to
792:47 - tell which resources she needs before
792:49 - hand to the operating system okay that
792:51 - is a prior knowledge now let's learn
792:53 - about resource allocation graph
792:55 - algorithm which is based on single
792:57 - instance
792:58 - type okay so as I said it is based on a
793:01 - prior knowledge the process need to tell
793:03 - which resources she needs beforehand to
793:05 - the operating system and based on the
793:07 - request operating system will grant or
793:10 - deny its
793:11 - request so on what factors operating
793:15 - system grants or deny the request it
793:17 - will
793:18 - see if operating system grants that
793:21 - resource to that
793:23 - process where the system will lead to
793:27 - okay if it it will lead to save State
793:29 - then resource will be granted and if it
793:31 - will lead to the unsafe State then
793:33 - resource should be denied
793:36 - so operating system will see the is
793:40 - fulfilling that request will lead system
793:42 - where will it be safe will it be unsafe
793:44 - what does safe signify the S safe
793:46 - signify that there won't be any deadlock
793:49 - and what does unsafe implies it says
793:52 - there is boring there may be likelihood
793:54 - of Deadlock deadlock may be present okay
793:58 - there are chances of Deadlock okay so
794:00 - unsafe doesn't mean deadlock UNF says
794:02 - there are chances of Deadlock okay so
794:04 - there are three points which you have to
794:06 - uh focus upon while Learning Resource
794:09 - allocation graph algorithm the first
794:10 - thing is resources are claimed a prior
794:13 - in the operating system okay that I have
794:15 - explained what is a Priory if the
794:18 - process Pi start executing then all
794:21 - claim edges must appear in the resource
794:23 - allocation
794:24 - graph see I have told you what is claim
794:27 - Edge claim Edge is that edge that dotted
794:29 - Edge which go from process to Resource
794:32 - which signifies that that process May
794:35 - request that resource some in the
794:38 - future okay so what does claim ad says
794:41 - in future request may happen Okay
794:44 - suppose if Pi request some resource R
794:48 - let let
794:50 - me if process Pi request some resource R
794:53 - then request is granted only if when
794:57 - request Edge is converted into assigned
795:00 - Edge and that introduction of New Edge
795:03 - is not going to
795:05 - lead or is not going to introduce a
795:07 - cycle in the graph let me repeat when a
795:12 - claim edch is converted into assigned
795:15 - Edge
795:17 - then cycle should not come in the graph
795:21 - see firstly it was claim Edge the
795:22 - process May request somewhere in the
795:24 - future then process actually request and
795:26 - then when operating system
795:29 - grant that resources to the process then
795:33 - assigned Edge comes and introduction of
795:35 - this new Edge should not
795:37 - introduce a cycle in the graph see
795:39 - adding a new Edge May introduce a cycle
795:41 - in the graph that should not be there
795:43 - and if that is present then operating
795:45 - system will deny see this if in resource
795:48 - allocation graph algorithm when we are
795:51 - talking about single instance type then
795:54 - cycle will lead to a
795:56 - deadlock okay so no cycle then then safe
796:00 - State and cycle then unsafe State why I
796:02 - written unsafe State instead of Deadlock
796:04 - if I knew that resource allocation graph
796:08 - algorithm work on single instance
796:09 - resource and we have learned here that
796:11 - if there are only single instance
796:12 - resource then cycle is necessary as well
796:14 - as sufficient so why have written here
796:16 - cycle will lead to unsafe State not
796:19 - deadlock the reason will be clarified in
796:21 - the example which I have taken so the
796:24 - base objective of resource allocation
796:25 - graph is is to always operate the system
796:29 - into safe State and what does safe State
796:31 - means if request Edge is converted into
796:33 - assigned Edge then that edge does not
796:36 - lead to a cycle in the RG if you getting
796:39 - confused don't worry here's a perfect
796:40 - example it says the P1 is holding R1 and
796:45 - this as shows that it may request for R2
796:48 - P2 is requesting R1 and may request for
796:51 - R2 in future so this is what this graph
796:53 - says okay here should be P2 you should
796:56 - correct that in your notes also now if I
796:58 - ask you is the current state is in safe
797:01 - State you will say absolutely it is in
797:03 - safe State because there is no
797:05 - possibility of cycle here see I cannot
797:07 - go this side because the arrow is in
797:09 - opposite direction so cycle is not
797:10 - present so I can say the system is in
797:12 - safe State when will system gets into
797:14 - unsafe State the system will get into
797:16 - unsafe State when a cycle is introduced
797:19 - okay so when a cycle will be introduced
797:21 - suppose R2 is granted to
797:24 - P2 now the arrow changes now cycle is
797:27 - introduced so I can say the system is in
797:30 - the system is in unsafe State why not
797:32 - deadlock because this Edge is not an
797:34 - actual Edge it is a claim Edge so for
797:38 - just saying we are saying that cycle is
797:40 - present but actually this is not an
797:42 - actual Edge this is a claim Edge it may
797:44 - request for R2 in future okay that's why
797:48 - we have written here that if cycle is
797:49 - present then it is unsafe state but if P
797:54 - actually request for R2 then it is
797:56 - surely a deadlock State not an unsafe
797:58 - State now it is surely in deadlock State
798:01 - how can I say it is in deadlock because
798:03 - first of all we are Learning Resource
798:05 - allocation graph
798:07 - algorithm and this algorithm is defined
798:10 - only for single instance resource and I
798:12 - have said that for single instance
798:14 - resource cycle is necessary as well as
798:17 - sufficient condition so when when P1
798:21 - request for R2 deadlock will surely
798:23 - happen see this R1 is with R1 is granted
798:27 - to P1 so P1 is holding R1 and requesting
798:30 - for R2 P2 P2 is holding R2 and
798:33 - requesting for R1 you can see a cycle
798:35 - clearly that's why deadlock is is
798:36 - present so claim Ed is also a part of
798:40 - graph claim is not different that's why
798:41 - we have said that
798:44 - when in this case we have said that the
798:47 - system is in unsafe State because cycle
798:49 - is
798:51 - forming but it is not an actual cycle
798:54 - clay match is not an actual as but it is
798:56 - still part of the graph okay I hope the
798:58 - point is clear
799:01 - now so the first system was in safe
799:04 - state it wents to unsafe State and then
799:05 - finally to Deadlock
799:08 - and what is the basic purpose of
799:09 - resource allocation graph algorithm it
799:11 - operates to keep the system is in safe
799:13 - mode in above case when claim Edge when
799:18 - claim Edge becomes the request
799:21 - Edge then it is allowed see here when
799:24 - this claim Edge must have become become
799:27 - request Edge at some time that's why R2
799:30 - is granted to P2 otherwise how will
799:32 - operating system know that P2 is
799:33 - requiring R2 so this clay Edge must have
799:38 - become request Edge at some moment so
799:41 - when this clim Edge become request Edge
799:43 - then also cycle was not present see here
799:46 - it is in the opposite direction but as
799:48 - soon as operating system fulfill its
799:50 - request and grants R2 to the P2 cycle is
799:53 - introduced well that will lead system to
799:55 - the unsafe State okay now you have to
799:59 - understand the difference between unsafe
800:00 - State and Deadlock unsafe state says
800:02 - there are chances of Deadlock not an
800:04 - actual deadlock so I can say this
800:07 - this is unsafe State and Deadlock is
800:09 - just a small part of it okay so System
800:13 - state there there can be they can be
800:14 - segregated into two safe and unsafe and
800:17 - Deadlock is a part of unsafe State okay
800:21 - and unsafe State just signifies the
800:22 - warning it is it say that deadlock may
800:26 - occur okay so this is what resource
800:29 - allocation graph algorithm in the next
800:31 - lecture we are going to see Bankers
800:33 - algorithm we were learning about
800:35 - deadlock avoidance we have already
800:37 - learned about resource allocation graph
800:40 - algorithm which was it was based for
800:43 - single instance
800:44 - resources now let's move to Banker's
800:47 - algorithm for multi- instance it has two
800:49 - subart safety algorithm and resource
800:52 - request algorithm before directly
800:54 - jumping just to safety algorithm let me
800:57 - establish the foundation okay so the N
801:00 - is the number of processes m is the
801:03 - number of
801:05 - resources okay
801:08 - maximum this is an two-dimensional array
801:11 - this is a 2d array which takes to
801:14 - parameter I and j i refers to the
801:17 - process and J refers to the resource so
801:20 - maximum of I comma J equals to K this
801:23 - says that process I requires maximum K
801:27 - copies of resource J I can say it as a
801:32 - demand what is the demand of process
801:35 - process I demands K copies of resource J
801:39 - and this demand is made a prior before
801:43 - execution okay let me repeat again
801:45 - process I demands K copies of resource
801:49 - let's move to allocation allocation
801:52 - says K copies were demanded but only a
801:57 - were allocated to process I let me
801:59 - repeat K copies of resource J were
802:02 - demanded but only a copies were
802:05 - allocated for now
802:07 - so allocation is always less than equal
802:09 - to
802:10 - demand and what is need need says how
802:14 - much more copies you want of resource J
802:18 - to fulfill your
802:20 - demand how much more copies this more is
802:22 - an important word so I say process I
802:26 - requires B more copies of resource J so
802:31 - need equals to demand minus location B =
802:34 - to K minus a
802:36 - be more copies required for satisfying
802:41 - the demand okay what is
802:44 - request request is time dependent
802:49 - request made by process I for C copies
802:53 - of J at time
802:55 - T at time T what the process is
802:58 - requesting and you can guess that
803:00 - request should always be less than need
803:03 - so the request made by process I at time
803:05 - T should always be less than need okay
803:09 - Total 1 to M this ISS that for resource
803:15 - J there are total Z copies present there
803:18 - are total Z instances of resource J
803:21 - available says that at time t e copies
803:25 - are available of resource J and I can
803:28 - say that available should always be less
803:30 - than total so e is less than equal to
803:34 - Z are you getting the point let me
803:37 - maximum was demanded process I demanded
803:41 - K copies of resource
803:43 - G okay and a copies were allocated so
803:47 - how much more copies it needed to
803:49 - satisfy the demand B more copies and at
803:53 - time T it request for C copies and that
803:57 - request should always be less than equal
803:59 - to the need the total Z copies of
804:03 - resource J are present and at time t e
804:07 - copies are present so I can
804:09 - say the available should always be less
804:12 - than equal to Total don't worry if
804:14 - you're getting confused when we will see
804:16 - the example you will get the clarity so
804:18 - if I say total 100 copies of a resources
804:23 - present I will say allocated R 70 then
804:26 - what is available available equals to
804:29 - Total minus allocation and this
804:31 - allocation is for all the
804:34 - process I have I had 100
804:36 - chocolates I distributed 70 chocolates
804:40 - in the class how much chocolates is
804:42 - available to me 30 chocolates and I can
804:45 - say that number of chocolates available
804:48 - to me should always be less than the
804:50 - total
804:51 - chocolates okay now based on these
804:55 - parameters the operating system will
804:57 - Define that at a time the system is in
805:00 - safe state or unsafe State let's see
805:03 - this example there are total five
805:05 - process I will name them as P1 P2 P3 P4
805:09 - and
805:10 - P5 these are the demands of that five
805:12 - process P1 demand 10 copies of resource
805:15 - R P2 demands eight copies of resource R
805:17 - in this in such in this way these are
805:20 - the demands of these processes
805:24 - respectively now based on this demand
805:27 - operating system allocated some of the
805:30 - resources to the
805:32 - processes and these more instances of
805:37 - that resource process need to satisfy
805:39 - their demand okay so I had
805:44 - total 21 copies of the resource R I have
805:48 - total I had total 21 chocolates okay now
805:53 - in this way I have allocated the
805:55 - chocolates to the processes so how much
805:57 - chocolates out of 21 I have allocated 19
806:00 - how much I am remaining with two
806:02 - chocolates now can I satisfy the any
806:05 - process can I satisfy the need of any
806:07 - process no at least I should have three
806:11 - chocolates so in this case I can say the
806:13 - system is
806:14 - unsafe the safety algorithm says system
806:17 - is set to be set to be safe if the need
806:20 - of all process can be satisfied with the
806:22 - available resources otherwise unsafe can
806:25 - the need of all process be satisfied
806:26 - with the available resources absolutely
806:28 - not absolutely not so I can say the
806:31 - system is in unsafe
806:33 - state so if available uh were two then
806:36 - the system was in unsafe State let me
806:39 - say now the available are initially
806:44 - 22 so if initially 22 were available I
806:47 - have allocated 19 how much I'm remaining
806:49 - with I'm remaining with here now is
806:53 - three now can I satisfy the need of any
806:55 - process yes I can satisfy so let's say I
806:58 - satisfi I satisfy the need of this
807:01 - P4 I allocate this three resources to
807:06 - satisfy the need of P4 now P4 will get
807:09 - these three resources okay so now how
807:12 - much allocated five were allocated five
807:15 - was the demand P4 will complete its
807:17 - execution and will return five to me
807:22 - again now how much are available five
807:24 - are available are you getting the point
807:26 - see initially how much I had I had three
807:29 - I allocated three to P4 to satisfy
807:33 - demand P4 now had five resources two was
807:38 - initially given now three more so total
807:39 - it has five resources what was the
807:41 - demand five only so P4 has what it was
807:45 - demanded what it has demanded so P4 will
807:47 - complete its execution and will return
807:50 - those five resources back to the
807:51 - operating system now how much are
807:53 - available now five is available I will
807:56 - give out of five three to this P5 now P5
808:03 - already had three Okay so P5 will
808:07 - complete its execution and will return
808:08 - these six resources to me again out of
808:12 - five I have all alloted three to it so
808:14 - how much I was remaining then two and
808:16 - this six will come again so now I have
808:19 - eight
808:20 - resources did you get the point I had
808:23 - five out of five I allotted three to it
808:25 - now three and three became six the need
808:28 - was the demand was satisfied now after
808:30 - the execution this six will come and
808:32 - join here 2 + 6 = 8 now how much I have
808:37 - I have eight okay so out of eight I
808:40 - allocate 7 to P3 remaining is 1 I
808:44 - located 7 7 and five was already there
808:47 - so 7 + 5 is 12 the demand is satisfied
808:50 - now these 12 after execution will be
808:52 - given back to the operating system so
808:54 - now I had 12 so initially I had 1 again
808:57 - 12 so now I have 13 13 is there with
809:01 - me now I satisfy the need of P2 so how
809:04 - much I have remaining nine
809:06 - 4 and four are eight after execution
809:09 - this eight will come and will be added
809:11 - here 9 and 8 is 17 okay now how much I
809:15 - had I had
809:16 - 17 now I satisfy the need of P5 so 12 is
809:20 - remaining with me satisfied the need of
809:22 - P5 5 and 5 is 10 the demand is satisfied
809:26 - after the execution this 10 this 10
809:28 - copies of resources will be given back
809:30 - so now
809:33 - 22 the need of all the processes is
809:35 - satisfied and how
809:38 - much copies of resources are with me 22
809:42 - resources that was the number of copies
809:44 - which I had initially so initially I had
809:46 - 22 after
809:48 - the after the uh satisfy satisfaction of
809:53 - all the uh demand of res of the demand
809:55 - of processes in the end how much I got
809:58 - again 22 so if you can see initially was
810:02 - 22 finally after satisfying all the
810:04 - demand I got 22 then and it means that
810:08 - it is a safe sequence to follow this it
810:11 - means that the system is in safe State
810:14 - based on the available resources I was
810:17 - able to satisfy the need of all the
810:19 - processes and the sequence which we
810:21 - follow which sequence we followed we
810:23 - followed firstly we satisfi the need of
810:25 - P4 then we satisfi the need of P5 then
810:27 - P3 then P2 then P1 then I satisfied the
810:31 - need of this P3 but it is not necessary
810:33 - I can satisfy the need of P1 also P4
810:35 - also
810:36 - so the safe sequence need not to be
810:38 - unique it can be different okay there
810:40 - can be multiple safe sequences all
810:43 - process must be satisfied but in that
810:44 - safe sequences so if safe sequence is
810:46 - coming and all the processes demands are
810:50 - satisfied then I can say the system is
810:51 - in safe
810:53 - state in the last lecture we were
810:55 - learning about Banker
810:57 - algorithm we learned a question in
811:00 - which single
811:02 - resource with multiple instances was
811:04 - present multiple instances represent in
811:08 - this we are going to see multiple
811:10 - resource with multiple instances let's
811:13 - see how are we going to tackle
811:15 - this let's first understand the question
811:18 - the question says based on the given
811:21 - time T not can you tell me the system is
811:23 - in safe state or not these are the
811:26 - process ID their demands are written
811:29 - here P0 demands seven copies of resource
811:32 - a five copies of resource B three copies
811:34 - of resource a P3 demands two copies of
811:37 - resource a two copies of resource B and
811:38 - two copies of resource these are the
811:41 - demands and the allocation is how much
811:44 - of their demand is fulfilled now zero
811:47 - copies of resource a have been given one
811:49 - copy of resource B zero copies of
811:51 - resource C given to p 0 so these are the
811:54 - allocation how much of their demand is
811:56 - fulfilled at time t0 how much more
812:00 - should be given to satisfy the demand is
812:02 - need and how can we calculate that
812:05 - demand minus allocation so 7 - 0 is 7 5
812:09 - - 1 is 4 3 - 0 is 3 so this is how we
812:13 - calculated the need need is how much
812:15 - more is needed to satisfy the
812:17 - demand this is the available the number
812:20 - of resources which we are available with
812:22 - this is the total resources how are we
812:25 - going to find the total
812:26 - resources the number of resources which
812:29 - we have allocated till now the number of
812:31 - resources which we are available with
812:32 - add them both and we will get total okay
812:35 - the question is can we satisfy the need
812:38 - of all processes with this scenario
812:40 - let's check we are available with three
812:43 - three and two copies of a b and c
812:47 - respectively can I satisfy the need of
812:49 - any process can I satisfy the need of
812:51 - this no the required are seven and I
812:54 - have three only can I satisfy of this
812:56 - yes yes and yes so I'm going to start
813:00 - with satisfying the need of
813:02 - P1 out of three I give one
813:06 - copy out of three I give two copies and
813:09 - out of two I give all the copies so what
813:12 - I'm remaining now I am remaining with
813:14 - two copies of resource a one copy of
813:17 - resource B and zero copies of resource
813:21 - C so I have completed the demand of P1
813:26 - so now P1 will freely execute and after
813:28 - execution it has to return the
813:30 - resources so the resources when when
813:34 - they will be returned they will be added
813:35 - back to the available resources what is
813:37 - the available 2 1 and 0er so 2 + 3 is
813:41 - 5 1 + 2 is 3 and 0 + 2 is
813:45 - 2 so now I am available with these many
813:49 - resources 5 3 and 2 can I satisfy the
813:51 - need of this no required is seven I have
813:54 - five only can I satisfy the need of P2
813:56 - no required is six I have five only can
813:58 - I satisfy the need of P3 yes I can so
814:01 - out of five zero is needed out of three
814:05 - 1 is needed so now out of three one is
814:09 - needed so I'm remaining with two out of
814:12 - two one is needed so I'm remaining with
814:13 - one so this is the remaining resources I
814:15 - have after satisfying the need of P3 so
814:18 - when P3 is execution will be completed
814:21 - it has to return the resources so it
814:22 - will return these resources 5 + 2 is 7 2
814:26 - + 2 is 4 and 1 + 2 is 3 so now I'm
814:30 - available with these many resources 7 4
814:33 - and 3 now which process need I can
814:36 - satisfy can I satisfy the need of this
814:38 - yes I can so I will allot 7 to p 0 four
814:44 - of resource B to p 0 and three 3 to P0
814:47 - okay so now I'm remaining with 0 0 and
814:51 - 0 the already allocated was 01 0 I have
814:55 - allocated 743 now so need plus
814:59 - allocation is is what the demand is so I
815:02 - have satisfied the demand of p 0 so p 0
815:05 - will fully execute now after execution
815:07 - it has to return the resources now what
815:09 - is the resources I'm left with I'm left
815:12 - with this 7 5 and
815:16 - 3 but I can see the number is different
815:19 - here it's like 7 4 and five but we are
815:22 - getting 7 5 and three it's just because
815:25 - I have chosen different path to show
815:27 - that there can be multiple CF
815:30 - sequences I am choosing a different path
815:32 - to complete if I able to get the same uh
815:37 - number of resources which I had in total
815:39 - then I can say the path was correct okay
815:42 - so let us prove
815:44 - that there can be multiple CF sequences
815:47 - so I am remaining with 7 5 and 3 let us
815:52 - satisfy the need of P2 P2 the number of
815:55 - required resources for a is six so now I
815:57 - remaining with 1 5 and three because B
816:00 - and C are not
816:01 - required p2's need is satisfied or
816:04 - demand is satisfied so I will say P2
816:06 - will execute freely and then it will
816:08 - come back it has to return the all the
816:10 - resources so 9 + 1 is
816:12 - 10 five and five I can say like this
816:18 - okay now I have satisfied the need of P2
816:22 - also now it's turn for P4 so for P4 how
816:27 - what if I satisfy the need of P4 then 10
816:29 - - 4 is 6 5 - 3 is 2 and 5 - 1 is 4 I I
816:34 - am available with with these many
816:36 - resources okay now p4's demand is
816:40 - fulfilled so it will execute freely and
816:43 - when after execution it will return it
816:45 - has to return the resources so 6 + 4 is
816:48 - 10 now I am available with 10 3 + 2 is 5
816:52 - 4 + 3 is 7 isn't that the total number
816:54 - of resources yes so I can say multiple
816:57 - safe sequences are possible plus I can
817:00 - also say that this scenario is of safe
817:03 - State because I was able to satisfy the
817:05 - need of each and every process available
817:07 - with me okay so the safe sequence which
817:11 - was followed here was P1 P3 P4 P2 and p
817:15 - 0 but sh sequence that we followed was
817:19 - P3 no it was I think P1
817:24 - P3 then uh p 0 P2 and P4 so the point is
817:30 - there can be multiple safe sequence it
817:32 - is no need that safe sequence should be
817:34 - unique so this is what Bankers algorithm
817:37 - in the next lecture we are going to see
817:38 - the resource request algorithm in the
817:41 - last lecture we have learned about
817:43 - safety algorithm of Banker's algorithm
817:46 - in this lecture it's time for the second
817:48 - part resource request
817:51 - algorithm they both work
817:54 - together to create the bankers algorithm
817:57 - okay so we are going to see how let's
818:00 - first understand resource request
818:02 - algorithm I hope you all remember the
818:03 - meaning of these uh variables Pi is the
818:06 - process requesting for some resource or
818:09 - the instance of resource at time T
818:11 - allocation is number of instances I have
818:13 - given to that process and need is how
818:16 - much more instances a process need to
818:18 - satisfy its demand and available means
818:20 - after location how many instances of the
818:24 - resources I'm left with that is
818:26 - available okay and we have also
818:28 - discussed that request should always be
818:30 - less than need and request should always
818:32 - be less than available resources okay I
818:35 - I cannot request more than my need I
818:37 - cannot request more than what is
818:39 - available okay now assume that we have
818:42 - satisfied the
818:44 - request process made some request and
818:47 - assume that we have satisfied now
818:50 - satisfying means we have already
818:52 - allocated that process those many number
818:55 - of instances of a resource that it is
818:57 - requesting so allocation will
818:59 - increase its need will decrease now it
819:02 - will need less number of uh instances
819:05 - than before to satisfy demand and number
819:08 - of
819:09 - available instances will
819:12 - decrease okay let me repeat after
819:14 - allocation the allocated number will
819:16 - increase the need will decrease because
819:18 - now the process needs less number of
819:20 - instances to satisfy demand and number
819:23 - of
819:24 - available instances will decrease okay
819:27 - so first things to check is is my
819:31 - request less than need the second thing
819:32 - to check is is my is the request less
819:35 - than
819:36 - available if both of them are true then
819:39 - assume that we have satisfied the
819:41 - request we are assuming so assuming we
819:44 - have satisfied the request what will be
819:46 - the new value of available need and
819:48 - allocated the value of available will
819:50 - decrease need will decrease and
819:51 - allocated will increase now we will run
819:54 - safety
819:56 - algorithm if the system is in safe State
819:58 - Grant the request I else deny request I
820:01 - and block the process so this is how
820:03 - resource request algorithm works
820:05 - with the help of safety
820:08 - algorithm let's see an
820:11 - example at time T1 P1
820:15 - requests one copy of resource a zero
820:18 - copy of resource B and two copies of
820:20 - resource C this is the request made by
820:23 - P1 at time T1 and we are available with
820:26 - 3 3 and two we have taken just the same
820:27 - example of uh we have used before this
820:30 - one same example here okay so the
820:34 - request now is 1 0 and 2 how are we
820:37 - going
820:38 - to proceed so the first thing I told you
820:41 - to check is is my request less than need
820:44 - so what is the need of process P1 the
820:46 - need of process P1 is 1
820:48 - 1212 the demand is 322 the located is 20
820:53 - and the need is 122 and at time T1 it
820:56 - request for
820:58 - 102 so is the request less than the need
821:02 - so I can say yes the request is less
821:04 - than equal to the need is my request
821:07 - less than equal to available what is
821:09 - available 3 3 and two and the requesting
821:11 - is 102 is then less than equal to
821:13 - available yes it is less than equal to
821:15 - available so after doing after checking
821:17 - both this I can say let's assume that
821:21 - request has been satisfied so if I
821:24 - have satisfied this request what will
821:27 - happen
821:29 - now out of available I will give one to
821:33 - process one this one resource to process
821:36 - one three copies of resource V to
821:38 - process one no not three it requires
821:41 - zero so for this time at time T1 process
821:43 - do not require for uh resource V so
821:46 - zero and two copies of C2 process one
821:52 - now now we have to update the need now
821:55 - we have to update the need so after the
821:57 - satisfaction of the
821:59 - request this available will decrease 230
822:03 - because I have satisfied 102 I have I
822:06 - have allocated that so the number of
822:09 - allocation will increase 2 +
822:12 - 102 1 02 so 3 0 and 2 so this is the
822:17 - allocation number the need will decrease
822:19 - Now 1
822:21 - 02 0 2 and 0 so need will also decrease
822:27 - available and need will decrease and
822:28 - allocation will increase so this is my
822:30 - new values now what we are going to do
822:32 - we are going to run the safety algorithm
822:34 - what is the the number of available
822:36 - resources I have now I have 2 3 and 0
822:40 - what is the need of process uh one now
822:43 - the need is 02 and 0 what is the
822:46 - allocation number 302 so 302 now based
822:50 - on the new values I will run safety
822:53 - algorithm okay so we are available with
822:57 - these many
822:58 - resources let's check whose need I can
823:01 - satisfy can I satisfy the need of P0 no
823:04 - can I satisfy the need of P1 yes I can
823:05 - satisfy out of two 0 will be given 3 two
823:09 - will be given so I will be remaining
823:12 - with 2 1 and then zero so these are the
823:16 - remaining resources after uh satisfying
823:19 - the demand of P1 these many resources
823:22 - will return back so I have to add them 3
823:24 - + 2 is 5 2 1 2 + 1 is 3 and 2 + 0 is 2
823:29 - so now I have these many
823:32 - resources 5 3 and 2 now now which whose
823:36 - needs I can satisfy can I satisfy the
823:37 - need of this no can I no can I yes I can
823:41 - satisfy the need of P3 so let's satisfy
823:43 - the need of
823:44 - P3 5 - 0 is 5 3 - 1 is 2 so now I have
823:52 - two copies of B available after
823:55 - satisfying the need of P3 then 2 - 1 is
823:59 - 1 so this is what I'm available with I
824:02 - have satisfied the demand of P3 now
824:04 - these resources with return back 5 + 2
824:06 - is 7 2 + 2 is 4 2 + 1 is 3 so now I have
824:10 - 5 7 43 resources available with me whose
824:14 - need I can satisfy now let's satisfy the
824:16 - need of
824:17 - P4 4 3 and
824:20 - 1 okay so 7 - 4 is
824:25 - 3 3 4 - 3 is 1 and 3 - 1 is 2 these many
824:31 - resources I have after satisfying 3 1
824:34 - and two after
824:35 - after satisfying the need of P4 now when
824:38 - P4 will execute after execution these
824:41 - many resources will come back so 7 + 4
824:43 - is 3 7 + what I'm saying 4 + 3 is 7 3 +
824:48 - 1 is 4 and 3 + 2 is 5 7 4 5 I have now
824:51 - remaining resources now can I satisfy
824:54 - the need of P0 yes I can satisfy
824:58 - so out of seven I will I have zero
825:01 - remaining out of four I have zero
825:02 - remaining out of five I have two
825:04 - remaining so these many resources I have
825:06 - after completing the need of p 0 so
825:10 - after execution these many resources
825:11 - will return and add 7 + 0 is 7 5 + 0 is
825:15 - 5 and 3 + 2 is 5 so I have these many
825:19 - Resources with me 7 755 now can I
825:24 - satisfy the need of P2 yes I can so out
825:27 - of seven I have given 6 to P2 so one is
825:30 - remaining with me five so 0 0 5 so 1 5 5
825:35 - is remaining with me so after P after
825:37 - execution of
825:38 - P2 these many resources will come back
825:41 - and add so 9 + 1 is 10 5 + 0 is 5 and 5
825:44 - + 2 is 7 isn't that the same number
825:47 - which we have in the beginning this
825:50 - total yes so I can say
825:53 - that the system is in safe state so if
825:57 - the system is in safe State I have found
825:59 - a safe sequence then this request can be
826:03 - satisfied or this request can be
826:06 - granted okay so this is how we have to
826:08 - find out whether a process request
826:10 - should be granted or denied now let's
826:13 - solve an interesting question it says an
826:15 - operating system uses Bankers algorithm
826:17 - for deadlock avoidance when managing the
826:20 - allocation of three resour type X Y and
826:22 - Y and Zed three process p 0 P1 and P2
826:26 - are there the table given below present
826:29 - the current system
826:30 - State here the allocation Matrix shows
826:33 - the current number of resources of each
826:35 - type allocated to each process and
826:37 - maximum Matrix shows the maximum number
826:39 - of resources of each type required by
826:41 - each process during its execution so
826:43 - maximum is the demand and allocation is
826:46 - the allocated till now there are three
826:49 - units of Type X so this is the
826:51 - available what we have
826:54 - 322 three units of Type X two units of
826:57 - type Y and two units of type Z is still
826:59 - available the system is currently in a
827:01 - safe State consider the following
827:04 - independent request for additional
827:06 - resource in the current state okay so
827:08 - the request says p 0 make a request of
827:11 - 002 and P1 makes a request of
827:13 - 20 now how how are we going to check
827:17 - whether this request will be fulfilled
827:20 - or not we are going to check using
827:23 - resource request
827:26 - algorithm this is the table which we are
827:28 - given with So based on this we will
827:31 - calculate the need need equals to demand
827:33 - minus allocation
827:35 - 8 - 0 is 8 4 - 0 is 4 3 - 1 is 2 so in
827:40 - this way we have calculated the need now
827:42 - the request says 0 0 and
827:45 - two first of all we have to check
827:47 - whether this request is valid or not the
827:49 - request is valid when it is less than
827:50 - equal to need is it yes it is the
827:53 - request is valid if it is less than
827:55 - equal to available is it yes it is now
827:59 - we have to check after satisfying this
828:02 - request whether the system will in safe
828:05 - state or not so let's say I'm satisfied
828:08 - uh what I'm going to do I'm going to
828:10 - decrease the value of need I'm going to
828:12 - decrease the value of available and
828:14 - increase the value of allocation now it
828:16 - will become
828:17 - three based on the updated values run
828:20 - safety algorithm and see whether the
828:22 - system Still Remains in the safe state
828:24 - or
828:25 - not okay so I have available 3 2 and0 I
828:29 - can satisfy the need of
828:31 - P1 okay so now after satisfying the need
828:35 - of P1 I'm available with 0 2 and 0 okay
828:41 - P1 after its execution will return these
828:44 - many resources so now I have 6 2 and 0
828:49 - so 6 4 and 0 available I have is 6 4 and
828:53 - 0
828:56 - now I can satisfy the request of
828:59 - P2 after satisfying the need of P2 how
829:03 - many resources I have now 5 2
829:07 - and C here we cannot satisfy the need of
829:11 - P2 because we have zero instances of
829:14 - type Zed but here P2 is asking for t two
829:17 - so we have to first satisfy the need of
829:21 - this p 0 can I satisfy the need of p 0
829:25 - no I cannot satisfy the need of p 0
829:29 - because the number of instances of
829:32 - resource X needed is 8 but we have six
829:35 - only so I can say I cannot satisfy the
829:38 - need of either p 0 or P2 so I can say
829:42 - that system has now come into unsafe
829:44 - state so I will say this request will be
829:48 - denied let's check for request number
829:50 - two request number two says that P1
829:53 - 20 2 is request less than
829:57 - available I have available of 322 yes it
830:00 - is less than available is it less than
830:02 - need so the need was 3
830:05 - yes it is less than need need is 3
830:08 - request is 20
830:11 - yes after satisfying the need will the
830:14 - system land into saf state or unsafe
830:16 - State how are we going to check that
830:18 - using using the safety algorithm so we
830:21 - will apply CFT algorithm on the updated
830:23 - values so now we have to update the
830:25 - values available resource how many
830:27 - available resource we have
830:29 - now 1 22 so 1 122 will be the available
830:32 - resource now
830:36 - and I have to decrease the need also so
830:39 - 3 was the need I have satisfied the need
830:43 - so now what is
830:45 - the need now or what is the updated need
830:48 - 1 0 0 see I have I have satisfied the
830:51 - need of 20 the initial need was 3 so
830:54 - what is the updated need 1
830:57 - 0 and allocation will be two more is
831:00 - allocated so three will be Chang to five
831:02 - so this is now the updated values now
831:04 - have to run safety algorithm on these
831:07 - values with 1 122 can I satisfy the
831:10 - request of P2
831:12 - yes so now I have available 0 0 and
831:17 - 0 P2 after running will give me back
831:21 - these resources so now I have
831:24 - 333 can I satisfy the need of p 0 now no
831:27 - I cannot so I have to first satisfy the
831:30 - need of P1 so after satisfying the need
831:33 - of P1
831:35 - how much I have remaining now 2 3 3 so
831:39 - P1 after running is going to give me
831:41 - these many resources back so 6 2 and 0
831:45 - are we got back so 8 6 and 2 8 3 and 2 5
831:48 - and 3 so 8 53 is now the available
831:51 - resources can I satisfy the need of p 0
831:54 - now yes I can so now I'm remaining with
831:58 - 0 1 and 1 after running I will get 843
832:04 - back back so I will get 843 back 843 8 5
832:08 - and
832:09 - 4 8 5 and 4 so this we have in in this
832:13 - manner we have satisfied the need of
832:15 - each and every process we have satisfied
832:17 - the demand of each and every process so
832:19 - I can say the system is in safe state so
832:23 - this request will be granted in the next
832:25 - lecture we are going to learn deadlock
832:27 - detection and Recovery
832:36 - now we are going to learn deadlock
832:37 - detection and
832:39 - recovery so when are we planning to
832:42 - apply this detection and Recovery thing
832:44 - when you see something odd let me ask
832:47 - you a simple question when you go to the
832:49 - doctor when you are not feeling well so
832:51 - the based on the symptoms you tell to
832:53 - the doctor doctor estimates the problem
832:55 - and run the test okay in the same way
832:58 - operating system notices the symptoms
833:00 - like underutilization of CPU majority
833:03 - processes are getting block so by these
833:05 - symptoms by noticing these symptoms
833:08 - operating system runs some
833:10 - test and by the diagnosis operating
833:14 - system tells whether the deadlock is
833:15 - present or not okay so this is what
833:18 - detection is based on the symptoms we
833:21 - run test and then we get the idea
833:23 - whether deadlock is present or not so in
833:26 - the same way when we divided the
833:29 - deadlock avoidance on the basis of
833:31 - number of instances a a resource contain
833:34 - like deadlock avoidance was divided into
833:36 - two part resource allocation graph and
833:38 - bankers algorithm in the same way for
833:41 - single instance resources we have weight
833:43 - for graph method and for multiple
833:45 - instance of resources we have safety
833:47 - algorithm method so first let's learn
833:50 - about single instance that is wait for
833:52 - graph in wait for graph what we do we
833:54 - remove the resources and just keep the
833:56 - processes so R3 will be removed and the
833:59 - arrow will go like this in this
834:01 - way this R4 will be removed and arrow
834:04 - will go like this or I can directly say
834:07 - this this R3 R5 will be removed and
834:10 - arrow will go like this okay so I hope
834:13 - you are getting the point we are
834:15 - removing the resources and just keeping
834:17 - the processes okay so weight for graph
834:19 - contain only the process and after we
834:23 - have drawn weight for graph Run Cycle
834:25 - detection algorithm that is if cycle is
834:28 - present or not and we are talking about
834:30 - single instance so we can say that if
834:32 - cycle is present then deadlock will be
834:34 - there there because for single instance
834:37 - resources the cycle is not only just the
834:40 - necessary condition but it is sufficient
834:42 - as
834:44 - well okay so after detection of
834:46 - algorithm what are we going to do victim
834:49 - processes will be sent as input to the
834:52 - recovery module the recovery module will
834:54 - do something and it will recover what we
834:57 - did first based on the symptoms we are
834:59 - going to run some test so okay if the
835:02 - resources are single instance then we
835:04 - will make a weight for graph how weight
835:07 - for graph is made by removing the
835:09 - resources and just keeping the processes
835:12 - and if I see a cycle present in the
835:14 - weight for graph then I can say that
835:16 - deadlock will be there because in single
835:18 - instance cycle is not only the necessary
835:21 - condition but sufficient as well and
835:23 - that victim processes will be sent to
835:24 - the recovery module okay now comes the
835:28 - multi
835:30 - instance this is allocation this is the
835:33 - request made and this is
835:35 - available
835:38 - okay so I can see that based on the
835:41 - available resources how many process
835:44 - request won't be fulfilled so p 0
835:47 - request will be fulfilled P1 failed P2
835:50 - fulfilled P3 failed P4 failed so P1 P3
835:53 - and P4 will be
835:55 - blocked see there are five processes and
835:58 - three of them are blocked majority
836:00 - process are getting blocked so there are
836:03 - chances of Deadlock
836:05 - system is safe if request of all
836:07 - processes satisfiable with the available
836:09 - copies in some order this is exactly
836:12 - like the safety
836:14 - algorithm but in safety algorithm what
836:17 - we used to say we say that the system if
836:21 - if the available resource are not able
836:23 - to satisfy the request of some processes
836:26 - then there we used to say uncf state has
836:29 - occurred but now here will say deadlock
836:31 - is
836:32 - there okay okay so let's see
836:36 - this can I satisfy the request of P0 yes
836:39 - so the location will come back the
836:43 - location will come back so 0 1 0 is now
836:45 - the available resources I have can I
836:48 - satisfy the request of P2 yes the
836:50 - location will come back now I have
836:54 - 3 1 and three this is the available
836:58 - resource now I
836:59 - have now can I satisfy the request of um
837:05 - P3 I can even satisfy for P1 also so
837:08 - okay let's
837:09 - P1 I satisfy the request of P1 now I am
837:12 - available with
837:14 - one one and one after P1 request is
837:19 - satisfied what is allocated now
837:22 - allocated now will be 4 0 and 2 so this
837:25 - will come back now I have 5 0 5 1 and 3
837:30 - this will come back and added
837:32 - here now I will will satisfy the request
837:35 - of P4 so in this way I can say that the
837:40 - request of all process can be satisfied
837:42 - in some
837:43 - order here what we are seeing
837:48 - that available was not able to satisfy
837:51 - the request of P1 was not able to
837:52 - satisfy the request of P3 was not able
837:55 - to satisfy the request of P4 so P1 P3
837:59 - and P4 were blocked but when available
838:02 - satisfies the request of P
838:04 - Z it got some of the resources back and
838:08 - when the resources available are enough
838:11 - to satisfy the request then those
838:12 - sleeping process or those blocked
838:14 - process will be brought back to the
838:17 - ricq okay so this is how safe state is
838:21 - achieved even though we got a symptom
838:23 - that out of five process three process
838:26 - are blocked but still we are saying that
838:29 - no problem because the result of the
838:30 - test is negative the result of the test
838:32 - says that dead log is not present
838:35 - okay now what happens P2 makes a new
838:39 - request P2 makes a new request 0
838:43 - 01 now what happens P2 makes a new
838:46 - request of 01 so let's see here P2 makes
838:49 - a new request of
838:51 - 0 0 0 and 1
838:54 - okay okay let's run safety algorithm now
838:57 - request of p 0 will be fulfilled this
838:59 - will come back and add here now I have
839:01 - available resource this can I can I
839:04 - satisfy the need of P1 no can I satisfy
839:06 - the need of P2 no can I no no so all of
839:10 - these process will be blocked only p 0
839:12 - was completed and it terminated so now
839:16 - these four process which I have with me
839:18 - are blocked all the process are blocked
839:21 - this is the case of Deadlock so these
839:23 - four processes will be sent back sent to
839:25 - the recovery module as an
839:28 - input okay so this is how it work let me
839:30 - repeat again what happens initially we
839:33 - saw that majority process are getting
839:35 - blocked so we should run safety
839:36 - algorithm we run safety algorithm and we
839:39 - successfully were able to satisfy the
839:41 - request of all the processes we can say
839:43 - the system is in safe State even though
839:45 - we got a symptom but no problem here
839:47 - because the test is negative but what
839:48 - happens now P2 makes a new request 001
839:52 - so when P2 makes a new request of 001 I
839:55 - was only able to satisfy the request of
839:56 - p 0 and rest of the process were blocked
839:59 - so this is the case of Deadlock okay now
840:02 - what happens these victim process will
840:04 - be sent to the recovery module as an
840:08 - input okay so how does this recovery
840:10 - module work let's see in the next
840:13 - video in the last lecture we have seen
840:16 - the deadlock detection now what happens
840:19 - after detection recovery so the
840:22 - deadlocked process will be sent to the
840:25 - recovery module and it has two ways to
840:28 - work either it works on processes or
840:29 - resources for process let's say there
840:32 - are three process P1 P2 P3 each
840:35 - dependent on one
840:37 - another so the first thing it can do is
840:40 - abort one process at a time until the
840:42 - elimination of Deadlock cycle suppose I
840:45 - uh removed this P3 now what happens when
840:48 - P3 is
840:50 - removed the resources of P3 will be
840:53 - given to
840:54 - P2 now P2 will complete after the
840:58 - completion P2 will return back those
841:00 - resources and will help P1 to complete
841:03 - in this way the deadlocked will will be
841:05 - solved and the process will complete but
841:09 - in this Solution One process has to
841:11 - sacrifice the second solution says
841:14 - delete all the process about all the
841:15 - deadlock
841:16 - process okay now comes the resource the
841:20 - resource solution says do the preemption
841:21 - of resources let me say P1 P2 and P3
841:25 - each depending on one another now what
841:29 - happens the P2 is a strong process
841:33 - strong in terms
841:34 - of priority so P2 is a strong process P2
841:38 - will snatch away the resources of P3 now
841:40 - P3 don't have the resources P2 will get
841:43 - itself completed and will return back
841:45 - the
841:47 - resources and P1 will get those
841:49 - resources because P1 was dependent on P2
841:51 - so P1 will get the resources and P1 will
841:54 - complete and when P1 will get completed
841:57 - it will return the resources to P3
841:58 - because P3 was dependent on P1 in this
842:01 - way neither of the process has to get
842:04 - deleted and all of them was completed
842:07 - without any
842:08 - loss okay so preemption was a method and
842:12 - roll back what is roll back we will see
842:14 - in a minute okay so now the question
842:17 - arise for abortion of one process which
842:19 - process to have we have to kill the
842:21 - algorithm says the one who has just
842:24 - started that process you have to kill
842:26 - okay then apply the deadlock detection
842:28 - algorithm again and again now comes the
842:31 - roll back part what we do we will keep
842:33 - preempting the latest resource add them
842:36 - to the available pool and run the
842:38 - detection algorithm again after each
842:40 - preemption and we will keep preempting
842:42 - until the cycle is broken so this is how
842:44 - resource preemption works and
842:47 - process recovery based on the process
842:49 - and resources
842:51 - okay now let's see the difference
842:54 - between prevention avoidance detection
842:57 - and ignorance this prevention and
843:00 - avoidance is like a proactive attitude
843:02 - you already take the preventive measures
843:05 - you already try to avoid the deadlock in
843:07 - these cases deadlock do not
843:10 - occur and this detection detection and
843:13 - Recovery is like a reactive attitude
843:15 - deadlock has occurred now do what you
843:17 - can do and the ignorance is the inactive
843:20 - attitude let's read this prevention this
843:23 - approach is about taking proactive
843:25 - measure to stop problems before they
843:27 - occur it's a proactive attitude because
843:29 - it involves planning ahead and taking
843:32 - action to prevent issues
843:34 - and what about avoidance this is about
843:36 - steering clear of potential problems it
843:39 - is a reactive attitude
843:41 - because it involves responding to the
843:43 - possibility of issues avoiding them so
843:47 - avoidance can also be segregated into
843:49 - reactive attitude because it involves
843:51 - responding to the possibility we we try
843:53 - to avoid the deadlock detection deadlock
843:57 - has occurred now do what you can
844:00 - do deals with the issues after they have
844:02 - happened and it ignorance this is when
844:05 - no action is taken either to prevent or
844:06 - avoid and recover from problem it is an
844:08 - inactive attitude because it involves
844:10 - doing nothing in response to potential
844:13 - or actual
844:15 - issues now let's see some problems so
844:18 - the total process are n each process
844:20 - need two copies of resource R the total
844:23 - number of available copies are 1 2 3 4 5
844:26 - and
844:27 - six now we have to tell now we have to
844:30 - tell minimum number of processes
844:32 - required to cause Deadlock
844:35 - let's take let's start with three
844:37 - process I have allotted both the process
844:40 - to two resources so they will all
844:43 - complete no possibility of Deadlock now
844:45 - let's go
844:47 - here we included five processes so what
844:50 - happens first one given to P1 second to
844:52 - P2 third one to P4 fourth one to P5
844:55 - fourth one to P4 and 5 one to P5 now one
844:59 - copy of resource R is remaining so I
845:01 - have to assign it to some of the process
845:02 - some process out of the let's say I'm
845:05 - assigning that to P1 now what will
845:07 - happen when P1 will complete it will
845:09 - release its resources back and that
845:13 - resources are going to help other
845:15 - process to complete in this
845:18 - way P5 with P5 process with five process
845:24 - the deadlock is not there now let's say
845:27 - I increase one more process now what
845:29 - happens first one given to P1 second to
845:30 - P2 third to p 3 4 to P4 fifth to P5 6 to
845:34 - P6 now I have used all the available
845:37 - resources in this case each of the
845:40 - process is waiting on another to
845:42 - leave a copy of resource so that it can
845:45 - complete this is just like the case of
845:47 - dining philosopher in which each
845:49 - philosopher picks up the left
845:52 - Fork so minimum minimum number of
845:55 - process to cause deadlock is six and
845:59 - maximum number for deadlock freedom is
846:01 - five maximum of number of process for
846:05 - which deadlock won't occur is five let's
846:07 - see another question there are three
846:09 - process now you have to tell me the
846:11 - resources each process require two
846:14 - resources now tell me the number of
846:15 - resources such
846:17 - that the deadlock will occur maximum
846:20 - number of resources to cause
846:23 - deadlock so maximum number of resources
846:25 - to C cause deadlock will be three 1 2 3
846:29 - see if I give one more deadlock won't
846:33 - occur so the maximum is three now
846:35 - minimum number to ensure deadlock
846:37 - Freedom will be four 1 2 3 deadlock is
846:40 - there if I give one more deadlock won't
846:43 - occur so I will say minimum four are
846:45 - required to ensure deadlock freedom is
846:48 - it clear see another see another problem
846:51 - end processes are there R has six copies
846:54 - each process require three copies now
846:57 - tell me the
846:59 - same so how much uh proc how many
847:03 - process are required to cause deadlock
847:05 - and maximum number of process for
847:07 - deadlock Freedom see
847:08 - this if I talk about P1 P2 and P3 each
847:11 - process now require three 1 2 3 4 5
847:15 - 6 I have used all of them and each
847:18 - process required three resources so I
847:21 - will say P1 will wait on P2 and P3 so
847:23 - that they will release their resources
847:26 - so that P1 can get one more to complete
847:29 - similarly the same case for P2 P2 is
847:31 - waiting on P1 and P3 so that it can get
847:34 - one Moree to complete so in this way I
847:36 - can say that minimum three resources
847:39 - minimum three process are enough to
847:42 - cause
847:44 - deadlock and maximum number of process
847:47 - to ensure deadlock freedom is two only 1
847:50 - 2 3 4 5 6 just two if I say three then
847:54 - the case of Deadlock may arise okay see
847:59 - this processes are there P1 P2 P3 P4 P5
848:02 - the maximum demand they have made is 10
848:05 - 8 5 12 6 now you have five process now
848:09 - you to tell me the resource number of
848:10 - resource maximum resource to cause
848:12 - deadlock so for deadlock to occur I will
848:16 - give 9 to P1 7 to p8 7 to P2 4 to P3 11
848:22 - to P4 and 5 to P5 now what will happen
848:26 - they will wait on each other to just get
848:28 - one more resources to
848:30 - complete this is the same case of dining
848:33 - philosopher so for maximum resource to
848:36 - cause deadlock you have to create the
848:37 - case of dining philosopher now they are
848:40 - waiting on each other to get just one
848:42 - more resource to complete so I will say
848:45 - 9 + 7 + 4 + 11 + 5 that is 36 so I will
848:50 - maximum number of resources to got
848:51 - deadlock is 36 and minimum to ensure
848:54 - deadlock freedom is see if I give one
848:57 - more resource to any of the process
848:59 - let's say I have given one more resource
849:01 - to this five P3 will complete and P3
849:05 - will release five resources back to the
849:07 - pool now what will happen P2 will get
849:10 - one P1 will get one P4 will get one P5
849:14 - will get one and one is still remaining
849:15 - in the pool all of them will complete so
849:18 - what I can say
849:19 - here if I just add one more
849:22 - resource then deadlock Freedom can be
849:26 - ensured so 37 resources minimum and 36
849:30 - maximum to cause deadlock and 37 to
849:32 - cause dead Freedom okay to solve such
849:36 - questions you should you should always
849:38 - remember the dining philosopher case now
849:41 - these are some homework problems you
849:42 - have to solve them this is a question
849:45 - which of the following statement is true
849:46 - with respect to deadlock the first says
849:48 - circular way weight is necessary
849:50 - condition for the formation of Deadlock
849:52 - yes it yes it is true in a system where
849:55 - each resource has more than one instance
849:57 - a cycle in its weight for graph indicate
849:59 - the presence of a
850:01 - deadlock no because because for multi-
850:04 - instance graph for multi- instance
850:06 - resource cycle is just a necessary
850:10 - condition indicates the presence of
850:12 - Deadlock no for single instance graph in
850:15 - wait for for ining single instance
850:18 - resource for wait for graph I can see
850:20 - cycle is sufficient and
850:24 - necessary if the current allocation of
850:27 - resources to process processes leads the
850:29 - system to UNF State then deadlock will
850:31 - necessarily occur
850:34 - no I cannot say that what I have told
850:36 - you they will go into unsafe State not
850:40 - deadlock unsafe state is not necessarily
850:43 - deadlock unsafe state is just a warning
850:46 - that in future deadlock may occur in
850:50 - resource allocation graph of a system if
850:52 - every Edge is assignment Edge then the
850:54 - system is not in deadlock
850:56 - stage in resource allocation graph of a
850:59 - system if every Edge is an assignment
851:01 - Edge
851:04 - then yes that is also true how can I say
851:07 - that look at the
851:11 - diagram the case we discussed
851:16 - was
851:18 - this P1 was holding R1 and waiting for
851:22 - R2 P2 was granted R2 and waiting for R1
851:27 - but you can see here cycle only forms
851:30 - when there are request edges if there is
851:33 - no request edges then cycle won't form
851:37 - and if cycle is not present then the
851:40 - deadlock will definitely won't
851:42 - occur okay so in resource allocation
851:45 - graph if every Edge in every Edge is a
851:47 - assignment Edge then this says that
851:50 - cycle is not present and if cycle is not
851:52 - present then I can say the system is not
851:54 - in deadlock State okay this is a
851:57 - homework question for you you should try
851:59 - okay this is also an homework question
852:00 - we'll discuss them in the next section
852:03 - SE okay so for now I can say deadlock is
852:08 - officially
852:09 - completed in the next section we will
852:11 - start memory
852:14 - management so let's first start with the
852:16 - homework discussion of the last lecture
852:19 - here we are given with consider the
852:20 - following snapshot of the system running
852:23 - and processes process I is holding XI
852:25 - instance of resource R so I can say xir
852:29 - is being acquired by
852:31 - pi for all I 1 to n for all I 1 to n
852:35 - currently all instances of R are
852:36 - occupied further for all I process I has
852:39 - placed a request for an additional Yi
852:41 - instance okay so process I has made a
852:44 - request for additional Yi instance of
852:47 - resource R while holding XI instance it
852:50 - already has it's it's already holding
852:52 - some XI instances there are exactly two
852:55 - process p and Q says that YP = to y = 0
852:59 - YP = to yal to 0 this says that process
853:03 - p and process Q are not requesting
853:06 - anymore okay so which one of the
853:08 - following can serve as a necessary
853:10 - condition to guarantee that system is
853:11 - not approaching a deadlock see this here
853:15 - here I have written all of the P ID
853:17 - process IDs P1 P2 PN and somewhere in
853:19 - between there must be process p and Q
853:21 - and then the p and the last process or
853:24 - here are the allocated resources so P1
853:26 - is holding X1 resources X1 instances of
853:29 - resource R P2 is holding X2 instances of
853:31 - resource r P3 is holding X3
853:34 - and process p is holding XP resource and
853:37 - process Q is holding XP resource see
853:39 - whenever I say resource I mean instance
853:41 - of that resource okay and then PN is
853:44 - holding xn okay now comes the request
853:47 - part here here you can see Yi is being
853:51 - requested by process Pi so I can say P1
853:54 - is requesting y1 P2 is requesting Y2 but
853:58 - here it is given that process p and
854:00 - process Q are not requesting anymore so
854:02 - process p will request zero instance and
854:04 - process Q will also request zero
854:06 - instance now comes the question which
854:09 - one of the following can serve as a
854:11 - necessary condition to guarantee that
854:13 - the system is not approaching a deadlock
854:16 - see we have zero available resources
854:20 - so and I have to satisfy the need of all
854:24 - these processes with that available
854:26 - equals to zero how can I satisfy I can
854:28 - satisfy the need of these two processes
854:31 - so when PQ and PP that is process p and
854:35 - process Q will start running and after
854:37 - execution they will release their
854:39 - resources back so how much available
854:41 - resources now I have I have XP plus X xq
854:45 - and with these available
854:47 - resources I must be able to satisfy the
854:50 - need of at least one process out of uh
854:55 - P1 to PN except P PP and PQ so with
854:59 - these Resources with these instances I
855:02 - should able to satisfy either of them at
855:05 - least
855:06 - one if I am able to satisfy the need of
855:09 - at least one so how can I write at least
855:11 - one minimum of Yi that is minimum of Yi
855:17 - I will be able to satisfy with these
855:19 - instances of resources and if it is then
855:21 - the system is not approaching datal log
855:24 - see if I say the xer xq that is number
855:28 - of available resources with me
855:30 - now is even not enough to satisfy the
855:33 - need of minimum of these uh request the
855:37 - least of or the minimum of that request
855:39 - I'm not able to satisfy with the
855:42 - resources I have available
855:44 - with that's that is the case of actual
855:47 - deadlock okay here I should write I is
855:49 - not equals to P or q and K is not equals
855:51 - to P because these processes have
855:52 - already completed that's why they have
855:54 - released their resources here and one
855:57 - more thing if I write XP plus xq is
855:59 - greater than maximum of Yi which means
856:03 - with with XP and XU they are well enough
856:06 - that I can satisfy the need of maximum
856:08 - of these I can satisfy the need of one
856:11 - whose request is maximum then I can say
856:13 - the system is totally safe there is no
856:15 - case of
856:16 - Deadlock okay I hope you got the idea
856:19 - how we did it with these available
856:21 - resources I should be able to satisfy
856:24 - the minimum amount of request or the
856:27 - least request made by the processor if
856:29 - yes then I can say system is not
856:31 - approaching Deadlock this was also a
856:33 - nice question it said consider the
856:35 - following resource allocation graph find
856:37 - if the system is in deadlock state so
856:40 - either you can try
856:42 - using that weight for graph but here you
856:45 - cannot use weight for graph directly
856:46 - because of multi- instance resources so
856:49 - how are you going to solve
856:52 - this we are going to solve using the
856:56 - detection algorithm see this which of
856:58 - the following uh find the system is in
857:00 - deadlock state or not so we are using
857:02 - detection we are detecting if the system
857:04 - is in deadlock state or not so we are
857:05 - not using prevention we are not using
857:07 - avoidance we are using detection and in
857:09 - detection which algorithm single
857:12 - instance no we are use multi- instance
857:14 - and how we use multi- instance using
857:16 - Bankers algorithm so we need to convert
857:19 - this resource allocation graph into a
857:21 - matrix R1 R2 and R3 are the type of
857:24 - resources P1 is
857:27 - holding P1 is holding one instance of R2
857:32 - request testing for one instance of R1
857:35 - and holding one instance of R1 so it's
857:37 - holding see see it's holding one
857:39 - instance of R1 one instance of R2 so I
857:41 - can write 1 1 0 for P1 I can write 1 1 0
857:46 - for P1 this is what P1 is allocated with
857:48 - if I have to write for p 0 then it's
857:51 - holding one instance of
857:53 - R1 and uh no nothing else it's just
857:57 - holding one instance of R1 yes it's
857:58 - holding one instance of R3 also so I
858:00 - will write 1 0 and 1 for p 0 I will
858:03 - write 10 1 so in this manner I will
858:06 - write the whole allocation thing now the
858:09 - request what's what's what it is
858:11 - requesting it's requesting see here it's
858:14 - requesting
858:15 - R1 and nothing else I will write 1
858:19 - 0 wait a minute yes it's I will write 1
858:22 - 0 0 for p 0 it's requesting R2 it's
858:26 - requesting R3 so I will write 0 1 1 I'll
858:30 - write 0 1 1 for P2 I will write for P2
858:33 - it's requesting one instance of
858:35 - R2 uh sorry it's requesting one instance
858:38 - of R3 and nothing else so 0 0 and 1 0 0
858:43 - and 1 it's just requesting one instance
858:45 - of R3 now P3 P3 where is P3 here is P3
858:49 - so P3 is requesting one instance of R2
858:52 - it's requesting one instance of R1 and
858:56 - see here it's requesting another
858:57 - instance of R2 so I'll write uh I'll
859:01 - write
859:04 - 1 2 0 1 12 0 so this is what is request
859:10 - this is allocation this is p ID now
859:13 - available resource which resource is
859:15 - available with me see here this R3
859:18 - resource is not given to anyone this
859:20 - this is not allocated to anyone R1 is
859:23 - completely allocated R2 is completely
859:25 - allocated I have just R3 available with
859:26 - me so I'll write 0 01 now with the help
859:29 - of this 01 can I satisfy the need of all
859:32 - these
859:33 - and if yes then the system is not in dad
859:35 - log state so first we have to satisfy
859:37 - the need of P2 when p2's need will be
859:39 - satisfied then I'm I'll be available
859:41 - with this allocation Will Come Back to
859:43 - Me 0 1 0 so I'll have 0 1 1 now with
859:48 - this 011 can I satisfy the need of p 0
859:50 - yes I can so this allocation will come
859:53 - to me again I'll have 1 0 and 1 which is
859:57 - one12 with this 112 can I satisfy the
859:59 - need of uh yes I can satisfy the need of
860:01 - P1 so I'll satisfy the need of P1 and
860:04 - this allocation will come back to me now
860:07 - I have 222 now I satisfy the need of P3
860:10 - so yes the system is safe I can satisfy
860:14 - the need of all the processes with the
860:17 - resources I'm available with so I'll say
860:19 - this system is not in deadlock State
860:22 - okay so this was all about deadlock and
860:26 - we have also discussed the homework
860:29 - problems congratulations we have
860:31 - completed our deadlock section now we
860:33 - are starting the memory management
860:36 - section what is memory memory is a
860:38 - electronic holding Place uh for data and
860:42 - instructions data and instruction
860:45 - that computer want to or the CPU want to
860:48 - reach quickly to see what is the need of
860:51 - memory because CPU is very
860:53 - fast hard disk is very slow slow we want
860:57 - something in between to coordinate with
860:59 - both that's what memory does
861:03 - memory whenever I say memory I mean by
861:05 - primary memory that is the main memory
861:07 - that is Ram Rome cach registers this
861:10 - cash and resists are just like the
861:11 - memory buts way faster cash is faster
861:14 - than RAM and resistors are faster than
861:18 - cash cash is smaller in size than Ram a
861:21 - resistor is smaller in size than cash
861:24 - okay so the more fast we become the less
861:28 - size we got okay see hard disk has the
861:30 - largest size RAM has little bit low size
861:34 - then cach more low and then register has
861:37 - the least size okay so Ram is also known
861:40 - as main memory or read write memory it's
861:42 - also known as random access memory this
861:44 - is readon memory related to file systems
861:47 - so this is Ram connected with address
861:49 - bus data bus and control signals this
861:52 - chip select it's it's just like what
861:54 - power on and power off thing what does
861:56 - this address bus do let's say I want to
861:58 - access the memory location at 10 1 0 so
862:02 - this 10 1 0 will be brought by address
862:04 - bus and what does this data bus do it
862:06 - brings the content of 101 0 to
862:10 - CPU and sometime it also uh carries
862:14 - addresses in in of the case of indirect
862:17 - addressing don't worry if you are just
862:19 - getting confused uh just take a look at
862:21 - it and we will learn more that in detail
862:23 - in our computer organization
862:24 - architecture course what you have to
862:26 - focus on in this is this linear
862:28 - one-dimensional view of memory how does
862:30 - memory look like this is what it is it
862:32 - is a linear array of words what is words
862:35 - what is word collection of
862:38 - bits uh if I say one word equals
862:42 - to one word equals to 8 bit 8 Bits or
862:46 - one
862:47 - bite then I can say that each cell in
862:50 - the memory consist of one byte one by
862:54 - see this memory is divided into lots of
862:56 - words lots of words memories divided
862:59 - into so what is this this this is
863:03 - address each word has a unique address
863:08 - if I say m of 1010 this is what address
863:12 - is each cell in the memory have a unique
863:16 - address and to and to access the content
863:18 - of a word we must have an
863:22 - address okay so let's say this is a cell
863:26 - or this is a word it has the address X
863:30 - and it has a length of M bits which
863:32 - means one word consist of M bits M bits
863:36 - M bits so if I say what is the size of
863:39 - memory number of words into M bits so n
863:44 - let's say n be the number of words M be
863:46 - the size of each word so this is the
863:48 - memory size n into
863:50 - M okay so M
863:53 - bits it is the word length and in word
863:57 - content is stored and what is content
863:59 - data and instruction okay so I have
864:01 - written that same thing here M width of
864:03 - a word word length xal to fixed length
864:05 - address in bits and total number of
864:08 - veres in let me discuss a small thing
864:09 - with you if you are not familiar with
864:10 - this let's say if I talk uh I have just
864:14 - one bit how many words I can address
864:16 - with uh let's say I make two blocks one
864:20 - block I can give address zero and
864:22 - another block I can give address one so
864:23 - if one bit I have I can address two
864:25 - blocks let's say I have two bits so how
864:28 - many blocks I can address I can address
864:30 - four blocks 0 0 0 1 1 Z and 1 one see
864:35 - what is the thing that I'm talking about
864:37 - with with let's say if I talk about two
864:40 - bits how many unique numbers you can
864:41 - generate with two bits that's what the
864:44 - number of words you can address with if
864:46 - I say I can generate four number with
864:48 - two bits that is 0 1 2 and 3 these are
864:51 - the four number that can be generated
864:52 - using two bits so I can say with two
864:56 - bits I can address four words so if I
864:59 - say I have three bits how many words I
865:02 - can address 0 0 1 0 0 0 0 0 1 0 1 0 0 1
865:09 - 1 101 in this way you go till
865:13 - 111 okay so you can address seven from 0
865:18 - to 7 you can address you can generate
865:21 - eight unique numbers so you can address
865:23 - eight words with three bits with three
865:26 - bits you can address eight words so it's
865:30 - like 2 to^ 3 with two bits I can address
865:33 - four words it's like 2 power 2 with one
865:36 - bit I can address two words so like 2^ 1
865:39 - so if I ask you if I ask you with n Bits
865:42 - let's say this is n Bits how many unique
865:45 - numbers I can generate you can generate
865:46 - two rais to power n
865:48 - numbers so how many words you can
865:50 - address with you can address 2 power n
865:52 - words so with nbit address you can have
865:58 - 2 to power n number of words
866:02 - okay so this
866:05 - mbit this mbit is the size of each word
866:09 - so this is the size of each word m bit
866:12 - and this is what the number of words are
866:14 - so M bits M into 2 ra to^ n is actually
866:18 - the size of my memory size of memory or
866:21 - I can say memory capacity I hope you are
866:23 - getting the point let me repeat again
866:25 - let me repeat again so that will clarify
866:27 - you from n Bits of address I can
866:31 - generate create 2 to power n unique
866:34 - numbers which can be helpful to address
866:36 - 2 power n words so the number of words I
866:39 - have is 2 power n and the size of each
866:41 - word is M
866:43 - bits so this is what my memory size is
866:47 - okay I I hope you got the point so this
866:49 - x this x is the fixed length address and
866:52 - it is in
866:54 - bits okay so memories is specified using
866:57 - number of words into width of a word n
866:59 - into M and let's say n is the size of
867:04 - address in bits so number of words can
867:06 - be 2^ n we have just discussed it now n
867:09 - is the word length n is the total number
867:11 - of words so I can write n = to 2^
867:15 - n or I can say number of
867:18 - words equal to 2 to power address size
867:21 - in
867:23 - bits I hope now it's clear so total
867:25 - number of words equal to 2 to^ size of
867:29 - address okay now comes the relation
867:32 - between n and n we have already talked
867:34 - about this uh let's say if I have three
867:36 - bits then I can address I can
867:39 - generate uh I said I made a mistake here
867:42 - yes so if I have three bits I can
867:44 - generate eight unique numbers which can
867:47 - be helpful in addressing of eight
867:50 - words okay so this is what uh I want to
867:54 - clarify now one thing you have to
867:56 - remember in 10 bits for 10
867:59 - bits I can for with 10 bits
868:02 - I can generate 2 to power 10 unique
868:04 - numbers and this 2 power 10 when we are
868:07 - talking about data is also known as K
868:10 - that is that th000 thing if I have 2 20
868:14 - 2 20 then this become 2 20 then it
868:17 - becomes M Mega if I say 30 bits then
868:21 - this is 2 30 that is giga so 10 bits can
868:25 - be useful to generate 1 kilow 20 bits
868:28 - can be useful to generate 1 Mews and 30
868:30 - bits can be useful to generate 1 G vers
868:33 - so if I'm problem here if I say Nal to
868:36 - 500 G which mean I have 500 g words then
868:40 - what will be the address size see for
868:44 - 500 Words I need to have nine bits
868:48 - because with eight bits I can only
868:50 - generate 256 words or I can say only
868:52 - generate 256 address and one address for
868:55 - each word with nine bits I can generate
868:58 - 52 addresses so for this 500 I I need to
869:02 - have 9 bits and for this G I need to
869:05 - have 30 bits we have just discussed it
869:06 - here 30 bits for 1 gab so 30 + 9 is 39
869:11 - why are we adding this because of this
869:13 - let me explain you in proper detail n
869:15 - equals to I can write it 2 power n into
869:18 - 2^ 30 so log 2 N will
869:23 - be 39
869:25 - bits remember this that the address size
869:29 - is always in
869:30 - bits the address size is always in bits
869:33 - okay Nal to 1,000k so for 1,000 uh I
869:37 - need to have 10 bits because with 10
869:39 - bits I can generate one2 for addresses
869:41 - if I just shift down to one bit from 9
869:43 - bit I can only generate 51 so I can
869:45 - write 10 bits for this 1,000 and 10 for
869:48 - this kilo so in total I will have 20 bit
869:51 - address number of words number of bits
869:54 - in the address and word length suppose
869:57 - if I say n equals to 13 bits which mean
870:01 - 13 bit address 13 bits are needed to
870:03 - refer one world of
870:05 - memory see if I use if I say my address
870:08 - size is two bits which mean two bits are
870:12 - needed to refer one word in the memory
870:14 - similar in similar way if I say my
870:17 - address size is 13 bit which means 13
870:19 - bits are needed to refer one word of
870:21 - memory okay m equal to 8 bit this is 1
870:25 - byte so m equals to 1 by that is word
870:27 - length so this each cell of a memory
870:31 - consist of of 1 by n = to 2^ 13 we got
870:36 - it from here which means with 13 bits I
870:39 - can generate 2^ 13 words so n = to 2^ 13
870:45 - words so I can write 2^ 13 as 2^ 3 into
870:49 - 2^ 10 and 2^ 10 can be written as
870:52 - K so I can
870:55 - write 8 K and what is the size of each
871:00 - word bite so I can write 8 KB is the
871:03 - size of memory so this is the capacity
871:04 - of memory in terms of bite and words now
871:07 - if I ask you what is the capacity of
871:09 - memory in terms of words then you write
871:11 - 8 kilow and if I ask you what is the
871:13 - capacity of memory in terms of bytes
871:14 - then you say 1 8 kilobyte because 1 Word
871:17 - equals to 1 by okay see this n equals to
871:21 - 18 bits which means I can generate 2^ 18
871:26 - 18 addresses which means I can have 2^
871:30 - 18 Words which means I have 2 10 into 2^
871:33 - 2^ 8 into 2^ 10 which is 256 kilow words
871:36 - I can have I can have 2^ kilow words and
871:40 - what is the size of each word the size
871:42 - of each word is 8 into 2 bits which
871:44 - means this is 1
871:46 - bite which means I can the size of each
871:49 - word is 2 by so if I ask you the world
871:52 - view of a memory then it is of 256 kilow
871:55 - and if I just put the value of word here
871:57 - that is 2 byte then I get 512 kilobyte I
872:02 - just substituted the value of word then
872:04 - I get the bite view of a memory and by
872:07 - default you can take one word as one
872:10 - bite okay let's move down just for the
872:13 - same thing uh we just for the sake of
872:16 - Simplicity we say this n is the size of
872:18 - memory size of
872:21 - memory n = to 64
872:24 - KB now it says that I have 64 KB of
872:29 - memory and what is the word
872:33 - length word length is is 4 byte
872:39 - so this question is important question
872:41 - you will feel the difference what is the
872:43 - meaning of world view and bite
872:45 - view world view says that each cell in
872:49 - the memory consist of word one
872:51 - word and bite view says each cell in the
872:55 - memory consist of one bite now the
872:58 - question is asked what will be the
872:59 - address length if I address the memory
873:02 - in terms of word and what will the
873:04 - address length if I address the memory
873:05 - in terms of bite so simple see here if I
873:09 - address the memory in terms of bite
873:11 - then I will have one bite of cell and
873:17 - there will be 2 to^ 16 this is 64 KB 2
873:21 - to^ 16 number of
873:25 - words so number of words are given can I
873:30 - find the address bit yes it will require
873:33 - 16 bits of
873:35 - addresses so n equals to 16 bit for B
873:38 - View and if I ask you for the word view
873:41 - then each cell in the memory consist of
873:44 - four byte so how many words I will
873:48 - require to address the full memory let's
873:51 - say the number of word I require is X
873:53 - each word has 4 byte and what is the
873:55 - size of memory 64 KB from B to B I got
873:58 - it cancelled and this is 16k
874:03 - and 16 can be written as 2^ 4 and this K
874:06 - can be written as 2^ 10 which means 2^
874:08 - 14 worlds are requir to address this uh
874:11 - to complete this whole memory so 2 to^
874:14 - 14 how many bits I will require 14
874:18 - bits okay so this is how it works let me
874:22 - repeat again how did I solve this so
874:24 - what does bite view say bite view says
874:26 - that one cell of a memory consist of one
874:29 - bite and what does word view say one
874:31 - cell of memory consist of one word and
874:33 - the word length is given to you word
874:36 - word length says the one word consist of
874:38 - four bytes so one cell of a memory
874:40 - consist of four bytes and you have 64 KB
874:44 - memory to complete or you have to 64 KB
874:47 - memory to address and each cell has 4
874:49 - byte so how many blocks you will require
874:51 - see each block has a size of 4 byte
874:54 - let's say I require X block to access
874:56 - the 64 KB memory so from here I can find
874:59 - that I require 2 to power 14 blocks
875:02 - or 14 words and to address these two 14
875:05 - words I should have 14 bits in my
875:08 - account so this 14 bits is required for
875:11 - word view now let's say I'm asking you
875:14 - for the bite view what does bite view
875:16 - says that one cell of a memory consist
875:18 - of one
875:20 - bite one cell of a memory consist of 1
875:22 - bite and my memory size is 64 KB I have
875:26 - block size of 1 bite and let's say I I
875:29 - have X blocks to access 64 KB memory how
875:33 - much block I require what is the value
875:34 - of x it's so simple 2^ 6 into 2^ 10 it
875:38 - is 2^ 16 which means I should have 16
875:41 - bits in my account to address these 2
875:44 - power 16
875:48 - blocks that's how I got 16 bits address
875:51 - for the bite View and 14 bit for the
875:52 - world view
875:55 - okay bite view means one word is one
875:58 - bite and word view means one word is
876:00 - given number of bytes I hope you got the
876:02 - point what does bite view say each word
876:05 - is one bite and what does word view say
876:07 - each word is given number of byes here
876:09 - each word is of four bytes okay so n is
876:12 - the total number of
876:14 - words and if I say one word equals to 8
876:17 - byte then this each cell in the block
876:20 - consist of 8 byte so same question if I
876:23 - ask you that if I say the word length is
876:25 - changed to 8 by then what will be the
876:27 - answer how many block of size 8 by are
876:31 - required to access the whole memory of
876:33 - 64 KB I'll just cancel the B to B and
876:36 - then
876:37 - 88s are 64 so I'll write 8 K which is 2^
876:41 - 3 into 2^ 10 2^ 13 so I should have 13
876:46 - bits in my account to access 2^ 13 words
876:50 - or 2^ 13 blocks or 2^ 13 cells of a
876:54 - member okay let's solve some other
876:56 - questions n = to 23 bits which it says
876:59 - that the address or 23 bits are required
877:03 - to address one block of a memory so from
877:06 - this I can tell that there are two ra
877:09 - to^ 23 words present in the memory and
877:12 - the size of each word is four bytes four
877:16 - bytes so if I say how many number of
877:18 - words are present then 2^ 23 words are
877:21 - present and what is the size of memory
877:23 - the size of memory is 2^ 23 23 into 2^ 2
877:29 - bytes which is 2 25 bytes which is two
877:32 - which is 2^ 5 into 2^ 20 byes this 2^ 20
877:36 - can be written as M and this 2^ 5 is 32
877:39 - so my memory size is 32
877:42 - MB okay now this is a homework question
877:45 - for you you have to find
877:47 - if the number of words are or the memory
877:50 - size is 8 gabit and each word have 64bit
877:56 - length then what is the number of words
877:58 - in bite View and world view world view
878:00 - and bite View
878:02 - so whatever we have discussed till now I
878:04 - think we should revise that okay so this
878:08 - is what memory is it is prime memory RAM
878:11 - R cach registers Ram is connected with
878:13 - address bus control bus and uh datab bus
878:16 - address bus brings the address from the
878:17 - CPU databas helps to transfer the
878:20 - content from RAM and CPU for let's say
878:22 - if I'm reading then databas transfers
878:24 - the content from Ram to CPU if I'm
878:26 - writing then databas transfer the
878:28 - content from CPU to Ram read and write
878:30 - are the control signal and Chip select
878:32 - says power on or power off linear one
878:34 - dimensional view of memory memory
878:35 - consist of these cells or blocks which I
878:38 - a word each word can be of either one
878:40 - bite or more than one bite if it is of
878:42 - one bite then I can say the memory is
878:43 - byte addressable if it is of more than
878:45 - one bite then I can say memory is word
878:48 - addressable okay the size of each word
878:50 - is mbit so M bit is the word length and
878:54 - if I have X bit address with X bit I can
878:57 - generate 2 to^ x unique addresses so I
878:59 - can address 2 power x blocks or I can
879:03 - address 2 power x cells or words each
879:07 - are the same thing now memories is
879:09 - specified using number of words into
879:12 - width of word so if I have let's say n
879:14 - number of words and the width of each
879:15 - word is M so I have n into m is the size
879:17 - of
879:18 - memory if I have uh total number of
879:21 - words are n then to find the address I
879:23 - will have to take log to n okay what is
879:26 - the relation between n and M just take
879:28 - the log so see what I want to tell you
879:31 - is do not remember anything it is just
879:33 - common sense do not remember
879:37 - anything so we learned about bite View
879:39 - and worldview how the things work uh try
879:42 - to solve this these four questions how
879:44 - many questions 1 2 3 and four try to
879:47 - solve these four questions by your on
879:49 - your own and this homework question
879:51 - also memory management part two let's
879:54 - say the size of address is 18 bits and
879:58 - the world length is of 24 bits so I can
880:00 - say
880:01 - each cell in the memory is of six bytes
880:05 - so n equals to 18 bits the number of
880:08 - words will be 2 to^ 18 so I can say the
880:11 - memory size is 2^
880:14 - 18 into 6 bytes for each word so this is
880:18 - the memory capacity any memory word you
880:20 - want to refer pass the address to
880:22 - address bus from address bus the address
880:25 - will be taken to the memory and that
880:27 - word the word with that memory location
880:30 - or that address will be activated and
880:32 - the content of that word will be taken
880:35 - from memory location to CPU with the
880:38 - help of databas these are control
880:40 - signals read and write are control
880:41 - signals so 01 is for the write operation
880:44 - and 1 Z is for the read operation
880:46 - there's nothing like one one or 0 0 what
880:49 - is bus bus is a group of wires and each
880:51 - wire can carry a bit so bus is nothing
880:54 - but a group of wire and what is the
880:56 - purpose of this chip select power on
880:59 - button that should be one and if chip
881:01 - select is zero which means the memory is
881:03 - powered off so what operation we can
881:06 - perform we can perform either read or
881:07 - write to perform any operation pass the
881:10 - address to address bus and that word in
881:11 - the memory will be activated pass the
881:13 - control signal either 1 0 or 01 1 Z is
881:16 - for read and 01 is for WR and then from
881:19 - databas content which may include data
881:22 - or instruction will reach the CPU send
881:24 - the address to address bus that word
881:26 - will activated and the that content will
881:28 - be sent from memory location to CPU with
881:30 - the help of data
881:31 - this these are the control signals one Z
881:34 - means read 0 1 means write chip select
881:37 - if zero then memory is powered off if
881:39 - one then power
881:41 - on okay so this is like an 7bit address
881:46 - to refer 128 words chip select one chip
881:49 - select two either you want to read or
881:50 - write address for address bus now what
881:53 - is this this is the capacity of memory
881:55 - 128 refers to 128 bit and this is the
881:59 - size of each word the size size of each
882:01 - word is 8 Bits which means 1 byte so I
882:04 - can see the memory size is 128 byte here
882:07 - one word equals to 1 by so this is a ram
882:11 - this is a Blog diagram of typical Ram
882:13 - chip what is included here chip select
882:15 - control signals address and datab bus
882:18 - address bus and datab
882:20 - bus now comes the part of loading and
882:25 - linking loading versus linking let's say
882:28 - I create a file named test.c compile it
882:31 - and compiler converts it into exe
882:34 - consist of instruction and data and
882:36 - where this ex is stored it is stored at
882:38 - the dis now it is the responsibility of
882:42 - loader to load that program from disk to
882:45 - main memory and from Main memory CPU
882:47 - will execute it so this is what we have
882:50 - learned already in our lecture one
882:52 - stored program concept one human
882:54 - architecture loading loading consist of
882:57 - or loading can be divided into two
883:00 - static and dynamic
883:01 - as the name suggest static which means
883:03 - the whole program is loaded in memory
883:05 - before
883:08 - execution and what is dynamic on demand
883:11 - loading let's take an example see this
883:14 - is our program okay
883:17 - and we start executing this main if do
883:21 - condition now we got a function and
883:23 - function is defined in some another
883:25 - program let's say now this program will
883:27 - also be
883:28 - loaded this program will get exec uted
883:32 - some G function is there defined in some
883:34 - other program now this program is
883:36 - getting loaded G is being executed now H
883:38 - comes defined in some other program now
883:41 - this program is being loaded so in this
883:43 - way when it is required then load this
883:45 - is what we call as Dynamic loading and
883:48 - loading the whole program this all four
883:52 - into main memory at once is called as
883:54 - static loading so by seeing you can say
883:57 - that what is the drawback of this uh
883:59 - static loading suppose
884:01 - if I write a condition here if condition
884:04 - and if condition is not fulfilled
884:06 - then we are not going to execute this F
884:09 - function so let's say the condition
884:11 - fails so this part will won't be
884:13 - executed and only this program will be
884:15 - executed but what we did in static
884:17 - loading we have loaded all three of all
884:21 - of them all of them into the main memory
884:24 - and these three are useless now they are
884:27 - just causing the wastage of a space so
884:30 - in that that case static loading is a
884:33 - bad choice because what is the drawback
884:36 - possible wastage of space ineffective
884:39 - utilization in case of condition or know
884:42 - at runtime because this condition will
884:44 - be run at runtime and at run time we are
884:46 - going to know if this function will be
884:49 - run or
884:51 - not that's where the static loading lags
884:53 - behind and what is the and what is the
884:56 - advantage of static loading the
884:58 - advantage is obviously faster execution
885:00 - let let say the condition is fulfilled
885:02 - now in Dynamic loading it take time to
885:05 - load the program from disk to memory it
885:09 - take time to load program for dis to
885:10 - memory so when all these program will be
885:12 - loaded it will cause time so Dynamic
885:17 - loading cause slower execution and
885:20 - static an static the whole program is
885:22 - loaded in memory before execution so if
885:25 - needed then every program is there at
885:28 - present there's no need to call them
885:29 - there's no need to bring them them from
885:31 - hard disk to memory all of them are
885:33 - actually present in the memory so this
885:34 - will cause faster execution so faster
885:37 - execution is the advantage so I can see
885:39 - this static loading is time efficient
885:41 - but space inefficient see here let's say
885:46 - for dynamic loading I only need just 10
885:49 - KB of space to
885:50 - start and let's say if the condition
885:53 - fails then I will complete the whole
885:55 - program in just 10 KB but in static
885:58 - loading as I say you load the whole
886:00 - program at once so I need 10 + 5 15 15
886:04 - and 15 30 30 and 20 50 KB of memory to
886:08 - start the program let's say the
886:10 - condition fails here also I did not
886:13 - require these three of them but they are
886:15 - still loaded into the memory so 40 KB of
886:18 - vage of SPAC is
886:20 - here
886:22 - okay now here should not be 40 KB it is
886:25 - 40 KB
886:28 - wastage as here you can see 10 + 5 15 15
886:32 - and 15 30 30 and 20 50 so 40 KB is
886:35 - wastage and 50 KB we require for
886:38 - Sal so if you want to save memory then
886:41 - go for dynamic loading which me which
886:42 - says loading on
886:44 - demand and you can guess no wastage of
886:47 - memory but it cause slower execution as
886:50 - it require only 10 KB of memory to start
886:53 - so this is what static and dynamic
886:55 - loading is in static loading you load
886:58 - the whole program at once in Dynamic
887:00 - loading you load load at
887:02 - demand in the last lecture we have
887:04 - studied about static and dynamic loading
887:07 - in this lecture we'll see what is
887:08 - linking so linking is the process of
887:10 - resolving external references what is
887:13 - external references suppose in a program
887:16 - whenever a compile compiler confronts a
887:19 - function which has not been defined
887:22 - before then what is what it will do see
887:26 - every function call is like a branch and
887:27 - goto statement Branch or goto statement
887:30 - so what compiler will do compiler will
887:32 - generate a BSA address and to where it
887:36 - has to jump that address will be left
887:39 - blank because it doesn't know where it
887:40 - is defined see this function f is
887:44 - defined after main so the compiler now
887:46 - here doesn't know where this function f
887:49 - is
887:50 - defined so it will leave a blank here it
887:54 - doesn't know where the SCF is defined it
887:56 - will leave a blank here so these blanks
887:58 - are unresolved references
888:01 - okay now there is also one thing which I
888:03 - want to clarify some students have
888:06 - misconception that compilation is start
888:08 - from Main this is completely false
888:11 - compilation start from the first line of
888:13 - the
888:14 - program then what does it start from
888:17 - Main execution is start from Main
888:18 - execution is start from Main compilation
888:20 - is start from first time of the program
888:23 - okay so now when the compiler first time
888:25 - confronts this function f it will
888:28 - generate a BSA
888:31 - that and it will leave blank blank to
888:34 - that blank this blank address is the
888:37 - address of where f is actually defined
888:39 - so it doesn't know where the f is
888:41 - actually defined so it leaves blank jump
888:43 - to F so compiler doesn't know this so it
888:46 - will leave it blank this is what
888:47 - unresolved reference is see here if this
888:52 - F has been defined before main function
888:56 - then compiler would have known the
888:57 - address that it has to jump here so it
889:00 - will write address of this part here but
889:03 - now compiler doesn't know where it has
889:04 - to jump it doesn't know where f is
889:06 - defined so it we leave blank
889:08 - here these blank are unresolved
889:11 - references
889:13 - okay for example if I use extern int x
889:17 - what does this say this say this integer
889:20 - X is present externally in some other
889:23 - file so it will leave blank here also so
889:26 - whoever address is the compiler don't
889:27 - know it will leave blank there
889:31 - so compiler will leave so many blanks
889:33 - while compiling the code blank for
889:36 - functions blank for external variables
889:37 - or
889:39 - objects so we need a we need someone to
889:42 - fill that blanks so here comes the
889:44 - Linker Linker is the module of operating
889:47 - system who is going to fill up these
889:49 - blanks okay so these blanks are filled
889:51 - up by
889:53 - Linker I already told you if this was
889:55 - the case that function f is already
889:57 - defined above then main comes and in
889:59 - main I use function f then the compiler
890:03 - will automatically fill up the address
890:05 - where it has to jump okay but now here
890:07 - it doesn't know where if is defined it
890:09 - will leave blank now we need someone to
890:11 - fill up those blank now comes the Linker
890:13 - to save us so linking can be of two type
890:16 - as it was loading it can be static or
890:19 - dynamic static linking is done before
890:22 - execution okay so what happens the UNL
890:26 - file which means the compiled file with
890:28 - blanks is the DOT obj file object file
890:33 - that contains unresolved references and
890:36 - that unresolved references when filled
890:38 - up by Linker which means linking is done
890:42 - then it becomes the exe file which is
890:44 - the result
890:45 - references okay so this is how aexe
890:49 - files look like main function function f
890:53 - is defined here and then scan of comes
890:55 - so how does exe file looks main at BX at
891:01 - X this function X is defined here and
891:04 - then in f i this function scan F will be
891:08 - converted into BSA y now this y will be
891:11 - the address where scanf is defined in
891:14 - this way okay so INE file all the
891:18 - external or unresolved references are
891:20 - resolved which means their addresses are
891:23 - put at the BSA parameter so now compiler
891:26 - can jump easily
891:31 - okay now what is the draw drawback is
891:33 - space in efficiency see Linker acts like
891:36 - a tailor what it do it Stitches the
891:39 - links of different pieces of clothes and
891:42 - here we can say the code to make it a
891:45 - meaningful
891:48 - program see here if Linker was not
891:52 - present to tell the compiler that this
891:54 - function f is defined here would it be a
891:57 - meaningful program no so Linker X like a
892:00 - tailor with with who stitches different
892:03 - pieces of clothes to make a meaningful
892:05 - fabric similarly Linker links different
892:07 - pieces of code to create or make a
892:10 - meaningful program in the next lecture
892:12 - we'll see what is dynamic linking or
892:14 - linking at
892:21 - runtime in the last lecture we have
892:23 - learned about static linking in this we
892:25 - are going to learn Dynamic linking that
892:28 - is how linking is done at the time you
892:30 - all know what is the meaning of linking
892:33 - resolving unresolved references giving
892:35 - the address to the BSA so now how does
892:38 - dynamic linking work with the help of
892:40 - stub what is St stub stub is a piece of
892:43 - executable code so I can say every
892:45 - unresolved reference which mean every
892:47 - blank address will be associated with a
892:50 - small piece of code known as Stu and
892:52 - that stuff is executable so at run time
892:54 - when that step will be
892:56 - executed at at run time when step will
892:58 - be executed it will activate the link
893:00 - Linker now it is responsibility of
893:02 - linker to find the address of that
893:04 - function in the memory and if that
893:07 - function is not present in the memory
893:09 - Linker will look for it in the compiler
893:11 - libraries compiler libraries that is
893:14 - present in the libraries that is present
893:17 - in the disk and if found there
893:20 - Linker will tell loader to load that
893:24 - module into the main memory okay so when
893:28 - this address will be found it will give
893:30 - it to the stub and now stub will provide
893:32 - it to the branch and save address so now
893:35 - here we got the address so this is how
893:37 - it works St and step executed at run
893:40 - time activates the Linker Linker found
893:42 - the address of function f in the main
893:44 - memory now that address will be given to
893:46 - step and step gives to the BSA that's
893:48 - how it work and I've already told you if
893:50 - function is not present in memory then
893:52 - Linker will look for compiler libraries
893:54 - on disk if found there then loader will
893:56 - load the module in the memory searching
893:58 - for addresses is the work of linkter
894:01 - loading the modules from disk to memory
894:04 - is the work of
894:06 - loader okay all modern system nowadays
894:09 - uses Dynamic linking and dynamic loading
894:11 - which means at
894:13 - runtime because that is space efficient
894:16 - you don't have to load the whole program
894:18 - in the beginning and but it is time
894:22 - inefficient okay so everything is done
894:24 - at run time so it take time at uh so it
894:27 - takes time to execute the full code
894:30 - code reusability is also a factor
894:33 - example scanf no need to give each
894:35 - function its own copy of scanf unlike
894:37 - static linking okay so we will load a
894:40 - single copy of scanf into memory and
894:42 - different function can call it we will
894:44 - give just the address of it instead of
894:46 - giving each function its own separate
894:48 - copy of scanner so this also provide
894:52 - reusability okay so modules libraries
894:55 - which are linked at runtime by Dynamic
894:56 - linking are generally called as dll you
894:59 - must have seen somewhere this uh like
895:02 - error the DL file is missing this type
895:05 - of DL file is missing so that is linked
895:08 - during runtime so these are Dynamic link
895:11 - libraries used in
895:16 - Windows and an important role that this
895:20 - Dynamic linking plays is it gives us the
895:22 - flexibility to change because modules
895:25 - are separate see application and their
895:27 - libraries are separately written they
895:29 - are not linked statically statistic
895:32 - statically which means we can change the
895:36 - library implementation without affecting
895:38 - the application
895:40 - see just like scanf we just give the
895:43 - address of it so address Remains the
895:46 - Same here is the library I we can change
895:48 - the Library without changing the
895:51 - application because what we have given
895:53 - in the application just the address so
895:55 - address Remains the Same what we change
895:57 - is the content of those Library so I can
896:00 - say that the library implementation can
896:02 - be changed without affecting the
896:05 - application so this is the flexibility
896:07 - that this Dynamic linking provides and
896:08 - why is it so because they are not linked
896:12 - statically suppose if they are just
896:14 - merged statically suppose they are
896:15 - linked statically all in one then can I
896:17 - change this no if I give just the
896:20 - address of it and here is the
896:22 - implementation in different uh place
896:25 - then I can say that I can change this
896:28 - Library implementation without affecting
896:30 - the
896:31 - application okay so I hope point is
896:33 - clear now what is the drawback of
896:36 - dynamic linking as everything is done at
896:38 - runtime so time will be the factor time
896:42 - inefficiency is present less
896:44 - Security in static the thing is complete
896:48 - everything is already there and have to
896:51 - do nothing at the run time are you
896:53 - getting the point see in security the
896:55 - problem happens where at runtime and if
896:59 - already has been done before nothing is
897:02 - we have to do nothing at the time then
897:04 - there is no loophole or vulnerability
897:07 - Concept in a static linking there is no
897:10 - vulnerability because nothing is done at
897:12 - the run
897:14 - time that's why Dynamic linking has less
897:18 - security okay so this was Dynamic
897:20 - linking in now let's see address
897:22 - binding Association of program
897:25 - instruction and data unit to memory
897:28 - locations what are we doing here we are
897:30 - associating instructions and data to
897:33 - memory locations memory location and
897:36 - that thing is known as address binding
897:38 - we are binding the address to whom
897:40 - instruction and data
897:43 - unit so binding is Association of
897:45 - attributes with
897:47 - entity suppose I write int X then here x
897:52 - is the variable or entity so what is the
897:55 - attribute associated with it name type
897:59 - value address size so the name is X that
898:02 - is name binding the type is int type
898:05 - binding value what is the value here no
898:09 - value is given to it so I can say
898:10 - garbage value or junk value what is
898:13 - address now this will be the address
898:16 - binding if I say that 4,000 is the
898:19 - address of this variable X variable X
898:22 - got binded with the address location
898:24 - 4,000 this is what address binding
898:27 - is are you getting the point giving
898:29 - address
898:30 - to instructions or data units this is
898:33 - what address binding is and what is
898:35 - binding binding is just the association
898:37 - of attributes with the entity here what
898:39 - is the entity X is the entity now if I
898:42 - give address to this entity say that
898:44 - this address is stored variable X is
898:47 - stored at memory location 4,000 now what
898:50 - I have done I have binded the variable X
898:53 - or entity x with a location 4,000 so
898:56 - this is what address binding is so we
898:59 - were seeing the that job of linker is to
899:01 - find addresses of these external objects
899:04 - functions or
899:05 - variables what was address binding
899:08 - address binding was associ of
899:09 - Association of program instructions and
899:12 - data units to memory locations okay
899:15 - Association of program instructions and
899:18 - data units to memory locations okay now
899:21 - let's see an example here I declare int
899:24 - a b and c a is given value equals to 1 b
899:28 - equals to 2 and C is the sum of a and B
899:31 - so
899:31 - let's break it into low level
899:34 - instruction one says store the value or
899:37 - store the constant one into variable a
899:41 - store constant 2 into variable B now
899:45 - load the value of a into R1 and load the
899:47 - value of B into R2 add R1 + R2 and store
899:50 - the result in R1 and then store the
899:53 - value of R1 into C and now we got c as
899:57 - sum of A and B so this is how
900:01 - this program this high level program is
900:03 - broken into low level so let's say this
900:06 - A B and C are they're in the memory
900:09 - location let's say at a equals to0 B is
900:11 - at 2 C is at location 4 so this is what
900:15 - data units are and these instruction
900:18 - will also be stored somewhere so these
900:20 - instructions are are the program
900:23 - instructions so Association of data
900:26 - units and program instruction
900:31 - to memory location so these are the
900:33 - memory location this is what address
900:35 - binding is okay so I took an example to
900:38 - show you how data units and instructions
900:40 - are stored in memory and giving them
900:42 - addresses is what address binding is so
900:45 - binding instruction and data unit to
900:47 - memory location is address binding now
900:49 - Comes The Binding time time at which
900:53 - binding take place does The Binding take
900:55 - place at compile time load time or run
900:58 - time so depends on which type of binding
901:01 - we are doing for example name binding
901:03 - the name binding is done at compile time
901:06 - type binding I write int X so I assign a
901:10 - name X to this variable so this is what
901:13 - name binding is and is done at compile
901:15 - time I'm assigning a type of this I'm
901:18 - assigning a type to this variable so
901:20 - this is what type binding is this is
901:23 - also this is also a compile time now
901:25 - comes the address binding so address
901:27 - binding is done at load time variable X
901:31 - get associated with memory location at
901:33 - load time and what is value binding when
901:37 - this in Tex will get a new value when it
901:39 - will
901:40 - happen let's say I write X = to 1 so
901:44 - this instruction will be executed to get
901:47 - its value so one will be stored at
901:49 - memory location X when this will happen
901:51 - when it will be executed so for
901:55 - execution we need runtime so that's why
901:58 - value binding is done at runtime and
902:00 - size binding same as
902:02 - compile okay so you have to remember
902:04 - this name binding type binding size
902:07 - binding this is what it's done at
902:09 - compile time address binding is done at
902:11 - load time and value binding is done at
902:13 - run time okay types of binding static
902:17 - binding and dynamic binding static
902:20 - binding says Association cannot change
902:23 - Dynamic binding says Association can
902:26 - change okay let's say entity is a person
902:30 - entity is a person I assign a name to a
902:33 - person let's say your name is
902:37 - Rahul okay so from the birth to that to
902:41 - death your name will remain same or
902:43 - let's say let's take an example of your
902:46 - fingerprints your fingerprints will
902:48 - remain same they will they are unique
902:49 - and they will remain
902:51 - same this is what static binding is the
902:54 - attribute which remain same to the whole
902:57 - lifetime these are static attributes and
903:01 - static binding and the attributes which
903:03 - changes with time are Dynamic binding
903:06 - for example age binding that is
903:09 - dynamic so I can say name attribute is a
903:12 - static type is a static if I say int X
903:16 - then name X is a static int this will
903:20 - remain same address will remain same
903:22 - value can be changed if I say x = to 1
903:24 - in the next line I can say x = to 2 then
903:27 - the value of x initially was 1 and it
903:29 - got change to two so value can change
903:32 - that's why it is dynamic and size can
903:35 - the size of X differ no it is defined at
903:39 - the compile time so this static size is
903:41 - also static so after of these attribute
903:43 - name type address value and size only
903:45 - value is dynamic
903:48 - okay now let's see the type of address
903:51 - binding based on time first is compile
903:54 - time address binding if addresses of
903:56 - data units and instructions are decided
903:58 - by the compiler then and it is compile
904:00 - time binding and that is purely static
904:03 - so compile time binding says the
904:05 - addresses of data unit and instructions
904:07 - are decided by compiler then it is
904:09 - compile time Bing what is load time
904:12 - compiler will not generate or associate
904:15 - the address loader will do so this is
904:17 - what load time
904:20 - binding here is a
904:23 - example so now what loader will do let's
904:26 - say there are three instructions with me
904:28 - so loader will generate let's say
904:33 - offsets now we'll see load time compile
904:35 - binding in this compiler does not
904:38 - generate or associate addresses loader
904:40 - will generate compiler will generate
904:42 - offsets which are not real addresses
904:45 - let's say the i1 is always at zero this
904:48 - is the first instruction now the
904:51 - instruction two will be stored at 0 plus
904:54 - size of i1 let me explain this is where
904:57 - the i1 is stored zero now now
904:59 - instruction two will be stored where
905:01 - after instruction one get completed so
905:03 - it will be stored at the size of I and
905:08 - where it does I3 will get stored I3 will
905:10 - get stored at
905:12 - here what is the address of this part
905:15 - size of i1 plus
905:16 - I2 so these are the offsets generated by
905:19 - compiler and it will be communicated to
905:22 - memory manager that is the OS module now
905:25 - memory manager will give the address of
905:26 - Base
905:27 - register base register says
905:30 - the instruction i1 is stored at 6,000
905:32 - these are not the real addresses these
905:34 - are just offset so what I will do I will
905:37 - say that i1 will be stored at
905:39 - instruction 6,000 because this is what
905:41 - the value of base registor is now I2
905:45 - will come at 604 this is what the size
905:48 - of i1
905:49 - is okay now I3 will come at 6,8 this is
905:54 - what the size of i1 + I2 is are you
905:57 - getting the point now they are the real
905:59 - addresses
906:01 - let me repeat again what happens at
906:02 - compile time the addresses and data unit
906:05 - instructions are decided by compiler and
906:08 - it's compile time binding what what does
906:10 - load time binding say it says that
906:12 - offsets are generated by compiler and
906:15 - then loader will assign the real
906:17 - addresses based on communication with
906:19 - memory manager what is the base register
906:22 - value adding the offset to that base
906:24 - register value loader will find the real
906:26 - addresses this is how it's
906:28 - done so so this was compile time and
906:31 - load time binding now we will see what
906:32 - is runtime address binding and one more
906:35 - thing during execution instruction and
906:38 - data unit does not change at load time
906:41 - and compile time binding let's see an
906:44 - example suppose these were the
906:46 - instructions of a
906:48 - process in the memory now what happens
906:51 - the process is swept out it is sent to
906:53 - the
906:54 - disk so what happens in
906:57 - static address binding this will remain
907:02 - empty this will remain empty addresses
907:05 - cannot change here and when swed in it
907:07 - will be assigned to the same addresses
907:09 - so when the swapping swap they will be
907:11 - spped in where will instruction V in
907:13 - come here instruction to here
907:15 - instruction three instruction four this
907:18 - is how they will come they won't change
907:21 - the address from there from where they
907:23 - were swept out the exact same location
907:26 - they will be swept in and now you have
907:28 - gu guessed what what would have happened
907:30 - at runtime address binding it is also
907:33 - done by loader itself but when this when
907:36 - the instructions are spped in they can
907:38 - be loaded to a different place so
907:40 - addresses can change during execution so
907:44 - this is a kind of good thing because it
907:46 - gives relocation flexibility now let's
907:49 - revise what we have learned till now
907:51 - what is address bending assigning
907:53 - addresses to instructions and data unit
907:56 - of a program okay so what are data units
907:59 - and instructions suppose this was our
908:01 - program when it is broken down into low
908:03 - level these variables are the data units
908:07 - like a is stored at address Zer B is
908:10 - stored at address 2 C is stored at
908:12 - address 4 so these are the data units
908:15 - assigning addresses to them is address
908:17 - binding these are the instructions these
908:19 - i1 I2 I4 I5 I6 these are the
908:21 - instructions so assigning addresses to
908:23 - them is what address binding is okay now
908:27 - it is not just the address binding
908:29 - different attribute is associated with
908:31 - different kind of binding for example
908:32 - name binding type binding address
908:34 - binding value binding and size
908:37 - binding so now the question arises which
908:39 - type of binding happens at which
908:42 - time either it is compile time load time
908:44 - or run time so I can say name type and
908:47 - size
908:49 - name type and size happens at load time
908:54 - happens as compile time sorry and
908:56 - address binding address binding happens
908:58 - at load time and value binding happens
909:00 - at runtime why run time because for
909:03 - Value to be assigned this instruction
909:05 - should be executed and execution happen
909:08 - when when we run the program that's why
909:10 - values assigned at run time types of
909:12 - binding static and dynamic in static
909:14 - type of binding Association do not
909:16 - change in Dynamic binding they change
909:19 - for example we have seen that uh in
909:22 - compile time and loow time
909:24 - binding if the instructions of a process
909:27 - are swapped out then this place will
909:29 - remain empty and when it's time to bring
909:33 - them back then they will be brought back
909:36 - to the same exact location so this is
909:38 - what static binding is they cannot
909:41 - change the value of the
909:42 - addresses but what happens in the
909:44 - dynamic type of binding if you are
909:46 - swabbed out from some location then it
909:48 - is possible that you can be swabbed in
909:51 - at different memory location this is
909:54 - what relocation flexibility is so in in
909:56 - Dynamic binding Association can change
910:01 - okay so name static name binding is
910:04 - static type binding static address
910:05 - binding is generally static value
910:07 - binding is dynamic because value can
910:09 - change size binding is static now the
910:11 - question arises if we say address
910:13 - binding is static then what about run
910:15 - time address binding which we have just
910:17 - seen now there the address got changed
910:20 - that's what we generally talk about
910:21 - address binding can be static okay so
910:24 - here I can change it to static static or
910:28 - dynamic
910:29 - okay so this is what general thing is
910:31 - generally we talk about compile time and
910:33 - load time but if we are focusing on
910:36 - runtime address binding then that will
910:38 - be
910:39 - dynamic types of address binding we have
910:41 - seen compile time addresses of data
910:44 - units and instructions are decided by
910:46 - compiler load time loader will assign
910:49 - the addresses based on communication
910:51 - with memory manager memory manager will
910:54 - have given loader the base register and
910:57 - loader will add the offsets generated Ed
910:59 - by compiler to the value of Base
911:01 - register to get the real addresses okay
911:05 - now we have learned about runtime
911:07 - address bending let's see how a program
911:10 - is completely executed multi-step
911:12 - processing of a user
911:14 - program okay let me okay multi-step
911:17 - processing of a user program Here Comes
911:19 - The Source program do c do c compiled
911:23 - compiler assem assembler this is compile
911:25 - time here we get object module obj this
911:28 - is not linked this is connected with or
911:31 - this has unresolved references now it
911:34 - comes or it goes to the linkage editor
911:37 - the Linker here will fill up the blanks
911:40 - it will send to the load module exe will
911:42 - be loaded into the main memory and now
911:46 - this was the program till now now it
911:48 - becomes the process now this process
911:50 - will be executed by CPU okay so what's
911:53 - written here Library function other
911:55 - object module given to the linkage as
911:57 - I've told you if it is if the addresses
912:00 - are not found in memory then it will uh
912:02 - search for libraries at the
912:05 - disk okay so this is how a program is
912:09 - executed so if I say address binding
912:12 - then this is the compile time address
912:14 - binding this is load time binding and
912:15 - this is the runtime binding so when does
912:18 - runtime binding
912:19 - happens during the execution time okay
912:23 - so now in the next lecture we will
912:24 - actually start our memory management
912:28 - techniques the memory management
912:30 - techniques can be segregated into two
912:32 - part the first one is contiguous and the
912:34 - second one is non-contiguous
912:36 - non-contiguous means distributed and
912:39 - contigous means centralized let's take
912:40 - an example suppose in disk this is our
912:43 - program it's of 100 KB so when we have
912:46 - loaded the whole program at one place
912:49 - the whole program at one place that
912:51 - means all 100 KB at one place this is
912:53 - what centralized
912:55 - allocation and when we have loaded we
912:58 - have broken the program into three parts
912:59 - 40 KB 40 KB and 4 KB and stored them at
913:03 - different places this is what
913:05 - distributed or non-contiguous memory
913:08 - allocation
913:09 - is okay so we will learn about
913:12 - overlays partitions variable and fixed
913:15 - body systems paging segmentation
913:18 - segmented paging demand paging all these
913:20 - things we are going to cover in this
913:21 - memory management section so these are
913:24 - the old techniques which is overlays
913:26 - partitions Bud systems these are the old
913:29 - techniques this body system we are going
913:30 - to cover in our miscellaneous topics in
913:32 - the end okay overlays and partition we
913:35 - will cover in this
913:38 - lecture so these are the old techniques
913:40 - but we have to study them because memory
913:43 - management fundamentally started from
913:45 - these well we know that these are the
913:47 - new techniques but the memory management
913:49 - fundamentally started from this if you
913:52 - remember in our science
913:53 - classes when we used to study atomic
913:56 - structure we also studies the Thompson
913:59 - Plum ping model we studied that raford
914:01 - model in the end we knew that these were
914:04 - the wrong but we still studied because
914:07 - the final thing fundamentally rise from
914:10 - the old things or the old theories
914:12 - that's why we are studying overlays
914:14 - partitions and body system okay
914:18 - so this all thing is managed by a module
914:21 - of operating system which is memory
914:24 - manager so now we will study the
914:26 - function and goals of memory manager the
914:28 - first thing is allocation before loading
914:30 - the process you have to first allocate
914:32 - the
914:33 - memory so this is what the memory
914:37 - manager helps with it helps with the
914:39 - allocation of which color I should
914:45 - choose I think this would be better
914:48 - before loading the process the process
914:50 - you have to first allocate the memory so
914:52 - this memory allocation is managed by
914:54 - memory manager
914:56 - protection suppose this is what uh
914:59 - memory looks like this is the system
915:00 - area user area with different processes
915:02 - in between now a process should not
915:06 - interfere with the space of different
915:09 - process so area of memory where program
915:11 - is loaded is the program address space
915:13 - so this is what the address space of P3
915:15 - this is what the address space of P2
915:17 - address space of
915:20 - P1 so P3 is address space should get its
915:24 - instruction executed in its own address
915:26 - space only and should not interfere with
915:29 - the addresses space of some different
915:30 - process so there should be no
915:32 - trespassing who handles this the memory
915:34 - manager so it is the task of memory
915:36 - manager to allocate the memory it is the
915:39 - task of me memory manager to ensure that
915:41 - there is no trespassing of instruction
915:43 - between the processes address
915:46 - space Free Space Management as the name
915:48 - suggest managing the free space address
915:51 - translation I hope you remember the
915:53 - logical address and physical address
915:55 - thing so the address translation is
915:57 - managed by memory manager and
915:59 - deallocation when the process is
916:02 - completed deallocating the memory the
916:05 - process has to return the resources the
916:07 - return the memory so that is all managed
916:09 - by memory
916:11 - manager now what are the goals of memory
916:14 - manager it works to minimize wastage to
916:17 - utilize the memory
916:19 - effectively okay so this is what
916:21 - fragmentation is we call in in memory
916:23 - management term we don't call it wastage
916:25 - we call fragmentation internal
916:28 - fragmentation external fragmentation
916:29 - we'll see it later but the vage has a
916:32 - new term here that is
916:34 - fragmentation okay ability to manage
916:37 - large program in small memory areas yes
916:39 - this is important suppose our memory is
916:43 - just of uh let's say here is the example
916:46 - here's the example given this is dis I
916:49 - have a program of 100
916:51 - KB but the free space I have only of 60
916:54 - K so by stalled program concept what we
916:57 - have to do we have to load the program
916:59 - into the main memory but can we do this
917:01 - can we do can we load the whole program
917:03 - into main memory no by stored program
917:06 - concept we cannot but we can with the
917:09 - help of virtual memory and overlays
917:12 - we'll see what is virtual memory and
917:13 - overlays in few
917:14 - minutes so what is the goal again
917:18 - minimize fragmentation and secondly
917:20 - manage larger program in small memory
917:25 - areas okay so this means operating
917:28 - system can load more program in
917:30 - memory and this actually means degree of
917:32 - multiprogramming increases and you all
917:35 - know if multiprogramming increases which
917:37 - means efficiency and throughput
917:39 - increases so this memory management or
917:42 - memory manager is a critical module of
917:45 - operating
917:46 - system now let's understand what is
917:50 - overlays take an example this is a
917:53 - assembler architecture this is what
917:55 - assembler
917:57 - is okay it has a pass one pass two pass
918:00 - one of 70 KB pass two of 80 KB don't
918:03 - worry if you don't know what is pass
918:05 - they will learn that in detail in our
918:08 - compiler design course so pass one has
918:12 - 70 KB Pass 2 has 80 KB symbol table
918:15 - common routines and overlay loader these
918:18 - are of 30 KB 20 KB and 10 KB
918:20 - respectively now the whole size of this
918:23 - assembler is 210 KB so to to convert any
918:27 - program into Assembly
918:30 - Language using this assembler we need
918:33 - 210 KB memory but what
918:36 - happens we had some budget constraint
918:39 - and we can only have a 150 KB memory
918:44 - now can we somehow convert a pro convert
918:48 - a or can we somehow use this assembler
918:50 - on this 150
918:53 - KB given that this is a two pass
918:55 - assembler that is two stage assembler
918:58 - and pass one and pass two are
919:00 - independent there's no relation between
919:02 - pass one and pass two we need one at a
919:04 - time so can
919:07 - we execute or can we use this assembler
919:11 - on this 150 KB yes we can so the main
919:14 - idea is complete pass one first and then
919:16 - replace it with the pass two as both are
919:18 - independent so what we have done this 3
919:21 - 4 5 which means uh the symbol table
919:24 - common routines and overload overlay
919:26 - loader this is necessary for everything
919:29 - this is necessary for every pass so what
919:31 - we have done we have kept it intact but
919:34 - as soon as pass one is executed what is
919:36 - the size of pass one it is 70 KB so the
919:39 - size of symbol table overlay and this
919:41 - complete size is 60 KB only so we have
919:43 - given at 60 KB now we are left with 90
919:46 - KB so first we have loaded pass one into
919:48 - it pass one into it pass one will be
919:51 - executed because it has everything to
919:54 - execute pass as soon as pass one is
919:56 - executed we will replace pass one with
919:58 - pass
919:59 - to so this is what overlays overlay
920:02 - means replace and it is possible only if
920:05 - program is divisible into independent
920:06 - modules so what does overlay say overlay
920:09 - say if you are running short of memory
920:11 - and you have some uh parts of a program
920:13 - which can run independently then replace
920:17 - as soon as one part is completed so this
920:19 - is what overlay
920:21 - is let's solve an let's understand
920:24 - overlay more with the help of an example
920:26 - suppose this is a program EXP added as a
920:29 - overlay tree and the size of a program
920:31 - is 92
920:33 - KV now tell me the minimum memory
920:36 - required to successfully execute this
920:38 - program using overlays you know what
920:39 - does overlay say search for the program
920:43 - units that are independent of each
920:46 - other
920:48 - so I can I can do like
920:51 - this root A and D this can be given as
920:57 - pass one root root A and E this can be
921:01 - assigned the name of pass two
921:04 - because when this is being executed
921:07 - there are there is no need of keeping b
921:09 - c f g h i j d in
921:13 - memory A and B are independent A and C
921:17 - are independent B and C are independent
921:19 - D and E are independent E and F are
921:21 - independent F and D are independent so I
921:24 - hope you getting the point when root A
921:26 - and D are there there is no need of
921:29 - keeping this whole tree in the main
921:31 - memory so what we are doing we are
921:33 - giving every from every path from root
921:36 - to node as a pass so we can say this is
921:39 - pass one this is pass two this is pass
921:42 - three pass 4 pass Five pass Six and pass
921:46 - seven and each pass can be executed
921:49 - independently so what we'll say first
921:51 - execute this how much memory we require
921:53 - 10 + 8 + 5 8 and 5 13 13 and 10 23 so we
921:57 - need 20 3 KV memory to execute pass 1
922:01 - for pass two 10 18 and 8 which means 8
922:04 - and6 so 26 KB memory required
922:09 - here 8 and 6 uh sorry 10 and 6 16 16 and
922:13 - 10 26 26 required here 10 and 7 17 17 +
922:17 - 12 29 29 K be required at pass 7 10 and
922:21 - 7 17 17 and 27 required at pass six 10
922:25 - and 7 17 17 and 9 it is I think 26 so 26
922:30 - can be required at pass five so I can
922:34 - say minimum memory required is maximum
922:37 - of memory required from pass 1 to pass 7
922:39 - that will be the minimum memory so the
922:42 - maximum memory required was at pass 7 so
922:44 - I can say if I have 29 KB of memory then
922:47 - we can execute this whole
922:51 - program without any problem so the size
922:55 - of program you can see was 92 KB but but
922:58 - we we were able to execute the whole
923:00 - program in just 29 KB how were we able
923:03 - to achieve this using overlays replace
923:06 - replace replace which is not us used
923:09 - here so let me explain you again so if
923:12 - you are executing this there is no need
923:14 - to keep this part and this part in the
923:15 - main
923:16 - memory okay now comes the partitioning
923:20 - partitioning means breaking the user
923:23 - space into
923:25 - cells so partitioning says they can be
923:28 - different type of partitioning fixed
923:29 - partitioning and variable partitioning
923:31 - we are first going to study fixed
923:34 - partitioning multiprogramming with fixed
923:36 - task you will get the idea why we have
923:39 - said multiprogramming fixed task in few
923:41 - minutes so what we have done this is our
923:43 - system area this is our user area let's
923:45 - expand this user area so what we have
923:47 - done we have divided this user area into
923:50 - different blocks they can be have
923:52 - different size but what we have done we
923:54 - have divided the user area into
923:55 - different blocks or different segments
923:58 - so we will divide it into fixed number
924:00 - of partitions and in each partition we
924:03 - are going to store a
924:07 - program a bigger program will be stored
924:09 - in the bigger partition and smaller
924:10 - program will be stored in the smaller
924:13 - partition so partition may be of
924:15 - different size but the important thing
924:16 - which you have to remember is only a
924:18 - single program can be stored in a single
924:20 - partition so there is a kind of one to
924:22 - one relationship here okay uh one to one
924:25 - relationship here so the size of program
924:28 - size of partitions can be different as
924:30 - program size are different so what we
924:33 - have learned till now partitioning can
924:35 - be of different type fixed partition
924:36 - variable partition in fix partition the
924:39 - pro the user area can be divided into
924:41 - different partitions of different size
924:44 - and each partition can stored only a
924:45 - single program and size of partition can
924:47 - be different because program size are
924:49 - different limit resistors it's a kind of
924:53 - resistor and what is what is the purpose
924:56 - of limit registor let's see here
925:00 - the purpose of limit register is to
925:01 - basically Define the size or instruction
925:04 - range of that
925:06 - process let's take an example suppose
925:08 - CPU generates an address of
925:13 - 2800 process Pi is running and it
925:16 - generates an address of 2800 but in main
925:18 - memory we have instructions of process
925:21 - Pi defined till 2500 only from 2,000 to
925:25 - 2500 let me Zoom it
925:29 - so it generates an address of 2800 but
925:32 - the process address space is from 2,000
925:36 - to 2500
925:38 - only now it is the responsibility of
925:41 - memory manager to ensure that because
925:43 - this 2800 can be the address space of
925:46 - some different process this Pi is being
925:49 - mischievous and it is trying to access
925:52 - the private address space of some
925:54 - different process so now it's the memory
925:57 - manager job to stop stop it how it's
925:59 - going to stop so what we have done the
926:01 - starting address is the Base address and
926:04 - this 500 is the limit so this 500 will
926:08 - be stored in the limit register so what
926:10 - happens the address comes here the
926:13 - firstly it will check
926:15 - is is the address greater than the Base
926:18 - address or greater than equal to the
926:19 - Base address because if it is less than
926:21 - equal to Base address then also Pi is
926:24 - trying to access the address space of
926:26 - some different process
926:28 - so first it will check if the address is
926:31 - of this area only how it will check it
926:33 - will first check if it is greater than
926:35 - 2,000 which means it of this part or
926:38 - not if no then it is a trap to operating
926:41 - system monitor addressing error and if
926:43 - yes if it founds that the address
926:47 - generated by the process consist of this
926:49 - area then it goes to the next phase it
926:52 - says the address you generated is it
926:55 - less than the base plus limit the
926:56 - address you generated is it less than
926:58 - this
927:00 - part which means now the address is
927:02 - confined to this area
927:05 - only but here what we see the address is
927:07 - of 2800 so here here it will say no the
927:11 - address is not less than 2800 is not
927:14 - less than 2500 so it will go here trap
927:17 - interrupt will generate saying
927:18 - addressing
927:19 - error now let's take an example suppose
927:23 - the address which is generated was
927:26 - 2100 now what happens it goes here it
927:29 - first check is 2100 greater than equal
927:31 - to 2,000 yes now it comes here it ask is
927:35 - 2100 less than 2500 yes then it can
927:40 - access so this is what limit register do
927:43 - this 500 is the limit register it is the
927:45 - size of the process address space and
927:48 - what does base register do it gives the
927:51 - starting
927:52 - address so this limit register done at
927:55 - the O voting time it used for
927:58 - partitioning so this is instruction
927:59 - range base plus limit architecture to
928:01 - ensure
928:03 - protection okay as we have CPU
928:06 - scheduling techniques we have techniques
928:07 - for partition allocation
928:10 - to partition allocation to suppose a new
928:13 - process comes uh a new program has 80 KB
928:16 - size we have to bring that into main
928:20 - memory now the main memory has different
928:22 - available partitions it has a partition
928:24 - of 200 KB it has a partition of 120 KB
928:27 - 70 KB 81 KB now in which partition it
928:31 - should go this is what partition
928:33 - allocation algorithm or partition
928:35 - allocation policy that we'll learn in
928:36 - the next
928:38 - lecture okay so now let's revise what we
928:41 - have learned till
928:46 - now memory management techniques consist
928:49 - of two part contigous and non-contiguous
928:51 - contiguous is when we bring the whole
928:53 - program at one place and non-contiguous
928:55 - ISS
928:56 - that it is
928:58 - dist it's first broken down and it is
929:00 - distributed at different locations of
929:01 - the memory now we have memory management
929:04 - techniques the old techniques include
929:06 - overlays partitions and body systems we
929:08 - have studied overlay what does overlay
929:09 - say we will see when the topic will come
929:12 - so these are the old techniques and
929:14 - these are the new techniques functions
929:16 - and goals are allocation protection and
929:18 - Free Space Management address
929:20 - translation deallocation goals is to
929:22 - minimize fragmentation and ability to
929:24 - manage larger program into smaller
929:26 - memory areas what does overlay say
929:28 - overly says that you don't need to take
929:31 - the whole program into main memory
929:32 - complete unit one first and then replace
929:35 - it with unit two as both are
929:37 - independent we have seen an example now
929:39 - partitioning partitioning of fixed
929:40 - partition we divide the whole program or
929:43 - the whole user area into different
929:45 - partitions and can they can be of
929:46 - different size limit what does limit
929:49 - register do it helps in the ensuring
929:51 - protection and now in the next lecture
929:54 - we'll learn
929:56 - how partitions are allocated see in CPU
929:59 - scheding what we have learned we have
930:01 - learned how from Main memory the which
930:04 - process should go to the CPU now in
930:07 - Partition allocation we will learn from
930:08 - hard disk at which place the pro the
930:11 - program should go
930:14 - okay now let's learn about partition
930:17 - allocation
930:19 - policy as we have different algorithms
930:21 - for CPU scheding similar way we have
930:24 - different policies named as first fit
930:26 - best fit next fit and worst fit let's
930:28 - see what they all
930:31 - say the first fit says search for the
930:35 - first slot or the first partition big
930:37 - enough to accommodate the program
930:39 - suppose here in the case for the first
930:42 - slot is 200 big enough to accommodate my
930:45 - program yes then according to the first
930:47 - fit policy this 80kb program will be
930:49 - stored at partition number one okay so
930:52 - 80kb program will be at 200 KB partition
930:56 - so 120 KB remain as waste because I have
930:59 - told you in Partition and program there
931:02 - is one to one
931:03 - relationship a program can be stored at
931:06 - only one partition or a partition can
931:08 - hold only one program so there's a one
931:10 - to one relationship and if 0kb program
931:14 - is stored in 200 KB partition then 120
931:17 - KB will go to waste that kind of wastage
931:20 - we call as internal
931:22 - fragmentation okay so in first fit what
931:24 - we do we search from the first partition
931:27 - in best fit what we do least internal
931:30 - fragmentation so here 80 KB can be
931:34 - stored at this part only 1 KB will be
931:37 - wasted here so which is the best fit
931:40 - here in such a way that the internal
931:42 - fragmentation or the wastage of memory
931:44 - will be least so least internal
931:46 - fragmentation smallest free partition
931:49 - big
931:50 - enough okay in first fit first free big
931:53 - enough in best fit smallest free big
931:55 - enough in next fit
931:58 - it works it works like the first fit
932:01 - search begins from the last location see
932:04 - in first fit we start from the first
932:06 - part in next fit we start from the last
932:09 - partition so next fit works like the
932:13 - first fit but here search begins from
932:15 - the last
932:16 - location and what does worst fit says
932:19 - largest big enough and what is the worst
932:21 - fit here the first fit is the 200 KB so
932:24 - let me revise again first free first fit
932:26 - says start from the first partition
932:29 - whichever partition is big enough to
932:30 - hold your program stored in that what
932:33 - does best fit say search all the
932:35 - partition and then calculate the
932:37 - internal fragmentation the partition
932:39 - with least internal
932:40 - fragmentation the program will be stored
932:43 - there now comes the next fit next fit
932:45 - says search from the
932:47 - last whichever partition is big enough
932:50 - to hold your program store there and the
932:51 - first F says search the all partitions
932:55 - whichever partition is maximizing the
932:57 - internal fragmentation that is the worst
933:00 - fit okay so in case of search in case of
933:03 - next fit search time can be saved and
933:07 - may work faster than first fit in some
933:09 - cases okay suppose uh here in this case
933:13 - first fit will be a bad choice next fit
933:18 - will be a good choice so doesn't matter
933:21 - much but here we say that the search
933:23 - time is less and it may F work faster
933:26 - than the first fit
933:28 - now we will learn about performance of
933:30 - fixed partition as we know fixed
933:32 - partition is static in nature so we can
933:34 - say internal fragmentation happens what
933:37 - is internal fragmentation suppose this
933:39 - is the partition size 1,00 KB and my
933:41 - program size is 1 KB only so the 999
933:44 - will be wasted that is internal
933:46 - fragmentation what is external
933:48 - fragmentation
933:50 - then external fragmentation says wastage
933:52 - of memory outside the partition but here
933:56 - in this fig partition
933:58 - there is no there is no such memory
934:00 - outside the partition see here this is
934:02 - memory divided into partition can you
934:05 - see a memory outside these partitions no
934:08 - each memory space is divided into
934:10 - partition so there's no memory outside
934:12 - the partition so I can say there is no
934:14 - external fragmentation in in case of
934:16 - fixed
934:17 - partition internal fragmentation
934:19 - obviously exists suppose I have program
934:21 - size of this much only so this whole
934:24 - Space is wasted internally so what is
934:26 - internal fragmentation vage of memory in
934:29 - the partition external fragmentation
934:30 - vage of memory outside the
934:33 - partition the degree of multiprogramming
934:35 - here is
934:36 - limited because the degree of
934:38 - multiprogramming is limited why because
934:40 - it is equal to the number of partition
934:41 - it cannot change it is
934:43 - limited okay maximum process size is
934:46 - also limited it is equal to the maximum
934:48 - partition size partition allocation
934:51 - policy which we follow is best
934:53 - fit so this was fixed partition in fixed
934:57 - partition the partition is of fixed size
935:00 - and each partition can hold a single
935:02 - program now comes variable partition as
935:04 - the name
935:05 - suggest partitions can be of different
935:08 - size depending upon depending upon
935:11 - process
935:12 - size multiprogramming with variable task
935:15 - here we say fixed partition as
935:17 - multi-programming with fixed task if you
935:19 - remember multiprogramming with fixed
935:20 - task now you may now you may have
935:23 - understood why we call it as fixed tasks
935:26 - okay because the degree of multi program
935:27 - in is limited here variable partition
935:31 - multiprogramming with variable task
935:33 - because we have Dynamic partitioning
935:35 - here this is let's say the process
935:37 - requirement P1 requires 35 kb of memory
935:40 - P2 requires 115 315 15 and 120 so
935:44 - initially no partition is there remember
935:46 - this point is important initially no
935:49 - partition is there the memory just like
935:51 - a free hole there is no partition now
935:55 - the partition is made ACC according to
935:58 - the process request when P1 comes 35 kb
936:00 - of partition is made when P2 comes 115
936:04 - KB more of partition is made P3 comes so
936:06 - partitions are made depending upon the
936:09 - process request and in the end the
936:12 - remaining area is just like a free hole
936:14 - if some another process come then
936:16 - another partition is
936:18 - made P2 and P4 have all its instruction
936:21 - executed so leave they will leave the
936:23 - memory uh let
936:25 - me okay so this is a case in which this
936:29 - process and this process has completed
936:31 - or has executed all its instructions so
936:34 - what they will do now they will leave so
936:36 - this is a free hole now here generated
936:39 - so this is P1 free hole 1 P3 free hole 2
936:42 - P5 free hole 3 now we have three free
936:44 - goals 115 KB 15 KB and 250 KB now a new
936:48 - process P6 comes with a request of 13
936:52 - KB now a request of P6 come with a
936:54 - request of 13 KB what we will do we will
936:57 - make a partition of 13 KB here in the
936:59 - free hole one and the remaining free
937:02 - hole of 102 KB and a new free hole will
937:05 - be created of 102 KB so this is what
937:07 - dynamic partitioning is
937:09 - there and the allocation how allocation
937:12 - is done same policies first fit next fit
937:16 - best fit and worst fit if I talk about
937:17 - first fit then this 13 KB is sent here
937:20 - new Partition is made of 13 KB at the
937:23 - free hole one if I talk about next fit
937:25 - then you search from the big from the
937:28 - last and if this free hole is able to is
937:31 - big enough to occupy this 13 KB then you
937:33 - create a new Partition here of 13 KV so
937:36 - if I talk about next fit then free hole
937:38 - 3 is suitable if I talk about best fit
937:41 - then free hole 2 is suitable you check
937:43 - all the free holes and whichever free
937:46 - hole is causing least external
937:49 - fragmentation
937:51 - here in that case in that
937:55 - case this is the best fit so if I bring
937:58 - down this here
938:00 - 13 now how much how much space is is
938:04 - remaining 2 KB spaces remaining and we
938:06 - know that uh if these are the normal
938:08 - size of the processes and by seeing that
938:11 - we can assume that that having a process
938:14 - with Just 2 KB size is
938:16 - very rare So this 2 KB space will remain
938:21 - as it is this is what external
938:22 - fragmentation
938:24 - is memory space outside the partition
938:27 - which cannot be used is what externally
938:29 - fragmented
938:31 - memory okay so which free hole cause the
938:34 - least external fragmentation this
938:36 - freeold 2 so the best fit is freeold 2
938:40 - now comes the worst fit it's of5 KB 15 K
938:44 - and 250 so this will be the worst fit
938:47 - now comes the performance issues
938:49 - internal fragmentation there's no
938:50 - internal fragmentation because
938:52 - partitions are made based on the process
938:55 - size so there can't be any inter
938:57 - internal fragmentation what is internal
938:58 - fragmentation in Partition when a
939:01 - process is able to occupy only this much
939:03 - space and you all know that a partition
939:06 - can hold hold only a single program so
939:08 - this space is wasted this is what
939:10 - internal fragmentation is and what is
939:11 - external fragmentation let's say this is
939:13 - the memory this is a partition or let's
939:16 - say this is the free hole I should say
939:18 - and these are the partitions already
939:19 - made here resides P1 here resides P2
939:21 - here is P3 now this is the freeold a
939:23 - process comes
939:25 - and creates a new part partion of here
939:29 - let's say P4 comes now there is some
939:31 - another process P5 but it cannot be
939:33 - accommodate in the this this partition
939:35 - space so this partitioner space is being
939:37 - wasted here this is what external
939:39 - fragmentation is what is external
939:41 - fragmentation memory wasted outside
939:44 - the partitions so this is what external
939:47 - fragmentation is let's discuss the
939:49 - performance issues external
939:51 - fragmentation yes it will cause external
939:53 - fragmentation internal fragmentation no
939:56 - so
939:58 - yeah see let's take an example this is a
940:00 - free hole one of 115 KB free hole 2 of
940:02 - 15 KB and free hole 3 of 250 KB now a
940:05 - new process comes which is a size of 280
940:07 - KB combining these these free holes have
940:10 - a much larger size is of 380 KB but what
940:13 - we are still telling this new process
940:15 - that memory is not available so the size
940:18 - of total free memory is greater than
940:20 - process request but it's still denied
940:23 - this is what external fragmentation is
940:25 - the size of total free memory is greater
940:27 - than the process request but we still
940:29 - deny the process that memory is not
940:31 - available this is what external
940:32 - fragmentation is degree of programming
940:34 - flexible maximum process size flexible
940:37 - partition allocation policy worst fit
940:40 - why worst fit because the worst fit will
940:42 - create the biggest free holes and if the
940:44 - freeh hole size is large in that case
940:46 - external fragmentation will be
940:49 - less best fit May create small free
940:52 - holes which may not accommodate new
940:53 - process so bu fit will create big free
940:55 - holes bigger free holes that accommodate
940:57 - the new
940:58 - processes now comes the question how are
941:01 - we going to solve this problem of
941:03 - external
941:05 - fragmentation so the answer is by Saving
941:08 - non-continuously let's see
941:11 - this here what we had we had a 280 KB
941:14 - process and we have a free holes
941:16 - of 115 KB 15 KB and 250 KB we deny that
941:22 - memory is not available only if the case
941:24 - when process is requesting the whole
941:26 - content should be placed at placed at
941:28 - one area if I say process hey process is
941:32 - it will it be okay with you if I place
941:35 - 250 KB of your area here and the
941:37 - remaining 30 KB and the remaining 30 KB
941:40 - here will it be okay with you and if
941:41 - process is yes I am willing to be stored
941:45 - non-continuously then external
941:47 - fragmentation issue will be resolved see
941:49 - here how to solve the problem of
941:51 - external
941:52 - fragmentation suppose this is the case
941:54 - 50k free hole 80k fre hole and 20K fre
941:57 - this is process one and process two now
941:59 - comes a new process of
942:01 - 85k traditionally it would be denied
942:04 - because continuously there is no space
942:06 - available to store
942:08 - 85k even if combining 150k is available
942:12 - but not continuously so what are we
942:14 - going to do we can make it either
942:16 - continuous by reallocating P1 and P2 to
942:18 - one end of the memory and creating a
942:20 - bigger freeold this is what we call
942:22 - compaction
942:23 - compaction we will shift this P1 and P2
942:26 - to a 1 and of a memory and we will
942:28 - create a bigger fre hole see here P1 and
942:31 - P2 shifted to one end and now a bigger
942:33 - free hole of 150 KB is there and this
942:35 - merging of free holes is what we call
942:37 - competion but this competion is not very
942:40 - much desirable because it is a timec
942:42 - consuming
942:44 - operation so if you remember the address
942:47 - binding
942:48 - concept now this P1 and P2 are shifted
942:52 - to a different location so this must
942:54 - support runtime address binding if you
942:57 - remember if we Swip out a process from
943:00 - one location and Swip in the process to
943:02 - a different location this is we call
943:03 - runtime address binding the addresses
943:07 - changes so this is undesirable solution
943:11 - the second solution was noncontiguous
943:13 - allocation store the program into
943:15 - non-contiguous part this is what I was
943:17 - talking about competion is not automatic
943:20 - but if two free holes are adjacent then
943:22 - they are automatically merged well
943:24 - that's a common that's a thing which
943:26 - comes from common sense that this is
943:29 - free hole one free hole 2 free hole one
943:31 - and free hole 2 then they are just a
943:33 - single free hole shown with a boundary
943:36 - but actually they are single FS but in
943:39 - competion suppose this is a free hole
943:41 - one here freeh hole one a process comes
943:44 - in between and now here is the free hole
943:46 - two in this case I can say these free
943:48 - hole won't merge competion is not
943:50 - automatic but if free hole would have
943:52 - been here then these two free hole will
943:56 - merge automatically or by default we
943:59 - believe that these free holes are single
944:01 - free
944:03 - hole okay so let me discuss it again so
944:06 - how we are we going to solve the problem
944:08 - of external fragmentation the answer one
944:10 - was the better one the better answer was
944:12 - non continguous allocation the second
944:14 - answer was compaction in competion what
944:16 - we do we merge the free holes to create
944:19 - a bigger free hole okay in in
944:21 - non-contiguous location what we do we
944:23 - break the program into two parts or
944:26 - parts in different parts and store them
944:28 - at different memory
944:30 - locations this is example of variable
944:34 - partitioning there's a partition of 2 MB
944:37 - partition 2 of 6 MB partition 3 of 3 MB
944:39 - 4 MB and 6 MB this is the OS system area
944:42 - and this is the user area and in these
944:45 - partitions process resides so in
944:47 - Partition one process one is there
944:48 - process two in Partition two process
944:50 - three and so on now what happens P2 and
944:52 - P4 are completed so when process
944:55 - completes then they will leave the area
944:58 - and will cause a free hole here free
944:59 - hole here now what happens P6 and p7
945:02 - arrives P6 is stored at this free hole
945:05 - the size of P6 is 4 MB so 4 MB is stored
945:08 - here and 2 MB free hole is created now
945:10 - here and p7 arrives p7 the size of p7 is
945:13 - 3 MB so what happens this 3 MB will be
945:16 - stored here and 1 MB of free will be
945:17 - created here now p8
945:19 - comes the size of p8 is of 3 MB and we
945:24 - have a total memory available of 3 m
945:27 - also but we cannot load p8 why
945:30 - because continuous allocation because p8
945:34 - demands continuous allocation and we
945:35 - don't have a memory at a single place we
945:38 - don't have 3 MB memory at a single place
945:40 - so p8 will be denied so this is what a
945:42 - basic example how variable partitioning
945:50 - Works let's solve some problems it says
945:53 - consider a memory system having six
945:55 - partitions of size 200 400 so these are
945:57 - the partition size given there are the
945:59 - four process of size the process
946:01 - requests are given using best fit
946:03 - allocation policy what partitions are
946:05 - not allocated or remains unallocated so
946:07 - what we will do we will allocate process
946:10 - in such a way that it will cause least
946:11 - fragmentation so P1 will be allocated to
946:13 - 400 will cost least
946:15 - fragmentation but it should be big big
946:17 - enough you cannot allocate to 200 okay
946:19 - you should know that so 357 will
946:21 - allocated to 400 if it would be
946:23 - allocated to 600 500 then it would cause
946:26 - more fragmentation so P1 will be
946:28 - allocated to 400 P22 this 250 210 will
946:32 - be allocated to 250 for this 468 will be
946:35 - allocated to 500 and this 49 this 49
946:38 - will be allocated to 200 so in this way
946:40 - I can say that 600 and 300 was
946:43 - unallocated it was an easy question uh
946:47 - what it said you have to allocate using
946:49 - best fit and whichever partition was
946:51 - unallocated you have to tell me that so
946:53 - 600 and 300 is the
946:55 - answer second second question it says
946:57 - consider the following memory map in
946:59 - which blank regions are not in use and
947:02 - hedged regions are in use so these are
947:03 - in use and these blank ones are not in
947:06 - use use variable partition with no
947:09 - competion the sequence of request for
947:11 - blocks of size 300 25 125 50k can be
947:15 - satisfied if we use now we have to
947:16 - choose among these options let's see the
947:19 - request are 300 25 125 and 50 First
947:23 - we'll choose with first fit so the first
947:25 - fit says
947:27 - a lot your processes to those partitions
947:31 - which are big enough to accommodate and
947:33 - you will search from the first one I
947:35 - searched for the first first one is it
947:37 - big enough to accommodate no second one
947:40 - is it big enough yes so 300 will be
947:42 - accommodated here now comes
947:44 - 25k is it big enough yes 25k will be
947:47 - alled here is it yes 125 will be
947:50 - allocated now comes the 50k so in this
947:53 - manner first fit partition it is
947:55 - suitable check for the best fit we will
947:59 - allocate in such a way that it will
948:00 - cause least fragmentation 300K will be
948:03 - allocated here 300K now comes 25k 25k
948:07 - will be allocated here
948:10 - 125k here now comes the 50k so there's a
948:13 - 25 KB free space available here also 25
948:17 - KB free space available but it is
948:19 - written in the question that we are not
948:20 - using competion so we will say that
948:23 - sorry process we won't accommodate you
948:25 - because we have no con 50k available
948:28 - with us so 50k can be accommodated so
948:30 - here best fit is a wrong choice first
948:32 - fit is actually a best
948:34 - choice now comes an interesting question
948:38 - consider a system with memory of size
948:40 - 1,000 kiloby it uses variable partition
948:42 - with no complection presently there are
948:44 - two partitions of 200k and 260k
948:46 - respectively so let's say P1 process
948:48 - resides in this partition P2 is in this
948:52 - what is the allocation request of the
948:53 - process which would always be denied
948:57 - so let's say this is the case this is
949:00 - the case P1 and P2 are continuously
949:03 - stored so these partitions are just one
949:06 - after another so the total size is of
949:08 - 460 and the remaining free hole is of
949:12 - 540 so I can say 541k request will all
949:16 - will always be
949:17 - denied clear now this is the good
949:21 - question the smallest allocation request
949:23 - which could be denied which could be
949:25 - denied is
949:27 - the smallest allocation request which
949:29 - could be denied
949:31 - so this
949:33 - 541 is denied in all
949:36 - cases
949:38 - but if we create free holes in such a
949:41 - way that out of these three one is
949:45 - denied can it be possible so what we do
949:48 - we shifted these two down and we created
949:51 - two free
949:52 - holes we created two free holes now the
949:55 - thing is
949:57 - the total value of these threee holes
949:59 - should
950:00 - be 540 and you divide 540 in any way you
950:05 - will have these
950:07 - three you will have these three
950:09 - accommodated so 131 will be stored 151
950:12 - will be stored and 181 will also be
950:14 - stored now comes an interesting part now
950:16 - what we do we create an additional free
950:20 - hole here by shifting P2 a little bit
950:22 - down so P1 is here P2 is here now we
950:25 - have created three fre hes let's say we
950:27 - have created three free holes so free
950:29 - hole 1 plus free hole 2 plus free hole 3
950:32 - should have total of
950:35 - 540 Let It Be 180 180 and
950:38 - 180 now 131 will be stored 151 will be
950:42 - stored but this 181 will be denied so
950:44 - the answer should of this question will
950:46 - be
950:47 - 181 I hope you got the idea so what we
950:50 - have done we have created free hes in
950:52 - such a way that 181 is denied let's see
950:55 - some another questions
950:57 - it says consider a system having memory
950:59 - size of 2^ 46 bytes it uses fixed
951:03 - partitioning divides into fixed size
951:05 - partitions each of size 2^ 24 bytes the
951:09 - OS maintains a process table with one
951:11 - entry per process each entry has two
951:14 - Fields the first is a pointer pointing
951:16 - to to partition in which the process is
951:19 - loaded and second field is process ID so
951:23 - let us draw what whatever has been given
951:25 - a memory has a size of 2 4 46 bytes okay
951:29 - fixed partitioning is used it means this
951:31 - memory has been divided into fixed
951:33 - partitions each of size each partition
951:36 - is of size 2^ 24 bytes so I can say the
951:39 - number of partitions are 2^ 46 divided
951:42 - by 2^ 24 and I can say it is 2^ 22 I can
951:48 - say and Os maintains a process table
951:50 - with one entry per process and always
951:53 - maintains a process table with one entry
951:56 - per process and each process has one
951:58 - entry in it each entry has two Fields
952:01 - the first is a pointer pointing to the
952:02 - partition the first is a pointer
952:04 - pointing to the
952:05 - partition and the second is the process
952:08 - ID let's say this is P1 so what it does
952:11 - it has divided the memory into several
952:13 - partitions and it is keeping a process
952:16 - table
952:17 - suppose suppose this P1 is being stored
952:20 - in Partition number 10 so the address of
952:23 - partition number 10 let's say 1 1 0 0 1
952:25 - something like that in binary okay I'm
952:28 - just taking a random
952:30 - number so in process table the process
952:34 - ID and at which location this process is
952:37 - stored in the memory that is being
952:39 - maintained so what is the question it
952:42 - says the size of process side is 4 by
952:45 - the size of pointer to the nearest by so
952:47 - we have to calculate the size of
952:50 - pointer to calculate the size of pointer
952:53 - we have to first understand what does
952:54 - pointer contain pointer contains the
952:56 - address of the partition in the
953:00 - memory to so we have to assign each
953:03 - partition a unique
953:06 - address we have 2 what 22 number of
953:09 - partitions which means we need 22
953:13 - bits we needs 22 bits to
953:17 - generate 2 22 unique addresses so the
953:21 - size of pointer will be of 22
953:24 - bits now the question is calculate the
953:28 - size of pointer to the nearest bite how
953:30 - many bytes are able to contain 22 bits I
953:34 - can say three bytes can contain 22 bits
953:37 - each by contain 8 bit so 8 into 3 24
953:41 - bits so the size of pointer to the
953:43 - nearest bite will be three bytes now the
953:46 - question arises why can't I take two
953:48 - bytes because with two bytes I can only
953:51 - generate 2 to^ 16 different kind of
953:54 - addresses but what we require 2 22 see
953:57 - if it is an extra then it is okay but it
954:01 - if it is less then that is not
954:03 - acceptable this is what we follow here
954:06 - the second question says size of process
954:08 - table in bites if system has 500
954:10 - processes if system has 500 processes
954:14 - then there will be 500 entries the size
954:17 - of each entry is three bytes for the
954:19 - pointer and 4 bytes for the process ID
954:24 - so it is 7 bytes 7 FS are 3500 bytes so
954:30 - the size of process table should be 3500
954:33 - that is the answer let us discuss it
954:35 - again what this problem is saying this
954:36 - is an important problem it
954:38 - says it
954:40 - says we have a memory of size 2 raed to^
954:43 - 46 PES we have divided that memory into
954:46 - several
954:47 - partition the total number of partitions
954:49 - are 2^ 22 each with size 2^ 24 so each
954:54 - partition each partition has size 2 24
954:57 - bytes and there are 2^ 22 such
955:01 - partitions that's how we got 2^ 46 bytes
955:04 - of memory now what OS has done OS has
955:07 - maintained a process table with one
955:09 - entry per process so OS has maintained a
955:13 - process table with one entry per
955:15 - process the first field of the entry
955:19 - contains a pointer to the partition in
955:22 - which that process is residing so the
955:26 - first entry contains the pointer and the
955:28 - second entry contains the process
955:30 - ID so what does pointer contain pointer
955:33 - has the address of that
955:35 - partition now we have to assign each
955:37 - partition a unique address how many
955:40 - partitions are there 2^ 22 partitions
955:43 - are there how many bits are we going to
955:45 - need to generate 2^ 22 unique numbers so
955:48 - that we can give 2^ 22 partitions unique
955:51 - addresses we need 22
955:55 - bits that's why the size of pointer will
955:58 - be 22 bits now it is asked size of
956:00 - pointer to the nearest bite so the size
956:02 - of pointer will be 22 divided by 8 floor
956:06 - function why floor sorry it is not floor
956:09 - function it is seiling function why
956:10 - sealing function because if it is more
956:13 - then it is okay if it is less then it is
956:16 - unacceptable why so because if we
956:19 - take if we take two bytes then we are
956:22 - only going to have 16 bits we will able
956:25 - to generate only 2 16 different numbers
956:28 - but how many different numbers we
956:29 - require 2^ 22 with three bytes I can
956:33 - generate 2 24 different
956:37 - numbers how many different numbers we
956:39 - require 2 22 that's okay okay so the
956:43 - size of process table in bytes will
956:45 - be if system has 500
956:49 - process three bytes for the pointer four
956:53 - bytes for the process ID each entry has
956:55 - seven
956:56 - bytes and the total number of entries
956:59 - are 500 so 7 into 500 that is 3500 this
957:03 - is what this question says is consider a
957:05 - system using variable partition with no
957:07 - competion we are not going to merge the
957:09 - free holes to create a bigger free hole
957:12 - free holes are given 4K 8K 20K 2K
957:16 - program sizes are given time for
957:18 - execution is given so what we have to do
957:20 - using best fit allocation policy and
957:22 - using fcfs CPU scheduling Technique we
957:25 - have to find the time of loading of each
957:27 - we have to find the time of completion
957:29 - of each and the first time we are given
957:32 - with
957:33 - here so firstly what we have to do we
957:35 - have to bring all these programs into
957:38 - memory to make them processes so we'll
957:41 - first bring so out of these we'll first
957:43 - start with this 2K where this 2K will be
957:46 - allocated at this free hole where this
957:48 - 14k will be allocated at this freeh hole
957:50 - at 20K where this 3K will be allocated
957:53 - 3K will be allocated at this 4K where
957:55 - this 6 K will be allocated see if you
957:57 - remember when 14k was allocated to 20K a
957:59 - free hole of 6K was remained there so we
958:01 - allocate that 6K here now now see here
958:06 - firstly 2K was allocated here and then
958:09 - 14k was allocated here 3K was allocated
958:11 - here and 20K was allocated here oh n 6K
958:15 - was allocated here to fill this free
958:17 - hole of 20K now what is the remaining we
958:19 - have 6K remaining as at 8K fre and 1K
958:23 - remaining at 4K fre
958:26 - okay now what we have done we have also
958:29 - you must have seen here this purple
958:31 - shade this purple shade is showing a a
958:35 - small Gap a gap to ensure that these are
958:37 - not adjacent otherwise they will go Le
958:39 - or merge
958:40 - automatically okay so what we have to do
958:44 - now we have to schedule them we have to
958:46 - schedule
958:48 - them see here only 10K and 20K will be
958:51 - at the disc this 2K will also be
958:53 - scheduled
958:54 - here so so which programs are in the
958:57 - disk now 10K and 20K are in the disk now
959:00 - we will first schedule these and after
959:02 - that and after that when we have free
959:05 - spaces then this 10K and 20K will also
959:08 - come in the memory so we will schedule
959:09 - them first how are we going to schedule
959:11 - we will schedule using fcfs ceding so
959:14 - which program came first 2K came first
959:17 - so we are going to schedule 2K first
959:19 - here is the let's say let's call them
959:21 - process the one who
959:23 - arrived let's call them process one the
959:26 - second one to arrive let's call them
959:27 - process two the third one to arrive
959:29 - process three okay so we have assigned
959:31 - the process ID based on the time they
959:32 - arrive okay this it's just a matter of
959:34 - representation it will not uh it will
959:37 - not matter
959:38 - actually okay so first 2K arrived for
959:42 - the time of 4 units so from 0 to 4 2K
959:44 - will run the next 14k ride for 10 units
959:46 - so from 4 to
959:49 - 14 this 14k will
959:52 - run from 4 to 14 this 14k run now you
959:55 - can see here this part has become empty
959:58 - now this part has become empty now so
960:01 - here at 14k free hole we can actually
960:03 - schedule 10K so here 10K will come so
960:07 - now this 14k fre is empty 10K has
960:09 - arrived here and and I have a free o of
960:13 - 4K also see here if this 14k has
960:17 - gone and I have now 10K here so I will
960:22 - also have a free hole of 4K remaining
960:25 - that's how it becomes a total sum of 20
960:29 - so scheduled scheduled that's 10K have
960:32 - come now which process 3K so 3K will be
960:36 - scheduled for how much time it has a
960:38 - first time of 2 units so from 14 to 16
960:40 - 3K will be scheduled now 6K 6K has a
960:43 - time of 1 unit so from 16 to 17 6K will
960:47 - be scheduled now if you remember 2K was
960:51 - brought into memory so 2K will be
960:52 - scheduled for 8 unit of time 2K will be
960:55 - scheduled for 8 unit of time so from 17
960:57 - to 25 from 17 to 25 2K will be shed now
961:01 - it's time for this 10K because after the
961:03 - 10K has come so 10K will be scheduled
961:06 - for 4 unit of time so from 25 to 29 10K
961:11 - will be scheduled so now if you see we
961:13 - have empty space for
961:16 - 20K this has been scheduled this has
961:18 - been scheduled this has been scheduled
961:19 - now 20K free is present here let me
961:22 - write like this schedu shedu
961:26 - now we have 20K freeold here so what are
961:29 - we going to do we are going to bring
961:30 - that 20K here in the memory now 20K will
961:33 - be sched what is the bu time of 20K 20K
961:36 - bu time is 1 only so from 29 to 30 this
961:39 - 20K will be scheduled so this is how we
961:43 - have we have uh done a question of
961:47 - partition allocation as well as CP
961:49 - scheding
961:50 - both okay so this is how it looks now
961:53 - load time P1 P2 P3 P4 P5 were loaded at
961:57 - 0er P6 was loaded at 14 here that was
962:00 - the 10K and p7 was loaded at 29 that was
962:02 - the 20K
962:04 - proc okay so this is how we have done
962:07 - this let me repeat again what we have
962:09 - done so firstly we have to allot using
962:12 - best fit allocation policy we have given
962:15 - the program into those free holes which
962:18 - causes least
962:19 - fragmentation so 2K was allocated here
962:22 - 14k was located here 3K was located here
962:24 - 6K was located here okay in this way we
962:27 - have allocated and 2K which was
962:29 - remaining was allocated here when 6K +
962:31 - 2K both were allocated at the slot of
962:33 - 8K now we will start scheduling because
962:37 - we have two more process two more
962:38 - programs in the disc and they are
962:41 - waiting as soon as the memory becomes
962:43 - empty for them or they have the memory
962:45 - have enough space to accommodate them
962:47 - they will come so when this 14k was when
962:51 - this 14k was executed it has left the
962:53 - memory so it made a free hole for for
962:55 - 10K 10K came there when this 10K was
962:58 - completely
963:00 - executed when this 10K when this 10K was
963:02 - completely executed and the remaining
963:04 - was uh what was the remaining the 6K so
963:07 - 6K and 10K when these were executed now
963:10 - it has created a free hole to commodate
963:12 - 20K also so there 20K
963:18 - comes and this way we have scheduled the
963:21 - processes okay now it's your homework to
963:23 - calculate the completion time from the G
963:25 - chart how are you going to do that when
963:27 - was p7 completed at time 30 when was P2
963:29 - completed at time 14 P4 at time 17 in
963:31 - this way you have to calculate the
963:33 - completion time loading time I've
963:35 - already told you consider the allocation
963:37 - of memory to a new process assume that
963:39 - none of the existing holes in the memory
963:41 - will exactly fit the process memory
963:43 - requirement hence what happens a new
963:45 - holes a new hole of a smaller size will
963:47 - be created if a location is made in any
963:50 - of the existing
963:51 - holes which of the following statement
963:53 - is true the first says the whole cre by
963:56 - next fit is never larger than the hole
963:58 - created by best fit well this is false
964:00 - best fit Works in order to create the
964:03 - smallest holes the second option says
964:05 - the hole created by worst fit is always
964:08 - larger than the hole created by first
964:09 - fit well this is also false because
964:12 - worst fit and first fit can be
964:14 - same so this always is creating a
964:17 - problem here the hole created by first
964:19 - fit is always larger than the hole
964:21 - created by next fit well this is this is
964:24 - false also because they may be equal
964:27 - they may be equal so if here it is
964:29 - written always larger that's create the
964:32 - problem the whole created by Best Fit is
964:35 - never larger than the hole created by
964:37 - first
964:38 - fit well this is true in all cases how
964:41 - can I say that because best fit works or
964:44 - the motive of best fit is to create the
964:46 - smallest holes so yes this is true best
964:49 - fit is the hole created by Best Fit is
964:52 - never larger than the hole created by
964:53 - first fit
964:56 - memory management part four
964:58 - non-continuous allocation what was
964:59 - non-continuous allocation suppose your
965:02 - process size is 100 KB but you have free
965:05 - space available for here 40 KB here 40
965:08 - KB and in the last somewhere 20 KB if
965:12 - you have used continuous allocation you
965:14 - won't be able to bring that process from
965:16 - dis to memory but if you have used
965:18 - nonous location what we will do we will
965:20 - break this process into parts of 40 KB
965:23 - 40 KB and 20 KB
965:26 - this 40 and 40 is 80 80 and 20 is 100 so
965:28 - that 40 will be stored here this 40 will
965:31 - be stored here and this 20 will be
965:32 - stored here this is what non-continuous
965:34 - allocation means you are not storing
965:37 - continuously okay so this non-continuous
965:40 - allocation is useful to prevent external
965:43 - fragmentation what was external
965:44 - fragmentation before that first
965:46 - understand what was internal
965:47 - fragmentation suppose this was your
965:49 - partition and your process took this
965:51 - much space only now this space will
965:53 - remain unused because in a partition
965:56 - only a single process can reside so this
965:59 - is what internal fragmentation
966:01 - was this internal fragmentation happens
966:03 - in the case of in the case
966:08 - of yes you remember fixed partitioning
966:11 - because partitions were fixed process
966:14 - size are different so in that case in
966:16 - some partition it is usual for some
966:20 - memory to get
966:21 - wasted so that is the drawback of fixed
966:24 - partitioning now what we have done we
966:26 - have introduced variable
966:29 - partitioning Vari variable partitioning
966:32 - create partitions based on the process
966:34 - size let's say the process size is 10 KB
966:37 - so initially the memory is nothing but
966:39 - the free hole so what happens when a 10
966:41 - KB process comes it create a partition
966:43 - of 10 KB so this is what variable
966:46 - partitioning was so we have a partition
966:50 - somewhere here somewhere here now what
966:52 - happens this 10 KB
966:54 - process let me create a better diagram
966:57 - suppose these are the partitions based
966:59 - on the process size okay now what
967:01 - happens P1 has been executed and it
967:04 - wants to leave the memory so now this uh
967:07 - P1 will get empty here this is now a
967:10 - free hole P3 also became ex also became
967:15 - a dead process so it will also leave the
967:16 - memory two fre have been created now P6
967:19 - has also left the memory three freees
967:21 - are there 20 KB or whatever was the size
967:25 - 20 KB 40 KB and 40 KB now a new process
967:28 - wants to enter into the memory let's say
967:30 - it size is 100
967:32 - KB what we will respond to that process
967:35 - we will respond in two of the either way
967:38 - the first way is hey process we are so
967:41 - sorry that you cannot be accommodate
967:43 - continuously continuously so you should
967:46 - remain in the
967:48 - dis the second way is a process I have
967:51 - an idea we don't have a 100 KB space
967:54 - continuously but if you you are
967:57 - comfortable we'll break you into three
967:58 - pieces of 40 KB 40 KB and 20 KB each and
968:01 - we will store you at the different
968:02 - location the process says yes I'm
968:04 - comfortable so this is what
968:06 - non-contiguous allocation
968:09 - is if the if the location was not
968:12 - continuous this 20 KB space will not be
968:15 - used if some process of size greater
968:18 - than or greater than 20 KB comes let's
968:21 - say a size of 100 KB have come if we
968:25 - have used continuous allocation this 20K
968:27 - will never be used but now we have used
968:31 - non-contiguous allocation so this has
968:33 - prevented the external fragmentation or
968:35 - the external memory wastage of this 20K
968:38 - so this is how non-contiguous allocation
968:40 - prevents the external fragmentation we
968:43 - have another method named compaction
968:46 - compaction was actually undesirable
968:47 - because it was time consuming operation
968:49 - required program to execute runtime
968:51 - atress binding so what we did in
968:53 - competion in competion we have let's see
968:55 - some process P1 a free hole here process
968:57 - P2 and a free hole here what we did we
969:00 - swept out the process P2 and then swept
969:03 - in at the different location so that the
969:07 - two free holes become adjacent to each
969:09 - other and if two free holes are adjacent
969:11 - to each other they will automatically
969:13 - CES resulting into a creation of bigger
969:16 - free hole so this is what competion is
969:18 - but it is undesirable because first it
969:20 - is time consuming the second it requires
969:23 - program to execute runtime at B and and
969:26 - let's learn what is address space
969:29 - address space is nothing but a set of
969:31 - words binded with the
969:33 - addresses memory is nothing but an
969:35 - address
969:36 - space it is also known as physical
969:38 - address space memory has different words
969:41 - each word has a unique address this is
969:43 - what address space is address space can
969:45 - be divided into two logical address
969:47 - space and physical address space logical
969:49 - address space is also known as virtual
969:51 - address space why virtual we will see it
969:53 - later in some time so before
969:55 - understanding the Las and the Pas we
969:57 - need to First understand what is logical
969:59 - address and physical address take this
970:02 - example I have already given you uh let
970:06 - me give it again suppose this is me this
970:08 - is you you come to me and ask hey do you
970:11 - know where is the library I say yes or I
970:14 - should uh you should ask me some private
970:16 - information like where is your house I
970:19 - say my house is you you just go 100 m
970:22 - straight and then take a left the second
970:24 - house is mine
970:26 - you go there it's good now what happens
970:30 - this information is e dropped by some
970:34 - Intruder he tries to do the same thing
970:37 - from different location he tries to go
970:39 - 100 m straight and take the left did he
970:41 - reach at my house no he reached at a
970:44 - different location though this is what
970:46 - logical address does but suppose if you
970:49 - asked me the address of my house and I
970:51 - have told you my house is at coordinate
970:52 - 10 comma 10
970:55 - then this robber would have directly
970:57 - jumped at my house 10 comma
971:00 - 10 because he's now available with the
971:02 - physical
971:04 - address and you were given with the this
971:06 - this go straight and take the left this
971:08 - was The Logical
971:09 - address okay so what is the need of
971:12 - creating this logical address and
971:13 - physical address can't we just create
971:15 - the physical address directly no suppose
971:19 - this process has created the physical
971:22 - address directly has generated the
971:24 - address to directly
971:26 - access the memory content the
971:28 - instruction or
971:29 - data who is stopping the process not to
971:32 - create the physical address or U the
971:36 - actual address of some different
971:39 - processes address space who is stopping
971:42 - this process to
971:43 - create the physical address or generate
971:46 - the physical address of some
971:48 - different instruction or data which it
971:50 - is not supposed to
971:53 - exess this is the security concern take
971:56 - an example uh it's little bit different
971:58 - but it will give you a feel what happens
972:01 - in the
972:03 - college
972:04 - suppose you are in examination Hall you
972:07 - write your role number iitv 44 this is
972:11 - your role
972:13 - number when this copy this answer sheet
972:15 - will be sent to a different department
972:18 - or when this answer sheet will be sent
972:20 - for copy checking what happens they
972:22 - change the actual role number with a D
972:25 - role
972:26 - number so this iitb 404 that's actual
972:29 - role number will be changed to this
972:31 - logical sequence of number which has no
972:36 - meaning why is it done so to ensure
972:39 - unbiased checking suppose I'm deer to
972:43 - some Professor so Professor when sees
972:45 - the copy IIT B 404 hey this role number
972:48 - I remember his is sh R number and he's a
972:51 - nice guy I should give I should check
972:53 - his copy little liberally or I should
972:55 - give him more marks that kind of thought
972:57 - may come into an examiner's mind or the
972:59 - the one who is checking the copies that
973:02 - kind of thought may come it's natural so
973:03 - what they do they change the
973:07 - address or I should say this they change
973:09 - the role number with a dummy role number
973:12 - which we call as logical role number
973:14 - this was our physical role number an
973:16 - actual role number to ensure unbias
973:19 - checking this is uh something similar is
973:21 - done here in the in the memory
973:25 - management part also process running in
973:27 - the CPU generates some logical address
973:29 - logical address is sent to memory
973:31 - management unit and it is converted into
973:34 - physical address that is the actual
973:35 - address that is the actual address of
973:38 - instruction and data which this process
973:40 - want to access so the process generate
973:43 - what it generates n bit logical address
973:45 - this nbit logical address is converted
973:47 - into nbit physical address or maybe
973:50 - different bit physical address not
973:52 - necessary of n Bits only
973:56 - the OS the OS has control on physical
973:59 - address so physical address is accessed
974:00 - only by the OS let me repeat what
974:03 - happens process generate logical address
974:05 - converted into physical address with the
974:06 - help of memory management unit and that
974:08 - physical address is the
974:10 - actual address where the data is stored
974:12 - this is how the conversion
974:15 - works okay now let us clarify this thing
974:20 - physical address
974:21 - thing suppose this is my memory and it
974:25 - contains several words each word
974:28 - associated with different
974:30 - address the width of the address or the
974:33 - number of bits in the physical address I
974:35 - say as physical address has n
974:40 - Bits how many words would have been
974:42 - there in the physical address space or
974:44 - in the main memory I can say 2 ra to
974:47 - power n Bits words should have been
974:50 - there so this is what the physical
974:54 - address space or the capacity of the
974:57 - memory 2 ra to power physical address 2
975:01 - ra to power physical address and
975:02 - physical address is always in the bits
975:03 - suppose I have four bit physical address
975:05 - then I can say then that there are 16
975:08 - words in the memory and if it is bite
975:10 - addressable then this 16 world or 16 by
975:14 - directly give me the capacity of the
975:19 - memory this is what happens in the
975:22 - physical address space physical address
975:23 - space equals to 2 power physical address
975:28 - now I have formul written why doesn't
975:30 - the process directly access the physical
975:31 - address space because of security if we
975:34 - allow P2 to access physical address
975:35 - directly then it can also access
975:37 - physical address of P1 and P2 who is
975:39 - stopping P2 access uh who is stopping P2
975:42 - to access physical address of the OS
975:45 - well that's a that's a very very serious
975:47 - concern who is the stopping process to
975:49 - access the operating system well
975:52 - operating system is also in the memory
975:53 - operating system also have some physical
975:56 - address if we allow a process to
975:59 - directly generate physical address who
976:01 - is stopping this process to access
976:03 - operating
976:04 - system well that's a thing of
976:07 - concern that's why operating system say
976:10 - let the process generate whatever they
976:12 - want I have the mapping table I will map
976:15 - and make a space accessible so that you
976:17 - cannot directly
976:19 - interfere that's why the addresses the
976:22 - set of addresses generated by the
976:24 - process is what logical address space is
976:27 - so OS says you generate whatever you
976:29 - want I have the mapping table I have the
976:31 - mapping table I will map I will map this
976:35 - RO number to this role
976:38 - number this is how this uh memory
976:42 - management or the translation of
976:43 - physical address and logical address
976:45 - works okay so OS maintains a
976:48 - table here mapping of all the logical
976:51 - address a process can generate and the
976:54 - corresponding and the corresponding
976:55 - physical
976:56 - addresses this table is maintained by
976:58 - the operating system so this is The
977:01 - Logical address each logical address
977:04 - corresponds to a world in the main
977:06 - memory each logical address correspond
977:09 - to the world in the main memory if you
977:11 - are not getting this just think why a
977:13 - process generate a logical address to
977:16 - access a word that's why each logical
977:19 - address should have been generated to
977:21 - access a word in the memory that's why I
977:23 - can say each logical address correspond
977:26 - to a word in the main memory so each
977:29 - logical address correspond to a physical
977:32 - address now comes the
977:35 - function of memory management unit the
977:37 - function is address translation program
977:40 - assume that I am in a logical memory OS
977:42 - will give it an
977:45 - illusion okay if I say formally it is an
977:47 - abstraction layer so what does program
977:49 - assumes program assumes that I am I am
977:53 - here in The Logical address
977:56 - Space Program assumes in that I am here
977:59 - in The Logical address space this
978:00 - process thinks that I am in The Logical
978:02 - address space and I'll generate The
978:03 - Logical address and this logical address
978:05 - will access the data and instructions
978:08 - here the process this process doesn't
978:10 - even know what is in the what is how OS
978:13 - is working in the back to ensure
978:15 - security this process doesn't even know
978:17 - this process thinks that everything
978:20 - resides in this logical space I generate
978:22 - The Logical address I get the data and
978:24 - instruction section from The Logical
978:25 - address process doesn't even know there
978:27 - exist some physical address or physical
978:29 - address space or main memory process
978:30 - doesn't know that there exist some
978:32 - memory management unit this is what
978:35 - abstraction actually
978:43 - is let's learn the design and
978:45 - implementation of non-continuous
978:47 - techniques we learn the organization of
978:50 - logical address space physical address
978:51 - space and memory management unit it will
978:54 - start with simple paging suppose The
978:56 - Logical address space is of 8 KB and The
978:59 - Logical address is of 13
979:02 - bits physical addresses is of 4 KB and
979:05 - physical address is of 12 bits now what
979:08 - we do we divide The Logical address
979:12 - space or the virtual address space into
979:14 - equal sized unit call Pages that's why
979:17 - we have named paging here what we have
979:20 - done this whole logical address
979:23 - space has been divided into equal sized
979:26 - equal sized remember this word equal
979:28 - sized
979:30 - Pages page sizes of one
979:33 - KB page size is of 1 KB so how many
979:37 - pages will be there 8 KB divided by 1 KB
979:41 - here I got eight pages from p 0 to
979:45 - p7 okay so the number of pages we get by
979:48 - logical address space divided by Page
979:52 - size the number of pages we got are
979:55 - eight
979:56 - pages now we have
979:58 - to for each page number for each page
980:02 - number how many bits are required three
980:05 - bits will be required for this page
980:07 - number 0 we'll require 0 1 and for page
980:09 - number seven we require
980:10 - 111 so page number P we we Define it by
980:14 - or we have a variable named P equals to
980:18 - log to n what is n number of pages how
980:22 - many page number or how many bits in the
980:24 - page number is required log to number of
980:29 - pages suppose I have n Bits in the page
980:33 - number which means I can generate 2 ra
980:35 - to power n different pages I hope I have
980:38 - told you from the both
980:40 - ways now what
980:44 - happens we will learn about page offset
980:47 - see the whole logical address space can
980:50 - be divided let's say for to keep it
980:52 - simple is only divided into two pages
980:55 - now each page will contain more than one
980:58 - word so there can be more than one word
981:01 - in a page now which word from that page
981:06 - we want to access we call that as page
981:11 - offset we divided into two pages this is
981:15 - word one word two word three and word
981:17 - four 1 2 3 and 4 this is 0 0 this word
981:21 - is 0 0 0 1 1 Z and 1 one now we want to
981:28 - access the fourth
981:30 - word so that address or uh that is
981:34 - called page offset which word we want to
981:37 - access from a particular page is called
981:39 - as page offset
981:41 - and how many bits are required in a page
981:45 - offset depends on the page size if there
981:47 - are four words then I require log to
981:50 - four bits if there are eight words then
981:53 - I require three bits so it depend how
981:56 - many words are there in a
981:59 - page so page offset will be equals to
982:02 - log to page size if page size is of four
982:04 - words then there will be two bits in the
982:07 - page offset so till now what we have
982:10 - learned the number of pages let's let's
982:13 - go from the
982:15 - start logical address space is divided
982:17 - into equal sized unit called
982:20 - pages okay each page may contain number
982:23 - of words
982:25 - and number of pages will be equal to
982:27 - this whole logical address space divided
982:29 - by Page size this is what we will give
982:32 - we will get by dividing logical address
982:35 - Space by Page size we'll get number of
982:38 - pages and we have to give each page a
982:41 - number we have to give each page a
982:43 - number so how many bits are required to
982:47 - give n Pages a number log to n Bits will
982:51 - be required or we can say the other way
982:54 - suppose suppose I have n Bits then I can
982:56 - give 2 ra to power n Pages a unique
982:59 - number so the page number will be log to
983:02 - number of pages now comes to page offset
983:05 - what does page offset say a page may
983:07 - contain diff a page may contain many
983:10 - words out of these which word you want
983:14 - to access this is what page offset is
983:17 - this page offset is the size how many
983:20 - bits you require to uniquely identify a
983:24 - word in a page what is Page offset how
983:28 - many bits you require to uniquely
983:31 - identify a word in a page this page
983:34 - number says how many bits is required to
983:37 - uniquely identify a a page from the set
983:40 - of
983:41 - pages I hope you now understand what is
983:44 - the this what is the formula of M what
983:46 - is p and what is
983:49 - D okay so how many bits need to refer
983:51 - one bite from 1 KB page that is 10 bits
983:54 - which is called as page
983:57 - offset okay let's say let's
983:59 - say this is a word in a page this is
984:03 - this is a word in a page and this is the
984:04 - whole page I want to access this
984:07 - instruction so from a whole page from a
984:10 - whole page there are number of words how
984:13 - many bits I need to give address or to
984:18 - uniquely identify each word in the page
984:21 - well that will be equal to the number of
984:23 - words there
984:24 - so number of words or the page size I
984:26 - will do what log two page size or I can
984:29 - say number of words there in a page
984:32 - equal to page size that is Page offset
984:36 - okay so let's let's understand by a
984:39 - different analogy also what happens this
984:41 - is our classroom this is the teacher
984:44 - this is the student the student or the
984:46 - teacher want to call this student so
984:49 - what will teacher do teacher will call
984:51 - the bench number one
984:54 - and from this bench teacher will call
984:56 - the third student from the left so this
985:00 - so this statement third student from the
985:03 - left this is what page offset
985:05 - is first bench this is what page number
985:09 - is I hope now you're getting the
985:13 - idea let me summarize again so what
985:17 - happens this logical address space is
985:19 - divided into equal size unit call pages
985:22 - and we have to give each page a
985:25 - different name or different address so
985:27 - that is what page number will help us
985:30 - we'll have to find the number of pages
985:32 - log to n will be the page number now we
985:36 - have successfully identified let's say
985:38 - 1 this is 0 0 or this is 01 we have
985:42 - success successfully identified this
985:45 - page contains our instruction this page
985:48 - contains our instruction now this page
985:50 - have several
985:52 - words which word from this page contains
985:54 - our instruction to find that we require
985:57 - a page
985:59 - offset we require a page offset let's
986:02 - say 1 1 1 this is the page offset this
986:05 - says the seventh
986:07 - word or this is the eth so this is0 1 2
986:10 - 3 4 5 6 7 so this word contains my
986:16 - instruction I hope now you have a clear
986:19 - idea what this page offset page number
986:21 - and number of pages
986:22 - means okay so that third student is Page
986:26 - offset the first bench is the page
986:28 - number and this classroom is the main
986:30 - memory this is how exactly logical
986:32 - addressing
986:34 - works so in a logical address format
986:37 - what we have we have this logical
986:40 - address divided into two parts the first
986:42 - part is page number it is used to
986:44 - identify which page contains our
986:47 - instruction and the second part is the
986:49 - page offset it is used to identify in
986:51 - this page which word contain my
986:53 - instruction
986:55 - let me repeat again and then we'll end
986:57 - our lecture logical address format has
987:01 - two Fields the first field is page
987:03 - number the second field is Page offset
987:05 - the first field says which page contains
987:09 - my instruction and the second field says
987:11 - in this page which word contains my
987:14 - instruction that's how you reach to the
987:17 - final
987:18 - part that's how you reach to the
987:20 - instruction that you want first you
987:22 - identify the page then you identify ify
987:24 - the word in that page that's containing
987:25 - your instruction in the next lecture we
987:28 - will see some questions that will
987:30 - increase your
987:31 - Clarity see this question The Logical
987:34 - address space is of 32 MB so I can say
987:37 - for 32 it is 5 and for MB it is 20 so I
987:39 - can say 25 2 power 25
987:43 - bytes for to address each by to address
987:47 - each by in total I would require a 25
987:50 - bit address suppose my instruction is at
987:53 - some this by present here how I'm going
987:56 - to reach that instruction firstly I have
987:59 - to I have to find in which page this
988:01 - instruction is there and then I will
988:03 - find in which word of the page
988:05 - instruction is present so in total in
988:08 - total I would require 25 bit after of
988:11 - this some of the page bits and some of
988:14 - the offset bits so how are we going to
988:16 - find the page bits for that we need to
988:18 - know the page size it is given 4 KB so I
988:21 - can say this 2^ 25
988:24 - bytes address space is divided into
988:27 - pages each of size 2^ 12 bytes so how
988:32 - many pages will be there 2^ 25 2^ 25
988:36 - divid 2^ 12 that is 2^ 13 pages are
988:40 - there to uniquely identify these pages I
988:44 - have to assign them page number how many
988:46 - bits are required to generates 2^ 13
988:49 - unique numbers I would require 13 bits
988:52 - so for page number 13 bits are required
988:56 - now 13 bits are given here how many bits
988:59 - I'm going to require for this offset 25
989:02 - - 13 that will be 12
989:05 - bits I hope you got the idea now okay
989:09 - see this question it ask let's say the
989:12 - total number of pages are 2K which means
989:15 - 2^ 11 pages The Logical address is of 32
989:18 - bits can you give me the page size can
989:21 - you give me the page size
989:24 - if the logical address is of 32 bits I
989:26 - can say The Logical address space will
989:28 - be of 2^ 32
989:31 - bytes I know this 2 32 bytes is divided
989:35 - into 2^ 11 pages so what will be the
989:39 - page size page size will be of logical
989:41 - address space divided by the number of
989:45 - pages so 2^ 32 divide 2^ 11 I get 2^ 21
989:51 - I can write 2^ 21 like this 2 power 2
989:55 - power 1 into 2^ 20 so I can say this is
989:59 - 2 MB so the page size is of 2 MB this is
990:02 - how you have to solve see don't mug up
990:04 - the things try to understand the concept
990:06 - if you just learn the formula you will
990:09 - believe me you will get stuck in the
990:11 - difficult questions but if you
990:13 - understand the concept no question will
990:15 - be difficult for
990:17 - you now we'll learn the organization of
990:20 - physical address
990:21 - space physical address space is divided
990:24 - into equal size units just like The
990:26 - Logical address space But Here we call
990:28 - them as
990:30 - frames and each frame hold on a one page
990:34 - so I can say the frame size will be
990:36 - equal to the page size let me repeat
990:40 - logical address space contain different
990:43 - pages and physical address space this is
990:46 - this is what the main memory is physical
990:48 - address space in the same way is divided
990:50 - into different frames and each frame
990:54 - contains one page see this Frame zero
990:58 - contains page number five frame one
991:00 - contains page number two frame two
991:02 - contains page number zero frame three
991:04 - contains page number seven so I can say
991:06 - this frame size should be equal to page
991:08 - size remember this this is an important
991:12 - concept so frame is meant for holding a
991:15 - page any page can be stored in any frame
991:18 - but remember only one page can be stored
991:20 - in one frame because the page size is
991:22 - equal to frame size so if I ask if I ask
991:26 - number of frames will be physical
991:28 - address space divided by frame size or I
991:31 - can also write physical address page
991:33 - divided by Page size what I have done
991:36 - this whole physical address has been
991:37 - divided into number of frames each frame
991:40 - is equal to one page or each frame size
991:43 - equal to a page size so I can write
991:45 - physical address space equals physical
991:47 - address spage divided by Page size
991:48 - equals to number of frames we denote
991:50 - number of frames with m
991:54 - and frame
991:55 - numbers depends on the number of frames
991:58 - log 2 number of frames this is what will
992:02 - be required
992:03 - to these many bits are required to give
992:07 - each frame a different number okay see I
992:10 - have if I have n Bits then I can
992:13 - generate 2 power n different numbers and
992:16 - these 2 power n different number can be
992:18 - assigned to these two power n frames so
992:20 - if I if I have to go other way around I
992:22 - can say if I have 2 power n frames then
992:26 - I would require n Bits we have done this
992:28 - concept so many
992:30 - times you should torrow with this okay
992:34 - and same frame offset page offset frame
992:37 - offset and Page offset are same frame
992:39 - size and Page size are
992:41 - same so physical address consist of
992:44 - frame number and offset frame number
992:48 - helps in finding in which frame our page
992:50 - is present and this offset is finding in
992:53 - that page in which world the instruction
992:55 - is present okay so let's see this
992:58 - logical address is of 2^ 31 bits
993:01 - physical address is of two uh physical
993:04 - address is of 20 bits page size is 4 KB
993:08 - page of 4 KB what can I tell from this
993:11 - logical address is 31 bits so I can say
993:13 - The Logical address space will be of 2^
993:16 - 31
993:17 - bytes and this logical address space is
993:20 - divided into pages each of size 4 KB
993:24 - I can write it as 2 and this K is 10 so
993:28 - 2 power 12 what is 2 31 -
993:33 - 12 it is 19 so I can say number of pages
993:36 - are 2^
993:38 - 19 okay now anything more check and tell
993:42 - I can tell number of frames also
993:44 - physical address space is of 2^ 20
993:47 - bytes and I have told you that each
993:50 - frame contain a single page so I can say
993:53 - frames size is equals to page size so
993:55 - this 2 ra^ 20 is the physical address
993:59 - space divided into different frames each
994:00 - of size 2^ 12 by
994:03 - this so I calculate 2^ 8 is the number
994:09 - of frames in the main memory 2^ 19 is
994:12 - the number of frames in The Logical
994:14 - address space number of pages in The
994:15 - Logical address space we don't call
994:17 - Pages as frames in The Logical letter
994:20 - space we call frames in physical letter
994:22 - space so Pages for l s and frames for
994:25 - PES
994:27 - okay now how many how many bits we
994:31 - require to uh give each frame a
994:34 - different number we require eight bits
994:36 - and how many for uh page we require 19
994:40 - bits now we have to find the offset what
994:43 - will the offset see this physical
994:46 - address space consist of 20 bits and I
994:49 - have 8 Bits for frames so it require 12
994:53 - bits for 12 bits for the offset can I go
994:57 - the other way from The Logical address
995:00 - yes The Logical address consist of 31
995:02 - bits 19 bits is assigned to page number
995:06 - so I will require 12 bits for offset
995:11 - this the 19 came from
995:13 - here I hope now the whole concept is
995:17 - clear how are we uh doing this or how
995:20 - how are we solving
995:21 - this let me repeat for the last and the
995:24 - final time I know you all are bored but
995:26 - this is an important concept no
995:28 - misconception should remain what happens
995:31 - logical address space is divided into
995:33 - different units called as
995:36 - Pages how many bits we require to give
995:39 - each page a different number that's
995:41 - called the page number so page number
995:42 - will be log 2
995:44 - N The Logical address consist
995:47 - of page number and offset what is page
995:51 - number used for to identify in which
995:53 - page instruction is present and what is
995:55 - this offset used for to identify in
995:58 - which word of that page my instruction
996:01 - is
996:02 - present okay now comes to the physical
996:04 - address part in physical address space
996:06 - what happens this whole main memory is
996:08 - divided into different units called as
996:11 - frames each frame is supposed to store a
996:14 - page each frame is supposed to store a
996:17 - page so I can say the page size will be
996:19 - equals to frame size this logical
996:22 - address is divided into different frames
996:24 - so I require
996:26 - F log to m m is the number of frames log
996:30 - to m is the number of bits for frame
996:34 - number and D will be the same now what
996:36 - is f will useful for f will tell you in
996:39 - which frame your page is present and D
996:42 - will tell you in which word of that page
996:45 - your instruction is
996:46 - present I hope the point is clear now
996:50 - let's see one more question and then we
996:51 - will learn organization of memory
996:54 - management unit in the next lecture the
996:55 - question says the system has 4K pages
996:58 - and 1K frames so the number of pages are
997:00 - 4K so I can say these are 2^ 12 and 1K
997:04 - frames number of frames are number of
997:06 - frames are 1K if I if I can find the
997:11 - frame size somehow so what I will do I
997:14 - will multiply the number of frames into
997:16 - frame size to get the size of main
997:18 - memory which is what the physical inter
997:20 - space that's what is asked so I have to
997:23 - find the frame size somehow but I know
997:25 - frame size equal to page
997:27 - size so how can I find the page size we
997:31 - are given with logical address that is
997:32 - 32 bit so The Logical address space is 2
997:35 - 32 and it is divided into 2^ 12 pages so
997:40 - what is the page size we got 2^
997:43 - 20 so we have how many frames we have 2^
997:48 - 10 frames each frame of size 2^ 20 so
997:51 - I'll get 2^ 30 that is 1 GB is the
997:54 - physical address space so this is what
997:58 - one method is we can go from a different
998:00 - way also we can find the physical
998:02 - address Space by finding the number of
998:04 - bits in physical address and then we
998:06 - will just do like this to find the bits
998:09 - in the physical address we need to find
998:11 - the this part frame number of uh bits in
998:15 - frame number and number of bits in
998:16 - offset how can you find the number of
998:18 - bits in offset with the help of frame
998:21 - size
998:24 - log two log to frame size or log to page
998:28 - size is what the offset
998:32 - is I hope you are not getting confused
998:34 - here let me give you a simple example we
998:37 - got the pay size is 2^ 20 our
998:40 - instruction is residing in one bit of
998:42 - this 2 20 bits to find the address of
998:46 - that particular bit we require we
998:49 - require 20 bits we require 20 bits
998:53 - to give a unique number to 2 20 bytes or
998:57 - a unique number to each word and nothing
999:00 - is given so we will see the memories
999:01 - world uh byte addressable so what what I
999:04 - can say the One World equal to 1
999:08 - byte 2ed to power 20 bytes are there
999:11 - which means each instruction or uh
999:14 - instruction which we want is stored in
999:16 - somewhere in a bite or I want a bite
999:20 - address to access that instruction well
999:22 - that's a better line I I want a bite
999:24 - address to access that instruction how
999:26 - can I find that bite address with the
999:27 - help of these 20 bits these 20 bits will
999:29 - generate 2 20 different kind of
999:32 - addresses that 2 20 different kind of
999:35 - addresses will be assigned to these many
999:37 - bytes in a page in a page so if I want
999:41 - to access a specific bite I want a 2 20
999:45 - bit address so that's what this D is if
999:49 - you're getting confused just remember
999:50 - the formula when you will solve more and
999:52 - more problem
999:53 - problem then this confusion will be
999:56 - eradicated and you will understand the
999:57 - concept for now if you are getting
999:59 - confused remember the formula what is
1000:01 - the formula of D log to page size or log
1000:04 - to frame size both are
1000:06 - same so I got 20 bits here now I have to
1000:10 - find the number of bits in frame number
1000:12 - how many frames are with me there are
1000:15 - total 2^ 10 frames here so I'll require
1000:19 - 10 bits for giving a unique number to
1000:24 - each frame so the total number of bits
1000:27 - in the physical address is 30
1000:30 - bits so what will the physical address
1000:32 - page 2^ 30 that is 1 GB we can also do
1000:35 - like
1000:37 - that
1000:38 - okay so this is what we have done now
1000:41 - logical address logical address space
1000:43 - consist of logical address this logical
1000:46 - address when raised to two ra to power
1000:48 - logical address will give you the
1000:49 - logical address space
1000:54 - this n is the number of pages m is the
1000:57 - number of frames p is the page number f
1001:00 - is the f f is the frame number D is the
1001:03 - offset okay how are you going to find
1001:05 - the page number you will find the page
1001:07 - number with the help of logical address
1001:09 - Space by Page
1001:12 - size how are you going to find the
1001:14 - number of bits in page number log to n
1001:17 - how are you going to find the number of
1001:18 - bits in the soft set log to page
1001:21 - size how are you going to find the
1001:23 - physical address space log to physical
1001:25 - address bits in the physical address how
1001:28 - are you going to find the number of
1001:29 - frames physical address space divided by
1001:33 - frame
1001:34 - size how are you going to find the
1001:36 - number of bits in a frame log 2 m how
1001:40 - are you going to find the offset bits
1001:42 - you can find by log to either frame size
1001:44 - or page size both are same I hope there
1001:47 - is no confusion now in the next lecture
1001:49 - we will learn organization of memory
1001:51 - management unit
1001:53 - so we were learning the address
1001:55 - translation and we have already studied
1001:57 - this analogy of physical address being
1002:00 - translated to logical address for
1002:02 - unbiased checking so our physical that
1002:05 - is the actual role number is being
1002:06 - translated to some dummy number that we
1002:08 - call logical role number for checking to
1002:10 - be
1002:11 - unbiased so what the management does it
1002:14 - translate this to this
1002:17 - but while assigning some dummy number to
1002:19 - the actual role number they must have
1002:21 - maintained some kind of table
1002:23 - so that when the result come they have
1002:27 - to when the result come they have to
1002:29 - upload the marksheet on uh regarding
1002:32 - this role number they are not going to
1002:34 - upload the marksheet of this dummy RO
1002:36 - number how is the student going to check
1002:38 - the marks he only knows his role number
1002:41 - so what happens they have to translate
1002:44 - it again back to the
1002:46 - physical role number how are we going to
1002:49 - how are they going to translate by using
1002:51 - this table they maintain where there is
1002:53 - the actual role number and there is the
1002:55 - dummy number that is assigned so using
1002:57 - this table they do the translation work
1003:00 - same happens in the case of memory
1003:02 - management unit let's go to that part so
1003:06 - in this lecture we will learn about
1003:07 - organization of memory management unit
1003:09 - and this is an important thing so you
1003:11 - have to pay more focus and
1003:13 - attention memory management unit also
1003:16 - maintain a table known as page table but
1003:19 - you have to remember each process has
1003:21 - its own page table each process has its
1003:24 - own page
1003:26 - table I should open that uh translation
1003:30 - diagram in some other
1003:32 - window so there is a process this
1003:35 - process is going to generate a logical
1003:37 - address and this logical address will be
1003:40 - sent to memory management unit memory
1003:42 - management unit will maintain a page
1003:45 - table and from the help of that page
1003:47 - table it is going to give the physical
1003:48 - address you know what logical address
1003:51 - consists of it consists of
1003:54 - page number and offset and what does
1003:56 - physical address consist of it consist
1003:58 - of frame number and offset so in memory
1004:01 - management unit in page table what is
1004:04 - written or what are the entries of the
1004:06 - page table page table
1004:08 - contains page table
1004:11 - contains the frame
1004:13 - number page table contains the frame
1004:15 - number where that page is stored suppose
1004:18 - if I write p 0 P1 P2 so how many entries
1004:21 - will be in the page table the number of
1004:23 - entries will be equal to number of
1004:25 - pages so I will write p 0 is stored in
1004:29 - the frame 7 P1 isor in the frame two P2
1004:32 - is instored in the frame three so this
1004:34 - is what this is what page table looks
1004:37 - like now what happens now what
1004:40 - happens I got this logical address so I
1004:44 - will with the help of this page number I
1004:47 - will go to that page number in the page
1004:49 - table and I will find that this page
1004:52 - number is stored in which frame of the
1004:54 - memory that frame number will be sent to
1004:56 - this Frame number that is logical that
1004:59 - is the physical address and this offset
1005:02 - will be copied as it
1005:04 - is why because frame size is equals to
1005:08 - page size so this is how page table
1005:11 - works so let us understand the points
1005:16 - regarding the organization of
1005:18 - mmu each process has its own page table
1005:22 - page table are stored in the memory and
1005:23 - the important thing is this whole page
1005:25 - table which I have made here this which
1005:28 - will contain frames and P0 to all these
1005:31 - numbers this will be stored here in the
1005:35 - memory this will be stored in the memory
1005:38 - only so the page table are instored in
1005:41 - memory page table are organized as a set
1005:43 - of entries known as page table entries
1005:45 - and you already know what what is in the
1005:47 - page table entries page table entries
1005:49 - contains the frame number
1005:53 - in which the indexed page numbers is
1005:57 - stored page number page table entry
1005:59 - would look like this this is P0 P2 P3
1006:01 - this is how the indexed page number are
1006:03 - stored the first entry corresponding to
1006:05 - the page zero the second entry
1006:07 - correspond to the page One automatically
1006:10 - well this is not the part of page table
1006:12 - entry you should remember
1006:14 - that if in page table looks like this
1006:17 - only F0 F7 fs3 then the index
1006:22 - automatically defines see this is the
1006:24 - index of page 0 so the index
1006:25 - automatically defin that page0 lies in
1006:27 - frame zero this is the index of page two
1006:30 - so the index automatically Define
1006:33 - the frame where this page is stored so 0
1006:36 - 1 2 3 4 if I if it is written somewhere
1006:39 - 22 and here it is written f17 so this is
1006:44 - page number 22 residing in frame number
1006:46 - 17 this is what page table looks
1006:49 - like okay so the number of entries in
1006:53 - the page table will be equal to number
1006:54 - of pages it contains the frame number in
1006:57 - which the page is present you already
1006:58 - know this and it is denoted at as e byes
1007:02 - so this e will be the size of one page
1007:07 - table
1007:08 - entries page table size equals to the E
1007:12 - is the size of one page table
1007:14 - entry the total page table size will be
1007:17 - number of pages because that many
1007:19 - entries will be there and size of each
1007:21 - entry let me rep
1007:23 - page table size will be equal to number
1007:25 - of entries will be equal to number of
1007:26 - pages multiplied by size of each
1007:31 - entry number of entries into size of
1007:33 - each entry this is what page table size
1007:40 - is here's a diagram of page table these
1007:43 - are the index representing the page
1007:45 - number and this binary number will
1007:47 - represent the frame numbers see if it is
1007:49 - written in the page table entry if it is
1007:51 - written like
1007:53 - if if it is written like 1 1 1 and 1 one
1007:58 - so what does this represent this
1007:59 - represent that page number 7 is at frame
1008:02 - number three this is the index
1008:05 - representing the page number and the
1008:07 - actual entry represent the frame number
1008:09 - so how does address translation
1008:11 - work process will generate The Logical
1008:14 - address in logical address you already
1008:16 - know the page number and the
1008:18 - offset this offset will be copied as it
1008:21 - is to the physical address and this page
1008:23 - number where this page number is
1008:25 - residing this corresponding to the page
1008:27 - number five it reside in the frame first
1008:31 - frame that is the 00 frame so this 0
1008:34 - will be sent here this is how we get the
1008:36 - physical address of 12bit and that from
1008:39 - this 12bit address I can directly access
1008:41 - the
1008:42 - memory so this is how translation of
1008:46 - address from logical address to physical
1008:48 - address
1008:49 - Works let's have a small revision let's
1008:52 - say we have a logical address space of 8
1008:54 - KB and logical address
1008:57 - of 13 bits how we got that 3 4 8 and 10
1009:01 - for K so 13 bits we have logical address
1009:05 - physical address space of 4 KB then two
1009:08 - for 4 and 10 for K hence we got 12 bits
1009:12 - our page size is of 1 KB so I can
1009:15 - directly say that offset will be of 10
1009:17 - bits this is how it will going to look
1009:20 - this is our logical address space of 8
1009:23 - KB with a page size of 1 KB so there
1009:24 - will be eight pages P from p 0 to p7
1009:28 - each of size 1
1009:29 - KB physical address space will be of 4
1009:33 - KB and each frame will have a size of 1
1009:35 - KB so there will be four frames F0 F1
1009:38 - FS2 and
1009:39 - F3 okay now let's
1009:43 - say the process generated the address of
1009:47 - p7 so this p7 will be existed from here
1009:51 - this will will be translate will be sent
1009:53 - to the memory management unit which has
1009:55 - access to page table this page table
1009:58 - will tell that this page that is p7 is
1010:01 - held at which frame it is at frame Zer
1010:04 - so 0 will be 0 0 will be at this Frame
1010:07 - number and this offset will be copied as
1010:10 - it
1010:11 - is hence we get a physical address and
1010:14 - from this physical address we are going
1010:16 - to access
1010:17 - the physical address space or main
1010:19 - memory so this how it work now now let's
1010:23 - again discuss some of the formulas page
1010:24 - number number of pages will be logical
1010:26 - address page divided by Page size number
1010:29 - of bits in page number will be log to
1010:32 - number of pages number of bits and
1010:34 - offset will be log to page size number
1010:36 - of frames will be physical address space
1010:38 - upon page size number of bits in frame
1010:41 - number will be log to number of frames
1010:43 - number of bits in offset will be same
1010:45 - log to page size number of bits needed
1010:48 - to refer a word within a
1010:50 - page so this is what offset is for and
1010:54 - each page table entry contains what it
1010:57 - contains the frame number so this is
1010:59 - what e is and the size of page table
1011:03 - will be number of entries in the page
1011:05 - table into page table entry one entry of
1011:09 - a one size of a one page table entry
1011:12 - this is e and this is number of page
1011:13 - table
1011:14 - entries now for the one last time let's
1011:16 - understand again how paging works then
1011:18 - we'll move to the problems so the CPU
1011:20 - generate this logical address which
1011:22 - which has P and D this P will be used to
1011:25 - look for f f will be copied here and D
1011:28 - will be copied here in this way we get
1011:30 - the physical address space that will be
1011:31 - used to access the physical memory or
1011:33 - main memory directly see this CPU
1011:37 - generates this logical address which has
1011:39 - page number and offset this page number
1011:42 - this page number will be sent to this
1011:45 - unit and it also have an output from
1011:48 - page table based register now you may
1011:50 - ask what is Page table based register
1011:52 - the address in the memory where the page
1011:54 - table is stored how CPU or the process
1011:57 - is going to know where my uh where my
1012:01 - page table is stored this page table
1012:03 - base register will tell so from here
1012:06 - they will access the page table with
1012:07 - this page number P1 so the entry of p uh
1012:12 - entry of the page table with index P1
1012:14 - will contain this Frame number frame
1012:16 - number will be copied here object will
1012:18 - be copied here that's how we got the
1012:21 - physical address which is the direct
1012:22 - access to the main
1012:24 - memory okay in the next lecture we are
1012:27 - going to see some of the
1012:36 - problems the a computer system using
1012:39 - paging technique implements an 8 KB page
1012:42 - so the page size I got from here is 8 KB
1012:45 - with a page table size of pts I got is
1012:48 - 24 MB the page table entry is of 24 bits
1012:51 - so I can say e is of three bytes what is
1012:54 - the length of virtual address in the
1012:57 - system we can solve this question using
1012:59 - two methods let us let me write here so
1013:03 - method one is you can go from like this
1013:06 - total virtual memory equals to number of
1013:09 - pages into size of each page or page
1013:12 - size you can either find the size of
1013:15 - total virtual memory like this or the
1013:17 - method two
1013:18 - says find the length of logical address
1013:23 - and then what are you going to do you
1013:24 - are going to do like this this is also
1013:26 - virtual memory size so whichever day you
1013:29 - prefer you can go from
1013:31 - this so the pace size given is 8
1013:35 - KB 8 KB is given I can directly find
1013:38 - that this is p size so D will be of
1013:42 - three bits from for8 and 10 bits for uh
1013:44 - this case so D will be log to 8 KB
1013:48 - equals to 13 bits
1013:52 - and what I'm what else I'm given with
1013:54 - I'm given with page size so now page
1013:56 - table entry page table size page table
1013:58 - size is 24 MB and the size of each entry
1014:02 - is three bytes so I can write number of
1014:04 - entries into e e is 3 bytes so from here
1014:08 - I can write B to be canceled n is 8 m =
1014:12 - to 2^ 3 into 2^ 20 = 2^ 23 so I got
1014:17 - number of pages or number of entries are
1014:19 - 2^ 23 so from here I can go with method
1014:23 - one also the number of pages I got 2^ 23
1014:25 - the size of each page is 2^ 13 2^ 13 so
1014:30 - from from here I can write the total
1014:32 - virtual memory is 2
1014:34 - 36 what method two says here we got the
1014:38 - value of D is 13
1014:40 - bits and from here there is n = to 2^ 23
1014:45 - this is what number of pages are so how
1014:47 - many bits are required to uniquely
1014:50 - address these 20 is for 23 Pages
1014:53 - obviously 23 bits so from here I can go
1014:56 - like the P will be 23 bits the total is
1015:01 - 36 bit La equal to 36 bit so I can draw
1015:04 - from like 2 power la which means 2^ 36
1015:07 - is the virtual memory
1015:10 - size 2^ 36 is 2^ 6 into 2^ 30 this is GB
1015:17 - and this is 64 so our total memory is
1015:19 - total main
1015:21 - memory 64 GB well that is we are talking
1015:25 - about Ram well it's a powerful CPU or
1015:27 - powerful computer it is a powerful
1015:33 - Ram well the main memory is 64 GB that's
1015:37 - a pretty good my laptop has only 16 GB
1015:41 - and initially I remember when I was in
1015:43 - sixth class I got my first
1015:46 - computer and that has 2 GB Ram we used
1015:49 - to play GTA y City uh those days nice
1015:52 - days but nowadays computer really have
1015:55 - like 64 GB
1015:57 - Ram so this was the question which we
1016:00 - have solved another easy question
1016:02 - consider a computer system with 40 bit
1016:04 - virtual addressing and pay size of 16
1016:08 - kiloby so should I solve here or should
1016:11 - just explain here this is an easy
1016:13 - question I should just explain here only
1016:16 - what does it say we have a 40 bit
1016:18 - virtual addressing which means La is of
1016:20 - 40 bits so I can say logical address
1016:23 - space will be of 2 power 40
1016:26 - bytes and a pace size of 16 Koby Pace
1016:29 - size is of 16
1016:31 - kiloby 16 kilobyte so I can write 2^ 14
1016:36 - bytes okay if the computer system has
1016:39 - one level page table per process and
1016:42 - each page table entry requires 48 bit so
1016:45 - the E is of 66 bytes the size of per
1016:50 - process page table is now we have to uh
1016:53 - tell the size of page table we have been
1016:55 - asked with pts so pts will be equals to
1016:57 - number
1016:58 - of pages
1017:01 - into or the number of entries into size
1017:04 - of each entry we are given with size of
1017:05 - each entry is six B 6 by how can I find
1017:09 - number of pages well L ided PS what is L
1017:14 - 2^ 40 what is PS 2^ 14 I should change
1017:17 - the color 2^ 4/ 2^ 14 this is what I
1017:21 - think I think 2^ 26 so the answer will
1017:24 - be pts = to 2^ 26 into 2^ or it is 6 I
1017:29 - think 6
1017:31 - bytes so the answer is 384 MB this is
1017:35 - the page table
1017:37 - size okay so this question can also be
1017:40 - solved using two ways now think about it
1017:43 - the same the similar way which we have
1017:46 - done with in the previous
1017:48 - question let's move to question number
1017:49 - three it says a computer system using
1017:52 - paging technique has a virtual address
1017:53 - of length l so this is virtual address
1017:57 - now I can say that logical address space
1018:00 - will be of 2 power
1018:02 - L the number of pages in the address
1018:05 - space are J N is Zed there are H frames
1018:11 - there are m is
1018:13 - H calculate the number of bits in the
1018:16 - page offset and the size of physical
1018:19 - address space so we have been asked with
1018:20 - the physical address space size and we
1018:22 - have been asked with d how can I find D
1018:25 - we have to find the page
1018:29 - size so we are been given with logical
1018:32 - address space we know the number of we
1018:35 - know the number of pages so we can
1018:37 - directly find page size equals to
1018:39 - logical address
1018:41 - space logical address space divided by
1018:43 - number of pages that is Z 2 to power L /
1018:48 - Z this is what the pa size is so how can
1018:51 - I find the offset from this log 2 2^ l/
1018:56 - Z this is what D
1018:58 - is now physical address space for
1019:01 - physical address space I need to know I
1019:04 - need to know the number of frames number
1019:07 - of frames into frame
1019:09 - size but luckily I know that page size
1019:12 - and frame size are same so I found that
1019:16 - page size is 2 power L by Z and I also
1019:19 - know the number of frames how many
1019:21 - frames are G I have I have H frames so
1019:25 - the physical address space we got is H
1019:27 - into 2^ L by Z okay now let's see what I
1019:31 - have
1019:32 - [Music]
1019:35 - written virtual address is of L bits
1019:37 - number of pages are Zed number of frames
1019:39 - are H how are we going to find D with
1019:42 - the help of page number so log to page
1019:45 - number is what the offset is how are we
1019:47 - going to find physical address space
1019:49 - with the help of number of frames into
1019:50 - size of frame
1019:52 - number of frames is given H how can I
1019:55 - find the size of frame size of frame is
1019:56 - same as size of page so how can I find
1019:59 - the size of Page from here I know that
1020:02 - logical address page is 2 power L the
1020:04 - number of pages are Z the number of page
1020:07 - into page size will be equals to total
1020:09 - memory total logical address space so
1020:11 - pay size equals to 2 power L by Z so
1020:14 - that's what I have written here 2 power
1020:15 - L now we got H into 2 L by Z and we also
1020:19 - got the offset that is log log 2 2 power
1020:23 - L by Z 2's power L
1020:27 - by consider system using simple paging
1020:29 - technique with a logical address of 32
1020:31 - bits so what we have we have logical
1020:34 - address of 32 bits 32 bits so I can say
1020:38 - logical address space is of 2^ 32 bytes
1020:41 - page table entry of 32 bits so I can say
1020:44 - e is of 4
1020:46 - bytes what must be the page size and
1020:49 - bytes so I've been asked with page size
1020:52 - such that page table of process exactly
1020:55 - fit in one frame of
1020:57 - memory what is asked page table of the
1021:00 - process page table of process which
1021:02 - means page table size should be equals
1021:04 - to frame size that's what it is
1021:07 - written page table Pro page table of the
1021:10 - process exactly fit in one frame of the
1021:13 - memory so page table size equals to
1021:15 - frame size what is frame size frame size
1021:17 - is nothing but the page size so this is
1021:19 - written page table size should be equals
1021:21 - to to page size and what is Page table
1021:24 - size number of entries or number of
1021:28 - number of processes which be equal to
1021:30 - number of pages into e we are given with
1021:33 - the value of e that is 4
1021:35 - by now page size this is
1021:38 - what the main cor of this problem is now
1021:42 - we have to find the number of pages how
1021:46 - are you going to find the number of
1021:48 - pages see in this equation we have only
1021:51 - one equation and two variables we can't
1021:54 - solve like that so what we have to do we
1021:56 - have to substitute the value of n what
1021:59 - is the value of n that can be
1022:00 - substituted we know the logical address
1022:02 - space is 2^ 32 so the N can be written
1022:05 - as 2^ 32 divided by the page size this
1022:09 - is what n is number of pages equals to
1022:13 - total memory or total logical space
1022:16 - divided by the paas size so what we have
1022:18 - got two
1022:21 - 2^ 32 divid P size this P size is sent
1022:24 - here it will become P size Square now I
1022:27 - have 2^ 32 into 2^ 2 which is 2^ 34 2^
1022:33 - 34 now what is the P size then we have
1022:36 - to take under root of this so paas size
1022:40 - will be equal to 2^ 17 bytes so this is
1022:44 - the
1022:44 - answer okay let's move to another
1022:47 - question it
1022:49 - says virtual addressal to 32 bits so I
1022:53 - can say virtual address space is 2 32
1022:56 - bytes page size is given 4
1022:59 - KB physical address space is given 64 MB
1023:03 - now we have to find page table size page
1023:06 - table size formula is n into
1023:08 - e we need to First find the value of
1023:11 - number of pages so what is the number of
1023:13 - pages here 2^ 32 this virtual address
1023:16 - page divided by Page size that's how we
1023:19 - can get the number of pages so 2^ 32
1023:21 - divid by by what is Page size 4 KB so 2
1023:23 - power 12 from here we get 2^ 20 these
1023:27 - are the number of
1023:29 - pages but how are we going to find this
1023:32 - page table entry without this we cannot
1023:35 - solve uh we cannot solve for the page
1023:38 - table size we need to find the page
1023:40 - table entry for this we should remember
1023:43 - what is installed in a page table entry
1023:45 - in a page table entry in a page table
1023:47 - entry frame number are stored
1023:52 - in a page table entry frame numbers are
1023:54 - stored so how are we going to find the
1023:57 - frame numbers we see here we are given
1023:59 - with physical address space so the
1024:02 - physical address space divided by Page
1024:04 - size is equals to frame number physical
1024:07 - address space is 64 MB so 2^ 6 into 2^
1024:12 - 20 divided by what is p size P size is 4
1024:16 - KB which is 2^ 2 into 2^ 10 so this is
1024:22 - it got it become 10 and from here it
1024:23 - becomes 4 so 2^ 14 2^ 14 so this is the
1024:28 - number of
1024:30 - frames we have 2^ 14 frames so the page
1024:35 - table entry page table entry size will
1024:37 - be 14
1024:39 - bits the p t entry size will be 14 bits
1024:43 - we can approximately say it is it is of
1024:46 - 2 bytes because we want to find the P
1024:49 - table size in bytes so what we we did we
1024:52 - said that page table entri is of 14
1024:54 - bits see you can also find the value in
1024:57 - bits No One Is Stopping You E equals to
1024:59 - so the page table size and bits will be
1025:02 - 14 into 2^ 20 well that's also an answer
1025:06 - but it looks good when it is written in
1025:07 - the bytes so what we have
1025:10 - done we have changed it to two bytes so
1025:14 - now it become 2 MB now the page table
1025:17 - size is approximately 2
1025:18 - MB now let's understand the performance
1025:21 - of of paging so the first issue which
1025:23 - arises is timing issue you all remember
1025:26 - that page table is stored in memory
1025:28 - suppose this is memory where
1025:30 - instructions and data are stored and
1025:32 - here below page table is stored so what
1025:35 - happens process generates The Logical
1025:38 - address logical address to be converted
1025:41 - into physical address we need to access
1025:44 - the page table also which is the work of
1025:47 - memory management unit so page table is
1025:50 - stored where it is stored in the main
1025:51 - memory
1025:52 - only how much time it will take firstly
1025:56 - it will access the page table so it will
1025:58 - take let's say the memory access time is
1026:01 - M so firstly it will access the page
1026:03 - Table after page table it will get the
1026:05 - physical
1026:06 - address so from physical address it will
1026:10 - access the instruction or data again so
1026:12 - how much time it is
1026:14 - taken M for accessing the page table and
1026:18 - M for accessing the data or instruction
1026:20 - so let us just read what is written here
1026:23 - it says timing issue page table is
1026:25 - stored in memory main memory access time
1026:27 - let's say m and it is in Nan seconds
1026:30 - what is M the amount of time CPU takes
1026:33 - to read or write the word from the
1026:36 - memory so the whenever you access main
1026:38 - memory the time taken is
1026:41 - M and what is the effective memory
1026:44 - access time effective memory access time
1026:47 - is actually 2m why 2 m firstly m is
1026:51 - required to access the page table and
1026:53 - then you get the address so another M
1026:55 - will be required to access the actual
1026:57 - memory or the thing which you actually
1026:59 - want to access so effectively you took 2
1027:04 - m time okay this is what I have written
1027:07 - here process generates virtual address
1027:09 - virtual address first will access the
1027:11 - main memory for getting the physical
1027:14 - address with the help of page table and
1027:17 - then after physical address you will get
1027:18 - the main you will get the address where
1027:21 - you your data or instruction is stored
1027:22 - so you'll access the memory again first
1027:24 - time to access the memory for page table
1027:25 - second time to get the actual
1027:28 - address so where this increases the
1027:31 - execution time suppose if the virtual
1027:34 - address if the process would have
1027:36 - directly generated the physical address
1027:38 - then we would have done it in just m
1027:40 - time but this concept of paging when we
1027:42 - introduced
1027:43 - this the execution time
1027:46 - increased we we want to make this 2 m
1027:50 - close to m while still keeping the
1027:52 - paging concept can we do
1027:54 - this we want to make this 2m the total
1027:59 - time taken is M plus M so what we want
1028:01 - to do we want to make this 2 m close to
1028:03 - M can we do
1028:06 - this so firstly let's focus on reducing
1028:10 - page table M this this m we will try to
1028:13 - reduce okay so how we going to
1028:16 - reduce we will in introduce the cach
1028:19 - memory we will introduce the cach memory
1028:23 - what will cash
1028:24 - memory give us or what will cash memory
1028:27 - bring to the table it is faster it is
1028:30 - well it is a little bit costly it is
1028:31 - small and it allow parallel
1028:35 - searching so what we do we allow some
1028:38 - entries of the page table we store in
1028:40 - the cach memory which has a shorter
1028:42 - excess
1028:43 - time what we do we we follow that there
1028:47 - are some some pages that we frequently
1028:49 - access so what we do
1028:53 - for those entries we maintain another
1028:55 - table that is that is in included in the
1028:58 - cach memory and the access time of cash
1029:01 - memory
1029:03 - is is faster so the time taken to access
1029:07 - cash memory is less than the time taken
1029:09 - to access the main memory so what this
1029:12 - is what we have done here some entries
1029:13 - of the page table we store in the cash
1029:15 - memory which has a shorter exess time
1029:17 - that is C is less than
1029:19 - M so now what is the procedure virtual
1029:23 - address when we generate virtual address
1029:25 - the memory management unit will look
1029:27 - that the generated virtual address is
1029:30 - that page present in the cache memory if
1029:32 - yes then it will access directly from
1029:34 - here and then we will get the address of
1029:38 - we'll get the physical address then it
1029:40 - will access the m so now what is the
1029:42 - time taken we have taken C plus M time
1029:44 - which is surely less than m + m which is
1029:47 - equal to 2 m so what we have done we
1029:49 - have made time lesser than
1029:53 - 2m but in case in case we have created a
1029:58 - cash table or we have introduced a cash
1030:02 - memory we the generated virtual address
1030:05 - that page is not found in the cash
1030:08 - memory then what we have to do we have
1030:09 - to visit the page table again that will
1030:12 - cost even more time than
1030:15 - 2m are you getting the point what I want
1030:18 - to say see first we had a timing issue
1030:22 - what timing issue we had that when we
1030:24 - introduced this concept of paging the
1030:26 - effective memory exess time had become
1030:29 - 2m so in solution we want to decrease
1030:31 - this 2 m time close to
1030:34 - M to do in order to do so we introduce
1030:38 - cache memory a kind of memory which has
1030:41 - a faster access time say if the main
1030:44 - memory access time is M then cash memory
1030:46 - access time will be C so I can say cash
1030:48 - memory access time is lesser than the
1030:49 - main memory access time so now what we
1030:52 - have have done for that virtual address
1030:55 - the page which we want to look for we
1030:57 - will first look in the cach
1030:59 - memory if found then we will directly
1031:02 - get the physical address and we will
1031:04 - access the main memory directly so now
1031:06 - what is the time taken the time taken is
1031:08 - C and M so the time taken is C plus M
1031:11 - which is surely less than 2 m as C is
1031:14 - less than M so I can say C+ m is less
1031:16 - than M plus
1031:18 - M or I can do like that c is less than m
1031:21 - add M both s side C plus m is less than
1031:23 - 2 m this was the main memory exess time
1031:25 - the actual the effective exess time
1031:27 - without the use of cach memory this was
1031:30 - the effective exess time M plus M where
1031:32 - m is the main memory access time C plus
1031:35 - m is the effective exess time if it is a
1031:38 - hit what is hit what is the meaning of
1031:40 - hit hit
1031:43 - is the page which we are looking is
1031:46 - found in the cach memory that is hit so
1031:48 - if it is a hit then the effective exess
1031:50 - time will be C plus
1031:51 - M what is C excess time of cash memory
1031:55 - excess time of main memory which is less
1031:56 - than 2 m so we have we have tried to
1031:59 - decrease the effective ACC exess time
1032:01 - with the help of cash
1032:02 - memory but what happens in the case of
1032:05 - Miss what
1032:06 - [Music]
1032:07 - happens we want to access that page
1032:10 - which we do not access frequently in
1032:12 - that case that page won't be found in
1032:14 - the cash memory so firstly we will look
1032:17 - in the cash memory we didn't find it
1032:20 - then we move move to the page
1032:23 - table there well at page table every
1032:27 - page is stor so there we will find the
1032:29 - actual physical address from that we
1032:32 - access the memory so now it is even more
1032:35 - than 2m what is the total time now time
1032:37 - to access cach memory time time to
1032:40 - access page table time to access the
1032:42 - main
1032:42 - memory this is what it cost to introduce
1032:46 - the cash
1032:48 - memory okay so effective access time now
1032:51 - I can write
1032:54 - is this way if it is hit
1032:59 - then c+m if it is missed then C+
1033:02 - m+m now we call this cash memory as
1033:06 - tlb translation look aside
1033:10 - buffer okay so what we have done till
1033:12 - now we have introduced cash memory cash
1033:15 - memory is faster costly small small and
1033:18 - it includes parallel searching so what
1033:19 - we have done some entries of the page
1033:21 - table that we frequently visit we store
1033:23 - in the cach memory which has a faster
1033:26 - access time which has a shorter access
1033:28 - time okay so C is less than M we first
1033:32 - check in Cache if not available we will
1033:34 - go to the page table and cach is also
1033:36 - known as tlb translation look as head
1033:38 - buffer this is how it looks like CPU
1033:41 - generates The Logical address that is of
1033:43 - page number and offset from page number
1033:46 - what we will do we will make first a
1033:48 - parallel search in the cach memory
1033:51 - as we are doing parallel search that's
1033:52 - why we are faster so C is the time taken
1033:55 - for searching in the cach memory let's
1033:58 - say it is a hit which means we have find
1034:01 - the page which we were looking
1034:02 - for we have found the page which we have
1034:05 - were looking for so tlb hit from here I
1034:07 - can directly know the frame
1034:09 - number and this offset will be copied as
1034:12 - it is and we got our physical address so
1034:14 - what is the time taken here time taken
1034:16 - to access this cash memory and time
1034:19 - taken to access the physical memory so
1034:20 - this this is C+ M now what happens we
1034:24 - have looked all over the cache uh memory
1034:28 - but we do not find the page which we
1034:29 - were looking for now what we will do we
1034:32 - will look for
1034:34 - the that page in the page table we we
1034:37 - had a tlb
1034:39 - Miss now we will search that page in the
1034:41 - page table as you all know page table
1034:44 - contain all the pages so we will find
1034:46 - the frame number of that page which we
1034:48 - were looking for from here we got the
1034:49 - frame number from here we got the offset
1034:52 - now we got the physical address so let's
1034:55 - compare the time which we took firstly
1034:57 - if it is a tlb hit then time to access
1035:00 - cash memory time to access main memory
1035:01 - it is C plus
1035:03 - M if it is a tlb Miss then we will first
1035:07 - access the cach memory to check now it
1035:09 - is a Miss then we will move to the main
1035:12 - memory page table we have found the page
1035:15 - now we'll access the main memory so the
1035:18 - time taken in both the cases the first
1035:20 - case the tlb is C plus M the tlb misses
1035:22 - C plus M plus
1035:24 - M okay so use of tlb is Justified only
1035:28 - if the heat ratio is high what is the
1035:29 - meaning of hit ratio is
1035:31 - high generally we find the page in the
1035:35 - cache we are looking for if this is the
1035:38 - case which means in most of the cases
1035:41 - the probability of finding the page is
1035:43 - high then the use of tlb Justified
1035:46 - otherwise what is the harm the first
1035:49 - harm is this tlb is very costly the
1035:52 - second harm is it is increasing it is
1035:54 - increasing the memory it is increasing
1035:56 - the access time even more firstly it was
1035:58 - 2 m now it is C + m +
1036:02 - m in case of tlb Miss so let me speak
1036:06 - again tlb is only Justified when the
1036:08 - heat ratio is
1036:09 - high okay now another thing if you have
1036:13 - noticed the entry of tlb the entry of
1036:17 - cach memory is different from the entry
1036:19 - of page table in the main memory let me
1036:21 - repeat again the entry of cach memory is
1036:24 - different from the entry of page table
1036:26 - in the main memory in main memory we had
1036:29 - indexes representing the pages and in
1036:31 - the entries we only had frame number but
1036:35 - here we had frame frame number and page
1036:38 - number side by side frame number and
1036:40 - page number side by
1036:42 - side okay so the entry of tlb is p plus
1036:47 - F what is p page number f is frame
1036:49 - number so log to n Pages plus log to M
1036:52 - frames if it is a tlb his then hit then
1036:56 - C plus M Which is less than 2 m if it is
1036:58 - a tlb Miss then C + 2 m which is greater
1037:00 - than
1037:01 - 2m okay now we defined hit ratio as the
1037:05 - name suggest hits upon total number of
1037:08 - searches and what is Miss ratio misses
1037:11 - upon total number of searches so I call
1037:15 - hit ratio as X and miss miss ratio as 1
1037:18 - -
1037:19 - x okay hits hits plus Miss equals to
1037:22 - total so I can now Define the effective
1037:25 - memory access time as time taken
1037:28 - effective memory access time when it is
1037:30 - a
1037:31 - hit effective memory access time when it
1037:33 - is a miss so this is the effective
1037:35 - memory access time using
1037:38 - tlb paging with tlb and physical address
1037:42 - cach if you remember we had the
1037:45 - effective memory access time of
1037:47 - 2m what we did we first access the page
1037:50 - table then from page table we get the
1037:52 - physical address and from there we
1037:55 - access the main memory instruction data
1037:57 - so it took M here and M here we tried to
1038:00 - reduce this m with the help of tlb with
1038:04 - tlb we introduced a cach concept of
1038:07 - parallel searching and this DLB reduced
1038:10 - the address translation
1038:12 - time we are applying the same concept
1038:15 - here physical address
1038:17 - cache this cache will reduce the the
1038:21 - final access time this is the m that we
1038:23 - are using to access the main
1038:27 - memory let me give you the proper
1038:30 - explanation
1038:34 - here let's say x is the hit ratio C1 and
1038:38 - C2 are the cach excess time C1 belongs
1038:40 - to tlb and C2 belongs to PC X1 is the
1038:43 - hit ratio of tlb and X2 is the hit ratio
1038:45 - of PC hope you remember what is hit
1038:47 - ratio the thing which we are looking for
1038:50 - if found in that cach that is a hit and
1038:53 - what is hit ratio Hit Upon total hits
1038:55 - upon total searches and what is a miss
1038:58 - miss upon total searches and Miss plus
1039:03 - hit this should be
1039:05 - one okay
1039:07 - so now we are going to see how this
1039:10 - thing this all tlb and PSC thing work
1039:13 - this is pi process in the CPU this
1039:16 - generates a virtual address this is p
1039:18 - and this is d p is the page number and D
1039:20 - is the off set you all know D will be
1039:22 - copied as it is in the physical address
1039:24 - we have to we have to find the frame
1039:27 - which contains this page number so
1039:30 - firstly we will look in the tlb cache
1039:34 - this will do the parallel searching and
1039:35 - tries to search if this page number is
1039:39 - in which frame number this page number
1039:41 - is in which frame number if it is
1039:44 - available here if we found that if we
1039:46 - found the frame number then we call it
1039:48 - as tlb hit that frame number number will
1039:50 - be passed on here D will be copied from
1039:53 - here here we got our physical
1039:55 - address the case two was the page number
1039:59 - which we are looking for is not
1040:01 - available in tlb in that case we will
1040:04 - first search for the tlb we first
1040:06 - searched for the tlb we failed now we
1040:09 - are going to page table that is tlb Miss
1040:12 - so the total time will be C plus M that
1040:15 - you all know and from here f it will be
1040:19 - F will come from here D will come from
1040:21 - here and there we got our physical
1040:23 - address till this part we have discussed
1040:25 - in the last lecture now comes the
1040:27 - interesting story what we do this is our
1040:30 - physical address this process wants to
1040:33 - access this instruction or
1040:34 - data so this physical address we will
1040:37 - search the corresponding instruction and
1040:40 - data regarding a physical address in
1040:42 - physical address
1040:44 - cache this physical address will be
1040:47 - searched here this physical address will
1040:49 - be searched here
1040:51 - parallel searching will happen and if
1040:53 - found then that corresponding
1040:55 - instruction and data will be accessed to
1040:56 - that process we call that as pacc hit
1041:00 - but what happens this physical address
1041:02 - was not available in the P then we will
1041:06 - move to the main memory and from Main
1041:09 - memory we will find the physical address
1041:12 - and that instruction and data will be
1041:13 - accessible to the process so that's how
1041:15 - that's how it work let me give you a
1041:17 - full
1041:18 - flowchart we first tried to look in the
1041:20 - tlb that page if it is not available
1041:23 - then we'll move to the page table from
1041:26 - either from tlb or from page table
1041:28 - depending on the hit or miss we will
1041:30 - find the frame number in which frame
1041:32 - number or page is stored and we will
1041:34 - find the offset directly from the
1041:36 - virtual address here we got our physical
1041:39 - address now we will look for this
1041:41 - physical address in PC if it is
1041:44 - available then that corresponding
1041:46 - instruction or data will be accessible
1041:47 - to the process if not we will look that
1041:50 - physical address in the main memory and
1041:51 - now that instruction of data will be
1041:53 - accessible to the process that's how it
1041:55 - worked so this was tlb hit this was tlb
1041:59 - Miss this was PS hit this was P Miss
1042:03 - okay now it's time to understand the
1042:04 - effective memory exess time of this tlb
1042:06 - and Pac the case one is we had a tlb we
1042:10 - had a tlb hit let me write here case one
1042:14 - tlb
1042:15 - hit phase two and then phase two case
1042:18 - two is tlb Miss
1042:22 - and then phase two what does phase two
1042:25 - contain phase two contain PSC hit and P
1042:31 - Miss okay so we are going to write
1042:35 - according to that so the first
1042:37 - is hit tlb
1042:40 - hit we find the physical address here
1042:44 - now from here it starts the phase two it
1042:47 - is PSA hit we found the instruction of
1042:50 - data
1042:52 - here PS Miss we first searched in the
1042:56 - PSC as it was a Miss then we came to the
1042:58 - main memory this was the case for tlb
1043:01 - hit now what happens we had a tlb Miss
1043:04 - we first looked in the tlb then we
1043:07 - looked in the page table now we have got
1043:10 - our physical address we will start
1043:12 - looking for the instruction of data in
1043:14 - the first we will look in the PSC let's
1043:18 - say it is a hit then we have exist from
1043:20 - the P only if it is a Miss we will first
1043:23 - look in the PC then in the main memory
1043:26 - so this is
1043:27 - how we have tried to reduce the excess
1043:30 - time we have tried to solve the timing
1043:32 - issue with tlb and physical address or
1043:35 - basically we have used the cach
1043:38 - memory let's solve some questions
1043:41 - consider system using paging with
1043:43 - tlb what hit ratio is required to reduce
1043:46 - the effective memory exess time from D
1043:49 - to Zed using TLP assume that TLP ex time
1043:52 - is K second so initially the time was 2m
1043:57 - finally the time
1043:58 - was we had
1044:01 - a tlb hit and then the accessing of C
1044:05 - this is for the tlb hit this is for
1044:07 - accessing the tlb or Cache memory this
1044:10 - is for accessing the main memory we had
1044:12 - a tlb miss this is for accessing the tlb
1044:15 - this is for accessing the page table
1044:17 - this is for accessing the memory now
1044:19 - what are we doing here
1044:21 - we are asked with this x what should be
1044:23 - the X such that we will reduce our
1044:26 - effective memory exis time from D to Z
1044:29 - initially it was D now it is Zed so from
1044:33 - here we can find the value of M what is
1044:34 - m m will be equal to D by2 we put the
1044:37 - value of M we are given with the tbx
1044:39 - system that is we are given with the
1044:40 - value of C we put the value of C also so
1044:43 - we have put the value of M we have put
1044:45 - the value of C so now we will find X so
1044:48 - from here we got X as k + z k + D minus
1044:51 - Z into 2
1044:53 - byd okay so this is the this is the uh
1044:58 - schematic view of how paging in with tlb
1045:01 - is done CPU generates The Logical
1045:03 - address from here we will look if it is
1045:05 - available in the cache if yes that is a
1045:07 - tlb hit and then here we find our frame
1045:10 - number this D will be copied as it is if
1045:13 - it is a tlb Miss if it is not found then
1045:15 - we will go to the page table from here
1045:18 - we find our frame number and
1045:21 - D will be copied as it is this is our
1045:23 - physical address we will access the main
1045:25 - memory now comes the second issue that
1045:28 - is space consumption issue you know the
1045:31 - page table size is number of processes
1045:35 - or I should say number of pages is not
1045:37 - each process has a separate page table
1045:41 - so this is number of number of pages it
1045:44 - was a slip of time equals to number of
1045:48 - entries okay so number of entries into
1045:51 - size of each entry what the page table
1045:52 - size is let's say we have a logical
1045:56 - address of 32
1045:57 - bits okay and Pace size is of 4 KB so
1046:01 - The Logical address space will be of 2^
1046:04 - 32
1046:06 - bytes n that is number of entries will
1046:08 - be 2^ 32 divided by 2^ 12 this is 2^ 12
1046:12 - bytes so we have around 1 million
1046:16 - entries and if each entry has a size of
1046:19 - four bytes then we have a page table of
1046:22 - 4 MB for each process we have a 4 MB
1046:27 - page table now Suppose there are 100
1046:29 - process then 400 MB of main memory is
1046:33 - just to store the page tables can you
1046:35 - can you imagine that 400 MB of main
1046:38 - memory just to store the page table well
1046:41 - that's a serious concern and we need to
1046:42 - reduce the space consumption so how are
1046:45 - we going to reduce the page table size
1046:47 - look at it we know that page table size
1046:50 - is equal to n into
1046:52 - entry this entry is fixed this entry
1046:55 - size is fixed what we can do we can draw
1046:59 - a relation that page table size is
1047:01 - directly dependent on the page on the
1047:04 - number of entries and this number of
1047:07 - entries is direct is directly or I
1047:10 - should say this number of entries is
1047:12 - directly dependent to one by Page size
1047:14 - or indirectly dependent to indirectly
1047:16 - dependent to page size so I can say page
1047:19 - table size is indirect ly dependent to
1047:20 - or indirectly proportional
1047:23 - to page size so if I say if I increase
1047:27 - the page size then page table size will
1047:30 - decrease why page table size will
1047:32 - decrease because if I increase the page
1047:34 - size then number of entries will
1047:37 - decrease in that manner pce table size
1047:41 - will decrease so we can reduce the pce
1047:43 - table size by increasing the paase size
1047:47 - we can reduce the P table size by
1047:49 - increasing the paas size
1047:50 - but but but there are side effects too
1047:53 - now this is your homework to
1047:55 - find what what are the disadvantages of
1047:58 - increasing the page
1048:01 - size in the last lecture we were
1048:03 - discussing about the performance of
1048:05 - paging we have seen the timing issue the
1048:07 - spacing issue to solve the timing issue
1048:09 - we tried using cach memory and to solve
1048:13 - the spacing issue we thought of that to
1048:16 - decrease page table size what is the
1048:18 - formula number of entries into size of
1048:21 - each entry we cannot change this but we
1048:23 - can change this so how are we going to
1048:28 - make this n small so in order to
1048:30 - decrease the page table size we can do
1048:32 - that by increasing the page size if page
1048:35 - size is large then the number of pages
1048:37 - will be less to cover the entire logical
1048:40 - space that is very obvious but
1048:44 - increasing the page size directly comes
1048:46 - with a several side effects the first
1048:48 - one is internal fragmentation
1048:50 - if you increase the page size more
1048:52 - internal fragmentation will occur see
1048:54 - this example suppose I have a program of
1048:56 - 1026 bytes and we have a pages of size
1049:00 - 1024 bytes only so what we will do 1024
1049:06 - of this 1026 will be stored in page one
1049:09 - and only two
1049:10 - bytes will be stored in page two so you
1049:13 - can see one22 bytes are wasted you
1049:16 - cannot store another program here in
1049:18 - this 1022 Byes this is completely
1049:21 - wastage so the internal fragmentation
1049:23 - here is 1022
1049:25 - bytes but let's say we decrease our page
1049:28 - size we have a pages of size 2 bytes
1049:32 - only so in just 513 pages with 2 bytes 2
1049:36 - bytes 2 bytes each we will cover the
1049:38 - whole 1026 byte
1049:42 - program here you can see number of pages
1049:45 - are obviously more but internal
1049:47 - fragmentation is zero it's completely
1049:50 - zero we won't waste a single bite here
1049:54 - so here we can see if we increase the
1049:56 - page size internal fragmentation will be
1049:58 - more and if pay size is less internal
1050:01 - fragmentation will be less that's what I
1050:02 - have written now the question arises if
1050:06 - we cannot increase the pay size so much
1050:08 - then what should be the optimal pay
1050:11 - size so let's say we have a virtual
1050:13 - address space of s bytes page table
1050:16 - entry consist of e bytes and Page sizes
1050:19 - of P bytes
1050:21 - we are finding the optimal
1050:25 - P optimal p means in which page table
1050:28 - size and internal fragmentation both are
1050:31 - minimum see if we increase the page size
1050:35 - page table size decreases but internal
1050:37 - fragmentation increases we want such
1050:40 - paas size in which internal
1050:42 - fragmentation is also minimum and Page
1050:44 - table size is also
1050:46 - minimum so what is will be the page
1050:49 - table size according to this s by P will
1050:52 - give number of pages into e will be the
1050:55 - page table size that's what I have
1050:56 - written
1050:57 - here internal fragmentation happens in
1051:00 - the last page of every process let's say
1051:02 - p by2 goes to the
1051:04 - waste okay so in last page of every
1051:07 - process internal fragmentation happens
1051:09 - see here also internal fragmentation was
1051:11 - where it was not in the first page it
1051:13 - was in the last page so what it is
1051:16 - saying it is saying that internal
1051:17 - fragmentation happens in the last page
1051:18 - of every process
1051:20 - we are assuming that for for the purpose
1051:22 - of solving this we are assuming that P
1051:25 - by 2 goes to
1051:27 - waste okay so the total overhead
1051:31 - is of this paging thing the total
1051:34 - overhead is px2 that is internal
1051:36 - fragmentation and S by P that is the pce
1051:39 - table size we want to minimize
1051:43 - this and how are we going to minimize
1051:45 - this we will differentiate this space
1051:47 - table or we will differentiate this
1051:49 - total overhead and make it equals to
1051:52 - zero and differentiate in respect of
1051:54 - what which variable we want to optimize
1051:56 - we want to optimize this page table page
1051:59 - size so we'll differentiate with respect
1052:00 - to page size this s e are constant and 1
1052:05 - by P what is the differentiation of 1x P
1052:07 - - 1X p s what is the differentiation of
1052:10 - P this 1X 2 will remain constant it is 1
1052:13 - so - 1 by p s e + 1X 2 and we will
1052:18 - equate it to zero and then we will solve
1052:21 - for p we got the value of P equal to 2 s
1052:25 - e we got the value equals to 2 s e now
1052:29 - if we say p by n goes to the waste here
1052:32 - here we have written if p by2 goes to
1052:35 - the waste that is half of the page goes
1052:38 - to
1052:39 - waste then the answer will be root2 SC
1052:42 - where s is the size of virtual address
1052:46 - space and E is the size of each entry of
1052:49 - the page table now I say if P by n goes
1052:52 - to the vist which means nth part of the
1052:55 - page of last or I I should properly say
1052:59 - this nth part of the last page of the
1053:04 - process nth part of the last page of the
1053:06 - process if that an part goes to the
1053:09 - waist then the optimal page size should
1053:14 - be root NS e where nth part is the vage
1053:17 - S is the virtual add space and E is the
1053:19 - past table entry
1053:21 - size so page size indeed impacts page
1053:25 - table size and internal fragmentation so
1053:28 - we want such page size in which page
1053:31 - table size is also less and internal
1053:33 - fragmentation is also
1053:42 - less let's start with a nice question it
1053:45 - says we have 2^ 32 byte of address space
1053:50 - 2^ 13 byte of page size and the page
1053:55 - table entry has four byte each page
1053:59 - table entry has a size of 4
1054:01 - byte when a process starts the page
1054:04 - table is copied to Hardware from memory
1054:07 - so from memory it is copied to Hardware
1054:10 - let's denote Hardware like
1054:12 - this at one word every 100 nond so this
1054:16 - is the speed of transfer one word is
1054:19 - transferred in 100 nond if each process
1054:23 - runs for 100
1054:26 - milliseconds including the time to load
1054:28 - the page table what fraction of CPU time
1054:31 - is devoted to loading the
1054:33 - page okay so first we will first
1054:37 - calculate the number of pages so the
1054:39 - number of pages will be logical address
1054:42 - page divided by Page size this will give
1054:44 - me I think 19 so the number of pages
1054:46 - will be 19 2^ 19 will be the number of
1054:48 - pages
1054:51 - each entry has 4 byte each entry has 4
1054:55 - byte so I can say the total page table
1054:59 - size will be 2^ 19 into 2^ 2 this is 2^
1055:05 - 21 byte this is what the page table size
1055:09 - is so it is nothing but 2 MB 2 MB is the
1055:13 - page table
1055:14 - size now it says if each process runs
1055:17 - for 100 millisecond
1055:20 - so this will include the burst time and
1055:23 - here it is written including the time to
1055:25 - load the p t so the process time will be
1055:28 - burst time plus page table load time and
1055:31 - that is given as 100
1055:35 - millisecond now the question is what
1055:38 - fraction of CPU time is devoted to
1055:39 - loading the page well that way we can
1055:42 - get that by load time divided by process
1055:45 - time load time divided by or I can say
1055:48 - total time this will give me what the
1055:51 - percentage of CPU devoted for
1055:55 - loading or if someone asked me what is
1055:58 - the percentage of CPU for just the burst
1056:01 - time not for the loading then I will
1056:03 - write burst Time divid by process time
1056:05 - this process time is the total time and
1056:07 - whichever percentage is being asked that
1056:09 - will be kept in numerator so load time
1056:11 - divide by process time into 100 because
1056:13 - we are were asked in percentage or what
1056:15 - fraction you can also solve like that if
1056:18 - you are asked with fraction that remove
1056:19 - this this
1056:20 - 100 but if we are writing in percentage
1056:23 - then we can multiply with 100 okay so it
1056:27 - says load time we have to first
1056:28 - calculate the load time how are we going
1056:30 - to calculate the load time we know that
1056:34 - the page table size is 2 21 by and one
1056:38 - word is loaded in 100 nond one word is
1056:43 - loaded in 100
1056:44 - nond now what is one word where it is
1056:48 - written the of word see here I have told
1056:52 - you that the page table is also a part
1056:55 - of memory and in in each page table it
1056:58 - is divided into
1057:00 - entries so this entry is also equal to
1057:05 - one word see what was one word the main
1057:08 - memory is divided into several units
1057:11 - several equal units this is what one
1057:13 - word was so this page T is also a part
1057:16 - of main memory and it is also divided
1057:18 - into some equal units which is called
1057:21 - word so this e will be equal to one word
1057:24 - so what is the value of e here 4 by so I
1057:27 - can say 4 byte is transferred in 100
1057:30 - nond how much this page table that is 2
1057:33 - 21 byte will take so it will take 100 ID
1057:36 - 2^ 2 into 2^ 19 I mean it will take 2^
1057:40 - 19 into 100
1057:42 - nond so the load time is 2^ 19 into 100
1057:48 - nond the process time is 100 millisecond
1057:52 - so which what will the percentage CPU
1057:54 - load time what will the percentage CPU
1057:57 - load time it will be 2^
1058:00 - 19 into 100
1058:03 - nond divided by 100 where this 100 came
1058:08 - from this 100 came from here 100 and
1058:13 - millisecond this millisecond is
1058:15 - converted into nanc so 1 millisecond
1058:18 - contain 10 6 NS we were given that the
1058:22 - load time is in Nan seconds see here 2^
1058:26 - 2 is transferred in 100 nond so we have
1058:29 - to convert the unit that's why we have
1058:31 - written
1058:35 - here 10 to 10^ 6 nond so this 100 to 100
1058:39 - will be canceled this 10^
1058:43 - 6 is kept here 2^ 9 is here see this
1058:49 - what are we doing here this 2^ 19 is
1058:53 - divided into two part 2^ 9 and 2^ 10
1058:57 - what is 2^ 10 it is 1024 but for the
1059:00 - sake of Simplicity we are keeping it as
1059:03 - 1,000 just for the approximation thing
1059:06 - so this 2^ 10 can be written as 10^ 3 so
1059:09 - from here
1059:11 - three 6 will be converted into three now
1059:13 - what are we left with 2^ 9 upon 10^ 3
1059:17 - and if we are finding it in percentage
1059:19 - then we will multiply it with 100 also
1059:21 - and if not then just keep this what is
1059:23 - 2^ 9 512 what is 10^ 3 it is th000 so
1059:28 - 512 divid 1,000 it will give 100 0152
1059:32 - this is the fraction of
1059:34 - CPU time devoted for
1059:37 - loading did you got the solution let me
1059:40 - repeat again let me summarize again so
1059:42 - what we had we had a question in which
1059:45 - what
1059:46 - happened we are given with some data and
1059:49 - it is is asked that how much fraction of
1059:52 - CPU time is devoted to load the page
1059:54 - table and the process runs for 100
1059:57 - millisecond this process time also
1059:59 - include the page table load
1060:01 - time so the percentage of CPU for
1060:04 - loading will be load Time divid by total
1060:07 - time into 100 so we have to find the
1060:10 - load time and process time we were given
1060:12 - with process time that's why we kept it
1060:14 - as it is 100 millisecond here we have to
1060:16 - find the load time how are we going to
1060:18 - find the load time
1060:19 - [Music]
1060:21 - we were given that 4 byte is transferred
1060:24 - in 100
1060:25 - nond then the whole page table will be
1060:28 - transferred in how much time so you have
1060:30 - to first find the size of page table how
1060:33 - can we find the size of page table we
1060:34 - know the formula number of entries into
1060:37 - size of each entry we were given that
1060:38 - size of each entry was 4 by we have to
1060:41 - find number of entries we know that
1060:42 - number of entries is equal to number of
1060:44 - pages how can you find number of pages
1060:46 - we were given with page size that is 2
1060:49 - 13 by and we were given with the logical
1060:52 - address space that is 2^ 32 so we can
1060:55 - write it as 2^ 19 so the number of
1060:58 - entries are 2^ 19 and 4 byte will be
1061:03 - multiplied and this will give me the
1061:04 - page table size that is 2^ 21
1061:08 - by now 4 by is transferred in 100 n 2^
1061:12 - 21 bytes will be transferred in how much
1061:13 - Nan so this will be transferred into T
1061:16 - 19 into 100 nond
1061:19 - so we will put the value of load time
1061:21 - here we know the process time here but
1061:24 - what is the problem this is given in
1061:25 - millisecond this is given in nanc so we
1061:27 - have to convert this millisecond into
1061:29 - Nan so this will be 10^ 6
1061:32 - nond how we converted that we know that
1061:36 - 1 second
1061:38 - involve 1,000 millisecond and 1 second
1061:41 - involved 10 power 9 nond so 1
1061:45 - millisecond will involve 10^ 6 nond
1061:49 - okay so that was put solved but we had
1061:53 - made a little approximation here we have
1061:55 - written 1024 equals to 1 0 just for the
1061:58 - sake of
1061:59 - Simplicity this will give me 10^ 3 so
1062:03 - from a million this 1,000 will cut a
1062:05 - million and will leave 1,000 now we have
1062:08 - 52 divid 1,000 so this will give me the
1062:13 - 0.512 but if we are finding in
1062:16 - percentage then it will be around 50%
1062:19 - let's see an interesting question it
1062:20 - says consider a system using paging
1062:23 - technique with a address space of
1062:25 - 65536 bytes you should remember this
1062:28 - number this is 2^ 16 okay the page size
1062:31 - in this system is 4096 bytes what is
1062:34 - this it is 1024 into
1062:36 - 4 the program consist of Text data and
1062:40 - stack sections as per the specification
1062:42 - given below so the text is of this much
1062:44 - bite data is of this much bite and stack
1062:46 - is of this much bite the page of a
1062:48 - program contains portion of only one
1062:50 - section that is either text or data or
1062:53 - stack does the program fit in the given
1062:55 - address space so the first approach some
1062:58 - of you might think is we can add all of
1063:01 - them and see whether this is equal to
1063:03 - 65536 or not if yes uh if it is equal to
1063:08 - or less than 3 65536 if yes then the
1063:10 - program fit if no then the program
1063:12 - doesn't fit well this is the worst
1063:14 - approach to follow because we are seeing
1063:16 - page wise a page can contain only either
1063:20 - text or data or text suppose this is our
1063:22 - page and it has only this much text then
1063:27 - this page will be wasted let me repeat
1063:30 - again to divide this into Pages let's
1063:33 - suppose in the last page we had this
1063:35 - much text only so this part will be
1063:38 - wasted so by just adding these we cannot
1063:41 - tell that this program will fit or not
1063:44 - because the program is divided page wise
1063:46 - and each page can contain only text data
1063:48 - or step
1063:49 - if it was written that a page can
1063:51 - contain text also it can contain some
1063:54 - part of data also and stack also which
1063:57 - means there is no kind of restriction
1063:58 - then I can say if I just add off all of
1064:00 - them and compare with the
1064:02 - 65536 so how are we going to solve this
1064:05 - question well it is easy we will divide
1064:07 - it into pages so for text how many page
1064:10 - are we going to require let's see what
1064:12 - is the what is the text bytes it is 3 2
1064:17 - 76 8 divided by 4096 so we are going to
1064:21 - require eight pages so eight pages for
1064:24 - text and then
1064:27 - 16386 divid 4096 we have got
1064:31 - 4.4 some pages so how many page we are
1064:34 - going to require four page and that's
1064:36 - where you have made the
1064:38 - mistake this data section will require
1064:41 - the five pages don't make the don't make
1064:43 - the mistake of approximation why is this
1064:46 - so let me tell you so this data section
1064:49 - has some like 4. four pages required so
1064:52 - four complete pages will be filled three
1064:55 - and four and the fifth one will be
1064:57 - minutely filled with that
1064:59 - 04 and what I have told you that a page
1065:03 - of a program contain the portion of
1065:04 - either text data or stack so if this
1065:07 - page is installed with data then you
1065:10 - cannot use this
1065:12 - space so if I do the approximation like
1065:14 - this this is 2^ 14 bytes and 16 KB so
1065:18 - what I did I I set it four this is where
1065:21 - you will make the mistake and now for
1065:23 - the stack section
1065:26 - 15870 divided by 496 this is 3.87 so how
1065:31 - much pages will it require three
1065:33 - complete pages
1065:34 - and 87 filled page so three complete
1065:38 - pages and 87 filled page this page will
1065:41 - be filled and this page will be wasted
1065:43 - so four pages required for this five
1065:46 - pages required for this and eight pages
1065:48 - required for this 8 and 5 13 13 and 4 17
1065:51 - how many pages does we have in our
1065:53 - program
1065:55 - divide
1065:56 - 655 36 with 4096 these much Pages we had
1066:01 - what is
1066:02 - 65536 it is the address bace and what is
1066:05 - 4096 page size so address space upon
1066:07 - page size will give you number of pages
1066:09 - so we had 16 pages but this program will
1066:12 - will consume 17 pages so I can say the
1066:15 - program does the program fit in the
1066:16 - given address space no the space of 2^
1066:19 - 16 we have base size we first calculated
1066:21 - the number of pages and we we calculated
1066:24 - how much Pages required for Text data
1066:25 - and stack for text 8 Pages for data for
1066:28 - data we will require five pages for this
1066:31 - part okay so even if you do like this if
1066:34 - you even if you take the log in like 2^
1066:38 - 14 thing then you won't have a complete
1066:40 - 14 you have
1066:42 - 14.1 and that is going to consume
1066:46 - another page so we cannot write it as 4
1066:49 - 14 so this will require five pages and
1066:53 - in the last page lots of internal
1066:55 - fragmentation will be there so total 17
1066:57 - Page required but we have only 16 so
1066:59 - we'll say
1067:01 - no instead of 4 kiloby if P sizes of 4
1067:05 - byte then what would happen we are going
1067:07 - to follow the same approach we will find
1067:09 - the number of pages we will find the
1067:11 - number of pages in each of the text data
1067:13 - in stack and number of pages the address
1067:15 - space is divided into if the sum of the
1067:18 - number of pages in these is less than or
1067:21 - equal to the number of pages in the
1067:22 - address space then I'll say it will be a
1067:25 - fit so number of pages is 2^ 16 divid 2^
1067:30 - 2 which is 2^ 14 so I have 1 16 384
1067:33 - pages in the address space now we have
1067:36 - to find the number of pages in Text data
1067:38 - and step how are we going to find just
1067:41 - divide it
1067:42 - by
1067:45 - 4 so just divide it by 4 by so we have
1067:49 - 8192 4097 and 3968 pages in text Data
1067:54 - stag respectively add them all we got
1067:57 - 16257 which is definitely less than
1067:59 - 16384 so I'll say instead of 4 kiloby if
1068:03 - Pace size would have been 4 byte
1068:06 - then the program would easily fit in the
1068:10 - previous case why the program was not
1068:12 - able to fit because of this much
1068:14 - internal
1068:16 - fragmentation okay maximum some page
1068:19 - size for program profit so what we have
1068:20 - done here we have reduced the page size
1068:22 - so many
1068:24 - times but what we want we had a page
1068:27 - size of initially we had a page size of
1068:29 - 4 kiloby when we reduced it to 4 byte
1068:33 - that is multiple times reduction then
1068:35 - the page then the program easily fit
1068:38 - onto the address space but what we want
1068:41 - we want the minimum reduction in this
1068:43 - page size or we want that maximum page
1068:46 - size such that program will fit
1068:49 - so what we have done we the total is
1068:52 - Pages 2^ 16 bytes n which means the
1068:55 - number of pages will be 2^ 16 divid by
1068:59 - let's say the page size is 2^
1069:01 - X = to 2^ 16 - x so number of pages
1069:06 - required for text is 2^ 15 - x for data
1069:10 - is 2^ 14. that four thing - x and for
1069:15 - stack is 2^ 13.95 - x
1069:19 - so what we'll
1069:20 - do we have tried to compare the number
1069:24 - of pages here and some of all these
1069:25 - Pages here so that's what it is this is
1069:29 - the equation but the problem is we
1069:31 - cannot solve this like that solving the
1069:33 - X from this equation is difficult
1069:36 - thing so what is the solution then try
1069:39 - this this is your
1069:41 - homework now let's learn what is hashed
1069:44 - paging I hope you all remember what is
1069:47 - hashing simp similar thing we are going
1069:49 - to implement here we are going to
1069:51 - associate a smaller page table with a
1069:54 - process what is the purpose of hashing
1069:57 - the purpose is to organize data in such
1069:59 - a way that searching becomes easy each
1070:02 - element will be associated with an
1070:05 - index so we will design a page page
1070:07 - table using hashing table and that will
1070:10 - be known as hashed page table don't
1070:11 - worry if you're not getting it let's see
1070:13 - with an help of an example suppose I
1070:15 - have a virtual address of 32 bits page
1070:17 - size is of 4 KB so 2^ 32 divid 2^ 12
1070:20 - this give me 2^ 20 these many number of
1070:23 - pages will be there so I have 1 million
1070:26 - Pages number of pages in page table will
1070:29 - be number of pages in the memory and how
1070:33 - many pages I have 1 million pages so in
1070:35 - page table I would have 1 million
1070:38 - entries but let me tell you a shocking
1070:41 - fact out of these 1 million entries
1070:43 - process generally use around 5 to six
1070:46 - pages only
1070:48 - but what conventional paging says even
1070:51 - if process use only five to six pages
1070:53 - but you have to store this whole page
1070:55 - table in the
1070:57 - memory that's what it is making space
1071:03 - inefficient suppose I have a modulo 10
1071:06 - function so what does modulo 10 function
1071:08 - do it gives me the last digit of a
1071:12 - number take the example I have 1076 I
1071:15 - hope you know what is modulo modulo gave
1071:18 - me the the remainder when divided by 10
1071:20 - for this 1076 mod 10 the answer should
1071:23 - be 6 which is the last digit how did I
1071:25 - got it see here divide by 10 1 10 7
1071:29 - comes down 6 comes here 0o and then
1071:33 - 7 7 0 6 this is how I got the answer as
1071:37 - six so whatever be the number the last
1071:42 - digit will be the answer so so how many
1071:46 - possibilities of the answer are there
1071:48 - for last dig for last digit I can have 0
1071:50 - 1 2 till 9 so these 10 entries are
1071:54 - possible if I have modular 10 function
1071:56 - let me repeat if I have modular 10
1071:58 - function then the result will always be
1072:00 - the last digit for that there will be
1072:03 - only 10 entries in my has table suppose
1072:05 - I have 1076 and 666 what will be the
1072:08 - modulo 10 function result it will it
1072:11 - will give six it will give six so both
1072:12 - want to be at the same index but what
1072:16 - happens only one entry can be present in
1072:19 - one index well that will lead to
1072:21 - Collision that will cause
1072:24 - problem i1 and I2 these numbers are
1072:26 - different but their last digit is same
1072:30 - so what it will lead to it will lead to
1072:31 - Collision so what are the Collision
1072:34 - resolution technique probing and
1072:35 - chaining here to resolve Collision we
1072:38 - will use chaining and chaining is
1072:39 - implemented using linked
1072:42 - list by hearing this by hearing link
1072:45 - list you must have a guessed what are we
1072:47 - going to do with the CH this Collision
1072:49 - problem suppose I have
1072:53 - 1076 settled at index 6 now another
1072:57 - number comes modul 10 the answer is six
1073:01 - want to go at this index but what
1073:03 - happens 1076 is already there so what I
1073:06 - will do I am going
1073:08 - to do like this I'm going to make it as
1073:11 - a linked
1073:14 - list suppose now another number come
1073:16 - let's say 56 so I will make another node
1073:19 - of 56 so this is how I am I will solve
1073:23 - the Collision problem see here each of
1073:27 - the desire of each of the number is
1073:28 - satisfied what every number wanted these
1073:31 - this all number wanted that their index
1073:33 - should be six now their index is six and
1073:35 - the Collision problem is also
1073:38 - solved so this is how hased page table
1073:42 - will work with Collision as with
1073:44 - chaining as the Collision resolution
1073:46 - technique suppose process generated this
1073:48 - P and D logical address D will be copied
1073:51 - as it is as you know and P is the
1073:53 - element for hash function suppose page
1073:56 - number five and 25 are there so what
1073:59 - will be the mod 10 result of five it is
1074:01 - five what will the mod 25 result of mod
1074:04 - 10 uh result of 25 it will be five only
1074:08 - so both have five index they both want
1074:10 - to come at index five so what I will
1074:13 - do I will make like this node for 25
1074:18 - node for five node for 25 and then I
1074:21 - will link it using a
1074:24 - pointer so what does the node contain
1074:27 - the node contains the page number the
1074:28 - frame number and pointer to the next
1074:30 - node node contain the page number what
1074:32 - is the page number page number five the
1074:34 - frame number where this page number is
1074:36 - stored in the main memory and pointer to
1074:38 - the next
1074:39 - number the page number the frame number
1074:43 - where it is stored in memory and the
1074:45 - pointer to the next number so this is
1074:46 - how it's going to work now what happens
1074:49 - this R will be copied as it
1074:51 - is that's what we wanted we wanted the
1074:54 - page number let's say this is assumed
1074:56 - let's say we wanted the frame number
1074:58 - where this page number 25 is stored we
1075:00 - wanted R so here we got R and D will be
1075:03 - copied from here that's how we get our
1075:05 - physical address and we will access the
1075:08 - memory but now the question
1075:09 - arises let's say I have 100 nodes here
1075:13 - and then I had some uh I have some node
1075:16 - whose frame number I wanted so how can I
1075:18 - reach there you have to first visit the
1075:21 - head node then the next node then the
1075:23 - next node then the next node obviously
1075:25 - the space is optimized but the time it
1075:28 - will be time
1075:29 - inefficient and you all know the
1075:31 - searching time in the link list is o n
1075:34 - Big O of n so I have to keep
1075:38 - searching until I reach the desired
1075:41 - node okay so instead of 1 million
1075:44 - entries we have a hash table with 10
1075:46 - entries only so from 1 million entry we
1075:49 - reach to only 10 entries and linked
1075:52 - linked list Associated to them so we
1075:54 - have done space optimization but as you
1075:56 - all know space and time optimization
1075:59 - Works in a tradeoff if we have if we
1076:02 - make it space optimized then it will
1076:04 - become time inefficient like we like it
1076:07 - happened in the case of static and
1076:08 - dynamic linking
1076:11 - loading from 1 million entries we reach
1076:13 - to 10 entries space is optimized but
1076:17 - time in efficiency Has Come O N Big O N
1076:21 - will be the search time of Link list so
1076:22 - if we want to jump to the 1003 we cannot
1076:25 - do it directly we have to start from
1076:27 - head and from one node to another we
1076:29 - have to jump until our desired entry or
1076:31 - desired node is
1076:33 - reached so it's a tradeoff between space
1076:35 - and time in vum architecture that's how
1076:37 - it works it is a tradeoff between space
1076:40 - and time between vum architecture so
1076:43 - time for searching i1 and I2 is
1076:44 - different but same in traditional here
1076:47 - let's say
1076:49 - let's say I want a page number five so
1076:51 - what will be the time we jumped here
1076:53 - directly absolutely no time but let's
1076:57 - say I want the frame number of 1025 so I
1077:01 - have to keep jumping from here to here
1077:03 - here to here here to until I reach
1077:06 - 1025 so searching time for i1 is
1077:10 - different from searching time of I2 even
1077:12 - though they have the same index but
1077:14 - searching time will be different as they
1077:15 - are in the linked list but
1077:18 - traditionally but traditionally we have
1077:21 - all entries in the same single page
1077:23 - table in this page table only we have
1077:25 - all entries so searching time of five
1077:28 - and searching time of 1025 will be
1077:32 - same so what we have tried to solve this
1077:35 - spacing issue we have tried increasing
1077:37 - the page size we have tried increasing
1077:39 - the we have tried using
1077:42 - hashing the next important thing which
1077:45 - we are going to try will be multi-level
1077:47 - paging
1077:48 - or recursive paging or hierarchial
1077:51 - paging as the name suggest paging on a
1077:53 - page
1077:54 - table let us start multi-level paging
1077:58 - hierarchial paging recursive paging
1078:00 - paging on a page table index of an index
1078:02 - it has so many names this is an
1078:04 - important topic you have to focus more
1078:05 - on it let us start with the
1078:09 - beginning paging on a page table why we
1078:12 - why we required paging the first thing
1078:15 - which comes to our mind is to overcome
1078:17 - the problem of problem of external
1078:19 - fragmentation paging solve external
1078:21 - fragmentation by allowing processes to
1078:23 - be divided into fixed size Pages this
1078:25 - virtual address space is divided into
1078:27 - fixed size pages and these pages are
1078:30 - stored in the main memory wherever the
1078:32 - frame is free so continuous allocation
1078:35 - need was eliminated so this can be
1078:37 - stored here this can be stored here this
1078:39 - can be stored here so these Pages can be
1078:41 - stored wherever the frame is
1078:44 - empty can be loaded into any available
1078:47 - memory frames avoiding the need for
1078:48 - continuous memory allocation and making
1078:50 - efficient use for scattered free memory
1078:52 - blocks so this was the first use we see
1078:55 - of simple
1078:57 - paging now after studying paging we did
1079:02 - some analysis performance analysis here
1079:04 - we saw some two
1079:06 - issues timing issue and spacing issue in
1079:11 - timing issue we tried to solve using
1079:13 - cach memory we tried using tlb we tried
1079:16 - using PS that somehow helped for spacing
1079:20 - issue we tried using we tried by
1079:23 - increasing the pace size but increasing
1079:26 - the page size causes or invites internal
1079:30 - fragmentation then we tried HED paging
1079:33 - for HED
1079:34 - paging we indeed reduce the space
1079:36 - overhead but at what
1079:40 - cost we tried using increasing page size
1079:42 - and then H paging H paging reduced this
1079:45 - space overhead but at the cost of search
1079:47 - time
1079:48 - this is our third attempt for spacing
1079:50 - issue that is multi-level paging we try
1079:54 - to reduce the size of page
1079:57 - table and how are we going to do that
1079:59 - with the help of paging on page table
1080:02 - what is paging as a concept what is
1080:04 - paging as a
1080:05 - concept divide the address space now
1080:09 - forget about virtual address space and
1080:10 - physical address just listen to this
1080:13 - divide the address space into fixed
1080:16 - units store these units into main memory
1080:20 - and access these units through Page
1080:22 - table this was paging let me repeat
1080:25 - divide the address space into fixed
1080:27 - units store those into main memory and
1080:30 - access them with the help of page table
1080:32 - this was paging
1080:36 - okay but what happened when we saw that
1080:39 - for like around 100 process we had
1080:41 - around 400 MB of main memory used up
1080:45 - just to store the page table so we saw
1080:48 - that size of page table is increasing
1080:50 - very much we want to solve that spacing
1080:53 - issue but the question arise but the
1080:56 - question arise when do we say that the
1080:58 - page table is small or page table is
1081:02 - large when do we say that so this is an
1081:04 - important line you have to remember when
1081:06 - page table fits in one frame of the
1081:09 - memory then we say that the size of page
1081:11 - table is acceptable when page table size
1081:15 - is equals to frame size or your you know
1081:18 - frame size equals to page size so when
1081:20 - page table size is equals to page size
1081:23 - then I can say that the page table size
1081:25 - is
1081:26 - acceptable okay so here it is written
1081:29 - paging as a concept General involve
1081:31 - three steps divide the address space
1081:32 - into Pages store the pages into main
1081:35 - memory and access those pages with the
1081:36 - help of page table this is what it is
1081:40 - written now let's see what are we
1081:42 - attempting here we have address of 32
1081:46 - bits so virtual address space of 2 32
1081:48 - bytes we have a page size of 4 KB so how
1081:51 - many pages will it have it will have
1081:53 - around 2 20 1 million Pages it will have
1081:57 - and you know in page table the number of
1082:00 - entries equals to the number of pages so
1082:01 - we'll have 1 million
1082:03 - entries you remember the fact which I
1082:06 - have told you in the HED paging video
1082:11 - that out of these 1 million Pages
1082:14 - process use around five to six pages
1082:17 - only rest are
1082:19 - unused out of these one million Pages
1082:22 - process use around five to six pages and
1082:24 - rest are unused suppose p 0 P1 some PX
1082:27 - py and PN these are the pages which
1082:30 - process use and rest this P2 and all
1082:32 - other pages are
1082:34 - unused take this an example okay now
1082:38 - what does paging say paging say divide
1082:40 - the address space into pages so we
1082:42 - divide the address space into address
1082:43 - space into Pages store these pages into
1082:46 - main memory so stored p 0 somewhere at
1082:49 - frame 3 P1 at where is P1 is stored at
1082:52 - frame X PX is stored at frame p and p n
1082:56 - is
1082:58 - stored you know mean you know what I
1083:01 - mean so these frames are stored
1083:02 - somewhere in the memory at different
1083:04 - frames and to access those pages what we
1083:07 - need we want a mapping table that is the
1083:10 - page
1083:11 - table so this index represent the page
1083:15 - and the entry represent the frame in
1083:17 - which that p is stored see here p 0 is
1083:20 - stored in frame three p 0 is stored in
1083:23 - frame
1083:25 - three PX is stored in frame two PX is
1083:28 - stored in Frame 2 that's what it
1083:30 - represent so you know out of these 1
1083:33 - million Pages only five are useful let's
1083:35 - say this p 0 P1 PX P1 and PN is useful
1083:38 - let's say this represent code this
1083:40 - represent data and this represent
1083:43 - stack so similarly in the page table
1083:47 - these five entries will be useful and
1083:49 - rest will
1083:50 - be and rest will be the unuseful entries
1083:54 - so I call them as chunks the entries
1083:57 - which are useful or these useful entries
1083:59 - are in one chunk this one chunk this
1084:01 - another chunk another chunk so basically
1084:03 - what we are doing we are trying to
1084:04 - achieve here as this logical address
1084:07 - space was divided into Pages this page
1084:10 - table should also be divided into Pages
1084:12 - because we are attempting to apply
1084:14 - paging on a page table how we applied
1084:17 - paging on this IAL address Space by
1084:18 - dividing into Pages similarly we are
1084:21 - trying to attempt paging on this page
1084:23 - table and how are we going to do that by
1084:25 - dividing this page table into pages but
1084:28 - instead of calling pages of the page
1084:30 - table we call them chunks of the page
1084:32 - table so this page table will be divided
1084:34 - into several
1084:36 - chunks so let's say the size of a size
1084:39 - of one chunk is 1 kilo
1084:42 - bir so how many chunks it will be
1084:44 - divided 2^ 20/ 2^ 10 to power 10 so
1084:48 - there will be around thousand chunks and
1084:51 - out of these thousand chunks only three
1084:53 - are
1084:54 - useful isn't that weird to reduce the
1084:57 - size of page table we have to apply the
1084:59 - concept
1085:01 - of paging on a page table and process is
1085:05 - associated with each of the page here
1085:08 - when we use only a single page
1085:10 - table but what will happen if I use
1085:13 - paging on a page table you'll understand
1085:15 - it what step one we follow page table is
1085:19 - divided into chunks of 1 kilow so number
1085:21 - of chunks will be 1 but out of this only
1085:23 - three are useful that's what we have
1085:24 - done till now the second is store chunks
1085:27 - into the memory we are going to store
1085:29 - these chunks into the memory so the c0
1085:31 - is stored somewhere here this C1 is
1085:33 - stored somewhere here and the C2 is
1085:35 - stored somewhere
1085:36 - here
1085:38 - now what are we doing here just try to
1085:41 - grasp
1085:41 - that how are we going to access those
1085:44 - chunks see we don't want to access each
1085:47 - and every entry of this page table
1085:49 - that's what it was to increase the page
1085:51 - size this was responsible the process
1085:53 - the attitude attitude of the process to
1085:56 - associate itself with these all entries
1085:58 - of page table that was causing the space
1086:01 - overhead but what we want we want
1086:04 - process to Associated associate with
1086:07 - these chunks only we don't want process
1086:09 - to associate with each entry of the page
1086:11 - table we want process to associate with
1086:13 - these chunks only because these are the
1086:15 - useful chunks rest is the Wast
1086:19 - stage are you getting it so what are we
1086:22 - doing we are creating another page table
1086:25 - which is going to store these
1086:28 - chunks so we'll write like
1086:31 - that zero this will now represent the
1086:34 - chunk here what it was representing the
1086:36 - page but now when we apply paging on a
1086:38 - page table what it will represent the
1086:39 - chunk so this chunk that is zero c0 is
1086:43 - stored there at
1086:45 - K C1 is stored there at
1086:49 - J okay so now you think is it is it wise
1086:55 - of process to associate itself with
1086:57 - these chunks and
1086:59 - not these entries because initially the
1087:03 - space overhead was try to calculate that
1087:05 - what was the space overhead what is
1087:06 - space
1087:08 - overhead the extra space which we are
1087:10 - using to apply the concept of paging
1087:12 - what is that ex page this page table
1087:14 - so what is the size of this page table
1087:17 - the size of page table which we
1087:18 - calculated was 4 MB let's say the entry
1087:20 - was 4 by so the size of page table was 4
1087:22 - MB now what are we doing we
1087:25 - are letting the process to associate
1087:28 - with the outer page table what is the
1087:29 - size of outer page table number of
1087:31 - chunks number of chunks how many chunks
1087:33 - are there 1K the size of each chunk was
1087:35 - to 1 kilow there were this is how we
1087:39 - calculated the number of
1087:40 - chunks 1 million entri is divided
1087:43 - into chunks of size 1 kilow so this is
1087:47 - what the number of chunks are the
1087:49 - process will be associated with a
1087:51 - process will be associated with page
1087:53 - table with have 1 Kil entries plus three
1087:56 - chunks of inner page Table Three chunks
1087:59 - of that page table which has this 1
1088:00 - million entries are you getting the
1088:02 - point what have we
1088:03 - done we with the help of another page
1088:06 - table we allowed the process we allowed
1088:08 - the process to access these chunks
1088:10 - directly not wasting time
1088:13 - here okay so process does not have to
1088:16 - include that
1088:17 - the the space overhead what will process
1088:20 - do process will access the useful thing
1088:22 - only see what have we done here we have
1088:27 - included the 1 million entries we don't
1088:29 - want the process to access associate
1088:31 - itself with 1 million entries so what
1088:32 - are we doing we are creating another
1088:34 - page table in which only these chunks
1088:37 - are
1088:38 - present so what process has to do now
1088:41 - access or associated with this page
1088:43 - table and these chunks of inner page
1088:45 - table so now initially the space
1088:48 - overhead was 4 MD Now what is the space
1088:53 - overhead the space overhead will be
1088:55 - let's say this size is of 4 bytes so 4
1088:57 - KB plus three chunks of inner P table
1089:01 - which means 3 K into 4 so this is be 12
1089:05 - KB so now it is associated with just 16
1089:09 - KB initially it was 4 MB now it is 16 KB
1089:15 - only are you seeing how much reduction
1089:17 - we have made here so earlier it was
1089:19 - associated with 1 million entry page
1089:22 - table now we have associated with it
1089:25 - only 1 kilow past table let's say each
1089:27 - word is of 4 by so one 4 KB past table
1089:32 - here let's say word of four by then 4 MB
1089:35 - here 4 KB plus we have to also access
1089:37 - the three chunks of inner page table so
1089:39 - 3 K into 4B that will be 12b so now 16
1089:43 - KB only so from 4 MB we have reached to
1089:46 - 16 KB
1089:49 - I hope you can see how much space
1089:51 - overhead we have reduced
1089:54 - now in the next lecture we are going to
1089:56 - see how addressing will be
1090:04 - done let us understand how multi-level
1090:06 - paging actually helps us suppose this is
1090:09 - our process in the CPU being executed it
1090:12 - generates an
1090:13 - address page number and in that page
1090:16 - number which word to access this D will
1090:18 - tell us so this is our virtual address
1090:21 - space and it has it has been divided
1090:24 - into various Pages this is p 0 this is
1090:27 - P1 p 0 P1 okay now what happens this
1090:32 - virtual address space this virtual
1090:34 - address space cannot be stored in the
1090:37 - one frame of the main
1090:39 - memory this virtual address space is
1090:42 - greater than the frame size of main
1090:44 - memory
1090:47 - as we all know that frame size equals to
1090:50 - page size and this virtual address space
1090:53 - contain lots of pages around we saw that
1090:56 - it contained around 1 million pages so
1090:59 - virtual address space is around 1
1091:01 - million times greater than the frame
1091:02 - size we cannot store the whole virtual
1091:05 - address space or the whole process we
1091:07 - cannot store the whole process into main
1091:09 - memory listen to this words these words
1091:13 - we cannot store the whole process into
1091:15 - main memory what we do
1091:17 - we only store the important pages in The
1091:24 - Frames this is our page table and this
1091:27 - is the main memory it only contains some
1091:30 - of the important pages of this virtual
1091:32 - address space so what
1091:33 - [Music]
1091:34 - happens this page table will contain the
1091:37 - entry so this p 0 index0 let's say it
1091:42 - stored in some frame X so at this Frame
1091:45 - at this Frame let's say this is the
1091:46 - frame number X at this Frame p 0 will be
1091:48 - stored so from here I got the frame
1091:51 - number from here I got the frame number
1091:54 - and this D will be copied as it is
1091:56 - that's how I got our physical address
1091:58 - and from physical address I can access
1092:00 - the main memory that's how paging
1092:02 - actually works but what paging is
1092:05 - actually meant for so that if the
1092:08 - virtual address space is million time
1092:11 - greater than the frame size I cannot
1092:13 - store the whole process in just one
1092:14 - frame of the
1092:15 - memory that's why we included that's why
1092:19 - we introduced this paging such that we
1092:21 - have to include only the important pages
1092:24 - in The
1092:24 - Frames we have to include only the
1092:27 - important pages in The
1092:29 - Frames so this page table will contain
1092:32 - the entries of those important Pages
1092:34 - only which are present in the main M
1092:36 - let's say frame X frame Y and frame Zed
1092:38 - this x y z contains the important Pages
1092:40 - p 0 P1 and P2 rest all are not important
1092:44 - this p 0 P1 and P2 these are important
1092:46 - and rest all are not
1092:48 - important so what will happen this page
1092:51 - table will contain the entries of all
1092:53 - the pages this page table will contain
1092:56 - the see we had 1 million pages so this
1092:59 - page table will contain 1 million
1093:02 - entries if if the page is not stored in
1093:05 - the frame then what will be present here
1093:07 - some invalid information or some invalid
1093:09 - frame number or whatever be the present
1093:12 - but this this entry won't be empty some
1093:15 - some in or some different information be
1093:19 - written but this will consume
1093:22 - space initially we were dealing with
1093:24 - this initially let's say we had 2^ 32
1093:28 - bytes of virtual add
1093:29 - space so we had initially this much
1093:32 - weight on us but what now happened we
1093:35 - have to
1093:37 - access this page table and only the
1093:40 - useful chunks of these virtual address
1093:43 - space in the
1093:45 - memory listen in main memory main memory
1093:48 - is a critical memory we do not store
1093:51 - unuseful or wastage in the main memory
1093:54 - we store only the useful parts of the
1093:56 - program in the main
1093:58 - memory but this virtual address space
1094:01 - was very large we cannot store this
1094:03 - virtual address space in a one frame
1094:05 - that's why we introduced paging with the
1094:07 - help of page table I have to the process
1094:11 - will be associated with each entry of
1094:12 - the page table and let me write this the
1094:16 - process will be associated
1094:18 - with associated with two things the
1094:23 - first whole page
1094:27 - table and second is useful entries
1094:31 - of useful entries which were actually
1094:34 - present in main memory so the useful
1094:36 - entries and the whole page table this is
1094:38 - what process will be associated
1094:40 - with okay now we understand what paging
1094:44 - is now the similar problem which we had
1094:47 - with virtual address space that we
1094:49 - cannot store the whole process into the
1094:51 - main memory we have to break it into
1094:54 - pages and then we have to store the
1094:57 - similar problem arised with this page
1094:58 - table now I cannot store this page table
1095:01 - into the frame of the main memory this
1095:04 - page table size has become greater than
1095:05 - the frame size so what we want to do we
1095:09 - will apply the same concept here we will
1095:11 - apply paging here now in this page table
1095:15 - I had 1 million entries and out of these
1095:17 - 1 million entries you know only some of
1095:20 - the entries were useful and rest all of
1095:23 - the entries were wastage and you also
1095:25 - know that page table is stored in the
1095:27 - main memory you also know that page
1095:30 - table is stored in the main memory I
1095:31 - don't want to store this Scrappy or
1095:33 - wasteful information in the main memory
1095:35 - that's why we are help taking the help
1095:38 - of another page
1095:39 - table so this page
1095:42 - table this page table as we did with the
1095:44 - virtual address space we divided into
1095:45 - the pages so what we going to do we are
1095:47 - going to divide this page table
1095:50 - into
1095:52 - chunks and the index represented the
1095:55 - page number here the
1095:57 - index represented the page number
1096:00 - here what will this index represent this
1096:03 - index will represent the chunk number
1096:04 - here so I divided the page table into
1096:07 - chunks let's say the chunk
1096:09 - zero is stored the chunk zero is stored
1096:14 - in some frame of the main memory let's
1096:16 - say frame a
1096:17 - this was a chunk one is stored in some
1096:20 - frame of the main memory let's say B so
1096:22 - or useful information was stored in
1096:24 - these two chunks only and rest was
1096:26 - wastage so the whole area this whole uh
1096:31 - this whole entries of the uh second
1096:34 - level page table this is the this was
1096:35 - the first one this is let's say let's
1096:37 - call this as the inner page table and we
1096:39 - will call it as the outer page table so
1096:42 - this whole area of the outer page table
1096:44 - doesn't contain any information it will
1096:46 - contain the invalid bit as it was in the
1096:48 - case of page table when the page which
1096:51 - was not useful in the which was the the
1096:54 - case the page which was not useful for
1096:57 - that case we stored invalid bit or
1097:00 - invalid information
1097:02 - here same thing we are going to apply
1097:04 - here we will store some invalid
1097:06 - information or invalid frame number here
1097:08 - but this will but this will take the
1097:12 - space now what
1097:14 - happens we will associate the process
1097:17 - now the process now will be associated
1097:20 - with whole Outer page table whole Outer
1097:23 - page
1097:24 - table and the useful
1097:28 - information of inner page
1097:31 - table initially when we had a single
1097:34 - level paging then the process was
1097:36 - associated with this page table and the
1097:39 - useful information of main memory now
1097:41 - what happened when we had an another
1097:44 - level of paging now the process will be
1097:46 - associated with this full page table and
1097:49 - the useful information of this page
1097:52 - table and that's how we actually reduced
1097:55 - the space overhead now let's move to the
1097:58 - PDF let me open the PDF so this is what
1098:01 - we have seen now when we have done the
1098:04 - outer level uh we have done the two
1098:06 - level paging then the process will be
1098:08 - associated with outer page table the
1098:10 - complete outer page table and the
1098:12 - important information of inner page
1098:14 - table which was the three chunks of
1098:15 - inner page table these three chunks of
1098:17 - the inner page table which were useful
1098:19 - only that will be
1098:21 - Associated initially we had a 4 MB
1098:25 - initially we had a 4 MB of page table
1098:29 - this was our space over but as we did
1098:32 - the As we did the outer level paging or
1098:36 - as we did the uh two level paging now
1098:38 - what happened the process will be
1098:39 - associated with outer page table it
1098:41 - contains 4 1K entries each of four bytes
1098:44 - so we have 4 KB and three chunks of
1098:47 - inner page Table Three chunks of inner
1098:49 - page table chunk one chunk two and chunk
1098:51 - three and each chunk has a size of 1 Kil
1098:54 - word each chunk has a size of 1 kilow
1098:57 - Word and one word is of four 4 byte so
1099:01 - total 12 KB so from 12 KB here and 4 KB
1099:05 - here I got 16 KB so initially I had 4 MB
1099:09 - of space overhead but now I have reduced
1099:11 - this page to 16
1099:14 - KB what was the frame size remember the
1099:17 - frame size the frame size was 4 KB only
1099:19 - the frame size was 4 KB only and the
1099:23 - page table size was 4 MB can I store a 4
1099:26 - KB 4 MB part in 4 KB that is impossible
1099:31 - that's why we have to reduce this we
1099:33 - have
1099:34 - to we we want a page table which is of 4
1099:38 - KB size from here I got a page table
1099:41 - which is a size of 4 KB so 1K entries
1099:43 - with 4 by each so 4 KB is the size of
1099:45 - page table now now I can store this page
1099:47 - table into a single frame of main
1099:51 - memory okay you got the point why we did
1099:54 - paging because we cannot store the whole
1099:56 - process into main memory only important
1099:58 - part can be stored the whole process
1100:01 - cannot be stored in the one frame of the
1100:03 - main
1100:03 - memory that's why we introduced a page
1100:07 - table because that page table can be fit
1100:10 - into one frame of the main memory but
1100:12 - what happened unfortunately the page
1100:14 - table size was so big that that we were
1100:18 - not able to fit that page table also in
1100:20 - the one frame of the main memory now
1100:22 - what we did we did paging again we got
1100:25 - another page table somehow luckily we
1100:28 - were able to fit that new page table
1100:30 - into one frame of the main memory that's
1100:32 - where our mission was
1100:35 - accomplished so what is the punch line
1100:37 - that you have to
1100:38 - remember the page table should be fit
1100:41 - into a single frame of the main memory
1100:44 - or the page table size should be equal
1100:46 - to the page
1100:48 - size okay in the next lecture we will
1100:51 - see how addressing is done okay I I felt
1100:53 - the need that this needs more
1100:55 - clarification or this needs more
1100:56 - explanation that's why I made another
1100:59 - video now let's understand how
1101:01 - addressing
1101:04 - Works initially when we had only single
1101:06 - page table we used to divide The Logical
1101:09 - address into two parts one had a page
1101:12 - number one part was the page number and
1101:14 - other was the
1101:15 - offset but but now we have two level
1101:19 - paging so what we are going to divide
1101:21 - now we are going to divide this page
1101:23 - number into two let's say P1 and D1
1101:26 - that's how we are going to perform the
1101:28 - addressing we had 32 bits of logical
1101:31 - address 4 KB of page
1101:34 - size so from page size I got 12 here and
1101:38 - from for page number I had 1 million
1101:41 - pages so from 1 million I will have 1
1101:44 - million page number and for that 1 mil
1101:46 - in page number I would require 20 bits
1101:49 - that's how I got 20 and 12 here okay
1101:52 - these were the number of pages equal to
1101:54 - number of entries in the inner page
1101:55 - table so we applied paging on logical
1101:59 - address and we
1102:01 - got we got it divided into two parts
1102:04 - page number and Page
1102:07 - size this was a log to number of pages
1102:11 - and this was log two page size now we
1102:15 - applied paging on a page table so we
1102:18 - need to divide this P so this P will be
1102:21 - divided on P1 that is number of chunks
1102:23 - and this D1 will be the chunk size as it
1102:26 - was here this was number of pages and
1102:28 - Page size this will be number of chunks
1102:30 - and chunk
1102:31 - size so this P will be divided into two
1102:35 - parts P1 and
1102:37 - D1 okay now comes the important part
1102:41 - number of entries in inner page table
1102:43 - were equal to number of pages in logical
1102:46 - address space so number of entries in
1102:48 - outer page table will be equal to number
1102:50 - of chunks in the inner page
1102:52 - table so how many entries in the outer
1102:55 - page table will be equal to the number
1102:59 - of entries in the outer page
1103:01 - table if I do log two of number of
1103:04 - entries that is number of
1103:06 - chunks then I will get my
1103:10 - P1 then I'll get my P1 so number of
1103:13 - entries this p is the number of entries
1103:16 - in the inner page table this P1 is the
1103:18 - number of
1103:19 - chunks of inner page table or entries in
1103:22 - the outer page
1103:24 - table and this D1 was the chunk size and
1103:28 - this D was the page size this D1 was
1103:31 - related to the chunk size and this D was
1103:33 - related to the page
1103:38 - size okay so number of chunks uh number
1103:42 - of entries in a chunk so this is related
1103:44 - to the number of entries in the chunk is
1103:46 - Rel to the chunk size okay so let me
1103:49 - repeat again what we did initially when
1103:51 - we had a single level paging then we
1103:53 - divided the logical address page into
1103:54 - two parts page number and offset now we
1103:57 - had multi-level paging now we have
1103:59 - paging on a page table so we'll divide
1104:01 - the page
1104:02 - number previously we divide The Logical
1104:04 - address now we'll divide the page number
1104:06 - page number in two
1104:08 - parts number of entries in the outer
1104:10 - page table and the size of a chunk or
1104:13 - chunk size and this will be the page
1104:16 - size so this is how we did we divided
1104:18 - the page number into two parts P1 and D1
1104:21 - and if we did this third level page
1104:23 - table third level paging firstly one
1104:26 - level paging divided into two page
1104:27 - number and offset second level paging
1104:29 - div this page number will be divided
1104:31 - into two number of entries in the outer
1104:33 - page table and chunk size if done the
1104:36 - third level paging
1104:38 - then number of entries in the outer to
1104:41 - Outer page table which means the third
1104:42 - page table and the chunk size of the
1104:44 - outer page table
1104:47 - we did paging because logical address
1104:49 - page was too big to fit in one frame of
1104:50 - the main memory but inner page table can
1104:52 - easily fit in one frame of the main
1104:53 - memory when inner page table became too
1104:56 - big to fit in the one frame of the main
1104:58 - memory we did paging creating outer page
1105:00 - table which can easily fit into one
1105:02 - frame of the main memory let me repeat
1105:03 - again this will clarify the this will
1105:06 - clarify the purpose of paging we did
1105:08 - paging because logical address page was
1105:10 - too big to fit in one frame of the main
1105:12 - memory but inner page table can easily
1105:15 - fit in one frame of the main memory but
1105:17 - what happened when inner page table
1105:19 - become too big 2 F in one frame of the
1105:21 - memory we did paging on inner page table
1105:24 - creating outer page table which can
1105:26 - easily fit in one of the main memory
1105:28 - this is the Crux of two level paging
1105:30 - this is how it looks like now CPU
1105:32 - generates this kind of address P1 D1 and
1105:35 - D suppose P1 is 10 D1 is 10 total 20 and
1105:41 - this
1105:41 - D okay now what happened this P1 this P1
1105:47 - will give me this P1 will give me the
1105:51 - chunk address this P1 will give me the
1105:53 - chunk address from here I will get the
1105:56 - chunk address I will reach to that chunk
1105:58 - this D1 will tell me to which page to
1106:01 - look for in that
1106:04 - chunk focus on this line a page contain
1106:07 - number of
1106:09 - words and a chunk contain number of
1106:12 - pages so this D tells me in in that page
1106:17 - in this D tells me which word to look
1106:20 - for in a page and this D1 tells me which
1106:23 - page to look for in a chunk and this P1
1106:26 - tells me where to find that
1106:29 - chunk okay so from P1 I got the address
1106:33 - of the chunk I reached to that Chunk on
1106:36 - that chunk with the help of D I found
1106:39 - that page and from that page I found the
1106:41 - frame number I copied the frame number
1106:44 - here I copied the D here that's how I
1106:46 - got the physical address
1106:50 - space okay so this B is the address of
1106:53 - one chunk of the inner page
1106:55 - table let me repeat
1106:58 - again it generated address this address
1107:01 - consist of three parts P1 D1 and D
1107:04 - firstly we need to see we want the frame
1107:07 - number what we actually want the frame
1107:10 - number in that frame our instruction is
1107:12 - present so how are we going to find that
1107:15 - instruction in the frame with the help
1107:16 - of this D but firstly we have to reach
1107:19 - to that frame how are we going to reach
1107:20 - to that frame firstly we will look for
1107:22 - that chunk which contain our frame after
1107:25 - we have found the address of that Chunk
1107:26 - we will look for that page which contain
1107:28 - our frame we found the frame sent here
1107:32 - and with the help of this D we will find
1107:34 - that in which word of that frame our
1107:37 - instruction or data is
1107:39 - present I hope now the thing is clear P1
1107:42 - is the address of chunk of inner page
1107:43 - table D1 is the address of frame of main
1107:45 - memory and D is the address of data or
1107:47 - instruction in the
1107:49 - frame okay that's how multi-level paging
1107:52 - works I have put lots of effort lots of
1107:55 - retakes I hope you like
1107:59 - it let's see these views of multi-level
1108:01 - paging we had outer page table inner
1108:04 - page table and memory in the last
1108:06 - lecture we learned how logical addresses
1108:08 - were generated okay so the outer level
1108:12 - page table contains the frame where the
1108:14 - chunks are stored the inner level page
1108:16 - table contains the frame where the pages
1108:18 - are restored okay and memory itself
1108:20 - contains the
1108:22 - frames now how logical address will be
1108:24 - worked how how are we going to work with
1108:26 - logical address this P1 will help us to
1108:28 - reach the required chunk this D2 will
1108:31 - help us to reach the required page in
1108:33 - that chunk and this D will do this D
1108:35 - will help us to reach the required word
1108:38 - which contain our instructional data so
1108:41 - from P1 we access the outer page table
1108:44 - this is the frame where the chunk is
1108:47 - stored we got to that
1108:49 - frame now we had D2 now we have to reach
1108:53 - to that page in the frame so we'll reach
1108:55 - to that page here we got our page this
1108:58 - is the actual frame this is the actual
1109:01 - frame where instruction of data is St
1109:03 - but it contains lot of word so in which
1109:06 - world I have to look for this D will
1109:08 - tell so I have to look at this one okay
1109:11 - P will help us to read the chunk re
1109:13 - reach to the chunk D will help us to
1109:15 - reach to that page and this another D
1109:18 - will help us to reach to the required
1109:20 - word in the frame see this CPU generates
1109:24 - this kind of logical address this page
1109:26 - table base register will give me the
1109:28 - address of outer page table as you know
1109:30 - that outer page table is also stored in
1109:31 - the memory all kind of page tables are
1109:34 - stored in the memory so where I have to
1109:36 - look for that page table this ptbr will
1109:39 - give you page table based register it
1109:40 - gives the index of outer page table so
1109:43 - from here I got the index of outer page
1109:45 - table from this 10 bit I got the address
1109:48 - of that chunk where my required page is
1109:51 - there so I reached to that page now this
1109:53 - 10 bit
1109:55 - will help me to search for that page in
1109:58 - the chunk so I reach to that page in the
1110:01 - chunk here I got the frame number where
1110:03 - that page is stored so I I will copy the
1110:05 - frame number here in the physical
1110:06 - address and this will be copied here so
1110:10 - now I got the complete physical address
1110:12 - so from here I will go to directly to
1110:14 - that word where my instruction of dat
1110:16 - I okay see this multi-level page table
1110:19 - what does it depicts it depicts that
1110:21 - process is not using all the
1110:23 - pages and we have to store only useful
1110:26 - entries okay so now we have completely
1110:30 - understood how multi level paging works
1110:33 - so paging generally involves three step
1110:35 - dividing the address page into Pages
1110:37 - storing the pages into frames accessing
1110:39 - the pages through Page table this is the
1110:41 - paging as a
1110:43 - concept what was the motive behind the
1110:45 - paging we want to optimize space
1110:47 - sacrificing time as you know that in
1110:48 - volum architecture space and time works
1110:51 - in a trade-off if we are optimizing
1110:54 - space we will be sacrificing time and if
1110:56 - we are optimizing time we will be
1110:57 - sacrificing
1110:59 - space now time for the effective memory
1111:01 - access time in one level paging we had 1
1111:05 - M for accessing the page table and 1 M
1111:06 - for accessing the memory in two level
1111:08 - paging we had 1 M for accessing the
1111:10 - outer page table 1 M for accessing the
1111:12 - inner page table and 1 m in accessing
1111:14 - the memory as you know this outer page
1111:16 - table inner page table both are stored
1111:17 - in memory so M will be the time for both
1111:20 - okay so in one level we need 2 m in two
1111:23 - level we need 3 m so in N level we are
1111:25 - going to need n+ 1 M so this is the
1111:27 - effective memory ex Sy time now the
1111:29 - question arises can we reduce them can
1111:31 - we reduce this effective memory access
1111:33 - time let's try with the help of tlb and
1111:35 - Pac in two level so here is the CPU it
1111:38 - generates this address so firstly we
1111:40 - will look in the tlb with the help of
1111:42 - this P that this page number is
1111:45 - contained in which frame number if I get
1111:47 - this this is a tlb hit I directly get
1111:49 - the frame number this D will be copied
1111:51 - here I will reach now I have physical
1111:54 - address so from this physical address
1111:56 - I'll first look at the PSC so
1112:00 - corresponding to a physical address can
1112:01 - I get my instruction of data if yes then
1112:05 - this is a PSC hit you will get your
1112:06 - instruction and data if no then you have
1112:09 - to search in the physical address
1112:12 - space now what about tlb Miss what
1112:15 - happens we when we have to actually
1112:17 - search in the page tables so
1112:21 - firstly with the help of this P1 we will
1112:25 - look in the outer page table we got the
1112:27 - address of that chunk now x with the
1112:29 - help of this D1 we will reach to that
1112:32 - frame now this Frame will be copied here
1112:34 - and this D will be copied here here I
1112:36 - got the physical address now again the
1112:37 - same thing either I will get PC hit so
1112:40 - corresponding to that P physical address
1112:43 - is that present in the PSC if yes then
1112:45 - it is a PS I will get the instruction of
1112:46 - data directly otherwise I have to search
1112:49 - in the physical address
1112:51 - space okay so this was a twole paging
1112:53 - with tlb and Pac now let's see the
1112:56 - effective memory access time were we
1112:58 - able to reduce them let's say the main
1113:01 - memory access time is M tlb access time
1113:05 - is C1 tlb hit ratio is X1 PC access time
1113:08 - is C2 P hit ratio is X2 now we have to
1113:11 - find the effective memor system so we'll
1113:14 - again take two cases the first case was
1113:16 - we had a tlb hit the second case was we
1113:18 - had a tlb miss so here I got our
1113:20 - physical address X1 C1 1 - X1 C1 + 2 m
1113:25 - here I got our physical address after
1113:28 - that this phase two part will come this
1113:30 - will be same in both the cases initially
1113:32 - I looked in the PC I got a hit X2 C2
1113:36 - will be the time taken but if I had a
1113:39 - Miss then 1 - X2 C2 + m why C2 plus M
1113:42 - because first I looked in the PC then M
1113:44 - same case here
1113:46 - first I look then tlb and then in the
1113:48 - page
1113:49 - tables here X2 I got a hit I as I looked
1113:54 - in the PC but here it was a miss so
1113:56 - first I looked in the PC then in the
1113:58 - main memory so that's how we calculated
1114:00 - the effective memory effective memory
1114:03 - access time in the next lecture we will
1114:04 - some of we will see some
1114:08 - numericals physical address space 256 M
1114:11 - be given logical address space 4GB frame
1114:13 - size 4 KB page table entry 2X
1114:16 - we have to apply the concept of paging
1114:18 - here we were given that logical address
1114:21 - space is 4GB and we can see that the
1114:24 - frame size is much smaller than the
1114:26 - logical address space we cannot fit the
1114:28 - whole process into a single frame that's
1114:31 - why we have to apply paging here so we
1114:33 - applied paging we divided this logical
1114:35 - address page into several pages
1114:39 - and stored each page in a frame that's
1114:42 - what we thought of so we divide The
1114:44 - Logical address
1114:46 - logical address space into different
1114:47 - pages each of size 4 KB so how many
1114:49 - pages were there 1 million pages so we
1114:52 - have to access those pages with the help
1114:54 - of page table 1 million pages so we have
1114:57 - how many entries in the page table 1
1114:58 - million entries what is the size of each
1115:02 - entry two bytes so 1 million into 2 by
1115:04 - will be 2 MB but another problem arised
1115:07 - here what that 2 MB is again greater
1115:11 - than frame size we have to do paging
1115:14 - again so we applied level two paging we
1115:19 - used another page table for the inner
1115:22 - page table so divide we divided the
1115:25 - inner page table into chunks we divided
1115:28 - the inner page table into chunks and we
1115:30 - want to store that chunk into 4 KB that
1115:33 - is the frame size so what we did we took
1115:36 - the chunk size as 4 KB see it is not
1115:38 - necessary that you took the chunk size
1115:40 - equal to frame size or page size it is
1115:42 - not necessary chunk size can be
1115:43 - different to frame size but here what we
1115:46 - want we want to apply the concept of
1115:48 - paging we want to store that chunk into
1115:51 - one frame of the memory so we said that
1115:53 - chunk size Let It Be 4 KB so this 2 MB
1115:58 - this was the 2 MB page table divided
1116:01 - into units we call them at chunks each
1116:05 - of size 4 KB so how many entries will be
1116:06 - there 2 mb/ 4 KB we will have 512
1116:11 - entries which is 2^ 9
1116:14 - entries so so we had 2^ 9 entries now we
1116:18 - have to find the size of Entry of outer
1116:21 - level page table
1116:23 - see this e will remain independent of
1116:27 - the level of paging what does this e
1116:29 - represent it is the frame this the entry
1116:32 - of the page table represent the frame in
1116:35 - which either the page is stored or chunk
1116:37 - is stored depending on which T page
1116:39 - table we are talking about this e will
1116:41 - represent the frame in which page is
1116:43 - stored when we are talking about inner
1116:45 - page table
1116:46 - this e will represent the frame in which
1116:48 - chunk is stored when we are talking
1116:49 - about outer page table so this e will
1116:52 - represent what basically it will
1116:53 - represent the frame so how many or what
1116:57 - will be the size of e will depends upon
1116:58 - the number of frames in the main
1117:01 - memory and the number of frames in the
1117:03 - main memory is independent of the level
1117:05 - of paging that we are applying so this e
1117:07 - will remain same we will have 2K 2B only
1117:10 - here so number of entries is 512 each
1117:13 - entry is a size of 2 by so we will have
1117:15 - 1
1117:16 - KB now you can see we can store that
1117:19 - outer level page table into one frame of
1117:23 - the main memory the one frame size is 4
1117:25 - KB and the outer level page size is 1 KB
1117:28 - yes we can store we can store that outer
1117:32 - level page into a single frame no need
1117:34 - to apply more paging here okay now we
1117:37 - learn how addressing will be
1117:39 - done so we
1117:41 - have let me erase all this extra part
1117:46 - we have data or instruction in some word
1117:49 - in the physical address space how are we
1117:51 - going to access the address of that word
1117:53 - firstly we will firstly we will go to
1117:56 - the outer level page table to access the
1117:58 - chunk see
1118:01 - word lots of word are there in a page
1118:05 - lots of pages are there in a
1118:07 - chunk so we will first find the frame in
1118:10 - which our chunk is
1118:12 - stored we will find the frame in which
1118:15 - our chunk is stored so how can I find
1118:18 - the frame with the help of outer level
1118:20 - page table how many entries we have in
1118:21 - the outer level page table we have 512
1118:24 - entri so nine bits will be required to
1118:26 - reach to that
1118:28 - chunk after that we have to reach to the
1118:30 - required
1118:32 - page how many entries are there in the
1118:34 - inner level page table we have 1 million
1118:36 - entries
1118:39 - but but these entries are divided into
1118:42 - chunks so we have with with the help of
1118:45 - this n bit we have reached to that chunk
1118:47 - which contain our
1118:48 - page okay now in that Chunk we have to
1118:51 - find the page
1118:53 - see this was our chunk it has several
1118:56 - Pages this page we want to access so we
1119:00 - have to first find how many entries are
1119:02 - there in a chunk in a single chunk how
1119:04 - many entries are
1119:07 - there how are we going to uh solve that
1119:10 - how many entries are there in a chunk
1119:13 - see what is a chunk size the chunk size
1119:16 - is 4
1119:18 - KB and what is the entry size the entry
1119:21 - size is 2 by how many entries can be fit
1119:23 - in this Chunk in this chunk two which
1119:27 - which means 2^
1119:30 - 11 bytes so how many entries can be
1119:33 - there oh not bytes by is canceled so
1119:35 - twoed to 11 entries how many bits are
1119:37 - required to reach that page 11 bits will
1119:40 - be required to reach to that
1119:42 - page now we have reached to that page
1119:45 - which contain our word this is our page
1119:47 - and it contains several words suppose I
1119:49 - want this word to access how I'm how I'm
1119:52 - going to access that word with the help
1119:54 - of with the help of page offset so log
1119:57 - to page size what is Page size 4 GB so I
1120:00 - require 12 bit to access the
1120:04 - word okay so this is how we did the
1120:08 - addressing in this question see here we
1120:12 - had an outer level page table the outer
1120:14 - level page table index will represent
1120:16 - the chunk number the entry will
1120:18 - represent the frame in which that chunk
1120:20 - is stored with the help of that we reach
1120:22 - to that chunk now we want to find that
1120:25 - page in the junk how are we going to
1120:26 - find with the help of D1 what does D1
1120:28 - represent log two number of entries in
1120:31 - the chunk how can we find number of
1120:33 - entries what is chunk size chunk size is
1120:35 - 4 KB what is the size of each entry it
1120:38 - is two white so I can find the number of
1120:40 - entries with the help of this so I got 2
1120:42 - power 11 entries in the chunk
1120:45 - so to reach that page I will need 11 bit
1120:49 - so 9 bit and 11 bit now I have reach to
1120:53 - that frame or that
1120:56 - page with the help of this 9 and 11 bit
1120:59 - I have reached to that frame which
1121:01 - contain my
1121:04 - page these 12 bits that is the page
1121:07 - offset will help me to reach to that
1121:09 - word which contain my data instraction
1121:11 - so this is how addressing is
1121:12 - done 20 this was the 20 how I got 20 I
1121:17 - had 1 million entries in the virtual
1121:18 - address Space 1 million pages in the
1121:20 - virtual address space that's why I got 1
1121:22 - million entries in the page table that's
1121:24 - how I got this 20 here now this we have
1121:27 - applied paging on that page table so you
1121:29 - have to find number of chunks in the
1121:31 - page table we got 512 chunks so number
1121:34 - of chunks in the page table equal to
1121:35 - number of entries in the outer page
1121:37 - table we got 52 so 9 bits will be
1121:40 - required now after we re reach to that
1121:44 - junk we have to find the page which
1121:46 - contain our word so to reach that word
1121:48 - to reach that page we have to find the
1121:51 - number of entries in the one chunk so we
1121:53 - had 2^ 11 entries in one chunk so we
1121:57 - will require 11 bits for that now we
1121:59 - have reached to that frame we from here
1122:02 - we got our frame number which has my
1122:06 - page which has my
1122:08 - page that contain that word which has my
1122:12 - instruction so till here I have reached
1122:15 - so from here I got the frame number and
1122:18 - this D will be copied
1122:21 - here so I got the physical address of
1122:25 - that word which contain my instructional
1122:28 - data okay let's see some more questions
1122:30 - it says in the context of operating
1122:33 - system which of the following statement
1122:34 - are correct with respect to
1122:36 - paging paging page size has no impact of
1122:39 - internal fragmentation well this is
1122:41 - completely false we have seen that when
1122:43 - we increase the page size it invites
1122:45 - internal fragmentation paging helps
1122:48 - solve the issue of external
1122:49 - fragmentation absolutely correct paging
1122:51 - incurs memory overhead
1122:53 - yes paging incurs memory overhead what
1122:56 - is memory overhead this is the same as
1122:58 - space overhead then what is space
1123:00 - overhead space overhead is the extra
1123:02 - space which we consumed to convert
1123:06 - logical address into physical address
1123:08 - what extra space is we did we consume we
1123:10 - consume page tables so paging incurs
1123:12 - memory over it yes
1123:15 - multi-level paging is necessary to
1123:16 - support pages of different size well we
1123:19 - did not talk about this we only talked
1123:21 - that multi-level paging why we use multi
1123:24 - level paging to optimize overheads H
1123:26 - Eads to optimize overheads so this will
1123:31 - be the correct this will be the correct
1123:33 - these two are
1123:34 - false another question consider a system
1123:37 - using two level paging
1123:39 - architecture the top level the top level
1123:42 - nine bits of the virtual address are
1123:44 - used to index to the outer page table
1123:46 - the next seven bits of the address are
1123:48 - used to index into the next trevel page
1123:51 - table the size of virtual address is 28
1123:53 - bits okay well this is an easy question
1123:55 - how large are pages and how many there
1123:57 - are in the virtual address space so easy
1124:00 - see
1124:02 - here we were given with two level paging
1124:04 - architectures the top level nine bits of
1124:08 - the virtual address are used to index
1124:09 - the outer page table which means 9 bit
1124:11 - is P1 the next bits of the seven used to
1124:15 - index the next l so D1 is
1124:18 - 7 the size of virtual address is 28 bit
1124:21 - so P1 + d1+ D = to
1124:24 - 28 how large are the pages and how many
1124:27 - are there well firstly we have to find
1124:30 - the page size how can I find the page
1124:32 - size with the help of this D so D will
1124:33 - be equals to this is
1124:35 - 9 this is 9 this is 7 so 9 + 7 16 D = to
1124:40 - 28 - 16 which is 12 so my page size is 2
1124:44 - 12 which is 2^ 2 into 2^ 10 which is 4
1124:48 - KB this is my page size and how many
1124:51 - pages are there I can find with the help
1124:53 - of this P1 + D1 equals to P if you
1124:56 - remember and what is this p 2 power P
1124:59 - will give me the number of pages so I
1125:01 - have how many pages I have 2^ 16
1125:05 - Pages 2^ 16 pages and Page size is this
1125:09 - second question if page table entry both
1125:12 - level is 32 bits in size which mean we
1125:14 - have we have four byte of page table
1125:16 - entry then what is the space overhead
1125:18 - needed to translate what is space
1125:20 - overhead the size of page tables only so
1125:22 - to convert The Logical address to
1125:24 - physical address how much space is
1125:25 - needed size of outer pH table size of
1125:27 - inner pH table what is the entry of
1125:29 - outer pH Table 2^ 9 here I
1125:32 - got and inner P table 2^ 7 and size of
1125:35 - each entry is 4X 4 by add them this will
1125:37 - be your space over it now the question
1125:40 - is is p size equal to chunk size well
1125:42 - that is not necessary chunk size can be
1125:46 - different but pce size should be equal
1125:49 - to frame size that is necessary let me
1125:51 - write pce size should be equal to frame
1125:53 - size not necessarily equal to chunk
1125:57 - size is Page table entry same for outer
1125:59 - page table and inner page table page
1126:01 - table entry will be same for any level
1126:04 - of paging because page table entry does
1126:08 - not depend upon the level of paging it
1126:10 - depends upon the frames in the main
1126:12 - memory so yes it will be same
1126:15 - consider a computer system using three
1126:17 - level paging architecture now we have
1126:18 - three levels outer page table middle
1126:21 - page table let let us call with this and
1126:24 - inner page
1126:26 - table with uniform size at all levels of
1126:30 - paging so here it is given that chunk
1126:32 - size equals to page size equals to frame
1126:34 - size here it is given okay so we call we
1126:38 - call the units of virtual address space
1126:41 - at Pages we calls the units of inner
1126:44 - page page table at as
1126:46 - chunks let us call the units of middle
1126:49 - page table again at like Pages
1126:51 - only I can't think of some another name
1126:54 - another cool name so let us keep it
1126:56 - simple and call it as page only page of
1126:58 - middle page table
1127:00 - okay the size of virtual address is 46
1127:03 - bit so we have a virtual address space
1127:05 - of 2^ 46
1127:08 - bytes page table entries at all level is
1127:11 - 4 by so we have equals to 4 by what must
1127:14 - be the page size in bytes such that the
1127:17 - outer page table exactly fits in one
1127:19 - frame of the memory so what we have to
1127:21 - do we have to find the page table size
1127:23 - of outer page table and should be equal
1127:25 - to frame size or page
1127:29 - size assume that pay size is in power of
1127:32 - two in bytes okay so let's say the pay
1127:35 - size is 2 power 2 power
1127:38 - D show the virtual address format
1127:41 - indicating the number of bits required
1127:44 - to access the three levels okay so we
1127:46 - will solve it we had three level paging
1127:49 - architecture so the virtual address is
1127:52 - 46 bits virtual address will now be
1127:55 - divided into how many parts 1 2 3 4 four
1128:00 - parts now it will be divided when we had
1128:02 - a single level paging then it was
1128:04 - divided into two parts two level paging
1128:05 - divided into three parts three level
1128:07 - paging it will be divided into four
1128:09 - parts this P2 this P2 will depict the
1128:12 - number of entries in outer page table
1128:14 - this D2 will depicts the number of
1128:16 - entries in one page of middle level page
1128:19 - table
1128:21 - this and this D1 will depict number of
1128:23 - entries in one
1128:26 - chunk and this D will depict the number
1128:30 - of words in a page did you get the point
1128:33 - see now the process will be associated
1128:36 - with outer page
1128:38 - table
1128:39 - and chunk of or the page of middle level
1128:43 - page table and chunk of outer level page
1128:45 - table useful pages of mid middle level
1128:47 - page table and useful chunks of inner
1128:49 - level page table so what we have to show
1128:52 - we have to find the page size such that
1128:55 - the number of entries in outer level
1128:57 - page table into e should be equal to
1129:00 - page size this is what we have to
1129:02 - prove and given that page size equal to
1129:05 - chunk size equal to page of outer page
1129:06 - table so I can write D equal to D1 = to
1129:09 - D2 okay it is given here okay uniform
1129:13 - pay SI at all level of P
1129:16 - page size in bites outer page table size
1129:19 - should be equal to frame size so number
1129:21 - of entries in the outer page table is I
1129:23 - should write 2 power P2 and 4B here
1129:28 - which is the size of each entry and it
1129:30 - should be equal to page size that is 2
1129:31 - power
1129:32 - D now let's see how are we going to
1129:35 - solve this so this this was the page
1129:38 - table one each entry is of 4 by and
1129:42 - number of entries in the in inner level
1129:45 - page table will be 2^ 46 that is virtual
1129:48 - address space upon page size let us call
1129:50 - that page size is X so 2 power x is the
1129:53 - page size and this is the virtual
1129:54 - address space this will give me the
1129:56 - number of pages and the number of
1129:58 - entries so how many entries we have take
1130:00 - this up for 2^ 46 - x so I have these
1130:04 - many entries in the inner level base
1130:07 - table now we have divided into chunks we
1130:11 - have divided this space table into
1130:12 - chunks and what is the chunk size again
1130:14 - 2^ X so how many entries we will have in
1130:17 - the page table
1130:20 - two the size of total page table divided
1130:23 - by the chunk size how many entries we
1130:25 - had 2^ 46 divided by 2^ 46 divided by
1130:31 - that is the number of
1130:33 - entries divided by the page size okay so
1130:37 - and this will give me this will give me
1130:39 - the number of entries in the page table
1130:40 - two and this will be the 4 by that is
1130:43 - the page size now we got the page table
1130:45 - size of page table two now we will
1130:49 - divide this page table again into pages
1130:52 - so we will write this here and it will
1130:56 - be divided again with 2^ X this will
1130:59 - give me the number of entries in the
1131:00 - outer page table and this will give me
1131:02 - the with multiplying with four by will
1131:05 - give me the size of outer page table now
1131:08 - we have found that size of outer page
1131:09 - table should be equal to the page size
1131:12 - so from here I can solve that xal to 13
1131:14 - so my page size will be 2^ 13 which is 8
1131:19 - KB don't worry if you didn't get it I'm
1131:21 - going to tell it again I'm going to
1131:24 - explain it again what we
1131:26 - did we have to find the number of
1131:28 - entries in the inner page table how can
1131:30 - we find we had logical address space of
1131:33 - 2^ 46 and the pay size is 2^ X so I have
1131:36 - found the number of entries is 2^ 46 - x
1131:39 - I have divided these entries into
1131:41 - chunks so I have divided these ENT is
1131:44 - into chunks of size 2^ X so this is the
1131:47 - number of entry in this page table two
1131:50 - and this is the 4 by that is number of
1131:53 - entry into size of each entry this is
1131:55 - this total is the size of page table two
1131:58 - now we have to find the size of page
1132:00 - table 3 we we will divide it with 2^ X
1132:04 - so this was the size of page table 2
1132:06 - divided with 2 power x now this will
1132:08 - give me the number of entries in the
1132:10 - outer page table and number of entries
1132:13 - in the outer page table when multiplied
1132:15 - with the size of each entry in the outer
1132:17 - page table will give me the size of
1132:18 - outer page table from here I got the
1132:20 - size of outer page table this is the
1132:22 - size of outer face table and in the
1132:24 - question it is given that I have to
1132:25 - equate with at one frame of the memory I
1132:29 - have to equate that with the one frame
1132:30 - of the memory and you know that one
1132:32 - frame of the memory equal to frame size
1132:34 - equal to page size so I equated with the
1132:36 - page size and I got x = 13 so my pay
1132:38 - size is 2^ 13 that is 88 KV so let us
1132:41 - generalize to solve thing quickly we
1132:44 - have a virtual address space of 2^ s
1132:46 - bytes virtual address s bytes let's see
1132:49 - e is of 2^ C bytes okay this is the what
1132:53 - is
1132:54 - this size of each ENT page size is 2^ X
1132:58 - levels of paging is L we are going to
1133:00 - generalize the
1133:01 - thing so if it is asked the size of
1133:04 - outer page table how are we going to
1133:06 - solve we have to first we have to first
1133:09 - find the number of entries in the inner
1133:11 - level page table so n equals to Virtual
1133:13 - address space upon page size so we got
1133:16 - the number of entries in the inner page
1133:18 - table into size of each entry so we got
1133:22 - the size of table 1 is 2^ s + C - x now
1133:26 - what we have to do we have to find the
1133:29 - number of entries in the outer page
1133:32 - table so what are we going to do we are
1133:33 - going to divide that again with 2 power
1133:37 - x so what we have got number of entries
1133:39 - in the outer page table
1133:42 - into the size of each entry here we got
1133:45 - so at L level the size of page table
1133:48 - will be S + lcus
1133:53 - LX if you are wondering how I got to
1133:56 - this see here at level two what I got I
1133:59 - got two here so at level L I will have L
1134:02 - here so the size of outer page table at
1134:05 - level L will be
1134:08 - this okay let's solve another question
1134:11 - we have virtual address of 46 bits so
1134:13 - virtual address space will be of 2 46
1134:16 - bytes we have page table entry of 4 by
1134:21 - we have page size of 2 power x we have
1134:24 - three level of paging and outer level
1134:27 - page table should be equal
1134:28 - to page
1134:30 - size are we attempting the same question
1134:33 - with this formula are we trying to
1134:35 - attempt the same question with this
1134:36 - formula I think so yes it is also 46 and
1134:40 - we
1134:41 - have we have 32 bit in 4X but I think we
1134:44 - are going to attempt the same question
1134:47 - with this formula
1134:49 - so what does method one says method one
1134:53 - says this will give me the size of first
1134:55 - level page table this will give me the
1134:57 - number of entries in the second level
1134:58 - page table this will give me the number
1134:59 - of entries in the third level page table
1135:02 - so P size has remained constant which
1135:05 - means D = to x what is D well this is so
1135:09 - P1 + P2 + P3 let's equals to
1135:12 - Y because as P size is constant so
1135:16 - number of entries will also be same so I
1135:18 - will write 3 y for that y y y and x for
1135:22 - this so 3 y + x = 46 so the outer page
1135:26 - table should be equal to the page size
1135:29 - so I will write 2^ Y into 4 by that
1135:33 - should be equal to the PA size so I will
1135:34 - write 2^ X = to 2^ Y into 2^ 2 so from
1135:39 - here I will get 2^ x = 2^ y + 2 from
1135:42 - here I got X = y + 2 so I will put that
1135:48 - here in this equation so 3 y + what is x
1135:52 - y + 2 3 y + y + 2 = 46 from here I got y
1135:56 - = 11 and x = 13 that's what we have got
1136:00 - here by solving through this we get the
1136:03 - same
1136:04 - answer that's an easy part or we have
1136:07 - solved it with the help of equations
1136:09 - here we have solved it with the help of
1136:11 - logic how we moved from one p to another
1136:15 - and then in the end we equated that with
1136:16 - the page
1136:18 - size okay consider a computer system
1136:21 - with 57 bit virtual addressing so we
1136:23 - have the virtual address of 57 bit using
1136:26 - multi-level Tre structured page table
1136:28 - with L levels for virtual to physical
1136:30 - address translation so we have L levels
1136:32 - of paging the page size is 4 KB and Page
1136:35 - table entries of 8 by so we have e equal
1136:38 - to 8 by and pay size is of 4 KB which
1136:40 - means 12 bits for D the value of L is so
1136:44 - we have to find the value of L so we can
1136:46 - find by this part the size of outermost
1136:48 - Bas table what was that S Plus lc- LX
1136:51 - should be equal to frame size and do we
1136:55 - know the value of c and x yes we know
1136:57 - the value of c c is 3 and X is
1137:00 - 12 this can be written as 2^ 3 so from
1137:04 - here I got c as 3 and X is 12 so by
1137:08 - solving this I got L = to 5 so it we
1137:11 - need five level of paging see
1137:14 - remembering
1137:15 - formulas is indeed going to help you to
1137:19 - save time in the
1137:20 - exam method 2 we had 45 and 12 see total
1137:26 - was 57 from this page size we got 12 so
1137:28 - 45 we got from here now page size we are
1137:32 - given with 4 KB page table entries of 8
1137:33 - by number of entries that can be stored
1137:35 - in one page will be number of entries
1137:38 - that can be stored in one page will
1137:40 - be total the page size divide by the
1137:43 - size of each entry that is 2^ 9 and from
1137:46 - here I can tell every page table will
1137:47 - have 2^ 9 entries so nine bits to access
1137:50 - so this will be uh 9 bit to xes each so
1137:54 - how many levels will be there five to
1137:56 - get it
1137:58 - 45 see here this was really nice concept
1138:02 - we were able to solve using this we were
1138:05 - able to solve the problem with the help
1138:07 - of this logic that we started with the
1138:09 - page table we started with the page
1138:11 - table size and then we moved it divided
1138:13 - it into chunks multiplied it with the
1138:16 - each entry and then find the size of
1138:18 - another page table again divided it with
1138:20 - the page size find the total number of
1138:22 - entries again multiplied with the size
1138:23 - of each entry got the size again and
1138:25 - then equated with the page size got the
1138:27 - answer that was the thing which we have
1138:29 - do but now what we have done the first
1138:31 - method which we used was we created a
1138:34 - formula that the size of outer level
1138:36 - page table is equal to S Plus LC minus
1138:39 - LX where C is
1138:40 - the C is the this word and this is the
1138:44 - size of each entry so if we have eight
1138:46 - by then C will become three and what is
1138:49 - X x is the page
1138:51 - size so the size of outer level page
1138:53 - entry should be equal to the page size
1138:56 - so we have to solve this s + L C- X
1138:59 - should be equal to X just solve this and
1139:01 - you'll get the
1139:03 - answer okay the another thing which we
1139:05 - are doing is it is said that the page
1139:08 - size is constant if page size is
1139:10 - constant which
1139:12 - means these entries will be same if
1139:15 - these entries will be same I can name it
1139:16 - as y y y and let us name it as
1139:20 - X so 3 y + x should be equal to 46 that
1139:25 - I know and another thing which I know is
1139:27 - outer page table should be equal to page
1139:28 - size so outer page table
1139:31 - is outer page table is this 2 to^ y this
1139:35 - is the size this is the outer page table
1139:36 - so 2^ Y into what is the size of each
1139:40 - entry we are given with 4 byes so 2^ 2
1139:42 - this should be equal to the base size we
1139:44 - write is 2^ X so 2^ X should be equal to
1139:47 - 2^ y + 2 here we got x = y + 2 we used
1139:51 - it here and we find that y = to 11 which
1139:55 - means each page table will have 2^ 11
1139:58 - entries in
1139:59 - it so X = to 13 I got from here if Y is
1140:04 - 11 then 11 into 3 is 33 x 46 from here I
1140:08 - got x = 13 what is X now 2^ X will give
1140:11 - me the page size that is 2^ 13 8 K will
1140:14 - be the my base size that's how I
1140:17 - solved so I solved this question using
1140:19 - two methods again the first was the
1140:21 - formula the second was that we know that
1140:23 - page size is constant so how many how
1140:27 - many levels of paging will require to
1140:30 - consume this 45 bit of Address given
1140:35 - that given that number of entries that
1140:39 - can be stored in one page is 2^ 9 so
1140:42 - each page table has power 9 entries so 9
1140:45 - + 9 + 9 plus how many times to get or to
1140:50 - cover this
1140:50 - [Music]
1140:52 - 45 each page table has how many entries
1140:54 - to rest power 9 so I will require nine
1140:57 - bit for one page
1140:58 - table how many entries I have to put so
1141:01 - that I can cover 45 I have to put five
1141:03 - entries so how many levels of page
1141:05 - paging I will have five levels of
1141:08 - paging so I hope with the help of this
1141:12 - you may have understood how multi Lev
1141:13 - ping
1141:22 - works we have learned about paging in
1141:24 - our previous lectures but there is a
1141:27 - problem with paging that need to be
1141:29 - discussed that is paging does not
1141:31 - preserve the users view of memory
1141:34 - location now what does this users view
1141:36 - means the users view means see like this
1141:40 - suppose I have a main program I have a
1141:42 - main function of of 5 KB in a program I
1141:45 - have a main function of 5 KB and the
1141:48 - page size is of 1 KB now this main
1141:51 - function will be distributed in five
1141:53 - pages and these five pages can be stored
1141:56 - anywhere in the memory wherever the
1141:57 - frame is free so a single function is
1142:01 - distributed all over the memory don't
1142:04 - you find it weird a single main function
1142:06 - a single main function is distributed in
1142:09 - all over the frames in the memory
1142:11 - because non-contiguous allocation is
1142:13 - allowed in so a single function is
1142:15 - distributed all over the
1142:17 - memory that's why this users view of
1142:20 - memory location is not
1142:22 - preserved now what is users view see
1142:26 - this main function in one segment we
1142:29 - create a segment square root function in
1142:32 - one segment so in users View program is
1142:35 - divided into units called segment and by
1142:38 - the time you have guessed that segment
1142:40 - need not to be equal suppose main
1142:41 - function is bigger than the square root
1142:43 - function so this segment will be bigger
1142:44 - than the segment one so this program is
1142:48 - divided into units called segments this
1142:50 - may include functions blocks procedure
1142:52 - call data structure these segments are
1142:55 - assumed to be stored at their entirely
1142:58 - non-contiguous locations in the
1143:01 - memory well we did the same with paging
1143:04 - isn't
1143:06 - it the pages were stored at
1143:09 - non-contiguous locations then what is
1143:11 - the difference between paging and
1143:12 - segmentation in segmentation also we
1143:14 - store the segments at different location
1143:16 - we can wherever the wherever there is
1143:18 - free space you can store a segment there
1143:20 - see here we store segment zero here
1143:22 - segment 3 segment 2 4 segment and
1143:24 - segment one down there we can store
1143:27 - wherever the the free spaces non
1143:29 - continuous allocation is
1143:31 - allowed then what is the difference
1143:33 - between paging and segmentation in
1143:36 - segmentation no matter how big this main
1143:38 - function is you have to store this at
1143:41 - one
1143:42 - place but what happened in paging this
1143:45 - main function was distributed all over
1143:47 - the
1143:48 - memory but here this main function no
1143:50 - matter how big it is it will be stored
1143:52 - at a single location now the question
1143:55 - arise if this main function is bigger
1143:58 - than the frame of the memory then what
1144:00 - will
1144:01 - happen the answer is there is no concept
1144:03 - of frames in this
1144:07 - segmentation physical memory was divided
1144:09 - into frames in which case when we
1144:11 - studied about paging and paging was
1144:14 - related to fixed
1144:16 - allocation here we have a kind of
1144:18 - variable
1144:20 - allocation for segment one for segment
1144:22 - one we will allow some memory here free
1144:25 - space is there for Segment zero we we
1144:28 - allow fragment zero here for segment one
1144:31 - there for Segment two there three four
1144:34 - there so there is no concept of frames
1144:37 - in the physical memory in segmentation
1144:40 - we talk about variable partitioning here
1144:43 - variable partitioning I hope you
1144:44 - remember what is variable partitioning
1144:46 - we create partitions based on the
1144:49 - segment
1144:50 - size okay so concept is similar to
1144:52 - paging but Pages were of same size and
1144:54 - segment is of different size the whole
1144:56 - segment is in one place on the memory
1144:58 - but segments are at non-contiguous
1144:59 - location this view was not preserved by
1145:02 - paging so the same example here we have
1145:04 - taken main function of 5 KB page size of
1145:07 - 1 KB then main function itself will be
1145:09 - distributed non-continuously but in
1145:11 - segmentation no matter how big the
1145:13 - segment this we will store entirely at
1145:15 - one location and there is no concept of
1145:18 - frames in segmentation wherever free
1145:20 - hole is present store the segment it's
1145:21 - like variable
1145:24 - partitioning so there we had page tables
1145:27 - here we'll have segment tables so the
1145:29 - number of entries in segment table will
1145:31 - be equal to number of segment now the
1145:33 - question arises how are we going to do
1145:36 - the addressing so this the entries in
1145:39 - the page table was like that the index
1145:42 - used to represent the page number and
1145:44 - entry is used to represent that frame
1145:46 - where the page where that page is
1145:48 - stored here The Logical address will be
1145:51 - generated like this segment number and
1145:53 - offset segment number and
1145:56 - offset and the entry will be of two
1145:59 - Fields limit and base this limit will
1146:02 - tell the size and the base will tell the
1146:04 - starting
1146:05 - address okay so this segment number will
1146:09 - tell me in which segment I have to look
1146:11 - and this offset will tell me how out of
1146:13 - these let's say there are the sizes of
1146:16 - thousand so out of these thousand word
1146:18 - which word do you want to read and from
1146:21 - this I can tell that offset must be less
1146:23 - than 1,000 suppose The Base address is
1146:26 - 1400 and the size is of 1,000 so from
1146:29 - 1400
1146:32 - to, 1400
1146:35 - to
1146:37 - 2400 no because Zer is included here so
1146:41 - 2 3 99 so till this I can can access the
1146:44 - words but what happened suppose my
1146:47 - suppose the address generated was of
1146:51 - 2699 can it be possible no because we
1146:55 - have the address should be in the range
1146:58 - of, 1400
1147:01 - to
1147:03 - 2399 and the offset out of these
1147:06 - thousand word in which word you have to
1147:07 - look I cannot write or I cannot uh write
1147:10 - offset as500 or some like 1100 because
1147:13 - because we have only thousand work words
1147:15 - to look for out of these thousand words
1147:18 - we have to choose one so offset will
1147:20 - tell out of these thousand word which
1147:23 - word do you want to read okay and the
1147:25 - address should be in this range okay so
1147:30 - how are we going to check if address in
1147:32 - this range and what will happen if
1147:33 - address is not in this range it will go
1147:36 - into the
1147:37 - Trap suppose if process is mischievous
1147:41 - and he and she tries to access the word
1147:43 - beyond the segment then it will go into
1147:45 - the Trap or addressing error will be
1147:48 - generated so from this segment number I
1147:51 - will reach to that
1147:52 - segment okay now here we will check that
1147:56 - if offset is less than the limit or not
1147:58 - the limit was of th000 words the offet
1148:01 - should be less than or equal to
1148:03 - th000 and if it is not then we will send
1148:06 - it to the addressing error or trap if
1148:08 - yes if the offset is in allowed range
1148:11 - then add the offset into the
1148:15 - base or I add the offset into the base
1148:18 - and then you will get the physical
1148:19 - address let me show with the help of
1148:21 - diagram suppose this was the segment and
1148:25 - in that segment we want to access this
1148:26 - word this was our base let's say the
1148:29 - Base address is 1,000 and the address of
1148:31 - this word is
1148:32 - 500
1148:34 - so the address of this word let let it
1148:36 - be500 so the offset will
1148:39 - be offset will be 500 which means out of
1148:42 - these, words let's say this the address
1148:46 - of the last word is one9 so out of these
1148:49 - th words I want to I want that word
1148:52 - which has the address of 1500
1148:55 - so whenever when I will
1148:58 - add the offset into the base I will get
1149:01 - to this so offset will tell me out of
1149:04 - these word which word you want to access
1149:06 - and if you add if you add the offset
1149:09 - into the base you will reach to that
1149:10 - word so that's how addressing is done
1149:12 - here
1149:13 - so to convert logical to physical what
1149:15 - we have to do we have to first check if
1149:17 - offset is less than the limit or not if
1149:20 - yes
1149:22 - then add the base into the offset and
1149:24 - you'll get the physical address of that
1149:27 - word okay so what this segment number is
1149:29 - used segment number is used to check the
1149:32 - segment table for base and the
1149:34 - trap
1149:35 - okay and what is the use of this limit
1149:38 - this limit is used to check if the
1149:40 - offset is not generated Beyond the
1149:43 - limits
1149:44 - suppose this was the allowed segment to
1149:47 - be accessed but what happened I
1149:49 - generated the offset of let's say, 1600
1149:51 - so now when I will add the offset into
1149:54 - the base it will go down to the next
1149:57 - segment no from here I will not yeah
1150:00 - suppose 1600 so I will go down to the
1150:02 - next segment because the offset is
1150:05 - greater than the
1150:08 - limit let me draw
1150:10 - another block here so the base was of
1150:14 - th000 this the total words in the
1150:16 - segment are let's say 1,000 the last
1150:18 - address is of 1 tri9 okay now suppose
1150:22 - the offset is generated of this word
1150:25 - till this offset is generated so I will
1150:26 - be able to access this word it is
1150:27 - allowed but if I generate the offset
1150:29 - greater than the limit then I will enter
1150:32 - into the segment of then I will enter
1150:34 - into the another segment which is not
1150:35 - allowed so what we have to do if the
1150:38 - process wants to access the segment
1150:40 - which it is not allowed to access then
1150:42 - we have to send it to the Trap so that's
1150:44 - what segment table is used segment table
1150:46 - is used first to check the limit whether
1150:49 - this offset is not trying to exceed the
1150:52 - limit and the second thing is we have to
1150:56 - get the Base address so that we can add
1150:58 - the offset to it and get the physical
1150:59 - address so that's how addressing in
1151:02 - segmentation is done let's see this
1151:06 - let's see this example this will make
1151:07 - you more clear consider the following
1151:09 - segment table we have segment we have
1151:13 - base and we have length length is limit
1151:16 - it is just a different name length is
1151:17 - the limit so what are the physical
1151:19 - address of the following logical address
1151:22 - segment Z and this is the offset so the
1151:24 - offset is 4302 but it has a limit of 600
1151:28 - so what will happen
1151:29 - now the Base address is zero the length
1151:32 - is 600 so the last address will be 599
1151:35 - but which address does it want to access
1151:38 - it wants to it wants to go till
1151:41 - 4302 this segment has been over here
1151:43 - only but it wants to access the data of
1151:46 - some other segment which is not allowed
1151:48 - so it will cause
1151:49 - trap trap will be cost the second
1151:52 - question segment number two segment
1151:55 - number two where is the segment number
1151:56 - two here is the segment number two the
1151:58 - offset is 50 so this was the segment
1152:01 - number two the Base address was 90 and
1152:04 - the offset is 50 but what is the what is
1152:07 - the length of the last word or what is
1152:09 - the address of the last word here in the
1152:11 - segment it is 1 8
1152:14 - 9
1152:16 - so 50 here is allowed I can access this
1152:20 - word so 90 + 50 will be the word or will
1152:23 - be the physical address of that word
1152:25 - which want to access from the main
1152:27 - memory 1 and
1152:29 - 15 1 C the offset is larger than the
1152:34 - limit so this will also generate a trap
1152:37 - third part base is 23 27 and the length
1152:41 - is 580 but the offset is yes less than
1152:44 - so what we will do we will add the
1152:45 - offset into the base 2 3 2 7 + 400 so
1152:49 - I'll get 7 2 7 this will be the physical
1152:53 - address of that word which we want to
1152:55 - access fourth the base is 1 1952 now if
1153:00 - the offset is less than this length
1153:02 - then it is allowed but here the offset
1153:05 - is 112 112 it will not be added because
1153:08 - the offset is greater so it will go into
1153:10 - the Trap so this is how segmentation is
1153:12 - done let me repeat whole thing again in
1153:15 - paging the users's view of memory was
1153:17 - not preserved the users view of memory
1153:19 - location was not preserved but here in
1153:20 - segmentation we semantically divide it
1153:23 - main function in one segment square root
1153:25 - in one segment sub rooting in one
1153:26 - segment stag in one segment symbol table
1153:28 - in one segment and how does symbol table
1153:30 - look like it has this will represent the
1153:33 - segment number this will represent the
1153:35 - limit and this will represent the base
1153:37 - what does this limit say it is the size
1153:39 - of the segment and what does this base
1153:40 - say it say it says the starting address
1153:43 - of the
1153:44 - segment starting address of the segment
1153:46 - now the process
1153:49 - generates the now the process generates
1153:52 - The Logical address this is The Logical
1153:54 - address it contains segment number and
1153:56 - offset how are we going to convert this
1153:58 - logical address into physical address
1154:00 - from this segment number we will move to
1154:02 - that index in the page in the segment
1154:04 - table okay now we will check is the
1154:08 - offset less than the limit if yes then
1154:10 - we will add this base to the offset and
1154:12 - the resultant will be the and the
1154:15 - resultant which we get will be the
1154:16 - physical address of that
1154:18 - word
1154:20 - okay so this is how segmentation is done
1154:25 - we have seen all of these things and how
1154:28 - trap is generated by trap is generated
1154:29 - we we have also seen this thing because
1154:31 - if the Trap wouldn't have been there
1154:33 - then the process May access the word of
1154:36 - the segment which it is not supposed to
1154:39 - in the next lecture we will see its
1154:41 - performance
1154:43 - now let's see the performance of
1154:45 - segmentation based on the two factors
1154:47 - time and space how much time it will
1154:49 - take M for the segment table and M for
1154:51 - the main memory where m is the main
1154:53 - memory access time segment table like
1154:56 - the page table also resides in the main
1154:58 - memory so firstly we have to access the
1155:00 - segment table to get the address and
1155:02 - then main memory to get the instruction
1155:05 - of data the addition and the comparison
1155:08 - will take the negligible time okay can
1155:10 - we reduce this time can we reduce this
1155:12 - to m we can with the help of tlb and PSC
1155:16 - if we are using tlb only then tlb it
1155:20 - look at the tlb we got the address
1155:22 - access it tlb Miss look at the tlb we
1155:26 - didn't get the address go at the segment
1155:29 - table first and then at the memory so C
1155:31 - plus 2m for that if we have used tlb
1155:35 - plus PSC then tlb hit got the
1155:39 - address first PS hit got the instruction
1155:43 - of data PSM Miss first looked at the PSC
1155:47 - and then to the memory tlb Miss first
1155:51 - look at the
1155:52 - tlb then segment table here I got the
1155:55 - physical address looked at the PC got
1155:58 - the instruction of data psms looked at
1156:01 - the PSC first then in the memory and
1156:03 - after that I got the instruction of data
1156:05 - so this is how the effective memory
1156:06 - access time is calculated if we have
1156:08 - used tlb or PC it is exactly the same
1156:11 - like we did in the paging okay now if we
1156:16 - talk about space then if segment table
1156:18 - becomes too large then apply paging on
1156:20 - segment table how can we apply paging
1156:23 - select some page size divide the segment
1156:25 - table into Pages store the pages in
1156:28 - frames access them through Page table
1156:30 - see we are not applying paging on
1156:34 - segments segments will be stored in one
1156:38 - location only and the different segments
1156:40 - can be stored non-continuously that
1156:42 - effect is undenied but what are we doing
1156:45 - we are applying paging on
1156:48 - [Music]
1156:49 - this uh internet sex
1156:52 - here this this table I'm talking if this
1156:56 - table has become large
1156:58 - than then we will apply paging on this
1157:00 - table we will divide it into pages and
1157:02 - we will store the pages into frames and
1157:05 - then we will access those pages with the
1157:07 - help of page
1157:09 - table okay so this is what we called
1157:13 - segmented paging we will look into
1157:14 - segmented paging in detail in our
1157:16 - miscellaneous topics okay paging versus
1157:19 - segmentation now it comes which is
1157:21 - better with respect to
1157:24 - fragmentation in paging we have internal
1157:26 - fragmentation at the last page in in
1157:29 - segmentation we have external
1157:31 - fragmentation at Main memory how paging
1157:36 - we have SE internal fragmentation at
1157:37 - last page
1157:39 - suppose suppose the program is divided
1157:41 - into pages and how much page it's going
1157:44 - to require let's say going to require
1157:45 - 4.1 pages so it will take four complete
1157:48 - pages and the fifth page only 01 space
1157:51 - will be used and rest will be unused so
1157:53 - this is how internal fragmentation is
1157:55 - present in the last page in case of
1157:58 - paging and how external external
1158:00 - fragmentation is there in case of
1158:02 - segmentation
1158:04 - suppose between two segments so so less
1158:08 - free space is there that we cannot fit a
1158:10 - different segment or a smaller segment M
1158:13 - there this space is tool less so this is
1158:16 - what external fragmentation is between
1158:19 - two segments the free hole is not big
1158:21 - enough to accommodate any new
1158:24 - segment so in paging we have internal
1158:27 - fragmentation at the last page and in
1158:29 - segmentation we have external
1158:31 - fragmentation at the main memory so in
1158:35 - paging internal fragmentation no
1158:36 - external fragmentation in segment we
1158:38 - have no internal fragmentation because
1158:41 - we follow variable partition
1158:43 - and we have external fragmentation in
1158:46 - main memory just like we organized we
1158:48 - did in the variable
1158:50 - partition okay and how are we going to
1158:52 - solve this external fragmentation issue
1158:54 - in
1158:55 - segmentation the first method is
1158:58 - compaction or defragmentation suppose we
1159:00 - have segment stored like this S1 freeh
1159:02 - hole S2 a bigger segment of size let's
1159:05 - say this much wants to get accommodated
1159:07 - here but we know that a segment either
1159:11 - it will be completely stored or will not
1159:13 - be stored so what we will do we will
1159:15 - shift this segment
1159:17 - here we'll create a bigger free hole now
1159:19 - this segment can be stored here so this
1159:21 - is what competion is as we did in the
1159:23 - variable partitioning it is also known
1159:25 - as def fragmentation but the problem
1159:28 - with competion is it is less it is not
1159:31 - diagram it is desirable it is less
1159:33 - desirable why because firstly it is time
1159:36 - consuming we have to swep out swep in
1159:38 - all that things and the second is
1159:41 - runtime address binding should should be
1159:42 - supported we are changing the addresses
1159:45 - of segments so runtime address binding
1159:47 - is supported so that makes it less
1159:49 - desirable the second option we have is
1159:51 - of segmented
1159:53 - paging segmented paging it reduces the
1159:56 - size of segment table and also the
1159:58 - external fragmentation we will study
1160:00 - that segment paging part in detail in
1160:02 - the last section so these are the topics
1160:06 - we will study in the last section of
1160:08 - miscellaneous topics okay in the next
1160:11 - lecture we will see what is virtual
1160:12 - memory
1160:15 - virtual memory it gives an illusion to
1160:17 - the programmer that huge amount of
1160:18 - memory is available for executing that
1160:21 - program which is larger than physical
1160:24 - memory it gives an illusion to the
1160:26 - programmer that there is enough memory
1160:29 - available for executing a kind of
1160:31 - program which is larger than physical
1160:33 - memory larger than Ram how it works how
1160:36 - it is implemented let's
1160:39 - see suppose we have a virtual address
1160:41 - space of 8 KB
1160:43 - and Main memory of 4 KB page size of 1
1160:45 - KB so this virtual address space will be
1160:47 - divided into pages of will be divided
1160:51 - into pages of size 1 k each from p 0 to
1160:53 - [Music]
1160:55 - p7 we know that it is not possible to
1160:57 - store all the pages into this main
1161:00 - memory because main memory size is
1161:01 - smaller than the virtual address
1161:04 - space see this virtual address space is
1161:07 - nothing but the
1161:10 - program and this is the
1161:13 - processing so it is not even feasible
1161:16 - for bringing the whole program into the
1161:18 - memory even if the space is available
1161:21 - then also it is not feasible to bring
1161:22 - the whole program into memory because as
1161:24 - I've told
1161:25 - you there may be several Pages there may
1161:28 - be let's say 1 million pages but only
1161:30 - few of them are
1161:32 - useful that's why out of these eight
1161:34 - pages let's say four of them are useful
1161:36 - so p 0 P1 P1 is not present so p 0 P2 p7
1161:43 - and P5 were useful so I brought them
1161:44 - here and or I can put it other way that
1161:48 - the size was 4kb only so I have to
1161:50 - select four important pages from these
1161:52 - eight pages and put it there okay but
1161:55 - what will happen in the case if I want
1161:58 - to refer that page which is not actually
1162:00 - present in the main memory let's say I
1162:01 - want to refer P6 then how this will
1162:06 - work so this virtual memory thing is
1162:09 - implemented with the help of demand
1162:11 - paging as the name suggest loading the
1162:14 - pages on demand from disk to
1162:17 - memory there is there are lots of pages
1162:21 - in a program but few of them are loaded
1162:24 - into the main memory creating the
1162:26 - process this is a program in the disk
1162:29 - this is a process in the
1162:31 - memory so each and every page which I
1162:34 - can or I want to refer is present in the
1162:37 - disk only few of them are present in the
1162:40 - memory now what will happen I have want
1162:42 - to refer that page which is not present
1162:45 - in the memory this is what demand paging
1162:47 - is loading the pages on demand from disk
1162:50 - to memory see this virtual memory is
1162:53 - mapped on the disk what is virtual
1162:55 - memory virtual memory is nothing but the
1162:57 - program program is present on the disk
1163:01 - this is the virtual address
1163:02 - space this is the this is the virtual
1163:05 - address this is the virtual address
1163:06 - space mapped on the disk I mean all the
1163:09 - program from p 0 to p7 or whatever
1163:12 - naming you write P1 to p8 are present on
1163:15 - the disk all the all the pages of that
1163:18 - program are present on the dis but few
1163:20 - of them are present on the memory so how
1163:22 - this it will going to work let's see
1163:24 - here suppose this is a process Pi
1163:27 - running on CPU it generates an address P
1163:30 - and
1163:32 - D the page size was 1
1163:35 - kiloby so the D will be of 10 bits and
1163:40 - number of pages were eight so P will be
1163:42 - of three bits it's good now let's say I
1163:45 - want to I want to refer to the page
1163:47 - number two I want to refer to this page
1163:51 - this entry will tell me in which frame
1163:54 - my page number two is stored so this is
1163:55 - 1 one is three in in binary we write
1163:59 - three as 1 one so 1 one is three so in
1164:02 - frame number three my page number two is
1164:04 - there but what will happen if I want to
1164:07 - refer to page number six what will
1164:09 - happen if I want to refer to page number
1164:11 - four or p page number
1164:14 - one now I want to tell you some more
1164:16 - thing which I have not told you before
1164:19 - in this
1164:20 - entry not only the not only the frame
1164:23 - number are stored various other things
1164:25 - are also stored one of them
1164:28 - is this bit this bit will tell me if the
1164:31 - page which I'm looking for is present in
1164:33 - the memory or not suppose page zero is
1164:37 - present in frame one so I will write one
1164:40 - here one will represent that it is a
1164:43 - page hit what is Page hit the page which
1164:46 - I'm looking for is present in the memory
1164:48 - this zero will tell me the page which
1164:51 - I'm looking for is not present in the
1164:52 - memory this is a page Miss so one will
1164:55 - represent the Page hit and zero will
1164:57 - represent the page
1164:59 - miss or I can say the one will represent
1165:02 - that the frame number which is written
1165:03 - here is valid or 0o will represent that
1165:07 - the entry here is
1165:09 - invalid okay so from here I got the
1165:11 - frame number
1165:13 - and from here I got the offset I got
1165:15 - physical address I will access the
1165:18 - memory similar let's take another case
1165:21 - suppose I wenter page number seven is St
1165:23 - in frame Zero from here I got from here
1165:26 - I got the frame number from offset I
1165:28 - will get the word which I want to look
1165:33 - and there I can get the physical address
1165:34 - this one will tell that the frame is
1165:36 - actually present in the memory but I am
1165:39 - more focused upon that case where we are
1165:42 - not finding the page which we are
1165:43 - looking for suppose the address is
1165:46 - generated of this page which is not
1165:47 - present in the memory which is a page
1165:50 - miss or we also call it as a page fault
1165:53 - the page is not present on the memory
1165:55 - but present on the disk you know that
1165:57 - every page which I can refer or I want
1165:59 - to refer is present on the disk every
1166:01 - page because the whole program is
1166:03 - present on the disk but whole program is
1166:05 - not present in the main memory if I want
1166:07 - to refer that page which is present on
1166:08 - the disk but not on the main memory that
1166:11 - phenomena is Page Miss
1166:13 - okay so what will happen now if I want
1166:15 - to refer that page which is causing a
1166:17 - page Miss
1166:18 - then process cing page fault will get
1166:22 - blogged we have to read the page from
1166:24 - the disk so this is what an iio
1166:26 - operation is and why the process is
1166:28 - blocked
1166:29 - because I hope you remember the process
1166:32 - transition diagram from ready it got to
1166:34 - running and from running it has
1166:36 - generated that address or it has
1166:38 - generated the address of that page which
1166:39 - is not present in the memory so what
1166:41 - will happen we have to read that from
1166:43 - the disk and reading or writing
1166:45 - operation on the disk is I operation so
1166:47 - this will go to the block State that's
1166:50 - why the process is
1166:52 - blogged now what will happen after the
1166:54 - process is blogged how are we going to
1166:55 - read the page we have to first perform
1166:58 - the mode shifting we have to shift the
1167:00 - mode from user to
1167:03 - Kernel
1167:04 - kernel virtual memory manager now
1167:08 - process is blocked then who will come to
1167:10 - the CPU virtual memory manager will be
1167:12 - on CPU taking charge summoning the disk
1167:15 - manager to find that required page and
1167:17 - have hand over the copy to that page to
1167:19 - virtual memory
1167:21 - manager let us see the whole process
1167:24 - what is going on suppose there's a
1167:25 - process running on the CPU it generates
1167:27 - an address of that page which is present
1167:29 - to the memory then I'll get the physical
1167:31 - address how here I will get the frame
1167:34 - number here I'll get the offset I get
1167:36 - the physical address I will access that
1167:37 - word but now the process has generated
1167:41 - the address of that page or process want
1167:43 - to refer that page which is not actually
1167:45 - present in the memory now what will
1167:47 - happen process will get blogged why
1167:50 - because that page which process want to
1167:52 - refer is present in the disk reading the
1167:55 - page from the dis is an IO operation and
1167:57 - for I operation process has to get
1167:59 - blocked after the process is blocked CPU
1168:01 - is empty from running the process has
1168:04 - went to the block state so no one is
1168:06 - there at the CPU now who will come
1168:08 - virtual memory manager will be on the
1168:09 - CPU taking charge summoning the disc
1168:12 - manager virtual me memory manager say
1168:13 - hey disk manager I want this page so
1168:16 - disk manager will look in the hard
1168:18 - disk and hand over the copy of that page
1168:20 - to virtual memory manager now virtual
1168:23 - memory manager will try to save that
1168:25 - copy of of that page to the main memory
1168:28 - it has got the page which I which the
1168:30 - process want to refer let's say P6 was
1168:32 - the page let's say P6 was the page that
1168:36 - uh process want to refer it was not
1168:37 - present here so process will get blocked
1168:39 - virtual memory memory manager will come
1168:41 - summon the disk manager to hand over
1168:43 - that copy of the page to virtual memory
1168:46 - manager now virtual memory manager has
1168:48 - the page
1168:50 - B6 what will virtual memory manager do
1168:52 - now it will try to fit that page into
1168:55 - main memory so that process can refer to
1168:57 - that page so here two cases will come
1169:00 - the first case
1169:01 - is we have an empty slot in the main
1169:04 - memory if the frame is empty then the
1169:07 - virtual memory manager will save that
1169:09 - page unblock the process eye process
1169:11 - will come to the ready State and it will
1169:13 - continue its work from there but what
1169:15 - will happen if the frame is not empty
1169:17 - like in this case frame is not empty so
1169:20 - we have to select a frame out of these
1169:23 - swap that out and swap P6
1169:27 - in the case one was there was an empty
1169:29 - frame present so I will put P6 there but
1169:33 - the case two is there is no empty frame
1169:34 - all the frame are already filled now
1169:36 - what will happen I will select a page
1169:40 - and I will select the page and I will
1169:42 - swep that out from the main memory and
1169:44 - swep in the
1169:47 - P6 same thing is written here if the
1169:49 - frame is not empty we need to swap we
1169:52 - have to select a page as a victim now
1169:54 - the question arise how are we going to
1169:56 - select the page as a victim there are
1169:58 - policies present to select the
1169:59 - page so what we will do P5 P5 let's say
1170:03 - P5 is the victim so we will swap out the
1170:07 - P5 what is the meaning of spping Out
1170:10 - means from Main memory I will put this
1170:12 - P5 back to the disk and from disk I will
1170:16 - put P6 here now this is what the main
1170:19 - memory looks like it has page number
1170:21 - seven page number zero page number six
1170:22 - and page number
1170:24 - two so we have replace or copy or
1170:28 - replace if updated in the memory we will
1170:30 - copy or replace if updated in the memory
1170:32 - so this is how demand paging is done and
1170:36 - all of the operating system which you
1170:38 - know like Windows Mac Unix all of them
1170:40 - follow this approach
1170:43 - let us understand the types of demand
1170:44 - paging the first is pure demand paging
1170:47 - or the default one in pure demand paging
1170:50 - we start the execution of the process
1170:52 - with empty frames the whole M main
1170:55 - memory is empty none of the page is
1170:57 - present there but in prefetch as the
1170:59 - name suggest we start with loaded Pages
1171:03 - see this page fault is like an interupt
1171:05 - which will result from mode which will
1171:07 - result in mode shifting from user mode
1171:09 - to Kernel mode
1171:11 - okay this is the point I want to mention
1171:14 - in the implementation of virtual memory
1171:16 - three three types of address spaces are
1171:18 - involved the first is the main memory
1171:20 - which is physical address space the
1171:22 - second is the virtual memory that is
1171:23 - which is the virtual address space and
1171:25 - third is the dis address space now can
1171:27 - you tell me the relation between
1171:29 - them physical address space is less or
1171:33 - equal to the virtual address space
1171:35 - because we need larger program this in
1171:38 - this virtual letter space program is
1171:40 - stored the program program is itself the
1171:43 - virtual address space so what is
1171:44 - physical address space in this processes
1171:47 - are stored so larger program should be
1171:49 - able to execute in smaller area that's
1171:52 - why we have a physical address space and
1171:54 - virtual address space virtual address
1171:56 - space is greater than the physical
1171:57 - address space now comes the disk address
1172:00 - space size of virtual memory is limited
1172:02 - by the size of disk see this is the
1172:07 - program this is the
1172:09 - process and this is the dis
1172:12 - itself so in disk there are multiple
1172:15 - programs okay and only some part of the
1172:18 - program are loaded into the main memory
1172:21 - that becomes the process so physical
1172:23 - address space is the smallest then comes
1172:26 - the virtual address space and then the
1172:27 - disk address space virtual memory is
1172:30 - mapped onto the disk mapped onto the
1172:32 - disk
1172:34 - so disk address space should be large
1172:37 - enough okay look at these diagrams
1172:40 - now CPU then cache memory then Ram then
1172:43 - virtual memory hard memory comes this is
1172:45 - what the conceptual view of main memory
1172:47 - is let's see this memory
1172:49 - hierarchy how data is transferred
1172:52 - between memory hierarchy so from virtual
1172:55 - memory it is transferred from virtual
1172:57 - memory data or pages are transferred
1172:59 - into main memory upon page P from Main
1173:02 - memory the data is transferred into cach
1173:05 - upon cach Miss and from cach we transfer
1173:09 - data into register via load or store
1173:11 - okay so this is the memory hierarchy
1173:14 - this is the conceptual view these are
1173:16 - the pages memory map either hit or miss
1173:20 - if hit then it is okay if Miss then swap
1173:23 - in swap out will happen this Miss is
1173:25 - also known as page fault if page fault
1173:27 - happens then what what happens the
1173:29 - process is blocked virtual virtual
1173:31 - memory manager will come into the CPU
1173:34 - virtual memory manager will summon the
1173:36 - disk manager to hand over the virtual
1173:38 - memory manager that is hand over him the
1173:41 - copy of that page so disk manager will
1173:45 - look at that page enter the disk find
1173:48 - that page copy that page into and copy
1173:51 - the page and hand over to the virtual
1173:52 - memory manager now what will virtual
1173:55 - memory manager do it will try to put
1173:57 - that page back into the main memory two
1173:59 - cases may occur the first is there exist
1174:02 - an empty slot for that page to be
1174:06 - shifted there but if no empty frame is
1174:08 - present then we have to select a victim
1174:10 - page remove that page from that frame
1174:12 - and place the newly copied frame uh
1174:16 - newly copied page into that
1174:18 - frame so this was the
1174:20 - idea apps taken to serve the page fault
1174:23 - firstly the program is loaded into the
1174:25 - main memory and then page table is
1174:28 - formed now process want to access that
1174:30 - page which is not present in the memory
1174:32 - then it will generate an interrupt mode
1174:34 - shifting will happen virtual memory
1174:36 - manager will become active and with the
1174:38 - help of disk manager it will try to
1174:40 - bring that page into
1174:42 - main memory again if the free frame is
1174:44 - present then it will put that page into
1174:46 - that free frame and then we'll update
1174:48 - the page table and restart the
1174:50 - instruction okay so these are the
1174:53 - steps page for service time pfst is the
1174:57 - amount of time taken by operating system
1174:58 - to serve the page for it is generally in
1175:00 - the millisecond and memory access time
1175:03 - is generally in the nanc in the next
1175:05 - lecture we will see the performance of
1175:06 - virtual
1175:09 - memory let's analyze the virtual memory
1175:13 - timing so instead of calculating
1175:15 - effective memory excess time we are
1175:18 - calculating here effective access time
1175:20 - we will take effective memory access
1175:22 - time as M
1175:24 - only so let us take that effective
1175:27 - memory access time is m page fault
1175:30 - service time is s and Page fault rate is
1175:35 - p and Page hit rate as 1 minus P here
1175:39 - the structure of formula will little bit
1175:41 - change change because in tlb or in
1175:43 - caching we used to take hit rate as X
1175:46 - and Miss rate as 1 - x but here we have
1175:49 - taken page fault that is the Miss rate
1175:51 - as p and hit rate as 1 minus P now we
1175:55 - will calculate effective excess time of
1175:57 - demand paging as virtual memory is
1175:59 - implemented using demand paging it will
1176:02 - be equal to if I had a hit then 1us P
1176:06 - into effective memory exess time plus if
1176:09 - I had a Miss then
1176:12 - first I have to serve the page fault so
1176:14 - s will come and then I will access the
1176:16 - memory but you know that page fault
1176:19 - service time is in milliseconds and Main
1176:22 - memory or effective memory access time
1176:25 - is in Nan seconds so I can ignore M here
1176:29 - I can write it as s so formula of
1176:32 - effective exis time for demand paging
1176:35 - will be demand paging will
1176:37 - be 1 - P into M plus P into s + m or I
1176:45 - can WR write here P into s let us
1176:49 - read performance calculation of demand
1176:51 - paging system if there is no page fault
1176:53 - effective access time is the effective
1176:55 - memory access time okay effective access
1176:56 - time equal to effective member access
1176:58 - time if there is a page fault we have
1177:01 - effective access time equals to firstly
1177:03 - page for search time and then effective
1177:04 - memory access time and we can
1177:07 - approximate that is to page for search
1177:08 - time because page for search time is
1177:10 - very large in comparison to effective M
1177:13 - ex time it is around like, and one so we
1177:15 - can ignore one in front of thand where
1177:19 - PFS is the page for service time since
1177:21 - the emat that is effective mem system is
1177:23 - very small compared to pfst it can be
1177:26 - ignored now we had a page for rate of P
1177:29 - then effective access time can be
1177:31 - calculated as follows so effective
1177:33 - access time equals to page fault into
1177:36 - effective access time of page fault what
1177:38 - is the effective access time of page
1177:39 - fault this page fault service time
1177:43 - and Page hit and then effective access
1177:46 - time no page fault that is emat only so
1177:49 - that's how we got our effective access
1177:51 - time now you can look for this example
1177:54 - effective memory access time for a given
1177:56 - system is 1 microc and the average page
1177:59 - for search time is at 10 millisecond you
1178:01 - can see the difference let's say p is
1178:04 - the page fault rate or the probability
1178:07 - of page fault then effective exis time
1178:08 - will be just put the values and you'll
1178:10 - get the answer
1178:15 - look at this amazing flowchart it will
1178:17 - contain all of the cases which we have
1178:19 - studied till
1178:20 - now we will start from CPU it generated
1178:24 - a virtual address then the first cases
1178:27 - which Sayed in the tlb and the two cases
1178:30 - which can arise is either it was a miss
1178:33 - or it was a hit if if it was a hit then
1178:36 - we generated the physical address if it
1178:39 - was a Miss then we have went and
1178:42 - searched to the search at the page table
1178:46 - now again two cases May generate the
1178:48 - first was in the in the page table we
1178:51 - had a hit it means the page which we
1178:54 - were looking for was present in the
1178:56 - memory we had a hit and the second case
1178:59 - which may arise is it may be a miss so
1179:02 - let's look at the Miss first if it was a
1179:05 - Miss then page fault will occur and we
1179:08 - will serve that page fault we will get
1179:09 - that page from the secondary memory that
1179:11 - is the hard disk we'll update the main
1179:13 - memory we'll update the cache and we'll
1179:15 - update the page table entry and then we
1179:18 - will go at the beginning again but if it
1179:21 - was a hit then we will generate the
1179:24 - physical address now we have included an
1179:27 - additional concept here of
1179:30 - updation in
1179:33 - cash if we had a Miss then we will not
1179:36 - let it be Miss always we will update it
1179:39 - so that next time when when we will
1179:40 - search for that page it will be easier
1179:43 - for us so here what we have done we have
1179:46 - updated the cashier we'll update the
1179:48 - cashier when it was a Miss in the tlb we
1179:51 - went to the page table we had a hit
1179:53 - there then we'll update the tlb
1179:56 - now okay tlb was updated so now it's
1180:01 - time to go and access that word or
1180:04 - instruction so we had physical address
1180:07 - now we had here physical address now now
1180:09 - let's say we went to the
1180:13 - PC again two cases may arise either it
1180:15 - may be a hit or it may be a Miss let's
1180:18 - say if it is a hit that means we found
1180:21 - the instruction or data corresponding to
1180:23 - that physical address then we will
1180:25 - return that value from cach to
1180:29 - CPU if it was a Miss then what will
1180:32 - happen we will update the cash we will
1180:34 - update the cash from Main memory what we
1180:37 - did in the case of page
1180:39 - table or what we did in the the case of
1180:41 - tlb we updated it using page table and
1180:44 - here we will update the PSC using main
1180:47 - memory so we will update the cach from
1180:48 - Main memory and then I will return the
1180:51 - value from cash either data or
1180:53 - instruction to the CPU so that's how it
1180:55 - work let us read it again for more
1180:58 - clarity CPU generated the virtual
1181:00 - address searched in the tlb two cases
1181:02 - may arise either hit or miss if it is a
1181:04 - Miss then I will look in the page table
1181:06 - if it is a hit then I will generate the
1181:08 - physical address update the tlv if it
1181:10 - was a miss then I will look then I will
1181:13 - uh serf the page fault update the main
1181:14 - memory cach and Page table entry now we
1181:17 - have got the physical address and then
1181:20 - we will search for that physical address
1181:22 - into cache whether that instruction or
1181:24 - data corresponding to that physical
1181:25 - address is available in the cach or not
1181:27 - if yes then we'll return that and if no
1181:30 - we'll update and then return so this was
1181:33 - the virtual memory concept with the help
1181:35 - of tlb and PSC plus we had an additional
1181:38 - concept of updation
1181:41 - I hope you liked
1181:49 - it let us solve some problems and you
1181:51 - know the drill you have to solve or
1181:53 - attempt them first and then see the
1181:55 - solution suppose the time to serve a
1181:57 - phage fault is on an average 10
1181:59 - milliseconds while a memory exess time
1182:01 - takes 1 microc then
1182:04 - 99.99% hit ratio this is 1 minus P hit
1182:09 - result in an average memory exess time
1182:11 - and this is nothing but effective excess
1182:13 - time so you have to just apply the
1182:14 - formula page fault occurred page for
1182:16 - service time page for did not occur and
1182:19 - Main memory exess time here this is
1182:21 - given 10 milliseconds this is given 1
1182:23 - microc this is given and you find this
1182:26 - by 1 minus uh hit
1182:30 - ratio so 99.99% was the hit ratio so
1182:35 - 0.01% will be the Miss Ratio or the page
1182:38 - fault rate so from here I got this now
1182:42 - we can see that the units are different
1182:44 - we have to bring them to the same unit 1
1182:47 - millisecond is 10 ra to^ - 3 seconds 1
1182:51 - microc is 10^ - 6 seconds so I can say 1
1182:56 - millisecond is 10 power 3 microc so I
1183:01 - will write here 1,000 and we'll solve
1183:03 - this and I got 1 micros and from there I
1183:06 - got
1183:08 - 0.9999 microc
1183:11 - so adding them I got this 1. n999 microc
1183:15 - as the answer question number two if an
1183:18 - instruction takes I microc and with a
1183:21 - page fall takes an additional J microc
1183:25 - then effective exess time if on average
1183:27 - a p page fa occurs after K instruction
1183:30 - is so we have to find the effective
1183:32 - instruction
1183:34 - time instruction I if it is just the
1183:38 - instruction then it takes I micros
1183:40 - seconds if it is a page page forward
1183:41 - then it will take additional see here
1183:43 - see here additional J is written so
1183:45 - additional J microc so I + J after every
1183:48 - K so I can write for first instruction
1183:52 - take I second take I and for K it will
1183:55 - take I + J just find the average I + i+
1183:58 - and then in the end i+ j total are K so
1184:02 - K in the denominator from here I got I +
1184:04 - J by K I can do this with the formula
1184:08 - also we know that page fault rate is K 1
1184:10 - by K so 1 by K into I + J + 1 upon 1 - K
1184:21 - into I only so this is Page fault
1184:24 - occurred time with page fault so it will
1184:27 - take I for instruction and J for
1184:29 - additional page fault service so page
1184:32 - fault occurred page for service time
1184:35 - page for did not occur memory exess Time
1184:37 - same
1184:38 - formula question number three you should
1184:41 - attempt this on your
1184:43 - own now let's see the solution assume
1184:46 - that we have a demand page memory it
1184:49 - takes 8 millisecond to serve a page
1184:51 - fault if empty frame is available or if
1184:55 - replaced page is not modified so let me
1184:57 - tell you a concept
1185:01 - that this was our memory suppose this
1185:05 - was the victim frame that is that will
1185:08 - be replaced with some other page
1185:11 - or let me start with the beginning
1185:12 - suppose a process generated an address
1185:14 - of that page which is not present in any
1185:16 - of the frame on the memory so what
1185:18 - happened page fault will occur now page
1185:20 - fault will be served so that page which
1185:23 - the process want to refer will be bring
1185:25 - brought to the
1185:26 - memory and no p no frame is available if
1185:30 - no frame is available then one of the
1185:33 - frames will be selected as victim and
1185:34 - that frame will be replaced with the
1185:37 - page which we have brought so the thing
1185:40 - is if the victim page has been modified
1185:43 - then we have to store that victim page
1185:46 - into the disk first so that the updated
1185:49 - data is not will not be lost and then
1185:51 - that page will be
1185:53 - restored so this is the concept so it it
1185:57 - says if an empty frame is available or
1186:00 - if a replaced page is not
1186:02 - modified if it is not modified then just
1186:05 - remove that from the uh memory just
1186:08 - throw it somewhere somewhere in the free
1186:09 - space and then store the page which you
1186:11 - want to
1186:13 - store that can only happen if either
1186:15 - empty frame is available or the replaced
1186:18 - page is not modified but the case is if
1186:21 - that victim page is modified then you
1186:23 - have to store that in this first and
1186:25 - then store that
1186:27 - page so this will take some additional
1186:30 - time so this uh the victim page which is
1186:33 - which has been
1186:34 - modified has been given a term dirty so
1186:40 - it says that
1186:41 - page for service time will be different
1186:43 - if the page is clean or the victim page
1186:46 - is not modified or the empty frame is
1186:49 - available then it will take 8
1186:51 - milliseconds
1186:52 - and 20 milliseconds if the page is dirty
1186:55 - or modified and it is also given that
1186:58 - 70% of the time page is modified so for
1187:01 - dirty I will write d as uh D equal to7
1187:05 - and from here 1 minus D will be3 which
1187:08 - means 30% of the time the page is clean
1187:10 - and for 70% of the time the page is
1187:12 - dirty memory excess time we are given
1187:14 - with 100 nond so we have to find the
1187:17 - acceptable page for rate for an
1187:19 - effective exess time no more than 2,000
1187:22 - nond so effective exess time less than
1187:25 - 2,000 NS and Page fault rate we have to
1187:27 - find just apply the formula effective
1187:30 - access time equals to page fault has
1187:32 - been occurred page fault service time
1187:35 - now we cannot directly write 8 or 20
1187:38 - here we have to find the effective
1187:41 - page for time so how can we find
1187:43 - effective page for time 8 milliseconds
1187:46 - when it is not dirty and 20 milliseconds
1187:49 - when it is dirty so from here I will get
1187:53 - it is 14 milliseconds and it is 2.4
1187:56 - milliseconds so from here I got 16.4
1187:59 - millisecs this is the effective page
1188:02 - fault
1188:03 - time page fault occurred effective page
1188:06 - for service time page fault did not
1188:07 - occur memory exess Time same formula we
1188:11 - put the values and solved for the value
1188:13 - of P because we want to know the
1188:17 - acceptable page for rate for the case
1188:19 - when the effective exess time is less
1188:22 - than 2,000
1188:24 - NS so from here we solved how did we
1188:27 - solve see here this this was in
1188:29 - milliseconds and this was in nanc so you
1188:31 - have to bring them to the same scale and
1188:34 - we solve this and we find that the
1188:36 - effective page fault rate uh no it is
1188:39 - just the page fault rate not effective
1188:41 - that was the effective page for service
1188:43 - time so the page fault rate should be
1188:45 - around
1188:47 - 0.01% or 10^ minus 4 okay see another
1188:54 - question consider a process executing on
1188:56 - an operating system that uses demand
1188:58 - paging the average time for a memory
1189:00 - access in the system is M units if the
1189:03 - corresponding memory page is available
1189:06 - in memory and D units of the memory page
1189:08 - causes a page f it has been experim
1189:10 - Mally measured that the average time
1189:12 - taken for memory access is X units so
1189:14 - this is E8
1189:20 - given which of the following is the
1189:22 - correct expression for the page fault
1189:24 - rate experienced by the
1189:26 - process so here x will be the effective
1189:30 - exess Time 1 minus P will be the time
1189:34 - when page fault has not occurred if page
1189:37 - fault has not occurred then access the
1189:38 - memory if page fault occurred then page
1189:40 - fault service time so just we have to
1189:43 - find P from this equation x = m - mp+ DP
1189:49 - so M will be sent here x - M and P will
1189:52 - be taken common from this and this D
1189:53 - minus will be sent to the denominator so
1189:55 - x - M upon D minus M will be the answer
1189:58 - that is
1189:59 - B now comes an amazing question it says
1190:03 - consider a paging system that uses one
1190:05 - level page table resing in main memory
1190:08 - okay so one level okay and a lb for
1190:11 - address
1190:12 - translation each main memory access time
1190:15 - takes 100
1190:17 - NS and tlb lookup takes 20 n
1190:22 - seconds each page transfer to and from
1190:26 - disk takes 5,000
1190:29 - NS 5,000
1190:32 - NS assume that the tlb hit ratio is 95%
1190:36 - so X is
1190:38 - 95% or I can write point 95 if we are
1190:41 - talking probability the page fault rate
1190:44 - is 10% so page fault rate will be p is
1190:48 - .1 assume that for 20% of the total page
1190:52 - faults a dirty page has to be written
1190:54 - back to the disk before required page is
1190:56 - read in from the disc that concept I've
1190:58 - told you so D will
1191:01 - be02 okay tlb update time is negligible
1191:05 - okay the average memory access time is
1191:07 - so easy question let us take this case
1191:10 - suppose a process Pi resting in CPO
1191:12 - generates a logical address firstly we
1191:14 - will look in the tlb if found then F
1191:17 - frame will be copied here and this D
1191:18 - will be copied here and we get our
1191:20 - physical address but if not we will
1191:22 - search first in the page table if page
1191:25 - table if found in the page table this
1191:27 - Frame will be copied here this D will be
1191:30 - copied here and we found our physical
1191:31 - address if not even found in page
1191:34 - table then two things can arise the
1191:37 - first is the victim page is dirty the
1191:40 - second thing is victim page is clean if
1191:42 - the victim page is clean then we have to
1191:44 - just bring from the disc and if victim
1191:47 - page is dirty then we have to first
1191:49 - store and then bring that page into the
1191:51 - disk
1191:52 - so this time is given that 5,000 nond
1191:57 - will be taken if we have to uh transfer
1192:00 - a page to and from the dis so in case of
1192:03 - clean only 5,000 nond will be taken and
1192:07 - for the dirty 5,000 NS for storing the
1192:11 - page back to the dis and 5,000 nond for
1192:14 - bringing the new page to the
1192:16 - memory so we have to just apply the
1192:18 - formula now effective memory access time
1192:21 - tlb hit tlb look up got the physical
1192:24 - address access the memory tlb
1192:26 - Miss first looked in the tlb but failed
1192:30 - then I mve to the page table it was
1192:33 - found in the page table here I got my
1192:35 - physical address access the memory now
1192:38 - what happened I had a tlv miss I had a
1192:41 - page miss or page F now I am looking in
1192:45 - the page table first but found that it
1192:47 - was not present
1192:49 - so chances are the page is dirty so if
1192:52 - the page is dirty then 2T time will be
1192:54 - taken that is 10,000 n seconds and if
1192:57 - the page is not dirty just 5,000 NS put
1193:00 - the values and you'll get your answer
1193:02 - okay so the answer was 54.5 NS so if the
1193:07 - page is clean then one dis operation if
1193:09 - the page is dirty then to disc discover
1193:11 - so simple in the next lecture we will
1193:13 - learn about page
1193:15 - replacement page
1193:17 - replacement first we'll learn about what
1193:20 - is reference string set of successfully
1193:23 - unique Pages referred in the given list
1193:25 - of virtual addresses this successfully
1193:28 - unique is important because if one page
1193:31 - is successfully not unique and the same
1193:33 - page we are referring then it won't
1193:35 - create a p it won't create a page fault
1193:38 - don't worry if you don't get that line
1193:40 - I'll explain it to you suppose virtual
1193:43 - address are generated like this way 702
1193:45 - 74 123
1193:47 - 654 483 012 934 in this way let's say
1193:52 - the virtual addresses are
1193:54 - created now the page size is 100 bytes
1193:58 - so this will belong to page 7even this
1194:00 - will belong to page 7even this will
1194:02 - belong to page 1 belong to Page 6 belong
1194:05 - to page 4 belong to page 0o belong to
1194:07 - page 9 I hope you are getting how I am
1194:09 - getting the the page number I'm getting
1194:11 - the page number by this virtual address
1194:15 - mod page size this will give me the page
1194:18 - number and what will be the offset here
1194:21 - the the page number is seventh and the
1194:24 - offset is two the offset is four the
1194:26 - offset is 23 the offset is 54 the offset
1194:28 - is 83 the offset is 12 the offset is
1194:31 - 34 okay so this this tells me that I
1194:35 - have to visit page number nine and word
1194:39 - number 34 in that
1194:41 - page that word will contain my
1194:43 - instruction of
1194:44 - data so this was the virtual address
1194:47 - generated now the reference string will
1194:51 - be 7 this seven won't be counted because
1194:55 - we want successively unique focus on the
1194:58 - word successively this seven won't be
1195:01 - counted then 123 so 1 6 now let's
1195:05 - suppose if seven comes again then we
1195:06 - will take it 4 0 and 9 this is what the
1195:11 - reference string is reference string is
1195:14 - not about Pages uh is not about
1195:16 - addresses it is about pages okay so this
1195:19 - this was the virtual address generated
1195:21 - and the reference will be reference
1195:22 - string will be about
1195:24 - pages okay so which page we want to
1195:28 - refer that page will come and
1195:30 - successively unique pages should be
1195:32 - there like here this seven won't come I
1195:35 - hope you got the idea so why
1195:37 - successfully unique we referred a page
1195:40 - page fault occurred we bought that page
1195:42 - into the memory now we are referring
1195:44 - that page again page fult cannot occur
1195:47 - okay so create reference string from
1195:49 - this virtual address 6 2 1 6 7 2
1195:55 - 95 okay as they are all successfully
1195:57 - unique successfully unique so we will
1196:00 - take them reference string has two
1196:03 - properties length and number of unique
1196:06 - Pages this number of unique Pages tells
1196:09 - us about the size of the process in
1196:11 - terms of
1196:13 - pages here let's calculate the number of
1196:15 - unique Pages 71 6 409 so six unique
1196:19 - pages are there and what is the length
1196:22 - of the reference string the length of
1196:24 - the reference string will be 6 only
1196:27 - suppose in this case 7 1 7 1 7 6 in
1196:33 - calculating the length we will calculate
1196:35 - these 37 but in calculating the N that
1196:38 - is the number of unit Pages referred we
1196:41 - won't calculate the N again and again I
1196:43 - hope that is
1196:44 - clear frame allocation
1196:47 - policies n represent number of process
1196:50 - SI demand frames for process i d is the
1196:54 - total demand m is the available frames
1196:56 - AI is the allocated frames this is
1196:58 - similar to the bankers algorithm number
1197:00 - of
1197:01 - processes frames demanded by process I
1197:05 - or for process i d is the total Demand
1197:08 - by all the processes m is the available
1197:10 - frames AI is the allocated frame to that
1197:12 - process I okay and you know that
1197:16 - allocated will always be less than equal
1197:17 - to demand we won't allocate more than
1197:19 - the
1197:21 - demand n equal to 5 which means five
1197:24 - unique process 1 2 3 4 5 m equal to 40
1197:28 - which means total available frames are
1197:32 - 40 okay these these were the demands P
1197:37 - P1 demanded 10 frames P2 demanded five
1197:39 - frames P3 demanded 35 P4 demanded 18 and
1197:42 - P5 demanded 12 some of sum them all and
1197:45 - you'll get the total demand that is D
1197:48 - will be 0 now there are different
1197:51 - allocation policies frame allocation
1197:53 - policies the first allocation policy
1197:55 - says that allocate them
1197:59 - equally how many how many total
1198:02 - available frames we have 40 so allocate
1198:03 - them each allocate them each eight eight
1198:06 - frames so 10 will be given eight frames
1198:08 - five it demand of five but it got eight
1198:12 - it demanded of 35 but it got 8 only it
1198:14 - demanded of 18 it got eight only so this
1198:17 - is absurd it should not be there because
1198:20 - P2 demanded just five and it got eight
1198:23 - more than its demand and P3 demanded 35
1198:26 - and it only got eight way less than its
1198:29 - demand so when should we use this equal
1198:32 - allocation policy this should be used
1198:34 - when all the process have almost equal
1198:36 - demand in this case demand is varing 10
1198:40 - 5 35 18 12 if would be around 10 11 10 9
1198:46 - 12 in that case this equal allocation
1198:49 - policy will somehow satisfy that okay
1198:53 - now there is a obvious point to be made
1198:55 - that if available frames are way greater
1198:58 - than the demand then there is no scene
1199:00 - of allocation
1199:03 - policy we create policies because the
1199:06 - demand is more and available is less if
1199:08 - the available is more and demand is less
1199:10 - then what is the need of decision
1199:13 - making the second policy comes of a
1199:16 - proportionate
1199:17 - allocation demand upon total into
1199:22 - available so this will be allocated to
1199:24 - each process demand upon
1199:27 - total
1199:30 - into demand upon total demand into total
1199:32 - available so this will proportionately
1199:35 - divide the total available
1199:37 - frames so this is what proportionate is
1199:40 - 50% rule says whatever the process ask
1199:43 - give it half of that if it ask 100 give
1199:46 - it 50 this is 50% R now the question
1199:50 - arises minimum number of frames
1199:52 - allocated to a
1199:54 - process the the minimum number of frames
1199:56 - allocated to that process what should be
1199:58 - the minimum number of frames the first
1200:00 - is that number of frames without them
1200:03 - process cannot execute the second point
1200:06 - is process should be able to execute
1200:08 - minimum one instr
1200:10 - instruction if minimum of one
1200:13 - instruction is being executed then those
1200:14 - are the minimum number of frames
1200:16 - allocated to that process which which
1200:18 - says at least these many frames should
1200:20 - be given to the process for
1200:23 - execution now if
1200:27 - uh process should be able to execute
1200:29 - minimum one instruction so if we have to
1200:31 - execute one instruction only then what
1200:33 - is the need of multiple frames because
1200:36 - instruction can be stored in one frame
1200:38 - so for one instruction shouldn't we need
1200:40 - just one frame so that is the question
1200:43 - but it is not that simple it depends
1200:46 - upon the instruction
1200:48 - architecture like uh we will discuss it
1200:52 - with more detail in computer
1200:54 - organization architecture course but
1200:56 - just for the sake of
1200:58 - explanation this is the op code and
1201:01 - these are the operant this op code is
1201:02 - like a code in binary which will tell
1201:05 - which operation to perform and these are
1201:07 - the
1201:08 - oints which tells on which variables we
1201:11 - have to perform that operation on or in
1201:13 - which literals you have to perform that
1201:16 - operation okay
1201:18 - suppose add R1 B so in this R1 + b the
1201:23 - result should be stored in R1 so this is
1201:26 - what an instruction is and this add will
1201:28 - be the op code let's say 0 1 1 0 this
1201:32 - represent the op code for
1201:34 - addition so this is the op code these
1201:37 - are the
1201:38 - oints now the the point is operant can
1201:42 - be distributed in multiple pages so we
1201:44 - cannot say that we only need one page or
1201:47 - one frame for an instruction to be
1201:49 - executed see instruction reside in a
1201:52 - single frame but operants can be
1201:54 - distributed or multiple pages so it
1201:57 - depends upon the instruction
1201:58 - architecture so for this question the
1202:00 - minimum number of page uh frames that
1202:02 - must be allocated to running process in
1202:04 - a virtual memory environment is
1202:05 - determined by the answer is instruction
1202:08 - set architecture
1202:16 - okay we are given with the reference
1202:18 - string you remember what was reference
1202:20 - string reference string was the number
1202:23 - of successfully unique Pages
1202:25 - referred or the string of successfully
1202:28 - unique pages and the total number is 20
1202:32 - and unique R six this six represent that
1202:34 - the process consist of six pages is St
1202:37 - in the disk okay now what will happen
1202:41 - naturally the process will ask for six
1202:43 - frames in the memory so that it can
1202:45 - bring its all the pages from dist memory
1202:48 - process will naturally ask for six
1202:50 - frames but what happens operatic system
1202:53 - shows no mercy and gives only three
1202:55 - frames to the process process requires
1202:58 - six frames but it gives only three
1203:00 - frames to the process okay so we will
1203:03 - start with the pure demand paging
1203:05 - remember what was pure demand paging
1203:07 - that we will start with the free frames
1203:09 - that there is no page present already in
1203:12 - the
1203:12 - memory process want to refer page number
1203:15 - seven but unfortunately that was not
1203:19 - present as we were starting with free
1203:21 - memory so that will cause a page fault
1203:23 - and seven will be brought from disk to
1203:26 - memory now process want to refer page
1203:30 - zero same case will happen here again a
1203:32 - page fault and zero will be brought from
1203:35 - disk to memory then page 1 and then same
1203:39 - case with page so three page FS have
1203:41 - occurred till now now what will happen
1203:44 - all the frames allocated to the process
1203:46 - is filled with the
1203:48 - pages process want to refer page number
1203:51 - two now but that is not present page
1203:54 - fault will occur again what will happen
1203:56 - now one of these Pages have to go from
1204:00 - the main memory and let this page number
1204:02 - two enter into the main memory but the
1204:05 - question is who will become the
1204:08 - victim so we will decide the victim on
1204:10 - the fif basis the first to come will be
1204:13 - the first to go out so when two will
1204:17 - come the seven it is it is the uh turn
1204:21 - of seven to go from Main memory to
1204:24 - somewhere else it will go back to the
1204:26 - disk so seven will go two will come now
1204:30 - process want to refer page number zero
1204:32 - page number Z is already present so no
1204:34 - page fault it wanton to refer page
1204:36 - number three a page fault will occur see
1204:38 - here so who will go now after 7 0 came
1204:42 - so 0 will go three will come after three
1204:46 - process want to refer page number zero
1204:48 - again what will happen this one will go
1204:51 - zero will come now again a page fult
1204:55 - process one to refer page number four
1204:57 - not present in the memory now it is the
1204:59 - chance for this two to go four will come
1205:03 - again a page F two will come again a
1205:06 - page F three will
1205:07 - come now zero no zero page fault three
1205:12 - will come present no page fault two
1205:16 - present no page fault one wants to come
1205:18 - but it is not present page fault two
1205:21 - will go one will come now two wants
1205:24 - process want to refer page number two
1205:25 - not present page fault will
1205:28 - occer Zero already present 1 already
1205:31 - present 7even is it present no Z will go
1205:34 - 7even will come zero is it present no
1205:38 - one will go Z will come one is it
1205:39 - present no two will go one will come so
1205:42 - by this we will calculate the number of
1205:44 - page falls so number of page falls are 1
1205:47 - 2 3 4 5 6 7 8 9 10 11 12 13 14 and 15 so
1205:53 - there are total 15 page FS when we
1205:57 - alloted the process only three frames
1205:59 - out of
1206:00 - six and based on which policy FIFA
1206:03 - policy so the number of page faults were
1206:06 - 15 when we had three pages or three
1206:09 - frames it so what will be the page fult
1206:11 - rate total number of references 20 Page
1206:15 - Fs in that 20 references were 15 so the
1206:18 - page fault rate will be
1206:21 - 75% now what will happen operating
1206:24 - system shows some mercy and aot it four
1206:27 - frames instead of three four frames are
1206:30 - there now it is your homework to
1206:32 - calculate how many page fa will occur so
1206:35 - this is your homework we'll discuss in
1206:37 - the next lecture and it is so obvious
1206:40 - that rate will
1206:42 - decrease why rate will decrease because
1206:44 - we have four frames now suppose if we
1206:47 - had another frame here then 70124 page
1206:51 - for will occur now Z wants to come Z is
1206:55 - already present three wants to come but
1206:57 - not present so three will go here zero
1207:00 - already present see there in the
1207:02 - previous case it caused a page fault but
1207:05 - now it is not a page fault zero is
1207:08 - already present
1207:10 - in this way the page fault rate will
1207:12 - decrease so you have to calculate how
1207:14 - many page fault will occur if we had a
1207:16 - number of pages or number of frames
1207:17 - allotted equal to
1207:20 - 4 make sure before starting this lecture
1207:23 - you have pen and paper along with
1207:26 - you a reference string is given this was
1207:29 - the reference string and in the last
1207:32 - lecture we have seen that if the process
1207:34 - has been allocated with three frames to
1207:37 - bring six pages from this dis to memory
1207:40 - then 15 page fault will occur this page
1207:42 - fault rate was 75% now the homework was
1207:46 - to check the number of page fault if the
1207:48 - process had instead of three frames if
1207:51 - the process has four frames then how
1207:54 - many page fault will occur so the answer
1207:56 - was
1207:58 - 10 the page fault rate significantly
1208:01 - decreased from 75% to 50% 15 by 20 is 75
1208:06 - and 10 x 20 is
1208:08 - 50% let us take another question this is
1208:10 - the reference string number of
1208:13 - references are 12 and the unique pages
1208:15 - are five calculate again for the three
1208:18 - frames and four frames pause the video
1208:20 - and
1208:21 - calculate so for the three frames I got
1208:24 - nine page fs and you will be surprised
1208:27 - to know that when I increased the number
1208:30 - of frames when I show when I showed some
1208:33 - mercy on the process and I have given
1208:35 - him extra frame so that it can easily
1208:37 - bring those five
1208:39 - pages from disk to memory so that it may
1208:43 - have less page fault but what happened
1208:45 - something unexpected has happened
1208:47 - instead of decreasing instead of
1208:50 - decreasing the
1208:51 - rate the page fault rate actually
1208:54 - increased against the natural
1208:58 - characteristics when we had three frames
1209:01 - there were nine page Parts when we had
1209:03 - four frames then we had 10 page fors how
1209:06 - is this
1209:07 - possible so it in increased against the
1209:10 - natural Char characteristic this is an
1209:13 - anomaly anomaly or whatever you
1209:15 - pronounce it anomaly so we call it as
1209:18 - bad
1209:20 - anomal so what happens generally page
1209:23 - fault rate and this is the number of
1209:25 - frames if I increase the number of
1209:27 - frames then page for trate significantly
1209:29 - decreased like happened in this case but
1209:33 - what happens when the number of frames
1209:36 - required is equals to number of pages
1209:38 - then after that no matter how many
1209:40 - frames I give to the process the page
1209:42 - fault rate will be same let me explain
1209:44 - you in this case there were six pages
1209:47 - available to the process or I should say
1209:50 - the process had six pages and number of
1209:52 - frames available were three in that case
1209:55 - 15 page F has
1209:57 - occurred if I had increased the number
1209:59 - of frames 10 page F will occurred let's
1210:02 - say I have increased to six
1210:05 - frames the number of pages has equal to
1210:07 - the number of frames available
1210:10 - s page fault occurred zero page fault
1210:13 - occurred one page fault occurred two
1210:15 - page fault
1210:17 - occurred three page fault occurred and
1210:20 - later in some point four page fault
1210:23 - occurred Beyond this whatever may be the
1210:27 - reference page fault will not occur
1210:29 - because whichever page the process want
1210:31 - to refer is present in my memory so
1210:34 - after that page fault won't occur so
1210:36 - that's why no matter how many frames I
1210:38 - increased is the page for rate will
1210:40 - remain
1210:41 - same so this was the general idea which
1210:45 - we thought of but what happened here in
1210:47 - the case it increased against the
1210:50 - natural characteristics it has gone
1210:51 - somewhere like
1210:54 - this the page fult rate increased
1210:58 - instead of
1210:59 - decreasing so this is an anomaly in case
1211:02 - a if I took six frames then six page
1211:04 - fault initially initial once due to the
1211:06 - pure demand paging and then the page
1211:08 - fault will remain same the above anomo
1211:11 - was discovered by badi badi ano says as
1211:14 - per the number of frames allocated to
1211:16 - the process increases as the number of
1211:18 - frames allocated the to the process
1211:20 - increases if I increase the frame number
1211:23 - then page fault also increase sometimes
1211:27 - and it only happens in the case of fif
1211:30 - or fif based
1211:32 - algorithms and the reason for this is
1211:34 - stack property of replacement you don't
1211:37 - have to go deep into this just remember
1211:39 - the reason the reason is stack property
1211:41 - of
1211:42 - replacement so let us revise what
1211:45 - happened in the in the in the last
1211:49 - lecture we have discussed a problem in
1211:51 - which we had three frames available then
1211:52 - 15 page pter cut then if we have four
1211:55 - frames available then page for rate
1211:56 - should obviously decrease this was the
1211:59 - idea and if I have allocated that many
1212:03 - frames which the which equals to the
1212:06 - number of pages the process has then
1212:09 - after that no page fault will
1212:12 - occur the number of page fault was six
1212:15 - or number of page fault was K here
1212:17 - because of pure demand paging if we talk
1212:20 - about the pre patch demand paging then
1212:22 - in that case if I had allotted frames
1212:26 - equal to the pages then the page fault
1212:28 - will be zero but default one is pure
1212:31 - demand paging so we were taking that
1212:32 - taking into account that to load the
1212:35 - pages like 7 0 1 2 3 4
1212:39 - this will cause a page fault every time
1212:41 - because initially we started with zero
1212:43 - initially we started with nothing it was
1212:46 - a free memory so when process referred
1212:49 - the seven it caused a page fault when
1212:51 - process referred zero it caused a page
1212:52 - fault so in that
1212:54 - manner six page fault will occur and
1212:57 - after that no matter how many frames I I
1212:59 - allot to the process page fault will
1213:01 - remain same due to Pure demand paging so
1213:03 - this was the idea but what happened in
1213:05 - this
1213:05 - example when I increased the frame
1213:08 - number
1213:10 - the page fault actually increased
1213:12 - against the natural characteristics so
1213:14 - this was bad anomal and it happens in
1213:16 - the fifo and fifo based algorithms or
1213:19 - fifo based allocation policies and the
1213:21 - reason behind this is stack property of
1213:25 - replacement optimal page replacement
1213:27 - will generate the minimum page Forge in
1213:30 - fif we Cho we have chosen that page
1213:32 - which was first to come in the memory as
1213:34 - a victim in this optimal page
1213:37 - replacement we will choose that page
1213:40 - which has not been used or which will
1213:42 - not be used for the longest duration of
1213:43 - time in
1213:46 - future let us take this case 701 CM
1213:49 - reference string page fault page fault
1213:52 - page fault why due to Pure demand paging
1213:56 - now page fault will occur out of this
1214:00 - 701 which will be the page to be
1214:03 - selected as victim
1214:05 - see that which page has not been used
1214:08 - for the longest duration of time in
1214:10 - future zero just used 1 used
1214:14 - 7 7 will be selected because 7 is the
1214:18 - page which will be used after so much
1214:21 - time so we will remove seven so compare
1214:25 - which will which page will be used after
1214:28 - the longest time that page you will
1214:29 - choose as a victim and remove that page
1214:32 - so 7 will be removed 7 will be gone two
1214:34 - will come now out of 207 we have these
1214:38 - pages in the memory 207 is present zero
1214:40 - no page fult
1214:43 - three 0 just used two just used one will
1214:46 - be used after the longest duration of
1214:49 - time so out of 2011 one will be removed
1214:53 - now three will be brought to the memory
1214:55 - we had 203 now zero no page fault now
1214:58 - process wish to refer page four not
1215:00 - present page fault will occur two just
1215:03 - used three just
1215:05 - used and zero will be used after the
1215:08 - longest this time so 0o will be gone and
1215:11 - four will come here after that we have 2
1215:15 - 43 in the memory 2 no page fault three
1215:18 - no page fault zero page fault will occur
1215:20 - because we have 2 43 no zero so which
1215:23 - will be removed three just used two just
1215:25 - used four is not used ever so four will
1215:29 - be removed now we have
1215:31 - 203 so here we have 203 three no page
1215:34 - fault two no page fault one who will be
1215:37 - removed now the one which has not been
1215:40 - used for the longest duration of time so
1215:41 - after 203 two used 0 used three has not
1215:45 - been used ever so three will be removed
1215:47 - one will come two present in the memory
1215:50 - zero present in the memory one present
1215:51 - in the memory seven page fault will
1215:53 - occur who will go 0 just used one just
1215:55 - used two has not been used for the
1215:58 - longest time in the future hey I have
1216:00 - noticed that I speaking the grammar
1216:03 - wrong it should be two instead of two
1216:05 - has not been used I should say two will
1216:08 - not be used
1216:09 - okay so two will not be used ever in the
1216:11 - future so 701 will be the final Pages
1216:16 - which will remain in our memory so how
1216:18 - many page fault has occurred 1 2 3 4 5 6
1216:22 - 7 8 9 so nine page fault will
1216:26 - occur and now four frames how we will
1216:29 - calculate for four frames we are we are
1216:31 - using pure demand paging 1 2 3 4 these
1216:34 - page fault will occur due to Pure demand
1216:35 - paging now we have 7012 in our memory
1216:40 - now out of this 7012 you know that 7 has
1216:42 - been used directly here so 7 will be
1216:44 - removed when this page fault will occur
1216:47 - so at place of seven three will come
1216:50 - after three zero already present four
1216:52 - page fault will occur who will go now
1216:55 - two used three used one is used at the
1216:58 - after the so much time so one will be
1217:00 - removed four will come now we have 3 0
1217:03 - 42 two present 3 present 0 present 3
1217:07 - present 2 present 1 is not present so
1217:09 - who will be gone four has not been used
1217:12 - ever four or I should again correct it
1217:14 - four will not be used ever so four will
1217:17 - be
1217:19 - gone but are you noticing that three has
1217:22 - also not been used so out of three and
1217:25 - four which should be
1217:27 - gone we will at the tie breaker we
1217:30 - always use F4 so the one who came first
1217:34 - will be gone first three will be gone
1217:36 - now are you noticing the difference
1217:39 - if we have two pages which won't be used
1217:42 - later see we had three and four this
1217:44 - zero will be used and two will be used
1217:47 - but this three and four will not be used
1217:50 - later so out of them which we have to
1217:52 - select as a victim the one who came
1217:54 - first so three will be selected one will
1217:56 - come
1217:57 - now okay so now I have
1217:59 - 1042 two present zero present one
1218:03 - present now seven wants to come who will
1218:06 - go we have
1218:09 - four and two not used ever 1 and zero
1218:12 - will be used so after four and two which
1218:14 - came first two was already present so
1218:17 - two will be gone see two has came here
1218:21 - and has not been gone till now so two
1218:23 - will go now so now seven will come now
1218:26 - calculate the number of page for 1 2 3 4
1218:29 - 5 6 7 and 8 page for really decreased
1218:33 - from 9 to 8 when we increased one frame
1218:36 - now check for this
1218:39 - we had bad's anomaly in this question
1218:43 - when we had three frames we got N9 page
1218:45 - fault when we had four frames then we
1218:46 - got 10 page fault which was against the
1218:49 - natural characteristic so here we
1218:51 - followed victim policy as fif now we
1218:54 - have to follow optimal replacement and
1218:56 - check does it suffer from the bades and
1218:58 - this is your homework or you can do it
1219:01 - now by pausing the video so for three
1219:04 - frames we got seven as the answer and
1219:06 - for four frames we got six as the answer
1219:08 - so I can say when we increase the frame
1219:11 - the page fault rise decreases so it is
1219:13 - not against the natural characteristic
1219:16 - so it does it does not suffer from bades
1219:19 - anomo and I have already told you that
1219:22 - fif and fifo based only those suffer
1219:25 - from bades
1219:27 - anomo but if you have observed there is
1219:30 - a serious problem in the implementation
1219:32 - of optimal
1219:34 - replacement what will the serious
1219:36 - problem it is similar to the sgf
1219:39 - remember the fgf CPU scheduling
1219:41 - algorithm in which the first time was
1219:44 - already
1219:46 - given but can you guess the bur time of
1219:48 - the upcoming processes no in the similar
1219:51 - way can you guess which pages will
1219:54 - process want in the future no you cannot
1219:58 - guess you cannot guess which Pages the
1220:00 - process will want in the future it is
1220:02 - purely dependent on the situations so
1220:05 - how will you look into the future which
1220:07 - pages are you going to refer like hgf it
1220:10 - is non implementable then why do we
1220:13 - study this we use this algorithm as a
1220:16 - benchmark that by this are this is the
1220:20 - least number of page faults possible and
1220:23 - your algorithm let's say let's say in
1220:25 - this case in this case the page faults
1220:27 - were eight okay so I can say these are
1220:30 - the least number of possible page faults
1220:32 - and my algorithm is producing let's say
1220:34 - 10 page FS so I can say yeah it is
1220:36 - closed but there is a scope of
1220:38 - improvement so it is it is used as a
1220:42 - benchmark okay in the next lecture we
1220:45 - will see an another policy that is least
1220:48 - recently used it is just the 180 shift
1220:52 - of the
1220:53 - optimal policy in optimal policy what we
1220:57 - did okay I think I should I should teach
1220:59 - this in the same lecture so in optimal
1221:01 - page replacement what we
1221:04 - did we thought that whichever page page
1221:08 - has not been used or whichever page will
1221:11 - not be used for the longest duration of
1221:12 - time in future that page will be removed
1221:15 - or that page will be chosen as victim we
1221:17 - have 180 shift the algorithm replace
1221:20 - that page which has not been used for
1221:23 - the longest duration of time in the past
1221:26 - so here has will come and there will
1221:27 - will
1221:29 - come there we were choosing the page
1221:32 - which will not been
1221:34 - for the page which will not been used
1221:37 - for the longest duration of time in
1221:39 - future here we are choosing the page
1221:41 - which has not been used for the longest
1221:43 - duration of time in the past so here
1221:46 - past is there and their future was there
1221:49 - so reference string is given 7012 03 the
1221:53 - same reference string page fault page
1221:55 - fault page fault due to Pure demand
1221:58 - paging now at this point which will go
1222:02 - the
1222:03 - one who has not been used for the
1222:06 - longest duration of time in the past see
1222:08 - one was recently used zero was recently
1222:10 - used seven was the least recently
1222:12 - [Music]
1222:14 - used that is the name of the algorithm
1222:17 - so 7 will go 2 1 will come now zero page
1222:21 - fault will occur which was the mo least
1222:24 - recently used one was the least recently
1222:26 - used so 20 3 one was gone now zero page
1222:30 - fault occurred least recently used after
1222:32 - 203 two was the least recently used two
1222:34 - will gone four will come 43 so in this
1222:37 - manner you have to proceed so you will
1222:39 - see the number of page
1222:40 - SPS then you have three frames is 12 and
1222:44 - you increase the number of pages or
1222:45 - number of frames then you will get a
1222:48 - pretty less page fault number so from 12
1222:51 - I reach to eight so this also does not
1222:53 - suffer from Bad
1222:55 - animal okay now let's see the most
1222:58 - recently used replace that page which
1223:02 - has just been
1223:03 - used replace that page which has just
1223:06 - been used if you are getting confused do
1223:08 - not in fif we replace that page which
1223:11 - came the first the first to come will be
1223:13 - the first to go out in optimal we
1223:16 - replace that page which will not be used
1223:18 - for the longest duration of time in the
1223:20 - future in the least recently used we
1223:23 - replace that
1223:24 - page which was least recently used or
1223:28 - which has not been used for the longest
1223:30 - duration of time in the
1223:32 - past and then most recently used replace
1223:35 - that page which has just been used so 7
1223:38 - 01 page for due to Pure demand paging
1223:40 - now two wants to come who will be gone
1223:43 - one will be chosen as Victim Because one
1223:45 - was recently used so in this manner you
1223:47 - have to proceed so in this page fors are
1223:51 - really high There are 16 page
1224:00 - fors now comes the counting algorithm
1224:03 - the criteria is a little bit different
1224:05 - here the criteria is count of
1224:09 - reference number of times a page is
1224:11 - referred that is the count of reference
1224:14 - and one special thing is when swep out
1224:17 - and then swep in set count equals to one
1224:20 - when swep out and then swep in set count
1224:22 - equals to
1224:23 - one and which page will be selected as
1224:27 - victim the one which has the least count
1224:29 - and here in the most frequently used the
1224:31 - one which has the highest count will be
1224:32 - selected as
1224:34 - victim okay let's see this this is the
1224:37 - reference string 71203 and so on page
1224:41 - fault occur page fault occur page fault
1224:43 - occurs due to Pure demand paging so now
1224:46 - the 701 has a count of 1 1 1 the 7th
1224:51 - page the zeroth page and the first page
1224:53 - has been counted or has been referred
1224:56 - one
1224:57 - time now two wants to come so page fault
1225:01 - will occur again which of them will be
1225:04 - gone or which which of them will be
1225:05 - selected as victim the one which has the
1225:08 - least count but here all of them is the
1225:09 - same count so we'll use fif the one who
1225:12 - came first will be the first to go so
1225:15 - seven will be replaced by two now two
1225:18 - will come and it has been referred one
1225:21 - time now zero Zer will be zero is being
1225:24 - referred second time so 1 + 1 now three
1225:28 - three wants to come who will be replaced
1225:30 - or who will be selected as victim one
1225:32 - will be selected as Victim Because two
1225:34 - and one both has same count but two just
1225:37 - came and one was already there so one
1225:39 - will be the first to go so this will be
1225:42 - selected and three will come at its
1225:44 - place zero count will increase now zero
1225:47 - has been referred three
1225:49 - times four wants to come who will be
1225:51 - gone out of two and three three just
1225:54 - came and two was already there so two
1225:55 - will be gone four will
1225:57 - come again page fa who will be gone now
1226:00 - four and three both have same count so
1226:02 - three will be gone because four just
1226:04 - came so three will be gone two will be
1226:06 - there now three wants to come now who
1226:08 - will be gone two just came so four will
1226:10 - be gone three here with count one now
1226:14 - zero zero has been referred again so the
1226:18 - count will increase to four now three
1226:20 - count will be increased to two so three
1226:23 - as a count two 0 is Count four and two
1226:27 - has been referred again so two will be
1226:29 - the count of two will be
1226:31 - two now one wants to come out of three
1226:34 - and two will be gone two was already
1226:36 - there three just came so two will be be
1226:38 - gone so two will come go and one will
1226:41 - come here now two wants to come again so
1226:45 - who will be gone out of 2 4 and one the
1226:47 - one which is the least count so one will
1226:48 - be gone two will
1226:51 - come now zero increase the reference
1226:55 - count now one one wants to come so who
1226:59 - will be replaced out of two five and one
1227:01 - the wi one which is the lowest count so
1227:03 - one this two will be replaced one will
1227:05 - come seven wants to come now now who
1227:08 - will be replaced the one will be
1227:09 - replaced seven now zero wants to come Z
1227:12 - is already there increase the count to
1227:14 - six now one wants to come who will be
1227:16 - replaced seven only because it has a
1227:19 - least count so one will come so page for
1227:22 - occurred in total least frequently used
1227:25 - are 13 now you have to do the same the
1227:28 - change is the one which has the highest
1227:30 - count you have to replace that and if
1227:33 - both the if both the pages have same
1227:35 - count then use free4 the one who came
1227:38 - first will be the first to go out okay
1227:41 - so this is your homework and calculate
1227:43 - the number of page for let's say it is
1227:44 - 15 just for the
1227:46 - sake most of the time it is found that
1227:49 - lru is closer to Optimal in terms of
1227:52 - performance so many operating system
1227:54 - either implement lru or variations of
1227:58 - lru and lru is implemented through stack
1228:01 - how it is implemented say we have 701 in
1228:03 - our frames so 7 will be pushed to the
1228:07 - stack 0 will be pushed and one will be P
1228:09 - one will be at top zero at the in the
1228:11 - bottom or zero in the middle and seven
1228:13 - in the bottom now this one is the most
1228:16 - recently used and seven is the least
1228:18 - recently used now what will happen pop
1228:20 - one pop zero and when you pop 7even the
1228:24 - seventh will be gone because we are
1228:26 - removing the least recently used now
1228:28 - push them back into this tag zero will
1228:30 - be pushed one will be pushed now two
1228:32 - wants to come at the place of seven so
1228:35 - two will come here now who is the most
1228:37 - recently used two is most recently used
1228:40 - and Z is the least recently used so
1228:42 - nothing happened just two came
1228:44 - here okay now comes the laru
1228:48 - approximations these algorithm are not
1228:50 - really lru but they are approximate they
1228:53 - approximate to the behavior of
1228:55 - lru so here comes a new term that is
1228:57 - reference bit the reference bit shows
1229:00 - each page in the page table will be
1229:01 - associated with a reference bit which
1229:04 - which shows that has the page been
1229:07 - referred so far
1229:08 - if zero then it is not referred and it
1229:11 - if it is one then it is referred at
1229:13 - least once okay so each page in the page
1229:16 - table will be associated with a
1229:18 - reference bit if zero not referred so
1229:20 - far if one referred at least once so
1229:24 - page table entry contains many attribute
1229:26 - like frame number valid or invalid time
1229:28 - of loading time of reference count of
1229:30 - reference and reference bit these are
1229:32 - the attributes of the page okay now
1229:35 - comes an important part what is epoch
1229:39 - if you have uh learned about deep
1229:40 - learning that Epoch is a cycle or Epoch
1229:44 - is a duration of time it is time Quantum
1229:48 - it is time Quantum so this is this is
1229:52 - the time scale and the epoch is the just
1229:55 - the duration of time say this is one
1229:57 - Epoch this is another Epoch this is
1229:59 - another Epoch and let's say this is the
1230:01 - time in present so we will look into the
1230:06 - pages that if this page has been
1230:08 - referred in Epoch 3 or not if it is
1230:12 - referred then we will set reference bit
1230:14 - as one and if it is not referred than
1230:16 - zero so we the reference bit is counted
1230:20 - based on the epoch Epoch means that the
1230:23 - current duration of
1230:25 - time okay so the page table entry is
1230:29 - associated with these many attributes
1230:30 - like frame number valid or invalid time
1230:33 - of loading time of reference count of
1230:35 - reference and reference bit reference
1230:37 - bit can be 0 or one zero suggest that
1230:40 - page is not referred so far during the
1230:42 - present Epoch and one says that at least
1230:45 - once in the current Epoch so reference
1230:47 - bit this reference bit we talk about in
1230:50 - the current Epoch in the current
1230:52 - duration of
1230:54 - time so let's say these were the process
1230:58 - or entries of the page table frame valid
1231:01 - invalid time of loading and reference so
1231:04 - this shows that page number zero has
1231:07 - been referred
1231:08 - at least once in the current e page
1231:11 - number three is not present in the
1231:13 - memory page number
1231:15 - five has not been referred in the
1231:19 - current Ok Okay so this is what
1231:22 - reference bit is so now we have five
1231:25 - pages 0 1 2 3 4 and 5 or it is six pages
1231:29 - sorry 0 1 2 3 six pages so out of these
1231:33 - six
1231:35 - pages the time of loading shows shows
1231:38 - that which page was loaded first in the
1231:40 - memory so the page number two was loaded
1231:43 - first in the memory and page number four
1231:45 - was loaded last in the memory these are
1231:46 - six is just a Sil mistake three okay so
1231:51 - p 0 P2 and P4 has been referred in the
1231:54 - current Epoch
1231:56 - P0 P2 and P4 this is what reference bit
1232:01 - is now if you remember the definition of
1232:03 - lru what lru said select that page as
1232:07 - the victim which has not been referred
1232:09 - to the longest duration in the
1232:11 - past which has not been referred to the
1232:13 - longest duration in the past and this is
1232:16 - what laru approximation we are studying
1232:18 - so reference Bit Zero matches with the
1232:21 - statement or reference bit one matches
1232:22 - with the statement what does reference
1232:24 - Bit Zero says page is not referred so
1232:27 - far it somehow matches with the
1232:29 - statement that page has not been refer
1232:31 - to the longest duration of time in the
1232:33 - past so R equals to zero so how are we
1232:36 - going to select the victim page scan
1232:38 - scan the page table right from the first
1232:40 - entry and as soon as you got R equals to
1232:42 - Z victimize that page so here which page
1232:45 - will be
1232:46 - victimized scan from the first entry
1232:49 - reference bit not zero reference Bit
1232:51 - Zero so page number one will be the page
1232:53 - to become the
1232:54 - victim okay now comes the question
1232:57 - if all of the pages has been referred at
1233:00 - least once say there is no reference bit
1233:04 - which is zero all reference bit are one
1233:06 - then what will happen then this
1233:08 - reference bit algorithm
1233:10 - fails okay now when one e box get
1233:13 - completed set R equals to zero I have
1233:16 - already told you that we talk about
1233:17 - reference bit during the current Epoch
1233:20 - during the current
1233:22 - Epoch let's let's take this as an
1233:24 - example
1233:26 - suppose some parameter K tells that how
1233:29 - many times your name was spoken by other
1233:32 - people in the year let's say
1233:36 - 2036 okay okay K tells that now what
1233:39 - happens 2036 just got completed and 2037
1233:43 - has started this is the year now what
1233:46 - will be the value of K zero because 2037
1233:50 - has just
1233:51 - started okay so this is what reference
1233:54 - bit is so as soon as the current eox get
1233:56 - completed set R equals to Z because when
1233:59 - the current eox has just completed none
1234:02 - of the page will be referred when the
1234:05 - time will pass then the reference start
1234:08 - so as soon as the current epox get
1234:10 - completed set R equals to Z so what was
1234:13 - the loophole here if every page has been
1234:16 - referred at least once then reference
1234:18 - bit algorithm fails now how are we going
1234:20 - to select the victim the second is
1234:23 - additional reference bit each page is
1234:26 - associated with more than one reference
1234:28 - bit let's say eight and this is a static
1234:31 - you cannot change it this is static this
1234:33 - is not Dynamic let's say if we are we
1234:36 - have selected that eight reference bit
1234:38 - or eight previous history will be saved
1234:41 - then it will be eight only it won't
1234:43 - change when the time will pass suppose
1234:45 - another epox get completed so you won't
1234:47 - add here nine what will happen this will
1234:50 - be lost
1234:53 - and R8 will become zero why zero because
1234:58 - if the current eox get completed set R
1235:00 - equals to
1235:01 - Z let me start again what happened we
1235:06 - introduced a new term reference bet
1235:07 - reference bit tells that if the page has
1235:11 - been referred till now in the current
1235:12 - oke then set it as one if it is not then
1235:15 - set it as zero now we are approximating
1235:18 - the lru what lru said select that page
1235:21 - as the victim which has been referred
1235:23 - which has not been referred to the
1235:24 - longest duration in the past and Ral to0
1235:27 - matches with the statement now what we
1235:29 - did in the reference bit we scann the
1235:31 - page table from the first entry and as
1235:32 - soon as we get R equals to Z we
1235:34 - victimize that page but what happens
1235:36 - when there is no such page there is no
1235:39 - such page which has not been referred
1235:41 - till now all of the page has been
1235:44 - referred what will happen then reference
1235:46 - bit algorithm fails then comes the
1235:48 - additional reference reference bit what
1235:50 - we do here we keeps the previous history
1235:53 - so we will check here all once no
1235:56 - problem get back or go in the previous
1235:59 - in the previous Pi PG and PK all of them
1236:01 - were referred don't worry go back in the
1236:05 - previous to previous ook Pi was was
1236:07 - referred PK was referred but PJ was not
1236:09 - referred so when a new page let's say PL
1236:11 - will come when page fault will occur so
1236:14 - who will get victimized PJ will get
1236:17 - victimized you getting the point so what
1236:20 - we are doing we are maintaining the
1236:21 - previous
1236:24 - history in R8 all of them were referred
1236:27 - so we cannot select which page to choose
1236:30 - as a victim in R7 again the same thing
1236:32 - but in R six PJ was not referred so
1236:35 - we'll select PJ as the victim okay okay
1236:38 - but what happens in the rare case when
1236:39 - all of them here is also one all of them
1236:41 - are one what will happen then in that
1236:44 - case this algorithm will also F and when
1236:47 - the current current EO gets completed do
1236:50 - the left Shi left shift operation and
1236:53 - select R8 equals to Z and R1 will be
1236:55 - lost so left shift will occur this will
1236:58 - be lost and select R8 as zero why zero
1237:01 - because when epox get completed set R
1237:03 - equals to
1237:04 - Z now comes an interesting algorithm
1237:07 - that is second chance or clock algorithm
1237:10 - the criteria is time of loading plus
1237:11 - reference
1237:13 - bit see we are giving second chance to
1237:16 - the pages let me explain so in this how
1237:21 - are we going to select the victim based
1237:23 - on the time of loading and reference bit
1237:25 - so we will go with the time of loading
1237:27 - which page was loaded first two was
1237:29 - loaded first go there it was the time of
1237:33 - loading was zero so two was loaded first
1237:34 - now check the reference BD is it is it Z
1237:38 - no it is not zero it is one change it to
1237:40 - zero and then move to the next which was
1237:44 - loaded next four was loaded next does it
1237:47 - uh have a reference Bit Zero select that
1237:49 - as victim what are we doing the page
1237:52 - with which get loaded first see its r
1237:54 - value if it is zero victimize it
1237:57 - victimize it if it is not if it is one
1237:59 - then set it to zero so P4 here will be
1238:02 - victimized now if if you can observe
1238:06 - that if all of the reference bit R1 then
1238:08 - also this algorithm will not fail why we
1238:11 - are because we are given second chance
1238:13 - to the pages see here let's say all of
1238:16 - them were one now what happened time of
1238:19 - loading two was the first to get loaded
1238:22 - so we will change it to zero now four
1238:25 - came so we will change it to zero now
1238:28 - who came this page number zero it has
1238:31 - reference bit of one change it to zero
1238:33 - move ahead three page number one came it
1238:36 - has a reference bit of one change it to
1238:37 - zero now page number five came it has a
1238:40 - reference bit of one change it to zero
1238:41 - so what we have done we have gone for
1238:43 - the full
1238:45 - cycle when all of the reference bit were
1238:48 - one we have gone to the full cycle how
1238:51 - based on the time of loading now we will
1238:53 - after one cycle go again in the same
1238:55 - order now who was loaded what was the
1238:59 - order the P2 was loaded first now it is
1239:01 - a reference bit of zero victimize it are
1239:03 - you getting the point see in reference
1239:07 - bit if all of the bits were one the
1239:09 - algorithm fails so what we did we
1239:11 - maintained the previous history okay I
1239:14 - believe that in the previous or in the
1239:16 - current Epoch all of the pages were
1239:18 - referred let's talk about the previous
1239:20 - Epoch where all of the pages were
1239:21 - referred yes all of the pages were
1239:22 - referred and previous to previous Epoch
1239:25 - PJ was not referred okay victimize that
1239:28 - now there is a rare case also here that
1239:31 - all of the pages were referred even in
1239:33 - the previous EPO also so what we will do
1239:37 - we are giving a second chance to the
1239:39 - pages we will go in the order of time of
1239:42 - loading and see the reference bit if the
1239:44 - reference bit is zero victimize that if
1239:46 - it is one then change it to zero in
1239:49 - order that when I will come again at
1239:51 - this point then the reference bit would
1239:54 - have been zero and I will select that
1239:56 - page to become victim that's why second
1239:58 - chance and the first chance we change
1240:00 - that to zero and in the second chance
1240:02 - this will be
1240:04 - victimized so this has actually solved
1240:06 - the problem when all of the pages were
1240:08 - referred in the previous epox
1240:10 - also okay so the page which get loaded
1240:12 - first see its r value if it is zero
1240:15 - victimize it if r value is 1 set it to
1240:17 - zero so here P4 will be victimized and
1240:20 - in this case P2 will be
1240:23 - victimized okay so when all of the pages
1240:25 - are Valu is one then fif page select fif
1240:27 - page get selected that's what we have
1240:29 - done here when all of them were one P2
1240:33 - was selected which came the earliest and
1240:36 - as soon as you hear the the name of fif
1240:38 - bades Ando should come to your mind so
1240:41 - when in Second Chance algorithm when all
1240:44 - of the reference bitar one then it is a
1240:46 - possibility that bades Animo may occur
1240:50 - we have seen the reference bit algorithm
1240:52 - we have seen the additional reference
1240:53 - bit we have seen the second chance
1240:55 - algorithm in Second Chance fif follow
1240:58 - fif order will be followed when all our
1241:01 - values are one and it will suffer from
1241:02 - Bad Anor now comes the enhanced second
1241:05 - chance it is like not recently used so
1241:09 - what does it say we will maintain
1241:12 - RM what is RM R suggest referenced and M
1241:16 - suggest modified or dirty bit so
1241:18 - criteria is RM R is reference and M is
1241:21 - or modified bit Dirty Bit so 0 0 0 1 1 0
1241:26 - and 1 1 this is the priority order 0 0
1241:30 - says page not referred and it is clean
1241:33 - also 01 says page not referred but it
1241:36 - has been modified one says page has been
1241:39 - referred but it is clean 1 one says page
1241:41 - has been referred and it is modified
1241:43 - also so which page we will select as
1241:46 - victim in this order we will select them
1241:49 - victim if 0 is available that will be at
1241:51 - the first priority to become victim so
1241:53 - priority is 1 2 3 4 this will be at the
1241:56 - least priority and this will be at the
1241:58 - highest priority okay now let's solve
1242:01 - some problem this is the page table
1242:03 - structure we got entries frame number
1242:06 - valid invalid time of loading reference
1242:08 - and modified bit now according to fif
1242:12 - which page will be selected as victim P3
1242:15 - will be selected as Victim Because it
1242:16 - came first according to reference bit
1242:18 - which page will be selected as victim
1242:20 - scan from the first entry as soon as you
1242:23 - get Ral to0 victimize that so P1 will be
1242:25 - victimized according to Second Chance
1242:27 - who will be
1242:28 - victimized go with the time of loading
1242:31 - Zer change it to zero so I will change
1242:33 - it to
1242:34 - zero now who came P1 p so P5 came and it
1242:39 - has a reference bit of
1242:40 - zero so P5 will be victimized according
1242:43 - to enhanced Second Chance choose which
1242:46 - is a RM of 00 so one will be victimized
1242:50 - P1 will be the answer okay consider a
1242:53 - system with v = to P = to 2^ 16 bytes P
1242:57 - size is 512 bytes the size of P table
1243:00 - entry is 4 bytes if the page table entry
1243:03 - contains beside other
1243:05 - information one valid invalid bit one
1243:07 - reference bit one modified bit and three
1243:09 - bits for page protection how many bits
1243:12 - can be assigned for storing other
1243:13 - attributes of the page also compute the
1243:15 - page table size and bytes so we have V =
1243:19 - to P = to 2^ 16 and Page size is 2 power
1243:23 - 9 bytes so we'll get the number of
1243:25 - entries it is 2^ 7 so how many how many
1243:29 - bits for storing the frame number as we
1243:32 - have seven entries so seven bits for
1243:33 - frame number and the remaining
1243:37 - 19 bits for rest of the other attributes
1243:40 - where were six bits were stored or where
1243:42 - were six bits six these six bits are
1243:44 - used here three bits for page Protection
1243:47 - One for modified one for reference and
1243:50 - one for valid invalid so six were used
1243:52 - here seven were used for frame number
1243:55 - remaining 19 bits will be for the rest
1243:57 - other attributes and what will be the
1243:59 - page table size the size of each entry
1244:01 - into number of entries we got 512 bytes
1244:05 - of page table
1244:07 - consider a virtual memory system with Fe
1244:09 - for replacement policy for an arbitrary
1244:11 - page access system increasing the number
1244:14 - of page frames in the main memory will
1244:16 - sometimes increase the page number or
1244:19 - sometimes sometimes increase the number
1244:20 - of page fault because this is what bad's
1244:22 - ano is what does it say The General
1244:26 - characteristic is if you increase the
1244:27 - frame number then page board generally
1244:29 - decrease but sometimes in the fifo based
1244:33 - page replacement what happens when you
1244:35 - increase the frame number the p page
1244:37 - fault rate also
1244:39 - increases a memory page containing a
1244:41 - heavily used variable that was
1244:43 - initialized very early and it is in
1244:45 - constant use is removed when fif page
1244:49 - replacement is used because here it is
1244:51 - written initialized very early so it is
1244:53 - brought first and if it is brought first
1244:56 - see here here is in the constant use so
1244:58 - lru won't be there Leo won't be there so
1245:01 - fif will be the present fif will be the
1245:03 - uh page replacement algorithm that is
1245:06 - being used here because it is written
1245:08 - initialized very
1245:10 - early recalls that bad's anomo is that
1245:14 - the page for rate may increase as the
1245:16 - number of allocated frames increases now
1245:18 - consider the following statement okay
1245:20 - random page replacement algorithm
1245:22 - suffers from Val
1245:23 - ano where a page chosen at random is
1245:26 - replaced the second says lru page
1245:29 - replacement algorithm suffers from bad
1245:32 - so this is false lru is never lru is
1245:35 - laru never suffers from bad
1245:37 - an the first statement is random page
1245:40 - replacement algorithm suffers from bad's
1245:42 - anomal well this can be true this can be
1245:47 - true because let's say by coincidence it
1245:50 - worked as fif and in fif bad Ando is
1245:53 - present so the answer is S1 may be true
1245:56 - and S2 is false S1 may be true and S2 is
1246:00 - false S1 is true when by coincident that
1246:03 - random page replacement algorithm worked
1246:05 - as
1246:09 - fif consider a process having reference
1246:12 - string l in which n unique Pages occur Z
1246:15 - frames are allocated to the process
1246:17 - calculate the lower bound and upper
1246:18 - bound of number of page fors so if
1246:21 - maximum uh we have a reference string of
1246:25 - L so what will be the maximum number of
1246:28 - page f l how because every reference
1246:31 - will cause a page fault in that case in
1246:34 - that case the maximum which will be l
1246:37 - number of page fault can occur and how
1246:39 - can every every reference cause the page
1246:42 - fault when we have allocated just one
1246:44 - frame to the memory suppose three page
1246:46 - brought to the memory CS page for now
1246:49 - four wants to come so four will be the
1246:54 - four will again cause a page for now
1246:56 - let's say five wants to come five will
1246:58 - again cause a page F so if we have just
1247:01 - one frame then every reference will
1247:03 - cause a page
1247:04 - fault that's why the maximum number of
1247:07 - page fault can occur will be the number
1247:08 - of reference and minimum number of page
1247:11 - fault is n when we are using pure demand
1247:14 - paging then in this will happen in the
1247:17 - case when we have allocated that number
1247:19 - of frames which uh which equals to the
1247:22 - number of pages in that case we have n
1247:25 - number of page fault and that only the
1247:27 - case of pure demand paging suppose the
1247:29 - process has six pages and if I have
1247:31 - allocated six frames then for the first
1247:33 - time when the first time the pages are
1247:35 - loaded then only six p page Port will
1247:37 - occur and after that no page P will
1247:39 - occur because we have every page
1247:41 - required in the memory
1247:45 - itself and in case of prefetch demand
1247:49 - paging what will happen in case of
1247:51 - prefetch it means all of the pages are
1247:53 - already present in the memory so in that
1247:55 - case no page F will occur so the minimum
1247:59 - is either n or zero and the maximum is l
1248:02 - l happens in the case when only one
1248:05 - frame is allocated and minimum happens
1248:07 - in the case when the number of frames
1248:09 - allocated equals to the number of page
1248:10 - of the
1248:13 - process in the next lecture we will
1248:15 - learn about
1248:16 - threshing
1248:18 - threshing just like deadlock it is
1248:20 - undesirable feature of operating system
1248:23 - what is threshing excessive or high
1248:26 - paging activity which means High page
1248:27 - fault rate and you know that when page
1248:31 - fault occurs the loading and saving
1248:33 - pages on the dis this kind of activities
1248:35 - happens and these is consume time so the
1248:38 - most of the time process will be
1248:39 - spending time on their page F service
1248:42 - and hence will get blocked you know that
1248:45 - reading a page from the disk is an iio
1248:47 - operation and iio operation in the when
1248:50 - the pro when the I operation is being
1248:52 - performed the process remains blocked we
1248:54 - have learned that in our transition
1248:56 - diagram now what
1248:59 - happens we have learned that in uni
1249:01 - programming operating system the
1249:02 - percentage CP utilization is less so
1249:05 - what we do in order to increase C
1249:08 - percentage CP CP utilization we think
1249:10 - that we should increase the degree of
1249:12 - multiprogramming what is
1249:13 - multiprogramming increases the number of
1249:15 - processes in the memory so we increase
1249:18 - the number of multiprogramming supposing
1249:21 - that if some process has went for the io
1249:24 - then some other process will be there on
1249:27 - which CPU can work upon and hence
1249:29 - increase the percentage utilization so
1249:32 - thinking that we increase the degree of
1249:34 - multiprogramming but at some point it
1249:36 - reach to the saturation and after that
1249:39 - the degree of multiprogramming kept on
1249:40 - decreasing and
1249:42 - decreasing this is the curve and the
1249:45 - last part of the curve is threshing see
1249:47 - this is
1249:49 - logical if you have a limited memory and
1249:53 - you want to you want to accommodate
1249:56 - maximum number of processes we are
1249:58 - increasing the degree of
1249:59 - multiprogramming that's what it means so
1250:01 - we want to increase the number of
1250:02 - processes to a high
1250:04 - number but what happened
1250:07 - when there are so many processes in The
1250:09 - Limited memory then each process will
1250:12 - get less memory each process will get
1250:15 - less number of frames so if number of
1250:17 - frames are less then page fault rate
1250:20 - will increase sign significantly if page
1250:23 - fault rate will increase significantly
1250:26 - then process will be spending most of
1250:28 - their time in the blocked State because
1250:31 - page for service during the page for
1250:32 - service process remains blocked so the
1250:35 - most of the time process will be blocked
1250:38 - and hence the percentage CP utilization
1250:40 - will
1250:41 - decrease this process is blocked
1250:43 - performing the page for service time or
1250:45 - during the page for service time this
1250:47 - process is also blogged blogged blogged
1250:49 - because each process gets so much little
1250:52 - frame to accommodate its pages and if
1250:55 - number of frames are less then page
1250:57 - fault will obviously occur more and the
1251:00 - process will spend most of their time in
1251:02 - just solving the page fault or serving
1251:04 - the page fault and will get remains
1251:07 - or will get blocked so this will
1251:09 - significantly decreas the percentage
1251:13 - subtilization okay so what is the reason
1251:15 - of threshing High degree of
1251:17 - multiprogramming less number of frames
1251:19 - and high page fa rate so this is the
1251:21 - same example here suppose Ram is of 4 GB
1251:23 - limited size and can accommodate 50
1251:26 - process ideally but after 50 process we
1251:28 - want to accommodate 55 and 60 then
1251:31 - frames will decrease to each process and
1251:32 - page for trade will
1251:34 - increase and if operat system is not
1251:37 - using good replacement technique then
1251:39 - also page for rate will
1251:41 - increase and it is obvious that if page
1251:44 - size is
1251:45 - small then there will be more pages and
1251:49 - there will be high page for trade if
1251:51 - page size is large then number of pages
1251:53 - are less frames are same if number of
1251:56 - pages are less then less page fault will
1252:00 - occur are you getting the point see
1252:03 - increasing the page size May decrease
1252:05 - the page for but you know that it will
1252:08 - invite internal
1252:10 - fragmentation so we have to do
1252:11 - everything in Balance now comes the
1252:14 - threshing control
1252:15 - strategies the first one is prevention
1252:18 - and the second is deadlock or just like
1252:20 - the deadlock the second one is detection
1252:22 - and
1252:23 - Recovery in prevention we want threshing
1252:26 - to occur we want threshing to never
1252:29 - occur and how can we do that by
1252:31 - controlling the degree of
1252:32 - multiprogramming and you know who
1252:34 - controls the degree of multiprogramming
1252:36 - long longterm
1252:37 - scheder and for detection and Recovery
1252:40 - how are we going to detect that
1252:42 - threshing is occuring when we see
1252:44 - symptoms like low SE utilization maximum
1252:47 - number of process getting blocked High
1252:49 - degree of multiprogramming high disk
1252:53 - utilization so these are the symptoms
1252:55 - for threshing and what will happen after
1252:58 - threshing has occurred how are we going
1252:59 - to recover process suspension we will
1253:02 - remove the processes from memory put it
1253:04 - in the dis bag who will do midterm
1253:08 - scheduler let me repeat again what was
1253:10 - threshing threshing is when we decrease
1253:12 - when we increase the number of
1253:13 - programming to a higher extent which
1253:16 - means we are increasing the number of
1253:19 - processes in the memory more than its
1253:21 - limit then what will happen each process
1253:24 - will be given less number of frames to
1253:27 - accommodate less number of pages and if
1253:29 - less number of pages are in there in the
1253:30 - memory then page fault rate will
1253:32 - increase if page fault rate is increased
1253:34 - then process will remain blocked for
1253:37 - most of the time because the time the
1253:40 - most of the time will be uh will be
1253:42 - spent on pageold service so this will
1253:45 - significantly decrease the percentage
1253:47 - CPU utilization this is what threshing
1253:49 - is now comes the threshing control
1253:52 - strategies the first is by controlling
1253:54 - the degree of multiprogramming if we are
1253:57 - not forcing the number of process to be
1254:00 - more in the memory then no
1254:03 - problem so who will Who will control
1254:06 - that long-term scheder detection how are
1254:09 - we going to detect that threshing may
1254:10 - have been
1254:12 - occurring if we find that low CPU
1254:14 - utilization is present maximum number of
1254:17 - process are getting blocked the degree
1254:18 - of multiprogramming is high but CPU
1254:20 - utilization is less the degree of
1254:22 - multiprogramming is high but CP
1254:23 - utilization is less which means
1254:25 - threshing should be the reason behind it
1254:28 - high disk utilization because uh we are
1254:30 - utilizing dis and reading the pages
1254:32 - again and again for different kind of
1254:34 - processes during their page for service
1254:36 - so disk utilization will increase CP
1254:39 - utilization will decrease degree of
1254:40 - multiprogramming will be high number of
1254:42 - processes will be more to get blocked so
1254:46 - these symptoms suggest that threshing
1254:48 - should be the
1254:49 - reason and recovery process suspension
1254:52 - well the main reason was the high degree
1254:54 - of multiprogramming with the help of
1254:56 - midterm scheder we can swep out the
1254:58 - processes from the memory and may
1255:00 - decrease the degree of multiprogramming
1255:02 - and who will control that midterm
1255:04 - scheder so the process suspension is the
1255:07 - uh is the solution for
1255:11 - threshing in the next lecture we will
1255:13 - learn about locality of
1255:16 - references now comes the question how
1255:18 - can our programming can affect threshing
1255:22 - and here when I say V I mean by
1255:24 - programmers not the OS developers
1255:26 - programmers like the one who writes C
1255:29 - program Java program these are the
1255:31 - programmers and how can that programming
1255:34 - can affect threshing is it possible
1255:37 - let's see so we are given with an
1255:40 - integer
1255:42 - array let's name it as a it is not an
1255:45 - ordinary array it is two dimensional
1255:47 - array so let us create
1255:51 - that uh I should use
1255:55 - standard let us assume this is the array
1255:59 - now what
1256:00 - happens the size of arrays number of
1256:03 - columns
1256:04 - are 120
1256:06 - and number of rows are also 128 so I can
1256:10 - write integer a the rows can go from 1
1256:14 - to
1256:15 - 128 and the columns can go from 1 to 128
1256:19 - and it is an integer array so if I write
1256:22 - it like this a 1A 1 till we have a 128
1256:30 - comma 1 till a 128a
1256:33 - 128 this is our Matrix a
1256:37 - now the question is suppose I write two
1256:40 - programs the program one is for I 1 to
1256:44 - 128 next Loop for J 1 to 128 set the
1256:49 - value of a j first and then i j i = to 1
1256:54 - and if I write similarly
1256:57 - here but what is the difference now I
1257:00 - write IA J = to 1 you know that
1257:04 - eventually both will work eventually
1257:06 - they will set each and every element of
1257:07 - Matrix to
1257:09 - one but how it will affect threshing
1257:13 - let's see that suppose I have a page
1257:15 - size
1257:16 - of 128
1257:19 - words and each word can store an
1257:23 - integer
1257:25 - so this is our Matrix and how are we
1257:28 - going to store this Matrix into the
1257:30 - memory we will store let's say using row
1257:33 - major order what is row major order
1257:38 - this
1257:38 - [Music]
1257:40 - row this row will be stored in one page
1257:44 - this row will be stored in one page so
1257:45 - how many pages will be there there will
1257:47 - be total 128
1257:49 - Pages this is what row major order is we
1257:51 - are storing in rows so the first page
1257:53 - will contain the first page this is
1257:56 - let's say this is the first page it will
1257:57 - contain a 1 comma 1 a 1 comma 2 till a
1258:02 - 1A 128 this will be stored in page 1
1258:06 - so how many page it will require it will
1258:08 - require 128 Pages for the complete
1258:11 - Matrix now what happens it will ask for
1258:14 - 128 pages but what happens only 127
1258:19 - frames are
1258:20 - available in the memory only 127 frames
1258:23 - are available this was our memory and
1258:27 - the total number of frames are just 127
1258:29 - so what will happen I will store page
1258:31 - one here page two here page three here
1258:33 - till page 127 and page 1
1258:36 - 128 is still store in the disk
1258:41 - okay now let's see the programs the
1258:44 - program said for I to 128 and for J to
1258:47 - 128 store A J comma I is 1 so I will I
1258:50 - will
1258:51 - refer I'll refer 1 comma 1 first I I
1258:55 - will set it to one then I will refer see
1258:57 - here J is first so column will come
1258:59 - first so 2 comma 1 then I will set it to
1259:03 - one then 3A 1 then I will set it to one
1259:07 - in such manner I will go till a 128a 1
1259:11 - and then I will set it to
1259:12 - 1 because J is written first so column
1259:17 - will come first so here it is column so
1259:20 - 1A 1 will be set to one it is
1259:23 - okay this is presented page page one and
1259:26 - we have that page one into the memory no
1259:28 - problem but when it will move to a2a 1
1259:31 - then what will happen it has to access
1259:33 - page number two which contains a2a 1 1 a
1259:37 - 2A 2 till a 2A 228 128 this is is page
1259:43 - two so in this manner it will access
1259:45 - page 1 page 2 page three till page 127
1259:49 - now it is turned for a 128 comma 1 to be
1259:52 - set as one but this page is not present
1259:54 - in the memory so what will happen it
1259:56 - will cause a page fault and when page
1259:57 - fault will occur this page will be
1259:59 - brought to memory but there is no free
1260:02 - space available so which frame will be
1260:03 - selected as victim let let us take fif
1260:07 - so the one who came first will be gone
1260:09 - first P1 is removed now p128 is
1260:14 - present so how many page fault has
1260:16 - occurred till now we were using pure
1260:18 - demand paging so initially the memory
1260:21 - was completely empty so 127 page fult
1260:23 - initially and this new page fult that is
1260:26 - 128 page for has occurred in one
1260:29 - cycle from a 1A 1 to a 128a 1 one page
1260:34 - for has occurred oh sorry 128 page for
1260:37 - has occurred in this one
1260:38 - cycle now how many cycles it will go it
1260:42 - will go till 128 Cycles so a now now who
1260:46 - will
1260:48 - come a 1A 2 a 1 comma 3 till a 1A 128
1260:57 - and in the next who will
1260:58 - come this will be the next cycle a 1
1261:02 - comma 3 a 2A 3 till a 128a 3 this will
1261:07 - be the another next cycle so in one
1261:09 - cycle we had 128 128 page parts so in
1261:13 - 128 Cycles how many page for we will see
1261:15 - 128 into 128 so this will be the total
1261:18 - number of page FS when we
1261:21 - have used this the first piece of code
1261:26 - now let's see we are using the second
1261:27 - piece of code now let me remove all of
1261:29 - this now we are storing like this IA J =
1261:34 - 1 in this this manner a 1A 1 then a 1A
1261:41 - 2 a 1A 1 128 in this manner it will be
1261:45 - stored now so for the first cycle how
1261:48 - many page fault will occur only one page
1261:50 - fault how this P1 will be brought only
1261:54 - for the for all of this 1 to 128 only P1
1261:58 - will be brought from disk to memory why
1262:00 - because P1 contained all of these frames
1262:02 - see here P1 has all of them from 1 to
1262:05 - 128
1262:06 - now it moved to the next cycle it
1262:10 - requires P2 now then to the next cycle
1262:12 - it requires P3 now and then to 127 so
1262:16 - from till 127 how many page fault has
1262:19 - occurred 127 page fault has occurred and
1262:21 - for the last for the last which this one
1262:24 - a 12812 a 128a
1262:28 - 128 P 128 should be there in the memory
1262:31 - but it is not so page Vault will occur
1262:33 - it wants to come who will go one 20 128
1262:37 - will come at the place of P1 We are
1262:38 - following fif so how many page fault are
1262:41 - there now only 128 page
1262:45 - faults let me repeat again what
1262:48 - happened when we are storing like this
1262:51 - AJ comma I = to 1
1262:54 - then we want we want to access page in
1262:57 - this manner first this page then this
1262:58 - page then this
1263:00 - page so page fault will occur for one
1263:03 - cycle 128 page faults will occur for
1263:06 - another cycle another page fault will
1263:08 - occur for another page cycle 128 another
1263:11 - page fault will occur so how many page
1263:13 - faults occur 128 into 128 128 in each
1263:17 - cycle and there are 128 Cycles but when
1263:19 - we stored like this a i comma gal to 1
1263:22 - then for the whole cycle I required only
1263:24 - one page for only one page for and how
1263:27 - many for one complete cycle only one
1263:30 - page fault has occurred and how many
1263:32 - cycles are there 128 Cycles so 128 page
1263:35 - faults will be there
1263:36 - so in this way just by swapping the
1263:38 - variables from J comma I to I comma J we
1263:42 - have saved so much we have reduced the
1263:45 - number of Page fors by 128 times there
1263:48 - it was 128 into 128 now it is just 128
1263:51 - we have reduced the number of page FS by
1263:54 - 128 times just by spping the two
1263:58 - variables this is all I have written
1264:03 - here suppose these were the two program
1264:05 - s the program size is 128 bits and we
1264:08 - were storing row major orders in this
1264:10 - way it is stored it will require 128
1264:12 - frames but only 127 looted so how many
1264:14 - page fault will occur with program 1 and
1264:17 - two 128 Square page fults when we were
1264:21 - writing like this A J comma I and only
1264:23 - 128 page falls when we are writing like
1264:26 - this so when we stored in row major
1264:28 - order but a j comma I is column major
1264:32 - order then it will increase the page f
1264:35 - are you getting the point see we stored
1264:36 - in row measor order but accessing in
1264:38 - column major order that is just the
1264:41 - opposite so it will obviously increase
1264:43 - the page F here in IA J we stored in row
1264:46 - major order and we were accessing also
1264:47 - in low major order this will create low
1264:50 - page
1264:50 - F so I can say program 1 is 128 times
1264:55 - lower than program
1264:57 - 2 because number of page Faults Are 128
1265:01 - times more in program one than in
1265:03 - program two and why is it so because
1265:06 - program 2 follows locality of
1265:10 - reference okay so now you have idea what
1265:12 - is locality of reference how does it
1265:14 - work just by spping two variables we
1265:18 - made the program 128 time
1265:22 - slower okay if we have written I comma J
1265:25 - then the program would have8 times
1265:27 - faster here it is slower store we
1265:30 - storing in row major order and accessing
1265:32 - in column major order it will naturally
1265:34 - increase the page for
1265:36 - we are storing in row major order and
1265:37 - also accessing in row maor order this
1265:40 - will lower the page for okay now it is
1265:44 - your homework what will happen if we
1265:46 - have a page size of 256 words and 64
1265:48 - words see here we had a page size of 128
1265:51 - words that means 128 integers can be
1265:55 - stored in a single page now your
1265:58 - homework is what will happen if the pay
1266:00 - sizes of 256 words and the pay sizes of
1266:02 - 64 wordss solve it
1266:05 - we have seen how program can change the
1266:08 - threshing rate can data structure do so
1266:10 - also can data structure do the same
1266:13 - let's see suppose we have to choose
1266:15 - between arrays and Link list let me
1266:16 - check if it is recording yes so which is
1266:19 - better in case of demand page
1266:21 - environment arrays are better how much
1266:25 - possibility that complete arrays in the
1266:26 - single page because the possibility that
1266:30 - the complete arrays in the single page
1266:31 - is more so it will cause less page for
1266:34 - and in link list
1266:36 - each node will be in the different page
1266:37 - that is possible it will cause higher
1266:39 - page fault this is just me it may cause
1266:42 - so if in general scenario someone ask
1266:45 - which is better array or link list in
1266:46 - the demand page environment say array
1266:48 - and what is the reason because it is
1266:50 - chances that there are chances that the
1266:53 - array may be in the single page and Link
1266:55 - list may be distributed over the pages
1266:58 - so arrays are more preferable in case of
1267:00 - demand page environment linear search
1267:02 - versus binary search linear search works
1267:05 - like an array will cause less page Fs in
1267:08 - binary search each node may be in the
1267:10 - different page maybe say I have said
1267:12 - maybe in the different page so the
1267:14 - number of page fors will be higher so I
1267:16 - can say linear search is better in case
1267:17 - of demand page
1267:21 - environment a programming technology or
1267:24 - data structure is said to be good in a
1267:26 - demand page environment if and only if
1267:29 - it satisfy the locality
1267:32 - model it satisfies the locality model so
1267:34 - what does locality of reference or
1267:36 - locality model says it says that it
1267:38 - should refer those pages only which are
1267:40 - loaded in the
1267:42 - memory it should refer those pages only
1267:44 - which are loaded in the memory so this
1267:45 - is what how the way we write the pro the
1267:49 - program or how we use the data structure
1267:52 - or the
1267:53 - algorithms this can significantly change
1267:56 - the rate of threshing see here we write
1267:59 - a program we just swap two variables and
1268:02 - the threshing rate changed in case of
1268:04 - data structure if we use a data
1268:06 - structure which is more suitable in the
1268:08 - demand page environment threshing rate
1268:09 - may change we used an algorithm which is
1268:11 - more suitable threshing rate may change
1268:14 - so this is the point which I want to
1268:16 - make that how we write
1268:18 - program that can really affect
1268:21 - threshing now comes the working set
1268:23 - strategy or model to minimize page for
1268:26 - rate and also utilize the memory
1268:28 - effectively it works on the principle of
1268:31 - locality of references now you all know
1268:33 - what is locality of references take this
1268:35 - example suppose I have main function in
1268:38 - that main function I have this another
1268:39 - function f in this function f I have
1268:42 - another function G in G I have another
1268:44 - function H and H I have another function
1268:46 - scan F the total program size is 55 KB
1268:51 - okay the page size is 1 KB so I will say
1268:54 - the number of pages required to load the
1268:56 - whole program will be
1268:58 - 55 so instead of a static demand of 55
1269:01 - frames see which locality and demand
1269:04 - accordingly this this is what the
1269:05 - working set strategy model
1269:07 - is instead of a static demand of 55
1269:11 - frames instead of directed demanding 55
1269:13 - frames see the locality first and then
1269:16 - demand
1269:18 - accordingly so when in main when you are
1269:21 - in main demand for 10 pages only when
1269:25 - you are in F demand two pages and there
1269:27 - we will not need the the old pages of
1269:30 - main when you are in this locality
1269:32 - demand 10 pages when you are in this
1269:34 - locality demand two pages
1269:35 - so in this way you have to
1269:39 - go whatever be the size of locality ask
1269:42 - for those many frames only so this will
1269:44 - create less page fault rate and better
1269:47 - memory
1269:49 - utilization let me repeat again see in
1269:52 - which locality you are and ask for that
1269:55 - many page only this is the
1269:57 - point it will lead to less page fault
1270:00 - rate and better memory
1270:02 - utilization it controls the page fault
1270:04 - and utilize effectively uses locality of
1270:06 - reference which is dynamic frame
1270:09 - allocation estimate the size of locality
1270:11 - in which the program is executing and
1270:13 - demand and demand those many frames
1270:16 - suppose this is the
1270:18 - process this is the reference string 45
1270:21 - 8245 the large reference string till 56
1270:24 - and it goes on now a new term comes that
1270:28 - is working set window and this is
1270:31 - defined at a particular
1270:32 - time have you learned about sliding
1270:34 - window window protocol in computer
1270:36 - networks this is similar to that so we
1270:39 - have a working set window at a time T
1270:42 - what is working set window set of unique
1270:45 - Pages referred in the reference string
1270:47 - during the past Delta references and
1270:50 - this Delta is some integer so during the
1270:53 - past let's say Delta B5 so during the
1270:55 - past five references set of unique Pages
1270:58 - referred in that reference string that
1271:01 - is working set
1271:03 - window let's say three unique Pages
1271:05 - refers to working set window sizes three
1271:07 - at that time
1271:09 - to okay did you get
1271:11 - it check for the number of unique pages
1271:15 - in the past Delta references in the
1271:16 - reference string that will be the size
1271:19 - of working set window at a particular
1271:20 - time T and this working set window is a
1271:23 - sliding window it
1271:24 - slides working set window at time T at
1271:29 - when I say Delta equals to 10 so how
1271:31 - many unique pages are there so past 10
1271:33 - references 1 2 3 3 4 5 6 7 8 9 and 10 so
1271:38 - from here to here how many unique Pages
1271:41 - were referred that is what the working
1271:43 - set window size is how many unique Pages
1271:45 - 19 51 52 53 54 56 58 so these are the
1271:49 - unique ones so I will say 1 2 3 4 5 6 7
1271:53 - so the working set window size is
1271:56 - 7 so right now we are in the locality
1271:59 - which is defined in terms of seven pages
1272:02 - ask operating system to give seven
1272:04 - frames this is how your going to
1272:05 - estimate the size of the locality and
1272:08 - we'll ask the number of frames
1272:11 - accordingly so is the system threshing
1272:14 - or Not by this framework if we are using
1272:16 - this framework is the system threshing
1272:18 - or not let's see so the number of
1272:20 - process we have is n the total available
1272:23 - frames let's say m and the demand for
1272:25 - each process for frame SI the number of
1272:29 - uh the size of working set window the
1272:31 - total demand at time T will be add all
1272:34 - the demands it will give you D the
1272:37 - number of processes are n total
1272:39 - available frames are M the total demand
1272:41 - is D and the demand for each process for
1272:44 - frames is determined by how by finding
1272:46 - this working set window this that's how
1272:48 - we demanded the number of
1272:50 - frames so if demand is somehow equal or
1272:56 - approximately same to the number of
1272:58 - frames available then no
1273:00 - threshing
1273:02 - if demand is less than the available
1273:05 - then no threshing we can still increase
1273:08 - the degree of multiprogramming see
1273:10 - demand is less available is more than no
1273:13 - threshing here if we increase the multi
1273:15 - now at that point we increase the degree
1273:18 - of multiprogramming chances of threshing
1273:20 - will rise at this point when available
1273:25 - are greater than the demand then the
1273:27 - system system is in ch
1273:28 - State no threshing increase the degree
1273:31 - of multiprogramming we are good but if
1273:34 - demand is is more and the available
1273:38 - frames are less then I will say the
1273:41 - system is threshing okay the whole
1273:44 - success of this working set strategy
1273:46 - model depends on Delta let's say the
1273:49 - ideal value of delta is 10 which means
1273:51 - if you are taking 10 as the delta in
1273:54 - which you are looking on to the past 10
1273:57 - references from Delta you are going to
1273:59 - set the working set window or the
1274:02 - sliding window
1274:03 - size let's say the ideal value is 10 now
1274:07 - you set the value of delta to 2 and in
1274:10 - another case you set the value of delta
1274:11 - to
1274:13 - 10 it is not 10 it is greater than 10
1274:16 - ideal value is 10 so it should be
1274:17 - greater than 10 suppose it is 16
1274:21 - okay now if Delta is two then it will
1274:24 - leads to more page fault and if Delta is
1274:26 - more then ineffective memory utilization
1274:29 - because what does Delta says Delta says
1274:32 - according to Delta only the working set
1274:34 - window size is defined and that many
1274:37 - pages or that many frames are demanded
1274:39 - from the memory if Delta is more than
1274:42 - wsw will also be more then demand will
1274:45 - also be more ineffective memory memory
1274:48 - utilization will happen if demand is
1274:50 - more then the system may lead to
1274:53 - threshing and if Delta is less if Delta
1274:56 - is less then number of frames demanded
1274:58 - will also be
1274:59 - less the ne the necessary frames let's
1275:02 - say are 15 but you selected so much less
1275:06 - Delta that you want to get 15 frames but
1275:09 - you ask asked for only three if the
1275:13 - number of frames are less so much less
1275:14 - then obviously this will lead to more
1275:16 - page
1275:17 - ports so the whole success depends how
1275:20 - you choose the Delta
1275:23 - value let's solve this question it says
1275:26 - let the page reference and the Delta B
1275:30 - this is the page reference and the Delta
1275:32 - B4 respectively the initial working set
1275:34 - at a time tal to0 contains the pages a d
1275:38 - e where a was referred at time tal to 0
1275:41 - D was referred at time tal to minus1 and
1275:44 - E was referred at the time tal to min-2
1275:47 - determine the total number of page fault
1275:49 - and the average number of page frames
1275:51 - used by Computing the working set of
1275:53 - each reference so with the end of this
1275:56 - question you will get a complete idea
1275:57 - how this working set model work so we
1276:00 - have a reference string this c c d b c e
1276:02 - c e a and d and Delta
1276:05 - four the initial working set was e d and
1276:10 - a this is the current time this is 1
1276:13 - second before the current time and 2
1276:14 - second before the current time this was
1276:15 - the working set at time
1276:17 - zero so you have to find the number of
1276:20 - page fults we have what we have to find
1276:22 - determine the total number of page fault
1276:24 - when average number of page frames used
1276:26 - by Computing the working set at each
1276:28 - reference okay so we will find the
1276:32 - working set window at every time
1276:36 - initially we had e d a only initially we
1276:39 - had EA only and the reference string is
1276:42 - c c d the reference string is
1276:46 - CCD so at Time 1 this is at the time
1276:50 - zero at time let's say t = to 1 C is
1276:53 - demanded what will happen page fault
1276:56 - will occur so the wsw at time one will
1276:59 - be look at the past four why four
1277:02 - because of this Delta is four look at
1277:03 - the past four reference
1277:05 - and select the number of unique pages
1277:07 - and include that in your wsw how many
1277:09 - unique Pages EAC so edac will be
1277:12 - included what is the size four is the
1277:15 - size okay so we have to calculate the
1277:19 - number of page Cs and average number of
1277:20 - page frames so for average we will see
1277:23 - for each and every reference and then we
1277:26 - will calculate the average so for time
1277:28 - equals to 1 we had four in our W WS W
1277:33 - now at time equals to 2 C is again asked
1277:36 - what will happen look at the past four
1277:39 - look at the past four see this the
1277:42 - working set window
1277:44 - slided see at the past four now how many
1277:47 - elements will be there C already there A
1277:51 - and D so C A and D the duplicate won't
1277:54 - come as I said unique number of uniqu
1277:57 - here where I have
1277:58 - defined this W and W set of unique pages
1278:02 - so if repeative or multiple coming then
1278:05 - take only one so the distinct will come
1278:08 - here c c a d won't be there only c a d
1278:11 - so the number of uh elements in wsw is
1278:14 - three now for time three which means now
1278:17 - we are asking for D is D present yes D
1278:20 - present no page
1278:23 - for so what will be the uh wsw size d c
1278:28 - and a so d c and a at time four at time
1278:31 - four who will be asked B is asked is B
1278:33 - present no B is not present so who will
1278:35 - come b d and c b d and c will be in the
1278:39 - wsw now see here page fault has occurred
1278:42 - here keep count of page fault also
1278:45 - because we have been asked with total
1278:47 - number of page fault and average number
1278:50 - okay so at C this at here C already
1278:56 - present D B so we have b d and c c
1279:01 - already present that's why we didn't
1279:03 - included it again now now here at time =
1279:06 - to 5 this c b d already present no it
1279:11 - won't come again so we have three in WS
1279:14 - W tal to 5 in this way we will keep on
1279:16 - going we'll keep shifting our window
1279:20 - and we'll again shift our window to here
1279:23 - now e c b d will come e CB D will come
1279:28 - now we'll shift our window again c e c e
1279:32 - b will come so we'll have three there
1279:35 - now at T = to 8 c and e will there only
1279:39 - so e and C are this this this and this
1279:42 - how many are distinct only two are
1279:43 - distinct so two will come here now at 9
1279:47 - a e c will be there a e c will be there
1279:50 - 3 at time 10 d a e c four will be there
1279:53 - four is there so now add all of them 4 3
1279:56 - 3 3 3 4 3 2 3 4 and divide it by 10 you
1280:01 - will get the answer the average one now
1280:04 - the number of page faults first page
1280:05 - fault second page fault third page fault
1280:07 - fourth page fault and fifth page fault
1280:09 - so the number of page fault occurred was
1280:11 - five
1280:13 - and average you you calculate I have
1280:15 - given you the formula add all of them
1280:18 - and divide it by
1280:27 - 10 now we are starting our new section
1280:30 - that is file system we have successfully
1280:33 - completed our memory management and
1280:35 - after file system the operating system
1280:37 - is over we will take our miscellaneous
1280:38 - topics The Leftovers okay if you notice
1280:43 - one thing about file
1280:45 - system it is the only visible part of
1280:47 - operating system you want to know how
1280:50 - file system looks let me show
1280:56 - you this is the file system we have
1281:00 - devices and drivers then we have so many
1281:03 - files in there directory in there there
1281:05 - are program files okay so this is what
1281:08 - the file system is let me close
1281:09 - it it is the only visible part of
1281:12 - operating system so we have CPU we have
1281:15 - disk CPU is an electronic device disk is
1281:19 - an electromechanical device so there is
1281:21 - surely an architectural difference to
1281:23 - harmonize that we would require a
1281:25 - interface card or interface chip then we
1281:28 - have device driver which is a device
1281:30 - specific software then comes the OS
1281:33 - which contain file system and device
1281:34 - manager which works
1281:36 - interactively so this was just the
1281:38 - theory now comes the important part that
1281:40 - is disk physically
1281:43 - structure look at this diagram first we
1281:46 - have a spindle and then e the spindle is
1281:50 - associated with four platters we call
1281:52 - them as platters you can see the
1281:53 - circular structure this is platter each
1281:56 - platter has two surface the upper
1281:58 - surface and the lower surface the upper
1282:00 - surface and the lower surface the lower
1282:01 - surface in this diagram you cannot see
1282:03 - but suppose a dis type structure and the
1282:06 - disc has the upper surface and lower
1282:08 - surface okay see
1282:11 - here this is the spindle and it is
1282:15 - associated with platters the circular
1282:16 - structure or oval structure whatever you
1282:20 - call
1282:21 - then each platter is associated with two
1282:24 - surfaces the upper surface and the lower
1282:26 - surface till now it's clear
1282:29 - now each surface is divided into tracks
1282:33 - you know the race tracks in the similar
1282:35 - way so each surface is divided into
1282:38 - tracks each track is divided into
1282:40 - sectors see this each track is divided
1282:43 - into
1282:44 - sectors so this sector or block is the
1282:47 - unit of data transfer generally measured
1282:49 - in bytes so when we transfer data we we
1282:53 - transfer the data in terms of sectors
1282:56 - and this sector is the unit of data
1282:58 - transfer so what we have learned till
1283:00 - now there exist a spindle spindle is
1283:02 - associated with platters each platter
1283:05 - has two surface the upper surface and
1283:06 - the lower surface each surface is
1283:08 - divided into tracks each track is
1283:11 - divided into
1283:12 - sectors
1283:14 - okay this spindle can rotate this
1283:17 - spindle can
1283:18 - rotate each surface is associated with a
1283:22 - read right
1283:24 - head the so for a letter I will say
1283:27 - there is upper re right head for the
1283:28 - upper surface and lower read right head
1283:30 - for the lower surface and read right has
1283:32 - is head is connected with arm assembly
1283:35 - which can move forward and
1283:37 - backward so this arm assembly can move
1283:40 - forward and backward the spindle can
1283:41 - rotate so this read right head can this
1283:45 - readr head can move to any sector it
1283:48 - want see the spindle can rotate and the
1283:51 - arm assembly can move forward and
1283:52 - backward so it can easily or freely move
1283:55 - to any sector which it
1283:57 - want okay now let look at this diagram
1284:00 - this is our read right head this is the
1284:02 - spindle this is the disc actual disk the
1284:05 - saved file in sectors the
1284:08 - actuator and then we have circuit board
1284:11 - used for the on and off of the disk we
1284:13 - have the ARM device configuration Port
1284:16 - data cable Port power port Etc so this
1284:19 - is what the device or the dis looks like
1284:23 - look at this
1284:25 - diagram we have arm assembly we have a
1284:29 - spindle in spindle we have platters and
1284:32 - each platter is connected each platters
1284:34 - have two surface the upper surface and
1284:36 - the lower surface each surface is
1284:38 - divided into
1284:40 - tracks and if I select the same track
1284:43 - number from all the surfaces and join
1284:45 - them with imaginary line then I got a
1284:48 - cylinder so this is the
1284:50 - cylinder consisting of same track number
1284:54 - okay so this is a platter this whole dis
1284:57 - is the platter it has this the circular
1284:59 - part is the platter it has the upper
1285:01 - surface and the lower surface each
1285:03 - surface is associated with number of
1285:05 - tracks each tracks is divided into
1285:07 - number of sectors see this is one sector
1285:10 - this small part this is one
1285:13 - sector and the spindle can rotate the
1285:15 - arm assembly can move forward and
1285:17 - backward so that this read right head
1285:19 - which is associated with each surface
1285:21 - each surface will have its own read
1285:23 - right head so that readed right head can
1285:24 - move freely to whichever sector it wants
1285:27 - to
1285:28 - go
1285:30 - okay so if we view the same track on
1285:32 - platter we get a cylinder and number of
1285:34 - tracks will be equal to number of
1285:35 - cylinder this is the obvious
1285:38 - thing now same sector on all the tracks
1285:41 - we call it as dis sector see
1285:45 - here this is this is the platter surface
1285:50 - the surface is divided into number of
1285:52 - tracks and if we select and track is
1285:54 - divided into sectors and if we select
1285:56 - the same sector number over all of the
1285:59 - tracks this sector in track
1286:01 - one in track two in track three in track
1286:04 - for I chose the same sector number in
1286:06 - all of the tracks then what I get I get
1286:08 - the dis
1286:10 - sector okay so this blue shade you can
1286:13 - see is one track and if I select the
1286:15 - same sector number over all of the
1286:17 - tracks then I get the disk sector and if
1286:21 - I select the adjacent sectors over over
1286:24 - the track then I get a cluster a group
1286:26 - of one or more adjacent sectors so uh
1286:30 - let us see here in this diagram this was
1286:31 - the track in which it divided into two
1286:34 - sectors so if now I select this and this
1286:39 - also then I get a cluster this will
1286:41 - become one
1286:42 - cluster okay now let's see the whole
1286:45 - thing we had a disk disk has platters
1286:48 - each platter have two surface surface is
1286:50 - divided into tracks tracks are divided
1286:53 - into sectors and each sector is
1286:55 - associated with two attributes the
1286:56 - sector number and the sector size the
1286:58 - sector number will be in the
1287:00 - bits 2 ra to power that number of bits
1287:03 - will give him the total number number of
1287:04 - sectors and the sector size will be each
1287:07 - sector or the smallest unit of data
1287:10 - transfer be will be that sector or how
1287:13 - many bytes can be transferred at one
1287:16 - go okay now comes the disk iio time what
1287:21 - is the dis iio time the time taken for
1287:24 - the data transfer but for data transfer
1287:27 - the data is in the certain sector but it
1287:31 - is possible that my read right head
1287:33 - could be at a different
1287:35 - track it is surely possible so what we
1287:38 - have to do in dis IO time we have to
1287:41 - select three things the first will be
1287:44 - the seek time what is seek
1287:47 - time my read WR head can be at a
1287:50 - different location so from this track
1287:52 - number one see this this is the track
1287:54 - number zero this is track number one
1287:56 - track number two track number three
1287:57 - track number four and this is track
1287:59 - number five and this is the sector which
1288:01 - I want to read but my read write has is
1288:04 - is in track number one so to move from
1288:07 - track number one to track number five
1288:09 - here this will be the seek time and how
1288:12 - will I move there with the help of with
1288:14 - the help of arm
1288:17 - assembly so from one track to another I
1288:20 - go then it will require one seek so head
1288:24 - have to make four seeks from track
1288:26 - number one to reach at track number five
1288:28 - how many SS will be made from track 1 to
1288:31 - track five four SS will be made okay
1288:34 - okay now comes the track track time what
1288:36 - is track track time the time taken by
1288:38 - the read right head to move from one
1288:40 - track to another it is same as the it is
1288:43 - same as the one seek time so the time
1288:47 - taken by read right head to move from
1288:50 - one track to another just the adjacent
1288:53 - one see if I moved from track number one
1288:55 - to track number two then how much time
1288:57 - will be taken that is track track time
1289:00 - that will be the the time taken for one
1289:03 - seek one track to another that is one
1289:05 - seek time and here I have to make four
1289:07 - seeks so four into I should say track
1289:10 - track time or one seek
1289:14 - time okay so if I have to the time of
1289:17 - one seek is actually the track track
1289:19 - time and the time taken to move from
1289:23 - track 1 to track five or the track which
1289:26 - you are in the source to destination
1289:28 - track that is the seek time so here
1289:31 - total number of seeks how many seeks we
1289:33 - have to make 4 six and track track time
1289:37 - so track to reach minus current track
1289:40 - number so 5 - 1 will be 4 so we have to
1289:42 - make four seeks into time of one seek
1289:45 - that is track track time this will be
1289:46 - the seek time see what was this Sky time
1289:50 - the time taken to transfer the data but
1289:52 - data can be in the different sector from
1289:55 - the current position of R head rri head
1289:57 - see here the read right head is present
1289:59 - here but the data is here so what I'm
1290:02 - going to do
1290:04 - I'm going to firstly move this red right
1290:07 - head to that current track it may be in
1290:09 - the different track we have to reach to
1290:11 - the different track in which of uh in
1290:14 - which the sector is present which has
1290:16 - our
1290:17 - data so firstly we had a seek time we
1290:20 - move to that sector so track to reach
1290:23 - minus current track number into track
1290:24 - track time now we are in that track
1290:28 - which contains our sector now what will
1290:30 - happen we have to rotate the spindle see
1290:33 - here
1290:34 - spindle can rotate the spindle can
1290:36 - rotate and this arm assembly can move
1290:38 - forward and backward so from in the SE
1290:41 - time the time taken by arm assembly to
1290:45 - make to move the read right head from
1290:47 - the current track number to the desired
1290:49 - track number that was the seek time now
1290:51 - it is time for spindle to rotate and see
1290:56 - here firstly it was here now the
1290:59 - position has changed to here but still
1291:00 - it is not on that sector we were on a
1291:03 - different track we reach to the same
1291:05 - track but now we are on the different
1291:07 - sector we have to reach to that same
1291:11 - sector so the time taken we need to
1291:13 - rotate it so that the sector comes under
1291:15 - the
1291:16 - head we need to rotate this in this way
1291:19 - so that this will move and will come
1291:21 - under the re right head the time taken
1291:23 - for this is what we call rotational
1291:26 - latency and it is generally taken as R
1291:29 - by2 what is r r is the time taken for
1291:31 - full rotation and it is made measured in
1291:35 - RPM so the rotational latency is taken
1291:37 - as r by2 r is the time taken for full
1291:40 - rotation so rotational Lance is time
1291:42 - taken for half the
1291:44 - rotation why we have taken the half
1291:47 - because generally it takes around half
1291:49 - the rotation for the sector to reach to
1291:52 - that current
1291:53 - head
1291:55 - okay now this is the
1291:58 - position firstly we were at a different
1292:01 - track our sector was at a different
1292:03 - track then we reach to the same track
1292:05 - but not at the same sector now what we
1292:08 - did we rotated it and the sector has
1292:11 - come under the head now what will happen
1292:13 - the transfer time will also be there see
1292:16 - firstly we were not at the same track
1292:17 - seek time was taken to reach at the same
1292:20 - track then we were not at the same
1292:22 - sector rotational latency was taken to
1292:25 - reach to the same sector now transfer
1292:28 - time will be the time taken to transfer
1292:32 - the data
1292:34 - amount of time taken by read right head
1292:36 - and transfer the data to the disk buffer
1292:40 - so what will be the transfer time it
1292:42 - will be the sector size upon track size
1292:45 - into R the sector size upon track size
1292:49 - into R this is what the transfer time is
1292:50 - so the dis IO time will be seek time
1292:54 - rotational latency time plus transfer
1292:55 - time remember this is it is an important
1292:58 - Concept in the last lecture we have seen
1293:01 - the seek time the rotational latency
1293:03 - time and the transfer times when some
1293:05 - sub gives the disio time we have seen
1293:07 - the seek time was the time taken by read
1293:11 - right head to go from current head to
1293:12 - the desired head that is seek time
1293:15 - rotational latency time was R by2 what
1293:17 - was R the time taken for full complete
1293:20 - rotation what was the transfer time
1293:23 - sector size divided by track size into
1293:26 - rotational time okay see rotational
1293:29 - latency is different from rotational
1293:31 - time rotational time is R rotational
1293:33 - latency is R by2 okay now comes the data
1293:36 - transfer rate disk transfer data from
1293:39 - rate this much Zed by r k b one track is
1293:46 - transferred in one
1293:49 - rotation one track is transferred in one
1293:51 - rotation so in 1 second how much data
1293:55 - will be transferred Z by R KB why KB
1293:59 - because we are keeping this rotational
1294:02 - time in milliseconds
1294:04 - okay now let's see this question
1294:06 - consider the following disk
1294:08 - specifications we are given with number
1294:10 - of platter 16 so there is a dis in which
1294:13 - there are 16 platters in such manner
1294:15 - There are 16 platters and you know that
1294:18 - each platter has two surfaces the upper
1294:20 - and the lower one number of tracks per
1294:23 - surface this is one track this is
1294:26 - another track another one in such manner
1294:28 - there are 512 tracks per surface number
1294:32 - of sectors per track this is a track
1294:35 - this is one sector another sector
1294:36 - another sector another sector in this
1294:38 - manner there are 2048 sectors in each
1294:41 - track the sector offset is 12 bit which
1294:44 - means the sector size is 2^ 12
1294:48 - bytes average seek time is 30
1294:50 - millisecond so the time taken by read
1294:53 - right head to reach from the current to
1294:55 - desired is 30 millisecond dis RPM is
1294:58 - 3600 so I can write in one rotation or
1295:02 - 3600 100 rotations are there in 1 minute
1295:05 - or 60 seconds so in 1 second or one
1295:08 - rotation will be in how much time 60
1295:10 - divid 3600
1295:14 - seconds this this will be uh this will
1295:17 - be the time taken for one
1295:19 - rotation so 60 divid 3600 seconds and if
1295:22 - I want to calculate in milliseconds then
1295:24 - multiply by 1,000 1 2 1 1 2 1 now there
1295:30 - are 6 the 600 divid 36 6 100x
1295:36 - 6 this will be the time taken for a
1295:40 - single uh rotation this is
1295:44 - 16.67 16.67 seconds are taken for one
1295:49 - rotation then how much time
1295:51 - for okay so we are asked with the first
1295:54 - is unform capacity of disk we have one
1295:58 - disk which has 16 platters each platter
1296:01 - has two surface each surface has 512
1296:04 - tracks each track has
1296:06 - 2048 sectors and each sector has a size
1296:09 - of 2 12 bytes so this will be the unform
1296:13 - capacity so when you multiply all of
1296:15 - them you get 2^ 37 which is 128 GB the
1296:19 - second question
1296:21 - is IOS time per sector we'll have to add
1296:25 - seek time rotational latency time and
1296:27 - transfer time seek time is given as 30
1296:30 - Mond rotational latency time will be R
1296:32 - by2 so we had R = to 16.67 so R by2 will
1296:36 - be around 8.3 and now we have to
1296:38 - calculate the transfer time what was
1296:40 - transfer time sector size upon track
1296:43 - size into R so I can write transfer time
1296:45 - as this is 1 by K so K will
1296:48 - be K will be sector size upon track size
1296:51 - into R so in this manner you will get
1296:54 - the transfer time from where you will
1296:56 - get the sector
1296:58 - size you have each and every data is
1297:00 - with you from there you will get sector
1297:02 - size the track size and then rotational
1297:05 - is given with you now the next is data
1297:08 - transfer rate what is data transfer rate
1297:11 - track size upon rotational latency not
1297:14 - latency rotational time rotational
1297:16 - latency is 1x2 which is R by2 is
1297:19 - rotational latencies R is the rotational
1297:21 - time so what is data transfer it Z by R
1297:25 - Zed is the track size and R is the
1297:26 - rotational
1297:28 - time kb per second so from there you
1297:31 - will get5 GB per second as the data
1297:33 - transfer
1297:34 - it one track is transferred in one
1297:36 - rotation then in 1 second how much track
1297:40 - will be transferred or how much uh data
1297:42 - will be
1297:43 - transferred okay now the next is sector
1297:47 - address so we have to find the sector
1297:50 - address in bits how are we going to find
1297:53 - log to number of sectors so we find that
1297:56 - total number of sectors are 2 by 25 so
1297:58 - there will be 25 bits for the sector
1298:02 - address and 12 bits for the 12 bits for
1298:05 - the sector offset so these 25 bits will
1298:11 - take me to the correct sector and these
1298:13 - 12 bits will take me to the correct word
1298:16 - okay now let us divide this also four
1298:20 - for the PLS we have 16 PLS one for the
1298:23 - surface we have two surfaces nine for
1298:25 - the track we have 512 tracks and number
1298:28 - of sectors are 2048 so I can write this
1298:30 - as 2 into 1024 which is nothing but 2
1298:33 - into 2^ 10 which is 2^ 11 so 11 bit for
1298:36 - the
1298:37 - sectors so this will be the total
1298:39 - address and sector address will
1298:42 - be this one this these 25 bits will take
1298:48 - me to the correct sector and these 12
1298:50 - bits will take me to the correct word so
1298:52 - sector address in bits are just 25 bits
1298:55 - these are the sector offset this will be
1298:56 - the total
1298:57 - address okay next
1299:01 - question consider dis with the following
1299:03 - specifications number of surface we have
1299:05 - 64 now the surface is directly given
1299:08 - outer diameter is 16 cm so outer radius
1299:10 - will be 8 cm inner diameter is 4 cm so
1299:14 - the inner radius will be 2 cm inter TR
1299:18 - distance is1 mm so we have a distance
1299:21 - for track is this 6 cm which is 8 - 2
1299:24 - this is 6 cm and the inter track
1299:27 - distance is1 mm so I can say 6 cm
1299:30 - divided .1 will give me the number of
1299:32 - tracks per surface maximum density is
1299:35 - given as 8,000 bits per CM calculate the
1299:38 - unform capacity of disk okay so the
1299:42 - question is we have to calculate the
1299:43 - capacity of the dis surfaces is already
1299:45 - given we have find the total number of
1299:47 - tracks per surface
1299:51 - so these will be the total number of
1299:53 - tracks all over the disk now if we can
1299:56 - find the track size then I can tell the
1299:59 - unform capacity of the dis but you know
1300:03 - the track is of different sizes see this
1300:05 - is the track innermost track and this is
1300:07 - the outermost
1300:10 - track innermost track is less than the
1300:13 - outermost track you can see it but also
1300:16 - we are keeping the size
1300:18 - same how can we do that by using wearing
1300:22 - density track length in centimeter into
1300:24 - density but we had maximum density given
1300:28 - is 6ou what was the maximum density I
1300:31 - think 8,000 so 8,000 bits per CM 8,000
1300:35 - bits per CM so where will be the maximum
1300:38 - density
1300:39 - used in the innermost
1300:42 - part because see
1300:47 - this length into density will give me
1300:50 - the
1300:52 - size we have to use the maximum density
1300:55 - when length is
1300:56 - less and minimum density when length is
1300:59 - maximum see this length into density
1301:02 - should be constant
1301:04 - density will be maximum when length is
1301:07 - minimum and density will be minimum when
1301:09 - length is maximum so where we will use
1301:11 - this 8,000 we will use in the inner
1301:13 - track so what is the inner track
1301:15 - distance the radius is given 2 pi r is
1301:17 - the circumference so 4 Pi cm is the
1301:19 - inner track distance what will be the
1301:21 - track capacity 4 Pi into 1 KB this is
1301:24 - the 8,000 bits are 1 KB 1,000 will be 1K
1301:30 - and and this 8 will be for
1301:33 - byte bit to byte conversion so this is 1
1301:37 - kilo bits multiplying with 8 will give
1301:39 - me 1 kilobytes so 8,000 bits are 1
1301:43 - kiloby so the track capacity is of 4 Pi
1301:46 - kilobyte the surface capacity is 600
1301:49 - into 4i kilobytes which will give me
1301:52 - 12.56 kiloby and the disc capacity will
1301:55 - be surface capacity into number of
1301:57 - surfaces which will give me 48 GB around
1302:00 - five around half GB did you you get it
1302:03 - let me repeat again so what we had in
1302:05 - the question we have to find the
1302:07 - capacity of the dis but we were not
1302:11 - giving with the track size we find that
1302:14 - total number of surface we have 64
1302:17 - number of tracks we have 600 but until
1302:21 - we do not find the track size we cannot
1302:24 - proceed so for track size we are given
1302:26 - with maximum density but now the
1302:28 - question is where we will use this
1302:30 - maximum density in the innermost part or
1302:32 - the outermost part because the track
1302:35 - size is same that is
1302:37 - undeniable and you can also see that
1302:39 - innermost part innermost track will less
1302:42 - than the outermost track and we are
1302:44 - keeping the size also same and how can
1302:46 - we achieve this by using weing
1302:49 - density okay now we know that length
1302:52 - into density will give me the
1302:54 - size and this should be constant so and
1302:57 - we are given with maximum density so
1303:00 - where we will use the maximum density in
1303:01 - the innermost rack because in the
1303:04 - innermost track length is minimum that's
1303:06 - why we are using the maximum
1303:08 - density so from there we get in each
1303:12 - track we have 12.56 KB of data and there
1303:16 - are 600 tracks in the surface so we get
1303:19 - the surface capacity from here and for
1303:22 - this capacity we have 64 such surfaces
1303:26 - so we'll multiply the 64 into surface
1303:29 - capacity from there we get 48 GB
1303:35 - how long does it take to load a 64
1303:37 - kiloby program from a dis so we have to
1303:40 - load a 64 kilobyte program from disk to
1303:42 - memory okay average seek time is 30
1303:45 - millisecond rotation time is 20 Mill so
1303:48 - rotational latency will be 10
1303:50 - millisecond track size is 32 kiloby page
1303:53 - size is 4
1303:55 - kiloby assume that Pages the pages of
1303:58 - the program are distributed randomly
1303:59 - around the disk okay so firstly we have
1304:01 - to calculate the time which will take
1304:06 - which it will take to transfer 64
1304:07 - kilobyte program from disk to memory
1304:10 - okay how many pages does it have 64 / by
1304:15 - 4 it has 16
1304:18 - pages and what will be the transfer time
1304:21 - for one page so firstly we have to go to
1304:24 - that page 30 millisecond and then
1304:27 - rotational latency and then transfer
1304:29 - time in one rotation one track is
1304:33 - transferred so in one page will be
1304:35 - transferred in how much time one
1304:37 - rotation divide by track size into page
1304:40 - size so Pace size divide
1304:43 - by the track size into rotational time
1304:46 - so from here we get the time taken to
1304:49 - load one page from disk to memory is 42
1304:51 - millisecond so the time taken to load 16
1304:54 - pages will be 680 millisecond now comes
1304:57 - to the part two what will be the
1304:59 - percentage saving in time if 50% of the
1305:02 - pages of pro program are
1305:04 - contigous so if 50% of the pages of
1305:06 - program are contigous which means out of
1305:08 - 16 pages eight pages are continuous and
1305:11 - eight pages are randomly distributed so
1305:14 - for random distribution 42.5 will be
1305:16 - multiplied with 8 to get uh 340
1305:20 - milliseconds so 340 milliseconds will be
1305:22 - taken to load these random pages into
1305:25 - memory now what will happen for these
1305:27 - eight pages which are
1305:29 - continuous see if these eight pages are
1305:33 - which means all the page belong to same
1305:35 - track so seek time will be 30 Mill 30
1305:39 - Mond which means the read right head is
1305:41 - now on the track which has all the pages
1305:44 - rotational latency will be R by2 now the
1305:47 - readr head is on the first
1305:51 - page
1305:55 - plus transfer time of eight pages see
1305:59 - here this is the time taken by read
1306:01 - write head to go to the track which
1306:04 - contain all the pages this is the time
1306:06 - taken by read right head to reach to
1306:08 - that uh to reach to that the position
1306:11 - where first page is there now all of the
1306:14 - pages are contigous so no need for
1306:16 - another seek time or rotational latency
1306:19 - we'll just transfer them back to back so
1306:22 - this will be this will come just for one
1306:25 - time and then transfer time for eight
1306:27 - pages so this will cause
1306:30 - me this is the how much time it took it
1306:33 - took 60 and 340 for that eight random
1306:37 - Pages 340 for 8 random pages and 60
1306:39 - millisecond for continuous pages so the
1306:41 - total was 400 millisecond initially the
1306:44 - total time taken was 680 in the case
1306:46 - when when all pages were randomly
1306:49 - distributed so the percentage saving is
1306:52 - 480 - 6 680 mod divide by 680 here we
1306:56 - get around 41% saving in time so what
1307:00 - will the percentage saving in time 41%
1307:02 - if 50% of the pages of program are
1307:06 - continuous okay let us uh let let me
1307:10 - read this question again and explain to
1307:12 - you again what happened here we have to
1307:15 - calculate the time taken to load the
1307:18 - program from disk to memory and the
1307:21 - program has 16 pages so we'll calculate
1307:23 - the time taken to load one page and
1307:25 - multiply it by
1307:26 - 16 as it is said that pages are
1307:29 - distributed randomly around the disk so
1307:32 - for each each page seek time will come
1307:34 - for each page rotational latency will
1307:35 - come for each page transfer time will
1307:37 - come as it is written there it is
1307:38 - randomly distributed around the
1307:41 - disk so for one page load time we found
1307:44 - it to be 42.5 millisecond so the 16 page
1307:47 - load time will be 680 MC the part two of
1307:50 - the question says what if the eight
1307:53 - pages are continuously there and eight
1307:56 - pages are randomly distributed so we
1307:58 - will multiply this 42.5 the time taken
1308:00 - to load one page into eight pages for
1308:03 - random distribution so we got 340 MC for
1308:08 - transferring those pages which were
1308:09 - randomly distributed now the pages which
1308:13 - are Contin continuously distributed or
1308:15 - continuously present continuously
1308:16 - present
1308:18 - then seek time will be there to for read
1308:22 - right head to go to that
1308:25 - track rotational rency will come for
1308:28 - read WR had to go to that page where the
1308:31 - contigous uh allocation has started or I
1308:34 - can say the read WR had to go to the
1308:36 - first page of those continuous Pages now
1308:41 - eight pages are back to back so I will
1308:43 - transfer them back to back no need for
1308:45 - another seek time no need for another
1308:46 - rotational
1308:47 - latency from there I got 60 millisecond
1308:50 - so the total is 400 millisecond only
1308:53 - when eight pages are continuously there
1308:55 - and eight pages are randomly distributed
1308:58 - now we have to calculate the percentage
1309:00 - Time Savings so this is how we
1309:01 - calculated and we got 4
1309:03 - 1% rotational Laten is taken into
1309:06 - account only once when the pages are
1309:07 - continuously distributed over one track
1309:09 - because the read right head of the disc
1309:12 - need to wait for dis to rotate to the
1309:14 - correct position only at the beginning
1309:16 - of read operation so in case of
1309:18 - continuous allocation there will be only
1309:20 - one rotational latency account once the
1309:23 - first page on the track is being read
1309:25 - the rest of the pages on the same track
1309:27 - can be read in continuous sweep as the
1309:30 - dis rotates this is because pages are
1309:33 - laid out continuously on the disk so
1309:35 - there is no need for disk to rotate
1309:37 - multiple times to different position to
1309:39 - read each page why because of
1309:41 - discontinuous distribution therefore
1309:43 - time taken for dis to rotate to the
1309:45 - correct position is only occurred in Ur
1309:48 - incurred once at the beginning of read
1309:50 - operation that's
1309:52 - why R by2 is taken only once at the for
1309:56 - the beginning thing when the read R head
1309:58 - will reach the first
1310:00 - page after that read that head can
1310:03 - continue reading the rest of the pages
1310:04 - on the track without additional
1310:06 - rotational
1310:07 - delay
1310:09 - okay an application require 100
1310:12 - libraries at startup each Library
1310:14 - require one dis access seek time is 10
1310:18 - millisecond dis RPM is 6,000 all 100
1310:22 - libraries are at random locations 50% of
1310:25 - the libraries require transfer time of
1310:27 - half rotation while for remaining 50% it
1310:29 - is negligible how long does it take to
1310:32 - to load all the libraries see we have
1310:35 - 100 libraries and each Library require
1310:37 - one dis access so for 100 libraries we
1310:40 - have 100 disc excess seek time is given
1310:43 - as 10 Mond disc RPM is given as 6,000 so
1310:48 - the rotational time we will calculate it
1310:50 - 60 second is taken for 6,000 rotations
1310:54 - so for one rotation how many seconds
1310:56 - will be
1310:57 - taken 10 milliseconds will be taken so
1311:00 - one rotation can be incurred in 10 10
1311:02 - milliseconds only now it says for 50
1311:05 - libraries transfer time is of half
1311:07 - rotation which is 5 millisecs and for
1311:10 - another 50 libraries the transfer time
1311:12 - is negligible it is close to zero so for
1311:15 - set one for 50 libraries we have 5
1311:17 - millisecond and for set 2 we have
1311:20 - zero so the time for set 1 will be 50
1311:23 - into 10 + 5 + 5 millisecond 1000
1311:27 - milliseconds and for set two we'll have
1311:30 - 15 into SE time rotational latency and
1311:32 - zero as it is written that transfer time
1311:34 - is zero so the total time will be 1.75
1311:37 - second we will add both of them now here
1311:39 - it is not written that they are
1311:42 - contigous that's why we have taken into
1311:44 - account every time for each dis
1311:47 - access like in the previous question if
1311:50 - contigous word would present then we
1311:53 - will take the seek time and rotational
1311:55 - latency only
1311:56 - once
1311:58 - okay in the next lecture we will learn
1312:00 - about logical structure of disk
1312:04 - we were learning file system it was the
1312:06 - only visible part of operating system we
1312:09 - have learned about disk physical
1312:10 - structure we have learned what was arm
1312:13 - what was platter sector track spindle
1312:16 - spr right head all the all these terms
1312:19 - we have learned we have learned that in
1312:21 - one disk there are several patters each
1312:23 - platter has two surfaces each surface
1312:26 - has tracks track is divided into sectors
1312:29 - sectors can be reached the firstly we
1312:32 - have to to reach to the correct sector
1312:34 - from where we will get the sector number
1312:37 - so sector number will help us to reach
1312:39 - to the correct sector and sector size
1312:41 - that is the sector offset will help me
1312:43 - to reach the correct word okay we have
1312:46 - seen dis IO time which included seek
1312:49 - time which included seek time rotational
1312:52 - latency time and transfer
1312:54 - time we have seen the data transfer rate
1312:57 - was Z by R
1313:00 - KB then we have send some numericals
1313:03 - which included to calculate unform
1313:05 - capacity IO time data transfer and
1313:08 - sector addresses then we have seen that
1313:12 - L into D remained constant so when I
1313:15 - will use the maximum capacity for the
1313:17 - innermost so this was the main concept
1313:20 - in that in this question what we did we
1313:22 - saw that if eight eight pages are
1313:24 - contiguous then there is no need to
1313:26 - include SE time and rotational time
1313:27 - rotational latency
1313:30 - again so if in case of contigous
1313:33 - allocation rotational latency will be
1313:35 - included only one time okay so this was
1313:38 - all we have learned Now we move to The
1313:40 - Logical structure of the disk or
1313:42 - formatting process
1313:45 - so for the to explain this I have a nice
1313:49 - example take example of your College
1313:52 - library that building of the library or
1313:54 - the library place can be said as disk
1313:57 - and books can be analogical to data now
1314:00 - suppose if I just dump thousands of
1314:02 - books in the Library without having
1314:04 - proper bookshelves Etc I mean without
1314:07 - any proper Furniture then searching
1314:08 - becomes horrible suppose in library
1314:11 - there are no bookshelves there is no
1314:13 - such kind of furniture to store the
1314:14 - books I just dump thousands of books or
1314:17 - lcks of books in that place in the
1314:20 - library building then searching a
1314:23 - particular book will become horrible for
1314:24 - you so Library without bookshelf is raw
1314:28 - disc and library with furniture is
1314:31 - formatted dis formatted dis has a
1314:33 - benefit of effective storage and faster
1314:37 - retrieval now whenever you visit
1314:39 - computer labs so for different classes
1314:41 - we have different operating system in
1314:43 - the same
1314:44 - computer for when we used to study C
1314:47 - programming so in the same computer we
1314:50 - used to study on ubben 2 and when we
1314:53 - used to take the computer organization
1314:55 - architecture class we used to open the
1314:57 - windows
1314:58 - software so the operating system first
1315:02 - when we used to uh study the cyber
1315:04 - security in our computer labs we used to
1315:06 - work on K Linux so same computer has
1315:09 - different different operating system how
1315:11 - is that possible with the help of
1315:14 - partitions in the disk so this is what
1315:16 - we call multi boot computer it is
1315:18 - generally done at the computer labs for
1315:20 - teaching purposes so this here is the
1315:23 - dis it is divided into several
1315:25 - partitions which contain operating
1315:26 - system 1 operating system two and
1315:27 - operating system three each partition
1315:29 - contain a different operating system but
1315:33 - if you are thinking that you can load
1315:35 - two of the operating system at the same
1315:36 - time into the memory this is not
1315:37 - possible at a time either one to will
1315:40 - run or Windows will run or k Linux will
1315:42 - run at a time only one will run so I can
1315:44 - say at a time one will be
1315:47 - loaded okay so dis is divided into
1315:49 - partitions there is one primary
1315:51 - partition and some extended or logical
1315:54 - drives see when you use to open your
1315:58 - this PC when you open this PC then you
1316:01 - can see several drives in there like C
1316:03 - drive or D drive e Drive F Drive G drive
1316:06 - so the C is the primary which contains
1316:08 - the bootable data which means our
1316:09 - operating system it contains extra data
1316:12 - on software also but basically why it is
1316:15 - known as primary because it has the
1316:17 - bootable part what is bootable part we
1316:19 - will see later and this extended or
1316:22 - logical drives this contain all the non-
1316:24 - bootable data like your songs video
1316:26 - games or your softwares all these things
1316:28 - is here in the extended logical drives
1316:32 - here you can see in os1 MBR is the
1316:34 - written what is MBR Master boot record
1316:38 - this is generally on the first primary
1316:40 - partition it contains partition table
1316:42 - and boot loader partition table contains
1316:45 - the information about the partition so
1316:48 - don't worry here are just the steps how
1316:51 - the or I can say how your computer
1316:54 - starts these are the steps so firstly we
1316:57 - switch on after switching on the power
1316:59 - comes in so this PD is the power on self
1317:03 - test which test that all are all the
1317:06 - devices electronically active this is
1317:08 - just the hardware test so you can see
1317:10 - when you start your computer all the
1317:12 - three lights or numb lock page scroll
1317:15 - and those lights just blink or in the
1317:17 - modern laptops the light over the cap
1317:19 - loog or the light over the mute button
1317:21 - blinks so this is the power on self test
1317:26 - then comes the BIOS basic input output
1317:28 - system initializes input output device
1317:30 - including the disk so firstly when we
1317:33 - switch on power on self test occurs what
1317:36 - is power on self test it checks whether
1317:38 - the devices are electronically active
1317:40 - this is a hardware test then what
1317:42 - happens bios happens it initializes the
1317:45 - input input output devices including the
1317:47 - disk now bootstrap what is bootstrap
1317:50 - small booting program what it does it
1317:53 - loads the master boot record into the
1317:55 - RAM and hand over the control to boot
1317:57 - loader so this MBR this MBR is loaded
1318:01 - into where it is MBR loaded into
1318:03 - RAM okay then what happens boot loader
1318:06 - reads partition table and display
1318:08 - options if available so if you remember
1318:11 - when you start your computer uh or in
1318:13 - the lab then you can see the different
1318:14 - options which options you select two or
1318:18 - k
1318:20 - Linux or the windows these three options
1318:23 - you can see so you can with the help of
1318:26 - the arrow down you can select any of the
1318:28 - operating system and choose that to
1318:30 - start so boot loader will load the
1318:32 - kernel program from the dis into the
1318:35 - memory then execution of the kernel will
1318:37 - load other operating system modules into
1318:39 - the memory like dispatcher virtual
1318:41 - memory
1318:42 - manager all these things will be loaded
1318:45 - firstly what happens power on when you
1318:48 - power on then power on self test is
1318:50 - occurred which checks are all the
1318:51 - devices electronically active then bios
1318:53 - test happens it check it initializes the
1318:56 - input output device then bootstrap it is
1318:58 - a small booting program which does what
1319:01 - it brings the MV into the main memory
1319:03 - and then what does MBR
1319:06 - do MBR has boot loader and partition
1319:09 - table so the boot loader reads the
1319:11 - partition table and display the options
1319:14 - like operating system one like Windows
1319:16 - or k Linux or one2 which you want to
1319:17 - select now you select K Linux then what
1319:20 - will happen boot loader will load the
1319:22 - kernel program from the dis into the
1319:23 - memory of that operating system of K
1319:26 - Linux and the execution of that kernel
1319:28 - will load the other OS modules like
1319:30 - dispatcher or virtual memory manager
1319:32 - into the memory so this is how the
1319:35 - operating system comes into the memory
1319:37 - so this was the booting process firstly
1319:39 - what happens you power on after power on
1319:42 - the power on self test occurs then bios
1319:45 - happens then bootstrap come when boot
1319:48 - strap is executed it brings the MBR into
1319:50 - the memory when MBR is brought then the
1319:52 - boot loader from the partition table
1319:54 - which which will let you choose which
1319:56 - operating system you want to bring to
1319:58 - the memory then the kernel will be
1320:00 - loaded and the execution of Kernel will
1320:01 - bring bring other programs like uh
1320:04 - dispatcher and virtual memory manag into
1320:05 - the into the memory and then finally the
1320:08 - operating system which you want to
1320:09 - choose will be brought from disk to the
1320:12 - memory this is what booting is bringing
1320:15 - the operating system from disk to
1320:19 - memory now we will learn about the
1320:21 - partition
1320:23 - structure what infrastructure are
1320:25 - embosed on the disk partition after
1320:27 - formatting so we have here is the
1320:30 - partition one the second part partion
1320:32 - let's say this is hard disk so the first
1320:34 - one this part is MBR the second part is
1320:38 - first partition boot sector the third
1320:40 - part is file system area of first
1320:41 - partition and data area of first
1320:43 - partition so the data area of the first
1320:46 - partition is just this much and the rest
1320:48 - of the space like is is taken up by MBR
1320:52 - the first partition board sector and the
1320:54 - file system area of first partition
1320:57 - that's why you may see you may have seen
1320:59 - that uh let me show you see my laptop
1321:01 - has a specification of 512 GB SSD and 16
1321:05 - GB Ram so if I click on this uh this PC
1321:09 - see here I get only 475 GB of free space
1321:13 - but I have purchased a 52 GB SSD then
1321:17 - where is all that remaining what is the
1321:20 - remaining
1321:22 - 512 minus 475 where is the 30 37 GB the
1321:27 - 37 GB is used up
1321:29 - here in the MBR in the first partition
1321:33 - boot sector in the file system area of
1321:35 - the first partition here is the more
1321:37 - clear way of partitioning see we have
1321:40 - these data blocks down there then we
1321:42 - have directory structure partition
1321:44 - control block and boot control
1321:47 - block data blocks you all know will
1321:49 - contain the applications and other
1321:52 - operating system files these will
1321:54 - include your GTA Y game this will
1321:56 - include your Microsoft Word Google
1321:58 - Chrome all these things will be included
1322:00 - here this this is the directory
1322:02 - structure what is directory structure
1322:04 - let me show you which contains the files
1322:07 - and
1322:08 - folders that is what directory structure
1322:13 - is these files and folders this is what
1322:15 - the directory structure is there we
1322:17 - click and I get this I get this this is
1322:21 - what the directory structure
1322:23 - is then PCB what is pcv partitioning
1322:27 - partition control block it gives
1322:29 - complete picture of partition just just
1322:31 - like the administrative
1322:33 - block and what is boot control block it
1322:36 - is the sector of partition that contains
1322:38 - the boot
1322:40 - program the first OS program initial or
1322:44 - uh initialization program or kernel the
1322:47 - boot block will contain Unix or Linux
1322:49 - and partition boot sector will conol
1322:51 - Windows this is how the multi- booting
1322:54 - or multi boot computers are made okay
1322:58 - let me repeat firstly we have in a disk
1323:01 - we have partitions the primary partition
1323:03 - contain the master boot record which
1323:05 - contain partition table and boot loader
1323:08 - so firstly when we switch down our
1323:10 - computer we have power on self test
1323:12 - after that we in power on self test we
1323:14 - check are all the devices electronically
1323:16 - active then we initialize the io devices
1323:19 - then bootstrap this bootstrap when
1323:22 - executed in the CPU this will load the
1323:24 - MBR Master boot record from disk to the
1323:27 - main memory which contains boot loader
1323:29 - and partition table so boot loader will
1323:31 - read partion table and display options
1323:33 - to choose which operating system would
1323:35 - you like to bring into the memory from
1323:38 - disk then after the taking input from
1323:41 - the user then boot loader will load the
1323:43 - kernel of that program from disk to the
1323:45 - memory and this is how and then
1323:47 - execution of that kernel will bring the
1323:49 - other modules into the memory then we
1323:50 - see partition structure it contains it
1323:53 - contains the boot control block
1323:55 - partition control block directory
1323:56 - structure and data blocks data blocks
1323:58 - contain the application directory
1324:00 - structure I have shown you what is
1324:01 - directory structure partition control
1324:03 - blocks give the complete picture of
1324:05 - partition just like the administrative
1324:07 - block and this boot control block it is
1324:10 - the sector of partition that contain the
1324:12 - boot program like the first OS program
1324:14 - like the kernel the boot block will
1324:16 - contain the Unix or Linux and the
1324:18 - partition boot sector will contain the
1324:20 - windows us this is just an example okay
1324:23 - in the next lecture we will see the file
1324:25 - versus directory
1324:35 - let's learn about File versus
1324:37 - directory what is the difference between
1324:39 - file and directory let me clearly tell
1324:42 - you directory contains the information
1324:45 - about files not the actual data now
1324:48 - comes the question what is file file is
1324:51 - nothing but an abstract data type just
1324:53 - like a process process has process was
1324:56 - also abstract data type which has its
1324:57 - own definition
1324:59 - representation operations and attributes
1325:02 - you remember that similarly file also
1325:05 - have the all four it has definition what
1325:08 - is the definition collection of
1325:10 - logically related entities or records
1325:12 - the representation it can be either flat
1325:15 - or it can be either
1325:18 - hierarchial flat means just the series
1325:20 - of bytes and hierarchial means the
1325:23 - higher level implementation like B trees
1325:26 - or B minus trees B plus B minus trees in
1325:28 - that manner operations like create
1325:32 - modify open read
1325:35 - truncate attributes name extension Owner
1325:40 - Mode blocks in use blocks in use means
1325:43 - in which block the file is present so
1325:46 - these are this is what the file is and
1325:48 - what is directory directory contains the
1325:51 - information about files okay now let's
1325:54 - see it formally representation
1325:56 - representation or structure flat or
1325:58 - record flat means series of bytes record
1326:01 - means series of Records like in
1326:02 - hierarchial tree it is the higher level
1326:05 - implementation operations are create
1326:06 - open read write seek truncate and
1326:09 - attributes name extension type Owner
1326:11 - Mode size date and time permissions
1326:14 - Block in use which means in which block
1326:16 - the file data is stored I'm talking
1326:18 - about the data blocks in the partition
1326:21 - structure attributes of the file are
1326:23 - stored in file control Block in in Linux
1326:27 - we call it as inode and in Windows we
1326:29 - call it as directory entry
1326:32 - so every partition contains directory
1326:35 - structure here is the directory
1326:36 - structure so every partition has its own
1326:39 - directory structure what is directory
1326:41 - special file which contains data about
1326:44 - other files it contains the metadata
1326:46 - what is metadata information about the
1326:48 - data or data about data this is metadata
1326:51 - so it contains metadata of files not the
1326:53 - actual
1326:55 - data the directory does not contain the
1326:58 - actual data of the files it just contain
1327:00 - the metadata so this is what a directory
1327:02 - entry looks like it is a linear
1327:04 - onedimensional array see this is the
1327:07 - directory entry let's say these are the
1327:09 - blocks in which the file is stored so it
1327:11 - tells that file one is stored in this
1327:13 - block file two is stored in this block
1327:15 - file three in this one and four in this
1327:16 - one in this
1327:18 - manner let's now see directory
1327:20 - structures the first one is single
1327:22 - directory structure for for all users we
1327:25 - have kept each and every file in the
1327:28 - same folder it is simple to implement
1327:32 - but as you know lots of searching time
1327:34 - will be there secondly naming config
1327:37 - problem in the same in the same
1327:40 - directory you cannot have two files with
1327:42 - the same name even if you try to store
1327:45 - it it the one like here the one will be
1327:48 - automatically added let's say you have a
1327:51 - movie do mp4 file already present if you
1327:55 - try to store the same file again then
1327:59 - one will be automatically added you
1328:01 - cannot store the two files with the same
1328:04 - name in the same directory so this is
1328:05 - what the naming conflict problem is and
1328:08 - bad organization well that's the thing
1328:11 - so the single directory for all users
1328:13 - mean we have kept every file in the same
1328:17 - folder okay so what is the uh Advantage
1328:21 - the advantage is simple to implement and
1328:23 - disadvantages it will take lots of
1328:25 - searching time naming conflict problem
1328:28 - plus bad organization two level director
1328:32 - separate directory for each user for
1328:34 - each user we have a separate directory
1328:35 - this is what two level directory is
1328:37 - efficient searching and path is involved
1328:39 - now see for user one we have another
1328:41 - directory which contain these files user
1328:44 - two we have another directory user three
1328:46 - another directory so what is two level
1328:48 - directory separate directory for each
1328:50 - user efficient searching and path is
1328:53 - involved now we can have same file for
1328:56 - different
1328:57 - user you know that we can have this
1329:00 - movie. MP4
1329:03 - in with same name we can store in store
1329:07 - it in different folder this is possible
1329:10 - that's what we are seeing we can have
1329:12 - same file name for different users but
1329:14 - there is no grouping capability which
1329:16 - means if we wanted to keep some files
1329:18 - separate that is not possible
1329:20 - multi-level directory the more advanced
1329:22 - version it is sub directories within the
1329:25 - other directories sub directories within
1329:27 - the other directories like we have the
1329:29 - root directory
1329:31 - then we have some other directories then
1329:33 - in this directory we have other
1329:35 - directories in this directory we have
1329:37 - more other directories so directories
1329:39 - within directories or sub directories
1329:40 - within other directories is what
1329:42 - multi-level director is it can be either
1329:44 - in the tree structure
1329:47 - or the general graph directory what is
1329:50 - tree Str what is the difference between
1329:52 - tree structure and graph directory in
1329:54 - tree there is no kind of cycle present
1329:56 - but here you can find the cycle from
1329:58 - here you can go to this book to every
1330:01 - and from a you can go again back to book
1330:04 - so in general graph directory we have
1330:06 - cycles and what is this directed
1330:08 - directed a cyclic graph it is used for
1330:11 - file sharing how many links are pointing
1330:14 - to the shared file this is the file
1330:16 - sharing suppose in this there are two
1330:19 - links pointing to the same
1330:22 - file so I will say link count of this
1330:25 - file will be two and as you know this is
1330:27 - a graph so for searching uh for
1330:30 - searching a file we may have to Traverse
1330:32 - the directory for that so we know that
1330:34 - there are two famous algorithm depth for
1330:37 - search and breadth for search directory
1330:39 - has a file support operation a special
1330:41 - operation on directory which is not
1330:43 - performed on a regular files
1330:46 - daverse in files we do not have such
1330:48 - kind of operation if you go there and
1330:51 - see the list of operations there is no
1330:54 - such kind of operation in file you can
1330:56 - either search uh wherever you
1330:58 - want in directory so in directory there
1331:01 - is a special kind of operation which
1331:02 - means daverse daverse mean you can
1331:05 - search in the whole directory for a
1331:07 - specific kind of file so this is what
1331:10 - it's written here so directory as a file
1331:12 - support this Traverse operation it's
1331:14 - special kind of operation which is not
1331:16 - performed on regular files now comes
1331:18 - this
1331:20 - question the question is consider a list
1331:22 - of linear list based directory
1331:24 - implementation in a file system each
1331:27 - directory is a list of nodes where each
1331:29 - node contains the file name along with
1331:30 - the metadata such as the list of
1331:33 - pointers to the data Block in this
1331:34 - manner consider a given directory Fu so
1331:37 - we have a given directory Fu which of
1331:39 - the following operation will necessarily
1331:41 - require a full scan of f for successful
1331:45 - completion the first is opening of an
1331:47 - existing file info if I want to open a
1331:51 - file let's say I want to open F2 do I
1331:53 - need to scan the whole uh do I need to
1331:56 - scan the whole directory f for just
1331:58 - opening a file there is no need let's
1332:00 - say I want to create a new file let's
1332:02 - say I want to create F5 but I want to
1332:04 - name it as
1332:06 - F3 I don't know that there is F3 below
1332:09 - somewhere I just coincidentally name it
1332:11 - as F3 what will
1332:13 - happen it will say there is a file with
1332:16 - the name F3 already exist do you want to
1332:19 - replace it or give it a new name so this
1332:23 - error will generate how this error will
1332:25 - generate because as I create a new file
1332:27 - and name it the whole name of the file
1332:31 - in that food directory will be scanned
1332:33 - such that there is no there is no file
1332:36 - present already with the same name so to
1332:39 - ensure that there is no naming Conflict
1332:41 - for creation of file yes the all the
1332:45 - file will be scanned renaming of
1332:47 - existing file same concept yes naming
1332:49 - conflict may arise deletion of an
1332:51 - existing file from F no there will be
1332:54 - no uh need to scan the whole folder
1332:57 - through for just deleting so for opening
1332:59 - and deleting no need for creation and
1333:02 - renaming yes we have to scan the whole
1333:06 - folder in the next lecture we will learn
1333:08 - about file system
1333:11 - implementation now comes the file system
1333:13 - implementation look this lecture is
1333:15 - going to be way too theoretical so I'm
1333:17 - just going to read it all okay the file
1333:20 - system is implemented in the layered
1333:22 - fashion we have application programs at
1333:24 - the top the core file system and the io
1333:27 - control and devices the applications
1333:30 - this application this execute the input
1333:32 - output statement and The Logical file
1333:35 - system this one uses directory structure
1333:38 - to provide the file organization module
1333:41 - with all information this logical file
1333:43 - system it uses the directory structure
1333:46 - to provide the file organization module
1333:49 - this is the file organization module
1333:51 - with all the information so initially we
1333:53 - have application programs which executes
1333:57 - the input output statements this logical
1333:59 - file system uses that directory
1334:01 - structure so that it can give
1334:02 - information to file organization module
1334:06 - this handles the files and their logical
1334:08 - blocks and physical blocks the file
1334:10 - organization handles the logical and
1334:13 - physical blocks physical file
1334:16 - system issues IO command to the device
1334:18 - driver to read and write physical blocks
1334:21 - on the disk issues IO command to the
1334:24 - device drivers this IO control consist
1334:26 - of device drivers and hand and interrupt
1334:29 - handlers and then comes the
1334:31 - devices which perform the actual eye
1334:33 - operation so let me read again
1334:35 - application execute input output
1334:37 - statements then comes the logical file
1334:39 - system it uses directory structure to
1334:42 - provide information to file organization
1334:44 - this file organization handles the files
1334:47 - and their logical and physical blocks
1334:50 - logical and physical
1334:52 - blocks and this physical file system IT
1334:55 - issues IO command to device drivers to
1334:58 - read and write physical blocks on the
1334:59 - disk and and these devices are the are
1335:02 - the one who actually performs the I
1335:05 - operation okay these devices include
1335:07 - Hardware dis or controller cards
1335:10 - Etc the io control level it consists of
1335:13 - device drivers and interrupt handlers to
1335:15 - transfer information between main memory
1335:18 - and disk system a device driver can be
1335:20 - thought of a translator which has input
1335:23 - of high level language like retrieve
1335:25 - block 123 and the output consist of
1335:29 - lowlevel Hardware specific instructions
1335:31 - the instructions specific to Hardware
1335:34 - that are used by the hardware
1335:36 - controllers which interfaces the io
1335:38 - device to the rest of the system okay so
1335:40 - the iio control level consist of device
1335:42 - drivers and interrupt handlers to
1335:45 - transfer information between main memory
1335:47 - and dis dis disk system this device
1335:50 - driver is a kind of translator which
1335:52 - takes the input as high level language
1335:54 - like retrieve block 123 and the output
1335:57 - consist of lowlevel Hardware Specific
1336:00 - Instructions
1336:01 - which interfaces the io device to the
1336:04 - rest of the system those instruction are
1336:06 - used by Hardware
1336:08 - controller then comes the basic file
1336:10 - system basic file system need only to
1336:14 - issue generic commands to the
1336:16 - appropriate device driver to read and
1336:18 - write physical block on the disk each
1336:20 - physical block is identified by its
1336:22 - number by its numeric disk address for
1336:25 - example drive 1 cylinder 73 track 2 and
1336:28 - Sector 10 so each phys physical block
1336:31 - what is a physical block sector it is
1336:34 - identified by its numeric disk address
1336:37 - as we have talked about it the sector
1336:39 - address and the sector offset this will
1336:41 - give me the address of the world so this
1336:43 - is the sector address and it goes like
1336:46 - drive 1 cylinder 73 track 2 Sector 10
1336:50 - this layer also manages the memory
1336:52 - buffers and cash that hold various file
1336:55 - system directory and data blocks okay
1336:58 - now comes the file organization module I
1337:00 - know it's both but I have to read it all
1337:03 - file organization modules know about
1337:05 - files and their logical blocks as well
1337:07 - as physical blocks by knowing the type
1337:10 - of file allocation used which type of
1337:13 - file allocation is used and the location
1337:15 - of the file this file organization
1337:17 - module it translate The Logical block
1337:20 - address to physical block address for
1337:24 - the basic file system to transfer the
1337:26 - file organization module knows about the
1337:29 - files and their logical blocks as well
1337:31 - as the physical blocks by knowing the
1337:33 - type of file allocation used and the
1337:35 - location of the
1337:37 - file the file organization can translate
1337:39 - The Logical I think the same thing has
1337:41 - been copied again a translation is
1337:43 - needed to locate each block the file
1337:45 - organization module includes the free
1337:47 - space manager which tracks unallocated
1337:50 - blocks and provides these block to file
1337:53 - organization module when requested so
1337:55 - this is just the
1337:56 - theory logical file system manages the
1337:59 - metadata information the metadata
1338:01 - include all of the file system structure
1338:04 - except the actual data as you know
1338:05 - metadata is just the data about data not
1338:09 - the actual data logical file system
1338:11 - manages the directory structure to
1338:13 - provide the file organization module
1338:15 - with the information of later needs
1338:17 - given a symbolic file name it maintains
1338:20 - a file structure via file control blocks
1338:23 - a file control block FCB anode in Unix
1338:26 - file system contains information about
1338:30 - the file including ownership the
1338:32 - permissions the locations of the file
1338:33 - and the
1338:34 - contents let me summarize so we have a
1338:37 - layered file system implementation it
1338:39 - includes application of the programs
1338:41 - then comes logical file system file
1338:43 - organization module and basic file
1338:45 - system this is the core part you can uh
1338:48 - read about it here in these paragraphs
1338:52 - okay then comes the io control and
1338:54 - devices application execute the input
1338:56 - output statement logical file system
1338:59 - uses directory structure to provide the
1339:01 - information to file organization it
1339:03 - handles their logical and physical block
1339:05 - addresses then this physical file system
1339:08 - issues IO command to the device drivers
1339:10 - this IO control consist of device
1339:12 - drivers and interrupt handlers and these
1339:14 - devices are the one who performs the
1339:16 - actual ey operations in the next lecture
1339:18 - we will see allocation
1339:20 - methods let's learn allocation methods
1339:23 - methods for allocating disk space to
1339:26 - files directories or any other data
1339:28 - structure we had this kind of disk
1339:30 - parage it included BCB the PCB directory
1339:33 - structures and here it was the data
1339:36 - blocks which contained the user data so
1339:39 - the data blocks these are numbered like
1339:41 - this there are two properties of data
1339:43 - blocks their address and their size the
1339:45 - size will be in bytes and the address
1339:46 - will be in bits 2 to power DBA will give
1339:50 - you the total number of dis blocks in
1339:53 - the in this area so DBA equals to 16
1339:57 - bits so there will be 2 power 16 blocks
1340:00 - DBS equal to 1 kilobyte so if someone
1340:03 - ask you maximum possible size file size
1340:06 - this will be equal to this area which
1340:08 - means total
1340:11 - blocks into block
1340:14 - size block size is given here total
1340:16 - blocks you can find by 2^ DBA and then
1340:20 - multiplied by DBS this will give you the
1340:23 - maximum possible file size of disc dis
1340:25 - size now there are several methods for
1340:28 - allocating the blocks to file
1340:31 - like contiguous non-contiguous and index
1340:33 - allocation in
1340:35 - contiguous there will be internal
1340:37 - fragmentation in the last
1340:39 - block external fragmentation yes
1340:42 - increasing file size that is
1340:47 - inflexible let's see with the help of an
1340:49 - example suppose this is my file this is
1340:52 - another file this is another file this
1340:55 - is another file so in this way the
1340:58 - blocks are located to files okay now how
1341:01 - internal fragmentation can be there
1341:03 - suppose my file needed 2.1 blocks so the
1341:07 - two blocks will be located and the third
1341:09 - one has to be allocated although it will
1341:12 - need only the point one of it in this
1341:15 - manner internal fragmentation now how
1341:17 - external fragmentation let's
1341:20 - say let's say there are four blocks 1 2
1341:23 - 3 and four or let's keep it to five now
1341:28 - these two blocks are allocated these two
1341:29 - blocks are allocated
1341:31 - now there is another process which needs
1341:33 - two block can it be given
1341:35 - no this this block will be wasted
1341:39 - external fragmentation increasing file
1341:41 - size I want to increase the file size
1341:43 - take the same case 1 2 3 4 5 I want to
1341:47 - increase the file size these two blocks
1341:48 - are allocated these two blocks were
1341:49 - allocated I want to increase the file
1341:51 - size of this file with two blocks can I
1341:54 - no because the two blocks are not
1341:57 - available that's why increasing file
1341:59 - size is inflexible or not generally
1342:02 - possible so plus two blocks may not be
1342:05 - available and how can it be accessed
1342:08 - using sequential or Random Access like
1342:10 - an
1342:11 - array and it is faster now comes the
1342:14 - non-contiguous allocation or linked
1342:16 - allocation wherever you find the block
1342:19 - use it but you have to link it see this
1342:22 - block allocated first see I find this
1342:25 - block free all allowed then I find this
1342:27 - block free alloted but you have to you
1342:29 - have to create create a link list of it
1342:31 - otherwise how are you going to find that
1342:33 - after accessing this block which block I
1342:35 - have to access so there will be a kind
1342:38 - of linked list okay so this directory
1342:42 - contains the file name Jeep start is at
1342:44 - 9 and end it as 25 so this is the start
1342:48 - here it goes first then here then here
1342:50 - and there it ends so in this manner I
1342:53 - hope you got the idea wherever block is
1342:55 - free allot it and then link them with
1342:57 - the link list
1343:01 - internal fragmentation yes see the point
1343:04 - is same suppose I need 2.1 blocks of the
1343:07 - data then what will happen if I need to
1343:10 - point one blocks for a file then two
1343:12 - blocks will be allocated and third one
1343:14 - will also be allocated although only
1343:16 - point one will be used rest of the space
1343:18 - will be
1343:20 - wasted internal fragmentation is present
1343:23 - but external fragmentation is removed
1343:25 - how initially when we had the continuous
1343:29 - allocation these two blocks were
1343:31 - allocated to a file these two blocks
1343:32 - were allocated to file suppose now a new
1343:34 - file comes which need two blocks I can't
1343:36 - allot it but here I can I allot a block
1343:40 - somewhere else then I link to this block
1343:43 - and allot it now in this manner external
1343:46 - fragmentation is reduced increasing file
1343:49 - size yes I can increase the file
1343:52 - size suppose I want to increase the file
1343:55 - size of
1343:56 - this of this process firstly I will
1343:59 - allot this block and the other block
1344:01 - wherever free types of access here this
1344:05 - is the problem here the types of access
1344:07 - will be only sequential because how can
1344:10 - I reach how can you reach to this block
1344:12 - without going like this because you
1344:14 - can't have address of this but in in
1344:17 - contiguous it works like an array so it
1344:20 - works like an array you can either have
1344:22 - sequential access or direct access like
1344:24 - an array it is faster in linked list you
1344:27 - cannot access the seventh node directly
1344:29 - you have to start from the head and hop
1344:31 - to the next to next node and next node
1344:33 - and then you will reach the node you
1344:35 - desired so the type of access will be
1344:37 - only sequential and slow
1344:40 - performance pointers consume dis space
1344:43 - there is another overhead here and
1344:46 - vulnerability of pointer is suppose this
1344:49 - was the first node and this pointer got
1344:52 - broken the whole file is damaged now so
1344:55 - if vulnerability of pointer is they can
1344:57 - get broken and will truncate the file
1344:59 - this will corrupt the whole
1345:01 - file now comes the third one is indexed
1345:04 - allocation of disk space what will
1345:08 - happen in this each file will maintain
1345:10 - an index block index block hold address
1345:14 - of the data blocks of the
1345:16 - file in this manner suppose 19 is the
1345:18 - block which is containing the address of
1345:20 - all the blocks which is present in the
1345:22 - file so here is a file named Jeep the
1345:25 - index block is present at Block 19 it
1345:27 - contains the the address of those block
1345:30 - which contain which contains the data uh
1345:32 - data of the file the 9th one the 16th
1345:35 - one the 25th one first block 10th block
1345:40 - so in this manner they all will be
1345:41 - connected now again a vulnerability if
1345:43 - index block got damaged then the whole
1345:45 - file will be gone but this index block
1345:48 - does not contain the data it contains
1345:50 - the array of the addresses of those
1345:53 - block which has the data so there are no
1345:56 - block to block links index itself is
1345:59 - pointing to all blocks
1346:02 - okay see this question have DB equal to
1346:05 - 16 bits DBS which means size is 1 KB
1346:09 - maximum file size with one index block
1346:11 - easy question you just need to find the
1346:14 - number of block addresses index block
1346:16 - can you store these many blocks will be
1346:19 - present in the file and then you
1346:22 - multiply with the D the data block size
1346:25 - and you will get your file size so you
1346:26 - have to find the number of addresses
1346:29 - these index block this index block and
1346:30 - is stored let's say x number of
1346:34 - addresses size of each address is 16
1346:36 - bits and the size of index block is 1 KB
1346:40 - so here I got X = to 2^ 9 so this index
1346:44 - block can store 512 addresses each of
1346:47 - each address has 16 bits in it so this
1346:51 - index block can point to 512
1346:54 - blocks each of size 1 K so what will be
1346:58 - the file size5 MB see this another
1347:02 - question a file system support the data
1347:05 - block size to be 4 KB each block can
1347:08 - hold 512 addresses the size of DBA in
1347:12 - bits will
1347:14 - be same question just the opposite
1347:17 - way the size of the data block which is
1347:21 - 2^ 2 into 2^ 10 into 2^ 3 for this bite
1347:27 - to bit conversion because we want the
1347:30 - address in bits so 2^ 15 bits is the
1347:33 - size total size of a block and it is
1347:35 - given that each block can store 512
1347:39 - addresses so how many addresses will be
1347:41 - or what will be the size of each address
1347:44 - let me repeat the size of a block which
1347:47 - can store 5002 addresses so what will be
1347:50 - the size of each address here I get X =
1347:53 - to 64
1347:54 - bits this was the indexed allocation now
1347:57 - the question is can I increase the file
1347:59 - size yes take more than one index block
1348:02 - then you can increase the file size
1348:03 - performance internal fragmentation yes
1348:06 - external fragmentation no because here
1348:08 - also noncontiguous allocation is there
1348:10 - can I increase the file size yes it is
1348:12 - flexible type of access will be both
1348:14 - sequential and random which means it is
1348:17 - similar to array reliability more than
1348:20 - linked as no pointers but
1348:23 - if index block got damaged then the file
1348:26 - will be gone space overhead some disk
1348:28 - space will be consumed for index blocks
1348:32 - because if the file size is more then
1348:35 - there will be more index blocks and if
1348:37 - more index blocks are present then the
1348:39 - overhead to store those index blocks in
1348:42 - the disk will also be there so this is
1348:44 - the
1348:46 - drawback case study Unix or Linux each
1348:50 - file node is associated with I
1348:53 - node let's say we have a file named gy.
1348:56 - C associated with iode 23 or this is the
1349:00 - Block in which the I node is
1349:04 - stored it contains some general
1349:06 - attributes like type owner date and time
1349:09 - size Etc and then comes the Block in use
1349:13 - it contains the 10 direct dis block
1349:17 - addresses it contains the 10 direct dis
1349:20 - block addresses so how much size will be
1349:23 - contributed by this block or this area I
1349:26 - can say 10 direct dis block addresses
1349:29 - each of size let's say 1 KB so 10 KB
1349:31 - will be contributed by this now what
1349:33 - happens I need more so I will point to
1349:37 - an index block which will point to
1349:40 - several data
1349:42 - blocks so in this manner here is the
1349:45 - single indirect disk block address it
1349:49 - points to an index block which points to
1349:51 - the several data blocks let's say the
1349:53 - index block can store 512
1349:56 - addresses so how many data blocks it is
1349:58 - pointing 512 data blocks each of size 1
1350:01 - KB so how how much size this is
1350:03 - contributing 512 into 1 KB which means
1350:06 - 512
1350:07 - KB now comes the more the double
1350:11 - indirect
1350:12 - pointer here is the block which points
1350:15 - to the index block can you imagine here
1350:18 - we had the direct addresses here we have
1350:21 - we are pointing to an index block which
1350:23 - contains several dis block here we have
1350:27 - a block which points to the several
1350:29 - index block
1350:31 - and each index block is pointing to the
1350:33 - several data blocks or disk blocks
1350:36 - whatever you want to call so this in
1350:39 - this block is pointing to 512 index
1350:42 - block each index block is pointing to
1350:44 - 512 data blocks and the size of each
1350:48 - data block is 1 KB so the total space
1350:51 - contributed by this will be 256
1350:53 - MB you get
1350:56 - it what it is written here we have mode
1350:59 - owners time stem size block count we
1351:01 - have direct blocks where we store the
1351:04 - addresses of the blocks directly we have
1351:07 - single indirect in single indirect what
1351:10 - we do we store the index block address
1351:13 - here the index block is pointed and then
1351:16 - this will point to the later uh dis
1351:19 - blocks or data blocks in this double
1351:21 - indirect this block will point to
1351:22 - several index blocks and these several
1351:24 - index block will point to the more dis
1351:28 - blocks and triple indir you can
1351:32 - guess we have a block which is pointing
1351:35 - to the index block this block is
1351:37 - pointing to the more index blocks and
1351:39 - this block is now pointing to
1351:41 - the the data blocks so the level are
1351:45 - increasing see if I if I ask you what
1351:48 - will be the size contributed by triple
1351:50 - indirect then 2^ 9 into 2^ 9 and then
1351:54 - more 2^
1351:56 - 9 this will be the answer 2 power 27
1352:01 - KB see when we had a single indirect
1352:05 - then only 1 * 2^ 9 when we have double
1352:08 - then 2 * 2^ 9 we have when we have
1352:11 - triple then three * 2^
1352:14 - 9 in this
1352:16 - manner now comes the second case study
1352:19 - which is dis operating system or Windows
1352:22 - operating system we have a directory
1352:25 - like this we have a file named jy. C we
1352:28 - here we have other attributes and the
1352:30 - block info is stored like this the first
1352:32 - dis block address and the last dis block
1352:35 - address but here the first and last is
1352:38 - written only what about the middle ones
1352:41 - so how to get information about other
1352:43 - blocks here should be blocks not
1352:46 - tables so how are we going to get
1352:48 - information about other blocks with the
1352:51 - fat file allocation table or we also
1352:53 - call it as Master file table it is like
1352:58 - this it contains the entries number of
1353:01 - blocks but these contains the address of
1353:04 - the next block see
1353:05 - here this is the master file table here
1353:09 - we have a starting block 217 this will
1353:11 - contain the address of the next block we
1353:13 - have to go to so we go to 68 now 618
1353:17 - contains the address of the next block
1353:18 - we have to go to 339 this will contain
1353:21 - minus1 which means end here so the
1353:24 - starting block quiz 2117 and the last
1353:27 - block is 339
1353:30 - so this is how it works so it is like
1353:32 - the link allocation but it is array
1353:35 - based so this will contain the
1353:37 - information about all the
1353:40 - blocks see here it is written the first
1353:42 - block is five so we move to the first
1353:44 - block then we know we have to move to
1353:46 - three we move to three then here it is
1353:48 - written seven so we move to seven one
1353:51 - move to one then move to two we move to
1353:54 - two then move to four four then move to
1353:56 - six six here Eight Is the End okay if we
1353:59 - move to 8 there then nothing is present
1354:01 - so from 5 to
1354:03 - 8 our uh this entry is written so it is
1354:07 - like this first go to 537 1 2 4 6 8 so
1354:11 - this is the first and this is the last
1354:14 - with the help of Master file what was
1354:16 - the full form Master file table we can
1354:19 - get the information about the middle one
1354:21 - blocks also
1354:23 - okay consider a consider a uni I node
1354:29 - structure that has has eight direct dis
1354:31 - block addresses and three indirect dis
1354:33 - block addresses namely single double and
1354:36 - triple okay dis block size is 1 kiloby
1354:39 - and each block can hold up to 128 disk
1354:41 - block
1354:42 - addresses calculate the maximum file
1354:44 - size with this IOD structure so we had
1354:47 - eight direct dis block three indirect
1354:49 - dis block namely single double and
1354:51 - triple okay so we have eight direct and
1354:53 - three indirect single double and triple
1354:55 - the size of one dis block is 1 KB and a
1354:58 - block can hold one 28 dis block
1355:00 - addresses okay so we have eight direct
1355:03 - dis block address so from here I can
1355:06 - get 8 KB directly from the direct dis
1355:10 - block addresses like here from direct I
1355:12 - got 8 KB from indirect now indirect has
1355:15 - three single double and triple from
1355:17 - indirect I'm going to get 128 into 1 KB
1355:20 - because a single block can store 128
1355:23 - addresses of the blocks so it will point
1355:26 - to 128 blocks each of size 1 KB so from
1355:29 - this indirect single I got 128 KB from
1355:32 - indirect double just two times for
1355:35 - triple take three times and all add all
1355:38 - of them you will get the maximum size
1355:41 - should I repeat okay what we had we had
1355:44 - eight direct dis block addresses and
1355:47 - each of size 1 KB so 8 KB I directly got
1355:50 - from here then I had three indirect dis
1355:53 - block dis block addresses of single
1355:55 - double and triple so I had the first one
1355:57 - is single the second one is double and
1355:59 - third third one is triple the single
1356:01 - block is going to point to 128 blocks
1356:04 - each of size 1 KB so this will point to
1356:07 - 128 this will contribute to 128 KB space
1356:10 - now the double
1356:11 - one this will point to an index block
1356:15 - this will point to 128 index blocks
1356:17 - which can point to 128 blocks each index
1356:20 - block is going to point 128 blocks and
1356:23 - one single block is going to point 128
1356:25 - index
1356:26 - blocks so 128 into 12 128 at this level
1356:30 - and 128 this level here 1 KB for each so
1356:34 - I'll get for double
1356:37 - 128 Square KB for
1356:41 - triple this will point to 128 index
1356:45 - blocks and this will again point to 128
1356:48 - index blocks and this will here now will
1356:50 - point to the 128 blocks each of size 1
1356:53 - KB 1 KB so 128 at this level 128 at this
1356:58 - level 128 at this level and 1 KB here so
1357:00 - I'll get 128 to^ 3 KB now when you add
1357:04 - all of them you get the total size the
1357:06 - maximum file size with this IOD
1357:09 - structure size of dis block address each
1357:12 - block is of size 1 KB it can store 128
1357:15 - dis blocks so each of size 1 KB so 8 K
1357:19 - bytes equals to 128 into DBA you can
1357:23 - just find it that DBA consist of 64
1357:27 - bytes is the file file size possible
1357:30 - over the given dis the maximum file size
1357:33 - we had was 2 GB and the maximum dis size
1357:37 - will be you remember how we can find the
1357:38 - maximum disc size 2 power DBA into
1357:43 - DBS so what is DBA DBA is 2^ 6 bytes so
1357:49 - it will be 2^ 2^ 6 which is 2^ 64 this
1357:53 - is way higher than 2 GB which is just
1357:55 - two uh 2^ 31 so yes this file is
1357:59 - possible over the given
1358:02 - disk okay yes so it is possible another
1358:06 - question the index node I node of a Unix
1358:09 - like file system has 12 Direct One 12 12
1358:13 - direct one single indirect and one
1358:15 - double indirect pointers the dis block
1358:17 - size is 4 KB and the disk block address
1358:19 - is 32 bit long the maximum possible file
1358:22 - size again the same pattern you can do
1358:24 - this same pattern we are going to follow
1358:26 - we get the answer as 4GB
1358:30 - the data blocks of very large file in
1358:32 - the Unix file system are allocated
1358:35 - using see if it is a very large file you
1358:38 - can see here you can see
1358:41 - here if I allot continuously I will get
1358:44 - very little memory I will get very
1358:47 - little space when I when I directly
1358:51 - given when I have directly pointed to
1358:53 - the blocks I got 8 KB when I had
1358:58 - indirect sing single extension then I
1359:01 - had 128 KB when I had double extension
1359:04 - then I had 2 power 14 KB triple
1359:06 - extension I had 2 power 16 KB so I
1359:08 - cannot uh I cannot allocate file of very
1359:12 - large uh size with continuous allocation
1359:15 - no index no this indexed allocation
1359:18 - somewhat gives a hope but here it is
1359:20 - written very large file so I would need
1359:23 - like triple or uh quadruple indirect
1359:27 - pointers I need like
1359:29 - this as I increase this number of blocks
1359:32 - here this 128 will keep on
1359:36 - multiplying in this manner with see we
1359:39 - are extending when we extend more I will
1359:41 - get more memory I will this will
1359:44 - contribute to the more space with with
1359:47 - the help of an extension of index
1359:48 - allocation the data blocks so very large
1359:51 - file in the Unix file system can be
1359:54 - allocated using large using a larger
1359:57 - Block in a fixed block size file system
1359:59 - needs to better disk throughput but poor
1360:02 - dis space utilization why poor because
1360:04 - we have internal fragmentation and why
1360:06 - better disk throughput because number of
1360:08 - bytes you can read with one dis XIs are
1360:10 - more so if I use a larger block size
1360:13 - then po dis utilization because of
1360:16 - internal fragmentation and better disk
1360:18 - throughput because we can read more
1360:20 - bytes with just one dis access another
1360:23 - question a file allocation table based
1360:26 - file system is being used and a total
1360:28 - overhead of of each entry in the file
1360:31 - allocation table is 4 bytes in in size
1360:35 - given a 100 into 10^ 6 bytes dis on
1360:40 - which the file system is stored and data
1360:42 - block sizes 10^ 3 bytes the maximum size
1360:45 - of a file that can be stored on dis in
1360:48 - units of 10^ 6 byte is so let's call 10^
1360:52 - 6 as
1360:53 - Sheba entry size is given as 4 bytes
1360:56 - here it is written four bytes now we
1360:58 - have to find number of blocks in the
1360:59 - file allocation
1361:01 - table so we call this 10^ 6 as Shiba and
1361:06 - so I will call this as the 100 shivba
1361:10 - this 100 into 10^ 6 by is 100 Shiva so
1361:13 - the number of blocks I get
1361:16 - as dis size upon block size so the dis
1361:20 - size is 100 shba and the block size is
1361:22 - this 10^ 3 so I'll get .1 Shiba blocks
1361:26 - in the file allocation table and you
1361:27 - know what Shiva is 10^
1361:29 - six okay now maximum file size will be
1361:33 - given dis dis size minus file allocation
1361:37 - table size because see here this part is
1361:40 - also going to consume some space this
1361:43 - will cause overhead so the maximum file
1361:45 - size will be the total dis size minus
1361:48 - overhead so how how much size I have the
1361:51 - total disc size is dis size is 100 shab
1361:54 - bytes and the file allocation or the
1361:57 - file allocation table what is the total
1361:59 - size of this4 shba how I got this point4
1362:03 - see the each entry size is4 the each
1362:07 - entry size is 4 byte and number of
1362:09 - entries are .1 sheiba so I'll get4
1362:12 - sheiba bytes for this uh file allocation
1362:15 - table size so the maximum file size can
1362:17 - be
1362:18 - 99.6 shab
1362:20 - bytes easy question just to confuse you
1362:23 - the main concept was the maximum file
1362:25 - size will be given dis size minus
1362:28 - overhead you have to also take account
1362:30 - of this file allocation table size see
1362:33 - this is not less if you if see I have
1362:36 - written Shiva here which is creating an
1362:39 - impression that it is so less this Shiva
1362:41 - is 10^ 6 now you can just imagine how
1362:45 - large this
1362:47 - is in the next lecture we will move to
1362:49 - the file management part
1362:52 - three consider a file system that stores
1362:55 - 128 dbas in the index table of the
1362:58 - directory
1363:00 - the block size is 4kb if the file size
1363:02 - is less than 128 blocks then these
1363:05 - addresses act as direct data block
1363:07 - address however if the file size is more
1363:10 - than 128 blocks then these 128 address
1363:14 - in the index table point to the next
1363:17 - level index block Each of which contain
1363:19 - 256 data block address so this is what
1363:21 - it is if the file size is more than 128
1363:24 - block then it will point to the block it
1363:27 - will point to 128 block each block will
1363:29 - point to 12 256 blocks each of size 4 KB
1363:34 - so 128 into 256 into 4
1363:40 - KB you're getting the point these
1363:44 - are these are 128 blocks each block will
1363:48 - point to 256 blocks or I can say now
1363:53 - here they are the direct data blocks so
1363:55 - these 128 blocks will point to
1363:59 - 128 into 256 data blocks each of size 4
1364:05 - KB so what is the maximum file size in
1364:08 - the system if the file size is less than
1364:10 - 512 KB then 128 address act as the
1364:15 - direct data address if the file size is
1364:17 - more than 512 KB then this way it will
1364:20 - work so the maximum file size is 128 MB
1364:23 - now don't wonder where I got this 512
1364:26 - just multiply them 2^ 7 into 2^ 2 by
1364:31 - that is 512
1364:35 - KB this 512 is the limit for direct
1364:38 - addressing if the file size exceeds this
1364:41 - 512 then we need to move to the indirect
1364:44 - and how the indirect will work here it
1364:46 - is given so following that we find that
1364:49 - the maximum file size is 128 into 256
1364:52 - into 4 KB now calculate we'll get 128 MB
1364:56 - another
1364:57 - question a file system system with a one
1364:59 - level directory structure is implemented
1365:02 - on a disc with a dis block size of 4 KB
1365:04 - each block has a size of 4
1365:07 - KB the disk is used as follows dis block
1365:11 - zero contains the boot control block so
1365:13 - the boot control block will take up size
1365:15 - 4
1365:16 - KB dis block one it contains file
1365:18 - allocation table consisting of 10 bit
1365:23 - entry per data block representing the
1365:25 - data block address of the next data
1365:27 - Block in the files so this file location
1365:29 - also consumed 4
1365:31 - KB block two and three will contains the
1365:33 - directory 32 32-bit entry per file so
1365:37 - this will consume 8 KB block four now
1365:41 - here we have we have the actual data
1365:43 - blocks so this was just the overhead and
1365:46 - from now we got to the actual data
1365:48 - blocks so the question is what is the
1365:50 - maximum possible number of
1365:53 - files this is what it looks like boot
1365:56 - control block for dis block zero block
1365:58 - one contains is the file allocation
1366:00 - table each entry is of 10
1366:03 - bits directory of 8 KB because we are
1366:07 - using two blocks here and the entry is
1366:10 - the entry size is 32bit from here we got
1366:13 - the data blocks so the maximum number of
1366:16 - files and maximum file size we have to
1366:19 - calculate the directory is taking 8 KB
1366:22 - and what is the entry size the entry
1366:24 - size is 4 bytes so the number of files
1366:28 - directory points to to what the file
1366:31 - each the entry is taking 4 byte and the
1366:33 - total size is 8 KB so how many addresses
1366:35 - are there 2K addresses which means how
1366:37 - many entries are there 2K entries which
1366:39 - mean how many files are there 2K
1366:42 - files and the file allocation table
1366:45 - contains 10 bit which is nothing but the
1366:48 - data block address because in file
1366:50 - allocation one this block will point to
1366:53 - the block which we have to go to the
1366:55 - next my English is so bad in file
1366:59 - allocation table this block will point
1367:02 - to the the block which we have to go
1367:05 - next so this will be the F entry of 10
1367:09 - bit it is nothing but the data block
1367:11 - address so what will be the maximum file
1367:13 - size we have done this kind of question
1367:16 - what is maximum file
1367:18 - size the dis size minus overhead what is
1367:21 - dis disk size the total number of blocks
1367:23 - into block into block size how many
1367:26 - blocks are present 2 power DBA so one24
1367:30 - blocks are present each of size 4 KB now
1367:32 - control overhead we have four blocks for
1367:34 - this each block is of size 4 KB so 16 16
1367:39 - KB is used up here so 2^ 12 minus 16 KB
1367:42 - is around 480
1367:44 - KB so this is the maximum file size and
1367:47 - number of files is 2K see this was an
1367:51 - super easy question nothing extra was
1367:54 - there you just have to calculate the
1367:55 - number of files and maximum file size
1367:57 - where can I get the number number of
1367:59 - files I got the number of files from
1368:00 - directory because directory in directory
1368:03 - the entries point to the
1368:05 - files and from we know the size of the
1368:09 - directory and size of each entry from
1368:11 - there we will get the number of entries
1368:13 - number of entries will tell me the
1368:15 - number of files so easy and the second
1368:17 - was maximum file size how can how can I
1368:20 - calculate the maximum file size total
1368:22 - dis size minus overhead we know what is
1368:25 - overhead this is overhead these four
1368:27 - blocks are overhead each of size 4 KB so
1368:30 - overhead is 16 KB now what is the dis
1368:34 - size the total blocks total
1368:37 - blocks into size of each block how many
1368:41 - total blocks are there how I'm going to
1368:43 - get that with this we know that f8
1368:46 - contains the block addresses and the
1368:48 - block address is of 10 bits so DBA we
1368:51 - are given with 10 bits so I can find the
1368:53 - total number of blocks are 2 10 each of
1368:56 - size 4 KB so from here I got the disk
1368:59 - size and then when I subtracted the disk
1369:02 - size minus control overhead I get the
1369:05 - maximum file size in the next lecture we
1369:07 - will see disk Free Space Management
1369:17 - algorithms disk Free Space Management
1369:20 - algorithm I'm given that the dis size is
1369:23 - of 20 bit 20 bytes DBS is of 1 KB and
1369:26 - DBA is of 16 bits
1369:29 - what will be the number number of
1369:31 - blocks so you may proceed with the two
1369:34 - ways either you divide the disk size
1369:36 - with the block size and you get 20K
1369:38 - blocks or you can directly go there and
1369:42 - do like this this will also give you the
1369:44 - number of blocks so which is correct
1369:46 - this 20K is correct or 64k is
1369:50 - correct I'll speak again I have dis size
1369:54 - of 20 MB and the block size is 1 KB now
1369:58 - if someone ask me the number of blocks
1370:00 - it will be dis size upon block size
1370:02 - which will give me 20K blocks but I'm
1370:05 - also given with the dis block address
1370:07 - which is 16
1370:09 - bits you will say you taught me that 2^
1370:12 - 16 will also give me the number of
1370:14 - blocks so which one is correct thises
1370:17 - 20K is correct and or 64 is
1370:20 - correct that's what I'm asking is 20K
1370:23 - correct or 64k
1370:25 - correct the answer is 20K is correct
1370:30 - this is the maximum possible so this 64k
1370:33 - is the maximum possible number of blocks
1370:36 - I have told you so many time what is the
1370:37 - maximum size of the disc the maximum
1370:40 - size of the disc is 2^ DBA
1370:43 - into this this is the maximum size and
1370:48 - this is the given
1370:51 - size DBA equals to 16 bit so the maximum
1370:56 - number of blocks that that can be there
1370:59 - is
1371:00 - 64k and this 20K are the the number of
1371:04 - blocks which are there this is can and
1371:07 - this is R
1371:10 - okay to refer 20K blocks how many bits
1371:13 - are needed five bits for that 20 and 10
1371:17 - for this scale so I'll get 15 bits is
1371:19 - needed so we need 15 bits but are using
1371:23 - 16 bits so the maximum possible disc
1371:26 - size is 64 MB that is maximum possible
1371:30 - number of blocks into block size but
1371:32 - what is the given dis size is 20 MB so
1371:35 - the given dis size will always less than
1371:37 - the maximum possible now you may wonder
1371:40 - what is the what is the difference
1371:42 - between given and maximum what is this
1371:44 - I'm talking about the free space
1371:47 - available I'm talking about the free
1371:49 - space available what can be the maximum
1371:52 - amount of free
1371:55 - space and what is the available free
1371:57 - space this is
1371:59 - so now the thing is clear to you this is
1372:03 - the available disk size and this will
1372:06 - give me the maximum disk size so these
1372:08 - are the available number of blocks which
1372:11 - are free these is the maximum number of
1372:14 - blocks which can be free okay now I
1372:17 - think the point is clear so there are
1372:20 - 20K blocks which are free so I can store
1372:23 - these 20K in form of Link list link list
1372:26 - of free blocks so initially the chain of
1372:28 - of 20K free blocks will be present
1372:30 - suppose out of these out of these 20K
1372:34 - blocks I want to allot some block to the
1372:37 - file let's say I want to allot these 20
1372:40 - out of these 20K I want to allot 10
1372:42 - blocks to the to some file what I will
1372:45 - do I will delete 10 blocks from this 20K
1372:48 - linked list and allot to the file and
1372:51 - allocate initially a chain of 20K free
1372:54 - blocks if I want to allocate some blocks
1372:56 - to the file let's say 10 blocks then
1372:58 - delete those 10 blocks from the linked
1373:00 - list and allocate as simple as that this
1373:03 - is what or this is what is the linked
1373:06 - list of free blocks if I allocate some
1373:08 - file to that block then that block won't
1373:10 - remain free that's why we are deleting
1373:12 - the blocks which I allowed to a file now
1373:16 - comes the free list this is list linked
1373:19 - list of blocks containing address of the
1373:21 - free blocks this is what the free list
1373:23 - is we are not maintaining the linked
1373:26 - list of the blocks we are maintaining
1373:29 - linked list of those blocks which
1373:32 - contain address of the blocks we are not
1373:34 - containing the we are not maintaining
1373:36 - the linked list of the data blocks we
1373:38 - are maintaining the linked list of the
1373:39 - address blocks which contain the address
1373:41 - of those free data blocks the point is
1373:44 - clear how many blocks of the free list
1373:47 - are needed to store 20K free data blocks
1373:51 - so let's
1373:52 - say the entry of or how many bits we are
1373:55 - using we are using 16 bits
1373:58 - and let's say x are the number of
1374:01 - entries what is the block size 1 KB so I
1374:04 - can store 512 addresses in one block so
1374:08 - I can store 512 addresses in one block
1374:11 - so how many blocks I need to store these
1374:14 - 20K block I can store 512 addresses in
1374:18 - one block let's say I need y blocks to
1374:22 - store the 20K so I got y = to 40 so I
1374:26 - need
1374:29 - 40 address block which contain each of
1374:33 - those address block which contain 512
1374:35 - addresses off block this will sums up to
1374:38 - 20K blocks the third is bit map or
1374:42 - vector it keep track of all the block
1374:44 - unlike free list see free list only kept
1374:49 - or linked list only kept the track of
1374:52 - those blocks which are free but this bit
1374:54 - map is going to keep track of all the
1374:57 - blocks ass associate a binary bit to
1374:59 - each block we are associating a binary
1375:01 - bit to each block doesn't matter whether
1375:03 - it is free or some file f
1375:05 - file why am I staming so much or some
1375:08 - file is allocated to that block doesn't
1375:11 - matter zero will be for the free and one
1375:13 - will be for
1375:15 - inuse what does this suggest that first
1375:18 - block is free what does this suggest the
1375:21 - second block is in use in this manner
1375:23 - you go so how many how many bits will be
1375:26 - there the number of bits will be equal
1375:28 - to the number of blocks how many blocks
1375:30 - are there 20K blocks so I will have 20K
1375:34 - bits so how many blocks are needed to
1375:37 - store our bit map see the total number
1375:39 - of bits we needed are 20K and in one
1375:42 - block how many bits are stored these
1375:44 - many bits so I'm going to need three
1375:46 - blocks to store the bit
1375:49 - map free list is faster as it keep track
1375:53 - of free blocks only no need to search
1375:55 - but here we need to search for some
1375:57 - block let's say I want to allocate 10
1375:59 - blocks to some file I want to allocate
1376:02 - 10 blocks to some file here what we did
1376:05 - we just deleted the 10 blocks from the
1376:07 - chain of Link list and given to them
1376:09 - here what we did we just deleted those
1376:12 - 10 addresses from some block and here
1376:14 - what we did we need to search for the 10
1376:17 - blocks which are free here searching
1376:19 - time will be
1376:21 - extra okay so free list or the linked
1376:24 - list is faster as it keep track of only
1376:27 - free blocks no need to search it keep
1376:30 - track of the binary map the bit map or
1376:34 - vector keep track of all the blocks
1376:36 - unlike free list so we need to search
1376:38 - which blocks are free the fourth is
1376:41 - counter method when we have continuous
1376:43 - free blocks then what we did we just
1376:45 - write the starting free dis block
1376:48 - address and the number of continuous
1376:50 - free dis blocks so from block five to 45
1376:55 - more
1376:56 - blocks till this the memory is free from
1377:00 - this from disk block address 85 to 200
1377:04 - more blocks the memory is free so this
1377:06 - is how we write let's say we have a file
1377:09 - of 20 blocks now which block we need to
1377:11 - allocate similar to what we did in the
1377:14 - partitioning we will follow the same
1377:16 - policy first bit worst fit and the best
1377:19 - fit first bit is Select from the first
1377:21 - entry if the number of free blocks are
1377:24 - greater than the number of the blocks
1377:27 - which file require alloted what does
1377:29 - best fit
1377:30 - say choose the least difference the
1377:33 - number of free blocks minus the blocks
1377:35 - which file require choose that block
1377:38 - which has this least difference so here
1377:41 - the difference is just five here the
1377:43 - difference is 25 here the difference is
1377:45 - 180 here the difference is 105 so I will
1377:49 - choose the block which has the least
1377:50 - difference
1377:52 - between the block which are available
1377:54 - and the block file needs
1377:58 - okay and after allocation we need to
1378:01 - update the tle also see if I allocated
1378:03 - let's say I allocated 20 block to this
1378:06 - now how much are free only five are free
1378:09 - so I have to update that tle also you
1378:12 - know what is tle the record so we have
1378:14 - to update the record
1378:16 - also consider a disk with B blocks F of
1378:20 - which are free disk block address is
1378:23 - dbits disk block size is X bytes we have
1378:26 - to calculate the given dis size maximum
1378:29 - possible disk size and relation between
1378:31 - B and D okay so this is simple and
1378:34 - straightforward question number of
1378:36 - blocks which we have is B what is the
1378:39 - size of each block X so this is the
1378:41 - given dis size dis size some of you make
1378:45 - a mistake of writing F into X see here
1378:50 - nowhere is written give me the dis size
1378:52 - which is free or give me the amount of
1378:55 - total space available for the files to
1378:57 - be allocated or nothing like that is
1379:00 - written there's nowhere asked the free
1379:03 - disk size it is written that given disk
1379:05 - size so the answer will be given dis
1379:08 - blocks into size of each block
1379:11 - simple maximum possible dis
1379:14 - size maximum possible blocks are 2^ D
1379:17 - and size of each block is X this is the
1379:19 - answer the relation between B and D you
1379:22 - know the relation between these two that
1379:24 - the given dis size is always less than
1379:26 - equal to maximum I can write BX is less
1379:30 - than equal to 2^ DX I cancel X from both
1379:33 - side I got B should be less than equal
1379:35 - to 2^ D this is the
1379:38 - relation what is the condition in which
1379:41 - free list uses less space than bitmap
1379:44 - firstly we have to calculate what we
1379:46 - have to calculate the size of free list
1379:49 - what was free list fre list contain
1379:51 - blocks which contain addresses of the
1379:53 - data blocks and these these blocks which
1379:56 - contain addresses of the data blocks are
1379:58 - connected in form of linked list so this
1380:01 - was free list now what will be the size
1380:03 - of free list see each block contain the
1380:07 - addresses so if I have to find the total
1380:11 - size of free list then I have to find
1380:13 - the total number of free blocks into
1380:17 - addresses of each block address size of
1380:20 - each block total number of free blocks
1380:22 - into address size of each block what is
1380:24 - the address size the address size of
1380:26 - each block is d so F into D will be the
1380:29 - size of free
1380:30 - list see don't complicate it we have
1380:36 - blocks in which addresses are there if I
1380:40 - see you okay let's keep it simple if I
1380:42 - see you this is the complete free list
1380:45 - it
1380:46 - contained it contained addresses of the
1380:49 - free blocks what will be the size of
1380:51 - this free list address size of one data
1380:54 - block into number of data blocks
1380:59 - or I can write address size of one entry
1381:03 - into number of entries and how many
1381:04 - entries will be there number of entries
1381:06 - will be number of free blocks so what is
1381:08 - the address size d what is the number of
1381:10 - entries F so F into D will be the size
1381:13 - of free list what will be the size of
1381:16 - bit map the size of bitmap will
1381:19 - be number of
1381:23 - blocks in
1381:25 - bits if you remember what was bit map
1381:28 - let's say I have 20K blocks so I will
1381:32 - have 20K bits here how many blocks I
1381:36 - have B blocks so I'll have B bits so the
1381:40 - condition in which free list uses less
1381:42 - space than bit map will be F into D
1381:45 - should be less than b that's
1381:47 - it this is the space used by free list
1381:52 - and this is the space used by
1381:55 - bitmap it's simple
1381:58 - question number two the beginning of
1382:01 - free space bit map looks like this after
1382:03 - the disk partition is first formated we
1382:07 - have this the first block is used by the
1382:10 - root directory the system always
1382:12 - searches for free blocks starting at the
1382:14 - lowest numbered block so after writing
1382:17 - file a which uses six blocks the bit map
1382:20 - looks like this so for six
1382:23 - blocks we'll have six ones 1 2 3 4 5 six
1382:28 - the first one is always there for the
1382:30 - root the root directory so the system
1382:33 - always searches for free blocks starting
1382:35 - at the lowest numbered block so after
1382:37 - writing file a which uses six blocks the
1382:39 - bit map looks like this this is for the
1382:41 - root and this six ones are for this file
1382:45 - a map after each of the following
1382:47 - additional actions as hex code what is
1382:51 - hex code in the hexagonal file B is
1382:54 - written Now using five blocks okay so
1382:57 - this was was just the
1382:58 - example okay so if I have written file B
1383:01 - then what will
1383:02 - happen so this a was the example but
1383:05 - here it is written additional actions
1383:08 - see this a will be counted and then
1383:11 - these actions are performed here it is
1383:12 - written already that additional
1383:14 - actions initially we have let me Zoom it
1383:18 - initially we have this one for the root
1383:21 - and rest all zero so I will write this
1383:24 - is 8 and this is 0 0 and 0 so XX will be
1383:27 - 8 ,000 then what happened file a is
1383:31 - allocated six blocks so one was for the
1383:33 - root 1 2 3 4 5 6 this is for a so this
1383:39 - is 0o this is z what is this triple 1 0
1383:43 - this is e in hexagonal and what is 1 1 1
1383:46 - 1 this is 15 so F represent 15 in
1383:49 - hexagonal this is what this is 14 this
1383:51 - is 15 this is 0 this is 0 so I have
1383:53 - written F e0 0 so file B is written
1383:57 - using five blocks okay now file a is
1384:01 - deleted file B is written using five
1384:03 - blocks so this was till a then 1 2 3 4 5
1384:09 - these five blocks are given to file B so
1384:12 - f f f for this this is 15 this is 15
1384:15 - this is 15 and then zero f f F0
1384:19 - for this file B is written using five
1384:22 - blocks now what happens file a is
1384:24 - deleted when file a is deleted so
1384:28 - this was for the file B this was for the
1384:30 - root and all the ones which we have made
1384:33 - for a which means these ones will be
1384:35 - made to zero because the file a is
1384:37 - deleted so those block will be free now
1384:39 - and for free what we write we write zero
1384:42 - now we have 81 fo this is 8 this is 1
1384:45 - this is f and this is
1384:47 - zero file C is written using eight
1384:50 - blocks now file C is written so where we
1384:52 - will write file file c 1 2 3 4 5 6 the
1384:57 - blocks which we which were initially
1384:59 - given to a which are now freed will be
1385:02 - given to C so six for six here and two
1385:06 - here two additional now what is the uh
1385:09 - hex 15 15 15 and
1385:13 - C now what happened file B is deleted so
1385:16 - what were the ones for file B these were
1385:18 - the ones so delete them these ones are
1385:20 - gone so I have f e that is 14 0 and
1385:26 - C this way this will be the answer it
1385:28 - was easy one nothing special was
1385:31 - there a file system uses an inmemory
1385:34 - cache to cash dis blocks the Mis rate of
1385:37 - the cash is shown in the figure so here
1385:39 - is the Mis rate this is the cash size
1385:41 - and this is the Mis rate when we
1385:44 - have when we have let's say 30 MB of
1385:47 - cash then the Miss rate is 40% when we
1385:50 - have 20 MB of cash then the Miss rate is
1385:52 - 60% when we have 50 mb of cash then the
1385:55 - Miss rate is 30% as we increase the cash
1385:57 - size it is obvious that Mis rate will
1386:01 - decrease the read the latency to read a
1386:03 - block from the cach is 1 millisecond and
1386:05 - to read a block from the dis is 10
1386:07 - millisecond assume that the cost of
1386:09 - checking whether a block exist in the
1386:12 - cash is negligible available cash size
1386:14 - are in multiples of 10 MB so the
1386:16 - question is the smallest cache required
1386:19 - to ensure that the average read latency
1386:22 - of less than 6 milliseconds so what will
1386:25 - be the read read latency suppose p is
1386:28 - the Mis rate so I can write p and when
1386:31 - it is a Miss then I'll have to read from
1386:33 - memory plus when it is a Miss then I can
1386:36 - read from cach should be less than 6
1386:39 - millisecond so it is 10 p + 1 minus P
1386:44 - should be less than 6 so it is 9 P less
1386:47 - than 5 so P should be less than 5 by 9
1386:49 - it's around
1386:51 - 55% so the Mis rate Mis rate should be
1386:57 - less than
1386:59 - 55% so where is 55% 55% is somewhere
1387:04 - here see now the cash can be either 20
1387:09 - or 30 I have written that Mis rate
1387:12 - should be less than 55% if I choose 30
1387:15 - so if I choose 20 then the Mis rate will
1387:17 - be greater than uh greater than 55% it
1387:20 - will be 60 and if I choose 30 then it
1387:24 - will be less than 55% that is 40
1387:28 - so either 60 or 40 what I have to choose
1387:31 - the Lesser one that is 40 so where I
1387:33 - will get the Lesser one 30 so the
1387:35 - smallest cash smallest cach which is
1387:39 - required to ensure that average read
1387:41 - Laten is less than 6 millisecond or I
1387:43 - can say the smallest cash required to
1387:45 - ensure that Miss rate is less than
1387:47 - 55% is
1387:50 - 30 see smallest I can either choose 20
1387:53 - or 30 but P should be less than 55% here
1387:58 - the p is greater than
1388:00 - 55% see 20 is smaller than 30 but I am
1388:03 - also increasing the Mis rate I don't
1388:05 - want to increase the Miss rate so the
1388:07 - smallest cash will be 30 to ensure that
1388:11 - the average read latency is less than 6
1388:14 - millisecond okay so this is what I have
1388:17 - written latency of cash is 1 millisecond
1388:19 - latency of dis is 10 millisecond so the
1388:21 - read latency should be less than 6
1388:23 - millisecond I write the latency formula
1388:25 - here less than 6 9 p is less than 5 I
1388:29 - got 55% and the Mis rate is p so cash is
1388:32 - in size of alpha into 10 MB which means
1388:35 - the multiple of 10 MB so according to
1388:37 - the graph I can choose 30 only if I
1388:41 - choose the smaller one if I choose the
1388:42 - smaller one that is 20 then the average
1388:46 - average read latency will exceed the 6
1388:48 - millisecond if I choose 30 then it is
1388:52 - perfect 30 is the smallest one if I
1388:54 - choose 40 yes it is less than in 40 p is
1388:58 - less than uh 55% but 40 is not the
1389:02 - smallest the smallest is asked so 30
1389:05 - will be the answer 30 MB is the
1389:07 - answer the amount of disk space that
1389:10 - must be available for page storage is
1389:12 - related to maximum number of processes n
1389:16 - the number of bytes in the virtual
1389:18 - address space is B and the number of
1389:20 - bytes in Ram is R give an expression of
1389:23 - the worst case disk space required let
1389:26 - us read the question again the amount of
1389:28 - dis space that must be available for
1389:31 - page storage is related to maximum
1389:33 - number of process n okay the number of
1389:36 - bytes in the virtual address space is B
1389:38 - and the number of bytes in the ram is R
1389:42 - give an expression of the worst case dis
1389:44 - space required see for the dis space
1389:47 - there is no relation of or there is no
1389:49 - need of this Ram thing to be given I can
1389:52 - ignore this ram ram thing because the
1389:54 - RAM and the disk space no relation
1389:57 - because we want to allocate the dis
1390:00 - space see in case of uh let me explain
1390:05 - with the help of this diagram suppose I
1390:07 - have a process Pi where is this mapped
1390:10 - where this virtual address piece is
1390:11 - mapped it is mapped onto the disk not on
1390:13 - the physical address
1390:14 - space physical address space is going to
1390:17 - be much lesser than the virtual address
1390:18 - space this virtual address space is
1390:20 - mapped onto the disk suppose now comes
1390:23 - another process then this virtual
1390:25 - address space will also going to be maed
1390:27 - on the
1390:28 - disk so the worst case the worst case
1390:32 - disk space required will be number of
1390:34 - process into size of each process which
1390:36 - is this virtual address space so n into
1390:38 - B will be the answer there is no need of
1390:40 - R being given so n into B is the answer
1390:44 - in the next lecture we will start with
1390:45 - the dis scheduling
1390:48 - algorithms dis scheduling just like CPU
1390:51 - can serve one process at a time
1390:53 - similarly the disk can only serve one IO
1390:56 - request at a time
1390:57 - just like shortterm scheder disk scheder
1391:01 - also
1391:01 - exist let's move directly to the dis
1391:04 - scheduling
1391:06 - techniques suppose the process request
1391:09 - this track or cylinder number cylinder
1391:11 - number 98 then the process want to
1391:14 - process want the read right head to go
1391:16 - on 183 then on 37 then on 122 14 124 65
1391:21 - and then in the end
1391:22 - 67 suppose the read right head is at 53
1391:28 - so total there are from 0 to 199 200
1391:32 - tracks are dist distributed evenly on
1391:34 - the surface on the surface there are 200
1391:37 - tracks in such a way and read right head
1391:39 - is currently on track number
1391:42 - 53 and what requests are made 98 183 37
1391:46 - in such manner requests are made the
1391:49 - first algorithm that is fcfs what does
1391:52 - this say as as the request comes serve
1391:55 - them in that order only first come first
1391:58 - sir so from 53 it will first go to 98
1392:01 - from 98 it will go to 183 from 183 it
1392:04 - will go to 37 as the request order came
1392:07 - 9 98 183 37 from 37 it will go to 122
1392:12 - from 122
1392:14 - to I think 14 yes and then 14 after 14
1392:19 - then to
1392:20 - 124 and then to 65 and then to 67 so in
1392:24 - this manner the request will be served
1392:26 - first first come first serve as the
1392:29 - request comes or the order in which the
1392:31 - request is made serve in that order only
1392:34 - this is what the fcfs says so total six
1392:37 - how many are made see from 53 to 98 from
1392:40 - 98 to 183 from 183 to 37 in this manner
1392:45 - you have to calculate the total se you
1392:46 - will get the total seeks are
1392:49 - 640 average seek per request will be
1392:52 - total number of six upon number of
1392:54 - requests so I have around 86 per request
1392:58 - which is a high number now comes the
1393:00 - shortest seek time
1393:02 - first you have this this you have this
1393:05 - request order suppose the read right
1393:08 - head is now 53 serve those request first
1393:11 - in which there will be least seek time
1393:15 - nearest closest track next this is the
1393:18 - another name nearest or closest track
1393:21 - next so from 53 I will go to 65 from 65
1393:24 - to 67 67 to 37 then 14 then 998 then 120
1393:29 - you have to choose the closest
1393:32 - one on when on 53 what was the closest
1393:36 - track you can go on the 65 then 67 on 67
1393:41 - which is the closest track you can go to
1393:43 - 37 so in this manner you have to proceed
1393:46 - and here the total number of ss were 640
1393:49 - and now see the total number of six it
1393:51 - has reduced drastically it is now just
1393:54 - the
1393:55 - 236 so the first first one was fcfs
1393:58 - algorithm serve in the order as the
1394:01 - request order comes serve in that order
1394:03 - only B part was go to the nearest or
1394:07 - serve the nearest or closest track
1394:10 - next this will give you the least amount
1394:13 - of seeks then comes the scan algorithm
1394:16 - top to bottom and bottom to top serving
1394:19 - for scan apart from knowing the position
1394:22 - of read right head should also know the
1394:24 - direction so from here what are you
1394:26 - going to do
1394:27 - see here from
1394:30 - 53 let's say the direction is in this
1394:32 - manner so I will go like this till 99
1394:35 - and whichever request comes in the
1394:37 - middle I'm going to serve them see from
1394:40 - I have started from 53 53 to 65 65 to
1394:43 - 667 then 98 then 122 then4 then 183 now
1394:47 - remember 183 was the last request made
1394:51 - but what happens it has to do the
1394:55 - complete round and then then turn at 199
1394:58 - so from 183 it has to go to 199 to
1395:01 - complete the to complete the round or to
1395:04 - change the direction it can change
1395:05 - direction on the extreme points only
1395:08 - what will happen so I'll go start with
1395:11 - 53 and then I should also know the
1395:13 - direction in which I'm going I'm going
1395:15 - in this direction so from 53 to 65 from
1395:18 - 53 go till 199 which is the end and
1395:21 - whichever request comes in the middle
1395:23 - serve them and then take the turn so
1395:25 - when you will take the turn
1395:28 - then comes what then you have two
1395:30 - requests remaining the 37 and the 14 so
1395:32 - 37 will come first and then the 14 now
1395:35 - you don't have to take the turn again
1395:37 - that's why you are not going to the
1395:39 - extreme end you just completed where the
1395:41 - your last request was that is 14 got the
1395:44 - point in fcfs we served in the order
1395:47 - which in which the request was made okay
1395:51 - so first uh at 53 the first request
1395:54 - first request was 98 so from 53 I will
1395:56 - go to 9 8 then the second request was
1395:58 - 183 so from 98 I'll go to 183 in this
1396:01 - manner I served all the request and the
1396:04 - total number of seeks I got was 640 the
1396:06 - second algorithm is shortest seek time
1396:09 - first and this serve the nearest or
1396:11 - closest track next so from 53 the
1396:14 - nearest track to which I can serve is 65
1396:18 - from 65 the near nearest track is 67 in
1396:21 - this manner I proceeded and completed or
1396:24 - the served all the request the then
1396:27 - comes the scan algorithm top to bottom
1396:29 - and bottom to top serving so it is just
1396:31 - like the direction you can start from 53
1396:33 - to 199 so this is what bottom to top
1396:37 - from less to more and you should
1396:40 - remember this point that in a scan
1396:43 - algorithm to take the backward turn or
1396:46 - to take any turn you need to go to the
1396:48 - last you can take turns on the extreme
1396:51 - only so from 183 to 199 this was
1396:54 - actually not useful but to take the Le
1396:57 - we need to go to the extremes okay so
1397:01 - the what is the drawback extra seeks
1397:04 - plus starvation to the process in
1397:05 - opposite direction let's say from 53 to
1397:09 - this
1397:10 - 199 it took so many
1397:13 - time that it it takes so many so much
1397:15 - time that this 37 and 14 are being
1397:19 - starved
1397:20 - suppose the read right head is at let's
1397:23 - say 12 the read right head is at 12 and
1397:27 - the last uh track can is at
1397:30 - 1,000 and one request is at 6 one one uh
1397:36 - one process request the sixth track
1397:39 - number so from I will first serve from
1397:42 - 12 to 13 14 till th000 and then I will
1397:45 - turn back and will reach to the six so
1397:47 - this this six will be starred for star
1397:50 - for so much time so what was the
1397:53 - drawback extra six plus star with
1397:56 - equation to the process in opposite
1397:58 - direction because you have to go till
1398:00 - the end to take the
1398:03 - turn this was scan the first was fcfs
1398:06 - serve in the order of the request the
1398:08 - second was shortest seek time serve the
1398:11 - nearest track first then scan go in One
1398:14 - Direction and then in that direction
1398:16 - whichever request process made keeps on
1398:18 - keep on serving it and then when you
1398:21 - have to take the turn you have to go to
1398:23 - the extreme this was a scan now comes
1398:25 - the look in instead of going to the last
1398:28 - take the turn at the last request
1398:30 - exactly rest exactly like this SC so
1398:32 - what will
1398:34 - happen same manner I will go till 183
1398:37 - now the look algorithm gives an extra
1398:40 - Edge that I have I do not have to go to
1398:44 - the extreme to take the turn I can take
1398:46 - the turn at the last request only also I
1398:49 - can take the turn at the last request
1398:51 - also no need to go to the extreme this
1398:53 - is what the benefit of L algorithm and
1398:57 - the rest is exactly like this scan what
1398:59 - does look say wherever your read right
1399:02 - head is go into the direction whichever
1399:04 - is specified keep on serving the uh
1399:07 - request made and at the last request of
1399:10 - that direction you can take the turn in
1399:12 - a scan I have to
1399:14 - go beyond the last request so that I can
1399:17 - take turn on the extremes here no need
1399:20 - to go to the
1399:21 - extremes now comes the C scan the
1399:23 - circular
1399:25 - scan in circular scan you can go in One
1399:28 - Direction only so you started from 53
1399:32 - you keep on serving and at 19 199 you
1399:36 - have to take the turn but remember you
1399:38 - cannot serve while going in this
1399:40 - direction you can serve in One Direction
1399:42 - only so from 53 you need to go to 199
1399:45 - and after 199 you have to travel back to
1399:49 - zero and then move in this direction
1399:51 - again to serve the 14 and 37 you got the
1399:55 - point in C scan the circular scan you
1399:58 - can serve in One Direction only so from
1400:00 - 53 to 199 you made the six and then from
1400:04 - 199 to Zer back so that you can move
1400:07 - again in this direction to serve the
1400:09 - remaining 14 and 13 so how many six will
1400:11 - be made from 53 to 199 and 199 to 0 and
1400:16 - then 0 to
1400:18 - 37 remember that these six will also be
1400:22 - counted when you are coming back this
1400:24 - will also be counted
1400:27 - okay now comes the C look
1400:30 - similar what does the look algorithm
1400:33 - gives facility or what facility does the
1400:35 - look algorithm gives the look algorithm
1400:37 - says you need not to go to the extreme
1400:40 - to take the turn you can take the turn
1400:42 - at the last request also so if I ask you
1400:45 - what is circular look similar from 53 to
1400:49 - 183 and then when you come back no need
1400:52 - to go to the extreme from 14 you can uh
1400:55 - go to the 307
1400:57 - but remember it can serve in One
1400:58 - Direction
1400:59 - only now let us summarize again all the
1401:02 - algorithms the first was the fcfs in
1401:05 - fcfs what we did we served in the
1401:09 - request order the order in which the
1401:11 - request was made I served in that order
1401:14 - only then comes the shortest seek time
1401:17 - first serve the closest track then comes
1401:21 - the scan go in One Direction keep on
1401:24 - serving the request in that direction
1401:26 - and then in the end after going to the
1401:29 - extreme you can take the turn and when
1401:31 - you are coming back whichever
1401:34 - process whichever process requests are
1401:36 - made in that direction you can make but
1401:38 - no need to go again to zero
1401:40 - because I do not have to take turn again
1401:44 - see from 53 to 99 I moved in One
1401:47 - Direction now I have to take turn that's
1401:49 - why I have to go to the
1401:51 - 199 otherwise if the request were only
1401:54 - from 53 to 183 then I will just go in
1401:56 - this
1401:57 - direction but now what happens I have
1402:00 - two other request waiting for me on the
1402:02 - other side so I have to go beyond 183 to
1402:07 - the extreme take the turn and serve in
1402:09 - that order now there is no request on or
1402:13 - there is no request which demand the
1402:14 - U-turn again so I will not go to the
1402:16 - extreme I just end at the 14 okay this
1402:19 - was scan then comes the look similar to
1402:22 - scan but what facility it gives no need
1402:25 - to go to the extreme to take the turn
1402:26 - you can take the turn at the last
1402:28 - request also so I'll go from 53 to 183
1402:32 - and then from 183 I will go back to 37
1402:35 - and 14
1402:36 - end C scan you can serve in a single
1402:40 - Direction only and you have to count
1402:43 - when you are coming back you have to
1402:44 - count those six also so from 53 to 199 I
1402:47 - will go and then from 199 to 0 and 0 to
1402:50 - 37 the see look the look algorithm
1402:53 - always gives the facility do not go to
1402:55 - the extremes 53 to 183 from 183 back to
1402:58 - 14 and then 37 so instead of going to
1403:01 - 199 and 0 it goes to 183 and 14 only
1403:05 - okay in the next lecture we will see
1403:07 - some problems on it then our file
1403:09 - management section will be
1403:11 - over after that we will start our
1403:13 - miscellaneous
1403:22 - topics consider a dis que with a request
1403:24 - for io2 blocks on cylinders same as trct
1403:27 - number 47 38 121 191 87 11 9210 the cook
1403:33 - scheduling algorithm is used the head is
1403:35 - initially at a cylinder number 63 moving
1403:38 - towards largest cylinder number on its
1403:40 - serving path so we are given with a
1403:42 - current head location and the direction
1403:44 - in which it will move the cylinders are
1403:47 - numbered from 0 to 199 so these are the
1403:50 - extremes the total head moment incurred
1403:52 - while serving these request is we have
1403:54 - to calculate the number of sixs and and
1403:56 - which algorithm we are using cook
1403:58 - algorithm what does cook say this is
1404:00 - circular look you can serve in One
1404:02 - Direction only but no need to go to the
1404:05 - extremes so from 63 I'll move to 191
1404:08 - from 191 to 10 and from 10 to
1404:12 - 47 sum them sum them all and you will
1404:15 - get 346 as the number of head movements
1404:18 - or number of seeks
1404:20 - made another question given the requests
1404:23 - and you have to solve using the first
1404:26 - fcfs and the second one is s test seek
1404:29 - next you can solve this an easy
1404:31 - question consider a storage disc with
1404:34 - four platters numbered as 0 1 2 3 so we
1404:37 - have four
1404:39 - platters and 200 cylinders number from 0
1404:43 - to 199 so we have four platters and on
1404:46 - each surface we have 200
1404:49 - cylinders and 256 sectors per track and
1404:53 - we have 256 sectors per track these are
1404:55 - the track these are the surfaces uh not
1404:57 - surface the sectors
1404:59 - sorry there will be two surface on each
1405:03 - platter there are four platters there
1405:05 - will be 200 tracks on each surface and
1405:08 - 256 sectors on each track the following
1405:11 - six request of the form sector number
1405:14 - cylinder number platter number are
1405:17 - received by the disc controller at the
1405:18 - same time so these are the request
1405:21 - received this is what this is the sector
1405:24 - number this is the cylinder number and
1405:26 - this this is the platter number so on
1405:27 - platter 2 go to the track 72 and or read
1405:32 - sector number 120 this is what this say
1405:35 - a b c this says on platter C go to the
1405:38 - sector number or go to the cylinder
1405:40 - number B and at that track go to the
1405:43 - sector number a the first represent the
1405:45 - sector the second one the track and the
1405:46 - third one is the platter so these
1405:48 - request I have received currently the
1405:50 - head is positioned at sector number 100
1405:54 - of cylinder 80 and it is moving toward
1405:57 - higher cylinder numbers the average
1405:59 - power dissipation in moving the head
1406:00 - over 100 cylinder is 200 M and for
1406:04 - reversing the direction of the head
1406:05 - moment once the power used is 15 Ms see
1406:09 - these are these are the kind of question
1406:12 - meant to scare
1406:14 - you like the big big things are given so
1406:17 - that you may get confused no need to get
1406:19 - scared from this question just write the
1406:21 - things down which are written power
1406:24 - dissipation associ ated with rotational
1406:27 - latency and switching of head between
1406:29 - different PL is negligible so there is
1406:31 - no power dissipated for rotational
1406:33 - latency and switching the head between
1406:36 - platters okay so here it is written that
1406:39 - we have to switch the head between
1406:41 - platters for this question assume that
1406:43 - there is only one read right
1406:46 - head okay there is only one read right
1406:49 - head and there is one surface only at
1406:52 - each
1406:53 - platter because there is no concept of
1406:55 - surface here and only one redite head is
1406:57 - present and for each surface for each
1407:00 - request I have to move this redite head
1407:02 - for let's say here is the platter two so
1407:04 - I will I will be at the platter two then
1407:06 - the request is from platter one then
1407:08 - this read at H will move to the platter
1407:09 - one assume for this
1407:12 - question the total power consumption in
1407:14 - mwatts to satisfy all the about dis
1407:16 - request using shortest seek time first
1407:19 - dis scheduling algorithm is easy
1407:20 - question no need to get scared what is
1407:23 - given we are given with the platters
1407:24 - that there are four platters
1407:26 - 200 tracks on each flatter and 256
1407:29 - sectors on each track so these are the
1407:31 - request made the sector number the track
1407:34 - number and the platter number if you
1407:36 - notice clearly there is no need for this
1407:38 - platter number as you know that moving
1407:41 - to a certain platter moving to a certain
1407:45 - platter needs moving to a certain
1407:48 - platter dissipates no power and moving
1407:51 - to a certain sector also dissipates no
1407:53 - power because it is written here that
1407:55 - power or dissipation associated with
1407:57 - rotational latency and switching off
1407:59 - head between different plers is
1408:02 - negligible this will cause the
1408:03 - rotational latency see when we are on a
1408:06 - certain track and when we have to reach
1408:08 - to a certain sector then rotational
1408:10 - latency is accounted but here it is
1408:12 - written that rotational latency is
1408:14 - negligible so we just have to reach to
1408:18 - the correct track on the correct platter
1408:20 - but here it is also written that there
1408:21 - is no need for going to the correct
1408:23 - platter also see this is just a way of
1408:25 - saying
1408:26 - here assume that all of them are on the
1408:28 - same platter with no uh read latency
1408:32 - rotational latency getting the point see
1408:35 - you can do this older way uh you can
1408:38 - take account of all these things and
1408:41 - drag them all the way to the question to
1408:42 - the end of the question but there is a
1408:45 - smart move you can make here it is
1408:47 - written that power dissipation
1408:48 - associated with rotational latency and
1408:51 - switching of head between different
1408:52 - plers is negligible so I have to reach
1408:54 - just to the current track just to the
1408:57 - correct track when I'm on the correct
1408:59 - track then everything is sorted because
1409:02 - known power disspation for this no power
1409:04 - dissipation for this so the actual
1409:06 - request we have to consider is this
1409:11 - only okay so here single Rite head for
1409:14 - multiple patterns that I already
1409:17 - told now extra things are given what is
1409:20 - that
1409:21 - given the current head is positioned at
1409:23 - sector number 100 of cylinder 80
1409:27 - so the current head is at track number
1409:29 - 80 moving toward the higher cylinder
1409:31 - numbers okay so from 80 it will go to I
1409:35 - think 199 this will be the direction to
1409:37 - move the average power dissipation in
1409:40 - moving the head over 100 cylinders is 20
1409:44 - MW so from for 100 track seeks 20 M
1409:48 - Power will be gone for one track seek
1409:50 - 1x5 M Power will be gone I just divided
1409:54 - 20 by 100 for reversing the direction 15
1409:57 - Ms is
1409:59 - needed power
1410:01 - dissipation the two two of the things
1410:04 - are dissipating the power switching the
1410:05 - heads and the the rotational L switching
1410:08 - the head is causing zero power
1410:12 - dissipation transferring the track
1410:15 - transferring the re right head from one
1410:16 - track to another that is causing the
1410:19 - main power dissipation and the second
1410:21 - reason behind the power dissipation is
1410:23 - reversing the direction see we are not
1410:25 - using the scan or look algorithm here we
1410:28 - are using the shortest shortest seek
1410:31 - time first so this will going to cause a
1410:34 - lot of Direction changes see
1410:37 - here these many Direction changes are
1410:39 - made so I have to take account of this
1410:42 - reversing the direction uh Power
1410:44 - dissipation also so these were the
1410:47 - request
1410:48 - made where I am I am at the 80th track
1410:52 - number so from 80 where I have to move I
1410:54 - have to move to 86 for
1410:56 - then I have to move to 76 then 116 then
1410:59 - 134 then 20 and then 16 in this manner I
1411:03 - have to move based on this shortest seat
1411:06 - time first dis Shing algorithm so the
1411:09 - power dissipation will be from 80 to 86
1411:12 - firstly I will calculate the power
1411:14 - disspation of seek only from 80 to 86 6
1411:19 - from 86 to 70 to 14 14 SS are made from
1411:22 - 72 to 116 44 SS are made from 116 to 134
1411:27 - 18 SE are made and then from 134 to 20
1411:32 - 114 SE are made from 20 to 16 46 are so
1411:35 - total number of ss are 200 and what is
1411:38 - the power dissipation uh caused by one
1411:40 - seek 1X 5 m so what will the power
1411:43 - dissipation just by the seek it will
1411:46 - be 40 m just by the seeks now for the
1411:51 - Now power disp caused when read right
1411:53 - head changes its direction the the first
1411:56 - Direction Change made is here it was
1411:58 - going here and then it changed the
1411:59 - direction the second Direction change
1412:01 - was made here it was going here and it
1412:03 - made it changed the direction and the
1412:05 - third was made here here here and here
1412:09 - so three Direction changes are made so
1412:12 - 45 + 40 gives me 85 M you get the
1412:16 - question what was it see whenever you
1412:19 - see a such kind of big question remember
1412:22 - most of them are meant to scare you
1412:26 - these it it the question has so many
1412:28 - irrelevant information that was not even
1412:32 - needed that was not even needed if I
1412:34 - instead of giving this this whole thing
1412:36 - if I just give you hey look I have this
1412:40 - request you have to you have to solve
1412:43 - this using shortest seek time and
1412:45 - remember for one seek time 1X 5 m is
1412:49 - needed or the power is dissipated and
1412:51 - for reversing the direction 15 M power
1412:53 - is dissipated can you give me the total
1412:55 - power dissip it was an easy question it
1412:57 - was so easy you have to just apply the
1413:00 - shortest seek algorithm and calculate
1413:03 - the number of SE the total sixs made
1413:05 - were 200 multip it by 1X 5 you got 40
1413:08 - and calculate the total number of
1413:10 - Direction changes first Direction Change
1413:13 - here second was here and third was here
1413:15 - so the total Direction change caused the
1413:17 - power dissipation to be 45 40 was due to
1413:20 - six so I got 85 this was an easy
1413:22 - question but as soon as I have given
1413:24 - this I have uh Twisted the question and
1413:27 - added some irrelevant information there
1413:30 - this may have Disturbed some of you what
1413:32 - was given consider the dis stage let let
1413:35 - me tell you which of the following
1413:36 - information was just to uh distract you
1413:40 - the four platter information was just to
1413:42 - distract you this number from 0 to 123
1413:45 - 200 cylinder this was useful information
1413:47 - was this useful see this 200 cylinders
1413:51 - was this useful we are using shortest
1413:54 - seek time first
1413:56 - we did not even use this 200 cylinder
1413:58 - this was also the irrelevant information
1414:01 - 256 sectors irrelevant information the
1414:04 - following six request was made this was
1414:08 - Irrelevant this was irrelevant no
1414:11 - cylinder number was required pler number
1414:12 - was irrelevant
1414:15 - so irrelevant irrelevant needed and then
1414:21 - currently the position sector number 100
1414:23 - this was needed uh sector number 100 no
1414:25 - need the track number 80 yes it was
1414:28 - needed moving toward higher cylinder
1414:31 - number was it needed yes it was needed
1414:34 - the average power dissipation yes it was
1414:36 - needed to calculate the power
1414:38 - dissipation for one seek and then
1414:41 - reversing the head yes this was needed
1414:43 - the power disp Associated see this was
1414:45 - the gamechanging line the power disp
1414:48 - associated with rotational latency and
1414:50 - switching off head between different
1414:51 - players is negligible this was the game
1414:53 - changing line the total power cons so
1414:56 - you can see how much information was
1414:59 - just to distract
1415:00 - you okay what would have happened if
1415:04 - what would have happened if it was not
1415:07 - written that the rotational latency is
1415:09 - not negligible and the switching the
1415:12 - head power is also present then this
1415:14 - information would be
1415:16 - useful okay so for every request I have
1415:19 - to add I have to add the rotational
1415:22 - latency and the time to switch the heads
1415:27 - so this was a this was I can say a nice
1415:29 - question let's move to another one
1415:31 - suppose a dis has 2001 cylinders
1415:34 - numbered from 0 to 200 at some time the
1415:37 - dis arm is at cylinder number 100 and
1415:40 - there is a q of dis AIS request 3 to 145
1415:44 - if the shortest seek time first is being
1415:45 - used for the scheduling dis dis access
1415:48 - the request for cylinder 90 is serviced
1415:50 - after how many number of request or
1415:53 - service serviced after number of request
1415:55 - easy question you can do it yourself
1415:59 - so from from 100 I will go to 105 first
1416:03 - then2 then
1416:05 - 90 so after how many request it was
1416:07 - served see first this request was served
1416:10 - then this request and then this request
1416:12 - so after three request 90 will be served
1416:14 - do not make a mistake to calculate the
1416:16 - jump instead of
1416:18 - request do not make a mistake to ignore
1416:20 - this 100 see this is also a request this
1416:23 - will also be served after the serving of
1416:25 - this request you go to the 105 and then
1416:27 - to 110 and then to
1416:30 - 90 okay another question consider a
1416:35 - consider an operating system capable of
1416:37 - loading and executing a single
1416:39 - sequential user process at a time this
1416:42 - is just another name of uni programming
1416:44 - operating system the dis head scheduling
1416:46 - algorithm used is first come first serf
1416:50 - if fcfs is replaced by shortest seek
1416:53 - time first claimed by the vendor to give
1416:56 - 50% better Benchmark result what is the
1416:59 - expected Improvement in the io
1417:01 - performance of the
1417:04 - user think about it and read the
1417:07 - question again what was it
1417:09 - saying the operating system is uni
1417:12 - programming if the operating system is
1417:14 - uni programming the scheduling topic is
1417:17 - insignificant for uni programming
1417:19 - operating
1417:21 - system so it doesn't matter whether you
1417:23 - use fcfs or sstf it will it will not
1417:26 - matter for uni programming operating
1417:29 - system there is no such kind of uh there
1417:32 - is no significance I can say of the
1417:35 - scheduling so what is the expected
1417:38 - Improvement in the io performance 0% did
1417:41 - you get it see what
1417:44 - happens just like the CPU scheduling
1417:46 - topic what happens in the disk scheding
1417:49 - there are multiple request at a given
1417:51 - time now the disk scheduler has to
1417:54 - choose which request it has to uh serve
1417:57 - just like the CP Shing technique there
1417:59 - were multiple process available in the
1418:01 - ready CU ready to be run on CPU so the
1418:05 - CPU Scher has to choose which process
1418:07 - out of these I have to uh take to the
1418:11 - CPU in the similar way for the dis Sher
1418:15 - there are multiple IO
1418:17 - request now it is on the dis scheduler
1418:20 - which I request it will serve but what
1418:23 - happens there is only a single process
1418:25 - in the memory so this will generate a
1418:29 - single this single IO request only no
1418:31 - multiple IO request case no dis
1418:34 - scheduling thing the pro the request
1418:36 - which is made just serve it because
1418:38 - there is only one request the scheduling
1418:41 - topic was significant when there are
1418:43 - multiple things at the time and you have
1418:44 - to choose one just like in the CP Shing
1418:48 - when there are multiple process in the
1418:49 - readyq you choose out of those multiple
1418:52 - you choose one
1418:53 - process in dis scheduling out of the
1418:56 - multiple I request you choose to serve
1418:59 - one but if the IU request is only one
1419:02 - then there is no concept of being of dis
1419:06 - schuling so there's no concept of using
1419:09 - uh fcfs or sstf whether you use any of
1419:12 - one of them you will get the same result
1419:14 - so what is the expected Improvement in
1419:16 - the io performance of the user user
1419:18 - program
1419:19 - 0% another question consider a disk with
1419:23 - the following pertinent details is the
1419:26 - track track time is 1 millisecond or I
1419:28 - can say one seek time is 1 millisecond
1419:31 - current head position is 65 and the
1419:33 - direction it will move will be for the
1419:36 - higher tracks the current clock time is
1419:38 - 160 millisecond okay consider the
1419:42 - following data set we are given with the
1419:44 - request serial number track number and
1419:46 - arrival of the request time or the time
1419:49 - of arrival of the request calculate the
1419:51 - time of decision at which time we have
1419:53 - to take the decision the requests which
1419:55 - are pending the head position the
1419:56 - selected request to be served seek time
1419:59 - using fcfs all these things I will solve
1420:01 - using fcfs and for rest of them it is
1420:03 - homework to
1420:05 - you so what happens we are at the time
1420:08 - the present is at the time 160
1420:10 - millisecond these request request one
1420:13 - request two request three and request
1420:15 - four has already been made so at time
1420:18 - 160 what are the pending request 1 2 3 4
1420:22 - at which time we have to take the
1420:23 - decision current time we have to take
1420:25 - the decision immediately to choose which
1420:28 - of the following request I will serve
1420:30 - what is the head position 65 the
1420:32 - selected request will be the one which
1420:34 - came first I'm using fcfs so who came
1420:37 - first 12 uh the request for track number
1420:40 - 12 came first what will be the seek time
1420:43 - from 65 to 12 53 seeks into 1
1420:46 - millisecond as I am given the track
1420:48 - track time is 1
1420:52 - millisec so after the request one is
1420:55 - served what is the time now 160 was
1420:58 - already there and 53 millisecond was
1421:01 - also taken to serve the process the
1421:03 - serve the request one I'm sorry if I say
1421:05 - these as process these are the request
1421:08 - so 160 +
1421:09 - 53
1421:11 - 23 will be the current time of the
1421:14 - decision when I have to serve the these
1421:17 - request which request one was already
1421:19 - served 2 3 4 was already present and at
1421:22 - time 23 this five would also have came
1421:25 - at it came at 175 millisecond so the
1421:28 - request which are pending now 2 3 4 5
1421:32 - the head position is at now 12 which
1421:35 - request I'm going to serve next who came
1421:38 - next this 85 the track number 85 so
1421:41 - request to for track number 85 so from
1421:44 - position 12 I'll move to 85 the total
1421:48 - number of seeks made are 73 the seek
1421:50 - time will be 73 millisecond now after
1421:52 - the request two is served after 213 and
1421:54 - then 73 will be added 3 and 36 718 286
1421:58 - this is the current
1422:00 - time any new request made no the pending
1422:03 - request are 345 what is the current time
1422:06 - 286 and we have to make decision here at
1422:10 - 286 which head position I will go the
1422:13 - one I at the head position 85 now where
1422:16 - I will go the one who came next who came
1422:19 - next at 140 so from 80 85 I'll move to
1422:24 - 40 how many SE are made 25 SE are made
1422:27 - not 25 I
1422:29 - think I moved to from 85 I moved to 40
1422:32 - 45 SS are made so 45 milliseconds will
1422:35 - be the seek time so in this manner you
1422:37 - have to proceed and complete till the
1422:38 - end so this was for the fcfs you have to
1422:41 - solve for ssf scan look C scan and C
1422:44 - look algorithm to get hold of these uh
1422:48 - dis scheduling algorithms you will get
1422:49 - Mastery over
1422:50 - this we have successfully completed our
1422:53 - whole file management section and in the
1422:56 - next lecture we are going to or in the
1422:58 - next section we will complete our
1423:00 - miscellaneous topics The
1423:02 - Leftovers topics I know this file file
1423:05 - management was a little bit of uh
1423:07 - theoretical topic but it also contained
1423:10 - some of the algorithms and
1423:13 - numericals hope you liked
1423:16 - it threads and multi-threading this will
1423:19 - be our first miscellaneous topic let's
1423:22 - start what is a thread thread is a
1423:25 - lightweight process now you must be
1423:28 - wondering why I call it as lightweight
1423:30 - we will see it in sometime you know what
1423:32 - is process programming execution
1423:35 - State let's first understand this
1423:38 - example of client server environment we
1423:40 - have clients 1 2 3 4 5 6 7 these are all
1423:44 - clients and this is our server which has
1423:46 - a big hard disk and this is our server
1423:49 - process we also call it as Damon
1423:51 - initially we used to serve in iterative
1423:54 - mode
1423:57 - process uh request one was made request
1424:00 - one served request three was made
1424:02 - request three served request six was
1424:04 - made request six served in this manner
1424:06 - we used to
1424:07 - serve but what
1424:10 - happened instead of sequential request
1424:13 - some of the clients requested at the
1424:14 - same time so what will happen these
1424:17 - requested will be queued up in a
1424:20 - buffer this sequential serving of the
1424:23 - request causes start ation or DeLay So
1424:27 - what is the solution for this
1424:29 - multi-process approach or the concurrent
1424:32 - servers the concurrent servers or the
1424:34 - multi-process approach now you must
1424:37 - remember the difference between
1424:38 - concurrency and
1424:41 - parallelism okay we are creating the
1424:44 - concurrent server not the parallel
1424:47 - servers see this this was the
1424:50 - server and we have three request cued up
1424:54 - here so what it did there were three
1424:57 - request pending so it creates three
1424:59 - child process independent of each other
1425:01 - and request one was assigned to child
1425:03 - process one request two was assigned to
1425:06 - child process two and request three was
1425:07 - assigned to child process
1425:09 - 3 so these child process are exact
1425:13 - replica of the parent process
1425:16 - server so now we have three processes
1425:20 - now we have three process in the ricu C1
1425:22 - C2 and C3 we will execute them in the
1425:25 - round robin fashion and it will create
1425:28 - an impression that their request is
1425:32 - being served at the same time what is
1425:35 - going on firstly I'm serving for some
1425:37 - time request one and then for some time
1425:39 - request two and then for some time
1425:40 - request three then I again back to
1425:42 - request one and then again back to
1425:43 - request and again back to request three
1425:45 - so instead of sequential
1425:48 - serving I created the child processes
1425:51 - and each request is assigned to a
1425:53 - process and and run those process in
1425:56 - round robin fashion it created an
1425:58 - impression that their request is being
1426:01 - served
1426:02 - concurrently but there is a s severe
1426:05 - drawback of this uh of this method it is
1426:08 - the redundancy of
1426:11 - code it is a severe drawback why because
1426:14 - code of the server process will be
1426:15 - copied as it is in the child process see
1426:18 - functionality of all the children will
1426:20 - be
1426:21 - same we can't we have an architecture in
1426:24 - which I will have one section of the
1426:26 - code and the resources which are
1426:28 - separately needed should be given to
1426:29 - each process see the functionalities or
1426:33 - the functions are defined in the code
1426:35 - and the functionality of these child
1426:37 - process are exactly same but the
1426:40 - resources are different so instead of
1426:43 - giving instead of having different code
1426:45 - and different resources for all of the
1426:47 - process can't we have an architecture in
1426:49 - which the code section remains same I
1426:52 - mean functionalities remain same and and
1426:54 - the resources which are separately
1426:56 - needed should be given to each process
1426:59 - in this manner I will avoid the memory
1427:02 - and resource
1427:03 - wastage this is what the idea of a
1427:05 - thread is thread is nothing but a
1427:08 - subprocess which will share all the
1427:11 - common resources thread is nothing but a
1427:15 - subprocess or lightweight process that's
1427:16 - why it is lightweight process it is not
1427:19 - a full process it is a sub process see
1427:25 - this let's say this is the process with
1427:27 - code section and resources this is
1427:29 - another process with code section and
1427:31 - resources another process with code
1427:33 - section and
1427:34 - resources and in thread what
1427:38 - happens this is the shared code
1427:41 - section and the resources are given to
1427:45 - this is thread one this is thread 2 and
1427:46 - this is thread the resources which are
1427:49 - separately needed are separately given
1427:51 - to the threads and the code section or
1427:53 - the functionalities which needed to be
1427:55 - same are shared by these threads so all
1427:58 - these threads have some shared thing in
1428:01 - common and the resources which are
1428:04 - separately needed are separately given
1428:06 - this is what thread is that's why it's
1428:08 - called lightweight
1428:10 - process so if someone ask you what is
1428:12 - the main reason for multi-threading
1428:14 - economy the resource sharing okay in
1428:16 - this manner it goes see this is the
1428:18 - single threaded
1428:20 - process and this is the multi-threaded
1428:23 - process this is the address space it
1428:25 - contains code Heap data files registers
1428:31 - stack or you can say this single
1428:33 - threaded process is nothing but a
1428:36 - process only the single threaded process
1428:38 - is nothing but a process only each
1428:41 - process will have its own code data
1428:44 - files register stack Heap but what
1428:47 - happens now when we move to the
1428:49 - multi-threaded process what happens the
1428:52 - code data and file are shared
1428:56 - but each thread will have its own set of
1428:59 - registers and stack each thread will
1429:01 - have its own set of register and stack
1429:04 - so these are the resources which I was
1429:05 - talking about that need to be separately
1429:08 - given to each thread and these were the
1429:12 - these are the shared thing or common
1429:14 - thing
1429:16 - okay so this is the default process the
1429:18 - single threaded process nothing but the
1429:20 - default process and there we it is the
1429:22 - thread now the question is is why we
1429:25 - throw why we show thread with a curvy
1429:28 - line what is the reason behind this
1429:31 - because the thread uh when the thread is
1429:34 - put like randomly it it is
1429:36 - curvy when you put a thread it is curvy
1429:40 - so uh the thread is a lightweight and
1429:43 - that's why we have given this a
1429:44 - lightweight uh process and the thread
1429:47 - when kept on something it becomes Curry
1429:49 - that's why the line is curry no no not
1429:52 - this is not the reason there is a more
1429:54 - logical reason behind this so why we are
1429:56 - using a curvy line because during the
1429:59 - execution of instruction there may be a
1430:01 - branch or jump instruction like see here
1430:03 - if there is a no Branch or jump
1430:05 - instruction I can
1430:07 - just put a straight line there but what
1430:10 - happens let's say I executed instruction
1430:12 - one instruction two and suddenly I have
1430:15 - to jump to next instruction then some
1430:17 - next instruction that's why there is a
1430:19 - curvy line here to represent the branch
1430:22 - instructions okay
1430:25 - each thread will have its own stack its
1430:28 - own function and register okay so each
1430:31 - thread will have its own stack and
1430:33 - resistors this is single threaded this
1430:35 - is multi- thread now concurrent servers
1430:38 - may be proceeded with two approach the
1430:40 - first was the multi-threaded approach
1430:42 - and the second was the first was the
1430:43 - multiprocess approach and the second was
1430:45 - the multi-threaded approach see here
1430:48 - this was the multiprocess approach when
1430:52 - we used fork and created the three child
1430:54 - processes this was the multiprocess
1430:57 - approach
1430:59 - and this was the multi-threaded
1431:02 - approach what we did we kept the
1431:05 - functionality part the same and or the
1431:08 - code part is the is kept same and the
1431:10 - resources which each the thread needed
1431:13 - is given separately to them so the
1431:15 - request one will be assigned to this
1431:16 - thread the request two will be assigned
1431:18 - to this thread and request three will be
1431:19 - assigned to this
1431:20 - thread okay so client
1431:25 - will request the server server will
1431:27 - create a new thread to serve the request
1431:30 - suppose this is a client it requested a
1431:32 - server server created a new thread to to
1431:35 - serve that request and it will assign
1431:39 - that thread the responsibility to
1431:40 - fulfill the request of the client and it
1431:42 - will resume listening for additional
1431:45 - client's request whenever a request
1431:47 - clients make whenever a request client
1431:49 - make the the server will create a new
1431:52 - thread and it will resume listening for
1431:55 - the additional client
1431:57 - request here are the benefits of the
1431:59 - multithread program let's read it the
1432:01 - first is the responsiveness
1432:02 - multi-threading and interactive
1432:04 - application may allow a program to
1432:06 - continue running even if a part of it is
1432:10 - blocked or performing a lengthy
1432:12 - operation thereby increasing
1432:14 - responsiveness to the user this quality
1432:17 - is especially useful in designing user
1432:18 - interfaces for instance consider what
1432:22 - happens when a user clicks a button that
1432:24 - result in the performance of time
1432:26 - consuming operation a single threaded
1432:28 - application would be unresponsive to the
1432:31 - user until the operation had completed
1432:33 - but what happens in the case of
1432:35 - multi-threaded in contrast if the time
1432:37 - consumer operation is performed in
1432:39 - separate thread then the application
1432:40 - remains responsiveness to the user for
1432:43 - the remaining threads so what what it is
1432:46 - saying that if it is a single threaded
1432:49 - process and we assign This Thread some
1432:50 - lengthy task then this application will
1432:54 - be unresponsive until this task becomes
1432:58 - complete so this was the single threaded
1433:02 - process now what happens in the
1433:03 - multi-threaded
1433:05 - process what I do I assign This Thread
1433:08 - the leny
1433:10 - task and these two thread will be still
1433:12 - working so multi-thread process bring or
1433:16 - multi-threaded program brings
1433:18 - responsiveness okay the second is
1433:20 - resource
1433:21 - sharing process can only share resources
1433:24 - through techniques such as shared memory
1433:26 - and message passing such techniques must
1433:29 - be explicitly arranged by the
1433:31 - programmers however thread share the
1433:33 - memory and the resource of the process
1433:35 - to which they belong by default default
1433:38 - the benefits of sharing code and data is
1433:40 - that it allows an application to have
1433:43 - several different threads of activity
1433:45 - within the same address space obviously
1433:47 - this is also a point that when process
1433:50 - Shar resources it has to use techniques
1433:53 - like shared memory and and message
1433:55 - passing Etc but when thread share
1433:58 - resources it happens in the same
1434:01 - process threads belongs to same process
1434:04 - and when the process share suppose these
1434:06 - are the two process and when they sh
1434:08 - share some resources they had to do by
1434:11 - shared memory and message but the thing
1434:14 - or the case with the threads is they
1434:16 - belong to the same
1434:18 - process they share the memory and
1434:21 - resources of the process to which they
1434:22 - belong by default the benefit of sharing
1434:25 - code and data is that it allows an
1434:26 - application to have several different
1434:28 - threads of activity within the same
1434:29 - address space Okay the third is
1434:33 - economy allocating memory and resources
1434:35 - for process creation is costly well when
1434:38 - you uh give all the resources to all the
1434:41 - processes that is going to uh harm your
1434:45 - economy because threat share the
1434:47 - resource of the process to which they
1434:48 - belong this it is more economical to
1434:50 - create in context which threads yes yes
1434:54 - that that is the point contact switching
1434:56 - of process is way more costlier than the
1434:59 - contact switching of
1435:01 - threads EMP
1435:04 - EMP empirically gauging the difference
1435:07 - in overhead can be difficult but in
1435:10 - general it is significantly more timec
1435:12 - consuming to create and manage process
1435:14 - than threats in Solaris for example
1435:16 - creating a process is about 30 times
1435:20 - more costlier than creating a thread
1435:23 - scalability the B benefits of
1435:24 - multi-threading can be even greater in
1435:27 - multiprocessor
1435:29 - architecture multiprocessor means when
1435:32 - we have more than one CPU so the
1435:33 - benefits of multi-threading can be even
1435:35 - greater in multiprocessor architecture
1435:38 - where thread may be running in parallel
1435:40 - on different processing CES a single
1435:42 - threaded process can run only on one
1435:44 - processor regardless of how many are
1435:46 - available we can explore this issue
1435:47 - further in the following section okay so
1435:50 - the scalability economy resource sharing
1435:53 - respons as all of them tells that
1435:57 - multi-threading is better than
1435:58 - multiprocessing again improved
1436:00 - performance due to less contact switch
1436:02 - each thread will have its own control
1436:04 - block just like PCB
1436:06 - of it's just like the PCB of the process
1436:09 - as we have PCB for the process we'll
1436:13 - have TCB thread control block for
1436:16 - Threads and you know threads are called
1436:20 - as lightweight process so it is General
1436:22 - thing that or it is obvious thing that
1436:24 - size of TCB should be less than the size
1436:27 - of
1436:30 - PCB if the size is less then contact
1436:34 - switching or the thread switching time
1436:35 - will be faster than process switching
1436:37 - time well what we switch while contact
1436:40 - switching of the process and threads TCB
1436:42 - and the pcbs and if size of one is
1436:45 - smaller than the later
1436:47 - then obviously the thread switching time
1436:50 - will be faster than the or thread
1436:52 - switching will be faster than the the
1436:54 - process switching so these are the
1436:56 - benefits of using a multi-threaded
1436:58 - program in instead of multiprocessing
1437:01 - the sixth is it can utilize the
1437:03 - multicore architecture and Achieve
1437:08 - parallelism see what it is saying
1437:11 - suppose I have a single I have a single
1437:13 - threaded program or I will say I will
1437:15 - have a process in which there is only
1437:17 - one thread this process can be assigned
1437:19 - to a single CPU here we have multiple
1437:21 - CPUs I'm talking about multiple
1437:24 - processor architecture so what happens
1437:27 - this is a single process it is assigned
1437:29 - to let's say C1 CPU the rest C2 and C3
1437:33 - are empty or C idle but what happens in
1437:36 - the multi-threaded process I can assign
1437:39 - each thread to a different CPU hence
1437:42 - utilizing properly the M multi-core
1437:44 - architecture or multi-processor
1437:46 - architecture and it achieves parallelism
1437:49 - this is the actual parallelism see what
1437:51 - we are doing there
1437:55 - wait it will load yes here we are not
1437:59 - using parallelism here we are here we
1438:03 - are using a concurrent approach you
1438:06 - remember the difference between
1438:07 - concurrency and parallelism in
1438:09 - concurrency we deal with different
1438:11 - things at a time first we are uh first
1438:15 - we are uh executing the child process C1
1438:18 - then child process C2 then C3 in round
1438:20 - robin fashion but at a time only one is
1438:24 - being executed this is concurrency we
1438:26 - are dealing with different things at a
1438:28 - time but what was parallelism
1438:31 - parallelism is we are doing the
1438:33 - different things at a time so at a time
1438:36 - this thread will also being executed
1438:37 - This Thread is also being executed and
1438:39 - this thread is also being executed this
1438:41 - is
1438:42 - parallelism
1438:44 - okay let's summarize what we have what
1438:47 - we have discussed thread is like a
1438:49 - lightweight copy of process that
1438:50 - executes independently threads share the
1438:53 - same address space each thread has a
1438:56 - separate program counter and may run
1438:58 - over different parts of the program each
1439:01 - thread has a separate stack for
1439:03 - independent function calls so these this
1439:05 - is the
1439:07 - summary here more
1439:09 - information threads versus process a
1439:12 - thread has no data segment or Heap a
1439:15 - thread cannot live on its own it need to
1439:17 - be attached to a process there can be
1439:20 - more than one thread in a process each
1439:22 - thread has its own
1439:24 - stack if a thread dies it stack is
1439:28 - reclaimed a process has code Heap stack
1439:31 - and other segments a process has at
1439:34 - least one thread well you know the
1439:35 - single
1439:36 - threaded process are by default or a
1439:40 - process is by default a single threaded
1439:42 - process heads within a process share the
1439:45 - same code files if a process dies all
1439:47 - thread dies
1439:50 - well threads lives inside the process if
1439:54 - a process dies all threads will die if
1439:56 - one thread die then other thread may
1439:59 - live but if a process die then all
1440:01 - threads will
1440:03 - die now comes the fork thing parent P
1440:07 - Fork a child c p and C does not share
1440:10 - any
1440:11 - memory this C is exact replica of the
1440:15 - process P the child C or the process C
1440:19 - is exact replica of process B all the
1440:22 - resources which were allocated to
1440:23 - process B will also be allocated to
1440:26 - process C it need complicated IPC
1440:29 - mechanisms to communicate you remember
1440:31 - when we have discussed a full full
1440:36 - section that how process synchronized
1440:39 - how process coordinate how process
1440:41 - communicate and you know how complex
1440:43 - this was that
1440:45 - was but in thread there is no such thing
1440:49 - we do not need a complicated IPC
1440:51 - mechanism they all reside in the same
1440:52 - process
1440:54 - so
1440:55 - for for communication between two
1440:58 - process we need comp complicated IPC
1441:00 - mechanisms to communicate extra copies
1441:02 - of code data in memory redundancy is
1441:06 - present now let's see parent P execute
1441:09 - two threads T1 and T2 T1 and T2 share
1441:13 - parts of the address space Global
1441:15 - variables can be used for communication
1441:17 - see this
1441:18 - simple instead of using complicated or
1441:21 - complex IPC mechanisms which we have
1441:23 - leared learned about set and lock or
1441:26 - thread uh the Peterson solution Decker
1441:29 - solution all this all the that
1441:31 - complicated stuff we do not need here
1441:33 - just the simple Global variables can
1441:35 - solve our purpose and smaller memory
1441:38 - footprint so simple so it says
1441:41 - multi-threading is much more economical
1441:44 - than
1441:45 - multi-processing parallelism a single
1441:47 - process can effectively utilize multiple
1441:49 - CPU CES understand that difference
1441:53 - between concurrent and parallelism well
1441:55 - I have discussed it already that a
1441:57 - single process here is a single process
1442:00 - with multiple threads can utilize the
1442:02 - multi-core architecture I will assign
1442:03 - This Thread to C1 This Thread to here
1442:06 - this thread to C3 these are the CPUs
1442:08 - each thread will be assigned to a
1442:09 - different CPU and therefore I can
1442:11 - utilize the multicore or multiprocess
1442:14 - architecture
1442:16 - effectively but if there are multiple
1442:21 - process if there are multiple process
1442:23 - and a sing CPU then what will happen I
1442:26 - will use concurrency see in concurrency
1442:29 - you remember the example of that coffee
1442:32 - machine in a single coffee machine with
1442:35 - two lines first it serve let's say of
1442:36 - males and then of
1442:38 - females first male comes then females
1442:41 - then females and male in such manner it
1442:43 - serves sometime this process sometime
1442:46 - this process sometime this process
1442:47 - sometime this process but what happens
1442:50 - when we have two coffee
1442:52 - machines mail line here the female line
1442:55 - here okay so when we are talking about
1442:58 - the case of two coffee machines that is
1443:00 - parallelism when one coffee machine
1443:02 - serving two lines that is
1443:06 - concurrency types of thread so there are
1443:08 - two types of thread the user level
1443:10 - thread and the kernel level thread user
1443:12 - level thread is threads that are created
1443:14 - and managed at user level without any
1443:17 - operating system support flexibility
1443:19 - given to users and here in the kernel
1443:22 - level threads are directly created and
1443:24 - managed by operating
1443:27 - system kernel level threads are the part
1443:29 - of process but managed independently by
1443:31 - the process so here operating system has
1443:36 - the complete control here operating
1443:37 - system gives the flexibility to users to
1443:40 - create threads so these These are the
1443:44 - user level threads we manage the
1443:46 - creation at user level with the help of
1443:48 - some package or Library
1443:50 - okay let's see the benefits operating
1443:53 - system is not able to see those threads
1443:55 - it will see it as a process it is good
1443:59 - as well as bad we call this as
1444:01 - transparency well it seems something
1444:04 - opposite but that's how it's called I
1444:07 - have checked on every platform when
1444:09 - operating system is not able to see
1444:11 - those threads it will see it as a
1444:13 - process when this happens well actually
1444:15 - the meaning of transparency is
1444:16 - everything is clear but here when
1444:19 - operating system is not able to see
1444:20 - those
1444:21 - threads then we call it as transparency
1444:24 - flexibility is given scheduling and
1444:26 - assigning the threads all is at the user
1444:29 - level see why this is good as well as
1444:31 - bad because operating system has now no
1444:34 - control over the you or operating system
1444:37 - doesn't give uh much Focus to those user
1444:39 - Level Threats so each and every
1444:43 - responsibility will come to a user now
1444:46 - it will create complication while
1444:48 - writing the program when user is
1444:50 - managing all the threats then the
1444:53 - program will become complicated
1444:55 - flexibility is scheduling assigning
1444:57 - threads all will be at the hand in the
1444:59 - hands of user faster contact switching
1445:01 - as you know no need of mode shifting
1445:03 - well this is the point which I forgot to
1445:06 - make there less
1445:09 - overhead in user level threads there is
1445:11 - no need of mode shifting it is if if
1445:15 - there is no need of mode shifting and
1445:17 - the threads are lightweight then less
1445:19 - overhead and faster contact switching
1445:20 - portability can run on different
1445:22 - operating system well then that is the
1445:24 - actual
1445:26 - benefit when these user level threads
1445:29 - are independent of operating system
1445:31 - which means I can run those on Unix I
1445:34 - can run the same user level thread at
1445:36 - Mac and windows well that will give me
1445:40 - the actual
1445:41 - portability and what is the
1445:43 - drawback lack of true parallelism even
1445:46 - if multi multiple processors are
1445:48 - available scheduling and management is
1445:50 - the responsibility of user now this is
1445:52 - going to increase the the complexity
1445:54 - blocking issues if one thread needs IO
1445:57 - OS will block the process well that's
1445:59 - well that's the point I want to make see
1446:03 - user these user level threads are
1446:06 - managed at the user level operating
1446:08 - system will see it as the process now
1446:11 - what happened this thread wants some IO
1446:14 - Services by operating system or this
1446:15 - wants the operating system to perform
1446:18 - some IO
1446:19 - service this wants to read some data
1446:21 - from the disk now what OS will do OS as
1446:25 - OS see them as the process OS is going
1446:27 - to block all of them if one thread makes
1446:31 - some IO request as you know whenever
1446:33 - process makes IO request operating
1446:35 - system blocks that process look put that
1446:37 - in the block CU similarly if some
1446:41 - thread makes an IO request operating
1446:44 - system see all these threads as the
1446:46 - process so it's going to block them
1446:48 - whole all of them as a
1446:50 - process that is the series drawback
1446:53 - blocking issues if one thread needs IO
1446:55 - OS will block all of the threads okay
1446:59 - and this will be solved if operate OS
1447:01 - kernel is
1447:03 - multi-threaded now what is the meaning
1447:04 - of this how blocking issues will be
1447:06 - solved if OS kernel is multi-threaded
1447:08 - see
1447:11 - here suppose This Thread This Thread
1447:14 - makes an IO request so instead of
1447:16 - blocking them
1447:18 - all this thread of the kernel level is
1447:21 - going to serve this user level thread
1447:23 - will serve the io and rest of the
1447:26 - threads will keep on working these these
1447:29 - kernel level threads will keep on
1447:31 - serving those user level
1447:33 - threads are you getting the point so
1447:36 - this thread make a request instead of
1447:38 - blocking the whole these all of threads
1447:41 - if the kernel level thread if the kernel
1447:43 - is multi-threaded this thread is going
1447:44 - to serve the io and rest of them will
1447:47 - keep on
1447:48 - working okay see this diagram here we
1447:52 - have the user space this is the kernel
1447:55 - space so this is a process which
1447:58 - contains several threads a process which
1447:59 - contains several threads now you know
1448:01 - that kernel maintains the process table
1448:04 - similar way process will maintains the
1448:06 - thread table okay so this was all about
1448:09 - user level thread now we'll learn about
1448:10 - kernel level thread direct operating
1448:13 - system
1448:14 - management direct operating system
1448:16 - management it will show True parallelism
1448:19 - kernel level threads can be executed on
1448:22 - multiple processor parall see at this
1448:25 - diagram initially what we had the
1448:29 - operating system as I as I told you
1448:30 - there is transparency operating system
1448:32 - will see them as the process instead of
1448:34 - threads so it will maintain a process
1448:36 - table only and the process will maintain
1448:38 - the thread table now this was the user
1448:41 - level thread now we comes to the kernel
1448:42 - level thread this is the kernel space so
1448:47 - in the kernal level threads you know
1448:49 - these the the operating system knows
1448:51 - that the threads are created here
1448:53 - operating system doesn't know that in
1448:55 - process threads are present that's why
1448:57 - it has only maintained the process table
1448:59 - here these threads are directly uh
1449:01 - supervised by the operating system so
1449:03 - operating system with process table also
1449:06 - maintains the thread table because the
1449:08 - these threads are acknowledged by
1449:10 - kernels or operating
1449:13 - system so with process table it will
1449:15 - also maintain the threat table oper
1449:18 - operating system is managing the process
1449:19 - and threats
1449:21 - both okay
1449:24 - blocking handling unlike user level
1449:26 - threads if one kernel level threads get
1449:29 - blocked other keep
1449:30 - running managed completely by the oper
1449:34 - see when in the user level thread
1449:37 - operating system see them as a process
1449:39 - if one thread will be blocked operating
1449:41 - system doesn't know that there are some
1449:44 - threads inside the process so to block
1449:46 - the operating system will block the
1449:48 - whole process uh the process as a
1449:51 - whole okay but in kernel level the
1449:54 - operating operating system knows that
1449:56 - there are different threads present so
1449:59 - instead of blocking the uh the whole
1450:01 - process it will block a thread only so
1450:05 - in kernal level threads if one is
1450:07 - blocked then others keep running and it
1450:09 - is managed completely by the OS so less
1450:12 - responsibility on the
1450:13 - user but slower contact switching than
1450:17 - user level thread you know that why is
1450:19 - it slower because it involves complex
1450:21 - data structur more scheduling overhead
1450:24 - and due to Kernel level
1450:25 - involvement the Contex switching time is
1450:28 - more in the kernel level threads and in
1450:33 - user level threads maintained at user
1450:35 - level simpler data structures this will
1450:37 - create or this will cause faster contact
1450:39 - switching let's compare user level
1450:42 - threads faster contact switching custom
1450:44 - scheduling as it is maintained by the
1450:46 - user less overhead but blocking issues
1450:49 - or no true
1450:51 - parallelism because the belong to a
1450:53 - single process by the operat as what
1450:55 - operating system know that this is a
1450:58 - process this is a just a process it
1451:01 - doesn't know that in that process there
1451:02 - are threads
1451:04 - living kernal Level Threats better
1451:06 - blocking handling true parallelism
1451:08 - better OS integration but higher
1451:10 - overhead or slower contact switching
1451:12 - let's read again and then we will close
1451:13 - the lecture user level threads faster
1451:15 - contact switching custom scheduling less
1451:18 - overhead but blocking issues no true
1451:20 - parallelism and in Cal Level Threats
1451:22 - better block better blocking headling
1451:25 - true parallelism better OS integration
1451:27 - as managed by OS only but higher
1451:29 - overhead and slower Contex
1451:33 - switching system call and Fork this is
1451:36 - our miscellaneous topic part two you
1451:39 - know what is a system call this is our C
1451:41 - program print f is in a standard C
1451:44 - library want to use the system call
1451:46 - right so we have to shift the mode from
1451:48 - user to Kernel and after the work is
1451:50 - done shift it back from kernel to user
1451:52 - you know all these things uh we have
1451:55 - learned in detail in our section
1451:58 - one now the question is How are
1452:01 - parameters passed from user to Kernel
1452:03 - mode there are three methods the first
1452:05 - one is register the second one is memory
1452:07 - and the third one is
1452:08 - stack if the number of parameters are
1452:10 - less we can directly pass those
1452:12 - parameters to operating system by
1452:14 - placing them onto
1452:15 - resistors and then resistors uh the
1452:18 - operating system will access those
1452:20 - parameters with those resistors if
1452:22 - number of parameters are more than the
1452:24 - resistors then we will store them in
1452:27 - form of a table or in a block in memory
1452:30 - and the block address will be passed to
1452:32 - the resistors and with the help of that
1452:35 - resistor operating system will access
1452:38 - those parameters and the third one is
1452:40 - stack we will place the parameters onto
1452:42 - the stack and operating system will pop
1452:44 - them off the stack and will use
1452:47 - them this is used when number of
1452:50 - parameters are less and these are used
1452:52 - when number of parameters are more the
1452:54 - same thing is written
1452:57 - here three methods used to pass
1452:59 - parameter to the the first or the
1453:01 - simplest one is pass the parameters and
1453:03 - resistor but what happens when the
1453:06 - parameters are more than resistors store
1453:08 - the parameters in a block or a table in
1453:10 - memory and address of the block is
1453:12 - passed as a parameter in a register this
1453:15 - approach is followed by Linux or Solaris
1453:17 - Linux and Solaris parameters placed or
1453:21 - pushed onto the stack by program and
1453:23 - popped off the stack by operating system
1453:26 - block and stack method do not limit the
1453:27 - number of number or length of the
1453:29 - parameters being used okay so what we
1453:31 - did this is X is the parameters for the
1453:34 - call we stored the address of that block
1453:37 - in the resistor and passed it onto the
1453:39 - passed it to the operating system so
1453:42 - address of the block of memory
1453:43 - containing parameters this is X and it
1453:46 - is passed to the operating system with
1453:48 - the help of a resistor and operating
1453:49 - system will access the system calls or
1453:53 - the
1453:54 - parameters now we should know some basic
1453:56 - system call related to the process
1453:58 - management file management and directory
1454:00 - management here it is written you can
1454:02 - read them all for Process Management
1454:04 - file management for directory management
1454:07 - and these are some of the miscellaneous
1454:09 - system
1454:16 - calls folk system
1454:19 - call as you have already heard about it
1454:22 - execution of FK system call results in
1454:24 - the creation of child process the code
1454:27 - of child process will be an exact
1454:29 - replica of parent process everything
1454:31 - will be copied just the duplicacy of
1454:34 - process will occur execution in child
1454:37 - will start from the next statement after
1454:39 - Fork till the end of a program okay
1454:42 - suppose this is my parent process here
1454:44 - somewhere comes
1454:46 - fork and some other lines of code then
1454:49 - when this Fork will be executed the same
1454:53 - code will be present in the child but
1454:55 - the execution will start from this
1454:57 - statement after the fork the above four
1454:59 - lines before Fork will also be there in
1455:02 - the child process but they won't be
1455:04 - executed the execution will begin from
1455:06 - the next statement after
1455:09 - fork and as I've told you process is
1455:13 - duplicated so there will be separate
1455:15 - area for memory child and parent are
1455:17 - independent no Master Slave relationship
1455:20 - there is just the duplicacy of process
1455:22 - and and one relation between child and
1455:24 - parent is the code of both child and
1455:26 - parent are same okay let's see here we
1455:30 - have this is the parent process okay
1455:33 - these two these two statements are of
1455:34 - parent process now if I ask you the
1455:37 - output of this code
1455:39 - then firstly will the execution begin
1455:42 - from Main this Fork Fork will be
1455:45 - executed as soon as this Fork is
1455:47 - executed creation of child process will
1455:50 - occur but the execution in child will
1455:53 - begin from the next statement after Fork
1455:57 - so what will be the order firstly the
1455:59 - fork of parent will be executed then
1456:02 - print F that is print statement of child
1456:04 - will be executed and then it will go
1456:06 - back and then the print of parent will
1456:08 - be executed and this child will will
1456:11 - have will be exact replica but execution
1456:14 - will start from the next statement after
1456:16 - Fork so if I ask you the output
1456:19 - then Fork this print statement and this
1456:23 - then this printing statement they will
1456:25 - print hello two times so hello and hello
1456:27 - will be the
1456:29 - output see this print F High fork and
1456:34 - print hello so firstly this print F high
1456:35 - will be executed so high will be printed
1456:38 - then Fork execution of fork will result
1456:40 - in the creation of child process so this
1456:42 - process will this child process will be
1456:44 - there code will be exact same but
1456:47 - execution will start from the next
1456:48 - statement so firstly this will be
1456:50 - executed then this then this and then
1456:52 - the meaning it will the control flow
1456:54 - will go back to parent and then
1456:55 - execution will start after the fork so
1456:58 - here print F will be printed or or hello
1457:00 - will be printed which is hello so what
1457:03 - will be the final output hi this is
1457:06 - printed Fork execution of child
1457:09 - execution will result in the creation of
1457:10 - child process then hello from child will
1457:13 - be printed and then hello from parent
1457:14 - will be printed so hi hello and hello
1457:17 - will be the
1457:19 - output see this we have three folks now
1457:22 - and and in the end I have print F
1457:24 - hello look it carefully how the control
1457:27 - flow goes this is the parent process and
1457:30 - 1 2 3 4 these are the statement numbers
1457:32 - first for executed creation of child
1457:35 - process code will exact same which means
1457:37 - these four statement will be same in all
1457:40 - of them so 1 2 3 4 here also but
1457:43 - execution will begin from next statement
1457:45 - after four which mean from two what is
1457:47 - the next statement again for so
1457:49 - execution of this will will result in
1457:51 - creation of another child
1457:53 - process execution will start from next
1457:56 - statement after Fork what is the next
1457:57 - statement again Fork the execution of
1457:59 - fork will result in the creation of
1458:00 - child process execution will begin from
1458:04 - begin from next statement after for what
1458:05 - is the next statement hello hello will
1458:07 - be printed control flow goes back see
1458:10 - three was already executed now again
1458:11 - hello will be printed control flow goes
1458:13 - back now three what is three Fork
1458:17 - execution of fork will result in the
1458:19 - creation of child process now in child
1458:22 - process execution start after Fork so
1458:24 - hello will be printed again control flow
1458:26 - goes back now four which is hello hello
1458:30 - will be printed again control flow goes
1458:32 - back now this is statement what's this
1458:34 - Fork execution will result in the
1458:37 - creation of child
1458:38 - process execution will start after four
1458:41 - which is from statement three execution
1458:43 - of three will result in the creation of
1458:45 - another child
1458:46 - process execution will start from next
1458:48 - statement that is four hello will be
1458:50 - printed control flow goes back hello
1458:52 - will be printed control flow goes back
1458:54 - now three what is three four will result
1458:57 - in the creation of another child process
1458:58 - execution start from next that is four
1459:00 - hello will be printed so how many times
1459:02 - hello will be printed 1 2 3
1459:09 - 4 5 6 7 and 8 so in the exact same order
1459:15 - hello will be printed okay so firstly
1459:17 - this hell printed control flow goes back
1459:19 - this hell printed control flow goes back
1459:21 - but here this statement control flow now
1459:23 - goes back this will be executed control
1459:26 - flow goes back here down there this will
1459:28 - be executed goes back this will be
1459:30 - executed here this will be executed and
1459:32 - then in the last this four will be
1459:34 - executed okay see if you are losing
1459:38 - somewhere don't worry create create on
1459:41 - your own when you will create this tree
1459:43 - on your own then you will get the idea
1459:45 - how this is executed just remember two
1459:47 - points what I have told you execution of
1459:50 - fork will result in the creation of
1459:51 - child process and the execution in the
1459:54 - child process will start after the fork
1459:56 - statement and all of the code will be
1459:59 - copied in the child process also but the
1460:02 - difference is execution will begin from
1460:05 - the statement after the
1460:07 - fork
1460:10 - okay let's move to this I have main
1460:14 - print one fork print two Fork print
1460:17 - three so what will happen these are the
1460:20 - five statements I have 1 2 3 4 five
1460:22 - statements in the parent process one
1460:24 - will be printed now Fork execution of
1460:26 - fork will result in the creation of
1460:27 - child process 1 2 3 4 5 all will be
1460:30 - there but what will be printed execution
1460:33 - start after Fork so three third
1460:36 - statement that is which is two two will
1460:38 - be printed and then four this four will
1460:41 - be executed which will result in the
1460:43 - creation of another child
1460:45 - process execution will start after this
1460:47 - for so three will be
1460:49 - printed okay so how does it goes one is
1460:52 - printed and then two is printed and then
1460:57 - three is printed and then it goes back
1460:59 - it goes back three is printed it goes
1461:02 - back this four Fork result in the
1461:05 - creation of child process three is
1461:07 - printed goes back three is printed so 1
1461:15 - 2 1 2 3
1461:19 - 3 2 3 3 this will be the order 1 2 3 3 2
1461:24 - 3 3 let me show you again
1461:27 - 1 then it goes here two then it goes
1461:31 - here three then it comes back three it
1461:34 - comes back two and then it goes down
1461:36 - here three and then it comes back three
1461:39 - so this will be the order okay now you
1461:41 - may have guessed from this that when I
1461:44 - was
1461:44 - using when I was using a single Fork
1461:47 - hello was printed two times when I was
1461:49 - using Three Forks hello was printed
1461:52 - eight times so if I have used one fork
1461:54 - then two process will be created two
1461:56 - forks four process will be created Three
1461:58 - Forks eight process will be created if I
1462:01 - used n Forks then 2 power n process will
1462:04 - be there but remember remember remember
1462:08 - this will these also include the parent
1462:10 - process see here when I had one fork
1462:12 - when I had one fork then there were two
1462:14 - process this process and this process
1462:16 - which also included the parent process
1462:18 - so if someone ask I have n number of
1462:20 - folks what will be the ch process 2^ n
1462:24 - and then minus one why minus one because
1462:27 - of this 2^ n also include the parent
1462:30 - process but we are asked with the child
1462:32 - process that's why 2^ n minus
1462:34 - 1 return value of for if I write
1462:38 - something like this int a equals to
1462:41 - Fork this when this statement will be
1462:45 - executed when this statement will be
1462:47 - executed then there will be a new child
1462:50 - process with the same code
1462:53 - but the value of fork will be different
1462:55 - in both of them for parent process the
1462:58 - value of fork will be positive but for
1463:00 - the child the value of fork will be zero
1463:02 - who maintains that the O Fork
1463:05 - routine see here I have a code like this
1463:09 - main int return return equals to fork
1463:12 - and if the return value equals to equals
1463:14 - to zero then this will be the child
1463:16 - process code and if else then this will
1463:21 - the parent process code and rest when no
1463:23 - condition is present then it will be
1463:25 - executed by both child and
1463:27 - parent what is the use of the return
1463:30 - value the four can return three value it
1463:32 - can return either negative zero or
1463:34 - positive if it returns positive then it
1463:36 - represent the parent process if it
1463:39 - returns zero then it represent the child
1463:41 - process and if it returns negative then
1463:44 - the execution of fork was a
1463:46 - failure okay so let's say this was our
1463:51 - program
1463:53 - this was the parent process so the value
1463:56 - of fork for parent process will be
1463:58 - something positive so we have written
1464:00 - here one who will maintain this Fork
1464:02 - routine of the operating system so one
1464:04 - is present here return equals to Fork if
1464:08 - return equals to equals to zero well
1464:10 - this is not zero so this part will not
1464:13 - be executed lse part will be executed
1464:15 - and the part which is not conditioned
1464:17 - will be executed did you get it I have
1464:20 - defined or I have declared the return
1464:24 - variable okay so there is a return
1464:25 - variable return equals to Fork as soon
1464:28 - as this Fork will be executed because
1464:30 - this is a parent process so some
1464:32 - positive value come here and a child
1464:34 - process will be created with return
1464:36 - value
1464:37 - zero did you get
1464:40 - it here I have declared the return value
1464:43 - return variable is declared here with
1464:45 - some garbage value in it return equals
1464:48 - to Fork as soon as this line is executed
1464:51 - return equals to Fork this one will come
1464:53 - here or any positive value will be
1464:55 - stored in the return and the execution
1464:59 - of fork will result in the creation of
1465:00 - child process so the child process same
1465:03 - thing are present same variable is
1465:05 - declared here also but the value of
1465:07 - return will be different the value of
1465:09 - return will be zero here this zero will
1465:11 - represent that this process is the child
1465:13 - process and the positive number will
1465:15 - represent that this process is the
1465:17 - parent process and who will maintain
1465:19 - these numbers of return os4
1465:22 - routine okay so what happens here if
1465:25 - return is one or any positive value then
1465:28 - this part will not be executed this part
1465:29 - and this part will be executed and if
1465:31 - return is zero then see this will this
1465:35 - will not be executed because I've told
1465:36 - you that execution in child will start
1465:39 - after the 4 key statement so execution
1465:41 - will begin from here is the return value
1465:43 - zero yes go inside the block else part
1465:46 - will not be executed this will be
1465:47 - executed why because this is not
1465:49 - conditioned so this the part of the code
1465:52 - which is not condition is executed by
1465:53 - both child and
1465:55 - parent okay see this question I have
1465:58 - main int AAL to 5 b = to 3 and C C = to
1466:02 - ++ a mtii b ++
1466:06 - okay print f a b c if Fork = toal to0
1466:12 - then a = to a + 5 b = to B + 3 print F
1466:16 - ab and C = to cus 1 otherwise which
1466:20 - means this will be the parent process
1466:22 - code b + a b + = to a plus = to 2 C I
1466:28 - have also included some uh I have also
1466:31 - made this question trickier by including
1466:34 - the concept of c c language print f a
1466:37 - comma b c = to C minus1 and then print f
1466:41 - c so if you see clearly this part this
1466:44 - if block will be executed only by fork
1466:47 - and will be ignored only by child and
1466:49 - will be ignored by the parent this part
1466:52 - will be executed only by the parent and
1466:54 - will be ignored by the child and this
1466:56 - part will be executed by
1466:59 - both try to solve this
1467:02 - question
1467:04 - okay so I have initially five 3 and
1467:09 - let's say Zer is present in the C now
1467:12 - what happened C equals to Plus+ a * b++
1467:16 - this Plus+ a says increase the value
1467:19 - first and then use so I increase the
1467:21 - value first 5 to six and then used here
1467:24 - and the value of a is also
1467:26 - updated this b++ says use the value of
1467:29 - B+ and then update so I've used the
1467:31 - value of B that is three here and then
1467:33 - updated it to four now what is c c is 18
1467:36 - so from here I got C is 18 print a b c
1467:40 - we printed a BC a is 6 B is 4 and C is
1467:44 - 18 this will be printed now this part
1467:48 - will be executed by child only this part
1467:50 - will be executed by parent only and this
1467:51 - part by both so let's see the child part
1467:54 - first the value of
1467:56 - a is the value of a is a + 5 so value of
1468:00 - a will be
1468:01 - 6 + 5 which is 11 now the value of B
1468:05 - will be what is the value of B 4 4 + 3 =
1468:09 - 7 print AB so we have print 11 and 7 and
1468:13 - then C = to C - 1 what was C
1468:17 - 18 17 will be there then then what is
1468:21 - there this part part will be executed by
1468:22 - both so print C which is 17 will be
1468:25 - printed also now comes the parent part
1468:28 - in parent part what is written b + B+ =
1468:32 - to a plus = to 2 so what will happen we
1468:34 - have to solve from
1468:36 - here AAL to a +
1468:39 - 2 what was a here the value of a what
1468:44 - value of a will you use will you use 11
1468:46 - or will you use
1468:48 - 6 obviously I will use
1468:52 - six only why see you may get confused by
1468:57 - by seeing this code you may see that
1469:00 - this is the block and this is the part
1469:03 - of same code so when I have updated the
1469:06 - value of a here and then when this else
1469:09 - block will be executed then updated
1469:11 - value should be used because it is the
1469:13 - part of same code then you are making a
1469:15 - mistake
1469:17 - because let me let me write clearly what
1469:20 - is the part of or or I can
1469:24 - say how parents see the code the parents
1469:27 - see the code as this part this part and
1469:32 - this part how child see the code this
1469:35 - part this part this part and this part
1469:39 - for child this part is not present and
1469:41 - for parent this part is not
1469:43 - present you must remember that parent
1469:46 - and child are different process with
1469:48 - different piece of code do not try to
1469:51 - think that there are some there are some
1469:53 - uh same process with same piece of code
1469:56 - no for child this is not present in its
1470:00 - code section and for parent this is not
1470:02 - present in its code section so what will
1470:06 - the value of a which I use for this
1470:08 - parent I will use the updated value
1470:11 - which is six so I will use six here so 6
1470:13 - + 2 is 8 6 + 2 is 8 and B = to B + a so
1470:19 - what was b b was 4 so 4 + 8 = 12 now
1470:22 - print AB this part will be executed
1470:24 - print
1470:25 - AB 8 and 12 will be printed and then C =
1470:29 - to C minus 1 C equals to C that is 17
1470:32 - and then in the end
1470:34 - this
1470:35 - 17 so this is how it works do not try to
1470:40 - think that they belongs to they belong
1470:42 - to some same piece of code or same
1470:43 - process
1470:45 - no I have told you the only relation
1470:47 - between child and parent is their code
1470:50 - is same otherwise they are two different
1470:53 - processes with different piece of code
1470:57 - did you get it so I will not use the
1471:00 - value of a which was updated here at the
1471:04 - parent section because for parent this
1471:07 - piece of code is not present in its code
1471:09 - section and for child this piece of code
1471:11 - is not present in its code section
1471:15 - okay let's solve some more interesting
1471:18 - problems we have a main function int Inn
1471:22 - for I = to 1 I less than = to n++ I if 4
1471:27 - = to = to 0 Print Star see this is in
1471:33 - the for Loop and how many times for Loop
1471:35 - is Run 1 to n so this will be executed n
1471:40 - times so when during the time of
1471:43 - condition checking this system call will
1471:45 - be made and what will happen creation of
1471:48 - child
1471:50 - process so this four could be executed
1471:52 - how many times n times as the four Loop
1471:55 - has run n times so this four could be
1471:57 - executed n times how many times or how
1472:01 - many total processes will be there 2
1472:03 - power n but in child process only this
1472:08 - code will be there if for equals to
1472:11 - equals to Z then Print Star this Print
1472:13 - Star is present in the code for child
1472:16 - process only for parent process the
1472:19 - parent process will just ignore this
1472:20 - code
1472:22 - so out of 2^ n one process is the parent
1472:25 - process and 2^ N minus 1 is are the
1472:28 - number of child process this one process
1472:31 - which is the parent process will ignore
1472:32 - this code and rest of them will print
1472:35 - star so how many times the star will be
1472:37 - printed 2^ n minus
1472:40 - one by during the solving during solving
1472:43 - this
1472:44 - question a confusion may arise that
1472:48 - is this node is the parent of this node
1472:51 - so so here should be one and here should
1472:52 - be zero isn't it no this is wrong
1472:55 - there's only one parent and rest are
1472:58 - child it doesn't matter where child
1473:01 - produces another baby but they'll both
1473:04 - remain a child to a parent so there will
1473:07 - be only one parent and rest are child
1473:10 - for that parent okay so the child of a
1473:13 - child is also a child to a
1473:14 - parent okay let's see some more
1473:18 - interesting problems we have int
1473:22 - I and N for I = to 1 I is less than
1473:25 - equal to n Plus+ I so this Loop will
1473:28 - also run for n times if I mod 2 = to
1473:32 - equal
1473:32 - to0 it says from 1 to n from 1 to n n
1473:38 - by2 will be the even numbers so this
1473:41 - will run for n by2 times so this
1473:43 - represent the even numbers so for all
1473:46 - those even numbers run the fork from 1
1473:49 - to n the number of times even number
1473:52 - come run this Fork so how many times
1473:55 - Fork will be run n by two times so how
1473:57 - many child processes will be there 2 ra
1473:59 - to Power number of
1474:01 - time number of times four qu
1474:05 - run minus one so how many times four n
1474:09 - by two times so the total number of
1474:11 - child processes will be this much let's
1474:13 - see another question but now here is the
1474:17 - change int I comma n for this Loop will
1474:21 - run for end times if 4 equals to Z here
1474:25 - is the end and you know we have no
1474:29 - brackets after the for Loop or we have
1474:31 - no brackets like that
1474:33 - here when we do not apply brackets then
1474:37 - the next line the next line will be
1474:40 - considered in the loop when we do not
1474:42 - apply bracket then the next line only
1474:44 - will be considered in the loop so for
1474:47 - this for Loop this line was considered
1474:49 - and here also we did not apply bracket
1474:51 - so this line will be also considered so
1474:53 - these two line will be considered in the
1474:54 - for Loop but here what
1474:57 - happened here we have applied a
1474:59 - semicolon here which means this will not
1475:02 - be in the for Loop
1475:05 - now so this will be printed or this will
1475:08 - be executed how many times n times so
1475:12 - how many child processes will be there
1475:14 - this Fork was executed n times so this
1475:16 - will create 2^ n minus one child
1475:19 - processes and
1475:22 - child process has not to do any specific
1475:25 - work see here what I've told you if Fork
1475:31 - equals to equals to zero and some body
1475:33 - is there then this these line of code
1475:35 - will be executed only by child process
1475:37 - but
1475:38 - here there are no specific such lines so
1475:41 - child process will not execute any
1475:43 - specific code that parent will not
1475:45 - execute this is outside the loop so this
1475:49 - will be executed by both child and
1475:50 - parent
1475:52 - so how many times the star will be
1475:54 - printed 2^ n minus 1 times by the parent
1475:58 - and One Time by child also so 2^ n * the
1476:01 - star will be printed did you get it
1476:05 - see if Fork equals to Z and some if some
1476:09 - bracket will be there and some lines of
1476:10 - code then these will be executed only by
1476:12 - child process and rest will be executed
1476:15 - by both child and parent but here child
1476:18 - has nothing specific to do so both child
1476:20 - and parent will execute this line how
1476:22 - many times the number of process how
1476:26 - many total process are there 2^ n so
1476:29 - this will be executed 2^ n times okay so
1476:32 - the number of times will be 2^
1476:35 - n see this Main in a if Fork equal toal
1476:40 - to
1476:40 - 0 a = to a + 5 and print a else a = to a
1476:46 - - 5 and then print a what is the
1476:48 - relation between U and
1476:50 - X so a is not initialized here so what
1476:53 - we are doing we are just taking for the
1476:54 - sake of Simplicity a equals to Z
1476:57 - remember when the values are not
1476:59 - initialized garbage value is present but
1477:01 - for the sake of Simplicity now we are
1477:02 - taking a equals to 0 if Fork equals to
1477:05 - equals to0 here Fork has come so
1477:07 - creation of child process will be there
1477:09 - now there are two process a child and a
1477:11 - parent both child and parent both child
1477:15 - and
1477:16 - parent has has nothing common child will
1477:20 - execute this code
1477:21 - and the parent will execute this code
1477:23 - and there is nothing outside the fs so
1477:26 - there is no common thing that the both
1477:28 - child and parent will execute initially
1477:29 - we have taken AAL to
1477:32 - 0 so for child a = to a + 5 so value of
1477:36 - a will be 5 and then it will print five
1477:40 - see like this I'll give the statement
1477:43 - one the statement two and the statement
1477:46 - three int a executed two
1477:51 - two now this is the parent process so
1477:54 - for parent process which piece of code
1477:56 - is present this piece of code we have
1477:58 - taken initially the value of a is zero
1478:00 - so value of a will be minus5 and it will
1478:02 - print
1478:03 - minus5 and at the same time the child
1478:06 - process is also present and the
1478:08 - execution will start from the next line
1478:10 - after the fork what is the next line a =
1478:12 - to a + 5 so a = to A+ 5 a was initially
1478:15 - zero now a equals to 5 print
1478:17 - five okay print five and this part is
1478:21 - not present in the this part is not
1478:24 - present in the child and this part is
1478:26 - not present in the parent so what is the
1478:29 - relation between U and X let's say the U
1478:33 - it is U is 5 and X is - 5 so what is the
1478:38 - relation I can say u = x + 10 well u = x
1478:43 - +
1478:46 - 10 okay note what is the note physical
1478:49 - address will be different virtual virual
1478:51 - address will be same physical address of
1478:53 - variable in child and parent will be
1478:55 - different but virtual address will be
1478:56 - same because what is virtual
1478:58 - address virtual address is related to
1479:01 - the code both code in child and parent
1479:04 - is same so the generation of virtual
1479:07 - address will also be same but as they
1479:10 - are to different process so the physical
1479:13 - address will be
1479:15 - different see if uh you can try this at
1479:18 - your home
1479:20 - also try to create a child process and
1479:23 - try to print the virtual address of a
1479:26 - variable you will see that virtual
1479:29 - address uh you will see that both
1479:31 - address of parent and child of that
1479:33 - variable will be
1479:34 - same both the address will be same then
1479:38 - how can I say physical address are
1479:40 - different see on printing we get virtual
1479:43 - address so those virtual address will be
1479:46 - same but physical address where the
1479:48 - variables are or the data are actually
1479:50 - stored in the memory will be different
1479:52 - for the different process okay and child
1479:55 - and parent are actually two different
1479:58 - process so for the physical address will
1480:00 - be different but virtual address of the
1480:02 - variables will be same till now we have
1480:05 - completed the fork system call threads
1480:08 - and multi-threading now it's time to
1480:10 - learn about inverted page table or
1480:12 - reverse paging you know that page table
1480:15 - also consume space so this is a
1480:18 - technique to reduce space overhead of
1480:19 - page table in page
1480:22 - each process will have its own virtual
1480:23 - address space and Page table so this is
1480:25 - the virtual address space it generates
1480:28 - the virtual address or logical address
1480:30 - this is page number here we will see the
1480:32 - frame in which that page is stored this
1480:34 - Frame number will be copied here and D
1480:35 - will be copied here there we got our
1480:38 - physical address
1480:39 - space okay so this was the concept of
1480:44 - paging but you remember that each
1480:47 - process will have its own virtual
1480:48 - address space suppose this is process I
1480:50 - and this is process J
1480:51 - process I will have its own virtual
1480:53 - address space and its own page table
1480:55 - process J will have its own virtual
1480:57 - address and its own page table okay so
1481:01 - the pages of this process J and the
1481:04 - pages of this process I are mapped onto
1481:07 - the same physical memory see here the
1481:12 - pages of let's say process I and process
1481:14 - J are present in the same main memory
1481:17 - suppose this is this p 0 and this p 0
1481:21 - both have same name so this p 0 is
1481:24 - present here and p 0 is present here so
1481:26 - what happens in the frame table in the
1481:29 - frame table so this is the frame number
1481:31 - and this is the page number of the
1481:34 - process we also include the process
1481:37 - ID because otherwise it will cause
1481:39 - confusion that this page number one is
1481:42 - of which process page it may be page
1481:45 - number one of process I it may be page
1481:47 - number one of process J and there are so
1481:49 - many process it could be page number one
1481:50 - of any process that's why we have
1481:54 - another section which will uh store the
1481:58 - process ID with the page number so this
1482:00 - is the frame number this index will tell
1482:04 - that at frame number four at frame
1482:07 - number four process I process I page
1482:11 - process one is stored so this will be
1482:14 - copied here and D will be copied here
1482:17 - and you know when process will generate
1482:20 - The Logical address
1482:21 - with page number it will also tell the
1482:25 - ID so we call this page number and ID
1482:27 - combination as key so this is the key so
1482:31 - we will search with this key in the
1482:33 - frame
1482:34 - table and number of entries will be
1482:36 - equal to number of
1482:38 - frames the point is Pages all the
1482:42 - processes are being mapped on the same
1482:44 - physical address space pages of all
1482:46 - process are being mapped on the same PS
1482:49 - can't we design a page table based on
1482:50 - the the PS some kind of global page
1482:53 - table for each process see what are we
1482:55 - doing here we know that each process
1482:58 - will have its own page table so instead
1483:00 - of
1483:01 - keeping page table instead of uh having
1483:04 - page table for every process why can't
1483:06 - we just create a global page
1483:08 - table see you know that the pages of
1483:12 - this process and the pages of this
1483:14 - process are both at the same place can't
1483:17 - we generate a global page table from the
1483:20 - help of this we will access the
1483:22 - pages you getting the point let me
1483:24 - repeat both the pages of this virtual
1483:27 - address and this virtual address space
1483:28 - are being stored at the same place can
1483:30 - we generate a global page table for all
1483:32 - the
1483:35 - processes can we generate that kind of
1483:37 - architecture this will going to
1483:39 - significantly reduce the page table
1483:43 - overhead so we are trying to create some
1483:46 - CL some kind of global page table so in
1483:48 - inverted paging one Global page table is
1483:50 - used used by all the process in
1483:52 - traditional approach let's say we have
1483:54 - 100 process then we will have 100 Pace
1483:56 - tables so to save his spce sacrifice
1483:59 - time to save space sacrifice time but
1484:02 - the search will increase in in
1484:05 - traditional the search time was constant
1484:07 - but here the search time will depend on
1484:09 - the number of entries so the search time
1484:10 - will increase but space will be
1484:13 - significantly saved when we'll see some
1484:15 - problems then you will going to realize
1484:18 - how much how much drastic change has
1484:20 - come by using this Global page table and
1484:23 - you know page table size is not less and
1484:26 - if we somehow are able
1484:28 - to combine all those pages all those
1484:31 - page table characteristic into one page
1484:33 - table then it will going to
1484:36 - revolutionize let's see this we have a
1484:39 - virtual address of 34 bits page size is
1484:42 - of 8 KB physical address is of 29 bit
1484:45 - page table entries of 32bit what is the
1484:47 - size of page table traditional versus
1484:50 - inverted
1484:51 - virtual addresses space will be 2^ 34
1484:54 - page size we know 8 KB so number of
1484:56 - pages or number of entries in the
1484:58 - traditional page table will be 2 21 and
1485:01 - the size of each entry is 4 by so here
1485:03 - it will be 8 MB the
1485:06 - total the page table size per process
1485:09 - will be 8 MB and how many processes are
1485:12 - there no we are talking about just one
1485:15 - process so the total page table size
1485:17 - will be of 8
1485:18 - MB number of entries in the we are
1485:21 - talking now about inverted page table so
1485:23 - number of entries will be equals to
1485:24 - number of frames how many frames are
1485:26 - there 2^ 29 and what is the uh page size
1485:32 - 2^ 13 so we'll have 2^ 16 entries the
1485:36 - table size here will be 2^ 16 into 2^ 2
1485:40 - as each entry will have four bytes so we
1485:43 - will have 256 KB only see in the
1485:46 - traditional case in the traditional case
1485:48 - we have P pce table uh size per process
1485:51 - 8 MB and here we have the global page
1485:54 - table of 256 KB now let's say there are
1485:57 - 100 process then traditionally it will
1485:59 - it will require 800 MB of memory to
1486:02 - store the page table only and in
1486:06 - inverted no matter how many processes
1486:07 - are there all of them are going to use a
1486:09 - global page
1486:10 - table 256 KB only did you get it let me
1486:15 - repeat again the problem was each table
1486:19 - will have its own virtual address space
1486:20 - and and will have its own page
1486:24 - table this virtual address space won't
1486:26 - create a problem because it is mapped on
1486:28 - the hard disk and hard disk has enough
1486:30 - size but the page table is stored in the
1486:34 - memory and each when each process will
1486:37 - have its own page table then what are we
1486:40 - doing traditionally we are storing each
1486:42 - page table into the
1486:43 - memory but we know what that the pages
1486:48 - of the virtual address space are stored
1486:50 - in the
1486:51 - frames of the memory so these pages are
1486:54 - also stored in the memory these pages
1486:55 - are also stored in the memory all of
1486:57 - them are mapped on the same physical
1486:59 - address pages of all process are being
1487:00 - mapped on the same physical address
1487:03 - can't we design a page table which is
1487:05 - global page table through which we can
1487:08 - address or we can uniquely identify the
1487:11 - page or we can uniquely identify the
1487:13 - frame in which the desired page of the
1487:15 - desired process is
1487:18 - present that's what this Frame table has
1487:20 - helped us to achieve let's say CPU
1487:23 - generated The Logical address here with
1487:25 - the logical address there is a little
1487:26 - bit
1487:27 - difference in page number we also have
1487:31 - the ID of the
1487:33 - process so this page number and the ID
1487:36 - will create a key and with this key we
1487:38 - are going to search in this Frame table
1487:40 - and what does frame table contain the
1487:42 - index contains the frame number and the
1487:45 - entries contain the page number and the
1487:47 - ID so this P1 is present here also P1 is
1487:50 - present here also if ID won't be there
1487:52 - then how I'm going to identify this P1
1487:55 - is of which process it may be of process
1487:58 - Pi it may be of process PG so ID is also
1488:02 - present
1488:04 - now search with this key in the frame
1488:09 - table in the traditional approach what
1488:11 - we were doing we were searching based on
1488:13 - the based on the index number see what
1488:16 - are we doing in the traditional we were
1488:18 - searching based on the index number this
1488:20 - P was searched at
1488:22 - this that's why the time taken to access
1488:26 - that particular uh access the particular
1488:28 - frame number or the time taken to
1488:30 - acquire that particular frame number was
1488:32 - constant why because we can directly
1488:34 - jump to that index we can directly jump
1488:36 - to that index but here we have to search
1488:39 - we are not searching through frame
1488:41 - number or the index we are not searching
1488:43 - through index we are searching based on
1488:46 - this key we will search for each and
1488:47 - every entry in the list
1488:51 - suppose the CPU want to or the process
1488:54 - want to access the frame in which page
1488:56 - number one of process I is present so it
1488:58 - will generate an address like P1 and
1489:01 - I okay so P1 and I now it is going to
1489:05 - search is P1 and I is present P1 I P1 I
1489:08 - P1 I no I got P1 I which index has or
1489:12 - which index has a stored this P1 I index
1489:14 - 4 is a stored so this will be copied
1489:16 - here and D will be copied here and
1489:18 - that's how I got my physical
1489:21 - address now each of them each of the
1489:24 - process is going to use this single
1489:27 - frame table instead of having own each
1489:30 - instead of having its own table own page
1489:32 - table every time we are using a global
1489:35 - page table or we call it as frame table
1489:37 - index contain the frame number and with
1489:39 - the help of this key we search each and
1489:41 - every entry wherever we get the entry
1489:43 - that index will be our answer and we are
1489:45 - going to take that index forward as the
1489:47 - frame number and D will be copied here
1489:49 - that's how I got my physical address
1489:51 - traditionally what we were
1489:53 - doing with the help of this page number
1489:56 - we were directly jumping to the
1489:58 - index and the entry was our answer here
1490:01 - the entry is not the answer the index is
1490:03 - the answer the index is what we want so
1490:06 - index will be copied here this D is
1490:07 - present here that's how we get the
1490:10 - physical
1490:11 - address okay so what we did the all the
1490:15 - pages of the process are mapped on the
1490:16 - same main memory so why can't we
1490:18 - generate a global page table that's what
1490:21 - we have tried to achieve here with the
1490:22 - help of this Frame table so inverted
1490:24 - paging one Global page table is used by
1490:26 - all the process in traditional approach
1490:28 - 100 process will have 100 page tables
1490:31 - but in uh inverted page table process no
1490:35 - matter how many processes are there
1490:37 - there will be only a single page table
1490:39 - which is global page table or we also
1490:40 - call it as frame table but the drawback
1490:43 - is here we can directly jump to the
1490:46 - index and find the frame number quick
1490:48 - quickly but here we have to search each
1490:49 - and every entry so what will be the
1490:51 - search time o n and what will the search
1490:53 - time the
1490:55 - constant okay so this question we have
1490:57 - tried remember one thing that number of
1491:00 - entries will be equals to number of
1491:01 - frames here the number of pages were
1491:04 - being used as index and here the frame
1491:07 - is used as index so how many indexes
1491:10 - will be there the number of frames so
1491:12 - how many entries will be there equals to
1491:13 - the number of frames okay so here the
1491:17 - page table size the traditional page
1491:18 - table size we got was 8 MB and and here
1491:20 - we got the page table sizes as 256 KV
1491:23 - now if there are 100 process then the
1491:26 - traditional approach will consume around
1491:28 - 800 MB and the inverted page table
1491:31 - approach will consume just 256 KB if it
1491:34 - were th000 process then it will consume
1491:36 - 8,000 MB and inverted will just consume
1491:39 - 256
1491:40 - KB did you get it how simple this
1491:43 - is can you compare the size this is
1491:46 - nothing in front of 800 MB

Cleaned transcript:

in this massive 25hour operating system course you will learn the fundamental and advanced operating system Concepts in detail the course starts with defining what an OS is and its various roles then you'll learn about topics like Process Management CPU scheduling deadlock handling strategies memory management and more this course will give you a comprehensive understanding of how operating systems function and manage resources hey there well you have just landed upon the most comprehensive operating system course on this platform we have gone to the depth and have discussed each and every important Concept in detail which is included in our us cabus so first let's discuss the cabus Opera operating system course can be divided into seven major parts the first one is Introduction and background now comes Process Management CPU scheding process synchronization or coordination then comes the deadlock memory management and then in the end file management I believe in certain phases of learning the first one is Theory we understand the concept with the help of real life examples the theory is completed now we comes to numericals I believe problem solving is the best way to check whether you have understood the concept or not then comes the revision my mother said if you fail to revise you fail to learn after some days when you will open the notes and you'll try to read from that everything will seem new to you it will feel like you have never attended this course okay revision is must now let me tell you what the course offers the course offers 25 hours of comprehensive content 400 pages of lecture notes are discussed here although I advise you to make your own short notes but if you want to have the same notes from which I teach to you then you can visit the website I'll paste the QR code there you can visit the website and download the notes from there now who should take this course this course is perfectly suited for University students for their semester exams perfectly suited we have taken 100 plus up Notch numericals all handpicked from the standard textbook of operating system like Stallings galin and Tenon bomb I have taken important problems from the gate exam course is perfectly suited for the University students the gate aspirant or anyone who wants their operating system fundamental solid anyone who is curious who is preparing for some job job interview this course is for you now one last thing a guideline you can cannot just sit back relax and watch this course as a Netflix series no when I discuss Theory you make short notes when I discuss numericals you pause the video and attempt the numerical first by your own see if you just directly see the solution of a problem the problem is wased for you this will not help you grow you will never understand the beauty behind the problem you will never understand where you could have made mistake and that mistake you are going to make in the exam that's why I sincerely request you pause the video first attempt by your own and the third important thing you need to revise let's meet in the first lecture bye welcome to the operating system course this is sh Sharma starting with the chapter one introduction and background so before starting this chapter I'm feeling the need to clarify that there are some prerequisites of this course so you should know or you should have a little bit knowledge about computer organization and architecture I mean little bit about what is computer it's Hardware how does it work its architecture little bit knowledge about that is required you should have a programming exposure with any language either C or Java or any language you prefer you should have little bit of programming exposure okay so these are the two prerequisite and if you do not have them there's no need to worry I will brush up those concepts for you and I will briefly explain you about them okay so we are starting with the chapter one introduction and background so what we will do in this chapter we'll start with what is operating system functions and goals of operating systems types of operating system multiprogram operating system architecture requirement and so on mode shifting system calls folk system calls and in the end as I have promised in the preview problem solving okay so these are the three textbooks which I'm following for creation of this course always concepts by galin tenan bomb and Stallings okay so let's start so the first question which arises in our mind is what is an operating system so I'll give you several definitions and I'll explain them one by one okay so operating system is an interface between user and computer what is an interface now I'll explain them but first we should know a little bit about component of Hardware then only you will get a better idea about what does operating system system basically do okay so there are three components or three units of Hardware input output memory input output memory and CPU which is also known as processor so in CPU there are two units control unit and arithmetic logic unit let me change the color I think this will be good okay so control unit and arthamatic logic unit we'll study about what is control unit so control unit is the unit that have power of of generation timing or control signal clock signals you may have heard about it that controls the operation it has also widely known for sequential execution of micro operations now the question arises what are micro operations these are the operations that are carried out on data stored on resistors let me clarify those definitions so this is the high level program written here int ABC B is = 1 Cal to 2 A = to B plus C okay so this is a high level statement a Max operation now when it is passed onto the compiler it converts into several micro instructions like load the value of B into register R1 load the value of B into register R1 load the value of C into register R2 now add R1 and R2 and load the result into R1 now store the value of R1 into memory a so these are some micro instructions okay now the control unit is responsible for sequential execution that is first you have to do this then this then this and then in the end this who is responsible control unit is responsible okay so this was the architecture in which memory input output and processor this was the architecture proposed by V Newman it is most famous architecture okay so now we'll move down so we have understood what is control unit now let's understand what is ALU ALU is called functional unit unit what functions is perform it performs like arithmetic and logical functions so it's the main unit that carries out arithmetic and logical operations it consists of adders subtractors and so on now comes the memory part so we have studied in our earlier classes that there are two types of memory primary memory and secondary memory primary memory is also called as main memory and secondary memory is also called as auxiliary memory primary memory includes Ram Rome cach registers it's faster to access it's expensive and it is lower size and one most important thing about primary memory is it's volatile what does volatile mean volatile mean that the content vanishes when the power supply goes off it doesn't happen in the secondary memory secondary memory is nonvolatile that is content does not vanishes when the power supply goes off let's take an example you have downloaded a movie now you shut down your computer when you start again you found find the movie present there already but let's take an example of um let's say terminal you have written some code and then when you close the terminal the code finishes it can never be brought back so this is the primary memory and the secondary memory are these are the hard disk the pen drives these are the example of secondary memory so we have in the one num architecture we have written the three parts memory CPU and input output so which memory here I am referring to I am referring here here to primary memory CPU access only primary memory which memory primary that's why I have written P then what about secondary memory I have not seen secondary memory in this architecture where is it so that's that's why I have written it in form of question so where is secondary memory then so as per volum architecture secondary memory are the part of input output devices input output devices I hope that you must know what are input output devices it's like monitor keyboard printer and hard disk these are input output devices okay now an important concept come here how are programs executed in the one Newman architecture so this is the most important part of one num architecture you must pay a little more Focus here okay so let's take with an example we started with a file test. C so this is a C file as here it is we are seeing the extension do c so it's a C file C file is passed to the compiler compiler converts into the executable form that is in form of instruction i1 I2 till I in let's say there are any instructions okay now this instruction this whole instruction is passed onto the operating system what does operating system do here it loads thee file into the main memory this is an important part so when a program is loaded in memory for execution this concept is known as stored program con concept this is an important concept so what does OS do it loads the exe file from hard disk to main memory and then from Main memory it is passed to the CPU and CPU do the sequential execution that is CPU first take the in instruction one i1 execute it then I2 then it will execute it until in the end I in now the question arises so here I have written CPU cannot execute the program directly from the hard disk why is it so why does CPU cannot directly access from the hard disk why does it require the main memory why does it require the operating system that needs that exe file first transferred into main memory and then in CPU why does it happen because hard diss are slow the computer has high and fast processing speed but it cannot fetch that much data from hard disk it requires a fast memory so CPU is fast hard disk is slow we need something that can match the speed of CPU so this is main memory that is RAM and it is fast as CPU okay so first operating system need to transfer XE file to main memory here which I have shown and then CPU loads the program from in memory itself and does sequential execution of the instructions so the instruction of the program are executed sequentially one after another that we will learn more in the computer organization architecture course so what we have learned about the fundamental principles of vum architecture we have learned about store program concept that is see operating system loads thex file from hard disk to CPU and then second point is then CPU does the sequential execution of the instructions any program that has to be executed must be stored in the main memory that is the Golden Rule you have to remember okay now you can understand what is an operating system so here is the user here is our Hardware so operating system act as a bridge for communication between user and hardware user talks in the high level language operating system system is an interface which converts that into machine language that is understandable by Hardware Hardware performs the execution then it send the result to operating system and then it send the result to user okay so what is this representation this represent that whole language of user is between symbols a to zed that is our English language and the whole language of the computer is between the set 0 and one between symbol 0 and one okay this is just the representation so question arises how does operating system perform so much of work how does it do this work so how it is done so OS consist of several modules it consists of modules like process manager memory manager file manager device manager and protection manager all this combines and become kernel kernel of operating system it is also known as core or nuclear is okay so what I have taught you till now let me put this all into the same picture this is our user this is our hardware and in between there is an interface so these are the users I have symbolized in the cycle form and in the bottom there's a hardware so operating system manages the hardware and it act as an interface so there are two levels of interface level one and level two level one is user OS interface that is like a command interpreter which consist of shell or GUI can be either so it's a user OS interface that helps in communication between user and the OS so the level one interface helps with communication between user and the OS and then OS kernel performs the operation that is required by the user with the help or with the management of the hardware Hardware consist of CPU main memory input output devices what are what is OS kernel OS kernel consist of all these module process manager memory manager file manager device manager and prodection manager okay so this was operating system definition number one now let's move to definition number two that is operating system also act as resource manager so which resources I'm talking about I'm talking about software resources and Hardware resources Hardware resources include computer sorry CPU monitors input output devices and software resources are file SEMA 4 monitors so you don't need to worry there's no need to worry we'll explain all of them file SEMA 4 monitors in detail when the time will come okay and the second part is control program it act as a control program let me also tell you one thing in Resource Management operating system perform the allocation of resources deallocation of resources freeing of resources Etc basically it manages the resources which resources hardware and software operating system is a control program a program that control all the operations of the computer definition number four set of utilities to simplify application development it takes charge of Hardware create environment or platform that help us to focus on development in the high level mode so what OS will do OS will perform the work at the back of the stage and will help or will allow us to write the code in the high level language and rest OS will manage we just have to write the code in high level language so this is the power of operting system so if I summarize what is an operating system operating system is a government so government is not a single person we cannot say uh let's say Joe Biden is the government of America no we don't say it like that we say government consist of lots of Ministries like Ministry of Health Ministry of Defense Ministry of uh science so operating system is is like a government it consist of several Ministries or we can say modules which modules I'm talking about I'm talking about the modules in the kernel like process manager file manager Etc so operating system is not a single program operating system is a service provider just like the government operating system is the resource manager just like the government so who manages the resources in the country government who provides the service to the people government okay so government controls the country in the same way OS controls everything in the computer okay so let me explain you again so user it communicate to the application of program application of program goes to the kernel operating system kernel then at the lowest level it is Hardware memory or devices okay so now the question arises in the introduction we should also study what are the goals of operating system operating system there are several goals like convenience that is the primary goal of daytoday operating system which we talk about and then efficiency efficiency means you should use your operating system make use of resources efficiently it should be reliable it means for which purpose operating system was designed that purpose should be achieved what is robustness operating system should be robust robust means strong enough to Bear errors operating system should be scalable operating system should have ability to evolve operating system should be portable it means it should have ability to work across different platforms Let me Give an example Windows operating system that is more portable than Mac operating system Mac operating system only works in the Apple devices whereas Windows operating system can Works in number of devices like Samsung Dell Etc okay so as I've said what is the primary goal of operating system the convenience so so there was a survey taken that which operating system would you prefer Unix or Windows most of the people have chosen Windows why because it was convenient even though Unix was more efficient Unix was more reliable it was more robust so the primary goal of operating system I'm not saying all operating system why because there are some different operating system like realtime operating system which have some deadline strict programs like like we say missile control satellite control nuclear system let's say air traffic control so all of these things have a strict deadline these are known as hard time real operating hard realtime operating system okay and the soft can be said to as ATM in which a deadline is strict deadline even if it's not met then it's not a big problem so in these cases here the main goal is reliability or efficiency in a missile system and is a missile control satellite control nuclear system Air Traffic Control efficiency and reliability are the main goal here convenience do not matter okay so it depends from operating system to operating system that which which is its primary goal either it is convenience or efficiency or reliability and so on what are the functions of operating system processor management these are all selfexplanatory functions it manages the processor memory detects the error it's responsible for the security and file management and we'll in detail explain I will explain them all in detail when we move ahead to this module of processor management to memory management these are all chapters okay so these are this is the first lecture let us revise what we have done we started with what is an operating system it's an interface between user and computer components of hardware is memory input output and CPU CPU consist of two control unit and arithmetic logic unit control unit is responsible for control signals that controls the operation and sequential execution of micro operations micro operations are the operations that are carried out on data stored in registers okay we have taken an example and then we understood what is ALU and then memory the two types of memory we have also understood what where is the secondary memory in one architecture how program are executed in one architecture this is an important part we've learned about stored program concept and sequential execution concept any program that has to be executed we've also learned this must be stored in the main memory then this we have learned we have learned how operating system act as a government okay this is the communication how does it communicates the user to Hardware there are two level of interfaces we have seen we have also understood how operating system act as a resource manager what are resources which we are here referring to control program application development simplification it act like a government and then goals and functions of operating system so in the next lecture we'll study types of operating system hello everyone welcome to the operating system course lecture two in this lecture we are going to study mainly about the multiprogramming operating system we are not going to discuss those operating system which could be understood just by the Google search so our main focus is understanding multiprogramming operating system we'll start with the introduction and then we'll move in depth okay so these operating system which are batch operating system multi program time sharing real time these are basic operating system and distributed OS and network os are Advanced operating system which has which are also known as multiprocessor operating system so what is multiprocessor and what what is uniprocessor we are going to learn later in the lecture so when the first generation of computer were arrived there were no OS in those computers in second generation magnetic tapes was introduced but then there also there was no operating system in third generation when magnetic disc was introduced which is hard dis or a floppy dis the operating system was introduced the operating system is basically divided into two parts uni programmed and multiprogrammed so the ability of operating system to hold a single program in a memory that is uni programming operating system okay so let us understood understand by the diagram so there are many ready to run programs in the hard disk and there is operating system also present in the hard disk at the time of booting operating system get loaded in the main memory so when booting occurs the operating system gets here in the main memory the area where the operating system resides is s area which is also known as system area and the area where programs get loaded are user area so in uni programming operating system only one out of these ready to run program s will get in the main memory so there is a restriction that only a one program from hard disk can be loaded in the main memory and when the CPU start execution on that program let's say in between the program want Services of iio devices input output devices let's say it is not present in CPU when it has went for the io devices then the CPU is empty and if CPU is empty then the proper utilization of CPU is not possible CPU is Idle we don't want that so in uni programming operating system the drawback is less efficiency less CPU utilization and less throughput we will see I have written all these things which I have said just now so let's understand again so there are various ready to run program in the hard disk these are the programs I'm talking about out of these program one program get loaded in the main memory OS can load only aing single program from the memory okay so if the single program that is loaded is not in the CPU let's say it has moved to the io devices then CPU becomes idle and if CPU becomes idle this is the situation we don't want we want efficient CPU utilization we want efficient CPU utilization because if CPU is idle throughput is less and efficiency is less what is throughput number of program executed per unit time okay so I've written that grut is number of programs completed in a unit time so let me clarify again in uni programming operating system the operating system can load only a single ready to run program from hard disk to main memory and if that program is not in CPU let's say it has gone for iio Io services so it is not in CPU there CPU is not uh working on that program then at that case CPU is Idle we don't want that because if CPU becomes idle the efficiency drops CPU zidle throughput drops what is throughput throughput is number of programs completed in a unit time okay do you know an example of uni programming operating system the example is Ms do Microsoft DOS it was there in the 1990s what is the full form Disk Operating System in MS DOS it was command based there was no GUI and only a single program can be loaded in the main memory what was the objective we want maximum CPU utilization so what do you suggest what do you suggest how can we maximize the CP utilization so we can maximize CP utilization by putting more and more programs there so if one program gets into the io devices or one program empty CPU for Io Services there should be other ready to run program for execution so if the P1 has moved to the io Services CPU will start executing on P2 hence CPU idleness decreases let's say even P2 went for Io Services then then also P3 will be there for CPU to work upon if three P3 went there will be P4 and so on so we want multiprogramming operating system multiprogramming operating system is operating system in which operating system has ability to load multiple program from hard disk to main memory okay so this is multiprogramming operating system operating system can hold hold multiple ready to run programs in the main memory so this is the case here are here is the P1 P1 went for Io Services now P1 the CPU is empty there are various program ready for execution the these are waiting okay so at one time yes this is the point I want to emphasize upon CPU can only execute or or only work upon a single program at a time so this I have written at a time only one program will run in any case in any case I'm talking about even multiprocessor operating system multiprocessor see the the computer which has multiple processor which has multiple CPU in that case also in one CPU there will be only one program that will be worked upon so at at at a time only one program only one will run in any case okay I hope I have clarified you I am absolutely sorry for my bad and nonfluent English because English is not my first language okay but I hope I'm able to speak that much English in which you understand the basic idea which I want to say okay so what we want we want maximum CPU utilization we want maximum efficiency we want maximum throughput so for that case multiprogramming operating system is a better choice okay because CPU idleness has been significantly decreased so multiprogramming operating system gives a impression of multiplexing because CPU is working upon different program first is let's say it's working upon P1 P1 went for iio now it's working on P2 now P2 has been executed P1 came back now it's working again on P1 then P2 then again P3 I hope you're getting the point so it's given a impression of multiplexing impression of multiplexing of CPU among different programs is there in multiprogramming operating system now you have also heard uh term named multitasking operating system so the multiprogramming and multitasking operating system are somehow same the Unix family of people says program as a program and windows family of people says program as a task so program is a programming task are the same thing okay now you now you may have doubt then what is process is process and program different we are going to learn that thing in detail in very much detail in the upcoming sections so for now just remember a program in execution is a process okay now let's move ahead now we'll learn the schematic view of multiprogramming operating system so let's say this is secondary storage it was a hard disk which I was talking about it has multiple ready to run programs like P1 P2 and P3 well program task and jobs are same thing these are the same thing just a notation okay so various jobs are loaded in the op in system let's say job one went for the io Services now job two is in execution and job two is in CPU so it is in execution and job three and job four these are ready and waiting for the CPU okay so this is a overall view of multiprogramming operating system let me explain again so this is a secondary storage it has multiple ready to run program that are loaded here let's say job one job two job three and job 4 job one has gone to the io devices job two is now in execution now also the there are two programs waiting and are ready and waiting for the CPU okay so this is a schematic view of multiprogramming operating system so in this case CPU utilization is increased and idleness is decreased now there are two types of multiprogramming also the preemptive one and non preemptive one what is preemptive multiprogramming forceful deallocation from CPU so this job one or let's say job two is in CPU so if a high priority job come here let's say it is job three job three has come there job three is waiting in main memory and it has a more priority then job two then what operating system will do operating system will say hey job two you should go now because a high priority job has come so job three will be there and job two will again be sent in there this is so this is forceful preemption job two has not completed his execution there are instructions remaining for execution in job two but a high high priority process job 3 came so operating system which for will forcefully deallocate job two and will send job three for allocation so this is preemptive multiprogramming forceful deallocation from CPU it can be based either upon priority or time let's say job two is working is is is getting executed from so much time that job three and job four are getting starved these are not getting chance to be there with CPU so what operating system will say operating system will say hey Job 2 you it's been a long time you have been there in the CPU now it's chance for job three and job four to be with CPU so either priority or time on the base of this CPU will forcefully deallocate processes from CPU what is non preemptive nonpreemptive is a type of multiprogramming in which nobody will force the program to leave the CPU it will release the CPU voluntarily in which cases either all the instructions are complete now there's no purpose of a job in the CPU because all all the instructions are now complete now why will job be with CPU now okay all instructions are completed the second case arises the job needs IOU job needs input output services so it will leave CPU voluntarily and the third is system call we will learn about this in detail in the later lecture okay so let us revise what we have learned till now so firstly we started with the types of operating system there are various type of operating system batch operating system multiprogramming time sharing realtime Network and distributed distributed and network are Advanced operating system and the rest are basic operating system these are basic operating system these are Advanced okay in the third generation magnetic dis was introduced a secondary storage was introduced which later gave the birth to different type of operating system uni programming and multiprogramming in uni programming the oper system can hold only a single program in the memory whereas in multiprogramming multiple program can be there or can be present in memory so if there is only one CPU at motherboard it is uniprocessor and if there are multiple CPUs at the motherboard these are multiprocessor operating system like I was talking about distributed and network okay so if multiple CP are present then is multiprocessor now let's talk about un programming schematic view so there are several there are several ready to run program in the hard disk now operating system has capability to load only one so P1 is loaded there P1 went for execution now P1 is there in the CPU CPU is working upon P1 but P1 wants IO services so P1 went P1 empties the CPU and goes to the io devices now CPU is empty it is not working upon any program it is Idle we don't want CPU idleness we want we want to minimize the CPU idess because CPU idleness decreases the efficiency and throughput so if CPU becomes idle then throughput and efficiency are decreased okay so we don't want that we want efficient CF utilization so there is example present MS DOS dis operating system which was introduced in the 1990s command based and it has no graphical user interface so what is our what was our objective to maximize CP utilization multiprogramming operating system is a better choice for that because o can hold multiple ready to run programs if a program is not present in the CPU let's say it's gone for Io Services then there are several other programs waiting to be there with CPU so CPU is never idle but there is a golden point at a time only one will run in the CPU at any case whether it is uniprocessor or multiprocessor so our objective is to maximize utilization maximize efficiency and maximize throughput multiprogramming operating system also gives an impression of multiplexing because CPU is working among different programs what is multitasking multitasking is the same as multiprogramming Unix family says program and windows family says task for the same thing now we have learned the schematic view of multiprogramming there are there is a secondary storage a hard disk or a floppy disc anything which has multiple ready to run programs now OS loads all these program several program whichever is the capacity we say degree the amount of programs let's say four programs are there in the main memory so the degree is four operating system can load four programs in the main memory so the degree of multiprogramming is four okay now job one has moved to the io devices job two is in execution still there are job three and job four ready and waiting for the CPU so this is a schematic view CPU utilization is increased and ID is decreased now we have learned about types of multiprogramming preemptive and non preemptive preemptive means forceful deallocation from CPU in non preemptive nobody will force the program to leave the CPU it will leave the CPU in only three cases either all the instructions are complete it needs an IO service or there's a system system call Okay so what is the drawback of multiprogramming operating system multiprogramming operating system can lead to starvation or indefinite waiting for other programs lack of interactiveness and responsiv how these are the tropics let me explain you so let's say there is a high priority task let's say antivirus antivirus wants to run there so let's say P1 is that antivir task now there are several this is in the CPU people in the CPU now there are several the task which are waiting P1 has been the antivirus scan has been going on since 2 hours now these tasks are starving to be there with CPU but this is not allowed this is a high priority task so response time for P2 P3 and P4 is significantly decreased interactiveness is decreased starvation or indefinite waiting for the other programs is there because P2 P3 and P4 do not know when will P1 leave the CPU so so these are the drawback of multiprogramming operating system or specifically saying non preemptive multiprogramming operating system so what do you think the recent operating system like Unix Linux and Mac operating system are they nonpreemptive or preemptive so I hope you have guessed correctly these are preemptive operating system because non preemptive introduces starvation which is undesirable so Windows 95 till Windows 11 Unix Linux and Mac these operating system are preemptive operating system because it improve responsiveness by forceful deallocation by operating system so that other rating program can get a chance to run on CPU okay so preemption is based on two things it's either on time or on priority so let's say operating system has given 10 seconds for PX NE and P and PX neither completed nor it went for Io so what operating system will say hey PX now you need to leave so these operating system are called as multiprogramming time shared operating system and let's move to the next part that is priority so PX was there enjoying with the CPU now a high priority task come let's say py and if priority of Y is greater than priority of X then OS remove PX from the CPU and let py enter the CPU because it has higher priority so preemption is done on two things time and priority if if it is done on time these are also known as time sharing operating system so this is a better schematic view of multitasking or multiprogramming operating system so if I say what is multitasking operating system then what is the difference between multitasking and multiprogramming then you can say a preemptive multiprogramming operating system is a multitasking operating system I hope you have understood very well till now so this is another schematic view a more detailed one so what happens first a job creation happen first and then it is moved to the ricq Don't Be Afraid by these names RQ IQ these are just uh a a way to symbolize things we are going to learn in detail in the section two Process Management okay so so the job is created first and then it has moved to the readyq when it is ready it stores ready to run program this is ready this is a type of data structure okay it is in the memory so scheduler is there which selects out of ready to run program which program should should go to the CPU let's say a program is there let's say P1 P1 is scheduled so P1 will be there on CPU now it will either be terminated so when in which cases P1 will leave CPU P1 will leave CPU in case of job termination or it wants an IO service so this is a part where it is V left CPU for Io services so it will request for Io there will be SE there may be several other program which were already there requesting for the iio so it has to wait in the queue and then it will get the io Services then it will go again in the RQ and and the cycle continues okay so when all the instructions are completed the job will get terminated now the important part comes there must be some architectural requirement for implementing a multiprogramming operating system architecture means Hardware requirement okay so let's discuss these there are three hard requirements so the first is secondary storage device which I was talking about let's say hard disk or oper input output devices these are the same must be dma compatible now you must be wondering what is dma and what does it mean by being dma compatible so we have discussed in detail in computer organization architecture course if you want to learn deep in the if you want to learn about dma for now just get this dma is direct memory access okay so what's the purpose of being DM compatible it means secondary storage devices must be efficient in data transfer between secondary storage and Main memory okay so first requirement is the secondary storage devices should be dma compatible the second requirement is memory system should support address translation now what is this address translation let me clarify so there is a program which is running on the CPU so how does it work it works like it generates The Logical address what is logical address it's a type of address to access its instruction or data from Main memory okay so what is The Logical address let's say let's understand by real word analogy okay so you come to me and you say hey shage do you know John's house I say yes from here you just go straight 200 M and turn left there's the John's house so this is a logical address this is your logical address and what is a physical address these are the exact coordinate of Jon's house I hope you are getting the point so program generate a logical address to access its instruction or data from Main memory okay and physical address is needed to access instruction or data from Main memory so now there must be a translator in between which translates or convert logical address into physical address so yes there exist a translator we call as memory management unit so what is what is its work its work is to trans or convert logical address into physical address physical address is the actual address of instruction and data unit in the main memory okay so now the question arises what is the need of logical address and physical address so the thing is security with one address let's say only physical each program would directly access physical memory Lo locations so let me clarify with the same example which we have taken so this is me this is you and this is John's house I said so what I said go 200 M and take left so this is The Logical address I have given just to you now if I given let's say the exact coordinate of John's address let's say 200 and 200 just take an example random example now if someone get to know this this will be a big problem let's say what I have told you if someone get to know that I have said you just know to go 200 M straight and then take left suppose this information is e dropped by someone else let's say Alice now Alice Alice has location different so if Alice tried to do do that 200 M and then to left it will not reach the John's house so it is for the security purpose that only logical address is being shared not the physical address so let's understand it formally so with one address only physical each program would directly access physical memory locations a buggy program could overwrite memory used by another program corrupting data and causing crashes logical addresses prevent this by creating an abstraction layer program operate with logical addresses and the O translate them to the physical addresses we are talking about this the memory management unit it translates logical address to the physical address ensuring program do not interfere with with each other's memory space so why we need two addresses just for the security purpose and in the later part of this course we will learn in very detail about logical address and physical address its conversion paging so the course has a lot of things to offer now the third Hardware requirement is CPU CPU must support dual mode operation so what is dual mode operation we are talking about user mode and kernel mode I'm sure you have heard about it user mode and kernel mode so what are user mode and kernel mode Let's discuss so user mode is a nonprivileged mode so what is the meaning of privilege and being nonprivileged so privilege instructions are like let's let's take an example it's like an ambulance on the road ambulance is privileged it does not have to follow the traffic symbols or any other traffic rule it is privileged for that because it is a priority to take patient as soon as possible to the hospital or let's say the Convoy of Chief Minister chief minister do not have to stop at the traffic right traffic light so these are the privileged people okay who are the nonprivileged people the Common Man common man is a nonprivileged people in the same way in the same way the user applications like Microsoft PowerPoint Microsoft Chrome Microsoft Word oops I have said Microsoft Chrome that mistake the Chrome the word the PowerPoint these these are the user applications these are like the common man on the road but there are some OS level kernel routine programs just like the chief minister and the ambulance which are privileged and what is the privilege they are getting that they will atomically perform no one will stop them in between when they are executing they will perform non preemptive multiprogramming and the user level user applications preemptive these are just the normal costs so user mode is preemptive mode and kernel mode is non preemptive mode because it is privileged so what are the example of user applications I have given Microsoft PowerPoint or any other random game you are playing these are example of user application what is the example of os level colel level routines Process Management file management system calls these are included in the privilege instructions so what does this signify the one and zero I have written besides user and kernel this symbolizes which mode we are in currently so there is there is a register in CPU which says PSW register that is processor status word it has a bit which we call is at mode bit if the mode bit is zero the mode is Kernel if the mode bit is one the mode is user mode okay so many times it becomes necessary to shift modes using user to Kernel or kernel to user so if some user application wants to Avil OS kernel level Services then mode shifting is required okay let let me read it again if some user application wants to Avail OS kernel level Services then more shifting is must because kernel level programs are privileged programs they run atomically and user level programs are nonprivileged programs so if user applications want to Avail some privilege instruction or Os services then mode should be shifted from user to Kernel okay in that case mode shifting is required okay so let me read this you will get more idea about what are what is actually kernel mode and a user mode in kernel mode the executing code has complete and unrestricted access to the underlying Hardware so I am talking about this so the upper layer contain users and then the users have access to the system programs application programs and the user program these all run in user mode Library routines also run in the user mode and then there exists some OS some Services which is availed only when their kernel mode is activated like system calls operating system or accessing the computer hardware which required kernel mode so the more we go up the more abstraction we achieve the more we go less the abstraction become less okay so now let let's discuss what I was discussing so in kernel mode the executing code has a complete and unrestricted access to the underlying Hardware it can execute any CPU instruction and reference any memory address so kernel mode can do anything in the computer so kernel mode is generally reserved for the lowest level most trusted functions of the operating system so we can we here we can also see the kernel mode is for the lowest level things so the kernel mode is generally reserved for the lowest level most Trust functions of the operating system because crashes in the kernel mode are catastrophic they will halt the entire PC so if kernel mode get crashed the change will be irreversible so let's discuss now about the user mode in user mode the executing code has no ability to directly access the hardware or reference memory so a user mode has a scope of till this it can at Max access the library routines okay so code running in the user mode must delegate to the system apis what are the system apis we are going to learn in detail in the next lecture let me tell you a little bit about it system apis are the interface which help to Transit from user mode to Kernel mode to access Hardware or memory so code running in user mode must delegate to the system API to access Hardware or memory due to the protection afforded by this sort of isolation crashes in the user mode are always recoverable because if something let's say if Google Chrome chist the operating system will be preserved because it is isolated so the crashes in the user mode are always recoverable unlike kernel mode crashes so most of the code running on your computer will execute in user mode so let's revise everything because it's it was a long lecture so first we started with the types of operating system then we understood the different types of operating system like uni program and multi program operating system in uni program the operating system can load only a single program from hard disk to main memory this introduces CPU idleness and it decreases through poent efficiency example of uni programming is dis operating system by macrosoft now our objective was to maximize CP utilization hence we introduced multiprogramming operating system in which operating system can load different programs from hard disk to main memory and if a program is not present in the CPU there are several other programs waiting to be with the CPU a golden rule was that at a time only one program will run in any case so this increases the CPU utilization it increases the efficiency it increases the throughput and it also gives impression of multiplexing of CPU among different programs program and task is the same thing Unix family people say program and windows family say task now there's a schematic view of operating of multiprogramming operating system there is a secondary storage there is a operating system in the S area and there are several jobs in the user area so if one job has gone to the I devices one is being executed there are several other like job three and job four ready and waiting for the CPU CPU utilization is increased and idleness is decreased there are two type of multiprogramming preemptive and non preemptive preemptive means forceful deallocation and non PR means nobody will force the program to leave the CPU it will leave CPU voluntarily in when what are the cases either all the instructions are complete the job is terminated or it needs an IO services or there's a system code we'll learn in detail what the system called in the next lecture what are the drawbacks of multiprogramming the drawback is it leads to starvation lack of interactiveness or responsiveness so the preemptive operating system preemptive types of multiprogramming improve the responsiveness by forceful deallocation the types the current operating system which we are using like Windows Linux Unix Max are preemptive operating system so preemption is based on time and priority if it is based on time then we say it's time sharing and if it's based on prty that there is no specific name just remember this if a high priority Tas come then CPU will throw the low priority task from the CPU so operating system will throw the low priority task from the CPU pardon me multitasking operating system is same as multiprogramming with preemption okay so this is another schematic view what are the architectural requirement the first is second day storage devices should be dma compatible what does it mean so the data should be transferred between secondary storage and memory efficiently memory system should support address translation it means logical address should be translated to physical address for the program to access instruction of data from the main memory why we need two addresses because of security reasons the processor should support dual mode what are the Dual mode user mode and kernel mode user mode has a mode bit of one and kernel mode has a mode bit of zero user mode have nonprivileged instructions and kernel mode is privileged it is nonpreemptive and it runs atomically so there is a mode bit which can be either zero or one Z symbolizes kernel mode and one symbolizes user mode the mode bit is in the register which register PSW processor status world so many times it becomes necessary to shift modes when it is necessary if a user application wants to Avail OS kernel level services so we have discussed in the end what is a kernel mode and user mode now in the next lecture we are going to learn how the mode shifting is done what is an interupt what is fork and then we will end the chapter one that is introduction background and then from the next to next lecture we'll start the new section Process Management hello everyone welcome to the operating system Master course problem solving session one of the section introduction and background so I have given you the dppp in the previous lecture I hope you have solved that and now you are seeing the solution see as I have said in the course preview if you failed to solve the DPP before and you are directly seeing the solution you are not going to appreciate the beauty behind the question the mistake which you may make and you have missed that okay you will fail to analyze where you are wrong you will never ever know where you are lagging in the concepts okay so I sincerely advise you to First solve the DPP and then see the solution okay so now let's move to the questions so the first question is multiple choice question it means out of these four choices only one is correct so let start consider the following statements operating system implementation has architectural constraints this is entirely true we have discussed it so many times let's take another example uh a a smartphone operating system cannot be implemented over a desktop operating system implementation have architectural constraints the second part says operating system is the set of utilities this is true we have given a definition of operating system based on this operating system is a set of utilities which simplifies application development I hope you remember that now so option C is correct both one and two are correct okay let's move to the question number two operating system working on strict deadlines are time sharing no realtime operating system yes this is true realtime operating system works on the strict deadlines and have time constraints for example like fire alarm system hard pacemaker missile control these are example of strict deadline or realtime operating system what must be the primary goal for a hard realtime operating system this is efficiency and only efficiency yeah it after efficiency reliability and robustness may come but the primary goal is the efficient convenience is not the primary goal it is primary goal for for some other operating system like mobile operating system or laptop operating system like Microsoft and Mac the convenien is primary goal for them but for hard realtime operating system like missile control can you afford a missile control to be inefficient no the consequences will be catastrophic then okay so the primary goal will be efficiency question number four this is a multiple select question it means out of these four one or more may be correct okay which of the following statement is our correct during booting OS is loaded into disk from Main memory no the opposite is true OS is loaded from disk to main memory during time of booting okay so this is false the area of memory where operating system is stored is known as the system area yes this is true I have said that this area is the system area and the area where programs or the process are stored are are user area so this was the system area this was the user area uni programming can load and execute a single program in a memory this is true yes it can load and execute only a single program in the memory uni programming suffers from idleness of the CPU this is also true because if a CPU goes for I device uh what I'm saying if the process leave the CPU for some IO Services the CPU is Idle then CPU has nothing to do so in uni programming CPU or unit programming suffers from the idleness of CPU in case of multiprogramming if one process goes for Io the other came for execution CPU will not remain as Idle as was in the uni programming okay so let's move to the question number five I hope the concept was clear for question number four it is a multiple choice question throughput is throughput is total number of program completed per unit time this is as simple as that this is false this is false this is false total number of program loaded now total number of program completed per unit time this was important question number six preemptive process have forceful deallocation this is true better response time yes this is true for example a process has been with the CPU with a a very long time and the other process which are waiting the RQ are starving so what OS will do OS will forcefully deallocate that process from CPU and will give other process waiting a chance to be with the CPU so a response time it's it is it has a better response time than nonpreemptive processes question number seven which of the following statements are true nonpreemptive process can lead to starvation yes this is the thing which I have discussed now non preemptive process is a good response time now preemptive process has a good response time noncp process can release CP voluntarily they always release CP voluntarily either in the case of execution of all instructions or some system call or IO call so for that for those reason nonpreemptive process release the CPU they cannot be forcefully deallocated from the CP question number eight function of operating system include Resource Management yes reliability uh no reliability is the goal of operating system it is not the function security yes security is the function control over system performance yes this is the function so reliability is the goal it is not the function so are there any more questions no the dpb is over now so I hope you got the point you need to First solve by yourself and then see the solution whether you have Sol it correctly or not okay goodbye welcome to the operating system Master course lecture 3 in this lecture we will learn more about user mode and kernel mode and we will see how mode shifting is done between user and kernel mode so we used to represent user and kernel mode like this so this is the user mode the kernel mode these are some user applications user applications are those application which you use like Google Chrome the Microsoft PowerPoint any game you play these are user application and they run in preemptive fashion it means nonatomic fashion it means that operating system can forcefully de locate if a high priority process has come okay and there is a kernel mode kernel mode in kernal mode OS program resides these are non preemptive and they run atomically they cannot be forcefully preemptive they cannot be forcefully deallocated from CPU by operating system so in CPU we have seen there is a registor named processor status World which has a bit named mode bit it could be zero or one zero represents kernel mode and one represents the user mode so we have seen that operating system is a service provider and user programs are the service user and whenever we need some operating system Services we need to shift our mode from user mode to Kernel mode and when our when our motive got completed after the completion of that service we need to switch back from kernel mode to user mode so this is the main objective of our course we will learn how this mod shifting done how the mode shifting is done and why it is necessary so we have seen that kernel level program are privileged program they run they have more rights than user level applications so whenever the user application want to get privileged or want some more rights the mode is shifted from user to gal mode okay so that's why the mode shifting is necessary because if user application want to Avail kernel level Services it has to shift mode from user to Kernel mode now I have also written a word named API so what is an API let's understand by an example so in India here we have EAS that act as an interface between the common people and the government let's let's represent government with a rectangle so these are eitas let's say government has issued a service of the citizenship identification card here in India it is known as AAR card AAR card so I want to Avail that Adar card that citizenship identi ification card from the government so I will not go directly to the any Ministry and will say I want an AAR card I will go to the eitas that will help me to Avail the service of AAR card given by the government for the people so to Avail those Services I will go to the emitra not the government in the same way we'll go to the application programmer interface then API which will tell us what OS Services we can Avail okay so now we will learn the implementation of mod shifting via application programmer interface that is API or seci what is Sci I also written here SCI is system call interface so either application programmer interface or a system call interface we'll learn the implementation of mode shifting via them okay so let's consider a program main int a b c these are the Vari variable I have declared then B = to 1 C = to 2 and then A = to B plus C so user program prr like a c program run in kernel mode no run in user mode so a user program like a c program run in user mode okay so I by mistake I have written this you need to correct them in your notes also okay so how this is implemented so firstly it will go to the compiler the compiler will translate it into instructions and then the ready to run programs that is the set of instructions will be loaded into main memory and then CPU will execute the instruction one by one and in this way these com these programs are executed now let's say I have also included a function here I also included a function okay so this is a user defined function so user defined functions are always implemented in user mode okay so let's say in this user defined function I have also defined I have also used print statement let's say print f percentage D and K we are printing the K value now tell me what is print F so print f is a predefined function we say it's a builin function or we also say it's a library function now I ask you where is the print F defined see f is defined in some let's say in another after the main f is defined okay now I ask you where is the print of defined in C program we write hash include std. do you think the print F defined in this file if you think so you are wrong print T is not defined in The Hider files print T are defined in the library file in header file in header file like stdi stdi Doh this only contain the function declaration or we also say that a function prototype not the function implementation the then where is the print T defined print T defined in the library files which has extension of Li so you must remember this C basic that print f is not defined in the header file it is defined in the library files then what is the use of header file it is used in type checking in syntactic correctness and if the proper argument are passed or not to check this the header file is there the function declaration is there but implementation of print f is not present in the header file so the implementation is present in library file like do a liary file anyway whether it is a predefined function or a user defined function all of both or or sorry both are executed in user mode pardon me English is not my first language that's why but I can speak well enough to make you understand the basic idea what I am trying to say okay so anyway whether it is a predefined function or a user defined function both are executed in user mode okay only operating system only operating system kernel routines or operating system service routines service routines routines or system calls system calls are executed in kernel mode rest functions like predefined function or builtin function we also say that and user defin function both are executed in user mode so which functions are executed in kernel mode or operating system service routine or system calls I hope you have got the idea so so why do predefined functions and user defined functions are executed in user mode simply because they are written by users now you may argue that printf is not or you can argue that in stdi file the print F declaration is there in I file the printf implementation is there I have not written them no you have not written but these are present in the compiler then I guess if they are present in the compiler they should be run by kernel level modes no you are wrong because compilers are not the part of operating system compiler is just a user application program like your other programs or other applications like Microsoft Excel compiler is no different from Microsoft Excel in terms of user and kernel mode so the other programs so the above program didn't require any mode shifting it can be executed completely in the user mode okay so let's take a program which require mode shifting so now I have included a system call in our program that is fork okay so main B = to 1 Cal to 2 the same program was there but I have included now a system call so what is a fork and what does it do so execution of fork result in creating child processes okay so what is a fork I have told you it result ex its execution results in creation of child process and what does it do it's a fun it's a type of function it's a special function and that special function is known as system call if you are conf getting confused between this definition don't worry in the next lecture we will go more and more deep in this part okay or we will take some good examples in the DPP which will help you to build your understanding on Fork so what is a fork Fork execution results in creation of child processes and it's a type of function it's a special function and these special functions are known as system calls what are system calls system calls are those functions which are called to the operating system and Fork is defined or implemented in the OS kernel Fork is an operat system routine so it cannot be directly executed by user mode so to execute this program we need to shift our mode from user to Kernel mode now we will see how to Avail the fork services offered by the operating system now the main concept starts of mode shifting so I have using using some uh short forms like CT CT means compile time BSA means branch and save address if you are getting confused what is a branch and save address and what is SVC supervisory call don't worry we will learn in detail what are those in our computer organization and architecture course for this course you just need to know what I'm going to tell for now okay so this was our program main we started with the main then there are some lines which we don't have to bother about then there is a function which is a predefined function or we can say a user defined function so at compile time user defined functions get transferred or get converted into instructions which we see as branch and save address and branch and save address instructions are non privilege instruction so if you are getting confused what is BSA do not worry we will learn in detail in our COA course okay so these branches save instructions save address instructions are executed in user mode and if an OS routine when it is compiled it is converted into SVC SVC is supervisory call so this supervisory call is executed in kernel mode because the fork requires some additional privileges because it has to replicate the parent process it has to create child processes so SVC includes some privilege instructions so what we need what we need now we need to change our mode from user to Kernel mode okay so let me let me clarify some of the basics high level program when it is compiled it's converted into instruction in the same way when user defined program that is written in the high level language when compiled it is converted into BSI instructions which is branch and C instruction and these are nonprivileged instruction so if user defined function is compiled it is compiled to a nonprivileged instruction and if an OS routine is compiled it is converted to the privilege instructions or it is also known as soft interrupt instructions so what is SVC SVC is supervisory call so when supervisory call at runtime will generate an software interrupt so there's interrupt interrupt means informing the operating system of some activity so there are two type of interrupt software interrupt and Hardware interrupt so we are seeing the example of software interrupt now let's take the example of Hardware interrupt why I'm writing the spelling wrong again and again Hardware interupt let's say Hardware interrupt is you are playing a game let's say rocket League at a CPU at a low processor and a low Ram let's say 2 GB Ram you you have installed a rocket League game on your 2GB Ram computer so the computer is getting Hot and Hot so an interrupt is generated from the hardware please close down these programs the CPU temperature is rising so these are Hardware interrupts and what are software interrupts software interrupts we are discussing now so SVC super supervisory call instructions which are generated when an OS routine is compiled so at compile time the OS routines in compile time generates the SVC and SVC during run time generates a software interrupt what is a software interrupt it informs the operating system of some activity so every instruction has a routine to serve it serve O Okay so this is known as ISR interrupt service routine let me clarify the story again so when OS routine are compiled it is converted into SVC when SVC during runtime is convert generates a software interrupt and software interrupts generate an ISR interrupt service routine every interrupt has a routine service routine to serve the operating system so interrupt service routine is generated and what interrupt service routine will do it has two major work so first firstly it will go and change the mode bit in the PS W processor status World register in the CPU it will change the mode bit from 1 to zero because we are converting from we are transferring from user mode to Kernel mode user mode has a mode bit of one and Kel mode has a mod bit of zero if we have changed the mode bit from 1 to Zer it means we have shifted to Kernel mode okay so now we have we are in the kernel mode we are in the kernel mode now now the question arises how to find where our Fork is we need the address of the fork okay so this was the first activity done by interupt service routine that it has changed the mode bit from 1 to zero now the second activity is interupt service routine has to find the address of the fork so for that OS maintains a table in the kernel known as dispatch table dispatch table is a data structure in Ram it tells what all services OS provides or the address with it so this is a dispatch table dispatch table and in dispatch table there is a name written a fork and its address so the address will be accessed and will go to Fork there are various instructions the instruction will be executed sequentially and the last instruction will be executed it will go again to the processor status word will convert the mode bit from 0 to 1 you know we have to also change back from kernel to user mode why why is necessary you know for the security purposes we cannot always give a user application the admin rights every time we need to change the rights as soon as the service is completed okay so as soon as the last instruction is executed you need to change the bit from 0 to 1 it means kernel mode to user mode so I I guess you have understood let me clarify the story again so what happens whenever the compiler find there is us kernel level program it during compile time it generates SVC that is supervisory call these are the privilege instruction so at SVC at runtime generate software interrupt and every interrupt has a routine to serve it so there is a ISR interrupt service routine interrupt what ISR will do it has two work firstly it will change the mode bit from 1 to zero and secondly it will go to the dispatch table in the operating system and we'll find the address where the where the fork is it will find the add address it will go to the fork execute the instruction one by one sequentially and the last instruction is executed it will again go to the PSW processor status word register and we will change the kernel mode to user mode by changing the mode bit from 0 to 1 and all operating systems follow this Paradigm of user and kernel mode conversion so there are three type of functions we have discussed in the previous 5 minutes the user defined function and the builtin functions these these functions user defin the builin are executed in user mode simply because they are written by the user kernel oh sorry compiler is not the part of operating system system calls are executed by kernel mode so there are three type of function user defined builtin and system calls the first two are executed in user mode and the last one that is system call is executed in the kernel mode okay so this was all the story of how mode shifting is performed now I have a task for you what you need to do you need to what you need to do you need to write everything which I have told in the previous 10 to 15 minutes in form of a flow chart in form of a flow chart you have to show how mode shifting is done and then you have to pause the video write that in your copy and then I will show you the answer so three 2 and 1 so this is the answer so OS routines are accessed through API so it will start with a fork like operating system routine at compile time it can generated SVC supervisory call and then at run time it generates ISR and then it generates it has to work changing the mode bit at the PSW and a dispatch table and in dispatch table it will find the address and it will do the sequential Atomic execution of instruction I have told you the in kernel mode the instructions are executed atomically because they are known preemptive privilege instructions and when the last instruction is executed it will go back to the processor status word and will change the mode bit and in this way the thing is completed okay so I have told you that print F implementation was in library file so if printf want to access the device and device control is with the operating system then it has also has to change the mode bit from user to Kernel so let's say in printf implementation there is some user mode level programs the statements and then suddenly a system call is there that is right so Library function like print F can also use system calls and when system call is there mode shifting will occur okay so in this way I have represented this so there is a user process user process executing system call and then system call Will generate a trap so you must be wondering now what is a trap don't worry it's same as an interrupt interrupt and trap are the same thing so mode WID will here is zero so it will execute it will change the mode WID from 0 1 to 0o mode bit is zero now now it will execute the system call it will change the mode bit from 0 to 1 and then it will return from the system call in this way the mode shifting is completed so no interrupt is generated during kernel to users transformation so you have you may see here there is a no trap while going back from kernel to user mode the interrupt is generated only when user to Kernel shifting is there okay so when we need just a vage instruction without interrupt to switch from kernel to user mode so we do not need an interrupt from kernel to user mode shifting so I hope you have understood how mode shifting is done and what are kernel and user mode properly so there's a DPP which I'm giving you right now you have to solve that and in the next lecture we will discuss them welcome to the operating system Master course this is DPP number two let's start so the first question says it is multiple select question which of the following statements are allowed in kernel mode only only kernel mode can do this user mode cannot do that so the first says enabling and disabling interrupts yes this is a kernel mode operation So the instructions that run in the kernel mode are known as privilege instructions and privilege instructions can only enable and disable interrupts reading the system time no user mode can also do do this contact switching contact switching is the part which we are going to learn later it is a very common thing we will learn don't worry for now so the Contex switching is also a kernel mode operation just remember this for now contact switching is a kernel mode operation and cannot be performed by user mode clear the memory clear the memory or remove any process from the memory this is a kernel mode operation so which options are the correct a c and d are correct okay let's move down to the question number two it is also a multiple select question it says which of the following are correct to switch from kernel mode to user mode the mode WID should be changed to one so so the kernel mode has a mode bit of zero and user mode has a mode bit of one to switch from kernel to user we have to change the mode bit to one so this option is correct to switch from kernel mode to user mode the mode should be so this is the same thing you have to what remember from kernel to user change the mode bit to one and from K uh user to Kernel change the mode bit to zero so this is a kernel mode operation this is a kernel mode bit and this is a user mode bit do you can do this now okay the question number two I hope you can do this the answer is uh change to one this is correct this is false this is false to switch from user to this is true so option A and D is true let's move to the question number three it is a multiple choice question user mode user mode is atomic no user mode is a mode bit of Zero no user mode is privilege no user mode is preemptive so this is true Cal mode is atomic it's mode bit has zero and it is privilege so I hope you can do this now this is true move to the question number four it is a multiple choice question system call is used to access operating system functionality system call is used to access operating system functionality this is common thing I don't think it needs some explanation question number five consider the following statements predefined function start executing in kernel mode and the second says user defined function start executing user mode so I've already told you predefined function whether it is predefined function or user defined function they both execute in user mode only the system calls or operating system service routine execute in the kernel mode so which is correct only second is correct user defined function start execute in the user mode predefined function also execute in the user mode it doesn't execute in the kernel mode question number six so this may be a tough question for you so let's solve it this now consider the following program main 444 so there are three folks and then a print statement and then return zero so what do you think how many times G to to 2 three will be printed uh so I have told you that execution of work results in the creation of child process so when this Fork will be executed these three will be copied I mean it's it's like the duplicating let's say if this is a fork and then some print statement print one so 2 * 1 will be printed so 1 one this will be the output let's say there are fork and then print one so when this Fork Fork will be executed these two will be duplicated let's say like this fork and print when this Fork will be executed this print will be duplicated so one and one and this this four will execute one and one so four * 1 will be printed in the similar way when there are three folks then eight time 2023 G 2023 will be printed so so I hope you are not understanding it properly so let me explain you a different way let me explain in form of a tree so when this Fork will be executed these three will be duplicated down there in the next level so I will write fork for this Fork another fork for this fork and a print statement for the last print statement now for this when this Fork will be executed these two child process will come there so Fork and the print statement will go there when this Fork executed this print will be duplicated so print will come here now when this Fork executed this fork and print will go there so I will write let me change the color uh let's choose this so it will like fork and then print when this Fork will be executed the print statement this print will go there okay when this for will executed this print statement will go there so print and then uh I guess now we will execute this Fork the print statement this print will go there so when we'll execute this Fork the print statement will come so now we can see all the forks are executed and only print statements are remaining in the leaf nodes so 1 2 3 4 5 6 7 and 8 so we have seen eight times the print statement was there what if I include another 4K here how many times this will be printed so we have seen if a fork if only one fork was there it was printed only one time oh it was printed for two time like fork and print so what will this Fork do it will duplicate this print statement so print and print two times print are there so if one fork was there it was printing two times if two Fork was there it will print four times if Three Forks are there we have seen it will print for eight times if if four Forks are there then it will print for 16 times times how did I get 16 so quickly because I have created a formula for this let end be the time Fork is present then the next statement just below the forks let's say fork Fork Fork so this Fork has present n times Fork n times so the next statement will be executed 2 ra to the^ n * here it was 2^ 1 it is 2^ 2 it is 2^ 3 if it is n then it will be 2 power N I hope now it is clear for you so let's move to the question number seven mod bit is present in is it present in main memory no it is present in dis now it is present in cash no it is present in the register I've already told you it is present in the register named PSW processor status world it is in the CPU at system boot time the hardware starts in kernel mode man the in the system boot times the hardware starts in the kernel mode okay so so this was the DPP number two we have discussed there was a special concept of fork which we learned and a formula we learned rest was the easy question so you should have done at least six question out of these eight correctly okay so if you're unable do not worry just try to focus more during the lectures and then avoid silly mistakes and you will make it through hello everyone welcome to the section two Process Management we are starting with the lecture six in this lecture we are going to learn everything about what is a process so some student may have doubt about a program and a process is the process and program same we will clarify that in detail in this lecture okay we will learn about what is a process it several definitions like we did in case of operating system in lecture one I will give you several definition of a process I will tell you what operations process can perform what are the attributes of a process how does the process look like in a memory so are you ready for this interesting lecture tighten your seat belts and let's start so we will first start with a difference between a program and a process so let me tell you straightly imagine you have written a high level code now you have compiled it it will be converted into doxe file if this is present in the hard disk this is a program if this is present in the memory this is a process it is so simple to understand so if a program ISE file and it is present in the hard disk it is a process it is a program and if a program is in execution I mean it is in the main memory then it it becomes a process so when program is loaded from dis to main memory it becomes the process process is the instance of a program process is the instance of a program okay so in program there are two things data and instructions data include operant and variables and instruction include add load multiply store there are various like SBC and BSA supervisory call and the BSA branch and save address we studied in the last lecture okay so let's understand by this example here we have declared three variable a b and c b is equal to 1 C = to 2 and a equal to B plus C so simple like that now when this will be passed to the compiler it will generate a list of instructions and this list of instruction is nothing but a program and if this is stored in the hard disk it is a program if this is stored in the memory it is a process so what we need to do we need to add the value of B and C and store it in a so we'll first load the constant value in B the constant value in C now the addition is performed between registers so we have to load the value of B into register 1 and C into register 2 add both registers and store the value or the result in R1 and then the store the value of R1 in a and we will get a equal to B plus C so this is the lowle instructions converted from the high level piece of Code by the compiler and these instructions if it stored in the hard disk are program if it stored in the memory is process so simple so process is something which is Created from the program okay now data is of two types static data and dynamic data so this is a part from C language course also but I think I am feeling the need to also add this here in the operating system course because this will be necessary when I will be explaining the process as abstract data type or process how the process look in the memory okay don't Focus what I said Just remember data is of two type static and dynamic static means fixed size or known size dynamic means it is weing or it may be of the fixed size but it is allocated at the run time so if Dynamic data is allocated at the run time is static data allocated at the compile time no the answer is wrong so I have written that at form of question at what time of a program execution memory allocation occurs for static data compile time no compile time is wrong why because compile time is meant for checking syntactic correctness and generating the code which code this instruction code I was talking about so what if just imagine the scenario what if I just compile the program and do not run it this is possible uh in Unix we see JCC and then uh the name test. c this mean I have compiled it and a file named a.out is created or okay so if I have to execute I have to write do/ a.out and then it will be executed okay but in this case what I'm doing I am just compiling the program and I'm not running it it means I have just written this in the terminal and pressed enter I have not written the next statement of executing so memory located at compile time is a wastage because I have not executed this I have just compiled what is the point of allocating the memory at compile time what if the user do not execute it it means the wastage of memory occurs if the memory is allocated at compile time compiler only decides how much memory allocation should be there compiler only decides how much okay so between compile time and run time there is another time that is load time what is load time load time is the time when the program is loaded from dis to memory for execution so for static data like this in a c for static data the memory is allocated at load time neither compile time nor run time but at the load time for dynamic data the memory is allocated at runtime okay I hope the concept is clear let's move ahead so I have written like this int n and I have created I have declared an array A N I have not created it I have declared an AR okay now what I'm doing I am taking the value of n from the user I taking the input n is this possible in C or is this valid in C so the answer is no this is not valid in C language so Dynamic array are not created in C language like this we are just taking the input and then a and no this is not the right way but can we do this in C++ yes this is allowed in C++ then if I want to implement the dynamic array how should I Implement in C so we used the term maloc okay if you are unaware about the Malo or you have heard the first heard the Malo for the first time this means you are weak in C programming so you must watch the C programming course before the operating system course because it is the prerequisite for the operating system course okay for now let's if you you have not don't worry for now I will give you enough information to understand the context which I'm here to give you for understanding this process thing okay so how we create the dynamic array of size n in C without by not doing this so alternatively we do this by Malo so we have created intn and declared a pointer and then we took the input from the user and then we declared a pointer which has created which in which is pointing the dynamic array of size n so this is how it is done this is how it is done so a regular integer is of two B so this n is of two B so this is declared in as a static form at the load time now this pointer is also declared the load time because this is also static now for Malo thing it means we are declaring a dynamic array so this Dynamic array will be allocating memory at run time so this point this pointer will be pointing to the dynamic array of size n this pointer is pointing to the dynamic array of size n so the address of the first element of the array and the pointer should be the same that is the only meaning of pointing it okay so this is how the dynamic memory location is done using Melo in C okay so we'll learn more about it in C and DSA Master course so as objec is to class in oops the same way process is to program object is the instance of a class in the same way process is the instance of a program okay so the first part of this lecture is over here which differentiate between a process and a program so I will say again what is the difference between process and program so high level code is converted intoe part by compiler if the XE file is in hard disk then it is a program if the XE file is in the memory then it is a process as simple as that okay so let's start with the process now the definition the representation the operation and the attributes this four thing we are going to learn about the process so what is the process process is the program in execution and if a program isn't execution it means it is using the computer resources program doesn't use the computer resources it is as good as dead but the process is alive it uses the Computer Resources it is like the program in execution so process is a program when it get loaded in the memory process is the instance of a program these three definitions I have already explained you the fourth one is process is active entity that is also I have explained you it means it using the computer resources program is passive it doesn't use resources it is dead and process is alive process is always in the memory program is always in the hard disk if the program is shifted from hard disk to memory it becomes the process process is the locus of control of operating system what does it mean it is the same as people are the locus of control for the government so people are the process and government is the operating system let me repeat locus of control of operating system is process in the same way locus of control of government is the people okay the process is the animated disp so this is a term used by an author so what does it represents it is representing that in a body there exist a soul in the same way in a program the soul is the process okay the program is dead without the process process is alive the soul is alive the body is dead the soul is alive the body is as good as dead if the soul is not present okay so I hope you understood what is the process its definition let me repeat process is nothing but a program in execution it is the instance of a program okay so when a program is transferred from hard disk to the memory it becomes the process now we have to learn from the developers perspective what is a process okay so process is an abstract data type or simply a data structure so any data structure is represented in four things each data structure have four part the definition the representation or we can say implementation third is Operation and fourth is attribute for example linked list link list is a data structure so what is the definition of the link list a link list is a linear data structure blah blah blah it has a definition how it is implemented it is implemented using nodes or data and reference to the next node what are the operation it can perform like insertion delion travel Etc what are the attributes he head tail size length data next null these are the attributes of the link list that's why I have told you that C+ C or C++ and DSA and Kaa is the prerequisite for this course so that you can relate better okay so for link list these are the four things any data structure have four parts definition representation operation and attributes like link list of the four parts the process similarly also have four parts I have I have cleared the definition for you now we will learn how the process is represented in the memory now in the same way we need to Define process we have defined the process how does the process look like in the memory okay so I have cleared you the program consist of two things instruction and data data is of two type static and dynamic and the program creates the process okay so how does the process look like in the memory how does the program creates the process by going from hard dis to the memory now the program is in memory it is process how does the process look like in the memory so the process process look like this the process has four parts text Data Heap and the St what is this aror representing is representing it is not fixed it is shiftable it shifted as per the needs okay so the first thing is the text text means the code section the second thing is the data data means Global variable and static data static data it means the fixed size data of fix size like we have seen int X that is the static data let me clarify the data is of two type the static data is of two type or the global variables is of two type or simply say data consist of two parts initialized and uninitialized data initialized data is like int x equal to 1 I have initialized the value of x to be one and un uninitialized data is that simply int X so uninitialized data is stored in another compartment and initialized data is stored in another compartment okay so text is clear it is the code section data is clear it is global variable and static data what is Heap Heap is the area in memory for dynamic memory allocation okay so Heap means D dynamic memory allocation and for a stack what is stack used the stack contains the activation record of function calls now if you are weak C Concepts you may wonder what are activation records so let me clarify that for you activation record does not not contain the address of the function so does activation record contain the address of the function no what does it contain then it contains the information and space of the local variables okay so let me give you an example so this is a piece of code int X Main and then static part static int y int K RL these are some variables I have defined and then a function and then again some something and then this function is this is the Declaration and this is the this is declaration and this is the definition okay now the function is defined here the function has two parameters int Zed and int e these are the argument these are the parameters so the function has two parameters int Z and int e and some other variables are also declared here like P Q and L blah blah blah so just take it as as example as a random code I have given to explain you how the activation records are created so this is what is this let me explain you what is this this is the global data so where is the global data will be stored it is stored here in the data section okay now now comes the main part main is the function I have said that activation records of function calls are stored in the stack so as soon as the compiler will reach at this line main an activation record for main will be created here so this activation record is created now in this activation record what does it store activation record stores the information and space of the local variables what are local variables here k r l are the local variables so I have written K RL the local variables here the space of the local variables and its information are stored plus a return address is also stored in the activation records so it will keep executing it will keep compiling these lines and then when it will reach here to another function call it will create an another activation record above the main activation record in the stack so another activation record is pushed as soon as it will reach this line of KR okay so what does it will contain it will contain the local variables z e p q l all are the local variables here so all of them will be stored plus I have said the return address so the return address is C let's say it's is a c so when this function will be compiled the compiler will point to this line that is the this is the return address let's say C is the return address so I will put return address is equals to C that is when this will be compiled you have to go back to the address which I'm giving you that is C so the compiler will start compiling from this line onwards K = to R+L and then the compilation continues so I hope you have you have got the idea what activation records are activation records are the part in the system Stacks that contain the information and a space of local variables plus it also contain the return address of that function in main it contain the return address of Main and in function f activation record it contains the returned address of function f that is if function f is completely compiled then the compiler has to move to this return address that is C that means the next line k equal to r+ okay so when the compiler will move to this this activation record will be deleted and when compiler will compile the last line of main this activation record of main will also be completed okay so activation record of main function gets deleted when the function is deleted or the function is completed okay I should have written completed here instead of deleted okay now it is good so how does the process look like it consist of four parts text it contains the code section initialized data it contains the data like int xal to 1 un uninitialized data it contains the data like int X and then Heap Heap contains the dynamic dynamically allocated memory and then stack contains the activation record of the function and they can shrink and grow as per the requirement okay and now I have a homework for you you have to learn about the VSS extension that is block start by symbol this is the homework you have to learn about this and then you have to comment I don't know you can comment here on you or not but this is the homework we will discuss that in the next lecture so activation record that part is discussed now we have also completed this part the representation part let's move to the operation part we'll move to the operation what several operation the process can perform it can perform the create create means resource allocation resource allocation process get created by this operation memory and resources which are necessary for the process are allocated I think it is simple it doesn't need any more explanation what is create operation create operation means allocating resources which are necessary for the process and the process gets created what is termination it means resource deallocation all the proc all the resources which were given to the process are taken back from the process and the process is destroyed for create the process was created and terminate the process gets terminated schedule the act of selecting process to run on the CPU out of several in multiprogramming operating system this was the OS and there were several processes waiting for the CPU so selecting out of these three which process should be there with the CPU first so this is scheduling the act of selecting process to run on the CPU execute or run executing instruction from code section so this is selfexplanatory I have no need to explain block and weight yes this is something which need explanation so process will get blocked when it will execute system call or iio operation it has to wait okay now the suspend part sometime we need to move the process from memory to disk so you must be wondering I have not explained this part the block and weight the suspend the resume so these all things are the part of transition diagram so process move from several States it starts from the create and then terminate in between there are several States like block ready running suspend these are the all parts of transition diagram of the process which we are about to discuss in the next lecture so for now just remember these are just the operation which process can perform what are those its intrig cases will be discussed in the next lecture when we will discuss the transition diagram of the process okay so what is block and weight the process will get blocked when it will execute system call or I operation suspend sometime we need to move the process from memory to disk resume if the if our motive is completed now we have to bring the process back from disk to memory this is the resume part and suspension means memory to disk resume means dis to memory okay now I have completed the third part of the process also that is the operations now let's come to the attributes so the first attribute is for identification type attribute that is the process ID the parent process ID the group ID Etc the CPU related attributes like program counter what is a program counter the program counter will always point to the next instruction to be executed so these are the attributes of the process priority that is the level of importance should be given by OS to the process the state which state the process is in is it in running State the suspended State the blocked State okay and the bust time how much time the process has spent in the C CPU for execution these all are the attributes CPU related okay memory related attributes the third thing it includes size limits the process in which area of the memory is present these are the things file related device related file related means list of the all files which are used by the process accounting related it means which of the following uh which resources are used by the process for execution so these all attributes identification related CPU related memory related file related device related accounting related Etc all the attributes are stored in the PCB that is process control block it is just like the ID card of the process it will contain the process ID its parent ID everything the every information about the process is in this PCB that is the process control block it contain the attribute of the process each process has its own PCB and the pcbs are stored in the memory so this was for this lecture six let's revise what we have done in this lecture so firstly we started with the difference between program and the process next we learned several C Concepts that were necessary to discuss and then next we move to the definition of the process and then we learn the process from developers perspective how the process is an abstract data type its definition it's representation implementation attributes and in the end we learned that all the attributes are stored in PCB the process control block which is stored in the memory each process has its own PCB now in the next lecture we will learn about the scheding cues queing diagrams the transition diagram which I was referring there and schedulers and dispatchers thank you hello everyone welcome to lecture eight of operating system Master course we'll start our discussion from process control block and then we will move to the states of the process which process covers from is it's beginning to end so during the whole process lifetime process covers several States process moves from one state to another and how the process moves which is represented through the process State transition diagram I'm going to guarantee you that the amount of depth which we are going to cover here in this lecture is unmatchable to any content on this platform and when I used to teach in classes people used to ask some common doubts I've also taken those doubts like this and their answers okay so we'll start our discussion now okay let's go so in the last lecture we have seen what PCB is so let's just revise so PCB is also known as process descriptor it's stored in the memory and the total content of the PCB is known as process context or process environment remember this I have talked about this in one of the DPP so context switching is related to this we are going to learn that context switching in the next next lecture okay so for now just remember the contents of the PCB is known as process context or process environment context the famous word during the process lifetime process goes from one state to another just like uh human it start with a child it it start with a infant and then child and then school boy adolesence and then youth in the end it dies old age and then it dies in the same way process also goes from various stages so this is the stage one the new in which process gets created resource allocation happens in the ready which process are in the ready state which are ready to run on the CPU so the process which are ready to run on the CPU belongs to the ready state in running State the process is actually in the CPU so the process is executing instructions on the CPU and then block SL weit it means it leave the CPU process need to perform I operation or execute a system call for I operation okay so I'm giving example like what is Io Io means reading something from the device writing something from writing something to the device I should use a proper preposition writing something to the device pardon me I'm learning the English language okay and then the last stage is terminate so the process has completed all of the instructions and resources are taken back from the process so resource deallocation happens okay so how many states are there new ready running block and wait and then terminate so we are starting with these five process only but as we move as we learn more we'll go we'll learn the two more stages that is suspend block and suspend ready okay so for now we will learn the process State transition diagram in five states only okay so this is the new state CPU oh operating system allocates the resource it create the process and when the process is created it is ready to be actually executed in the CPU so in this ready stage the process is ready for CPU okay now what is scheduling and what is dispatch scheduling means making a decision out out of many ready processes which will be chosen for the CPU I've told you several times that only one process can run on CPU at a time so out of several ready process out of sever I have let me represent out of several ready process I have already told you in in this way there are several process P1 P2 P3 PN out of these only one will be with the CPU being executed okay so now OS has to choose out of these ready processes which I have to s to CPU so that is scheduling and what is dispatch dispatch means CPU gains the right to execute instruction of that process CPU gains the right to execute instruction of that process so I'm feeling the need to clarify your doubt we say it's just a matter of saying that we say the first the process was in hard disk and then it has moved to main memory here the process has actually moved from hard disk to main memory in hard disk it was a program in main memory we say it as a process it has actually moved the process has actually moved but when we say the process from Main memory has moved to CPU that is just a a way of saying it has not actually moved to CPU CPU has got the control to execute instructions of the process let's imagine like this okay so this was the OS and then uh let's say the P1 process is in the main memory so there are several instruction like i1 I2 I3 now the CPU has gained the rights over the instruction instu of the process one to execute them now CPU will execute instruction one and then instruction two and then instruction three the the process has not actually went these instruction has not actually went to the CPU the CPU is at its place the process is in main memory CPU has got rights to execute those instructions okay so the process Still Remains in the main memory CPU just gets the control to execute the process in the same way when we say the process was initially in the CPU let's imagine this is just a way of seeing and then it has moved to the io devices to perform some iio Services now CPU is empty this is just a way to explain a child okay you are you are children in context to operating system so this is a way to explain the process has not actually moved from CPU to I devices okay the process resides in the main memory process does not perform the I operation we learn this later in this lecture okay so the process does not perform the I operation it is the operating system which perform the I operation process tells the O while remaining in the main memory that I need the I services so it will make a system call the process will make a system call that OS will hear and then OS will say what is it the process say to OS see OS I require this and this IO Services the pro the operating system will say okay you wait in here in the memory I will do that service for you and then I will give you the results I hope you got the point so the process always remains in the main memory either it is being executed by the CPU or it is getting some IO services from the operating system it is in the main memory or we will learn it later the process either it is in the main memory or in the hard disk sometimes the process need to be shifted from Main memory to the hard disk also from till now we have learned that we need to shift the program from hard disk to main memory so that it becomes the process now I'm also telling you that operating system also feel the need to shift the process from Main memory to hard disk can you guess why because there is so much clutter in the main memory so that operating system feel I need to clear some process I have to hold some process I have to keep some process on hold so it will shift the process from Main memory to the hard disk so that the number of process in the main memory becomes manageable for the OS okay so operate the process does not go to the CPU or to the io devices is it resides either in the main memory or in the hard disk so this was the concept I felt you must be cleared with Okay so this concept should be crystal clear now let's move to our state diagram so we started with the new the process get created the resource allocation done is done and then the process is moved to the ready State and then out of several ready State CPU will choose one and then uh sorry operating system will choose one and then it will give rights to the CPU to execute the instruction of the processes okay so that part if the CPU start executing it its instruction the process is in running State now if all the instructions of the process are executed then the process transits from running to termination running to termination because all of the instructions of the process has been executed now let's see the process feels that it requires some input output services so it will make a system call for an io2 oos hm so it will make a system call Now voice will say okay you wait so it will take the rights of execution from CPU and the process is in weight State or the process is blocked from being executed by operating system so the process is in waight state where it is waiting it is waiting in the main memory okay so the process is in weightage state when the io or system call has been completed the process has got what it wanted it is again shifted to it is again shifted to ready state so let me clear you the story again so the process started with a new resource allocation happens the process is created it is in the ready State ready to be executed by the CPU out of several ready processes CPU is given one process by the operating system that choosing the one process out of several ready process is scheduling and then giving the op uh giving the CPU the rights to execute the instruction is dispatching if the CPU start executing the instruction the process is in running State and then if all the instructions of the CPU if if all the instruction has been executed by the CPU then the process isn't termination stage okay while running there is a need for input output Services then the operate the process will make a system call to the operating system operating system will say okay you wait in the main memory I'll do the io services for you and we'll give you the results the when the operating when the operating system give the process the results or the io service which it needed it is again sent back to ready stage ready to be executed the rest of the instructions okay suppose let's say the instructions are i1 I2 I3 I4 and I5 in I3 it requires some IO services so the instruction one is executed by the CPU 2 is executed and then in the third stage if it needs IO then it will be the the operating system will take the rights from the CPU for ex for executing the instructions and the process will wait in the main memory and when the operating system completed the io services and give the io results to the process it will again be sent to the ready state for next instruction to be executed so when the scheduler will choose the process let's say this process was P1 when the Scher will choose P1 and send it to the running stage the CPU will execute its remaining instructions so I hope the story is clear to you okay so when will the process Transit from running to block State when it needs some IO call and when IO call is completed it is again sent back to ready state for its remaining instruction to be executed okay now there's a question arises by seeing this process straight transition diagram can you guess which type of operating system is it is it multiprogramming operating system or uni programming operating system so we can here observe that there is a ready State Ready State contain all those processes which are ready to be scheduled for Execution this itself clears the point that there are several processes which OS is holding in the main memory it means it is multiprogramming operating system so due to this ready State we can say this is a multiprogramming operating system now my question two whether this is a diagram of preemptive operating system or non preemptive operating system can you tell me yes you are correct this is a diagram of of non preemptive operating system because the process is exiting the CPU only when either it is completed or it needs an iio service if I made a shift like this it becomes a preemptive system that the process is forcefully preempted from the CPU and put back to the ready stage okay so what is scheduling and dispatching scheduling means selecting and dispatching means giving control okay so what should be the state transition diagram for uni programming operating system so for uni programming operating system there is a no need for ready stage because there's only one process so when the process is created it will directly send to the running state if it needs some IO it will go to the block State and then when the io service is completed it will again come back to the running stage and then it is terminated so no ready stage because there's only a single program or process okay so let's move now every process will complete from running state only so you you can see there's only one path for termination stage that comes from the running stage only there is only one path from running state to the termination state so the process will complete from running state only you should remember this because it is an important concept so I must clarify this more so we will write like this exit in the end of the program that statement must be executed on CPU to terminate the process so it should be in the running State before it get terminated okay so I have already cleared this this is a diagram for non preemptive and then if I do this transition that is forceful deallocation Force for deallocation now it has become preemptive okay so this is preemptive based m programming operating system okay so here you can see here in this you can see the process will leave the CPU voluntarily on its own when it is leaving the CPU either it is completed or it needs some I or system call so in this case in this case preemption is not occurring and here the preemption is there based on either time or either priority okay so let's move down here are some important notes that you must remember number either process is in a ready State running state or blocked State the process is in the main memory let me clarify either the process is in the ready State the running State or the blocked State the process is in the main memory okay this is the part where the process is entering the main memory the resource allocation is being occurring well this is a grammatical error so this is a part where resource allocation occurs and this is a part where resource deallocation occurs here it is entering the main memory here it is leaving the main memory in these three states that is ready running and block and weight the process is actually in the main memory okay so either process is in ready State running state or blocked State the process is in the main memory in new it is entering the main memory in terminate it is leaving the main memory Point number two there can be multiple process in ready and blocked State theoretically infinite process can be in the radiant block State there there is no limit there is no limit it depends upon the capacity of ram it depends upon the capacity of operating system to manage that much service that much processes okay so this is the operating system here let's say the hard disk it has theoretically infinite processes and this this Ram or main memory is theoretically infinite so operating system can load and manage theoretically infinite processes so how many state can be in the ready or blocked State theoretically infinite but how many process can be in the running state so I have told you several time that at a time CPU can work upon only a single process if it is a multiprocessor CPU let's say it has n CPUs then n processes can be in the running State let's say let's say if it has if the system has n CPU then end processes can be in the running State at a single time if it has one CPU if it is uniprocessor then only one process will be executed by the CPU at a time okay so I have written there can be at Max One Running process for one CPU at Max One Running process for one CPU if there are multiple CPU there can be multiple running process depending upon the number of CPUs so maximum process and radi blocked State can be theoretical infinite maximum process in the running State depends upon the number of CPUs there can be multiple process in radiant blocked state but there can be only one process running for one CPU okay so now the important part come that is the suspension so we'll learn the suspension part and we'll continue or the we'll continue the seven State transition diagram this part we will continue in the next lecture okay so now we'll understand what is suspension so let's take the example of a classroom suppose uh let me write in the this page okay suppose take this example this is me teaching in a classroom okay there are several students like let's say the capacity of classroom is 100 students so when I came from uh my home to to the school I see there are already 150 students sitting in the classroom for my lecture so what I will say I will say hey guys uh why didn't you 50 guys the 50 guys which were standing here by disciplined 50 guys there are there I say why hey why don't you 50 guys go out in another classroom when I will complete my lecture for these 100 students I will call you again and I will give you the same lecture so the 50 I says okay sir no problem we are good with this so what I have done these 150 students are the process which are unmanageable by this OS so the students are representing the process and this is me the operating system and what does this classroom represent this classroom represents the main memory and what does this classroom represents which I have told the 50 students to go go this represent the hard disk so you remember I have told you one time that there is a case in which the operating system transfer the process from Main memory to the disk what we usually do we usually brings the process from dis to main memory but here in this case we are transferring the process from Main memory to the dis why is it so why do you think I have sent those 50 student to the next class because I want to improve performance I don't want any disturbance the heat of the classroom will increase because there are so much students above capacity in the same way the suspension this process is suspension suspension of 50 50 students that is the 50 process the 50 processes should be moved from Main memory to the dis to improve the performance to improve the efficiency so the what does I have written here so let's say there are 120 ready programs ready to run programs in the main memory and Os can handle only 100 so the OS will transfer the rest 20 from Main memory to the hard disk to improve the performance this is suspension so I already took the example of a classroom now the question arises from which states we can suspend the processes we can State we can suspend from those we can suspend only those students see here we can suspend only those students which are already present in this classroom I cannot suspend the student which is standing outside the classroom I cannot suspend the student which is going out of this classroom what is the point of saying that I'm suspending a student which is already going out of a classroom so this student which is standing out of the classroom is the process in the new state and this student which is going out of the classro is the process in the termination stage so which isent students I can suspend I can suspend those students which are there in this classroom so I can suspend those processes operating system can suspend those processes which are in the main memory so which processes are in the main memory the process in the ready State the process in the running State and the process in the blogged state now can you guess which is the most desirable state for suspension the ready state is the most desirable State for the suspension because in this state the process is already being executed by the CPU in this state the process is waiting for operating system to complete its IO call so ready state is the most desirable state for suspension so I have written this ready state is the most desirable state for suspension because the there the process is neither running nor performing and input output call okay so in the next lecture this lecture length is going way high it's already half an hour so in the next lecture we will learn the seven State process transition diagram goodbye okay so let's continue our lecture so in the last lecture we discussed the need of suspension of the process because we want to improve the performance we've also discussed an example of the classroom so we can suspend the state from ready we can suspend the process from ready State running State and blocked State because these are the states in which the process is in memory what is a suspension suspension means Shifting the process from memory to the dis this is the suspension so we can only suspend those process which are in the memory we cannot suspend those process which are not in the memory like the process in the new state and the terminated state so which is the most desirable state for suspension ready State because there the process is neither running nor performing the io we have discussed all that in our previous lecture now we will see the transition diagram so from ready State we can suspend the process to the state suspend ready and if we want to bring the process back from dis to memory you will say it resume so suspend resume suspend means Shifting the process from memory to the disk and then resuming means shift Shifting the process back from disk to memory we can also suspend a process from CPU the process which is currently running but this is not desirable so I have denoted those transition which are possible but not desirable with dotted lines okay so we can also suspend from block State the process which is waiting in the memory for a long time we will suspend the process hey you can you are just waiting there and you are making the me memory messy so you can just go and wait in the dis because it's doing nothing it's just waiting so OS will say you can wait in the disc also so it will suspend the process to the suspended block State and well and when it thinks the process should be brought back to the memory it will resume so suspension resume okay so we have taken an example so this is the process Pi it was waiting for some IO from a long time now OS will say Hey you are just waiting so why can't you wait in the main why can't you wait in the disk instead of waiting the main memory so OS will transfer to disk to improve the pro efficiency it will transfer the process to the disk so it will come here Pi so it will in the suspended block State and when o will get the time to Surf this process when the iio operation is completed by the OS it won't remain in the suspended block state it is now ready to be brought back to the memory okay so this was the case suspended block state it was waiting for some resources now when it is ready to be scheduled it is in the suspended ready State and from suspended ready state it will go back to the ready State like this okay so for example if a process is waiting for a data from a file it will in the suspended block State until the data becomes available once the data is ready or IO service which it was asking for is completed the process transition to the suspended ready the process transition to the suspended ready State and can be scheduled to run by the operating system okay so so let's discuss these points I have written I summarized here let's read this process is running State initially the process is in running State execute its instructions okay now the process request for the io service or a system call the process may require IO service such as reading from a file or sending a data over the network it makes a system call to request the services this was the part two like it this is the thing which we are discussing now now the process is in the blocked State the process transition to a blocked State while waiting for the requested IO operation to complete while in this state the process is not actively executed instructions hence what the operating system will do it will send this process from memory to the disk to improve the efficiency now the operating Sy system handle the requested iio operation for example if the process requested to read data from a file the operating system would perform the necessary dis ey operation to read the data into the memory now the process resumes for I operation is complete the process transition back to the ready State indicating that it is ready to continue executing the operating system scheduler will determine when to schedule this this thing scheduler we will discuss in the next lecture what is a scheder and dispatcher okay in detail so I hope hope you are getting somewhat what I'm saying but to clarify it fully let us see the legendary seven State process transition diagram we'll clarify from the beginning to the end so the first the new state I hope you know what is a new state it is the state which contain the pcvs of the process which are ready to be loaded in the main memory so the process is created the process is allocated the resources in the ready state the scheduler will schedule the process and dispatch to the CPU so scheduling and dispatching is being done in the ready State the process transitions from ready to the Running by scheder and dispatcher and now three cases are there either it terminates or preemption happens or it needs an IO service from the operating system so if the preemption happens it goes back to the ready state if it's terminate it go to the terminate state it ends and if it requires some IO service it will go to the block State now if it is waiting from a long time the OS will say hey you're just waiting doing nothing in the memory memory is a place for the process which are important you are just waiting here so you can also wait in the dis so it will suspend the process and we'll move to the suspended block State now from suspended block state it can go two way either it will directly resume to the block state or it will go to the suspended ready and from suspended ready it will resume to the ready so the process may follow this path or may follow this path okay so here I have written when an application need to perform an ie operation such as reading or writing a file it make a request to the kernel through a system call the kernel then handles th operation and when the operation is complete it Returns the result to the application so this is the part the IE operation part which I'm discussing here now there is a case there is a new thing which I'm discussing for the first time this is the new thing suppose a process is in the ready State ready to be scheduled for Execution but suddenly OS says Hey process you are getting resources R1 R2 and R3 and I am in the sudden need of resource R1 so I am taking the resource R1 from you so the resource R1 is preempted by the OS now what will happen the process cannot be scheduled because it lacks the resources which it needed so it will go to the block State and when OS will return the resources to the process it will go to the r State again okay so now I have discussed completely what is a process State transition diagram how the process Transit from one state to another now let's address some of the doubts which may arise in your mind so why the process is moved from blogged to the suspended block okay so why the process has moved from blogged to the suspended block let's discuss here the process is moved to the suspended block State due to the resource management and multitasking needs so this is just the formal thing which I've told you already when the process is in Block state it is waiting for an ey operation to complete okay so this was the thing which Ive written there also it is waiting for some eye operation okay however sometime the operating system need to free up the resources like memory so or it might need to pause the process for other reasons like if the user searches to a different application in these cases the operating system can move the process from blogged state to the suspended blog State this is the thing from for these reason the operating system can move the process from blocked state to the suspended block State okay so I have summarized that point to just in to improve efficiency in suspended block State the process is not only waiting for an i operation to complete but it is also swept out of main memory it is in the disk now and placed onto the disk storage this frees of the system resources and allow the operation to work on active processes that's why the process a move from blogged state to the suspended blog State okay so this is the thing once the operation is complete the system resources are now available again the process can be moved back to the main memory and transition to the ready state where it is eligible to continue running on the CPU so that's the thing now the question number two why send to suspend ready instead of ready okay why is the need to send to suspend ready instead of just ready so why don't from this suspended block State why don't we can directly transfer it to the ready State instead of suspended ready State why is it so so transition from suspended block to suspended ready instead of directly to the ready state it is due to the way how operating system works it is the way of operating system it's due to the way operating system manage memory and resources so when a process is in supended blog state it is not in the main memory but it's swept out of the disk this is done to free of the main memory for active processes this is the same thing which is which I am telling you again and again so that you may remember it so when the I operation that the process was waiting for is complete now the I operation is complete this I operation is complete the process becomes ready in a logical sense but it is not in the main memory this is the thing you need to focus upon so when the operation is complete the process is ready in a logical sense but it is in the disk now it was in the dis and even when the I operation is complete the OS has not shifted the process from disc to memory it is even now in the disk only it is red in The Logical sense but it is even the but it is in the dis okay so it is not in the main memory so it is suspended ready State before the process can actually be executed move to the ready State actual ready state it need to be brought back to the main memory from the disk this operation is known as swapping or loading okay you need to remember this point swapping and loading it is important that's why I have put here because it will be an important thing in the next lecture we will learn about the contact switching okay so the decision of when to load the process back to the main memory is made by the operating system based on the various Vector like system load memory uses this is the thing okay now another question why resuming the process from suspended block to block instead of sending it to the suspended ready and then ready so now you may get the doubt that there are two paths from suspended block to reach the ready State path number one this path let me draw again this path and path number two this path which path it should follow in which cases can be the doubt so the process is just waiting in these both stages it's doing nothing nothing but waiting so if the process if the operating system resumes the process from suspended block to block state it we can infer that the operating system has enough resources to bring the process from disk to memory and when the operating system doesn't bring the process from dis to memory just it changes the stage from suspend block to suspend ready the process in both stages are in the disk only it suggest that the operating system is experiencing the lack of resources that's why it's keeping the process in disk and not bringing it to the memory and when the time will be appropriate the operating system will bring the process from suspend ready to ready States it mean when the time will be appropriate the operating system will bring the process from dis to the memory here in the both stages the process is doing nothing but waiting operating system has brought the process from dis to memory before time it means the operating system has enough resources okay so this was all the point let's summarize the full lecture from starting to the end so what was PCB PCB is nothing but the process descriptor we have seen there are several uh attributes pointer what is this pointer we will learn in the next lecture okay process State process number program counter registers everything so there are several stages like new ready running block and wait we have seen the process State transition diagram when the process Transit from one state to another in which cases what is the reason okay we have discussed everything in detail okay so this was all the thing which we have discussed several points and then what's the motive behind suspension several States regarding suspension uh example to explain the suspension properly and then the 7 State process transition diagram in the end and we have taken some doubts now okay you don't have to read this this was something absurd written so here we are ending your lecture goodbye hello everyone welcome to the lecture 10 of operating system Master course in the last lecture we have learned about the process transition diagrams in this lecture we will learn about the scheduling cues and the state queuing diagram okay so we'll first learn about what is a q so Q is a data structure which follows the fif discipline okay okay so I hope you know a little bit about what is a q how it is implemented so Q is implemented using a linked list okay so link list is also a data structure so there are two type of cues on memory que and on dis Q okay so on memory Q has another two types ready q and block Q This correspond to the states ready State and the blocked state so in ricq the pcbs of the process process which are ready to be executed are stored like P PJ PK these are the process which are ready to be executed so ricu contains the list of the pcbs of the ready process so what is a RQ it's a link list which follows the fif discipline okay so I hope you remember the image which I have shared of the PCB so it has the first block named pointer so now you have now you can understand what does that P that pointer mean so this is the PCB and it has a little bit a part of pointer which points to the next PCB just like the link list in link list one node points to the next node so this is the head node and this point to the next PCB then next then next and so on so nodes in this link list are the pcbs and this is the head pointer as we used to have in the linked list and another queue which is in the memory is the block Q block Q Q correspond corresponds to the block state in the process State transition diagram so block Q is also known as divice Q each input output device has its own Q like input output device one has its own device Q one two has its own Q three has its own queue so each device has its own que and it contains the list of the pcbs that get blogged onto that device okay so what does device que contain list of the PCB that get blogged onto that device those processes which are interested in getting the io Services of device one those pcbs are there in this device q1 okay so let me revise again there are two type of qes on memory q and on dis Q on memory Q contain two type of cues ready q and block Q ready Q contains the pcbs of those processes which are ready to be executed and device Q contains the list of the PCB that get blog onto that device for the iio services okay so block Q is also known as device Q these are the same thing device q and the block are the same thing let's now move to the on dis cues so on this queue contain job queue and suspend queue so this is similar to the process State transition diagram the job Q is corresponding to the new state and suspend Q is corresponding to the suspended block and suspended ready state so what does job Q contain it contain the program ready to be loaded in the memory okay and what does suspend que contain it contain the list of the processes that get suspended from the memory onto the disk this is simple to understand these names are selfexplanatory okay so let me again revise revision is the important thing we started with the scheding cues cues is a data structure which follows the fee for discipline there are two type of cues on memory and on disk on memory que contain ready q and block Q ready Q corresponding to the ready state which contains the list of the pcps which are of the processes which are ready to be executed by the CPU and the block Q contain there the block Q have several devices q and each device que contain the list of those processes or the PCB of those processes which are blogged onto that device for the io Services okay and on this queue contain two type of cues job Que and suspend Q job Q is corresponding to the new state and suspend Q correspond to these states suspended block and suspended ready job Q contain the program that are ready to be loaded in the memory these are the this is the hard disk it contains several programs now what we have to do we have to load this program into the memory so these programs are stored in the job que okay so I hope I'm clear with this okay now let's move to the state queuing diagram in this diagram we are also showing the cues as well as the states which it correspond hence its name is State queuing diagram which you also written here the state queing diagram so the cycle starts with job Cube the job cube contain list of the pcbs which are ready to be loaded in the main memory out of several ready process the scheduler chooses a one process and then shift the process from or give the control the process okay so now we are moving forward to the state queing diagram topic so the thing is started with job Q job Q contains the list of the PCB which are ready to be loaded in the main memory out of several ready processes the scheduler chooses a process and dispatcher give control of that process instruction to the CPU for execution now there are several possibilities either the process has all its instruction executed by the CPU then the process will terminate and if the process needs some IO operation then it will move to the block State the process needs some system call then also it will move to the block State the process got interrupted by some interrupt then it will also go to the block state or there is a possibility that the time given by operating system to the process for execution in the CPU has expired now the time SL is expired suppose the 10 second was given to the process 10 second is over the process has still not executed all its instruction by the CPU so the operating system will say now your time is over you need to go out and join the ricq again so the time SL expired preemption is done on the basis of time it could be on the basis of some interrupt either a system call so this is the state queuing diagram so we started with the job queue then ready queue then some device queue we can say and then the block Q the same thing now you may wonder what is the fork system called we have also talked about in our previous lecture by the execution of fork system call it creates the child process we have also discussed in our previous dpps okay so if any noncompleted process exits from the CPU will join back to the ricq eventually okay firstly it will it may go to the block State and then to the readyq or it may directly go to the RQ in case of preemption okay so this is the handmade diagram again so that you may remember it properly so let's create the state queing diagram we started with the job queue okay it's it correspond to the new state of the process State transition diagram so we started with job que then the program are loaded into the memory it becomes the process out of several ready process the scheduler chooses a one process and transfer to the CPU I know the Scher doesn't do that Scher just chooses the process the dispatcher is the main protagonist here the dispatcher give control to CPU for execution of the instructions of the process okay so scheduling will done out of several ready process one process will be selected and will be given to CPU for execution in case of preemption it comes back to the Rue now there are several possibility either it terminates or it move for to the blog state for some input output operation okay it is also possible that the process get suspended from ricu so it may get suspend or it may get resumed it can also be suspended from the running state but as we have talked in the previous lecture it is not desirable so this is the state King diagram okay now let's move to the topic schedulers and dispatchers so scheduling mean making a decision and dispatching beans we'll cover it later so first we'll learn about what is a scheder do scheduling what is scheduling making a decision what decision choosing a process out of several processes so where we have to make the decision we have to make the decision in the job queue ready queue suspend queue we have also we we we will also make a decision in the blog que but we will not focus on that we will focus on these three job queue readyq and the suspend que so what is the formal definition of scheduler Scher is the compon ENT of operating system that makes the decision as simple as that what are the three types of scheder longterm scheder shortterm scheder and mediumterm SCH why we say them as long short and medium these names are given on the basis of frequency of activation you will understand that more longterm Scher what does it do it brings the new process it brings the process from New State to ready state so from job Q to the ready que long long term Scher will work let me speak again from job queue to ready que longterm scheder will work what will it do see this is the hard disk it has several it has several programs that are ready to be loaded in the memory now we have to select only three programs from these six so scheder will choose which program I have to load in the memory so let's say longterm SCH decide this one this one and this one so this decision is made by the longterm scheder so what will longterm scheder do it will changes the state of the process from new to ready I hope you got the point now let's move to the most important shortterm scheder it will schedule the process out of several ready process it will schedule it will choose one process that need to be executed so it is also known as CPU Sher because it give it select the process for execution on CPU now the third scheduler is mid mediumterm scheder so what is it responsible for it is responsible for process suspension and resuming so this part this part is done by mediumterm scheduler this part is done by shortterm scheder and this part is done by longterm scheder I hope you are now clear with the point let me speak again this part of suspension and resuming is handled by mediumterm scheduler this part of scheduling to the CPU is handled by short ter scheder and this part of loading the process from disk to memory is handled by longterm Scher okay so this is the diagram you may read this from job Q to RQ longterm SCH RQ to CPU shortterm Scher and for suspension work mediumterm scheder is responsible so now another question important question which scheduler controls the degree of multiprogramming now you should remember what is the degree of multiprogramming so I have told you that this is the main memory this is operating system now there are several process in multiprogramming operating system in M minority let's say P1 P2 and P3 so what is the degree of this operating system what is the degree of multiprogramming we will say the degree is three because there are three process in the main memory now whose work is this to choose how many process will go from hard disk to main memory longterm schedu responsible so longterm scheder controls the degree of multiprogramming it loads the new program in the memory okay now we'll move to the dispatcher so how many topics we have covered till now we learned about the sheding cues the state queuing diagram the dispatcher the scheduler and now we'll move to the dispatcher okay so what is the dispatcher dispatcher is responsible for carrying out the activity of context switching now you may wonder what is contact switching so you you you can remember this name from the dpb1 we have discussed contact switching is entirely a kernel mode operation okay so what is contact switching we will discuss it now so contact switching is the activity of loading and saving the process during a process switch on CPU I hope you have understood nothing from this let me explain from an example so this is the radue there are several process p a PB PC and PD lying in the ricq this is the CPU this is the block Q okay so now you are clear with the diagram now you are clear with the situation okay so first firstly the PA was being executed in the CPU the PA was being executed in the CPU now preemption occurs let me speak speak again firstly p being executed in the CPU suddenly preemption occurs so what will this dispatcher will do it will save the context or we can also say PCB it will save the PCB from PA to the radue and will load the PCB of the next process let me let me speak the definition again activity of loading and saving the process during a process switch what is a process switch saving the PCB of the CPU living process so what was the CPU leaving process here PA was the CPU leing process so saving the PCB saving where either in the ricq or a block q that depends on the situation so what is a process switch saving the PCB of the CPU leaving process and loading the PCV of the next process let me let me clarify fully now so at first the context of PA was active there in the CPU so the context of PA was active now suddenly either preemption occurs or PA wants an IO service so what will it do it will leave the CPU so saving the PCB of CPU living process saving where if it is the case of preemption then saving to the RQ if it is the case of IO service then saving to the block Q so saving the pro PCB of the CPU leaving process and loading the PCB of next process now we need to load the PCB because CPU can't remain idle so we save the PCV of CPU living process and we load the PCV of the next process this is the context switch or the process switch so at first the context of P was active now the context of PC is active this is the contact switch now the time taken by the dispatcher to do this this contact switching is also known as contact switching time or CPU scheduling overhead or dispatch latency just remember the names now we will discuss these name when the topic will come like in CPU scheduling we will disc discuss this in detail okay now the next Point dispatcher is not involved in the suspension of process there the MTS will work the important Point regarding dispatcher was it works only with the shortterm scheduler so here here only dispatcher will work in this case the schedulers are there okay so dispatcher Works only with the shortterm Sher in case of suspension or loading the process from hard dis to main memory separate or individual schedulers are there like longterm Scher and mediumterm scheder so dispatcher has nothing to do with the suspension of the process so let's revise the full lecture now we started with the scheduling cues and then we learned the state queuing diagram then we saw some diagrams the handwritten State King diagram and then we learned about the schedulers and dispatcher what does it do scheder chooses and dispatcher does the rest of the work and then in the end we learned the the we learned about the dispatcher in detail in the next lecture we will learn about CPU scheduling and our this process management section will be over or new section that is CPU Shing start I'm giving you a DPP now you need to solve and explore how the process are scheduled what are the criterias the tiebreaker rules mode of operations every sort of process time like arrival time burst time completion time turnaround time and their formulas the algorithms like FCF FS sjf srtf lrf hrnn round robin priority based multi level Qing everything will be covered in this section and there are so much questions which we will do so my sincere request to you all is first try the question and then see the answer the chances of silly mistakes in this section is very high and it is a totally numerically oriented section there are lots and lots of questions in the DPP and in the lectures so without wasting any more time let's start so there was a thing which I want to discuss uh from the last lecture so I've included that in a form of question so the question says there's a two time T1 and T2 T1 is the time between user to colal mode shift and T2 is the process Swit time now which one is bigger so we can easily infer that T2 will be greater than T1 that is process which time will be greater than the user to Kernel mode switch time why because process switch or contact switch is a kernel mode operation itself and the default mode is user mode so we need to shift the mode from user to Kernel while switching the process so process switching time involves the mode shifting time so T2 involves T1 so T2 must be bigger than T1 now let's move to our main topic that is CPU scheduling what does CPU scheduling means it is nothing but design and implementation of shortterm Scher what was the work of shortterm Scher the work was out of several ready to run process schedule a process for execution on CPU now shortterm Scher must have some criteria to select the process okay so these criteria are included in the CPU scheduling technique so shortterm SCH have function and goal just like the any other component of operating system what is the function of shortterm scheder shortterm scheder so the function is to select a process from RQ to run on the CPU there are several process waiting in the ricq for CPU so selecting out of those waiting process for execution on CPU what is the goal to maximize CPU utilization to maximize the throughput to maximize the efficiency these are the goal and what is the other counterpart minimize waiting time minimize the turnaround time and minimize the response time so you must be wondering what are those waiting time turnaround time and response time you are well versed with CP utilization through point and efficiency now what are those waiting time response time so these are included in the topic process time so there are several we are going to look one by one so the first is arrival time or submission time this is the time at which the process enters the ricq for the first time so there was the hard disk and from hard disk there exist a program so that program will be loaded into main memory so this time when the process arrives in the main memory for the first time or in the ricu for the first time this Pro this time is known as arrival time and the process arrives from hard disk so in terms of State when the process come from New State to the ready State for the first time this is the arrival time why I'm saying for the first time because there will be several time when the process leaves the red EQ and come back again in the redu we have seen this in detail in our last section that is process transition diagram so from new to ready when the process arrives for the first time in the ricu this time is known as arrival time what is waiting time the time is spent by the process waiting the ricu I hope this is all clear so there is a time when the process spends in the ricu waiting for the execution by the CPU so that time will be the waiting time I have represented that time like this so it will be easy to remember what is the burst time the amount of time the process has spent in the running State or the time spent by the process running on CPU is the burst time so the burst time is the time which CPU takes for execution of the process or the time spent by the process running on CPU what is iob time the time spent by the process waiting for I operation in the blogged state so I have represented like this when the process is in blocked State waiting for IO this is the io bu time there's a note Ive discussed that already several time but for the revision purposes I've included that note in most modern operating system when a process initiates an IO input output operation it typically doesn't perform the actual I operation itself what is does instead it usually initiates the operation and then enters a blocked State waiting for the operation to handle the I of operation on its behalf waiting for the operating system to handle the ey operation on its behalf so what does it do it just initiates and the rest thing is handled by operating system okay now the fifth time is completion time as as the name suggests the time when the process shifts it state from running to terminated the time at which the process terminate the time at which the last instruction of the process is executed by the CPU the time at which the process leaves the CPU for termination stage okay so there is a diagram which is known as state timing diagram okay so the first when the process arrives in the Ric is known as arrival time and when the process weights in the ricu for the CPU that is the weight time one weight time one what is weight time one waiting for the CPU for first time and then the CPU executes then start executing the instruction of that process so that time will be the first time suddenly it requires some IO service so it will wait in the block distate that is the io wait and that time will be included in the iobs time it again goes to the Rue and then wait and waits for the CPU for the second time so this is the wait time to and and so on so process arrives in the radue arrival time process running on CPU burst time and process waiting for Io that is IO burst time so I hope this is clear let's move down what is turnaround time turn around time is the time spent by the process between the transitions in the States from new to terminate so it's it's like the lifetime of the process completion time minus arrival time the time which when it's come from hard disk to main memory till the time it get terminated that time is known as turnaround time I hope I am clear SO waiting time can also be expressed in form of turnaround time so this is the lifetime whole lifetime and this is the time it was being either it was being in the running state or it was in the blocked state so the time when the process was in ready state is total time minus when the process was in ready State and the process was in blog distate so I hope this is clear let me write it down this is the total time and this is the time when the process was in uh running State let me write again the running State and this was the time when the process was in log disted okay so waiting time can also be expressed like this let's move to the seventh part that is schedule length what is schedule length say total time taken to complete all n process as per the schedule Suppose there are n process in the Rue this was the Rue 1 2 3 till n so the total time taken by all these process to complete is schedule length Okay so what is a schedule schedule is the order in which the process gets completed like P1 P2 P3 this was the order okay so this is a schedule and what is its length we will discuss it after a minute or two so first of that I want to discuss the number of schedule that is possible with n process suppose this is there let's just take this example only so there are three process P1 P2 and P3 how many schedules are possible with these three process think about it suppose there are three students student one student three student student one student 2 and student 3 in how many orders you can arrange the students so in three factorial ways this is a common peration and combination if there are n objects we can arrange those n objects in N fact factorial ways in the same way how many schedule are possible with n process n factorial so is this always true why because this is true only in the case of non preemptive scheding let's take the example of preemptive scheding then with these three P1 P2 and P3 these are the three processes in how many possible schedules or we can schedule this in how many possible ways okay so let's take I first schedule P1 and then P2 and then P3 so this was the possible case one when the P1 was completely executed then P2 and then P3 now what I do I schedule let's say two instructions of P1 and then I preempted it now let's say I schedule two instructions of P2 and then I preempted it now P1 came again executed it next two in next two instructions then P2 came again then P3 came so I hope now you are getting the point that there is a infinite possibility let's start with the P2 and then I instruction I executed two instructions of P2 then P1 came now I executed three instructions of P1 and then P3 came then P1 came again then P2 came again then P1 came again then P2 came again then P3 came then P1 came then V2 G so there are so many possible ways in preemptive scheduling case so there are infinite theoretically infinite possible ways to schedule end processes if the processes are preemptive in non preemptive case P1 have to execute completely first and then P2 will come it will execute the complete first and then P3 will come let's take another uh case suppose P2 came first then P1 and then P3 suppose P1 came first and then P3 and then P2 let's take P2 came first and then P3 and then P1 let's take P1 uh P3 came first and then P1 and then P2 P3 came first and then P2 and then P1 so there are so many possible ways okay so is there any other way left P1 came first and then these two shifted and replaced and then P2 came first and then these two these two P1 and P3 and then P3 and P1 these two uh exchanged and then P3 came first P1 P2 and P2 P1 so only these six possible ways are there because in nonpreemptive case a process has to complete properly only then a new process will come into the CPU it will not be preempted forcefully so how many schedules are possible with n process and torial if the case is non preemptive and infinite if the case is preemptive I hope you got the point now we were discussing about the schedule length schedule length was the total time taken to complete all end process so how will you represent schedule length in terms of any formula is this sum of turnaround time is this the sum of life cycle of all the process no this is false because if you add turnaround time fall process it will become more than L that is uh I hope you get the feel of this if you add the life cycle of all the process it will be greater than the schedule length or if you add the bur time of all the process it will include I bur time too so what is l l is the completion time of last process minus arrival time of the first process this is the schedule length what was the schedule length you must focus on the definition total time taken to complete all in process as per schedule total time taken to complete all and process as per schedule so this is the schedule length so the completion time of the last process let's say P3 came at the last so the completion time of P3 where it goes yeah completion time of P3 minus arrival time of the first process that is P1 this is the schedule length that is completion time or arrival time of P1 to the completion time of P3 completion time of the last process minus arrival time of the first process this is the schedule length Okay so maximum of CI minus minimum of AI what is CI completion time and what is AI it is arrival time I hope you are clear now now throughput throughput is number of process completed per unit time so let's say there are n process and the total time was schedule length and the throughput will be n by number of process that is n completed per unit Time divid by L now there is another thing that is Contex switching time or scheduling overhead this is also known as dispatch latency so contact switching time or scheduling overhead is Delta we are representing is it with Delta and another point to note is for Simplicity we are just including the loading time we are not including the saving time in this data because it will increase the complexity of the problems process which was already running in the CPU taking that process out of the CPU and saving it somewhere else let's say in the blocked queue that time we are not taking we are only taking the the time for the dispatcher to load the PCB of a process in the radue to the CPU we are taking only that time to be Delta we are not taking this time just for the problem solving purposes just for the sake of Simplicity okay so the time taken by the dispatcher to load the PCB from RQ onto the CPU is Delta that is seding overhead just remember this okay so let's revise what we have done till now so we started our lecture with this that there are T1 and T2 I have discussed that the process switching time involved the mod shifting time then we move to the CPU scheding what is CPU scheding it is nothing but the implementation of shortterm scheder shortterm Sher has a goal and a function and we discuss several process times arrival time the time when the process arrives in the reue waiting time the amount of time is spent by the process in the RQ bu time the amount of time is spent uh by the process running on CPU I time the the time spent by the process in the blogged state completion time the time at which the process completes this is the completion time turnaround time completion time minus arrival time it's also known as lifetime of the process when the process came in the uh when when the process was allocated resources till the process was uh the resources was deallocated from the process that time is turn around time the time is spent with the process between new to terminated State waiting time can also be represented turnaround time that is the total time minus time spent by the process in the running State and the blocked State this was the time spend of the process in the ready state so we can write like this the time spent by the process in ready State plus the time spent by the process in running State plus the time spent by the process in the blocked state is the turnaround time I hope you are clear now so we are not taking we are not making that it that complex that we are including the suspend time and the suspended blocked and no we are just making it simple we are just uh dealing with with the five State transition diagram which we have we have discussed in the initial part of the lecture of process State transition diagram I hope you remember that now so for problem solving purposes we only include that we discussed the schedule length then schedule length is the total time total time taken to complete all in process it is not for a single process the above times which you have seen like completion time and arrival time these are the property of a single process the schedule length is the property or uh it is related with the schedule that is the total time taken to complete all n process it's Collective okay uh now we discussed the formula schedule possible with n process that was n factorial in case of preemptive infinite May possible and then we discuss the formula of L that is the completion time of last process minus arrival time of the first process maximum of completion time minus arrival of uh minimum of arrival time what was the throughput number of process completed per unit time and n represented the number of process and L represented the total time okay then we discussed the contact switching time or scheduling overhead that is Delta for Simplicity we just took the loading time we ignored the saving time so the time taken by dispatcher to load the PCV from Rue onto CPU so we stopped our last lecture at this point what was the Delta it was dispatch latency the time taken by the dispatcher to load the PCB from RQ onto CPU this time is taken and the saving time is ignored now where we need scheduling we not only need scheduling when the process Transit from ready to running state but at different parts of straight transition like running to terminated running to waiting and waiting to ready we also need scheding but our main focus will be on this transition because we are here implementing the shortterm scheduler okay so scheduling is of two type preemptive and non preemptive in algorithms where the process is forcefully deallocated because of the operating system way of working or any time constraint or priority you know all this so that part of scheduling is preemptive scheduling and the rest is non preemptive where the process completes its last execution it is it leaves the CPU voluntarily that is non preemptive and the preemptive you all know CPU bound process those process which perform a lot of computation in Long burst and very little IO you know what is birth time the time is spent by the process in in running state so CPU bound process are those process which perform long competitions in Long burst it means it take long time with the CPU and very little IO and IO bound process performs lots of IO followed by short bu of computation okay these are the process which are focused on iO and these are the pro process which works lot with CPU ideally system should be the mix of both to make maximize CPU and iio utilization let's say a process only works with a CPU then iio is idle and let's say the process perform lots of IO and and a very less competition than CPU is ID so in ideal case it should be a mix of both to maximize CPU and IO utilization okay so this was all the introduction now we will move to the main part of this that is the algorithms we will learn some algorithms so the first algorithm is first come first serve what is the selection criteria arrival time the process which comes first get scheduled first what is the mode of operation non preemptive mode of operation conflict resolution suppose two process arrived at the same time then we will choose the process with the lower process ID now I want to clarify a point that for conflict resolution there is a no fixed criteria but the best one is choose the process for lower process idid in any algorithm which we are going to discuss later in the course choose the process with the lower process ID whenever a conflict on selection criteria occurs suppose two process arrive at the same time choose the one with lower process ID okay you must remember that fcfs is non preemptive otherwise you are going to make mistakes there okay we'll also take some assumptions while discussing about these algorithm is time is in clock text we are not talking about some milliseconds or uncond n time is in clock text okay just for Simplicity no IO times and scheduling overhead we will take it as zero in later part of the course we will take or let's say in the next lecture we will take iob buus also and we will also take some significant value of Shing overhead too okay now I hope you get the idea what is CFS suppose the process which comes or arrives first get scheduled first but there is a serious problem with fcfs scheduling so let's say this is the process which arrived first so it says we I could stay here forever anyway I'm not going back to the end of the queue okay so and the operating system says to the these process which which say hurry up I waiting for you you have you with the processor for ages look at the size of that que this is the new process which came which arrived at the last and when these process complaint about the first process to operating system he says sorry first come first served so this is a serious problem this long process causes the starvation so in this course we will uh symbolizes the process with a large bus time as long process and the process with the short bus time as short process okay so large Bus Time long process Short Bus Time short process okay so this is the process which have a large bus time it is a long process which has been with the CPU for ages and these newly arrived process are waiting for that for a long time okay and this process it it has been in a grief that hey there are so many already waiting for the CP so it is just devastated to see look at the size of that queue and operating system give no shits it says sorry first come first start so fcfs causes a serious problem named starvation you can suggest uh why does it come it comes due to its non preemptive nature okay so this was just for additional information now we will practice some of the fcfs algorithm okay so let's practice the fcfs algorithm so we will be given with this type of uh table these are the process IDs 1 2 and three these are the process ID one signifies the process number one process number two and process number three 80 is the arrival time BT is the first time CT is the completion time turnaround time and waiting time so these are given to us that is the process ID arrival time and the burst time now we need to find the completion time turnaround time and waiting time how we are going to find that how will know that the process one will complete at which time or what is the life cycle time of the or turnaround time of the process one how we will know that for how much time the process waited in the ricu so to solve this we need to learn a technique of making a chart known as Gant chart a Gant chart okay so how we will make this so the first point about the Gant chart which you need to remember is it always start from zero no matter what so what does fcfs algorithm say the one who arrives first get scheduled first so who arrived first all of them arrived at the same point at Time Zero it means when we start looking at this all of the process were in the ricu so we will say the time was zero so all arrived at the same time now what we will use as the tiebreaking rule lower process ID will be scheduled first if the rest arrived at the same time so process number one will be scheduled first so process number one will be scheduled there for how much time it will run in the CPU so this Gant CH represent the CPU this is the CPU I can write here CPU okay so for how much time the process one will be with the CPU for four units so for four units the process will be P1 will be in the CPU and then it will be executed so the process P1 will be over after four time four units now process 2 was already waiting and it will be given more priority than process 3 because of its lower process ID so between P2 and P3 P2 will be scheduled so after P1 P2 will be scheduled and for how much time it will be with the CPU for three units so 4 units was the time taken by process one and then later three units that is from 4 unit to S units P2 will be with the CPU so we will write for 427 P2 will be there and now the P3 will be scheduled for how much time it will it will be with the CPU for 5 units so from 7 unit to 12 unit P3 will be there with the CPU so these are the Bus Time 4 3 and 5 and this is the timeline so in G chart what we represent so this is a Gand chart Gand chart it represent the CPU in this bar we write process and then in the xaxis this AIS time elapsed okay so I hope now I'm clear in G chart is a way of representing a schedule so what is a schedule here P1 then P2 then P3 this was the schedule so G chart represent a schedule and in the xaxis time elapsed is the represented okay so 12 unit was needed to complete the schedule so schedule length will be from 0 to 12 this will be the schedule length Okay so what will be the completion time of P1 P1 completed at four units so completion time of P1 will be 4 units okay what will be the completion time of P2 P2 completed at 7 so the completion time of P2 will be 7 what will be the completion time of P3 12 so 4 7 and 12 this will be the 4 7 and 12 will be the completion time now what is the turnaround time turn around time is completion time minus arrival time so here arrival time is zero so we can say that turnaround time will be equal to the completion time so we can write here as it is 4 7 and 12 now we'll see waiting time okay so what is my tip is to you regarding waiting time is you should calculate waiting time with the chart instead going to the formula okay so what is waiting time let's let's look at by the chart so when P P1 arrived at Zer and it get scheduled at the zero so for how much time it waited it waited for 0 time units because when it arrived it get immediately scheduled okay P2 arrived at0 when was it scheduled it arrived at Zer it has to wait for 4 units and then it was scheduled so waiting time will be 4 and when did P3 arrived it arrived at zero and when it get scheduled it scheduled at 7 from so from 0 to 7 it has to wait so waiting time was 04 and 7 I hope you are now clear with this you see if you want to calculate the waiting time with the formula you can also do that so what is with the waiting time turn around time minus bust time so turnaround time was nothing but completion time and burst time was it's written there so you just need to subtract the completion time from Bust time so let's do this completion timeus Bus Time 4 4 is 0 7 3 is 4 and 12 5 is 7 so I have taught you how to calculate the waiting time from either chart or from the formula okay so let's revise let's revise because the next question you have to do that fcfs algorithm first come first sir one who arrived first gets served first if all arrived at the same time then lower process ID will be given preference so here P1 will be scheduled first P1 scheduled first it will run for how many units of time four units of time because fcfs is completely nonpreemptive the process will leave the CPU voluntarily okay so we are not talking about any IO here so it will be with the CPU until it completes so from 0 to 4 we will how how did we write four here all right because the bu time of process one was 4 4 so from 0 to 4 P1 will be the will be with the CPU and from 4 to 7 three units P2 will be scheduled why because after because this is the priority given while checking the process ID P1 will be given the highest priority and then P2 and then P3 because we give more priority to the lower ID process okay so after uh P2 was over then P3 came it scheduled it was with the CPU for 5 units so from 7 to 12 it was with the CPU so from 0 to 4 P1 4 to 7 P2 and 7 to 12 was P3 okay so let's try another question it says so this was already given to us let's trite so two process arrived at Time Zero process one and process two which will be scheduled first process one will be scheduled first so we will write process one here and for how much time for two bus times so for two units P1 will be with the CPU okay now which will be scheduled P2 will be scheduled because it arrived earlier P2 will be scheduled then rest of the process so how for how much time P2 will be scheduled the bus time that is 1 so from 2 to three p will be there now this get executed completely this get executed now there these are the three process remaining who arrived first among the three process three arrived first because it arrived at two units okay so for how much time it will be executed 3 units so 3 to six 3 units P3 will be executed now these three are completed rest two are remaining who arrived earlier P4 arrived earlier so P4 will be scheduled for two units so from 6 to 8 P4 will be there now the last one it gets scheduled for and for how much time four units so 8 to 12 4 units so if you are facing problem indirectly doing this you can also make a time and a rue thing so it keep it helps you to keep track of the process which are in the ricq so at Time Zero P1 and P2 were present at time two P1 was gone and P2 and P3 was there in the Rue at time two P2 and P3 were there in the Ric okay at time three P3 and P4 were there at time three at time 3 P3 and P4 were there because it arrived at unit 2 and it arrived at time three so at time three both were present in the ricu at Time 5 P3 P4 and P5 at time 6 P4 and P5 so the basic purpose of uh writing this is time and ricu thing is you get to know which process are present in the ricq and among which process you have to compare the arrival time suppose at time Zer we saw P1 and P2 was present so we need to compare the arrival time of these two process only so we'll compare for these two process whose arrival time is more see both are same so now what we will do we will apply the tiebreaking rule that is lower process ID so which has lower process ID P1 is lower process ID right P1 is lower than P2 P2 is higher so we are talking about these numbers okay so so between them P1 will be scheduled first and then P2 so when P1 was getting scheduled for two units at time two P3 was also present and P2 was was also present in the ricu and P1 has went to running and then ex execute and then terminated so P1 was terminated and then at time two P2 and P3 were present in the ricq okay so in this way you can do this and now you have to compare between P2 and P3 between P2 and P3 who arrived earlier P2 arrived earlier so P2 will be scheduled P2 will be scheduled for one bu time so at time three we will see P2 was gone and P4 came so now we to compare between P3 and P4 so it's just a helping hand if you get more and more confused in how to apply fcfs algorithm it will signify significantly reduce your Sly mistakes let's move to the question number three it's again on fcfs algorithm so this is given to you to us and now we have to calculate completion time turnaround time and waiting time so I'll create the Gant chart and you have to fill the values by seeing the Gant chart so this you have to do as your homework okay so we will see here so there are four process which arrived at different times so the first process arrived at time three so now you may Wonder between time 0 and time three what will CPU do it has nothing to do it will remain idle so from 0 to 3 the CPU will remain idle now I have told you you must remember that in Gant chart you always start with zero so from 0 to three no one was there with the CPU so we will represent this part as Idle now at time P1 came and it get executed with the CPU for five units so from 3 to 8 P1 came at 3 and from it executed till 5 units so from 3 to 8 P1 was there with the CPU the next process came at 10 so 8 to 10 again the CPU is idled and from 10 to 12 P2 get executed for two busts okay so for for two unit P2 get executed now the next process that is the P3 which came at time 15 so again from from 12 to 15 CPU is idled the process 3 get executed for 4 units so from 15 to 19 P3 will be there with the CPU and then now no idleness because P4 came 1 second before or one unit before the P3 get completed P4 came one unit before P3 came completed P3 completed at 19 and P4 came at 18 so there's no idess P4 will wait for one unit until the P3 get completed and then P4 will get immediately scheduled so from 19 to 5 minutes more that is 24 P4 will be there so this is the Gant chart and it always start from zero so for CPU was idle for how many units three here two here and three again here so 3 and 3 6 6 and 2 8 so CPU was idle for 8 units what is the schedule length what is the schedule length completion time of the last process to AR time of the first process I should speak in opposite order so the arrival time of first process to the completion time of last process this is the schedule length this will not be counted in the schedule length so there is an interesting concept of percentage CPU idleness so what will be the percentage CPU idess for this G chart so one thing you must remember about the percentage CP idess is it is always calculated over schedule length l so we will not see we will not see this part we will only calculate the percentage where CPU was idle for this duration only so the percentage CP idess is calculated over l so for how much time the CP was idled 2 and three so 5 units divided by 24 to 23 is 21 so 5x 21 into 100 this was the percentage CPU idleness so 5x 21 into let me divide 100 for percentage we multiplied by 100 to calculate the percentage so this was the percentage CPU idleness now we will see one more question and then there's a homework for you you have to calculate the percentage CP idleness in this given question okay so let's do this so we are again given with the three things process number arrival time and the burst time okay so let me take this now it's good so we will compare the arrival time who arrived first Pro process to arrived at time three so between 0 to 3 it will be idle and for time three it arrived so P2 will be scheduled at time three and it will run for 1 unit from 3 to 4 it will run and then the next process arrived at Time 5 so 4 to 5 CPU will be idle and then process one will be scheduled for two units so from 5 to 7 process one will be there and the next process arrived at time 8 so from 7 to 8 again the CP will be added and the process three will be scheduled at time 8 and it will run for 4 units so from 8 to 12 the process three will be with the CPU so what will be the G chart this is the G chart it always start with a zero what will be the schedule length the schedule length will be the completion time of last process to arrival time of the first process to 12 3 that is 9 is the schedule length Okay so in the same way in the same way you should try a question on yourself too so try this question and I have given you the answer that is percentage C is 4X 23 so you you should get get this must remember if such situation arise where the CPU idle for initial part do not include this in the percentage CPU ID L because it is always calculated over the schedule length so we'll only calculate this and this okay so try this and try to get the answer and do not stop until you get this 4X 23 okay welcome to the interesting part of CPU scheduling in which we will include the Delta and IUS time too so my intention is not to scare you but this is a new variety of problems which we are going to see in this lecture this is an important lecture sit with pen and paper and first solve the question by yourself when I will say and then see the solution okay so what what is Delta what is the significance of Delta let me explain Suppose there uh suppose take the case in which the Delta is negligible okay P1 was there in the RQ at time zero and it has a burst time of 4 units so what we did we used to directly schedule P1 for 0 to 4 we did like that but now the scenario has changed the dispatcher has took two unit of time before the process can start running so from 0 to 2 it was the time taken by the dispatcher to transmit or or Transit the process from ready to running so this was the time taken by the dispatcher and now the process will run for 4 units so initially the process was completing at 4 units of time now the process is completing at 6 unites so completion Time Has Changed okay so don't worry we we will learn about this when we see the problems so in problems we will be given with the process life cycle like first it was with the running first it was running and then it got to blocked State and then again it came uh for running so this is the life cycle which will be given burst time iob bur time and the bur time okay it can also be like iur time burst time and iob burst time that will be a another difficult part this what I'm saying this IO burst time burst time and I burst time so this is a Next Level problem okay so don't worry we will see them one by one so initially in the initial problems we will be given with the burst time IO burst time and the burst time and let's say Delta is one okay so this is we will start with just one process so this is process number one arrived at the RQ at time zero and this is the life cycle that is it was running in the CPU for 3 units then for 5 units it went for Io and then again two units it went it run on the CPU and then it terminated so at time Z P1 was present in the RQ so the load time of dispatcher that it loaded did the PCB of P1 in the CPU it took one unit of time so from 0 to 1 the time was taken by the dispatcher and for three units the time was taken by the process to run on CPU so 1 to 4 that is the three unit of time taken by the process to run so and one unit of time was taken by the dispatcher so we have completed for four units we have completed this part okay now the process has went for Io so from 4 to 9 that means the five unit the process was with the io okay and it came back again at time 9 see if you if you directly jumped to the CP lecture without understanding the process State transition diagram you will never going to understand what is going on here see what the process State transition diagram was the process was in the ready State then it moved to the running State and then whenever process get blogged for Io it cannot go back directly here what it will do it will first go to the ready like this and then from readyq it will be scheduled and again there dispatcher will take the load time because what is the straight transition happening here from ready to running from ready to running so dispatcher will take again one unit of time so from 9 to 10 let me explain again okay from 0 to 1 it was the time taken by dispatcher to load the process 1 PCB from ricq to the CPU and 1 to 4 was time taken by the process one in the CPU from 4 to 9 that is the five unit is taken by the process at IO at time 9 it came again at the RQ and one unit was taken by the dispatcher to schedule it to the CPU or trans transfer or load the process in CPU and for two units the process ran at the CPU and then it got terminated so I hope this thing is now clear to you okay let's take another question yeah so we did not took the time okay I have written this so the the time taken by dispatcher or the Delta like here one unit it was the only time taken to load the process the saving time was not in included it was negligible hence or we took it we took it as negligible so the time taken by dispatcher only to load was taken but saving was not taken what did dispatcher do it load and save the time taken to load was taken and save was ignored okay question number two okay do you want to try it yourself go ahead be brave and try now I'm giving you the answer so the we are doing the fcfs algorithm so we will compare the arrival time who arrived first process one arrived first so process one will be in the RQ at time zero and the scheduling uh or the dispatch latency is Time 1 so to load the process in CPU it will take one unit of time so to loading P1 it will take one unit and then P1 will run for three units so P1 will run for three units and then for seven units it will go to the iio so from 4 to 11 it will go to the iio and will and it will go back again to the RQ at time 11 okay so at Time 4 there was no one with the CPU so OS will decide or scheder will decide there is no one with the CPU and there are there is a process arrived at time two that is ready to be scheduled so P2 arrived at time two and no one is there in the CPU at time four so what OS will do OS will say hey P2 you can go in the CPU so P2 will be loaded in the CPU the loading time is 1 unit and P2 will load for 5 so from 5 to 10 P2 will be there with the CPU okay now at 10 at 10 no one is there with the CPU and P3 has arrived at Time 5 and P2 went for the iio for two units so P2 will return in the RQ at time 12 from 10 to 12 from 10 to 12 it was with the io and at 12 it will return in the r Q so at time 10 no one is there with the CPU so what OS will decide there is a process which came at Time 5 is ready to be scheduled at the CPU so why not schedule process three so one unit of time will be taken for loading and then one unit of time is the bust time so 12 11 to 12 P3 will be there now P3 will go for Io for till tell to 16 so at time 16 P3 will be there with the ricu so now time 11 P1 came and now at time 12 no one was there with the CPU so o will say Hey listen at time 11 P1 came and no one is there with the CPU hey scheduler why don't you schedule the process P1 again at the CPU so sh would say okay sir P1 will be scheduled and one unit of time was taken for loading and two units of time was taken by P1 at the CPU so from 13 to 15 this will be completed at time 15 P1 will leave the CPU and it will get terminated because this was completed this was completed and this was completed at time 15 the CPU is again empty so o will say hey there is a process which came to the r equ at time 12 why don't you schedule that so okay we will schedule that so at time 15 P2 will get scheduled so one unit of time will be taken for loading and the rest three units will be taken by as a bu time now at time 19 no one is there with the CPU but os's hey there's a process which came at time 16 why don't you schedule that okay sir we'll schedule P3 so one unit of time will be taken to load and two units to complete so two units to complete so I hope everything is clear I hope everything is clear so what will be the schedule length completion time of the last process till the arrival time of the first process now there is a very very important thing I want to clarify this timing this loading timing is not a waiting time for the P1 let's say let's let's imagine this suppose you are the process and you are in the RQ and there's a CPU which is empty so what I'm doing now so this is you and this is CPU okay uh let's take a time that is uh you arrived at the process Q at 400 and the CPU became empty at 500 okay so at 500 I said to you hey come on let's go to the CPU CPU is empty now now the time taken by you to go from ricq to the CPU was 10 minutes so the CPU started execution on you at 510 so what will be the time you waited you waited for only 1 hour this this time was not the waiting time try to understand this so so this Transit time is not waiting time okay now I have important thing to discuss that system has multiple IO devices this thing you should notice here so from Time 4 to 11 P1 was with the iio from 10 to 12 P2 was with the IU so at time 11 or let's say at time uh 10.5 both P1 and P2 was with the iio this is only possible when system has multiple iio devices and I operation can be concurrent if the system has a single device then P2 has to wait till 10 to 11 until P1 get gets it IO done at time 11 so at 10 to 11 P2 will wait and then from 11 to 13 P2 will completes its IO I hope that's clear now and the CPU idleness so during the whole schedule length at what time CPU is Idle No CPU is not idle for any time this is the transit time CPU is not idle okay now let's let's calculate the waiting time so I have told you two ways to calculate the waiting time one from the G chart and from the formula so we'll first calculate the Gant chart okay so P1 was ready at Time Zero when when was it scheduled for the first time it was scheduled at time zero so first the time the weight was zero and then when it came again it came again at time 11 when was it scheduled it was scheduled at time 12 so from 11 to 12 1 unit of time was there to wait in the ricu see I have told you an example that 10 minutes was not included in the waiting time so we will not include this in the waiting time this is Transit time not waiting time will take this time as the time when P1 was actually scheduled okay so P1 only waited from time 11 to 12 when it was finally decided to get scheduled over the CPU okay so the waiting time of P1 was 0 and 1 0 and 1 this was the time P1 waited okay so 1 was the waiting time of of P1 waiting time of P2 it arrived at time two when was it scheduled first time it it was scheduled at Time 4 so two units of time from 2 to 4 this was the time P2 waited in the RQ so two units and when it came again it came again at time 12 when was it scheduled again it was scheduled at time 15 okay so see we will not include this time in the waiting time so it was scheduled at time 15 so from 15 to 12 how much time is wa it waited for 3 units okay now P3 when did P3 came in the Rue at Time 5 so P3 was there in the Rin Time 5 when was it scheduled it was scheduled at time 11 so see this was the mistake you can do in generally we see this time but now we have to take in account this time also so from 5 5 to 10 it waited only we will not include this time time as the waiting time 5 to 10 only 5 so 5 will be there see why I'm focusing on this so much that you should not include this time is the waiting time why I'm focusing on this because generally when we calculate waiting time from the chart what we see when it arrived and when did it get scheduled so we directly see like this okay we tend to ignore that part in general cases when there is no scheduling uh or CPU Shing overhead so we tend to ignore this part and we directly take this so this can be a critical mistake you may make okay so you have to remember this part that this is not waiting time you do not include that part in the waiting time okay so five was the waiting time made done by the process 3 at the first and then when it came again in the RQ it came again in time 16 when was it scheduled again it was scheduled at time 19 so from 16 to 19 it it waited for 3 units so from chart we calculated the waiting time but you should not calculate the waiting time from formula why not formula because there may be some cases like in this case you may remember your old waiting time formula that is turnaround time minus bust time but here a special case has come that is this is also present this may change the formula that is the weight time as formula was turnaround time minus burst time so according to the formula 15 was the turnaround time 15 was the turnaround time the time spent by the process or the whole life cycle of the process so the turnaround time was completion time minus arrival time so 15 was the turnaround time what was the bu time this was The Bu time that is bus time and the I bu time 7 and 3 10 10 and 2 12 so 15 12 is 3 so P1 should have waited for three units but it only waited for one unit it so where did we go wrong we ignored that part okay so waiting time in waiting time this will be the formula when we take account as CPU scheduling overhead 2 so turnaround time minus bus time plus I time plus n into Delta number of time a process get scheduled on the CPU so P1 was scheduled for how much time 1 and two so what will be the formula now 15 minus this was 12 plus two time it was scheduled and what was the CP scheding overhead 2 so 2 into sorry I think the CP shoulding over was 1 yes one so 1 1 into 2 that is 2 so it will come here so 15 14 is equal to 1 now the answer is correct so to remove all this begining let's always take a pledge to let's take a pledge to always calculate waiting time from the chart ignore the formula it may make it may let you to make mistake okay take this pledge you will always calculate the waiting time from the chart okay that is the Gant chart you will calculate waiting time from here not the formula let's move to another question in which iob buus time is bus time and then iobs time so this is a great question you should try your you should try this question on your own first and then see the solution so let's see the solution so there are three process which arrived at time zero so all three process was present in the radic at time 0 P1 P2 and P3 were present at Time Zero okay the process started with the iob bus time first and then the bus time came do you think it is possible is it possible for a process to directly go from ready state to the io no this is not possible so how can IUS time come first so this should have been the scenario so the first process go from Runing to running and then from running it should go to the block state that is the io so what a special thing is that when the process get scheduled from ready to running CPU scheduling overhead will come it will execute a single instruction in the CPU and then it will go to the io let me write and then block a process cannot directly go from ready to block unless the case of resource preemption happens but this that's a rare case we are just taking the general scenario so from ready to running and then block can a process directly go to the io no so it has to first go to the running State and then block so when the process Transit from running ready to running State data comes there is a time which dis dispatcher takes to Transit the process from ready to running so Delta will be accounted here okay so what I'm trying to tell you is so when the process P1 will be scheduled at the process P1 will be scheduled at the running and then it will execute a single instruction and it will go to the IU so Delta for P1 will be there one unit of time and then it will will go to the io from 1 to let's say 2 units so from 1 to 3 1 to 3 for 2 units it will be the io now the process two will come it will again go to the running State and the time will be taken by the dispatcher will be 1 units so from 1 to 2 P2 came to the running State and then immediately it went for Io immediately went for Io for how much time for four units so for four units it was with the io it came back to the RQ at time six and P1 came back to the r at time three now P3 when did P3 came at time zero so P3 will be scheduled now P3 will be scheduled for running and then from running state it will immediately transit to IO so from 3 to how much time six units so from 3 to six that is for 9 units it will be the io and at time 9 it will again come back to the RQ now who is in the RQ P1 P2 and P3 are in the ricu at times doots 3 6 and 9 respectively so at time three P1 will be scheduled in the running quebe uh what I'm saying P1 will be scheduled from ready to running State okay so again dispatcher will take its own time so 3 to 4 will be the time taken by dispatcher for P1 and then P1 will perform its bu time with the CPU so from 4 to 11 P1 will perform its bus time and then from 11 to 12 it will perform its IO for one unit so it will perform its IO and then at time 12 it will come back to the RQ so P1 came back at time 12 okay now now now I want to I want to uh tell something important about this P1 state it has completed this this and this when the P1 came back at the RQ it has to again schedule to exit Okay uh let me again Mark the point so first the P1 was in the RQ it goes to the running state for this so that it can go to the block state to perform the io of two units it again performed the io of two units now when it performed the I of two units it came back to the ready State and then it was again scheduled to perform the bus time for S units okay it performed the bus time and then it was uh it go to the block state to perform the I of one unit okay the I of one unit is performed now the process has done its every part now the process want to terminate how can it terminate I have to told several times that process can terminate only from the running state so it will go again there at the right State get scheduled again and from running state it will terminate so this was the important point or this was the beauty behind this question so P1 will be scheduled again P1 will schedule again it will execute its exit instruction the last instruction and then at time 49 it will terminate okay so where were we in the diagram so P1 completed it came at time 12 okay so now at time 11 now at time 11 who is present in the ricu at time 11 P2 and P3 both are present so which we will take P2 we will take so P2 will get scheduled due to its lower process ID when P2 will be scheduled the dispatcher will take one unit of time and then P2 will take its 14 unit of BU time so 14 unit of BU time taken by P2 now the time is 26 okay P2 will go to the I P2 will go to the io for time 28 so at time 28 P2 will go back to the RQ this is clear now at time 26 CPUs is ID there's no one with the CPU so we need to schedule a process for CPU so who is in the redq P3 and P1 are present in the RQ at time 26 so we will schedule P3 so one unit of time taken by the dispatcher and P3 will take 21 units of time as a burst time so 21 unit of time as the burst time has taken and then three unit as IO so 48 to 51 at 51 the P3 will be again at the RQ now at time 48 who CPU is Idle who will come who will come now P1 will get scheduled so P1 will get scheduled it got terminated and then who will be get scheduled P2 will get scheduled so P2 will get scheduled for how much time no time see see see no time no time no time to execute just a single instruction exit and then it will terminate so this was the time taken by dispatcher process took negligible time again the time taken by the dispatcher process took negligible time from 50 to 51 no one was present in the Ric Cube at time 51 P3 came so for 50 to 51 CPU will remain idle at time 51 P3 came so P3 came at time 51 P3 will get scheduled one unit toen by the dispatcher and nothing was taken by the P3 because it has to execute a single instruction only and then it will execute so let me clarify the whole question again so at first process need to come to the running state so that it can go for Io and at last process need to come at the running state so that it can terminate and in between the simple uh thing which we were doing was the same so this was the part which was good about this question okay so let me clarify again so what happened here there were three process initially we scheduled the process based on the lower process ID Delta was the time taken by the dispatcher and then process executed or the process took its time in the blocked State when the OS performed its I operation so 1 2 3 this was the I operation done by the process and then at time three P1 will came so we did like this so there's one important thing that when the time when the time when the process completes IO you should remember to transfer that process to Rue and write the time above it otherwise it will be confusing suppose at time let's say 50 at time 50 if you did not write the time here 51 you may forgot that the P1 the P3 came at 51 and it there's a slight chance possible that you schu P3 at time 50 if you fail to write here 501 okay so what my advice to do such complex question is make ricu and then uh do the calculations for the Gant chart you have any problem understanding this question try to do do this on your own explore okay watch the video repeat the video okay so this was an important question to clarify your fcfs Concepts this was the hardest question possible in the fcfs okay uh another next category could be that there is only single I this will this will be the supreme god question for fcfs if I say the iobt comes first there is a CPU shiing overhead and there is a single iio device that will be the Supreme question or the hardest question that can be formed on fcfs okay but that is not required and academics level so we will just go with this okay so this was the important concept here from ready to running to go to the block distate from ready here the process want to to go to the block distate from ready state so it cannot directly go from ready to block it has to come to the CPU first it has to come to the CPU first execute a single instruction for iio for Io it will execute a system call and then the OS will allow the process to go to the blocked State and when the process want to terminate so here the process was in blocked State and it want to what is going on so here the process wanted to terminate but it cannot directly terminate at from blocked state so it has to go to the running State that's why these three part came okay so this was an really good question now here are the tips to solve such question always create time and ricu thing this is must okay start G chart from zero this is also a good tip always remember transition diagram if you forgot the transition diagram you may make a mistake of including of not including this and this part in the Gant chart do not include the delta in the waiting waiting time while including while calculating from the chart okay so these are the four tips let me read again always create time in ricu things start gting chart from zero always remember transition diagram and do not include Delta in waiting time we stopped our last lecture at this amazing question this was a really good question in which the process started with the io bu time and then bu time and then again came the iur time in this question the process need to go to the CPU first and then block Q it will execute a single instruction on the CPU let's say the system call so that it can go to the block que and when it came back when it has completed all its IO and in and it came back for termination it has to again go to the CPU to execute a single instruction let's say exit instruction to terminate so this part and this part people generally misses because they do not have a conceptual understanding understanding of process transition diagram which we have okay so we also seen some tips like we need to always create time and ricu we should start our G chart from Time Zero we should always remember the transition diagram okay like in this question and we should not include the dispatch Laten in waiting time okay now I have another question for you a simpler one so you need to do the same question with dispatch latency as zero and you need to find the CPU idleness and the schedule length the answer is this so I request you to solve the question first and then until the answer arrives you need to you need to fight okay so let's see the answer now so we are solving with zero dispatch latency okay so in the radue at time zero three processes process 1 2 and three were available so these proces are present at time zero so we'll schedule this process at Time Zero again the process need to go from ready state to block state but it is not possible unless the case of resource preemption is there so for ready Q to block Q it has to go to the running State first and then it can go to the block Q so it will come to the CPU execute a single instruction let's say for negligible time and then it will go to the io so it will perform a two unit of IO and then at time two it will again go to the RQ so from 0 to0 P1 was executing in the CPU and then for two unit it went for the iio and at time two it came back with the ricq same stories for P2 from 0 to Z it performed the a single instruction at CPU it went for Io for four units at and at time four it came to the RQ similarly for B3 it came to the RQ at time six okay now now at time two at time two P1 was there but from 0 to 2 there was no one with the CPU so from time 0 to time 2 the CPU will remain idle because the first process which came in the Rue for CPU came at time two so from 0 to two CPU was idle at time 2 P1 came for performing the seven unit of verst time so from 2 to 9 that is the seven unit P1 will be with the CPU at time 9 it will go for Io so for one unit so it will came back to the ricu at time 10 so P1 was back in the ricu at time 10 now at time 9 who was who are in the readyq ready to be scheduled so till time 9 P2 and P3 are available who will be schedule now the process which came earlier who came earlier P2 came earlier so we will schedule P2 for how much time for 14 unit so from 9 to 23 that is the 14 unit P2 will be with the CPU at time 23 it will go to perform IO so from 23 to 25 it be it will be performing IO and at time 25 it will come back to the RQ now at time 23 which processes are in the CPU so at time 23 P3 and P1 are present who came earlier P3 came earlier so we will schedule P3 now from time 23 to 44 that is the 21 units of BU time P3 will be there with the CPU and at time 44 it will go to the io so it will perform IO for three units of time and at time 47 it will come back to the ricq so at time 44 which processes are present in the ricq so P1 and P2 are present in the ricq so we will schedule P1 now P1 will be scheduled for how much time see this part was completed this part was completed this part was completed too now P1 will come to the CPU just for performing a single instruction that was the exit instruction so it will come to the CPU for negligible time let's say for time zero so from time 44 to time 44 P1 will be the with the CPU performing a single operation and then it will end so P1 ended and it didn't come back to the ricu because the process is complete now now we will schedule P2 according to the arrival time again P2 will execute a single instruction and then it will terminate now at time 44 who is present in the ricq see no one is present in the ricq these all process gets terminated at time 47 P3 came so from time 44 to 47 CPU will remain idle and at time 47 P3 will come to the CPU for executing a single instruction that is the exit instruction and then it will terminate so I hope thing is clear now if you made some mistake try to analyze where did you lag in your Concepts okay so what will be the schedule length completion time of the last process till the arrival time of the first process so this will be the schedule length that is the 47 and what is the CPU idleness CPU was idled for 2 units here and three units here so total 5x 47 okay I hope it is clear uh now you have to calculate for part A for this part you have to calculate the CPU overhead activity dispatcher was working for how much time divided by the schedule length total time dispatcher time upon total time that will give the percentage CPU overhead activity so total time was completion time of the last process that is 53 till the arrival time of the first process process processes were ready uh processes arrived at the Ric time Z from 0 to 52 that will be the schedule length so from 0 to 52 52 will come at the denominator for schedule length and for how much time the dispatcher was active so percentage CP you overhead 1 2 3 4 5 6 7 8 and 9 so 9 by 52 will be the answer that will give the percentage CP over reductivity okay to calculate the percentage you need to multiply it by 100 now if I ask what will the percentage CPU efficient then total minus percentage C over activity plus percentage CV or you can calculate directly like the time when the CP was active efficiently working was this time this time and this time this is nothing this is nothing and this is nothing so you can calculate like this or if you have already calculated the percentage CP over acity and percentage CP ID you can directly subtract them by 100 and you will get your answer for percentage CPU efficiency now I have three good questions for homework and you must solve it otherwise if you just seeing the video and do are not solving the homework question which I'm giving you will lag behind in the end okay you'll eventually not make the most out of this course okay so you need to solve the question which I give to you similarly this question for Shing overhead equals to two and uh Next Level question for I iobt first then BT and then iobt for scheding over length equals to scheduling overhead equals to 1 now a third question try question one and two we need to try this question and this question assuming system has only one IO device did we discuss a question uh in which the system has only one I device this is see if you are getting scared by this question number three do not get scared it is as simple as the previous ones are what you need to do just take into account that just like CPU we were doing that there can be only one process in a CPU at a time in the same way you have to take into account that there can be only one process performing Io if the if another process want to perform IO at the same time then it has to wait until the first first process completes its IO so you need to take account an additional waiting time okay it is not as hard as it seems okay so you need to try question one and two you need to try this question and this question if the system has only one IO device if one process is performing the io other has to wait okay so I want you to try them now it is the time to discuss the homework question which I have given you for fcfs algorithm so there are three process available along with the arrival time and their lifetime it was first with the CPU then IO and then the CPU so let's start so which process is available at time Z P1 is available so P1 will be scheduled and the dispatch Laten is two so two unit will be taken by dispatcher and three unit will be taken by P1 now at time five which process are available at in the ricq P2 is available so two unit will be taken by the dispatcher and two unit will be taken by the P2 now you may see there is no IO it means zero unit of IO performed it means the process didn't even go for the io that means the process will continue till completion so from 7 it will go till 12 at time 12 which process is available so P1 went for the io at Time 5 for 4 unit so it will return back in the radue at time 9 so P1 will be available at time 12 so we will schedule P1 there two unit will be taken by the dispatcher and two unit will be taken by the the P1 so 12 to 14 dispatcher and 14 to 16 taken by the P1 now at time 16 which process are available no process available P3 came at time 20 so from 16 to 20 CP will remain idle at time 20 P3 will get scheduled so from 20 to 22 the dispatch latency P3 will be scheduled and for one unit it will with the CPU at time 23 it will go for 15 unit of IO so from 23 to to 38 the process have gone for Io and no processor is available in the Radu at time 23 so CPU will remain idle at time 38 the P3 will go back in the radue so at time 38 P3 will be available for scheduling we will schedule P3 two unit will be taken by dispatcher and six unit will be taken by the P3 and then at time 46 all of them will end let's move to the question number two in this question there are three process and three uh and their arrival times in their life cycle is given so this question was the special one as we discussed earlier in the lecture the the process directly want to go to to the block Q from ready but this is not possible as you know so the process has to go to the running State and from there it can go to the block State and from block when it will complete its IO for the last time it it cannot go directly to exit state so first it has to go to the ready State and then then it has to go to the running State and then it will terminate so when the process will go from ready to running for the first time it will execute a single instruction that is the system call and when the process want to terminate directly from the Block state it has to go to the running State first VI ready state to execute a single instruction that is exit so we will assume that it took negligible time to exit to uh execute those instructions so we took 10 and one and and 11 can you see from 11 to 11 from 10 to 10 from 1 to 1 so these are the time taken to execute just a single instruction for the first phase the instruction was system call and for the last phase like this one and and this one and this one so these are the exit instructions so I hope you can do that now uh I know I have made a Sil mistake here I was very exhausted while solving these questions so I made a mistake that from time 0 to 3 the CPU will remain idle but I forgot that the process the first process arrived at time three so I started with time zero so you have to shift the whole timeline by three units but that won't work because there are some idle patches in the Gart so you have to do this question whole again this is wrong the calculation is wrong but the concept is correct you have to do as I have told you in the concepts remember the transition diagram and check again because the chances of s mistakes in these questions are very high let's solve the question number three so the question number three was you have to solve the about two question with a with assuming that there is only one IO why why don't we take a new question and we will assume that the nonconcurrent io is present it means the whole system has only a single IO device so let's start so process 1 2 3 arrival time is given and their life cycle so which process is available at time Z P1 is available in the rad at time Z so we will schedule P1 and we have assumed that the dispatch Laten is zero so we will directly schedu P1 we schedu P1 at Time Zero it will run for two units it will run for two units and then it will go to iio for 2 to 2 to 7 for 5 units for 5 units it will go to iio so till time 7 P1 will Beck the io let's discuss about the CPU so at time 2 P1 went for the io so CPU is Idle now but there is a process ready to be scheduled in RQ that is P2 so why don't we P2 we scheduled P2 for three units of time so from 2 to 5 P2 will be the CPU and for 10 units P2 went for the io so P2 went for the io for how much time for 10 minutes so from 5 to 10 from 5 to 10 P2 has to go to the io but but but there's only a single device which will which is being used by the process 1 till time 7 so from 7 5 to 7 it has to wait until the I device becomes empty then from 7 to 17 for 10 units P2 will work so you have to account this waiting time also because there is a single IO device so when it will be emptied by P1 then only P2 can go to that device so from unit 5 to unit 7 it has to wait and from 7 to 17 this will execute this uh or from 7 to 17 it will use di services for 10 minutes of time okay now let's discuss about the C CPU then at time which process is present in the CPU P2 and P3 both are present but P3 and went for the iio so P2 is went for the io so P3 is the only process we will schedu P3 for one unit of time so from 5 to 6 P3 will get scheduled and from and then it has to do three units of IO so it will wait until the process two leaves the io at time 17 at time 17 it will do three units of IO from 17 to 20 it will come back in the radue at time 20 P2 will come back in the radue at time 17 and P1 will come back in the Rue at time 7 so from 6 to 7 there's no process available in Rue for scheduling so the CPU will remain idle at time 7 P1 will get scheduled for three unit of time so from 7 to what I've have done oh no I again made a mistake here you should not try this question when you were exhausted so from 7 to it should be 10 it should be 10 so it should be 10 so from 7 to 10 P1 will uh execute at rest of the bust time that is the three unit of time at time 17 so from 10 to 17 the CP will remain idle at time 17 P2 will come P2 will execute its two unit of IO so from 7 to 19 uh it's not I it bus time so it will execute two unit of its bus time so from 17 to 19 P2 will work and and at time 19 no process is present in the ricu the process P3 came at the ricu at time 20 so from 19 to 20 the CPU will again remain idle and at time 20 P3 will get scheduled for the 5 unit of its first time remaining so at time 25 this will be over so I hope there is no confusion but I'll explain it again so what we have done what we have done this is 10 okay so what we have done now we will assume that there is only one IO device and if there is only one IO device the process has to wait until the previous process exits the io hi we completed our fcfs algorithm in the last lecture and from this lecture we will start our new algorithm that is the shortest job first so as the name suggest what you think about it in fcfs we scheduled that process which arrived first so in sgf that is the shortest job first we will schedule those process which has a less less burst time so this is based on the burst time the amount of time the process spends with the CPU if the process has less bus time it will be given higher priority than the process which as a large bus time so we will represent those process which is a high bus time as a long process and the process Which is less bus time or short bu time is short process so short process are given priority than the long process in shortest job first and like fcfs it is non preum to so a process cannot be forcefully deallocated okay so for conflict resolution as we did in the fcfs we will take the lower process ID see if P1 and P2 both has the same bus time then we will schedule P1 first okay okay so among the process present in the ricu select the process with least bust time and schedule it on the CPU so this is the line you have to remember for shortest job first among the process present in the RQ we need to select those process which have least bus time and schedule it on CPU okay let's solve the question so these were the processes and these are the arrival time and these are the bus time this is the thing which will be given to us okay now remember this point remember this point among the process present in the Rue among the process present in the radue we need to compare the bus time of only those process which are already present in the Rue all already remember this word already present in the Rue do not compare those process if they are not present in the ricu okay so a process arrived at time zero so P1 arrived at Time Zero we will schedule P1 no matter what because this is the only process present in the ricu now so we will schedule P1 and if P1 is scheduled in non preemptive algorithms then it will not exit CPU unless it has completed all its instruction or it need to perform the io okay so here I the case of I is not present so we will we will take the case that it will exit the CPU only if it will it has completed all its instruction so for two bust units it will be there with the CPU and then it will exit at time two which processes are present in the Rue at time two only P2 is present because P1 has exited and P2 is present in the RQ so we will schedule P2 directly without any comparison because this is the only process present in the RQ so for three units of time P2 will be with the CPU at time five which processes are present in the CPU so at time three P3 came and and time five P4 came so we will see till time five which process are present in the CPU so P3 and P4 are present in the ricu I I didn't want to use the word cvu it was Ru okay so P3 and P4 are present in the ricq at time five so we will compare the bu time of those process which are present in the Rue at the same time so for P3 and P4 which process has less Bus Time P3 has less bus time so we schedule P3 there we will schedule P3 and it will it will be with the CPU for one bu unit so it will be with the CPU till time 6 and it will exit at time six which Pres process are present in the Rue so at time six no new process has came so we'll schedule P4 because this is the only process present in the Rue P4 will be with the CPU for two units so from 6 to 8 P4 will be present with the CPU and at time P4 at time at time 8 P4 will exit Okay so at time 8 which process are present in the ricq at time 8 P5 is the only process in the Rue so we will schedule P5 without any thinking so from 8 to 11 for three bust unit P3 will be with the CPU at time 11 which process are present in the red CU process 6 it came at time 10 so we will schedule P6 without any thinking so we will schedule P6 for two units of time so from two units of time from 11 to 13 P6 will be the CPU I hope the point is clear why I took this question with this data set so as to clear the point that we need to compare the bus time of only those process which are present in the ricu and among those process select the process with least but time least bu time and schedule it on CPU I hope the point is clear now I have written there also that bus time is only compared with the processes in the r okay let's try another question so these are the six processes their arrival time and bust time are given to us now let's see which process are present in the ricu at time zero so no process is present in the radic at Time Zero the first process which came in the ricu was P4 at time two so from 0 to two CPU will be idle because no process is present in the ricq at time two P4 came so we will schedule P4 for how much time for three units so from 2 to 5 P4 will be present at time five which process are present in the RQ at time five P5 is present P6 is present and P2 is present so P5 P6 P2 P5 and P6 are present at time five so which process will be scheduled among the these these three process which are present in the r at same time the process which has least bust time which process has least bust time among these three process P2 P5 and P6 P2 P5 and P6 uh all these process have the same bus time so we will use the tiebreaking criteria that is schedule the process which have lower process ID so we schedule P2 here P2 will be executed for two units so from 5 to 7 P2 will be the CPU at time 7 which processes are present in the CPU at time 7 P3 a new process came so these process are present in the CPU at time seven because these two got executed and these three are present so we need to compare the bust time of these three process P5 P6 and P3 so P5 P6 have bust time of two and P3 have a burst time of four so we will schedule either P5 or P6 now we will use the tiebreaking criteria P5 is a lower process ID than P6 so we will schedu P2 P5 so we will schedule P5 here P5 will get a executed for two units so from 7 to 9 P5 will be executed at time 9 which process is present in the CPU so at time 9 no new process came these two process are available we will schedule the process which has a lower burst time so process 6 has a lower bu time so we will schedule process 6 okay for two units so at time 11 which processes are available in the RQ P1 came a new process P1 came at time 10 so these two process are ail avilable till time 11 so we will schedule the process which has a lower bus time which process has a lower Bus Time among P3 and P1 so P1 has a lower bust time so we'll schedule P1 for one bust unit so from 11 to 12 P1 will be the CPU and at the last P3 will get scheduled for 4 units so from 12 to 16 P3 will be with the CPU and then the P3 will exit at time 16 which process are present in the Rue all the processes has been executed so no new process is there we will end our Gant chart here now if I ask what is the schedule length the schedule length is the arrival time of the first process to the completion time of the last process so schedule length will be 14 what will be the percentage CPU idleness the CPU was not idle during the whole schedule length Okay so I hope the point is clear now let me revise again or let me give you the road map see at any time see the process which are present in the ricu if there are mple process present in the RQ see which process is a lesser bur time schedule this that process and if two process have the same bur time schedule the process with the lower process ID only compare the bus time of those process which are present in the radue at the same time okay so here we see at time five at time five P3 and P4 represent in this sgf we do not see the arrival time of the process okay the arrival time is only seen when there is a single process present in the RQ like there it was the single process present so we'll schedule that without any thought okay so I hope the point is clear how the sgf works so in the last lecture we completed the sgf algorithm that is the shortest job first now we will learn the preemptive sgf a new type of sgf that is the preemptive sgf and we call it as srtf shortest remaining time first what will be the selection criteria of this srtf similar to g f that is the burst time we will schedule those process which have a lower burst time okay and the mode of operation will be preemptive and the tiebreaking rule will be the similar to SDF that is the lower process ID I have an important note for you preemption of running process is based on the availability of a strictly shorter process this is an important point I will come back to it again when we will see some questions then I will refer it again now another point that is out of the process present in the radue select the one having the least was time similar to sgf and we will continue to the run on CPU that process until a new process with shorter Bus Time arrives and I should not write here shorter we should I should write strictly shorter strictly shorter bus time okay so let me read it again out of the process this is the part which you need to remember for sgf out srtf okay in sgf till this part was correct and as it was non preemptive so we will continue to the run on CPU until the process completes but here a new additional thing came that is we need to preempt the process if a new process with shorter bu time arrives okay so I hope the point is clear so let's try so we will first schedule the process based on the sgf algorithm that is the nonpreemptive algorithm at Time Zero which process are present in the RQ at Time Zero only P1 was present so we will schedule that P1 no matter what so we will schedule that P1 for five best units so we P1 from 0 to 5 at time five which processes are present in the ricu only P2 is present P1 is ended so P2 will be scheduled for two units so from 5 to 7 P2 will be scheduled so this was when the sgf case was there when we were talking about the non preemptive case now let's take the case of srtf what I have said select the one with have least verse time so which process are present in the radic at time zero so P1 was present in the IQ so we will schedule the process P1 okay so from 0 to 2 units we only schedule till 2 units why because we will continue to the run that process of CPU until a new process arrives at time to a new process arrives so from 0 to two we will run and a new process arrives so we'll see that if the new process has a burst time strictly shorter than the remaining bust time that is three so two is strictly shorter than three so we we will preempt the P1 we will preempt the P1 and we will schedule P2 for two units of BU time so we will schedule the P2 for 2 unites of bus time so P2 completed at Time 4 and then we will go back to P1 P1 will be scheduled for 3 units of its remaining time so from 4 to 7 P un was scheduled let me clarify it again in sgf we directly Shu the process by just comparing the burst time of the process present in the RQ at P1 was present in the RQ so P1 was scheduled so from 0 to 5 as it was non preemptive P1 will completes and then after completion it will leave the CPU so at time five which process are present P2 was present so we schedule the P2 for 2 units that way now in srtf I have said we need we will continue to run the process on CPU until a new process arrives and if a new process AR we need to compare the burst time if the burst time of the new process is strictly less than the remaining time of the old process then we will schedule the new process and preempt the old process I hope you got the point so here in the case of srtf which process are present in the radicate time zero only P1 was present so we will schedule P1 and we'll continue to the Run P1 until a new process arrive at time two a new process arrive so we will compare the burst time of the new process and the remaining time of the old process if the burst time of new process is strictly shorter than the remaining time of old process we will preempt the old process and will schedule the new process so P1 will be preempted at time to and P2 will be scheduled P2 will be scheduled so no new process came till P2 has completed its instructions so at time for P2 will leave the CPU and the remaining process that is P1 will came to execute its rest of the instruction for three units of time so I hope the point is clear now I want to make another point that is if P2 also is a burst time of three let's let's write this if P2 also has a burst time of three so then we will check time to a new process arrived yes a new process arrived does the new process have a strictly shorter burst time than the already running process no it is not strictly shorter it's it's equal so we will not preempt the process in that case I have written shorter or I should write strictly shorter okay so if P2 also has a burst time of three then remaining burst time is not strictly greater than the uh new process burst time so no preemption will be there at time two there is another process available in RQ which is a bu time is lesser than the remaining bu time of currently running process hence we preempted that in older case in this case if the first time would have been three then we should we would not have preempted that part okay I hope the srtf is clear now let's move down and we will see a question which algorithm has more context switches is it sgf or srtf we are given with this information P1 P2 and 3 P3 are the process numbers this is the arrival time and this is the burst time so we'll first draw the Gant chart for sgf and then srtf so let's draw for sgf first so at Time Zero which process was present in the rigu at time Z P1 was present for bu time five so P will run in the CPU from 0 units to 5 units okay at time five which process are present in the Rue process two and process three are present process two came at time one and process three came at time two so till time five these two process are present in the ricu with this bus time now we will choose the process with lesser bus time so P3 will be chosen I will schedule P3 for two units so from 5 to 7 P3 will run and for rest of the time for four units P2 will come so how many contact switches first Contact switch and second contact switch so it took two switches in sjf now let's see for srtf in srtf which process will be scheduled only P1 will be scheduled because it was the only process present in the Rue so we will schedule P1 for how much time we will schedule until a new process arrives so at at time one we will see and stop we will stop and then see whether a new process arrived yes new process arrived that is P2 does the P2 have a birst Time strictly shorter than the remaining bus time of P1 so at Time 1 P1 have run for one unit so the remaining bus time will be four now P2 also have a bus time of four and P1 also have bus time of four there is no strictly shorter concept they are equal so we will not preempt so this will go run till P at time to at time to a new process arrived till time to P1 have run for two units so the remaining bus time was three and the bus time of new process is strictly shorter than the remaining bus time so here we will preempt the P1 and then P3 will be scheduled P3 will be scheduled for 2 units because this has the least best time so for 2 to 4 P3 will be scheduled and then which will come P1 will come because it has a lesser bus time than P2 so P1 will come and it will run for the remaining three units so from 4 to 7 P will been run and then from 7 to 11 the remaining this part P2 it will run from 7 to 11 so how many contact switches 1 2 and three so three contact switches for srtf and two contact switches for sgf so it was it was an obvious thing because srtf was preemptive it was an obvious thing to suggest that srtf would have more contact switches than sgf okay so what is this point I have written check every time whenever new process arrives so at time one we checked because a new process arrived at time one at time two we check because a new process arrived at time two so we need to check every time whenever new process arrives and if the bust time of the new newly arrived process is strictly shorter than the B first time of remaining process or currently running process then we will preempt otherwise we will not preempt I hope the point is clear let's see another question so why don't to do it as a homework okay I have also given you a solution so try this as a homework and in the next lecture we will discuss so let's start with the homework question which I have given you so this is srtf question and there are six process given to us along with your arrival time and birst time so we need to calculate the entries in the grand chart for srtf algorithm so we can see at time 0 to2 there is no no process available so from 0 to two CPU will be idle at time two we can see there are two processes that is P2 and P6 that have arrived and The Bu time of P6 is lesser than bu time of P2 so we will schedule P6 first and we have to run P6 until a new process arrives so a new process arrives at time three a new process arrives at time 3 which is a burst time of 6 and the remaining burst time of P6 was 7 so we need to preempt it because you know the reason so at time three P6 will be preempted and will be sent back to RQ and P1 will be scheduled because it has a bus time lesser than the remaining bus time of P6 so we need to run P1 for how much time till a new process arrives so we have to keep running P1 until a new process arrives at time for a new process arrive that is P5 and it has a burst time lesser than the remaining burst time of P1 so we will schedule P5 we have to run P5 until a new process arrive at time five a new process arrive which is a burst time lesser than the burst time of remaining P5 so we will schedule P3 and we have to keep running P3 until a new process arrive at time six a new process arrive which is a burst time equal to the remaining bus time of P3 so we will not preempt P3 we preempt only in the case of strictly shorter I have told you this several times so we will not preempt P P3 at time six we will keep it running till it's completes so at time seven there's no new process now now I want to clarify an important point there that I should write it here it behaves like sjf when new process stops coming so now if the new process stops coming preemption will stop okay because the preemption only happens when there is a new process which has a shorter bu time than the remaining bus time of the old process so when new no new process is coming then there will be no preemption sgf become srtf becomes sgf so at time 8 at time 7 also no new processor is there so now which which process is in the RQ at time seven at time 7even all of the process have been arrived so we will schedule the process which has the least best time that is P4 P3 is completed so we will schedule P4 now P4 will come there and it will run for one unit until it get completes so now how many process are completed P4 is completed P3 is completed is there any process which is completed no the rest are remaining now at time it which process will be scheduled the process which has a lesser bus time so we will see which process is a lesser bus time it has a five it has 10 it has three it has seven so three is a lesser bus time so we will schedule P5 for how much time until it completes because on this time srtf becomes sgf so P5 got completed now P5 is also complete which process should be scheduled next the one which has a lesser bus time out of 5 10 and 7 five is a lesser bus time so we will schedule P1 there and it will complete till 5 minutes so till 11 11 to 16 P1 will run now which process should be scheduled this is also completed there are two process remaining 10 and 7 so we will schedule the seventh one that is P6 so we will schedule P6 16 + 7 that is 23 so we will schedule until 23 and then at time 23 the last process that is P2 which has the largest bu time will be scheduled so at 22 to 33 P2 will be there I think this has become easy now okay it it may seems difficult in the beginning but everything is difficult in the beginning okay when you were small when you when you used to write a b c d that was also difficult at that time everything is difficult in the beginning okay do not worry so this is a homework question for you this is a homework question you need to solve I have also given you the answer this is 8.25 okay now another question three process arrive at Time Zero with CPU but of 16 20 and 10 milliseconds if the scheder has a prior knowledge about the length of the cvu bust the minimum achievable waiting time for these process in a non preemptive Sher is how many milliseconds now to solve this question we need to learn about the performance of sgf and srtf so we need to learn about the performance of sgf that is non preemptive and srtf that is preemptive and these two algorithm are said to be optimal algorithm so is there any problem regarding these algorithm why are they optimal because both of them favors the shorter process I I have said shorter process refers to those process which has a less burst time with respect to other process so what are the advantages and disadvantages of doing this favoring shorter process the disadvantages is it causes starvation to the longer process as soon as new process with shorter Bus Time Keeps arriving the longer process will never get a chance to run on CPU and what is the advantage an ages as they favor shorter process so in a fixed time segment more number of process can be completed or more jobs could be done in less duration it means it maximizes throughput minimizes the average waiting time and average turnaround time okay now is there any problem regarding these sgf and srtf they are good yes there is a problem because think about this they work on the burst time burst time is the time required by the process to execute all its instruction on CPU they work on the burst time their implementation is the problem because we do not know the prior bust time of the processes how can we how can we know for how much time process will run on the CPU that's why it needs prior bust time its implementation is not possible okay so since the bu time of process are not known a Priory they are not practically implementable if this is the case then why did you teach a shage you may ask this question then why did we study them because theoretically sgf is an optimal algorithm and we use sgf as a benchmark to measure the performance of other algorithms okay this is quite understand understandable thing so sgf can be implemented with predictive verst times what are the techniques to predict the best time we'll see later but let us do that question what was the question there there are three processes which arrive at Time Zero it means at Time Zero all three processes were available in the RQ with CPU bust off 16 20 and 10 Mond if the scheder that's why it is written there it has already prior knowledge about the length of the CPU bust this is theoretical okay the minimum achievable average waiting time for these process in a non preemptive mode is so which is the best algorithm for the least waiting time sgf and srtf and which one out of these two we have to use here the one which is non pre that is sgf so we will use sgf okay so it's a easy question you just have to apply sgf and calculate the waiting time I hope you can do that let's move to the next question you should try this on your own and then see the solution so there are four process P1 P2 and P3 P4 and the buth time of P4 that is equals to Z is unknown to us and the thing which is given is total waiting time should be equal to 4 now solve the question this is a good question you must solve this and then see the solution otherwise you won't appreciate the beauty of this question okay so let's go so there are four process along with the arrival times and first time are given so we need to calculate the value of Zed okay so let's discuss the approach first so what we will do we will calculate the waiting time we will we will see that this process has to collectively wait for four unit of time okay so we will schedule the process in such a way that the waiting time equals 4 Okay so at time Z which process was available only P1 was available so P1 will get scheduled from 0 to 1 P1 will scheduled and at Time 1 a new process has arrived which is a burst time lesser than the burst time of currently running process so P1 will get preempted and P2 will run for one unit and at time two and at time two only P1 was present in the RQ these process came later after time to so P1 will get scheduled again till here let's calculate the waiting time let's calculate the waiting time so P1 has waited for how much time P1 waited for one unit of time when P2 was running P2 waited for how much time P2 waited for zero now P3 and P4 are remaining so let's erase all this P3 and P4 both has to wait three unit of time I hope you got this because P1 has already waited for one unit of time now these two collectively have to wait three unit of time okay P3 arrived at time three P3 arrived at time three so it has already waited for one unit of time it has already waited for one unit of time so we can write here that P3 and P4 has to wait two unit of time okay let me uh speak again P3 arrived at this moment and the next schedule process the next process which have to be scheduled will be scheduled at Time 4 so P3 is already waited for one unit of time so these two process have has to now collectively wait for 2 units of time now let's discuss the important part which process should be scheduled first out of these P3 and P4 as we don't know the value of Z so let discuss the cases let's say P3 will get scheduled first okay let's schedule the P3 first if we schedule P3 first then P4 will have to wait for how much time the first time of P3 when weu P3 then it will run for 7 and then p 4 will get scheduled now P4 will wait for how much time it will wait for three units of time if P4 will wait for three units of time that is not possible that's already exceeding this so it is not possible that we scheduled P3 first it means we have to schedule P4 first let's schedule P4 first if we schedule P4 first and for how much time P3 have to wait it it has to wait for Z unit of time so P3 has to wait for Zed unit of time and for how much time P4 Will Wait P4 had had arrived at time four and and it gets scheduled at time four it arrived at time four and it gets scheduled the time for so for how much time it has waited it has waited for nothing so Z + 0 = 2 it means Z = to 2 it means the first time of process 4 will be two now after we have found the value of two let's verify so let's do this as two now let's schedule the remaining process so P4 will get schedule first P4 will get scheduled first because it is a lesser first time so P4 will run for two units that is six and then P3 will be scheduled for 3 units of time that is N9 now let's calculate the waiting time of all process for how much time P1 has waited P1 has waited initially nothing and then P1 has waited for 1 unit of time okay for how much time P2 waited P2 waited for nothing as it arrived at Time 1 and it get scheduled at Time 1 so P1 waited for nothing now for how much time P3 had waited P3 had waited for one unit here as it arrived let's let's discuss directly as it arrived at time three and it get schedule for time six so it waited for three units so total weight will be four the total weight will be four so the option is uh the value we have found is correct so in the previous lecture we somewhere discussed that sgf is the optimal algorithm but there is a problem with the sgf it's implementation we do not know the bur time a prior we can only predict them so in this lecture we are going to learn about some of the prediction techniques for CPU birds so there are two type of techniques static and dynamic in a static Technique we look at the total verst time let me give you an example so first is the process size there was an old process which is a size of 101 KB and it ran on the CPU for 20 seconds there's a new process which has a size of 100 KV so we can say that it will approximately run around 20 seconds in the CPU so this is how we predicted based on the size okay there is another method to predict the static burst time on the basis of type there are four let's say there are we have segregated these processes in various classes let's say the operating system type process interactive process foreground process background process OS process take an average burst time of 5 Seconds interactive process average bust time of 10 seconds then 15 seconds and 30 seconds then there is a new process which has arrived and it has a type of background process so we can say it will approximately run around 30 seconds so these are the methods which we have predicted the static first times okay now the another technique is dynamic but what I want to tell you is while remaining in the radue we want to predict how much time will be of the next burst so while remaining in the NQ we need to predict how much time will it is going to take for the next burst while remaining The Rue we want to predict how much time it will take for the next burst while remaining The Rue I hope you got the point so these are the two predictions which we have already made now while remaining in this radue we want to make the predictions for this CPU P so how can we do that now how we will predict dynamically so for dynamic predictions we have a technique named exponential averaging technique or aging algorithm so this is the diagram which I was there referring to this is T1 that is the completed bus time so T1 will represent the this vt1 T1 will represent the bt1 and to one will represent and T one will represent the time which we have predicted for the first bust I hope you got the point this was the actual and this was we predicted let me write again this was the time which we predicted and this was the time which actually process took so for this to3 will be the time which we want to predict and T3 will be the time which was actually taken by the process so to n + 1 represent the next CPU busts so here the value of n will be 2 what is the n signifies n signifies how many times the process has already been with the CPU so here two times the process has already been with the CPU now we want to predict for the next bursts see to n plus1 represent the next CPU bu so the formula that we experimentally derived that is to n +1 is equals to Alpha TN + 1 Alpha TN so what does this signify Alpha is just a constant which lies between 0 to 1 so what does this Alpha signify it signifies the weight so for the prediction of next CPU bust how much weightage we are giving to the already completed CPU busts plus how much weightage we are giving to the predicted CPU busts okay so to calculate the next CPU bust we are giving some weightage to the actual time taken plus we are giving some weightage to the pr predicted time I hope I am able to clarify what I want to say weightage given to the actual time taken weightage given to the predicted time so we will calculate the T n+1 in this way so what is it it is a recurrence relation so how are we going to solve this recurrence relation V will put the value of TN so this this method is known as back substitution so what does we do here we will find the value of TN and we'll put it back here okay so if the equation as a t n + 1 = Alpha TN + 1 Alpha t n so what we will do we will just subtract 1 so this will become t n equal to Alpha tnus 1 + 1 Alpha t n minus 1 so this will give the value of to n this is how recurrence relation work so what we will do we will substitute back the value of TN now we get this what we will do now we will solve it first we'll simplify it first so we will get this after the substitution value of TN and then we will get to n minus one what we will do we'll again find the value and we will put it so we found the value of to n minus one and then we put it what we will get then we get this part and then we will keep putting the value of to then we will put the value of to n minus 2 and then to n minus 3 and we will keep putting the value until we reach to 1 this is to until we reach to one now now the thing now the question arises okay so we started with to n we put the value of t n minus one and then we put the value of t n minus 2 and at last we reach the value of to n what we will do then we have to do nothing because the value of to 1 will be given to us this value is known as initial guess so let's take the analogy of factorial we cannot find factorial of any number until we know the factorial of zero that is one can you find the factorial of five yes uh without 0 factorial No 5 into 4 into 3 into 2 into 1 into 0 factorial you can find the value of this but how will you get the value of this because in factorial you cannot put negative values so you cannot find the value of any factorial until the initial guess is given to you so here the value of T1 will be given that is to1 will be given that is the initial guess so what we can infer given the value of L Alpha and to one one can predict any CPU bus let me clarify again so in HF the main problem which arised was its implementation we do not know the burst time of the process a prior so we need some prediction techniques to predict some CPU bus so there were two techniques static and dynamic in static we used the two methods of size and type in Dynamic what we do while remaining in the Rue we want to predict how much time it will take for the next verse so we derived a recurrence relation so this was the recurrence relation given what we will do we want to solve this recurrence relation so we found the value of TN and then we put the value of TN back in the original equation and we will keep on doing until we reach T1 and the value of T1 we know because it is the initial guess it is similar as if we know the value of 0 factorial to find the factorial of any number so given the value of T1 and Alpha we can predict any next CPU bu so let's take the question it will clarify you more let's solve this question now consider a system using so I hope the point is clear let's move to the question consider a system using aging algorithm to predict the next CPU bu given alal to 2 and to 1al to 10 the process Bus Time hour that is this is T1 this is T2 this is T3 this is T4 these are the actual completed burst time now we need to predict the next CPU first okay so we'll use the equation to n + 1 equal to Alpha TN + 1 Alpha t n so we need to find the fifth bust so we'll predict the next CP bu four has already been completed so n is equal to 4 so we will put the value of n equal to 4 so T 5 = to Alpha T4 + 1 Alpha T 4 so we got this equation here we know the value of alpha T4 1 Alpha we don't know the value of T4 so we'll write the equation for T4 what we will do we will put n = 3 so we will get T 4 = to Alpha to T3 + 1 Alpha to 3 we don't know the value of to 3 we'll do this again uh to 3 = to Alpha T2 + 1 Alpha to 2 we do this again to 2 = to Alpha T 1 + 1 Alpha T 1 we did this we kept on putting the values until we reach the initial guess are we given the value of initial guess yes so this is the value which we are given with now we know the value of this this this and this so we can find the value of T 2 we will put the value of T2 here we'll find the value of to 3 we will put the value of T 3 here we'll find the value of T 4 and we'll put the value of T 4 and we'll get the value of to 5 so in this way we'll get the next CPU burst it was an easy question so this is an important formula you need to remember this what does it say t n + 1 equal to Alpha TN + 1 Alpha t n Alpha signifies the weightage okay but the problem of starvation is still continuing in this sgf whether preemptive or non preemptive because longer process will starve against the solter process this fact cannot be denied so how we will solve this problem yes that is the hrrn algorithm highest response ratio next now you may wonder what is response ratio so response ratio is this waiting time plus burst time divided by burst time and burst time is also known as service time so the response ratio is commonly known as W + S / s Well w is the waiting time s is the worst time and s in the denominator is the first time can you can you infer something from this response ratio can you infer something yes the process with the shorter bus time is preferred but the process which has been waiting for a long time is being given more priority than the shter process do not worry when we will see the numerical you will get a more understanding of this so the next process is to run is the one whose response ratio that is this part is the highest so the response ratio is highest that process will be given more priority longer process waiting from a long time will have high response ratio and that was the problem which got solved with this hrr and algorithm now W + S / s that means if waiting time increases then response ratio increases if burst time decreases then response ratio increases it means the shorter process is given priority that fact cannot be denied but the longer process which has been waiting from long time will have high response ratio so when waiting time increases the response ratio increases and that process will be scheduled first whose response ratio is high and its mode is non preemptive it works on a non preemptive mode and the tiebreaker thing is again the lower process ID suppose two process have same response ratio then the process which have lower process ID will be favored so let's see a numerical and then we'll get a better idea of this so these are the data sets now let's first solve using sgf so which process is available at Time Zero process one so we will schedule process one for bus time three so till process 0 till time 0 to 3 P1 will run at time three is there any new process which has arrived yes P2 has arrived so we'll schedule P2 for sixth bus time so from 3 to 9 P2 will run now all three process has been arrived till P2 completes now P3 P4 and P P5 are present in the ricu which process has shorter bust time P5 has shorter bust time so we schedule P5 from for two bust units so from 9 to 12 P5 will run from 9 to 11 P5 will run now out of them which process is shorter Bus Time P3 so their P3 will run for 4 units of time so from 11 to 15 P3 will run and at last for five units of time P4 will run so this part this Gant chart is based on the hgf algorithm what we can infer from this see at this point at at time 9ine at time 9 see at this point P3 arrived at Time 4 but it got scheduled at time 11 and P5 arrived at time 8 and it get immediately scheduled because it was shorter so this is something unfair being done to process the now let me speak again P3 arrived at Time 4 and P5 arrived at time 8 but still P5 got scheduled at timeline just because it has a shorter bus time this was something unfair being done to process 3 it arrived at Time 4 it should be scheduled earlier but P5 is favored because of a shorter bus time so P3 has been waiting for a long time this should not be the thing so how can this problem be solved using hrnn SO waiting time of P5 is 1 and waiting time of P3 is 7 this is unfair so let's solve this by using hrrn now what we do in hrnn let me recall so out of the process present in the RQ we calculate the waiting time and The Bu time and then we will do waiting time plus bust time divided by bust time that is the response ratio and we'll compare the response ratio between those process only which is present in the Radu at the time of scheduling and there's a special thing this waiting time is not the waiting time for the complete Gant chart it is the waiting time till the time which we are seeing when we'll solve the question you will get a better idea what I I want to say okay so which process is present in the radue at Time Zero P1 is present so we will schedule P1 for three units of time as I say it was non Prem for time at time 2 P2 was present so P2 will be scheduled because this was the only process we need not to think anything if there is only process in the ricu for scheduling scheder will not think anything and it will directly schedule that only process so P2 will be scheduled so from 3 to 9 as it is a bu time of 6 P2 will be there at time 9 which processes are present in the Rue at time 9 P3 P4 and P5 are present so these processes are present in the Rue at time 9 now we will calculate the response ratio because there out of these three process scheder has to select one so it will calculate the response ratio for these three processes for P3 what is the waiting time it arrived at time 4 and we are seeing at time 9 or the short time scheduler is at the moment of time 9 so from 4 to 9 how much unit P3 waited P3 waited for 5 units of time and what was the birth time of P3 4 and 4 so 5 + 4 divided 4 that is 9 by 4 which is 2.25 let's calculate for P4 P4 arrived at time six and shortterm Sh is planning to schedule at time 9 so at this time till this time how much unit P3 P4 waited P4 waited for 3 units of time and what is the first time 5 so 3 + 5 divid 5 that is 1.6 is the response ratio for P4 till time line now we'll see P5 so P5 P5 arrived at time 8 and the current time is time 9 so tell how much time is wait it waited it waited for 1 unit so 1 + 2 divided 2 that is 1.5 now out of these three response ratio 2.25 is the highest that is of P3 so we will schedule P3 here and it will run non preemptively for four units of bus time so from 9 to 13 P3 will run at time 13 which processes are present in the RQ P4 and P5 now we'll calculate the waiting time till time 13 so we'll calculate for P4 P4 arrived at time 6 till time 13 how much unit it has waited it waited for 7 units of time and The Bu time was 5 so we have written 7 + 5id 5 that is 2.4 is the response ratio for P4 now let's calculate for P5 so for P5 what is the arrival time it arrived at time 8 and the current time is 13 so till how much time it waited it waited for 5 units of time so 5 plus its bu time 2id 2 that is 3.5 out of these two which is greater 3.5 is greater so we'll schedule P4 P5 next and P5 will run for how much unit of time two units so 13 to 15 P5 will run and in the end the only process which is remaining in the ricq is P4 so we will schedule P4 directly so and P4 will run for 5 minutes of time so from 15 to 20 P4 will run now what we can see this was the longer process and this was the shorter process hrnn preferred that longer process which has been waiting from a long time so the problem of starvation solved so let's start our class with a new algorithm that is longest remaining time first this algorithm is exactly the opposite of algorithm srtf which we have studied earlier in srtf we used to schedule those process which has a shortest worst time among the process present in the ricu so here as the name suggest we will schedule the longest one but there is a catch that we will discuss later while solving the question so this algorithm is not easy as it seems this is a difficult one you have to be extra careful while solving these questions so the selection criteria is first time and the mode of operation is preemptive this make it dangerous and there is another thing that is the tiebreaker rule which was common in all of the algorithm which we have discussed if the tie if there is a need of tiebreaker rule we will we will take the lowest process ID we will prefer that process okay so let's start with the question and you will get an idea of what I was saying so at the time zero there are three process available in the radue so we will schedule the process which has a largest bus time so P3 has the largest bus time that is 8 so we will schedule P3 now for how much time P3 will run that is the main thing so in srtf what we used to say out of the several process present in the red EQ we will choose a process and we will schedule it to the CPU and for how much time this process will run this process will run until a new process arrives or there is a process present in the radue which has a burst time which has a burst time strictly shorter than the remaining verst time of currently running process so this we used to say we used to emphasize more upon strictly shorter thing as I said this algorithm is exactly the opposite of srtf so what we will do in this algorithm or you tell me what is the opposite of a strictly shorter thing the opposite of a strictly shorter is equal or greater equal or greater the opposite of strictly shorter is equal or greater so what we will do here we will keep P3 running will keep P3 running until there is a process present in the radue which has a burst time of either will will check of either eal or greater than the remaining burst time of currently running process I mean I am saying this very slowly because this needs an extra care so we will keep P3 running until there's a new until there's a process present in the ricu that is P2 which is a burst time of either equal so yes equal thing satisfies P3 is a bus time of 8 and it has already run for 4 units so the remaining bus time will be 4 and four and four are equal so what we will do we will preempt P3 and we will send it back to the radue and we will schedule P2 and we will schedule P2 because this is the process which has a burst time equal or greater than the burst time of than the remaining burst time of previously running process so four and four were equal so what we did we preempted P3 see we we never used to preempt a process in srtf if the bur time were equal but in ltf we will preempt a process if the bus time are equal so at time four four and four are equal so what we did we preempted P3 and we scheduled P2 so P2 will be scheduled now for how much time P2 will run P2 will run for only one unit of time because when P2 will run for one unit of time there is a process present in the RQ which is a bu time of greater than the remaining bus time of P2 so 4 is greater than three so we will preempt P2 and we and we will send it back to the RQ and will schedule P3 now for how much time P3 will run P3 will also run for one of time only because when P3 will run for one unit of time there is a process present in the RQ which has a burst time equal to the remaining bus time of process P3 so we will preempt P P3 send it back to the radue and we will schedule P2 again now P2 will run for only one unit of time because there is a process present in the RQ which has a burst time greater than the remaining bus time of P P2 so we will preempt P2 and we will schedule P3 now P3 will also run for 1 unit of time because the remaining bus time of P3 is equal to the bust time of two processes present in the radue now out of these two process which we will choose the process with the lower bu ID so we will choose the process P1 okay now P1 will run again see have you seen some pattern here the same pattern is going to follow now the B time of P1 P2 and P3 is 222 so which will be scheduled first so they will they will be scheduled alternatively so first P1 will run as P1 will run its remaining time will become one remaining bu time will become one now there are two process present in the redq which is a first time greater than the remaining bu time of P1 so we will schedule out of these two process now which process we will choose the process with the lower bu lower process ID so P2 will be scheduled here so P1 will be send back to the ricq and P2 will be scheduled P2 will be scheduled now P2 will also run for unit of time because there is a process present in the RQ which is a bu time greater so P3 will be scheduled now for how much time P3 will will run P3 will run for only one unit of time because if it has run for one unit of time there are two process present in the radue which is a burst time equal to the bu time of remaining bu time of currently running process so we will preempt P3 and now out of these two process we will schedule a process which is a lower bust ID lower process ID so we will SCH P1 and the same thing goes goes on P3 when when P1 will run this will become zero and there are two process present in the r which is burst time greater than zero so out of these two the process with the lower bur lower process ID will be preferred so P2 will be scheduled P2 will run for one unit of time and then there is a process present in the radue which is a Burge time greater than P2 so P2 will be preempted and P3 will go and in this manner all the process ends so this was a little bit weird algorithm and it and it requires an extra care to to solve such question okay so let's draw another question so this is the thing which we are given with and we have to find the average completion time of A and B okay so let's do this now there are three process present in the radue at time zero so we will schedule the process which has a largest bu time so now c will go there c will run for three units of time because at three unit of time there will be a process present in the RQ which has a bus time equal to the bus time of currently running process so six and six are equal so we will schedule C and we will so we will preempt C and we will schedule b b will run for how much time we will run for only one of time because there is a process present in the radue which has a bur time greater than the remaining bus time of currently running process so C's bust time is greater than than the B's bu time so 6 is greater than 5 so we will preempt B and we will schedule C now C3 will again run for one unit only so this thing will goes on and on until they all becomes equal so c will go there his bus time will become five five and five are equal c will get preempted B will be get scheduled then B's bus time will become four now there's a process which has a bu time greater so c will again get scheduled now c will run for only one unit because there are process available which is a bu time equal to C so out of these two the one which has a lower process ID that is a will be scheduled so a will come here a will run for only one unit as there are process with greater bust time so out of these two B will be scheduled so B will run for three and there's a process with greater verst time then C will be scheduled c will run for only one unit of time because there are process available in the RQ which which has a bust time equal to the bust time of currently running process so after of these two the process with the lower lower process ID will get scheduled so a will get scheduled here a will run for only one unit because the two is shorter than two is lesser than three and three so after these two B will be scheduled as it has a lower process ID so B will go there b will run for two units because 3 is greater B will run for only one unit remaining time will be two 2 is lesser than three so three uh that is the c will be scheduled now the same thing goes and on until the everything ends to zero so I hope you got the idea so now what we were asked we were asked find the average of the completion time of A and B so what will the completion time of A and B A completed at 17 and B completed B completed at 18 so 17 + 18 divid 2 is the answer let's solve some other questions in a system in a system using single processor a new process arrives at a rate of 10 process per minute and each such process requires 5 Second of service time what is the percentage CP utilization so this this is a very easy question six in 60 seconds that is a new process arrive at at a rate of 10 process per minute it means in 60 second 10 processes arrive that means in 6 second one process arrives and each such process requires 5 Second of service time so what is the CP utilization so there are 10 process each requires 5 Second of service time so 50 seconds will be the service time of all these 10 processes and the completion time will be the 60 so the percentage utilization will be the useful time upon the total time the useful time will be 50 and the total time was 60 so 50 divid 60 into 100 will be the percentage C utilization so this was a easy question let's move to another question six jobs are waiting to be run the expected running times are 975 21 so I made in this way and X respectively so this is X find the value of x using hdf algorithm so I have included those questions of old algorithm so for the revision purposes okay so I was thinking something about the dpps so I thought I should share the DPP with you for your practice uh I think I have solved enough questions in the lectures only uh so I will share the DP with you you solve them I will share the answers and the detailed solution detailed printed solution I will type them with you instead of making a whole video of this lengthy uh solving because there are at least 7 to eight questions per DPP and there are almost 5 to six dpps so it will take lot of time to discuss each question one by one and there are and they are easy question as compared to the question discussed in the lectures so what I was thinking I will share them with you if you get some doubt you may ask me and I will share the detailed solution with you okay so let's move to this question six jobs are waiting to be run then expected running times are this one find the value of x using SDF okay so let us schedule all the process are available at time zero so which process has the least bu time because this is sgf shortest job first and this is nonpreemptive so P5 will be scheduled it will run until completion at time when which process are present all of them are present so P5 will be over now I have to choose the smallest among the among these process except P5 so P4 this process has the shortest ver time so P4 will get scheduled it will run until completion now which process now P3 P3 is the shortest among 97 and x x is the One X lies between 5 and 7 so it will be greater than five hence P3 will be scheduled first P3 will be scheduled until 8 now X will come because its value lies between 5 to 7 and these ones are greater than 7 so X will be sh to next so P6 P6 with the first time of X so 8 to 8 + 6 will be scheduled next now P2 for 7 so 15 + x and then P1 that is 24 + x so what we are given there the expected running times are this and this uh X is the range of X is given and average completion time is 13 so we'll add the completion time of all and will divided by six because there are six process that will give me the average so P5 completed at 1 P4 at 3 P3 at 8 P6 at 8+ 6 P2 15 + 6 and P1 is 24 We'll add all of them and divide by six as there are six process and this 13 is given to us so X will be equal to this part and in just computation so I hope you got the idea how to solve these type of questions in the next lecture we will see an important algorithm that is priority based scheduling let's move to the new algorithm named priority based Shing this algorithm works exactly like sgf or srtf that means it could be nonpreemptive or it could be preemptive except that it looks for priority instead of BU time so the process with the hard priority will be given preference in terms of scheduling what is a priority it is a number assigned in corresponding to the level of importance of a process let's say OS processes the that is operating system service routine will be given higher preferences than the user process okay so the OS process will have higher priority it could be non preemptive or preemptive and the tie breaker will be the same that is lower process ID okay so if two process with the same priority comes then the one with the lower process ID will be selected So based on the type size and the resources integer value is given to a process that is the priority okay so what is the default convention the default convention is higher the number higher the priority will be there higher the number higher the priority okay so if it is given in the question that 10th be the lowest priority and number one be the highest priority then you have to take accordingly okay but the default one is higher number higher priority so let's solve using both preemptive and non preemptive so these are the process these are the priority of the process arrival time and the burst time let's solve using non preemptive so this is the arrival time P1 arrived first so we will schedule P1 and it will run until completion because this is the case of non preemption so it will run until 4 at time four which processes are available process two and process three which has a higher priority process three so we will schedule process three until it completes so it will run for 5 minutes of time so 4 to 9 process 3 will run and in the end process two will run for 9 to 12 so this was the case for non preemptive and for the preemptive case process will continue to run until a new process with the higher priority arrives so P1 was the first to come in the C in the RQ so P1 will be scheduled first and it will run until a new process the higher priority arrives so P2 is the new process with higher priority so it will run until one and then P1 will be preempted and P2 will be scheduled and P2 will run until a new process with high priority arrives so P2 will run until one unit and P3 arrives now P3 is the process with the highest priority so it will run until completion so it is a worst time of 5 so it will run from 2 to 5 and then which processes are present in the ricu now P1 and P2 which is a higher priority P2 so we will schedule P2 until it completes see see in srtf whenever the process stopped arriving it behaves like sgf or the preemption or we do not preempt the process when there is no new process arrival okay so when new process stops coming will stops the preemption so here at time three 0 1 2 so at time three at time three no new process came so after this we did not preempt any process before its completion okay so these process left the CPU after their completion only okay so I got the point this is similar to srtf and sgf but in srtf we used to focus on first time and here we will focus on priority this is as simple as that let's solve another question so there are six process available these are the priority this is the arrival time and this is the burst time so let's create Gant chart so we can see there is no new no process at Time Zero so the the first process arrived at time two from 0 to two the CPU will remain idle at time two at time two I can see that process 4 is available at time two the process 4 is available with priority three so I will schedule process 4 until a new process arrives at time three that is a higher priority than process four priority so six is greater than three so we will preempt four and we will schedule P2 now P2 will run until a new process arrives with a higher priority so after time time three new process arrives when a new process arrives at time four that is P1 but it Priority is lesser than the priority of P2 so we will ignore that process and then another process comes at P at time five which is a higher priority so we will preempt that process and we will schedule the process with the higher priority so P5 will be scheduled and I can see that it has a second highest priority so it will run until the new process with the higher priority comes so after 3 units a new process with the high PRI but it bu time is two so it will complete at time 7 at time seven which process are available in the RQ P2 is available with the the highest priority because at time five P5 got erased and the new process with the highest priority will come at time 8 so at time 7 P2 will be the process with the highest priority so we will schedule P2 and it will run until a process with the highest priority that is P3 with the priority 8 will come so as the process with the highest priority come the process with the lower priority that is six is lower with lower as compared to eight so this will get preempted and P3 will be scheduled and it will run until it gets completed because it the highest priority process so till 8 to 14 it will run as it is a bus time of 6 okay now which process will come now which process will come P6 will come P6 has a priority of five and it has arrival time of three so P6 will be scheduled why not P2 I think P2 got completed here 3 to 5 that is 2 unit and 1 unit so P2 was completed and the next highest process and the process with the highest priority after P2 and P5 was P6 so we will schedule P6 here so P6 will run for how much time P6 will run for five minutes of time because now new process has start arriving so whenever new process stops arriving the mode changes it becomes from preemptive to non preemptive okay so say the mode changes from preemptive to non preemptive now when the process get scheduled it will run until completion so this will run until completion run until completion run and run okay so at time 23 P4 will get over so what will be the schedule length completion time of the last process till the arrival time of the first process so from 2 to 23 that is 21 will be the answer for schedule length so let's start the part two of priority based scheduling in priority based scheding what we used to do we used to schedule the process based on the priority it is a number assigned to the process which was corresponding to the level of importance given to process okay so priority can be the static or dynamic static priority means fixed priority and dynamic means wearing can priority be wearing yes we will understand after some time so the problem will pursue that is the starvation to lower priority process because if high priority process keeps on coming then OS will never schedule a low priority process that will cause to the starvation to it and this is unfair so what we will do we will increase the priority so lower priority process will become higher priority process after some time that means the priorities are not fixed they are wearing they are Dynamic so Dynamic priorities that is based on the Aging algorithm will be the solution for starvation don't worry we will solve some questions on that okay so let's move to the question number one what does it say uh there's a system with three process P1 P2 and P3 and they have infinite instances of these process so the first instance arrival time of each process first instance is 1 millisecond what I want to say there are three process P1 P2 and P3 and they have infinite instances of them okay the first instance are arrived at Time 1 millisecond the second instance of P1 arrived at Time 4 and the third instance at time 7 so they have periods okay 3 7 and 20 3 7 and 20 okay so now the question is what is the completion time of first instance of process P3 so I have said there are three process P1 P2 P3 there they have infinite instances so when the what is the time when this instance will get over okay so nothing we have to just schedule and there is one more Point given that the priority is inverse of the period so the parity of process one will be 1X 3 P2 will be 1X 7 and third will be 1x2 so let's schedule so we will start with Time Zero which process is available at Time Zero no process was available all of them came at Time 1 millisecond so from 0 to 1 CPU will become idle at Time 1 which process will be scheduled the process with the higher priority this will be scheduled P1 will be scheduled for how much time as this is of higher priority it will complete until it will execute until completion so from 1 to two P1 will schedule so first instance of P1 completed at time two now who will come P2 will come P2 will run for 2 units of time so P2 will run for 2 unites of time because this is the highest priority process among P2 and P3 P1 was over now P2 and P3 are remaining so P2 will be scheduled for 2 unites of time so from 2 to 4 P2 will get scheduled now which process are available in the ricq P3 and P1 the second instance of P1 came at Time 4 so P3 and P1 these are the two process present in the ricq Which is higher priority P1 is high priority so P1 will get sched for how much time for one unit of time it has one unit of bust time now at time five which processes are present at time five only P3 is present I guess yes only P3 is present so P3 will run for how much time until a new process with higher priority arrives so P3 will run for 2 units of time because at time 7 P1 came which is of higher priority so P3 will get preempted at time 7 and P1 will come okay so from 7 to 8 it will run because it will run until completion as it is the process with the highest priority so it has wor time of one so it will run from 7 to 8 now which pluses are present in the RQ P2 is present because at time 8 the second instance of P2 came so P2 is present P2 will come in the RQ or P2 will come in the CPU and it will run for 2 units of time so from 8 to 10 P2 will run now the third instance came from came at time 7 third instance I think this was all completed now the fourth instance of P2 oh sorry a fourth instance of P1 will come at time 10 so fourth in instance will get scheduled it will run for one unit of time I said they have infinite instances they have infinite instances so the fourth will come at time 10 now P1 Will C schedu see P3 is not getting chance to be run after this first P1 came then P2 came then again P1 came now P3 will give the chance because P2 is over and its next instance will come come at time 15 P1 is over and its next instance will come at time 13 so at time 11 only P3 have have been in the CPU so it will run for how much time its remaining bu time so P3 has already run for 2 units here so it will run for 2 minutes here so what will the completion time of first instance of P3 at 13 so 13 will be the time 13 millisecond will be the answer now let's solve a question on Aging algorithm consider a system using preemptive priority baseding dynamically changing priorities the priorities are Dynamic on its arrival a process is assigned to a priority of zero so when the process arrives the priority is set to Zero running process priority increases at the rate of beta and the priority of process in ricu increases the rate of alpha by dynamically changing the values of Alpha and beta one can achieve different scheding disciplines well that is clear because see if the priority if the prior of the process in the RQ is more than the priority of process running then it will be preemptive and if the priority of running process is more than the priority of ready process then it will be non preemptive I hope you got the point so what will be the disciplin be followed by the following conditions so let's see if the process arrives the priority is zero process in ricu increases by Alpha rate and processes running increases by Beta rate so in a job queue when a new process arrives it has a priority of priority increase by Alpha rate so let's say at time one at time one what will the priority of ricq what will the pariy of processing ricq at Time 1 it will be Alpha because initially at Time Zero it was Zero at time one let's say it increased by Alpha so the priority of process in the ricu will be Alpha and what will the priority of process in the CPU running at Time 1 it will be beta so now we have to compare Alpha and beta beta so if beta is greater than Alpha which I mean to say if the priority of process running is greater than priority of process in the ready then no ready process can ever preempt the running process because beta is greater than Alpha so it will behave like fcfs first come first serve and if if ready process have always greater priority than the running process if ready process have always the greater priority than running process process but but a newly arrived process have always greater priority than ready process and running process then what will happen think think if a newly ared process have greater priority than running process and ready process then the newly arrived process will be scheduled first which means the one who came at last will get scheduled first so last come first serve and here the one who came earlier will be scheduled first I hope you going to point the one who came earlier will be scheduled first and in this the one who came at last will be scheduled first okay so if you have some doubt this is an easy question think about it here's the question read it again think about it see the solution and you will and your doubt will clear automatically welcome to the new lecture and in this lecture we learn about the round robin algorithm this is the most famous scheduling technique in this roundr algorithm let's understand the IDE if the process fails to execute all its instruction in the given time Quantum so we assign a fixed time Quantum let's say of 4 seconds if the process gets its all instruction complete in the 4 second this is well and good otherwise the pro the OS will preempt that process and will give chance to other processes to be with the CPU and that process that preempted process will go to the end of the Rue and go to the end of the ricq so let's see round an algorithm this algorithm is used in preemptive based multiprogramming time sharing operating system okay what does it do it improves interactiveness and responsiveness of the system so let's understand this by real life example so what we used to do in India we used to play cricket on the Terrace of our house okay so I I can recall when we were smaller when we when we were younger there was a big uh there was a big ba the big brother he used to play for so so far so long he used to play and we we the smaller kids do not get a chance to bet so we decided a rule we created a rule that every one of us will play only six balls that is in in one hour consist of six balls so every one of us will play only six balls and whether you are out or not you have to retire and give chance to other players to bet okay so that such things do not happen that uh a player who is good to a player who is good in cricket do not get out easily and we used to just ball and field and and in in childhood days we we used to think that balling and Fielding is boring and batting is a good thing so we all of us want to bat but this big boy doesn't let us to bat he was good in cricket so we decided a rule that whether you are out or not you have to leave you have to retire after after six balls you will go there in the fielders and one of us will go to B okay so the similar case is there the similar case is here in the round robin we assign a Time Quantum to a process whether a process completes its instruction in this time Quantum or not the process has to leave after that time Quantum and other processes who are waiting for the CPU will get a chance to be with the CPU so the criteria will be the arrival time plus the time Quantum and the mode of operation will be this is obvious preemptive okay so let's see the question first before starting the question I have a tip for you always maintain the status of ricu and keep cutting the processes which have been over from ricu see this is an important thing this is not only mandatory for round robin I suggest you should maintain ricq for any of the SCH algorithm this will decrease the chances of silly mistake which you may make but in case of round robin it is almost impossible or it is very very difficult to create Gant chart without the help of radue otherwise you may make mistake okay so what is my tip always maintain the status of ricu always and always maintain the status of ricu especially while solving the round robin questions and keep cutting the process from ricu like this way those which are completed keep cutting okay so let's see this question here the time Quantum is two which means a process will run for 2 units and then it will pre automatically so let's start so P1 P2 and P3 all are available at time zero so which process will will schedule the one who arrived earlier all of the arrived them same time so we will use the tri breaker rule TI breaker rule that is the lower process ID so we will schedule P1 what is the burst time of P1 P1 is burst time of 4 unit so we will schedule for two time Quantum and then it will preempt so P1 P2 and P3 all of them were available at Time Zero now what will happen till time two till time two P1 will run and it will go to the end of the radue at time two see I have seen I have written this I have written this if the time Quantum expires then OS will preempt the process and the preempted process will go to the end of the ricu so this P1 this P1 when it will get preempted it will go to the end of Rue so this was the Rue and it will go there now what will happen let's see at time to P2 will get scheduled now P2 will get scheduled it will run for how much time it will run for 2 units of time so it will run for 2 minutes of time now the remaining bus time I have maintained here 5 3 and 4 two now who will run now P3 will run P3 will run for how much time it is a bu time of three so it will run for two units and the remaining will be one so it will run there and after at Time 4 P2 will go at the end of ricu and at time 6 p 3 will go at the end of ricu now what will happen see this was completed now I will schedule P1 so P1 will get scheduled for how much time for 2 units of time so this will get over and P1 completed if P1 completed there is no need to send back to the Rue it will go to the terminate stage it will end so at time 8 P1 ended now which process is available P2 is available so we'll schedule P2 so we'll schedule P2 then the remaining time will be 1 unit so at time 10 P2 will again go back to the ready Cube okay so now P2 gets over now the turn is of P3 so P3 will run for how much time the remaining bus time is one so P3 will run for one unit of time so from 11 P3 will run and it will end here now P2 will run so I will cancel it and P2 will go there so in this way if you just put a cross mark there it will be easy for you to remember that we have scheduled all the process which has a cross mark okay I I hope you got the idea so this round dropping is a new type of uh Shing technique so I suggest you to do this Sol this question or on your own now and get this G chart okay so let us go there and solve another question this is a new question this is a another variety of round dring question which you will explore see there are five processes okay each arrived at different time and they have the bus time also given the time Quantum is two so we will schedule process P4 as it arrived at time three the earliest so from 0 to 3 CP will remain idle and at time three P4 will get scheduled for how much time the time Quantum is two so out of three two will get over so one will remain now at time five at time five P4 will go at the back of Rue but at time five we can see that P1 and P5 are also present in the ricu so firstly the new process will come and then the preempted process will join them at the back I'll speak again P4 ran in the CPU from time 3 to 5 L A Time five I see there are two process already available that is P1 and P5 so what I will do I will enter these process I will enter this process in the ricq first and then the preemptive process will go at the back of Rue so the firstly the new arrived process so the new process will come in the RQ and then the preemptive process will go let me this week again first the new process and then the preemptive process the new process and then the preemptive process so I hope you got the idea now let's continue our discussion so so P4 was present in the radic time three so from 0 to 3 the CP will remain idle and at time three P4 will come P4 will run for 2 units of time P4 will run for 2 units of time and the remaining bus time will be one at time five there are two new process that is P1 which arrived at time four and P5 which arrived at time five so I will schedule the new process in the RQ I will sent the new process in the RQ and then the preemptive preempted process will go so new process then preemptive process now I will cancel this part and then when I schedule P1 I will cancel this part okay so I have already scheduled P4 now I'm going to schedule P1 so I will cancel this P1 will get scheduled P1 is a bu time of four so it will run for 2 units of time it run for 2 units of time that is from 5 to 7 from 5 to 7 p Dr at time 7 is there a new new process no no new the next new process came at time 8 so at time 7 no new process came so I will directly send this P1 at the end of RQ this was the end of RQ then there so P4 will go there and P1 will go at the end of ricu now I will schedule P5 so P5 will come P5 is a bus time of four so two will be the remaining bus time so P5 will get scheduled here now from 7 to9 P5 will come P5 will come at time line I can see that there is a new process so the firstly the new process will come and then the preempted process will come new process will come first and then the preempted process so preempted process will go there now what I will do now I will schedule P4 so P4 was scheduled again for how much time it will run for one unit of the remaining bus time so P4 will run for one unit at time 10 is there any new process no the next new process is going to come at time 15 so at time 10 which process are available these processes are available so I will schedule P1 first then P3 and then P5 I can see the process which that is P2 came at time 15 so the new process will come first so at time 15 P2 will come and then the preempted process that is P3 will go there okay so I hope you got the idea so in the same way you have to complete the Gant chart so let me revise again what we have done till now so round dring algorithm is a kind of algorithm which has a fixed time unit a fixed time slice if the time slice expires then the OS will preempt the process and then that preempted process will go at the end of RQ after the new process comes Okay so the tip was always maintain the status Rue and keep cutting from Rue so we have seen this question let us let us do let us uh revise this question again because this is an important question firstly 0 to 3 CP will remain idle at time three P4 will get scheduled it will run for how much time at time three P4 run for two unit of time because this is time Quantum two one will be remaining this one will be scheduled later at this moment of time so P4 will get completed at 10 now will come P1 will come so P1 will get scheduled at time 7 at time 7 which process are available in the RQ P5 and P4 are available so they will come first and then people will go behind them and then we will schedule accordingly P5 P4 P1 and then the new process will come that is P3 and then the old process that is p P5 will go there now new process is present then it will come otherwise this this get over P5 P4 get over then P3 will go there here new process come then P5 that is this part will get sheded so in the same way you have to keep on going this is a ly question I don't want to waste my time on this I hope I have given you the concept now the computition part you can do on your own let's see another question let's move to another question this is a smaller one so we'll complete this question this is a round robin question in this question the process first go to The Bu time and then I and then again comes okay so let's solve I think this is an interesting question so the first process arrived at time zero so we'll schedule process P1 for how much time for two time Quantum so from 0 to 2 P1 will be there and I have I have written the bu time in there okay so from 0 to two two units will be subtracted from three so one will remain now which will come at time two P2 also arrived in the RQ so P2 will be scheduled for how much time for 2 units so from five 2 units subtracted that this three will remain now at Time 4 which process will come P3 is present in the ricq but it came at time three and P1 came back to the Ric time two so P1 will come first so P1 will come here for how much time it will run for one unit of time so it will run for 1 unit of time it has completed its bus time the first phase of the bus time now it will go to IO at time then time from 5 to 5 from 5 to 5 that is time 10 so it will come back in the ricu at time 10 okay at time five which process are present in the ricu at time five these processes are present in the ricu P3 was over so P1 was over so P3 will be there for how much time P3 will run P3 will run for 2 units of time so P3 will run for 2 units of time now the first phase of first phase for the first time of P3 was over now it will go for I from 7 to 9 it will go to I and then P3 will come back to the to the Rue at which time at 9 so P3 will come back here now P2 will be scheduled for how much time see time Quantum was 2 unit and three was the remaining bus time so one will remain for the bus time of P2 so two unit will be there now P3 will come again P3 has completed this part and this part now P3 will come there again from 9 to 11 11 P3 will end so P3 ended at time 11 now which processes are present in the RQ now P2 will get scheduled P2 will get scheduled for how much time P2 will run for just one unit so from 11 to 12 P2 will run now which process will come P1 will come and at time 12 P2 completed this part so it will go for Io till 20 till 20 okay so it will come back to the radic at time 20 now P1 P1 is a how much time remaining 1 so P1 will execute for how much time no no no no now we have moved to this part so P1 will execute for two units of time so two unit will be remaining so P will execute for two unit of time but there is no other process in the Rue so it will execute for two more so execute for two more so from 12 to 16 it will execute now there's an important part which I want to emphasize upon you think operating system will preempt P1 at this moment yes it has preempted P1 in this moment because so P1 will continue its execution preemption will obviously happen there at time 14 at time 16 which process are present in the ricu see P1 got over P1 got over P3 got over now the only process which is left is P2 but what it is doing it is performing its IO till 20 so CP is nothing to do till 20 so will wait till 20 so at this time CPU will remain idle at time 20 it will come back to the CPU to execute the one unit of B time so it will come back to from 20 to 21 P2 will come back to the CPU and at time 21 this will preempt or this will terminate okay so these are the some questions for homework so these are the easy questions you can do on your own okay so I have also shared the solution with you see the question the next one this is also homework homework question and in the next lecture we will learn about the response time so in the last lecture we have seen about round robin algorithm we have solved some questions on it in this lecture we will learn about the performance of round robin see the homework question and learn the New Concept of response time in the first lecture of CPU scheding I have talked about it that the goal of CPU scheding is to minimize the turnaround time waiting time and response time we have talked about this but this was remaining so in this lecture we'll clarify what is response time so let's start with the performance of round robin performance of round robin depends upon the time Quantum its value if it is taken very small small large and very large what is the consequence of that so if we have taken very small time Quantum then the efficiently will be nearly zero most of the time will be taken by dispatcher to schedule the task as soon as the task starts running on the CPU it will again be preempted and then a new process has to come dispatcher has to work and as soon as the new process start to be executed then that process will also get preempted and a new process will come so efficiency the net efficiency will drop to zero dispatcher will take the most of the time and the useful time what is the formula of efficiency useful time upon total time so the total time will be contributed most by the dispatcher and the useful time will be very less so efficiency will drop to zero if the time Quantum is taken small then then there will be more contact switching and there will be more overhead what is overhead dispatch latency but the responsiveness will increase if the time Quant is reasonably small then responsiveness will definitely increase if the time Quantum is reasonably large then contact switching will less so overhead will be less but interactiveness will decrease if I took time Quantum very large then let's say the time Quantum is is greater than the maximum of BU time then the round robin will perform like fcfs because none of the process will get preempted in between because the time Quantum is greater than the maximum of burst time so it will be least interactive and it will behave just like the fcfs algorithm what was the selection criteria of round robin arrival time plus time time Quantum and if time Quantum if time Quantum is greater than the first time of any process then it will behave just like fcfs I hope you got the idea let's discuss the homework question which I have given you it is a very nice question if you haven't solved this till now I request you I sincerely request you to please pause the video and solve this question this will teach you so many things okay so let's begin it is it is not a difficult question it is an easy question just a conceptual one so what this what does this question say we will learn consider a system okay with n processes arriving at time zero so at Time Zero all the end process are present in the ricu with substantially large bust time so bust time let's say each process a bust time of 100 the CPU scheduling overhead is s so the Delta is s the time Quantum is QC and time Quantum is Q using round robin scheduling what must be the value of time Quantum Q such that each process is guaranteed to gets gets a turn at time at the CPU exactly after T seconds in it subsequent run on the CPU okay so how we will start this question see every CPU scheduling question it starts with the creation of Gant chart as soon as you create Gant chart you'll get an idea of how to solve it so let us start so here it is written every process there are n process and every process arrived at time zero so each process was present in the radue at time zero and it has a very large ver time so we need not think of B time why this line is given this line is given to prevent this case Okay so if bu times are substantially large then it will be mandatory for for the process to preempt in between of its execution bus time is larger than the time Quantum okay the CPU scheduling overhead is s second and time Quantum is Q using this we have to schedule in such a that each process is guaranteed to gets its turn at CPU exactly after T seconds in the subsequent run so what I have said in round robin when the process gets preempted it go back and join the end of the queue so when all these process will get it turn after that P1 turn will come so we are asking this is asking just that part that we have to schedule in such a way that each process is guaranteed to get its turn exactly after T seconds so this should be the T P1 got it turned exactly after the 3 second so this should be t Okay so let's draw the G chart schedule P1 0 to S we have seen that overhead was s so 0 to S will be the time taken by dispatcher s to S + q that is Q will be time taken by process P1 and then again P2 will get scheduled so s will be the time taken by the dispatcher so 2 s+ Q will be the time taken by the dispatcher and Q will be the time taken by P2 so 2 s + 2 Q will be the time taken by P2 in the same way if P1 completed at s+ Q P2 completed its first turn at 2 s + 2 Q so PN will complete this this process will complete its first turn at NS + NQ P1 at 1 s + 1 Q P2 at 2 s + 2 Q P3 at 3 S + 3 Q so PN at NS + NQ now this P1 will go and join the back of the que so now it is the turn for P1 to get scheduled s will be the time taken by the dispatcher now the turn off now after this much time P1 got it turn to run on CPU here it is written it subsequent run on CPU it subsequent run on CPU so after how much time P1 will start running so for for this case we will include this Delta 2 you must have made a mistake if you haven't read the question properly here it is written using Round Rob and scheding what must be the value of time Quantum Q such that each process is guaranteed to get its turn at the CPU exactly after TC in its subsequent run on CPU run on CPU is given so we will so from this part P1 have started running so we will include this Delta 2 so from this this this moment to this moment this will be the T so exactly after T second P1 got a chance to run on CPU so now what we will do we'll calculate this length so what is this length this is s+ q and this is n + 1 s + Q This was NS + NQ and there is a additional s so it will be n + 1 s+ Q so n + 1 s + Q minus s+ Q will give me this length so I have written this and then from this equation I have solved to get the value of Q easy peasy now there are some inferences which we can derive from this Q so if Q is equal to exactly equal to tus NS n minus1 tus NS nus1 then process P1 will get onto CPU exactly after T second if Q is less what is does it mean time Quantum is less then P2 will run less P3 will run less P4 will run less but the but the t is fix so what does this signify this signify that process will get onto CPU at least once within the time T if the time Quantum decreased then P2 will run less P3 will run less P4 will run less but this this length is fixed let me right this length is fixed this length is fixed if the process between these lengths between this length run for lesser time let's say P2 run for this time only and get preempted P3 run for this time only and get pred so P1 will get a chance earlier than the previous case are you following let me speak again this length is fixed the t is fixed if Q is lesser which means P2 run less than before P3 run less than before P4 run less less than before PN run less than before so P1 will get a chance earlier than the previous case Okay so process will get onto CPU at least once within the time T here the proc process got onto CPU exactly after the time T here the process will get onto CPU exactly once within the time T and when time Quantum become large and when time Quantum is become large it means P2 has run more P3 has run more P4 has run more so what can we infer we can infer process will get onto CPU after at least every time 10 seconds I have also explained them more so what does this say signify process will get onto CPU after at least every 10 second this says if the value of Q is large P1 will wait either TC or more than T that is selfexplanatory because if this become larger if this become larger then P1 has to wait either t or more than T if this become smaller if P2 run lesser than the usual then P1 has to wait either less than t or equal 2 D I hope you are understanding see let me speak again let me speak again if this is exactly equal then P1 get to run on CPU exactly after the TC this was the time T if the time Quantum is decreased in time Quantum is decreased then every process will run lesser than the usual P2 will run less P3 will run less so in this case in this case process will get onto at least once within the time T So P1 has to wait either time T second or lesser than time TC if P2 run less then P3 run less P4 run less so all the process will over earlier than the previous case so P1 will get a chance earlier that is the point I'm trying to make here P1 will get a chance earlier here P1 will get a chance later here P1 will get a chance exactly after T I hope now the point is clear okay so this I have mentioned so this was a fantastic question let us learn about A New Concept that is response time time of admitting the request to the time of generating its result there the one thing is missing that is first result and it is not end yes the right is correct so you may think response time as the turnaround time it is somewhat similar to turnaround time in turnaround time what we used to say completion time minus arrival time the time when the process was admitted in the ricq till the time the process ended that time was the turnaround time but here one thing got changed that is time of admitting the request to the Rue till the time of generating its first result so when the process will complete for the first time that time minus arrival time will be the response time let's take an example suppose there's a process P1 which arrived in the ricu OR got admitted at the time let's say 4 so at Time 4 it was let's say sheduled or let's say it has to wait for 6 unit so at time 10 it was scheduled and it is a bust time of total 20 so it has run for 5 minutes of time so from 10 to 15 it has run now the remaining ver time is 15 so the time when it was admitted in the process till the time it has generated its first result that is the response time I hope you have got the idea now so let me clarify again the difference between turnaround time and response time so the turnaround time was that was the total time taken to execute a process starting from the moment till it enter the system until it completes the execution and exits the system the formula of turnaround time was completion time minus arrival time I hope you remember that now what is response time response time is the time taken from a from response time is the time taken from when a request was submitted until the first response was produced so this time was the response time when the request was taken until the first response was produced okay so the formula of response time will be first response time minus arrival time I hope now you have the clear idea of what is a response time let's solve a question on this then we will end our lecture consider a system using round dring scheduling with 10 process all arriving at Time Zero each process is associated with 20 identical request each process request consumes 20 millisecond of CPU time after which it spends 10 m milliseconds time on iO thereafter initiate subsequent request assume scheduling CPU scheduling overhead of 2 millisecond and time Quantum of 20 calculate the response time of first request of the first process easy question I have told you definition try to solve on your own just give it a try okay let's see the solution so what was given in the question each process was present in the radue at time zero and there are 10 processes each process has identical request 20 identical requests each process each process I has a 20 identical request and each request takes 20 milliseconds of CPU and 10 milliseconds of IO and the time Quantum is 20 the scheding over overhead is two now the question is asked as response time of first request of the first process so what we do in such type of question nothing the approach one is create G chart and we will automatically know what we have to do so we'll do the scheduling so what P11 represent it represent the first request of the first process so P11 represent the first request of the first process so P1 will be scheduled two unit taken by dispatcher and 20 as the bus time and the time Quantum is also 20 so it's a good coincidence so from 2 to 22 P1 will run P11 will run and for 10 seconds or milliseconds whatever be the unit 10 milliseconds it will go for iio at time 32 it will go again at here so this will be the this will be the second request of the process one how many pro how many requests are there 20 requests are there how many process are there 10 process are there so I hope you got the point at this time P11 left the CPU for 10 units it was in the io and then at time 32 the second request of process one enters the ricu Okay so what is the response time of first request of the first process so the time when it was admitted till the time it has generated its first result that is from 22 to 0 that is the 22 millisecond will be the answer now the another question is calculate the response time of first request of the last process first request of the last process response time of first request of the last process what is the last process P1 is the last process so P10 is the last process when was P10 admitted the first request of P10 that is p101 when it was admitted they all were admitted at Time Zero when it got completed it got completed at time 220 so from 0 to 220 this will be the response time so 220 will be the answer question number three response time of subsequent request of any process in these type of question just take the process one so what will the response time of subsequent request which means the request number two so the response time of request number two that is p12 will be the time at which it was admitted till the time at which it was completed so it were admitted at time 32 we have seen here and when it will be completed it will be complet at time 242 so the response time will be result minus admission that is 242 32 which will give 210 as the answer so this was also a good question in lectures we have taken questions which is handpicked by me these are all questions which will give you a new a new thinking okay so now our response time topic is over round robin topic is over in the next lecture we'll start with the multilevel CU congratulations we are at the last lecture of CPU scheduling we will start with the multilevel queue and after this the CPU scheduling will be complete I have something to tell you that in CPU scheding section we have solved enough numericals so I don't think there is a separate problem solving session for each algorithm so even though I will give you a dppp with detailed answers so you can try them on your own and one thing I was planning I should make a revision video of whatever we have done till now let's revise them in let's say an half an hour we make a revision video okay so let's start with the multilevel Q scheduling all algorithm which we have read till now was based on the single ricq system isn't it fantastic whatever algorithm which we have read till now was based on single ricu system so every kind of process every type of process was fit in a single ricu whether it was OS process background process foreground process a user process every process was in a single ricu system and for every kind of process we can apply only a single scheduling technique could it be possible that for OS process we can apply first come first serve and for user process we can apply round robin algorithm no it was not possible until the multilevel ricu came so what were the drawbacks of single ricu system there are different type of process all mixed up and placed in a single ricu so the different process are os process user process user process include interactive process foreground process background process so when all these process are mixed up and placed in a single Rue the searching time and filtering time of these process will be high if I want to search a single process let's say a foreground process then in a single ricu where all these process are mixed up the searching time and filtering time will be high each process is bound to follow a single scheduling technique which I have discussed earlier so what is the solution for this multiple rues so what we will do we will create multiple ricu like system process interactive process interactive editing process badge process student process so these are the different ricu for different type of process this is the ricu for least priority process and this is the ricu for highest priority process so different radices for different type of process now what happens different scheduling algorithm can be applied to different Q let's say I decide to apply fcfs here and apply round robin here can it be done yes it is possible but in the case of single ricq it was not possible so Q's are now divided in the the based off priorities the higher priority process should be scheduled first and then only lower priority process can be scheduled do you know what I'm talking about it the higher priority process should be scheduled first and then only the lower priority process can be scheduled can youer what I'm about to say let's say there's a process P1 in the student process so this P1 can only be scheduled when this process when this Rue this Rue this radue and this ricq all are empty then only P1 will be scheduled let's say there's a process named PX this PX can only be scheduled when this and this rues are empty so to schedule this to schedule this these three should be these three higher priority CU should be empty because the higher priority Pro higher priority process should be scheduled first then only lower priority process can be scheduled so this is a problem man this student process will start so what could be done star of the process lying on the low level what could be done the solution is multilevel Q scheduling so what we will do see we will penalize the process that have been running longer we will penalize them we will put that process in the lower CU suppose the the process in the ricq one it is already ran for let's say some four units of time now what we will do we will shift that process from this queue to this queue we will decrease its priority so what we will do we will penalize the process penalize it in what terms in terms of priority so we'll decrease the priority of those process which have been running longer so what we will do let's say this was ricu Zero at the top top level this process was admitted dispatched it has run for time Quantum of three but it has not completed so we will transfer it to the RQ one that is of lower priority we will increase the time Quantum time Quantum is equals to 5 now it has gone to CPU again it was not completed so we will move to the ricq 2 which means we will decrease the priority we will penalize them for the those process which have been running longer now you may have a doubt so how can be three CPUs no it's not 3 CPU it's just a representation it is one okay so the process which have been running longer will keep on decreasing the priority when the process is transfer from readyq 0 to RQ 1 we will not schedule the process immediately we will wait until the first que becomes empty so I've already told you the student process will only be scheduled when these four process are EMP when these four ricu are empty there is no process in these ricu then only this ricu process will be scheduled so when the process is transferred we will not schedule that immediately we'll wait until the upper cubes become empty so let's solve a question on this consider a system which is a CPU bond process CPU bond process means which is no IO which require the burst time of 80 Seconds the multilevel feedback you why we say feedback feedback feedback that's why we say feedback the multi level feedback Q scheduling algorithm is used and the Q time Quantum is 4 second time Quantum is 4 second and in each level It Is incremented by 10 second I have said we'll increase the time Quantum so here the time Quantum is incremented by 10 seconds how many times the process will be interrupted or preempted how many times the process will be preempted on which Q the process will terminate its execution so it's it's an easy problem so time Quantum was 80 this is a longer process it started its execution from q1 so at q1 the first the time Quantum was four so it will execute for four units of time and the remaining bus time will be 76 it will be feeded back to the RQ 2 which is of lower priority it has a Time Quantum of 14 we have said that time Quantum will increment by 10 seconds so 4 to 14 now it will run for 14 minutes of time and then it will be preempted what is 76 14 that is 62 so 62 will be preempted to this now 10 unit will be increased more 62 24 what will be the answer 38 38 will be preed to this 38 34 will again increase 10 34 will be preempted to this this no not 34 38 34 is 4 so 4 will be preempted to this and 44 4 will be as only four the time Quantum is 44 and the remaining best time is only four so it will complete here okay so at which queue it got completed 1 2 3 4 and F on Fifth Q it was completed and how many times it was interrupted 1 2 3 4 it was not interrupted here it got completed so for four times it got interrupted and it completed at the fifth que so this was an easy concept of multilevel Q scheduling at this moment or CPU scheding lecture is completely over congratulations hello welcome to the new section process synchronization and coordination this is lecture one we we going to learn about how process communicates interprocess communication and processing synchronization what is synchronization and what is its need so let me give you in introduction about the section this section is different from CPU scheduling that was numerically oriented and this section is logical and is reasoning oriented you have to focus while learning okay it is not hard but you need to focus okay it is logical so let's start what is IPC IPC is interprocess communication so let's talk generally there are two entities person one and person two let let's put it here person one with a mobile and person two with a mobile and they wish to communicate in this world when two entities wish to communicate there should be a shared media in between there should be a shared media and that shared media should be accessible to both it could be Hardware or software Hardware include wire cables wireless and software include protocols so my main point is if two entities wish to communicate there should be a shared media and that shared media should be accessible to both that I want to explain in the same way if two process wish to communicate there should be a shared media too it could be a file so a file in memory is known as pipe okay so what is pipe pipe is equivalent of file in hard disk so this shared media is known as IPC mechanism interprocess communication mechanism it could be a simple Global variable so what you have to remember if two process wish to communicate there should be a shared media there should be a shared media okay and this communication can be intra process too suppose in a process if two entities wish to communicate what what can be these two entities these two entity can be function so if these two entities wish to communicate there should be a common thing too there should be a shared thing too so let's uh let me recall you some of the C Concepts how can two functions in a program communicate by parameter passing and Global variables here you can also see shared thing okay so whatever I I have spoken till now you have to remember just a single line if two entities wish to communicate there should be a shared media that's it okay now let's talk about processes so the process are of two type independent and coordinating as the name suggest as the name suggest independent means no communication between the processes and coordinating means they cooperate they communicate okay communication happens so these are the type of processes okay now let's move to the main part that is synchronization what is synchronization you have heard about it so many times what is synchronization let me explain you in layman terms synchronization is nothing but doing something that is agreed or performing that is already decided that is synchronization okay so what problems arises due to the lack of synchronization let's discuss them one by one so in IPC environment lack of synchronization lead to the following problem the first one is inconsistency how inconsistency is generated we commonly call it as race problem to process race to update a common variable and they produce an unexpected result or they produce an incorrect result or wrong result that is inconsistency okay data loss as the name suggest and the third is deadlock what is deadlock or lock up deadlock is waiting for something that is never going to happen deadlock is waiting for something that is never ever going to happen we also call it as infinite blocking of the processes suppose uh the traffic got accumulated from all the four sides now this part of traffic expecting these three of them to back off and this part is expecting these three of them to back off so in this biger ring they all get stuck at the same place and none of them is ready to move back so this part this this situation is known as dead Lock they got logged up for infinite time and Deadlock is the most undesirable situation because processes not only get blocked but they also hold up the resources so that's why that's why we need synchronization synchronization is very much essential okay so let me explain you synchronization with the help of some examples so what is synchronization agreement or understanding between the entities let's take the example number one sharing a lawn among neighbors so these are the two neighbors H1 and H2 H1 is the house owner of house one and H2 is the house own of house to they have pets H1 has cat and H2 has a dog now there should be an agreement regarding the timing of lawn uses otherwise you know the consequences this could release cat and this could release the dog and you know what will happen so there should be a agreement regarding the timing so let's say they decide that the morning session will be for the cat and evening will be for the dog so this agreement is known as synchronization and and these two follows the agreement then they are in the syn okay let's discuss another problem more milk problem I hope you know what is PG paying guest so let's say in a hostel there are three paying guests P1 P2 and P3 okay so they have an agreement what is agreement if any one of us notices that that there is no milk in the fridge he should go out and buy so this fellow came come to the fridge and he notices that there is no milk in the fridge he goes out when he was out another fellow comes he notices that there is no milk in the fridge he also goes out he also do the same thing so they all are out at the same time and they all of them bring milk for each other also so what will be the problem all of them notice one by one and goes out to buy milk so what will be the problem more milk problem so what is the solution solution will be past it note suppose he goes out he paste a note that I'm going out and when these two will come and see that there is no milk in the fridge but P1 has go P1 has gone out to buy some milk so they will stay and wait for him so this could lead to a solution so what I'm basically trying you to explain is what is synchronization let's understand it formally now so process synchronization refers to the coordination and control of the concurrent process why concurrent process because if the process are not concurrent suppose P1 is uh performing its action at 8 a.m. let's let's just take an example and P2 is performing its uh actions on let's say 12 p.m. so they are working on different times so they are not concurrent so what will be the need of synchronization synchronization is only needed when the process are working together control of the concurrent process in computer system so that they execute properly without interfering with each other it involves methods and mechanism to manage to access to manage access to the shared resources such as data device or in that example loan loan was the shared resource preventing conflicts ensuring orderly execution what is orderly execution so in the morning session cat will come and in evening section dog will come so that is the orderly execution so let's discuss again what is process synchronization agreed upon protocol in IPC environment V process work according to the agreed upon protocol that is synchronization to avoid inconsistency data loss and Deadlock Okay so P1 and P2 they are having some shared resources which is accessible to both and there exist an agreement protocol between them for synchronization let's let's take an example this is process one that is the track one and this is process two that is the track two now there exist a shared resource there exist a shared resource so there should be a protocol for the uses of this shared resource by both of the process otherwise the you know the consequences that could be catastrophic if both the trains come from here at the same time let's take another example suppose this is device one device two they both issues a command for printing the file at the same time so what will happen may result print of two different PDFs at the same page okay so these are the problem that could arise if the process lacks synchronization so what could be solution for this problem let's talk about generally what could be solution depending upon whether the printed is already printer is already begin used by another process or not the operating system must decide whether to Grant the printing request if the printer is free or to deny the request and classify the process as waiting process until the printers available becomes available so this gives the command this also gives the command so operating system will decide you wait I will first print the file of this computer and then I will come to you so this is a general solution okay I hope you all know now let's talk about the type of synchronization what are the two types of synchronization listen this synchronization thing only happens when the process communicates so in independent process there is no need of synchronization synchronization is only needed in coordinating process when communication happens so there are two type of synchronization competitive and and the second one is cooperative so as the name suggest what is competitive process compete for the accessibility of a shared resource process compete and what is cooperative execution of one process affects the another that is dependency so I hope you are craving for an example of both weit for Cooperative process there is a famous example that is producer consumer problem I hope you have heard it before if you have read operating system already this is a very famous problem and we are going to look for its solution in many different ways let's first talk about the competitive synchronization for the Amazon sale there's an single iPhone piece available that is that is available at at a great discount so all of three buy to wants to buy an iPhone for a single piece of iPhone listed on Amazon at the same time so these three are competiting these are these are in competition for this iPhone so this is an example of competition let's take another example in terms of process so this is P1 and this is P2 and this is a shared variable that is variable C so P1 wants to increment the value of C that's C = to C + 1 and P2 wants to decrement the value of C that is C minus minus so what will be the expected result so the expected result will be uh first P1 increments that is 5 + 1 6 and P2 decrements that is five so the expected result is five but there are some cases when we get the result either six or four this could also possible that we can get result either six or four so this is the example of competitive synchronization example four people trying to book a single seat in a train that is example of competitive synchronization okay let's understand the producer consumer problem so there is a producer which produce an item and there is a consumer which consumes an item what item a data item okay so what does producer do producer attempts to place the data item onto buffer and consumer attempts to consume the data item from buffer so what does producer do it it produces and what does Consumer do it consumes but there is a catch they attempts why attempts because the buffer is bounded so if the buffer is full then producer cannot place the item into to the buffer and if the buffer is empty consumer cannot consume that's why I used the word attempts okay so let's say producer produces X and then producer produces y now producer want to produce Zed what is what is this this is a variable which has a data type of integer and what does it what does it store it stores the value of next empty slot firstly when these two were there the next empty slot was two and when producer produces this data item Z then the next empty slot becomes three so this will update the value three these are the slots I hope you know so this is the producer consumer problem so what will the what will be the condition if the buffer is full producer cannot produce and if the B is empty consumer cannot consume so this is an example of cooperating processes P1 that is process producer process and consumer process they are cooperating because the actions of one affects the actions of the other that's why they are in the cooperation and this example which we have seen that three people are trying to buy a single piece of iPhone present in the Amazon sale or two process want to update the value of of a shared variable at the same time or four people trying to book a single seat in a train that is example of competitive synchronization and this is an example of Cooperative synchronization when actions of the world affect the actions of the other okay so if the synchronization is competitive then what does the lack of synchronization causes is it causes inconsistency and data loss in case of Cooperative it causes data lock so can data lock arise in in this producer and consumer problem we will see later okay and there there is another note what does it say an application in IPC environment may involve either cooperation competition or both so later we will see that producer consumer problem is an example of both competitive and and Co Cooperative how competitive we'll see it later when we'll see the code the C code okay so what we have learned in this whole lecture we have learned that for communication there need a shared resource and that shared resource should be accessible to the both entities okay and process are of two type independent and coordinating independent process do not communicate hence they do not require synchronization coordinating process communicates hence they require synchronization and what does the lack of synchronization causes inconsistency that is wrong results data loss and Deadlock we learned a new term that is deadlock what is deadlock waiting for an event that is never going to happen we have seen some examples that is sharing a laan m Mill problem and we have also learned a formal definition of process synchronization okay and then in the end we learn learned what is competitive and Cooperative synchronization we have seen some examples and we also learned that application in an IPC can involve either cooperation or competition or both let's start lecture two in this lecture we will see a famous condition known as race condition in the last lecture we have studed about synchronization what is the need of synchronization how process communicate we learned about IPC its mechanism shared media and stuff in this lecture we'll start with the race condition so there are two process P1 and P2 and they are in a race they are in a competition to update the value of a shared variable let's say C P1 wants to increment it and P2 wants to decrement it so what will be the high level code it could be Cal to C + 1 and the low level and the high level code for decrement will be Cal to cus1 and what will be the low LEL code corresponding to them the low level will be this so this will the low level will be generated by compiler that is the assembly code so the three instructions are there and they will be executed sequentially so what we will do we'll first load the value of C into register R1 we'll increment the value of register R1 and we will store the value of R1 back to C so this is how it will be executed at low level similarly for decrement the value of C that is the memory will be loaded into register R2 it will be decremented and the decremented value will be stored back to the memory so C is a memory okay this part till this part whatever computation is being done it is being done in the register at part I3 it changes the value at memory remember this till this part whatever being done whatever competition is being done is done at register level the final value of register is not stored until instruction three at instruction 3 the value of C is changed okay so now how we can get the result 6 or four when the expected result is five this is inconsistency so how inconsistency happen let's see suppose consider this scenario in RQ there are two process available P1 and P2 at time t CPU scheder decide let's schedule P1 first so P1 will be scheduled now before going ahead I want to share a universal assumption that in user process they can get preempted after any instruction this user process can be preempted even before executing instruction one it could be preempted after execut instruction one before I2 it could be preempted here it could be preempted here any anywhere it could be preempted anywhere here so user process can be preempted anytime anywhere after any instruction you have to take into account this assumption so P1 ver first scheduled what happens P1 executes instruction i1 and I2 what will P1 do P1 loads the value of register of memory P1 loads the value from memory into register that is value five and it will increment it so the value of R1 is 5 instruction I2 okay let's go back so what it will do it will first load the value of C into R1 and it's incremented so what will the value of R1 now the value of R1 is six okay this part is represented like this i1 and I2 that is the R1 is now have value six at this point it got preempted it it got preempted at this point I have said user process can be preempted at any time so user process gets preempted here so P1 gets preempted here so P represents preempted now it's time for P2 because CPU can't be added so P2 will be brought from ricq to the CPU and P1 which was which was previously in the CPU will be sent back to the ricq because it has its instruction remaining to be executed so at time T1 let's say at another time P2 will start executing its instructions so P2 will execute i1 I2 and I3 so it has executed all of three so let's go back so what it will do it will first load the value of C into R2 it has decremented the value and it has again loaded the value of C of R2 into C that is it has made the final changes it has made the final changes because it has also executed its instruction three it has first loaded the value it has first loaded the value into R2 the value of C was five so five has loaded it has decremented the value now the value of al2 is four and and it has loaded the value of R2 back into the C so it has stored the value of R2 into C see the instruction I3 okay so the third instruction is the instruction in which final changes has been made this was remaining okay now P2 has completed all its instructions so it will leave the CPU it's turned for P1 to come back so now P1 will come back and I have I have told you several times that when a process comes back from ricu to the CPU it will resume it will not restart so it will resume from instruction I3 where it got preempted so what is instruction I3 making the final changes again what is instruction I3 is storing the value of R1 what is the value of R1 the value of R1 was six so it will store the value of R1 that is 6 back into C now what is the final value the final value is six and what was the expected value the expected value should be five because P1 increments and P2 decrements so the result should be unchanged so it should be five but what we got we got six this is inconsistency this is race condition P1 and P2 are not in synchronization so this type of problem are caused now we have got value six but can we got value four yes the thing is opposite there are two ways to get four so the first is do the same same thing in opposite fashion start with the P2 first preempt here complete the instruction of P1 and when P2 comes back make the final changes again store the value of R2 into the C that was four okay another way is another way is at time T1 so this was the time at time T P1 executed instruction i1 and I2 and it got preempted so the first case this this and that preempted now what is the what is the scenario R1 has the value of six the value of C is still five because no final changes has been made because it got preempted before final changes now what happens at time T1 P2 also gets preempted here P2 executes these two instruction and get preempted now in Ru there are two process now in readyq there are two process P1 and P2 ready to make the final changes now it depends now it depends if P1 make the changes first let's say P1 make the changes first and then P2 make the changes that is four so the final fin changes the final answer will be four case two P2 make the changes first the value of C will be four and now P1 comes so it will change back to six so the value of C can be either six or can be either four depending which process updates or make the final changes first so what was expected the expected value was what was expected the expected value was five but what we got we got either six or four depending which process updates first so this is raise condition I so this is an important point I should I felt that I should write it in the notes whenever a process comes back to the CPU it will resume not restart so this above scenario is a clear demonstration of inconsistency the process to update last will win then what is the solution is it ever possible to get a correct value is it possible if yes then in which scenario the answer is when there is no preemption when there is no preemption what P1 does P1 executes all these three instruction and then when it gets completed it leaves the CPU and then P2 comes it executes all these three instructions so what happens let's see P1 executes all these three instructions so what happens this is the value of R1 this is the value of C that is five first load the value of C into R1 so value of C will be loaded into R1 c will be loaded into R1 that is 5 now what happens increment R1 let's increment R1 let's make it six now store the value of R1 back into the C store the value of R1 back into the C now the value will be six now the value of C will be six okay P1 has executed all its instruction now it's chance for P2 to execute P2 will come load the value of R2 into C sorry load the value of C into R2 the one which is written later that value will be loaded into the thing which is written before see if we have to store we will write R2 later if we have to load we will write R2 first okay so value of C will be loaded into R2 so what is the value of C 6 6 will be loaded into R2 what are decrement R2 so five will be the value store the value of R2 back into C so now the value will be five finally the value is five so this is the expected value this is the correct result when we got correct result when there is no preemption when we executed either P1 first and then P2 or either P2 first and then P1 in both cases we will get correct result but if any of the process get preempted in between then it causes inconsistency so here I have written so when there is no preemption then we will get correct result but as an end user see as an end user we want a solution that always give me correct result why I should bother let's say let's say there is a there's a children 5yearold children wants to play a game in a in a smartphone but it has got some problem problem because of risk condition why should the end user a 5yearold give about whether a process gets preempted or not he wants a correct solution every time he wants a correct result every time whether preemption takes place or not I do not I do not bother whether preemption happens or not as an end user I want correct solution let's start with the implementation of producer consumer problem there are two processes a producer process and a consumer process producer process produces an item and place the item into through the bounded buffer why bounded bounded means a fixed size so the size will be n and the index will be from 0 to n minus one I hope this is clear so process P that is the producer process is going to produce an item and place it onto the bounded buffer and what will consumer do it is going to consume an item from the bounded buffer producer produces consumer consumes as simple now now there are two pointers pointer in and pointer out pointer in refers to the pointer of next empty slot what is the next empty slot here two and out refers to the first filled slot what is the first filled slot you can see Zero that is X now producer produces and place it onto the buffer in I hope I'm making sense because this is the next empty slot producer will see the next empty slot and will place an item onto the bounded buffer what from where the consumer consumes it consumes the from buffer out what is out the first filled slot now let's move to the code part we are defining a global variable n what is n the size of the bounded buffer let's say it is 100 now we are also defining a variable named count it is also a global variable count what does count refer to it refers to the number of data items in the buffer if a producer produce and place the data item in the buffer the count will increase and if a consumer will consume then the count will decrease we are also defining a bounded buffer of size n so it's an array of integer type buffer n now we are going to write the producer and the consumer code so what are the major changes that we are going to make when a producer produce and when a consumer consumes let's discuss them so we are first going to check a producer produce only when the bounded buffer is not full and a consumer consume only when the bounded buffer is not empty okay so what will producer do first it will produce and place the item in a variable named item P let's say the produced item item P let me write item P so the producer produced and placed the item in this variable item P now we have to place the item p in the buffer where we will place we will place at buffer in so we'll play place it as buffer in okay but these all will only happen when the bounded buffer is speak after me bounded buffer is not full so if the bounded buffer is full what we have to do we have to make the producer busy weight until the consumer consumes and make a space for the item to be placed into the bounded buffer okay so when the item will be placed in the buffer in then we have to increase the value of count two so we will do count Plus+ also so let's see in the code so what we will do we will produce and place the item into the variable named item P so what will produce item do let's say the produce item is a function in a library already present produced item is placed in the variable item P okay now we will check we will check whether the bounded buffer is full or not so we will use while count equals to equals to n we will check whether count count equals to equals to n whether count is equals to n or I can directly say if the bounded buff is full then the producer cannot produce and place the atom it it may produce the producer May produce but it cannot place so it may produce but it cannot place so it has to first check whether the bounded buffer is full or not if full then it will wait until preemption happens and consumer takes the control and it consumes an item and makees space for the producer to place the item so producer May produce but it cannot place before checking so we'll first check we'll first check so the busy waiting thing will happen what is busy waiting busy waiting is testing the condition again and again and what is waiting for what it is waiting for to proceed further okay so let me speak again producer will produce and place the item into the variable item P now it is in the variable item P it is not in the buffer so before place before placing into the buffer we have to first check so we checked and it is not full it has some space available it will go down buffer in equals to item P we will place the item P what is item P item p is containing the produced item so we will place the item P into the in what is in the next empty slot so we plac item P into the buffer in now we have to increase the value of n because now the next empty slot will be the next one let's let's take this case what is the next empty slot two if the producer Place item let's say Z Now the next empty slot will be three so we have to increase the value of in also what does this circular thing say let's say the last here it is produced so it will go back and produce that and place the item at index 0o if the last item was at n minus one it will go back and place the item at zero I hope this point is clear this thing is for the circular and count Plus+ because item is placed into the buffer so the number of item will be increased so this was the code for producer item so for the producer now I am giving you a challenge to write the code for the consumer what changes you have to think about it so for Consumer the consumer consumes when the consumer can consume it can consume only when it can consume only when there exists some item into the buffer when the buffer is nonempty okay let's say the buffer is non empty what changes you have to make you have to make you have to decrease the value of count because the consumer has consumed an item you have to increase the value of out because what does out signify first filled slot let's say consumer had consumed this now the first filled slot is this one that is one so we have to increase the value of out two same same case for the last thing suppose consumer consume from this part now from where the next time consumer will consume from this so it has to go back so for circular thing will be out equals to out + 1 modul n okay so let's see the consumer code vo consumer void now item C item c will be the item C represents the consumed item the item which is going to be consumed so before anything before making changes before any change making we have to check whether the whether the bounded buffer is empty or not if the bounded buffer is empty busy wait until the producer produce and place an item into the buffer then item c will be representing the item that is going to be consumed so which item is going to be consumed buffer out now we have to increase the value of out decrease the value of count and consume the item in the end see see there is a thing in consumer the condition was at the top while in producer the condition was at the second statement at B why why this is so because a producer can produce but it cannot place so this represent a producer can produce but it cannot place before placing it has to check the condition no statement can be made before checking if the bounded buffer is empty none of these changes will be made I hope I am clear so this was the all the implementation of producer and consumer in C language in the last lecture we discussed about the producer and consumer problem implementation so we are going to see some more points on that so the producer and consumer problem are involved in Cooperative synchronization why because they are getting affected by each other now this this point you all know but there is some special point that this case of producer and consumer problem is involved in both competitive and Cooperative synchronization how competitive uh let me tell you see if you carefully watch the uh if you carefully observe the code then you can see there is a shared variable count there's a shared variable count so let's say this is the producer code this is the consumer code the producer executes these four instruction and get preempted here and the consumer execute these three instruction get preempted here just before updating the value of count because they are user process and user process can be preempted anywhere at any time so they got preed here there this part and this part they get preed just before updating the value of now this is the situation producer and consumer process are in the ricq waiting to update the value of count okay so this situation this situation if you recall is exactly similar to our previous problem that causes inconsistency what was the previous problem the race condition so these producer and consumer are in a race to update the value of Shield variable count okay so let let me recall you there are two process producer and consumer producer want to increase the value of count consumer want to decrease the value of count let's say the initial value of count is five now the expected expected results are six and uh expected result is five but what we can get we can get six and four depending on which process updates the value of count at last the one which update first loses and the one which updated to the last that value of count will be the final value of count so this I have already discussed before in our previous lecture what point I'm here to make that producer and consumer is a case in which a process or the processes are involved in a cooperative and competitive synchronization both okay I hope the point is clear so to solve this problem we are going to need a synchronization tool a synchronization tool so that synchronization tool we are going to see in the next lecture in the previous lecture we saw that we need a synchronization tool to avoid some problems in this lecture we are going to explore more suppose uh let's talk about a disease named malaria I hope you have heard about it so what is the necessary condition for malaria to spread in a Lo in a locality so the necessary condition is stagnant water if a stagnant water is not present so mosquito larva won't breed there and mosquitoes won't be there so the main culprit that is the mosquito would not be present in that locality so chances of malaria spreading is very less so stagnant water mosquitoes the main culprit should be there and unhygienic environment so these are the necessary condition for malaria to spread in a locality let's talk about the synchronization problem so this was a problem these are the necessary condition this is the problem let's talk about the synchronization problems necessary condition condition so the first condition is critical section there should be a shared resource if there is no shared resource there won't be any synchronization problem we have discussed it earlier also okay so what is critical section the part of a program where shared resources are accessed the part of a program where shared resources are accessed okay so let's say this is a program it consists of two things noncritical section and critical section noncritical section consist of local variables which belong to that process only and critical section consist of those variables which belongs to both the processes let's say two process are there want to communicate so critical section is the section which has shared variable let's talk here uh in the case of producer consumer problem let's say item P equals to produce item this is a noncritical section because item P or produce item this belongs only to the producer process while this count this n this buffer this count again this and this belongs to both the processes producer and consumer they can be they are accessible to both the process so this is the critical section see remember the first class of Process Management I have said that not Process Management process synchronization I have said that for communication to happen between two entities there should be a shared media and that shared media should be accessible to both that's the same thing okay so that shared media is known as critical section so for synchronization problem there must present a critical section and the second condition is raise condition say if the processes are not in rise to update a update a shared variable let's say count if producer and consumer are not in Risk to update the value of count then there will be no problem for synchronization problem to occur what are the necessary condition the first is that there should be some shared variable there should be critical section and the second is for that shared variable processes should be in race to update the value okay so the race condition is necessary situation where the process are trying to access critical section and final result depends on the order they finish their update now here like malaria for the case of malaria stagnant water and unhygienic environment is similar as critical section and race condition but the main culprate is still missing can you guess the name of main culprit think yes the the main culprit is preemption which type of preemption premature preemption let let's let's see the situation so here are the critical section P1 enters the critical section P1 was still executing the instructions of the critical section but it got preempted prematurely now P2 wants to enter critical section P2 will enter and that causes problem so the premature preemption when a process has not completed the all this all its instructions in the critical section but it got preempted prematurely and some another process enters critical section that causes problem so what is the main culprit here preemption and which type of preemption premature preemption okay so we need some solution uh to solve all these problems so the solution is we need some synchronization mechanism or let's say security guard so can you guess the purpose of the security guard see the problem arise when two or more process enters critical section when two or more process are in the critical section see critical section and CPU are different things let's say here is the CPU these process are present in the ricu okay now P1 is in the CPU now P1 is in the CPU P1 started executing its instruction the critical section let's in between it got preempted P1 is still in the critical section this is the uh denot we denote it like that that P1 has not completed all its instruction from the critical section P1 got removed from the CPU it went back to the RQ now P2 enters P2 enters okay so P2 is in the CPU started executing instructions want to enter the critical section but P1 has its unfinished work in the critical section so it's still lying there not executing any instructions further because it is not present in the CPU P2 is there so it's still lying there now the problem arise when P2 enters critical section 2 so this is the problem so we need to solve this problem using a security guard so can you guess the purpose of security guard yes you guessed correctly security guard will allow only one process enter at a time in the critical section let's say P1 get preempted in between let's say p P2 has P2 is in the CPU now security guard will prevent P2 entering the critical section P2 cannot enter critical section security guard will prevent it okay let's say P2 got preed again and P1 get the chance P1 is present in the CPU now P1 resumed its instruction completed critical section get over got terminated now when P2 comes it is allowed to enter critic iCal section okay so this is the purpose of security guard not only this not only this security guard also notifies other processes when a process or the previously running process in the critical section has completed its instructions let's say P1 has completed its instruction so the security guard will notify other processes hey critical section is empty now you can go any one of you can go okay so there are two purposes of security first is and we have divided security guard in two entry section and exit section entry section will allow out of these three process only one to enter critical section and exit section what's the purpose of exit section it will notifies other process that the previously running process in the critical section has completed its instruction now any one of you can go now in the critical section I hope I'm clear uh let's see again here so P1 p P3 want to enter critical section so there comes the enter section first which allows only one process to access critical section let's say P1 entered P1 completed its instruction went to the exit section this exit section notifies other process P2 and P3 that critical section is empty now okay so when process exits the critical section it notifies the other processes so how this synchronization mechanism looks like first comes the noncritical section or the section which does not have any shared resource for critical section that is this is critical so we need some security guard up and Below enter section and exit section then again comes the noncritical section so this is the this is the synchronization mechanism okay note what is the note process running in user mode can get preempted anywhere any number of times after completing any instruction so this is a kind of assumption we will take to solve synchronization problem what is the Assumption process running in user mode can get preempted anywhere after any instructions any number of times okay you have to remember this in the next lecture we will see the requirements of critical section problem here we have seen the necessary condition so what is the difference between necessary condition and requirements so necessary conditions are the conditions which are necessary for problem to happen like mosquitoes are necessary for malaria to spread and what are the requirement these are the requirement to be fulfilled to make sure the solution is correct okay so we will discuss them in the next lecture let's discuss the requirements of critical section problem these are the conditions that must be satisfied by synchronization mechanism to make sure the solution is correct and what was necessary condition these are the condition necessary to happen necessary for problem to happen Okay so let's discuss the requirements the first is Mutual exclusion what does this say that there should be only a single process in the critical section at a time no two process should be present in the critical section at the same time remember this line in any synchronization mechanism we discuss the first thing which we are going to check is this line is there any possibility that two process enter critical section at the same time if yes then the mutual exclusion is not guaranteed so what is mutual exclusion no to process should be present in critical section at the same time as this diagram depicts so a process is already present in the critical section uh another process enter this is wrong more processor enter this is wrong in this critical section only single process there and these all processes are out so this is good thing okay so only one rest are out so mutual exclusion is guaranteed so repeat after me what is mutual exclusion no go to process should be in the critical section at the same time okay let's discuss the second condition that is progress okay so what does progress mean that a process let's say P1 P2 and P3 these are the process P1 is not interested to enter critical section so it should not block the interested processes like P2 and P3 let me speak again noninterested process process or uninterested process should not block the entry of interested process this is the progress okay so P1 and P2 these two want to enter P3 is not interested so P3 has no right to block the progress of others uninterested process should not block the entry of interested process this is progress okay now the third part bounded waiting listen carefully P1 P2 P3 these are the three process wants to enter critical section P1 first uh goes to entry section allowed because no other process is present in the critical section vents to critical section comes out now it goes again it goes again joins the queue goes again enter enter the entry section goes to critical section again goes to exit section now this fellow joins again see P1 is laughing at the face of P2 and P3 that you fellows are waiting from so much time and whenever I come back I directly go to the critical section so you keep on waiting I will keep on going into the critical section P1 will laugh at the face of P2 and P3 so this is not correct P2 and P3 do not know for how much time they have to wait okay so this should not happen this should not happen this is not fair so this is the thing which I have represented P1 enters goes to critical section exits joins the que again enters again goes to critical section exits goes again enter this keep on happening and P2 and P3 are waiting so this these these two process P2 and P3 should not wait forever for their turn Okay so this is bounded waiting okay so let me erase all these things huh so I have written in form of statements no process has to wait to access critical section there should be a bound on number of times a process is allowed to enter critical section before other process request is granted let me uh revise all the requirements again the first was Mutual exclusion what does it say no two process should be allowed in the critical section at the same time What does progress say an uninterested process has no right to block the progress of other interested process and what does bounding waiting bounded waiting say no process has no process can enter critical section again in again while the other interested process are waiting forever okay so the weight should be bounded it should not be unbounded that they are starving for infinite time okay so these are the requirements if P2 and P3 are not interested then P1 should not be blocked otherwise progress will be violated if Mutual exclusion is not guaranteed then what problems that arise are inconsistency and loss of data if Mutual exclusion is not guaranteed two or more process can enter critical section and they will be in RIS condition then to update a value of count as we saw that let's say producer want to update the value of count by + one and consumer want to decrease the value of count by minus one and the initial value of Count by Five so the expected result was five but we got four or six so this uncon inconsistency happens due due to the reason that producer and consumer entered critical section at the same time so when Mutual exclusion is not guaranted inconsistency and loss of data happens what is inconsistency wrong results and this is selfexplanatory loss of data if bounded waiting is not guaranted then starvation P2 and P3 are starving here okay and if progress is not guaranted then then it is unfair solution indefinite postponement let's say P3 is not interested and it has also blocked the entry of P1 and P2 so this is unfair so we have completed the requirements in the next in the next lecture we are going to see some synchronization mechanisms or simply Solutions of these problems now comes the synchronization mechanisms I'm going to take the name of all synchronization mechanisms that we are going to study later so I should not say synchronization mechanisms are the solution these are just the tries we try to solve the problem okay so let me give an example uh busy waiting and non busy waiting and these are subcategorized into software hardware and OS based that you can all read lock variables and strict alternation are not solution so which synchronization mechanism I should categorize them as solution the one which guarantees Mutual exclusion the one which guarantees progress and bounded waiting if these three are satisfied by a Sol by a mechanism then I can categorize that mechanism as solution out of all these I cannot say all of them are solution let me give you an example see take these two log variable guarantees progress but it fails to guarantee Mutual exclusion and bounded waiting these two are not guaranted strict alternation is opposite it hinders progress but it guarantees Mutual exclusion and bounded waiting which loog variable was unable to give and loog variable was giving something which was not possible for strict alternation to give so why don't we merge the good qualities of both of them let me let me explain loog variable gives Mutual exclusion uh sorry log variables gives progress fails to give Mutual exclusion and bounded waiting strict alternation provides Mutual exclusion hinders progress and provides bounded waiting so why don't we mer mer the good qualities of them and create a perfect solution that is Peterson or ders algorithm so we cannot categorize lock variable and strict alternation as solution sometimes we say them as solution but they are not in literal terms what is solution solution is the one that satisfy all the requirement Mutual exclusion bounded waiting and progress lock variables and District alternation are not Solutions Peterson and deer algorithm solution okay but sometime sometimes we say lock variable as software solution we just say we doesn't mean that as actual solution okay so let me read so synchronization mechanisms are of two types bounded waiting and nons sorry busy waiting and non busy waiting busy waiting is also known as spin lock and non busy waiting is also known as blocking and these are subcategorized into software hardware and OS based software are user mode Hardware as special instructions and OS based or kernel mode so four these are the four type of software solution two types of Hardware solution TSL instruction and swap instruction and OS based are sleep and wake up semaphor and monitors I hope you have somewhere heard the name of semap for before okay so don't worry we are going to study them in detail in every case possible in each of the synchronization mechanisms we are going to solve lots of problem in these uh synchronization mechanisms and these problems will be logical okay so let's see some assumptions process enter critical section for finite amount of time this is the first assumption because if say the process enters critical section for infinite amount of time and we have also guaranteed its Mutual exclusion it will make other process starve because Mutual exclusion won't allow any other process to enter critical section and this process is not leaving the crital section so other process will Dive Dive because of die because of starvation so we have to assume that process enter critical section for a finite amount of time and come out of it it never gets stuck in the critical section this is the first assumption process can never get stuck in a critical section second thing is if a process is in entry section then it means it is interested in the critical section uh in the previous lecture I have discussed about process sorry progress what was progress an uninterested process should not block the entry of interested process now I should clarify what is interested process interested process the process who wants to enter critical section and if a process wants to enter critical section then only they will enter entry section otherwise they will never enter into entry section let me speak again if a process is interested in critical section or wants to go in critical section then only it will tries to to enter entry section otherwise it will not okay so this is the second assumptions we are taking the third is a process is said to have left the critical section only when it has executed its exit section and the fourth is a process can get preempted from CPU while executing either entry section or critical section or exit section a user process can get preempted anywhere after any instruction any number of time okay so let me read the assumptions again a process will never stuck in the critical section A process will enter into entry section only when it is inst interested in the critical section and the third is a process is said to have left critical section only when it has executed its exit section and the fourth is a process can get preempted from anywhere after any instruction any number of times let's discuss our first synchronization mechanism that is lock variable can you suggest something from the name lock variable a variable named lock which is used to represent whether critical section is free or in use it is a busy waiting solution I hope you all know what is busy waiting and it is a software solution do you remember the the types we discussed in the last lecture software solution Hardware solution operating system system and software solution are implementable at user mode Hardware Solutions are are special instructions and operating systems are based on kernel mode okay so it is a software solution so it is a way to say a solution it is not an actual solution okay I have discussed that thing in the last lecture we just say it as a solution but is not an actual solution it does not satisfy all the requirements to be a solution can you remember the requirements yes the requirements are it should guarantee Mutual exclusion it should guarantee progress and bounded waiting okay so let's see how does it work so in entry section we Define a variable named lock variable which can take two value either zero or one what does Z represent Z represent that critical section is free no process is in the critical section at the moment and what does one represent critical section is in use a process is already present in the critical section okay so let's say it is the beginning okay a process enters into entry section see that lock is zero that means critical section is free goes into critical section and changes the value of log to one it's it's similar as if uh there's a there's a room someone enters the room and lock it it from inside and when it is logged from inside if some other process see a room is logged from inside then it understands that someone is already present in the room so lock 0 or 1 0o means critical section is free and one means critical section is in use and what does exit exit section do when a man comes out of a room then what does it do it unlocks the room and goes out see it is similar like a like a bathroom situation or toilet situation whatever you call if a man enters into a toilet what does he do he locks it from inside suppose another man comes and see a toilet is locked from inside understand that someone is already present he will wait until the man unlocks and comes out okay same is the case Zero means critical section is free one means critical section is in use and when a process EX exits what does it do it changes the log to zero which says critical section is now free okay so this is the main idea of lock now let's see the implementation the entry section okay so we Define lock and we sets set it value initially to zero what does Z represent initially the critical section is free no one is in the toilet okay or any room let's say toilet if you feel it gross so let's take an example of a room so let's say in a room initially the room is open anyone can enter hence the lock is equals to zero void process in I so this is a process code now here it comes noncritical section and then the entry section while loog equals toal to 1 then busy weight what does this represent this represent busy weight it says if loog equals to 1 whether log is equals to 1 what does one say critical section is in use so it says if critical section is is in use check this condition again and again again and again and it busy weits busy in what checking the condition whether critical section is free or in use and waiting to proceed further okay so if critical section is in use it will busy weit and let's say critical section is not in use this is the initial case so loog is equals to0 while loog equals to equals to 1 no this is false it will go down lock equals to 1 it will change the value of lock equals to 1 and it will enters the critical section and when it has performed all the instructions of critical section the process intends to go out so before going out what does it do changes the value of lock equals to Zer it unlocks the room okay so I hope you got the idea just think think it it as a toilet or some room uh for um for couples to to go in okay so let's say process represent a couple I hope uh now you can get the idea let's say a process represent a couple a couple enters the room an open room uh and then locks the room from inside do whatever they want to do in the critical section and when they want to come out they will unlock the room for another couples I hope now you got the idea so what is the two things the couples do before entering into the room the first thing is the first thing is it will check it will check if someone is already present in the room if yes then they will wait busy wait if no they will enter lock the room perform whatever they want to perform and then they comes out by unlocking the room I hope you got the idea see this entry section is in the written in the high level code when it will be in the when it will pass to compiler it will be changed to low level code that is assembly good so what does it look like load the value of lock into some resistor RI compare the value of RI with zero jump if not zero to statement B again so this is busit and store the value of lock store the value of one constant one into lock do to get this is the same thing written here did you get it see lock the uh load the value of lock into RI let's say this is register RI and the value of lock was initial zero so this value will be loaded here compare RI with zero is the value of RI equals to Z yes it is equals to Z so what will it will do it will go to the next statement jump if not zero but it is zero so it will ignore this statement will go down store the value of constant 1 into the lock variable so now in lock in lock variable one will be stored now I hope you got the idea in the last that is exit section store the value of 0er into the loog what does this mean lock the room from inside what does this mean check if critical section is free and what does this mean unlock the room when you comes out in the last lecture we have seen the high level implementation and lowlevel implementation of lock variable let's understand from this diagram also there are two process P1 and P2 available in the ricq let's say P1 enters in the CPU P1 got scheduled on the CPU P1 shows interest to enter into critical section so what it has to do it has to enter into entry section first and what is entry section check if the value of log equals to 1 if not then change the value of lock equals to 1 so P1 enters P1 P1 want to enter critical section so it will check if the value of lock equals to one no the value of lock was zero so it will change the value of lock equals to 1 now P2 P1 is started executing there some instructions of the critical ction and suddenly premature preemption happens let's say P2 is a high priority process P2 comes here P2 comes in the CPU what it will do it has also interest to go into the critical section so it will go to the entry section first while value of lock equals to 1 yes the value of lock equals to 1 check the condition again does the value of lock equals to 1 yes check the condition again is log equals to one yes check the condition again so it will keep on checking the condition again and again it will busy wait until the time slice expires now the P2 got preempted from the CPU P1 got the chance again P1 was shed on the CPU P1 resumed P1 resumed completed its critical section when it got when it want to get out from the critical section it has to execute exit section and what does exit section say change the value of lock to zero now the value of loog is zero now P2 got chance P1 has P1 has been terminated now P2 got chance on the CPU again P2 will resume so P2 will check is the value of log equals to 1 so the value of loog loog is not equals to one the value of loog is zero so it will escape the busy V now it will change the value of loog equals to one so value of loog will be changed again to one goes into gral section complete the critical section and when it come comes out it will unlock the critical section so I hope you got the idea how does loog variable work so let me read it again when P1 was in the critical section lock variable will not allow P2 enter critical section so P2 will be busy waiting until P1 comes back exits critical section by updating the lock variable so I hope you understand how does log variable works so now I a question for you does this law guarantees Mutual exclusion every time is there any possibility that Mutual exclusion get violated is there any possibility that P1 and P2 gets into critical section at the same time think about it see the code and think about it is there any possibility that P1 and P2 enters the critical section at the same time what I'm about to say is a Golden Rule for solving questions like that whenever you see whenever you see an entry section of two statements preempt in between let me speak again whenever you see entry section of two statements preempt in between if you preempt in between of these two statements then you will get some uh good results to infer okay so we are going to do the same let's preempt in between so we have to preempt the process in such a manner that two process are in the critical section at the same time that is mutual exclusion is violated we try in such a way so how we can do that we will preempt between the two statements of Entry section so the first statement consist of these three instructions and the second consist of this one instruction so we try to preempt after this instruction let's go so here let me draw the value of lock R1 and R2 okay now store the value or load the value of lock into R1 so what is the initial value of log initially is zero initially is zero so we'll load that value into R1 now compare the value of R1 with 0o is it zero yes it is zero so it will go to the statement three jump if not zero but it is zero so it will not go anywhere it tries to go to statement 4 but what we have to do we have to preempt before it can execute the statement 4 so it got preempted before the process can change the value of lock now process two is in the CPU process two starts load the value of lock into R2 what is the value of lock it is zero load it into the R2 okay compare the value of R2 is the value of R2 equals to Z yes it is z jump if not zero to statement B but it is zero so it will not jump anywhere now it tries to go to store lock equals to 1 so you can see preempting P2 here will give us no benefit because let me explain more so now P2 has executed fourth statement also so you have to preempt just one process either P1 or P2 so we have preempted P1 so no need to preempt P2 P2 executed fourth instruction also that is store the value of one into the log so change the value 0 to 1 okay now what does loog equals to 1 represent loog equals to 1 represent that critical section is not free so P2 gets into critical section start executing critical section but what what happens premature preemption so we are preempting P2 here premature preemption happens P2 is in the critical section but it got preempted from the CPU now what will happen P1 will start its execution P1 will resume what P1 will do P1 will start from this instruction P1 will change the value of lock 1 to1 this instruction will executed what does this instruction say load the value or store the value of constant one into the lock so one will be stored into the lock now what we will do it will enter the critical section no one is going to stop P1 from entering the critical section so P1 will enter the critical section P2 was already present in the critical section this will cause inconsistency and loss of data so does lock guarantees Mutual exclusion every time no it doesn't guarantee Mutual exclusion if pre happens between the two statements of Entry section I hope you got the idea you want to read I have also written the numbers so first this will instruction this instruction will executed this one this one and then it will get preempted now what will happen P1 gets preempted P2 will start execution it loads the value of lock into R2 these things happens now it will change the value of lock from 0 to 1 starts execute using the instructions of critical section but it gets preempted in between now P2 gets in P1 gets into the CPU started from where it left store the value of loog equals to one loog was already one but it will change the value of lock equals to 1 now it will enter critical section is there anyone present to stop P1 from entering critical section given that P2 is already there in the critical section no one is there so P1 and P2 will be in the critical section at the same time this is a major reason for inconsistency Mutual exclusion is violated so both process are in critical section Mutual exclusion is violated is progress guaranteed can a noninterested process prevent interested process from going into the critical section no see I have explained you an assumption I think the Assumption number two it was that if a process is uninterested in critical section it will never ever enter the entry section and if a uninterested process never enters the entry section how can it change the value of lock equals to 1 can an uninterested couple go inside and lock lock them themselves in the room so that other couples do not enter no this not happen that this does not happen so in the same way a process will not go into the intersection even if it is uninterested to go to critical section and lock the critical section this will not do this this won't be done by any process who is uninterested so can a noninterested process prevent interested process process prevent the interested process from going to the critical section no this doesn't happen so yes progress is guaranteed okay so I have also explained in this way P1 is not interested P2 is interested P1 will be busy here in noncritical SE it will never ever enter the entry section so lock value will always be zero for P2 for P2 critical section will be always free okay now the third condition is waiting bounded a process should not go into critical section when there exist another interested process okay so what does uh bounded waiting say a process should not go to critical section uh I should write here again when there is an another existing interested process so let's check let's check suppose P1 completes its critical section check if the value of log equals to Z yes the value of loog equals to0 changes the value of loog equals to 1 enters critical section when completes all the instruction enters exit section change the value of lock equals to Z again comes here now the value of lock is again Z so lock is zero it will go there check if the value of lock equals to Z no change the value of lock equals to 1 enters critical section changes the value of log to zero again goes again goes again goes again no one is there to stop P1 going again and again while P2 is there waiting for its turn to get into the critical section so bounded waiting no bounded waiting is not guaranteed waiting can be unbounded for P2 so suppose p exits critical section make the value of log equals to zero and quickly joins readyq to go into the critical section again a process can successfully enter critical section multiple times while other process are waiting for their turn to ENT critical section so lock variable guarantees progress but it fails to guarantee Mutual exclusion and bounded vitting okay so let's see a this thing lock variable is a busy waiting solution leading to wastage of CPU time Cycles so yes it is a busy fitting solution because see this part can something be done like this a process comes to the entry section check if critical section is free or not let's say it is not free so why does it have to check the condition again and again wasting the CPU Cycles why does it have to check the condition again and again with wasting the CPU Cycles can something be done like this that a process check the condition that critical section is not free it itself gets blogged and when the process which was in the critical section comes out in the exit section it wake up wakes up the wakes up the blocked process or it's unblocked the sleeping process are you getting what I'm trying to say see this point lock variable is a busy waiting solution leading to the wastage of CPU time Cycles why does the CPU Cycles get wasted because a process checks the condition again and again can something be done like this that the process need not have to check the condition again and again instead what happens is process checks the condition once see if the critical section is not free then it itself get blocked it itself get blocked let's say P1 sleeps let's say P2 P1 was in the critical section P2 comes check that critical section not free get into the sleeping que let's say sleeping queue this is the new name sleeping queue now when P1 completes the critical section goes to the exit section now it is responsibility for P1 to wake up the sleeping process that is P2 it says Hey P2 wake up now I have completed the critical section you can go into the critical section if something like this can be happened then the wastage of CPU cycle can be pre preempted prevented okay so let's see what is this several concurrent process are attempting to share an iio device in an attempt to achieve Mutual exclusion each process is given a following structure Okay so code unrelated to device use that is noncritical section repeat until b equals to false b equals to True code to X is shared b equals to false code unrated to device see what happens even if the variable is changed we we thinks that is a difficult question it is exactly similar to the lock variable which have which we have discussed earlier so here busy is equals to loog false is zero and true equals to 1 now check codee unrelated to device that we don't bother about noncritical section repeat until bz equals to false that is lo lo equals to0 if lock equals to0 then go to the next statement b equals to 2 which means lock equals to 1 now so this is similar like while log so this is similar to what we have studied in the previous uh this code this thing this is exactly similar what they have done instead of lock they have written busy instead of one they have written true and instead of uh zero they have written false so this thing can also be written like that log is not equals to Z okay so they have just changed the way of a representation so this code is exactly similar to the lock variable code which we have discussed now check the following uh options which of the following are true for this approach it provide a reasonable solution to the problem of guanting mutual exclusion no we have discussed recently that lock variable does not guarantee Mutual exclusion because if you preempt here Mutual exclusion is not guaranteed it may consume substantial CPU time accessing the busy variable yes this thing lock variable is a busy betting solution it leads to wastage of CPU time or Cycles third it will fail to guarantee Mutual exclusion yes this is true so option option two and option three are correct in the last lecture we have seen log variable in this lecture we will move to the next synchronization mechanism that is strict alternation do you remember the problems which lock variable has caused the first was Mutual exclusion lock variable doesn't guarantee Mutual exclusion every time in which cases Mutual exclusion was not guaranteed in in entry section when there were two statements preempt in between the two statements preempt after one statement is executed in that case Mutual exclusion was not guaranteed and bounded waiting was also not guaranteed a progress can go again and again while some other interested process kept on waiting for infinite time or starving for unbounded time now the next synchronization mechanism is strict alternation let's check so the strict alternation is also a busy waiting solution and it is a software solution implementable at user mode similar to the lock variable and it is a two process solution do you remember the lock variable was a multiprocess solution where is it so the lock variable was a multiprocess solution strict alternation and Peterson algorithm these are the two process solution what does two process mean this solution only work when there are two process in consideration so what we do strictly on Alternate bi basis process takes turn to enter critical section so strictly on Alternate basis first P1 goes then P2 then again P1 goes then P2 and in this way they completes the critical section so let's see the code int turn equals to random 0 or 1 so turn is a variable that can take two values either Z or 1 and we randomly assign the value of the variable turn it can can be either zero or one randomly so let's write the code void process Z here it is a problem it should be process one yeah void process Zer so we are talking about p 0 and P1 so these are the two processes while noncritical section while turn equals to 1 critical section turn equals to one so what does this say this says so the turn turn signifies which process should go in the critical section now if turn is zero then p 0 should go into the critical section if turn is 1 then P1 should go in the critical section so here in the busy weight condition it checks while turn equals to 1 is it the case that turn equals to 1 if yes then keep on checking the condition busy weight if turn equals to 1 keep on checking the condition busy weight otherwise go into critical section after you complete the critical section change the value to of turn initially let's say the value of turn was Zero let's say the value of turn was zero so critical section completed condition checking turn is not equals to one so it will bypass it goes to the critical section when it completes the critical section now it has to change the value of turn to one because what we said strictly on Alternate basis so first turn value of turn was Zero it means p 0 went to the critical section now when it has completed its critical section then it has to change the value of turn equals to 1 which means now it is the turn of process one to go into the critical section so let's check this while P1 similar for process one check if turn equals to zero then Vis it otherwise go into critical section and when you complete the critical section make sure to change the value of turn I hope you understand this solution this is easier than lock variable okay so is mutual exclusion guaranteed can you check this so when was Mutual exclusion not guaranted in lock variable when we preempt in between two statements of Entry section what is the entry section here just this one and exit section just this one so mutual exclusion will be guaranteed let's see let's see so the what does log variable meant if it is zero which means critical section is free if it is one which means critical section is not free if turn equals to I which means it is p is turned to enter into the critical section and if turn equals to J it is PJ is turned to enter into the critical section I hope this is clear now let's check the scenario there are two process p 0 and P1 in the RQ which are interested in going to critical section let's say p 0 was scheduled first on the CPU and turn equals to zero and this was randomly saved randomly assigned so p 0 was executing its instructions in the critical section at s finally it got preempted so p 0 was already present in the critical section now let's say p 0 is preempted from the CPU P1 comes so P1 will start so the value of turn equals to 0 because p 0 has not completed its critical section and the value of turn equals to one is still remaining to be executed so the value of turn equals to zero now goes to the noncritical section while turn equals to Z yes turn equals to Z so it will keep on checking the condition again and again until the time slice or the time Quantum of P1 expires when P1 expires then P1 is preed from the CPU sent back to the RQ and p 0 comes back now p 0 will resume when p 0 complete this its instruction of the critical section then it goes to the exit section what is the exit section change the value of turn so the turn equals to one now now when one tries to enter critical section it will because it will not get stuck in the busy waiting condition okay so what is the busy waiting condition turn equals to equals to Z but the value of turn is one now because p 0 has completed this instruction so the value of turn has changed now when P1 will try to enter when P1 will try to execute this instruction it will not get stuck in the busy waiting I hope the thing is clear so now P1 cannot enter critical section until p 0 set the value of turn as one so is mutual exclusion guaranted yes the mutual exclusion is guaranteed can you infer more so let's say turn equals to random 0a 1 see see there are two process p 0 and P1 and the value of turn is set randomly let's say the value of turn is zero here but p 0 is not interested to go to the critical section if p 0 is not interested to go to the critical section it will never ever enter entry section it will never go to this critical section and it will never execute this turn equals to one and if turn equals to 1 is never executed then P1 in any case cannot go into the critical section so p 0 is uninterested process is hindering the progress of P1 which is interested process let me speak again p 0 is not interested to go to critical section if it never goes to critical section which means it will never execute the exit section and what was the exit section change the value of turn so turn equals to 1 will never happen and if this never happen P1 cannot go to critical section ever so an uninterested process has hindered the progress of interested process so progress is hindered here which was not in the lock variable so this is the same thing let's say turn equals to random 0 1 gives one it means it is Pi's turn to enter critical section but she is not interested ENT the critical section if she doesn't enter I'm talking about the process if she doesn't doesn't enter in the critical section then she will never execute the exit section turn will never be set to zero p 0 is blocked by a noninterested one progress is hindered so it is just an example what I want to say Mutual exclusion is guaranteed progress is hindered because an uninterested process take anyone either p 0 or P1 it is just an example take any process that uninterested process will never change the value of turn equals to the other process so other process other interested process will never be equal will will never be able to enter the critical section so an uninterested process is blocking the progress of interested process so progress is hindered is the waiting bounded yes wait is bounded what was the meaning of unbounded waiting the meaning of unbounded waiting was P1 kept on going to the critical section again and again again and again again and again while an other interested process that is P1 is starving and p 0 is laughing at the face of P1 this was bounded waiting this was unbounded waiting now here in the case you see when p 0 enters into the critical section it must change the value of turn equals to other process which means p 0 is giving chance to other process to enter to the critical section now which means p 0 cannot enter into the critical section two times in a row let me explain so let's say the initial value of turn was Zero Turn was zero this condition will be escaped goes to the critical section now turn equals to one try to go again now it will get stuck here as turn equals to one when it tries to go again it will get stuck in this Loop so bounded waiting is present as there is a strict alternation bounded waiting as there is a strict alternation now let's revise so lock variable and turn variable what is the difference Mutual exclusion was not guaranted by lock variable it was it is guaranteed by turn progress progress is guaranteed by lock variable but in turn an un uninterested process can block other interested process bounded waiting bounded waiting was not uh ensured in lock variable but it is ensured in turn as there is a strict alternation between the order of process which goes into the critical section busy waiting the both are busy waiting solution and busy waiting vage the CPU Cycles okay and last thing is number of process lock variable is a multiprocess solution while turn variable is a two process solution so these are the difference between lock variable and turn variable so till now we have covered two synchronization mechan mechm lock and turn okay now the last thing the value of turn need not to be equals to 0 or 1 it can be any either I comma J so we are generalizing it is not necessary that only p 0 and P1 are there in the program it can be either process like it can be p8 and P9 that can also be possible so we are generalizing in terms of I and J so let's say in turn equals to random I comma J so we are assigning the value of turn randomly either I or J turn can take here two values I or J if it is I then it is the turn of process I to enter the critical section and if it is J then it is the proc it is the turn of process J to enter the critical section so simil same thing in process I check if it is the turn of process J to enter if yes then keep on busy waiting otherwise goes to the critical section and in the exit section change the value of turn to the other process same thing is happening here okay so lock and strict alternation are incorrect solution why because they are not satisfying all the requirements log was not log was not giving Mutual exclusion and bounded waiting and alternation is not giving progress so all three condition Mutual exclusion progress and bounding waiting should be satisfied but here some of the other is not satisfied so these are incorrect Solutions so here is a homework problem here's a homework problem check this in turn equals to random i j so this is a problem you have to tell is this guanting Mutual exclusion is this guanting progress and bounded waiting try this in the last lecture we have seen strict alternation which provides Mutual exclusion and bounded waiting and if you recall the middle one that is the progress was ensured by lock variable so Lo variable has ensured progress strict alternation in ensures bounded waiting and mutual exclusion why not we Club the good qualities of both and create a perfect solution we have done the same thing that is Peterson solution has been made by combining the good qualities of lock variable and strict alternation and it is a solution in literal terms it provides all the three matual exclusion bounded waiting and progress it is a busy waiting solution software solution implementable at user mode and it is a two process solution that means it will only work when there are two process into consideration let's say pi and PJ so we are defining so let me tell you what is the main idea of this Peterson solution we are using two variables flag variable and turn variable so what does flag and turn refer to flag variable suggest if a process is interested to go into critical section or not flag gives the interest for a process let's say for process I if the value of flag is zero which means process is not interested and if the value is one which means process is interested and turn you all know what is the meaning of turn which process should enter into the critical section which process so turn means if turn equals to I that suggest Pi should enter into critical section if turn is I which means Pi should enter into the critical section and if it is J which means PJ should enter I hope this is clear so what we are doing here is what we are doing initially initially we are setting the value of flag to false we are saying initially no process is interested to go into the critical section okay now when the process code will be there here let's check this check the intersection we are changing the value of flag it to true for process I we are changing the value of flag I to true and we are changing the value of turn to the value of the process we are changing the value of turn to the value of the process what does this mean so the concept of turn that is a global variable will be used when both of them are interested simultaneously if turn equals to zero so both the processes are updating the value of turn according to their value if it is process I then it will change the value of turn to I and if it is J then it will change the value of turn to J okay so let's say there are two process p 0 and P1 p 0 updated the value of turn to zero and what will P1 do it will change the value of turn to one now comes the important part now comes the important part the process to update the value of turn and the last will wait the process which will update the value of turn in the last Will Wait so we will check what is the value of turn if the value of turn is one it means that p 0 has updated it already and P1 has updated later and if the value of turn is zero which means P1 has already updated the value and p 0 has updated it in the last so we will check what we will check change the value of flag I to True make the process interested change the value of turn to the process value now check if other process is interested and the value of turn equals to I then busy weight let me explain again let's say p 0 and P1 both are interested to enter into the critical section both has changed the value of flag to True when both are interested they will change the value of flag to true now both wants to change the value of turn to their value so p 0 update p 0 change the change the value of turn to zero and P1 changed the value of turn to one now when you see if the value of turn is zero that means P1 has updated first and then p 0 has updated in the last that's why the value of turn is zero you all know the process which updates last that value of turn will be saved finally let me write this the process which updates last that value of turn will eventually remain so if the value of turn equals to I that means the process I has updated the value of turn in the last so the the process which will update the value of turn in the last will wait okay so check if other process is interested and the value of turn equals to I this means that the other process that is the the process J has already changed the value of turn to J and later Pi I changed the value of turn to I that's why the value of turn is I eventually so which process should wait whose value is there in the turn so that process Will Wait so I hope the point is clear let me explain again initially what we are doing we are defining the value of n22 that is n refers to the number of process true means one and false means zero we are also defining this we are also defining an array of size n initialized to false so initi initially we are saying that all process are uninterested so let's say if there are two process then flag two and both are initialized to false that is both the process are uninterested in the beginning and in turn we are declaring a variable turn see here we are not initializing turn in the pre previous case that is of a strict alternation what we were saying we were saying Turn equals to random of I comma G we are not doing this here what we are doing we are letting the process change the value of turn accordingly according to their values and the process which updates the value of turn at the last that process has to wait because the other process has already updated the value of turn so that process should go first same concept we are applying here so this is the process code void process in I we are talking about process I and J refers to the other process what does this line means this line says that J is the other process here comes the critical section what we are doing changing the value of lag to True making the process interested changing the value of turn to I which means it is the turn of process I to enter critical section this is how process thinks and when it will check that other process is also interested and the value of turn is equals to my value which means I have updated the value of turn in the last and other process is interested too which means the other process should enter the critical section first because it has changed the value of turn earlier than me so I should wait okay so this is entry section and what is exit exit section so when the process completes the critical section it will make itself uninterested okay so let's summarize what we have said what a process does it change the flag value to True set the turn equals to the process ID check if other process is interested and I am the last one to update turn then I should bate so this is the main summary of Peterson solution okay so how does the process gets he was the last one to update if a process find out find out its ID and the value of turn is same then it is the last one to update so I have said said this thing several times I hope the thing is clear let me speak again P1 and P2 are two process P1 should change the value of turn to one and P2 should change the value of turn to two in the end we finally see that the value of turn is two so which process do you think has updated the value of turn earlier p okay so this is clear in the next video we will see how this is a correct solution in the last lecture we have seen the implementation of Peterson solution in this lecture we will see why Peterson solution is a correct solution so initially two processes are in the ru p 0 and P1 and the value of flag is initialized to false which means in the beginning both the process are uninterested to go into the critical section pz is scheduled into the CPU at time T1 and P1 at time T2 so T1 at time T1 p 0 is in the CPU and I is equals to0 and J equals to 1 which means the process which we are considering has the ID of zero and the other process has the ID one see in turn and in lock we have written two solutions for for p 0 different different code for P1 different code but here what we are doing we are have written this line that this is the code of whichever process we are considering and J is the other process Pi is the process which we are considering and J is the other process so in this case in this case which is pi p 0 and in this case which is Pi Pi is P1 so in this case we were considering p 0 and in this case we are considering P1 so whichever process we are considering I refers to that process ID and J is the process ID of other process so P0 has completed three sections noncritical section flag 0 equals to True which means it has completed these three instructions these three instructions and it got preed here noncritical section changed the value of FL to true and turned to I which means zero so these three part are completed and it got preempted here now at time T2 P1 is scheduled so I = to 1 J = to 0 it does the similar thing noncritical section change the value of like to true and turn to one now you know that P1 was the last one to update the value of turn so it will bate check here when it will it has completed noncritical section change the flag to True did this turn equals to I now see when it will check this condition we are talking about the P1 when P1 will check this condition it will it will see that the other process is interested as P0 has already completed this instruction so it will see the flag of P0 is true the flag of p 0 that is the flag of other process is true and the value of turn equals to one because this process has updated in the last so it will get stuck in this condition checking it will busy so which process will busy weight P1 will busy weit so it will be busy weting now at time D3 p 0 will join the CPU again now the value of I equal to 0 and J = to 1 I refers to the current process which is the current process zero so I will refer to the ID of the current process so I equals to Z and J equals to the other process what it will do now it will start from this p 0 will start from statement D because it got printted here and when process returns it will resume it will not restart so it will start from statement D it will check is the other process interested yes the other process is interested and what is the value of turn the value of turn is equals to J the value of turn is equals to J in the last turn equals to 1 so the value of turn equals to J so it will not wait it will escape this waiting condition and enters the critical section enters the critical section okay so this is how Mutual exclusion is guaranteed when both process are interested so whichever process updates the value of turn in the last will beate c p 0 and P1 were both interested to go into the critical section and here we can see that one process has to busit so this is how Mutual exclusion is guaranteed when both the process are interested now we have a concept of flag if other process is not interested then it won't let the other process busy it because of her see busy waiting only happens when the other process is interested and the other process has updated the value of turn earlier than the current process I will speak this line again busy waiting only happens when the other process is interested and the other process has changed the value of turn earlier than the current process now in context to progress the other process will never change the value of flag to True see I have already said if a process is interested then only it will go to the entry section and the first statement of the entry section is change the value of true if a process is not interested it will never go to the entry section it will never change the value of flag to true so it will never let the other process busy weit so the progress is not hindered here I hope you are appreciating the beauty of Peterson solution so now we have concept of flag if other process is not interested then it won't let the other process busy because of it okay so noninterested process guaranteed progress now how the bounded weight is guaranteed let's say let's see from the code let's see from the code p 0 wants to enter critical section two times in a row can this happen or not let's check P0 completes noncritical section change the value of flag to True change the value of turn to zero now it's checks if flag J equals to true and turn equals to I initially let's say it escapes this condition because we are checking if it can enter the critical section two times in a row so let's assume it has entered first time completes the critical section completes the exit section change the value of flag to false now it wants to go again so what it will do completes the noncritical section change the value of flag to True change the value of turn to I so this is the critical thing change the value of turn to I which means change the value of turn to zero other interested process is there and the value of turn equals to zero which means it will busiate it cannot go again similar thing I have written here let's Z let's say p 0 completes critical section and it quickly completes its rest of the instruction to enter the critical section again while the other process is still waiting which means while the other process is interested okay which means the flag of other process is true is that possible no why because we have a concept of turn if p 0 wants to go again it cannot go because let's say for the first time it completes the critical section completes the ex exit section now goes again to the entry section change the value of FL to True change the value of turn to zero you got this other process is interested and the value of turn is equals to Z see p 0 itself changed the value of turn to Z and in the next statement it checks whether the value of turn equals to zero or not it is zero and the other person is interested so it will buyit it cannot enter again because P0 was the last one to update the turn and the process which updates the turn in the last should be Z so did you see how intricately this is crafted this Peterson solution let's revise again so what we do in the peton solution we change the value of flag to true we change the value of turn equals to the idea of the process and checks if the other process is true if the flag of the other process is true which means other process is also interested and the value of turn equals to the I which means this process has updated the value of turn in the last which means this process should Bey okay so this is how Peterson solution guarant is mutual exclusion in the second case we have a concept of flag an uninterested process will never change the value of flag to True initially it is set to false an uninterested process will never go to the entry section and it will never change the value of flag to true that's why it will never hinder it will never hinder the progress of other interested process in the third bounded waiting we have a concept of turn which ensures that a process cannot go into the critical section two times in a row so that's why Peterson solution is a correct solution I hope now it is clear hi do you remember the problem which I have given you you have to tell whether this piece of code provides Mutual exclusion bounded waiting and progress or not so let's check line by line in turn equals to random I comma J so we are randomly assigning the value of turn to either I or J void process in I so this is the code of running process I refers to the running process and J refers to the process which is other than I J equals to not I the process which is not running while one noncritical section while turn is not equals to I so this can also be written as y turn equals to J so what does this line say it says if if it is the turn of another process then busy weit change the value of turn to J and what is J J is not I goes to the critical section again change the value of turn to J so this is the code now we are here to check whether this provide a mutual exclusion or not so do not have to read from this PDF I made a little mistake here read from this so what are the statements of the entry section initially the noncritical section then in the intersection we are checking if it is the turn of another process if yes then bate change the value of turn to J now I've told you that whenever there are Whenever there are two or more statements in the entry section then preempt in between to check M exclusion or deadlock or anything preempt in between so we are doing the same thing we are preempting in between p 0 is the process under consideration so the value of I equal to 0 and value of JAL to 1 and we are seeing initially the value of turn is zero p 0 completes the noncritical section now checks the condition while turn is not equals to zero well the value of turn is equals to zero so this condition is false do not vate escapes this condition and here it got preempt preempt just before turn equals to one okay so whenever the process comes back it will start with turn equals to one okay now comes P1 so now P1 is the process under consideration so the value of I will be 1 and value of J will be zero completes the noncritical section tries to enter into the critical section so firstly it have to go into the entry section now the value of turn equals to Z checks while turn is not equals to 1 yes turn is not equals to 1 it is equals to Z the condition is true B it so it is not able to enter into the critical section while this process can enter so here we can say Mutual excution is guaranteed but but have you checked the traditional way what was the traditional way what was the definition the definition is two process should not be into the critical section at the same time so what what are we doing we are letting one process enter into the critical section and there we are preempting it and we will see that if another process can also enter into the critical section or not so at time T1 P0 is the process in the consideration I = to 0 Z = to 1 turn equals to 0 initially completes the noncritical section why turn equals 2 equal to 1 no no this is false escapes the busy weight change the value of turn to one goes to the critical section gets preempted here now the value of turn is 1 okay p 1 is the process let's say at time T T2 P1 is the process into the consideration I = 1 J = to 0 completes the noncritical section while turn equals to equals to zero is this true no this is false turn equals to one so it will not busy weight goes to the next statement turn equals to0 enters the critical section when p 0 is in critical section when p 0 is in critical section no one is there to stop P1 from entering so here we can say m Mutual exclusion is not guaranteed let's check for Progress so we are randomly initializing the value of I and J let's say the value of turn is value of turn is J as we can as it is randomly initialized so we can say we can initialize the value of turn to anything either I or J okay so let's say the turn turn is initialized to J which means it is the turn of process J to enter critical section but process J is not interested not interested to enter critical section if it is not interested it is never going to change the value of turn to another process so the progress is hindered progress now turn let's say the value of turn was J so pi and PJ are two process in the RQ PJ is the not process which is not interested for critical section so Pi will get stuck in the v loop as PJ will never enter into the critical section so the value of turn equals to I will never happen so the progress is hindered here what about bounded waiting can a process enters into the critical section two times in a row if yes then the waiting is unbounded let's see let's see p 0 is the process goes into critical section so here I equal to 0 and Jal to 1 goes into the noncritical section while false because let's say the turn equals to Z zero in the beginning so is it the turn of another process no condition becomes false now the value of turn is changed to one so what does this say it is the turn for another process to enter so when the when after completing all these steps when p 0 trying to enter again into the critical section there it will get stuck in the busy weight Loop because the value of turn has been changed to one so P0 cannot enter into the critical section so the bounded waiting is guaranteed so I hope you now know how to get how to infer from a piece of code that either bounded waiting Mutual exclusion or progress is guaranteed or not okay in the at the last time for the last time I should use better prepositions for the last time let's see the formal definitions of all these things all these requirements Mutual exclusion I'm just going to read it you all know the meaning of all things them just for the formal sake this property ensures that if a process is executing in its critical section then no other process can execute in their critical section okay this property ensure that if no process is executing in its critical section and there exist some process that wish to enter their critical section then selection of the process that will enter the critical section next cannot be postponed indefinitely this is progress and bounded waiting this property ensures that there exist a bound or limit on the number of times there exist a bound or limit on the number of times that other process are allowed to enter into their critical sections after a process has made a request to enter into critical section and before that request is granted so what does bounded waiting say that a process should not be allowed or there should be a limit on the number of process going into the critical section again and again if there exists some another interested process and what does progress say progress says that an uninterested process should not hinder or should not block the interested process and what does mutual exclusion say you all know there should not be two or more process in the critical section okay so in the next lecture we are going to start dear's algorithm hope you all remember Peterson algorithm in this Le we are going to see the optimized version of Peterson algorithm that is D's algorithm and it is a correct algorithm too it provides M exclusion bounded waiting and progress so how does it work let's see void Deckers algorithm in I so I is the process under consideration and J is the other process okay while one noncritical section so let me give you a situation this is u this is the other process you are process I and your friend is the process J so both are friends so what happens there is a TV screen here which gives the value of turn variable so what happens you loudly say I am interested to go into the critical section so what you do you change the value of flag I to true but you also check at your friend's face he also seems interested to go into the critical section so what do you check you check whether your friend is interested to go to the critical section if he is interested then what you will do you will look at the TV screen of turn if it is the turn of your friend to go into the critical section what you will do you will become a good man you will say okay my friend should go into the critical section I am an uninterested for now I am uninterested for now so we'll change the value of your flag to false and you will say I will wait until it's my turn to enter into the critical section so until the turn equals to equals to J you are going to busy wait and as soon as as soon as at the TV screen you say it's my turn to go into the critical section what you will do you will change your flag to interested or true through you'll go into the critical section and when you comes out it is your responsibility to say okay I have done my work now I am un interested to go into the critical section my friend you can go will change the value of false and you will say the value of turn will be equals to J so this is how Decker's algorithm work okay so let's read the full code Decker's algorithm vo Decker in i j is the other process I is the process under consideration completes the noncritical section you say hey I am interested but you will also look at your friend's face if he also seems interested and then you look at the TV screen of turn the turn suggest that J should go so you will become a good man you will say hey my friend you can go I am uninterested for now and I will wait until it's my turn to go into the critical section and as soon as your turns appear uh or your ID appears at the TV screen you say now I am interested to go into the critical section you goes to the critical section after the completion of critical section you say now I'm uninterested my friend you can go it's now your turn I hope dear algorithm is clear now now we'll see why dear algorithm is correct algorithm let's check for Mutual exclusion the algorithm uses two Boolean variable flag I and flag J to indicate if a process wants to enter critical section it also users turn to decide which process can enter critic section when both want to this ensure that only one process can enter into a critical section providing Mutual exclusion so the mutual exclusion is guaranteed now let's check for Progress if a progress doesn't want to enter the critical section it sets its flag as false this allow other process to enter critical section if it wants to this ensure that if a process GS to ENT critical section it eventually will providing progress see initially the value of flag is false for both the process and I have said that a process will enter into the entry section only when it is interested to go into the critical section so it will never change its value to true the value of flag will always remains false and if the value of flag will always remains false it will never going to bate the other process so the progress is guaranteed because the value of flag will never be set to true if a process doesn't enter the entry section and an uninterested process never ever enters the ENT section bounded waiting the turn variable ensures that the process alternately enter the critical section and they both want to enter c here whenever it completes the exit section the turn is set to J and if it tries to go again it will stuck here okay so process cannot enter the critical section two times in a row in bounded waiting okay so I hope the point is clear how deer algorithm is correct it provides Mutual exclusion progress and bounded waiting we have completed the software solution for synchronization the lock variable the turn variable that is a strict alternation Peterson solution and Decker's algorithm in this lecture we are going to start the new topic synchronization using Hardware but before that let's discuss some problems so there are two process P1 and P2 that need to access critical section of the code consider the following synchronization con used by these process and you have to tell whether they provide mutex progress mutex means Mutual exclusion progress bounded waiting and Deadlock okay so for the mutex let's discuss the two condition the first is preempt in the critical section and see if the other process is also able to enter into the critical section or not the other one is preempt in between the two state M of Entry section so let's check for the critical section first there are two variable want one and want two initially set to false now let's see what happens want 1 equals to True here in this code wants 1 equals to true so I'm going to change the value to True while wants two equals to true no this is false so we are not going to busy weit enter into the critical section preempt here let's go to the second process wants 2 equals to true so we are changing the value of wants two to true now while want 1 equals to True is it true yes it is true so it is going to Vis it it won't be able into the it won't be able to enter into the critical section now we will check the second condition that is preempt here want 1 equals to True preempt wants two equals to true so this is the the case now go here while wants to equals to True yes it is true so it is going to busy go here now while wants 1 equals to True yes it is true so it is also going to both process are busy waiting this is the case of dat log let me explain again first this statement wants one equals to true then this statements 1 to equals to true then this statement and then this so both are busy waiting both get blocked so this is the case of Deadlock so deadlock is present Mutual exclusion is also guaranteed now check for Progress let's see P2 is the process uninterested to go into the critical section so initially the value of want one and want two is set to false and P2 is the process that is not interested to go into the critical section if P2 is not interested can it block P1 to go into the critical section if P2 is not interested it will never change its value to true and if the value of want to is never true then P1 is never going to beate so progress is also guaranteed an uninterested process is not hindering or blocking the interested process to enter into the critical section so progress is also guaranteed Mutual exclusion guaranteed progress guaranteed deadlock also guaranteed check for the bounded waiting for bounded waiting see if a process can enter into the critical section two times in a row wants 1 equals to True while one two equals to True initially the one two is false so it enters into the critical section now want to equals to false okay now wants to equals to false it was initially False only so this is true once one has become true and this is false it tries to go again want one is true change the value to True is want to equals to true no it is false enters into the critical section now change the value of one two to false again tries to go again wants two equals to True yes it is true is the value of one 22 true no it is false so it enters again a process can enter again and again into the critical section while other interested process is waiting so bounded waiting is not guaranted if it was the case of strict alternation then bounded waiting will also be present and for case of a strict alternation they never have deadlock the case of Deadlock will never be present in the case of strict alternation okay let's let's see another question variable P equals to false variable Q equals to false code for process X is given for process Y is given you have to tell is there any possibility of Deadlock does this guarantee Mutual exclusion this is an homework question and easy one you can do this on your own let's move to the synchronization Hardware so each processor supports some special Hardware instructions that are Atomic in nature okay so do you mean what do you mean by atomic Atomic means that they cannot be preempted until they gets completed it's just like the kernel mode instructions okay so these instructions these special instructions are Atomic in nature so we are discussing about TSL and swap instruction they are also based on busy waiting and they can be used at user mode as a special instructions so they are they are being used as user mode only but they are special instructions hence Atomic in nature they belong to the hardware category and it is a multiprocess solution see lock variable was a multiprocess solution turn variable was a two process solution Peterson was a two process solution deers was a two process solution this TSL and swep we will see it later later these are multiprocess solution this Hardware solution TSL and swap are multiprocess solution what are they we are going to see in the next lecture and it is a lock based solution lock based solution do you know the full form of TSL test and set lock so these are the lock based solution this is just an introduction video we are going to see them in detail you in this lecture we are going to start our first synchronization Hardware mechanism that is TSL TSL stand for test and set lock so what does it do let me tell in brief DSL takes a parameter lock m% loog that is the address of lock so what does TSL do TSL Returns the current value of lock let's say initially the loog is set to the loog is set to false so what does TSL will return TSL will return the value as false and then it will change the value of log to true so what does TSL do TSL Returns the current value of log and set the value of log to True okay so this is what I have written TSL M loog process executing TSL Returns the current value of log and sets the value of log always to true so first it will read the current value and write the current value to True okay so whatever be the value either true or false this will be returned and then the value of log will be changed to true so this is what TSL does now before we are going to see how TSL is going to solve the critical section problem we'll first see how TSL works so what is the function behind TSL bull TSL why bull because TSL returns a boan variable either true or false I have said first it will return it Returns the current value of loog so what does loog contain either true or false so firstly it will return so return type will be Boolean Bo esteric Target so here we have written m% lock and here we have written esteric Target so Target is a pointer pointing to the lock here we are using passing by reference so Target is a pointer pointing to the lock what does return Value Store bu return value return value is going to store the current value of lock let's say let's discuss the previous example which I have given so according to that previous example the return value of lock will be false and so let me write it again so initially the value of log was set to false okay so return value is going to store the value of log that is false so return value will store false and then set the value of log to true so we are going to set the value of log to true and return the return value what is the return return value false so what does it will return TSL will return false and will set the value of log to True okay so this is how TSL work now last statement which I am going here to made before we will see how this solves the critical section problem is these three instruction will execute atomically no preemption so it Returns the value of log and set it to true and this is done atomically okay so let's see how this solves the critical section problem initially let's set the value of log to false void process in I while one now see noncritical section is executed and then while TSL M percent loog is equals to is equals to true this is entry section critical section and then set log to false let's see how how it is going to solve the critical section problem there are two process in the RQ P1 and P2 okay P1 P1 firstly scheduled at CPU start executing the critical section P1 is still in the critical section and it gets preempted now P2 comes now P2 is in the CPU let's check whether P2 can also enter into the critical section or not if it is capable to enter into the critical section this DSL is not going to provide the mutual exclusion let's see whether it is capable or not so initially when the P1 wants to enter critical section what it has to do it has to First execute the noncritical section it will check whether the value which TSL return is true or not so initially the value was false so what does TSL will do TSL will change the value of log to true and Returns the current previous value what was the previous value false so it will return false is false equals to true no it is not hence it will go into the critical section it was still in the critical section before it got preempted so P1 is still in the critical section now P2 got scheduled let's check whether P2 is also capable executes the noncritical section while TSL M m% log what does TSL do TSL Returns the current value of log what is the current value of log true so it will return true and sets the value of log to true so it return true is true equals to True yes it is true so it will keep on visting visting and visting until until P1 completes the critical section goes to the exit section change the value of log to fals so it will change the value of log to FS now when P2 will get hold of CPU when P2 will be in the CPU it will resume resume from where from here now it will see TSL Returns the current value of log what is the current value of log false is false equals to true no it is not now it can go into the critical section so I can make a statement P2 can go into the critical section only when P1 has completed its exit section so it guarantees Mutual exclusion does it guarantees progress yes it guarantees progress how because let's say there are two process P1 and P2 P1 is not interested to go to the critical section so a process which is not interested to go to the critical section will never ever visit the entry section so the value of lock will be never changed to true it will remain false so when P2 tries to enter false is not equals to true it will easily Escape The Waiting condition so P1 is not hindering P1 is uninterested process so uninterested process not hindering the way of interestate process hence progress is guaranteed noninterested process will never change the value of log to ro okay now comes the now comes the scenario of bounded waiting is bounded waiting satisfied I think it's not why let's see P1 completes the critical section goes to the TSL initially the value of lock was false so when this will be executed this DSL it will change the value of log to true but it will return the current value as false so false is not equals to True easily escapes the critical section goes to the ENT section it will change the value goes to the exit section it will change the value to false again try to go what does TSL will return it will return the current value that is false false is not equal to True will again Escape The Waiting condition hence P1 can go into the critical section again and again while P2 is still waiting so P1 will l in the face of P2 but P2 can do nothing so bounded waiting is not guaranteed but I have seen in this logic bounded waiting is not guaranted but in galin textbook so which textbook textbook are we referring to we are referring to galin so in galin textbook they have added additional logic in TSL which will make it right like a round robin so first P1 will go it will execute for some time and then P2 will go so in this manner a a type of turn is introduced P1 P2 P1 P2 it's it's like a round robin so they have added additional logic and if that additional logic is there then it will ensure bounded weight but here in the basic logic bounded weight is not ensured P1 can go into the critical section again and again so if you are interested you can just go to the Galvin textbook read the additional logic and try to understand okay but here in the uh the case which we are talking about bounded weight is not initialized P1 can go into the bounded weight is not there not present P1 can go into the critical section again and again okay so I hope how TSL work is clear in the next lecture we are going to see the swep mechanism let us start the swap mechanism this is based on lock in key mechanism so what does I refer here to we'll see later but let's first see the introduction part swap mechanism based on lock and key and it is atomic in nature so this web function this will make sure that these three instructions will be ex executed atomically so what does are the these three instruction these three instructions are for swapping the values stored in the variable A and B so why are we using here the call by reference not directly because we want the changes to reflect into the original data also we are changing inside a function we also want that original data should also be changed that's why we are using call by reference if you don't know call by reference it's your homework to understand how call by reference work okay so let's first understand how spping work for swapping what we have to do we have to use a temporary variable otherwise the value of one variable will be lost what I am saying here is let's see this is variable a this is variable B it is stored value five it store value 7 now I want to swap the values of A and B let's say I want seven here and five here how can this be achieved let's see okay I cannot directly store the value of a into B I cannot directly write here five otherwise the seven will be gone okay so first we have to store the value of s into a temporary variable before changing the value of B so we have stored the value of B into some temporary variable T now this can be overridden and here the value of T will be stored back to a so this is how swipping is done let's see here we are defining a temporary variable we store the value of a into the temporary variable now the value of a is safe I can directly store the value of B into a the value of a is already safe now the B value of B is stored in a and then the value of a indirectly I'm saying the value of a is now stored in B so value of B is stored in a and value of a is stored in B this is how swipping is done using a temporary variable now you got how spping is done let's see how this spping is useful in solving the critical section problem set the value of lock to false initially the value of lock that is a global variable is set to false void process in I P1 let's say P1 is the process and has a value of key to True initially we have set the value of key2 true P now P1 wish to enter into the critical section so what it will do it will first execute the noncritical section goes to statement B while key equals to equals to true it will check whether key equals to True yes it is true it will enter into the V Loop swap the value of lock in key now we have to exchange the value of lock and key lock will become true and key will become false as it is a vop it has to go check the condition again the value of key is true no the value of key is false so it is going to escape this while loop goes to the critical section now we wish to now we wish that this spping mechanism solve the critical section problem so so we are going to check when P1 is in the critical section does another process also enters is another process capable to enter into the critical section that we are checking so we will preempt in the critical section so P1 is still in the critical section P2 wish to enter what is the value of lock lock is true now P2 wish to enter so this is P2 and I have said initially the value of key in process is true P2 completes the noncritical section is the value of key to is true yes it is true it will swap the value of key and lock the value of key and lock will be swed so true will be here and true will be here the value of Key and Lock is swapped but the keys is still true so when it is going to check the condition again it has to swap again the value of login key so it is going to it is just swipping the value again and again checking the condition swipping the value busy weight busy weight until the value of log becomes false and how can value of log become false when P1 completes the critical section executes the exit section now value of loog has been changed to false now if P2 wish to enter see in now presently no one is the no one is in the critical section now P2 wish to enter the value of lock has been changed to false by P1 exit section so P2 will start here check check does the value of key is equals to True yes it is equals to True swap the value of lock and key so it will swap this will become false and this will become true now it is going to check the condition again is the value of key true no it is false so it will escape now it can enter easily into the critical section but what a statement I can make here the mutual exclusion is guaranteed see here P1 completes non critical section key equals to True swap the value now lock is true key is false enters critical section got preempted P2 is to enter completes noncritical section key is true swap the value of lock in key but it has to CH it has to check the condition again key is true yes swap the value key is true yes swap the value key is true yes swap the value until P1 completes its exit section change the value of lock now when it will swap the value the key will become false and lock will true now when it's going to check the condition the key is false so now it can enter into the critical section only when P1 completes the critical section so we can say Mutual exclusion is guaranteed P2 is unable to enter into the critical section when P1 was present there does it guarantee progress yes progress is guaranteed as no uninterested process will change the value of lock not blocking the other process okay in particular the code could lead to the situation known as starvation if one process quickly finish its critical section and reenters it before the other process it has it chance to set lock it could potentially keep reentering the critical section indefinitely while the other process Waits unboundedly so here I can also say that bounded waiting is not guaranteed a process can enter into the critical section again and again again and again by setting the value of log to false okay see to enter into the critical section what is the major thing required the value of log should be false critical section should not be logged the value of log should be false so a process can change the value of log to false in its EX in it exit section and can enter into the critical section again and again while other process is waiting so bounded waiting is not guaranteed but similar to the TSL if additional logic is added then bounded waiting can be guaranteed but here in this case bounded waiting is not guaranteed so this was swap mechanism it guarantees Mutual exclusion progress but fail to guarantee bounded w so we have completed test and set and swep mechanism let's see a problem on this enter critical section and leave critical section functions are there to implement the critical section of a process and are realized using test and set instruction X is initialized to zero which says critical section is free so when test and set X will be executed it will return the value of x and will set to one which says critical section is busy so this is similar to the test and set which we have studied now based on this try to solve or try to guess which of the following four options is correct so the first says the about solution of critical section is deadlock free yes test and set is deadlock free the solution is starvation free no this is false because a process can enter into the critical section any number of times while some other process is waiting other process is starving so starvation free this is false starvation can be present the process enters critical section in feif folder no this is false there's no no restriction for process to enter only in folder they can enter in any order fourth more than one process can enter critical section at the same time no test and set log successfully provide Mutual exclusion so only option one is correct now an interesting problem that is priority inversion problem see if someone ask you an interview which is a high probability give me a best example of Deadlock give me a best example of Deadlock then you are going to say this priority inversion problem this has happened in one of a NASA's Mars project finder project so what happened that let me explain you in brief there are two process PL and pH PL refers to the low priority process and pH refers to the higher priority process so all correct busy waiting Solutions suffer from Priority inversion problem and this problem is only when we are using preemptive priority based scheduling I hope you all recall what is preemptive priority based scheduling so initially PL was there PL got to the CPU went to the entry section completed entry section was executing the instructions of critical section but suddenly it sees that there is a high priority process present in the ricu so it has to leave it has to leave CPU go back into the ricu now pH is entering into the CPU pH is in the CPU pH says I wish to enter into the critical section 2 tries to enter into the critical section but denied why because PL is PL is already present pH feels bad I am the process with higher priority how can pH remain in critical section when I am I want to enter PL Hey listen PL you should leave the critical section immediately PL says listen sir the thing is I cannot complete my instructions until you leave the CPU so that I can complet my complete my remaining instruction of critical section exit and then you can go to the critical section till I am in the critical section you cannot enter into the critical section PL says how dare you to talk me to talk to me like this I am the process with the higher priority I am not leaving the CPU PL also says okay go and try try to enter to critical section if you can I am not leaving the critical section as well so pH is waiting for PL to enter critical section PL is waiting for pH to leave CPU so that it can complete the remaining instructions of critical section pH is waiting on PL PL is waiting on ph deadlock perfect example of Deadlock so let me read pH is also interested into critical section but it it cannot be allowed no matter how high the priority is it cannot be allowed until there is some process present in the critical section so pH cannot be allowed to enter section until P1 completes and for completion PL needs CPU pH won't leave CPU because of its ego so there are the they present the conflict of two principles the first is priority and the second is of mutual exclusion priority says a low process a low priority process should leave whenever a high priority process come Mutual exclusion says there should be only a single process into critical section pH cannot enter into the critical section until PL leaves both will be adment do you know the meaning of adment the adment means stubborn stubborn both are stubborn to leave this causes deadlock so I have given you if I have already told you if someone in the interview ask you example of Deadlock this is the best one this problem occurred in the NASA's Mar Mars Pathfinder project so what is the solution the solution of the problem is priority inheritance see the thing is you can drive the inter VI the way you speak let's say it has started with tell me your favorite subject and then you say operating system they ask what is deadlock you give the definition of Deadlock now they ask can you give me an example then you say yes I can give you an example and you give this perfect example this priority inversion problem first thing is the interview will be the interviewer will be very much impressed and the second thing is he will ask what is the solution then then you are going to say priority inheritance PL will inherit the priority of pH and vice versa for PL so what happens when this uh when this type of problem occurs then that uh a low priority process is present in the critical section and a high priority process has occupied CPU then we have to invert the priority PL will get the priority of pH so what will happen now pH will leave PL will come PL will execute the instructions and then when the critical section will be over it will execute the exit section and then it will get its own priority back now pH will enter into the CPU and then can easily enter the critical section so I hope you all you have understood what is priority inversion problem and what is the solution priority inherit inheritance we are going to exchange the priority of low priority and high priority process now an amazing homework question it has various parts and if you can do this give yourself a nice trate this is an amazing question we are going to discuss this in the next lecture let me explain you the problem Fetch and add X comma I is an atomic read modify WR instruction that reads the value of memory location X increment it by value of I and Returns the old value of x it is used in the studio code as shown below to implement a busy weight lock so this this Fetch and add L comma fun this could be implemented like in this way this is not a part of question this I have given you in form of a hint so fetch and add log int X in I these are the parameters taken by Fetch and adlog these are the parameters int return value the store the value of x into the return value increment the value of x by I and then return the return value so what does it do read modify write instruction that reads the value of memory location X reads the value of memory location X incremented by value I incremented by value I and Returns the old value of x and Returns the old value of x it is used in the pseudo code shown bu to implement a busy weight lock L is assigned integer unassigned integer and shared variable initialized to zero the value Z correspond to the lock being available if the value is zero which means the lock is available while any nonzero value correspond to the lock being not available non zero says the lock is not available Zer says lock is available okay so acquire lock while Fetch and add L comma 1 initially let's say the value of L is set to zero initially the critical section is free what it will do Fetch and add l so what is going to do L increase the value of L by 1 so now what will be the value of L the value of L will be 1 and in the next instruction it says set the value of loog to one set the value of loog to One release loog so this was the end entry section and this is the exit section so to release loog set the value of loog to zero so what are we doing here while Fetch and add it is going to increase the value of loog by one and then in the next line we are setting the value of loog to one okay so what does this entry section make it will make the program it will make the process busy weight if L is greater than zero so if L equals to Z CR section is free if L is greater than Z CR section is not free so if L is greater than Z then it will busy weate and why we have written Lal to 1 here that you have to figure it out why we have written Lal to 1 so so in log while one Fetch and add and n% log one so this is atomic returning the value of log and and increasing the value of block by one will be done atomically and then L equal to 1 why are we doing this figure it out so these are the problems which you have to solve so the first problem is we have set the value of Lal to 1 if this would not have been there then the value overflow would have been occurred how value of overflow would be occurred if L is not one figure it out the second problem is does this provide Mutual exclusion does this piece of code provide Mutual exclusion the third is can it be possible after a moment that no one can go to the critical section can it be possible that lock is one and critical SE critical section is three what I've said in the beginning if lock is zero then critical section is free if Any number greater than zero then not free but is it possible that the value of lock is one and critical section is free starvation from some starvation for some process is it there so you have to figure out these five questions this is an amazing amazing problem give it a Time solve it and if you are able to solve it correctly give yourself a nice trck because this is a difficult question this requires presence of mind this requires logic so in the last lecture I've given you a problem to solved this was a nice and interesting question before solving this let's first revise some some of the synchronization mechanism properties so the lock variable and District alternation are just the opposite lock variable doesn't provide Mutual exclusion and bounded waiting while stct alternation provides lock variable provides progress but stct alternation doesn't p and Decker are complete TSL and swap they provide Mutual exclusion and progress but fails to provide bounded waiting but an additional logic tsln swap also provides bounded waiting so it depends in which context we are talking about so now we will move on to the question we have been given a function fetch an add which Returns the value of x and increase the value of x by I and this was the enter section and this was the exit section now the first question if you remember was what will happen if Lal to 1 wouldn't have been there wouldn't have been there so for that case let's trace this initially the value of log is zero it goes there what it will return it will return zero and increases the value of log by one so now the value of log is one remember this while zero it will not get entered into the loop it will escape this condition goes into the critical section okay now the value of lock is one for another process when it will go there while fetching at lock what it will return it will return one and increase the value of loog by 1 so initially the value of log was zero so 0 was returned and then it was increased to one now for the second time when this will come here the value of log is one so one will be written and it will be increased by 1 so now the value of log will be 2 for the third time when it will come two will be returned and it will be increased by 1 three four time four will be returned and it will increase to I hope you are getting the point so this will happen only when L = to 1 is not set there okay so this will only happen when Lal to 1 is not present but if Lal to 1 is present then this overflow wouldn't have been there let me repeat for the first time lock is zero goes there what it will return zero escapes the condition goes into the critical section for the second process when it comes what will the value of lock see when the first time when the value of lock equals to0 was return it was also increased by one so now the value of lock is one if the value of lock is one it will return one and increase the value of loog by 1 so now the value of loog is two and we have assumed that Lal to 1 is not present goes again returns two and increase the value of log by 1 now three goes again returns three increase the value of log by one now the value of log will be four goes again returns four increase the value of log by one the value is five so this cycle will keep on going on going on and going on until the value overflow would be there okay so I hope you got the point how Lal to 1 is saving the overflow now we we are taking the case when Lal to 1 is present then what will happen initially L equal to 0 it returns Z change the value of log to one goes into the critical section for this another process now the value of loog is one is returned and then the value of loog is increased by one so now the value of loog is two but it will also go there in the loop in the loop condition so Nal to 1 is set so value of two will be set to 1 so by writing this C equals to 1 it will keep on oscillating between 1 and 2 okay so I hope you got the point how Lal 1 is saving the Overflow if Lal 1 is not present the value overflow will be there if Lal to 1 is present the value of log will oscillate between 1 and two I hope you got the idea now the second question does it provide manual exclusion so let's check Suppose there are three process in the RQ P1 P2 and P3 okay critical section initially is empty and the value of log equals to zero for the first time okay now what happens P1 at the time T1 goes try to go into the critical section so fa AA is the Fetch and add log initially the value of log was zero so it will return zero and will change the value of log to one okay so it has all passed the conditions now it can easily go into the critical section so it will go into the critical section and there it get preempted okay so now P1 is in the critical section it has not completed the critical section but before it got preempted and the value of log is one now at time T2 let's say P2 also want to enter the critical section goes to the fion add log what it returns it Returns the value of log one and changes the value of log to two and then what will happen in the v you you remember that we have set the value of log to one so the value of log will be set to one and then when it goes again to check the condition the value of one will be return return and log will be set to two and then again so it will busy here it will busy here loog will be one initially the loog one will be written the value of log will be changed to two and then when this statement will be executed the log value will be back changed to one goes again the value of 1 will be returned 2 1 2 1 this will keep on going on so this cycle one will be returned increase to two again set to one one will be return increase to two so this will keep on going on it will busy wa now let's say at time T3 P1 comes again completes the critical section and it will execute the exit section and what was in the exit section L equal to 0 so it will change the value of log to 0 at time T4 P2 wants to go again so it P2 goes to the Fetch and add lock so now the value of lock is zero so fetch and add lock loog will return zero increase the value of log by one now what is the value of uh log log is one and the value of log which was return was zero so it will not get stuck in the busy weight it can easily go into the critical section completes the critical section and again set the value of L to zero to show that now the critical is free so I hope you got the idea that overflow is not possible and it also guarantees Mutual exclusion okay it it was easy so question in question B was easy now let's check question C can it be possible after a moment that no one can go to the critical section can it be possible so let's see that at time T1 let's say P1 wants to enter the critical section initially the value of log was zero so it will return zero and will change the value of log to one goes to the critical section and then get preempted now at time T2 P2 wants to enter into the critical section the value of log was changed to one so it will return one and will increase the value of log to 2 now what happens is it gets preempted before it could set the value of log to one so let me show it here so this was all these statements were executed but here it got preed before it can set the value of log to one so we are solving the question can it be possible after a moment that no one can go to the critical section for that case we are preempting before it could set L equal to 1 now what will happen see so here is a general observation Whenever there are two statements in entry section preempt after one to get good inferences so I have told you several times Whenever there are two statements in the entry section so there were two statements preempt after one preempt here to get good inferences and here we have got also so now the value of lock what is the value of lock now the value of lock is two okay so at time P1 at time at time at time T3 P1 was there in the critical section if you remember P1 was preempted while it was in the critical section so P1 was in the critical section what it do now it completes the critical section change the value of log to 0 and leaves okay P1 has done all all its work now at time P4 P2 comes back P2 comes hold of the CPU it start executing its instruction so which instruction it will execute it will execute Lal to 1 it will execute lals to 1 fet and now what will happen see P2 has executed this instruction so it will go again and check the condition so it will go again and check the condition it will go again and check the condition what fetch ad log will return it will return one and it will increase the value of log to two so you got the idea it is busy waiting now so it is busy waiting is there anyone in the in the critical section no no one is the is in the critical section P1 was present in the critical section but it has completed all its work work it has left the critical section no one is present in the critical section but when P2 came it itself changed the value of log to one and you should remember the value of log equals to 1 represent that the critical section is not free but in reality the critical section is free no one is present so this is something wrong here P2 should logically go into the critical section because critical section should be free P1 when it when it was leaving it has changed the Val of log equals to0 which imply that critical section is free anyone can go into it but what happened P2 changed the value of log equals to one so this is something like this P2 without entering into the critical section has said to everyone has has told everyone that critical section is logged but actually inside no one is in the critical section so P2 should logically go into the critical section but it failed critical section is free the value of log is oscillating between 1 and two but no one is able to go into the critical section let's let's say at another time P3 P3 will always busy weit because lock is not equals to Z afterward so this is something stuck see no now what is the situation no one can go into the critical section critical section is logged into from inside so this is similar to the room which is logged from inside and no one is present in there also so that similar case have been occurred so have you noticed something there will be so many processes which can be preempted after increasing the value of L so this this may also this may also be the case so what I have said preempt before it can set the value of log equals to one so this is similar like a process one come process one came increase the value of log by one and fail to set the value of log equals to one process two came increase the value of loog by one process three came increase the value of loog by one and all of them all of the process failed to set the value of lock equals to one so each and every process will come increase the value of Lock by one come increase the value of Lo by one come increase the value of log by one and eventually what will happen if the value of log will keep on increasing and increasing and increasing what will happen overflow so this is the similar case so here overflow will occur so there will be so many processes which can be preempted after increasing the value of L so overflow may happen let's say the let's say the integer is of two bytes we are taking the 32bit architecture so let's say the integer value is of 2 by so the maximum value possible is 32,767 so if the number of process are less than this number then this mechanism will work correctly but if the number of process are more than the size of integer you know what will happen overflow okay so this was the case now we have done this question this question and this question now uh fine a fine question can it be possible that a loog equals to 1 which means the critical section is logged no one can go into it until it is the lock is released so can it be possible then critic that critical section is logged and also it is free log equals to 1 and critical section is also free can it be possible so we have already seen that it is possible here in the case lock was one lock was one and critical section was also free because no one was in the critical section P1 has already left the critical section but what happened that P2 when it came it by mistake set the value of lock equals to 1 so this was also done starvation for some process does some process starve obviously the process will starve so now I have important note I have important note for you that unless special focus is given to exceptional case think generally so one of my student come to me and ask this question which of the following algorithm suffers from starvation so I told him that sgf and priority will be the answer but he also said that fcfs should also be there because in some rare cases fcfs also suffers from starvation so I have given me I have been given the solution Manual of of galin textbook exercise so what happened I show in the answer of the actual the authorized authors the galin so there it was given that fcfs doesn't suffer from starvation it inherently doesn't suffer from starvation except the case for infinite Loops so until a special focus is given to exceptional case we should always think generally for this question the answer will be sgf and priority not the fcfs now comes to the blocking mechanisms or non busy Solutions so in the entry section we have a while loop we are talking about the busy Solutions so why busy Solutions were not preferred so in the entry section we have a while loop so have you ever thought how it sus for the CPU to check condition again and again again and again even if in the one check we get an idea that critical section is free or not so this this this V condition is the vage of CPU time in form of Loops so the process in just one check it can get the idea whether critical section is free or not why it has to busy wait until the time Quantum expires why is it so it is wasting its's time so to tackle that we got an idea that the process should test the condition only once if the critical section is free you are free to enter go into the critical section if not it should immediately get blocked it should immediately release the CPU and should get blocked let's let me explain suppose P1 is present in the ricu P1 goes to the CPU start executing the ENT section in ENT section in just one check it get an idea that critical section is not free someone is already present there let's say P2 so what it will do it will immediately release the CPU and should get blocked so that the other process present in the critical section that is P2 should take charge of the CPU so the P2 comes into the CPU start executing its remaining instructions of the critical section so that it can quickly execute critical section come out execute critical execute the exit section and unblock the blogged process let me tell you the story again there were two process P1 and P2 P2 was already present in the critical section okay so P1 wants to also go there P1 goes to the CPU start executing the instruction of Entry section in entry section in just one check it got an idea that critical section is not free P2 is already present there so what it will do it will immediately leave the CPU why so that P2 can complete it critical section see it is a winwin situation for both P1 cannot enter into the critical section until P2 leaves the critical section because only one process can be present in the critical section so P1 wants to to go into the critical section as soon as possible but it will it can only be it will only happen when P2 completes the remaining section of the critical section so instead of busy waiting again and again checking the condition again and again wasting the time of P1 and P2 both why shouldn't it get blocked and let P2 get charge of the CPU so that it can complete its remaining instructions when P2 completes its remaining instructions P1 is also getting benefited because P1 when P2 quickly execute the critical section P2 will come out execute the exit section and will unblock the blocked process so P1 was blocked it will unblock P1 hey even now you can go into the critical section it is free so this is the best case for busy waiting we have used while and in non busy waiting we will use if then else in while what will happen we will go again and again check the condition again and again if then else will only work once condition true then block if false then enter simple and easy so for this blocking mechanism we have three things sleep and wake up SEMA force and monitors so first learn about the sleep and wake up sleep and wake up it is a blocking construct based on the blocking mechanism or non Business Solutions it is a multiprocess solution and it behaves like an primitive like system call which means it is non preemptive no one can preempt it in between it's Atomic so let me tell you the story when the process executes sleep it gets blogged into the Sleep que a new name sleep que till some other process wakes up so let's take this scenario P1 was present in the RQ goes into the CPU start executing the entry section but what happens it checks that P2 is present in the critical section already it goes execute the sleep function sleep function will put the P1 into the Sleep Q so P1 will release the CPU immediately and P2 will take the charge now what happens P2 is in the CPU it completes the remaining instruction of the critical section and exits the critical section now it will exit it it will complete its exit section in the exit section what it will do it will wake up P1 so from the Sleep Q it will put P1 back to the RQ now P1 can go into the CPU do the same thing again checks the ENT section now critical section is free it can easily go into the critical section so this is how sleep mechanism work instead of being there in the CPU checking the condition again and again wasting the time of itself and also P2 it get blocked and let P2 completes its critical section when P2 completes goes to the exit section P2 will put the P1 back to the radic from the Sleep Cube now in the r CU P1 can go check the condition critical section is free and P1 is free to enter critical section so this is how it work now we will see the producer consumer problem but with the non busy solution we are going to do we will convert the busy waiting solution into the non busy waiting solution so what we are going to do we will make the consumer sleep when the buffer is empty and make the producer sleep when the buffer is full okay okay so we are not going to check the condition again and again wasting the time what we will do we will simply check if the buffer is empty consumer go to sleep buffer is full producer go to sleep now it is the duty of producer and consumer for producer to wake up the consumer and for Consumer to wake up the producer process so producer process will wake up the consumer when the first item is placed before that it might be sleeping so and the consumer will wake up the producer when the first item will be consumed so consumer will wake up producer when an item is consumed from the full buffer before that it might be sleeping so these are the four point that you have to remember now let's go to the code so this these were the global variables which we have defined void producer producer in item P item P will be the produced item and initially in was zero so do you remember the producer consumer process in the buffer there are these are this was the bounded buffer and we have two pointers in and out in will be the index of next empty slot for the produced item to be placed and out will be the index of the first empty slot first filled slot the slot from where the consumer can consume so in Empty Out full in is for the producer out is for the consumer I hope you remember that item P so we'll place the produce item into the the item P variable if count equals to equals to N Sleep If count equals to equals to n what does it mean that the buffer is full if the buffer is full no need of producer just go to the sleep if it is not so then place the produced item into the buffer at the empty slot and increase the value of empty slot by one and if it is if it is the last slot then do the circular thing that's why mod n so if this is the last not then go there place it here okay increase the value of counter by one but why because an item is placed and in the end if count equals to one wake up the consumer see we have to wake up the consumer when the first item is placed if the count equals to one which means the first item is placed we have to wake up the consumer let me repeat again declare a variable item P place the produced item at item P if count equals to n which means if the buffer is full make the producer sleep if it is not place the produced item into the buffer increase the value of n by one increase the value of count by one and if the count equals to one which means the first item is placed then we have to wake up the consumer because before that it might be sleeping similarly for the consumer code item c will be the item that will be consumed so if the count equals to zero which means the buffer is empty then there's no need for Consumer to wake up so it just go to the sleep because buffer is empty it cannot consume from empty buffer if it is not then item c will be the item at the buffer so from the out it will consume an item C out will be increased by one and count will be decreased by one see let me uh give you a pictorial representation let me check if it is recording yes okay so let's say the initially the value of count is zero so the consumer will go to sleep producer produce an item and it wakes up the consumer consumer got waked up now let's say this was the item C so the buffer do out this was the first item placed by the producer consumer is now ready to consument so item c will be equals to buffer. out so this will be the item C now we have to increase the value of out plus out plus one so now the out will be this consumer has already consumed this item so we have to increase the value of out if it is the circular case just for the producer just like the producer we have to do the circular thing if it is the last uh item if it is the last item in the buffer then it has to go again to the first item so that's why more than and we have to decrease the value of count because a item is consumed okay so I hope you got the idea now last thing if count equals to n minus one from the full buffer from the full buffer if one item is consumed now what is will be the number of items n minus one full buffer is n items one item is consumed so the item will be nus one so if count equals to n minus1 from the full buffer one item is consumed we have to wake up the producer because before that it might be sleeping and then consume item C see these four things are the main make consumer sleep when the buffer is empty make producer sleep when the buffer is full wake up consumer when the first item is placed wake up producer when the when an item is consumed from the full buffer okay so this was the code now we will analyze it in the next video Let's analyze the solution which we have discussed in the last lecture I have told you so many times Whenever there is more than one statement in the intersection preempt after one let's say there are two statements preempt after one preempt in between that will this will give you so many nice inferences let's check here this is an very very very interesting case Okay so focus and listen there's a cooperation and competition both so is there any possibility of Deadlock or inconsistency let's see so this was the entry section I have told you to preempt here if I preempt here before a process can go to sleep what will happen let's see so I have taken a small buffer of three things of three slots 0 1 and two and initially the value of count is zero n is equal to 3 there are three slots okay so n equal to 3 now what happens at time T1 consumer comes if count equals equals to Z yes count equals to Z initially the count is zero no item is in the buffer so what it has to do it has to make itself sleep but what happens before it can make itself sleep it get preempted here so whenever it will come back it will go to the sleep so whenever process come back whenever consumer get hold of the CPU it will start executing from the next instruction and what is the next instruction sleep so whenever it will come back it will go to the sleep at time T2 producer comes does count equals to n no count is not equals to n count is zero and N is three so it will produce its first item place it in the buffer increment the count now count is one if you remember if the count is one the it is the duty of producer to wake up the consumer so if count is one it will wake up the consumer but consumer never slept so producer will think it has done its work it has done its duty of waking up the consumer but the consumer never slept so what producer will do it will goes back and repeats this until the buffer is full producer will keep on producing item and item and item until the buffer is full buffer is now full X Y and Z these items are produced now count equals to three which is equals to n so if count equals to Wi yes then go to sleep producer goes to the sleep now producer go to The Sleep producer goes to sleep now consumer will get hold of the CPU what consumer will do it will execute it next instruction that is sleep producer goes to producer is already in the Sleep queue consumer also comes in the Sleep queue see this is a very dangerous situation producer will think that consumer will wake her up consumer will think that producers will wake her up and they are both sleeping comfortably in the Sleep ke so this is the case of Deadlock so here I have said producer goes to the sleep thinking that consumer will wake her up as soon as she consumes an item but producer doesn't know that consumer is also going to sleep so both the process are sleeping comfortably with assumption that one will wake the other so this is the case of Deadlock so yes deadlock is there and is there any case of inconsistency yes inconsistency is also also there because producer and consumer tries to update the value of count simultaneously so this is similar to the race condition so what is the solution of this problem this is a very very nice problem that both have gone to the Sleep Queue at the same time producer will think consumer will wake her up consumer will think producer will wake her up and they're both sleeping this was the case of dead dog and and for the inconsistency they tries to update the value of count simultaneously like the is condition p p tries to increase so this is just a case let's say the value of count is five P tries to producer tries to increase it and consumer tries to consume it so the value should be five but we get the answer like six and four I've discussed this so many times this is the race condition so what is the solution of this the solution is SEMA 4 and this is what we practically use we are going to learn more about SEMA 4 in the next lecture let's see what is semap 4 it is a practical inuse tool we use it practically most famous blocking construct OS based that is component of operating system Cal which means the operations are Atomic in nature general purpose utility which means it is used to solve several problems like critical section problem classical IPC problems and concurrency mechanisms it is implemented as an abstract data type like we used to do in the process thing process was also implemented as an abstract data type which has its own implementation and it has its own operations so what are the operations involved in semaphore the first is down and the second is up the down operation what does it do it just decrease the value by one it is also known as weight or p and what does up suggest it suggest it will increase the value by one it's also known as signal or V okay so what is the definition definition SEMA 4 abstract data type that takes only integer values remember this it only takes integer values and for integer value it can be classified into two binary SEMA 4 and Counting SEMA 4 binary SEMA 4 as the name suggest takes only two values Z or one it is also known as MX and Counting seor takes any integer value and it is also known as general semap for so we are going to first see the counting semaphor that is sm4 and the values it take is from minus infinity to plus infinity this is how it it is represented typed F struct int values Q Type L counting sem 4 so the counting sem4 consist of two things the first is it is a structure and it is named as counting S 4 which has two things the first is the value and the second is Q Type L and what does this Q type contain it contains the list of PCV of those process that gets blocked while performing down operation unsuccessfully so what is unsuccessful down operation we are going to see in a few minute so this thing this is Kernel mode and this is user mode so after defining the variable we have to mandatorily initialize it and the initialize value will be it depends on the application whatever value we initialize similarly or accordingly it will work so this means will depends upon application so let's say we have said the counting semap 4 S do value is one so we said the value is one if we perform the down operation then what happens then again it goes to the kernel mode as I said the operations are Atomic in nature so the down operation so this we did the initialization or the Declaration kernel mode setting the values user mode and Performing the operation again on the kernal mode so what does down operation do it decrements the current value of s that is the SEMA 4 so this was s do value we declared a sem 4 accounting SEMA 4 S and we set the value equals to 1 now we are performing a down operation on that counting S4 s so what does a down operation do it decrements the current value of sem 4 S by 1 so what was the value initially it was one so s do Val equal to S do valus one we say that the result is either successful or unsuccessful if it is successful it goes to the next statement if it is unsuccessful it's blogged in the Q so this was I was talking about Q Type L it contains the list of pcbs of those process that gets blocked while performing down operation unsuccessfully so I've said while performing down operation two things can happen either it can get performed successfully or unsuccessfully if it is successfully performed we go to the next statement if it is unsuccessfully performed we are blocked in the queue which Q This Q Type L ql okay so this is the next thing now the question arises how to identify whether we are blocked or unblocked whether the operation was successful or unsuccessful so if S4 do value is negative put the process PCV in the Q that is the Sleep Q and block the process s DOL is this is the Q name you can see here we declared accounting S for S so s DOL this is the que so we will put the process in the queue and block the process which means it's sleeping now else return to the next statement okay so how we get to know that the operation was successful or unsuccessful if the value of counting sem4 becomes negative then it is unsuccessful if the value if the return value is positive or greater than or zero if it is positive or zero then it is successful if negative unsuccessful if positive or zero successful okay now comes the question if we set the value equals to 5 how many down operations can be carried out successfully if the value of count4 is set to five how many down operation can be performed successfully so what we did we start decreasing the value by one so at five We performed down operation successful four how we know it was successful because the value is still positive we decreased it one down operation four another down operation three another down operation two another down operation 1 now let's let's perform another down operation another down operation it is zero now is it successful yes what I said if it is non negative then it is successful it doesn't depend whether it is zero or positive if it is non negative successful so five down operations were successful let's perform another down operation now the value is minus one now we can say the value became negative hence it is unsuccessful okay now another process came and performed another down operation another down operation it becomes minus 2 again unsuccessful so this the process which perform down operation on this and the process which perform down operation on this both get blogged so the number of blogged process are two so there are two process in UL suppose another process which came and performed down operation on this so the value of s will be minus 3 and number of blocked process will be three I hope you got the idea okay so positive value of the SEMA 4 indicate that those many down operations can be performed successfully so what was the value of 74 here s = to 5 so we performed five down operations successfully and after that process starts getting blocked we can also observe another thing here let's say when the value of sem 4 was min2 how many processes were blocked two processes were blocked let's say another process came and performed down operation now the value is minus 3 how many process are blocked now so the process which performed down operation on this did an unsuccessful down operation so this process will also be blocked so the number of blocked process will be three now when the value of 74 was minus 3 so a thing we can notice when it was minus one then one process was blocked when it was min2 two process were blocked when it was minus 3 three processes were blocked so we can give two inferences here positive value of the sem 4 indicate that those many down operation can be performed and after carrying out a series of down operation if the value of SEMA 4 becomes negative then the magnitude of the negative value indicates get the number of blogged process so I hope the point is clear so the first thing says if s equal to 5 these many down operations can be performed and after performing a series of down operation if the value of sem4 let's say is minus 8 then we can say 8 process 8 process are blocked eight process are residing in the ql okay so now let's check another thing so this was the radue now out of these ready out of these three process some process will enter into the entry section so let's say a process enters into the ENT section performs the uh instructions in the ENT section goes to the critical section P1 goes to the critical section and then completes the exit section and then goes out so by doing this what we do how does this sem4 thing how does the sema4 provides Mutual exclusion we are going to see that so out of these three process a process came and performs the ENT section and in ENT section what we do we decrease the value of S 4 by one so initially let's say the sem4 value was X so X down operation can be performed successfully when X becomes zero then the number of let's say uh three down operations will performed so all three process will get blogged okay and let's say the value of initially let's say the value of x was three so 1 two three three down three down operations can be performed successfully so all three process will be successful in performing down operation and they all will enter the critical section are you getting the point let me explain more clearly so initially let's say the value of sem 4 was one only okay P1 got the chance to get hold of CPU and it start executing the instructions of Entry section what is the instruction in the entry section P of s which means down operation of on S so what is the value of s one so it will perform down operation and now the value of s will become zero nice okay it will go into the critical section P1 is still in the critical section and somehow it got preempted now let's say P2 get the chance P2 goes to the entry section will perform a down operation on S equals to0 if s equals to 0 then down operation will be minus one and I hope you remember that if the value of down operation after performing the value of down operation if the value of s is negative then it is an unsuccessful down operation and in the case of unsuccessful down operation we block the process so the process P2 will get blocked it will it won't be able to enter into the critical section same case for the P3 let's say P3 also attemp to go into the critical section so what was the value of s it was minus one it performs another down operation it becomes minus 2 which means two process now P3 is also blocked two process are blocked and only P1 can complete okay now let's see P1 was in the critical section P1 get again chance to get hold of CPU see it start executing the remaining instructions of critical section completes the critical section now V of s what is V of s it is the up operation so what P1 will do it will perform an up up operation so s equals to from minus 2 it will perform an up operation from 2 to 1 what does minus one suggest it suggest that only one process should be blocked so it will wake up another process let's say P2 is waked up now what will P2 do it will start executing from the next instruction it has already executed this so the next instruction is just the critical section it goes to the critical section happily now when it comes out it will perform the up operation when it will perform the up operation this minus one will become zero what does this suggest it means P2 will wake up P3 also P2 exits the exit section now it's turned for p P3 P3 will again resume from where from the next instructions so it will it has already completed this it will go directly in the critical section P3 comes out what does it will do now it will increase the value of S 4 by 1 so one so this is how sem 4 provides Mutual exclusion if one process in the critical section is present then no other process will be able to go into the critical section if they try they will get blocked and they will will be awaken or they will uh come out of the blocked que only when some process completes their exit section so I hope you got the idea let's read this thing also so when P1 was in the critical section and P2 and P3 tries to go into the critical section then they get blocked in the ql and it is a f4q generally so the basic objective of up operation is to wake up a sleeping process so s = to min2 when the up operation was performed it was minus one so what does this suggest P3 is sleeping now and P2 is awake and P2 is awake then it will go to the Rue as you have as you have studied that from the blocked que we go to the RQ so it goes to the RQ and then it will start executing from the next instruction what is the next instructions go to the critical section okay as it has already completed its entry section so what does up operation we have studied the down operation what does up operation look like up on counting sem4 s increase the value by 1 if the value is negative if the value is negative or equals to zero select a process from sleeping que and wake up else return so it is the duty of up operation that if the value is negative or equals to Z then it has to wake up a sleeping process okay so this is what we had done here when the value was increased when the value was increased from 2 to 1 up operation has awaken P2 and when the value was increased fromus 1 to 0 up operation has awaken P3 okay so this is how it work so when P1 is performing up operation indirectly it wakes up P2 and put it into the critical section and when P2 performs up operation it wakes a P3 P3 goes to the Ric and then critical section and then again it performs the operation and for that case for that case when performs the up operation the value is now one see for P3 what was the value for P3 s was already zero so when P3 has completed the exit section which means P3 will perform an up operation on zero so what will be value now one so P3 has performed up operation the value is now one is the value if the value is negative or equals to Z no it is positive so it will not perform the waking up of any process if s equals to Z and then up up operation is performed on it then the process will not wake any process why because there is no process in the slip que because the value of s equals to Z suggest what there is no process in the slip CU and this is what we had written here in form of condition I hope you got the idea so no wake up call if s do value is positive if s equals to Z I have to wake up one more process if the initial value of s was one so mutual exclusion is violated here are you understanding it if the value of su 4 was not one if the value of sem4 was not one see here if the value of sem4 was not one then Mutual exclusion will be violated let's say I put the value of S 4 S2 so what does s = to 2 suggest it means two process can now go into the critical section simultaneously let me show you let's say the value of S4 was 2 P1 comes decrease the value by 1 P1 goes to the critical section let's say P1 get preempted here P2 comes decrease the value by 1 now it is zero see both P1 and P2 has performed a successful down operation so no one is stopping P1 P2 also to go to the critical section so at the same time P1 and P2 are both present in the critical section so this is how Mutual exclusion is violated if the value of sem4 is greater than one okay so this is how semor works this is how the ensures Mutual exclusion in the next lecture we are going to see some of the basic problems of uh up and down operation now let's discuss some super easy questions in the initial value of counting SEMA 4 is 8 and we have to perform these operations what will the final value super easy this is down operation p is down operation and V is up operation for down operation you do nothing but to incre to decrease the value by one and for up operation you increase the value by one so for this what can you do 8 10 + 1 5 + 2 6 + 3 what will be the value you get you get 7 and what does 7 signify it says that there are 17 process blocked in the Sleep G another question counting sem4 what will be the initial value of counting sem4 such that after performing these operations up and down the final value which I get is minus 6 super easy you can do this by two ways either you can make an equation like x 12 + 4 6 + 3 8 + 1 should be equal to 6 you can do do like this or you can just think like that let's say we started with 6 and instead of doing down operation we what we did we did up operation so it's nothing just we started the opposite thing minus 6 for up operation we added and for down operation we subtracted so in this way we get the final value as 12 you can do that from the both ways or directly saying this is the same thing which you did in the equation also okay so the final value which you got is 12 which means if the initial value of sem4 would have been 12 then after performing these series of down and up operation we get the final value as Min 6 another question question consider a non negative counting S 4 S the operation PS decrements s and vs increments s same thing during execution 20 PS operations and 12 vs operations are issued in some order okay the largest initial value of s for which at least one PS operation will remain blocked so for at least one PS operation that remain blocked in the end the value of SEMA 4 in the end should be less than or equal to minus1 for at least we have written this less than or equal to minus1 for exactly one operation one PS operation to remain blocked then value should be minus one and for at least one then value should be less than equal to minus1 so what we did we take the initial value as X so X and how many down operation 20 so x 20 how many up operation 12 + 12 = to S and that s should be less than equal to 1 after performing calculations we get the value of x should be less than equal to 7 so what will the largest value 7 Easy Peasy okay let's see the practical application of sem4 how it is used in Practical life Suppose there is a client server architecture there are several clients and server can manage only 100 request at a time and there are so many clients that they are sending 5,000 request so if all the 5,000 request reach at the server how does server is going to manage them so this problem can be solved using counting SEMA 4 which ensure that only 100 or th000 requests so whatever be the number 1,000 request go and rest wait so what we did we set the value of s equals to 1,000 try to set an analogy or try to set a connection see in the case of process and critical section whatever be the value we set that number of process can go into the critical section here we said that if s equal to 2 then P1 and P2 both can go into the critical section if I said s = to 1 only then only P1 was able to go and rest two of them were blocked similarly think that there are 5,000 processes and it is feasible that only thousand of them can go into the critical section so for that case what should be the value of s so the value of s should be set to th000 so this is how so these processes can be set as clients and the critical section can be sent as server I hope you got the idea so how to set that only thousand process should go into the server so this can be solved as setting the value of counting some of 4S th000 so every request will perform a down operation on S and after it gets served it will perform up then so this is how this will work so when th000 down operation will be performed or when th000 request will go to the server for uh servicing then 1,1 request will be blocked because the value is set to, so this is how it works okay in the next lecture we are going to see binary SEMA 4 Counting sem4 is complete now so we should make a revision so how does counting sem4 work type def instruct what is the use of type def to give it a name so we give it a name as counting se4 so counting se4 is two things values and Q the value mean what is the initial value of counting sem4 let's say for the client server architecture the initial value was 1,000 okay so this uh declaring is done in the kernel mode setting up the value initializing is done in the user mode and we have to mandator initialize it let's say we initialize that to th000 so th000 process can go into the critical section so it has two operations the first is down and the second is up for down operation what you have to do you have to decrease the value by one and after decreasement if the value becomes negative then we have to put the process into sleep Q else go to the next statement and how we get to know that the process is process has performed a successful or unsuccessful down operation the down operation is successful when the value is non negative and it is unsuccessful when the value is negative okay so we have seen everything how it is ensuring Mutual exclusion and then we will see up operation and what you have to do in up operation increase the value by one if the value is less than or equals to zero which means we have to select a process and wake it up from the sleeping quebe otherwise else return okay let's start the binary semap 4 binary semap 4 can takes only two value either zero or one so how it is declared type def struct type def for BM because we want to rename it and struct because it is a structure which contains two things just like the CM now we have to use enum why enum because this variable value of type enum can take only two values either zero or one it is a binary semore and it can take only two Val vales either 0 or 1 it has a sleep que similar to the counting semap 4 which contains the list of all those processes PCB which fail to perform perform an successful down operation okay so while performing down operation there are only two possibilities because the value of s can be either Z or 1 so when down operation is performed on zero the value will still remain zero it won't become minus one because it is a binary semap 4 so the value will still remain zero and it will be blocked but if the down oper operation is performed on one the value will become zero and success it won't get blocked okay so there are only two possibilities while performing down operation you can get on zero the result will be zero but for one case the process will be blocked and for another case it will be successful user mode binary sem4 we have to initialize it we can initialize it from either zero or one if it is initialized to zero which means no process can go into the critical section if it is initialized to one which means only one process can be in the critical section at a time okay so we have to perform down operation and if the down oper operation is successful we go to the next statement so what is down operation down on binary sem 4 S if the value of s is 1 set the value to zero return else put the this process PCB in sleep q and block it so this is what we are doing while performing down operation if the value is one then set the value to zero return return where return to the next statement otherwise put this process PCB and block it what is the otherwise case this is the case if the value of s is not one which means the value will be zero if it is zero then block it if it is zero put this process PCB in the slip Cube while performing dou operation okay so it will never take negative values we won't know how many processes are blocked there okay so in counting semaphore when we used to do down operation the value of s keep on decreasing as I have said in the previous video uh in one question we get the value of s is minus 17 so we can easily identify that there are 17 processes sleeping in the block Q or 17 process blocked in the cing both are the same but here we can only see the value of s s either 0 or 1 if the value of s is z we cannot tell how many process are there in the sleeping queue because it won't take any negative values okay so let's see this scenario there are three process present in the radue and they are both eager to go into the critical section and they are all eager to go into the critical section let's say a process P1 gets a chance to get hold of CPU start executing the instructions of Entry section performs the down operation on S performs the down operation s now it becomes zero goes to the critical section is it still in the critical section but somehow it get preempted P2 wants to go into the critical section performs the down operation on zero and if the down operation is performed on zero what happens it get blocked so P2 is blocked now P3 comes what is the value of down what is the value of s it is still zero P3 comes to the entry section start executing this down operation but again when the down operation is performed on zero it will also get blocked so there are two processes blocked but the value of SEMA 4 is zero so by seeing the value of semor in this case we cannot tell how many process are blocked but this is somehow providing Mutual exclusion because when P1 was in the critical section P2 and P3 were unable to go into the critical section so what will happen P1 completes the instructions of critical section comes out of the critical section goes to the exit section and what and what does it will do it will increase the value by one so what is vs increase the value of sem4 by 1 so the value of sem 4 will be directly increased to one will this happen let's see let's see so if there is a process in either critical section or block Q the value of SEMA 4 must be zero must be zero if the process is in either critical section or block Q the value of S4 must be zero so how will up operation will be performed for up operation check if there is no block process then the value set value to one and and if there are block process in the block Q then wake up a process and send it to the critical section are you getting the point see let's say the value of s at some point is zero can you tell me by seeing this how many process are blocked in the uh sleeping queue can you can you tell me no it is not possible so how can you directly increase the value of s to one by performing up operation when there are still processes present in the sleeping queue you can't so we are going to check it first if there is no process in the sleeping queue what we are going to do we are going to just increase the value by one and if there are process present in the sleeping Q then what will will do we won't increase the value directly to one for up operation we will we are going to wake up a process from the sleeping key just wake up the process no need to increase the value of s okay so this is what we are doing here how will up operation will be performed if there is no block process then value of s is 1 if there are process in the block block you then wake up a process and send it to the critical section why we are sending it directly to the critical section because when a process get blocked it has already completed the instructions of the critical section and when it will come again it will resume from the next instruction what is the next instruction critical section so it will go directly into the critical section so this is how up operation is performed up on binary sem 4 S if sleep Q is not empty select a process from L and wake up and if it is empty select set the value of s to one so for performing down operation we had two possibilities if the value was Zero block it if the value was one decrease the value and success go to the next instruction But Here If s equals to Z again two possibilities set it to zero and when when the Q is not empty and select a process and wake it up if Q is empty set the value to one and remember one thing whether it is a case of binary sem 4 or counting SEMA 4 up operation is always and always successful for the case of down operation the thing of success and unsuccess is defined up operation is always successful down operation is somewhere sometimes successful and sometimes not when successful I've already told you so what does s equals to one suggest s equals to 1 says critical section is free and the Q is also empty and what does s equal to0 suggest it says a process is is either in the critical section or in the block Q okay so if s = to 1 and and some say let's increase the value or uh perform an unop up operation then the value will remain one only because it is a binary S4 it can take only two values either 0o or one so performing an up operation on one will result in one only it won't increase it to two because it is a binary sem4 okay for S = to 0 up operation if it is the first operation so if it is the first operation then it logically means that Q is empty what I'm saying here is the value of s is set to zero and up operation is the first operation which means that the Q is empty because it is just the starting of the thing so in that case the value of s will be directly set to one and the status is Success so the up operation will be always successful and what do s equal to one suggest critical section is free and Q is empty s equal to0 says a process is in either in the critical section or block q but if we are directly saying s equals to 0 we are performing an oper up operation what will be the value we cannot directly tell if it is the first operation then we can directly tell s equal to 1 because the Q will be empty and if it is not the first operation we have to see whether Q is empty or not then we will tell what will be the value when up operation is performed on zero okay you got the idea process never get blocked while performing up operation can get blocked while down whether it is counting or binary semop 4 I have already made this point this sleeping Cube which we are talking about here is dynamic of course dynamic because a process comes performs the down operation and get blocked if it is not Dynamic if it is not Dynamic let's say there are only two slots present process one came get blocked process two came get blocked p 0 was already in the critical section so P1 came get blocked P2 came get blocked now what will happen if the P3 come it should also get blocked in the same Q so for that thing we have kept this sleeping Q as Dynamic okay let us revise and then we will solve the question so for binary semap 4 it can take only two Val either 0 or one if the value is zero if the value is zero what does this suggest it says that critical section is not free or a process is in the sleeping Cube okay and if it is one it says critical section is also free and there is no process in the sleeping okay it has two operations just like the counting semor down and up but there their working is different in down operation there are two possib ities if the value of sem4 is 0 or one if the value of sem4 is zero and we are performing a down operation block the process which means what does zero suggest appro critical section is not free so when a down operation will be performed on zero which means a process is wants to go to the critical section when it is being acquired by some other process so what we have to do we have to block that process if it is one what does that mean critical section is free so just decrease the value and it is Success okay and how up operation will be performed if there is no block process if the Q is empty if the Q is empty increase the value by one and what does one suggest critical section is free and if the Q is not empty wake up a process select a process from the que and wake it up so this is how down and up operations is get performed now now comes a question binary sem 4 S is set to one initially and there are several or there is a series of up and down operation 10 down operation 2 up 18 down 3 up 4 down five up okay so what will be the value of s now you cannot directly do this 1 10 + 2 + 18 now you cannot directly do this we have to keep track of number of process in the block Q so how this will happen let's say s = to 1 and what we are doing we we are performing 10 down operation so what will happen there will be nine process in the block you see P1 process will be able to go into the critical section and P2 P3 till P10 will be blocked okay now what happens two up operations so for two up operation this P2 and P3 will be waken up by the process so P2 and P3 will be waken up and we are performing 18 down operations again so what will be the uh status of Q here P4 to P10 now 18 down operation so P4 P5 to p28 three up operation P4 P5 and P6 will be waken up so p7 to p28 now four up operations four up four down operations which means p7 p8 from p28 four new process will come and join this sleep que so p32 five five operations so p7 p8 P9 P10 P1 will be wck so from p12 to p32 these process will be in the sleeping so what will be the size of Q size of uh Q the size will be 21 and what will be the final value s = to 0 I hope you got the point how we are doing this let me explain again see we cannot directly do like this I hope you know why we can't directly do like this because this is a binary sem for it can take only two values either 0o or one so when s = to 1 and we have performed 10 down operations so P1 will be able to go into the critical section rest process will get blocked so P2 P3 and P10 will get blocked now we have performed two up operation how does up operation work we see whether the Q is empty or not Q is not empty so when Q is not empty the value remains zero but what we do we wake up the two process from the Sleep Q so we wake up P2 and P3 will be waken up P2 and P3 will be removed from on the sleeping quebe now P4 P5 till P10 is in the sleeping queue we performed 10 down operation which means 18 new process came and get blogged so these process came and get blogged now what we do we perform three up operation what happens the value is zero and the Q is not empty so we will select three process and wake them up P4 P5 and P6 will be removed and from p7 to p28 they will be in the sleeping queue four down operation four new process came and join this queue p32 five of operation five process will be removed from this queue p7 p8 P9 P10 P1 and from p12 to p32 they will remain in the Sleep C and what is the value zero okay and what is the size 21 and the value is zero so I hope you understand what is sem 4 how does it work what is counting SEMA 4 how up and down operation works both in counting and binary SEMA 4 why we cannot increase is the value of binary S 4 just like as we did in the counting S 4 so these were some basic things which you should know let's see if semap 4 provides Mutual exclusion bounded waiting in progress or not in the previous lecture we have seen that counting SEMA 4 with s equal to 1 or binary SEMA 4 provides Mutual exclusion okay now let's okay let's see again how does it provide a mutual extion just for the sake of revision first P1 goes to the critical section by changing the value of s from 1 to 0 okay P1 is still in the critical section but somehow it get preempted now P2 wants to go to the critical section so first it has to pass the entry section in entry section it has to perform down operation on S equals to0 the value will remain zero but P2 will get blocked similarly if P3 also wanted to go to the critical section it has to first pass the entry section and the value of s is still zero so when it will perform down operation what happens is P3 will also get blocked so if a process is already present in the critical section it has changed the value of s from 1 to zero and if some other process wants to go to the critical section at the same time then s = to0 will prevent them from entering because performing a down operation on S equal to 0 the value will remain zero but the process get blocked so this is how Mutual exclusion is ensured now let's talk about progress suppose P1 P2 and P3 were the three process present in the ricu P1 and P2 were the interested process and P3 was not interested to go to the critical section so I have told you several time that a process who is not interested to go to the critical section will never ever enters the entry section so P3 will never enter the entry section P3 will never perform a down operation on S so P3 will never bother P1 and P2 it will not become hindrance in the path of P1 and P2 if P3 is not interested she will not bother about us so in that case progress is also ensured let me repeat again Mutual exclusion is ensured because of value of s equal to Z if some other process tries to go they will get blocked progress will be ensured because P3 will never ever enters the entry section so it will never bother P1 and P2 okay now comes the interesting part let's check if P1 can enter into critical section again and again while other interested process are sleeping can it happen which means does it provide bounded waiting let's check so P1 P2 and P3 were the three process present in the ricq interested to go to the critical section okay P1 initially the value of s was one P1 goes to the ENT section section change the value of s from 1 to 0 present in the critical section now somehow it got preempted here P2 attempts to go to the critical section by first passing from the entry section but what happens from zero value will remain zero but P2 will get blocked so P2 is in the sleeping Q now P3 also attempts so P3 also performs done operation the value will remain zero but P3 will get blocked okay okay now P1 get the chance of CPU again it started it execution it performed the remaining execution of critical section goes to the exit section and then in the exit section what will it will do it will wake up P2 and put it back to the ricq okay by performing the exit section P1 is free now but it it is still in the CPU so what it will attempt it will attempt to go to the entry section again again P2 is in the ricq P3 is sleeping and P1 is in the CPU okay the value of s is zero now so when P1 tries to go to the critical section by first passing from the entry section what happens the value will still remain zero but P1 will get blocked because the value of s was zero so now P1 is blocked what happens P3 is sleeping P2 is in the ricu and P1 has also joined P3 so P3 and P1 are in the Ric are in the sleeping q and P2 is in the RQ P2 will get now chance of the CPU will start its execution from the remaining instruction from the next instruction so what is the next instruction the critical section itself so P2 will go to the critical section now so this is how we have preent prevented pre P1 to go to the critical section again and again if a process attempts to go to the critical critical section again it get blocked so this is how bounded waiting is also ensured and semaphor we are given with two semaphores s and t both initialized to one and two process process I and process J in entry section we have down on S down on T and here in process J we have down on T and then down on S for exit section up on T upon on S here up on S and then up on T so the question is does it guarantee Mutual exclusion and what about deadlock okay so for that we has to preempt somewhere in C and I have told you several times that whenever there are two statements in the entry section preempt in between so you remember the note so we going to preempt here initially the value of s is one and value of T is also one so let's say the first process I tries to go to the critical section goes to entry section down on S the value of s is now zero preemption process J comes down on T tal to Z okay preemption now process I again down on T the value of T is already zero so when it perform down on T process I will get blocked now it is the chance of process J down on S the value of s was already zero P process J will also get blocked so if preemption occurs here in the both process and then the other process continue from the next section both of the process gets blocked and there is no one to wake them up because in sem force it is the duty of other process to wake the sleeping process and here both the process are sleeping comfortably who is going to wake them up so this is the case of Deadlock so when preemption happens here Pi will be blocked and PG will be blocked too is deadlock present yes deadlock is present now the question is does it guarantee Mutual exclusion let's see so first what happens the case is again from the starting s = to 1 and T = to 1 process 1 goes to the critical section change the value of s to 0 change the value of T to 0 goes to the critical section somehow got preempted before it can complete the critical section now it is the chance of process J to go to the critical section attempts down on T get blocked so if a process is already present in the critical section the other process can not go so does it does it guarantee Mutual exclusion no it is not possible you can preempt anywhere in check Mutual exclusion is present and Deadlock is also present so deadlock is there preemption between the two of the down operations now the question arises if I preempt between these two down operation deadlock happens can something be done that even I preempt after the first instruction that headlock is saved can something be done think about it pause the video think about it can something be done yes the sequence of both the process performing down operation should be the same in above question the sequence was reversed that was the case when deadlock was occuring let's see if the sequence of both the process performing down operation is same so we are taking the case this to thick m p of s p of T and here P of S and P of T not changing the sequence now when s = to 1 comes to this it changes the value of s to0 we are preempting here now it is the chance of process J process J again start with performing a down operation on S the value of s was already zero so this process will get blocked I hope you are getting the point deadlock was occurring because the sequence was different if the sequence was same PS is PS will will perform the down operation on S and then process G when tries to do the same it gets blogged so this is how deadlock can be preempted if the sequence is different okay so this was a nice question let's move to the question number two byus semor s = to 1 and tal to 0 so now we have two sem fores s and t the value of s is initialized to 1 and T to Zer there are two process process I and process J okay this is the critical section and these are the entry section entry and exit section respectively entry and exit section respectively okay so the question is what is the regular expression that gets generated when these two work concurrently suppose firstly process I wants to go to the critical section p on T which means if the value of T is set to zero it is necessary that process J should start first because if process I tries to start first it gets blocked so process J will start first s = to 1 PS it will perform a down operation on S the value of s will now be zero goes to the critical section print 0o print zero okay so what does this suggest this suggest that the regular expression that will be generated in that regular expression zero will be printed first okay now the case can arise can I preempt here and start from this no because until the value of T is increased 1 cannot be pred so first two Z will be there okay so I have written I explained the same thing s = to 1 and T = to 0 if tal to 0 if this tries to go there it get blogged so firstly we have to start with PJ s = to 0 both are printed now when the value of t equal to 1 is there so when this both 0 and0 will be printed and then the up operation will be performed on this SEMA 4 T when the up operation will be performed the value will be one okay so now we can go there perform down on T now the value will be zero then print one and then print one so now again the question arise can I preempt here and then from Start From Here Again can it be possible no it is not possible because the value of s was changed to Zero by this statement so 0 will not come again until this vs is executed let me speak again from the beginning so first we'll start from here print two zeros make the value of T2 1 we'll start from here print 2 one and then we will change the value of S2 again 1 okay so the answer will be 0 0 1 1 0 0 1 1 and this will keep on going on okay so 0 0 1 1 plus repeat so this will this is the regular expression that will be generated okay so I hope you got the point we are going on alternatively because of these in process I we are performing a down operation on T but up operation on S similarly in process J we are performing down operation on S but up operation on T so this will ensure the alternative printing of 0 and one so for Zer and then ones Zer and then ones and why not 1 1 0 0 1 1 0 0 why not this because the initial value of T was set to zero okay now the question arise does it ensures Mutual exclusion progress and bounded waiting let's check Mutual exclusion is ensured because until a process increases the value of t or s or I can say until a process completes its exit section other process cannot start to go to the critical section this is clear so mutual exclusion is ensured does it provides progress let's check suppose suppose PJ is uninterested to go to the critical section if PJ is uninterested can Pi can go no let me speak again PJ is not interested to go to the critical section so PJ will never ever go to the entry section will never ever go to the exit section and will not increase the value of T and if the value of T is zero then Pi can also not go to the critical section in this way an uninterested process is hindering the progress of interested process so progress is not guaranteed progress is not there bounded waiting can a process go again and again again and again again and again while some other interested process is waiting no we have seen that alternation is ensured first 0 0 then 1 one then 0 0 then 1 one so yes Mutual exclusion ured progress not and bounded waiting is ured okay so we can say that Mutual exclusion there progress not there and Boundary diving implication of a strict alternation Pi cannot enter until PG exits from exit section so this is this was an also a nice question let's move to the question number three we are given an array of binary S 4 we name it as M and it it consist of five elements and all initialized to one so m0 initialized to one M1 initialized to one M2 initialized to one so in this way till M4 it is initialized to one so there are five binary s fors all initialized to one now there are five processes also from 0 to 1 so p 0 P1 P2 till P4 are the five processes involved in this question and we are given a code of each process also while one p of MI i p of m i + 1 mod 4 critical section so this is the entry section and this is the exit section so we should write the code of first process to get a better understanding so we are writing the code of p 0 here okay p 0 the first statement will be P of m0 which means for process0 the binary S 4 value will be decreased and for p of M1 which means the binary process the binary semaphor of process one process one will also be decreased to zero so if p 0 tries to go to the critical section m0 will be made zero M1 will also be made zero okay goes to the critical section performs an un up operation on both m0 and M1 so this is how a process is working and why this percentage mode for for the circular thing for case for this case when we are writing the code of P4 then we are thinking we are talking about P4 and p 0 so that's why we are using a mod for the circular thing okay so p 0 and P1 for this p 0 uh I should write this m0 and M1 for p 0 M1 and M2 for P1 M2 and M3 for P2 M3 and M4 for P3 and M4 and m0 for P4 this is how it works okay so we are writing the code for P1 also M1 M2 critical section M1 M2 I hope you got the idea okay so what I was doing I was explaining the question so now the question is what is the maximum number of process that can be in the critical section so what is the maximum number of process p 0 Let's first start directly P0 wants to go to the critical section decreases the value of m0 and M1 is in the critical section let's say preemption happens here P1 tries to go to the critical section P1 will get blocked because p 0 has decreased the value so P1 will get blocked now let's talk about P2 can P2 enter P2 can enter because it doesn't contain m0 or M1 so P2 can enter P2 will change the value of M2 and M3 to zero now let's check for P3 can P3 enter so M3 and M4 is included in P3 but P2 has changed the value of M3 so for this reason P3 will also get blocked now the question for P4 can P4 enter no because m0 was made to zero so P4 will also get blocked so p 0 and P2 can be in the critical section at the same time Mutual exclusion not guaranteed so the question was what is the maximum number of process that can be in the critical section two okay I think I should explain the question from the beginning again and should give you a brief idea again so the question was we have a array of binary sem4 forget about this we are given with m0 and M1 that will be included in the code of process p 0 so when p 0 tries to go to the critical section it decreases the value of two binary semaphores itself and the other one so m0 and M1 will be made to zero for case of P1 M1 and M2 will be made to zero so in this way the thing goes on now the question is how many processes can go into the critical section at the same time that's what we are checking so for case of p 0 it decreases the value of m0 and M1 to 0 when P1 tries to go due to P0 this Mischief P1 cannot go P1 will be blocked now for the case of P2 can P2 go yes there's no one blocking P2 M2 and M3 will be made to zero and P2 will pass can P3 go to critical section no because P2 has made the value of M3 to0 so P3 will also be blocked can P4 go P4 will also not be able to go because the value of m0 was made to Z by p 0 that's why P4 cannot go to the critical section so the two process which can go are P2 and p 0 and P2 I hope it's clear now or you can do like that also uh let's start with P1 if P1 can go to the critical section then apart from P1 P3 can go and D all will be blocked okay so this is how this work now Mutual exclusion is not guaranteed the question number two does it uh suffer from deadlock let's see what happens is as there are two instructions in the critical section we say preempt in between so we preempt it from here here here here and here this is a dangerous Case C if I preempt it from here the value of M will be Chang m0 will be zero if I PRT it from here the value of M1 will be Zer and for this case M2 will also be zero for this case M3 will be Z and for this case M4 will be zero all of them are made to zero all of the process for perform their first instruction and get preempted and they will wait on each other for their second instruction they cannot go the c p 0 performs the first instruction okay and get preempted P1 performs the first instruction and get preempted so the value of binary sem4 is now zero for all of the M when p 0 will start performing this it will get blocked when P2 will P1 will start performing this it will get blocked for P2 blocked in this way P3 and P4 will also get blogged all of the process are now blogged and no one is there to wake them up so this is a case of Deadlock let's see another interesting question binary semap 4 S T and z are given so the initial value of s is 1 and T and z are zero so what can you say by seeing this only you can say that whichever process which is using T and Zed as their semap 4 in their entry section those process cannot start first so PJ and PK cannot start first so Pi will be bound to start first because the value of s is one okay this is the entry section this is the exit section and this is the critical section while one which means Pi can run again and again PG and PK will run only once because they don't have any while loop here okay so let's see the flow Pi while one it will change the value of s20 print and star and then it will invoke pi and PK PG and PK so it will change the value of T from 0 to 1 Z from 0 to 1 enabling PJ and PK to run okay so now the value of T 1 T = to 1 will be changed to zero in this statement and then VSS so now PJ and PK PJ and PK are helping pi to run again and again okay now the question is what is the minimum and maximum number of stars that can get printed can you tell me the maximum and minimum number of stars see Pi is helping PG and PK and PG and PK are helping pi to print more and more stars so initially the value of s was one changed to zero but here the value value of s was again changed to one and then when PK will run after PJ it will perform an an up operation on value one performing an un operation up operation on value one is going to waste that up operation because up the value will remain the same so this is the main point that you have to focus upon that you cannot increase the value more than one if this is the case you are wasting an up operation here so why why can't you fit Pi again in between to get the maximum number of stars what I'm saying is if you perform like this Pi PJ and PK and then Pi you are getting two stars and but if you doing like this Pi PJ and then you are enabling Pi again here pi and then PK and then again Pi you are getting three stars here okay if you're feeling difficulty in it let me give you a nice explanation here okay initially the value was set to one it will go here change the value to zero print an star change the value of VT and v z to one so now the value of T is 1 and Zed is 1 this operation will be performed the value of T will become zero now and value of Z will become zero okay now vs so the value of s was initially zero it will change back to one and then if you perform directly PK after PJ then this the value was one up operation will performed on one the value will still remain one and then if you try to perform Pi again the value was one it can go again there print another star and then we'll change the value of VT and VZ back to one but even after VT and VZ even after T and Zed are one again these process cannot run because there is no while loop in in them they are destined to run only once so these will not run again now when p p tried to run again it cannot run the value was Zero okay so in this way only two stars can get printed okay but now what we are doing we have enabling Pi here also so when pi will be performed here let me uh give you an idea so we have enabled Pi here Pi will run first change the value of s to zero and then it this will run change the value of s to one again now if we if we use Pi here the value of s will be changed to zero and then we use PK it will change back to one and then we can use again Pi here by using pi in between PG and PK we are utilizing an up operation that was being wasted in the previous case so this is how we can get maximum and minimum number of stars let's see another variation of this question in which we are not using VZ here this is the question okay so here in this question we are not using VZ here there's no VZ here so what are we doing Pi is enabling PJ PJ is enabling PK and PK is again enabling Pi so in this case a type of cycle is being formed so what will happen now now s equals to initially was one will be changed to zero one star will be printed PJ will be enabled and then PK will be enabled Z will be changed back to zero s will be changed back to one again P will run another star will print and then value of T will be changed to one but unfortunately there's no while loop in P PG and PK so PG and PK cannot run again cannot increase the value of s again that's why two stars will be printed only in every case which means the maximum and minimum number of stars that can be printed were only two okay so this is an homework question what does this say consider a counting SEMA 4 initialized to two there are four concurrent process Pi PJ PK and pl the process pi and PJ desire to increment the current value of variable C by 1 so p i and PJ will increase the value of C by 1 whereas PK and PK PK and pl decrement the value of C by 1 PK and pl will decrement by one minus what can be the minimum and maximum value of C after all the process finish their update and remember the value of counting sem 4 is two so value of counting sem 4 was two pi and PJ wants to increase the value and PK and pl wants to decrease the value okay and a process will execute only once there's no while loop now you have to tell what is the maximum and minimum value of C after all the process finish their update okay so you can write the code of process like that process X increment decrement increment and then C = to C+ 1 depends on the process for I and J the value will be plus and for K and L the value will be minus and this is not a single operation it consists of three micro operation load increment decrement and store So based on this you have to think where to preempt where not and then you have to tell me the maximum and minimum possible value of C after all the process finished their update okay let's see some more questions consider three processes using four binary sem4 a b c and d in the order shown below which sequence is a deadlock free sequence Okay so so we need to preempt in such a manner that in any preemption cases even one of the XY Z is able to complete then it is deadlock free and if not then deadlock is present so we are given with binary semop fores which means they are all initialized to one initialize to one okay so we need to see which sequence is deadlock fore so let's start with option one PA a value a changeed to zero PB value B changed to zero and PC value C changed to zero okay now PB it will get stuck here PC will get stuck here and PD value changeed to zero PC will get stuck PD will get stuck and Pa will get stuck so all of them are stuck this sequence is not deadlock free so this is how you have to attempt let's move to option two PB uh change to zero then again PB stuck PA change to zero PA a stuck PC change to zero now again PC stuck PC stuck PD change to zero and then again stuck now what you can see all see all of them are not stck like in the case one what will happen now PD will start executing so the process with sem4 d will start executing because this process has not been blocked so PD is going to release its sem4 at some point so when it will release this D from block block state will come back and when this will come back D will be going to execute it coming back there at this line okay so this C let me use some different pen this C is going to be executed because this is not blog so it's going to release release its semaphor at some point so what will happen this C this blogged c will come back to life okay so this has this has completed this has completed and this has already been uh has never been blocked so all of these are completed so this sequence is not deadlock free you cannot preempt in any case which you want and lead to a deadlock this won't happen Okay so this sequence is deadlock free I can guaranteed say that option two is deadlock free let's check for some more options B will change to zero c will change to zero a will change to zero then deadlock okay so this is not deadlock free obviously a will change to z c will change to zero blogged B will change to Zero blogged D change to zero c blogged d blocked a blocked so this is again going to lead to deadlock so option two is the deadlock free sequence okay I have explained it here also so because how option two is not deadlock because it's going to release the resources it SEMA 4 at some point later so it will change the value back to one okay so this is how this is not deadlock free it's time for the homework problem so each of the set of n process executes the following code using two semaphor A and B so there are two semores A and B A is initialized to one b b is initialized to zero and there is a shared variable named count which is initialized to zero and it is not used in code section P so there is a code section P then some lines of code and then code section Q what does this line of code say perform weight on a and then increase the value of count if count equals to number of process then signal on B signal on a weight on B signal on B so let me explain you more uh clear way let's say there are three process P1 P2 and P3 okay so P1 first performs the code section P now it has to perform weight on a so it will change the value of a from 1 to Z the value of count will be increased the value of count will be increased and this won't be performed because the value of count is not equals to one perform signal on a we perform signal on a change the value of a to one and wait on B see the value of B was initially zero so this will be blocked another process comes let's say P2 comes goes to the code section P perform weight on a same thing goes to code section P perform weight on a does the count equals to number of process no increase the value of a and get blocked okay now another process P3 comes performs code section p P perform uh weight on a so the value of a will be changed back to zero does the count equals to the number of process yes now the count is equals to number of process change the value of uh B to 1 signal on B We performed signal on B signal on a we change the value of a back to one and then perform weight on B We performed weight on B and then signal on B and then performed the code section Q So based on this you you have to answers you have to answer or choose among these of the four options the first option says it ensures that no process execute code section Q before every process has finished code section P it ensures that two process are in code section Q at any time it ensures that all the process execute code section P mutually exclusively it ensures that at most n minus1 process are in code section P at any time so out of these four options you have to select okay so this is a homework question now this is an interesting problem consider two functions increment and decrement increment goes like this weight on S increases the value of signal on S weight on S decreases the value signal on S and the initial value of x is given as 10 five process invoke increment and three process invoke decrement X is a shared variable initialized to 10 okay so there are two cases case one and case two case one says the value of s is set to one and it is a binary semap 4 and case two says the the value of s is set to two and it is a counting S 4 so what can you infer from this for case one we have to do sequential execution and for case two we can let two process enter into the critical section and for these two cases V1 and V2 are the values minimum possible values of the implementation of in i1 and I2 then chooses for the value of x for V1 and V2 okay so V1 and V2 are the minimum possible values of X when i1 and I2 are implemented so we have to now tell the value use of V1 and V2 so how how are we going to approach this question let's say there are five process P1 P2 P3 P4 and P5 interested for the increment and three process P6 p7 p8 interested for the decrement okay so the weight this is the increment function weight on S increases the value signal on S but this is not a single single statement this consist of three micro operations load increment and store similarly wait on S decrement load decrement store and signal on S so this is how it work and for case i1 the value of s is one which means we have to do sequential execution okay so P1 will come increases the value P6 will come and decrease the value so anyhow they perform in any order the value will remain 12 why 10 was the initial value five process for incrementation and three for decementation the value will remain 12 no matter how what is the order of these process let's say P1 and then then P6 and then p7 and then p8 and then P2 and then P4 and then P3 and P5 no matter what be the order the value for case 1 will be 12 the minimum value will be 12 okay or I can say the maximum will also be the 12 because no matter how the process executes the value will remain 12 I have already told you so the the minimum and maximum is the same for case two the things get interesting because now there are two process that can be into the critical section okay and if there are two process in the critical section what will happen the rise condition two process will raise to update the value of s of X and if two process raise to update the value of x we should let the decrement one win so that we get the minimum possible value of uh X so what are we doing we are making these process race P1 and P6 and let P6 win P2 and p7 and let p7 win P3 and p8 and let p8 win and then P4 and P5 will run but do not let them run individually we are going to race between them also for P4 and P5 we will let any of them one win so what will be the value 10 and then P6 win so 9 and then p7 win and then 8 and then p8 win and then seven and out of these two anyone will win so eight again so the final value should be8 so the value answer should be 12a 8 but don't be too don't be in too hurry to take the answer because this is wrong why it is wrong see we are going to we are letting two process race so what are we basically doing we are wasting P1 P2 and P3 we are intentionally wasting P P1 P2 and P3 by fighting it to P6 p7 and p8 so P1 P2 and P3 are wasted and among them we have uh made any one of them win so the final value should be it how it is wrong let me tell you let's say initially P1 and P6 were in the fight P1 has completed its load increment and store but what happened P6 P6 has completed its load liement but somehow it has not stored its value in critical section the two process which were there in initially was P1 and P6 P1 has completed and changed the value of x from 10 to 11 and P6 is still in execution it has not executed its instruction 3 so the store instruction is not executed by P6 now what will happen P1 will go out and P2 will come P2 will increase the value again from 12 but P6 has has intentionally not completed its third instruction that is stored okay now what will happen P2 has completed all these three instructions and then P3 will come P3 will change the value from 12 to 13 but P6 is doing some mischief and it is not executing its third instruction so store will now also not executed P3 has changed the value to 13 now it is time for P4 P4 came changed the value from 13 to 14 P6 is still not P6 has still not executed in store now it's time for P5 P5 completed the value has changed to 15 now the value of x is now 15 but P6 has still not executed its instructions now what will happen when P5 has stored P5 is stored the value of 15 now P6 comes and say Hey I want to store the value so the OS asks P6 what is your value P6 says when I was doing my computation I did on like this so now the value which I want to store is nine so P6 is going to store the value from 15 to 9 see this uh see the cunningness of P6 from 15 it has changed back to it 9 now p7 comes now p7 comes and then among p7 p8 they have made such a uh coalition between them that p7 says hey p8 you first decrements the value p p says okay so it's it has stored the value 8 now p7 says now I will store now so the minimum value is now 7 that's why I have said don't be hurry to take the answer because 12a 8 was also present in the option so many of your students must have chosen this but the correct answer is 12a 7 so this was the question from the gate examination of India amazing question okay so this I have written everything in form of statement so that it would be easy for you to read again for revision purposes so initially s = to 22 process can be in critical section at the same time let them raise to update the value of x and then always makes makes the decrement one win so this was our first approach so among P6 and P1 and P6 we made P6 win P2 and p7 we made p7 win and then among P4 and P5 we made anyone win so the final value which we thought of is eight but this was wrong then a idea pop into our mind that is it necessary to store the decreased value of count after only one increment so let all P1 P P1 P2 P3 P4 and P5 increment it to 15 and now P6 stores its value from that is X = to 9 and then p7 P had come X = to 7 is the final answer if you want more clarity or another way of of proceeding I have written this you can read this same thing but uh some different way to uh Express okay in the next lecture we are going to see some classical IPC problems producer consumer now this now the correct implementation reader writer and dining philosophers okay let's discuss the homework problem first and then we'll move to the producer consumer problem okay so we were given with a variable C equals to Z initialized to zero and two process pi and PJ wants to increments the value of c and PK and pl were wishing to decrement the value of C we have seen that counting Su of 4 S = to 2 means two process can be in the critical section at the same time and in this question we had to find the minimum and maximum value of C so for minimum value we will put these two in the critical section and let both them race and make pkin similarly we did in the last lecture last question we make them PJ and P PG and pl race and let PL win so the value minimum value will be min2 okay and for incrementing part for the maximum value what we'll do we'll make pi and PJ win so the maximum value will be two minimum value will be min2 and if I say binary SEMA 4 instead of using counting SEMA 4 you are using binary sem 4 S = to 1 then what will the minimum and maximum value the minimum and maximum value will be same which will be C equals to Z see by using binary semop 4 race condition is eliminated so pi and PJ pi and PK only one process can be in the critical section at the same at the time so Pi will be in the critical section will increase PK then will come and decrease PJ will come and then again increase and pl will come and then again decrease so the process will execute sequentially that's why for binary 4 the value will be zero for minimum and maximum case both now comes the producer and consumer problem the interesting thing till now we have seen two implementations of producer consumer problem the first one was busy waiting the second one was sleep wake up busy waiting suffers from inconsistency and sleep wake up suffers from deadlock remember when producer and consumer both are sleeping comfortably in the Sleep queue thinking that other will other one will wake them up but both were sleeping so these were the incorrect implementations now we are going to see the correct implementation using semap fores so we are going to define the bounded buffer of size 100 okay so these were the global variables bounded buffer of size 100 okay now instead of defining the count thing the count variable what are we doing we are defining two counting semap fores empty and full initially all the slots are empty so we are defining mtal to n and initially no no one was full all the slots were empty that's why full was zero and then binary S 4 MX = to 1 used between producer and consumer to ensure Mutual exclusion between buffer and these two were used for condition checking okay now let's see the producer code item P this will be the produced item in equals to Z I hope you remember what is in in is the next empty slot for producer to place an item so initially the in will be set to zero we are going to place the produced item into item P this was the noncritical section and now we are defining the entry section the entry section consist of two down operations the first is down on empty can you tell me when the producer process needs to be blocked when all the slots are full at that case producer should stop that's what we are doing here if Mt equals to Z which means all the slots are full we need to to stop the producer that's why we are performing down operation on empty and then we are performing down operation on mutex so this is just for the mutual exclusion and then the intersection is completed now comes the critical section we are going to place that buffer place that item P that is the produced item into the buffer where at index in that is the empty slot and then we are going to increase the value of Mt slot after placing that item in equals to n+ 1% per n okay and now comes the exit section we are going to up the MX upon full y upon full because we have increased a value which value see initially the full was Zero we have incremented one so now the full will be one now comes the code of consumer item c will be the consumed item out equals to zero remember what out signify it signify the index from which cons conser can consume an item while one down on full we need to stop the consumer when there is no item to consume in the buffer so that case full equals to zero so we will perform down on full when full is zero which means there is no item to consume then we need to block the consumer and down on mutex just for the mutual exclusion item c will be the consumed item increase the value of out upon mutex up empty why upon empty because we have made another slot empty consumer has consumed from an item so the value of empty slot will increase that's why upon Mt and then consume item item C this is the noncritical section again so this is how producer and consumer work by the help of sem for so this is a correct implementation now the question arise how producer and consumer are in cooperation so here it is written this were the implementation this was the producer implementation and this was the consumer implementation see the producer wakes up the consumer here producer wakes up the consumer here and consumers wake up the producer here so this is how they are both in cooperation okay so you need to remember these Five Points the first is if the buffer is full block producer P if if buffer is empty block consumer see producer should wake up consumer when he is sleeping and consumer should wake up producer when he is sleeping and mutual exclusion should exist between producer and consumer so these are the five points that will ensure the correct implementation of semur or producer consumer problem using SEMA 4 I should say okay have you remembered we discussed a question in which the order the changing the order between the entry section was leading the situation to deadlock similar thing will happen here if the mutex is not at the second instructions second instruction of the entry section this will lead to deadlock or I should say if we change the order then this will lead to deadlock see down on Mt initially the value was n decreased to n minus one down on MX initially the value was 1 decreased to zero down on full the value was already full this will be blocked so no case of mutual exclusion is VI viated okay now comes the deadlock thing can deadlock occur can both the process get blocked no this won't get blocked both of them will run now to check whether deadlock will occur we are going to preempt here okay as we used to do down on Mt n minus one down on full Full was full was already zero so this will get blocked but this this won't so this will run keep on running and then after it completes the exit section this is going to wake up the consumer thing okay so this is how it works no case of Deadlock but what if I change the order down on empt down on mutex but what I'm doing here down on mutex and then down on full okay let's see so first we did this down on mutex mutex value changed to zero down on full get blocked the value is minus one and then comes here down on empty the value change to n minus1 and then down mutex the mutex is already zero this will get blocked so both are blocked here if both are blocked then this is the case of Deadlock so what you have to remember while writing this down newex will always be in the instruction two of the entry section when it was this at the second instruction it was working fine when the mutex value changed or the for one case the mutex came up in that case deadlock occurred so this is an un undesirable case that's why the order is important in the last lecture we have seen the implementation of producer consumer problem using semap in this lecture we are going to see some more problems on that so that our understanding becomes better okay Ive also told you to remember a fact that mutex should always be at the instruction two of the entry section if it is not at one case if it's come above then the chances of Deadlock are present deadlock seems to happen Okay let's solve this question it says consider the following solution to the producer consumer synchronization problem I sincerely request you to First you attempt this question and then we will discuss okay so this is just an implicit advice you have to follow that in each and every question we discuss i' I've told you in the beginning also that whenever I solve a question pause the video and solve yourself try to attempt yourself even if you fail doesn't matter but when you attempt you are going to appreciate the beauty appreciate the beauty behind the concept of the question you can appreciate where you had made mistake or where you can make mistake and okay so I I hope you got the point what is the purpose of solving the question first and then seeing the solution okay so let's solve consider the following solution producer consumer synchronization problem the shared buffer sizes n semap 4 R Mt full and mutex defined with the respective value of 0 n and one seeing something odd empty value is zero which means the buffer is already full full Valu is n which means the buffer is already full and MX is one see in the solution which we have discussed using SEMA 4 V what we have assumed that initially the buffer is empty but I think here we are using assuming that the buffer is initially full okay we'll go with that semop 4 empty denotes the number of available slots in the buffer for the consumer to read from now this is this is just the opposite which we have learned before I I got the idea behind the question they are just trying to confuse us so what are they trying to do they they have just changed the meaning of empty and full they are also they are also taking the empty buffer in the beginning I got this okay so SE empty denotes the number of available slots in the buffer for Consumer and full denotes it must be for the producer to write to yes so empty denotes available slots filled with the item and full denotes number of empty slots okay placeholder variables PQ and r r s and they can be assigned with either empty or full and valid sem for operations are weight and signal so we have to assign the value of pqrs in such a way that this code works for uh producer consumer problem okay producer consumer I have told you five things to remember do you remember the five things are when the buffer is full block producer when the buffer is empty block consumer producer should wake up consumer when he's sleeping and consumer should wake up producer when he's sleeping and mutual exclusion should be there we will apply the exact same concept producer it should be sleeping when the buffer is full okay and what does full denotes full denotes the number of empty slots if I say if number of empty slots in the beginning is zero then producer should get blocked so we are performing weight operation on full what does full represent here this is not that typical full it represents number of empty slots and if I say number of empty slots is zero in the beginning which means producer should go to sleep that's why we are performing weight operation here on the foot and when an item is added to the buffer empty SEMA 4 should be increased with one when an item is added empty sema4 should be increased with one why because empty empty symbolizes available slots filled with an item so when an item is added to the buffer available slots filled with an item should increase okay so if you're getting confused just see that they have just changed the meaning of full and empty so what we are going to do we are going to just change the assignment of full full and empty here so you remember we have a sign like this empty full full empty so what are we going to here do full empty empty full so the answer should be full empty empty full C so you have to correct them at your notes also answer is not D it's C okay it's just a a mistake to take D but the answer is full empty empty full how we have done that we have just notices that the meaning of full and empty has changed here so we will just change the assignment also so full empty empty full is the answer let's move to question number two consider the procedure below for producer consumer problem which uses SEMA fores okay so this is a nice question SEMA 4 n Nal to Z number of items sem 4 S = to 1 it represents the mutex okay there are two codes given producer and consumer what does producer do it produce an item apply log to the critical section goes to the action add the item to the buffer free the lock increase the value of n because number of items here are now increased with one void consumer while true what is consumer doing consumer is first applying log to the critical section Sam wait why s wait here because it cannot go to the critical section or consume from a bounded buffer until there is some item already present for there it to be consumed okay that's why Sam weit n if there is item present go to the critical section consume the item s signal as free the lock and then we are free to consume okay so what we have done here let me repeat again producer produces apply a lock add the item to the buffer remove the lock increase the value of n what consumer do apply lock check if there is some item present or not if not then get blocked remove the item from the buffer remove the lock consume the item okay so this is what happens now the question is producer will be able to add an item to the buffer but consumer can never consume it why is it so let's check is that is true or not so producer will be able to add an item to the buffer producer produces apply a lock add the item to the buffer removes the loog increase the value of number of items so producer is able to produce yes but consumer can never consume it why is it so let's see same weight on s s is changed to zero same weight on n n is equal to Z Now removes the item from the buffer s is set to one consumes the item so this statement is false because consumer is able to consume the item question number or the option b the consumer will remove no more than one item from the buffer why is it so let's say the producer produced 10 item consecutively 1 2 2 3 4 5 6 okay till 10 items Now consumer is free to consume no one is just stopping that see while true consumer can consume as many times same weight on S so when producer has produced an item or it has left the critical section it must have changed the value of S2 one so now consumer won't be blocked here Sam weight on N so this will change the value to 9 removes the item from the buffer change the value of signal s back to 1 so n should be n here and it can consume okay so this was the first cycle now it tries to goes again s weit on S it will change the value of s to zero s weight on N it will change the value of n to 8 removes item from the buffer change the value of s to one again and consumes so it has consumed more than one item from The Bu so this is also false deadlock occurs if the consumer succeeds in acquiring sema4 s when the buffer is empty yes this is true how let's say consumer tries to go Sam weight on s s is changed to zero Sam weight on n n is initially already zero so this consumer will get blocked now comes here same weight on s s was already zero so this is this also get blocked this also get blocked let me repeat again the initial value of s is 1 and N is Zer when consumer applies log to the critical section s is changed to zero and it gets blocked here because the value of n is zero so consumer is blocked here now now producer tries to go consumer has changed the value of H to Zer producer cannot also go producer will also get blocked so both the process are blocked it is the case of Deadlock next option the starting value for the sem 4 n must be one and not zero for deadlock free operation is that necessary let's see so we are given that the starting value of sem 4 n must be one and not zero for deadlock free operation next's check so for deadlock free operation what we have to do this instruction mxe is at instruction one so we have to swap for solving the deadlock so let's say we have S that in that case the deadlock can be resolved but what we are given here the value of n should be initially one and not zero for deadlock fre operation let's see so we can think of any case in which n is one and Deadlock can happen can you think of that let's see from the consumer side s is changed to zero n is changed to consumer can freely go it is not blocked let's say it get preed here tries to go from here producer tries to go s is already zero producer will get blocked consumer will now chance consumer will consume or consumer will uh change the value of n to zero again now it's chance for producer to go consumer will change the value of s also to one so producer can freely go now in that case either you start with the producer first n is initially one no one is stopping producer to go to the critical section if one process can go to the critical section then other will also go after some time when the lock is released so the if the starting value of sem for n is 1 and not zero then it is dead log free yes it is true so this is again wrong this is this is true okay so C and D is the answer you need to correct that both in your uh notes okay the first question answer is C and the second question answer is C and D in the next lecture we are going to see reader writer problem solution in the last lecture we have seen some problems on producer consumer SEMA for implementation in this lecture we are going to see the interesting reader writer problem and it solution using semor let me tell you what is reader writer problem Suppose there is some database with records okay now there are two process a reader and a writer both have access to the database and what does reader do it read one or more records from the database and what does writer do writes to one or more records from the database or to the database okay now the problem is reader and writer should not be able to access database at the same time this is the problem it should not be there that reader and writer both are present in the database because a writer may be writing that thing and reader May read the updated value or reader May read the old value and writer May write to the new value so there is some kind of of problem there you can feel it too so what we want that reader and writer should not be able to access database at the same time what is the solution just just use a mutex let's say there is a binary 7 for mutex equal to 1 down on mutex critical section upon mutex problem solved this is it no there is something more to the problem which is there are multiple readers and multiple writers so multiple writers multiple writers cannot be in the critical section at the same time you can feel it too a reader and a writer cannot be in the critical section at the same time but multiple readers can be in the critical section at the same time or multiple readers can be in the database at the same time because readers are causing no harm they are the writers because writers update the value so multiple writers should not be there a reader and writer should not be there multiple readers can be there so this is what we have to implement using semap see this there can be multiple readers and writers so the reading is not a problem reading plus writing will be a problem writing will be a problem so multiple writers can't be there multiple readers can be there a reader and writer can't be there so this is what we have to implement okay and there is some another problem which is starvation to the writers let's say this is our database okay I have assigned so there is a reader and there is a writer so I have told reader to go into the into the critical section of the database first so reader goes okay start its reading another reader comes because multiple readers can be in the critical section at the same time that's why I allow another reader to go to the critical section also then another reader come then another reader come so the readers keep on coming and the writer is waiting so the writer is waiting and readers keep on coming this caus starvation to the writers let's take another case in which writer goes first reader got blocked when another writer comes let's say writer two writer three and writer four all of them will get blocked until writer one performs its operation and let's say writer one is performing its operation for a long time then writer two writer three and writer four and every writer which will come after writer four or the writers will keep on coming and will and will get and will keep on getting blogged and blogged so this will cause a starvation to the writers so this is the problem which we have to solve okay so what can we think of it let me explain you there are two process reader and writer okay let me explain you the main idea what happens this is the database okay for the first case writer comes it will lock the database from inside perform its writing operation and when it will come out it will remove the lock and will go out so this is what a writer do as simple as that but the problem is with the readers so what a reader going to do let's say this is R1 this is the leader of the reader this is the first reader which has shown interest to enter into the database reader come check the database if it is logged from the inside let's say writer one is present already what it will do it will tell the other writers hey the critical section or the database is logged from inside all of us should get blogged until the writer perform its operation okay so this is how readers are going to cooperate but let's say there is no there's no writer present in the database so what it will do reader one will come lock the database from inside for the writers only for the writers only and will allow its fellow readers to enter into the database so R2 can easily go R3 can easily go R4 can easily go and when they will come out of the database or let's say they have Performance Reading so they will go out R1 goes out R2 goes out R3 goes out and now it is the the responsibility for R4 that is the last reader to tell the writers that now we have performed our reading you can go now so R4 have the responsibility to remove the lock which the first reader that is the leader of the reader R1 has applied on the database are you getting the point let me repeat again and then we will move to the code see there are reader and the writer Pres if writer comes it will lock for lock the database from inside for everyone either either it be a reader or it be a writer writer one performs its operation writes the thing and before going out it will remove the lock and it goes out so this is how R do its operation and how reader do reader one will come and check if there is a lock on the database already for the readers which some writer must have been applied or or locked the database from inside it will car its fellow readers R2 R3 and R4 to get blocked that we all of us should get blogged until writer one perform its operation and when writer one will perform the operation it will go by removing the lock at the database so the lock will be removed now reader one comes it applies the log log for whom only for the writers reader one comes it allows other its fellow readers to go and read at the database reader one has completed its reading so it will leave reader two has completed reader two will leave reader three will leave but now the last reader the last reader that is reader 4 it is the responsibility for reader 4 to remove the lock which reader one has acquired at the database so that other writers may get to know that the now database is free we can go into the database I hope you got the idea let's see the implementation of reader and writer using SE we will maintain a reader count also to know that if that reader is the first reader or the last reader that's why because we have to take account of leaders and the last reader that's why we are maintaining a readers count okay so int RC that is the readers count that is number of readers present in the critical section okay so readers count is the value of uh the readers present in the critical section see suppose RI is the reader that wants to enter into the critical section so it will try to increase the value of readers count and RJ is the reader that has completed its reading so it will try to decrease the value of readers count can you see this as a race condition because multiple readers may want to access readers count for incre increment and decrement so this will cause inconsistency in some way that's why we are maintaining a mutex which is used by readers for readers count and we are maintaining a binary 74 database which is used by reader and writer to access database as the critical as access database as critical section are you getting the point we are maintaining two binary seaone the first one is mutex mutex is for the readers count and another one is the database database is for the critical section mutex is used only by the readers and database is used by the readers and writer to get access of the critical section okay now what is the major function of the writer it has to just go to the database apply the lock and if someone is present get blocked this is the uh major work and whenever the writing is done when it will go it will release the lock so this is what we have done here void writer perform down operation on database that is acquiring the lock performing the database right and releasing the lock as simple as that but the readers implementation is a bit tricky what readers have to do whenever a reader enter into the database it has to increase the value of readers count by one to prevent inconsistency we have to perform or the reader have to perform a lock or a down operation on mutex so that some if some another reader want to decrement that won't cause inconsistency suppose if a reader is incrementing the value of reader count and another reader comes and it wants to decrement the value of readers count let's say somewhere at this point then this will prevent them download mutex will prevent them for causing inconsistency okay so mutex is used by readers only to increment or decrement the readers count okay suppose reader one comes perform down on mutex increase the value of reader count initially it was zero so now reader count is one and I have told you if the reader is the leader or it is the first reader it has to check whether some writer is present into the critical section or not if it is present then other readers should also get blogged so reader one will get blogged where it will get blogged at the instruction C and let's say some reader two also wants to go to the critical section it tries to first in the value of readers count it won't be able to it will get blocked directly here so R1 R2 and any other reader which try to go will get blocked so this is what happens mutex initially changed to zero reader counts changeed to one database let's say the DB that is the down on mutex is already Zero by some writer so a leader will be blocked at instruction C at this point and rest others will be blocked at instruction a at this point only I hope you are getting the idea okay now what happens let's say there is no writer present in the critical section so now what leader of the readers will do it will change the value of DB to Z why to prevent other writers entering into the critical section okay now as it has changed the value of RC to 1 it will increase the value of mutex or it will release the lock it has acquired on the readers count shared variable now what it will do it has successfully entered into the critical section or I can say it has sucessfully enter into the database so it will perform the read operation on the database and now when it has done when it is done with its reading then what will happen it should go out of the database so before going out of the database it should decrease the value of readers count by one so what it will do it will perform the down operation it will acquire the lock performs the reading or performs the decrement on the readers count and will release the mutex but here is the catch also I have told you if it is the last leader that is R4 in our case then it should be a responsibility for R4 to tell other writers that database is now free so the last one should unlock so if it is the last one that is reader count equals to zero then it should unlock the database and then upon M Tex so this is how reader wrer problem is solved using 74 let me read again if it's the first writer it checks that database has writer already then it will get blocked rest all of the readers will be blocked and if it sees no one is there in the database it can go there and simply lock it for the writers only readers can enter and no need to lock every time so the first reader is the leader of all other readers so what are we doing here down mutex before accessing the reader count and before making it up lock if it is the first reader and unlock if it is the last one so the last one is unlocking and lock is performed by the first leader okay so this is how it work now let's revise what we have done in the readers writer problem let me repeat again what happens there is a database there are two process reader process and the writer process a writer process can go only if there is no other writer or reader present in the database so when a writer process try to go it will perform a down operation on DB which will automatically adjust if there's some other reader or other writer present then it will get blogged if not it will go acquire the lock go into the critical section if some other writer tries to enter it will get blocked now what for the reader let's say there are four readers R1 R2 R3 and R4 R1 is the reader R sorry R1 is the first reader so it will become the leader first reader is the leader so when a reader leader tries to enter it will see that critical section is logged or not if yes it will tell other readers also to get blogged so all of the readers will get blogged and when this it will go out it will tell the other readers that c section is not free you can go so R1 will go R1 will go first R1 will go first we'll see if this if there is no other reader no other writer it will lock the database from inside for the writers only and other readers are free to go so R2 will go then R3 will go and R4 will go and when they have performed their reading operation R1 will go out will decrement the value of RC R2 will go out will decrement the value of RC R3 will go out will decrement the value of RC and when R4 will go out the RC will be zero because there is no other reader present in the database so RC will become zero and when RC will Zero it is the responsibility of reader 4 that is the last reader to tell other writers that database is now free you can go and write or perform your right operation so this is how reader writer problem works or this is how reader writer problem is solved using the semaphor I hope you like this uh I hope you liked it now let's move to the new problem that is dining philosophers problem it consists of some philosophers discussing on some topic and then when one philosopher become hungry he eats the meal in front of him using a knife and fork these knife and fork are shared okay so when philosopher 2 is eating he'll pick up the the knife pick up the fork and we start eating but in case if P1 and P3 also become hungry at the same time they won't be able to eat because they need fork and knife but when P3 will try to pick up the fork this Fork is already in use by P2 so P3 fails to pick up this Fork hence won't be able to eat when P1 will try to pick up this knife this knife is already in use by P2 so P1 also fails to eat so these knife and fork are shared between these philosophers if one philosopher is eating then these two philosopher can't eat okay so this is what I've written here n is greater than two that is number of philosophers should be greater than equal to two philosophers eating noodles and using a knife and fork is shared between these two when a Philosophers become hungry he'll pick up the left thing that is or the left fork and then the right if successful but why I have written if successful because in that case in this case P1 is unable to pick up the right thing that's why I written if successful and if not then P1 won't be able to eat so a philosopher start eating only when he pick ups the right successful picks up the left successful so left and right are both picked up and successful okay now you can see this problem suffers severely from deadlock how let's say a Philosophers picks up the left thing and get preempted picks up the left thing and get preed suppose this philosopher picks up the the left knife and get preempted picks up the left Fork get preempted picks up the left knife get preempted picks up the left Fork get preed picks up the left knife gets pred picks up the left Fork get preed now each of the knife and fork is acquired by some philosopher and other philosopher is waiting for other philosopher to release that knife so this is waiting for him this is waiting for him waiting for him waiting for him so there consist a cycle in which a philosopher is waiting on another to release that lock see p 0 is waiting on P1 P1 is waiting on P2 P2 is waiting on P3 P3 is waiting on P4 P4 is waiting on P5 and P5 is waiting on p 0 so this is how deadlock occurs in this ding philosopher problem so how in which case dead log occur all of are hungry all of them prevents uh preempts after picking one thing they all picks up the left thing and get preed fork0 is acquired by p 0 for is required by P1 2 by P3 and all of them p 0 is waiting on P1 P1 on P2 P3 on P3 P3 on P4 P4 on P5 and P5 again on p 0 so this is a case of Deadlock okay so how this dining philosopher problem is implemented let's see so we have defined six philosophers here let N equals to 6 void philosopher and I while one think this is the case when a philosopher is thinking think I now it gets hungry take Fork I take Fork I + 1 mod n why mod n for the circular thing for this for this that's why for the circular thing we have written mod n picks up the left Fork picks up the Right Fork if successful eat after eating put back left Fork put back the Right Fork this is it this is how a philosopher work you will think suppose now thinking he gets hungry he takes up the left Fork takes up the Right Fork if successful then eat put back the left Fork put back the Right Fork this is how a philosopher work now the question arises what is the maximum concurrency how many philosophers can eat at a time without deadlock let's say now we change the number for Nal to 5 what is the maximum number of philosophers that can be eating okay let's say philosopher zero tries to wait picks up the left four picks up the Right Fork P1 tries to it gets blogged because F Fork one is already acquired by p 0 now in this case we are ignoring the fact that knife and fork are different we are just taking into consideration that a a philosopher require two Fork we are saying that knife and fork are the same what I'm saying instead of segregating between knife and fork we are saying they are just forks and a process and philosopher require two Fork to eat two forks to eat okay so this is what we are doing suppose we are saying p 0 requires are Fork 0 and Fork 1 P1 requires now Fork 1 but it will get blocked because Fork 1 is already required by p 0 now P2 comes P2 acquires 42 and Fork 3 P3 comes get blocked because P3 has acquired it wants to go to the fork 3 but Fork 3 is already acquired with 42 P4 comes F4 and F0 but F4 F0 is already acquired with p 0 so at Max two philosophers can it you can also see here let me go back yeah you can also see here in this case how many philosopher can eat this can eat freely this can eat freely and this can eat freely in case of six philosophers but if let's say I remove this philosopher and this knife then how many can eat only this can eat and this can eat okay so this is not a hard question what you have to do what you have to do just allocate folks to the philosopher and if some other philosopher wants to acquire the same Fork then make it blocked this is it p 0 wants to get Fork 0 and Fork one give them give him P1 wants to get Fork one but it is required with uh p 0 block it P2 wants F2 and F3 give him P3 wants F3 block him because F3 is already with F2 P4 wants F4 and F0 block because F0 is already with p 0 so this is how you have to do for n = to 3 when when there are three philosophers the answer will be and the answer should be one C if there are three philosophers and oh for Three Philosophers can it be three knives yes for three Three Philosophers three folks will be there at a time only one philosopher can eat with using this so these two will wait I think I must have I must want to return six here you can see for six this philosopher can eat freely this philosopher can eat freely and this philosopher can eat freely so for Nal to six three of the philosophers can act can eat freely okay now the question arise how to prevent that deadlock case so the first answer is semaphor based and the second is non semaphor based okay let's discuss the first non semaphor based answer let's say there are two philosophers sitting on a table with two forks in between see the number of forks is equal to the number of philosopher and one philosopher require two forks for eating you have to remember this condition what I have said the number of forks is equal to number of philosophers and each Phil each philosopher require two forks for eating okay so now here two philosophers are sitting on a table and there are two folks present you can see these blue the blue ones are the folks so now what we have to do we have to make this veloc pher picks left first and then right and this philosopher should pick right first and then left see how this is going to solve the problem this philosopher what is the left of this philosopher this one so this will pick this what is the right of this philosopher this one so when this philosopher has already acquired this Fork this philosopher should also try to acquire the same Fork otherwise if this philosopher acquire this Blue Fork the deadlock will occur each of them has acquired a fork that is required by the other a cycle will be so this is a deadlock condition what we have to do he picks the left Fork first and then right make him pick the right Fork first and then left in that way deadlock won't occur let's see picks up the left Fork first he also tries to pick up the Right Fork first but this Fork is acquired by this one gets blocked now he can pick up that that one eat properly and then when after eating he will release them so when this will try now they can both eat one after another so first this it and then the other one so this is how non semop for solution work picks left first and then right picks right first and then left this Fork is right one to the P2 P1 left picks the left Fork P2 tries for the right one and get blocked because what the fork which is left to P2 is right for the P1 or you can say the other way the fork which is left to P1 1 and is right to P2 so both will try to pick up the same fork okay let's say P1 has acquired the lock first then P2 will get blocked this is how deadlock will be saved otherwise let's say this has picked this fork and this has picked this Fork now this philosopher is waiting on this philosopher to release the fork and this philosopher is waiting on this philosopher to release the fork this will be a case of Deadlock so what we have to do make one philosopher change the pattern let's say all philosophers are picking left first first and then right left first and then right left first and then right make one philosopher pick right first and then left in this case deadlock won't occur believe me deadlock won't occur make one philosopher choose the different way okay so n minus one philosophers let's say there are total n philosophers so n minus one philosophers will go first left and then right and N philosopher will choose first right and then left okay so let's say P1 be that n philosopher will first choose the right fork and then the left Fork so this is how P1 works okay now let's uh start the thing P4 picks up the left Fork first P5 picks up the left Fork first P1 tries to pick the right Fork first but Right Fork is already required will get blocked so P1 will is blocked here okay P2 picks up the left Fork first P3 picks up the left Fork first and now it's chance for P4 again P4 will pick the right Fork see here so after eating will be done off for P4 now P4 can eat see P4 has required both these folks so P4 can eat when P4 will eat after eating P4 will release them now P5 can eat after eating P5 can release them now P1 can eat so P1 tries to pick this get blocked P1 tries to pick this it can pick successfully but when tries to pick this gets blocked now what will happen chance for P2 P2 cannot pick this gets blocked chance for P3 P3 can pick this so P3 will eat P3 will eat after eating we release both of them now chance for P2 P2 can pick this now P2 will eat P2 will release both of them now it chance for P1 P1 can pick this again now P1 can eat and will successfully release them so this is how deadlock is pre prevented when one of the philosophers is has changed the path all of them were moving from left to right and one of them was odd so what he choose he chose left to right so this is how deadlock can be saved that's what I'm trying to tell here okay okay so this was the non semap 4 based solution it was semap for free it was deadlock free how it works out ofense n philosopher let N minus one go from left to right and then one philosopher will go from left right to left or you can do like that even number should pick first left then right and OD number should pick first right and then left you can do like both both the ways will save you from deadlock so this is how non semaphor based solution worked now comes to the semaphor based solution what are we what are we doing here put semaphore control on taking and releasing the fork how we'll discuss later in the chapters of monitor so there are some miscellaneous topic which I will discuss in the end like uh we have not discussed in detail about Fork system call we have not discussed about threading multithreading we have not discussed uh monitors in later part of the course we will learn when we will learn about memory management we will learn segmented paging and inverted paging in the last of the course that is the miscellaneous topics okay so we'll discuss that part in the later part of the course that is we'll discuss when we will study monitors okay so this was the dining philosophers problem let's start our lecture with the sleeping Barber problem this problem is from ten and bomb textbook if you want to have a reference you can visit the textbook okay so the problem is there is a barber shop okay there's one Barber and and chairs for in customers as you can see this in the picture if there are no customers then the barber sits on his chair and sleep as Illustrated in this way when a new customer arrives and the barber is sleeping then he'll wake up the barber suppose a customer arrives and the barber is sleeping he'll wake up the barber when a new customer arrives and the barber is busy then he'll just sit on the waiting chairs like this and if there are no chairs available then he'll just leave okay so now you have to tell me the possibility of Deadlock how deadlock can arise in this situation let me give you a hint when a customer doesn't vacate the only chair even after the haircut in that scenario deadlock may arise now you have to think how okay now let's move to the our last topic of this section current concurrency versus sequentiality okay so see this program begin statement one statement 2 statement 3 statement 4 a = B+ c d = to e CR F K = A+ d l = k CR D so this will execute sequentially okay now if we see this uh for this in operation if we see the micro instruction or micro operations which are instruction one load the value of B into register load the value of C into register add and store the value of R1 + R2 into register R1 and then store the value of register into a so after all these instructions this statement will be executed so this will go like sequential execution you all know but but I say if permissible if it is allowed then which statement can execute concurrently you know the meaning of concurrent execution parallely okay not not directly see there's a difference between concurr concurrency and parallelism but if you do not know the meaning of concurrency paral ISM can give you a hint okay so if permissible which statement can be executed concurrently so the statement which are not dependent on each other can be executed concurrently or concurrently you can say together okay see statement S1 a = to B+ C statement S2 d = e CR F these two statement are independent how can I say that which statements are dependent those statements are dependent for if one if the output of one statement becomes input for the other see like this S1 and S3 the output of one statement becomes input to the other C S3 and S4 the output of one statements become input for the other so these are dependent so these dependent instructions or these dependent statements cannot be executed together or concurrent ly okay now see this S1 and S2 they can be concurrently executed after this S1 and S2 you can execute S3 and after S3 you can execute S4 so this graph which I have made here is the Precedence graph it is also directed graph what does this show S1 and S2 should be executed first after that S3 after that S4 there is there is no order or there is no significance of order to be followed while executing these S1 and S2 so this is what concurrency means why because S1 and S2 are independent okay let's take another example let's see this presidence graph can you tell me which statements can be concurrent the statements which are independent which statements are independent those statements are independent in which the output of doesn't becomes the input for the other okay see this can I say S1 and S2 are independent no because the output of S1 will become independent the output of S1 will become input of S2 can I say S1 and S3 no the same thing is there also can I say S2 and S3 yes they are independent so they can be concurrent can I say S3 and S4 Yes because the output of S4 or output of S3 is not becoming input for the other I hope you're getting the point can I say S5 and S6 are independent or concurrent yes can I say S4 and S5 no because output of S4 is becoming input for the S5 can I say the same thing for S4 and S6 no can I say this S5 and S S6 can be concurrently executed with S3 yes can I say S3 and S7 can be conr executed no because the output of I hope you're getting the point okay so you have to see like this this if it is on the other Branch then I can say that they can be concurrent okay now let's understand the difference between concurrency and parallelism concurrency let me tell you directly let me tell you two words which will make it clear concurrency means multiprogramming and parallelism means multi processing let me repeat again concurrency means multiprogramming I hope you already remember what is multiprogramming we had this OS and there are multiple programs in the main memory and then CPU executes sometimes P1 and sometimes P2 and sometimes P3 so this is multiprogramming what is multiprocessing in one CPU P1 is being executed in another CPU P2 is being executed in another CPU P3 is being executed this is multiprocessing which include multiprocessors okay so let's read this a system is said to be concurrent if it can support two or more actions in progress at the same time okay same to multiprogramming a system is set to concurrent effec support support C support two or more actions in progress at the same time set analogy with that multiprogramming two or more process can be supported for Progress at the same time parallelism a system is said to be parallel if it can support two or more actions executing see this executing word is important executing simultaneously and here progress word is important concurrency is about dealing with a lot of things at once and parallelism about doing lots of things at once okay concurrency is dealing and parallelism is doing don't worry if you are not getting it I have plenty of examples to solve this confusion two or more actions can go along together together or progress together okay so take this example you sit at a chair eating snacks watching lectures and listening to lufy beats in the background this is you dealing with multiple things at a time and what is parallelism in that situation simultaneous execution one person is eating snack one person is watching lecture one person is listening to lfy beads and these are happening at the same time so this is the difference between concurrency and parallelism concurrency leads to parallelism or I can say parallelism can be derived through concurrency okay see this this is sequential execution first this one then this one then this one then this one then this then this then this first all blue ones get executed and then the red ones what happens here sometimes blue one sometimes red one like the CPU do with the processes sometime this process sometime this process this is concurrent we are dealing with the blue ones and the red ones at the same time and noce parallel execution blue ones and red ones are being executed at the same time okay so this is the progress this is the execution okay see this concurrency sometime the blue processor sometime the green sometime blue sometime green here green and blue are being executed together take another analogy concurrent means two cues at one coffee machine sometime this one go some this one go then this one then this one and what is parallelism two Q's on different coffee machines here this coffee machine is dealing with the two different cues and here is the doing I hope you're getting uh the idea okay interleaved execution in multiprogramming this is concurrency you know what is the meaning of intered execution the CPU sometimes execute P1 sometimes execute P2 but it is the same CPU parallelism is possible with multi multiple CPUs or multi code okay concurrency can be segregated into two parts pseudo and real the real concurrency is actual parallelism and the pseudo concurrencies one CPU we get an impression of concurrency see this this is sudo concurrency and this is real concurrence real parallelism actually doing two things simultaneously and here we are just getting an impression of concurrency we are just seeing suppose suppose this is in a black box both of them are in a black box you can't see what is in there so you can see that or you can from the output you can say that blue ones are also coming and red ones are also coming in the output I get an impression that both are being executed at the same time but is it so no sometime this one sometime this one sometime this one sometime this one in this black box when you see the output you can also say that same thing I can see blue ones and R ones coming out of the box so I can say the same thing for here also that both are being executed but the difference is clear here we are just getting an impression of the concurrency and here is the actual concurrency okay this is done when there is a single CPU and this is done when we have two core CPUs because this can be executed on one CPU and this on the other here there is one CPU sometime this is executed and sometime this is I hope now the difference is clear okay so that that thing which we call as sometimes P1 sometimes P2 that is called as that is called as interl execution among processes okay now let me ask you a question Suppose there are two statements SI and SJ SI is AAL to B plus C and SJ is d = e cross F now tell me can they be executed concurrently yes they can be executed because the output of one statement is not becoming the input for the other they all have different variables so yes they can be executed concurrently let's see another question tell this A = to B plus C D = to B CR C can they be executed sequen concurrently yes you can also guess this because the output of one is not becoming the input for the other is a becoming input for this D no we are just reading the values so yes they can also be executed concurrently even though they have shared resources but they are only reading the value of B and C okay so if the output of one becomes input for the other then those two statements won't be concurrent here so you have to remember this line okay for every statement two sets can be defined the reading set and the writing set see above these for this can you define the reading set and the writing set yes reading set will include reading set of Si will include B and C and the writing set of Si will include a because the value of a is overridden or or overwritten and the B and C are red only okay so this is read set set of all those variable whose values are R and right set is all those variables whose values are updated so for this a go to B plus C B and C variables are in the read set and a will be in the right set suppose this statement a + = to ++ B cross c so this can be simplified to this a = to a + Plus+ b into c now can you tell me what is the read set and what is the right set see for a b and c you can check that value of all the variables are updated see the value of a will be updated for sure the value of B will be updated but how this Plus+ B and b++ are different here we will first increase the value of B by one and then we'll use it we'll first decrease the value of C by 1 and then we'll use it but what happens in the case of b++ we'll first use the value of B and then we'll increase it so a = to a +++ b cross c first increase its value by one then use so the value of each of the variable is being updated so what will the read set a b and c and sorry what is the right set a b and c and read will be fine okay now let me ask you an amazing question can you guess this index S3 equals to is SC F perc D and X okay so what is the statement there is some variable index and you are taking the input for it okay now you have to tell me scan F now you have to tell me the read set and the right set think about it pause the video you think about it the read set and the right set okay I'm showing you the answers now so the read set will be five and the right set will be X how this is uh did you think of the opposite answer maybe possible see initially when you just declare a variable without assigning any value then there is some garbage value stored here garbage some garbage value initially and when you take input from the user that garbage value let's say I pressed five on the keyboard for this integer so that garbage value will be replaced by that five okay so the value of x was initially this some garbage value and now it is updated to five so I can say the value is updated so the read set will be X and what is the sorry I always see a so the right set will be X and what will the read set five because we have not read this value so why is it necessary for uh why is it necessary to read this garbage value no it is not necessary so the read set will be fine the right side will be X similarly for S print X for printing we just read the value we do not update that so for print the value will be X so the read value will be X and the right will be F these are just some uh practice question to boost you uh when you can how to find a read set and right set because from this read set and right set I can say if two statements are concurrent or not if if between the right set of the first statement and the read set of the second statement if there is nothing common then the statement SI and SJ are concurrent if the read set and the right the read set of first first statement and the right set of another statement if there's nothing common then SI and SJ can be concurrent if the read if the right set of first first statement and the right set of second statement if there's nothing common then the SI and SJ can be concurrent so this is called as burn steam concurrency condition for two statements you derive what is read set and what is the right set and then see if there is something common in between if yes then they are not concurrent and if no then they can be concurrent okay so this is Burnstein concurrency condition okay now let's see concurrency mechanism how this concurrency is actually implemented and this is not from any textbook okay so C C++ Java sequential language but how can concurrency be applied we can apply it using pair begin and parent so this pair refers to the parallel and this Co begin which is the same name for pair begin and parent co begin and co end is for concurrent okay so uh let me tell you how this works begin S1 S2 S3 and end when you write this sequential execution will happen first S1 then S2 and then S3 but if you write pair begin and pair end in that case we are allowing for concurrent execution see this firstly s0 s0 came as the root node pair begin S1 S2 and S3 so the they are the concurrent so I can put them on the same level on different branches and then after this block I had S4 so after this I had S4 so I hope you get the difference between how this pair begin and pair end are uh making the Precedence graph different for this only begin and end we did the sequential execution and for pair begin and Pa end we are allowing for concurrent execution okay okay see this S1 pair begin S2 S3 S4 begin so we are now using nested begin and pair begin and now you have to do the draw the Precedence graph we start with the S1 so this is the root node we start with the S1 pair begin PA and and then in the end S1 so whatever will come here and then in the end we will had S11 now pair begin S2 S3 S4 so S2 S3 and S4 will be concurrent statements okay begin S5 S6 and end see this here we are using begin so S5 and S6 will be sequential I can see S5 and S6 are sequential begin S7 S8 S9 so S7 S8 and S9 will be sequential S7 S8 and S9 are sequential and then in the end S10 in the end S10 see this S2 S3 S4 this one this one and this one will be concurrent and this one in this one S5 and S6 are sequential S7 S8 and S9 are sequential so this is how it's going to look if you're feeling difficulty don't worry I have plenty of examples write program now it's it's different now you have to go the opposite way write program for the graph see S1 so we'll write S1 here now S2 and S3 can be concurrently executed so I will apply pair begin S2 and S3 but see S2 had some more sequential executions like S2 after that S4 and then S5 and S6 so I'll first write S3 and then I will apply begin why begin because I need some sequential execution steps now I'll write S2 and then S4 so this part is covered and then I I should write S5 and S6 but they are sequential but they are concurrent so I can write S2 S4 and then this pair begin thing and then in the end end and then parent and then in the end S7 let me repeat again see S1 came here this part was related to concurrent execution so I'll write pair begin and pair end here okay now forget about this S3 and S2 are concurrent so I'll write S3 and S2 but you see S4 and S3 are also concurrent S5 S6 and S3 are also concurrent that's why we are keeping the S3 outside and this begin and end in the one part okay so S3 will be outside begin now we are talking about this tree okay begin S2 S2 will become the root node for this tree and then I need S4 S4 Here and Now I want concurrent execution for S5 and S6 that's why I've used pair begin here and then end now let's modify the question a little bit instead of S3 going straight to S7 why don't we make like this S3 going to S6 now it's a homework problem we have to write the program just as we did here okay in this graph we made a little bit of change instead of going like this we changed to this okay let us start our discussion of final part with the homework problem I've given you a homework problem in which I change the Edge from this to this okay this is The Edge now you have to tell what will be the code of this graph so I start with S1 I start with S1 and then I can see these two these two blocks are these two nodes are concurrent okay can I say these two are concurrent also no I cannot directly say because the statement the the section or I can say the node S3 is making S6 dependent on itself the output of S3 is the input of S6 so I cannot say S5 and S6 are concurrent always because this is from a different branch and this may be from a different branch that's why I cannot say S5 and S6 concurrent as always like I did in the last question in the last question S5 and S6 were indeed con current but now it is not so how we going to proceed with this let's see we have two cases we have two options we started with S1 here pair begin S3 and then this S2 S4 and also include S5 and S6 here I'm talking about of this block including here after s sport so what is the problem that may arise the problem is this Edge this pair begins is you can start with either S3 or this or this statement you can either start with both of them so I say why I can't start with this so I start with this begin S2 S4 and I said I'm including this block also here so S5 and then S6 but the problem is can you execute S6 before executing S3 no that's why we have to we cannot include this block here that's why we need to separate this block what we did in the last question in the in the previous lecture we included this block here but you cannot do this now why let me repeat again because the input of S6 is the output of S3 they are dependent on each other they cannot be in pair begin with different statements with this and this okay I hope you're getting the idea that's why I need to separate this block but separation also caused a problem this code says you need to First execute S1 then this block then this block and then S7 this block includes S3 in it this blocks include S5 in it so the code says you cannot execute S5 before executing S3 but the graph says yes you can the graph says you can so there is some kind of contradiction there is some kind of complication in the solution I had only two cases either to include that block here or to keep it separate by keeping that block here I'm volting this Edge this Edge and by keeping the blocks separate I'm including an additional age so this is creating a problem this is complicated now okay so can I say about S5 and S6 they are concurrent no sometimes they are and sometimes they are not because S6 depends on S3 and S4 both and these two belongs to different branches okay that's why I cannot say S5 and S6 are always concurrent so the program is you cannot complete S5 before completing S3 but the graph says yes the program would be okay if I put an edge from S3 to S5 but now the edge is not present so there is some kind of problem in the solution the answer is it is non implementable we cannot implement this with pair begin and pair end alone such graphs are implementable using semap for let's see how so we Define number of binary sem fores a b c d e FG and all of them are set to zero so what idea we are using here we are using that as we have defined all of the binary S4 to zero I cannot move to a statement directly see this forget about this graph forget about everything here okay just see this in pair begin I have several statements here okay can I jump directly to this statement and start executing no because I would be directly blocked away because the value of a is initially zero can I directly jump here yes I can jump here I can start executing S1 increased the value of a now can I go there yes now can I come here so what does this VA and Pa VA is increasing up operation on a and Pa is down operation on a so what are we doing we have initialized the value of binary S 4 all of them to zero and now we are making it like a condition that before you execute this statement before you execute the or I should say before you execute this statement you have to execute the above one because in the above one only you have a key to access this statement because if you do not do this this VA you are not able to go ahead with this statement you you won't be able to execute S2 you won't be ex able to execute S4 I hope you're getting the idea let me put it in a simple words v s p or I should say v s p a k suppose S and K are two statements so which statement are you going to execute first obviously VA because initially the value of a is zero if you try to directly go and execute a statement K you will fail you will be directly blocked away that's why it is necessary to execute a statement s first so VA a = to 1 s first will be executed now we comes to PA now the value of a is set to Z Z and now I can execute a statement K so this is how we are using the help of or we are taking the help of SEMA 4 to create a sequence here we have created sequence you need to execute first s and then K only here sequence is created so that's why we are using SEO to create a sequence let's see how are we going to use that sequence thing in in this our uh our question so we want S1 to be executed first then S2 and S3 that's why we we created a lock here and a key here so if someone directly try to execute S2 and S3 they will be directly blocked away so it has to First acquire the key where is the key here is the key so first execute S1 acquire the key for this statement acquire the key for this statement and then end now I have key for S2 and S3 both it's upon me it's or I can say it's my choice on which I should go I can either go to SD I can go to I can go to S2 or I can go to S3 it's my choice why I am given with a choice because these two statements are concurrent we were not given we were not given the choice for S1 we have to execute S1 first because by doing all these things we want to create a sequence we need to execute S1 first now you get a choice to execute S2 or S3 for S2 you after S2 you have to execute S4 see this after S2 you have to execute to S4 there's no other choice so in this this way we are we are planning to proceed or in this way we are going to solve this problem let's now see Again Begin S1 acquire key for this statement acquire key for this statement now let's say I begin with this PA we open the door for this path execute S2 S4 now now now now what happens before going to S5 or S6 before going to S5 or S6 I have to acquire key for S5 or S6 so I have to acquire key for S see this this is the key VC is the key for S5 so I acquired key for S5 and then I acquired key for S6 also see by executing S4 I acquired key for either S5 and then S6 and then we ended now I jumped to here I have key for S5 so I go to this statement executed S5 go got a key to execute the statement 7 got a key to execute the statement 7 so what I want I directly go there to execute the statement 7 but I what I found there is another lock here and what does this lock say this lock say man you need to execute S6 before going to before coming to me because S7 it is dependent on S6 also so what I was trying to do after executing S5 I was directly trying to jump to S7 but the S7 says I have another lock for you and this lock will be opened only when S6 will be executed see see here this lock will be opened this lock will be opened after when S6 is executed okay so what I did I executed this this this got a key for s for the first lock of S7 and then remember I had also key for S6 so I moved here completed uh open the first log for S6 see this S6 also has two logs one and second so the first I got for S4 and the second I need to get from S3 so the first loog I executed I I opened using the key which I got from which I got from executing S4 now I want second key from where I can get remember I had a key for S3 also by executing the first statement I key I got a key so I applied I or I used that key here opened the lock for S3 executed S3 and got the key for S6 now I can open the second lock for S6 executed the S6 got a key for the second lock of S7 opened the second lock executed the S7 and then end for the beginning it may seem complicated but it is not believe me it is not complicated it is just like a it is just like uh remember we used to in in in childhood we used to solve that maze problem you go there go there and then we finally get out of the maze so this is similar to that you just go with the flow execute s S1 first executed S1 first now I got a key for S2 and S3 I got a key for S2 and S3 it's upon me which uh way I I go so I decide to go on the S2 way I decide to go on the S2 Way open the log for S2 executed S2 then S4 got a key for S5 that this VC I got a key for S5 because why why I written like this because for S5 it is necessary to execute S4 first that's why we created lock there at the before S5 and then this lock key is available after S4 so I got a key for S5 and after executing S4 I also got a key for S6 because the output of S4 is input for S6 that's why a key should be given after executing S4 for S6 that's why I got a key here now what I got what I have with me I have the key for S3 which I got from EX this statement I got a key for S5 and I got a key for S6 so I decide to go with the S5 I go with the S5 open the door for S5 execute the statement S5 now you can see S7 is dependent on S5 so I will get a key of S7 after executing S5 now I give got a key for S7 what I decide I decide directly go to the S7 I decide to go to the7 open the first lock but what I see there there is another lock also for this Edge in this and say you have to first open S6 so I go to the S6 I have a I have a key for S6 which I got from this S4 I open the first door for S6 now I've got another lock and this lock will be opened by S3 this lock will be opened by S3 so I go to the S3 execute S3 see I had a key for S3 executed the S3 and I got a key for V which is the second loog of S6 so I've got the second loog of S6 executed S6 got the key for the second lock of S7 for the second lock of S7 exe open the lock and then executed S7 and then end okay so this is how we are going to solve this uh par begin and parent using semop fores okay let me tell you one last time this shortcut for S6 you need to have two keys for S7 you need to have two keys for S5 you need to have only one key for S4 you need to have only one key for S2 you need to have one key for S3 you need to have one key so based on the edges there will be that number of locks see for S6 we had two locks for S7 we had two locks okay so this is how we will proceed with it I hope you understood how are we solving using semap and to check that I have a homework for you the homework is try writing the same program with less than than seven semores try writing the program with less than sem4 see here we used 1 2 3 4 5 6 7 binary sem4 can you optimize it to use that in less than 7 774 try this let's discuss some more problems so we are given with a code and we have to draw the graph let's start S1 we made S1 in the starting pair begin and this pair begin ends here so I can say S9 will be the last S9 will be the last now what comes S2 and S4 so there is a edge for S2 and then S4 S2 and S4 are sequential then this part S3 S3 will be the in the beginning and that S3 and this pair begin PA end will be sequential so S3 and this will be sequential first S3 and then this pair begin S5 pair begin S5 see S5 and this part will be concurrent S5 and this part is concurrent and then S6 and S8 are sequential S6 and S8 are sequential and then par end this ends now what was in the par begin S2 S4 S3 in this part and S7 and S7 and then the end comes S9 so then in the end comes S9 so this is the graph easy question number two we are given with a function void p a b c void q d e Main pair begin p and Q and P and Q can be concurrently executed now we have to select the valid sequences okay I can either start with P I can start with Q I can go like this let me write all the possibility I can go like this first P then Q first Q then P for some time p and then for some time Q for some time q and then for some time P I can go with any of the way for sometime P for sometime Q for sometime P for sometime Q I can go this way also but in all of the sequences the order should be valid B cannot come before a e cannot come before D okay so based on this we have to select the valid sequences can this be valid a b c d e yes we execute first p and then q a b c and then d e so yes this is valid a d b e c is this valid a d b e c yes this is valid I have said we can execute P for some time then Q then again P then Q then again we can go like that there's no problem in that because PA begin d e a b c d e AB b c we can go like that first q and then p d c e b a d and then C no this cannot come because C cannot come before a see here you can see C cannot come before a so this is false this is wrong a e b d c a e no this is false after a even if you are going to Q then D should come see these are sequential these are sequential but these p and Q are concurrent okay so a cannot come or I can say C cannot come before a or E cannot come before D so you have to check that okay so out of these 1 2 and three are correct let's move to the next question this was a nice question in X 0 and Y is z co Co is same as PA begin so it ends here this is co begin begin x = 1 y = x so whenever you are given with the code for better understanding you should make the Precedence graph so we made a precedence graph we started and then this part and this part are concurrent that's why we made this part and this part concurrent this part included this x = 1 y = y + x and this part include Y = 2 and then x = x + 3 so we have to proceed in the same way in the same way now final values of X and Y which of the following values are possible let's check that is this possible is this possible x = 1 Y = 2 let's see so we started with X = 0 here is the start we started with X = 0 and Y = 0 so I go with this first 1 x = 1 and then 3 Y = 2 x = 1 y = 3 but wait the program is not over yet and then I come to two y = y + x what was y y was 2 y = y + x 2 + 1 = 3 so we got 3 here and then four x = x + 3 x = x + 3 what was x 1 3 so X is 4 the final values are 3 and 4 it is not 1 and two so I have not got it yet let's check for another sequence I started with this I go like this okay let's check 3 4 why would = 2 x = so Y = 2 2 x = to 3 now because initially the X was Z here now I go here x = 1 and y = 2 + 1 = 3 so the value which I got is 1 and 3 no it is not 1 2 3 4 if I go in another fashion like 1 2 3 and 4 in this way then does it go like that x = 1 y = y + x initially the Y was 0 so y will also be 1 now y becomes 2 Y = 2 now let's check for x x = 1 + 3 = 4 now the value which I got is 2 and 4 so this is not there so I can say x = 1 and y = 2 is not possible let's check for another x = 1 for this case x = 1 and y = 3 I should go like 3 4 1 and 2 in that case I got the value 3 4 and 1 and 2 in that case we got x = 1 because the value of x was last updated here and y = 3 how y = to the value of y was last updated here 2 + 1 = 3 so this is correct yes can I got x = 4 and y = 6 let's check for that can I get so this was this was not true this was true can I get x = 4 and y = 6 Let's see we start with we start with one and then we two and then three and four are here 1 and 2 okay so x = 1 so we go like that x = 1 okay and Y = 2 yes and then we move down here x = x + 3 which is 1 + 3 = 4 now I'll go here so this is this way I'm moving now I get here the value of y was last updated to 2 and the value of x is 4 so 2 + 4 = 6 so now I got 2 + 4 = 6 so this is also true so the answer was second and third let's move to the next question the question says int x = 0 y = to 20 so initial value was 0 and 20 we have two binary S4 MX and NY and they are both set to one MX = to 1 and m y = 1 we are given with two concurrent blocks this block and this block and so we made a graph PX x = x + 1 M VX MX see both MX are present here MX X = to y + 1 and vmx now what is the final possible values of X what is the possible values of X we have to get that so as we can see the value of MX is 1 I can say this is the critical section so I say we start with P1 first and then P2 so P1 first it comes here P = to MX now P MX so MX will be changed to Z x = x + what is the initial value of x 1 now V MX MX is changed back to 1 now this comes MX is changed back to zero X = to y + 1 so the value was X was what was the value of x initially it was set to one now what happens here x = y + 1 what is y 20 20 + 1 = 22 21 so in this way I can get the final value of x is 21 I get the final value of x is 21 if I go opposite if I go opposite first this way x = y + 1 what is the value of x initial it was 0 so 0 or so y + 1 = 21 I get the value of x is 21 now I go here x = x + 1 21 + 1 = 22 so 22 so if I say you directly you can solve this question without even lifting a pen how is it possible because you can see we are using binary SEMA 4 here binary SEMA 4 with value one can't you remember that this implies sequentiality there is no such concurrency if we are using Mutual exclusion concurrency means that we are not using Mutual exclusion binary sem 4 with value 1 implies sequentiality we have to first execute either this one and then this one or we can go like this one and then this one but we have to be sequential we have to be sequential we can execute either this block first and then this block or can do the opposite like this one and then this one so the final possible values are 21 22 now it's your homework question if P MX and vmx were not there then what will the value of x think on low level what is the meaning of low level break it onto the instructions like load increment store do like that and and then tell me the value of x if Mutual exclusion was not present okay so this is your homework try this let us start our last topic of the section process synchronization fork and join this is not that traditional Fork which we used to talk about it is not the system called and they are Atomic let's see the syntax of the fork is for l what does this fork in join do this the fork divides and the join joins let's see what does the fork divide execution of this Fork will result in starting of two competitions concurrently which will be the two competitions the first statement after fork and the statement at which label is pointing these two will be concurrently started being executed which two the statement right after fork and the statement which label is pointing so these two statement will be concurrently executed the execution of fork result in starting two computations concurrently the first one is which is immediately after the fork and the second one is which is at label L see this and you'll get more clarity int count equals to two why we have def defined count here for joining purposes this count signify how many edges are meeting at that point if I say count equals to three which which means three edges are meeting at the junction okay s one the root node now comes the division that's why we use Fork so Fork Fork l what does l points L points to the statement three S3 so S3 and what is the immediate next instruction after Fork S2 so S2 and S3 will be concurrently being started executing so S2 and S3 are concurrent here now I have to join I have to join how can I join after S2 the control should go to join after S3 the control should go to join so that's why after S2 to make the control flow go to the join we made the label of join as X and then we wrote go to x so after S2 the control should go to join after S3 the control should go to join for S2 the join was not the next immediate statement that's why we included go to statement but for S3 the join was the next immediate statement that's why there is no need to write go to here it will automatically go to statement X without writing the go to because it is the next statement okay so we write after statement X2 go to x and after statement S three the x is automatically here so join will join two statements so these two are joined and at and they are joined at which node the node which is written or the statement which is written right after the join which is as4 do not worry if you are feeling too much of information overload this is an easy concept and you'll get it believe me so what does join do join in count count equals to count minus one if count is not zero then exit else return forget about this this is not much important but I'm telling you okay let's solve some more question you'll get the idea we'll get back to it we'll see some more questions so S1 what we want we need to Fork so S1 Fork L and L should point to which S3 so the next immediately statement is S2 and L should point to S3 L should point to S3 okay now after S2 I want the control go to S4 control go to S4 now I want Fork here I want Fork here Fork K and K should be S6 and the next immediate statement is S5 so the control will be divided to S5 and S6 S5 and S6 here now after S5 S6 and S6 I want to join them so control should go to the join statement so after S5 the control should go to join so after S5 the control should go to join where is the join join is at Zed so I made the label Zed so after S5 control should go to label Zed after S3 after S3 control should go to label Zed control should go to label Zed and after S6 the label Zed itself here so we did not include it go to and then in the end join count S7 so after join whichever node is present at that node the merging will be there okay I hope you got the idea how it's working so road map is if you are dividing include Fork the next statement and l l is S2 okay and if you want to join join count and then in the end whichever node we are joining write that so this is how four can join work so let's see what was written here after S2 and S3 the control should come to join out of the one which complete at last going to make the count Z that will start as 4 easy same thing it's written here now let's see if if there are more questions yes there are more questions P1 P2 P3 and P4 okay so P1 I want to divide that into three parts see this is an interesting problem in Fork if I write Fork L then the immediate instruction after Fork let's say S1 I'll get S1 here and whichever instruction this level is pointing let's say S2 those two will start concurrently but how I'm going to branch that into three is there any way is there any way to Branch them into three so first of all if you are planning to join them into one node then you should make the count equals to three P1 Fork L Fork L we divided into P2 and L is pointing to another fork and that fork is pointing to another thing that is p Fork so we are using two forks so the first fork and the second Fork are you seeing this the first fork and the second Fork P2 P2 is executed and then label n is pointing to another Fork x n is pointing to another Fork X after X P3 is there after X P3 is there and the next statement that will be there is P4 so P4 is come here so these three will be concurrent and now we have to join them how are we going to join them after P2 the control should go to P5 the control should go to P5 and we have made a label join K so control should go to join K here this way after P3 the control should go to join after P3 the control should go to join X after P3 okay after P3 the control should go to there okay now after P4 the control should go to this join but it is already there that's why we did not include go to so we came here and these three will be joined to which node P5 which is immediately just just after the join let's move to another question this will clarify all your doubts n and M are set to two n is set to two and M is set to two two folks are there which which means right just after the start the program will be divided into three branches for two folks the program will be divided into three branches the first is S1 the first is S1 the second one is the label L3 where is label L3 the label L3 yes this is here the S2 the second one is S2 and the third one will be level L4 where is level L4 here S4 the third one will be here S4 so the program right after the star divided into three things three branches after s the label comes to join n the label comes to join n so we have to join we have to join we have to join and what is n n is the two which means two of the edges are going to join and come at where S3 so S3 will be the point where two edges are joining which two edges are there so the first one is after S1 the L1 which is joining statement comes so the first Edge will be of S1 and the second Edge will be of will be of the statement after which the control is shifted to the label one which statement after which control has been shifted to label one see is there any go to statement go to go to go to go to go to label one is here so after S2 I am finding a go to statement which is sending me back to join so after S2 join is going to happen see we did the same thing everywhere don't get confused whichever edges we want to join after that node we sent the control to the go to statement or the join statement see after P2 we want to join after P2 we want to join that's why we sent to joining statement after P3 we want to join after P3 we want to join that's why we sent to the joining statement after P4 the control will automatically go to join that's why P4 is here to join same thing is happening here after S1 control automatically get to join that's why join after S2 the control has been shifted to join I use the help of go to statement that's why S2 will be there and whichever node is after that join statement the edges will be merging there that's why S3 is here okay after S3 after S3 join M so some join operation will here happen also okay now I have to find the go to statement which is sending the control to this label to go to statement go to statement go to no go to this go to what is sending label to join n no I want the control to join M L4 L2 see here I have found so after S4 the control has been sent to this so from S4 The Edge will come because after S4 the control has been sent to this so after S4 The Edge will come now what will happen whatever be the node after that join statement join will happen there so the join will happen at S5 see in the previous case whichever node after coming join that is S3 join will happen there whichever node after coming the join join will happen there that why join happened here okay now what happens go to next what is next this has already been executed already been executed already been executed go to already been executed now this thing S6 that's why we xess so this is how we solve the questions of for and join just remember one thing or two things I should say for four Fork you should remember two things the control will be divided at two nodes the first which is immediately after the fork and the second will be the fork which is it labeling to see the fork is labeling to L which is S3 should come so S3 came here for fork you have to remember these two things for join which two things you have to remember for join you have to remember after join whichever node is coming join will happen at that node merging will happen at that node and whichever node after which the the control is sent to the join statement that node edges will be merged at the node which is coming after the joining statement let me repeat again see after S5 the control has been sent to join so S5 Edge will be merged at S7 after S6 the control has been sent to join so S6 Edge will be merged at S7 after S3 the control has been sent to join so S3 Edge will be joined at S7 okay so these things you have to remember for for so basically here our section of process synchronization is over but before just uh making it end like that let's see some revision questions the question says consider the following C code where s is a sem4 initialized to five in line two and counters a shared variable initialized to zero in line one assume that the increment operation in line 7 is not Atomic are saying the counter is set to zero the SEMA 4 is set to five there is some function which include two two weight operation one increment and two signal operation it says if five thre execute the function PA of concurrently which are the following program or behavior is are possible there's a deadlock involving all the threads is that possible yes it is possible let's say there are five threads T1 T2 T3 T4 T5 the first one come execute this weight on so this becomes four gets preempted second one come execute the first operation s becomes three now this one comes s becomes two now this one comes s becomes one now this one comes s z now now T1 comes again and start with this but s is zero will get blocked T2 come again and start with this s is zero T will get blocked will get blocked blocked blocked so all of them are blogged in this way deadlock is present so the question was asking which of the following are possible is deadlock possible yes preempt after one instruction and then execute all of them and then when they will come back again they'll get blocked okay so this is deadlock is possible the second question says the value of counter is five after all threads successfully complete the PA of instruction yes the value of counter will be five how let all threads execute sequentially in that case first T1 will execute and then T2 will execute and then T3 and then T4 and then T5 in this way if the sequential execution happen the value of counter is five the value of counter is one after all the threads successfully complete the execution of perrow can the value of counter be one yes when the counter will one okay see this process one P1 or the thread one load increment and it just get preempted before it can store let P2 P3 P4 and P5 complete make the changes so the initially it was Zero when it when P3 was about to make the changes it gets pred P2 P4 P3 and P5 comes makes the changes make it to 4 and now P1 is storing its value as one so this is how the counter is one see we have have done so much of questions like this don't uh feel confused if you are feeling confused just go back watch some lectures we have solved so much of difficult question on that this is an easy one you should uh this should be a cake for cake work for you okay P1 and then in the end we store load increment preemption make that that these process complete and then P1 is come to store so the final value will be one yes this is true the value of counter is zero after all threads execute or successfully complete the execution of per no the value of counter can never ever be zero in any case after the execution of all these threads okay the value of counter can be 1 2 3 4 5 depends on how process executes so so this was an this was uh uh brainstorming question how can the value be one this this way how can value be two these two store later and these two comes first so after P3 P4 and P5 have completed the execution now P1 and P2 comes and store their value so this is how value can be two value can be three when when P4 and P5 makes the change and then P1 P2 and P3 sequential execute and make the value three so this is way things will go on okay now there is another homework question for you if we initialize the sem 4 to one and remove one weight and Signal here so what is the question now the S 4 value is now one and vit s count Plus+ signal s signal s what is the possible value of the count now you have to tell me this see if you tell this wrong I'm going to come at your home and give you a nice beating because we have done this type of question so many times you can even in a blink of eye you can you should tell the answer of this let's move to the next question this is a homework question solve it yourself let's move to the next question int count equals to Z while test let's see another similar question it says int Counting equal to Z void test and then in test there are five times count Plus+ par begin and then two times test so this is like this I can segregate into two count Plus+ count Plus+ five times here also count Plus+ count Plus+ five times now it's asking what is the minimum and maximum value of the count see this is an amazing question this is a nice question you should give it a try for maximum you can directly say when the the value of count will be maximum when the execution is done sequentially first find time this and then five time this in that case the value will be 10 so the maximum value is 10 but can you guess the minimum value the minimum let me tell you something the minimum value is not five and the minimum value is not one now you have to tell me what will be the minimum value and this is a homework problem we will discuss it later okay so here we have officially completed our process synchronization section in the next section we will start Deadlock we have successfully completed our last section that is process synchronization in this section we are going to learn about deadlock what is deadlock how deadlock happen how we can prevent deadlock how we can recover if deadlock is already happened all these things we are going to cover in this section let's start with what is deadlock deadlock is when two or more processes are waiting for an event that is never going to happen or waiting for the happening of an event that is never going to happen Okay so let's say process P1 is waiting process P2 let's say there is a resource some resource R1 that is hold by process P1 and there is some resource R2 that is hold by process P2 now process P1 wanted resource R2 and process P2 want resource R1 they are both waiting that they can get resources but P1 is saying you first release then I'll complete my work and then you will get both resources and P2 is saying the same thing both are adant do you know the meaning of adant it is a stubborn so both are being stubborn I don't know spelling of stubborn is that the spelling anyway so in deadlock the process need to be stubborn otherwise deadlock will not happen and the process should be non preemptive otherwise what will happen suppose P1 is a high priority process so what it will do it will just snatch away the resource R2 from process to so this should not also happen in a deadlock so what is deadlock deadlock is P1 is waiting for P2 to release resource R2 and P2 is waiting for P1 to release resource R1 in this way they are waiting for such an event that is never going to happen why because processes are stubborn they are they will never ever release their resources okay so this is what deadlock is they waiting for an event that is never going to happen but you see they are not only just waiting they are also holding up the resources so this is the worst thing they do not only wait but they hold up the resources the consequences will be uh the throughput and efficiency drops ineffective utilization of resources therefore this deadlock thing is undesirable okay now we have to also understand the difference between what is deadlock and what is a starvation they seems similar in some way but they are not starvation is blocking for indefinite time you do not know the time when you'll get the chance and Deadlock is you have been blocked for infinite time you have been blocked forever and what is starvation blocking for indefinite time so you should know the difference between indefinite and infinite infinite means forever and indefinite means you just don't know okay so here are some examples of Deadlock this is Rachel and this is Ross Rachel wants to make omelette and Ross wants to make pancake so for omelette and pancake they both need a pan and an oil so what happens Rachel gets the oil to start cooking and Ross grabs the pan what happens now they are both stubborn Rachel won't release the oil till she get the pan and Rose won't leave the pan till he get the oil so in this way they are both both being stubborn so adamancy is required for deadlock Rachel is waiting for Ross to release the pen and Ross is waiting for Rachel to release the oil in this way they are both waiting and they will wait for forever so this is what deadlock is okay so we can say Ross uh Rachel is the process one and Ross is the process two let oil be the resource R1 and pan with the resource R2 okay so resource R1 that is uh this o has been assigned to process one that is Rachel so resource R1 is assigned to process one and process one is waiting for resource R2 that is the pan and resource R2 has been assigned to process two that is Ross and Ross is waiting for resource one that is the oil so in this way deadlock occurs so for deadlock cycle is required okay here is another meme from 3 D movie if you not watched that movie you should watch it's a great movie so this is a meme from that M so interviewer ask the candidate explain deadlock and we will hire you the candidate replies hire me and then I'll explain to you so this is exactly what deadlock is let's discuss the salary so now System model what kind of system we are assuming for the study of Deadlock so n depicts the number of process P1 P2 till PN m m depicts the resources R1 R2 RM they can be the hardware resource or software resource okay and the resource can be either single instance or multi instance resource what is multi instance copies of the single instance Source okay now this is the process process request the operating system to Grant the resource operating system can do two things it can grant or it can deny suppose the resources granted process will use the resource and it will release and give it back to the OS and suppose the OS denies the process request then what happens process get blocked and it will starve and suppose after some time operating system feel pity on the process he grants the resources what happens then process will reuse the resources and then after the completion of work it will release the resources back to the operating system but this is a case that that process get blocked and operating system never grants that process it's required re resources then what happens it will be blocked forever there's no one who will wake up the process and say hey your resources has been granted you can go and do your work now no this process has been blogged forever and this is what exactly deadlock is okay for example SEMA 4 in One S then single instance in multiple s then multiple instance it's just the thing that resource can be of two types single instance and multi instance multi instance is nothing but the copies of single instance this is what it's written here now comes the necessary condition for deadlock the first is there should be critical section some shared resource deadlock will never happen among independent processes see here if if Rachel if Rachel never wanted the pen and if Ross never wanted the oil do you think deadlock will happen no deadlock won't happen so deadlock never happens among independent process so there should be some critical section there should be some shared resources the second Point says process should hold some resource and should wait for another this is also the necessary condition for deadlock suppose Rael would have never hold the oil and is never asking for the pen do you think deadlock will happen no for deadlock hold and weight should be there processes holding some resources see here in this case also hold and weight is present so hold and weight is necessary condition for Deadlock process should be holding some resources and asking for another resource if holding weight is if hold and weight is there can I say it implies deadlock no it doesn't imply deadlock but if I say deadlock is there can I say hold and weight must be there yes hold and weight must be there see this suppose this is what this is uh process Pi process Pi has been holding resource R1 and requesting for R2 and R2 has been acquired by PJ do you think deadlock will happen in this case no deadlock will not happen see here here Pi is holding and waiting some of the resources but PJ is not there PJ is not waiting for the for R1 which has been called by pi so in this case deadlock won't happen why see this Pi is just requesting for resource R2 and is it has not get resource R2 delet it PJ has resource art so what it will do it will just use the resource and see here and when a process is granted with some resource it will use the resource and will release back to the operating system so when this PJ will release this this R2 it will be granted to Pi and Pi will do its work is there any case of infinite blocking present no so I cannot say if hold and weight is there see hold and weight is there but deadlock is present no deadlock is not present but but if I say dead log is present then hold and weight should be there yes this should be there see example of Deadlock py P1 is holding some resource and requesting for another P2 is holding some resource and requesting for the another if deadlock is present then hold and weight will be there so if I say hold and weight implies deadlock see this no it doesn't imply deadlock does deadlock implies hold and weight yes see this deadlock implies hold and weight okay third thing no forceful snatching of resource no preemption should be there take this scenario suppose Ross and Rachel are brother and sister and what happens this uh Ross is the big brother what happens he pushes the Rachel away and by force he snatches the this oil bottle do you think now Ross is going to wait for infinite time no this will not happen until she complain his father about his behavior this is one going to happen so if forceful snatching is allowed then deadlock will not happen I hope you are getting the point no forceful snatching of resource this is also a necessary condition and the fourth necessary condition is circular weight should be present circular weight should be there see P1 is waiting on P2 P2 is waiting on P3 and P3 is waiting on P1 in that case deadlock will happen see here no circular thing no deadlock circular thing is present Deadlock lock circle cycle is present deadlock cycle is present deadlock okay so cycle should be there for deadlock okay if these four condition are present then there is a possibility of Deadlock see see here if I say if there is critical section present then there will be deadlock can I go from necessary condition to deadlock no but can I go the opposite way yes if deadlock is present then these necessary condition must be fulfilled see if I say if I say critical section is present then will it lead to deadlock no is this a joke no critical section if critical section is present then there should be deadlock absolutely not and if deadlock is there there should be critical section yes it is necessary it must be there otherwise deadlock won't happen if I say hold and weight is present then deadlock should happen no it is not necessary but if I say Deadlock is there then Wen weight should be there yes this is must same thing for it if I say oh I can say for this thing circular weight if I say deadlock is there then circular weight must be present yes but if I say circular weight is there then deadlock will happen think about it if circular weight is there then deadlock will happen can I say for fourth condition that I can go both around ways can I say so if circular weight is present then deadlock will going to happen I cannot say this because circular weight is a necessary condition not the sufficient one consider this case uh John needs a screwdriver from Mar Mary needs pliers from Ken Ken needs a wrench from Lisa Lisa needs the screwdriver from John and now what happens John says hey Lisa take this screw driver which means they are not admin now so can I say circular weight implies that no what happens if one of them is not adment then deadlock won't be there so circular weight is not the sufficient condition for deadlock but the necessary one if I said deadlock is there then circular weight will be present yes that is must so if these four condition are present then there is a possibility of Deadlock and if deadlock is there then these four condition must be present I hope you got the point now okay in the next lecture we are going to see resource allocation graph let's start with the resource allocation graph the graph consist of vertices and edges in the same way resource allocation graph vertices of two different types processes and resources process is represented using this circular node with pi in between like P1 P2 in this way processes are represented and resources are represented using this square or rectangular node it can be of two different types single instance and and multi instance single instance has one dot in between and multi instance it has multiple dots in in this rectangular body but this dots represent number of instances suppose here are three dots which says there are three instances of resource RG okay now comes to the edge The Edge can be of three types claim Edge request Edge and assigned Edge so the claim says Pi is the process claiming the resource RI and RI is a single resource single instance resource request Edge PJ is a process requesting for multiple resources or two resources of or two instances of resource RG and assigned Edge is the opposite way resource RK has been assigned to the process PK okay let me repeat again so in resource allocation graph there are vertices and edges vertices can be divided into two process and resources resources can be of two types single instance and multi instance the number of dots in the representation that is the rectangle says the number of instance of that resource there are three dots which says there are three instance of resource RJ now comes the edge claim Edge request Edge and assigned Edge the dotted dotted Edge is the claim Edge which means process Pi is claiming the resource RI the single instance of resource RI request Ed says process PJ is requesting for two resource or two instance of resource RJ it's not two resource it's two instance of resource RJ and assigned Ed single instance resource RK has been assigned to process PK so request and assigned is clear what is the claim Ed claim is the process May request that resource in the future and request as says it is actually requested and assigned Ed is resource all allocated to that process claim says may request in future request says it has already requested and assigned says the resource has been already allocated to that process okay so this is resource allocation graph so here one more thing to notice see I have made two arrows here this two arrows signifies number of instances that PJ is requesting suppose if if in a case in which there should be there will be two two resource of RK and that two resources are already allocated to PK so I will add an additional edge here so the number of edges represent how many instances of that resource have been either requested or assigned okay so number of request or assignment is that many edges okay so this is how resource allocation graph looks like process P1 is requesting the resource R1 the single instance of resource R1 has been assigned to process P2 process P2 is requesting for R3 and single instance of R3 has been assigned to process P3 okay one instance of resource R2 has been assigned to P2 and another instance of of resource R2 has been assigned to process P1 okay and this uh one instance of resource R4 has been assigned to process P4 so this is how you have to read the resource allocation graph see this process P1 has got one instance of resource R2 and is requesting for R1 but R1 is not free or R1 is already assigned to process P2 so operating system is not able to give resource R1 directly to P1 so in that case P1 will move to the block State same case for P2 P2 is acquiring resource R2 and resource R1 but is requesting for resource R3 but resource R3 has been already assigned to process P3 so in that case P2 will get to block state P3 but p3s will be able to run on CPU because it has already required that resource which is necessary for it to run on CPU so P3 will is free to run on CPU P3 will run on CPU P3 will after completion of its work it will release the resource R3 and that R3 will be then granted to P2 and after P2 complete its work it will release resource R1 and resource R2 so that R1 will be assigned to P1 now and P1 From the Block state will be wake up by the operating system and that R1 resource will be granted to P1 so this is how it's going to work graph G2 P1 is requesting for resource R1 but is has acquired resource R2 P3 is requesting for resource R2 but has acquired resource R1 P2 is requesting or this is an allocated so R1 is allocated to P2 now see now see P1 is holding R2 and requesting for R1 P3 is holding R1 and requesting for R2 but R2 has been assigned to this P4 do you think deadlock will occur in this case no deadlock won't occur what I've have said if all the processes are blocked by the operating system because the resources were not available at that time to give to the process in that case only deadlock will occur I have said all the process even if one process is free to run on CPU then that process see here that process will release its resour and will prevent deadlock same case is going to happen here R4 see this P4 is going to release resource R2 that R2 will be given to P3 P3 will complete its work and that P3 is going to release resource R1 and that resource R1 will be eventually given to process P1 see here cycle is present but deadlock is not present so from necessary condition I cannot go to deadlock but from deadlock I can go to necessary Neary condition if you are getting confused just remember this line necessary condition are not the sufficient condition if deadlock is present it means that necessary condition must be fulf fulfilled then after deadlock can happen but necessary condition are not sufficient condition same case happened here cycle should be there for deadlock to happen if deadlock is present then cycle must have been there but if I say cycle is present will deadlock happen I cannot guarantee that see this case let's see an interesting case suppose if I add an edge here what can you tell about uh will deadlock occur in this resource allocation graph analyze and see P1 is holding R2 and requesting for R1 P2 is holding R1 and R2 and requesting for R3 P3 is holding R3 and requesting for R2 P1 will be blocked because R1 is not available as it is hold by P2 P2 will be blocked because R3 is not available and P3 will be blocked because R2 is not available in this way these three process will be blocked but see here P4 will run completely P4 even after running will release the resources R4 but can you think R4 is going to help in this matter no it is already isolated so for that case deadlock will be there in this resource allocation graph before was not blocked it was free but even after completing its work and releasing its resources R4 is not going to help in this matter for there I can see it is not required for all of the process to get blocked okay see firstly you have to check if all the process are blocked or not if yes then you can say directly deadlock is present if no then check those process which are not blocked after releasing their resources are are they going to help in the matter of solving deadlock if yes if they will help then deadlock won't OCC and if no then deadlock will occur as simple as that till now we have understand what is deadlock and what is a resource allocation graph how are you going to identify deadlock by seeing a resource allocation graph now we are going to see deadlock handling strategies the first one is deadlock prevention the second one is deadlock avoidance these two deal with the case when deadlock do not occur prevention and avoidance as the name suggest the third one is deadlock detection and Recovery the fourth one is deadlock ignorance so these two deal with the case when deadlock either have occurred already or will occur in future as the name such as deadlock detection can deadlock occur in future and Deadlock recovery if deadlock has already occurred then how are we going to recover from that the fourth one say is deadlock ignorance ostrich algorithm do you know what OST ostrich ostrich does it bury its head into the mud so this is what ostrich algorithm is that is no strategy if deadlock have occurred let it happen we will see the worst cases so this is what deadlock ignorance is okay in deadlock idence we are going to learn about Banker's algorithm this is a very famous algorithm by dter dter is the person who implemented SE 4 you have heard his name so many times in this computer science engineering so txra is a great man or was a great man I don't know dtra have done so many contribution in the field of CSC okay anyway deadlock detection in this we are going to see the doctor's algorithm and Deadlock ignorance or algorithm so we let start with the ignorance ofch algorithm which is no strategy algorithm so when system will go to the deadlock it will get hanged it will get hanged so in that case what we do we press the restart button and fortunately unfortunately what we say windows Unix Linux all uses a algorithm because deadlock occurs very rarely and the cost of prevention is high that's why they say if deadlock occurs just put your head into the mud just bu your head like ostrich do daytoday operating system the deadlock occur very rarely and the cost of prevention high so it doesn't require the deadlock prevention we have to what we have we have to use this deadlock prevention in those operating system in which data and time are critical for those operating system in which we can afford deadlock to happen we don't give much much attention because the cost of prevention is high but in those operating system in which we cannot afford deadlock to happen in which data and time are critical in that case we have to use deadlock prevention strategies you cannot lose one bite of data even for 1 millisecond system should not be down even for a 1 millisecond for example Air Traffic Control missile control satellite control system in these critical operating systems deadlock prevention should be acknowledged okay so now we are going to see deadlock prevention and how are we going to prevent deadlock by negating one or more necessary condition can you remember the necessary condition which we have studied for deadlock the first one was there should be a shared resource there should be critical section the second one was hold and waight the third one we did was no pre no pre preemption and the fourth one was circular weight so if I negate either of these four strategies either of these four conditions then deadlock will not happen see what I have said necessary condition as the name suggest these four condition all of these condition are necessary to happen at the same time for deadlock to occur and if I am able to negate even one of these four condition then deadlock will not happen Okay so this is what deadlock prevention does negating one or more of the necessary condition so let's see one by one which condition I can negate critical section can we remove a critical section well I cannot even imagine of a multiprogrammed operating system without a shared resource so critical section will be there it is almost practically impossible to remove critical section okay so this thing critical section condition is no dissatisfied viable now let's move to the second condition hold and weight instead of hold and weight can we adjust it to hold or weight can we do like that let's see so process must request and be allocated all resources prior to its start if we can do something like that in that case hold and wait thing can be avoided see this P1 for 30 minutes of phase 1 P1 wants R1 and R2 and for 20 minutes of phase 2 P2 P P1 bonds R2 and R3 so generally what process do after the phase 1 that is after 30 minutes process P1 will release R1 hold R2 and will request for R3 because process 1 knows that after after Phase 1 in Phase 2 P1 will going to need R2 so it releases R1 and hold R2 and request for R3 so this is the case of hold and weight but if r R3 is not available it's going to wait so this hold and weight we want to avoid how can we avoid this hold and weight so we have two protocols to avoid this hold and weight the first one is to avoid this case of hold and weight we can do like this process will ask for all R1 R2 and R3 before the beginning of phase 1 so for the whole time when process is going to run in the CPU process will prior request all the resources which is going to need for its whole phases for Phase 1 Phase 2 and even if in future it will go for some phase three then combining all these phases which resources process one will need that it should ask even before phase one so this is what protocol one says so if available hold these resources go on do the work and this will prevent the case of hold and vit because it has got all the resources which which is going to need so there is no waiting there so if available hold and if not wait see there is no hold and wait it's hold or wait if available then hold if not then wait so there is or between either of them will happen either available or not available but there no case of hold and wait but this protocol one gives some serious drawbacks the first one is starv Vision see this process one is waiting for that perfect chance in which R1 is also free R2 is also free and R3 is also free in that case P1 will request and will get these three suppose R1 and R2 P1 is acquired P1 is required R1 R2 but not R3 so what it will do it will release them wait for that time in which R3 is also free request for all these things but what happens R3 is free now R1 is free now but R2 has been acquired by some other process P2 because it is not holding them so for finding that perfect moment R1 R2 and R3 all of them are free this has to wait for a lot of time P1 has to starve so starvation is the obvious drawback the second one is inefficiency in Phase One why are we holding R3 for 30 minutes see why what protocol one says hold all the resources which you are going to need in future even before phase one so when phase one will start for these 30 minutes R3 will be holded by P1 so this is very inefficient utilization of resources so to recover that or to find a better algorithm we had moved to protocol 2 what protocol 2 says process must release all resources before making a fresh or new request suppose this thing happens P1 got resource R1 and R2 completed its phase for 30 minutes now phase one is completed after Phase 1 process will releasee R1 and R2 according to protocol 2 and will ask for R2 and R3 again see P1 has just released R2 and it asking for R2 again so there may be a chance in which when it has released R2 suddenly it got assigned to some other process so it has to wait again so starvation is still present but inefficiency has been renoved inefficiency has been removed see we are not holding R3 in the phase one so in this case hold and weight is not present so for both protocol one and protocol 2 hold and weight has been avoided so out of these four condition first one is non diss satisfiable hold and weight is this satisfiable but it comes with serious drawbacks now comes to the condition three no preemption can we preempt can we preempt let's see so preent preemption of resources from the process can be of two types either forceful preemption or self preemption forceful preemption says running process should not get blocked forceful preemption says running process should not get blocked and self preemption says adopt selfless attitude say this allow pi to forcefully take away RB without bothering what will happen to pjc this is CPU process Pi is running on the CPU ra is already located to process Pi now what happens Pi wants a new process a new request uh what I'm saying Pi wants a new resource RB so it's requesting for a new resource RB but see RB is already allocated to PJ but what my protocol says forceful preemption says running process is of utmost prity running process should not get locked so I will snatch away the resource RB from PJ and will give it to D without bothering what will happen to PG later so running process got the right to snatch away the resources from ready process so this is forceful preemption and what does self preemption says running process Pi founds out that RB is not available instead of snatching RB it will release its resources ra thinking that others might be in need of my resource why should I hold and wait up why should I hold the resource and wait for some other resource instead I should release my resources in order that someone might be present there who is hoping to get the resource which is present with me so both these strategies prevent deadlock let me revise no preemption can it be avoided yes we can do preemption based on two protocols the first is forceful and the other is self what does forceful forceful say running process should not get blocked Pi is Pi already has resource R and is requesting for a new resource RB which is already allocated to some other ready process so what happens Pi snatches away RV from PJ not thinking of PJ what will happen to PJ it snatches away its resources complete its work it's like a selfish attitude and it self self preemption it adopts a selfless attitude Pi is running on CPU ra is allocated to Pi but instead of snatching our resources of RB what happens Pi release away its resources by seeing the hey RB is already located to PJ I cannot get RB from PJ so should I or I should release away my resources because someone there might be someone there might be present who is requesting resource ra so Pi is adopting a selfless attitude by releasing away its resources okay now again comes the problem of starvation you can guess why fourth condition is circular fate circular fate prevented by total order relation among processes and resources so what is this total order relation we will see so the protocol says assign unique number to each resource and never allow a process to request a lower numbered resource than the last one allocated see this so what happen we assign a unique number to each resource there are this is the list of resources I have allocated I have allotted a unique number to each resource to Resource a IED 10 to Resource d i alled four so this is this is a resource ID a unique number okay and now never allow a process to request a lower numbered resource then the last one allocated see this PR PR has been allocated see the resource ID was three now PRI can only request for those resources which has a resource ID greater than three can it a request for B yes 8 8 is greater than three yes now it can only request for those resources which has a resource ID greater than 8 can it request for D no can it request for G no can it request for a yes because the resource ID of a is greater than the resource ID of B so what are we doing here basically we are removing the cycle and we are introducing linearity to avoid circularity okay so what does this algorithm say process I can only request for those resources which have ID greater than 10 now now it can only ask for those resources which have ID greater than 10 which means it can ask for either F or e that's it okay now say this if process I request for those resources which has a ID less than 10 then what happens suppose process I request for G then what will happen it has to go back and you can see the cycle is forming if request if it request for five then cycle condition what to do then resource preemption okay so you know what to do you have to preempt the resource and then Grant again how suppose after getting a after getting a resource with resource ID 10 the process wants to get resource with the resource ID of five which means process one to get resource G now what will we have to do we have to snatch away the resource with resource ID 10 we have to snatch away with the resource with resource ID 8 and now I can give the proc with resource id5 so now 3 5 8 and 10 now we are going to Grant it again so basically whatever we're doing we are just avoiding circularity we do not want circularity the first firstly the process got resource three then eight then 10 now it wants five so what I will do I will preempt 10 preempt eight assign five and then we'll Grant again 8 and 10 so in this way the linearity is maintained as circularity do not come the resource given plus linearity is there now starvation is obvious starvation may come because when I preempted these resources some other process May request for this so I can give process request I can give process the source id5 but when it will request for 8 and 10 Again these were already allocated to some different process so it has to starve so this granting again thing is dangerous it invites starvation so after these four condition which conditions which we can negate so the first one was can we remove critical section no we cannot remove critical section second one was hold and waight can we avoid hold hold and weight yes we can avoid hold and weight by two protocol the first one was ask for all resources in the beginning the second one says if you made a new request you should release all the previously assigned resources the third one says no preemption yes we can preempt the first one is forceful the second one was self and the fourth one says circular weight can circular or the cycle be avoided yes it can be avoided by this algorithm a process can request only those resources which has a resource ID greater than the previously allocated resource ID okay in this way the cycle is preed prevented in our previous lectures we have learned about resource allocation graph in this lecture we are going to see an interesting property of resource allocation graph so if RG is a resource of multi instance type then cycle is only a necessary condition focus on the word necessary if cycle is present there may or may not be deadlock but if deadlock is there then there must be cycle cycle must have been there okay but but if there are only single instance type resources in that particular area of a graph where cycle is forming then in that case cycle is necessary and sufficient also in that case I can see cycle leads to deadlock see for General cases I cannot see necessary condition leads to deadlock this is false but if deadlock is present then necessary condition must have been fulfilled but here in this case if only single instance type resources are present then I can say cycle leads to deadlock then I can say cycle leads to dead log is correct okay you have to remember this so let us summarize only multi instance cycle is necessary combination of multi and single instance cycle is necessary only single instance cycle is necessary and sufficient so in our last lecture we have learned about deadlock prevention in deadlock prevention what we try to do we try to negate one of the four necessary conditions in deadlock avoidance what are we going to learn let's see so deadlock avoidance can be divided into two parts are single instance and multi instance single instance in which resources have a single copy and multi instance combination of single and multi instance a resource can have multiple instances okay so in single instance we are going to learn about resource allocation graph algorithm and for multi instance we are going to learn about Bankers algorithm you must have heard the name before okay so both algorithm are based on a prior knowledge you know meaning of a prior beforeand and the operating system should know that with that the process is going to need which resources in future while executing so that is a prior knowledge every process need to tell which resources she needs before hand to the operating system okay that is a prior knowledge now let's learn about resource allocation graph algorithm which is based on single instance type okay so as I said it is based on a prior knowledge the process need to tell which resources she needs beforehand to the operating system and based on the request operating system will grant or deny its request so on what factors operating system grants or deny the request it will see if operating system grants that resource to that process where the system will lead to okay if it it will lead to save State then resource will be granted and if it will lead to the unsafe State then resource should be denied so operating system will see the is fulfilling that request will lead system where will it be safe will it be unsafe what does safe signify the S safe signify that there won't be any deadlock and what does unsafe implies it says there is boring there may be likelihood of Deadlock deadlock may be present okay there are chances of Deadlock okay so unsafe doesn't mean deadlock UNF says there are chances of Deadlock okay so there are three points which you have to uh focus upon while Learning Resource allocation graph algorithm the first thing is resources are claimed a prior in the operating system okay that I have explained what is a Priory if the process Pi start executing then all claim edges must appear in the resource allocation graph see I have told you what is claim Edge claim Edge is that edge that dotted Edge which go from process to Resource which signifies that that process May request that resource some in the future okay so what does claim ad says in future request may happen Okay suppose if Pi request some resource R let let me if process Pi request some resource R then request is granted only if when request Edge is converted into assigned Edge and that introduction of New Edge is not going to lead or is not going to introduce a cycle in the graph let me repeat when a claim edch is converted into assigned Edge then cycle should not come in the graph see firstly it was claim Edge the process May request somewhere in the future then process actually request and then when operating system grant that resources to the process then assigned Edge comes and introduction of this new Edge should not introduce a cycle in the graph see adding a new Edge May introduce a cycle in the graph that should not be there and if that is present then operating system will deny see this if in resource allocation graph algorithm when we are talking about single instance type then cycle will lead to a deadlock okay so no cycle then then safe State and cycle then unsafe State why I written unsafe State instead of Deadlock if I knew that resource allocation graph algorithm work on single instance resource and we have learned here that if there are only single instance resource then cycle is necessary as well as sufficient so why have written here cycle will lead to unsafe State not deadlock the reason will be clarified in the example which I have taken so the base objective of resource allocation graph is is to always operate the system into safe State and what does safe State means if request Edge is converted into assigned Edge then that edge does not lead to a cycle in the RG if you getting confused don't worry here's a perfect example it says the P1 is holding R1 and this as shows that it may request for R2 P2 is requesting R1 and may request for R2 in future so this is what this graph says okay here should be P2 you should correct that in your notes also now if I ask you is the current state is in safe State you will say absolutely it is in safe State because there is no possibility of cycle here see I cannot go this side because the arrow is in opposite direction so cycle is not present so I can say the system is in safe State when will system gets into unsafe State the system will get into unsafe State when a cycle is introduced okay so when a cycle will be introduced suppose R2 is granted to P2 now the arrow changes now cycle is introduced so I can say the system is in the system is in unsafe State why not deadlock because this Edge is not an actual Edge it is a claim Edge so for just saying we are saying that cycle is present but actually this is not an actual Edge this is a claim Edge it may request for R2 in future okay that's why we have written here that if cycle is present then it is unsafe state but if P actually request for R2 then it is surely a deadlock State not an unsafe State now it is surely in deadlock State how can I say it is in deadlock because first of all we are Learning Resource allocation graph algorithm and this algorithm is defined only for single instance resource and I have said that for single instance resource cycle is necessary as well as sufficient condition so when when P1 request for R2 deadlock will surely happen see this R1 is with R1 is granted to P1 so P1 is holding R1 and requesting for R2 P2 P2 is holding R2 and requesting for R1 you can see a cycle clearly that's why deadlock is is present so claim Ed is also a part of graph claim is not different that's why we have said that when in this case we have said that the system is in unsafe State because cycle is forming but it is not an actual cycle clay match is not an actual as but it is still part of the graph okay I hope the point is clear now so the first system was in safe state it wents to unsafe State and then finally to Deadlock and what is the basic purpose of resource allocation graph algorithm it operates to keep the system is in safe mode in above case when claim Edge when claim Edge becomes the request Edge then it is allowed see here when this claim Edge must have become become request Edge at some time that's why R2 is granted to P2 otherwise how will operating system know that P2 is requiring R2 so this clay Edge must have become request Edge at some moment so when this clim Edge become request Edge then also cycle was not present see here it is in the opposite direction but as soon as operating system fulfill its request and grants R2 to the P2 cycle is introduced well that will lead system to the unsafe State okay now you have to understand the difference between unsafe State and Deadlock unsafe state says there are chances of Deadlock not an actual deadlock so I can say this this is unsafe State and Deadlock is just a small part of it okay so System state there there can be they can be segregated into two safe and unsafe and Deadlock is a part of unsafe State okay and unsafe State just signifies the warning it is it say that deadlock may occur okay so this is what resource allocation graph algorithm in the next lecture we are going to see Bankers algorithm we were learning about deadlock avoidance we have already learned about resource allocation graph algorithm which was it was based for single instance resources now let's move to Banker's algorithm for multi instance it has two subart safety algorithm and resource request algorithm before directly jumping just to safety algorithm let me establish the foundation okay so the N is the number of processes m is the number of resources okay maximum this is an twodimensional array this is a 2d array which takes to parameter I and j i refers to the process and J refers to the resource so maximum of I comma J equals to K this says that process I requires maximum K copies of resource J I can say it as a demand what is the demand of process process I demands K copies of resource J and this demand is made a prior before execution okay let me repeat again process I demands K copies of resource let's move to allocation allocation says K copies were demanded but only a were allocated to process I let me repeat K copies of resource J were demanded but only a copies were allocated for now so allocation is always less than equal to demand and what is need need says how much more copies you want of resource J to fulfill your demand how much more copies this more is an important word so I say process I requires B more copies of resource J so need equals to demand minus location B = to K minus a be more copies required for satisfying the demand okay what is request request is time dependent request made by process I for C copies of J at time T at time T what the process is requesting and you can guess that request should always be less than need so the request made by process I at time T should always be less than need okay Total 1 to M this ISS that for resource J there are total Z copies present there are total Z instances of resource J available says that at time t e copies are available of resource J and I can say that available should always be less than total so e is less than equal to Z are you getting the point let me maximum was demanded process I demanded K copies of resource G okay and a copies were allocated so how much more copies it needed to satisfy the demand B more copies and at time T it request for C copies and that request should always be less than equal to the need the total Z copies of resource J are present and at time t e copies are present so I can say the available should always be less than equal to Total don't worry if you're getting confused when we will see the example you will get the clarity so if I say total 100 copies of a resources present I will say allocated R 70 then what is available available equals to Total minus allocation and this allocation is for all the process I have I had 100 chocolates I distributed 70 chocolates in the class how much chocolates is available to me 30 chocolates and I can say that number of chocolates available to me should always be less than the total chocolates okay now based on these parameters the operating system will Define that at a time the system is in safe state or unsafe State let's see this example there are total five process I will name them as P1 P2 P3 P4 and P5 these are the demands of that five process P1 demand 10 copies of resource R P2 demands eight copies of resource R in this in such in this way these are the demands of these processes respectively now based on this demand operating system allocated some of the resources to the processes and these more instances of that resource process need to satisfy their demand okay so I had total 21 copies of the resource R I have total I had total 21 chocolates okay now in this way I have allocated the chocolates to the processes so how much chocolates out of 21 I have allocated 19 how much I am remaining with two chocolates now can I satisfy the any process can I satisfy the need of any process no at least I should have three chocolates so in this case I can say the system is unsafe the safety algorithm says system is set to be set to be safe if the need of all process can be satisfied with the available resources otherwise unsafe can the need of all process be satisfied with the available resources absolutely not absolutely not so I can say the system is in unsafe state so if available uh were two then the system was in unsafe State let me say now the available are initially 22 so if initially 22 were available I have allocated 19 how much I'm remaining with I'm remaining with here now is three now can I satisfy the need of any process yes I can satisfy so let's say I satisfi I satisfy the need of this P4 I allocate this three resources to satisfy the need of P4 now P4 will get these three resources okay so now how much allocated five were allocated five was the demand P4 will complete its execution and will return five to me again now how much are available five are available are you getting the point see initially how much I had I had three I allocated three to P4 to satisfy demand P4 now had five resources two was initially given now three more so total it has five resources what was the demand five only so P4 has what it was demanded what it has demanded so P4 will complete its execution and will return those five resources back to the operating system now how much are available now five is available I will give out of five three to this P5 now P5 already had three Okay so P5 will complete its execution and will return these six resources to me again out of five I have all alloted three to it so how much I was remaining then two and this six will come again so now I have eight resources did you get the point I had five out of five I allotted three to it now three and three became six the need was the demand was satisfied now after the execution this six will come and join here 2 + 6 = 8 now how much I have I have eight okay so out of eight I allocate 7 to P3 remaining is 1 I located 7 7 and five was already there so 7 + 5 is 12 the demand is satisfied now these 12 after execution will be given back to the operating system so now I had 12 so initially I had 1 again 12 so now I have 13 13 is there with me now I satisfy the need of P2 so how much I have remaining nine 4 and four are eight after execution this eight will come and will be added here 9 and 8 is 17 okay now how much I had I had 17 now I satisfy the need of P5 so 12 is remaining with me satisfied the need of P5 5 and 5 is 10 the demand is satisfied after the execution this 10 this 10 copies of resources will be given back so now 22 the need of all the processes is satisfied and how much copies of resources are with me 22 resources that was the number of copies which I had initially so initially I had 22 after the after the uh satisfy satisfaction of all the uh demand of res of the demand of processes in the end how much I got again 22 so if you can see initially was 22 finally after satisfying all the demand I got 22 then and it means that it is a safe sequence to follow this it means that the system is in safe State based on the available resources I was able to satisfy the need of all the processes and the sequence which we follow which sequence we followed we followed firstly we satisfi the need of P4 then we satisfi the need of P5 then P3 then P2 then P1 then I satisfied the need of this P3 but it is not necessary I can satisfy the need of P1 also P4 also so the safe sequence need not to be unique it can be different okay there can be multiple safe sequences all process must be satisfied but in that safe sequences so if safe sequence is coming and all the processes demands are satisfied then I can say the system is in safe state in the last lecture we were learning about Banker algorithm we learned a question in which single resource with multiple instances was present multiple instances represent in this we are going to see multiple resource with multiple instances let's see how are we going to tackle this let's first understand the question the question says based on the given time T not can you tell me the system is in safe state or not these are the process ID their demands are written here P0 demands seven copies of resource a five copies of resource B three copies of resource a P3 demands two copies of resource a two copies of resource B and two copies of resource these are the demands and the allocation is how much of their demand is fulfilled now zero copies of resource a have been given one copy of resource B zero copies of resource C given to p 0 so these are the allocation how much of their demand is fulfilled at time t0 how much more should be given to satisfy the demand is need and how can we calculate that demand minus allocation so 7 0 is 7 5 1 is 4 3 0 is 3 so this is how we calculated the need need is how much more is needed to satisfy the demand this is the available the number of resources which we are available with this is the total resources how are we going to find the total resources the number of resources which we have allocated till now the number of resources which we are available with add them both and we will get total okay the question is can we satisfy the need of all processes with this scenario let's check we are available with three three and two copies of a b and c respectively can I satisfy the need of any process can I satisfy the need of this no the required are seven and I have three only can I satisfy of this yes yes and yes so I'm going to start with satisfying the need of P1 out of three I give one copy out of three I give two copies and out of two I give all the copies so what I'm remaining now I am remaining with two copies of resource a one copy of resource B and zero copies of resource C so I have completed the demand of P1 so now P1 will freely execute and after execution it has to return the resources so the resources when when they will be returned they will be added back to the available resources what is the available 2 1 and 0er so 2 + 3 is 5 1 + 2 is 3 and 0 + 2 is 2 so now I am available with these many resources 5 3 and 2 can I satisfy the need of this no required is seven I have five only can I satisfy the need of P2 no required is six I have five only can I satisfy the need of P3 yes I can so out of five zero is needed out of three 1 is needed so now out of three one is needed so I'm remaining with two out of two one is needed so I'm remaining with one so this is the remaining resources I have after satisfying the need of P3 so when P3 is execution will be completed it has to return the resources so it will return these resources 5 + 2 is 7 2 + 2 is 4 and 1 + 2 is 3 so now I'm available with these many resources 7 4 and 3 now which process need I can satisfy can I satisfy the need of this yes I can so I will allot 7 to p 0 four of resource B to p 0 and three 3 to P0 okay so now I'm remaining with 0 0 and 0 the already allocated was 01 0 I have allocated 743 now so need plus allocation is is what the demand is so I have satisfied the demand of p 0 so p 0 will fully execute now after execution it has to return the resources now what is the resources I'm left with I'm left with this 7 5 and 3 but I can see the number is different here it's like 7 4 and five but we are getting 7 5 and three it's just because I have chosen different path to show that there can be multiple CF sequences I am choosing a different path to complete if I able to get the same uh number of resources which I had in total then I can say the path was correct okay so let us prove that there can be multiple CF sequences so I am remaining with 7 5 and 3 let us satisfy the need of P2 P2 the number of required resources for a is six so now I remaining with 1 5 and three because B and C are not required p2's need is satisfied or demand is satisfied so I will say P2 will execute freely and then it will come back it has to return the all the resources so 9 + 1 is 10 five and five I can say like this okay now I have satisfied the need of P2 also now it's turn for P4 so for P4 how what if I satisfy the need of P4 then 10 4 is 6 5 3 is 2 and 5 1 is 4 I I am available with with these many resources okay now p4's demand is fulfilled so it will execute freely and when after execution it will return it has to return the resources so 6 + 4 is 10 now I am available with 10 3 + 2 is 5 4 + 3 is 7 isn't that the total number of resources yes so I can say multiple safe sequences are possible plus I can also say that this scenario is of safe State because I was able to satisfy the need of each and every process available with me okay so the safe sequence which was followed here was P1 P3 P4 P2 and p 0 but sh sequence that we followed was P3 no it was I think P1 P3 then uh p 0 P2 and P4 so the point is there can be multiple safe sequence it is no need that safe sequence should be unique so this is what Bankers algorithm in the next lecture we are going to see the resource request algorithm in the last lecture we have learned about safety algorithm of Banker's algorithm in this lecture it's time for the second part resource request algorithm they both work together to create the bankers algorithm okay so we are going to see how let's first understand resource request algorithm I hope you all remember the meaning of these uh variables Pi is the process requesting for some resource or the instance of resource at time T allocation is number of instances I have given to that process and need is how much more instances a process need to satisfy its demand and available means after location how many instances of the resources I'm left with that is available okay and we have also discussed that request should always be less than need and request should always be less than available resources okay I I cannot request more than my need I cannot request more than what is available okay now assume that we have satisfied the request process made some request and assume that we have satisfied now satisfying means we have already allocated that process those many number of instances of a resource that it is requesting so allocation will increase its need will decrease now it will need less number of uh instances than before to satisfy demand and number of available instances will decrease okay let me repeat after allocation the allocated number will increase the need will decrease because now the process needs less number of instances to satisfy demand and number of available instances will decrease okay so first things to check is is my request less than need the second thing to check is is my is the request less than available if both of them are true then assume that we have satisfied the request we are assuming so assuming we have satisfied the request what will be the new value of available need and allocated the value of available will decrease need will decrease and allocated will increase now we will run safety algorithm if the system is in safe State Grant the request I else deny request I and block the process so this is how resource request algorithm works with the help of safety algorithm let's see an example at time T1 P1 requests one copy of resource a zero copy of resource B and two copies of resource C this is the request made by P1 at time T1 and we are available with 3 3 and two we have taken just the same example of uh we have used before this one same example here okay so the request now is 1 0 and 2 how are we going to proceed so the first thing I told you to check is is my request less than need so what is the need of process P1 the need of process P1 is 1 1212 the demand is 322 the located is 20 and the need is 122 and at time T1 it request for 102 so is the request less than the need so I can say yes the request is less than equal to the need is my request less than equal to available what is available 3 3 and two and the requesting is 102 is then less than equal to available yes it is less than equal to available so after doing after checking both this I can say let's assume that request has been satisfied so if I have satisfied this request what will happen now out of available I will give one to process one this one resource to process one three copies of resource V to process one no not three it requires zero so for this time at time T1 process do not require for uh resource V so zero and two copies of C2 process one now now we have to update the need now we have to update the need so after the satisfaction of the request this available will decrease 230 because I have satisfied 102 I have I have allocated that so the number of allocation will increase 2 + 102 1 02 so 3 0 and 2 so this is the allocation number the need will decrease Now 1 02 0 2 and 0 so need will also decrease available and need will decrease and allocation will increase so this is my new values now what we are going to do we are going to run the safety algorithm what is the the number of available resources I have now I have 2 3 and 0 what is the need of process uh one now the need is 02 and 0 what is the allocation number 302 so 302 now based on the new values I will run safety algorithm okay so we are available with these many resources let's check whose need I can satisfy can I satisfy the need of P0 no can I satisfy the need of P1 yes I can satisfy out of two 0 will be given 3 two will be given so I will be remaining with 2 1 and then zero so these are the remaining resources after uh satisfying the demand of P1 these many resources will return back so I have to add them 3 + 2 is 5 2 1 2 + 1 is 3 and 2 + 0 is 2 so now I have these many resources 5 3 and 2 now now which whose needs I can satisfy can I satisfy the need of this no can I no can I yes I can satisfy the need of P3 so let's satisfy the need of P3 5 0 is 5 3 1 is 2 so now I have two copies of B available after satisfying the need of P3 then 2 1 is 1 so this is what I'm available with I have satisfied the demand of P3 now these resources with return back 5 + 2 is 7 2 + 2 is 4 2 + 1 is 3 so now I have 5 7 43 resources available with me whose need I can satisfy now let's satisfy the need of P4 4 3 and 1 okay so 7 4 is 3 3 4 3 is 1 and 3 1 is 2 these many resources I have after satisfying 3 1 and two after after satisfying the need of P4 now when P4 will execute after execution these many resources will come back so 7 + 4 is 3 7 + what I'm saying 4 + 3 is 7 3 + 1 is 4 and 3 + 2 is 5 7 4 5 I have now remaining resources now can I satisfy the need of P0 yes I can satisfy so out of seven I will I have zero remaining out of four I have zero remaining out of five I have two remaining so these many resources I have after completing the need of p 0 so after execution these many resources will return and add 7 + 0 is 7 5 + 0 is 5 and 3 + 2 is 5 so I have these many Resources with me 7 755 now can I satisfy the need of P2 yes I can so out of seven I have given 6 to P2 so one is remaining with me five so 0 0 5 so 1 5 5 is remaining with me so after P after execution of P2 these many resources will come back and add so 9 + 1 is 10 5 + 0 is 5 and 5 + 2 is 7 isn't that the same number which we have in the beginning this total yes so I can say that the system is in safe state so if the system is in safe State I have found a safe sequence then this request can be satisfied or this request can be granted okay so this is how we have to find out whether a process request should be granted or denied now let's solve an interesting question it says an operating system uses Bankers algorithm for deadlock avoidance when managing the allocation of three resour type X Y and Y and Zed three process p 0 P1 and P2 are there the table given below present the current system State here the allocation Matrix shows the current number of resources of each type allocated to each process and maximum Matrix shows the maximum number of resources of each type required by each process during its execution so maximum is the demand and allocation is the allocated till now there are three units of Type X so this is the available what we have 322 three units of Type X two units of type Y and two units of type Z is still available the system is currently in a safe State consider the following independent request for additional resource in the current state okay so the request says p 0 make a request of 002 and P1 makes a request of 20 now how how are we going to check whether this request will be fulfilled or not we are going to check using resource request algorithm this is the table which we are given with So based on this we will calculate the need need equals to demand minus allocation 8 0 is 8 4 0 is 4 3 1 is 2 so in this way we have calculated the need now the request says 0 0 and two first of all we have to check whether this request is valid or not the request is valid when it is less than equal to need is it yes it is the request is valid if it is less than equal to available is it yes it is now we have to check after satisfying this request whether the system will in safe state or not so let's say I'm satisfied uh what I'm going to do I'm going to decrease the value of need I'm going to decrease the value of available and increase the value of allocation now it will become three based on the updated values run safety algorithm and see whether the system Still Remains in the safe state or not okay so I have available 3 2 and0 I can satisfy the need of P1 okay so now after satisfying the need of P1 I'm available with 0 2 and 0 okay P1 after its execution will return these many resources so now I have 6 2 and 0 so 6 4 and 0 available I have is 6 4 and 0 now I can satisfy the request of P2 after satisfying the need of P2 how many resources I have now 5 2 and C here we cannot satisfy the need of P2 because we have zero instances of type Zed but here P2 is asking for t two so we have to first satisfy the need of this p 0 can I satisfy the need of p 0 no I cannot satisfy the need of p 0 because the number of instances of resource X needed is 8 but we have six only so I can say I cannot satisfy the need of either p 0 or P2 so I can say that system has now come into unsafe state so I will say this request will be denied let's check for request number two request number two says that P1 20 2 is request less than available I have available of 322 yes it is less than available is it less than need so the need was 3 yes it is less than need need is 3 request is 20 yes after satisfying the need will the system land into saf state or unsafe State how are we going to check that using using the safety algorithm so we will apply CFT algorithm on the updated values so now we have to update the values available resource how many available resource we have now 1 22 so 1 122 will be the available resource now and I have to decrease the need also so 3 was the need I have satisfied the need so now what is the need now or what is the updated need 1 0 0 see I have I have satisfied the need of 20 the initial need was 3 so what is the updated need 1 0 and allocation will be two more is allocated so three will be Chang to five so this is now the updated values now have to run safety algorithm on these values with 1 122 can I satisfy the request of P2 yes so now I have available 0 0 and 0 P2 after running will give me back these resources so now I have 333 can I satisfy the need of p 0 now no I cannot so I have to first satisfy the need of P1 so after satisfying the need of P1 how much I have remaining now 2 3 3 so P1 after running is going to give me these many resources back so 6 2 and 0 are we got back so 8 6 and 2 8 3 and 2 5 and 3 so 8 53 is now the available resources can I satisfy the need of p 0 now yes I can so now I'm remaining with 0 1 and 1 after running I will get 843 back back so I will get 843 back 843 8 5 and 4 8 5 and 4 so this we have in in this manner we have satisfied the need of each and every process we have satisfied the demand of each and every process so I can say the system is in safe state so this request will be granted in the next lecture we are going to learn deadlock detection and Recovery now we are going to learn deadlock detection and recovery so when are we planning to apply this detection and Recovery thing when you see something odd let me ask you a simple question when you go to the doctor when you are not feeling well so the based on the symptoms you tell to the doctor doctor estimates the problem and run the test okay in the same way operating system notices the symptoms like underutilization of CPU majority processes are getting block so by these symptoms by noticing these symptoms operating system runs some test and by the diagnosis operating system tells whether the deadlock is present or not okay so this is what detection is based on the symptoms we run test and then we get the idea whether deadlock is present or not so in the same way when we divided the deadlock avoidance on the basis of number of instances a a resource contain like deadlock avoidance was divided into two part resource allocation graph and bankers algorithm in the same way for single instance resources we have weight for graph method and for multiple instance of resources we have safety algorithm method so first let's learn about single instance that is wait for graph in wait for graph what we do we remove the resources and just keep the processes so R3 will be removed and the arrow will go like this in this way this R4 will be removed and arrow will go like this or I can directly say this this R3 R5 will be removed and arrow will go like this okay so I hope you are getting the point we are removing the resources and just keeping the processes okay so weight for graph contain only the process and after we have drawn weight for graph Run Cycle detection algorithm that is if cycle is present or not and we are talking about single instance so we can say that if cycle is present then deadlock will be there there because for single instance resources the cycle is not only just the necessary condition but it is sufficient as well okay so after detection of algorithm what are we going to do victim processes will be sent as input to the recovery module the recovery module will do something and it will recover what we did first based on the symptoms we are going to run some test so okay if the resources are single instance then we will make a weight for graph how weight for graph is made by removing the resources and just keeping the processes and if I see a cycle present in the weight for graph then I can say that deadlock will be there because in single instance cycle is not only the necessary condition but sufficient as well and that victim processes will be sent to the recovery module okay now comes the multi instance this is allocation this is the request made and this is available okay so I can see that based on the available resources how many process request won't be fulfilled so p 0 request will be fulfilled P1 failed P2 fulfilled P3 failed P4 failed so P1 P3 and P4 will be blocked see there are five processes and three of them are blocked majority process are getting blocked so there are chances of Deadlock system is safe if request of all processes satisfiable with the available copies in some order this is exactly like the safety algorithm but in safety algorithm what we used to say we say that the system if if the available resource are not able to satisfy the request of some processes then there we used to say uncf state has occurred but now here will say deadlock is there okay okay so let's see this can I satisfy the request of P0 yes so the location will come back the location will come back so 0 1 0 is now the available resources I have can I satisfy the request of P2 yes the location will come back now I have 3 1 and three this is the available resource now I have now can I satisfy the request of um P3 I can even satisfy for P1 also so okay let's P1 I satisfy the request of P1 now I am available with one one and one after P1 request is satisfied what is allocated now allocated now will be 4 0 and 2 so this will come back now I have 5 0 5 1 and 3 this will come back and added here now I will will satisfy the request of P4 so in this way I can say that the request of all process can be satisfied in some order here what we are seeing that available was not able to satisfy the request of P1 was not able to satisfy the request of P3 was not able to satisfy the request of P4 so P1 P3 and P4 were blocked but when available satisfies the request of P Z it got some of the resources back and when the resources available are enough to satisfy the request then those sleeping process or those blocked process will be brought back to the ricq okay so this is how safe state is achieved even though we got a symptom that out of five process three process are blocked but still we are saying that no problem because the result of the test is negative the result of the test says that dead log is not present okay now what happens P2 makes a new request P2 makes a new request 0 01 now what happens P2 makes a new request of 01 so let's see here P2 makes a new request of 0 0 0 and 1 okay okay let's run safety algorithm now request of p 0 will be fulfilled this will come back and add here now I have available resource this can I can I satisfy the need of P1 no can I satisfy the need of P2 no can I no no so all of these process will be blocked only p 0 was completed and it terminated so now these four process which I have with me are blocked all the process are blocked this is the case of Deadlock so these four processes will be sent back sent to the recovery module as an input okay so this is how it work let me repeat again what happens initially we saw that majority process are getting blocked so we should run safety algorithm we run safety algorithm and we successfully were able to satisfy the request of all the processes we can say the system is in safe State even though we got a symptom but no problem here because the test is negative but what happens now P2 makes a new request 001 so when P2 makes a new request of 001 I was only able to satisfy the request of p 0 and rest of the process were blocked so this is the case of Deadlock okay now what happens these victim process will be sent to the recovery module as an input okay so how does this recovery module work let's see in the next video in the last lecture we have seen the deadlock detection now what happens after detection recovery so the deadlocked process will be sent to the recovery module and it has two ways to work either it works on processes or resources for process let's say there are three process P1 P2 P3 each dependent on one another so the first thing it can do is abort one process at a time until the elimination of Deadlock cycle suppose I uh removed this P3 now what happens when P3 is removed the resources of P3 will be given to P2 now P2 will complete after the completion P2 will return back those resources and will help P1 to complete in this way the deadlocked will will be solved and the process will complete but in this Solution One process has to sacrifice the second solution says delete all the process about all the deadlock process okay now comes the resource the resource solution says do the preemption of resources let me say P1 P2 and P3 each depending on one another now what happens the P2 is a strong process strong in terms of priority so P2 is a strong process P2 will snatch away the resources of P3 now P3 don't have the resources P2 will get itself completed and will return back the resources and P1 will get those resources because P1 was dependent on P2 so P1 will get the resources and P1 will complete and when P1 will get completed it will return the resources to P3 because P3 was dependent on P1 in this way neither of the process has to get deleted and all of them was completed without any loss okay so preemption was a method and roll back what is roll back we will see in a minute okay so now the question arise for abortion of one process which process to have we have to kill the algorithm says the one who has just started that process you have to kill okay then apply the deadlock detection algorithm again and again now comes the roll back part what we do we will keep preempting the latest resource add them to the available pool and run the detection algorithm again after each preemption and we will keep preempting until the cycle is broken so this is how resource preemption works and process recovery based on the process and resources okay now let's see the difference between prevention avoidance detection and ignorance this prevention and avoidance is like a proactive attitude you already take the preventive measures you already try to avoid the deadlock in these cases deadlock do not occur and this detection detection and Recovery is like a reactive attitude deadlock has occurred now do what you can do and the ignorance is the inactive attitude let's read this prevention this approach is about taking proactive measure to stop problems before they occur it's a proactive attitude because it involves planning ahead and taking action to prevent issues and what about avoidance this is about steering clear of potential problems it is a reactive attitude because it involves responding to the possibility of issues avoiding them so avoidance can also be segregated into reactive attitude because it involves responding to the possibility we we try to avoid the deadlock detection deadlock has occurred now do what you can do deals with the issues after they have happened and it ignorance this is when no action is taken either to prevent or avoid and recover from problem it is an inactive attitude because it involves doing nothing in response to potential or actual issues now let's see some problems so the total process are n each process need two copies of resource R the total number of available copies are 1 2 3 4 5 and six now we have to tell now we have to tell minimum number of processes required to cause Deadlock let's take let's start with three process I have allotted both the process to two resources so they will all complete no possibility of Deadlock now let's go here we included five processes so what happens first one given to P1 second to P2 third one to P4 fourth one to P5 fourth one to P4 and 5 one to P5 now one copy of resource R is remaining so I have to assign it to some of the process some process out of the let's say I'm assigning that to P1 now what will happen when P1 will complete it will release its resources back and that resources are going to help other process to complete in this way P5 with P5 process with five process the deadlock is not there now let's say I increase one more process now what happens first one given to P1 second to P2 third to p 3 4 to P4 fifth to P5 6 to P6 now I have used all the available resources in this case each of the process is waiting on another to leave a copy of resource so that it can complete this is just like the case of dining philosopher in which each philosopher picks up the left Fork so minimum minimum number of process to cause deadlock is six and maximum number for deadlock freedom is five maximum of number of process for which deadlock won't occur is five let's see another question there are three process now you have to tell me the resources each process require two resources now tell me the number of resources such that the deadlock will occur maximum number of resources to cause deadlock so maximum number of resources to C cause deadlock will be three 1 2 3 see if I give one more deadlock won't occur so the maximum is three now minimum number to ensure deadlock Freedom will be four 1 2 3 deadlock is there if I give one more deadlock won't occur so I will say minimum four are required to ensure deadlock freedom is it clear see another see another problem end processes are there R has six copies each process require three copies now tell me the same so how much uh proc how many process are required to cause deadlock and maximum number of process for deadlock Freedom see this if I talk about P1 P2 and P3 each process now require three 1 2 3 4 5 6 I have used all of them and each process required three resources so I will say P1 will wait on P2 and P3 so that they will release their resources so that P1 can get one more to complete similarly the same case for P2 P2 is waiting on P1 and P3 so that it can get one Moree to complete so in this way I can say that minimum three resources minimum three process are enough to cause deadlock and maximum number of process to ensure deadlock freedom is two only 1 2 3 4 5 6 just two if I say three then the case of Deadlock may arise okay see this processes are there P1 P2 P3 P4 P5 the maximum demand they have made is 10 8 5 12 6 now you have five process now you to tell me the resource number of resource maximum resource to cause deadlock so for deadlock to occur I will give 9 to P1 7 to p8 7 to P2 4 to P3 11 to P4 and 5 to P5 now what will happen they will wait on each other to just get one more resources to complete this is the same case of dining philosopher so for maximum resource to cause deadlock you have to create the case of dining philosopher now they are waiting on each other to get just one more resource to complete so I will say 9 + 7 + 4 + 11 + 5 that is 36 so I will maximum number of resources to got deadlock is 36 and minimum to ensure deadlock freedom is see if I give one more resource to any of the process let's say I have given one more resource to this five P3 will complete and P3 will release five resources back to the pool now what will happen P2 will get one P1 will get one P4 will get one P5 will get one and one is still remaining in the pool all of them will complete so what I can say here if I just add one more resource then deadlock Freedom can be ensured so 37 resources minimum and 36 maximum to cause deadlock and 37 to cause dead Freedom okay to solve such questions you should you should always remember the dining philosopher case now these are some homework problems you have to solve them this is a question which of the following statement is true with respect to deadlock the first says circular way weight is necessary condition for the formation of Deadlock yes it yes it is true in a system where each resource has more than one instance a cycle in its weight for graph indicate the presence of a deadlock no because because for multi instance graph for multi instance resource cycle is just a necessary condition indicates the presence of Deadlock no for single instance graph in wait for for ining single instance resource for wait for graph I can see cycle is sufficient and necessary if the current allocation of resources to process processes leads the system to UNF State then deadlock will necessarily occur no I cannot say that what I have told you they will go into unsafe State not deadlock unsafe state is not necessarily deadlock unsafe state is just a warning that in future deadlock may occur in resource allocation graph of a system if every Edge is assignment Edge then the system is not in deadlock stage in resource allocation graph of a system if every Edge is an assignment Edge then yes that is also true how can I say that look at the diagram the case we discussed was this P1 was holding R1 and waiting for R2 P2 was granted R2 and waiting for R1 but you can see here cycle only forms when there are request edges if there is no request edges then cycle won't form and if cycle is not present then the deadlock will definitely won't occur okay so in resource allocation graph if every Edge in every Edge is a assignment Edge then this says that cycle is not present and if cycle is not present then I can say the system is not in deadlock State okay this is a homework question for you you should try okay this is also an homework question we'll discuss them in the next section SE okay so for now I can say deadlock is officially completed in the next section we will start memory management so let's first start with the homework discussion of the last lecture here we are given with consider the following snapshot of the system running and processes process I is holding XI instance of resource R so I can say xir is being acquired by pi for all I 1 to n for all I 1 to n currently all instances of R are occupied further for all I process I has placed a request for an additional Yi instance okay so process I has made a request for additional Yi instance of resource R while holding XI instance it already has it's it's already holding some XI instances there are exactly two process p and Q says that YP = to y = 0 YP = to yal to 0 this says that process p and process Q are not requesting anymore okay so which one of the following can serve as a necessary condition to guarantee that system is not approaching a deadlock see this here here I have written all of the P ID process IDs P1 P2 PN and somewhere in between there must be process p and Q and then the p and the last process or here are the allocated resources so P1 is holding X1 resources X1 instances of resource R P2 is holding X2 instances of resource r P3 is holding X3 and process p is holding XP resource and process Q is holding XP resource see whenever I say resource I mean instance of that resource okay and then PN is holding xn okay now comes the request part here here you can see Yi is being requested by process Pi so I can say P1 is requesting y1 P2 is requesting Y2 but here it is given that process p and process Q are not requesting anymore so process p will request zero instance and process Q will also request zero instance now comes the question which one of the following can serve as a necessary condition to guarantee that the system is not approaching a deadlock see we have zero available resources so and I have to satisfy the need of all these processes with that available equals to zero how can I satisfy I can satisfy the need of these two processes so when PQ and PP that is process p and process Q will start running and after execution they will release their resources back so how much available resources now I have I have XP plus X xq and with these available resources I must be able to satisfy the need of at least one process out of uh P1 to PN except P PP and PQ so with these Resources with these instances I should able to satisfy either of them at least one if I am able to satisfy the need of at least one so how can I write at least one minimum of Yi that is minimum of Yi I will be able to satisfy with these instances of resources and if it is then the system is not approaching datal log see if I say the xer xq that is number of available resources with me now is even not enough to satisfy the need of minimum of these uh request the least of or the minimum of that request I'm not able to satisfy with the resources I have available with that's that is the case of actual deadlock okay here I should write I is not equals to P or q and K is not equals to P because these processes have already completed that's why they have released their resources here and one more thing if I write XP plus xq is greater than maximum of Yi which means with with XP and XU they are well enough that I can satisfy the need of maximum of these I can satisfy the need of one whose request is maximum then I can say the system is totally safe there is no case of Deadlock okay I hope you got the idea how we did it with these available resources I should be able to satisfy the minimum amount of request or the least request made by the processor if yes then I can say system is not approaching Deadlock this was also a nice question it said consider the following resource allocation graph find if the system is in deadlock state so either you can try using that weight for graph but here you cannot use weight for graph directly because of multi instance resources so how are you going to solve this we are going to solve using the detection algorithm see this which of the following uh find the system is in deadlock state or not so we are using detection we are detecting if the system is in deadlock state or not so we are not using prevention we are not using avoidance we are using detection and in detection which algorithm single instance no we are use multi instance and how we use multi instance using Bankers algorithm so we need to convert this resource allocation graph into a matrix R1 R2 and R3 are the type of resources P1 is holding P1 is holding one instance of R2 request testing for one instance of R1 and holding one instance of R1 so it's holding see see it's holding one instance of R1 one instance of R2 so I can write 1 1 0 for P1 I can write 1 1 0 for P1 this is what P1 is allocated with if I have to write for p 0 then it's holding one instance of R1 and uh no nothing else it's just holding one instance of R1 yes it's holding one instance of R3 also so I will write 1 0 and 1 for p 0 I will write 10 1 so in this manner I will write the whole allocation thing now the request what's what's what it is requesting it's requesting see here it's requesting R1 and nothing else I will write 1 0 wait a minute yes it's I will write 1 0 0 for p 0 it's requesting R2 it's requesting R3 so I will write 0 1 1 I'll write 0 1 1 for P2 I will write for P2 it's requesting one instance of R2 uh sorry it's requesting one instance of R3 and nothing else so 0 0 and 1 0 0 and 1 it's just requesting one instance of R3 now P3 P3 where is P3 here is P3 so P3 is requesting one instance of R2 it's requesting one instance of R1 and see here it's requesting another instance of R2 so I'll write uh I'll write 1 2 0 1 12 0 so this is what is request this is allocation this is p ID now available resource which resource is available with me see here this R3 resource is not given to anyone this this is not allocated to anyone R1 is completely allocated R2 is completely allocated I have just R3 available with me so I'll write 0 01 now with the help of this 01 can I satisfy the need of all these and if yes then the system is not in dad log state so first we have to satisfy the need of P2 when p2's need will be satisfied then I'm I'll be available with this allocation Will Come Back to Me 0 1 0 so I'll have 0 1 1 now with this 011 can I satisfy the need of p 0 yes I can so this allocation will come to me again I'll have 1 0 and 1 which is one12 with this 112 can I satisfy the need of uh yes I can satisfy the need of P1 so I'll satisfy the need of P1 and this allocation will come back to me now I have 222 now I satisfy the need of P3 so yes the system is safe I can satisfy the need of all the processes with the resources I'm available with so I'll say this system is not in deadlock State okay so this was all about deadlock and we have also discussed the homework problems congratulations we have completed our deadlock section now we are starting the memory management section what is memory memory is a electronic holding Place uh for data and instructions data and instruction that computer want to or the CPU want to reach quickly to see what is the need of memory because CPU is very fast hard disk is very slow slow we want something in between to coordinate with both that's what memory does memory whenever I say memory I mean by primary memory that is the main memory that is Ram Rome cach registers this cash and resists are just like the memory buts way faster cash is faster than RAM and resistors are faster than cash cash is smaller in size than Ram a resistor is smaller in size than cash okay so the more fast we become the less size we got okay see hard disk has the largest size RAM has little bit low size then cach more low and then register has the least size okay so Ram is also known as main memory or read write memory it's also known as random access memory this is readon memory related to file systems so this is Ram connected with address bus data bus and control signals this chip select it's it's just like what power on and power off thing what does this address bus do let's say I want to access the memory location at 10 1 0 so this 10 1 0 will be brought by address bus and what does this data bus do it brings the content of 101 0 to CPU and sometime it also uh carries addresses in in of the case of indirect addressing don't worry if you are just getting confused uh just take a look at it and we will learn more that in detail in our computer organization architecture course what you have to focus on in this is this linear onedimensional view of memory how does memory look like this is what it is it is a linear array of words what is words what is word collection of bits uh if I say one word equals to one word equals to 8 bit 8 Bits or one bite then I can say that each cell in the memory consist of one byte one by see this memory is divided into lots of words lots of words memories divided into so what is this this this is address each word has a unique address if I say m of 1010 this is what address is each cell in the memory have a unique address and to and to access the content of a word we must have an address okay so let's say this is a cell or this is a word it has the address X and it has a length of M bits which means one word consist of M bits M bits M bits so if I say what is the size of memory number of words into M bits so n let's say n be the number of words M be the size of each word so this is the memory size n into M okay so M bits it is the word length and in word content is stored and what is content data and instruction okay so I have written that same thing here M width of a word word length xal to fixed length address in bits and total number of veres in let me discuss a small thing with you if you are not familiar with this let's say if I talk uh I have just one bit how many words I can address with uh let's say I make two blocks one block I can give address zero and another block I can give address one so if one bit I have I can address two blocks let's say I have two bits so how many blocks I can address I can address four blocks 0 0 0 1 1 Z and 1 one see what is the thing that I'm talking about with with let's say if I talk about two bits how many unique numbers you can generate with two bits that's what the number of words you can address with if I say I can generate four number with two bits that is 0 1 2 and 3 these are the four number that can be generated using two bits so I can say with two bits I can address four words so if I say I have three bits how many words I can address 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 101 in this way you go till 111 okay so you can address seven from 0 to 7 you can address you can generate eight unique numbers so you can address eight words with three bits with three bits you can address eight words so it's like 2 to^ 3 with two bits I can address four words it's like 2 power 2 with one bit I can address two words so like 2^ 1 so if I ask you if I ask you with n Bits let's say this is n Bits how many unique numbers I can generate you can generate two rais to power n numbers so how many words you can address with you can address 2 power n words so with nbit address you can have 2 to power n number of words okay so this mbit this mbit is the size of each word so this is the size of each word m bit and this is what the number of words are so M bits M into 2 ra to^ n is actually the size of my memory size of memory or I can say memory capacity I hope you are getting the point let me repeat again let me repeat again so that will clarify you from n Bits of address I can generate create 2 to power n unique numbers which can be helpful to address 2 power n words so the number of words I have is 2 power n and the size of each word is M bits so this is what my memory size is okay I I hope you got the point so this x this x is the fixed length address and it is in bits okay so memories is specified using number of words into width of a word n into M and let's say n is the size of address in bits so number of words can be 2^ n we have just discussed it now n is the word length n is the total number of words so I can write n = to 2^ n or I can say number of words equal to 2 to power address size in bits I hope now it's clear so total number of words equal to 2 to^ size of address okay now comes the relation between n and n we have already talked about this uh let's say if I have three bits then I can address I can generate uh I said I made a mistake here yes so if I have three bits I can generate eight unique numbers which can be helpful in addressing of eight words okay so this is what uh I want to clarify now one thing you have to remember in 10 bits for 10 bits I can for with 10 bits I can generate 2 to power 10 unique numbers and this 2 power 10 when we are talking about data is also known as K that is that th000 thing if I have 2 20 2 20 then this become 2 20 then it becomes M Mega if I say 30 bits then this is 2 30 that is giga so 10 bits can be useful to generate 1 kilow 20 bits can be useful to generate 1 Mews and 30 bits can be useful to generate 1 G vers so if I'm problem here if I say Nal to 500 G which mean I have 500 g words then what will be the address size see for 500 Words I need to have nine bits because with eight bits I can only generate 256 words or I can say only generate 256 address and one address for each word with nine bits I can generate 52 addresses so for this 500 I I need to have 9 bits and for this G I need to have 30 bits we have just discussed it here 30 bits for 1 gab so 30 + 9 is 39 why are we adding this because of this let me explain you in proper detail n equals to I can write it 2 power n into 2^ 30 so log 2 N will be 39 bits remember this that the address size is always in bits the address size is always in bits okay Nal to 1,000k so for 1,000 uh I need to have 10 bits because with 10 bits I can generate one2 for addresses if I just shift down to one bit from 9 bit I can only generate 51 so I can write 10 bits for this 1,000 and 10 for this kilo so in total I will have 20 bit address number of words number of bits in the address and word length suppose if I say n equals to 13 bits which mean 13 bit address 13 bits are needed to refer one world of memory see if I use if I say my address size is two bits which mean two bits are needed to refer one word in the memory similar in similar way if I say my address size is 13 bit which means 13 bits are needed to refer one word of memory okay m equal to 8 bit this is 1 byte so m equals to 1 by that is word length so this each cell of a memory consist of of 1 by n = to 2^ 13 we got it from here which means with 13 bits I can generate 2^ 13 words so n = to 2^ 13 words so I can write 2^ 13 as 2^ 3 into 2^ 10 and 2^ 10 can be written as K so I can write 8 K and what is the size of each word bite so I can write 8 KB is the size of memory so this is the capacity of memory in terms of bite and words now if I ask you what is the capacity of memory in terms of words then you write 8 kilow and if I ask you what is the capacity of memory in terms of bytes then you say 1 8 kilobyte because 1 Word equals to 1 by okay see this n equals to 18 bits which means I can generate 2^ 18 18 addresses which means I can have 2^ 18 Words which means I have 2 10 into 2^ 2^ 8 into 2^ 10 which is 256 kilow words I can have I can have 2^ kilow words and what is the size of each word the size of each word is 8 into 2 bits which means this is 1 bite which means I can the size of each word is 2 by so if I ask you the world view of a memory then it is of 256 kilow and if I just put the value of word here that is 2 byte then I get 512 kilobyte I just substituted the value of word then I get the bite view of a memory and by default you can take one word as one bite okay let's move down just for the same thing uh we just for the sake of Simplicity we say this n is the size of memory size of memory n = to 64 KB now it says that I have 64 KB of memory and what is the word length word length is is 4 byte so this question is important question you will feel the difference what is the meaning of world view and bite view world view says that each cell in the memory consist of word one word and bite view says each cell in the memory consist of one bite now the question is asked what will be the address length if I address the memory in terms of word and what will the address length if I address the memory in terms of bite so simple see here if I address the memory in terms of bite then I will have one bite of cell and there will be 2 to^ 16 this is 64 KB 2 to^ 16 number of words so number of words are given can I find the address bit yes it will require 16 bits of addresses so n equals to 16 bit for B View and if I ask you for the word view then each cell in the memory consist of four byte so how many words I will require to address the full memory let's say the number of word I require is X each word has 4 byte and what is the size of memory 64 KB from B to B I got it cancelled and this is 16k and 16 can be written as 2^ 4 and this K can be written as 2^ 10 which means 2^ 14 worlds are requir to address this uh to complete this whole memory so 2 to^ 14 how many bits I will require 14 bits okay so this is how it works let me repeat again how did I solve this so what does bite view say bite view says that one cell of a memory consist of one bite and what does word view say one cell of memory consist of one word and the word length is given to you word word length says the one word consist of four bytes so one cell of a memory consist of four bytes and you have 64 KB memory to complete or you have to 64 KB memory to address and each cell has 4 byte so how many blocks you will require see each block has a size of 4 byte let's say I require X block to access the 64 KB memory so from here I can find that I require 2 to power 14 blocks or 14 words and to address these two 14 words I should have 14 bits in my account so this 14 bits is required for word view now let's say I'm asking you for the bite view what does bite view says that one cell of a memory consist of one bite one cell of a memory consist of 1 bite and my memory size is 64 KB I have block size of 1 bite and let's say I I have X blocks to access 64 KB memory how much block I require what is the value of x it's so simple 2^ 6 into 2^ 10 it is 2^ 16 which means I should have 16 bits in my account to address these 2 power 16 blocks that's how I got 16 bits address for the bite View and 14 bit for the world view okay bite view means one word is one bite and word view means one word is given number of bytes I hope you got the point what does bite view say each word is one bite and what does word view say each word is given number of byes here each word is of four bytes okay so n is the total number of words and if I say one word equals to 8 byte then this each cell in the block consist of 8 byte so same question if I ask you that if I say the word length is changed to 8 by then what will be the answer how many block of size 8 by are required to access the whole memory of 64 KB I'll just cancel the B to B and then 88s are 64 so I'll write 8 K which is 2^ 3 into 2^ 10 2^ 13 so I should have 13 bits in my account to access 2^ 13 words or 2^ 13 blocks or 2^ 13 cells of a member okay let's solve some other questions n = to 23 bits which it says that the address or 23 bits are required to address one block of a memory so from this I can tell that there are two ra to^ 23 words present in the memory and the size of each word is four bytes four bytes so if I say how many number of words are present then 2^ 23 words are present and what is the size of memory the size of memory is 2^ 23 23 into 2^ 2 bytes which is 2 25 bytes which is two which is 2^ 5 into 2^ 20 byes this 2^ 20 can be written as M and this 2^ 5 is 32 so my memory size is 32 MB okay now this is a homework question for you you have to find if the number of words are or the memory size is 8 gabit and each word have 64bit length then what is the number of words in bite View and world view world view and bite View so whatever we have discussed till now I think we should revise that okay so this is what memory is it is prime memory RAM R cach registers Ram is connected with address bus control bus and uh datab bus address bus brings the address from the CPU databas helps to transfer the content from RAM and CPU for let's say if I'm reading then databas transfers the content from Ram to CPU if I'm writing then databas transfer the content from CPU to Ram read and write are the control signal and Chip select says power on or power off linear one dimensional view of memory memory consist of these cells or blocks which I a word each word can be of either one bite or more than one bite if it is of one bite then I can say the memory is byte addressable if it is of more than one bite then I can say memory is word addressable okay the size of each word is mbit so M bit is the word length and if I have X bit address with X bit I can generate 2 to^ x unique addresses so I can address 2 power x blocks or I can address 2 power x cells or words each are the same thing now memories is specified using number of words into width of word so if I have let's say n number of words and the width of each word is M so I have n into m is the size of memory if I have uh total number of words are n then to find the address I will have to take log to n okay what is the relation between n and M just take the log so see what I want to tell you is do not remember anything it is just common sense do not remember anything so we learned about bite View and worldview how the things work uh try to solve this these four questions how many questions 1 2 3 and four try to solve these four questions by your on your own and this homework question also memory management part two let's say the size of address is 18 bits and the world length is of 24 bits so I can say each cell in the memory is of six bytes so n equals to 18 bits the number of words will be 2 to^ 18 so I can say the memory size is 2^ 18 into 6 bytes for each word so this is the memory capacity any memory word you want to refer pass the address to address bus from address bus the address will be taken to the memory and that word the word with that memory location or that address will be activated and the content of that word will be taken from memory location to CPU with the help of databas these are control signals read and write are control signals so 01 is for the write operation and 1 Z is for the read operation there's nothing like one one or 0 0 what is bus bus is a group of wires and each wire can carry a bit so bus is nothing but a group of wire and what is the purpose of this chip select power on button that should be one and if chip select is zero which means the memory is powered off so what operation we can perform we can perform either read or write to perform any operation pass the address to address bus and that word in the memory will be activated pass the control signal either 1 0 or 01 1 Z is for read and 01 is for WR and then from databas content which may include data or instruction will reach the CPU send the address to address bus that word will activated and the that content will be sent from memory location to CPU with the help of data this these are the control signals one Z means read 0 1 means write chip select if zero then memory is powered off if one then power on okay so this is like an 7bit address to refer 128 words chip select one chip select two either you want to read or write address for address bus now what is this this is the capacity of memory 128 refers to 128 bit and this is the size of each word the size size of each word is 8 Bits which means 1 byte so I can see the memory size is 128 byte here one word equals to 1 by so this is a ram this is a Blog diagram of typical Ram chip what is included here chip select control signals address and datab bus address bus and datab bus now comes the part of loading and linking loading versus linking let's say I create a file named test.c compile it and compiler converts it into exe consist of instruction and data and where this ex is stored it is stored at the dis now it is the responsibility of loader to load that program from disk to main memory and from Main memory CPU will execute it so this is what we have learned already in our lecture one stored program concept one human architecture loading loading consist of or loading can be divided into two static and dynamic as the name suggest static which means the whole program is loaded in memory before execution and what is dynamic on demand loading let's take an example see this is our program okay and we start executing this main if do condition now we got a function and function is defined in some another program let's say now this program will also be loaded this program will get exec uted some G function is there defined in some other program now this program is getting loaded G is being executed now H comes defined in some other program now this program is being loaded so in this way when it is required then load this is what we call as Dynamic loading and loading the whole program this all four into main memory at once is called as static loading so by seeing you can say that what is the drawback of this uh static loading suppose if I write a condition here if condition and if condition is not fulfilled then we are not going to execute this F function so let's say the condition fails so this part will won't be executed and only this program will be executed but what we did in static loading we have loaded all three of all of them all of them into the main memory and these three are useless now they are just causing the wastage of a space so in that that case static loading is a bad choice because what is the drawback possible wastage of space ineffective utilization in case of condition or know at runtime because this condition will be run at runtime and at run time we are going to know if this function will be run or not that's where the static loading lags behind and what is the and what is the advantage of static loading the advantage is obviously faster execution let let say the condition is fulfilled now in Dynamic loading it take time to load the program from disk to memory it take time to load program for dis to memory so when all these program will be loaded it will cause time so Dynamic loading cause slower execution and static an static the whole program is loaded in memory before execution so if needed then every program is there at present there's no need to call them there's no need to bring them them from hard disk to memory all of them are actually present in the memory so this will cause faster execution so faster execution is the advantage so I can see this static loading is time efficient but space inefficient see here let's say for dynamic loading I only need just 10 KB of space to start and let's say if the condition fails then I will complete the whole program in just 10 KB but in static loading as I say you load the whole program at once so I need 10 + 5 15 15 and 15 30 30 and 20 50 KB of memory to start the program let's say the condition fails here also I did not require these three of them but they are still loaded into the memory so 40 KB of vage of SPAC is here okay now here should not be 40 KB it is 40 KB wastage as here you can see 10 + 5 15 15 and 15 30 30 and 20 50 so 40 KB is wastage and 50 KB we require for Sal so if you want to save memory then go for dynamic loading which me which says loading on demand and you can guess no wastage of memory but it cause slower execution as it require only 10 KB of memory to start so this is what static and dynamic loading is in static loading you load the whole program at once in Dynamic loading you load load at demand in the last lecture we have studied about static and dynamic loading in this lecture we'll see what is linking so linking is the process of resolving external references what is external references suppose in a program whenever a compile compiler confronts a function which has not been defined before then what is what it will do see every function call is like a branch and goto statement Branch or goto statement so what compiler will do compiler will generate a BSA address and to where it has to jump that address will be left blank because it doesn't know where it is defined see this function f is defined after main so the compiler now here doesn't know where this function f is defined so it will leave a blank here it doesn't know where the SCF is defined it will leave a blank here so these blanks are unresolved references okay now there is also one thing which I want to clarify some students have misconception that compilation is start from Main this is completely false compilation start from the first line of the program then what does it start from Main execution is start from Main execution is start from Main compilation is start from first time of the program okay so now when the compiler first time confronts this function f it will generate a BSA that and it will leave blank blank to that blank this blank address is the address of where f is actually defined so it doesn't know where the f is actually defined so it leaves blank jump to F so compiler doesn't know this so it will leave it blank this is what unresolved reference is see here if this F has been defined before main function then compiler would have known the address that it has to jump here so it will write address of this part here but now compiler doesn't know where it has to jump it doesn't know where f is defined so it we leave blank here these blank are unresolved references okay for example if I use extern int x what does this say this say this integer X is present externally in some other file so it will leave blank here also so whoever address is the compiler don't know it will leave blank there so compiler will leave so many blanks while compiling the code blank for functions blank for external variables or objects so we need a we need someone to fill that blanks so here comes the Linker Linker is the module of operating system who is going to fill up these blanks okay so these blanks are filled up by Linker I already told you if this was the case that function f is already defined above then main comes and in main I use function f then the compiler will automatically fill up the address where it has to jump okay but now here it doesn't know where if is defined it will leave blank now we need someone to fill up those blank now comes the Linker to save us so linking can be of two type as it was loading it can be static or dynamic static linking is done before execution okay so what happens the UNL file which means the compiled file with blanks is the DOT obj file object file that contains unresolved references and that unresolved references when filled up by Linker which means linking is done then it becomes the exe file which is the result references okay so this is how aexe files look like main function function f is defined here and then scan of comes so how does exe file looks main at BX at X this function X is defined here and then in f i this function scan F will be converted into BSA y now this y will be the address where scanf is defined in this way okay so INE file all the external or unresolved references are resolved which means their addresses are put at the BSA parameter so now compiler can jump easily okay now what is the draw drawback is space in efficiency see Linker acts like a tailor what it do it Stitches the links of different pieces of clothes and here we can say the code to make it a meaningful program see here if Linker was not present to tell the compiler that this function f is defined here would it be a meaningful program no so Linker X like a tailor with with who stitches different pieces of clothes to make a meaningful fabric similarly Linker links different pieces of code to create or make a meaningful program in the next lecture we'll see what is dynamic linking or linking at runtime in the last lecture we have learned about static linking in this we are going to learn Dynamic linking that is how linking is done at the time you all know what is the meaning of linking resolving unresolved references giving the address to the BSA so now how does dynamic linking work with the help of stub what is St stub stub is a piece of executable code so I can say every unresolved reference which mean every blank address will be associated with a small piece of code known as Stu and that stuff is executable so at run time when that step will be executed at at run time when step will be executed it will activate the link Linker now it is responsibility of linker to find the address of that function in the memory and if that function is not present in the memory Linker will look for it in the compiler libraries compiler libraries that is present in the libraries that is present in the disk and if found there Linker will tell loader to load that module into the main memory okay so when this address will be found it will give it to the stub and now stub will provide it to the branch and save address so now here we got the address so this is how it works St and step executed at run time activates the Linker Linker found the address of function f in the main memory now that address will be given to step and step gives to the BSA that's how it work and I've already told you if function is not present in memory then Linker will look for compiler libraries on disk if found there then loader will load the module in the memory searching for addresses is the work of linkter loading the modules from disk to memory is the work of loader okay all modern system nowadays uses Dynamic linking and dynamic loading which means at runtime because that is space efficient you don't have to load the whole program in the beginning and but it is time inefficient okay so everything is done at run time so it take time at uh so it takes time to execute the full code code reusability is also a factor example scanf no need to give each function its own copy of scanf unlike static linking okay so we will load a single copy of scanf into memory and different function can call it we will give just the address of it instead of giving each function its own separate copy of scanner so this also provide reusability okay so modules libraries which are linked at runtime by Dynamic linking are generally called as dll you must have seen somewhere this uh like error the DL file is missing this type of DL file is missing so that is linked during runtime so these are Dynamic link libraries used in Windows and an important role that this Dynamic linking plays is it gives us the flexibility to change because modules are separate see application and their libraries are separately written they are not linked statically statistic statically which means we can change the library implementation without affecting the application see just like scanf we just give the address of it so address Remains the Same here is the library I we can change the Library without changing the application because what we have given in the application just the address so address Remains the Same what we change is the content of those Library so I can say that the library implementation can be changed without affecting the application so this is the flexibility that this Dynamic linking provides and why is it so because they are not linked statically suppose if they are just merged statically suppose they are linked statically all in one then can I change this no if I give just the address of it and here is the implementation in different uh place then I can say that I can change this Library implementation without affecting the application okay so I hope point is clear now what is the drawback of dynamic linking as everything is done at runtime so time will be the factor time inefficiency is present less Security in static the thing is complete everything is already there and have to do nothing at the run time are you getting the point see in security the problem happens where at runtime and if already has been done before nothing is we have to do nothing at the time then there is no loophole or vulnerability Concept in a static linking there is no vulnerability because nothing is done at the run time that's why Dynamic linking has less security okay so this was Dynamic linking in now let's see address binding Association of program instruction and data unit to memory locations what are we doing here we are associating instructions and data to memory locations memory location and that thing is known as address binding we are binding the address to whom instruction and data unit so binding is Association of attributes with entity suppose I write int X then here x is the variable or entity so what is the attribute associated with it name type value address size so the name is X that is name binding the type is int type binding value what is the value here no value is given to it so I can say garbage value or junk value what is address now this will be the address binding if I say that 4,000 is the address of this variable X variable X got binded with the address location 4,000 this is what address binding is are you getting the point giving address to instructions or data units this is what address binding is and what is binding binding is just the association of attributes with the entity here what is the entity X is the entity now if I give address to this entity say that this address is stored variable X is stored at memory location 4,000 now what I have done I have binded the variable X or entity x with a location 4,000 so this is what address binding is so we were seeing the that job of linker is to find addresses of these external objects functions or variables what was address binding address binding was associ of Association of program instructions and data units to memory locations okay Association of program instructions and data units to memory locations okay now let's see an example here I declare int a b and c a is given value equals to 1 b equals to 2 and C is the sum of a and B so let's break it into low level instruction one says store the value or store the constant one into variable a store constant 2 into variable B now load the value of a into R1 and load the value of B into R2 add R1 + R2 and store the result in R1 and then store the value of R1 into C and now we got c as sum of A and B so this is how this program this high level program is broken into low level so let's say this A B and C are they're in the memory location let's say at a equals to0 B is at 2 C is at location 4 so this is what data units are and these instruction will also be stored somewhere so these instructions are are the program instructions so Association of data units and program instruction to memory location so these are the memory location this is what address binding is okay so I took an example to show you how data units and instructions are stored in memory and giving them addresses is what address binding is so binding instruction and data unit to memory location is address binding now Comes The Binding time time at which binding take place does The Binding take place at compile time load time or run time so depends on which type of binding we are doing for example name binding the name binding is done at compile time type binding I write int X so I assign a name X to this variable so this is what name binding is and is done at compile time I'm assigning a type of this I'm assigning a type to this variable so this is what type binding is this is also this is also a compile time now comes the address binding so address binding is done at load time variable X get associated with memory location at load time and what is value binding when this in Tex will get a new value when it will happen let's say I write X = to 1 so this instruction will be executed to get its value so one will be stored at memory location X when this will happen when it will be executed so for execution we need runtime so that's why value binding is done at runtime and size binding same as compile okay so you have to remember this name binding type binding size binding this is what it's done at compile time address binding is done at load time and value binding is done at run time okay types of binding static binding and dynamic binding static binding says Association cannot change Dynamic binding says Association can change okay let's say entity is a person entity is a person I assign a name to a person let's say your name is Rahul okay so from the birth to that to death your name will remain same or let's say let's take an example of your fingerprints your fingerprints will remain same they will they are unique and they will remain same this is what static binding is the attribute which remain same to the whole lifetime these are static attributes and static binding and the attributes which changes with time are Dynamic binding for example age binding that is dynamic so I can say name attribute is a static type is a static if I say int X then name X is a static int this will remain same address will remain same value can be changed if I say x = to 1 in the next line I can say x = to 2 then the value of x initially was 1 and it got change to two so value can change that's why it is dynamic and size can the size of X differ no it is defined at the compile time so this static size is also static so after of these attribute name type address value and size only value is dynamic okay now let's see the type of address binding based on time first is compile time address binding if addresses of data units and instructions are decided by the compiler then and it is compile time binding and that is purely static so compile time binding says the addresses of data unit and instructions are decided by compiler then it is compile time Bing what is load time compiler will not generate or associate the address loader will do so this is what load time binding here is a example so now what loader will do let's say there are three instructions with me so loader will generate let's say offsets now we'll see load time compile binding in this compiler does not generate or associate addresses loader will generate compiler will generate offsets which are not real addresses let's say the i1 is always at zero this is the first instruction now the instruction two will be stored at 0 plus size of i1 let me explain this is where the i1 is stored zero now now instruction two will be stored where after instruction one get completed so it will be stored at the size of I and where it does I3 will get stored I3 will get stored at here what is the address of this part size of i1 plus I2 so these are the offsets generated by compiler and it will be communicated to memory manager that is the OS module now memory manager will give the address of Base register base register says the instruction i1 is stored at 6,000 these are not the real addresses these are just offset so what I will do I will say that i1 will be stored at instruction 6,000 because this is what the value of base registor is now I2 will come at 604 this is what the size of i1 is okay now I3 will come at 6,8 this is what the size of i1 + I2 is are you getting the point now they are the real addresses let me repeat again what happens at compile time the addresses and data unit instructions are decided by compiler and it's compile time binding what what does load time binding say it says that offsets are generated by compiler and then loader will assign the real addresses based on communication with memory manager what is the base register value adding the offset to that base register value loader will find the real addresses this is how it's done so so this was compile time and load time binding now we will see what is runtime address binding and one more thing during execution instruction and data unit does not change at load time and compile time binding let's see an example suppose these were the instructions of a process in the memory now what happens the process is swept out it is sent to the disk so what happens in static address binding this will remain empty this will remain empty addresses cannot change here and when swed in it will be assigned to the same addresses so when the swapping swap they will be spped in where will instruction V in come here instruction to here instruction three instruction four this is how they will come they won't change the address from there from where they were swept out the exact same location they will be swept in and now you have gu guessed what what would have happened at runtime address binding it is also done by loader itself but when this when the instructions are spped in they can be loaded to a different place so addresses can change during execution so this is a kind of good thing because it gives relocation flexibility now let's revise what we have learned till now what is address bending assigning addresses to instructions and data unit of a program okay so what are data units and instructions suppose this was our program when it is broken down into low level these variables are the data units like a is stored at address Zer B is stored at address 2 C is stored at address 4 so these are the data units assigning addresses to them is address binding these are the instructions these i1 I2 I4 I5 I6 these are the instructions so assigning addresses to them is what address binding is okay now it is not just the address binding different attribute is associated with different kind of binding for example name binding type binding address binding value binding and size binding so now the question arises which type of binding happens at which time either it is compile time load time or run time so I can say name type and size name type and size happens at load time happens as compile time sorry and address binding address binding happens at load time and value binding happens at runtime why run time because for Value to be assigned this instruction should be executed and execution happen when when we run the program that's why values assigned at run time types of binding static and dynamic in static type of binding Association do not change in Dynamic binding they change for example we have seen that uh in compile time and loow time binding if the instructions of a process are swapped out then this place will remain empty and when it's time to bring them back then they will be brought back to the same exact location so this is what static binding is they cannot change the value of the addresses but what happens in the dynamic type of binding if you are swabbed out from some location then it is possible that you can be swabbed in at different memory location this is what relocation flexibility is so in in Dynamic binding Association can change okay so name static name binding is static type binding static address binding is generally static value binding is dynamic because value can change size binding is static now the question arises if we say address binding is static then what about run time address binding which we have just seen now there the address got changed that's what we generally talk about address binding can be static okay so here I can change it to static static or dynamic okay so this is what general thing is generally we talk about compile time and load time but if we are focusing on runtime address binding then that will be dynamic types of address binding we have seen compile time addresses of data units and instructions are decided by compiler load time loader will assign the addresses based on communication with memory manager memory manager will have given loader the base register and loader will add the offsets generated Ed by compiler to the value of Base register to get the real addresses okay now we have learned about runtime address bending let's see how a program is completely executed multistep processing of a user program okay let me okay multistep processing of a user program Here Comes The Source program do c do c compiled compiler assem assembler this is compile time here we get object module obj this is not linked this is connected with or this has unresolved references now it comes or it goes to the linkage editor the Linker here will fill up the blanks it will send to the load module exe will be loaded into the main memory and now this was the program till now now it becomes the process now this process will be executed by CPU okay so what's written here Library function other object module given to the linkage as I've told you if it is if the addresses are not found in memory then it will uh search for libraries at the disk okay so this is how a program is executed so if I say address binding then this is the compile time address binding this is load time binding and this is the runtime binding so when does runtime binding happens during the execution time okay so now in the next lecture we will actually start our memory management techniques the memory management techniques can be segregated into two part the first one is contiguous and the second one is noncontiguous noncontiguous means distributed and contigous means centralized let's take an example suppose in disk this is our program it's of 100 KB so when we have loaded the whole program at one place the whole program at one place that means all 100 KB at one place this is what centralized allocation and when we have loaded we have broken the program into three parts 40 KB 40 KB and 4 KB and stored them at different places this is what distributed or noncontiguous memory allocation is okay so we will learn about overlays partitions variable and fixed body systems paging segmentation segmented paging demand paging all these things we are going to cover in this memory management section so these are the old techniques which is overlays partitions Bud systems these are the old techniques this body system we are going to cover in our miscellaneous topics in the end okay overlays and partition we will cover in this lecture so these are the old techniques but we have to study them because memory management fundamentally started from these well we know that these are the new techniques but the memory management fundamentally started from this if you remember in our science classes when we used to study atomic structure we also studies the Thompson Plum ping model we studied that raford model in the end we knew that these were the wrong but we still studied because the final thing fundamentally rise from the old things or the old theories that's why we are studying overlays partitions and body system okay so this all thing is managed by a module of operating system which is memory manager so now we will study the function and goals of memory manager the first thing is allocation before loading the process you have to first allocate the memory so this is what the memory manager helps with it helps with the allocation of which color I should choose I think this would be better before loading the process the process you have to first allocate the memory so this memory allocation is managed by memory manager protection suppose this is what uh memory looks like this is the system area user area with different processes in between now a process should not interfere with the space of different process so area of memory where program is loaded is the program address space so this is what the address space of P3 this is what the address space of P2 address space of P1 so P3 is address space should get its instruction executed in its own address space only and should not interfere with the addresses space of some different process so there should be no trespassing who handles this the memory manager so it is the task of memory manager to allocate the memory it is the task of me memory manager to ensure that there is no trespassing of instruction between the processes address space Free Space Management as the name suggest managing the free space address translation I hope you remember the logical address and physical address thing so the address translation is managed by memory manager and deallocation when the process is completed deallocating the memory the process has to return the resources the return the memory so that is all managed by memory manager now what are the goals of memory manager it works to minimize wastage to utilize the memory effectively okay so this is what fragmentation is we call in in memory management term we don't call it wastage we call fragmentation internal fragmentation external fragmentation we'll see it later but the vage has a new term here that is fragmentation okay ability to manage large program in small memory areas yes this is important suppose our memory is just of uh let's say here is the example here's the example given this is dis I have a program of 100 KB but the free space I have only of 60 K so by stalled program concept what we have to do we have to load the program into the main memory but can we do this can we do can we load the whole program into main memory no by stored program concept we cannot but we can with the help of virtual memory and overlays we'll see what is virtual memory and overlays in few minutes so what is the goal again minimize fragmentation and secondly manage larger program in small memory areas okay so this means operating system can load more program in memory and this actually means degree of multiprogramming increases and you all know if multiprogramming increases which means efficiency and throughput increases so this memory management or memory manager is a critical module of operating system now let's understand what is overlays take an example this is a assembler architecture this is what assembler is okay it has a pass one pass two pass one of 70 KB pass two of 80 KB don't worry if you don't know what is pass they will learn that in detail in our compiler design course so pass one has 70 KB Pass 2 has 80 KB symbol table common routines and overlay loader these are of 30 KB 20 KB and 10 KB respectively now the whole size of this assembler is 210 KB so to to convert any program into Assembly Language using this assembler we need 210 KB memory but what happens we had some budget constraint and we can only have a 150 KB memory now can we somehow convert a pro convert a or can we somehow use this assembler on this 150 KB given that this is a two pass assembler that is two stage assembler and pass one and pass two are independent there's no relation between pass one and pass two we need one at a time so can we execute or can we use this assembler on this 150 KB yes we can so the main idea is complete pass one first and then replace it with the pass two as both are independent so what we have done this 3 4 5 which means uh the symbol table common routines and overload overlay loader this is necessary for everything this is necessary for every pass so what we have done we have kept it intact but as soon as pass one is executed what is the size of pass one it is 70 KB so the size of symbol table overlay and this complete size is 60 KB only so we have given at 60 KB now we are left with 90 KB so first we have loaded pass one into it pass one into it pass one will be executed because it has everything to execute pass as soon as pass one is executed we will replace pass one with pass to so this is what overlays overlay means replace and it is possible only if program is divisible into independent modules so what does overlay say overlay say if you are running short of memory and you have some uh parts of a program which can run independently then replace as soon as one part is completed so this is what overlay is let's solve an let's understand overlay more with the help of an example suppose this is a program EXP added as a overlay tree and the size of a program is 92 KV now tell me the minimum memory required to successfully execute this program using overlays you know what does overlay say search for the program units that are independent of each other so I can I can do like this root A and D this can be given as pass one root root A and E this can be assigned the name of pass two because when this is being executed there are there is no need of keeping b c f g h i j d in memory A and B are independent A and C are independent B and C are independent D and E are independent E and F are independent F and D are independent so I hope you getting the point when root A and D are there there is no need of keeping this whole tree in the main memory so what we are doing we are giving every from every path from root to node as a pass so we can say this is pass one this is pass two this is pass three pass 4 pass Five pass Six and pass seven and each pass can be executed independently so what we'll say first execute this how much memory we require 10 + 8 + 5 8 and 5 13 13 and 10 23 so we need 20 3 KV memory to execute pass 1 for pass two 10 18 and 8 which means 8 and6 so 26 KB memory required here 8 and 6 uh sorry 10 and 6 16 16 and 10 26 26 required here 10 and 7 17 17 + 12 29 29 K be required at pass 7 10 and 7 17 17 and 27 required at pass six 10 and 7 17 17 and 9 it is I think 26 so 26 can be required at pass five so I can say minimum memory required is maximum of memory required from pass 1 to pass 7 that will be the minimum memory so the maximum memory required was at pass 7 so I can say if I have 29 KB of memory then we can execute this whole program without any problem so the size of program you can see was 92 KB but but we we were able to execute the whole program in just 29 KB how were we able to achieve this using overlays replace replace replace which is not us used here so let me explain you again so if you are executing this there is no need to keep this part and this part in the main memory okay now comes the partitioning partitioning means breaking the user space into cells so partitioning says they can be different type of partitioning fixed partitioning and variable partitioning we are first going to study fixed partitioning multiprogramming with fixed task you will get the idea why we have said multiprogramming fixed task in few minutes so what we have done this is our system area this is our user area let's expand this user area so what we have done we have divided this user area into different blocks they can be have different size but what we have done we have divided the user area into different blocks or different segments so we will divide it into fixed number of partitions and in each partition we are going to store a program a bigger program will be stored in the bigger partition and smaller program will be stored in the smaller partition so partition may be of different size but the important thing which you have to remember is only a single program can be stored in a single partition so there is a kind of one to one relationship here okay uh one to one relationship here so the size of program size of partitions can be different as program size are different so what we have learned till now partitioning can be of different type fixed partition variable partition in fix partition the pro the user area can be divided into different partitions of different size and each partition can stored only a single program and size of partition can be different because program size are different limit resistors it's a kind of resistor and what is what is the purpose of limit registor let's see here the purpose of limit register is to basically Define the size or instruction range of that process let's take an example suppose CPU generates an address of 2800 process Pi is running and it generates an address of 2800 but in main memory we have instructions of process Pi defined till 2500 only from 2,000 to 2500 let me Zoom it so it generates an address of 2800 but the process address space is from 2,000 to 2500 only now it is the responsibility of memory manager to ensure that because this 2800 can be the address space of some different process this Pi is being mischievous and it is trying to access the private address space of some different process so now it's the memory manager job to stop stop it how it's going to stop so what we have done the starting address is the Base address and this 500 is the limit so this 500 will be stored in the limit register so what happens the address comes here the firstly it will check is is the address greater than the Base address or greater than equal to the Base address because if it is less than equal to Base address then also Pi is trying to access the address space of some different process so first it will check if the address is of this area only how it will check it will first check if it is greater than 2,000 which means it of this part or not if no then it is a trap to operating system monitor addressing error and if yes if it founds that the address generated by the process consist of this area then it goes to the next phase it says the address you generated is it less than the base plus limit the address you generated is it less than this part which means now the address is confined to this area only but here what we see the address is of 2800 so here here it will say no the address is not less than 2800 is not less than 2500 so it will go here trap interrupt will generate saying addressing error now let's take an example suppose the address which is generated was 2100 now what happens it goes here it first check is 2100 greater than equal to 2,000 yes now it comes here it ask is 2100 less than 2500 yes then it can access so this is what limit register do this 500 is the limit register it is the size of the process address space and what does base register do it gives the starting address so this limit register done at the O voting time it used for partitioning so this is instruction range base plus limit architecture to ensure protection okay as we have CPU scheduling techniques we have techniques for partition allocation to partition allocation to suppose a new process comes uh a new program has 80 KB size we have to bring that into main memory now the main memory has different available partitions it has a partition of 200 KB it has a partition of 120 KB 70 KB 81 KB now in which partition it should go this is what partition allocation algorithm or partition allocation policy that we'll learn in the next lecture okay so now let's revise what we have learned till now memory management techniques consist of two part contigous and noncontiguous contiguous is when we bring the whole program at one place and noncontiguous ISS that it is dist it's first broken down and it is distributed at different locations of the memory now we have memory management techniques the old techniques include overlays partitions and body systems we have studied overlay what does overlay say we will see when the topic will come so these are the old techniques and these are the new techniques functions and goals are allocation protection and Free Space Management address translation deallocation goals is to minimize fragmentation and ability to manage larger program into smaller memory areas what does overlay say overly says that you don't need to take the whole program into main memory complete unit one first and then replace it with unit two as both are independent we have seen an example now partitioning partitioning of fixed partition we divide the whole program or the whole user area into different partitions and can they can be of different size limit what does limit register do it helps in the ensuring protection and now in the next lecture we'll learn how partitions are allocated see in CPU scheding what we have learned we have learned how from Main memory the which process should go to the CPU now in Partition allocation we will learn from hard disk at which place the pro the program should go okay now let's learn about partition allocation policy as we have different algorithms for CPU scheding similar way we have different policies named as first fit best fit next fit and worst fit let's see what they all say the first fit says search for the first slot or the first partition big enough to accommodate the program suppose here in the case for the first slot is 200 big enough to accommodate my program yes then according to the first fit policy this 80kb program will be stored at partition number one okay so 80kb program will be at 200 KB partition so 120 KB remain as waste because I have told you in Partition and program there is one to one relationship a program can be stored at only one partition or a partition can hold only one program so there's a one to one relationship and if 0kb program is stored in 200 KB partition then 120 KB will go to waste that kind of wastage we call as internal fragmentation okay so in first fit what we do we search from the first partition in best fit what we do least internal fragmentation so here 80 KB can be stored at this part only 1 KB will be wasted here so which is the best fit here in such a way that the internal fragmentation or the wastage of memory will be least so least internal fragmentation smallest free partition big enough okay in first fit first free big enough in best fit smallest free big enough in next fit it works it works like the first fit search begins from the last location see in first fit we start from the first part in next fit we start from the last partition so next fit works like the first fit but here search begins from the last location and what does worst fit says largest big enough and what is the worst fit here the first fit is the 200 KB so let me revise again first free first fit says start from the first partition whichever partition is big enough to hold your program stored in that what does best fit say search all the partition and then calculate the internal fragmentation the partition with least internal fragmentation the program will be stored there now comes the next fit next fit says search from the last whichever partition is big enough to hold your program store there and the first F says search the all partitions whichever partition is maximizing the internal fragmentation that is the worst fit okay so in case of search in case of next fit search time can be saved and may work faster than first fit in some cases okay suppose uh here in this case first fit will be a bad choice next fit will be a good choice so doesn't matter much but here we say that the search time is less and it may F work faster than the first fit now we will learn about performance of fixed partition as we know fixed partition is static in nature so we can say internal fragmentation happens what is internal fragmentation suppose this is the partition size 1,00 KB and my program size is 1 KB only so the 999 will be wasted that is internal fragmentation what is external fragmentation then external fragmentation says wastage of memory outside the partition but here in this fig partition there is no there is no such memory outside the partition see here this is memory divided into partition can you see a memory outside these partitions no each memory space is divided into partition so there's no memory outside the partition so I can say there is no external fragmentation in in case of fixed partition internal fragmentation obviously exists suppose I have program size of this much only so this whole Space is wasted internally so what is internal fragmentation vage of memory in the partition external fragmentation vage of memory outside the partition the degree of multiprogramming here is limited because the degree of multiprogramming is limited why because it is equal to the number of partition it cannot change it is limited okay maximum process size is also limited it is equal to the maximum partition size partition allocation policy which we follow is best fit so this was fixed partition in fixed partition the partition is of fixed size and each partition can hold a single program now comes variable partition as the name suggest partitions can be of different size depending upon depending upon process size multiprogramming with variable task here we say fixed partition as multiprogramming with fixed task if you remember multiprogramming with fixed task now you may now you may have understood why we call it as fixed tasks okay because the degree of multi program in is limited here variable partition multiprogramming with variable task because we have Dynamic partitioning here this is let's say the process requirement P1 requires 35 kb of memory P2 requires 115 315 15 and 120 so initially no partition is there remember this point is important initially no partition is there the memory just like a free hole there is no partition now the partition is made ACC according to the process request when P1 comes 35 kb of partition is made when P2 comes 115 KB more of partition is made P3 comes so partitions are made depending upon the process request and in the end the remaining area is just like a free hole if some another process come then another partition is made P2 and P4 have all its instruction executed so leave they will leave the memory uh let me okay so this is a case in which this process and this process has completed or has executed all its instructions so what they will do now they will leave so this is a free hole now here generated so this is P1 free hole 1 P3 free hole 2 P5 free hole 3 now we have three free goals 115 KB 15 KB and 250 KB now a new process P6 comes with a request of 13 KB now a request of P6 come with a request of 13 KB what we will do we will make a partition of 13 KB here in the free hole one and the remaining free hole of 102 KB and a new free hole will be created of 102 KB so this is what dynamic partitioning is there and the allocation how allocation is done same policies first fit next fit best fit and worst fit if I talk about first fit then this 13 KB is sent here new Partition is made of 13 KB at the free hole one if I talk about next fit then you search from the big from the last and if this free hole is able to is big enough to occupy this 13 KB then you create a new Partition here of 13 KV so if I talk about next fit then free hole 3 is suitable if I talk about best fit then free hole 2 is suitable you check all the free holes and whichever free hole is causing least external fragmentation here in that case in that case this is the best fit so if I bring down this here 13 now how much how much space is is remaining 2 KB spaces remaining and we know that uh if these are the normal size of the processes and by seeing that we can assume that that having a process with Just 2 KB size is very rare So this 2 KB space will remain as it is this is what external fragmentation is memory space outside the partition which cannot be used is what externally fragmented memory okay so which free hole cause the least external fragmentation this freeold 2 so the best fit is freeold 2 now comes the worst fit it's of5 KB 15 K and 250 so this will be the worst fit now comes the performance issues internal fragmentation there's no internal fragmentation because partitions are made based on the process size so there can't be any inter internal fragmentation what is internal fragmentation in Partition when a process is able to occupy only this much space and you all know that a partition can hold hold only a single program so this space is wasted this is what internal fragmentation is and what is external fragmentation let's say this is the memory this is a partition or let's say this is the free hole I should say and these are the partitions already made here resides P1 here resides P2 here is P3 now this is the freeold a process comes and creates a new part partion of here let's say P4 comes now there is some another process P5 but it cannot be accommodate in the this this partition space so this partitioner space is being wasted here this is what external fragmentation is what is external fragmentation memory wasted outside the partitions so this is what external fragmentation is let's discuss the performance issues external fragmentation yes it will cause external fragmentation internal fragmentation no so yeah see let's take an example this is a free hole one of 115 KB free hole 2 of 15 KB and free hole 3 of 250 KB now a new process comes which is a size of 280 KB combining these these free holes have a much larger size is of 380 KB but what we are still telling this new process that memory is not available so the size of total free memory is greater than process request but it's still denied this is what external fragmentation is the size of total free memory is greater than the process request but we still deny the process that memory is not available this is what external fragmentation is degree of programming flexible maximum process size flexible partition allocation policy worst fit why worst fit because the worst fit will create the biggest free holes and if the freeh hole size is large in that case external fragmentation will be less best fit May create small free holes which may not accommodate new process so bu fit will create big free holes bigger free holes that accommodate the new processes now comes the question how are we going to solve this problem of external fragmentation so the answer is by Saving noncontinuously let's see this here what we had we had a 280 KB process and we have a free holes of 115 KB 15 KB and 250 KB we deny that memory is not available only if the case when process is requesting the whole content should be placed at placed at one area if I say process hey process is it will it be okay with you if I place 250 KB of your area here and the remaining 30 KB and the remaining 30 KB here will it be okay with you and if process is yes I am willing to be stored noncontinuously then external fragmentation issue will be resolved see here how to solve the problem of external fragmentation suppose this is the case 50k free hole 80k fre hole and 20K fre this is process one and process two now comes a new process of 85k traditionally it would be denied because continuously there is no space available to store 85k even if combining 150k is available but not continuously so what are we going to do we can make it either continuous by reallocating P1 and P2 to one end of the memory and creating a bigger freeold this is what we call compaction compaction we will shift this P1 and P2 to a 1 and of a memory and we will create a bigger fre hole see here P1 and P2 shifted to one end and now a bigger free hole of 150 KB is there and this merging of free holes is what we call competion but this competion is not very much desirable because it is a timec consuming operation so if you remember the address binding concept now this P1 and P2 are shifted to a different location so this must support runtime address binding if you remember if we Swip out a process from one location and Swip in the process to a different location this is we call runtime address binding the addresses changes so this is undesirable solution the second solution was noncontiguous allocation store the program into noncontiguous part this is what I was talking about competion is not automatic but if two free holes are adjacent then they are automatically merged well that's a common that's a thing which comes from common sense that this is free hole one free hole 2 free hole one and free hole 2 then they are just a single free hole shown with a boundary but actually they are single FS but in competion suppose this is a free hole one here freeh hole one a process comes in between and now here is the free hole two in this case I can say these free hole won't merge competion is not automatic but if free hole would have been here then these two free hole will merge automatically or by default we believe that these free holes are single free hole okay so let me discuss it again so how we are we going to solve the problem of external fragmentation the answer one was the better one the better answer was non continguous allocation the second answer was compaction in competion what we do we merge the free holes to create a bigger free hole okay in in noncontiguous location what we do we break the program into two parts or parts in different parts and store them at different memory locations this is example of variable partitioning there's a partition of 2 MB partition 2 of 6 MB partition 3 of 3 MB 4 MB and 6 MB this is the OS system area and this is the user area and in these partitions process resides so in Partition one process one is there process two in Partition two process three and so on now what happens P2 and P4 are completed so when process completes then they will leave the area and will cause a free hole here free hole here now what happens P6 and p7 arrives P6 is stored at this free hole the size of P6 is 4 MB so 4 MB is stored here and 2 MB free hole is created now here and p7 arrives p7 the size of p7 is 3 MB so what happens this 3 MB will be stored here and 1 MB of free will be created here now p8 comes the size of p8 is of 3 MB and we have a total memory available of 3 m also but we cannot load p8 why because continuous allocation because p8 demands continuous allocation and we don't have a memory at a single place we don't have 3 MB memory at a single place so p8 will be denied so this is what a basic example how variable partitioning Works let's solve some problems it says consider a memory system having six partitions of size 200 400 so these are the partition size given there are the four process of size the process requests are given using best fit allocation policy what partitions are not allocated or remains unallocated so what we will do we will allocate process in such a way that it will cause least fragmentation so P1 will be allocated to 400 will cost least fragmentation but it should be big big enough you cannot allocate to 200 okay you should know that so 357 will allocated to 400 if it would be allocated to 600 500 then it would cause more fragmentation so P1 will be allocated to 400 P22 this 250 210 will be allocated to 250 for this 468 will be allocated to 500 and this 49 this 49 will be allocated to 200 so in this way I can say that 600 and 300 was unallocated it was an easy question uh what it said you have to allocate using best fit and whichever partition was unallocated you have to tell me that so 600 and 300 is the answer second second question it says consider the following memory map in which blank regions are not in use and hedged regions are in use so these are in use and these blank ones are not in use use variable partition with no competion the sequence of request for blocks of size 300 25 125 50k can be satisfied if we use now we have to choose among these options let's see the request are 300 25 125 and 50 First we'll choose with first fit so the first fit says a lot your processes to those partitions which are big enough to accommodate and you will search from the first one I searched for the first first one is it big enough to accommodate no second one is it big enough yes so 300 will be accommodated here now comes 25k is it big enough yes 25k will be alled here is it yes 125 will be allocated now comes the 50k so in this manner first fit partition it is suitable check for the best fit we will allocate in such a way that it will cause least fragmentation 300K will be allocated here 300K now comes 25k 25k will be allocated here 125k here now comes the 50k so there's a 25 KB free space available here also 25 KB free space available but it is written in the question that we are not using competion so we will say that sorry process we won't accommodate you because we have no con 50k available with us so 50k can be accommodated so here best fit is a wrong choice first fit is actually a best choice now comes an interesting question consider a system with memory of size 1,000 kiloby it uses variable partition with no complection presently there are two partitions of 200k and 260k respectively so let's say P1 process resides in this partition P2 is in this what is the allocation request of the process which would always be denied so let's say this is the case this is the case P1 and P2 are continuously stored so these partitions are just one after another so the total size is of 460 and the remaining free hole is of 540 so I can say 541k request will all will always be denied clear now this is the good question the smallest allocation request which could be denied which could be denied is the smallest allocation request which could be denied so this 541 is denied in all cases but if we create free holes in such a way that out of these three one is denied can it be possible so what we do we shifted these two down and we created two free holes we created two free holes now the thing is the total value of these threee holes should be 540 and you divide 540 in any way you will have these three you will have these three accommodated so 131 will be stored 151 will be stored and 181 will also be stored now comes an interesting part now what we do we create an additional free hole here by shifting P2 a little bit down so P1 is here P2 is here now we have created three fre hes let's say we have created three free holes so free hole 1 plus free hole 2 plus free hole 3 should have total of 540 Let It Be 180 180 and 180 now 131 will be stored 151 will be stored but this 181 will be denied so the answer should of this question will be 181 I hope you got the idea so what we have done we have created free hes in such a way that 181 is denied let's see some another questions it says consider a system having memory size of 2^ 46 bytes it uses fixed partitioning divides into fixed size partitions each of size 2^ 24 bytes the OS maintains a process table with one entry per process each entry has two Fields the first is a pointer pointing to to partition in which the process is loaded and second field is process ID so let us draw what whatever has been given a memory has a size of 2 4 46 bytes okay fixed partitioning is used it means this memory has been divided into fixed partitions each of size each partition is of size 2^ 24 bytes so I can say the number of partitions are 2^ 46 divided by 2^ 24 and I can say it is 2^ 22 I can say and Os maintains a process table with one entry per process and always maintains a process table with one entry per process and each process has one entry in it each entry has two Fields the first is a pointer pointing to the partition the first is a pointer pointing to the partition and the second is the process ID let's say this is P1 so what it does it has divided the memory into several partitions and it is keeping a process table suppose suppose this P1 is being stored in Partition number 10 so the address of partition number 10 let's say 1 1 0 0 1 something like that in binary okay I'm just taking a random number so in process table the process ID and at which location this process is stored in the memory that is being maintained so what is the question it says the size of process side is 4 by the size of pointer to the nearest by so we have to calculate the size of pointer to calculate the size of pointer we have to first understand what does pointer contain pointer contains the address of the partition in the memory to so we have to assign each partition a unique address we have 2 what 22 number of partitions which means we need 22 bits we needs 22 bits to generate 2 22 unique addresses so the size of pointer will be of 22 bits now the question is calculate the size of pointer to the nearest bite how many bytes are able to contain 22 bits I can say three bytes can contain 22 bits each by contain 8 bit so 8 into 3 24 bits so the size of pointer to the nearest bite will be three bytes now the question arises why can't I take two bytes because with two bytes I can only generate 2 to^ 16 different kind of addresses but what we require 2 22 see if it is an extra then it is okay but it if it is less then that is not acceptable this is what we follow here the second question says size of process table in bites if system has 500 processes if system has 500 processes then there will be 500 entries the size of each entry is three bytes for the pointer and 4 bytes for the process ID so it is 7 bytes 7 FS are 3500 bytes so the size of process table should be 3500 that is the answer let us discuss it again what this problem is saying this is an important problem it says it says we have a memory of size 2 raed to^ 46 PES we have divided that memory into several partition the total number of partitions are 2^ 22 each with size 2^ 24 so each partition each partition has size 2 24 bytes and there are 2^ 22 such partitions that's how we got 2^ 46 bytes of memory now what OS has done OS has maintained a process table with one entry per process so OS has maintained a process table with one entry per process the first field of the entry contains a pointer to the partition in which that process is residing so the first entry contains the pointer and the second entry contains the process ID so what does pointer contain pointer has the address of that partition now we have to assign each partition a unique address how many partitions are there 2^ 22 partitions are there how many bits are we going to need to generate 2^ 22 unique numbers so that we can give 2^ 22 partitions unique addresses we need 22 bits that's why the size of pointer will be 22 bits now it is asked size of pointer to the nearest bite so the size of pointer will be 22 divided by 8 floor function why floor sorry it is not floor function it is seiling function why sealing function because if it is more then it is okay if it is less then it is unacceptable why so because if we take if we take two bytes then we are only going to have 16 bits we will able to generate only 2 16 different numbers but how many different numbers we require 2^ 22 with three bytes I can generate 2 24 different numbers how many different numbers we require 2 22 that's okay okay so the size of process table in bytes will be if system has 500 process three bytes for the pointer four bytes for the process ID each entry has seven bytes and the total number of entries are 500 so 7 into 500 that is 3500 this is what this question says is consider a system using variable partition with no competion we are not going to merge the free holes to create a bigger free hole free holes are given 4K 8K 20K 2K program sizes are given time for execution is given so what we have to do using best fit allocation policy and using fcfs CPU scheduling Technique we have to find the time of loading of each we have to find the time of completion of each and the first time we are given with here so firstly what we have to do we have to bring all these programs into memory to make them processes so we'll first bring so out of these we'll first start with this 2K where this 2K will be allocated at this free hole where this 14k will be allocated at this freeh hole at 20K where this 3K will be allocated 3K will be allocated at this 4K where this 6 K will be allocated see if you remember when 14k was allocated to 20K a free hole of 6K was remained there so we allocate that 6K here now now see here firstly 2K was allocated here and then 14k was allocated here 3K was allocated here and 20K was allocated here oh n 6K was allocated here to fill this free hole of 20K now what is the remaining we have 6K remaining as at 8K fre and 1K remaining at 4K fre okay now what we have done we have also you must have seen here this purple shade this purple shade is showing a a small Gap a gap to ensure that these are not adjacent otherwise they will go Le or merge automatically okay so what we have to do now we have to schedule them we have to schedule them see here only 10K and 20K will be at the disc this 2K will also be scheduled here so so which programs are in the disk now 10K and 20K are in the disk now we will first schedule these and after that and after that when we have free spaces then this 10K and 20K will also come in the memory so we will schedule them first how are we going to schedule we will schedule using fcfs ceding so which program came first 2K came first so we are going to schedule 2K first here is the let's say let's call them process the one who arrived let's call them process one the second one to arrive let's call them process two the third one to arrive process three okay so we have assigned the process ID based on the time they arrive okay this it's just a matter of representation it will not uh it will not matter actually okay so first 2K arrived for the time of 4 units so from 0 to 4 2K will run the next 14k ride for 10 units so from 4 to 14 this 14k will run from 4 to 14 this 14k run now you can see here this part has become empty now this part has become empty now so here at 14k free hole we can actually schedule 10K so here 10K will come so now this 14k fre is empty 10K has arrived here and and I have a free o of 4K also see here if this 14k has gone and I have now 10K here so I will also have a free hole of 4K remaining that's how it becomes a total sum of 20 so scheduled scheduled that's 10K have come now which process 3K so 3K will be scheduled for how much time it has a first time of 2 units so from 14 to 16 3K will be scheduled now 6K 6K has a time of 1 unit so from 16 to 17 6K will be scheduled now if you remember 2K was brought into memory so 2K will be scheduled for 8 unit of time 2K will be scheduled for 8 unit of time so from 17 to 25 from 17 to 25 2K will be shed now it's time for this 10K because after the 10K has come so 10K will be scheduled for 4 unit of time so from 25 to 29 10K will be scheduled so now if you see we have empty space for 20K this has been scheduled this has been scheduled this has been scheduled now 20K free is present here let me write like this schedu shedu now we have 20K freeold here so what are we going to do we are going to bring that 20K here in the memory now 20K will be sched what is the bu time of 20K 20K bu time is 1 only so from 29 to 30 this 20K will be scheduled so this is how we have we have uh done a question of partition allocation as well as CP scheding both okay so this is how it looks now load time P1 P2 P3 P4 P5 were loaded at 0er P6 was loaded at 14 here that was the 10K and p7 was loaded at 29 that was the 20K proc okay so this is how we have done this let me repeat again what we have done so firstly we have to allot using best fit allocation policy we have given the program into those free holes which causes least fragmentation so 2K was allocated here 14k was located here 3K was located here 6K was located here okay in this way we have allocated and 2K which was remaining was allocated here when 6K + 2K both were allocated at the slot of 8K now we will start scheduling because we have two more process two more programs in the disc and they are waiting as soon as the memory becomes empty for them or they have the memory have enough space to accommodate them they will come so when this 14k was when this 14k was executed it has left the memory so it made a free hole for for 10K 10K came there when this 10K was completely executed when this 10K when this 10K was completely executed and the remaining was uh what was the remaining the 6K so 6K and 10K when these were executed now it has created a free hole to commodate 20K also so there 20K comes and this way we have scheduled the processes okay now it's your homework to calculate the completion time from the G chart how are you going to do that when was p7 completed at time 30 when was P2 completed at time 14 P4 at time 17 in this way you have to calculate the completion time loading time I've already told you consider the allocation of memory to a new process assume that none of the existing holes in the memory will exactly fit the process memory requirement hence what happens a new holes a new hole of a smaller size will be created if a location is made in any of the existing holes which of the following statement is true the first says the whole cre by next fit is never larger than the hole created by best fit well this is false best fit Works in order to create the smallest holes the second option says the hole created by worst fit is always larger than the hole created by first fit well this is also false because worst fit and first fit can be same so this always is creating a problem here the hole created by first fit is always larger than the hole created by next fit well this is this is false also because they may be equal they may be equal so if here it is written always larger that's create the problem the whole created by Best Fit is never larger than the hole created by first fit well this is true in all cases how can I say that because best fit works or the motive of best fit is to create the smallest holes so yes this is true best fit is the hole created by Best Fit is never larger than the hole created by first fit memory management part four noncontinuous allocation what was noncontinuous allocation suppose your process size is 100 KB but you have free space available for here 40 KB here 40 KB and in the last somewhere 20 KB if you have used continuous allocation you won't be able to bring that process from dis to memory but if you have used nonous location what we will do we will break this process into parts of 40 KB 40 KB and 20 KB this 40 and 40 is 80 80 and 20 is 100 so that 40 will be stored here this 40 will be stored here and this 20 will be stored here this is what noncontinuous allocation means you are not storing continuously okay so this noncontinuous allocation is useful to prevent external fragmentation what was external fragmentation before that first understand what was internal fragmentation suppose this was your partition and your process took this much space only now this space will remain unused because in a partition only a single process can reside so this is what internal fragmentation was this internal fragmentation happens in the case of in the case of yes you remember fixed partitioning because partitions were fixed process size are different so in that case in some partition it is usual for some memory to get wasted so that is the drawback of fixed partitioning now what we have done we have introduced variable partitioning Vari variable partitioning create partitions based on the process size let's say the process size is 10 KB so initially the memory is nothing but the free hole so what happens when a 10 KB process comes it create a partition of 10 KB so this is what variable partitioning was so we have a partition somewhere here somewhere here now what happens this 10 KB process let me create a better diagram suppose these are the partitions based on the process size okay now what happens P1 has been executed and it wants to leave the memory so now this uh P1 will get empty here this is now a free hole P3 also became ex also became a dead process so it will also leave the memory two fre have been created now P6 has also left the memory three freees are there 20 KB or whatever was the size 20 KB 40 KB and 40 KB now a new process wants to enter into the memory let's say it size is 100 KB what we will respond to that process we will respond in two of the either way the first way is hey process we are so sorry that you cannot be accommodate continuously continuously so you should remain in the dis the second way is a process I have an idea we don't have a 100 KB space continuously but if you you are comfortable we'll break you into three pieces of 40 KB 40 KB and 20 KB each and we will store you at the different location the process says yes I'm comfortable so this is what noncontiguous allocation is if the if the location was not continuous this 20 KB space will not be used if some process of size greater than or greater than 20 KB comes let's say a size of 100 KB have come if we have used continuous allocation this 20K will never be used but now we have used noncontiguous allocation so this has prevented the external fragmentation or the external memory wastage of this 20K so this is how noncontiguous allocation prevents the external fragmentation we have another method named compaction compaction was actually undesirable because it was time consuming operation required program to execute runtime atress binding so what we did in competion in competion we have let's see some process P1 a free hole here process P2 and a free hole here what we did we swept out the process P2 and then swept in at the different location so that the two free holes become adjacent to each other and if two free holes are adjacent to each other they will automatically CES resulting into a creation of bigger free hole so this is what competion is but it is undesirable because first it is time consuming the second it requires program to execute runtime at B and and let's learn what is address space address space is nothing but a set of words binded with the addresses memory is nothing but an address space it is also known as physical address space memory has different words each word has a unique address this is what address space is address space can be divided into two logical address space and physical address space logical address space is also known as virtual address space why virtual we will see it later in some time so before understanding the Las and the Pas we need to First understand what is logical address and physical address take this example I have already given you uh let me give it again suppose this is me this is you you come to me and ask hey do you know where is the library I say yes or I should uh you should ask me some private information like where is your house I say my house is you you just go 100 m straight and then take a left the second house is mine you go there it's good now what happens this information is e dropped by some Intruder he tries to do the same thing from different location he tries to go 100 m straight and take the left did he reach at my house no he reached at a different location though this is what logical address does but suppose if you asked me the address of my house and I have told you my house is at coordinate 10 comma 10 then this robber would have directly jumped at my house 10 comma 10 because he's now available with the physical address and you were given with the this this go straight and take the left this was The Logical address okay so what is the need of creating this logical address and physical address can't we just create the physical address directly no suppose this process has created the physical address directly has generated the address to directly access the memory content the instruction or data who is stopping the process not to create the physical address or U the actual address of some different processes address space who is stopping this process to create the physical address or generate the physical address of some different instruction or data which it is not supposed to exess this is the security concern take an example uh it's little bit different but it will give you a feel what happens in the college suppose you are in examination Hall you write your role number iitv 44 this is your role number when this copy this answer sheet will be sent to a different department or when this answer sheet will be sent for copy checking what happens they change the actual role number with a D role number so this iitb 404 that's actual role number will be changed to this logical sequence of number which has no meaning why is it done so to ensure unbiased checking suppose I'm deer to some Professor so Professor when sees the copy IIT B 404 hey this role number I remember his is sh R number and he's a nice guy I should give I should check his copy little liberally or I should give him more marks that kind of thought may come into an examiner's mind or the the one who is checking the copies that kind of thought may come it's natural so what they do they change the address or I should say this they change the role number with a dummy role number which we call as logical role number this was our physical role number an actual role number to ensure unbias checking this is uh something similar is done here in the in the memory management part also process running in the CPU generates some logical address logical address is sent to memory management unit and it is converted into physical address that is the actual address that is the actual address of instruction and data which this process want to access so the process generate what it generates n bit logical address this nbit logical address is converted into nbit physical address or maybe different bit physical address not necessary of n Bits only the OS the OS has control on physical address so physical address is accessed only by the OS let me repeat what happens process generate logical address converted into physical address with the help of memory management unit and that physical address is the actual address where the data is stored this is how the conversion works okay now let us clarify this thing physical address thing suppose this is my memory and it contains several words each word associated with different address the width of the address or the number of bits in the physical address I say as physical address has n Bits how many words would have been there in the physical address space or in the main memory I can say 2 ra to power n Bits words should have been there so this is what the physical address space or the capacity of the memory 2 ra to power physical address 2 ra to power physical address and physical address is always in the bits suppose I have four bit physical address then I can say then that there are 16 words in the memory and if it is bite addressable then this 16 world or 16 by directly give me the capacity of the memory this is what happens in the physical address space physical address space equals to 2 power physical address now I have formul written why doesn't the process directly access the physical address space because of security if we allow P2 to access physical address directly then it can also access physical address of P1 and P2 who is stopping P2 access uh who is stopping P2 to access physical address of the OS well that's a that's a very very serious concern who is the stopping process to access the operating system well operating system is also in the memory operating system also have some physical address if we allow a process to directly generate physical address who is stopping this process to access operating system well that's a thing of concern that's why operating system say let the process generate whatever they want I have the mapping table I will map and make a space accessible so that you cannot directly interfere that's why the addresses the set of addresses generated by the process is what logical address space is so OS says you generate whatever you want I have the mapping table I have the mapping table I will map I will map this RO number to this role number this is how this uh memory management or the translation of physical address and logical address works okay so OS maintains a table here mapping of all the logical address a process can generate and the corresponding and the corresponding physical addresses this table is maintained by the operating system so this is The Logical address each logical address corresponds to a world in the main memory each logical address correspond to the world in the main memory if you are not getting this just think why a process generate a logical address to access a word that's why each logical address should have been generated to access a word in the memory that's why I can say each logical address correspond to a word in the main memory so each logical address correspond to a physical address now comes the function of memory management unit the function is address translation program assume that I am in a logical memory OS will give it an illusion okay if I say formally it is an abstraction layer so what does program assumes program assumes that I am I am here in The Logical address Space Program assumes in that I am here in The Logical address space this process thinks that I am in The Logical address space and I'll generate The Logical address and this logical address will access the data and instructions here the process this process doesn't even know what is in the what is how OS is working in the back to ensure security this process doesn't even know this process thinks that everything resides in this logical space I generate The Logical address I get the data and instruction section from The Logical address process doesn't even know there exist some physical address or physical address space or main memory process doesn't know that there exist some memory management unit this is what abstraction actually is let's learn the design and implementation of noncontinuous techniques we learn the organization of logical address space physical address space and memory management unit it will start with simple paging suppose The Logical address space is of 8 KB and The Logical address is of 13 bits physical addresses is of 4 KB and physical address is of 12 bits now what we do we divide The Logical address space or the virtual address space into equal sized unit call Pages that's why we have named paging here what we have done this whole logical address space has been divided into equal sized equal sized remember this word equal sized Pages page sizes of one KB page size is of 1 KB so how many pages will be there 8 KB divided by 1 KB here I got eight pages from p 0 to p7 okay so the number of pages we get by logical address space divided by Page size the number of pages we got are eight pages now we have to for each page number for each page number how many bits are required three bits will be required for this page number 0 we'll require 0 1 and for page number seven we require 111 so page number P we we Define it by or we have a variable named P equals to log to n what is n number of pages how many page number or how many bits in the page number is required log to number of pages suppose I have n Bits in the page number which means I can generate 2 ra to power n different pages I hope I have told you from the both ways now what happens we will learn about page offset see the whole logical address space can be divided let's say for to keep it simple is only divided into two pages now each page will contain more than one word so there can be more than one word in a page now which word from that page we want to access we call that as page offset we divided into two pages this is word one word two word three and word four 1 2 3 and 4 this is 0 0 this word is 0 0 0 1 1 Z and 1 one now we want to access the fourth word so that address or uh that is called page offset which word we want to access from a particular page is called as page offset and how many bits are required in a page offset depends on the page size if there are four words then I require log to four bits if there are eight words then I require three bits so it depend how many words are there in a page so page offset will be equals to log to page size if page size is of four words then there will be two bits in the page offset so till now what we have learned the number of pages let's let's go from the start logical address space is divided into equal sized unit called pages okay each page may contain number of words and number of pages will be equal to this whole logical address space divided by Page size this is what we will give we will get by dividing logical address Space by Page size we'll get number of pages and we have to give each page a number we have to give each page a number so how many bits are required to give n Pages a number log to n Bits will be required or we can say the other way suppose suppose I have n Bits then I can give 2 ra to power n Pages a unique number so the page number will be log to number of pages now comes to page offset what does page offset say a page may contain diff a page may contain many words out of these which word you want to access this is what page offset is this page offset is the size how many bits you require to uniquely identify a word in a page what is Page offset how many bits you require to uniquely identify a word in a page this page number says how many bits is required to uniquely identify a a page from the set of pages I hope you now understand what is the this what is the formula of M what is p and what is D okay so how many bits need to refer one bite from 1 KB page that is 10 bits which is called as page offset okay let's say let's say this is a word in a page this is this is a word in a page and this is the whole page I want to access this instruction so from a whole page from a whole page there are number of words how many bits I need to give address or to uniquely identify each word in the page well that will be equal to the number of words there so number of words or the page size I will do what log two page size or I can say number of words there in a page equal to page size that is Page offset okay so let's let's understand by a different analogy also what happens this is our classroom this is the teacher this is the student the student or the teacher want to call this student so what will teacher do teacher will call the bench number one and from this bench teacher will call the third student from the left so this so this statement third student from the left this is what page offset is first bench this is what page number is I hope now you're getting the idea let me summarize again so what happens this logical address space is divided into equal size unit call pages and we have to give each page a different name or different address so that is what page number will help us we'll have to find the number of pages log to n will be the page number now we have successfully identified let's say 1 this is 0 0 or this is 01 we have success successfully identified this page contains our instruction this page contains our instruction now this page have several words which word from this page contains our instruction to find that we require a page offset we require a page offset let's say 1 1 1 this is the page offset this says the seventh word or this is the eth so this is0 1 2 3 4 5 6 7 so this word contains my instruction I hope now you have a clear idea what this page offset page number and number of pages means okay so that third student is Page offset the first bench is the page number and this classroom is the main memory this is how exactly logical addressing works so in a logical address format what we have we have this logical address divided into two parts the first part is page number it is used to identify which page contains our instruction and the second part is the page offset it is used to identify in this page which word contain my instruction let me repeat again and then we'll end our lecture logical address format has two Fields the first field is page number the second field is Page offset the first field says which page contains my instruction and the second field says in this page which word contains my instruction that's how you reach to the final part that's how you reach to the instruction that you want first you identify the page then you identify ify the word in that page that's containing your instruction in the next lecture we will see some questions that will increase your Clarity see this question The Logical address space is of 32 MB so I can say for 32 it is 5 and for MB it is 20 so I can say 25 2 power 25 bytes for to address each by to address each by in total I would require a 25 bit address suppose my instruction is at some this by present here how I'm going to reach that instruction firstly I have to I have to find in which page this instruction is there and then I will find in which word of the page instruction is present so in total in total I would require 25 bit after of this some of the page bits and some of the offset bits so how are we going to find the page bits for that we need to know the page size it is given 4 KB so I can say this 2^ 25 bytes address space is divided into pages each of size 2^ 12 bytes so how many pages will be there 2^ 25 2^ 25 divid 2^ 12 that is 2^ 13 pages are there to uniquely identify these pages I have to assign them page number how many bits are required to generates 2^ 13 unique numbers I would require 13 bits so for page number 13 bits are required now 13 bits are given here how many bits I'm going to require for this offset 25 13 that will be 12 bits I hope you got the idea now okay see this question it ask let's say the total number of pages are 2K which means 2^ 11 pages The Logical address is of 32 bits can you give me the page size can you give me the page size if the logical address is of 32 bits I can say The Logical address space will be of 2^ 32 bytes I know this 2 32 bytes is divided into 2^ 11 pages so what will be the page size page size will be of logical address space divided by the number of pages so 2^ 32 divide 2^ 11 I get 2^ 21 I can write 2^ 21 like this 2 power 2 power 1 into 2^ 20 so I can say this is 2 MB so the page size is of 2 MB this is how you have to solve see don't mug up the things try to understand the concept if you just learn the formula you will believe me you will get stuck in the difficult questions but if you understand the concept no question will be difficult for you now we'll learn the organization of physical address space physical address space is divided into equal size units just like The Logical address space But Here we call them as frames and each frame hold on a one page so I can say the frame size will be equal to the page size let me repeat logical address space contain different pages and physical address space this is this is what the main memory is physical address space in the same way is divided into different frames and each frame contains one page see this Frame zero contains page number five frame one contains page number two frame two contains page number zero frame three contains page number seven so I can say this frame size should be equal to page size remember this this is an important concept so frame is meant for holding a page any page can be stored in any frame but remember only one page can be stored in one frame because the page size is equal to frame size so if I ask if I ask number of frames will be physical address space divided by frame size or I can also write physical address page divided by Page size what I have done this whole physical address has been divided into number of frames each frame is equal to one page or each frame size equal to a page size so I can write physical address space equals physical address spage divided by Page size equals to number of frames we denote number of frames with m and frame numbers depends on the number of frames log 2 number of frames this is what will be required to these many bits are required to give each frame a different number okay see I have if I have n Bits then I can generate 2 power n different numbers and these 2 power n different number can be assigned to these two power n frames so if I if I have to go other way around I can say if I have 2 power n frames then I would require n Bits we have done this concept so many times you should torrow with this okay and same frame offset page offset frame offset and Page offset are same frame size and Page size are same so physical address consist of frame number and offset frame number helps in finding in which frame our page is present and this offset is finding in that page in which world the instruction is present okay so let's see this logical address is of 2^ 31 bits physical address is of two uh physical address is of 20 bits page size is 4 KB page of 4 KB what can I tell from this logical address is 31 bits so I can say The Logical address space will be of 2^ 31 bytes and this logical address space is divided into pages each of size 4 KB I can write it as 2 and this K is 10 so 2 power 12 what is 2 31 12 it is 19 so I can say number of pages are 2^ 19 okay now anything more check and tell I can tell number of frames also physical address space is of 2^ 20 bytes and I have told you that each frame contain a single page so I can say frames size is equals to page size so this 2 ra^ 20 is the physical address space divided into different frames each of size 2^ 12 by this so I calculate 2^ 8 is the number of frames in the main memory 2^ 19 is the number of frames in The Logical address space number of pages in The Logical address space we don't call Pages as frames in The Logical letter space we call frames in physical letter space so Pages for l s and frames for PES okay now how many how many bits we require to uh give each frame a different number we require eight bits and how many for uh page we require 19 bits now we have to find the offset what will the offset see this physical address space consist of 20 bits and I have 8 Bits for frames so it require 12 bits for 12 bits for the offset can I go the other way from The Logical address yes The Logical address consist of 31 bits 19 bits is assigned to page number so I will require 12 bits for offset this the 19 came from here I hope now the whole concept is clear how are we uh doing this or how how are we solving this let me repeat for the last and the final time I know you all are bored but this is an important concept no misconception should remain what happens logical address space is divided into different units called as Pages how many bits we require to give each page a different number that's called the page number so page number will be log 2 N The Logical address consist of page number and offset what is page number used for to identify in which page instruction is present and what is this offset used for to identify in which word of that page my instruction is present okay now comes to the physical address part in physical address space what happens this whole main memory is divided into different units called as frames each frame is supposed to store a page each frame is supposed to store a page so I can say the page size will be equals to frame size this logical address is divided into different frames so I require F log to m m is the number of frames log to m is the number of bits for frame number and D will be the same now what is f will useful for f will tell you in which frame your page is present and D will tell you in which word of that page your instruction is present I hope the point is clear now let's see one more question and then we will learn organization of memory management unit in the next lecture the question says the system has 4K pages and 1K frames so the number of pages are 4K so I can say these are 2^ 12 and 1K frames number of frames are number of frames are 1K if I if I can find the frame size somehow so what I will do I will multiply the number of frames into frame size to get the size of main memory which is what the physical inter space that's what is asked so I have to find the frame size somehow but I know frame size equal to page size so how can I find the page size we are given with logical address that is 32 bit so The Logical address space is 2 32 and it is divided into 2^ 12 pages so what is the page size we got 2^ 20 so we have how many frames we have 2^ 10 frames each frame of size 2^ 20 so I'll get 2^ 30 that is 1 GB is the physical address space so this is what one method is we can go from a different way also we can find the physical address Space by finding the number of bits in physical address and then we will just do like this to find the bits in the physical address we need to find the this part frame number of uh bits in frame number and number of bits in offset how can you find the number of bits in offset with the help of frame size log two log to frame size or log to page size is what the offset is I hope you are not getting confused here let me give you a simple example we got the pay size is 2^ 20 our instruction is residing in one bit of this 2 20 bits to find the address of that particular bit we require we require 20 bits we require 20 bits to give a unique number to 2 20 bytes or a unique number to each word and nothing is given so we will see the memories world uh byte addressable so what what I can say the One World equal to 1 byte 2ed to power 20 bytes are there which means each instruction or uh instruction which we want is stored in somewhere in a bite or I want a bite address to access that instruction well that's a better line I I want a bite address to access that instruction how can I find that bite address with the help of these 20 bits these 20 bits will generate 2 20 different kind of addresses that 2 20 different kind of addresses will be assigned to these many bytes in a page in a page so if I want to access a specific bite I want a 2 20 bit address so that's what this D is if you're getting confused just remember the formula when you will solve more and more problem problem then this confusion will be eradicated and you will understand the concept for now if you are getting confused remember the formula what is the formula of D log to page size or log to frame size both are same so I got 20 bits here now I have to find the number of bits in frame number how many frames are with me there are total 2^ 10 frames here so I'll require 10 bits for giving a unique number to each frame so the total number of bits in the physical address is 30 bits so what will the physical address page 2^ 30 that is 1 GB we can also do like that okay so this is what we have done now logical address logical address space consist of logical address this logical address when raised to two ra to power logical address will give you the logical address space this n is the number of pages m is the number of frames p is the page number f is the f f is the frame number D is the offset okay how are you going to find the page number you will find the page number with the help of logical address Space by Page size how are you going to find the number of bits in page number log to n how are you going to find the number of bits in the soft set log to page size how are you going to find the physical address space log to physical address bits in the physical address how are you going to find the number of frames physical address space divided by frame size how are you going to find the number of bits in a frame log 2 m how are you going to find the offset bits you can find by log to either frame size or page size both are same I hope there is no confusion now in the next lecture we will learn organization of memory management unit so we were learning the address translation and we have already studied this analogy of physical address being translated to logical address for unbiased checking so our physical that is the actual role number is being translated to some dummy number that we call logical role number for checking to be unbiased so what the management does it translate this to this but while assigning some dummy number to the actual role number they must have maintained some kind of table so that when the result come they have to when the result come they have to upload the marksheet on uh regarding this role number they are not going to upload the marksheet of this dummy RO number how is the student going to check the marks he only knows his role number so what happens they have to translate it again back to the physical role number how are we going to how are they going to translate by using this table they maintain where there is the actual role number and there is the dummy number that is assigned so using this table they do the translation work same happens in the case of memory management unit let's go to that part so in this lecture we will learn about organization of memory management unit and this is an important thing so you have to pay more focus and attention memory management unit also maintain a table known as page table but you have to remember each process has its own page table each process has its own page table I should open that uh translation diagram in some other window so there is a process this process is going to generate a logical address and this logical address will be sent to memory management unit memory management unit will maintain a page table and from the help of that page table it is going to give the physical address you know what logical address consists of it consists of page number and offset and what does physical address consist of it consist of frame number and offset so in memory management unit in page table what is written or what are the entries of the page table page table contains page table contains the frame number page table contains the frame number where that page is stored suppose if I write p 0 P1 P2 so how many entries will be in the page table the number of entries will be equal to number of pages so I will write p 0 is stored in the frame 7 P1 isor in the frame two P2 is instored in the frame three so this is what this is what page table looks like now what happens now what happens I got this logical address so I will with the help of this page number I will go to that page number in the page table and I will find that this page number is stored in which frame of the memory that frame number will be sent to this Frame number that is logical that is the physical address and this offset will be copied as it is why because frame size is equals to page size so this is how page table works so let us understand the points regarding the organization of mmu each process has its own page table page table are stored in the memory and the important thing is this whole page table which I have made here this which will contain frames and P0 to all these numbers this will be stored here in the memory this will be stored in the memory only so the page table are instored in memory page table are organized as a set of entries known as page table entries and you already know what what is in the page table entries page table entries contains the frame number in which the indexed page numbers is stored page number page table entry would look like this this is P0 P2 P3 this is how the indexed page number are stored the first entry corresponding to the page zero the second entry correspond to the page One automatically well this is not the part of page table entry you should remember that if in page table looks like this only F0 F7 fs3 then the index automatically defines see this is the index of page 0 so the index automatically defin that page0 lies in frame zero this is the index of page two so the index automatically Define the frame where this page is stored so 0 1 2 3 4 if I if it is written somewhere 22 and here it is written f17 so this is page number 22 residing in frame number 17 this is what page table looks like okay so the number of entries in the page table will be equal to number of pages it contains the frame number in which the page is present you already know this and it is denoted at as e byes so this e will be the size of one page table entries page table size equals to the E is the size of one page table entry the total page table size will be number of pages because that many entries will be there and size of each entry let me rep page table size will be equal to number of entries will be equal to number of pages multiplied by size of each entry number of entries into size of each entry this is what page table size is here's a diagram of page table these are the index representing the page number and this binary number will represent the frame numbers see if it is written in the page table entry if it is written like if if it is written like 1 1 1 and 1 one so what does this represent this represent that page number 7 is at frame number three this is the index representing the page number and the actual entry represent the frame number so how does address translation work process will generate The Logical address in logical address you already know the page number and the offset this offset will be copied as it is to the physical address and this page number where this page number is residing this corresponding to the page number five it reside in the frame first frame that is the 00 frame so this 0 will be sent here this is how we get the physical address of 12bit and that from this 12bit address I can directly access the memory so this is how translation of address from logical address to physical address Works let's have a small revision let's say we have a logical address space of 8 KB and logical address of 13 bits how we got that 3 4 8 and 10 for K so 13 bits we have logical address physical address space of 4 KB then two for 4 and 10 for K hence we got 12 bits our page size is of 1 KB so I can directly say that offset will be of 10 bits this is how it will going to look this is our logical address space of 8 KB with a page size of 1 KB so there will be eight pages P from p 0 to p7 each of size 1 KB physical address space will be of 4 KB and each frame will have a size of 1 KB so there will be four frames F0 F1 FS2 and F3 okay now let's say the process generated the address of p7 so this p7 will be existed from here this will will be translate will be sent to the memory management unit which has access to page table this page table will tell that this page that is p7 is held at which frame it is at frame Zer so 0 will be 0 0 will be at this Frame number and this offset will be copied as it is hence we get a physical address and from this physical address we are going to access the physical address space or main memory so this how it work now now let's again discuss some of the formulas page number number of pages will be logical address page divided by Page size number of bits in page number will be log to number of pages number of bits and offset will be log to page size number of frames will be physical address space upon page size number of bits in frame number will be log to number of frames number of bits in offset will be same log to page size number of bits needed to refer a word within a page so this is what offset is for and each page table entry contains what it contains the frame number so this is what e is and the size of page table will be number of entries in the page table into page table entry one entry of a one size of a one page table entry this is e and this is number of page table entries now for the one last time let's understand again how paging works then we'll move to the problems so the CPU generate this logical address which which has P and D this P will be used to look for f f will be copied here and D will be copied here in this way we get the physical address space that will be used to access the physical memory or main memory directly see this CPU generates this logical address which has page number and offset this page number this page number will be sent to this unit and it also have an output from page table based register now you may ask what is Page table based register the address in the memory where the page table is stored how CPU or the process is going to know where my uh where my page table is stored this page table base register will tell so from here they will access the page table with this page number P1 so the entry of p uh entry of the page table with index P1 will contain this Frame number frame number will be copied here object will be copied here that's how we got the physical address which is the direct access to the main memory okay in the next lecture we are going to see some of the problems the a computer system using paging technique implements an 8 KB page so the page size I got from here is 8 KB with a page table size of pts I got is 24 MB the page table entry is of 24 bits so I can say e is of three bytes what is the length of virtual address in the system we can solve this question using two methods let us let me write here so method one is you can go from like this total virtual memory equals to number of pages into size of each page or page size you can either find the size of total virtual memory like this or the method two says find the length of logical address and then what are you going to do you are going to do like this this is also virtual memory size so whichever day you prefer you can go from this so the pace size given is 8 KB 8 KB is given I can directly find that this is p size so D will be of three bits from for8 and 10 bits for uh this case so D will be log to 8 KB equals to 13 bits and what I'm what else I'm given with I'm given with page size so now page table entry page table size page table size is 24 MB and the size of each entry is three bytes so I can write number of entries into e e is 3 bytes so from here I can write B to be canceled n is 8 m = to 2^ 3 into 2^ 20 = 2^ 23 so I got number of pages or number of entries are 2^ 23 so from here I can go with method one also the number of pages I got 2^ 23 the size of each page is 2^ 13 2^ 13 so from from here I can write the total virtual memory is 2 36 what method two says here we got the value of D is 13 bits and from here there is n = to 2^ 23 this is what number of pages are so how many bits are required to uniquely address these 20 is for 23 Pages obviously 23 bits so from here I can go like the P will be 23 bits the total is 36 bit La equal to 36 bit so I can draw from like 2 power la which means 2^ 36 is the virtual memory size 2^ 36 is 2^ 6 into 2^ 30 this is GB and this is 64 so our total memory is total main memory 64 GB well that is we are talking about Ram well it's a powerful CPU or powerful computer it is a powerful Ram well the main memory is 64 GB that's a pretty good my laptop has only 16 GB and initially I remember when I was in sixth class I got my first computer and that has 2 GB Ram we used to play GTA y City uh those days nice days but nowadays computer really have like 64 GB Ram so this was the question which we have solved another easy question consider a computer system with 40 bit virtual addressing and pay size of 16 kiloby so should I solve here or should just explain here this is an easy question I should just explain here only what does it say we have a 40 bit virtual addressing which means La is of 40 bits so I can say logical address space will be of 2 power 40 bytes and a pace size of 16 Koby Pace size is of 16 kiloby 16 kilobyte so I can write 2^ 14 bytes okay if the computer system has one level page table per process and each page table entry requires 48 bit so the E is of 66 bytes the size of per process page table is now we have to uh tell the size of page table we have been asked with pts so pts will be equals to number of pages into or the number of entries into size of each entry we are given with size of each entry is six B 6 by how can I find number of pages well L ided PS what is L 2^ 40 what is PS 2^ 14 I should change the color 2^ 4/ 2^ 14 this is what I think I think 2^ 26 so the answer will be pts = to 2^ 26 into 2^ or it is 6 I think 6 bytes so the answer is 384 MB this is the page table size okay so this question can also be solved using two ways now think about it the same the similar way which we have done with in the previous question let's move to question number three it says a computer system using paging technique has a virtual address of length l so this is virtual address now I can say that logical address space will be of 2 power L the number of pages in the address space are J N is Zed there are H frames there are m is H calculate the number of bits in the page offset and the size of physical address space so we have been asked with the physical address space size and we have been asked with d how can I find D we have to find the page size so we are been given with logical address space we know the number of we know the number of pages so we can directly find page size equals to logical address space logical address space divided by number of pages that is Z 2 to power L / Z this is what the pa size is so how can I find the offset from this log 2 2^ l/ Z this is what D is now physical address space for physical address space I need to know I need to know the number of frames number of frames into frame size but luckily I know that page size and frame size are same so I found that page size is 2 power L by Z and I also know the number of frames how many frames are G I have I have H frames so the physical address space we got is H into 2^ L by Z okay now let's see what I have written virtual address is of L bits number of pages are Zed number of frames are H how are we going to find D with the help of page number so log to page number is what the offset is how are we going to find physical address space with the help of number of frames into size of frame number of frames is given H how can I find the size of frame size of frame is same as size of page so how can I find the size of Page from here I know that logical address page is 2 power L the number of pages are Z the number of page into page size will be equals to total memory total logical address space so pay size equals to 2 power L by Z so that's what I have written here 2 power L now we got H into 2 L by Z and we also got the offset that is log log 2 2 power L by Z 2's power L by consider system using simple paging technique with a logical address of 32 bits so what we have we have logical address of 32 bits 32 bits so I can say logical address space is of 2^ 32 bytes page table entry of 32 bits so I can say e is of 4 bytes what must be the page size and bytes so I've been asked with page size such that page table of process exactly fit in one frame of memory what is asked page table of the process page table of process which means page table size should be equals to frame size that's what it is written page table Pro page table of the process exactly fit in one frame of the memory so page table size equals to frame size what is frame size frame size is nothing but the page size so this is written page table size should be equals to to page size and what is Page table size number of entries or number of number of processes which be equal to number of pages into e we are given with the value of e that is 4 by now page size this is what the main cor of this problem is now we have to find the number of pages how are you going to find the number of pages see in this equation we have only one equation and two variables we can't solve like that so what we have to do we have to substitute the value of n what is the value of n that can be substituted we know the logical address space is 2^ 32 so the N can be written as 2^ 32 divided by the page size this is what n is number of pages equals to total memory or total logical space divided by the paas size so what we have got two 2^ 32 divid P size this P size is sent here it will become P size Square now I have 2^ 32 into 2^ 2 which is 2^ 34 2^ 34 now what is the P size then we have to take under root of this so paas size will be equal to 2^ 17 bytes so this is the answer okay let's move to another question it says virtual addressal to 32 bits so I can say virtual address space is 2 32 bytes page size is given 4 KB physical address space is given 64 MB now we have to find page table size page table size formula is n into e we need to First find the value of number of pages so what is the number of pages here 2^ 32 this virtual address page divided by Page size that's how we can get the number of pages so 2^ 32 divid by by what is Page size 4 KB so 2 power 12 from here we get 2^ 20 these are the number of pages but how are we going to find this page table entry without this we cannot solve uh we cannot solve for the page table size we need to find the page table entry for this we should remember what is installed in a page table entry in a page table entry in a page table entry frame number are stored in a page table entry frame numbers are stored so how are we going to find the frame numbers we see here we are given with physical address space so the physical address space divided by Page size is equals to frame number physical address space is 64 MB so 2^ 6 into 2^ 20 divided by what is p size P size is 4 KB which is 2^ 2 into 2^ 10 so this is it got it become 10 and from here it becomes 4 so 2^ 14 2^ 14 so this is the number of frames we have 2^ 14 frames so the page table entry page table entry size will be 14 bits the p t entry size will be 14 bits we can approximately say it is it is of 2 bytes because we want to find the P table size in bytes so what we we did we said that page table entri is of 14 bits see you can also find the value in bits No One Is Stopping You E equals to so the page table size and bits will be 14 into 2^ 20 well that's also an answer but it looks good when it is written in the bytes so what we have done we have changed it to two bytes so now it become 2 MB now the page table size is approximately 2 MB now let's understand the performance of of paging so the first issue which arises is timing issue you all remember that page table is stored in memory suppose this is memory where instructions and data are stored and here below page table is stored so what happens process generates The Logical address logical address to be converted into physical address we need to access the page table also which is the work of memory management unit so page table is stored where it is stored in the main memory only how much time it will take firstly it will access the page table so it will take let's say the memory access time is M so firstly it will access the page Table after page table it will get the physical address so from physical address it will access the instruction or data again so how much time it is taken M for accessing the page table and M for accessing the data or instruction so let us just read what is written here it says timing issue page table is stored in memory main memory access time let's say m and it is in Nan seconds what is M the amount of time CPU takes to read or write the word from the memory so the whenever you access main memory the time taken is M and what is the effective memory access time effective memory access time is actually 2m why 2 m firstly m is required to access the page table and then you get the address so another M will be required to access the actual memory or the thing which you actually want to access so effectively you took 2 m time okay this is what I have written here process generates virtual address virtual address first will access the main memory for getting the physical address with the help of page table and then after physical address you will get the main you will get the address where you your data or instruction is stored so you'll access the memory again first time to access the memory for page table second time to get the actual address so where this increases the execution time suppose if the virtual address if the process would have directly generated the physical address then we would have done it in just m time but this concept of paging when we introduced this the execution time increased we we want to make this 2 m close to m while still keeping the paging concept can we do this we want to make this 2m the total time taken is M plus M so what we want to do we want to make this 2 m close to M can we do this so firstly let's focus on reducing page table M this this m we will try to reduce okay so how we going to reduce we will in introduce the cach memory we will introduce the cach memory what will cash memory give us or what will cash memory bring to the table it is faster it is well it is a little bit costly it is small and it allow parallel searching so what we do we allow some entries of the page table we store in the cach memory which has a shorter excess time what we do we we follow that there are some some pages that we frequently access so what we do for those entries we maintain another table that is that is in included in the cach memory and the access time of cash memory is is faster so the time taken to access cash memory is less than the time taken to access the main memory so what this is what we have done here some entries of the page table we store in the cash memory which has a shorter exess time that is C is less than M so now what is the procedure virtual address when we generate virtual address the memory management unit will look that the generated virtual address is that page present in the cache memory if yes then it will access directly from here and then we will get the address of we'll get the physical address then it will access the m so now what is the time taken we have taken C plus M time which is surely less than m + m which is equal to 2 m so what we have done we have made time lesser than 2m but in case in case we have created a cash table or we have introduced a cash memory we the generated virtual address that page is not found in the cash memory then what we have to do we have to visit the page table again that will cost even more time than 2m are you getting the point what I want to say see first we had a timing issue what timing issue we had that when we introduced this concept of paging the effective memory exess time had become 2m so in solution we want to decrease this 2 m time close to M to do in order to do so we introduce cache memory a kind of memory which has a faster access time say if the main memory access time is M then cash memory access time will be C so I can say cash memory access time is lesser than the main memory access time so now what we have have done for that virtual address the page which we want to look for we will first look in the cach memory if found then we will directly get the physical address and we will access the main memory directly so now what is the time taken the time taken is C and M so the time taken is C plus M which is surely less than 2 m as C is less than M so I can say C+ m is less than M plus M or I can do like that c is less than m add M both s side C plus m is less than 2 m this was the main memory exess time the actual the effective exess time without the use of cach memory this was the effective exess time M plus M where m is the main memory access time C plus m is the effective exess time if it is a hit what is hit what is the meaning of hit hit is the page which we are looking is found in the cach memory that is hit so if it is a hit then the effective exess time will be C plus M what is C excess time of cash memory excess time of main memory which is less than 2 m so we have we have tried to decrease the effective ACC exess time with the help of cash memory but what happens in the case of Miss what happens we want to access that page which we do not access frequently in that case that page won't be found in the cash memory so firstly we will look in the cash memory we didn't find it then we move move to the page table there well at page table every page is stor so there we will find the actual physical address from that we access the memory so now it is even more than 2m what is the total time now time to access cach memory time time to access page table time to access the main memory this is what it cost to introduce the cash memory okay so effective access time now I can write is this way if it is hit then c+m if it is missed then C+ m+m now we call this cash memory as tlb translation look aside buffer okay so what we have done till now we have introduced cash memory cash memory is faster costly small small and it includes parallel searching so what we have done some entries of the page table that we frequently visit we store in the cach memory which has a faster access time which has a shorter access time okay so C is less than M we first check in Cache if not available we will go to the page table and cach is also known as tlb translation look as head buffer this is how it looks like CPU generates The Logical address that is of page number and offset from page number what we will do we will make first a parallel search in the cach memory as we are doing parallel search that's why we are faster so C is the time taken for searching in the cach memory let's say it is a hit which means we have find the page which we were looking for we have found the page which we have were looking for so tlb hit from here I can directly know the frame number and this offset will be copied as it is and we got our physical address so what is the time taken here time taken to access this cash memory and time taken to access the physical memory so this this is C+ M now what happens we have looked all over the cache uh memory but we do not find the page which we were looking for now what we will do we will look for the that page in the page table we we had a tlb Miss now we will search that page in the page table as you all know page table contain all the pages so we will find the frame number of that page which we were looking for from here we got the frame number from here we got the offset now we got the physical address so let's compare the time which we took firstly if it is a tlb hit then time to access cash memory time to access main memory it is C plus M if it is a tlb Miss then we will first access the cach memory to check now it is a Miss then we will move to the main memory page table we have found the page now we'll access the main memory so the time taken in both the cases the first case the tlb is C plus M the tlb misses C plus M plus M okay so use of tlb is Justified only if the heat ratio is high what is the meaning of hit ratio is high generally we find the page in the cache we are looking for if this is the case which means in most of the cases the probability of finding the page is high then the use of tlb Justified otherwise what is the harm the first harm is this tlb is very costly the second harm is it is increasing it is increasing the memory it is increasing the access time even more firstly it was 2 m now it is C + m + m in case of tlb Miss so let me speak again tlb is only Justified when the heat ratio is high okay now another thing if you have noticed the entry of tlb the entry of cach memory is different from the entry of page table in the main memory let me repeat again the entry of cach memory is different from the entry of page table in the main memory in main memory we had indexes representing the pages and in the entries we only had frame number but here we had frame frame number and page number side by side frame number and page number side by side okay so the entry of tlb is p plus F what is p page number f is frame number so log to n Pages plus log to M frames if it is a tlb his then hit then C plus M Which is less than 2 m if it is a tlb Miss then C + 2 m which is greater than 2m okay now we defined hit ratio as the name suggest hits upon total number of searches and what is Miss ratio misses upon total number of searches so I call hit ratio as X and miss miss ratio as 1 x okay hits hits plus Miss equals to total so I can now Define the effective memory access time as time taken effective memory access time when it is a hit effective memory access time when it is a miss so this is the effective memory access time using tlb paging with tlb and physical address cach if you remember we had the effective memory access time of 2m what we did we first access the page table then from page table we get the physical address and from there we access the main memory instruction data so it took M here and M here we tried to reduce this m with the help of tlb with tlb we introduced a cach concept of parallel searching and this DLB reduced the address translation time we are applying the same concept here physical address cache this cache will reduce the the final access time this is the m that we are using to access the main memory let me give you the proper explanation here let's say x is the hit ratio C1 and C2 are the cach excess time C1 belongs to tlb and C2 belongs to PC X1 is the hit ratio of tlb and X2 is the hit ratio of PC hope you remember what is hit ratio the thing which we are looking for if found in that cach that is a hit and what is hit ratio Hit Upon total hits upon total searches and what is a miss miss upon total searches and Miss plus hit this should be one okay so now we are going to see how this thing this all tlb and PSC thing work this is pi process in the CPU this generates a virtual address this is p and this is d p is the page number and D is the off set you all know D will be copied as it is in the physical address we have to we have to find the frame which contains this page number so firstly we will look in the tlb cache this will do the parallel searching and tries to search if this page number is in which frame number this page number is in which frame number if it is available here if we found that if we found the frame number then we call it as tlb hit that frame number number will be passed on here D will be copied from here here we got our physical address the case two was the page number which we are looking for is not available in tlb in that case we will first search for the tlb we first searched for the tlb we failed now we are going to page table that is tlb Miss so the total time will be C plus M that you all know and from here f it will be F will come from here D will come from here and there we got our physical address till this part we have discussed in the last lecture now comes the interesting story what we do this is our physical address this process wants to access this instruction or data so this physical address we will search the corresponding instruction and data regarding a physical address in physical address cache this physical address will be searched here this physical address will be searched here parallel searching will happen and if found then that corresponding instruction and data will be accessed to that process we call that as pacc hit but what happens this physical address was not available in the P then we will move to the main memory and from Main memory we will find the physical address and that instruction and data will be accessible to the process so that's how that's how it work let me give you a full flowchart we first tried to look in the tlb that page if it is not available then we'll move to the page table from either from tlb or from page table depending on the hit or miss we will find the frame number in which frame number or page is stored and we will find the offset directly from the virtual address here we got our physical address now we will look for this physical address in PC if it is available then that corresponding instruction or data will be accessible to the process if not we will look that physical address in the main memory and now that instruction of data will be accessible to the process that's how it worked so this was tlb hit this was tlb Miss this was PS hit this was P Miss okay now it's time to understand the effective memory exess time of this tlb and Pac the case one is we had a tlb we had a tlb hit let me write here case one tlb hit phase two and then phase two case two is tlb Miss and then phase two what does phase two contain phase two contain PSC hit and P Miss okay so we are going to write according to that so the first is hit tlb hit we find the physical address here now from here it starts the phase two it is PSA hit we found the instruction of data here PS Miss we first searched in the PSC as it was a Miss then we came to the main memory this was the case for tlb hit now what happens we had a tlb Miss we first looked in the tlb then we looked in the page table now we have got our physical address we will start looking for the instruction of data in the first we will look in the PSC let's say it is a hit then we have exist from the P only if it is a Miss we will first look in the PC then in the main memory so this is how we have tried to reduce the excess time we have tried to solve the timing issue with tlb and physical address or basically we have used the cach memory let's solve some questions consider system using paging with tlb what hit ratio is required to reduce the effective memory exess time from D to Zed using TLP assume that TLP ex time is K second so initially the time was 2m finally the time was we had a tlb hit and then the accessing of C this is for the tlb hit this is for accessing the tlb or Cache memory this is for accessing the main memory we had a tlb miss this is for accessing the tlb this is for accessing the page table this is for accessing the memory now what are we doing here we are asked with this x what should be the X such that we will reduce our effective memory exis time from D to Z initially it was D now it is Zed so from here we can find the value of M what is m m will be equal to D by2 we put the value of M we are given with the tbx system that is we are given with the value of C we put the value of C also so we have put the value of M we have put the value of C so now we will find X so from here we got X as k + z k + D minus Z into 2 byd okay so this is the this is the uh schematic view of how paging in with tlb is done CPU generates The Logical address from here we will look if it is available in the cache if yes that is a tlb hit and then here we find our frame number this D will be copied as it is if it is a tlb Miss if it is not found then we will go to the page table from here we find our frame number and D will be copied as it is this is our physical address we will access the main memory now comes the second issue that is space consumption issue you know the page table size is number of processes or I should say number of pages is not each process has a separate page table so this is number of number of pages it was a slip of time equals to number of entries okay so number of entries into size of each entry what the page table size is let's say we have a logical address of 32 bits okay and Pace size is of 4 KB so The Logical address space will be of 2^ 32 bytes n that is number of entries will be 2^ 32 divided by 2^ 12 this is 2^ 12 bytes so we have around 1 million entries and if each entry has a size of four bytes then we have a page table of 4 MB for each process we have a 4 MB page table now Suppose there are 100 process then 400 MB of main memory is just to store the page tables can you can you imagine that 400 MB of main memory just to store the page table well that's a serious concern and we need to reduce the space consumption so how are we going to reduce the page table size look at it we know that page table size is equal to n into entry this entry is fixed this entry size is fixed what we can do we can draw a relation that page table size is directly dependent on the page on the number of entries and this number of entries is direct is directly or I should say this number of entries is directly dependent to one by Page size or indirectly dependent to indirectly dependent to page size so I can say page table size is indirect ly dependent to or indirectly proportional to page size so if I say if I increase the page size then page table size will decrease why page table size will decrease because if I increase the page size then number of entries will decrease in that manner pce table size will decrease so we can reduce the pce table size by increasing the paase size we can reduce the P table size by increasing the paas size but but but there are side effects too now this is your homework to find what what are the disadvantages of increasing the page size in the last lecture we were discussing about the performance of paging we have seen the timing issue the spacing issue to solve the timing issue we tried using cach memory and to solve the spacing issue we thought of that to decrease page table size what is the formula number of entries into size of each entry we cannot change this but we can change this so how are we going to make this n small so in order to decrease the page table size we can do that by increasing the page size if page size is large then the number of pages will be less to cover the entire logical space that is very obvious but increasing the page size directly comes with a several side effects the first one is internal fragmentation if you increase the page size more internal fragmentation will occur see this example suppose I have a program of 1026 bytes and we have a pages of size 1024 bytes only so what we will do 1024 of this 1026 will be stored in page one and only two bytes will be stored in page two so you can see one22 bytes are wasted you cannot store another program here in this 1022 Byes this is completely wastage so the internal fragmentation here is 1022 bytes but let's say we decrease our page size we have a pages of size 2 bytes only so in just 513 pages with 2 bytes 2 bytes 2 bytes each we will cover the whole 1026 byte program here you can see number of pages are obviously more but internal fragmentation is zero it's completely zero we won't waste a single bite here so here we can see if we increase the page size internal fragmentation will be more and if pay size is less internal fragmentation will be less that's what I have written now the question arises if we cannot increase the pay size so much then what should be the optimal pay size so let's say we have a virtual address space of s bytes page table entry consist of e bytes and Page sizes of P bytes we are finding the optimal P optimal p means in which page table size and internal fragmentation both are minimum see if we increase the page size page table size decreases but internal fragmentation increases we want such paas size in which internal fragmentation is also minimum and Page table size is also minimum so what is will be the page table size according to this s by P will give number of pages into e will be the page table size that's what I have written here internal fragmentation happens in the last page of every process let's say p by2 goes to the waste okay so in last page of every process internal fragmentation happens see here also internal fragmentation was where it was not in the first page it was in the last page so what it is saying it is saying that internal fragmentation happens in the last page of every process we are assuming that for for the purpose of solving this we are assuming that P by 2 goes to waste okay so the total overhead is of this paging thing the total overhead is px2 that is internal fragmentation and S by P that is the pce table size we want to minimize this and how are we going to minimize this we will differentiate this space table or we will differentiate this total overhead and make it equals to zero and differentiate in respect of what which variable we want to optimize we want to optimize this page table page size so we'll differentiate with respect to page size this s e are constant and 1 by P what is the differentiation of 1x P 1X p s what is the differentiation of P this 1X 2 will remain constant it is 1 so 1 by p s e + 1X 2 and we will equate it to zero and then we will solve for p we got the value of P equal to 2 s e we got the value equals to 2 s e now if we say p by n goes to the waste here here we have written if p by2 goes to the waste that is half of the page goes to waste then the answer will be root2 SC where s is the size of virtual address space and E is the size of each entry of the page table now I say if P by n goes to the vist which means nth part of the page of last or I I should properly say this nth part of the last page of the process nth part of the last page of the process if that an part goes to the waist then the optimal page size should be root NS e where nth part is the vage S is the virtual add space and E is the past table entry size so page size indeed impacts page table size and internal fragmentation so we want such page size in which page table size is also less and internal fragmentation is also less let's start with a nice question it says we have 2^ 32 byte of address space 2^ 13 byte of page size and the page table entry has four byte each page table entry has a size of 4 byte when a process starts the page table is copied to Hardware from memory so from memory it is copied to Hardware let's denote Hardware like this at one word every 100 nond so this is the speed of transfer one word is transferred in 100 nond if each process runs for 100 milliseconds including the time to load the page table what fraction of CPU time is devoted to loading the page okay so first we will first calculate the number of pages so the number of pages will be logical address page divided by Page size this will give me I think 19 so the number of pages will be 19 2^ 19 will be the number of pages each entry has 4 byte each entry has 4 byte so I can say the total page table size will be 2^ 19 into 2^ 2 this is 2^ 21 byte this is what the page table size is so it is nothing but 2 MB 2 MB is the page table size now it says if each process runs for 100 millisecond so this will include the burst time and here it is written including the time to load the p t so the process time will be burst time plus page table load time and that is given as 100 millisecond now the question is what fraction of CPU time is devoted to loading the page well that way we can get that by load time divided by process time load time divided by or I can say total time this will give me what the percentage of CPU devoted for loading or if someone asked me what is the percentage of CPU for just the burst time not for the loading then I will write burst Time divid by process time this process time is the total time and whichever percentage is being asked that will be kept in numerator so load time divide by process time into 100 because we are were asked in percentage or what fraction you can also solve like that if you are asked with fraction that remove this this 100 but if we are writing in percentage then we can multiply with 100 okay so it says load time we have to first calculate the load time how are we going to calculate the load time we know that the page table size is 2 21 by and one word is loaded in 100 nond one word is loaded in 100 nond now what is one word where it is written the of word see here I have told you that the page table is also a part of memory and in in each page table it is divided into entries so this entry is also equal to one word see what was one word the main memory is divided into several units several equal units this is what one word was so this page T is also a part of main memory and it is also divided into some equal units which is called word so this e will be equal to one word so what is the value of e here 4 by so I can say 4 byte is transferred in 100 nond how much this page table that is 2 21 byte will take so it will take 100 ID 2^ 2 into 2^ 19 I mean it will take 2^ 19 into 100 nond so the load time is 2^ 19 into 100 nond the process time is 100 millisecond so which what will the percentage CPU load time what will the percentage CPU load time it will be 2^ 19 into 100 nond divided by 100 where this 100 came from this 100 came from here 100 and millisecond this millisecond is converted into nanc so 1 millisecond contain 10 6 NS we were given that the load time is in Nan seconds see here 2^ 2 is transferred in 100 nond so we have to convert the unit that's why we have written here 10 to 10^ 6 nond so this 100 to 100 will be canceled this 10^ 6 is kept here 2^ 9 is here see this what are we doing here this 2^ 19 is divided into two part 2^ 9 and 2^ 10 what is 2^ 10 it is 1024 but for the sake of Simplicity we are keeping it as 1,000 just for the approximation thing so this 2^ 10 can be written as 10^ 3 so from here three 6 will be converted into three now what are we left with 2^ 9 upon 10^ 3 and if we are finding it in percentage then we will multiply it with 100 also and if not then just keep this what is 2^ 9 512 what is 10^ 3 it is th000 so 512 divid 1,000 it will give 100 0152 this is the fraction of CPU time devoted for loading did you got the solution let me repeat again let me summarize again so what we had we had a question in which what happened we are given with some data and it is is asked that how much fraction of CPU time is devoted to load the page table and the process runs for 100 millisecond this process time also include the page table load time so the percentage of CPU for loading will be load Time divid by total time into 100 so we have to find the load time and process time we were given with process time that's why we kept it as it is 100 millisecond here we have to find the load time how are we going to find the load time we were given that 4 byte is transferred in 100 nond then the whole page table will be transferred in how much time so you have to first find the size of page table how can we find the size of page table we know the formula number of entries into size of each entry we were given that size of each entry was 4 by we have to find number of entries we know that number of entries is equal to number of pages how can you find number of pages we were given with page size that is 2 13 by and we were given with the logical address space that is 2^ 32 so we can write it as 2^ 19 so the number of entries are 2^ 19 and 4 byte will be multiplied and this will give me the page table size that is 2^ 21 by now 4 by is transferred in 100 n 2^ 21 bytes will be transferred in how much Nan so this will be transferred into T 19 into 100 nond so we will put the value of load time here we know the process time here but what is the problem this is given in millisecond this is given in nanc so we have to convert this millisecond into Nan so this will be 10^ 6 nond how we converted that we know that 1 second involve 1,000 millisecond and 1 second involved 10 power 9 nond so 1 millisecond will involve 10^ 6 nond okay so that was put solved but we had made a little approximation here we have written 1024 equals to 1 0 just for the sake of Simplicity this will give me 10^ 3 so from a million this 1,000 will cut a million and will leave 1,000 now we have 52 divid 1,000 so this will give me the 0.512 but if we are finding in percentage then it will be around 50% let's see an interesting question it says consider a system using paging technique with a address space of 65536 bytes you should remember this number this is 2^ 16 okay the page size in this system is 4096 bytes what is this it is 1024 into 4 the program consist of Text data and stack sections as per the specification given below so the text is of this much bite data is of this much bite and stack is of this much bite the page of a program contains portion of only one section that is either text or data or stack does the program fit in the given address space so the first approach some of you might think is we can add all of them and see whether this is equal to 65536 or not if yes uh if it is equal to or less than 3 65536 if yes then the program fit if no then the program doesn't fit well this is the worst approach to follow because we are seeing page wise a page can contain only either text or data or text suppose this is our page and it has only this much text then this page will be wasted let me repeat again to divide this into Pages let's suppose in the last page we had this much text only so this part will be wasted so by just adding these we cannot tell that this program will fit or not because the program is divided page wise and each page can contain only text data or step if it was written that a page can contain text also it can contain some part of data also and stack also which means there is no kind of restriction then I can say if I just add off all of them and compare with the 65536 so how are we going to solve this question well it is easy we will divide it into pages so for text how many page are we going to require let's see what is the what is the text bytes it is 3 2 76 8 divided by 4096 so we are going to require eight pages so eight pages for text and then 16386 divid 4096 we have got 4.4 some pages so how many page we are going to require four page and that's where you have made the mistake this data section will require the five pages don't make the don't make the mistake of approximation why is this so let me tell you so this data section has some like 4. four pages required so four complete pages will be filled three and four and the fifth one will be minutely filled with that 04 and what I have told you that a page of a program contain the portion of either text data or stack so if this page is installed with data then you cannot use this space so if I do the approximation like this this is 2^ 14 bytes and 16 KB so what I did I I set it four this is where you will make the mistake and now for the stack section 15870 divided by 496 this is 3.87 so how much pages will it require three complete pages and 87 filled page so three complete pages and 87 filled page this page will be filled and this page will be wasted so four pages required for this five pages required for this and eight pages required for this 8 and 5 13 13 and 4 17 how many pages does we have in our program divide 655 36 with 4096 these much Pages we had what is 65536 it is the address bace and what is 4096 page size so address space upon page size will give you number of pages so we had 16 pages but this program will will consume 17 pages so I can say the program does the program fit in the given address space no the space of 2^ 16 we have base size we first calculated the number of pages and we we calculated how much Pages required for Text data and stack for text 8 Pages for data for data we will require five pages for this part okay so even if you do like this if you even if you take the log in like 2^ 14 thing then you won't have a complete 14 you have 14.1 and that is going to consume another page so we cannot write it as 4 14 so this will require five pages and in the last page lots of internal fragmentation will be there so total 17 Page required but we have only 16 so we'll say no instead of 4 kiloby if P sizes of 4 byte then what would happen we are going to follow the same approach we will find the number of pages we will find the number of pages in each of the text data in stack and number of pages the address space is divided into if the sum of the number of pages in these is less than or equal to the number of pages in the address space then I'll say it will be a fit so number of pages is 2^ 16 divid 2^ 2 which is 2^ 14 so I have 1 16 384 pages in the address space now we have to find the number of pages in Text data and step how are we going to find just divide it by 4 so just divide it by 4 by so we have 8192 4097 and 3968 pages in text Data stag respectively add them all we got 16257 which is definitely less than 16384 so I'll say instead of 4 kiloby if Pace size would have been 4 byte then the program would easily fit in the previous case why the program was not able to fit because of this much internal fragmentation okay maximum some page size for program profit so what we have done here we have reduced the page size so many times but what we want we had a page size of initially we had a page size of 4 kiloby when we reduced it to 4 byte that is multiple times reduction then the page then the program easily fit onto the address space but what we want we want the minimum reduction in this page size or we want that maximum page size such that program will fit so what we have done we the total is Pages 2^ 16 bytes n which means the number of pages will be 2^ 16 divid by let's say the page size is 2^ X = to 2^ 16 x so number of pages required for text is 2^ 15 x for data is 2^ 14. that four thing x and for stack is 2^ 13.95 x so what we'll do we have tried to compare the number of pages here and some of all these Pages here so that's what it is this is the equation but the problem is we cannot solve this like that solving the X from this equation is difficult thing so what is the solution then try this this is your homework now let's learn what is hashed paging I hope you all remember what is hashing simp similar thing we are going to implement here we are going to associate a smaller page table with a process what is the purpose of hashing the purpose is to organize data in such a way that searching becomes easy each element will be associated with an index so we will design a page page table using hashing table and that will be known as hashed page table don't worry if you're not getting it let's see with an help of an example suppose I have a virtual address of 32 bits page size is of 4 KB so 2^ 32 divid 2^ 12 this give me 2^ 20 these many number of pages will be there so I have 1 million Pages number of pages in page table will be number of pages in the memory and how many pages I have 1 million pages so in page table I would have 1 million entries but let me tell you a shocking fact out of these 1 million entries process generally use around 5 to six pages only but what conventional paging says even if process use only five to six pages but you have to store this whole page table in the memory that's what it is making space inefficient suppose I have a modulo 10 function so what does modulo 10 function do it gives me the last digit of a number take the example I have 1076 I hope you know what is modulo modulo gave me the the remainder when divided by 10 for this 1076 mod 10 the answer should be 6 which is the last digit how did I got it see here divide by 10 1 10 7 comes down 6 comes here 0o and then 7 7 0 6 this is how I got the answer as six so whatever be the number the last digit will be the answer so so how many possibilities of the answer are there for last dig for last digit I can have 0 1 2 till 9 so these 10 entries are possible if I have modular 10 function let me repeat if I have modular 10 function then the result will always be the last digit for that there will be only 10 entries in my has table suppose I have 1076 and 666 what will be the modulo 10 function result it will it will give six it will give six so both want to be at the same index but what happens only one entry can be present in one index well that will lead to Collision that will cause problem i1 and I2 these numbers are different but their last digit is same so what it will lead to it will lead to Collision so what are the Collision resolution technique probing and chaining here to resolve Collision we will use chaining and chaining is implemented using linked list by hearing this by hearing link list you must have a guessed what are we going to do with the CH this Collision problem suppose I have 1076 settled at index 6 now another number comes modul 10 the answer is six want to go at this index but what happens 1076 is already there so what I will do I am going to do like this I'm going to make it as a linked list suppose now another number come let's say 56 so I will make another node of 56 so this is how I am I will solve the Collision problem see here each of the desire of each of the number is satisfied what every number wanted these this all number wanted that their index should be six now their index is six and the Collision problem is also solved so this is how hased page table will work with Collision as with chaining as the Collision resolution technique suppose process generated this P and D logical address D will be copied as it is as you know and P is the element for hash function suppose page number five and 25 are there so what will be the mod 10 result of five it is five what will the mod 25 result of mod 10 uh result of 25 it will be five only so both have five index they both want to come at index five so what I will do I will make like this node for 25 node for five node for 25 and then I will link it using a pointer so what does the node contain the node contains the page number the frame number and pointer to the next node node contain the page number what is the page number page number five the frame number where this page number is stored in the main memory and pointer to the next number the page number the frame number where it is stored in memory and the pointer to the next number so this is how it's going to work now what happens this R will be copied as it is that's what we wanted we wanted the page number let's say this is assumed let's say we wanted the frame number where this page number 25 is stored we wanted R so here we got R and D will be copied from here that's how we get our physical address and we will access the memory but now the question arises let's say I have 100 nodes here and then I had some uh I have some node whose frame number I wanted so how can I reach there you have to first visit the head node then the next node then the next node then the next node obviously the space is optimized but the time it will be time inefficient and you all know the searching time in the link list is o n Big O of n so I have to keep searching until I reach the desired node okay so instead of 1 million entries we have a hash table with 10 entries only so from 1 million entry we reach to only 10 entries and linked linked list Associated to them so we have done space optimization but as you all know space and time optimization Works in a tradeoff if we have if we make it space optimized then it will become time inefficient like we like it happened in the case of static and dynamic linking loading from 1 million entries we reach to 10 entries space is optimized but time in efficiency Has Come O N Big O N will be the search time of Link list so if we want to jump to the 1003 we cannot do it directly we have to start from head and from one node to another we have to jump until our desired entry or desired node is reached so it's a tradeoff between space and time in vum architecture that's how it works it is a tradeoff between space and time between vum architecture so time for searching i1 and I2 is different but same in traditional here let's say let's say I want a page number five so what will be the time we jumped here directly absolutely no time but let's say I want the frame number of 1025 so I have to keep jumping from here to here here to here here to until I reach 1025 so searching time for i1 is different from searching time of I2 even though they have the same index but searching time will be different as they are in the linked list but traditionally but traditionally we have all entries in the same single page table in this page table only we have all entries so searching time of five and searching time of 1025 will be same so what we have tried to solve this spacing issue we have tried increasing the page size we have tried increasing the we have tried using hashing the next important thing which we are going to try will be multilevel paging or recursive paging or hierarchial paging as the name suggest paging on a page table let us start multilevel paging hierarchial paging recursive paging paging on a page table index of an index it has so many names this is an important topic you have to focus more on it let us start with the beginning paging on a page table why we why we required paging the first thing which comes to our mind is to overcome the problem of problem of external fragmentation paging solve external fragmentation by allowing processes to be divided into fixed size Pages this virtual address space is divided into fixed size pages and these pages are stored in the main memory wherever the frame is free so continuous allocation need was eliminated so this can be stored here this can be stored here this can be stored here so these Pages can be stored wherever the frame is empty can be loaded into any available memory frames avoiding the need for continuous memory allocation and making efficient use for scattered free memory blocks so this was the first use we see of simple paging now after studying paging we did some analysis performance analysis here we saw some two issues timing issue and spacing issue in timing issue we tried to solve using cach memory we tried using tlb we tried using PS that somehow helped for spacing issue we tried using we tried by increasing the pace size but increasing the page size causes or invites internal fragmentation then we tried HED paging for HED paging we indeed reduce the space overhead but at what cost we tried using increasing page size and then H paging H paging reduced this space overhead but at the cost of search time this is our third attempt for spacing issue that is multilevel paging we try to reduce the size of page table and how are we going to do that with the help of paging on page table what is paging as a concept what is paging as a concept divide the address space now forget about virtual address space and physical address just listen to this divide the address space into fixed units store these units into main memory and access these units through Page table this was paging let me repeat divide the address space into fixed units store those into main memory and access them with the help of page table this was paging okay but what happened when we saw that for like around 100 process we had around 400 MB of main memory used up just to store the page table so we saw that size of page table is increasing very much we want to solve that spacing issue but the question arise but the question arise when do we say that the page table is small or page table is large when do we say that so this is an important line you have to remember when page table fits in one frame of the memory then we say that the size of page table is acceptable when page table size is equals to frame size or your you know frame size equals to page size so when page table size is equals to page size then I can say that the page table size is acceptable okay so here it is written paging as a concept General involve three steps divide the address space into Pages store the pages into main memory and access those pages with the help of page table this is what it is written now let's see what are we attempting here we have address of 32 bits so virtual address space of 2 32 bytes we have a page size of 4 KB so how many pages will it have it will have around 2 20 1 million Pages it will have and you know in page table the number of entries equals to the number of pages so we'll have 1 million entries you remember the fact which I have told you in the HED paging video that out of these 1 million Pages process use around five to six pages only rest are unused out of these one million Pages process use around five to six pages and rest are unused suppose p 0 P1 some PX py and PN these are the pages which process use and rest this P2 and all other pages are unused take this an example okay now what does paging say paging say divide the address space into pages so we divide the address space into address space into Pages store these pages into main memory so stored p 0 somewhere at frame 3 P1 at where is P1 is stored at frame X PX is stored at frame p and p n is stored you know mean you know what I mean so these frames are stored somewhere in the memory at different frames and to access those pages what we need we want a mapping table that is the page table so this index represent the page and the entry represent the frame in which that p is stored see here p 0 is stored in frame three p 0 is stored in frame three PX is stored in frame two PX is stored in Frame 2 that's what it represent so you know out of these 1 million Pages only five are useful let's say this p 0 P1 PX P1 and PN is useful let's say this represent code this represent data and this represent stack so similarly in the page table these five entries will be useful and rest will be and rest will be the unuseful entries so I call them as chunks the entries which are useful or these useful entries are in one chunk this one chunk this another chunk another chunk so basically what we are doing we are trying to achieve here as this logical address space was divided into Pages this page table should also be divided into Pages because we are attempting to apply paging on a page table how we applied paging on this IAL address Space by dividing into Pages similarly we are trying to attempt paging on this page table and how are we going to do that by dividing this page table into pages but instead of calling pages of the page table we call them chunks of the page table so this page table will be divided into several chunks so let's say the size of a size of one chunk is 1 kilo bir so how many chunks it will be divided 2^ 20/ 2^ 10 to power 10 so there will be around thousand chunks and out of these thousand chunks only three are useful isn't that weird to reduce the size of page table we have to apply the concept of paging on a page table and process is associated with each of the page here when we use only a single page table but what will happen if I use paging on a page table you'll understand it what step one we follow page table is divided into chunks of 1 kilow so number of chunks will be 1 but out of this only three are useful that's what we have done till now the second is store chunks into the memory we are going to store these chunks into the memory so the c0 is stored somewhere here this C1 is stored somewhere here and the C2 is stored somewhere here now what are we doing here just try to grasp that how are we going to access those chunks see we don't want to access each and every entry of this page table that's what it was to increase the page size this was responsible the process the attitude attitude of the process to associate itself with these all entries of page table that was causing the space overhead but what we want we want process to Associated associate with these chunks only we don't want process to associate with each entry of the page table we want process to associate with these chunks only because these are the useful chunks rest is the Wast stage are you getting it so what are we doing we are creating another page table which is going to store these chunks so we'll write like that zero this will now represent the chunk here what it was representing the page but now when we apply paging on a page table what it will represent the chunk so this chunk that is zero c0 is stored there at K C1 is stored there at J okay so now you think is it is it wise of process to associate itself with these chunks and not these entries because initially the space overhead was try to calculate that what was the space overhead what is space overhead the extra space which we are using to apply the concept of paging what is that ex page this page table so what is the size of this page table the size of page table which we calculated was 4 MB let's say the entry was 4 by so the size of page table was 4 MB now what are we doing we are letting the process to associate with the outer page table what is the size of outer page table number of chunks number of chunks how many chunks are there 1K the size of each chunk was to 1 kilow there were this is how we calculated the number of chunks 1 million entri is divided into chunks of size 1 kilow so this is what the number of chunks are the process will be associated with a process will be associated with page table with have 1 Kil entries plus three chunks of inner page Table Three chunks of that page table which has this 1 million entries are you getting the point what have we done we with the help of another page table we allowed the process we allowed the process to access these chunks directly not wasting time here okay so process does not have to include that the the space overhead what will process do process will access the useful thing only see what have we done here we have included the 1 million entries we don't want the process to access associate itself with 1 million entries so what are we doing we are creating another page table in which only these chunks are present so what process has to do now access or associated with this page table and these chunks of inner page table so now initially the space overhead was 4 MD Now what is the space overhead the space overhead will be let's say this size is of 4 bytes so 4 KB plus three chunks of inner P table which means 3 K into 4 so this is be 12 KB so now it is associated with just 16 KB initially it was 4 MB now it is 16 KB only are you seeing how much reduction we have made here so earlier it was associated with 1 million entry page table now we have associated with it only 1 kilow past table let's say each word is of 4 by so one 4 KB past table here let's say word of four by then 4 MB here 4 KB plus we have to also access the three chunks of inner page table so 3 K into 4B that will be 12b so now 16 KB only so from 4 MB we have reached to 16 KB I hope you can see how much space overhead we have reduced now in the next lecture we are going to see how addressing will be done let us understand how multilevel paging actually helps us suppose this is our process in the CPU being executed it generates an address page number and in that page number which word to access this D will tell us so this is our virtual address space and it has it has been divided into various Pages this is p 0 this is P1 p 0 P1 okay now what happens this virtual address space this virtual address space cannot be stored in the one frame of the main memory this virtual address space is greater than the frame size of main memory as we all know that frame size equals to page size and this virtual address space contain lots of pages around we saw that it contained around 1 million pages so virtual address space is around 1 million times greater than the frame size we cannot store the whole virtual address space or the whole process we cannot store the whole process into main memory listen to this words these words we cannot store the whole process into main memory what we do we only store the important pages in The Frames this is our page table and this is the main memory it only contains some of the important pages of this virtual address space so what happens this page table will contain the entry so this p 0 index0 let's say it stored in some frame X so at this Frame at this Frame let's say this is the frame number X at this Frame p 0 will be stored so from here I got the frame number from here I got the frame number and this D will be copied as it is that's how I got our physical address and from physical address I can access the main memory that's how paging actually works but what paging is actually meant for so that if the virtual address space is million time greater than the frame size I cannot store the whole process in just one frame of the memory that's why we included that's why we introduced this paging such that we have to include only the important pages in The Frames we have to include only the important pages in The Frames so this page table will contain the entries of those important Pages only which are present in the main M let's say frame X frame Y and frame Zed this x y z contains the important Pages p 0 P1 and P2 rest all are not important this p 0 P1 and P2 these are important and rest all are not important so what will happen this page table will contain the entries of all the pages this page table will contain the see we had 1 million pages so this page table will contain 1 million entries if if the page is not stored in the frame then what will be present here some invalid information or some invalid frame number or whatever be the present but this this entry won't be empty some some in or some different information be written but this will consume space initially we were dealing with this initially let's say we had 2^ 32 bytes of virtual add space so we had initially this much weight on us but what now happened we have to access this page table and only the useful chunks of these virtual address space in the memory listen in main memory main memory is a critical memory we do not store unuseful or wastage in the main memory we store only the useful parts of the program in the main memory but this virtual address space was very large we cannot store this virtual address space in a one frame that's why we introduced paging with the help of page table I have to the process will be associated with each entry of the page table and let me write this the process will be associated with associated with two things the first whole page table and second is useful entries of useful entries which were actually present in main memory so the useful entries and the whole page table this is what process will be associated with okay now we understand what paging is now the similar problem which we had with virtual address space that we cannot store the whole process into the main memory we have to break it into pages and then we have to store the similar problem arised with this page table now I cannot store this page table into the frame of the main memory this page table size has become greater than the frame size so what we want to do we will apply the same concept here we will apply paging here now in this page table I had 1 million entries and out of these 1 million entries you know only some of the entries were useful and rest all of the entries were wastage and you also know that page table is stored in the main memory you also know that page table is stored in the main memory I don't want to store this Scrappy or wasteful information in the main memory that's why we are help taking the help of another page table so this page table this page table as we did with the virtual address space we divided into the pages so what we going to do we are going to divide this page table into chunks and the index represented the page number here the index represented the page number here what will this index represent this index will represent the chunk number here so I divided the page table into chunks let's say the chunk zero is stored the chunk zero is stored in some frame of the main memory let's say frame a this was a chunk one is stored in some frame of the main memory let's say B so or useful information was stored in these two chunks only and rest was wastage so the whole area this whole uh this whole entries of the uh second level page table this is the this was the first one this is let's say let's call this as the inner page table and we will call it as the outer page table so this whole area of the outer page table doesn't contain any information it will contain the invalid bit as it was in the case of page table when the page which was not useful in the which was the the case the page which was not useful for that case we stored invalid bit or invalid information here same thing we are going to apply here we will store some invalid information or invalid frame number here but this will but this will take the space now what happens we will associate the process now the process now will be associated with whole Outer page table whole Outer page table and the useful information of inner page table initially when we had a single level paging then the process was associated with this page table and the useful information of main memory now what happened when we had an another level of paging now the process will be associated with this full page table and the useful information of this page table and that's how we actually reduced the space overhead now let's move to the PDF let me open the PDF so this is what we have seen now when we have done the outer level uh we have done the two level paging then the process will be associated with outer page table the complete outer page table and the important information of inner page table which was the three chunks of inner page table these three chunks of the inner page table which were useful only that will be Associated initially we had a 4 MB initially we had a 4 MB of page table this was our space over but as we did the As we did the outer level paging or as we did the uh two level paging now what happened the process will be associated with outer page table it contains 4 1K entries each of four bytes so we have 4 KB and three chunks of inner page Table Three chunks of inner page table chunk one chunk two and chunk three and each chunk has a size of 1 Kil word each chunk has a size of 1 kilow Word and one word is of four 4 byte so total 12 KB so from 12 KB here and 4 KB here I got 16 KB so initially I had 4 MB of space overhead but now I have reduced this page to 16 KB what was the frame size remember the frame size the frame size was 4 KB only the frame size was 4 KB only and the page table size was 4 MB can I store a 4 KB 4 MB part in 4 KB that is impossible that's why we have to reduce this we have to we we want a page table which is of 4 KB size from here I got a page table which is a size of 4 KB so 1K entries with 4 by each so 4 KB is the size of page table now now I can store this page table into a single frame of main memory okay you got the point why we did paging because we cannot store the whole process into main memory only important part can be stored the whole process cannot be stored in the one frame of the main memory that's why we introduced a page table because that page table can be fit into one frame of the main memory but what happened unfortunately the page table size was so big that that we were not able to fit that page table also in the one frame of the main memory now what we did we did paging again we got another page table somehow luckily we were able to fit that new page table into one frame of the main memory that's where our mission was accomplished so what is the punch line that you have to remember the page table should be fit into a single frame of the main memory or the page table size should be equal to the page size okay in the next lecture we will see how addressing is done okay I I felt the need that this needs more clarification or this needs more explanation that's why I made another video now let's understand how addressing Works initially when we had only single page table we used to divide The Logical address into two parts one had a page number one part was the page number and other was the offset but but now we have two level paging so what we are going to divide now we are going to divide this page number into two let's say P1 and D1 that's how we are going to perform the addressing we had 32 bits of logical address 4 KB of page size so from page size I got 12 here and from for page number I had 1 million pages so from 1 million I will have 1 million page number and for that 1 mil in page number I would require 20 bits that's how I got 20 and 12 here okay these were the number of pages equal to number of entries in the inner page table so we applied paging on logical address and we got we got it divided into two parts page number and Page size this was a log to number of pages and this was log two page size now we applied paging on a page table so we need to divide this P so this P will be divided on P1 that is number of chunks and this D1 will be the chunk size as it was here this was number of pages and Page size this will be number of chunks and chunk size so this P will be divided into two parts P1 and D1 okay now comes the important part number of entries in inner page table were equal to number of pages in logical address space so number of entries in outer page table will be equal to number of chunks in the inner page table so how many entries in the outer page table will be equal to the number of entries in the outer page table if I do log two of number of entries that is number of chunks then I will get my P1 then I'll get my P1 so number of entries this p is the number of entries in the inner page table this P1 is the number of chunks of inner page table or entries in the outer page table and this D1 was the chunk size and this D was the page size this D1 was related to the chunk size and this D was related to the page size okay so number of chunks uh number of entries in a chunk so this is related to the number of entries in the chunk is Rel to the chunk size okay so let me repeat again what we did initially when we had a single level paging then we divided the logical address page into two parts page number and offset now we had multilevel paging now we have paging on a page table so we'll divide the page number previously we divide The Logical address now we'll divide the page number page number in two parts number of entries in the outer page table and the size of a chunk or chunk size and this will be the page size so this is how we did we divided the page number into two parts P1 and D1 and if we did this third level page table third level paging firstly one level paging divided into two page number and offset second level paging div this page number will be divided into two number of entries in the outer page table and chunk size if done the third level paging then number of entries in the outer to Outer page table which means the third page table and the chunk size of the outer page table we did paging because logical address page was too big to fit in one frame of the main memory but inner page table can easily fit in one frame of the main memory when inner page table became too big to fit in the one frame of the main memory we did paging creating outer page table which can easily fit into one frame of the main memory let me repeat again this will clarify the this will clarify the purpose of paging we did paging because logical address page was too big to fit in one frame of the main memory but inner page table can easily fit in one frame of the main memory but what happened when inner page table become too big 2 F in one frame of the memory we did paging on inner page table creating outer page table which can easily fit in one of the main memory this is the Crux of two level paging this is how it looks like now CPU generates this kind of address P1 D1 and D suppose P1 is 10 D1 is 10 total 20 and this D okay now what happened this P1 this P1 will give me this P1 will give me the chunk address this P1 will give me the chunk address from here I will get the chunk address I will reach to that chunk this D1 will tell me to which page to look for in that chunk focus on this line a page contain number of words and a chunk contain number of pages so this D tells me in in that page in this D tells me which word to look for in a page and this D1 tells me which page to look for in a chunk and this P1 tells me where to find that chunk okay so from P1 I got the address of the chunk I reached to that Chunk on that chunk with the help of D I found that page and from that page I found the frame number I copied the frame number here I copied the D here that's how I got the physical address space okay so this B is the address of one chunk of the inner page table let me repeat again it generated address this address consist of three parts P1 D1 and D firstly we need to see we want the frame number what we actually want the frame number in that frame our instruction is present so how are we going to find that instruction in the frame with the help of this D but firstly we have to reach to that frame how are we going to reach to that frame firstly we will look for that chunk which contain our frame after we have found the address of that Chunk we will look for that page which contain our frame we found the frame sent here and with the help of this D we will find that in which word of that frame our instruction or data is present I hope now the thing is clear P1 is the address of chunk of inner page table D1 is the address of frame of main memory and D is the address of data or instruction in the frame okay that's how multilevel paging works I have put lots of effort lots of retakes I hope you like it let's see these views of multilevel paging we had outer page table inner page table and memory in the last lecture we learned how logical addresses were generated okay so the outer level page table contains the frame where the chunks are stored the inner level page table contains the frame where the pages are restored okay and memory itself contains the frames now how logical address will be worked how how are we going to work with logical address this P1 will help us to reach the required chunk this D2 will help us to reach the required page in that chunk and this D will do this D will help us to reach the required word which contain our instructional data so from P1 we access the outer page table this is the frame where the chunk is stored we got to that frame now we had D2 now we have to reach to that page in the frame so we'll reach to that page here we got our page this is the actual frame this is the actual frame where instruction of data is St but it contains lot of word so in which world I have to look for this D will tell so I have to look at this one okay P will help us to read the chunk re reach to the chunk D will help us to reach to that page and this another D will help us to reach to the required word in the frame see this CPU generates this kind of logical address this page table base register will give me the address of outer page table as you know that outer page table is also stored in the memory all kind of page tables are stored in the memory so where I have to look for that page table this ptbr will give you page table based register it gives the index of outer page table so from here I got the index of outer page table from this 10 bit I got the address of that chunk where my required page is there so I reached to that page now this 10 bit will help me to search for that page in the chunk so I reach to that page in the chunk here I got the frame number where that page is stored so I I will copy the frame number here in the physical address and this will be copied here so now I got the complete physical address so from here I will go to directly to that word where my instruction of dat I okay see this multilevel page table what does it depicts it depicts that process is not using all the pages and we have to store only useful entries okay so now we have completely understood how multi level paging works so paging generally involves three step dividing the address page into Pages storing the pages into frames accessing the pages through Page table this is the paging as a concept what was the motive behind the paging we want to optimize space sacrificing time as you know that in volum architecture space and time works in a tradeoff if we are optimizing space we will be sacrificing time and if we are optimizing time we will be sacrificing space now time for the effective memory access time in one level paging we had 1 M for accessing the page table and 1 M for accessing the memory in two level paging we had 1 M for accessing the outer page table 1 M for accessing the inner page table and 1 m in accessing the memory as you know this outer page table inner page table both are stored in memory so M will be the time for both okay so in one level we need 2 m in two level we need 3 m so in N level we are going to need n+ 1 M so this is the effective memory ex Sy time now the question arises can we reduce them can we reduce this effective memory access time let's try with the help of tlb and Pac in two level so here is the CPU it generates this address so firstly we will look in the tlb with the help of this P that this page number is contained in which frame number if I get this this is a tlb hit I directly get the frame number this D will be copied here I will reach now I have physical address so from this physical address I'll first look at the PSC so corresponding to a physical address can I get my instruction of data if yes then this is a PSC hit you will get your instruction and data if no then you have to search in the physical address space now what about tlb Miss what happens we when we have to actually search in the page tables so firstly with the help of this P1 we will look in the outer page table we got the address of that chunk now x with the help of this D1 we will reach to that frame now this Frame will be copied here and this D will be copied here here I got the physical address now again the same thing either I will get PC hit so corresponding to that P physical address is that present in the PSC if yes then it is a PS I will get the instruction of data directly otherwise I have to search in the physical address space okay so this was a twole paging with tlb and Pac now let's see the effective memory access time were we able to reduce them let's say the main memory access time is M tlb access time is C1 tlb hit ratio is X1 PC access time is C2 P hit ratio is X2 now we have to find the effective memor system so we'll again take two cases the first case was we had a tlb hit the second case was we had a tlb miss so here I got our physical address X1 C1 1 X1 C1 + 2 m here I got our physical address after that this phase two part will come this will be same in both the cases initially I looked in the PC I got a hit X2 C2 will be the time taken but if I had a Miss then 1 X2 C2 + m why C2 plus M because first I looked in the PC then M same case here first I look then tlb and then in the page tables here X2 I got a hit I as I looked in the PC but here it was a miss so first I looked in the PC then in the main memory so that's how we calculated the effective memory effective memory access time in the next lecture we will some of we will see some numericals physical address space 256 M be given logical address space 4GB frame size 4 KB page table entry 2X we have to apply the concept of paging here we were given that logical address space is 4GB and we can see that the frame size is much smaller than the logical address space we cannot fit the whole process into a single frame that's why we have to apply paging here so we applied paging we divided this logical address page into several pages and stored each page in a frame that's what we thought of so we divide The Logical address logical address space into different pages each of size 4 KB so how many pages were there 1 million pages so we have to access those pages with the help of page table 1 million pages so we have how many entries in the page table 1 million entries what is the size of each entry two bytes so 1 million into 2 by will be 2 MB but another problem arised here what that 2 MB is again greater than frame size we have to do paging again so we applied level two paging we used another page table for the inner page table so divide we divided the inner page table into chunks we divided the inner page table into chunks and we want to store that chunk into 4 KB that is the frame size so what we did we took the chunk size as 4 KB see it is not necessary that you took the chunk size equal to frame size or page size it is not necessary chunk size can be different to frame size but here what we want we want to apply the concept of paging we want to store that chunk into one frame of the memory so we said that chunk size Let It Be 4 KB so this 2 MB this was the 2 MB page table divided into units we call them at chunks each of size 4 KB so how many entries will be there 2 mb/ 4 KB we will have 512 entries which is 2^ 9 entries so so we had 2^ 9 entries now we have to find the size of Entry of outer level page table see this e will remain independent of the level of paging what does this e represent it is the frame this the entry of the page table represent the frame in which either the page is stored or chunk is stored depending on which T page table we are talking about this e will represent the frame in which page is stored when we are talking about inner page table this e will represent the frame in which chunk is stored when we are talking about outer page table so this e will represent what basically it will represent the frame so how many or what will be the size of e will depends upon the number of frames in the main memory and the number of frames in the main memory is independent of the level of paging that we are applying so this e will remain same we will have 2K 2B only here so number of entries is 512 each entry is a size of 2 by so we will have 1 KB now you can see we can store that outer level page table into one frame of the main memory the one frame size is 4 KB and the outer level page size is 1 KB yes we can store we can store that outer level page into a single frame no need to apply more paging here okay now we learn how addressing will be done so we have let me erase all this extra part we have data or instruction in some word in the physical address space how are we going to access the address of that word firstly we will firstly we will go to the outer level page table to access the chunk see word lots of word are there in a page lots of pages are there in a chunk so we will first find the frame in which our chunk is stored we will find the frame in which our chunk is stored so how can I find the frame with the help of outer level page table how many entries we have in the outer level page table we have 512 entri so nine bits will be required to reach to that chunk after that we have to reach to the required page how many entries are there in the inner level page table we have 1 million entries but but these entries are divided into chunks so we have with with the help of this n bit we have reached to that chunk which contain our page okay now in that Chunk we have to find the page see this was our chunk it has several Pages this page we want to access so we have to first find how many entries are there in a chunk in a single chunk how many entries are there how are we going to uh solve that how many entries are there in a chunk see what is a chunk size the chunk size is 4 KB and what is the entry size the entry size is 2 by how many entries can be fit in this Chunk in this chunk two which which means 2^ 11 bytes so how many entries can be there oh not bytes by is canceled so twoed to 11 entries how many bits are required to reach that page 11 bits will be required to reach to that page now we have reached to that page which contain our word this is our page and it contains several words suppose I want this word to access how I'm how I'm going to access that word with the help of with the help of page offset so log to page size what is Page size 4 GB so I require 12 bit to access the word okay so this is how we did the addressing in this question see here we had an outer level page table the outer level page table index will represent the chunk number the entry will represent the frame in which that chunk is stored with the help of that we reach to that chunk now we want to find that page in the junk how are we going to find with the help of D1 what does D1 represent log two number of entries in the chunk how can we find number of entries what is chunk size chunk size is 4 KB what is the size of each entry it is two white so I can find the number of entries with the help of this so I got 2 power 11 entries in the chunk so to reach that page I will need 11 bit so 9 bit and 11 bit now I have reach to that frame or that page with the help of this 9 and 11 bit I have reached to that frame which contain my page these 12 bits that is the page offset will help me to reach to that word which contain my data instraction so this is how addressing is done 20 this was the 20 how I got 20 I had 1 million entries in the virtual address Space 1 million pages in the virtual address space that's why I got 1 million entries in the page table that's how I got this 20 here now this we have applied paging on that page table so you have to find number of chunks in the page table we got 512 chunks so number of chunks in the page table equal to number of entries in the outer page table we got 52 so 9 bits will be required now after we re reach to that junk we have to find the page which contain our word so to reach that word to reach that page we have to find the number of entries in the one chunk so we had 2^ 11 entries in one chunk so we will require 11 bits for that now we have reached to that frame we from here we got our frame number which has my page which has my page that contain that word which has my instruction so till here I have reached so from here I got the frame number and this D will be copied here so I got the physical address of that word which contain my instructional data okay let's see some more questions it says in the context of operating system which of the following statement are correct with respect to paging paging page size has no impact of internal fragmentation well this is completely false we have seen that when we increase the page size it invites internal fragmentation paging helps solve the issue of external fragmentation absolutely correct paging incurs memory overhead yes paging incurs memory overhead what is memory overhead this is the same as space overhead then what is space overhead space overhead is the extra space which we consumed to convert logical address into physical address what extra space is we did we consume we consume page tables so paging incurs memory over it yes multilevel paging is necessary to support pages of different size well we did not talk about this we only talked that multilevel paging why we use multi level paging to optimize overheads H Eads to optimize overheads so this will be the correct this will be the correct these two are false another question consider a system using two level paging architecture the top level the top level nine bits of the virtual address are used to index to the outer page table the next seven bits of the address are used to index into the next trevel page table the size of virtual address is 28 bits okay well this is an easy question how large are pages and how many there are in the virtual address space so easy see here we were given with two level paging architectures the top level nine bits of the virtual address are used to index the outer page table which means 9 bit is P1 the next bits of the seven used to index the next l so D1 is 7 the size of virtual address is 28 bit so P1 + d1+ D = to 28 how large are the pages and how many are there well firstly we have to find the page size how can I find the page size with the help of this D so D will be equals to this is 9 this is 9 this is 7 so 9 + 7 16 D = to 28 16 which is 12 so my page size is 2 12 which is 2^ 2 into 2^ 10 which is 4 KB this is my page size and how many pages are there I can find with the help of this P1 + D1 equals to P if you remember and what is this p 2 power P will give me the number of pages so I have how many pages I have 2^ 16 Pages 2^ 16 pages and Page size is this second question if page table entry both level is 32 bits in size which mean we have we have four byte of page table entry then what is the space overhead needed to translate what is space overhead the size of page tables only so to convert The Logical address to physical address how much space is needed size of outer pH table size of inner pH table what is the entry of outer pH Table 2^ 9 here I got and inner P table 2^ 7 and size of each entry is 4X 4 by add them this will be your space over it now the question is is p size equal to chunk size well that is not necessary chunk size can be different but pce size should be equal to frame size that is necessary let me write pce size should be equal to frame size not necessarily equal to chunk size is Page table entry same for outer page table and inner page table page table entry will be same for any level of paging because page table entry does not depend upon the level of paging it depends upon the frames in the main memory so yes it will be same consider a computer system using three level paging architecture now we have three levels outer page table middle page table let let us call with this and inner page table with uniform size at all levels of paging so here it is given that chunk size equals to page size equals to frame size here it is given okay so we call we call the units of virtual address space at Pages we calls the units of inner page page table at as chunks let us call the units of middle page table again at like Pages only I can't think of some another name another cool name so let us keep it simple and call it as page only page of middle page table okay the size of virtual address is 46 bit so we have a virtual address space of 2^ 46 bytes page table entries at all level is 4 by so we have equals to 4 by what must be the page size in bytes such that the outer page table exactly fits in one frame of the memory so what we have to do we have to find the page table size of outer page table and should be equal to frame size or page size assume that pay size is in power of two in bytes okay so let's say the pay size is 2 power 2 power D show the virtual address format indicating the number of bits required to access the three levels okay so we will solve it we had three level paging architecture so the virtual address is 46 bits virtual address will now be divided into how many parts 1 2 3 4 four parts now it will be divided when we had a single level paging then it was divided into two parts two level paging divided into three parts three level paging it will be divided into four parts this P2 this P2 will depict the number of entries in outer page table this D2 will depicts the number of entries in one page of middle level page table this and this D1 will depict number of entries in one chunk and this D will depict the number of words in a page did you get the point see now the process will be associated with outer page table and chunk of or the page of middle level page table and chunk of outer level page table useful pages of mid middle level page table and useful chunks of inner level page table so what we have to show we have to find the page size such that the number of entries in outer level page table into e should be equal to page size this is what we have to prove and given that page size equal to chunk size equal to page of outer page table so I can write D equal to D1 = to D2 okay it is given here okay uniform pay SI at all level of P page size in bites outer page table size should be equal to frame size so number of entries in the outer page table is I should write 2 power P2 and 4B here which is the size of each entry and it should be equal to page size that is 2 power D now let's see how are we going to solve this so this this was the page table one each entry is of 4 by and number of entries in the in inner level page table will be 2^ 46 that is virtual address space upon page size let us call that page size is X so 2 power x is the page size and this is the virtual address space this will give me the number of pages and the number of entries so how many entries we have take this up for 2^ 46 x so I have these many entries in the inner level base table now we have divided into chunks we have divided this space table into chunks and what is the chunk size again 2^ X so how many entries we will have in the page table two the size of total page table divided by the chunk size how many entries we had 2^ 46 divided by 2^ 46 divided by that is the number of entries divided by the page size okay so and this will give me this will give me the number of entries in the page table two and this will be the 4 by that is the page size now we got the page table size of page table two now we will divide this page table again into pages so we will write this here and it will be divided again with 2^ X this will give me the number of entries in the outer page table and this will give me the with multiplying with four by will give me the size of outer page table now we have found that size of outer page table should be equal to the page size so from here I can solve that xal to 13 so my page size will be 2^ 13 which is 8 KB don't worry if you didn't get it I'm going to tell it again I'm going to explain it again what we did we have to find the number of entries in the inner page table how can we find we had logical address space of 2^ 46 and the pay size is 2^ X so I have found the number of entries is 2^ 46 x I have divided these entries into chunks so I have divided these ENT is into chunks of size 2^ X so this is the number of entry in this page table two and this is the 4 by that is number of entry into size of each entry this is this total is the size of page table two now we have to find the size of page table 3 we we will divide it with 2^ X so this was the size of page table 2 divided with 2 power x now this will give me the number of entries in the outer page table and number of entries in the outer page table when multiplied with the size of each entry in the outer page table will give me the size of outer page table from here I got the size of outer page table this is the size of outer face table and in the question it is given that I have to equate with at one frame of the memory I have to equate that with the one frame of the memory and you know that one frame of the memory equal to frame size equal to page size so I equated with the page size and I got x = 13 so my pay size is 2^ 13 that is 88 KV so let us generalize to solve thing quickly we have a virtual address space of 2^ s bytes virtual address s bytes let's see e is of 2^ C bytes okay this is the what is this size of each ENT page size is 2^ X levels of paging is L we are going to generalize the thing so if it is asked the size of outer page table how are we going to solve we have to first we have to first find the number of entries in the inner level page table so n equals to Virtual address space upon page size so we got the number of entries in the inner page table into size of each entry so we got the size of table 1 is 2^ s + C x now what we have to do we have to find the number of entries in the outer page table so what are we going to do we are going to divide that again with 2 power x so what we have got number of entries in the outer page table into the size of each entry here we got so at L level the size of page table will be S + lcus LX if you are wondering how I got to this see here at level two what I got I got two here so at level L I will have L here so the size of outer page table at level L will be this okay let's solve another question we have virtual address of 46 bits so virtual address space will be of 2 46 bytes we have page table entry of 4 by we have page size of 2 power x we have three level of paging and outer level page table should be equal to page size are we attempting the same question with this formula are we trying to attempt the same question with this formula I think so yes it is also 46 and we have we have 32 bit in 4X but I think we are going to attempt the same question with this formula so what does method one says method one says this will give me the size of first level page table this will give me the number of entries in the second level page table this will give me the number of entries in the third level page table so P size has remained constant which means D = to x what is D well this is so P1 + P2 + P3 let's equals to Y because as P size is constant so number of entries will also be same so I will write 3 y for that y y y and x for this so 3 y + x = 46 so the outer page table should be equal to the page size so I will write 2^ Y into 4 by that should be equal to the PA size so I will write 2^ X = to 2^ Y into 2^ 2 so from here I will get 2^ x = 2^ y + 2 from here I got X = y + 2 so I will put that here in this equation so 3 y + what is x y + 2 3 y + y + 2 = 46 from here I got y = 11 and x = 13 that's what we have got here by solving through this we get the same answer that's an easy part or we have solved it with the help of equations here we have solved it with the help of logic how we moved from one p to another and then in the end we equated that with the page size okay consider a computer system with 57 bit virtual addressing so we have the virtual address of 57 bit using multilevel Tre structured page table with L levels for virtual to physical address translation so we have L levels of paging the page size is 4 KB and Page table entries of 8 by so we have e equal to 8 by and pay size is of 4 KB which means 12 bits for D the value of L is so we have to find the value of L so we can find by this part the size of outermost Bas table what was that S Plus lc LX should be equal to frame size and do we know the value of c and x yes we know the value of c c is 3 and X is 12 this can be written as 2^ 3 so from here I got c as 3 and X is 12 so by solving this I got L = to 5 so it we need five level of paging see remembering formulas is indeed going to help you to save time in the exam method 2 we had 45 and 12 see total was 57 from this page size we got 12 so 45 we got from here now page size we are given with 4 KB page table entries of 8 by number of entries that can be stored in one page will be number of entries that can be stored in one page will be total the page size divide by the size of each entry that is 2^ 9 and from here I can tell every page table will have 2^ 9 entries so nine bits to access so this will be uh 9 bit to xes each so how many levels will be there five to get it 45 see here this was really nice concept we were able to solve using this we were able to solve the problem with the help of this logic that we started with the page table we started with the page table size and then we moved it divided it into chunks multiplied it with the each entry and then find the size of another page table again divided it with the page size find the total number of entries again multiplied with the size of each entry got the size again and then equated with the page size got the answer that was the thing which we have do but now what we have done the first method which we used was we created a formula that the size of outer level page table is equal to S Plus LC minus LX where C is the C is the this word and this is the size of each entry so if we have eight by then C will become three and what is X x is the page size so the size of outer level page entry should be equal to the page size so we have to solve this s + L C X should be equal to X just solve this and you'll get the answer okay the another thing which we are doing is it is said that the page size is constant if page size is constant which means these entries will be same if these entries will be same I can name it as y y y and let us name it as X so 3 y + x should be equal to 46 that I know and another thing which I know is outer page table should be equal to page size so outer page table is outer page table is this 2 to^ y this is the size this is the outer page table so 2^ Y into what is the size of each entry we are given with 4 byes so 2^ 2 this should be equal to the base size we write is 2^ X so 2^ X should be equal to 2^ y + 2 here we got x = y + 2 we used it here and we find that y = to 11 which means each page table will have 2^ 11 entries in it so X = to 13 I got from here if Y is 11 then 11 into 3 is 33 x 46 from here I got x = 13 what is X now 2^ X will give me the page size that is 2^ 13 8 K will be the my base size that's how I solved so I solved this question using two methods again the first was the formula the second was that we know that page size is constant so how many how many levels of paging will require to consume this 45 bit of Address given that given that number of entries that can be stored in one page is 2^ 9 so each page table has power 9 entries so 9 + 9 + 9 plus how many times to get or to cover this 45 each page table has how many entries to rest power 9 so I will require nine bit for one page table how many entries I have to put so that I can cover 45 I have to put five entries so how many levels of page paging I will have five levels of paging so I hope with the help of this you may have understood how multi Lev ping works we have learned about paging in our previous lectures but there is a problem with paging that need to be discussed that is paging does not preserve the users view of memory location now what does this users view means the users view means see like this suppose I have a main program I have a main function of of 5 KB in a program I have a main function of 5 KB and the page size is of 1 KB now this main function will be distributed in five pages and these five pages can be stored anywhere in the memory wherever the frame is free so a single function is distributed all over the memory don't you find it weird a single main function a single main function is distributed in all over the frames in the memory because noncontiguous allocation is allowed in so a single function is distributed all over the memory that's why this users view of memory location is not preserved now what is users view see this main function in one segment we create a segment square root function in one segment so in users View program is divided into units called segment and by the time you have guessed that segment need not to be equal suppose main function is bigger than the square root function so this segment will be bigger than the segment one so this program is divided into units called segments this may include functions blocks procedure call data structure these segments are assumed to be stored at their entirely noncontiguous locations in the memory well we did the same with paging isn't it the pages were stored at noncontiguous locations then what is the difference between paging and segmentation in segmentation also we store the segments at different location we can wherever the wherever there is free space you can store a segment there see here we store segment zero here segment 3 segment 2 4 segment and segment one down there we can store wherever the the free spaces non continuous allocation is allowed then what is the difference between paging and segmentation in segmentation no matter how big this main function is you have to store this at one place but what happened in paging this main function was distributed all over the memory but here this main function no matter how big it is it will be stored at a single location now the question arise if this main function is bigger than the frame of the memory then what will happen the answer is there is no concept of frames in this segmentation physical memory was divided into frames in which case when we studied about paging and paging was related to fixed allocation here we have a kind of variable allocation for segment one for segment one we will allow some memory here free space is there for Segment zero we we allow fragment zero here for segment one there for Segment two there three four there so there is no concept of frames in the physical memory in segmentation we talk about variable partitioning here variable partitioning I hope you remember what is variable partitioning we create partitions based on the segment size okay so concept is similar to paging but Pages were of same size and segment is of different size the whole segment is in one place on the memory but segments are at noncontiguous location this view was not preserved by paging so the same example here we have taken main function of 5 KB page size of 1 KB then main function itself will be distributed noncontinuously but in segmentation no matter how big the segment this we will store entirely at one location and there is no concept of frames in segmentation wherever free hole is present store the segment it's like variable partitioning so there we had page tables here we'll have segment tables so the number of entries in segment table will be equal to number of segment now the question arises how are we going to do the addressing so this the entries in the page table was like that the index used to represent the page number and entry is used to represent that frame where the page where that page is stored here The Logical address will be generated like this segment number and offset segment number and offset and the entry will be of two Fields limit and base this limit will tell the size and the base will tell the starting address okay so this segment number will tell me in which segment I have to look and this offset will tell me how out of these let's say there are the sizes of thousand so out of these thousand word which word do you want to read and from this I can tell that offset must be less than 1,000 suppose The Base address is 1400 and the size is of 1,000 so from 1400 to, 1400 to 2400 no because Zer is included here so 2 3 99 so till this I can can access the words but what happened suppose my suppose the address generated was of 2699 can it be possible no because we have the address should be in the range of, 1400 to 2399 and the offset out of these thousand word in which word you have to look I cannot write or I cannot uh write offset as500 or some like 1100 because because we have only thousand work words to look for out of these thousand words we have to choose one so offset will tell out of these thousand word which word do you want to read okay and the address should be in this range okay so how are we going to check if address in this range and what will happen if address is not in this range it will go into the Trap suppose if process is mischievous and he and she tries to access the word beyond the segment then it will go into the Trap or addressing error will be generated so from this segment number I will reach to that segment okay now here we will check that if offset is less than the limit or not the limit was of th000 words the offet should be less than or equal to th000 and if it is not then we will send it to the addressing error or trap if yes if the offset is in allowed range then add the offset into the base or I add the offset into the base and then you will get the physical address let me show with the help of diagram suppose this was the segment and in that segment we want to access this word this was our base let's say the Base address is 1,000 and the address of this word is 500 so the address of this word let let it be500 so the offset will be offset will be 500 which means out of these, words let's say this the address of the last word is one9 so out of these th words I want to I want that word which has the address of 1500 so whenever when I will add the offset into the base I will get to this so offset will tell me out of these word which word you want to access and if you add if you add the offset into the base you will reach to that word so that's how addressing is done here so to convert logical to physical what we have to do we have to first check if offset is less than the limit or not if yes then add the base into the offset and you'll get the physical address of that word okay so what this segment number is used segment number is used to check the segment table for base and the trap okay and what is the use of this limit this limit is used to check if the offset is not generated Beyond the limits suppose this was the allowed segment to be accessed but what happened I generated the offset of let's say, 1600 so now when I will add the offset into the base it will go down to the next segment no from here I will not yeah suppose 1600 so I will go down to the next segment because the offset is greater than the limit let me draw another block here so the base was of th000 this the total words in the segment are let's say 1,000 the last address is of 1 tri9 okay now suppose the offset is generated of this word till this offset is generated so I will be able to access this word it is allowed but if I generate the offset greater than the limit then I will enter into the segment of then I will enter into the another segment which is not allowed so what we have to do if the process wants to access the segment which it is not allowed to access then we have to send it to the Trap so that's what segment table is used segment table is used first to check the limit whether this offset is not trying to exceed the limit and the second thing is we have to get the Base address so that we can add the offset to it and get the physical address so that's how addressing in segmentation is done let's see this let's see this example this will make you more clear consider the following segment table we have segment we have base and we have length length is limit it is just a different name length is the limit so what are the physical address of the following logical address segment Z and this is the offset so the offset is 4302 but it has a limit of 600 so what will happen now the Base address is zero the length is 600 so the last address will be 599 but which address does it want to access it wants to it wants to go till 4302 this segment has been over here only but it wants to access the data of some other segment which is not allowed so it will cause trap trap will be cost the second question segment number two segment number two where is the segment number two here is the segment number two the offset is 50 so this was the segment number two the Base address was 90 and the offset is 50 but what is the what is the length of the last word or what is the address of the last word here in the segment it is 1 8 9 so 50 here is allowed I can access this word so 90 + 50 will be the word or will be the physical address of that word which want to access from the main memory 1 and 15 1 C the offset is larger than the limit so this will also generate a trap third part base is 23 27 and the length is 580 but the offset is yes less than so what we will do we will add the offset into the base 2 3 2 7 + 400 so I'll get 7 2 7 this will be the physical address of that word which we want to access fourth the base is 1 1952 now if the offset is less than this length then it is allowed but here the offset is 112 112 it will not be added because the offset is greater so it will go into the Trap so this is how segmentation is done let me repeat whole thing again in paging the users's view of memory was not preserved the users view of memory location was not preserved but here in segmentation we semantically divide it main function in one segment square root in one segment sub rooting in one segment stag in one segment symbol table in one segment and how does symbol table look like it has this will represent the segment number this will represent the limit and this will represent the base what does this limit say it is the size of the segment and what does this base say it say it says the starting address of the segment starting address of the segment now the process generates the now the process generates The Logical address this is The Logical address it contains segment number and offset how are we going to convert this logical address into physical address from this segment number we will move to that index in the page in the segment table okay now we will check is the offset less than the limit if yes then we will add this base to the offset and the resultant will be the and the resultant which we get will be the physical address of that word okay so this is how segmentation is done we have seen all of these things and how trap is generated by trap is generated we we have also seen this thing because if the Trap wouldn't have been there then the process May access the word of the segment which it is not supposed to in the next lecture we will see its performance now let's see the performance of segmentation based on the two factors time and space how much time it will take M for the segment table and M for the main memory where m is the main memory access time segment table like the page table also resides in the main memory so firstly we have to access the segment table to get the address and then main memory to get the instruction of data the addition and the comparison will take the negligible time okay can we reduce this time can we reduce this to m we can with the help of tlb and PSC if we are using tlb only then tlb it look at the tlb we got the address access it tlb Miss look at the tlb we didn't get the address go at the segment table first and then at the memory so C plus 2m for that if we have used tlb plus PSC then tlb hit got the address first PS hit got the instruction of data PSM Miss first looked at the PSC and then to the memory tlb Miss first look at the tlb then segment table here I got the physical address looked at the PC got the instruction of data psms looked at the PSC first then in the memory and after that I got the instruction of data so this is how the effective memory access time is calculated if we have used tlb or PC it is exactly the same like we did in the paging okay now if we talk about space then if segment table becomes too large then apply paging on segment table how can we apply paging select some page size divide the segment table into Pages store the pages in frames access them through Page table see we are not applying paging on segments segments will be stored in one location only and the different segments can be stored noncontinuously that effect is undenied but what are we doing we are applying paging on this uh internet sex here this this table I'm talking if this table has become large than then we will apply paging on this table we will divide it into pages and we will store the pages into frames and then we will access those pages with the help of page table okay so this is what we called segmented paging we will look into segmented paging in detail in our miscellaneous topics okay paging versus segmentation now it comes which is better with respect to fragmentation in paging we have internal fragmentation at the last page in in segmentation we have external fragmentation at Main memory how paging we have SE internal fragmentation at last page suppose suppose the program is divided into pages and how much page it's going to require let's say going to require 4.1 pages so it will take four complete pages and the fifth page only 01 space will be used and rest will be unused so this is how internal fragmentation is present in the last page in case of paging and how external external fragmentation is there in case of segmentation suppose between two segments so so less free space is there that we cannot fit a different segment or a smaller segment M there this space is tool less so this is what external fragmentation is between two segments the free hole is not big enough to accommodate any new segment so in paging we have internal fragmentation at the last page and in segmentation we have external fragmentation at the main memory so in paging internal fragmentation no external fragmentation in segment we have no internal fragmentation because we follow variable partition and we have external fragmentation in main memory just like we organized we did in the variable partition okay and how are we going to solve this external fragmentation issue in segmentation the first method is compaction or defragmentation suppose we have segment stored like this S1 freeh hole S2 a bigger segment of size let's say this much wants to get accommodated here but we know that a segment either it will be completely stored or will not be stored so what we will do we will shift this segment here we'll create a bigger free hole now this segment can be stored here so this is what competion is as we did in the variable partitioning it is also known as def fragmentation but the problem with competion is it is less it is not diagram it is desirable it is less desirable why because firstly it is time consuming we have to swep out swep in all that things and the second is runtime address binding should should be supported we are changing the addresses of segments so runtime address binding is supported so that makes it less desirable the second option we have is of segmented paging segmented paging it reduces the size of segment table and also the external fragmentation we will study that segment paging part in detail in the last section so these are the topics we will study in the last section of miscellaneous topics okay in the next lecture we will see what is virtual memory virtual memory it gives an illusion to the programmer that huge amount of memory is available for executing that program which is larger than physical memory it gives an illusion to the programmer that there is enough memory available for executing a kind of program which is larger than physical memory larger than Ram how it works how it is implemented let's see suppose we have a virtual address space of 8 KB and Main memory of 4 KB page size of 1 KB so this virtual address space will be divided into pages of will be divided into pages of size 1 k each from p 0 to p7 we know that it is not possible to store all the pages into this main memory because main memory size is smaller than the virtual address space see this virtual address space is nothing but the program and this is the processing so it is not even feasible for bringing the whole program into the memory even if the space is available then also it is not feasible to bring the whole program into memory because as I've told you there may be several Pages there may be let's say 1 million pages but only few of them are useful that's why out of these eight pages let's say four of them are useful so p 0 P1 P1 is not present so p 0 P2 p7 and P5 were useful so I brought them here and or I can put it other way that the size was 4kb only so I have to select four important pages from these eight pages and put it there okay but what will happen in the case if I want to refer that page which is not actually present in the main memory let's say I want to refer P6 then how this will work so this virtual memory thing is implemented with the help of demand paging as the name suggest loading the pages on demand from disk to memory there is there are lots of pages in a program but few of them are loaded into the main memory creating the process this is a program in the disk this is a process in the memory so each and every page which I can or I want to refer is present in the disk only few of them are present in the memory now what will happen I have want to refer that page which is not present in the memory this is what demand paging is loading the pages on demand from disk to memory see this virtual memory is mapped on the disk what is virtual memory virtual memory is nothing but the program program is present on the disk this is the virtual address space this is the this is the virtual address this is the virtual address space mapped on the disk I mean all the program from p 0 to p7 or whatever naming you write P1 to p8 are present on the disk all the all the pages of that program are present on the dis but few of them are present on the memory so how this it will going to work let's see here suppose this is a process Pi running on CPU it generates an address P and D the page size was 1 kiloby so the D will be of 10 bits and number of pages were eight so P will be of three bits it's good now let's say I want to I want to refer to the page number two I want to refer to this page this entry will tell me in which frame my page number two is stored so this is 1 one is three in in binary we write three as 1 one so 1 one is three so in frame number three my page number two is there but what will happen if I want to refer to page number six what will happen if I want to refer to page number four or p page number one now I want to tell you some more thing which I have not told you before in this entry not only the not only the frame number are stored various other things are also stored one of them is this bit this bit will tell me if the page which I'm looking for is present in the memory or not suppose page zero is present in frame one so I will write one here one will represent that it is a page hit what is Page hit the page which I'm looking for is present in the memory this zero will tell me the page which I'm looking for is not present in the memory this is a page Miss so one will represent the Page hit and zero will represent the page miss or I can say the one will represent that the frame number which is written here is valid or 0o will represent that the entry here is invalid okay so from here I got the frame number and from here I got the offset I got physical address I will access the memory similar let's take another case suppose I wenter page number seven is St in frame Zero from here I got from here I got the frame number from offset I will get the word which I want to look and there I can get the physical address this one will tell that the frame is actually present in the memory but I am more focused upon that case where we are not finding the page which we are looking for suppose the address is generated of this page which is not present in the memory which is a page miss or we also call it as a page fault the page is not present on the memory but present on the disk you know that every page which I can refer or I want to refer is present on the disk every page because the whole program is present on the disk but whole program is not present in the main memory if I want to refer that page which is present on the disk but not on the main memory that phenomena is Page Miss okay so what will happen now if I want to refer that page which is causing a page Miss then process cing page fault will get blogged we have to read the page from the disk so this is what an iio operation is and why the process is blocked because I hope you remember the process transition diagram from ready it got to running and from running it has generated that address or it has generated the address of that page which is not present in the memory so what will happen we have to read that from the disk and reading or writing operation on the disk is I operation so this will go to the block State that's why the process is blogged now what will happen after the process is blogged how are we going to read the page we have to first perform the mode shifting we have to shift the mode from user to Kernel kernel virtual memory manager now process is blocked then who will come to the CPU virtual memory manager will be on CPU taking charge summoning the disk manager to find that required page and have hand over the copy to that page to virtual memory manager let us see the whole process what is going on suppose there's a process running on the CPU it generates an address of that page which is present to the memory then I'll get the physical address how here I will get the frame number here I'll get the offset I get the physical address I will access that word but now the process has generated the address of that page or process want to refer that page which is not actually present in the memory now what will happen process will get blogged why because that page which process want to refer is present in the disk reading the page from the dis is an IO operation and for I operation process has to get blocked after the process is blocked CPU is empty from running the process has went to the block state so no one is there at the CPU now who will come virtual memory manager will be on the CPU taking charge summoning the disc manager virtual me memory manager say hey disk manager I want this page so disk manager will look in the hard disk and hand over the copy of that page to virtual memory manager now virtual memory manager will try to save that copy of of that page to the main memory it has got the page which I which the process want to refer let's say P6 was the page let's say P6 was the page that uh process want to refer it was not present here so process will get blocked virtual memory memory manager will come summon the disk manager to hand over that copy of the page to virtual memory manager now virtual memory manager has the page B6 what will virtual memory manager do now it will try to fit that page into main memory so that process can refer to that page so here two cases will come the first case is we have an empty slot in the main memory if the frame is empty then the virtual memory manager will save that page unblock the process eye process will come to the ready State and it will continue its work from there but what will happen if the frame is not empty like in this case frame is not empty so we have to select a frame out of these swap that out and swap P6 in the case one was there was an empty frame present so I will put P6 there but the case two is there is no empty frame all the frame are already filled now what will happen I will select a page and I will select the page and I will swep that out from the main memory and swep in the P6 same thing is written here if the frame is not empty we need to swap we have to select a page as a victim now the question arise how are we going to select the page as a victim there are policies present to select the page so what we will do P5 P5 let's say P5 is the victim so we will swap out the P5 what is the meaning of spping Out means from Main memory I will put this P5 back to the disk and from disk I will put P6 here now this is what the main memory looks like it has page number seven page number zero page number six and page number two so we have replace or copy or replace if updated in the memory we will copy or replace if updated in the memory so this is how demand paging is done and all of the operating system which you know like Windows Mac Unix all of them follow this approach let us understand the types of demand paging the first is pure demand paging or the default one in pure demand paging we start the execution of the process with empty frames the whole M main memory is empty none of the page is present there but in prefetch as the name suggest we start with loaded Pages see this page fault is like an interupt which will result from mode which will result in mode shifting from user mode to Kernel mode okay this is the point I want to mention in the implementation of virtual memory three three types of address spaces are involved the first is the main memory which is physical address space the second is the virtual memory that is which is the virtual address space and third is the dis address space now can you tell me the relation between them physical address space is less or equal to the virtual address space because we need larger program this in this virtual letter space program is stored the program program is itself the virtual address space so what is physical address space in this processes are stored so larger program should be able to execute in smaller area that's why we have a physical address space and virtual address space virtual address space is greater than the physical address space now comes the disk address space size of virtual memory is limited by the size of disk see this is the program this is the process and this is the dis itself so in disk there are multiple programs okay and only some part of the program are loaded into the main memory that becomes the process so physical address space is the smallest then comes the virtual address space and then the disk address space virtual memory is mapped onto the disk mapped onto the disk so disk address space should be large enough okay look at these diagrams now CPU then cache memory then Ram then virtual memory hard memory comes this is what the conceptual view of main memory is let's see this memory hierarchy how data is transferred between memory hierarchy so from virtual memory it is transferred from virtual memory data or pages are transferred into main memory upon page P from Main memory the data is transferred into cach upon cach Miss and from cach we transfer data into register via load or store okay so this is the memory hierarchy this is the conceptual view these are the pages memory map either hit or miss if hit then it is okay if Miss then swap in swap out will happen this Miss is also known as page fault if page fault happens then what what happens the process is blocked virtual virtual memory manager will come into the CPU virtual memory manager will summon the disk manager to hand over the virtual memory manager that is hand over him the copy of that page so disk manager will look at that page enter the disk find that page copy that page into and copy the page and hand over to the virtual memory manager now what will virtual memory manager do it will try to put that page back into the main memory two cases may occur the first is there exist an empty slot for that page to be shifted there but if no empty frame is present then we have to select a victim page remove that page from that frame and place the newly copied frame uh newly copied page into that frame so this was the idea apps taken to serve the page fault firstly the program is loaded into the main memory and then page table is formed now process want to access that page which is not present in the memory then it will generate an interrupt mode shifting will happen virtual memory manager will become active and with the help of disk manager it will try to bring that page into main memory again if the free frame is present then it will put that page into that free frame and then we'll update the page table and restart the instruction okay so these are the steps page for service time pfst is the amount of time taken by operating system to serve the page for it is generally in the millisecond and memory access time is generally in the nanc in the next lecture we will see the performance of virtual memory let's analyze the virtual memory timing so instead of calculating effective memory excess time we are calculating here effective access time we will take effective memory access time as M only so let us take that effective memory access time is m page fault service time is s and Page fault rate is p and Page hit rate as 1 minus P here the structure of formula will little bit change change because in tlb or in caching we used to take hit rate as X and Miss rate as 1 x but here we have taken page fault that is the Miss rate as p and hit rate as 1 minus P now we will calculate effective excess time of demand paging as virtual memory is implemented using demand paging it will be equal to if I had a hit then 1us P into effective memory exess time plus if I had a Miss then first I have to serve the page fault so s will come and then I will access the memory but you know that page fault service time is in milliseconds and Main memory or effective memory access time is in Nan seconds so I can ignore M here I can write it as s so formula of effective exis time for demand paging will be demand paging will be 1 P into M plus P into s + m or I can WR write here P into s let us read performance calculation of demand paging system if there is no page fault effective access time is the effective memory access time okay effective access time equal to effective member access time if there is a page fault we have effective access time equals to firstly page for search time and then effective memory access time and we can approximate that is to page for search time because page for search time is very large in comparison to effective M ex time it is around like, and one so we can ignore one in front of thand where PFS is the page for service time since the emat that is effective mem system is very small compared to pfst it can be ignored now we had a page for rate of P then effective access time can be calculated as follows so effective access time equals to page fault into effective access time of page fault what is the effective access time of page fault this page fault service time and Page hit and then effective access time no page fault that is emat only so that's how we got our effective access time now you can look for this example effective memory access time for a given system is 1 microc and the average page for search time is at 10 millisecond you can see the difference let's say p is the page fault rate or the probability of page fault then effective exis time will be just put the values and you'll get the answer look at this amazing flowchart it will contain all of the cases which we have studied till now we will start from CPU it generated a virtual address then the first cases which Sayed in the tlb and the two cases which can arise is either it was a miss or it was a hit if if it was a hit then we generated the physical address if it was a Miss then we have went and searched to the search at the page table now again two cases May generate the first was in the in the page table we had a hit it means the page which we were looking for was present in the memory we had a hit and the second case which may arise is it may be a miss so let's look at the Miss first if it was a Miss then page fault will occur and we will serve that page fault we will get that page from the secondary memory that is the hard disk we'll update the main memory we'll update the cache and we'll update the page table entry and then we will go at the beginning again but if it was a hit then we will generate the physical address now we have included an additional concept here of updation in cash if we had a Miss then we will not let it be Miss always we will update it so that next time when when we will search for that page it will be easier for us so here what we have done we have updated the cashier we'll update the cashier when it was a Miss in the tlb we went to the page table we had a hit there then we'll update the tlb now okay tlb was updated so now it's time to go and access that word or instruction so we had physical address now we had here physical address now now let's say we went to the PC again two cases may arise either it may be a hit or it may be a Miss let's say if it is a hit that means we found the instruction or data corresponding to that physical address then we will return that value from cach to CPU if it was a Miss then what will happen we will update the cash we will update the cash from Main memory what we did in the case of page table or what we did in the the case of tlb we updated it using page table and here we will update the PSC using main memory so we will update the cach from Main memory and then I will return the value from cash either data or instruction to the CPU so that's how it work let us read it again for more clarity CPU generated the virtual address searched in the tlb two cases may arise either hit or miss if it is a Miss then I will look in the page table if it is a hit then I will generate the physical address update the tlv if it was a miss then I will look then I will uh serf the page fault update the main memory cach and Page table entry now we have got the physical address and then we will search for that physical address into cache whether that instruction or data corresponding to that physical address is available in the cach or not if yes then we'll return that and if no we'll update and then return so this was the virtual memory concept with the help of tlb and PSC plus we had an additional concept of updation I hope you liked it let us solve some problems and you know the drill you have to solve or attempt them first and then see the solution suppose the time to serve a phage fault is on an average 10 milliseconds while a memory exess time takes 1 microc then 99.99% hit ratio this is 1 minus P hit result in an average memory exess time and this is nothing but effective excess time so you have to just apply the formula page fault occurred page for service time page for did not occur and Main memory exess time here this is given 10 milliseconds this is given 1 microc this is given and you find this by 1 minus uh hit ratio so 99.99% was the hit ratio so 0.01% will be the Miss Ratio or the page fault rate so from here I got this now we can see that the units are different we have to bring them to the same unit 1 millisecond is 10 ra to^ 3 seconds 1 microc is 10^ 6 seconds so I can say 1 millisecond is 10 power 3 microc so I will write here 1,000 and we'll solve this and I got 1 micros and from there I got 0.9999 microc so adding them I got this 1. n999 microc as the answer question number two if an instruction takes I microc and with a page fall takes an additional J microc then effective exess time if on average a p page fa occurs after K instruction is so we have to find the effective instruction time instruction I if it is just the instruction then it takes I micros seconds if it is a page page forward then it will take additional see here see here additional J is written so additional J microc so I + J after every K so I can write for first instruction take I second take I and for K it will take I + J just find the average I + i+ and then in the end i+ j total are K so K in the denominator from here I got I + J by K I can do this with the formula also we know that page fault rate is K 1 by K so 1 by K into I + J + 1 upon 1 K into I only so this is Page fault occurred time with page fault so it will take I for instruction and J for additional page fault service so page fault occurred page for service time page for did not occur memory exess Time same formula question number three you should attempt this on your own now let's see the solution assume that we have a demand page memory it takes 8 millisecond to serve a page fault if empty frame is available or if replaced page is not modified so let me tell you a concept that this was our memory suppose this was the victim frame that is that will be replaced with some other page or let me start with the beginning suppose a process generated an address of that page which is not present in any of the frame on the memory so what happened page fault will occur now page fault will be served so that page which the process want to refer will be bring brought to the memory and no p no frame is available if no frame is available then one of the frames will be selected as victim and that frame will be replaced with the page which we have brought so the thing is if the victim page has been modified then we have to store that victim page into the disk first so that the updated data is not will not be lost and then that page will be restored so this is the concept so it it says if an empty frame is available or if a replaced page is not modified if it is not modified then just remove that from the uh memory just throw it somewhere somewhere in the free space and then store the page which you want to store that can only happen if either empty frame is available or the replaced page is not modified but the case is if that victim page is modified then you have to store that in this first and then store that page so this will take some additional time so this uh the victim page which is which has been modified has been given a term dirty so it says that page for service time will be different if the page is clean or the victim page is not modified or the empty frame is available then it will take 8 milliseconds and 20 milliseconds if the page is dirty or modified and it is also given that 70% of the time page is modified so for dirty I will write d as uh D equal to7 and from here 1 minus D will be3 which means 30% of the time the page is clean and for 70% of the time the page is dirty memory excess time we are given with 100 nond so we have to find the acceptable page for rate for an effective exess time no more than 2,000 nond so effective exess time less than 2,000 NS and Page fault rate we have to find just apply the formula effective access time equals to page fault has been occurred page fault service time now we cannot directly write 8 or 20 here we have to find the effective page for time so how can we find effective page for time 8 milliseconds when it is not dirty and 20 milliseconds when it is dirty so from here I will get it is 14 milliseconds and it is 2.4 milliseconds so from here I got 16.4 millisecs this is the effective page fault time page fault occurred effective page for service time page fault did not occur memory exess Time same formula we put the values and solved for the value of P because we want to know the acceptable page for rate for the case when the effective exess time is less than 2,000 NS so from here we solved how did we solve see here this this was in milliseconds and this was in nanc so you have to bring them to the same scale and we solve this and we find that the effective page fault rate uh no it is just the page fault rate not effective that was the effective page for service time so the page fault rate should be around 0.01% or 10^ minus 4 okay see another question consider a process executing on an operating system that uses demand paging the average time for a memory access in the system is M units if the corresponding memory page is available in memory and D units of the memory page causes a page f it has been experim Mally measured that the average time taken for memory access is X units so this is E8 given which of the following is the correct expression for the page fault rate experienced by the process so here x will be the effective exess Time 1 minus P will be the time when page fault has not occurred if page fault has not occurred then access the memory if page fault occurred then page fault service time so just we have to find P from this equation x = m mp+ DP so M will be sent here x M and P will be taken common from this and this D minus will be sent to the denominator so x M upon D minus M will be the answer that is B now comes an amazing question it says consider a paging system that uses one level page table resing in main memory okay so one level okay and a lb for address translation each main memory access time takes 100 NS and tlb lookup takes 20 n seconds each page transfer to and from disk takes 5,000 NS 5,000 NS assume that the tlb hit ratio is 95% so X is 95% or I can write point 95 if we are talking probability the page fault rate is 10% so page fault rate will be p is .1 assume that for 20% of the total page faults a dirty page has to be written back to the disk before required page is read in from the disc that concept I've told you so D will be02 okay tlb update time is negligible okay the average memory access time is so easy question let us take this case suppose a process Pi resting in CPO generates a logical address firstly we will look in the tlb if found then F frame will be copied here and this D will be copied here and we get our physical address but if not we will search first in the page table if page table if found in the page table this Frame will be copied here this D will be copied here and we found our physical address if not even found in page table then two things can arise the first is the victim page is dirty the second thing is victim page is clean if the victim page is clean then we have to just bring from the disc and if victim page is dirty then we have to first store and then bring that page into the disk so this time is given that 5,000 nond will be taken if we have to uh transfer a page to and from the dis so in case of clean only 5,000 nond will be taken and for the dirty 5,000 NS for storing the page back to the dis and 5,000 nond for bringing the new page to the memory so we have to just apply the formula now effective memory access time tlb hit tlb look up got the physical address access the memory tlb Miss first looked in the tlb but failed then I mve to the page table it was found in the page table here I got my physical address access the memory now what happened I had a tlv miss I had a page miss or page F now I am looking in the page table first but found that it was not present so chances are the page is dirty so if the page is dirty then 2T time will be taken that is 10,000 n seconds and if the page is not dirty just 5,000 NS put the values and you'll get your answer okay so the answer was 54.5 NS so if the page is clean then one dis operation if the page is dirty then to disc discover so simple in the next lecture we will learn about page replacement page replacement first we'll learn about what is reference string set of successfully unique Pages referred in the given list of virtual addresses this successfully unique is important because if one page is successfully not unique and the same page we are referring then it won't create a p it won't create a page fault don't worry if you don't get that line I'll explain it to you suppose virtual address are generated like this way 702 74 123 654 483 012 934 in this way let's say the virtual addresses are created now the page size is 100 bytes so this will belong to page 7even this will belong to page 7even this will belong to page 1 belong to Page 6 belong to page 4 belong to page 0o belong to page 9 I hope you are getting how I am getting the the page number I'm getting the page number by this virtual address mod page size this will give me the page number and what will be the offset here the the page number is seventh and the offset is two the offset is four the offset is 23 the offset is 54 the offset is 83 the offset is 12 the offset is 34 okay so this this tells me that I have to visit page number nine and word number 34 in that page that word will contain my instruction of data so this was the virtual address generated now the reference string will be 7 this seven won't be counted because we want successively unique focus on the word successively this seven won't be counted then 123 so 1 6 now let's suppose if seven comes again then we will take it 4 0 and 9 this is what the reference string is reference string is not about Pages uh is not about addresses it is about pages okay so this this was the virtual address generated and the reference will be reference string will be about pages okay so which page we want to refer that page will come and successively unique pages should be there like here this seven won't come I hope you got the idea so why successfully unique we referred a page page fault occurred we bought that page into the memory now we are referring that page again page fult cannot occur okay so create reference string from this virtual address 6 2 1 6 7 2 95 okay as they are all successfully unique successfully unique so we will take them reference string has two properties length and number of unique Pages this number of unique Pages tells us about the size of the process in terms of pages here let's calculate the number of unique Pages 71 6 409 so six unique pages are there and what is the length of the reference string the length of the reference string will be 6 only suppose in this case 7 1 7 1 7 6 in calculating the length we will calculate these 37 but in calculating the N that is the number of unit Pages referred we won't calculate the N again and again I hope that is clear frame allocation policies n represent number of process SI demand frames for process i d is the total demand m is the available frames AI is the allocated frames this is similar to the bankers algorithm number of processes frames demanded by process I or for process i d is the total Demand by all the processes m is the available frames AI is the allocated frame to that process I okay and you know that allocated will always be less than equal to demand we won't allocate more than the demand n equal to 5 which means five unique process 1 2 3 4 5 m equal to 40 which means total available frames are 40 okay these these were the demands P P1 demanded 10 frames P2 demanded five frames P3 demanded 35 P4 demanded 18 and P5 demanded 12 some of sum them all and you'll get the total demand that is D will be 0 now there are different allocation policies frame allocation policies the first allocation policy says that allocate them equally how many how many total available frames we have 40 so allocate them each allocate them each eight eight frames so 10 will be given eight frames five it demand of five but it got eight it demanded of 35 but it got 8 only it demanded of 18 it got eight only so this is absurd it should not be there because P2 demanded just five and it got eight more than its demand and P3 demanded 35 and it only got eight way less than its demand so when should we use this equal allocation policy this should be used when all the process have almost equal demand in this case demand is varing 10 5 35 18 12 if would be around 10 11 10 9 12 in that case this equal allocation policy will somehow satisfy that okay now there is a obvious point to be made that if available frames are way greater than the demand then there is no scene of allocation policy we create policies because the demand is more and available is less if the available is more and demand is less then what is the need of decision making the second policy comes of a proportionate allocation demand upon total into available so this will be allocated to each process demand upon total into demand upon total demand into total available so this will proportionately divide the total available frames so this is what proportionate is 50% rule says whatever the process ask give it half of that if it ask 100 give it 50 this is 50% R now the question arises minimum number of frames allocated to a process the the minimum number of frames allocated to that process what should be the minimum number of frames the first is that number of frames without them process cannot execute the second point is process should be able to execute minimum one instr instruction if minimum of one instruction is being executed then those are the minimum number of frames allocated to that process which which says at least these many frames should be given to the process for execution now if uh process should be able to execute minimum one instruction so if we have to execute one instruction only then what is the need of multiple frames because instruction can be stored in one frame so for one instruction shouldn't we need just one frame so that is the question but it is not that simple it depends upon the instruction architecture like uh we will discuss it with more detail in computer organization architecture course but just for the sake of explanation this is the op code and these are the operant this op code is like a code in binary which will tell which operation to perform and these are the oints which tells on which variables we have to perform that operation on or in which literals you have to perform that operation okay suppose add R1 B so in this R1 + b the result should be stored in R1 so this is what an instruction is and this add will be the op code let's say 0 1 1 0 this represent the op code for addition so this is the op code these are the oints now the the point is operant can be distributed in multiple pages so we cannot say that we only need one page or one frame for an instruction to be executed see instruction reside in a single frame but operants can be distributed or multiple pages so it depends upon the instruction architecture so for this question the minimum number of page uh frames that must be allocated to running process in a virtual memory environment is determined by the answer is instruction set architecture okay we are given with the reference string you remember what was reference string reference string was the number of successfully unique Pages referred or the string of successfully unique pages and the total number is 20 and unique R six this six represent that the process consist of six pages is St in the disk okay now what will happen naturally the process will ask for six frames in the memory so that it can bring its all the pages from dist memory process will naturally ask for six frames but what happens operatic system shows no mercy and gives only three frames to the process process requires six frames but it gives only three frames to the process okay so we will start with the pure demand paging remember what was pure demand paging that we will start with the free frames that there is no page present already in the memory process want to refer page number seven but unfortunately that was not present as we were starting with free memory so that will cause a page fault and seven will be brought from disk to memory now process want to refer page zero same case will happen here again a page fault and zero will be brought from disk to memory then page 1 and then same case with page so three page FS have occurred till now now what will happen all the frames allocated to the process is filled with the pages process want to refer page number two now but that is not present page fault will occur again what will happen now one of these Pages have to go from the main memory and let this page number two enter into the main memory but the question is who will become the victim so we will decide the victim on the fif basis the first to come will be the first to go out so when two will come the seven it is it is the uh turn of seven to go from Main memory to somewhere else it will go back to the disk so seven will go two will come now process want to refer page number zero page number Z is already present so no page fault it wanton to refer page number three a page fault will occur see here so who will go now after 7 0 came so 0 will go three will come after three process want to refer page number zero again what will happen this one will go zero will come now again a page fult process one to refer page number four not present in the memory now it is the chance for this two to go four will come again a page F two will come again a page F three will come now zero no zero page fault three will come present no page fault two present no page fault one wants to come but it is not present page fault two will go one will come now two wants process want to refer page number two not present page fault will occer Zero already present 1 already present 7even is it present no Z will go 7even will come zero is it present no one will go Z will come one is it present no two will go one will come so by this we will calculate the number of page falls so number of page falls are 1 2 3 4 5 6 7 8 9 10 11 12 13 14 and 15 so there are total 15 page FS when we alloted the process only three frames out of six and based on which policy FIFA policy so the number of page faults were 15 when we had three pages or three frames it so what will be the page fult rate total number of references 20 Page Fs in that 20 references were 15 so the page fault rate will be 75% now what will happen operating system shows some mercy and aot it four frames instead of three four frames are there now it is your homework to calculate how many page fa will occur so this is your homework we'll discuss in the next lecture and it is so obvious that rate will decrease why rate will decrease because we have four frames now suppose if we had another frame here then 70124 page for will occur now Z wants to come Z is already present three wants to come but not present so three will go here zero already present see there in the previous case it caused a page fault but now it is not a page fault zero is already present in this way the page fault rate will decrease so you have to calculate how many page fault will occur if we had a number of pages or number of frames allotted equal to 4 make sure before starting this lecture you have pen and paper along with you a reference string is given this was the reference string and in the last lecture we have seen that if the process has been allocated with three frames to bring six pages from this dis to memory then 15 page fault will occur this page fault rate was 75% now the homework was to check the number of page fault if the process had instead of three frames if the process has four frames then how many page fault will occur so the answer was 10 the page fault rate significantly decreased from 75% to 50% 15 by 20 is 75 and 10 x 20 is 50% let us take another question this is the reference string number of references are 12 and the unique pages are five calculate again for the three frames and four frames pause the video and calculate so for the three frames I got nine page fs and you will be surprised to know that when I increased the number of frames when I show when I showed some mercy on the process and I have given him extra frame so that it can easily bring those five pages from disk to memory so that it may have less page fault but what happened something unexpected has happened instead of decreasing instead of decreasing the rate the page fault rate actually increased against the natural characteristics when we had three frames there were nine page Parts when we had four frames then we had 10 page fors how is this possible so it in increased against the natural Char characteristic this is an anomaly anomaly or whatever you pronounce it anomaly so we call it as bad anomal so what happens generally page fault rate and this is the number of frames if I increase the number of frames then page for trate significantly decreased like happened in this case but what happens when the number of frames required is equals to number of pages then after that no matter how many frames I give to the process the page fault rate will be same let me explain you in this case there were six pages available to the process or I should say the process had six pages and number of frames available were three in that case 15 page F has occurred if I had increased the number of frames 10 page F will occurred let's say I have increased to six frames the number of pages has equal to the number of frames available s page fault occurred zero page fault occurred one page fault occurred two page fault occurred three page fault occurred and later in some point four page fault occurred Beyond this whatever may be the reference page fault will not occur because whichever page the process want to refer is present in my memory so after that page fault won't occur so that's why no matter how many frames I increased is the page for rate will remain same so this was the general idea which we thought of but what happened here in the case it increased against the natural characteristics it has gone somewhere like this the page fult rate increased instead of decreasing so this is an anomaly in case a if I took six frames then six page fault initially initial once due to the pure demand paging and then the page fault will remain same the above anomo was discovered by badi badi ano says as per the number of frames allocated to the process increases as the number of frames allocated the to the process increases if I increase the frame number then page fault also increase sometimes and it only happens in the case of fif or fif based algorithms and the reason for this is stack property of replacement you don't have to go deep into this just remember the reason the reason is stack property of replacement so let us revise what happened in the in the in the last lecture we have discussed a problem in which we had three frames available then 15 page pter cut then if we have four frames available then page for rate should obviously decrease this was the idea and if I have allocated that many frames which the which equals to the number of pages the process has then after that no page fault will occur the number of page fault was six or number of page fault was K here because of pure demand paging if we talk about the pre patch demand paging then in that case if I had allotted frames equal to the pages then the page fault will be zero but default one is pure demand paging so we were taking that taking into account that to load the pages like 7 0 1 2 3 4 this will cause a page fault every time because initially we started with zero initially we started with nothing it was a free memory so when process referred the seven it caused a page fault when process referred zero it caused a page fault so in that manner six page fault will occur and after that no matter how many frames I I allot to the process page fault will remain same due to Pure demand paging so this was the idea but what happened in this example when I increased the frame number the page fault actually increased against the natural characteristics so this was bad anomal and it happens in the fifo and fifo based algorithms or fifo based allocation policies and the reason behind this is stack property of replacement optimal page replacement will generate the minimum page Forge in fif we Cho we have chosen that page which was first to come in the memory as a victim in this optimal page replacement we will choose that page which has not been used or which will not be used for the longest duration of time in future let us take this case 701 CM reference string page fault page fault page fault why due to Pure demand paging now page fault will occur out of this 701 which will be the page to be selected as victim see that which page has not been used for the longest duration of time in future zero just used 1 used 7 7 will be selected because 7 is the page which will be used after so much time so we will remove seven so compare which will which page will be used after the longest time that page you will choose as a victim and remove that page so 7 will be removed 7 will be gone two will come now out of 207 we have these pages in the memory 207 is present zero no page fult three 0 just used two just used one will be used after the longest duration of time so out of 2011 one will be removed now three will be brought to the memory we had 203 now zero no page fault now process wish to refer page four not present page fault will occur two just used three just used and zero will be used after the longest this time so 0o will be gone and four will come here after that we have 2 43 in the memory 2 no page fault three no page fault zero page fault will occur because we have 2 43 no zero so which will be removed three just used two just used four is not used ever so four will be removed now we have 203 so here we have 203 three no page fault two no page fault one who will be removed now the one which has not been used for the longest duration of time so after 203 two used 0 used three has not been used ever so three will be removed one will come two present in the memory zero present in the memory one present in the memory seven page fault will occur who will go 0 just used one just used two has not been used for the longest time in the future hey I have noticed that I speaking the grammar wrong it should be two instead of two has not been used I should say two will not be used okay so two will not be used ever in the future so 701 will be the final Pages which will remain in our memory so how many page fault has occurred 1 2 3 4 5 6 7 8 9 so nine page fault will occur and now four frames how we will calculate for four frames we are we are using pure demand paging 1 2 3 4 these page fault will occur due to Pure demand paging now we have 7012 in our memory now out of this 7012 you know that 7 has been used directly here so 7 will be removed when this page fault will occur so at place of seven three will come after three zero already present four page fault will occur who will go now two used three used one is used at the after the so much time so one will be removed four will come now we have 3 0 42 two present 3 present 0 present 3 present 2 present 1 is not present so who will be gone four has not been used ever four or I should again correct it four will not be used ever so four will be gone but are you noticing that three has also not been used so out of three and four which should be gone we will at the tie breaker we always use F4 so the one who came first will be gone first three will be gone now are you noticing the difference if we have two pages which won't be used later see we had three and four this zero will be used and two will be used but this three and four will not be used later so out of them which we have to select as a victim the one who came first so three will be selected one will come now okay so now I have 1042 two present zero present one present now seven wants to come who will go we have four and two not used ever 1 and zero will be used so after four and two which came first two was already present so two will be gone see two has came here and has not been gone till now so two will go now so now seven will come now calculate the number of page for 1 2 3 4 5 6 7 and 8 page for really decreased from 9 to 8 when we increased one frame now check for this we had bad's anomaly in this question when we had three frames we got N9 page fault when we had four frames then we got 10 page fault which was against the natural characteristic so here we followed victim policy as fif now we have to follow optimal replacement and check does it suffer from the bades and this is your homework or you can do it now by pausing the video so for three frames we got seven as the answer and for four frames we got six as the answer so I can say when we increase the frame the page fault rise decreases so it is not against the natural characteristic so it does it does not suffer from bades anomo and I have already told you that fif and fifo based only those suffer from bades anomo but if you have observed there is a serious problem in the implementation of optimal replacement what will the serious problem it is similar to the sgf remember the fgf CPU scheduling algorithm in which the first time was already given but can you guess the bur time of the upcoming processes no in the similar way can you guess which pages will process want in the future no you cannot guess you cannot guess which Pages the process will want in the future it is purely dependent on the situations so how will you look into the future which pages are you going to refer like hgf it is non implementable then why do we study this we use this algorithm as a benchmark that by this are this is the least number of page faults possible and your algorithm let's say let's say in this case in this case the page faults were eight okay so I can say these are the least number of possible page faults and my algorithm is producing let's say 10 page FS so I can say yeah it is closed but there is a scope of improvement so it is it is used as a benchmark okay in the next lecture we will see an another policy that is least recently used it is just the 180 shift of the optimal policy in optimal policy what we did okay I think I should I should teach this in the same lecture so in optimal page replacement what we did we thought that whichever page page has not been used or whichever page will not be used for the longest duration of time in future that page will be removed or that page will be chosen as victim we have 180 shift the algorithm replace that page which has not been used for the longest duration of time in the past so here has will come and there will will come there we were choosing the page which will not been for the page which will not been used for the longest duration of time in future here we are choosing the page which has not been used for the longest duration of time in the past so here past is there and their future was there so reference string is given 7012 03 the same reference string page fault page fault page fault due to Pure demand paging now at this point which will go the one who has not been used for the longest duration of time in the past see one was recently used zero was recently used seven was the least recently used that is the name of the algorithm so 7 will go 2 1 will come now zero page fault will occur which was the mo least recently used one was the least recently used so 20 3 one was gone now zero page fault occurred least recently used after 203 two was the least recently used two will gone four will come 43 so in this manner you have to proceed so you will see the number of page SPS then you have three frames is 12 and you increase the number of pages or number of frames then you will get a pretty less page fault number so from 12 I reach to eight so this also does not suffer from Bad animal okay now let's see the most recently used replace that page which has just been used replace that page which has just been used if you are getting confused do not in fif we replace that page which came the first the first to come will be the first to go out in optimal we replace that page which will not be used for the longest duration of time in the future in the least recently used we replace that page which was least recently used or which has not been used for the longest duration of time in the past and then most recently used replace that page which has just been used so 7 01 page for due to Pure demand paging now two wants to come who will be gone one will be chosen as Victim Because one was recently used so in this manner you have to proceed so in this page fors are really high There are 16 page fors now comes the counting algorithm the criteria is a little bit different here the criteria is count of reference number of times a page is referred that is the count of reference and one special thing is when swep out and then swep in set count equals to one when swep out and then swep in set count equals to one and which page will be selected as victim the one which has the least count and here in the most frequently used the one which has the highest count will be selected as victim okay let's see this this is the reference string 71203 and so on page fault occur page fault occur page fault occurs due to Pure demand paging so now the 701 has a count of 1 1 1 the 7th page the zeroth page and the first page has been counted or has been referred one time now two wants to come so page fault will occur again which of them will be gone or which which of them will be selected as victim the one which has the least count but here all of them is the same count so we'll use fif the one who came first will be the first to go so seven will be replaced by two now two will come and it has been referred one time now zero Zer will be zero is being referred second time so 1 + 1 now three three wants to come who will be replaced or who will be selected as victim one will be selected as Victim Because two and one both has same count but two just came and one was already there so one will be the first to go so this will be selected and three will come at its place zero count will increase now zero has been referred three times four wants to come who will be gone out of two and three three just came and two was already there so two will be gone four will come again page fa who will be gone now four and three both have same count so three will be gone because four just came so three will be gone two will be there now three wants to come now who will be gone two just came so four will be gone three here with count one now zero zero has been referred again so the count will increase to four now three count will be increased to two so three as a count two 0 is Count four and two has been referred again so two will be the count of two will be two now one wants to come out of three and two will be gone two was already there three just came so two will be be gone so two will come go and one will come here now two wants to come again so who will be gone out of 2 4 and one the one which is the least count so one will be gone two will come now zero increase the reference count now one one wants to come so who will be replaced out of two five and one the wi one which is the lowest count so one this two will be replaced one will come seven wants to come now now who will be replaced the one will be replaced seven now zero wants to come Z is already there increase the count to six now one wants to come who will be replaced seven only because it has a least count so one will come so page for occurred in total least frequently used are 13 now you have to do the same the change is the one which has the highest count you have to replace that and if both the if both the pages have same count then use free4 the one who came first will be the first to go out okay so this is your homework and calculate the number of page for let's say it is 15 just for the sake most of the time it is found that lru is closer to Optimal in terms of performance so many operating system either implement lru or variations of lru and lru is implemented through stack how it is implemented say we have 701 in our frames so 7 will be pushed to the stack 0 will be pushed and one will be P one will be at top zero at the in the bottom or zero in the middle and seven in the bottom now this one is the most recently used and seven is the least recently used now what will happen pop one pop zero and when you pop 7even the seventh will be gone because we are removing the least recently used now push them back into this tag zero will be pushed one will be pushed now two wants to come at the place of seven so two will come here now who is the most recently used two is most recently used and Z is the least recently used so nothing happened just two came here okay now comes the laru approximations these algorithm are not really lru but they are approximate they approximate to the behavior of lru so here comes a new term that is reference bit the reference bit shows each page in the page table will be associated with a reference bit which which shows that has the page been referred so far if zero then it is not referred and it if it is one then it is referred at least once okay so each page in the page table will be associated with a reference bit if zero not referred so far if one referred at least once so page table entry contains many attribute like frame number valid or invalid time of loading time of reference count of reference and reference bit these are the attributes of the page okay now comes an important part what is epoch if you have uh learned about deep learning that Epoch is a cycle or Epoch is a duration of time it is time Quantum it is time Quantum so this is this is the time scale and the epoch is the just the duration of time say this is one Epoch this is another Epoch this is another Epoch and let's say this is the time in present so we will look into the pages that if this page has been referred in Epoch 3 or not if it is referred then we will set reference bit as one and if it is not referred than zero so we the reference bit is counted based on the epoch Epoch means that the current duration of time okay so the page table entry is associated with these many attributes like frame number valid or invalid time of loading time of reference count of reference and reference bit reference bit can be 0 or one zero suggest that page is not referred so far during the present Epoch and one says that at least once in the current Epoch so reference bit this reference bit we talk about in the current Epoch in the current duration of time so let's say these were the process or entries of the page table frame valid invalid time of loading and reference so this shows that page number zero has been referred at least once in the current e page number three is not present in the memory page number five has not been referred in the current Ok Okay so this is what reference bit is so now we have five pages 0 1 2 3 4 and 5 or it is six pages sorry 0 1 2 3 six pages so out of these six pages the time of loading shows shows that which page was loaded first in the memory so the page number two was loaded first in the memory and page number four was loaded last in the memory these are six is just a Sil mistake three okay so p 0 P2 and P4 has been referred in the current Epoch P0 P2 and P4 this is what reference bit is now if you remember the definition of lru what lru said select that page as the victim which has not been referred to the longest duration in the past which has not been referred to the longest duration in the past and this is what laru approximation we are studying so reference Bit Zero matches with the statement or reference bit one matches with the statement what does reference Bit Zero says page is not referred so far it somehow matches with the statement that page has not been refer to the longest duration of time in the past so R equals to zero so how are we going to select the victim page scan scan the page table right from the first entry and as soon as you got R equals to Z victimize that page so here which page will be victimized scan from the first entry reference bit not zero reference Bit Zero so page number one will be the page to become the victim okay now comes the question if all of the pages has been referred at least once say there is no reference bit which is zero all reference bit are one then what will happen then this reference bit algorithm fails okay now when one e box get completed set R equals to zero I have already told you that we talk about reference bit during the current Epoch during the current Epoch let's let's take this as an example suppose some parameter K tells that how many times your name was spoken by other people in the year let's say 2036 okay okay K tells that now what happens 2036 just got completed and 2037 has started this is the year now what will be the value of K zero because 2037 has just started okay so this is what reference bit is so as soon as the current eox get completed set R equals to Z because when the current eox has just completed none of the page will be referred when the time will pass then the reference start so as soon as the current epox get completed set R equals to Z so what was the loophole here if every page has been referred at least once then reference bit algorithm fails now how are we going to select the victim the second is additional reference bit each page is associated with more than one reference bit let's say eight and this is a static you cannot change it this is static this is not Dynamic let's say if we are we have selected that eight reference bit or eight previous history will be saved then it will be eight only it won't change when the time will pass suppose another epox get completed so you won't add here nine what will happen this will be lost and R8 will become zero why zero because if the current eox get completed set R equals to Z let me start again what happened we introduced a new term reference bet reference bit tells that if the page has been referred till now in the current oke then set it as one if it is not then set it as zero now we are approximating the lru what lru said select that page as the victim which has been referred which has not been referred to the longest duration in the past and Ral to0 matches with the statement now what we did in the reference bit we scann the page table from the first entry and as soon as we get R equals to Z we victimize that page but what happens when there is no such page there is no such page which has not been referred till now all of the page has been referred what will happen then reference bit algorithm fails then comes the additional reference reference bit what we do here we keeps the previous history so we will check here all once no problem get back or go in the previous in the previous Pi PG and PK all of them were referred don't worry go back in the previous to previous ook Pi was was referred PK was referred but PJ was not referred so when a new page let's say PL will come when page fault will occur so who will get victimized PJ will get victimized you getting the point so what we are doing we are maintaining the previous history in R8 all of them were referred so we cannot select which page to choose as a victim in R7 again the same thing but in R six PJ was not referred so we'll select PJ as the victim okay okay but what happens in the rare case when all of them here is also one all of them are one what will happen then in that case this algorithm will also F and when the current current EO gets completed do the left Shi left shift operation and select R8 equals to Z and R1 will be lost so left shift will occur this will be lost and select R8 as zero why zero because when epox get completed set R equals to Z now comes an interesting algorithm that is second chance or clock algorithm the criteria is time of loading plus reference bit see we are giving second chance to the pages let me explain so in this how are we going to select the victim based on the time of loading and reference bit so we will go with the time of loading which page was loaded first two was loaded first go there it was the time of loading was zero so two was loaded first now check the reference BD is it is it Z no it is not zero it is one change it to zero and then move to the next which was loaded next four was loaded next does it uh have a reference Bit Zero select that as victim what are we doing the page with which get loaded first see its r value if it is zero victimize it victimize it if it is not if it is one then set it to zero so P4 here will be victimized now if if you can observe that if all of the reference bit R1 then also this algorithm will not fail why we are because we are given second chance to the pages see here let's say all of them were one now what happened time of loading two was the first to get loaded so we will change it to zero now four came so we will change it to zero now who came this page number zero it has reference bit of one change it to zero move ahead three page number one came it has a reference bit of one change it to zero now page number five came it has a reference bit of one change it to zero so what we have done we have gone for the full cycle when all of the reference bit were one we have gone to the full cycle how based on the time of loading now we will after one cycle go again in the same order now who was loaded what was the order the P2 was loaded first now it is a reference bit of zero victimize it are you getting the point see in reference bit if all of the bits were one the algorithm fails so what we did we maintained the previous history okay I believe that in the previous or in the current Epoch all of the pages were referred let's talk about the previous Epoch where all of the pages were referred yes all of the pages were referred and previous to previous Epoch PJ was not referred okay victimize that now there is a rare case also here that all of the pages were referred even in the previous EPO also so what we will do we are giving a second chance to the pages we will go in the order of time of loading and see the reference bit if the reference bit is zero victimize that if it is one then change it to zero in order that when I will come again at this point then the reference bit would have been zero and I will select that page to become victim that's why second chance and the first chance we change that to zero and in the second chance this will be victimized so this has actually solved the problem when all of the pages were referred in the previous epox also okay so the page which get loaded first see its r value if it is zero victimize it if r value is 1 set it to zero so here P4 will be victimized and in this case P2 will be victimized okay so when all of the pages are Valu is one then fif page select fif page get selected that's what we have done here when all of them were one P2 was selected which came the earliest and as soon as you hear the the name of fif bades Ando should come to your mind so when in Second Chance algorithm when all of the reference bitar one then it is a possibility that bades Animo may occur we have seen the reference bit algorithm we have seen the additional reference bit we have seen the second chance algorithm in Second Chance fif follow fif order will be followed when all our values are one and it will suffer from Bad Anor now comes the enhanced second chance it is like not recently used so what does it say we will maintain RM what is RM R suggest referenced and M suggest modified or dirty bit so criteria is RM R is reference and M is or modified bit Dirty Bit so 0 0 0 1 1 0 and 1 1 this is the priority order 0 0 says page not referred and it is clean also 01 says page not referred but it has been modified one says page has been referred but it is clean 1 one says page has been referred and it is modified also so which page we will select as victim in this order we will select them victim if 0 is available that will be at the first priority to become victim so priority is 1 2 3 4 this will be at the least priority and this will be at the highest priority okay now let's solve some problem this is the page table structure we got entries frame number valid invalid time of loading reference and modified bit now according to fif which page will be selected as victim P3 will be selected as Victim Because it came first according to reference bit which page will be selected as victim scan from the first entry as soon as you get Ral to0 victimize that so P1 will be victimized according to Second Chance who will be victimized go with the time of loading Zer change it to zero so I will change it to zero now who came P1 p so P5 came and it has a reference bit of zero so P5 will be victimized according to enhanced Second Chance choose which is a RM of 00 so one will be victimized P1 will be the answer okay consider a system with v = to P = to 2^ 16 bytes P size is 512 bytes the size of P table entry is 4 bytes if the page table entry contains beside other information one valid invalid bit one reference bit one modified bit and three bits for page protection how many bits can be assigned for storing other attributes of the page also compute the page table size and bytes so we have V = to P = to 2^ 16 and Page size is 2 power 9 bytes so we'll get the number of entries it is 2^ 7 so how many how many bits for storing the frame number as we have seven entries so seven bits for frame number and the remaining 19 bits for rest of the other attributes where were six bits were stored or where were six bits six these six bits are used here three bits for page Protection One for modified one for reference and one for valid invalid so six were used here seven were used for frame number remaining 19 bits will be for the rest other attributes and what will be the page table size the size of each entry into number of entries we got 512 bytes of page table consider a virtual memory system with Fe for replacement policy for an arbitrary page access system increasing the number of page frames in the main memory will sometimes increase the page number or sometimes sometimes increase the number of page fault because this is what bad's ano is what does it say The General characteristic is if you increase the frame number then page board generally decrease but sometimes in the fifo based page replacement what happens when you increase the frame number the p page fault rate also increases a memory page containing a heavily used variable that was initialized very early and it is in constant use is removed when fif page replacement is used because here it is written initialized very early so it is brought first and if it is brought first see here here is in the constant use so lru won't be there Leo won't be there so fif will be the present fif will be the uh page replacement algorithm that is being used here because it is written initialized very early recalls that bad's anomo is that the page for rate may increase as the number of allocated frames increases now consider the following statement okay random page replacement algorithm suffers from Val ano where a page chosen at random is replaced the second says lru page replacement algorithm suffers from bad so this is false lru is never lru is laru never suffers from bad an the first statement is random page replacement algorithm suffers from bad's anomal well this can be true this can be true because let's say by coincidence it worked as fif and in fif bad Ando is present so the answer is S1 may be true and S2 is false S1 may be true and S2 is false S1 is true when by coincident that random page replacement algorithm worked as fif consider a process having reference string l in which n unique Pages occur Z frames are allocated to the process calculate the lower bound and upper bound of number of page fors so if maximum uh we have a reference string of L so what will be the maximum number of page f l how because every reference will cause a page fault in that case in that case the maximum which will be l number of page fault can occur and how can every every reference cause the page fault when we have allocated just one frame to the memory suppose three page brought to the memory CS page for now four wants to come so four will be the four will again cause a page for now let's say five wants to come five will again cause a page F so if we have just one frame then every reference will cause a page fault that's why the maximum number of page fault can occur will be the number of reference and minimum number of page fault is n when we are using pure demand paging then in this will happen in the case when we have allocated that number of frames which uh which equals to the number of pages in that case we have n number of page fault and that only the case of pure demand paging suppose the process has six pages and if I have allocated six frames then for the first time when the first time the pages are loaded then only six p page Port will occur and after that no page P will occur because we have every page required in the memory itself and in case of prefetch demand paging what will happen in case of prefetch it means all of the pages are already present in the memory so in that case no page F will occur so the minimum is either n or zero and the maximum is l l happens in the case when only one frame is allocated and minimum happens in the case when the number of frames allocated equals to the number of page of the process in the next lecture we will learn about threshing threshing just like deadlock it is undesirable feature of operating system what is threshing excessive or high paging activity which means High page fault rate and you know that when page fault occurs the loading and saving pages on the dis this kind of activities happens and these is consume time so the most of the time process will be spending time on their page F service and hence will get blocked you know that reading a page from the disk is an iio operation and iio operation in the when the pro when the I operation is being performed the process remains blocked we have learned that in our transition diagram now what happens we have learned that in uni programming operating system the percentage CP utilization is less so what we do in order to increase C percentage CP CP utilization we think that we should increase the degree of multiprogramming what is multiprogramming increases the number of processes in the memory so we increase the number of multiprogramming supposing that if some process has went for the io then some other process will be there on which CPU can work upon and hence increase the percentage utilization so thinking that we increase the degree of multiprogramming but at some point it reach to the saturation and after that the degree of multiprogramming kept on decreasing and decreasing this is the curve and the last part of the curve is threshing see this is logical if you have a limited memory and you want to you want to accommodate maximum number of processes we are increasing the degree of multiprogramming that's what it means so we want to increase the number of processes to a high number but what happened when there are so many processes in The Limited memory then each process will get less memory each process will get less number of frames so if number of frames are less then page fault rate will increase sign significantly if page fault rate will increase significantly then process will be spending most of their time in the blocked State because page for service during the page for service process remains blocked so the most of the time process will be blocked and hence the percentage CP utilization will decrease this process is blocked performing the page for service time or during the page for service time this process is also blogged blogged blogged because each process gets so much little frame to accommodate its pages and if number of frames are less then page fault will obviously occur more and the process will spend most of their time in just solving the page fault or serving the page fault and will get remains or will get blocked so this will significantly decreas the percentage subtilization okay so what is the reason of threshing High degree of multiprogramming less number of frames and high page fa rate so this is the same example here suppose Ram is of 4 GB limited size and can accommodate 50 process ideally but after 50 process we want to accommodate 55 and 60 then frames will decrease to each process and page for trade will increase and if operat system is not using good replacement technique then also page for rate will increase and it is obvious that if page size is small then there will be more pages and there will be high page for trade if page size is large then number of pages are less frames are same if number of pages are less then less page fault will occur are you getting the point see increasing the page size May decrease the page for but you know that it will invite internal fragmentation so we have to do everything in Balance now comes the threshing control strategies the first one is prevention and the second is deadlock or just like the deadlock the second one is detection and Recovery in prevention we want threshing to occur we want threshing to never occur and how can we do that by controlling the degree of multiprogramming and you know who controls the degree of multiprogramming long longterm scheder and for detection and Recovery how are we going to detect that threshing is occuring when we see symptoms like low SE utilization maximum number of process getting blocked High degree of multiprogramming high disk utilization so these are the symptoms for threshing and what will happen after threshing has occurred how are we going to recover process suspension we will remove the processes from memory put it in the dis bag who will do midterm scheduler let me repeat again what was threshing threshing is when we decrease when we increase the number of programming to a higher extent which means we are increasing the number of processes in the memory more than its limit then what will happen each process will be given less number of frames to accommodate less number of pages and if less number of pages are in there in the memory then page fault rate will increase if page fault rate is increased then process will remain blocked for most of the time because the time the most of the time will be uh will be spent on pageold service so this will significantly decrease the percentage CPU utilization this is what threshing is now comes the threshing control strategies the first is by controlling the degree of multiprogramming if we are not forcing the number of process to be more in the memory then no problem so who will Who will control that longterm scheder detection how are we going to detect that threshing may have been occurring if we find that low CPU utilization is present maximum number of process are getting blocked the degree of multiprogramming is high but CPU utilization is less the degree of multiprogramming is high but CP utilization is less which means threshing should be the reason behind it high disk utilization because uh we are utilizing dis and reading the pages again and again for different kind of processes during their page for service so disk utilization will increase CP utilization will decrease degree of multiprogramming will be high number of processes will be more to get blocked so these symptoms suggest that threshing should be the reason and recovery process suspension well the main reason was the high degree of multiprogramming with the help of midterm scheder we can swep out the processes from the memory and may decrease the degree of multiprogramming and who will control that midterm scheder so the process suspension is the uh is the solution for threshing in the next lecture we will learn about locality of references now comes the question how can our programming can affect threshing and here when I say V I mean by programmers not the OS developers programmers like the one who writes C program Java program these are the programmers and how can that programming can affect threshing is it possible let's see so we are given with an integer array let's name it as a it is not an ordinary array it is two dimensional array so let us create that uh I should use standard let us assume this is the array now what happens the size of arrays number of columns are 120 and number of rows are also 128 so I can write integer a the rows can go from 1 to 128 and the columns can go from 1 to 128 and it is an integer array so if I write it like this a 1A 1 till we have a 128 comma 1 till a 128a 128 this is our Matrix a now the question is suppose I write two programs the program one is for I 1 to 128 next Loop for J 1 to 128 set the value of a j first and then i j i = to 1 and if I write similarly here but what is the difference now I write IA J = to 1 you know that eventually both will work eventually they will set each and every element of Matrix to one but how it will affect threshing let's see that suppose I have a page size of 128 words and each word can store an integer so this is our Matrix and how are we going to store this Matrix into the memory we will store let's say using row major order what is row major order this row this row will be stored in one page this row will be stored in one page so how many pages will be there there will be total 128 Pages this is what row major order is we are storing in rows so the first page will contain the first page this is let's say this is the first page it will contain a 1 comma 1 a 1 comma 2 till a 1A 128 this will be stored in page 1 so how many page it will require it will require 128 Pages for the complete Matrix now what happens it will ask for 128 pages but what happens only 127 frames are available in the memory only 127 frames are available this was our memory and the total number of frames are just 127 so what will happen I will store page one here page two here page three here till page 127 and page 1 128 is still store in the disk okay now let's see the programs the program said for I to 128 and for J to 128 store A J comma I is 1 so I will I will refer I'll refer 1 comma 1 first I I will set it to one then I will refer see here J is first so column will come first so 2 comma 1 then I will set it to one then 3A 1 then I will set it to one in such manner I will go till a 128a 1 and then I will set it to 1 because J is written first so column will come first so here it is column so 1A 1 will be set to one it is okay this is presented page page one and we have that page one into the memory no problem but when it will move to a2a 1 then what will happen it has to access page number two which contains a2a 1 1 a 2A 2 till a 2A 228 128 this is is page two so in this manner it will access page 1 page 2 page three till page 127 now it is turned for a 128 comma 1 to be set as one but this page is not present in the memory so what will happen it will cause a page fault and when page fault will occur this page will be brought to memory but there is no free space available so which frame will be selected as victim let let us take fif so the one who came first will be gone first P1 is removed now p128 is present so how many page fault has occurred till now we were using pure demand paging so initially the memory was completely empty so 127 page fult initially and this new page fult that is 128 page for has occurred in one cycle from a 1A 1 to a 128a 1 one page for has occurred oh sorry 128 page for has occurred in this one cycle now how many cycles it will go it will go till 128 Cycles so a now now who will come a 1A 2 a 1 comma 3 till a 1A 128 and in the next who will come this will be the next cycle a 1 comma 3 a 2A 3 till a 128a 3 this will be the another next cycle so in one cycle we had 128 128 page parts so in 128 Cycles how many page for we will see 128 into 128 so this will be the total number of page FS when we have used this the first piece of code now let's see we are using the second piece of code now let me remove all of this now we are storing like this IA J = 1 in this this manner a 1A 1 then a 1A 2 a 1A 1 128 in this manner it will be stored now so for the first cycle how many page fault will occur only one page fault how this P1 will be brought only for the for all of this 1 to 128 only P1 will be brought from disk to memory why because P1 contained all of these frames see here P1 has all of them from 1 to 128 now it moved to the next cycle it requires P2 now then to the next cycle it requires P3 now and then to 127 so from till 127 how many page fault has occurred 127 page fault has occurred and for the last for the last which this one a 12812 a 128a 128 P 128 should be there in the memory but it is not so page Vault will occur it wants to come who will go one 20 128 will come at the place of P1 We are following fif so how many page fault are there now only 128 page faults let me repeat again what happened when we are storing like this AJ comma I = to 1 then we want we want to access page in this manner first this page then this page then this page so page fault will occur for one cycle 128 page faults will occur for another cycle another page fault will occur for another page cycle 128 another page fault will occur so how many page faults occur 128 into 128 128 in each cycle and there are 128 Cycles but when we stored like this a i comma gal to 1 then for the whole cycle I required only one page for only one page for and how many for one complete cycle only one page fault has occurred and how many cycles are there 128 Cycles so 128 page faults will be there so in this way just by swapping the variables from J comma I to I comma J we have saved so much we have reduced the number of Page fors by 128 times there it was 128 into 128 now it is just 128 we have reduced the number of page FS by 128 times just by spping the two variables this is all I have written here suppose these were the two program s the program size is 128 bits and we were storing row major orders in this way it is stored it will require 128 frames but only 127 looted so how many page fault will occur with program 1 and two 128 Square page fults when we were writing like this A J comma I and only 128 page falls when we are writing like this so when we stored in row major order but a j comma I is column major order then it will increase the page f are you getting the point see we stored in row measor order but accessing in column major order that is just the opposite so it will obviously increase the page F here in IA J we stored in row major order and we were accessing also in low major order this will create low page F so I can say program 1 is 128 times lower than program 2 because number of page Faults Are 128 times more in program one than in program two and why is it so because program 2 follows locality of reference okay so now you have idea what is locality of reference how does it work just by spping two variables we made the program 128 time slower okay if we have written I comma J then the program would have8 times faster here it is slower store we storing in row major order and accessing in column major order it will naturally increase the page for we are storing in row major order and also accessing in row maor order this will lower the page for okay now it is your homework what will happen if we have a page size of 256 words and 64 words see here we had a page size of 128 words that means 128 integers can be stored in a single page now your homework is what will happen if the pay sizes of 256 words and the pay sizes of 64 wordss solve it we have seen how program can change the threshing rate can data structure do so also can data structure do the same let's see suppose we have to choose between arrays and Link list let me check if it is recording yes so which is better in case of demand page environment arrays are better how much possibility that complete arrays in the single page because the possibility that the complete arrays in the single page is more so it will cause less page for and in link list each node will be in the different page that is possible it will cause higher page fault this is just me it may cause so if in general scenario someone ask which is better array or link list in the demand page environment say array and what is the reason because it is chances that there are chances that the array may be in the single page and Link list may be distributed over the pages so arrays are more preferable in case of demand page environment linear search versus binary search linear search works like an array will cause less page Fs in binary search each node may be in the different page maybe say I have said maybe in the different page so the number of page fors will be higher so I can say linear search is better in case of demand page environment a programming technology or data structure is said to be good in a demand page environment if and only if it satisfy the locality model it satisfies the locality model so what does locality of reference or locality model says it says that it should refer those pages only which are loaded in the memory it should refer those pages only which are loaded in the memory so this is what how the way we write the pro the program or how we use the data structure or the algorithms this can significantly change the rate of threshing see here we write a program we just swap two variables and the threshing rate changed in case of data structure if we use a data structure which is more suitable in the demand page environment threshing rate may change we used an algorithm which is more suitable threshing rate may change so this is the point which I want to make that how we write program that can really affect threshing now comes the working set strategy or model to minimize page for rate and also utilize the memory effectively it works on the principle of locality of references now you all know what is locality of references take this example suppose I have main function in that main function I have this another function f in this function f I have another function G in G I have another function H and H I have another function scan F the total program size is 55 KB okay the page size is 1 KB so I will say the number of pages required to load the whole program will be 55 so instead of a static demand of 55 frames see which locality and demand accordingly this this is what the working set strategy model is instead of a static demand of 55 frames instead of directed demanding 55 frames see the locality first and then demand accordingly so when in main when you are in main demand for 10 pages only when you are in F demand two pages and there we will not need the the old pages of main when you are in this locality demand 10 pages when you are in this locality demand two pages so in this way you have to go whatever be the size of locality ask for those many frames only so this will create less page fault rate and better memory utilization let me repeat again see in which locality you are and ask for that many page only this is the point it will lead to less page fault rate and better memory utilization it controls the page fault and utilize effectively uses locality of reference which is dynamic frame allocation estimate the size of locality in which the program is executing and demand and demand those many frames suppose this is the process this is the reference string 45 8245 the large reference string till 56 and it goes on now a new term comes that is working set window and this is defined at a particular time have you learned about sliding window window protocol in computer networks this is similar to that so we have a working set window at a time T what is working set window set of unique Pages referred in the reference string during the past Delta references and this Delta is some integer so during the past let's say Delta B5 so during the past five references set of unique Pages referred in that reference string that is working set window let's say three unique Pages refers to working set window sizes three at that time to okay did you get it check for the number of unique pages in the past Delta references in the reference string that will be the size of working set window at a particular time T and this working set window is a sliding window it slides working set window at time T at when I say Delta equals to 10 so how many unique pages are there so past 10 references 1 2 3 3 4 5 6 7 8 9 and 10 so from here to here how many unique Pages were referred that is what the working set window size is how many unique Pages 19 51 52 53 54 56 58 so these are the unique ones so I will say 1 2 3 4 5 6 7 so the working set window size is 7 so right now we are in the locality which is defined in terms of seven pages ask operating system to give seven frames this is how your going to estimate the size of the locality and we'll ask the number of frames accordingly so is the system threshing or Not by this framework if we are using this framework is the system threshing or not let's see so the number of process we have is n the total available frames let's say m and the demand for each process for frame SI the number of uh the size of working set window the total demand at time T will be add all the demands it will give you D the number of processes are n total available frames are M the total demand is D and the demand for each process for frames is determined by how by finding this working set window this that's how we demanded the number of frames so if demand is somehow equal or approximately same to the number of frames available then no threshing if demand is less than the available then no threshing we can still increase the degree of multiprogramming see demand is less available is more than no threshing here if we increase the multi now at that point we increase the degree of multiprogramming chances of threshing will rise at this point when available are greater than the demand then the system system is in ch State no threshing increase the degree of multiprogramming we are good but if demand is is more and the available frames are less then I will say the system is threshing okay the whole success of this working set strategy model depends on Delta let's say the ideal value of delta is 10 which means if you are taking 10 as the delta in which you are looking on to the past 10 references from Delta you are going to set the working set window or the sliding window size let's say the ideal value is 10 now you set the value of delta to 2 and in another case you set the value of delta to 10 it is not 10 it is greater than 10 ideal value is 10 so it should be greater than 10 suppose it is 16 okay now if Delta is two then it will leads to more page fault and if Delta is more then ineffective memory utilization because what does Delta says Delta says according to Delta only the working set window size is defined and that many pages or that many frames are demanded from the memory if Delta is more than wsw will also be more then demand will also be more ineffective memory memory utilization will happen if demand is more then the system may lead to threshing and if Delta is less if Delta is less then number of frames demanded will also be less the ne the necessary frames let's say are 15 but you selected so much less Delta that you want to get 15 frames but you ask asked for only three if the number of frames are less so much less then obviously this will lead to more page ports so the whole success depends how you choose the Delta value let's solve this question it says let the page reference and the Delta B this is the page reference and the Delta B4 respectively the initial working set at a time tal to0 contains the pages a d e where a was referred at time tal to 0 D was referred at time tal to minus1 and E was referred at the time tal to min2 determine the total number of page fault and the average number of page frames used by Computing the working set of each reference so with the end of this question you will get a complete idea how this working set model work so we have a reference string this c c d b c e c e a and d and Delta four the initial working set was e d and a this is the current time this is 1 second before the current time and 2 second before the current time this was the working set at time zero so you have to find the number of page fults we have what we have to find determine the total number of page fault when average number of page frames used by Computing the working set at each reference okay so we will find the working set window at every time initially we had e d a only initially we had EA only and the reference string is c c d the reference string is CCD so at Time 1 this is at the time zero at time let's say t = to 1 C is demanded what will happen page fault will occur so the wsw at time one will be look at the past four why four because of this Delta is four look at the past four reference and select the number of unique pages and include that in your wsw how many unique Pages EAC so edac will be included what is the size four is the size okay so we have to calculate the number of page Cs and average number of page frames so for average we will see for each and every reference and then we will calculate the average so for time equals to 1 we had four in our W WS W now at time equals to 2 C is again asked what will happen look at the past four look at the past four see this the working set window slided see at the past four now how many elements will be there C already there A and D so C A and D the duplicate won't come as I said unique number of uniqu here where I have defined this W and W set of unique pages so if repeative or multiple coming then take only one so the distinct will come here c c a d won't be there only c a d so the number of uh elements in wsw is three now for time three which means now we are asking for D is D present yes D present no page for so what will be the uh wsw size d c and a so d c and a at time four at time four who will be asked B is asked is B present no B is not present so who will come b d and c b d and c will be in the wsw now see here page fault has occurred here keep count of page fault also because we have been asked with total number of page fault and average number okay so at C this at here C already present D B so we have b d and c c already present that's why we didn't included it again now now here at time = to 5 this c b d already present no it won't come again so we have three in WS W tal to 5 in this way we will keep on going we'll keep shifting our window and we'll again shift our window to here now e c b d will come e CB D will come now we'll shift our window again c e c e b will come so we'll have three there now at T = to 8 c and e will there only so e and C are this this this and this how many are distinct only two are distinct so two will come here now at 9 a e c will be there a e c will be there 3 at time 10 d a e c four will be there four is there so now add all of them 4 3 3 3 3 4 3 2 3 4 and divide it by 10 you will get the answer the average one now the number of page faults first page fault second page fault third page fault fourth page fault and fifth page fault so the number of page fault occurred was five and average you you calculate I have given you the formula add all of them and divide it by 10 now we are starting our new section that is file system we have successfully completed our memory management and after file system the operating system is over we will take our miscellaneous topics The Leftovers okay if you notice one thing about file system it is the only visible part of operating system you want to know how file system looks let me show you this is the file system we have devices and drivers then we have so many files in there directory in there there are program files okay so this is what the file system is let me close it it is the only visible part of operating system so we have CPU we have disk CPU is an electronic device disk is an electromechanical device so there is surely an architectural difference to harmonize that we would require a interface card or interface chip then we have device driver which is a device specific software then comes the OS which contain file system and device manager which works interactively so this was just the theory now comes the important part that is disk physically structure look at this diagram first we have a spindle and then e the spindle is associated with four platters we call them as platters you can see the circular structure this is platter each platter has two surface the upper surface and the lower surface the upper surface and the lower surface the lower surface in this diagram you cannot see but suppose a dis type structure and the disc has the upper surface and lower surface okay see here this is the spindle and it is associated with platters the circular structure or oval structure whatever you call then each platter is associated with two surfaces the upper surface and the lower surface till now it's clear now each surface is divided into tracks you know the race tracks in the similar way so each surface is divided into tracks each track is divided into sectors see this each track is divided into sectors so this sector or block is the unit of data transfer generally measured in bytes so when we transfer data we we transfer the data in terms of sectors and this sector is the unit of data transfer so what we have learned till now there exist a spindle spindle is associated with platters each platter has two surface the upper surface and the lower surface each surface is divided into tracks each track is divided into sectors okay this spindle can rotate this spindle can rotate each surface is associated with a read right head the so for a letter I will say there is upper re right head for the upper surface and lower read right head for the lower surface and read right has is head is connected with arm assembly which can move forward and backward so this arm assembly can move forward and backward the spindle can rotate so this read right head can this readr head can move to any sector it want see the spindle can rotate and the arm assembly can move forward and backward so it can easily or freely move to any sector which it want okay now let look at this diagram this is our read right head this is the spindle this is the disc actual disk the saved file in sectors the actuator and then we have circuit board used for the on and off of the disk we have the ARM device configuration Port data cable Port power port Etc so this is what the device or the dis looks like look at this diagram we have arm assembly we have a spindle in spindle we have platters and each platter is connected each platters have two surface the upper surface and the lower surface each surface is divided into tracks and if I select the same track number from all the surfaces and join them with imaginary line then I got a cylinder so this is the cylinder consisting of same track number okay so this is a platter this whole dis is the platter it has this the circular part is the platter it has the upper surface and the lower surface each surface is associated with number of tracks each tracks is divided into number of sectors see this is one sector this small part this is one sector and the spindle can rotate the arm assembly can move forward and backward so that this read right head which is associated with each surface each surface will have its own read right head so that readed right head can move freely to whichever sector it wants to go okay so if we view the same track on platter we get a cylinder and number of tracks will be equal to number of cylinder this is the obvious thing now same sector on all the tracks we call it as dis sector see here this is this is the platter surface the surface is divided into number of tracks and if we select and track is divided into sectors and if we select the same sector number over all of the tracks this sector in track one in track two in track three in track for I chose the same sector number in all of the tracks then what I get I get the dis sector okay so this blue shade you can see is one track and if I select the same sector number over all of the tracks then I get the disk sector and if I select the adjacent sectors over over the track then I get a cluster a group of one or more adjacent sectors so uh let us see here in this diagram this was the track in which it divided into two sectors so if now I select this and this also then I get a cluster this will become one cluster okay now let's see the whole thing we had a disk disk has platters each platter have two surface surface is divided into tracks tracks are divided into sectors and each sector is associated with two attributes the sector number and the sector size the sector number will be in the bits 2 ra to power that number of bits will give him the total number number of sectors and the sector size will be each sector or the smallest unit of data transfer be will be that sector or how many bytes can be transferred at one go okay now comes the disk iio time what is the dis iio time the time taken for the data transfer but for data transfer the data is in the certain sector but it is possible that my read right head could be at a different track it is surely possible so what we have to do in dis IO time we have to select three things the first will be the seek time what is seek time my read WR head can be at a different location so from this track number one see this this is the track number zero this is track number one track number two track number three track number four and this is track number five and this is the sector which I want to read but my read write has is is in track number one so to move from track number one to track number five here this will be the seek time and how will I move there with the help of with the help of arm assembly so from one track to another I go then it will require one seek so head have to make four seeks from track number one to reach at track number five how many SS will be made from track 1 to track five four SS will be made okay okay now comes the track track time what is track track time the time taken by the read right head to move from one track to another it is same as the it is same as the one seek time so the time taken by read right head to move from one track to another just the adjacent one see if I moved from track number one to track number two then how much time will be taken that is track track time that will be the the time taken for one seek one track to another that is one seek time and here I have to make four seeks so four into I should say track track time or one seek time okay so if I have to the time of one seek is actually the track track time and the time taken to move from track 1 to track five or the track which you are in the source to destination track that is the seek time so here total number of seeks how many seeks we have to make 4 six and track track time so track to reach minus current track number so 5 1 will be 4 so we have to make four seeks into time of one seek that is track track time this will be the seek time see what was this Sky time the time taken to transfer the data but data can be in the different sector from the current position of R head rri head see here the read right head is present here but the data is here so what I'm going to do I'm going to firstly move this red right head to that current track it may be in the different track we have to reach to the different track in which of uh in which the sector is present which has our data so firstly we had a seek time we move to that sector so track to reach minus current track number into track track time now we are in that track which contains our sector now what will happen we have to rotate the spindle see here spindle can rotate the spindle can rotate and this arm assembly can move forward and backward so from in the SE time the time taken by arm assembly to make to move the read right head from the current track number to the desired track number that was the seek time now it is time for spindle to rotate and see here firstly it was here now the position has changed to here but still it is not on that sector we were on a different track we reach to the same track but now we are on the different sector we have to reach to that same sector so the time taken we need to rotate it so that the sector comes under the head we need to rotate this in this way so that this will move and will come under the re right head the time taken for this is what we call rotational latency and it is generally taken as R by2 what is r r is the time taken for full rotation and it is made measured in RPM so the rotational latency is taken as r by2 r is the time taken for full rotation so rotational Lance is time taken for half the rotation why we have taken the half because generally it takes around half the rotation for the sector to reach to that current head okay now this is the position firstly we were at a different track our sector was at a different track then we reach to the same track but not at the same sector now what we did we rotated it and the sector has come under the head now what will happen the transfer time will also be there see firstly we were not at the same track seek time was taken to reach at the same track then we were not at the same sector rotational latency was taken to reach to the same sector now transfer time will be the time taken to transfer the data amount of time taken by read right head and transfer the data to the disk buffer so what will be the transfer time it will be the sector size upon track size into R the sector size upon track size into R this is what the transfer time is so the dis IO time will be seek time rotational latency time plus transfer time remember this is it is an important Concept in the last lecture we have seen the seek time the rotational latency time and the transfer times when some sub gives the disio time we have seen the seek time was the time taken by read right head to go from current head to the desired head that is seek time rotational latency time was R by2 what was R the time taken for full complete rotation what was the transfer time sector size divided by track size into rotational time okay see rotational latency is different from rotational time rotational time is R rotational latency is R by2 okay now comes the data transfer rate disk transfer data from rate this much Zed by r k b one track is transferred in one rotation one track is transferred in one rotation so in 1 second how much data will be transferred Z by R KB why KB because we are keeping this rotational time in milliseconds okay now let's see this question consider the following disk specifications we are given with number of platter 16 so there is a dis in which there are 16 platters in such manner There are 16 platters and you know that each platter has two surfaces the upper and the lower one number of tracks per surface this is one track this is another track another one in such manner there are 512 tracks per surface number of sectors per track this is a track this is one sector another sector another sector another sector in this manner there are 2048 sectors in each track the sector offset is 12 bit which means the sector size is 2^ 12 bytes average seek time is 30 millisecond so the time taken by read right head to reach from the current to desired is 30 millisecond dis RPM is 3600 so I can write in one rotation or 3600 100 rotations are there in 1 minute or 60 seconds so in 1 second or one rotation will be in how much time 60 divid 3600 seconds this this will be uh this will be the time taken for one rotation so 60 divid 3600 seconds and if I want to calculate in milliseconds then multiply by 1,000 1 2 1 1 2 1 now there are 6 the 600 divid 36 6 100x 6 this will be the time taken for a single uh rotation this is 16.67 16.67 seconds are taken for one rotation then how much time for okay so we are asked with the first is unform capacity of disk we have one disk which has 16 platters each platter has two surface each surface has 512 tracks each track has 2048 sectors and each sector has a size of 2 12 bytes so this will be the unform capacity so when you multiply all of them you get 2^ 37 which is 128 GB the second question is IOS time per sector we'll have to add seek time rotational latency time and transfer time seek time is given as 30 Mond rotational latency time will be R by2 so we had R = to 16.67 so R by2 will be around 8.3 and now we have to calculate the transfer time what was transfer time sector size upon track size into R so I can write transfer time as this is 1 by K so K will be K will be sector size upon track size into R so in this manner you will get the transfer time from where you will get the sector size you have each and every data is with you from there you will get sector size the track size and then rotational is given with you now the next is data transfer rate what is data transfer rate track size upon rotational latency not latency rotational time rotational latency is 1x2 which is R by2 is rotational latencies R is the rotational time so what is data transfer it Z by R Zed is the track size and R is the rotational time kb per second so from there you will get5 GB per second as the data transfer it one track is transferred in one rotation then in 1 second how much track will be transferred or how much uh data will be transferred okay now the next is sector address so we have to find the sector address in bits how are we going to find log to number of sectors so we find that total number of sectors are 2 by 25 so there will be 25 bits for the sector address and 12 bits for the 12 bits for the sector offset so these 25 bits will take me to the correct sector and these 12 bits will take me to the correct word okay now let us divide this also four for the PLS we have 16 PLS one for the surface we have two surfaces nine for the track we have 512 tracks and number of sectors are 2048 so I can write this as 2 into 1024 which is nothing but 2 into 2^ 10 which is 2^ 11 so 11 bit for the sectors so this will be the total address and sector address will be this one this these 25 bits will take me to the correct sector and these 12 bits will take me to the correct word so sector address in bits are just 25 bits these are the sector offset this will be the total address okay next question consider dis with the following specifications number of surface we have 64 now the surface is directly given outer diameter is 16 cm so outer radius will be 8 cm inner diameter is 4 cm so the inner radius will be 2 cm inter TR distance is1 mm so we have a distance for track is this 6 cm which is 8 2 this is 6 cm and the inter track distance is1 mm so I can say 6 cm divided .1 will give me the number of tracks per surface maximum density is given as 8,000 bits per CM calculate the unform capacity of disk okay so the question is we have to calculate the capacity of the dis surfaces is already given we have find the total number of tracks per surface so these will be the total number of tracks all over the disk now if we can find the track size then I can tell the unform capacity of the dis but you know the track is of different sizes see this is the track innermost track and this is the outermost track innermost track is less than the outermost track you can see it but also we are keeping the size same how can we do that by using wearing density track length in centimeter into density but we had maximum density given is 6ou what was the maximum density I think 8,000 so 8,000 bits per CM 8,000 bits per CM so where will be the maximum density used in the innermost part because see this length into density will give me the size we have to use the maximum density when length is less and minimum density when length is maximum see this length into density should be constant density will be maximum when length is minimum and density will be minimum when length is maximum so where we will use this 8,000 we will use in the inner track so what is the inner track distance the radius is given 2 pi r is the circumference so 4 Pi cm is the inner track distance what will be the track capacity 4 Pi into 1 KB this is the 8,000 bits are 1 KB 1,000 will be 1K and and this 8 will be for byte bit to byte conversion so this is 1 kilo bits multiplying with 8 will give me 1 kilobytes so 8,000 bits are 1 kiloby so the track capacity is of 4 Pi kilobyte the surface capacity is 600 into 4i kilobytes which will give me 12.56 kiloby and the disc capacity will be surface capacity into number of surfaces which will give me 48 GB around five around half GB did you you get it let me repeat again so what we had in the question we have to find the capacity of the dis but we were not giving with the track size we find that total number of surface we have 64 number of tracks we have 600 but until we do not find the track size we cannot proceed so for track size we are given with maximum density but now the question is where we will use this maximum density in the innermost part or the outermost part because the track size is same that is undeniable and you can also see that innermost part innermost track will less than the outermost track and we are keeping the size also same and how can we achieve this by using weing density okay now we know that length into density will give me the size and this should be constant so and we are given with maximum density so where we will use the maximum density in the innermost rack because in the innermost track length is minimum that's why we are using the maximum density so from there we get in each track we have 12.56 KB of data and there are 600 tracks in the surface so we get the surface capacity from here and for this capacity we have 64 such surfaces so we'll multiply the 64 into surface capacity from there we get 48 GB how long does it take to load a 64 kiloby program from a dis so we have to load a 64 kilobyte program from disk to memory okay average seek time is 30 millisecond rotation time is 20 Mill so rotational latency will be 10 millisecond track size is 32 kiloby page size is 4 kiloby assume that Pages the pages of the program are distributed randomly around the disk okay so firstly we have to calculate the time which will take which it will take to transfer 64 kilobyte program from disk to memory okay how many pages does it have 64 / by 4 it has 16 pages and what will be the transfer time for one page so firstly we have to go to that page 30 millisecond and then rotational latency and then transfer time in one rotation one track is transferred so in one page will be transferred in how much time one rotation divide by track size into page size so Pace size divide by the track size into rotational time so from here we get the time taken to load one page from disk to memory is 42 millisecond so the time taken to load 16 pages will be 680 millisecond now comes to the part two what will be the percentage saving in time if 50% of the pages of pro program are contigous so if 50% of the pages of program are contigous which means out of 16 pages eight pages are continuous and eight pages are randomly distributed so for random distribution 42.5 will be multiplied with 8 to get uh 340 milliseconds so 340 milliseconds will be taken to load these random pages into memory now what will happen for these eight pages which are continuous see if these eight pages are which means all the page belong to same track so seek time will be 30 Mill 30 Mond which means the read right head is now on the track which has all the pages rotational latency will be R by2 now the readr head is on the first page plus transfer time of eight pages see here this is the time taken by read write head to go to the track which contain all the pages this is the time taken by read right head to reach to that uh to reach to that the position where first page is there now all of the pages are contigous so no need for another seek time or rotational latency we'll just transfer them back to back so this will be this will come just for one time and then transfer time for eight pages so this will cause me this is the how much time it took it took 60 and 340 for that eight random Pages 340 for 8 random pages and 60 millisecond for continuous pages so the total was 400 millisecond initially the total time taken was 680 in the case when when all pages were randomly distributed so the percentage saving is 480 6 680 mod divide by 680 here we get around 41% saving in time so what will the percentage saving in time 41% if 50% of the pages of program are continuous okay let us uh let let me read this question again and explain to you again what happened here we have to calculate the time taken to load the program from disk to memory and the program has 16 pages so we'll calculate the time taken to load one page and multiply it by 16 as it is said that pages are distributed randomly around the disk so for each each page seek time will come for each page rotational latency will come for each page transfer time will come as it is written there it is randomly distributed around the disk so for one page load time we found it to be 42.5 millisecond so the 16 page load time will be 680 MC the part two of the question says what if the eight pages are continuously there and eight pages are randomly distributed so we will multiply this 42.5 the time taken to load one page into eight pages for random distribution so we got 340 MC for transferring those pages which were randomly distributed now the pages which are Contin continuously distributed or continuously present continuously present then seek time will be there to for read right head to go to that track rotational rency will come for read WR had to go to that page where the contigous uh allocation has started or I can say the read WR had to go to the first page of those continuous Pages now eight pages are back to back so I will transfer them back to back no need for another seek time no need for another rotational latency from there I got 60 millisecond so the total is 400 millisecond only when eight pages are continuously there and eight pages are randomly distributed now we have to calculate the percentage Time Savings so this is how we calculated and we got 4 1% rotational Laten is taken into account only once when the pages are continuously distributed over one track because the read right head of the disc need to wait for dis to rotate to the correct position only at the beginning of read operation so in case of continuous allocation there will be only one rotational latency account once the first page on the track is being read the rest of the pages on the same track can be read in continuous sweep as the dis rotates this is because pages are laid out continuously on the disk so there is no need for disk to rotate multiple times to different position to read each page why because of discontinuous distribution therefore time taken for dis to rotate to the correct position is only occurred in Ur incurred once at the beginning of read operation that's why R by2 is taken only once at the for the beginning thing when the read R head will reach the first page after that read that head can continue reading the rest of the pages on the track without additional rotational delay okay an application require 100 libraries at startup each Library require one dis access seek time is 10 millisecond dis RPM is 6,000 all 100 libraries are at random locations 50% of the libraries require transfer time of half rotation while for remaining 50% it is negligible how long does it take to to load all the libraries see we have 100 libraries and each Library require one dis access so for 100 libraries we have 100 disc excess seek time is given as 10 Mond disc RPM is given as 6,000 so the rotational time we will calculate it 60 second is taken for 6,000 rotations so for one rotation how many seconds will be taken 10 milliseconds will be taken so one rotation can be incurred in 10 10 milliseconds only now it says for 50 libraries transfer time is of half rotation which is 5 millisecs and for another 50 libraries the transfer time is negligible it is close to zero so for set one for 50 libraries we have 5 millisecond and for set 2 we have zero so the time for set 1 will be 50 into 10 + 5 + 5 millisecond 1000 milliseconds and for set two we'll have 15 into SE time rotational latency and zero as it is written that transfer time is zero so the total time will be 1.75 second we will add both of them now here it is not written that they are contigous that's why we have taken into account every time for each dis access like in the previous question if contigous word would present then we will take the seek time and rotational latency only once okay in the next lecture we will learn about logical structure of disk we were learning file system it was the only visible part of operating system we have learned about disk physical structure we have learned what was arm what was platter sector track spindle spr right head all the all these terms we have learned we have learned that in one disk there are several patters each platter has two surfaces each surface has tracks track is divided into sectors sectors can be reached the firstly we have to to reach to the correct sector from where we will get the sector number so sector number will help us to reach to the correct sector and sector size that is the sector offset will help me to reach the correct word okay we have seen dis IO time which included seek time which included seek time rotational latency time and transfer time we have seen the data transfer rate was Z by R KB then we have send some numericals which included to calculate unform capacity IO time data transfer and sector addresses then we have seen that L into D remained constant so when I will use the maximum capacity for the innermost so this was the main concept in that in this question what we did we saw that if eight eight pages are contiguous then there is no need to include SE time and rotational time rotational latency again so if in case of contigous allocation rotational latency will be included only one time okay so this was all we have learned Now we move to The Logical structure of the disk or formatting process so for the to explain this I have a nice example take example of your College library that building of the library or the library place can be said as disk and books can be analogical to data now suppose if I just dump thousands of books in the Library without having proper bookshelves Etc I mean without any proper Furniture then searching becomes horrible suppose in library there are no bookshelves there is no such kind of furniture to store the books I just dump thousands of books or lcks of books in that place in the library building then searching a particular book will become horrible for you so Library without bookshelf is raw disc and library with furniture is formatted dis formatted dis has a benefit of effective storage and faster retrieval now whenever you visit computer labs so for different classes we have different operating system in the same computer for when we used to study C programming so in the same computer we used to study on ubben 2 and when we used to take the computer organization architecture class we used to open the windows software so the operating system first when we used to uh study the cyber security in our computer labs we used to work on K Linux so same computer has different different operating system how is that possible with the help of partitions in the disk so this is what we call multi boot computer it is generally done at the computer labs for teaching purposes so this here is the dis it is divided into several partitions which contain operating system 1 operating system two and operating system three each partition contain a different operating system but if you are thinking that you can load two of the operating system at the same time into the memory this is not possible at a time either one to will run or Windows will run or k Linux will run at a time only one will run so I can say at a time one will be loaded okay so dis is divided into partitions there is one primary partition and some extended or logical drives see when you use to open your this PC when you open this PC then you can see several drives in there like C drive or D drive e Drive F Drive G drive so the C is the primary which contains the bootable data which means our operating system it contains extra data on software also but basically why it is known as primary because it has the bootable part what is bootable part we will see later and this extended or logical drives this contain all the non bootable data like your songs video games or your softwares all these things is here in the extended logical drives here you can see in os1 MBR is the written what is MBR Master boot record this is generally on the first primary partition it contains partition table and boot loader partition table contains the information about the partition so don't worry here are just the steps how the or I can say how your computer starts these are the steps so firstly we switch on after switching on the power comes in so this PD is the power on self test which test that all are all the devices electronically active this is just the hardware test so you can see when you start your computer all the three lights or numb lock page scroll and those lights just blink or in the modern laptops the light over the cap loog or the light over the mute button blinks so this is the power on self test then comes the BIOS basic input output system initializes input output device including the disk so firstly when we switch on power on self test occurs what is power on self test it checks whether the devices are electronically active this is a hardware test then what happens bios happens it initializes the input input output devices including the disk now bootstrap what is bootstrap small booting program what it does it loads the master boot record into the RAM and hand over the control to boot loader so this MBR this MBR is loaded into where it is MBR loaded into RAM okay then what happens boot loader reads partition table and display options if available so if you remember when you start your computer uh or in the lab then you can see the different options which options you select two or k Linux or the windows these three options you can see so you can with the help of the arrow down you can select any of the operating system and choose that to start so boot loader will load the kernel program from the dis into the memory then execution of the kernel will load other operating system modules into the memory like dispatcher virtual memory manager all these things will be loaded firstly what happens power on when you power on then power on self test is occurred which checks are all the devices electronically active then bios test happens it check it initializes the input output device then bootstrap it is a small booting program which does what it brings the MV into the main memory and then what does MBR do MBR has boot loader and partition table so the boot loader reads the partition table and display the options like operating system one like Windows or k Linux or one2 which you want to select now you select K Linux then what will happen boot loader will load the kernel program from the dis into the memory of that operating system of K Linux and the execution of that kernel will load the other OS modules like dispatcher or virtual memory manager into the memory so this is how the operating system comes into the memory so this was the booting process firstly what happens you power on after power on the power on self test occurs then bios happens then bootstrap come when boot strap is executed it brings the MBR into the memory when MBR is brought then the boot loader from the partition table which which will let you choose which operating system you want to bring to the memory then the kernel will be loaded and the execution of Kernel will bring bring other programs like uh dispatcher and virtual memory manag into the into the memory and then finally the operating system which you want to choose will be brought from disk to the memory this is what booting is bringing the operating system from disk to memory now we will learn about the partition structure what infrastructure are embosed on the disk partition after formatting so we have here is the partition one the second part partion let's say this is hard disk so the first one this part is MBR the second part is first partition boot sector the third part is file system area of first partition and data area of first partition so the data area of the first partition is just this much and the rest of the space like is is taken up by MBR the first partition board sector and the file system area of first partition that's why you may see you may have seen that uh let me show you see my laptop has a specification of 512 GB SSD and 16 GB Ram so if I click on this uh this PC see here I get only 475 GB of free space but I have purchased a 52 GB SSD then where is all that remaining what is the remaining 512 minus 475 where is the 30 37 GB the 37 GB is used up here in the MBR in the first partition boot sector in the file system area of the first partition here is the more clear way of partitioning see we have these data blocks down there then we have directory structure partition control block and boot control block data blocks you all know will contain the applications and other operating system files these will include your GTA Y game this will include your Microsoft Word Google Chrome all these things will be included here this this is the directory structure what is directory structure let me show you which contains the files and folders that is what directory structure is these files and folders this is what the directory structure is there we click and I get this I get this this is what the directory structure is then PCB what is pcv partitioning partition control block it gives complete picture of partition just just like the administrative block and what is boot control block it is the sector of partition that contains the boot program the first OS program initial or uh initialization program or kernel the boot block will contain Unix or Linux and partition boot sector will conol Windows this is how the multi booting or multi boot computers are made okay let me repeat firstly we have in a disk we have partitions the primary partition contain the master boot record which contain partition table and boot loader so firstly when we switch down our computer we have power on self test after that we in power on self test we check are all the devices electronically active then we initialize the io devices then bootstrap this bootstrap when executed in the CPU this will load the MBR Master boot record from disk to the main memory which contains boot loader and partition table so boot loader will read partion table and display options to choose which operating system would you like to bring into the memory from disk then after the taking input from the user then boot loader will load the kernel of that program from disk to the memory and this is how and then execution of that kernel will bring the other modules into the memory then we see partition structure it contains it contains the boot control block partition control block directory structure and data blocks data blocks contain the application directory structure I have shown you what is directory structure partition control blocks give the complete picture of partition just like the administrative block and this boot control block it is the sector of partition that contain the boot program like the first OS program like the kernel the boot block will contain the Unix or Linux and the partition boot sector will contain the windows us this is just an example okay in the next lecture we will see the file versus directory let's learn about File versus directory what is the difference between file and directory let me clearly tell you directory contains the information about files not the actual data now comes the question what is file file is nothing but an abstract data type just like a process process has process was also abstract data type which has its own definition representation operations and attributes you remember that similarly file also have the all four it has definition what is the definition collection of logically related entities or records the representation it can be either flat or it can be either hierarchial flat means just the series of bytes and hierarchial means the higher level implementation like B trees or B minus trees B plus B minus trees in that manner operations like create modify open read truncate attributes name extension Owner Mode blocks in use blocks in use means in which block the file is present so these are this is what the file is and what is directory directory contains the information about files okay now let's see it formally representation representation or structure flat or record flat means series of bytes record means series of Records like in hierarchial tree it is the higher level implementation operations are create open read write seek truncate and attributes name extension type Owner Mode size date and time permissions Block in use which means in which block the file data is stored I'm talking about the data blocks in the partition structure attributes of the file are stored in file control Block in in Linux we call it as inode and in Windows we call it as directory entry so every partition contains directory structure here is the directory structure so every partition has its own directory structure what is directory special file which contains data about other files it contains the metadata what is metadata information about the data or data about data this is metadata so it contains metadata of files not the actual data the directory does not contain the actual data of the files it just contain the metadata so this is what a directory entry looks like it is a linear onedimensional array see this is the directory entry let's say these are the blocks in which the file is stored so it tells that file one is stored in this block file two is stored in this block file three in this one and four in this one in this manner let's now see directory structures the first one is single directory structure for for all users we have kept each and every file in the same folder it is simple to implement but as you know lots of searching time will be there secondly naming config problem in the same in the same directory you cannot have two files with the same name even if you try to store it it the one like here the one will be automatically added let's say you have a movie do mp4 file already present if you try to store the same file again then one will be automatically added you cannot store the two files with the same name in the same directory so this is what the naming conflict problem is and bad organization well that's the thing so the single directory for all users mean we have kept every file in the same folder okay so what is the uh Advantage the advantage is simple to implement and disadvantages it will take lots of searching time naming conflict problem plus bad organization two level director separate directory for each user for each user we have a separate directory this is what two level directory is efficient searching and path is involved now see for user one we have another directory which contain these files user two we have another directory user three another directory so what is two level directory separate directory for each user efficient searching and path is involved now we can have same file for different user you know that we can have this movie. MP4 in with same name we can store in store it in different folder this is possible that's what we are seeing we can have same file name for different users but there is no grouping capability which means if we wanted to keep some files separate that is not possible multilevel directory the more advanced version it is sub directories within the other directories sub directories within the other directories like we have the root directory then we have some other directories then in this directory we have other directories in this directory we have more other directories so directories within directories or sub directories within other directories is what multilevel director is it can be either in the tree structure or the general graph directory what is tree Str what is the difference between tree structure and graph directory in tree there is no kind of cycle present but here you can find the cycle from here you can go to this book to every and from a you can go again back to book so in general graph directory we have cycles and what is this directed directed a cyclic graph it is used for file sharing how many links are pointing to the shared file this is the file sharing suppose in this there are two links pointing to the same file so I will say link count of this file will be two and as you know this is a graph so for searching uh for searching a file we may have to Traverse the directory for that so we know that there are two famous algorithm depth for search and breadth for search directory has a file support operation a special operation on directory which is not performed on a regular files daverse in files we do not have such kind of operation if you go there and see the list of operations there is no such kind of operation in file you can either search uh wherever you want in directory so in directory there is a special kind of operation which means daverse daverse mean you can search in the whole directory for a specific kind of file so this is what it's written here so directory as a file support this Traverse operation it's special kind of operation which is not performed on regular files now comes this question the question is consider a list of linear list based directory implementation in a file system each directory is a list of nodes where each node contains the file name along with the metadata such as the list of pointers to the data Block in this manner consider a given directory Fu so we have a given directory Fu which of the following operation will necessarily require a full scan of f for successful completion the first is opening of an existing file info if I want to open a file let's say I want to open F2 do I need to scan the whole uh do I need to scan the whole directory f for just opening a file there is no need let's say I want to create a new file let's say I want to create F5 but I want to name it as F3 I don't know that there is F3 below somewhere I just coincidentally name it as F3 what will happen it will say there is a file with the name F3 already exist do you want to replace it or give it a new name so this error will generate how this error will generate because as I create a new file and name it the whole name of the file in that food directory will be scanned such that there is no there is no file present already with the same name so to ensure that there is no naming Conflict for creation of file yes the all the file will be scanned renaming of existing file same concept yes naming conflict may arise deletion of an existing file from F no there will be no uh need to scan the whole folder through for just deleting so for opening and deleting no need for creation and renaming yes we have to scan the whole folder in the next lecture we will learn about file system implementation now comes the file system implementation look this lecture is going to be way too theoretical so I'm just going to read it all okay the file system is implemented in the layered fashion we have application programs at the top the core file system and the io control and devices the applications this application this execute the input output statement and The Logical file system this one uses directory structure to provide the file organization module with all information this logical file system it uses the directory structure to provide the file organization module this is the file organization module with all the information so initially we have application programs which executes the input output statements this logical file system uses that directory structure so that it can give information to file organization module this handles the files and their logical blocks and physical blocks the file organization handles the logical and physical blocks physical file system issues IO command to the device driver to read and write physical blocks on the disk issues IO command to the device drivers this IO control consist of device drivers and hand and interrupt handlers and then comes the devices which perform the actual eye operation so let me read again application execute input output statements then comes the logical file system it uses directory structure to provide information to file organization this file organization handles the files and their logical and physical blocks logical and physical blocks and this physical file system IT issues IO command to device drivers to read and write physical blocks on the disk and and these devices are the are the one who actually performs the I operation okay these devices include Hardware dis or controller cards Etc the io control level it consists of device drivers and interrupt handlers to transfer information between main memory and disk system a device driver can be thought of a translator which has input of high level language like retrieve block 123 and the output consist of lowlevel Hardware specific instructions the instructions specific to Hardware that are used by the hardware controllers which interfaces the io device to the rest of the system okay so the iio control level consist of device drivers and interrupt handlers to transfer information between main memory and dis dis disk system this device driver is a kind of translator which takes the input as high level language like retrieve block 123 and the output consist of lowlevel Hardware Specific Instructions which interfaces the io device to the rest of the system those instruction are used by Hardware controller then comes the basic file system basic file system need only to issue generic commands to the appropriate device driver to read and write physical block on the disk each physical block is identified by its number by its numeric disk address for example drive 1 cylinder 73 track 2 and Sector 10 so each phys physical block what is a physical block sector it is identified by its numeric disk address as we have talked about it the sector address and the sector offset this will give me the address of the world so this is the sector address and it goes like drive 1 cylinder 73 track 2 Sector 10 this layer also manages the memory buffers and cash that hold various file system directory and data blocks okay now comes the file organization module I know it's both but I have to read it all file organization modules know about files and their logical blocks as well as physical blocks by knowing the type of file allocation used which type of file allocation is used and the location of the file this file organization module it translate The Logical block address to physical block address for the basic file system to transfer the file organization module knows about the files and their logical blocks as well as the physical blocks by knowing the type of file allocation used and the location of the file the file organization can translate The Logical I think the same thing has been copied again a translation is needed to locate each block the file organization module includes the free space manager which tracks unallocated blocks and provides these block to file organization module when requested so this is just the theory logical file system manages the metadata information the metadata include all of the file system structure except the actual data as you know metadata is just the data about data not the actual data logical file system manages the directory structure to provide the file organization module with the information of later needs given a symbolic file name it maintains a file structure via file control blocks a file control block FCB anode in Unix file system contains information about the file including ownership the permissions the locations of the file and the contents let me summarize so we have a layered file system implementation it includes application of the programs then comes logical file system file organization module and basic file system this is the core part you can uh read about it here in these paragraphs okay then comes the io control and devices application execute the input output statement logical file system uses directory structure to provide the information to file organization it handles their logical and physical block addresses then this physical file system issues IO command to the device drivers this IO control consist of device drivers and interrupt handlers and these devices are the one who performs the actual ey operations in the next lecture we will see allocation methods let's learn allocation methods methods for allocating disk space to files directories or any other data structure we had this kind of disk parage it included BCB the PCB directory structures and here it was the data blocks which contained the user data so the data blocks these are numbered like this there are two properties of data blocks their address and their size the size will be in bytes and the address will be in bits 2 to power DBA will give you the total number of dis blocks in the in this area so DBA equals to 16 bits so there will be 2 power 16 blocks DBS equal to 1 kilobyte so if someone ask you maximum possible size file size this will be equal to this area which means total blocks into block size block size is given here total blocks you can find by 2^ DBA and then multiplied by DBS this will give you the maximum possible file size of disc dis size now there are several methods for allocating the blocks to file like contiguous noncontiguous and index allocation in contiguous there will be internal fragmentation in the last block external fragmentation yes increasing file size that is inflexible let's see with the help of an example suppose this is my file this is another file this is another file this is another file so in this way the blocks are located to files okay now how internal fragmentation can be there suppose my file needed 2.1 blocks so the two blocks will be located and the third one has to be allocated although it will need only the point one of it in this manner internal fragmentation now how external fragmentation let's say let's say there are four blocks 1 2 3 and four or let's keep it to five now these two blocks are allocated these two blocks are allocated now there is another process which needs two block can it be given no this this block will be wasted external fragmentation increasing file size I want to increase the file size take the same case 1 2 3 4 5 I want to increase the file size these two blocks are allocated these two blocks were allocated I want to increase the file size of this file with two blocks can I no because the two blocks are not available that's why increasing file size is inflexible or not generally possible so plus two blocks may not be available and how can it be accessed using sequential or Random Access like an array and it is faster now comes the noncontiguous allocation or linked allocation wherever you find the block use it but you have to link it see this block allocated first see I find this block free all allowed then I find this block free alloted but you have to you have to create create a link list of it otherwise how are you going to find that after accessing this block which block I have to access so there will be a kind of linked list okay so this directory contains the file name Jeep start is at 9 and end it as 25 so this is the start here it goes first then here then here and there it ends so in this manner I hope you got the idea wherever block is free allot it and then link them with the link list internal fragmentation yes see the point is same suppose I need 2.1 blocks of the data then what will happen if I need to point one blocks for a file then two blocks will be allocated and third one will also be allocated although only point one will be used rest of the space will be wasted internal fragmentation is present but external fragmentation is removed how initially when we had the continuous allocation these two blocks were allocated to a file these two blocks were allocated to file suppose now a new file comes which need two blocks I can't allot it but here I can I allot a block somewhere else then I link to this block and allot it now in this manner external fragmentation is reduced increasing file size yes I can increase the file size suppose I want to increase the file size of this of this process firstly I will allot this block and the other block wherever free types of access here this is the problem here the types of access will be only sequential because how can I reach how can you reach to this block without going like this because you can't have address of this but in in contiguous it works like an array so it works like an array you can either have sequential access or direct access like an array it is faster in linked list you cannot access the seventh node directly you have to start from the head and hop to the next to next node and next node and then you will reach the node you desired so the type of access will be only sequential and slow performance pointers consume dis space there is another overhead here and vulnerability of pointer is suppose this was the first node and this pointer got broken the whole file is damaged now so if vulnerability of pointer is they can get broken and will truncate the file this will corrupt the whole file now comes the third one is indexed allocation of disk space what will happen in this each file will maintain an index block index block hold address of the data blocks of the file in this manner suppose 19 is the block which is containing the address of all the blocks which is present in the file so here is a file named Jeep the index block is present at Block 19 it contains the the address of those block which contain which contains the data uh data of the file the 9th one the 16th one the 25th one first block 10th block so in this manner they all will be connected now again a vulnerability if index block got damaged then the whole file will be gone but this index block does not contain the data it contains the array of the addresses of those block which has the data so there are no block to block links index itself is pointing to all blocks okay see this question have DB equal to 16 bits DBS which means size is 1 KB maximum file size with one index block easy question you just need to find the number of block addresses index block can you store these many blocks will be present in the file and then you multiply with the D the data block size and you will get your file size so you have to find the number of addresses these index block this index block and is stored let's say x number of addresses size of each address is 16 bits and the size of index block is 1 KB so here I got X = to 2^ 9 so this index block can store 512 addresses each of each address has 16 bits in it so this index block can point to 512 blocks each of size 1 K so what will be the file size5 MB see this another question a file system support the data block size to be 4 KB each block can hold 512 addresses the size of DBA in bits will be same question just the opposite way the size of the data block which is 2^ 2 into 2^ 10 into 2^ 3 for this bite to bit conversion because we want the address in bits so 2^ 15 bits is the size total size of a block and it is given that each block can store 512 addresses so how many addresses will be or what will be the size of each address let me repeat the size of a block which can store 5002 addresses so what will be the size of each address here I get X = to 64 bits this was the indexed allocation now the question is can I increase the file size yes take more than one index block then you can increase the file size performance internal fragmentation yes external fragmentation no because here also noncontiguous allocation is there can I increase the file size yes it is flexible type of access will be both sequential and random which means it is similar to array reliability more than linked as no pointers but if index block got damaged then the file will be gone space overhead some disk space will be consumed for index blocks because if the file size is more then there will be more index blocks and if more index blocks are present then the overhead to store those index blocks in the disk will also be there so this is the drawback case study Unix or Linux each file node is associated with I node let's say we have a file named gy. C associated with iode 23 or this is the Block in which the I node is stored it contains some general attributes like type owner date and time size Etc and then comes the Block in use it contains the 10 direct dis block addresses it contains the 10 direct dis block addresses so how much size will be contributed by this block or this area I can say 10 direct dis block addresses each of size let's say 1 KB so 10 KB will be contributed by this now what happens I need more so I will point to an index block which will point to several data blocks so in this manner here is the single indirect disk block address it points to an index block which points to the several data blocks let's say the index block can store 512 addresses so how many data blocks it is pointing 512 data blocks each of size 1 KB so how how much size this is contributing 512 into 1 KB which means 512 KB now comes the more the double indirect pointer here is the block which points to the index block can you imagine here we had the direct addresses here we have we are pointing to an index block which contains several dis block here we have a block which points to the several index block and each index block is pointing to the several data blocks or disk blocks whatever you want to call so this in this block is pointing to 512 index block each index block is pointing to 512 data blocks and the size of each data block is 1 KB so the total space contributed by this will be 256 MB you get it what it is written here we have mode owners time stem size block count we have direct blocks where we store the addresses of the blocks directly we have single indirect in single indirect what we do we store the index block address here the index block is pointed and then this will point to the later uh dis blocks or data blocks in this double indirect this block will point to several index blocks and these several index block will point to the more dis blocks and triple indir you can guess we have a block which is pointing to the index block this block is pointing to the more index blocks and this block is now pointing to the the data blocks so the level are increasing see if I if I ask you what will be the size contributed by triple indirect then 2^ 9 into 2^ 9 and then more 2^ 9 this will be the answer 2 power 27 KB see when we had a single indirect then only 1 * 2^ 9 when we have double then 2 * 2^ 9 we have when we have triple then three * 2^ 9 in this manner now comes the second case study which is dis operating system or Windows operating system we have a directory like this we have a file named jy. C we here we have other attributes and the block info is stored like this the first dis block address and the last dis block address but here the first and last is written only what about the middle ones so how to get information about other blocks here should be blocks not tables so how are we going to get information about other blocks with the fat file allocation table or we also call it as Master file table it is like this it contains the entries number of blocks but these contains the address of the next block see here this is the master file table here we have a starting block 217 this will contain the address of the next block we have to go to so we go to 68 now 618 contains the address of the next block we have to go to 339 this will contain minus1 which means end here so the starting block quiz 2117 and the last block is 339 so this is how it works so it is like the link allocation but it is array based so this will contain the information about all the blocks see here it is written the first block is five so we move to the first block then we know we have to move to three we move to three then here it is written seven so we move to seven one move to one then move to two we move to two then move to four four then move to six six here Eight Is the End okay if we move to 8 there then nothing is present so from 5 to 8 our uh this entry is written so it is like this first go to 537 1 2 4 6 8 so this is the first and this is the last with the help of Master file what was the full form Master file table we can get the information about the middle one blocks also okay consider a consider a uni I node structure that has has eight direct dis block addresses and three indirect dis block addresses namely single double and triple okay dis block size is 1 kiloby and each block can hold up to 128 disk block addresses calculate the maximum file size with this IOD structure so we had eight direct dis block three indirect dis block namely single double and triple okay so we have eight direct and three indirect single double and triple the size of one dis block is 1 KB and a block can hold one 28 dis block addresses okay so we have eight direct dis block address so from here I can get 8 KB directly from the direct dis block addresses like here from direct I got 8 KB from indirect now indirect has three single double and triple from indirect I'm going to get 128 into 1 KB because a single block can store 128 addresses of the blocks so it will point to 128 blocks each of size 1 KB so from this indirect single I got 128 KB from indirect double just two times for triple take three times and all add all of them you will get the maximum size should I repeat okay what we had we had eight direct dis block addresses and each of size 1 KB so 8 KB I directly got from here then I had three indirect dis block dis block addresses of single double and triple so I had the first one is single the second one is double and third third one is triple the single block is going to point to 128 blocks each of size 1 KB so this will point to 128 this will contribute to 128 KB space now the double one this will point to an index block this will point to 128 index blocks which can point to 128 blocks each index block is going to point 128 blocks and one single block is going to point 128 index blocks so 128 into 12 128 at this level and 128 this level here 1 KB for each so I'll get for double 128 Square KB for triple this will point to 128 index blocks and this will again point to 128 index blocks and this will here now will point to the 128 blocks each of size 1 KB 1 KB so 128 at this level 128 at this level 128 at this level and 1 KB here so I'll get 128 to^ 3 KB now when you add all of them you get the total size the maximum file size with this IOD structure size of dis block address each block is of size 1 KB it can store 128 dis blocks so each of size 1 KB so 8 K bytes equals to 128 into DBA you can just find it that DBA consist of 64 bytes is the file file size possible over the given dis the maximum file size we had was 2 GB and the maximum dis size will be you remember how we can find the maximum disc size 2 power DBA into DBS so what is DBA DBA is 2^ 6 bytes so it will be 2^ 2^ 6 which is 2^ 64 this is way higher than 2 GB which is just two uh 2^ 31 so yes this file is possible over the given disk okay yes so it is possible another question the index node I node of a Unix like file system has 12 Direct One 12 12 direct one single indirect and one double indirect pointers the dis block size is 4 KB and the disk block address is 32 bit long the maximum possible file size again the same pattern you can do this same pattern we are going to follow we get the answer as 4GB the data blocks of very large file in the Unix file system are allocated using see if it is a very large file you can see here you can see here if I allot continuously I will get very little memory I will get very little space when I when I directly given when I have directly pointed to the blocks I got 8 KB when I had indirect sing single extension then I had 128 KB when I had double extension then I had 2 power 14 KB triple extension I had 2 power 16 KB so I cannot uh I cannot allocate file of very large uh size with continuous allocation no index no this indexed allocation somewhat gives a hope but here it is written very large file so I would need like triple or uh quadruple indirect pointers I need like this as I increase this number of blocks here this 128 will keep on multiplying in this manner with see we are extending when we extend more I will get more memory I will this will contribute to the more space with with the help of an extension of index allocation the data blocks so very large file in the Unix file system can be allocated using large using a larger Block in a fixed block size file system needs to better disk throughput but poor dis space utilization why poor because we have internal fragmentation and why better disk throughput because number of bytes you can read with one dis XIs are more so if I use a larger block size then po dis utilization because of internal fragmentation and better disk throughput because we can read more bytes with just one dis access another question a file allocation table based file system is being used and a total overhead of of each entry in the file allocation table is 4 bytes in in size given a 100 into 10^ 6 bytes dis on which the file system is stored and data block sizes 10^ 3 bytes the maximum size of a file that can be stored on dis in units of 10^ 6 byte is so let's call 10^ 6 as Sheba entry size is given as 4 bytes here it is written four bytes now we have to find number of blocks in the file allocation table so we call this 10^ 6 as Shiba and so I will call this as the 100 shivba this 100 into 10^ 6 by is 100 Shiva so the number of blocks I get as dis size upon block size so the dis size is 100 shba and the block size is this 10^ 3 so I'll get .1 Shiba blocks in the file allocation table and you know what Shiva is 10^ six okay now maximum file size will be given dis dis size minus file allocation table size because see here this part is also going to consume some space this will cause overhead so the maximum file size will be the total dis size minus overhead so how how much size I have the total disc size is dis size is 100 shab bytes and the file allocation or the file allocation table what is the total size of this4 shba how I got this point4 see the each entry size is4 the each entry size is 4 byte and number of entries are .1 sheiba so I'll get4 sheiba bytes for this uh file allocation table size so the maximum file size can be 99.6 shab bytes easy question just to confuse you the main concept was the maximum file size will be given dis size minus overhead you have to also take account of this file allocation table size see this is not less if you if see I have written Shiva here which is creating an impression that it is so less this Shiva is 10^ 6 now you can just imagine how large this is in the next lecture we will move to the file management part three consider a file system that stores 128 dbas in the index table of the directory the block size is 4kb if the file size is less than 128 blocks then these addresses act as direct data block address however if the file size is more than 128 blocks then these 128 address in the index table point to the next level index block Each of which contain 256 data block address so this is what it is if the file size is more than 128 block then it will point to the block it will point to 128 block each block will point to 12 256 blocks each of size 4 KB so 128 into 256 into 4 KB you're getting the point these are these are 128 blocks each block will point to 256 blocks or I can say now here they are the direct data blocks so these 128 blocks will point to 128 into 256 data blocks each of size 4 KB so what is the maximum file size in the system if the file size is less than 512 KB then 128 address act as the direct data address if the file size is more than 512 KB then this way it will work so the maximum file size is 128 MB now don't wonder where I got this 512 just multiply them 2^ 7 into 2^ 2 by that is 512 KB this 512 is the limit for direct addressing if the file size exceeds this 512 then we need to move to the indirect and how the indirect will work here it is given so following that we find that the maximum file size is 128 into 256 into 4 KB now calculate we'll get 128 MB another question a file system system with a one level directory structure is implemented on a disc with a dis block size of 4 KB each block has a size of 4 KB the disk is used as follows dis block zero contains the boot control block so the boot control block will take up size 4 KB dis block one it contains file allocation table consisting of 10 bit entry per data block representing the data block address of the next data Block in the files so this file location also consumed 4 KB block two and three will contains the directory 32 32bit entry per file so this will consume 8 KB block four now here we have we have the actual data blocks so this was just the overhead and from now we got to the actual data blocks so the question is what is the maximum possible number of files this is what it looks like boot control block for dis block zero block one contains is the file allocation table each entry is of 10 bits directory of 8 KB because we are using two blocks here and the entry is the entry size is 32bit from here we got the data blocks so the maximum number of files and maximum file size we have to calculate the directory is taking 8 KB and what is the entry size the entry size is 4 bytes so the number of files directory points to to what the file each the entry is taking 4 byte and the total size is 8 KB so how many addresses are there 2K addresses which means how many entries are there 2K entries which mean how many files are there 2K files and the file allocation table contains 10 bit which is nothing but the data block address because in file allocation one this block will point to the block which we have to go to the next my English is so bad in file allocation table this block will point to the the block which we have to go next so this will be the F entry of 10 bit it is nothing but the data block address so what will be the maximum file size we have done this kind of question what is maximum file size the dis size minus overhead what is dis disk size the total number of blocks into block into block size how many blocks are present 2 power DBA so one24 blocks are present each of size 4 KB now control overhead we have four blocks for this each block is of size 4 KB so 16 16 KB is used up here so 2^ 12 minus 16 KB is around 480 KB so this is the maximum file size and number of files is 2K see this was an super easy question nothing extra was there you just have to calculate the number of files and maximum file size where can I get the number number of files I got the number of files from directory because directory in directory the entries point to the files and from we know the size of the directory and size of each entry from there we will get the number of entries number of entries will tell me the number of files so easy and the second was maximum file size how can how can I calculate the maximum file size total dis size minus overhead we know what is overhead this is overhead these four blocks are overhead each of size 4 KB so overhead is 16 KB now what is the dis size the total blocks total blocks into size of each block how many total blocks are there how I'm going to get that with this we know that f8 contains the block addresses and the block address is of 10 bits so DBA we are given with 10 bits so I can find the total number of blocks are 2 10 each of size 4 KB so from here I got the disk size and then when I subtracted the disk size minus control overhead I get the maximum file size in the next lecture we will see disk Free Space Management algorithms disk Free Space Management algorithm I'm given that the dis size is of 20 bit 20 bytes DBS is of 1 KB and DBA is of 16 bits what will be the number number of blocks so you may proceed with the two ways either you divide the disk size with the block size and you get 20K blocks or you can directly go there and do like this this will also give you the number of blocks so which is correct this 20K is correct or 64k is correct I'll speak again I have dis size of 20 MB and the block size is 1 KB now if someone ask me the number of blocks it will be dis size upon block size which will give me 20K blocks but I'm also given with the dis block address which is 16 bits you will say you taught me that 2^ 16 will also give me the number of blocks so which one is correct thises 20K is correct and or 64 is correct that's what I'm asking is 20K correct or 64k correct the answer is 20K is correct this is the maximum possible so this 64k is the maximum possible number of blocks I have told you so many time what is the maximum size of the disc the maximum size of the disc is 2^ DBA into this this is the maximum size and this is the given size DBA equals to 16 bit so the maximum number of blocks that that can be there is 64k and this 20K are the the number of blocks which are there this is can and this is R okay to refer 20K blocks how many bits are needed five bits for that 20 and 10 for this scale so I'll get 15 bits is needed so we need 15 bits but are using 16 bits so the maximum possible disc size is 64 MB that is maximum possible number of blocks into block size but what is the given dis size is 20 MB so the given dis size will always less than the maximum possible now you may wonder what is the what is the difference between given and maximum what is this I'm talking about the free space available I'm talking about the free space available what can be the maximum amount of free space and what is the available free space this is so now the thing is clear to you this is the available disk size and this will give me the maximum disk size so these are the available number of blocks which are free these is the maximum number of blocks which can be free okay now I think the point is clear so there are 20K blocks which are free so I can store these 20K in form of Link list link list of free blocks so initially the chain of of 20K free blocks will be present suppose out of these out of these 20K blocks I want to allot some block to the file let's say I want to allot these 20 out of these 20K I want to allot 10 blocks to the to some file what I will do I will delete 10 blocks from this 20K linked list and allot to the file and allocate initially a chain of 20K free blocks if I want to allocate some blocks to the file let's say 10 blocks then delete those 10 blocks from the linked list and allocate as simple as that this is what or this is what is the linked list of free blocks if I allocate some file to that block then that block won't remain free that's why we are deleting the blocks which I allowed to a file now comes the free list this is list linked list of blocks containing address of the free blocks this is what the free list is we are not maintaining the linked list of the blocks we are maintaining linked list of those blocks which contain address of the blocks we are not containing the we are not maintaining the linked list of the data blocks we are maintaining the linked list of the address blocks which contain the address of those free data blocks the point is clear how many blocks of the free list are needed to store 20K free data blocks so let's say the entry of or how many bits we are using we are using 16 bits and let's say x are the number of entries what is the block size 1 KB so I can store 512 addresses in one block so I can store 512 addresses in one block so how many blocks I need to store these 20K block I can store 512 addresses in one block let's say I need y blocks to store the 20K so I got y = to 40 so I need 40 address block which contain each of those address block which contain 512 addresses off block this will sums up to 20K blocks the third is bit map or vector it keep track of all the block unlike free list see free list only kept or linked list only kept the track of those blocks which are free but this bit map is going to keep track of all the blocks ass associate a binary bit to each block we are associating a binary bit to each block doesn't matter whether it is free or some file f file why am I staming so much or some file is allocated to that block doesn't matter zero will be for the free and one will be for inuse what does this suggest that first block is free what does this suggest the second block is in use in this manner you go so how many how many bits will be there the number of bits will be equal to the number of blocks how many blocks are there 20K blocks so I will have 20K bits so how many blocks are needed to store our bit map see the total number of bits we needed are 20K and in one block how many bits are stored these many bits so I'm going to need three blocks to store the bit map free list is faster as it keep track of free blocks only no need to search but here we need to search for some block let's say I want to allocate 10 blocks to some file I want to allocate 10 blocks to some file here what we did we just deleted the 10 blocks from the chain of Link list and given to them here what we did we just deleted those 10 addresses from some block and here what we did we need to search for the 10 blocks which are free here searching time will be extra okay so free list or the linked list is faster as it keep track of only free blocks no need to search it keep track of the binary map the bit map or vector keep track of all the blocks unlike free list so we need to search which blocks are free the fourth is counter method when we have continuous free blocks then what we did we just write the starting free dis block address and the number of continuous free dis blocks so from block five to 45 more blocks till this the memory is free from this from disk block address 85 to 200 more blocks the memory is free so this is how we write let's say we have a file of 20 blocks now which block we need to allocate similar to what we did in the partitioning we will follow the same policy first bit worst fit and the best fit first bit is Select from the first entry if the number of free blocks are greater than the number of the blocks which file require alloted what does best fit say choose the least difference the number of free blocks minus the blocks which file require choose that block which has this least difference so here the difference is just five here the difference is 25 here the difference is 180 here the difference is 105 so I will choose the block which has the least difference between the block which are available and the block file needs okay and after allocation we need to update the tle also see if I allocated let's say I allocated 20 block to this now how much are free only five are free so I have to update that tle also you know what is tle the record so we have to update the record also consider a disk with B blocks F of which are free disk block address is dbits disk block size is X bytes we have to calculate the given dis size maximum possible disk size and relation between B and D okay so this is simple and straightforward question number of blocks which we have is B what is the size of each block X so this is the given dis size dis size some of you make a mistake of writing F into X see here nowhere is written give me the dis size which is free or give me the amount of total space available for the files to be allocated or nothing like that is written there's nowhere asked the free disk size it is written that given disk size so the answer will be given dis blocks into size of each block simple maximum possible dis size maximum possible blocks are 2^ D and size of each block is X this is the answer the relation between B and D you know the relation between these two that the given dis size is always less than equal to maximum I can write BX is less than equal to 2^ DX I cancel X from both side I got B should be less than equal to 2^ D this is the relation what is the condition in which free list uses less space than bitmap firstly we have to calculate what we have to calculate the size of free list what was free list fre list contain blocks which contain addresses of the data blocks and these these blocks which contain addresses of the data blocks are connected in form of linked list so this was free list now what will be the size of free list see each block contain the addresses so if I have to find the total size of free list then I have to find the total number of free blocks into addresses of each block address size of each block total number of free blocks into address size of each block what is the address size the address size of each block is d so F into D will be the size of free list see don't complicate it we have blocks in which addresses are there if I see you okay let's keep it simple if I see you this is the complete free list it contained it contained addresses of the free blocks what will be the size of this free list address size of one data block into number of data blocks or I can write address size of one entry into number of entries and how many entries will be there number of entries will be number of free blocks so what is the address size d what is the number of entries F so F into D will be the size of free list what will be the size of bit map the size of bitmap will be number of blocks in bits if you remember what was bit map let's say I have 20K blocks so I will have 20K bits here how many blocks I have B blocks so I'll have B bits so the condition in which free list uses less space than bit map will be F into D should be less than b that's it this is the space used by free list and this is the space used by bitmap it's simple question number two the beginning of free space bit map looks like this after the disk partition is first formated we have this the first block is used by the root directory the system always searches for free blocks starting at the lowest numbered block so after writing file a which uses six blocks the bit map looks like this so for six blocks we'll have six ones 1 2 3 4 5 six the first one is always there for the root the root directory so the system always searches for free blocks starting at the lowest numbered block so after writing file a which uses six blocks the bit map looks like this this is for the root and this six ones are for this file a map after each of the following additional actions as hex code what is hex code in the hexagonal file B is written Now using five blocks okay so this was was just the example okay so if I have written file B then what will happen so this a was the example but here it is written additional actions see this a will be counted and then these actions are performed here it is written already that additional actions initially we have let me Zoom it initially we have this one for the root and rest all zero so I will write this is 8 and this is 0 0 and 0 so XX will be 8 ,000 then what happened file a is allocated six blocks so one was for the root 1 2 3 4 5 6 this is for a so this is 0o this is z what is this triple 1 0 this is e in hexagonal and what is 1 1 1 1 this is 15 so F represent 15 in hexagonal this is what this is 14 this is 15 this is 0 this is 0 so I have written F e0 0 so file B is written using five blocks okay now file a is deleted file B is written using five blocks so this was till a then 1 2 3 4 5 these five blocks are given to file B so f f f for this this is 15 this is 15 this is 15 and then zero f f F0 for this file B is written using five blocks now what happens file a is deleted when file a is deleted so this was for the file B this was for the root and all the ones which we have made for a which means these ones will be made to zero because the file a is deleted so those block will be free now and for free what we write we write zero now we have 81 fo this is 8 this is 1 this is f and this is zero file C is written using eight blocks now file C is written so where we will write file file c 1 2 3 4 5 6 the blocks which we which were initially given to a which are now freed will be given to C so six for six here and two here two additional now what is the uh hex 15 15 15 and C now what happened file B is deleted so what were the ones for file B these were the ones so delete them these ones are gone so I have f e that is 14 0 and C this way this will be the answer it was easy one nothing special was there a file system uses an inmemory cache to cash dis blocks the Mis rate of the cash is shown in the figure so here is the Mis rate this is the cash size and this is the Mis rate when we have when we have let's say 30 MB of cash then the Miss rate is 40% when we have 20 MB of cash then the Miss rate is 60% when we have 50 mb of cash then the Miss rate is 30% as we increase the cash size it is obvious that Mis rate will decrease the read the latency to read a block from the cach is 1 millisecond and to read a block from the dis is 10 millisecond assume that the cost of checking whether a block exist in the cash is negligible available cash size are in multiples of 10 MB so the question is the smallest cache required to ensure that the average read latency of less than 6 milliseconds so what will be the read read latency suppose p is the Mis rate so I can write p and when it is a Miss then I'll have to read from memory plus when it is a Miss then I can read from cach should be less than 6 millisecond so it is 10 p + 1 minus P should be less than 6 so it is 9 P less than 5 so P should be less than 5 by 9 it's around 55% so the Mis rate Mis rate should be less than 55% so where is 55% 55% is somewhere here see now the cash can be either 20 or 30 I have written that Mis rate should be less than 55% if I choose 30 so if I choose 20 then the Mis rate will be greater than uh greater than 55% it will be 60 and if I choose 30 then it will be less than 55% that is 40 so either 60 or 40 what I have to choose the Lesser one that is 40 so where I will get the Lesser one 30 so the smallest cash smallest cach which is required to ensure that average read Laten is less than 6 millisecond or I can say the smallest cash required to ensure that Miss rate is less than 55% is 30 see smallest I can either choose 20 or 30 but P should be less than 55% here the p is greater than 55% see 20 is smaller than 30 but I am also increasing the Mis rate I don't want to increase the Miss rate so the smallest cash will be 30 to ensure that the average read latency is less than 6 millisecond okay so this is what I have written latency of cash is 1 millisecond latency of dis is 10 millisecond so the read latency should be less than 6 millisecond I write the latency formula here less than 6 9 p is less than 5 I got 55% and the Mis rate is p so cash is in size of alpha into 10 MB which means the multiple of 10 MB so according to the graph I can choose 30 only if I choose the smaller one if I choose the smaller one that is 20 then the average average read latency will exceed the 6 millisecond if I choose 30 then it is perfect 30 is the smallest one if I choose 40 yes it is less than in 40 p is less than uh 55% but 40 is not the smallest the smallest is asked so 30 will be the answer 30 MB is the answer the amount of disk space that must be available for page storage is related to maximum number of processes n the number of bytes in the virtual address space is B and the number of bytes in Ram is R give an expression of the worst case disk space required let us read the question again the amount of dis space that must be available for page storage is related to maximum number of process n okay the number of bytes in the virtual address space is B and the number of bytes in the ram is R give an expression of the worst case dis space required see for the dis space there is no relation of or there is no need of this Ram thing to be given I can ignore this ram ram thing because the RAM and the disk space no relation because we want to allocate the dis space see in case of uh let me explain with the help of this diagram suppose I have a process Pi where is this mapped where this virtual address piece is mapped it is mapped onto the disk not on the physical address space physical address space is going to be much lesser than the virtual address space this virtual address space is mapped onto the disk suppose now comes another process then this virtual address space will also going to be maed on the disk so the worst case the worst case disk space required will be number of process into size of each process which is this virtual address space so n into B will be the answer there is no need of R being given so n into B is the answer in the next lecture we will start with the dis scheduling algorithms dis scheduling just like CPU can serve one process at a time similarly the disk can only serve one IO request at a time just like shortterm scheder disk scheder also exist let's move directly to the dis scheduling techniques suppose the process request this track or cylinder number cylinder number 98 then the process want to process want the read right head to go on 183 then on 37 then on 122 14 124 65 and then in the end 67 suppose the read right head is at 53 so total there are from 0 to 199 200 tracks are dist distributed evenly on the surface on the surface there are 200 tracks in such a way and read right head is currently on track number 53 and what requests are made 98 183 37 in such manner requests are made the first algorithm that is fcfs what does this say as as the request comes serve them in that order only first come first sir so from 53 it will first go to 98 from 98 it will go to 183 from 183 it will go to 37 as the request order came 9 98 183 37 from 37 it will go to 122 from 122 to I think 14 yes and then 14 after 14 then to 124 and then to 65 and then to 67 so in this manner the request will be served first first come first serve as the request comes or the order in which the request is made serve in that order only this is what the fcfs says so total six how many are made see from 53 to 98 from 98 to 183 from 183 to 37 in this manner you have to calculate the total se you will get the total seeks are 640 average seek per request will be total number of six upon number of requests so I have around 86 per request which is a high number now comes the shortest seek time first you have this this you have this request order suppose the read right head is now 53 serve those request first in which there will be least seek time nearest closest track next this is the another name nearest or closest track next so from 53 I will go to 65 from 65 to 67 67 to 37 then 14 then 998 then 120 you have to choose the closest one on when on 53 what was the closest track you can go on the 65 then 67 on 67 which is the closest track you can go to 37 so in this manner you have to proceed and here the total number of ss were 640 and now see the total number of six it has reduced drastically it is now just the 236 so the first first one was fcfs algorithm serve in the order as the request order comes serve in that order only B part was go to the nearest or serve the nearest or closest track next this will give you the least amount of seeks then comes the scan algorithm top to bottom and bottom to top serving for scan apart from knowing the position of read right head should also know the direction so from here what are you going to do see here from 53 let's say the direction is in this manner so I will go like this till 99 and whichever request comes in the middle I'm going to serve them see from I have started from 53 53 to 65 65 to 667 then 98 then 122 then4 then 183 now remember 183 was the last request made but what happens it has to do the complete round and then then turn at 199 so from 183 it has to go to 199 to complete the to complete the round or to change the direction it can change direction on the extreme points only what will happen so I'll go start with 53 and then I should also know the direction in which I'm going I'm going in this direction so from 53 to 65 from 53 go till 199 which is the end and whichever request comes in the middle serve them and then take the turn so when you will take the turn then comes what then you have two requests remaining the 37 and the 14 so 37 will come first and then the 14 now you don't have to take the turn again that's why you are not going to the extreme end you just completed where the your last request was that is 14 got the point in fcfs we served in the order which in which the request was made okay so first uh at 53 the first request first request was 98 so from 53 I will go to 9 8 then the second request was 183 so from 98 I'll go to 183 in this manner I served all the request and the total number of seeks I got was 640 the second algorithm is shortest seek time first and this serve the nearest or closest track next so from 53 the nearest track to which I can serve is 65 from 65 the near nearest track is 67 in this manner I proceeded and completed or the served all the request the then comes the scan algorithm top to bottom and bottom to top serving so it is just like the direction you can start from 53 to 199 so this is what bottom to top from less to more and you should remember this point that in a scan algorithm to take the backward turn or to take any turn you need to go to the last you can take turns on the extreme only so from 183 to 199 this was actually not useful but to take the Le we need to go to the extremes okay so the what is the drawback extra seeks plus starvation to the process in opposite direction let's say from 53 to this 199 it took so many time that it it takes so many so much time that this 37 and 14 are being starved suppose the read right head is at let's say 12 the read right head is at 12 and the last uh track can is at 1,000 and one request is at 6 one one uh one process request the sixth track number so from I will first serve from 12 to 13 14 till th000 and then I will turn back and will reach to the six so this this six will be starred for star for so much time so what was the drawback extra six plus star with equation to the process in opposite direction because you have to go till the end to take the turn this was scan the first was fcfs serve in the order of the request the second was shortest seek time serve the nearest track first then scan go in One Direction and then in that direction whichever request process made keeps on keep on serving it and then when you have to take the turn you have to go to the extreme this was a scan now comes the look in instead of going to the last take the turn at the last request exactly rest exactly like this SC so what will happen same manner I will go till 183 now the look algorithm gives an extra Edge that I have I do not have to go to the extreme to take the turn I can take the turn at the last request only also I can take the turn at the last request also no need to go to the extreme this is what the benefit of L algorithm and the rest is exactly like this scan what does look say wherever your read right head is go into the direction whichever is specified keep on serving the uh request made and at the last request of that direction you can take the turn in a scan I have to go beyond the last request so that I can take turn on the extremes here no need to go to the extremes now comes the C scan the circular scan in circular scan you can go in One Direction only so you started from 53 you keep on serving and at 19 199 you have to take the turn but remember you cannot serve while going in this direction you can serve in One Direction only so from 53 you need to go to 199 and after 199 you have to travel back to zero and then move in this direction again to serve the 14 and 37 you got the point in C scan the circular scan you can serve in One Direction only so from 53 to 199 you made the six and then from 199 to Zer back so that you can move again in this direction to serve the remaining 14 and 13 so how many six will be made from 53 to 199 and 199 to 0 and then 0 to 37 remember that these six will also be counted when you are coming back this will also be counted okay now comes the C look similar what does the look algorithm gives facility or what facility does the look algorithm gives the look algorithm says you need not to go to the extreme to take the turn you can take the turn at the last request also so if I ask you what is circular look similar from 53 to 183 and then when you come back no need to go to the extreme from 14 you can uh go to the 307 but remember it can serve in One Direction only now let us summarize again all the algorithms the first was the fcfs in fcfs what we did we served in the request order the order in which the request was made I served in that order only then comes the shortest seek time first serve the closest track then comes the scan go in One Direction keep on serving the request in that direction and then in the end after going to the extreme you can take the turn and when you are coming back whichever process whichever process requests are made in that direction you can make but no need to go again to zero because I do not have to take turn again see from 53 to 99 I moved in One Direction now I have to take turn that's why I have to go to the 199 otherwise if the request were only from 53 to 183 then I will just go in this direction but now what happens I have two other request waiting for me on the other side so I have to go beyond 183 to the extreme take the turn and serve in that order now there is no request on or there is no request which demand the Uturn again so I will not go to the extreme I just end at the 14 okay this was scan then comes the look similar to scan but what facility it gives no need to go to the extreme to take the turn you can take the turn at the last request also so I'll go from 53 to 183 and then from 183 I will go back to 37 and 14 end C scan you can serve in a single Direction only and you have to count when you are coming back you have to count those six also so from 53 to 199 I will go and then from 199 to 0 and 0 to 37 the see look the look algorithm always gives the facility do not go to the extremes 53 to 183 from 183 back to 14 and then 37 so instead of going to 199 and 0 it goes to 183 and 14 only okay in the next lecture we will see some problems on it then our file management section will be over after that we will start our miscellaneous topics consider a dis que with a request for io2 blocks on cylinders same as trct number 47 38 121 191 87 11 9210 the cook scheduling algorithm is used the head is initially at a cylinder number 63 moving towards largest cylinder number on its serving path so we are given with a current head location and the direction in which it will move the cylinders are numbered from 0 to 199 so these are the extremes the total head moment incurred while serving these request is we have to calculate the number of sixs and and which algorithm we are using cook algorithm what does cook say this is circular look you can serve in One Direction only but no need to go to the extremes so from 63 I'll move to 191 from 191 to 10 and from 10 to 47 sum them sum them all and you will get 346 as the number of head movements or number of seeks made another question given the requests and you have to solve using the first fcfs and the second one is s test seek next you can solve this an easy question consider a storage disc with four platters numbered as 0 1 2 3 so we have four platters and 200 cylinders number from 0 to 199 so we have four platters and on each surface we have 200 cylinders and 256 sectors per track and we have 256 sectors per track these are the track these are the surfaces uh not surface the sectors sorry there will be two surface on each platter there are four platters there will be 200 tracks on each surface and 256 sectors on each track the following six request of the form sector number cylinder number platter number are received by the disc controller at the same time so these are the request received this is what this is the sector number this is the cylinder number and this this is the platter number so on platter 2 go to the track 72 and or read sector number 120 this is what this say a b c this says on platter C go to the sector number or go to the cylinder number B and at that track go to the sector number a the first represent the sector the second one the track and the third one is the platter so these request I have received currently the head is positioned at sector number 100 of cylinder 80 and it is moving toward higher cylinder numbers the average power dissipation in moving the head over 100 cylinder is 200 M and for reversing the direction of the head moment once the power used is 15 Ms see these are these are the kind of question meant to scare you like the big big things are given so that you may get confused no need to get scared from this question just write the things down which are written power dissipation associ ated with rotational latency and switching of head between different PL is negligible so there is no power dissipated for rotational latency and switching the head between platters okay so here it is written that we have to switch the head between platters for this question assume that there is only one read right head okay there is only one read right head and there is one surface only at each platter because there is no concept of surface here and only one redite head is present and for each surface for each request I have to move this redite head for let's say here is the platter two so I will I will be at the platter two then the request is from platter one then this read at H will move to the platter one assume for this question the total power consumption in mwatts to satisfy all the about dis request using shortest seek time first dis scheduling algorithm is easy question no need to get scared what is given we are given with the platters that there are four platters 200 tracks on each flatter and 256 sectors on each track so these are the request made the sector number the track number and the platter number if you notice clearly there is no need for this platter number as you know that moving to a certain platter moving to a certain platter needs moving to a certain platter dissipates no power and moving to a certain sector also dissipates no power because it is written here that power or dissipation associated with rotational latency and switching off head between different plers is negligible this will cause the rotational latency see when we are on a certain track and when we have to reach to a certain sector then rotational latency is accounted but here it is written that rotational latency is negligible so we just have to reach to the correct track on the correct platter but here it is also written that there is no need for going to the correct platter also see this is just a way of saying here assume that all of them are on the same platter with no uh read latency rotational latency getting the point see you can do this older way uh you can take account of all these things and drag them all the way to the question to the end of the question but there is a smart move you can make here it is written that power dissipation associated with rotational latency and switching of head between different plers is negligible so I have to reach just to the current track just to the correct track when I'm on the correct track then everything is sorted because known power disspation for this no power dissipation for this so the actual request we have to consider is this only okay so here single Rite head for multiple patterns that I already told now extra things are given what is that given the current head is positioned at sector number 100 of cylinder 80 so the current head is at track number 80 moving toward the higher cylinder numbers okay so from 80 it will go to I think 199 this will be the direction to move the average power dissipation in moving the head over 100 cylinders is 20 MW so from for 100 track seeks 20 M Power will be gone for one track seek 1x5 M Power will be gone I just divided 20 by 100 for reversing the direction 15 Ms is needed power dissipation the two two of the things are dissipating the power switching the heads and the the rotational L switching the head is causing zero power dissipation transferring the track transferring the re right head from one track to another that is causing the main power dissipation and the second reason behind the power dissipation is reversing the direction see we are not using the scan or look algorithm here we are using the shortest shortest seek time first so this will going to cause a lot of Direction changes see here these many Direction changes are made so I have to take account of this reversing the direction uh Power dissipation also so these were the request made where I am I am at the 80th track number so from 80 where I have to move I have to move to 86 for then I have to move to 76 then 116 then 134 then 20 and then 16 in this manner I have to move based on this shortest seat time first dis Shing algorithm so the power dissipation will be from 80 to 86 firstly I will calculate the power disspation of seek only from 80 to 86 6 from 86 to 70 to 14 14 SS are made from 72 to 116 44 SS are made from 116 to 134 18 SE are made and then from 134 to 20 114 SE are made from 20 to 16 46 are so total number of ss are 200 and what is the power dissipation uh caused by one seek 1X 5 m so what will the power dissipation just by the seek it will be 40 m just by the seeks now for the Now power disp caused when read right head changes its direction the the first Direction Change made is here it was going here and then it changed the direction the second Direction change was made here it was going here and it made it changed the direction and the third was made here here here and here so three Direction changes are made so 45 + 40 gives me 85 M you get the question what was it see whenever you see a such kind of big question remember most of them are meant to scare you these it it the question has so many irrelevant information that was not even needed that was not even needed if I instead of giving this this whole thing if I just give you hey look I have this request you have to you have to solve this using shortest seek time and remember for one seek time 1X 5 m is needed or the power is dissipated and for reversing the direction 15 M power is dissipated can you give me the total power dissip it was an easy question it was so easy you have to just apply the shortest seek algorithm and calculate the number of SE the total sixs made were 200 multip it by 1X 5 you got 40 and calculate the total number of Direction changes first Direction Change here second was here and third was here so the total Direction change caused the power dissipation to be 45 40 was due to six so I got 85 this was an easy question but as soon as I have given this I have uh Twisted the question and added some irrelevant information there this may have Disturbed some of you what was given consider the dis stage let let me tell you which of the following information was just to uh distract you the four platter information was just to distract you this number from 0 to 123 200 cylinder this was useful information was this useful see this 200 cylinders was this useful we are using shortest seek time first we did not even use this 200 cylinder this was also the irrelevant information 256 sectors irrelevant information the following six request was made this was Irrelevant this was irrelevant no cylinder number was required pler number was irrelevant so irrelevant irrelevant needed and then currently the position sector number 100 this was needed uh sector number 100 no need the track number 80 yes it was needed moving toward higher cylinder number was it needed yes it was needed the average power dissipation yes it was needed to calculate the power dissipation for one seek and then reversing the head yes this was needed the power disp Associated see this was the gamechanging line the power disp associated with rotational latency and switching off head between different players is negligible this was the game changing line the total power cons so you can see how much information was just to distract you okay what would have happened if what would have happened if it was not written that the rotational latency is not negligible and the switching the head power is also present then this information would be useful okay so for every request I have to add I have to add the rotational latency and the time to switch the heads so this was a this was I can say a nice question let's move to another one suppose a dis has 2001 cylinders numbered from 0 to 200 at some time the dis arm is at cylinder number 100 and there is a q of dis AIS request 3 to 145 if the shortest seek time first is being used for the scheduling dis dis access the request for cylinder 90 is serviced after how many number of request or service serviced after number of request easy question you can do it yourself so from from 100 I will go to 105 first then2 then 90 so after how many request it was served see first this request was served then this request and then this request so after three request 90 will be served do not make a mistake to calculate the jump instead of request do not make a mistake to ignore this 100 see this is also a request this will also be served after the serving of this request you go to the 105 and then to 110 and then to 90 okay another question consider a consider an operating system capable of loading and executing a single sequential user process at a time this is just another name of uni programming operating system the dis head scheduling algorithm used is first come first serf if fcfs is replaced by shortest seek time first claimed by the vendor to give 50% better Benchmark result what is the expected Improvement in the io performance of the user think about it and read the question again what was it saying the operating system is uni programming if the operating system is uni programming the scheduling topic is insignificant for uni programming operating system so it doesn't matter whether you use fcfs or sstf it will it will not matter for uni programming operating system there is no such kind of uh there is no significance I can say of the scheduling so what is the expected Improvement in the io performance 0% did you get it see what happens just like the CPU scheduling topic what happens in the disk scheding there are multiple request at a given time now the disk scheduler has to choose which request it has to uh serve just like the CP Shing technique there were multiple process available in the ready CU ready to be run on CPU so the CPU Scher has to choose which process out of these I have to uh take to the CPU in the similar way for the dis Sher there are multiple IO request now it is on the dis scheduler which I request it will serve but what happens there is only a single process in the memory so this will generate a single this single IO request only no multiple IO request case no dis scheduling thing the pro the request which is made just serve it because there is only one request the scheduling topic was significant when there are multiple things at the time and you have to choose one just like in the CP Shing when there are multiple process in the readyq you choose out of those multiple you choose one process in dis scheduling out of the multiple I request you choose to serve one but if the IU request is only one then there is no concept of being of dis schuling so there's no concept of using uh fcfs or sstf whether you use any of one of them you will get the same result so what is the expected Improvement in the io performance of the user user program 0% another question consider a disk with the following pertinent details is the track track time is 1 millisecond or I can say one seek time is 1 millisecond current head position is 65 and the direction it will move will be for the higher tracks the current clock time is 160 millisecond okay consider the following data set we are given with the request serial number track number and arrival of the request time or the time of arrival of the request calculate the time of decision at which time we have to take the decision the requests which are pending the head position the selected request to be served seek time using fcfs all these things I will solve using fcfs and for rest of them it is homework to you so what happens we are at the time the present is at the time 160 millisecond these request request one request two request three and request four has already been made so at time 160 what are the pending request 1 2 3 4 at which time we have to take the decision current time we have to take the decision immediately to choose which of the following request I will serve what is the head position 65 the selected request will be the one which came first I'm using fcfs so who came first 12 uh the request for track number 12 came first what will be the seek time from 65 to 12 53 seeks into 1 millisecond as I am given the track track time is 1 millisec so after the request one is served what is the time now 160 was already there and 53 millisecond was also taken to serve the process the serve the request one I'm sorry if I say these as process these are the request so 160 + 53 23 will be the current time of the decision when I have to serve the these request which request one was already served 2 3 4 was already present and at time 23 this five would also have came at it came at 175 millisecond so the request which are pending now 2 3 4 5 the head position is at now 12 which request I'm going to serve next who came next this 85 the track number 85 so request to for track number 85 so from position 12 I'll move to 85 the total number of seeks made are 73 the seek time will be 73 millisecond now after the request two is served after 213 and then 73 will be added 3 and 36 718 286 this is the current time any new request made no the pending request are 345 what is the current time 286 and we have to make decision here at 286 which head position I will go the one I at the head position 85 now where I will go the one who came next who came next at 140 so from 80 85 I'll move to 40 how many SE are made 25 SE are made not 25 I think I moved to from 85 I moved to 40 45 SS are made so 45 milliseconds will be the seek time so in this manner you have to proceed and complete till the end so this was for the fcfs you have to solve for ssf scan look C scan and C look algorithm to get hold of these uh dis scheduling algorithms you will get Mastery over this we have successfully completed our whole file management section and in the next lecture we are going to or in the next section we will complete our miscellaneous topics The Leftovers topics I know this file file management was a little bit of uh theoretical topic but it also contained some of the algorithms and numericals hope you liked it threads and multithreading this will be our first miscellaneous topic let's start what is a thread thread is a lightweight process now you must be wondering why I call it as lightweight we will see it in sometime you know what is process programming execution State let's first understand this example of client server environment we have clients 1 2 3 4 5 6 7 these are all clients and this is our server which has a big hard disk and this is our server process we also call it as Damon initially we used to serve in iterative mode process uh request one was made request one served request three was made request three served request six was made request six served in this manner we used to serve but what happened instead of sequential request some of the clients requested at the same time so what will happen these requested will be queued up in a buffer this sequential serving of the request causes start ation or DeLay So what is the solution for this multiprocess approach or the concurrent servers the concurrent servers or the multiprocess approach now you must remember the difference between concurrency and parallelism okay we are creating the concurrent server not the parallel servers see this this was the server and we have three request cued up here so what it did there were three request pending so it creates three child process independent of each other and request one was assigned to child process one request two was assigned to child process two and request three was assigned to child process 3 so these child process are exact replica of the parent process server so now we have three processes now we have three process in the ricu C1 C2 and C3 we will execute them in the round robin fashion and it will create an impression that their request is being served at the same time what is going on firstly I'm serving for some time request one and then for some time request two and then for some time request three then I again back to request one and then again back to request and again back to request three so instead of sequential serving I created the child processes and each request is assigned to a process and and run those process in round robin fashion it created an impression that their request is being served concurrently but there is a s severe drawback of this uh of this method it is the redundancy of code it is a severe drawback why because code of the server process will be copied as it is in the child process see functionality of all the children will be same we can't we have an architecture in which I will have one section of the code and the resources which are separately needed should be given to each process see the functionalities or the functions are defined in the code and the functionality of these child process are exactly same but the resources are different so instead of giving instead of having different code and different resources for all of the process can't we have an architecture in which the code section remains same I mean functionalities remain same and and the resources which are separately needed should be given to each process in this manner I will avoid the memory and resource wastage this is what the idea of a thread is thread is nothing but a subprocess which will share all the common resources thread is nothing but a subprocess or lightweight process that's why it is lightweight process it is not a full process it is a sub process see this let's say this is the process with code section and resources this is another process with code section and resources another process with code section and resources and in thread what happens this is the shared code section and the resources are given to this is thread one this is thread 2 and this is thread the resources which are separately needed are separately given to the threads and the code section or the functionalities which needed to be same are shared by these threads so all these threads have some shared thing in common and the resources which are separately needed are separately given this is what thread is that's why it's called lightweight process so if someone ask you what is the main reason for multithreading economy the resource sharing okay in this manner it goes see this is the single threaded process and this is the multithreaded process this is the address space it contains code Heap data files registers stack or you can say this single threaded process is nothing but a process only the single threaded process is nothing but a process only each process will have its own code data files register stack Heap but what happens now when we move to the multithreaded process what happens the code data and file are shared but each thread will have its own set of registers and stack each thread will have its own set of register and stack so these are the resources which I was talking about that need to be separately given to each thread and these were the these are the shared thing or common thing okay so this is the default process the single threaded process nothing but the default process and there we it is the thread now the question is is why we throw why we show thread with a curvy line what is the reason behind this because the thread uh when the thread is put like randomly it it is curvy when you put a thread it is curvy so uh the thread is a lightweight and that's why we have given this a lightweight uh process and the thread when kept on something it becomes Curry that's why the line is curry no no not this is not the reason there is a more logical reason behind this so why we are using a curvy line because during the execution of instruction there may be a branch or jump instruction like see here if there is a no Branch or jump instruction I can just put a straight line there but what happens let's say I executed instruction one instruction two and suddenly I have to jump to next instruction then some next instruction that's why there is a curvy line here to represent the branch instructions okay each thread will have its own stack its own function and register okay so each thread will have its own stack and resistors this is single threaded this is multi thread now concurrent servers may be proceeded with two approach the first was the multithreaded approach and the second was the first was the multiprocess approach and the second was the multithreaded approach see here this was the multiprocess approach when we used fork and created the three child processes this was the multiprocess approach and this was the multithreaded approach what we did we kept the functionality part the same and or the code part is the is kept same and the resources which each the thread needed is given separately to them so the request one will be assigned to this thread the request two will be assigned to this thread and request three will be assigned to this thread okay so client will request the server server will create a new thread to serve the request suppose this is a client it requested a server server created a new thread to to serve that request and it will assign that thread the responsibility to fulfill the request of the client and it will resume listening for additional client's request whenever a request clients make whenever a request client make the the server will create a new thread and it will resume listening for the additional client request here are the benefits of the multithread program let's read it the first is the responsiveness multithreading and interactive application may allow a program to continue running even if a part of it is blocked or performing a lengthy operation thereby increasing responsiveness to the user this quality is especially useful in designing user interfaces for instance consider what happens when a user clicks a button that result in the performance of time consuming operation a single threaded application would be unresponsive to the user until the operation had completed but what happens in the case of multithreaded in contrast if the time consumer operation is performed in separate thread then the application remains responsiveness to the user for the remaining threads so what what it is saying that if it is a single threaded process and we assign This Thread some lengthy task then this application will be unresponsive until this task becomes complete so this was the single threaded process now what happens in the multithreaded process what I do I assign This Thread the leny task and these two thread will be still working so multithread process bring or multithreaded program brings responsiveness okay the second is resource sharing process can only share resources through techniques such as shared memory and message passing such techniques must be explicitly arranged by the programmers however thread share the memory and the resource of the process to which they belong by default default the benefits of sharing code and data is that it allows an application to have several different threads of activity within the same address space obviously this is also a point that when process Shar resources it has to use techniques like shared memory and and message passing Etc but when thread share resources it happens in the same process threads belongs to same process and when the process share suppose these are the two process and when they sh share some resources they had to do by shared memory and message but the thing or the case with the threads is they belong to the same process they share the memory and resources of the process to which they belong by default the benefit of sharing code and data is that it allows an application to have several different threads of activity within the same address space Okay the third is economy allocating memory and resources for process creation is costly well when you uh give all the resources to all the processes that is going to uh harm your economy because threat share the resource of the process to which they belong this it is more economical to create in context which threads yes yes that that is the point contact switching of process is way more costlier than the contact switching of threads EMP EMP empirically gauging the difference in overhead can be difficult but in general it is significantly more timec consuming to create and manage process than threats in Solaris for example creating a process is about 30 times more costlier than creating a thread scalability the B benefits of multithreading can be even greater in multiprocessor architecture multiprocessor means when we have more than one CPU so the benefits of multithreading can be even greater in multiprocessor architecture where thread may be running in parallel on different processing CES a single threaded process can run only on one processor regardless of how many are available we can explore this issue further in the following section okay so the scalability economy resource sharing respons as all of them tells that multithreading is better than multiprocessing again improved performance due to less contact switch each thread will have its own control block just like PCB of it's just like the PCB of the process as we have PCB for the process we'll have TCB thread control block for Threads and you know threads are called as lightweight process so it is General thing that or it is obvious thing that size of TCB should be less than the size of PCB if the size is less then contact switching or the thread switching time will be faster than process switching time well what we switch while contact switching of the process and threads TCB and the pcbs and if size of one is smaller than the later then obviously the thread switching time will be faster than the or thread switching will be faster than the the process switching so these are the benefits of using a multithreaded program in instead of multiprocessing the sixth is it can utilize the multicore architecture and Achieve parallelism see what it is saying suppose I have a single I have a single threaded program or I will say I will have a process in which there is only one thread this process can be assigned to a single CPU here we have multiple CPUs I'm talking about multiple processor architecture so what happens this is a single process it is assigned to let's say C1 CPU the rest C2 and C3 are empty or C idle but what happens in the multithreaded process I can assign each thread to a different CPU hence utilizing properly the M multicore architecture or multiprocessor architecture and it achieves parallelism this is the actual parallelism see what we are doing there wait it will load yes here we are not using parallelism here we are here we are using a concurrent approach you remember the difference between concurrency and parallelism in concurrency we deal with different things at a time first we are uh first we are uh executing the child process C1 then child process C2 then C3 in round robin fashion but at a time only one is being executed this is concurrency we are dealing with different things at a time but what was parallelism parallelism is we are doing the different things at a time so at a time this thread will also being executed This Thread is also being executed and this thread is also being executed this is parallelism okay let's summarize what we have what we have discussed thread is like a lightweight copy of process that executes independently threads share the same address space each thread has a separate program counter and may run over different parts of the program each thread has a separate stack for independent function calls so these this is the summary here more information threads versus process a thread has no data segment or Heap a thread cannot live on its own it need to be attached to a process there can be more than one thread in a process each thread has its own stack if a thread dies it stack is reclaimed a process has code Heap stack and other segments a process has at least one thread well you know the single threaded process are by default or a process is by default a single threaded process heads within a process share the same code files if a process dies all thread dies well threads lives inside the process if a process dies all threads will die if one thread die then other thread may live but if a process die then all threads will die now comes the fork thing parent P Fork a child c p and C does not share any memory this C is exact replica of the process P the child C or the process C is exact replica of process B all the resources which were allocated to process B will also be allocated to process C it need complicated IPC mechanisms to communicate you remember when we have discussed a full full section that how process synchronized how process coordinate how process communicate and you know how complex this was that was but in thread there is no such thing we do not need a complicated IPC mechanism they all reside in the same process so for for communication between two process we need comp complicated IPC mechanisms to communicate extra copies of code data in memory redundancy is present now let's see parent P execute two threads T1 and T2 T1 and T2 share parts of the address space Global variables can be used for communication see this simple instead of using complicated or complex IPC mechanisms which we have leared learned about set and lock or thread uh the Peterson solution Decker solution all this all the that complicated stuff we do not need here just the simple Global variables can solve our purpose and smaller memory footprint so simple so it says multithreading is much more economical than multiprocessing parallelism a single process can effectively utilize multiple CPU CES understand that difference between concurrent and parallelism well I have discussed it already that a single process here is a single process with multiple threads can utilize the multicore architecture I will assign This Thread to C1 This Thread to here this thread to C3 these are the CPUs each thread will be assigned to a different CPU and therefore I can utilize the multicore or multiprocess architecture effectively but if there are multiple process if there are multiple process and a sing CPU then what will happen I will use concurrency see in concurrency you remember the example of that coffee machine in a single coffee machine with two lines first it serve let's say of males and then of females first male comes then females then females and male in such manner it serves sometime this process sometime this process sometime this process sometime this process but what happens when we have two coffee machines mail line here the female line here okay so when we are talking about the case of two coffee machines that is parallelism when one coffee machine serving two lines that is concurrency types of thread so there are two types of thread the user level thread and the kernel level thread user level thread is threads that are created and managed at user level without any operating system support flexibility given to users and here in the kernel level threads are directly created and managed by operating system kernel level threads are the part of process but managed independently by the process so here operating system has the complete control here operating system gives the flexibility to users to create threads so these These are the user level threads we manage the creation at user level with the help of some package or Library okay let's see the benefits operating system is not able to see those threads it will see it as a process it is good as well as bad we call this as transparency well it seems something opposite but that's how it's called I have checked on every platform when operating system is not able to see those threads it will see it as a process when this happens well actually the meaning of transparency is everything is clear but here when operating system is not able to see those threads then we call it as transparency flexibility is given scheduling and assigning the threads all is at the user level see why this is good as well as bad because operating system has now no control over the you or operating system doesn't give uh much Focus to those user Level Threats so each and every responsibility will come to a user now it will create complication while writing the program when user is managing all the threats then the program will become complicated flexibility is scheduling assigning threads all will be at the hand in the hands of user faster contact switching as you know no need of mode shifting well this is the point which I forgot to make there less overhead in user level threads there is no need of mode shifting it is if if there is no need of mode shifting and the threads are lightweight then less overhead and faster contact switching portability can run on different operating system well then that is the actual benefit when these user level threads are independent of operating system which means I can run those on Unix I can run the same user level thread at Mac and windows well that will give me the actual portability and what is the drawback lack of true parallelism even if multi multiple processors are available scheduling and management is the responsibility of user now this is going to increase the the complexity blocking issues if one thread needs IO OS will block the process well that's well that's the point I want to make see user these user level threads are managed at the user level operating system will see it as the process now what happened this thread wants some IO Services by operating system or this wants the operating system to perform some IO service this wants to read some data from the disk now what OS will do OS as OS see them as the process OS is going to block all of them if one thread makes some IO request as you know whenever process makes IO request operating system blocks that process look put that in the block CU similarly if some thread makes an IO request operating system see all these threads as the process so it's going to block them whole all of them as a process that is the series drawback blocking issues if one thread needs IO OS will block all of the threads okay and this will be solved if operate OS kernel is multithreaded now what is the meaning of this how blocking issues will be solved if OS kernel is multithreaded see here suppose This Thread This Thread makes an IO request so instead of blocking them all this thread of the kernel level is going to serve this user level thread will serve the io and rest of the threads will keep on working these these kernel level threads will keep on serving those user level threads are you getting the point so this thread make a request instead of blocking the whole these all of threads if the kernel level thread if the kernel is multithreaded this thread is going to serve the io and rest of them will keep on working okay see this diagram here we have the user space this is the kernel space so this is a process which contains several threads a process which contains several threads now you know that kernel maintains the process table similar way process will maintains the thread table okay so this was all about user level thread now we'll learn about kernel level thread direct operating system management direct operating system management it will show True parallelism kernel level threads can be executed on multiple processor parall see at this diagram initially what we had the operating system as I as I told you there is transparency operating system will see them as the process instead of threads so it will maintain a process table only and the process will maintain the thread table now this was the user level thread now we comes to the kernel level thread this is the kernel space so in the kernal level threads you know these the the operating system knows that the threads are created here operating system doesn't know that in process threads are present that's why it has only maintained the process table here these threads are directly uh supervised by the operating system so operating system with process table also maintains the thread table because the these threads are acknowledged by kernels or operating system so with process table it will also maintain the threat table oper operating system is managing the process and threats both okay blocking handling unlike user level threads if one kernel level threads get blocked other keep running managed completely by the oper see when in the user level thread operating system see them as a process if one thread will be blocked operating system doesn't know that there are some threads inside the process so to block the operating system will block the whole process uh the process as a whole okay but in kernel level the operating operating system knows that there are different threads present so instead of blocking the uh the whole process it will block a thread only so in kernal level threads if one is blocked then others keep running and it is managed completely by the OS so less responsibility on the user but slower contact switching than user level thread you know that why is it slower because it involves complex data structur more scheduling overhead and due to Kernel level involvement the Contex switching time is more in the kernel level threads and in user level threads maintained at user level simpler data structures this will create or this will cause faster contact switching let's compare user level threads faster contact switching custom scheduling as it is maintained by the user less overhead but blocking issues or no true parallelism because the belong to a single process by the operat as what operating system know that this is a process this is a just a process it doesn't know that in that process there are threads living kernal Level Threats better blocking handling true parallelism better OS integration but higher overhead or slower contact switching let's read again and then we will close the lecture user level threads faster contact switching custom scheduling less overhead but blocking issues no true parallelism and in Cal Level Threats better block better blocking headling true parallelism better OS integration as managed by OS only but higher overhead and slower Contex switching system call and Fork this is our miscellaneous topic part two you know what is a system call this is our C program print f is in a standard C library want to use the system call right so we have to shift the mode from user to Kernel and after the work is done shift it back from kernel to user you know all these things uh we have learned in detail in our section one now the question is How are parameters passed from user to Kernel mode there are three methods the first one is register the second one is memory and the third one is stack if the number of parameters are less we can directly pass those parameters to operating system by placing them onto resistors and then resistors uh the operating system will access those parameters with those resistors if number of parameters are more than the resistors then we will store them in form of a table or in a block in memory and the block address will be passed to the resistors and with the help of that resistor operating system will access those parameters and the third one is stack we will place the parameters onto the stack and operating system will pop them off the stack and will use them this is used when number of parameters are less and these are used when number of parameters are more the same thing is written here three methods used to pass parameter to the the first or the simplest one is pass the parameters and resistor but what happens when the parameters are more than resistors store the parameters in a block or a table in memory and address of the block is passed as a parameter in a register this approach is followed by Linux or Solaris Linux and Solaris parameters placed or pushed onto the stack by program and popped off the stack by operating system block and stack method do not limit the number of number or length of the parameters being used okay so what we did this is X is the parameters for the call we stored the address of that block in the resistor and passed it onto the passed it to the operating system so address of the block of memory containing parameters this is X and it is passed to the operating system with the help of a resistor and operating system will access the system calls or the parameters now we should know some basic system call related to the process management file management and directory management here it is written you can read them all for Process Management file management for directory management and these are some of the miscellaneous system calls folk system call as you have already heard about it execution of FK system call results in the creation of child process the code of child process will be an exact replica of parent process everything will be copied just the duplicacy of process will occur execution in child will start from the next statement after Fork till the end of a program okay suppose this is my parent process here somewhere comes fork and some other lines of code then when this Fork will be executed the same code will be present in the child but the execution will start from this statement after the fork the above four lines before Fork will also be there in the child process but they won't be executed the execution will begin from the next statement after fork and as I've told you process is duplicated so there will be separate area for memory child and parent are independent no Master Slave relationship there is just the duplicacy of process and and one relation between child and parent is the code of both child and parent are same okay let's see here we have this is the parent process okay these two these two statements are of parent process now if I ask you the output of this code then firstly will the execution begin from Main this Fork Fork will be executed as soon as this Fork is executed creation of child process will occur but the execution in child will begin from the next statement after Fork so what will be the order firstly the fork of parent will be executed then print F that is print statement of child will be executed and then it will go back and then the print of parent will be executed and this child will will have will be exact replica but execution will start from the next statement after Fork so if I ask you the output then Fork this print statement and this then this printing statement they will print hello two times so hello and hello will be the output see this print F High fork and print hello so firstly this print F high will be executed so high will be printed then Fork execution of fork will result in the creation of child process so this process will this child process will be there code will be exact same but execution will start from the next statement so firstly this will be executed then this then this and then the meaning it will the control flow will go back to parent and then execution will start after the fork so here print F will be printed or or hello will be printed which is hello so what will be the final output hi this is printed Fork execution of child execution will result in the creation of child process then hello from child will be printed and then hello from parent will be printed so hi hello and hello will be the output see this we have three folks now and and in the end I have print F hello look it carefully how the control flow goes this is the parent process and 1 2 3 4 these are the statement numbers first for executed creation of child process code will exact same which means these four statement will be same in all of them so 1 2 3 4 here also but execution will begin from next statement after four which mean from two what is the next statement again for so execution of this will will result in creation of another child process execution will start from next statement after Fork what is the next statement again Fork the execution of fork will result in the creation of child process execution will begin from begin from next statement after for what is the next statement hello hello will be printed control flow goes back see three was already executed now again hello will be printed control flow goes back now three what is three Fork execution of fork will result in the creation of child process now in child process execution start after Fork so hello will be printed again control flow goes back now four which is hello hello will be printed again control flow goes back now this is statement what's this Fork execution will result in the creation of child process execution will start after four which is from statement three execution of three will result in the creation of another child process execution will start from next statement that is four hello will be printed control flow goes back hello will be printed control flow goes back now three what is three four will result in the creation of another child process execution start from next that is four hello will be printed so how many times hello will be printed 1 2 3 4 5 6 7 and 8 so in the exact same order hello will be printed okay so firstly this hell printed control flow goes back this hell printed control flow goes back but here this statement control flow now goes back this will be executed control flow goes back here down there this will be executed goes back this will be executed here this will be executed and then in the last this four will be executed okay see if you are losing somewhere don't worry create create on your own when you will create this tree on your own then you will get the idea how this is executed just remember two points what I have told you execution of fork will result in the creation of child process and the execution in the child process will start after the fork statement and all of the code will be copied in the child process also but the difference is execution will begin from the statement after the fork okay let's move to this I have main print one fork print two Fork print three so what will happen these are the five statements I have 1 2 3 4 five statements in the parent process one will be printed now Fork execution of fork will result in the creation of child process 1 2 3 4 5 all will be there but what will be printed execution start after Fork so three third statement that is which is two two will be printed and then four this four will be executed which will result in the creation of another child process execution will start after this for so three will be printed okay so how does it goes one is printed and then two is printed and then three is printed and then it goes back it goes back three is printed it goes back this four Fork result in the creation of child process three is printed goes back three is printed so 1 2 1 2 3 3 2 3 3 this will be the order 1 2 3 3 2 3 3 let me show you again 1 then it goes here two then it goes here three then it comes back three it comes back two and then it goes down here three and then it comes back three so this will be the order okay now you may have guessed from this that when I was using when I was using a single Fork hello was printed two times when I was using Three Forks hello was printed eight times so if I have used one fork then two process will be created two forks four process will be created Three Forks eight process will be created if I used n Forks then 2 power n process will be there but remember remember remember this will these also include the parent process see here when I had one fork when I had one fork then there were two process this process and this process which also included the parent process so if someone ask I have n number of folks what will be the ch process 2^ n and then minus one why minus one because of this 2^ n also include the parent process but we are asked with the child process that's why 2^ n minus 1 return value of for if I write something like this int a equals to Fork this when this statement will be executed when this statement will be executed then there will be a new child process with the same code but the value of fork will be different in both of them for parent process the value of fork will be positive but for the child the value of fork will be zero who maintains that the O Fork routine see here I have a code like this main int return return equals to fork and if the return value equals to equals to zero then this will be the child process code and if else then this will the parent process code and rest when no condition is present then it will be executed by both child and parent what is the use of the return value the four can return three value it can return either negative zero or positive if it returns positive then it represent the parent process if it returns zero then it represent the child process and if it returns negative then the execution of fork was a failure okay so let's say this was our program this was the parent process so the value of fork for parent process will be something positive so we have written here one who will maintain this Fork routine of the operating system so one is present here return equals to Fork if return equals to equals to zero well this is not zero so this part will not be executed lse part will be executed and the part which is not conditioned will be executed did you get it I have defined or I have declared the return variable okay so there is a return variable return equals to Fork as soon as this Fork will be executed because this is a parent process so some positive value come here and a child process will be created with return value zero did you get it here I have declared the return value return variable is declared here with some garbage value in it return equals to Fork as soon as this line is executed return equals to Fork this one will come here or any positive value will be stored in the return and the execution of fork will result in the creation of child process so the child process same thing are present same variable is declared here also but the value of return will be different the value of return will be zero here this zero will represent that this process is the child process and the positive number will represent that this process is the parent process and who will maintain these numbers of return os4 routine okay so what happens here if return is one or any positive value then this part will not be executed this part and this part will be executed and if return is zero then see this will this will not be executed because I've told you that execution in child will start after the 4 key statement so execution will begin from here is the return value zero yes go inside the block else part will not be executed this will be executed why because this is not conditioned so this the part of the code which is not condition is executed by both child and parent okay see this question I have main int AAL to 5 b = to 3 and C C = to ++ a mtii b ++ okay print f a b c if Fork = toal to0 then a = to a + 5 b = to B + 3 print F ab and C = to cus 1 otherwise which means this will be the parent process code b + a b + = to a plus = to 2 C I have also included some uh I have also made this question trickier by including the concept of c c language print f a comma b c = to C minus1 and then print f c so if you see clearly this part this if block will be executed only by fork and will be ignored only by child and will be ignored by the parent this part will be executed only by the parent and will be ignored by the child and this part will be executed by both try to solve this question okay so I have initially five 3 and let's say Zer is present in the C now what happened C equals to Plus+ a * b++ this Plus+ a says increase the value first and then use so I increase the value first 5 to six and then used here and the value of a is also updated this b++ says use the value of B+ and then update so I've used the value of B that is three here and then updated it to four now what is c c is 18 so from here I got C is 18 print a b c we printed a BC a is 6 B is 4 and C is 18 this will be printed now this part will be executed by child only this part will be executed by parent only and this part by both so let's see the child part first the value of a is the value of a is a + 5 so value of a will be 6 + 5 which is 11 now the value of B will be what is the value of B 4 4 + 3 = 7 print AB so we have print 11 and 7 and then C = to C 1 what was C 18 17 will be there then then what is there this part part will be executed by both so print C which is 17 will be printed also now comes the parent part in parent part what is written b + B+ = to a plus = to 2 so what will happen we have to solve from here AAL to a + 2 what was a here the value of a what value of a will you use will you use 11 or will you use 6 obviously I will use six only why see you may get confused by by seeing this code you may see that this is the block and this is the part of same code so when I have updated the value of a here and then when this else block will be executed then updated value should be used because it is the part of same code then you are making a mistake because let me let me write clearly what is the part of or or I can say how parents see the code the parents see the code as this part this part and this part how child see the code this part this part this part and this part for child this part is not present and for parent this part is not present you must remember that parent and child are different process with different piece of code do not try to think that there are some there are some uh same process with same piece of code no for child this is not present in its code section and for parent this is not present in its code section so what will the value of a which I use for this parent I will use the updated value which is six so I will use six here so 6 + 2 is 8 6 + 2 is 8 and B = to B + a so what was b b was 4 so 4 + 8 = 12 now print AB this part will be executed print AB 8 and 12 will be printed and then C = to C minus 1 C equals to C that is 17 and then in the end this 17 so this is how it works do not try to think that they belongs to they belong to some same piece of code or same process no I have told you the only relation between child and parent is their code is same otherwise they are two different processes with different piece of code did you get it so I will not use the value of a which was updated here at the parent section because for parent this piece of code is not present in its code section and for child this piece of code is not present in its code section okay let's solve some more interesting problems we have a main function int Inn for I = to 1 I less than = to n++ I if 4 = to = to 0 Print Star see this is in the for Loop and how many times for Loop is Run 1 to n so this will be executed n times so when during the time of condition checking this system call will be made and what will happen creation of child process so this four could be executed how many times n times as the four Loop has run n times so this four could be executed n times how many times or how many total processes will be there 2 power n but in child process only this code will be there if for equals to equals to Z then Print Star this Print Star is present in the code for child process only for parent process the parent process will just ignore this code so out of 2^ n one process is the parent process and 2^ N minus 1 is are the number of child process this one process which is the parent process will ignore this code and rest of them will print star so how many times the star will be printed 2^ n minus one by during the solving during solving this question a confusion may arise that is this node is the parent of this node so so here should be one and here should be zero isn't it no this is wrong there's only one parent and rest are child it doesn't matter where child produces another baby but they'll both remain a child to a parent so there will be only one parent and rest are child for that parent okay so the child of a child is also a child to a parent okay let's see some more interesting problems we have int I and N for I = to 1 I is less than equal to n Plus+ I so this Loop will also run for n times if I mod 2 = to equal to0 it says from 1 to n from 1 to n n by2 will be the even numbers so this will run for n by2 times so this represent the even numbers so for all those even numbers run the fork from 1 to n the number of times even number come run this Fork so how many times Fork will be run n by two times so how many child processes will be there 2 ra to Power number of time number of times four qu run minus one so how many times four n by two times so the total number of child processes will be this much let's see another question but now here is the change int I comma n for this Loop will run for end times if 4 equals to Z here is the end and you know we have no brackets after the for Loop or we have no brackets like that here when we do not apply brackets then the next line the next line will be considered in the loop when we do not apply bracket then the next line only will be considered in the loop so for this for Loop this line was considered and here also we did not apply bracket so this line will be also considered so these two line will be considered in the for Loop but here what happened here we have applied a semicolon here which means this will not be in the for Loop now so this will be printed or this will be executed how many times n times so how many child processes will be there this Fork was executed n times so this will create 2^ n minus one child processes and child process has not to do any specific work see here what I've told you if Fork equals to equals to zero and some body is there then this these line of code will be executed only by child process but here there are no specific such lines so child process will not execute any specific code that parent will not execute this is outside the loop so this will be executed by both child and parent so how many times the star will be printed 2^ n minus 1 times by the parent and One Time by child also so 2^ n * the star will be printed did you get it see if Fork equals to Z and some if some bracket will be there and some lines of code then these will be executed only by child process and rest will be executed by both child and parent but here child has nothing specific to do so both child and parent will execute this line how many times the number of process how many total process are there 2^ n so this will be executed 2^ n times okay so the number of times will be 2^ n see this Main in a if Fork equal toal to 0 a = to a + 5 and print a else a = to a 5 and then print a what is the relation between U and X so a is not initialized here so what we are doing we are just taking for the sake of Simplicity a equals to Z remember when the values are not initialized garbage value is present but for the sake of Simplicity now we are taking a equals to 0 if Fork equals to equals to0 here Fork has come so creation of child process will be there now there are two process a child and a parent both child and parent both child and parent has has nothing common child will execute this code and the parent will execute this code and there is nothing outside the fs so there is no common thing that the both child and parent will execute initially we have taken AAL to 0 so for child a = to a + 5 so value of a will be 5 and then it will print five see like this I'll give the statement one the statement two and the statement three int a executed two two now this is the parent process so for parent process which piece of code is present this piece of code we have taken initially the value of a is zero so value of a will be minus5 and it will print minus5 and at the same time the child process is also present and the execution will start from the next line after the fork what is the next line a = to a + 5 so a = to A+ 5 a was initially zero now a equals to 5 print five okay print five and this part is not present in the this part is not present in the child and this part is not present in the parent so what is the relation between U and X let's say the U it is U is 5 and X is 5 so what is the relation I can say u = x + 10 well u = x + 10 okay note what is the note physical address will be different virtual virual address will be same physical address of variable in child and parent will be different but virtual address will be same because what is virtual address virtual address is related to the code both code in child and parent is same so the generation of virtual address will also be same but as they are to different process so the physical address will be different see if uh you can try this at your home also try to create a child process and try to print the virtual address of a variable you will see that virtual address uh you will see that both address of parent and child of that variable will be same both the address will be same then how can I say physical address are different see on printing we get virtual address so those virtual address will be same but physical address where the variables are or the data are actually stored in the memory will be different for the different process okay and child and parent are actually two different process so for the physical address will be different but virtual address of the variables will be same till now we have completed the fork system call threads and multithreading now it's time to learn about inverted page table or reverse paging you know that page table also consume space so this is a technique to reduce space overhead of page table in page each process will have its own virtual address space and Page table so this is the virtual address space it generates the virtual address or logical address this is page number here we will see the frame in which that page is stored this Frame number will be copied here and D will be copied here there we got our physical address space okay so this was the concept of paging but you remember that each process will have its own virtual address space suppose this is process I and this is process J process I will have its own virtual address space and its own page table process J will have its own virtual address and its own page table okay so the pages of this process J and the pages of this process I are mapped onto the same physical memory see here the pages of let's say process I and process J are present in the same main memory suppose this is this p 0 and this p 0 both have same name so this p 0 is present here and p 0 is present here so what happens in the frame table in the frame table so this is the frame number and this is the page number of the process we also include the process ID because otherwise it will cause confusion that this page number one is of which process page it may be page number one of process I it may be page number one of process J and there are so many process it could be page number one of any process that's why we have another section which will uh store the process ID with the page number so this is the frame number this index will tell that at frame number four at frame number four process I process I page process one is stored so this will be copied here and D will be copied here and you know when process will generate The Logical address with page number it will also tell the ID so we call this page number and ID combination as key so this is the key so we will search with this key in the frame table and number of entries will be equal to number of frames the point is Pages all the processes are being mapped on the same physical address space pages of all process are being mapped on the same PS can't we design a page table based on the the PS some kind of global page table for each process see what are we doing here we know that each process will have its own page table so instead of keeping page table instead of uh having page table for every process why can't we just create a global page table see you know that the pages of this process and the pages of this process are both at the same place can't we generate a global page table from the help of this we will access the pages you getting the point let me repeat both the pages of this virtual address and this virtual address space are being stored at the same place can we generate a global page table for all the processes can we generate that kind of architecture this will going to significantly reduce the page table overhead so we are trying to create some CL some kind of global page table so in inverted paging one Global page table is used used by all the process in traditional approach let's say we have 100 process then we will have 100 Pace tables so to save his spce sacrifice time to save space sacrifice time but the search will increase in in traditional the search time was constant but here the search time will depend on the number of entries so the search time will increase but space will be significantly saved when we'll see some problems then you will going to realize how much how much drastic change has come by using this Global page table and you know page table size is not less and if we somehow are able to combine all those pages all those page table characteristic into one page table then it will going to revolutionize let's see this we have a virtual address of 34 bits page size is of 8 KB physical address is of 29 bit page table entries of 32bit what is the size of page table traditional versus inverted virtual addresses space will be 2^ 34 page size we know 8 KB so number of pages or number of entries in the traditional page table will be 2 21 and the size of each entry is 4 by so here it will be 8 MB the total the page table size per process will be 8 MB and how many processes are there no we are talking about just one process so the total page table size will be of 8 MB number of entries in the we are talking now about inverted page table so number of entries will be equals to number of frames how many frames are there 2^ 29 and what is the uh page size 2^ 13 so we'll have 2^ 16 entries the table size here will be 2^ 16 into 2^ 2 as each entry will have four bytes so we will have 256 KB only see in the traditional case in the traditional case we have P pce table uh size per process 8 MB and here we have the global page table of 256 KB now let's say there are 100 process then traditionally it will it will require 800 MB of memory to store the page table only and in inverted no matter how many processes are there all of them are going to use a global page table 256 KB only did you get it let me repeat again the problem was each table will have its own virtual address space and and will have its own page table this virtual address space won't create a problem because it is mapped on the hard disk and hard disk has enough size but the page table is stored in the memory and each when each process will have its own page table then what are we doing traditionally we are storing each page table into the memory but we know what that the pages of the virtual address space are stored in the frames of the memory so these pages are also stored in the memory these pages are also stored in the memory all of them are mapped on the same physical address pages of all process are being mapped on the same physical address can't we design a page table which is global page table through which we can address or we can uniquely identify the page or we can uniquely identify the frame in which the desired page of the desired process is present that's what this Frame table has helped us to achieve let's say CPU generated The Logical address here with the logical address there is a little bit difference in page number we also have the ID of the process so this page number and the ID will create a key and with this key we are going to search in this Frame table and what does frame table contain the index contains the frame number and the entries contain the page number and the ID so this P1 is present here also P1 is present here also if ID won't be there then how I'm going to identify this P1 is of which process it may be of process Pi it may be of process PG so ID is also present now search with this key in the frame table in the traditional approach what we were doing we were searching based on the based on the index number see what are we doing in the traditional we were searching based on the index number this P was searched at this that's why the time taken to access that particular uh access the particular frame number or the time taken to acquire that particular frame number was constant why because we can directly jump to that index we can directly jump to that index but here we have to search we are not searching through frame number or the index we are not searching through index we are searching based on this key we will search for each and every entry in the list suppose the CPU want to or the process want to access the frame in which page number one of process I is present so it will generate an address like P1 and I okay so P1 and I now it is going to search is P1 and I is present P1 I P1 I P1 I no I got P1 I which index has or which index has a stored this P1 I index 4 is a stored so this will be copied here and D will be copied here and that's how I got my physical address now each of them each of the process is going to use this single frame table instead of having own each instead of having its own table own page table every time we are using a global page table or we call it as frame table index contain the frame number and with the help of this key we search each and every entry wherever we get the entry that index will be our answer and we are going to take that index forward as the frame number and D will be copied here that's how I got my physical address traditionally what we were doing with the help of this page number we were directly jumping to the index and the entry was our answer here the entry is not the answer the index is the answer the index is what we want so index will be copied here this D is present here that's how we get the physical address okay so what we did the all the pages of the process are mapped on the same main memory so why can't we generate a global page table that's what we have tried to achieve here with the help of this Frame table so inverted paging one Global page table is used by all the process in traditional approach 100 process will have 100 page tables but in uh inverted page table process no matter how many processes are there there will be only a single page table which is global page table or we also call it as frame table but the drawback is here we can directly jump to the index and find the frame number quick quickly but here we have to search each and every entry so what will be the search time o n and what will the search time the constant okay so this question we have tried remember one thing that number of entries will be equals to number of frames here the number of pages were being used as index and here the frame is used as index so how many indexes will be there the number of frames so how many entries will be there equals to the number of frames okay so here the page table size the traditional page table size we got was 8 MB and and here we got the page table sizes as 256 KV now if there are 100 process then the traditional approach will consume around 800 MB and the inverted page table approach will consume just 256 KB if it were th000 process then it will consume 8,000 MB and inverted will just consume 256 KB did you get it how simple this is can you compare the size this is nothing in front of 800 MB
