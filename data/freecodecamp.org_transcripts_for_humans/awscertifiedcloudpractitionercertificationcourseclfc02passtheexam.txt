With timestamps:

00:00 - hey this is Andrew Brown over here on
00:02 - free Camp bringing you another free
00:04 - Cloud certification study course and
00:06 - this time we are looking at the ads
00:09 - Cloud practitioner also known as the CF
00:12 - C02 and the way we're going to achieve
00:14 - ads certification is through lectur
00:16 - content Hands-On labs and as always I
00:19 - provide you a full free practice exam
00:21 - the best way to support uh more free
00:24 - study courses like this one is to
00:25 - purchase the optional paid additional
00:28 - materials it's going to help you on your
00:30 - exam and it's going to allow me to
00:31 - produce more of these uh great Cloud uh
00:34 - certification study courses if you don't
00:37 - know me I'm Andrew Brown and this is the
00:39 - fourth time I've taught this uh
00:41 - certification so it's really refined at
00:43 - this point and I've taught a bit of
00:45 - everything in the cloud so we've looked
00:47 - at adabs Azure gcp terraform kuber dedes
00:50 - you name it I've taught it uh but that's
00:52 - about it and I will see you in class in
00:55 - the next video
00:58 - ciao
01:01 - hey this is Angie Brown and we are at
01:02 - the start of our journey asking the most
01:04 - important question first which is what
01:06 - is the adus cloud practitioner well it's
01:09 - ad's entry level certification that's
01:12 - going to teach you things like the cloud
01:13 - fundamentals so we're talking cloud
01:15 - Concepts architectures deployment models
01:18 - it's a close look at adus core Services
01:21 - which would be our compute our storage
01:22 - our Network our databases and it's a
01:24 - quick look at the vast amount of adus
01:27 - services and functionality around adus
01:29 - so we're looking at identity security
01:32 - billing pricing support and a lot more
01:35 - stuff and we'll get into that in the
01:37 - course and we'll even look at the exam
01:38 - guide outline but uh yeah there is a lot
01:41 - of stuff um the course code for this
01:43 - certification is now the clf C02 the old
01:47 - one was the
01:48 - c01 uh the way to know if there is a new
01:51 - course is if this becomes the c03 if you
01:53 - see that then this course um may be out
01:56 - of date um but uh yeah right now it's a
01:58 - C02
02:00 - um often people refer to this
02:02 - certification as the CCP to stand for
02:05 - the certified clock practitioner how you
02:07 - want to refer to it is up to you but uh
02:09 - there are a few ways of describing this
02:12 - certification I want to point out that
02:14 - adus is the leading cloud service
02:16 - provider in the world and the cloud
02:18 - practitioner is the most common starting
02:20 - point for people breaking into the cloud
02:22 - so even if you're going to uh utilize
02:25 - another cloud service provider I'm just
02:27 - going to say that you're going to get a
02:28 - really good uh Foundation with this
02:30 - certification even if it's not the uh
02:32 - same provider uh so who is the
02:34 - certification for well consider the
02:36 - cloud practitioner if you are new to
02:38 - cloud and you're learning the
02:39 - fundamentals you are at the executive
02:41 - management or sales level and you need
02:43 - to acquire strategic information about
02:46 - Cloud for adoption or
02:48 - migration or you are a senior Cloud
02:50 - engineer or Solutions architect who
02:52 - needs to reset or refresh their adus
02:54 - knowledge after working uh with cloud
02:57 - services or adus for multiple years
03:00 - um it's always a surprise that when I
03:02 - come back and I refresh this course uh
03:04 - the things that have changed and it's
03:05 - very easy to uh miss those things so
03:08 - yeah this this certification is for
03:10 - everybody so what is the value of the
03:12 - certification well this uh certification
03:15 - provides the most expansive view
03:17 - possible of cloud architecture and ads
03:20 - it uh we I would describe this as having
03:22 - a bird's eye view or the 50,000 ft view
03:25 - so with that in mind uh the idea here is
03:28 - to promote big pictures thinking we're
03:30 - zooming out and assessing the cloud or
03:32 - itus landscape for things like changes
03:35 - Trends opportunities um and it's
03:38 - important to understand about being
03:39 - strategic about the approach and process
03:41 - for your journey and that's why I like
03:43 - the certification so much and I strongly
03:46 - uh recommend it for everybody's Journey
03:49 - so what is the value of the
03:50 - certification well it's not a difficult
03:53 - exam uh it's it's not going to validate
03:55 - that you can build Cloud workloads so if
03:58 - you are trying to obtain a technical te
03:59 - implementation role like develop Cloud
04:01 - developer Cloud engineer devops engineer
04:04 - uh it's not going to be enough to attain
04:06 - those technical Cloud roles um but it
04:09 - could help short list your resume for
04:10 - interviews um the exam covers content
04:13 - not found in other certifications so it
04:15 - is recommended as an essential study
04:16 - guide uh for your adus journey do not
04:19 - skip this one uh some people like to go
04:21 - straight to the solution to architect
04:23 - and then they realize that they didn't
04:24 - set a good foundation or they just have
04:27 - gaps uh in their knowledge which could
04:29 - really help out in their careers so
04:31 - really do not skip this one um I like to
04:33 - make these road maps to give you an idea
04:36 - uh in terms of where you can go after
04:38 - this certification so here is uh all the
04:40 - certifications currently that AOS has
04:43 - notice that I have the data engineer
04:44 - it's a really small one it just became
04:46 - uh came out as a baa exam it's not as
04:48 - hard as the professionals it's just
04:50 - where I place it on this diagram um but
04:53 - the idea is that we have a lot of
04:54 - different ways that we can navigate or
04:57 - uh work through these certifications and
04:59 - these can generally map to particular
05:01 - roles in the cloud so uh very often
05:04 - people go right to the uh Solutions
05:06 - architect I'm just getting my pen out
05:08 - here but very often this is the approach
05:10 - that'll go straight to here uh right
05:12 - after the solution architect because
05:13 - they're very similar um in terms of uh
05:16 - scope and Challenge and difficulty where
05:19 - the solution architect is a broad
05:20 - certification just like the cloud
05:22 - pratitioner but it's more focused on the
05:24 - technical knowledge uh whereas this one
05:27 - of course is much more broad the cloud
05:30 - and then after that people will
05:31 - generally go for the developer or the
05:32 - CIS office administrator in my personal
05:34 - opinion I really do think that people
05:37 - should study all three Associates and do
05:39 - all three Associates at the same time uh
05:41 - because really I don't find that uh it
05:44 - makes sense to leave out the ssops admin
05:46 - or developer knowledge um it's just the
05:48 - way that itus Engineers their
05:49 - certifications but when you go to other
05:51 - ones like let's say Google they only
05:53 - have one associate and they have all the
05:56 - um they call Cloud engineer and it has
05:58 - everything in it and so again I just
06:00 - feel like you should take all three but
06:02 - you decide what works for you um and you
06:05 - know you can see that there are various
06:07 - routes but I want to just make it very
06:08 - clear that certifications do not
06:11 - validate programming they do not uh make
06:14 - you do technical diagramming they don't
06:16 - necessarily make you do code management
06:19 - and there's many other technical skills
06:21 - that are required for obtaining
06:22 - technical roles like these roles um and
06:24 - that is not the purpose of certification
06:26 - certification is supposed to give you
06:28 - knowledge specifically on AWS and so
06:30 - just understand that you need to make
06:32 - sure you get those skills uh somewhere
06:34 - else I do try to uh slot in a lot of
06:38 - these uh technical skills uh where I can
06:40 - and so if you're uh if we're doing
06:42 - something in the course and you're
06:44 - wondering why are we doing this when
06:45 - it's not on the certification it's
06:46 - because I'm trying to give you those
06:47 - adjacent skills uh so that you are
06:50 - successful um in the future okay so how
06:53 - long does it take to uh study to pass
06:56 - this exam well depends right it depends
06:59 - but if you're a beginner we're probably
07:01 - looking at 30 hours so this is someone
07:02 - who's never used databus or cloud
07:04 - provider before uh you've never written
07:06 - code or had a technical role if you're
07:08 - experienced uh your study time is going
07:10 - to be very low like as low as 6 hours
07:12 - even lower uh if possible um especially
07:15 - if you've already taken the
07:16 - certification I sat it um uh blind right
07:20 - I didn't look up anything and I passed
07:22 - it no problem um but uh so it says here
07:25 - you know if we've practiced we have
07:27 - experience working with ads if we have
07:29 - an equivalent experience in another
07:30 - cloud service provider some people are
07:32 - coming over from Azure or gcp so they
07:35 - can kind of map their knowledge over to
07:37 - Ada of us or if they have a strong
07:39 - background in technology uh you might
07:41 - really be already familiar with these
07:43 - kind of offerings from
07:45 - another uh like from another discipline
07:47 - and so your study time can be really low
07:49 - but I would say that um you know the
07:51 - average study time is probably 24
07:54 - hours so yes it's closer to the beginner
07:57 - level but that's the average study time
07:58 - that we found in and so it's basically a
08:00 - split between 50 lectures and Labs so
08:02 - labs are Hands-On skills and 50% with
08:05 - practice exams uh a lot of people forget
08:08 - that practice exams are part of the
08:10 - study process so make sure that you do
08:12 - do that uh we do recommend a study a
08:14 - study time of one to two hours a day uh
08:16 - for 14 days uh what does it take to pass
08:20 - the exam we're still going on with this
08:21 - here but you know you have to watch
08:23 - those lecture videos and memorize key
08:25 - information this is a knowledge based
08:27 - exam it's not a uh it does not test your
08:29 - skills so knowledge is key here uh you
08:31 - should do Hands-On Labs we call those
08:33 - follow alongs within your own account uh
08:35 - this is just going to help uh cement the
08:37 - knowledge in your head it really makes a
08:40 - a huge difference so really do those
08:42 - Hands-On labs and get practice exams to
08:45 - simulate the real exam you absolutely
08:47 - need to do this because if you don't
08:49 - you're going to find that you did all
08:51 - the study materials and then uh the exam
08:54 - is its own uh Beast so make sure that
08:57 - you go get some practice exams there's a
08:59 - lot lot of places that you can get get
09:00 - them from uh we offer a full free
09:03 - practice exam I think we're the only
09:04 - provider that does this but um we give
09:06 - you like a full free practice exam and
09:09 - we also have some paid ones so the best
09:11 - way to support this this content that we
09:13 - produce is to purchase our additional
09:15 - paid materials uh if you don't have the
09:17 - money that's okay we still have at least
09:19 - one full free practice exam to help you
09:21 - out you can find that over at exam
09:23 - pro. cfy
09:27 - C02 it looks like but it's a zero uh
09:31 - let's talk about the content outline so
09:33 - there are four domains and you have to
09:35 - understand that each domain has its own
09:36 - waiting this is going to determine how
09:38 - many questions in that domain will show
09:40 - up on your exam the first one is cloud
09:42 - Concepts so that's for 24% so we're
09:45 - looking at between 15 to 16 questions
09:47 - domain two is about security and
09:49 - compliance so that's 30% it's a a quite
09:52 - high up there so we have about 1920
09:54 - questions for cloud Technologies and
09:56 - services it's 34% so understanding the
09:59 - offerings of adss is the most important
10:01 - thing in the exam it's the highest
10:02 - percentage here so we're going to
10:04 - definitely get 22 questions and then uh
10:07 - we have domain four so billing pricing
10:08 - and support where it's at 12% so we have
10:12 - eight questions not a lot for billing
10:14 - pricing support definitely important
10:16 - because it's very easy to get overbuild
10:17 - in the stuff but just you know point out
10:20 - that you need to know a wide range of
10:22 - adus services you need to know about
10:24 - core Services more in depth so where do
10:26 - you take this exam well you can take it
10:29 - at the um at an inperson test center or
10:32 - online from the convenience of your own
10:33 - home I personally like to take it in a
10:35 - test center if there is one near me I
10:38 - used to live in Toronto now I don't so
10:40 - there's no test centers near me and so I
10:42 - have to do it online it's just so much
10:44 - less stressful walking into a building
10:45 - and everything is uh controlled whereas
10:48 - at home you might have a lot of things
10:50 - going on and that can cause a lot of
10:52 - stress but you know do what makes sense
10:54 - for you so adus delivers the exams via
10:56 - Pearson View and so uh there's Pearson
10:59 - view they have the online system which
11:02 - you do uh you install on your computer
11:04 - and then they also have a network of
11:06 - test centers they partner with uh
11:08 - previously adabs also offered it via PSI
11:11 - um they don't do this anymore I'm not
11:13 - sure why they changed this before it was
11:15 - only PSI then they added Pearson and now
11:18 - they've dropped PSI so your only option
11:20 - is Pearson view I just want to point out
11:22 - what a prct exam means it means that
11:24 - it's it's someone is supervising uh your
11:28 - um your exam while you're taking it so
11:30 - you're not cheating so it's very common
11:32 - that when you check in they're going to
11:35 - ask to look around your room you might
11:37 - even have to talk to them uh and it's
11:39 - just again to make sure that what you do
11:42 - is um your exam was legit legit so when
11:46 - they issue your badge you know it's for
11:48 - real anyway let's talk about grading
11:50 - here so the passing grade here is 700
11:53 - out of a a th000 points and so you need
11:55 - to get around 70% to pass ad of us like
11:58 - many other Cloud providers use scaled
12:00 - scoring so um that doesn't mean if you
12:03 - get exactly 70% that you'll pass but uh
12:06 - I mean more or less it works out to to
12:08 - be that okay so the response types uh we
12:11 - have here well first of all we have 65
12:13 - questions and there are 50 questions
12:16 - that are scored and then there's 15 that
12:18 - are unscored and if that sounds bizarre
12:22 - I mean I I agree with you I think it's
12:24 - odd that they give you 15 unscored
12:26 - questions but the reason ads will do
12:28 - this is that they want to introduce new
12:30 - questions um to help test against the
12:33 - difficulty of the exam um because you
12:35 - know maybe some people know more than uh
12:38 - what they're expecting so they can
12:39 - adjust the difficulty of the exam I
12:41 - think that they use it as an anti-che
12:43 - mechanism as well but from the test
12:45 - taker it can get a bit stressful because
12:47 - you can get 15 really crazy wild
12:49 - questions that were not in your um uh
12:52 - course studies and it's just adab us
12:55 - testing things out and so I just want to
12:57 - point out don't get stressed out when
12:58 - you take this exam and you get a really
13:00 - funny question it's probably one of
13:01 - those unscored questions but on top of
13:03 - that you know there are 15 scored
13:06 - questions you can get wrong so you can
13:09 - get a total of 30 questions wrong on
13:11 - this exam and pass I just want to make
13:13 - that uh really clear there there is no
13:15 - penalty for wrong questions so
13:17 - absolutely always submit an answer and
13:19 - take your best guess the format of the
13:21 - questions are multiple choice and
13:22 - multiple answer so you know it's not too
13:25 - stressful in terms of the formatting of
13:27 - questions
13:29 - um there are again 15 unscored questions
13:31 - of the exam they will not count towards
13:33 - your final score why are there unscored
13:35 - questions uh they're there to evaluate
13:37 - the introduction of new questions
13:39 - they're there to determine if the exam
13:40 - is too easy and the passing score of the
13:42 - question difficulty needs to be
13:43 - increased to discover users who are
13:45 - attempting to cheat the exam or steal
13:46 - dump exam questions if you encounter
13:49 - questions you've never studied for uh
13:50 - that seem really hard keep your cool and
13:52 - remember that they may be unscored
13:54 - questions just really want to emphasize
13:56 - that there in terms of the duration you
13:58 - get 1.5 hours so you have about 1.5
14:01 - minutes per question your exam time is
14:03 - 90 minutes your seat time is20 minutes
14:07 - what are we saying when we say seat time
14:09 - this is the time it takes uh or that you
14:11 - should allocate for the full exam uh
14:15 - that includes uh things like reviewing
14:17 - the instructions uh showing on uh
14:19 - showing the online Proctor your
14:21 - workspace reading accepting the NDA
14:23 - completing the exam provide the feedback
14:26 - at the exam so a lot of people go okay
14:28 - my exam starting or I have 90 or 90
14:31 - minutes exam but really you want to show
14:33 - up 30 minutes prior uh because that
14:35 - checkin process can be really really
14:37 - stressful so you know just consider that
14:40 - uh the full scope of time you need to
14:42 - dedicate for these exams this uh
14:44 - certification is valid for 36 months so
14:47 - that's 3 years before recertification
14:49 - some other providers uh like Azure if
14:52 - you do the fundamentals it's forever um
14:54 - other ones have require you to refresh
14:57 - every year other ones um you don't have
15:00 - to take the full exam you have a
15:02 - reassessment that is free inabus likes
15:04 - to do it this way the nice thing though
15:06 - is that when you do pass a certification
15:09 - um somewhere ads allows you to get the
15:11 - next exam half off uh so at least there
15:14 - are cost saving mechanisms if you do
15:16 - pass an exam for the next follow-up
15:18 - certification but yeah uh that is pretty
15:21 - much a breakdown of uh the exam guide we
15:23 - will go and take a look at the actual
15:25 - exam guide so we can uh understand the
15:27 - full scope of what's in there uh but
15:30 - yeah we'll see you in the next one okay
15:32 - [Music]
15:36 - ciao hey everybody it's Andrew Brown and
15:38 - we are here on the training and
15:39 - certification page on the adus website
15:42 - and what I want to do here is I want to
15:44 - pull up the exam guide so that we can um
15:48 - make sure that we know exactly what it
15:51 - is that we're getting ourselves into uh
15:53 - we did cover this in summary in the
15:54 - previous video but uh I think it's
15:56 - always useful for you to know exactly
15:58 - where these things are adabs is always
16:00 - changing their marketing pages and I've
16:01 - already noticed a few changes here so um
16:04 - just understand that's the nature of
16:05 - cloud notice here that it's talking
16:07 - about the uh beta exam certification so
16:09 - even earlier we talked about the data
16:11 - engineer or we at least showed it on our
16:13 - journey map and it's not even it's not
16:15 - even 100% out beta so you can see we're
16:17 - kind of prepping for the future here I
16:19 - also want to point out that they have
16:20 - this like certifications path uh thing
16:23 - and I I don't really like it because I
16:25 - don't think it's very accurate so the
16:27 - first thing they show is Solutions
16:28 - architect and they don't even say you
16:30 - need to get the other two associate
16:32 - certifications which you absolutely
16:34 - should do if before you go for your
16:35 - Solutions architect professional the
16:37 - data analytics is no longer a uh
16:40 - certification that adus is producing so
16:42 - this is an out-of-date document so I
16:43 - just want you to understand that these
16:44 - are marketing Pages they're here to
16:46 - maximize the amount of certifications
16:48 - you need to obtain my goal is not to
16:51 - make you take every certification my
16:53 - goal is to make sure that you are
16:55 - prepared uh to do the job and um I just
16:59 - want to you know help you avoid going
17:02 - down the certification route and getting
17:04 - too many certifications that aren't
17:05 - going to benefit you so just take these
17:07 - with a grain of salt when you're reading
17:08 - them okay so anyway what I want to do is
17:11 - drop this down and go to Cloud
17:12 - partitioner um and here on the cloud
17:15 - cloud practitioner page if we scroll on
17:17 - down we got prepare for the exam and
17:19 - here we'll click the exam guide and
17:21 - it'll open up a PDF and it'll give us
17:23 - all the information we need to know this
17:25 - is what AB has been doing for a long
17:26 - time is making these um examp guide PDFs
17:29 - which I really like uh but anyway the
17:31 - first thing we should do is confirm the
17:33 - course code so this one says CF CO2 so
17:35 - we know we are on the right track and
17:37 - then down below here it says this exam
17:39 - validates the candidates ability to
17:40 - complete the following task I want to
17:42 - highlight some key wordss
17:44 - explain understand describe and identify
17:47 - so understand that this certification is
17:50 - not checking whether you know how to do
17:52 - Cloud it's more if you understand Cloud
17:56 - um and the majority of aable
17:57 - certification
17:58 - in fact all of them are multiple choice
18:02 - and multiple answers so they can't
18:04 - really check if you were able to do
18:07 - something in Cloud so just understand
18:08 - the limits of certifications at least
18:10 - eight of the certifications based on
18:12 - their testing mechanisms so when it says
18:15 - Target candidate it's saying uh where
18:17 - you should be in order to pass this exam
18:19 - and so they're suggesting that if you
18:21 - had six months of exposure to adabs uh
18:24 - with Cloud design implementation operate
18:27 - operation then uh you should be able to
18:29 - pass it it's just weird uh worded
18:31 - strangely because it makes it sound like
18:32 - you should have this experience um
18:35 - before you even start studying which is
18:36 - not true they just mean like if you want
18:38 - to pass it you don't need six months to
18:40 - pass this exam that's crazy you just
18:42 - need what we recommended which was um uh
18:46 - the amount of hours we said the average
18:47 - hours is 24 hours so um I'm not sure why
18:50 - they put six months I guess it's just
18:52 - they're for those who are really having
18:54 - a hard time with Cloud they give you a
18:56 - lot of uh um scope or room there but you
18:59 - can see they're pointing out from non-it
19:01 - backgrounds recommended us knowledge
19:03 - Cloud concept security core Services
19:06 - economics that's that's just a repeating
19:07 - of the
19:08 - domains um notice it says job tasks that
19:11 - are out of scope is
19:13 - coding um Cloud architecture design load
19:17 - performance and testing I'm highlighting
19:19 - these three because I just want to point
19:21 - out that in associate level professional
19:24 - and Specialty they actually do ask
19:27 - questions around troubleshooting mation
19:29 - and I suppose they do architectural
19:30 - design but they never ever ever No
19:33 - certification in ads is going to test
19:35 - your coding skills architectural diagram
19:37 - skills and they're not really good about
19:39 - load and performance testing they have
19:40 - like use case scenarios but um just
19:43 - understand again the limits of these
19:44 - certifications coming down below to the
19:46 - response types we got our multiple
19:48 - choice our multiple
19:49 - response um so that's pretty clear there
19:52 - there is uh 50 scored questions there's
19:55 - 15 unscored questions so that is very
19:58 - clear C the uh the the the point system
20:02 - is based out of a th to th000 points the
20:05 - lowest you can get is 100 points I don't
20:06 - know how that works why like why can't
20:08 - you get zero points I don't know the
20:10 - passing score is
20:11 - 700 so that's what we need to score
20:15 - there then down below here it's just
20:18 - talking about the course outline and it
20:19 - actually has a comparison of the old clf
20:21 - co1 so we can take a look there and see
20:23 - what actually has changed so down below
20:26 - here we have our Cloud cont Concepts as
20:28 - security compliance our Cloud technology
20:30 - services our bilding pricing support and
20:33 - then it comes in and starts describing
20:35 - all this stuff now I need to make it
20:38 - very clear how IUS makes their exams
20:41 - they give you a huge list of things you
20:43 - need to learn but if you learn um each
20:48 - one of these things you can end up
20:50 - overstudying or you'll find that the
20:53 - like the exam guide outline is not one
20:55 - to one I'll give you an example we'll
20:57 - look at something else so I'm going to
20:58 - go to Hashi Corp here for a second Hashi
21:00 - Corp terraform
21:02 - certification as a as an example of how
21:05 - different adab certifications are so for
21:08 - hashicorp they will this is their exam
21:11 - guide they'll give you each of these
21:12 - items and you can be 100% sure that
21:15 - every single thing every one one of
21:18 - these things will show up on the exam
21:19 - one to one so it's very easy to know
21:22 - exactly what you need to study for um
21:25 - and uh if you know all these things
21:27 - you'll you will pass in us they list all
21:30 - these things but they won't all show up
21:33 - they they're pulling from a very large
21:35 - pool so to kind of narrow down what you
21:37 - need to study you need to have a good
21:40 - sense of um overall everything and and
21:44 - you're just going to get some things
21:45 - wrong but um anyway coming back here the
21:48 - first Cloud Concepts they're talking
21:49 - about the benefits of
21:51 - cloud so we have a section on benefits
21:53 - of cloud and so they talk about the
21:55 - value proposition so there's like six or
21:57 - nine of them I forget we have a multiple
21:59 - slides on that and so we're talking
22:01 - about economics scale benefits of global
22:03 - infrastructure advantages of high
22:05 - availability elasticity and uh agility I
22:08 - think we call these Cloud architecture
22:10 - terminologies because they're not really
22:12 - benefits I mean they are benefits of
22:13 - cloud but I I like to group them a
22:15 - little bit differently then we have
22:16 - identified design principles for abis
22:18 - Cloud so we have the well architect
22:19 - framework this uh was for the most part
22:22 - never in the clf1 for 90% of its history
22:26 - and then they decided last year or
22:28 - something to add it in um and it and uh
22:32 - before even wasn't even the solution
22:33 - architect associate but now it's even at
22:35 - this level and that's totally fine you
22:37 - only need to know it at a very high
22:38 - level so um it's not too difficult to
22:41 - learn but it it's a white paper it's a
22:43 - PDF that um you know just describes how
22:47 - adus thinks that you should design uh
22:49 - your architecture then we have
22:52 - understand the benefits of strategies
22:53 - and migration to the cloud so we have
22:56 - Cloud adoption strategies uh Cloud
22:58 - adoption framework so um this was this
23:01 - was not in the last exam but uh luckily
23:04 - I included it because I thought it was
23:05 - something that was very important and so
23:07 - I already have it in the certification
23:09 - course even from the last one they
23:12 - actually do ask quite a few questions
23:14 - around the cloud adoption framework but
23:15 - when you look at and again this one's
23:17 - like a white paper just like this one
23:19 - above here and we'll talk about what
23:20 - white white papers are if you if you
23:22 - never heard that term uh it'll make
23:23 - sense in the course but the cloud
23:25 - adoption framework um there's not a lot
23:27 - to it but on the exam they'll ask you a
23:29 - lot of questions around it so you just
23:30 - have to have good common sense um about
23:34 - choosing those answers if that makes
23:36 - sense um identifying appropriate
23:38 - migration
23:39 - strategies sure I guess so I never got
23:42 - any snowball questions um they they say
23:45 - snowball here we go down below here
23:48 - understand concepts of cloud
23:50 - economics so cost Savings of moving to
23:53 - Cloud aspects of cloud
23:55 - economics uh fixed costs compared with
23:57 - VAR able costs they're talking about U
24:00 - Opex Opex and
24:03 - capex understanding the associate of on-
24:05 - premise
24:06 - environments uh understand the
24:07 - difference between licensing strategies
24:09 - and adabs never ever really ever
24:11 - mentioned uh bring your own licenses
24:13 - ever in their certification courses and
24:16 - I never got this on the exam and other
24:17 - people I sat for the new exam never uh
24:20 - encountered this still good to know but
24:23 - I'm just saying that I don't know why
24:24 - it's listed in here because it's
24:25 - definitely not on the exam but it is a
24:27 - good thing to note the basic level
24:29 - understand the concept of right sizing
24:32 - um and maybe I'll go back and make a
24:34 - slide on that cuz I don't think I
24:35 - actually make a deliberate slide on that
24:37 - but I think what they mean there is
24:39 - understanding uh like how horizontal
24:41 - scaling and stuff uh stuff like that
24:43 - works but um again no questions on the
24:45 - exam for right sizing at least not from
24:48 - its technical definition like that
24:50 - identify benefits of
24:52 - automation I think there might have been
24:54 - one question of saying like hey which
24:56 - one lets you automate stuff and you just
24:58 - chose Cloud information but they really
24:59 - don't talk a whole they don't ask a lot
25:01 - of questions on the exam about iic
25:04 - infrastructure as a code identifying uh
25:06 - managed a services this is something
25:08 - they do a lot in exams like describe a
25:11 - service you pick it we have security and
25:13 - compliance so we have the Ed shared
25:15 - responsibility model you absolutely need
25:17 - to know that that for sure always always
25:20 - appears on the exam um customers
25:22 - responsibility they'll do this a lot
25:24 - they'll say like they'll give you a
25:25 - scenario of um of like a typical
25:29 - workload or resource and then you have
25:30 - to uh determine if it's the customers's
25:32 - responsibility or adab Us's
25:34 - responsibility describing responsibility
25:36 - of the customer itus share so again this
25:39 - is just all the share responsibility
25:40 - model still here describing how the itus
25:41 - respons responsibilities and customer
25:43 - responsibilities can shift depending on
25:44 - the the service used so yeah this is
25:48 - basically the sh responsibility model
25:50 - understand the it Cloud security governs
25:52 - compliance so uh compliance governments
25:56 - Concepts benefits of Cloud security they
25:59 - don't really talk about that uh they
26:02 - really directly ask that in the exam but
26:04 - yes we do cover that where to capture
26:06 - and locate logs that are associated with
26:07 - Cloud security they absolutely do not
26:10 - ask that on the exam I'm not sure why
26:11 - that's here um identify where to find
26:14 - A's compliance information that will
26:16 - absolutely be on the exam understanding
26:17 - compliance needs among Geographic
26:20 - locations and
26:21 - industries um sure I mean they're
26:23 - talking about we have a slide in this in
26:25 - the um Global infrastructure but it's um
26:28 - like data sovereignty and like gov cloud
26:32 - and things like that describing how
26:34 - customers secure resources for ads so
26:37 - just generally knowing the security
26:39 - services y that absolutely is on the
26:40 - exam identifying different encryption
26:43 - options I never got this on my exam I
26:45 - never heard of anyone else getting this
26:47 - but um if they are going to talk about
26:48 - this they're probably going to talk
26:49 - about it around S3 recognizing services
26:53 - that Aid in governance and compliance
26:55 - absolutely absolutely for sure that the
26:57 - you will get questions around uh things
27:00 - like fips or Hippa or like common common
27:04 - compliance certifications not specific
27:06 - datab best but just in general um here
27:09 - they're just talking about specific
27:10 - Security Services this is kind of a
27:11 - repeat of what they're talking about up
27:13 - here um but there's the say there's
27:15 - identity service governance service it's
27:17 - all the same thing here recognizing
27:18 - compliance requirements that uh vary
27:20 - among adus Services sure identify adus
27:22 - management capabilities so they're
27:24 - talking about IM am um the adus root
27:27 - account we got
27:28 - a separate slide on that uh principal of
27:30 - leas privilege absolutely absolutely
27:31 - will they will ask that there a single
27:33 - sign on also known as it identity Center
27:36 - I don't know anyone who's gotten this as
27:37 - a question on their
27:38 - exam but uh it's we got a slide for
27:42 - it understanding access Keys yep we
27:44 - cover that PO uh password policies
27:46 - credential storage Secrets manager
27:48 - systems manager um just a bunch of stuff
27:52 - identify components and resources of
27:53 - security describing a security features
27:56 - so ACL
27:58 - a wff security groups they really don't
28:01 - ask these on the exam so I'm just trying
28:03 - to make a point that they're asking for
28:05 - all this stuff and they don't even it
28:07 - doesn't even show up in the exam so um
28:10 - and you know we can just keep going and
28:12 - going through this and I can keep
28:14 - telling you what is and isn't but if you
28:16 - go down below it gets even crazier
28:18 - because they go any of this stuff could
28:19 - show up in the exam it's just like a big
28:21 - list it's
28:23 - crazy so you know I know that seems
28:26 - stressful but you know just follow
28:28 - follow me uh in this course and I you
28:31 - will absolutely pass if you go through
28:33 - my content you'll have no issue there
28:35 - and we'll avoid all the stuff that
28:36 - doesn't show up and don't stress out
28:39 - about this exam guide now let's go take
28:40 - a look here and see where the rebalance
28:42 - has changed so notice here that this
28:44 - went from 26% to 24% they never used to
28:47 - do this so I really appreciate this is
28:48 - now in the exam guide but we got 25 to
28:50 - 30% 33 to 34% 16 to 12% why they would
28:55 - reduce this one I don't know but it is a
28:58 - shuffle whatever um they of course
29:00 - increased uh the technology section more
29:02 - and did some basic rewarding support
29:05 - should have always been in there so it
29:07 - was always under that section but uh
29:09 - it's nice that they labeled it as such
29:12 - um so notice here it says no content was
29:16 - deleted from the exam and um this was
29:19 - the largest struggle for me for the
29:21 - certification because I already made all
29:24 - the content for the last one my old one
29:26 - is not spired and I was struggling
29:29 - because I already had this as well this
29:31 - is the only thing that they added that
29:33 - was new to the certification and then
29:35 - they just rework these numbers here and
29:37 - so um you know I just I added I did add
29:41 - more I add more Labs I added more um
29:43 - other stuff there but I'm just going to
29:45 - say like I don't know why they did an
29:47 - update from co1 to CO2 because barely
29:49 - anything changed now I shouldn't say
29:51 - that the exam questions did change I
29:52 - noticed that the exam questions um the
29:55 - quality of them kind of uh have dropped
29:57 - I'm wondering if they're using
29:58 - generative AI to generate out questions
30:01 - or or something but um there's something
30:03 - the quality of questions are are
30:05 - definitely um different and I would say
30:07 - that they're more uh they're not worded
30:09 - as clearly as they used to be for
30:11 - whatever reason um but anyway you'll
30:13 - still be okay it's totally fine uh
30:16 - recategorization of clf CO2 and so they
30:18 - just did a shuffle of um of these points
30:22 - and I again I really don't think that
30:24 - the the new one is better how useful is
30:26 - this exam guide I should probably give
30:27 - them uh survey feedback but anyway just
30:30 - give you an idea how much stuff there is
30:32 - in here do not stress out just stick
30:34 - with the course you'll absolutely pass
30:36 - uh and uh you know hopefully that gives
30:38 - you uh some better confidence there but
30:39 - we'll see you in the next one uh chiao
30:43 - [Music]
30:46 - chiao hey this is Andrew Brown from exam
30:48 - Pro and what we're looking at here is a
30:51 - free practice exam that I provide with
30:53 - you uh for this course and all you have
30:55 - to do is sign up on exam Pro you don't
30:57 - even need a credit card and you can
30:59 - redeem uh the free available content
31:02 - here and this is really up to date and
31:04 - very well simulates what you will see on
31:07 - the actual exam and it's a full set full
31:09 - 65 questions so you're getting a real
31:11 - simulation here but what I'm going to do
31:13 - is just start it off here we're not
31:15 - going to do the whole thing I'm just
31:16 - going to click through and show you a
31:17 - couple of them so you have an idea um
31:19 - the level of difficulty these questions
31:21 - are so the first question we got
31:23 - presented with here is which a support
31:25 - plans provide access to the seven core
31:28 - trusted advisor checks and so that is a
31:30 - question that you might need to answer I
31:32 - don't want to spoil this for you so I'm
31:34 - not going to tell you the answer we'll
31:35 - go to the next one so a large accounting
31:37 - firm wants to utilize OS to store
31:39 - customer accounting information in
31:41 - archive storage and must store this
31:42 - information for 7 years due to
31:44 - Regulatory Compliance which dat service
31:47 - meets this requirement so the first one
31:49 - you'll notice this one is multiple
31:51 - choice or sorry multiple answers so you
31:53 - have to select multiples before you can
31:55 - submit your answer and the the next one
31:57 - here is just a single choice so those
31:59 - are the two types of questions you will
32:01 - see on the exam they're not going to ask
32:03 - you anything about coding you're not
32:05 - going to see any kind of code um in
32:07 - terms of length that's pretty much what
32:09 - we'll see in terms of the uh questions I
32:12 - think in many cases I wrote a little bit
32:14 - more more like um in the style the
32:17 - solutions architect associate to make it
32:18 - slightly more difficult just so that
32:20 - you're a little bit overprepared so if
32:22 - you do well on these practice exams
32:24 - you're going to do uh well on the exam
32:27 - okay so I just wanted to kind of get you
32:29 - that exposure there
32:31 - [Music]
32:34 - okay hey everyone it's angrew brown and
32:37 - I have opened our exam simulator this is
32:40 - on the exam Pro platform and this is the
32:42 - free Set uh that I promised uh folks in
32:45 - the course so no cost to go get this one
32:47 - you just have to sign up and and access
32:49 - it but the reason I have it open is
32:51 - because I really want to talk about a
32:53 - very specific type of question that
32:55 - we've included in here that will not
32:57 - appear on your exam so uh for those who
32:59 - are familiar with Azure certifications
33:02 - um at the associate level or higher
33:05 - there's this question type called a case
33:06 - study and what a case study is I'll I'll
33:09 - just pull it up here but I believe uh in
33:11 - this randomization of this practice exam
33:13 - set I think it's this one here but what
33:15 - a case study is it gives you a scenario
33:18 - that you have to read through or a a
33:20 - case study about a company so you read
33:23 - about the company you look at the
33:24 - objective its requirements constraints
33:26 - this St can all be different there could
33:28 - be diagrams all sorts of stuff in here
33:30 - but the idea is that you are
33:31 - contextualizing a business use case and
33:33 - they're going to be asked a series of
33:35 - questions uh multiple choice multiple
33:37 - select and it all ties back to that case
33:40 - study so the reason we included this is
33:42 - that um we believe that this is going to
33:44 - give you better comprehension and a
33:46 - higher chance of passing so it's not
33:49 - going to appear in your exam but we
33:50 - include it as an extra challenge to you
33:53 - so that you have um a higher chance of
33:55 - passing now if you don't like this we do
33:58 - have other practice exams they of course
33:59 - are paid that uh that are just the
34:02 - normal style which is all multiple
34:04 - choice multiple select for um this this
34:06 - course the cloud partitioner um but you
34:09 - know we do have them in half of the
34:10 - practice exam sets because uh again I
34:13 - think that it's going to be good for you
34:15 - so hopefully you see that as a bonus but
34:16 - I just wanted to give you a heads up um
34:18 - about this uh because you'll counter me
34:20 - like what the heck is this um the other
34:23 - thing I want to point out is that when
34:24 - you enter a case study it's like having
34:25 - a mini exam within your exam so once
34:27 - you've answered all these questions uh
34:29 - you can't go back and and um you can
34:33 - while you're within the case study but
34:34 - if you get to the end of this and submit
34:36 - the case study you can't go back and
34:38 - update it so just be aware of that um
34:41 - and you know again hopefully you like
34:43 - this we love feedback to hear what
34:45 - people like but it's just they always
34:46 - appeared in Azure exams and uh we want
34:49 - to see them in 8 us ones as well because
34:51 - I think they're just really good for uh
34:52 - testing your knowledge but anyway we'll
34:54 - see you in the next one okay
34:55 - ciao
34:59 - [Music]
35:01 - hey everyone it's Andrew Brown your
35:02 - favorite Cloud instructor and what I
35:04 - want to do in this video is to show you
35:06 - um a unique feature that is in our
35:08 - platform um just in case you come across
35:11 - it while you're while you're uh doing
35:13 - the materials I can't remember if it's
35:14 - in the free or paid tier I believe it's
35:15 - in the paid tier so I'm not trying to
35:18 - upsell anyone but I just want to make
35:19 - sure people are aware of that while they
35:21 - are um taking this course but sometimes
35:23 - what you'll see in the follow along so
35:25 - like for example we have S3 down here
35:28 - which is for uh Cloud simple storage uh
35:30 - and I don't have them always included in
35:32 - the videos but um at some point I might
35:34 - do that but the idea is that um we have
35:36 - these validators and validators what
35:38 - they can do is they can verify uh
35:40 - whether you actually have uh the
35:43 - resources uh deployed in your cloud
35:46 - account um so it's like an additional
35:48 - check to make sure that you did it right
35:51 - so for example we have this one for S3
35:53 - so it says setup an S3 bucket it is
35:55 - account validation so so this tool
35:57 - performs an automated check on your
35:58 - personal cloud infrastructure to confirm
36:00 - its alignment with the build project
36:02 - requirements make sure you input precise
36:04 - values for your infrastructure
36:05 - components so let's go through that and
36:07 - show you this I'm showing this as an
36:08 - example but you know you'll see them in
36:10 - other in other fongs and lookout for for
36:13 - that stuff I believe in the to-do it'll
36:15 - even show it uh here so if you watch the
36:18 - video and you watched it to the end or
36:19 - you press that button there but you'll
36:20 - get your your uh your star uh for that
36:23 - but the way it works let's go through it
36:25 - so the first thing is I want to uh click
36:27 - on this new run button and then what
36:29 - we'll do is we'll have an agreement so
36:31 - this agreement is confirming that you
36:33 - understand that you are using your own
36:35 - cloud account uh and we are going to uh
36:39 - need to get readon access to it and just
36:41 - understand that you are using uh you're
36:43 - providing us access to account that is
36:45 - your own account and it's not your
36:46 - company's account because obviously we
36:48 - don't want to get in trouble for
36:50 - accessing data that we're not supposed
36:51 - to have and you don't want to get in
36:52 - trouble for that so that's just a a
36:54 - friendly reminder so I'm going to click
36:56 - the I agree and the accept the next
36:57 - thing it's going to ask for is your itus
36:59 - account ID the region that you're
37:01 - deploying in and then it there might be
37:03 - additional uh parameters that it wants
37:05 - to know so that we can test against it
37:07 - so what I'm going to do is just log into
37:09 - my adus account it'll just take me a
37:11 - moment and we'll fill this out for real
37:13 - okay now of course I'm filling out this
37:15 - example here but I just want to point
37:17 - out that um uh you know you're just
37:20 - going to have to follow this procedure
37:21 - and it'll be slightly different for each
37:22 - one uh for that okay be back in just a
37:25 - second all right so I'm logged into and
37:28 - uh one of my ad's accounts I have a lot
37:30 - of them uh I think this one is my
37:32 - developers one so uh for this particular
37:35 - follow along you would have created an
37:36 - S3 bucket right and so um what I'm going
37:39 - to do here is go to S3 and I already
37:41 - know what to do so it's not too hard for
37:43 - me but I'm going to go ahead and create
37:44 - myself a new bucket I'm going to make
37:46 - note of the region that I'm deploying in
37:48 - so S3 is a bit unique because it shows
37:50 - Global but you are still deploying to a
37:52 - specific region so we'll go ahead and
37:54 - create that bucket I'm just going to say
37:56 - my validator bucket as a test notice
37:59 - where it's deploying Us East one I could
38:01 - change that to anything else like ca
38:03 - Central um I am in Canada so doesn't
38:06 - hurt to deploy where I am and we'll go
38:08 - here and go all the way down and I'm
38:10 - going to go and create this bucket okay
38:13 - so um that bucket name was I forget it
38:15 - was like something like validator and so
38:17 - what I need to do is copy that name
38:19 - we'll go back over here and so it's
38:21 - asking for the bucket name so there's
38:22 - the bucket name we need to it account ID
38:25 - that always appears in the top right
38:27 - corner and they have a nice um clipboard
38:29 - button there to get that in there and
38:31 - the region so we deploy that in CA
38:33 - Central 1 so it says there CA Central
38:35 - one you're always using this uh
38:37 - programmer's name not the full name but
38:39 - this this fun handle you can see them
38:41 - all here on the right hand side if
38:42 - you're not sure about that but what
38:44 - we'll do is go back over here we'll
38:46 - paste in that user region and so what
38:48 - this is going to do is create a um a
38:50 - cloud formation template that's going to
38:52 - give access to us to uh your account so
38:55 - we'll go ahead and hit save and continue
38:57 - and so now we uh We've inputed our
39:00 - parameters those have been saved and now
39:01 - it's saying we need to access your Cloud
39:03 - resources so we want you to generate
39:05 - this cloud formation template we're
39:06 - going to press the button we'll wait a
39:08 - moment and we can either download this
39:10 - template or use the adab CLI to run it
39:13 - um the CLI command is a lot easier to
39:16 - use and I'm going to recommend that you
39:17 - always do that and uh so what we're
39:20 - going to do is generate out this CLI
39:22 - command and we're going to get this
39:23 - oneline command and I'm going to go back
39:26 - over to AWS sorry I know I'm going
39:28 - really fast but it's just how it is and
39:30 - at the top left corner we have this
39:32 - little button here that's for cloud
39:33 - shell we're going to open it up I know
39:36 - coding scary but it's really important
39:38 - to get as much coding experience or
39:39 - scripting as you can so strongly
39:41 - recommend you follow along here but uh
39:43 - it's going to open up and once it's it's
39:45 - open we can paste that in now sometimes
39:48 - this wants to have some kind of EBS
39:50 - storage so you might have to say yes and
39:52 - wait a little bit um that's just the
39:54 - norm for cloud storage but I'm going to
39:56 - go back here I'm going to copy this
39:58 - command okay and we're going go back
40:00 - over here I'm going to right click and
40:02 - paste and this always happens when
40:05 - there's a multitext line we got a pop up
40:06 - here and we're just going to review it
40:08 - looks good so notice it has a template
40:09 - URL so that's the template it's pulling
40:11 - in um there's temporary credentials to
40:15 - uh to allow that uh it's going to create
40:17 - a stack name called exam Pro validation
40:19 - and it's going to say capability named I
40:21 - am now this might fail because I've done
40:23 - it before but we'll go ahead and paste
40:24 - it in I'm going to hit enter
40:27 - and it looks like it's creating the
40:29 - stack so we'll go over to cloud
40:32 - formation and uh we'll go
40:37 - here and I'll just get this out of the
40:39 - way I don't want that open right now and
40:41 - so I'm just going to give this a
40:43 - refresh and did that create that right
40:46 - now that was the name of the stack right
40:49 - exam Pro validation that is correct and
40:52 - if I go over
40:53 - here uh what's the date today I don't
40:56 - even know because that might be an older
40:58 - date I mean it's November so I I don't
41:02 - think that one worked because I already
41:03 - had it uh working there before um so
41:06 - what I'm going to do
41:07 - here I'm going to go ahead and delete
41:09 - this one okay so I just want to point
41:12 - out like if you're doing multiple
41:13 - validators in the system you always have
41:15 - to roll it back tear it down okay like
41:17 - the old one so I'll delete that one
41:20 - again cuz I just don't have a strong
41:22 - confidence that it was actually deployed
41:24 - so I'll be back here in just a moment it
41:26 - tears down all right it actually did uh
41:29 - finish tearing down so that is um there
41:32 - but I'm going to go back here I'm going
41:33 - to attempt to run this command again so
41:35 - go ahead and copy this and I will paste
41:38 - it in again we'll say paste and I'll hit
41:41 - enter and uh it says already existed in
41:44 - the sack well what are you talking about
41:46 - it's definitely uh definitely not there
41:49 - that's what I thought I would get as an
41:50 - error the first time around so this is
41:54 - CA Central 1 oh oh you know what it is
41:57 - I'm in North Virginia so you got to be
41:59 - very careful with your um your regions
42:02 - so I go over
42:03 - here so I I I did delete one that was
42:06 - from another one that's why I was
42:07 - confused because I thought it already
42:09 - existed I have to delete it out th this
42:11 - is normal in Cloud right so just
42:13 - understand that when I do follow alongs
42:16 - I don't edit out the tricky Parts
42:18 - because I know it makes it a little bit
42:20 - confusing but it really does help to
42:22 - demonstrate uh how confusing Cloud can
42:24 - be and how to work through those proc
42:26 - but over here CA Central so this is
42:28 - deployed 11:15 that's the date that I've
42:30 - deployed this on so that makes sense uh
42:33 - here so we just got to be very uh aware
42:36 - of that so this is in C Central one uh
42:38 - but we'll go back over here and so this
42:40 - is done so we know that it's done
42:42 - because it's here it's in the region
42:43 - that we expect it to be in so now the uh
42:46 - the permissions are done we can run the
42:48 - polar so what the polar is going to do
42:50 - is it's now going to pull data from your
42:53 - account uh uh and that way we're going
42:55 - to to uh be able to then validate
42:58 - whether things are correct so we'll go
42:59 - ahead and run the pull and notice it
43:01 - says S3 API list buckets it flashed it
43:04 - really quickly but the way this tool
43:06 - works is it's actually using the adab
43:08 - CLI underneath so I'm just going to go
43:10 - ahead and just show you what this
43:13 - is uh and just show you a quick
43:15 - reference here so the ad C is a
43:17 - pragmatic way to um uh access uh
43:21 - information uh for eight of us we
43:23 - probably show that somewhere in this
43:25 - course and so the command it was running
43:27 - I believe was I should know I coded this
43:31 - was S3
43:32 - API and then it was like list
43:36 - buckets uh list buckets so that's the
43:38 - command it ran so really what the
43:40 - validator did it it did ads S3 API list
43:44 - buckets okay and if you notice this it
43:46 - returns back Json so we get back the
43:48 - payload that's what we are story in our
43:50 - own adus account which by the way we
43:52 - delete after a period of time I don't
43:54 - remember how much time but we we don't
43:56 - hold on to your data for long cuz we
43:57 - don't really want it um but yeah so here
44:00 - it's returning back that data and so
44:02 - somewhere in here that there the the
44:04 - buckets in here right so we've pulled
44:06 - that data and it's there and so now we
44:07 - can run the validator we'll click run
44:10 - validator and it's super fast because we
44:13 - already have the data downloaded and
44:14 - it's doing one check here so it says
44:16 - should have bucket matching name so you
44:19 - can see it's it's doing it's loading
44:21 - from a Json file that's called S3 API
44:24 - list buckets we always name our the Json
44:25 - files app after the commands and it's
44:27 - looking through buckets so if we go over
44:30 - here all the top here for a moment you
44:33 - can see buckets so it's looking within
44:35 - this array and it's trying to match a
44:37 - name called my validator bucket which
44:39 - which which you provided to
44:41 - us so somewhere in here I have a lot of
44:44 - buckets in this account somewhere in
44:46 - here uh there it is it's there and so
44:49 - that's how that works um but yeah just
44:51 - look out for those validators um and uh
44:54 - try to run them and and validate that uh
44:57 - you are able to uh do this stuff okay
44:59 - but we'll see you in the next one okay
45:01 - ciao oh wait wait wait wait wait wait
45:03 - wait I didn't show you how to clean up
45:05 - I'm just running off screen here so once
45:07 - you're
45:08 - done uh what you can do is you can go
45:10 - over to Cloud information here and you
45:12 - should do this is go ahead and delete
45:14 - the stack okay um because that's going
45:16 - to tear down the permissions so that we
45:18 - no longer have access to your account um
45:21 - so that's kind of an important thing to
45:23 - do um but uh we'll go ahead and the
45:26 - other thing about these permissions is
45:27 - that we're only asking for exactly what
45:29 - we need access to so in this in this uh
45:32 - permissions it only generate out to get
45:34 - access to uh the S3 bucket specifically
45:37 - what we're accessing for so even if you
45:39 - left it up it's usually okay it's safe
45:41 - but um you know if there's no reason for
45:44 - us to have access anymore you should all
45:46 - obviously delete it um but yeah that one
45:48 - is now gone and so now we are absolutely
45:50 - done I'm going to go ahead and just
45:51 - close this out here but yeah hopefully
45:53 - uh that makes it pretty clear how
45:55 - validators working in our system and you
45:56 - see the benefit to getting that uh check
45:59 - in your real account
46:02 - [Music]
46:05 - ciao hey this is Andrew Brown from exam
46:07 - Pro and we are at the start of our
46:09 - journey asking the most important
46:10 - question first which is what is cloud
46:13 - computing so cloud computing is the
46:15 - practice of using a network of remote
46:16 - servers hosted on the internet to store
46:19 - manage and process data rather than a
46:21 - local server or personal computer and so
46:24 - when we're talking about on premise you
46:26 - own the servers you hire the IT people
46:28 - you pay or rent the real estate you take
46:31 - all the risks but with a cloud provider
46:33 - uh someone else owns the servers someone
46:35 - else hires the IT people someone else
46:37 - pays or rents the real estate and you
46:39 - are responsible for configuring cloud
46:41 - services and code and someone takes care
46:43 - of the rest of it for you
46:46 - [Music]
46:49 - okay so to understand cloud computing we
46:52 - need to look at the evolution of cloud
46:54 - hosting going all the way back to 19
46:55 - 1995 where if you wanted to host your
46:58 - website or web app you'd have to get a
47:00 - dedicated server so that would be one
47:02 - physical machine dedicated to a single
47:04 - business running a single project a site
47:07 - or an app and as you can imagine these
47:09 - are expensive because you have to uh buy
47:11 - out write the hardware have a place to
47:13 - store it the network connection having a
47:16 - person to maintain it um but it did give
47:18 - you a guarantee of high security um and
47:21 - they still do as of today so this model
47:22 - hasn't gone away but it's been
47:24 - specialized for a particular use case
47:26 - then came along the virtual private
47:28 - server so the idea is we still had one
47:30 - physical machine but now we were able to
47:33 - subdivide um our machine into
47:35 - submachines via
47:37 - virtualization and so essentially you're
47:39 - running a machine within a machine and
47:41 - so you had better utilization of that
47:43 - machine um running multiple web apps as
47:46 - opposed to having a physical machine per
47:48 - project so you got better utilization
47:50 - and isolation of resources and so uh
47:54 - these two options still requireed you to
47:56 - purchase a machine a dedicated machine
47:58 - and so that was still kind of expensive
48:00 - but then came along shared hosting and
48:02 - so if you remember uh the mid 2000s like
48:05 - with GoDaddy or HostGator or any of
48:07 - those sites where you had really cheap
48:09 - hosting the idea is that you had this
48:11 - one physical machine shared by hundreds
48:13 - of businesses and the way this worked it
48:16 - relied on uh tenants underutilizing
48:18 - their resources so you know you wouldn't
48:20 - have a submachine in there but you'd
48:22 - have a folder with permissions that you
48:24 - could use um and so you would really
48:27 - share the cost and this was very very
48:28 - cheap um but you were limited to
48:31 - whatever that machine could do and you
48:33 - were very restricted in terms of the
48:35 - functionality you had and there was just
48:37 - poor isolation meaning that you know if
48:39 - one person decided to utilize the server
48:41 - more they could hang up all the all the
48:43 - websites on that single server then came
48:46 - along Cloud hosting and the idea is that
48:48 - you have um multiple physical machines
48:50 - that act as one system so this is
48:52 - distributed computing and so the system
48:54 - is abstracted into mult multiple cloud
48:56 - services and the idea is that you
48:58 - basically get the advantages of a lot of
49:00 - the things above so it's flexible you
49:02 - can just add more servers um it's
49:05 - scalable it's very secure because you
49:07 - get that uh virtual isolation you get it
49:11 - extremely at a low cost because you're
49:12 - sharing that cost with the users where
49:14 - in the shared hosting it might be
49:15 - hundreds of businesses we're looking at
49:17 - thousands of businesses and it was also
49:20 - highly configurable because it was a
49:21 - full virtual machine now uh Cloud
49:23 - actually uh still includes all of these
49:26 - types of Hosting they haven't gone away
49:29 - uh but it's just the idea that you now
49:30 - have more of a selection for your use
49:32 - case uh but hopefully that gives you an
49:33 - idea what cloud hosting looks like and
49:36 - it really has to come down to
49:37 - distributed computing
49:39 - [Music]
49:42 - okay hey this is Andrew Brown from exam
49:45 - Pro and before we talk about ads we need
49:47 - to know what is Amazon so Amazon is an
49:49 - American multinational computer
49:51 - technology corporation headquarted in
49:52 - Seattle Washington and so this is the
49:55 - Seattle skyline with the Space Needle
49:58 - and Amazon was founded in 1994 by Jeff
50:00 - Bezos and the company started as an
50:02 - online store for books and expanded to
50:04 - other products so as you can see this is
50:07 - Jeff Bezos a long time ago and he has
50:09 - this interesting spray painted sign and
50:12 - his desk is held up by cinder blocks and
50:14 - it looks like his uh desk is like an old
50:17 - uh table or something and he's working
50:20 - really late and he used to be a
50:22 - millionaire at this time and he would be
50:24 - driving into work his Honda Accord
50:27 - because you know he just his motivation
50:29 - was always to put all the money back
50:30 - into the company so he really shows that
50:32 - he worked really hard and it did pay off
50:34 - because Amazon has expanded uh Beyond
50:36 - just an online Ecommerce store into a
50:38 - lot of different things such as cloud
50:41 - computing which is Amazon web services
50:43 - Digital streaming such as Amazon Prime
50:45 - video Prime music they bought
50:47 - twitch.tv they owned the Whole Foods
50:49 - Market grocery store they have all this
50:51 - artificials intelligence they own low
50:54 - orbit satellites and a lot more stuff
50:57 - it's hard to list at all and so Jeff
51:00 - Bezos today is not the um the CEO it's
51:04 - actually Andy jasse is the current CEO
51:07 - of Amazon he was previously the CEO of
51:08 - AWS so Jeff Bezos can focus on space
51:11 - travel so there you
51:13 - [Music]
51:17 - go hey this is Andrew Brown from xampro
51:19 - and we are taking a look at Amazon web
51:22 - services and this is the name that
51:24 - Amazon calls their provider service and
51:26 - it's commonly referred to just as AWS so
51:29 - here is the old logo where we see the
51:31 - full name and here is the new logo but I
51:33 - like showing the old logo because it has
51:35 - these cubes which best represent what
51:38 - AWS is and it is a collection of cloud
51:40 - services that can be used together under
51:42 - a single unified API uh to build uh a
51:46 - lot of different kinds of workloads so
51:48 - adus was launched in 2006 and is the
51:50 - leading cloud service provider in the
51:52 - world I put an aster there because
51:54 - technically
51:55 - adus existed before 2006 and a cloud
51:59 - service provider uh which is what adus
52:01 - is is often initialized as CSP so if you
52:04 - hear me saying CSP I'm just saying cloud
52:06 - service provider okay so just time to
52:10 - look at the timeline of when Services
52:12 - rolled out the first one came out in uh
52:15 - 2004 it was simple Q service sqs and
52:18 - this service still exists as of today
52:20 - but at the time it was the only service
52:22 - that was publicly available so it wasn't
52:24 - exactly a cloud service provider at this
52:26 - time and it was neither ads it was just
52:29 - sqs but then a couple years later we had
52:32 - simple storage service also known as S3
52:34 - which was launched uh in March of 2006
52:37 - and then a couple months later we had
52:39 - elastic compute Cloud also known as ec2
52:42 - um and ec2 is still uh like the most
52:45 - used service within AWS and is like the
52:47 - backbone for pretty much everything
52:49 - there then in 2010 it was reported that
52:52 - all of amazon.com's retail sites had
52:54 - migrated to to AWS so even Amazon was
52:57 - using AWS uh Full Steam and to support
53:00 - industrywide training and and skill
53:02 - standardization itus began offering a
53:04 - certification program for computer
53:07 - Engineers on April 2013 uh and this is
53:10 - the type of certifications that we are
53:12 - doing as we speak um so I just want you
53:14 - to know that ad us was the one leading
53:16 - uh Cloud certifications if we just want
53:18 - to take a look here at the executive
53:20 - level as of today the CEO is Adam he's
53:23 - the former CTO of tableau and he spent a
53:25 - decade with adus as a VP of Marketing
53:27 - sales and support so he was there he had
53:30 - left for a bit and now he is back then
53:32 - we have uh wner and he's the CTO of AWS
53:35 - he's been uh the CTO for pretty much the
53:38 - entire time ad was existed with the
53:40 - exception of sometime of the first year
53:42 - he's famous for uh quoting everything
53:44 - fails all the time and then there's Jeff
53:47 - bar who's the chief evangelist so um if
53:49 - you're ever wondering who is writing all
53:51 - the blog posts and talking about ad bus
53:53 - it's it's always Jeff bar
53:56 - [Music]
53:59 - okay all right so what I want to do here
54:01 - is expand on what is a cloud service
54:04 - provider also known as a CSP just
54:06 - because there's a lot of things out in
54:07 - the market there that might look like a
54:09 - CSP uh but they actually are not so
54:12 - let's go through this list and see what
54:14 - makes a CSP so this is a company which
54:17 - provides multiple cloud services ranging
54:20 - from tens to hundreds of services those
54:22 - cloud services can be chained together
54:24 - to create CL architectures those cloud
54:26 - services are accessible via a single
54:29 - unified API so in ad's cases that is the
54:31 - adus API um and from that you can access
54:35 - the CLI the SDK the Management console
54:38 - those cloud services utilize metered
54:40 - building based on usage so this could be
54:42 - per second per hour uh vpcu memory
54:46 - storage things like that those cloud
54:48 - services have Rich monitoring built in
54:50 - so you know every API action is tracked
54:54 - and you have access to that so in A's
54:56 - case it's Aus cloud trail and the idea
54:59 - here is those cloud services have
55:00 - infrastructure as a service offering so
55:03 - IAS that means they have networking
55:06 - compute uh storage databases things like
55:09 - that those cloud services offers
55:12 - automation via infrastructure as code so
55:14 - you can write code to set everything up
55:17 - and so here's just kind of a example of
55:19 - an architecture where we have a very
55:21 - simple uh web application running on ec2
55:23 - behind a load bouncer with the domain
55:25 - with r 53 but the idea is just to show
55:27 - you that you know you're changing these
55:29 - things together if a company offers
55:31 - multiple cloud services under a single
55:33 - UI but do not meet most of or all of
55:36 - these requirements it would just be
55:37 - referred to as a cloud platform so when
55:39 - you hear about twio or hashy Corp or
55:42 - data bricks those are Cloud platforms
55:45 - and adabs Azure gcp are cloud service
55:48 - providers
55:49 - [Music]
55:52 - okay all right let's take a look here at
55:55 - the landscape of cloud service providers
55:57 - this is generally broken down into tier
55:59 - one tier 2 tier three but I've modified
56:01 - it to give each tier its own name as I
56:03 - don't like to think of them as rankings
56:05 - and more so that uh these cloud service
56:07 - providers are specialized for a
56:09 - particular thing um and I've also added
56:11 - a fourth tier because you know the
56:13 - internet has always talked about three
56:14 - tiers but there really is a fourth tier
56:16 - and I wanted to make sure we had uh the
56:18 - full scope here included so in the top
56:21 - tier you're going to recognize uh some
56:23 - common names there Amazon web service
56:25 - Microsoft Azure Google Cloud platform
56:27 - and Alibaba cloud in North America and
56:30 - Europe uh adab us Azure and gcp are
56:33 - known as The Big Three um but Alibaba
56:35 - cloud is huge as well if you're in the
56:37 - Asia region specifically China so it's
56:40 - really just going to be dependent on
56:41 - where you live where uh which are
56:43 - considered the most um commonly known or
56:46 - popular uh but we'll talk about that
56:48 - here in a moment but the reason um I
56:50 - call tier one top tier is that these are
56:54 - you know very well-known providers
56:56 - they're ear early to Market they have
56:57 - strong synergies between their services
57:00 - um they're just really good cloud
57:02 - service providers you cannot go wrong
57:03 - with uh these providers then we have our
57:05 - tier two or I would call our mid-tier uh
57:08 - these are backed by really well-known
57:10 - tech companies but I would just say that
57:13 - um their ability to become top tier uh
57:16 - did not work out the way they planned so
57:18 - IBM at one point was looking to be a top
57:21 - tier provider um but they just did not
57:23 - keep up with um AWS and they just
57:26 - slipped into this mid- tier and kind of
57:29 - specialized at least for a while into ml
57:32 - AI services and now they're just more
57:34 - like very expensive um Enterprise U
57:38 - managed
57:39 - infrastructure for their existing
57:41 - clientele Oracle um very very
57:44 - inexpensive that's their play they try
57:46 - to uh be the cheapest but their uh
57:50 - service um overall is not uh fun to use
57:55 - interestingly enough I believe Microsoft
57:56 - Azure was just signing a contract to use
57:59 - Oracle Cloud so it's not unusual for
58:00 - some of these cloud service providers or
58:02 - these organizations to use other
58:04 - providers because they want to use their
58:06 - Global infrastructure but uh yeah Oracle
58:09 - cloud is uh not doing that great there
58:13 - are other ones in the Asia region like
58:16 - uh Hawaii cloud and tensent Cloud I
58:18 - honestly don't know a whole lot about
58:20 - them but they do show up on the magic
58:22 - quadrant so it's possible the Asia
58:25 - region that these are the big three and
58:27 - uh AWS Azure and gcp do not play a
58:30 - larger role but from our perspective I
58:32 - put them into that mid tier because they
58:35 - just don't have Global uh awareness or
58:37 - Global um market dominance like the
58:41 - other three uh up there looking at the
58:44 - light tier uh these were traditionally
58:46 - virtual private servers so they just
58:48 - specialized in that and they turn to
58:50 - offer more core infrastructure service
58:53 - offerings so we we have a vulture I
58:56 - always thought it was pronounced Vol but
58:57 - it's actually vulture digital ocean and
59:00 - aimi connected Cloud which was formerly
59:01 - known as Leno or Leno um so they merg
59:05 - their companies together and I mean they
59:08 - want to be like a cloud service
59:11 - providers but they're very very light in
59:13 - terms of their offering so um you know
59:15 - they'll have things like serverless and
59:18 - being able to run a kubernetes cluster
59:20 - and some cloud storage and stuff but
59:22 - they won't have things like uh the the
59:25 - same level of event
59:27 - driven metered billing or or other kinds
59:31 - of functional that you you come to
59:33 - expect in the top tiers but you know if
59:36 - you're working with a smaller
59:37 - organization they are a lot simpler to
59:39 - uh to utilize so they are a great
59:41 - introduction to Cloud for companies that
59:43 - find the top tier uh too complex and
59:46 - then looking at the fourth tier I call
59:48 - this the private tier this is uh
59:50 - basically software that you can deploy
59:52 - onto your own uh machines in your data
59:54 - centers to get the same kind of um
59:57 - functionality that you would if you were
59:59 - using let's say adabs or any of these
60:01 - other providers and um you know
60:04 - previously I would put open stack into
60:05 - the mid tier because in a sense that it
60:07 - was kind of like a cloud service
60:09 - provider that was using uh quite a bit
60:12 - but I didn't feel like it had had good
60:13 - fit there so that's why we made this a
60:15 - fourth tier and we have a few different
60:17 - softwares we have open stack Apache
60:19 - Cloud stack those are both open source
60:21 - and there's VMware vpar I have an aster
60:24 - there because it's not really the same
60:26 - thing but it is used a lot everywhere to
60:29 - manage a lot of virtual machines and so
60:32 - I I kind of feel like it should fit in
60:34 - there but that gives you kind of an idea
60:36 - of the landscape of cloud and we'll see
60:38 - you in the next
60:40 - [Music]
60:43 - one so how do we determine who is the
60:46 - leader in Cloud well one way of
60:47 - indicating that is the gardener magic
60:49 - quadrant for cloud so the magic quadrant
60:52 - is a series of market research reports
60:53 - published by the IT consulting firm
60:55 - Garder that rely on proprietary
60:58 - qualitative qualitative data analysis
61:00 - methods to demonstrate market trends
61:02 - such as Direction maturity and
61:03 - participants so it says a series of
61:06 - reports uh but the only thing I've ever
61:08 - seen are these Graphics where they show
61:11 - um a uh the quadrant it's a it's a
61:14 - diagram that summarizes all the
61:16 - information so I think you have to you
61:17 - might have to pay to access uh the
61:20 - reports um because it's definitely not
61:22 - just uh publicly accessible knowledge
61:24 - and I don't think they would show all of
61:26 - uh how this stuff is calculated but uh
61:29 - let's just take a look at this graphic
61:31 - here so notice we have challengers in
61:32 - the top left corner leaders in the top
61:35 - right corner in the bottom left corner
61:37 - we have Niche players and then in the
61:38 - bottom right corner we have Visionaries
61:40 - so the idea here is that The Closer you
61:42 - are to this top Corner uh the better you
61:44 - are doing and the one that is closest to
61:46 - it is Amazon web services followed with
61:49 - Microsoft pretty close uh in second
61:52 - Google to the left Alibaba cloud X
61:54 - Oracle and then we have IBM 10cent and
61:58 - Hawaii and there are other players but
62:01 - they are so small that they are not
62:02 - showing up there and we showed that in
62:04 - the landscape of csps or um maybe this
62:08 - is only for first they consider what uh
62:10 - we call First tier or top tier cloud
62:13 - service providers it's really useful to
62:15 - look at last year's uh mq and to see how
62:18 - things have moved so it looks like uh it
62:21 - uh Microsoft has shifted a little bit
62:23 - forward here and gone a little bit
62:25 - closer to AWS Google has significally
62:28 - moved up and um Alibaba Cloud it seems
62:31 - to be moving more uh to the right um and
62:34 - again I'm just showing what their
62:35 - movements were from this year to that
62:37 - year so they are over here now Oracle is
62:39 - way over here now and for whatever
62:42 - reason Huawei cloud is on the board so
62:45 - it's interesting to see how they move
62:47 - another thing that's um interesting here
62:49 - is that this one is 2022 of June and
62:52 - this one is July of 2021 and right now
62:57 - as the time I'm recording this video
62:58 - it's 2023 near the end of the year um
63:02 - and I could not find a 2023 one so even
63:04 - if it says June or July they will
63:07 - release these out in October November
63:09 - Etc way later in the year and so for
63:11 - whatever reason they have yet to make um
63:14 - the latest one available so I'm still
63:16 - curious to see what that is here so I'm
63:18 - just giving you the information that we
63:19 - have but you can look at this stuff um
63:22 - basically on the The Gardener website if
63:25 - you want to see um any of these magic
63:27 - quadrants for any of the industries
63:29 - there and what I find is is that if uh
63:32 - companies doing really well they'll
63:34 - always post it on their website so it's
63:36 - very easy to find the uh Magic quadrant
63:38 - for cloud on the ads website because
63:40 - they're the leader so they definitely
63:41 - want to show that there U but yeah there
63:43 - you
63:44 - [Music]
63:48 - go so a cloud service provider can have
63:52 - hundreds of cloud services that are
63:53 - grouped into various types of services
63:56 - but the four most common types of cloud
63:58 - services for infrastructures of service
64:01 - uh and I call these the four core would
64:03 - be compute so imagine having a virtual
64:06 - computer that can run applications
64:08 - programs and code networking so imagine
64:11 - having virtual Network defining internet
64:13 - connections or network isolation between
64:15 - services or outbound to the internet
64:17 - storage so imagine having a virtual hard
64:19 - drive that can store files databases so
64:22 - imagine a virtual database for storing
64:24 - reporting data or a database for general
64:27 - purpose web applications and uh AWS in
64:30 - particular has 200 plus cloud services
64:33 - and I want to clarify what cloud
64:36 - computing means because notice that we
64:37 - have cloud computing Cloud networking
64:39 - cloud storage Cloud databases but the
64:42 - industry often just says cloud computing
64:45 - to refer to all categories even though
64:47 - uh it has computer in the name so just
64:49 - understand when someone says cloud
64:50 - computing uh they don't just generally
64:52 - mean the subcategory they're talking
64:53 - about all of cloud
64:56 - [Music]
64:59 - okay so adus has a lot of different
65:02 - cloud services and I just want to kind
65:04 - of go quickly over the types of
65:06 - categories that we can encounter here
65:08 - and just mention the four core so any
65:10 - CSP that has IAS will always have these
65:13 - four core service offerings we have
65:15 - computes so Nat this would be ec2 VMS
65:18 - storage this could be something like EBS
65:20 - virtual hard drives database so that
65:22 - could be RDS SQL databases networking
65:24 - and content delivery but really it's
65:26 - networking uh and this would be VPC so
65:29 - private Cloud Network okay so uh let's
65:32 - just look at all the categories that are
65:34 - outside the four core so there could be
65:35 - analytics application integration arvr a
65:39 - cost management blockchain business
65:41 - application containers customer
65:43 - engagement developer tools and user
65:45 - Computing game Tech iot Machine learning
65:49 - management and governance Media Services
65:51 - migration uh and transfer most mobile
65:54 - Quantum Technologies robotics satellites
65:57 - security identity and compliance if
65:59 - there was more I would not be surprised
66:01 - but you can see there's a lot of stuff
66:02 - that's going on
66:07 - here so let's take a look at all the
66:09 - itaba services that are available to us
66:11 - so if you're on the marketing website
66:12 - which is adab.
66:14 - amazon.com what you'll see in the top
66:16 - left corner is products and so these are
66:19 - all the categories and for whatever we
66:20 - want if it's like ec2 we can go into
66:23 - here and we can read all about it so
66:26 - usually we'll have our overview all
66:28 - right and that's not very useful and
66:31 - then we'll go over to features and so
66:34 - this is can be kind of useful to get
66:35 - some basic information and pricing which
66:38 - is something you'll do a lot in adabs is
66:40 - you're always going to be going to a
66:41 - service looking up its price and so
66:44 - you'll make your way over uh here every
66:46 - single one is different a very important
66:48 - page would be like getting started so
66:50 - this will give you basic information but
66:52 - what I do is I like to go all the way
66:54 - down to the bottom here and find my way
66:56 - over to the documentation so I'll go
66:57 - here to documentation to get that deeper
67:00 - knowledge about that service and as you
67:02 - can see things get pretty deep with AWS
67:05 - in terms of the information they have so
67:07 - hopefully that gives you an idea of the
67:09 - scope also when you're logged into
67:10 - databus and this will be when we create
67:12 - our account uh you can explore all the
67:14 - services this way as well so these are
67:16 - all the adus services uh but you just
67:18 - notice that there's two ways to uh
67:20 - explore them where this is actually you
67:22 - just actually utilizing the services is
67:24 - and then the marketing website is you
67:26 - reading about them and learning all
67:27 - about them
67:28 - [Music]
67:31 - okay hey this is Andrew Brown from exam
67:34 - Pro and we are looking at the evolution
67:35 - of computing your cloud service provider
67:37 - has all of these offerings and the idea
67:39 - is that you need to choose the one that
67:41 - meets your use case a lot of times this
67:43 - all has to come around the utilization
67:45 - of space that's what we're trying to
67:46 - illustrate here in this section here and
67:48 - the trade-offs of why you might want to
67:50 - use some of these offerings okay for
67:53 - dedicated we're talking about a uh a
67:55 - physically uh a physical server wholly
67:57 - utilized by single customer that's
67:59 - considered single tenant and uh for
68:02 - Google Cloud we're talking about um
68:05 - single node clusters and bare metal
68:07 - machines where you have control of the
68:09 - virtualization so you can install any
68:11 - kind of hypervisor or virtualization you
68:13 - want in the system the trade-off here
68:15 - though is that you have to guess upfront
68:17 - what your capacity is going to be and
68:19 - you're never going to 100% utilize that
68:20 - machine cuz it's going to have to be a
68:22 - bit under in case the utilization goes
68:24 - up that's you're choosing the CPUs and
68:25 - the memories you're going to end up
68:27 - overpaying because you're uh you'll have
68:29 - under underutilized server uh it's not
68:31 - going to be easy to vertically scale
68:33 - it's not like you can just say resize it
68:35 - because the machine you have is what you
68:36 - have right you can't add more I mean I
68:39 - suppose they can insert more memory for
68:41 - you but that's a manual migration uh so
68:43 - it's very difficult um and replacing the
68:46 - server is also very difficult okay so
68:49 - you're limited by the host operating
68:50 - system it's not virtualized so whatever
68:53 - is on there is is on there um and that's
68:55 - what your apps are going to have access
68:56 - to uh if you decide to run more than one
68:59 - app which is not a good practice for
69:00 - these kind of machines uh you're going
69:02 - to end up with a resource sharing where
69:04 - one machine might utilize more than the
69:06 - others technically with a dedicated
69:08 - machine you have a guarantee of security
69:09 - privacy and full utility of the
69:11 - underlying resources I put an aster
69:12 - there because yes it's more secure but
69:16 - uh but it's up to you to make sure that
69:18 - it's more secure so you have that's up
69:20 - to your skills of security right whereas
69:22 - if you had a virtual machine or anything
69:24 - above that there's more responsibility
69:26 - on the cloud service provider to just
69:28 - provide a secure machine and they can do
69:31 - a better job than you so why would you
69:33 - use a dedicated machine well maybe
69:34 - you're doing high performance Computing
69:36 - where you need these machines like very
69:38 - close together and you have to choose
69:40 - what kind of virtualization you need to
69:42 - have okay so then we're looking at
69:45 - virtual machines the idea here is you
69:46 - can run a machine within a machine the
69:48 - way that works is we have a hypervisor
69:51 - this is a software layer that lets you
69:52 - run the virtual machine
69:54 - uh the idea here is now it's
69:55 - multi-tenant you can share the cost with
69:57 - multiple customers you're paying for a
69:59 - fraction of the server uh you'll still
70:01 - end up overpaying for the underutilized
70:02 - virtual machine because a virtual
70:04 - machine is just like you have to still
70:05 - say how many V vcpus how much memory and
70:09 - your app is you know you don't want an
70:11 - app that uses 100% right you want to use
70:13 - exactly the amount you need but you can
70:14 - see here you know there's still going to
70:16 - be some
70:17 - underutilization uh you limited by the
70:19 - guest operating system now but now it's
70:21 - virtualized so at least it's very easy
70:23 - to uh possibly migrate away if you
70:26 - choose to run uh more than one app on a
70:29 - virtual machine it it can still run into
70:31 - resource sharing conflicts uh it's
70:33 - easier to export or import images for
70:35 - migration it's easier to vertically or
70:38 - horizontally scale okay and virtual
70:40 - machines are the most common and popular
70:42 - offering for compute because people are
70:44 - just very comfortable with those then
70:46 - you have containers and the idea is you
70:47 - have a virtual machine running these
70:49 - things called containers the way they do
70:51 - that is similar to a hypervisor but in
70:53 - instead you have um like here is a
70:55 - Docker demon so it's just a um a
70:58 - container software layer okay to run
71:01 - those containers there's different kinds
71:02 - Docker is the most popular uh and the
71:04 - great thing is you can maximize the uh
71:06 - the the capacity because you can easily
71:09 - add new containers resize those
71:11 - containers use up the rest of the space
71:13 - it's a lot more flexible okay uh your
71:16 - containers will share the same
71:17 - underlying OS but they are more
71:20 - efficient than multiple VMS uh multiple
71:22 - apps can run Side by without being
71:24 - limited uh by the same OS requirements
71:26 - and not cause conflicts during resource
71:28 - sharing so containers are really good
71:30 - but you know the tradeoff is there a lot
71:32 - more work to maintain then you have
71:34 - functions functions go even step further
71:37 - and the idea is that you uh the the
71:40 - containers where we where we talked
71:42 - about that's a lot of work to maintain
71:44 - now the cloud service provider is taking
71:46 - care of those containers generally
71:48 - sometimes not it depends if it's servers
71:50 - or not but the idea is that you don't
71:52 - even think about and this is called
71:54 - servess compute but you don't even think
71:55 - about uh the OS or anything you just
71:58 - know that what your runtime is you run
72:00 - Ruby or python or node and you just
72:02 - upload your code and you just say uh I
72:05 - want this to be able to run uh uh for
72:07 - this long uh and use this amount of
72:09 - memory okay you're only responsible for
72:12 - your code and data nothing else it's
72:13 - very cost effective you only pay for the
72:15 - time the code is running uh and VMS only
72:18 - run when there is code to be executed
72:20 - but because of that there is this
72:21 - concept of cold starts and this is uh
72:24 - where the virtual machine has to spin up
72:27 - and so sometimes requests can be a bit
72:28 - slow so there's a bit of trade-off there
72:30 - but functions or serverless compute is
72:32 - generally one of the best offerings as
72:33 - of today but most people are still
72:36 - getting kind of comfortable with that
72:37 - Paradigm
72:38 - [Music]
72:41 - okay hey this is Andrew Brown from exam
72:43 - Pro and we are taking a look at the
72:45 - types of cloud computing and the best
72:47 - way to represent this is a stacked
72:49 - pyramid and we'll start our way at the
72:51 - top with SAS also known as software as a
72:53 - service so this is a product that is run
72:56 - and managed by the cloud service
72:58 - provider you don't have to worry about
73:00 - how the service is maintained it just
73:01 - works and remains available so examples
73:03 - of this and actually uh the first uh
73:05 - company to coin this was actually
73:07 - Salesforce um then there's things like
73:09 - Gmail Office 365 so think Microsoft Word
73:13 - Excel things like that and they run the
73:14 - cloud okay and SAS is generally designed
73:18 - for customers in mind then came along
73:21 - platforms of service um also known as
73:24 - and these focus on the development or
73:26 - sorry the deployment and management of
73:28 - your apps so you don't worry about
73:30 - provisioning configuring or
73:31 - understanding the hardware or operating
73:33 - system and so here we' have things like
73:36 - elastic beant stock Heroku which is very
73:39 - popular among developers that just want
73:41 - to launch their code or Google app
73:43 - engine and that is the old logo but
73:45 - that's the logo I like to use because I
73:47 - think it looks cool and so these are
73:49 - intended for developers the idea is that
73:51 - you just deploy your code um and the
73:54 - platform does the rest then there is
73:56 - infrastructure as a service um there's
73:59 - no way to say that like it's easy to say
74:01 - SAS or pass but there's no easy way to
74:03 - say IAS so this is the basic building
74:06 - blocks for cloud it it provides access
74:08 - to networking features computers and
74:10 - data storage space and the idea here is
74:12 - you don't worry about the IT staff data
74:14 - centers and hardware and so that would
74:17 - be like Microsoft Azure AWS Oracle Cloud
74:20 - things like that and these are for admin
74:23 - Traders okay so there you
74:26 - [Music]
74:29 - go hey this is Andrew Brown from exam
74:32 - Pro and we are taking a look at cloud
74:33 - computing deployment models starting
74:35 - with public cloud and the idea here is
74:38 - that everything when I say everything
74:39 - I'm talking about the workloads the
74:41 - projects the code is built on the cloud
74:43 - service provider so here is a diagram
74:46 - where we have a ec2 instance a virtual
74:49 - machine running her application and then
74:51 - we have our database in RDS
74:53 - and we have the internet coming into our
74:55 - adus account and so everything is
74:57 - contained all of our infrastructure is
74:59 - within AWS all right uh and so this is
75:03 - known as being Cloud native or Cloud
75:05 - first and I put an aster beside Cloud
75:07 - native because that was a term uh that
75:10 - was uh used prior to Cloud Serv
75:12 - providers to refer to Containers or
75:14 - open- Source um uh models being deployed
75:18 - and being mobile other places so just
75:20 - understand that it has two meanings but
75:22 - uh in the context of this cloud of just
75:23 - being like native to the cloud like
75:25 - using Cloud to begin with okay then we
75:27 - have private Cloud so everything built
75:29 - on a company's data center uh and being
75:32 - built on a data center is known as being
75:34 - on premise because that is where the
75:36 - data center resides near where you work
75:39 - and so here you could be using Cloud but
75:41 - you'd be using openstack which would be
75:43 - a private Cloud so here we have our on
75:45 - premise Data Center and uh the
75:47 - internet's coming into our data center
75:49 - and we're running on open stack where we
75:51 - can launch virtual machines and a
75:52 - database
75:54 - okay then there's the concept of a
75:56 - hybrid Cloud so using both on premise
75:59 - and a cloud service provider together
76:01 - and so the idea here is we have our on
76:03 - premise Data Center and then we have an
76:06 - established connection maybe it's a VPN
76:08 - connection maybe it is a direct
76:10 - connection um but the idea is that we're
76:12 - bridging that connection and uh
76:14 - utilizing both our private and our
76:17 - public uh stuff to uh create a cloud
76:20 - workload then there is a fourth one
76:23 - called cross Cloud um sometimes it's
76:25 - known as multicloud and sometimes it's
76:27 - erroneously referred to as hybrid Cloud
76:30 - but it generally is not uh hybrid Cloud
76:33 - okay the idea here is when you're using
76:34 - multiple Cloud providers and so one
76:37 - example here could be using services
76:39 - like Azure Arc so Azure Arc allows you
76:42 - to extend your um control plane uh so
76:45 - that you can deploy containers for
76:47 - kubernetes in um Azure within Amazon eks
76:52 - Within gcp
76:53 - n's engine but you know being cross
76:56 - Cloud doesn't necessarily mean that
76:57 - you're running a using a service that
77:00 - use Works across the cloud and manages
77:02 - it it could just mean using multiple
77:03 - providers at the same time another
77:05 - service that is similar to Azure Arch
77:07 - but is for Google Cloud uh platform is
77:10 - also known as anthos um adab us has
77:13 - traditionally not been um cross Cloud uh
77:16 - friendly and so we haven't seen any kind
77:18 - of developments there where we see these
77:20 - other services that are or CL Prov
77:23 - behind AWS trying to promote it to uh
77:26 - grab more of the market share
77:29 - [Music]
77:32 - okay so let's talk about the different
77:34 - deployment models and what kind of
77:36 - companies or organizations are still
77:38 - utilizing uh for these particular
77:40 - categories so for cloud again this is
77:42 - where we're Fally utilizing cloud
77:43 - computing hybrid is a combination of
77:46 - public cloud and on Prem or private
77:48 - cloud and then on Prem is deploying
77:50 - resources on premise using
77:51 - virtualization resource management tools
77:53 - sometimes called private cloud or could
77:55 - be utilizing something like open stack
77:57 - so for companies that are starting out
77:59 - today or are small enough to make the
78:01 - leap from virtual private server to a
78:03 - cloud service provider this is where
78:04 - we're looking at Cloud so we're looking
78:06 - at startups SAS offerings new projects
78:08 - and companies um so maybe this would be
78:10 - like base camp Dropbox Squarespace then
78:13 - for hybrid these are organizations that
78:15 - started with their own data center but
78:16 - can't fully move to Cloud due to the
78:18 - effort or migration or security
78:20 - compliance so we're talking about Banks
78:22 - fintech investment management large
78:24 - professional service providers Legacy on
78:26 - Prem so maybe CIBC which is a bank deoe
78:29 - uh the CCP or CPP investment board and
78:33 - then for on premise these are
78:34 - organizations that cannot run on cloud
78:36 - due to strict Regulatory Compliance or
78:38 - the sheer size of the organization or
78:40 - they just have like an outdated uh idea
78:43 - of what cloud is so they just have a lot
78:45 - of uh difficulties in terms of politics
78:47 - adopting Cloud um so this would be
78:49 - public sector like government super sens
78:51 - of data like hospitals large Enterprise
78:53 - with heavy regulation insurance
78:55 - companies um so again hospitals maybe
78:58 - AIG the government of Canada and so I
79:01 - shouldn't say that they aren't using
79:02 - Cloud but um you know because uh adabs
79:06 - and all the cloud service providers have
79:09 - um uh public sector offering so um you
79:12 - know I'm just trying to Stage as an
79:14 - example of things that could be still
79:15 - using on premise so you know I know the
79:18 - government of Canada definitely uses uh
79:20 - cloud in a lot of ways same with AIG and
79:23 - hospitals but you know generally these
79:24 - are the the last holdouts of on Prem
79:26 - because there really isn't a a good
79:29 - reason to be fully on premise anymore uh
79:31 - but again there are some things that are
79:33 - still doing that
79:34 - [Music]
79:38 - okay hey this is Andrew Brown from exam
79:40 - Pro and we are at the start of our
79:41 - journey creating ourselves an adus
79:43 - account so what you need to do is go to
79:45 - ads. amazon.com if you don't have a lot
79:48 - of confidence how to get there just type
79:49 - in adabs into Google and then click here
79:52 - on the L link where it says adus
79:53 - amazon.com it'll take you to the same
79:55 - place now notice we have a big orange
79:58 - button in the top right corner so this
80:00 - says sign into the adus console um it's
80:02 - the if it's the first time you've ever
80:04 - been to this website so if I go to adab.
80:07 - amazon.com Incognito it will have the
80:10 - create an Abus Account button um I don't
80:12 - know why they don't keep this consistent
80:14 - across the board but I wish they did but
80:16 - if you are on the screen you can click
80:17 - here or there um but if you do see
80:20 - something that doesn't say uh you know
80:22 - create an account account or or Etc you
80:24 - can just sign
80:25 - in okay and then down below you can hit
80:28 - create a new a account so that's the way
80:31 - you're going to get in there and so
80:32 - you're going to put an email a password
80:34 - and create an adist account name um I've
80:36 - created this so many times and it's so
80:39 - hard to set up new emails I'm not going
80:40 - to do this again it's not complicated
80:42 - but one thing I need to tell you is that
80:43 - you do need to have a credit card you
80:45 - cannot create an account without a
80:47 - credit card um and for those who are in
80:49 - places where maybe you don't have a
80:52 - traditional credit card card maybe you
80:53 - can get a prepaid one so up here in
80:54 - Canada we have a company called coo and
80:57 - so coo is um a Visa debit card and so
81:01 - it's basically a virtual prepaid credit
81:03 - card and so these do work on the
81:05 - platform as well so if you have a
81:06 - traditional credit card or possibly
81:08 - could find one of these uh you still
81:10 - have to load up with money but it does
81:11 - give you a bit more flexibility to
81:12 - create that account so what I want you
81:14 - to do is go through that process
81:16 - yourself it's not complicated and I'll
81:18 - see you on the other end
81:21 - okay
81:24 - so once you finished creating your
81:26 - account you should be within the adus
81:28 - Management console and this is the page
81:29 - you're always going to see when you log
81:31 - in it's always going to show the most
81:33 - recent Services here um and you'll
81:36 - notice in the top right corner that I
81:37 - have my account called exam Pro if
81:39 - you're wondering how do you change that
81:41 - name what you do is to go to my accounts
81:44 - here and once there you'll have your
81:46 - account settings up here if you go to
81:48 - edit uh you can change that name here
81:51 - okay so you know sometimes when you
81:53 - create your account you don't like the
81:55 - account name that you gave it and so
81:56 - that's your opportunity to fix it um but
81:59 - once we're in our account what I want
82:00 - you to do is immediately log out because
82:02 - I want you to get familiar with the way
82:04 - you log into AWS because it is a bit um
82:07 - different than other providers and so I
82:10 - don't want you to uh get hung up later
82:12 - on with your account so I've logged out
82:15 - I'm going to go ahead and log back in so
82:17 - you can click the orange button or what
82:18 - I like to do is drop down my account and
82:21 - go to itus Management console
82:23 - it's a lot more clear and you notice
82:25 - we're going to have two options root
82:26 - user and I am user so this is what I'm
82:30 - talking about for the confusion so when
82:32 - you log into your root user account you
82:35 - all are always using an email and when
82:37 - you're logging as an IM user you're
82:39 - actually going to be entering the
82:40 - account ID or account Alias but what
82:42 - we'll do is go to the root user and this
82:44 - is the email you use to sign up with the
82:46 - account so for me uh I called this one
82:50 - Andrew plus sandbox exampro . Co I'm
82:53 - going to go to next sometimes you get
82:55 - this character box it's very annoying
82:57 - but it happens time to time and so what
82:59 - I'm going to do is just go ahead and
83:01 - type that in
83:03 - okay and hopefully it likes it and then
83:06 - I'm just going to enter in my
83:08 - password all right and I'll be back into
83:11 - my account and so notice it takes me
83:12 - back to ABS Management console so the
83:14 - root account is not something we want to
83:16 - be generally using uh except for um very
83:19 - particular use cases and we do cover
83:22 - that in the course uh but what I want
83:24 - you to do is go set yourself up with a
83:26 - proper account and so what we'll do is
83:29 - go to the top here and type in am and
83:31 - this stands for identity and access
83:33 - management and we'll click on am
83:36 - here and on the left hand side we're
83:38 - going to see a bunch of options here um
83:40 - and so notice right away we get to the I
83:42 - IM dashboard where it's going to start
83:44 - to make some recommendations for us the
83:46 - first one is always to add MFA
83:48 - multiactor
83:50 - authentication another thing you can do
83:51 - is set an account account Alias so you
83:53 - can see that I've set one here prior so
83:55 - if I just go ahead and remove it the way
83:57 - we'd have to log in is via the account
83:59 - Alias uh which is the same as the
84:01 - account ID and so I don't really like
84:03 - that so I'm going to just rename it to
84:04 - Deep Space 9 and uh these are unique so
84:07 - you have to pick something that is
84:09 - unique to you so it could be your
84:11 - company name or things like that it's
84:12 - going to make it a lot easier to log in
84:15 - uh when we create our additional user
84:16 - here so we'll come back to MFA at some
84:18 - point here what I want you to do is go
84:19 - over to users and go ahead and make
84:21 - yourself a new user and so I'm going to
84:24 - call this one Andrew
84:26 - Brown and I'm going to enable
84:28 - programmatic access I'm going to enable
84:30 - ads Management console so this one's
84:32 - going to allow me to use the apis to
84:34 - programmatically work with ads and this
84:36 - one here is going to allow me to just
84:38 - log into the console which is uh pretty
84:40 - fair here so now that I have this we can
84:43 - autogenerate or give it a custom
84:44 - password I'm just going to autogenerate
84:46 - for the time being and here it says You
84:48 - must create a new password at the next
84:49 - sign in which sounds fair to me and we
84:52 - go ahead and create ourselves a new
84:53 - group so it's pretty common to create a
84:56 - group called admin and notice here this
84:58 - is where we're going to have a bunch of
85:00 - different policies so the first one here
85:01 - which is admin and access provides full
85:04 - access to a services and resources and
85:06 - this pretty much gives you almost nearly
85:09 - almost the same capabilities as the um
85:12 - AWS root user account uh and so that's
85:15 - going to be okay because we are an admin
85:17 - in our account so I'll checkbox that on
85:19 - but I just want to show you here if you
85:20 - drop down filter policies and you went
85:23 - to adus manage job functions these are a
85:25 - bunch of uh pre-made uh adus uh policies
85:29 - that you could apply uh to different
85:32 - users so what's really popular after the
85:34 - administrator access is to usually give
85:36 - the power user access and so this one
85:38 - allows um a user to do basically
85:41 - anything they want with the exception of
85:43 - management of users and groups so you
85:45 - know it could be that that's something
85:47 - that you'd want to do for some of your
85:48 - users I just don't want to have any
85:50 - trouble so I'm going to give us um admin
85:52 - access here and we're going to go ahead
85:54 - and create this
85:55 - group and so here is the group that we
85:58 - are creating we're going to go next we
86:00 - can apply our tags if we want I'm not
86:02 - going to bother we're going hit next
86:03 - review and then hit create
86:05 - user all right and so now what it's
86:07 - doing is it's showing us the access ID
86:09 - and the access uh key secret that we can
86:12 - use to programmatically access AWS and
86:14 - then there's a password here so I'm
86:15 - going to go ahead and show it and what
86:17 - I'm going to do is just copy this into a
86:19 - clipboard
86:21 - anywhere
86:27 - and so I'm just copying that off screen
86:29 - here because I'm going to need it to log
86:30 - in and I'm just going to remember my
86:32 - username as well all right and so what
86:34 - we'll do is go ahead and hit
86:37 - close so what I'll do is go back to my
86:40 - dashboard here and remember I set my
86:42 - account Alias as Deep Space 9 but we
86:43 - could also use the account ID to log in
86:46 - I'm just going to grab my account ID off
86:48 - screen here and what I want to do now is
86:50 - go ahead and log out and now log into
86:53 - this I user and this is the one that you
86:55 - should always be using within your 's
86:58 - account you shouldn't be using your root
86:59 - user account so what I'll do is go over
87:02 - to I am user here and notice now that it
87:04 - says account ID so 12 digits or the
87:06 - account Alias so here I can enter in uh
87:09 - these numbers here or I can enter in my
87:12 - Alias which is Deep Space 9 and again
87:15 - you'll have to come up with your own
87:16 - creative uh one there for yourself and
87:19 - we'll go ahead and hit next and so
87:21 - notice what it's going to do is now ask
87:23 - me what my IM username is so I Define
87:25 - mine as Andrew Brown and then uh we had
87:28 - an autogenerated a password there so
87:30 - that we had saw and so I'm going to
87:31 - place that in there we'll go ahead and
87:33 - hit sign in and so now right away it's
87:36 - going to ask me to reset the password so
87:38 - I'm going to put the old password in
87:39 - there and so now I need a new password I
87:41 - strongly recommend that you generate out
87:44 - uh your passwords to be very strong I
87:46 - like to go to password generator and
87:48 - I'll drop this down and I'll do
87:50 - something really long like 48 characters
87:52 - and um if you don't like weird
87:55 - characters you can take those out there
87:56 - sometimes it loads here so you got to
87:58 - try it twice um and I'm going to go down
88:00 - to whoops
88:02 - 48 there we go and so that's pretty darn
88:04 - long so I'm going to copy that off
88:06 - screen here so I do not
88:08 - forget and you probably would want to
88:10 - put this in a password manager something
88:12 - like Dashlane or some sort of thing like
88:16 - that and we'll go ahead and we will
88:18 - paste that in and we'll see whoops I
88:21 - don't want uh Google to save it uh and
88:23 - we'll see if it takes it and so there we
88:25 - go so what I'll do is now log out and
88:30 - I'll make sure my new password works
88:32 - because you really don't want to have
88:33 - problems later so we'll type in Deep
88:34 - Space 9 Andrew Brown again this is going
88:38 - to be based on what your uh what you
88:41 - have set and we'll go ahead and log in
88:43 - and there I am and so now notice there
88:45 - doesn't say um exam Pro or whatever it
88:48 - says Andrew Brown at Deep Space 9 so
88:50 - it's using the county alias and showing
88:52 - the name and that's how I'm going to
88:53 - know whether I'm the root account user
88:55 - or whether I'm logged in as an I am user
88:58 - all right so there we
89:00 - [Music]
89:04 - go okay so now that we have the proper
89:07 - user account to log in I just want to
89:10 - point out uh about regions so in the top
89:12 - right corner you'll notice it says North
89:14 - Virginia here it possibly will say
89:16 - something completely else for you but
89:19 - what you'll do is you'll click and drop
89:21 - that down and you you'll see a big list
89:22 - of regions and so sometimes when I log
89:25 - in ads it likes to default me to U East
89:28 - uh Us East Ohio but I honestly like to
89:30 - launch all my stuff in Us East North
89:33 - Virginia even though I'm in Canada I
89:35 - probably should be using the Canada
89:36 - central region down here um but the
89:38 - default region is going to be based on
89:40 - your locality okay so just understand
89:43 - that it might be different I strongly
89:45 - recommend for um all of our follow
89:47 - alongs you run in Us East one because Us
89:50 - East one is the original
89:52 - um the original region and it also has
89:56 - the most access to Ada services and some
89:58 - Ada Services um such as like billing and
90:02 - and cost and things like that are only
90:03 - going to show up in Us East uh North
90:06 - Virginia so just to make our lives a lot
90:08 - easier we're going to set it there but I
90:10 - want you to understand that some
90:11 - services are Global Services meaning
90:13 - that it doesn't matter what region
90:15 - you're in it's going to default to
90:16 - Global and one example could be
90:18 - cloudfront so if I jump over to
90:20 - cloudfront here for a moment
90:23 - and uh we do seem to have uh some CLR
90:25 - distributions here from a prior uh
90:28 - follow along but notice up here that it
90:30 - now says Global so CLR does not require
90:32 - a region selection let's make our way
90:35 - over to
90:37 - S3 all right and this one's also Global
90:40 - so again this one does not require a
90:43 - region selection but if you go over to
90:45 - something like
90:48 - ec2 okay this has a a region dependency
90:51 - so just be really careful about that
90:53 - because a lot of times you'll be doing a
90:55 - follow along and you'll be like why
90:57 - aren't these resources here or whatever
90:58 - and it's because this got switched on
91:00 - you and it can happen at any time so
91:01 - just be uh cautious or aware of that
91:04 - [Music]
91:07 - okay so one of the major advantages of
91:10 - using ads or any cloud service provider
91:13 - is that it utilizes metered billing so
91:16 - that is different from a fixed cost
91:17 - where you'd say Okay I want a server for
91:19 - x amount of dollars every month but the
91:21 - way us works is that it's going to bill
91:23 - you on the hour on the second based on a
91:26 - bunch of factors and so you're going to
91:28 - be able to get services at a lower cost
91:30 - however if you choose an expensive
91:33 - service and you forget about it or
91:36 - there's misconfiguration where you
91:37 - thought you were launching something
91:39 - that was cost effective but turned out
91:41 - to be very expensive you could end up
91:42 - with a very large Bill very very quickly
91:45 - and so uh that is a major concern for a
91:47 - lot of people utilizing Cloud but
91:50 - there's a lot of great toolings built
91:51 - into adabs to allow you to catch
91:54 - yourself if you happen to make that
91:56 - mistake and before we go ahead and learn
91:59 - how to do that I want to show you uh
92:01 - some place where you could end up having
92:04 - excessive spend without knowing it so
92:06 - one example and this is actually
92:08 - happened to me when I first started
92:09 - using AWS uh before I even knew about
92:12 - all the billing tools is I wanted to
92:14 - launch a reddis instance and so you you
92:17 - just have to watch you don't have to do
92:18 - this but um elasticache is a service
92:21 - that allow you to launch either a mcash
92:23 - or reddis uh database and I just wanted
92:26 - to store a single value and so I went
92:29 - here and I scrolled down it looked all
92:31 - good and I hit create but I wasn't
92:33 - paying attention because apparently itus
92:35 - likes to default the no type here to the
92:37 - cash
92:38 - r6g dolar all right and you know you
92:43 - might think that Abus has your best
92:44 - interest in play and most services are
92:46 - pretty good they they make sure that
92:48 - they're either free or very low spend
92:50 - but some of these and elastic cash is an
92:52 - older service where they just have these
92:54 - weird defaults so um you know if we were
92:57 - to go look up this the
93:00 - RG6 uh
93:02 - large all right and look at it
93:07 - spend all right and we would go over
93:09 - here whoops I think I went to the China
93:12 - One but if we were to go over here and
93:14 - look for that instance I'm just trying
93:16 - to find it here for cost this
93:19 - one down below
93:22 - um this doesn't say pricing does it say
93:24 - our pricing
93:26 - here here it is so this one cost
93:30 - um this one costs about 2 cents per hour
93:33 - it doesn't sound like a lot but if we go
93:35 - here and we do the math we say 730 730
93:38 - is the amount of hours in a month that
93:40 - is
93:41 - $150 okay so if you don't know about
93:44 - that and forget about that that's going
93:45 - to be $150 and I'm going to tell you
93:47 - that it used to be a lot higher I'm
93:49 - pretty sure they used to have it
93:50 - defaulted to something like
93:52 - like this or that because I remember I
93:54 - did this and I had a bill that came in
93:56 - that was like $3,000 USD and I'm in
93:59 - Canada so like $3,000 USD is like a
94:02 - million dollars up here and so I
94:04 - remember um it was a big concern and I
94:07 - freaked out but that was okay because
94:09 - all I had to do was go to support and
94:11 - what I had done is I went to the support
94:17 - center and I had opened a support case
94:20 - and I just said hey I had this really
94:23 - big bill so you go here right and you
94:26 - look for billing and uh you look for
94:29 - something like charging query or
94:31 - misspend and you say you know um you
94:36 - know like help my bill's too
94:39 - high and you just say like you explain
94:41 - the problem saying hey you know I was
94:43 - using elastic cash and it was set to a
94:45 - large default and I wasn't aware about
94:47 - it can you please give me back the money
94:49 - and the great thing is that ads is going
94:51 - to to give you a free pass if it's your
94:53 - first time where you've had a
94:54 - misspending they generally will say Okay
94:58 - um you know don't do it again and if it
95:00 - happens again you will get build but go
95:01 - ahead and learn how to set up building
95:03 - alerts or things like that okay so just
95:05 - so you know don't freak out if you do
95:07 - have a really high Bill you're going to
95:08 - get a single free pass but now that we
95:10 - know that let's go learn uh how to set
95:13 - up a budget
95:14 - [Music]
95:18 - okay all right so now that we've had a
95:21 - bit of a story about um over spend for
95:24 - misconfiguration let's learn how to
95:26 - protect ourselves against it and we're
95:28 - going to go ahead and set up a budget so
95:31 - go to the top here and type in budget
95:34 - and what that will do is bring us over
95:35 - to the billing dashboard another way to
95:37 - get here is to go click at the top here
95:39 - and go to my billing dashboard and then
95:41 - you'll see the leftand menu here and so
95:44 - the great thing about budgets is that
95:46 - the first two are free it says there is
95:48 - no additional charge for any those
95:49 - budgets you pay for configured us us
95:51 - Mage but I'm pretty sure that that's not
95:54 - true because it used to be ABS budget
95:58 - reports okay so that cost
96:00 - something it used to be that Abus
96:02 - budgets um after success enabled will Ur
96:05 - 10 cents daily so in addition to budget
96:07 - monitor you can add actions to your
96:09 - budgets the first two action enable
96:12 - budgets are free okay so just be aware
96:14 - that just because it says there's no
96:16 - additional charge read into it because
96:19 - sometimes the the Fine Line will tell
96:20 - you it does something but I know that
96:22 - the first two are free what we'll do is
96:24 - go ahead and create a budget just going
96:26 - to close these other tabs here since we
96:27 - have no need for them and we're going to
96:29 - be presented with a bunch of budget
96:30 - types uh we're considered about cost
96:32 - today so we're going to go with a cost
96:34 - budget and notice we can change the
96:36 - period from monthly to daily to
96:37 - quarterly to annually if you change it
96:39 - to daily um you won't get forecasting so
96:42 - I don't want that today but a monthly is
96:44 - pretty good you can have a reoccurring
96:46 - which is strongly recommended and then
96:47 - you can put a fixed cost notice that I
96:49 - already have some spend on this account
96:51 - so it was like 25 bucks last month I'm
96:54 - going to set my uh budget here to
96:57 - $100 and you can add filters here to um
97:01 - uh filter that cost out so if you want
97:03 - to say only for this region or things
97:05 - like that you could do that uh notice
97:07 - that this is my spend over here um so
97:09 - this is my budget and that's the actual
97:11 - cost notice my cost has been going up
97:12 - the last few months because I've been
97:13 - doing things with this account and so
97:16 - what I'll do is say simple budget here
97:19 - we'll hit next
97:22 - and so now it's asking us if we want to
97:24 - configure alerts we probably do so you'd
97:26 - hit ADD alert and then you'd set a
97:28 - threshold like 80% or you could say an
97:31 - absolute value and then You' put in your
97:33 - emails like Andrew exampro
97:35 - doco and I want to point out that this
97:37 - is using um itus
97:41 - SNS or it should be anyway so Amazon SNS
97:44 - has no upfront cost based on your stuff
97:46 - here so even though you're filling out
97:47 - an email you know and maybe it doesn't
97:50 - show it but I'm pretty sure that this
97:51 - would create an
97:53 - SNS topic but what we'll do is hit next
97:55 - here we have an alert so we're just uh
97:59 - reviewing actually this is for attaching
98:00 - any action so maybe we want some kind of
98:03 - follow-up thing to happen here so we say
98:05 - add
98:05 - action and uh requires specific I in
98:09 - permissions on your
98:11 - behalf okay sure so I guess you could
98:15 - follow up actions that's no different
98:17 - than um a building alarm but we're not
98:20 - really worried about that right now now
98:22 - I'm not going to bother with an action
98:25 - and we'll go ahead and create a
98:26 - budget and so here it's going to say
98:29 - that our budget is $100 it's going to
98:30 - show us the amount used forecast amount
98:32 - current budget sometimes this takes time
98:34 - to uh show up so I'm going to hit
98:36 - refresh and see if it shows up
98:39 - yet there we go so notice we have
98:41 - forecast amount $23 current budget Etc
98:44 - forecasted budget uh forecasted versus
98:47 - budget so it's pretty straightforward on
98:49 - how that works um I'm just curious if it
98:51 - actually created an SNS event so I'm
98:53 - going to go over here because a lot of
98:56 - services utilize SNS so if I go over
98:58 - here default Cloud watch alarm um so I
99:03 - think this is something I had created
99:04 - before so I'm going to go ahead and just
99:06 - delete it says default Cloud watch
99:09 - alarms I'm going to just click into here
99:11 - and see what I
99:12 - have
99:14 - confirmed so I think it might have used
99:17 - this when we created it but um the
99:19 - reason I'm bringing up SNS is that
99:20 - there's a lot of services that allow you
99:22 - to uh email yourself for alerts and it
99:25 - always integrates with this service and
99:26 - so I just want kind of want to point
99:27 - that out so that you remember what SNS
99:29 - is for um but yeah so setting up a
99:31 - budget is not too hard so there you
99:34 - [Music]
99:37 - go all right so now that we've set a
99:40 - budget what I want to talk to you about
99:42 - is the free tier and the free tier is
99:44 - something that available to you uh for
99:46 - the first 12 months of a new adus
99:47 - account and allows you to utilize adus
99:49 - services without incurring any cost to
99:52 - you and so it's in your advantage to
99:54 - utilize this free tier um as you are
99:56 - experimenting and learning cloud so if
99:59 - you want to learn about all the
100:00 - offerings what you do is go to Google
100:02 - type in adus free tier and you'll get
100:03 - this page that explains all the sorts of
100:05 - things here so you can get uh 750 hours
100:09 - on ec2 RDS things like that there are
100:12 - stipulations in terms of what it would
100:14 - be so here this is a T2 or T3 micel mic
100:17 - uh micro running Linux Red Hat um or
100:21 - other type of os's okay so there are uh
100:24 - details you have to read the fine print
100:26 - some services are only available for the
100:28 - first two months things like that so
100:31 - it's going to highly vary based on
100:33 - service but it's worth giving this a
100:34 - read in areas that you are interested in
100:37 - now the thing is is how do you know that
100:39 - you are still in the free tier or you go
100:41 - outside of it and that's what I want to
100:43 - talk to you about right now so I am
100:45 - actually in another adist account so
100:46 - notice in the top right corner it says
100:48 - brown. laap or hyphen laptop exampro
100:50 - doco sometimes I will switch into
100:52 - different AIS accounts during these
100:53 - follow alongs so I can best show you um
100:56 - you know the settings so if you make
100:58 - your way over to
101:00 - billing and actually I should show you
101:02 - up here if we go to my dealing B
101:04 - dashboard just trying to be consistent
101:06 - here and you go to the left- hand side
101:08 - to billing preferences what you can do
101:10 - is enable receive free tier usage alerts
101:13 - and then put your email in there and
101:14 - save that and so turn on this feature to
101:16 - receive email alerts when your adus
101:19 - service usage is approaching or deleted
101:21 - data was free tier usage limits if you
101:22 - wish to receive these alerts etc etc etc
101:26 - right and while you're there I want you
101:29 - to also checkbox receive billing alerts
101:32 - so I can show you how to set a bing uh a
101:34 - billing alert and ITA says you know
101:36 - budgets are a new thing but billing
101:38 - alerts are still something that we use
101:40 - as of today so if you checkbox that on
101:42 - we'll be able to see your cost if we go
101:45 - back here uh it should show you um it's
101:48 - because I'm out of the free tier on this
101:50 - account but but it would show you in the
101:52 - alerts you know your usage there so
101:54 - example here is if we scroll down this
101:56 - is the documentation tracking your a
101:58 - free tier usage you would see like a box
102:01 - like this and would say hey your free
102:02 - tier usage limit is here and you're over
102:05 - it okay so that generally would show up
102:08 - on this panel here but again I'm outside
102:10 - of the free tier so I'm not seeing it
102:12 - here um today
102:15 - okay so you know hopefully that is clear
102:18 - um but yeah there you go
102:21 - [Music]
102:25 - all right so we created ourselves a
102:27 - budget we're monitoring our free tier
102:30 - but there's another way that we can
102:32 - monitor our spend and that is through
102:33 - building alerts or alarms and it is the
102:36 - old way before uh we had abis budgets
102:39 - this was the only way you could do it
102:40 - but I still recommend it because there
102:42 - is a bit more flexibility here with this
102:44 - service and so I wanted to teach you
102:46 - early on so that you know it's available
102:48 - to you or if you want to play around
102:49 - with it in the future so what you'll do
102:51 - is go to the top here and type in
102:54 - cloudwatch and cloudwatch is one of
102:56 - those Services where it's actually a
102:57 - collection of services so there's
102:59 - cloudwatch alarms cloudwatch logs
103:01 - cloudwatch metrics those are all
103:03 - Individual Services and aabus loves to
103:06 - update their interface so sometimes
103:08 - you'll be presented with this option to
103:10 - uh change the latest interface I'm going
103:12 - to try out the new interface here um and
103:14 - that is one challenge with datab is you
103:16 - always have to expect that they're going
103:17 - to change the UI on you and you're going
103:19 - have to work through it so just
103:21 - understand that I try to keep my videos
103:22 - up toate as best I can but part of the
103:25 - challenge is getting used to that so
103:27 - this is what they have today I don't
103:28 - know if they're going to stick with this
103:29 - but this is what it looks like but what
103:31 - I want you to do is make your way over
103:32 - to alarms on the left hand
103:34 - side and notice that we actually have a
103:36 - section just for billing which is
103:38 - interesting I don't remember them having
103:39 - that before so it's new so uh here it
103:42 - says it was cloudwatch help can help you
103:44 - monitor the charges of Bill remember
103:46 - that we had to turn that on get 10 free
103:48 - alarms with 1,000 free email
103:50 - notifications each month as part of the
103:52 - free tier so understand that if you
103:54 - create billing LS they do cost money um
103:57 - as well if you go over that limit but
103:59 - you sure get a lot 10 free alarms is
104:01 - quite a bit what we'll do is go ahead
104:03 - here and create ourselves alarm we are
104:04 - going to go and choose a metric and so
104:07 - here are the options we could choose
104:08 - from and so we I think would like um
104:14 - billing and see we can do buy service or
104:17 - total estimated charge we're going to do
104:18 - a total estimated charge we can only
104:20 - select USD I've never seen any other
104:22 - currency ever there and so here we kind
104:24 - of get this little graph where we can
104:26 - see stuff um but this is a lot more
104:28 - powerful than budgets because you can do
104:30 - anomaly detection uh so like here it
104:33 - will actually check base between a range
104:35 - as opposed to just going through a
104:37 - particular value but what I'll do is
104:38 - just set a value here like uh $50 right
104:43 - so notice that it sets the line up here
104:45 - and this is my current spend here right
104:47 - and so back to anomaly detection this is
104:49 - a lot smarter so so uh the idea is that
104:51 - if something is outside this band of a
104:54 - certain amounts um then it would alert
104:56 - okay but I'm going to go back here I'm
104:59 - just going to set this to
105:00 - $50 and that looks okay to me you can
105:03 - change the period 6 hours is fine um and
105:07 - there's additional configuration that's
105:08 - fine as well we're going to go ahead and
105:10 - hit next uh and so the idea is that um
105:13 - you know if it passes that red line it
105:15 - will go to an in alarm State and then
105:18 - what it will do is uh we want to
105:21 - uh have it to trigger an SNS topic so I
105:24 - would generally just create a new one
105:25 - here we'll just say my billing
105:28 - alarm Okay and then here we'll just set
105:31 - the email Andre exam
105:33 - pro. and we'll go ahead and create that
105:37 - topic and so that is now set I don't
105:40 - know if it would uh confirm it we might
105:41 - have to go to our email to confirm it so
105:43 - notice it says pending confirmation so
105:45 - what it has done is it sent me out an
105:47 - email and it wants me to click that link
105:49 - to confirm term um that I want to
105:52 - subscribe to it so I might just do that
105:53 - off screen to show you here
105:56 - okay so I'm just going to pull up my
105:58 - email here just give me a
106:02 - moment okay and so if I come back here
106:05 - this is the email that came in so I'm
106:06 - just going to confirm that subscription
106:08 - says I'm confirmed good and if I refresh
106:11 - this page we can now see that that that
106:14 - is confirmed all right so we'll scroll
106:17 - down here so we can uh trigger an auto
106:19 - scaling AC so maybe you know if you have
106:21 - too many servers you say hey the cost is
106:23 - too much shut down those servers there's
106:25 - ec2 actions things like that so these
106:27 - are kind of similar to um budgets right
106:31 - there's system manager actions I imagine
106:33 - all these things are available in
106:34 - budgets as well but budgets just makes
106:36 - it a little bit easier to look at so I'm
106:37 - going just say my simple building alarm
106:42 - here we'll hit
106:44 - next all right we'll hit create alarm
106:47 - and there you go so bilding alarms don't
106:49 - have like four forecasting and things
106:51 - like that um but you know they are they
106:54 - do have their own kind of special
106:55 - utility and so I utilize both okay so
106:58 - there we go we'll just go back to our
106:59 - Management console and move on to the
107:00 - next
107:01 - [Music]
107:05 - one so one of the strongest
107:07 - recommendations that adus gives you is
107:09 - to say to set MFA on your adus root user
107:13 - account so that's something we're going
107:14 - to do right now so make sure you're
107:16 - logged into the root user account so I'm
107:17 - going to go log out as my IM user I'm
107:20 - going to go back and log in and I'm
107:23 - going to log in as my uh root user here
107:26 - so to do that no sometimes it will be
107:28 - expanded as the I am user click and sign
107:31 - into root user here we'll have root user
107:33 - I'm going to go ahead and enter my email
107:35 - that I used and if you do switch
107:38 - accounts frequently they will ask you
107:40 - these silly captures which drive me
107:41 - crazy but uh you know it happens you
107:44 - probably won't encounter it as much as I
107:45 - do and so I'm going to go ahead and grab
107:48 - my password here and paste it on in
107:51 - and so now that I'm in what I want to do
107:53 - is make my way over to
107:55 - am and I'm going to go and look for
107:59 - users actually sorry just right here add
108:01 - an MFA root user we're going to go ahead
108:04 - and hit add
108:05 - MFA all right and so that's going to
108:07 - bring us to this screen and so here we
108:09 - can activate our MFA and so we have a
108:12 - few options here so we have virtual MFA
108:15 - device u2f security key other Hardware
108:18 - like a uh
108:20 - J galto token so you know I generally
108:24 - use this because I have a security key
108:27 - and I want to show you what I'm talking
108:28 - about so this is how I log into my
108:31 - machine or my ad account this is a
108:34 - security key an UB key that sits on my
108:36 - desk I tape it so it doesn't fall fall
108:38 - off the cord but the idea is that when I
108:40 - log in I have to press this little
108:42 - button here to double confirm before I
108:45 - get into my account uh but if you don't
108:46 - have a security key you can just use a
108:48 - virtual MFA and all that means is you're
108:50 - going to um use something on your phone
108:54 - to log in so we'll click continue here
108:56 - and so it says install a compatible app
108:58 - on your mobile phone or device and so if
109:01 - you click and open this what it will do
109:03 - is tell you about some things that you
109:04 - can use um so if we scroll down to
109:08 - Virtual here they suggest uh if you have
109:11 - Android iPhone so aie dual mobile last
109:13 - path Microsoft authenticator Google
109:16 - Authenticator so Google Authenticator
109:18 - Microsoft authenticator and a here I
109:20 - have all those three installed um
109:22 - honestly aie has the the nicest simplest
109:25 - um UI but I'm using Microsoft authentic
109:28 - authenticator quite a bit so anyway
109:30 - whichever you want to do it's fine but
109:32 - what we'll have to do is go back here
109:34 - and then it says use your virtual MFA
109:36 - app on your device camera to scan your
109:38 - QR code so once you have one of those
109:41 - apps installed like aie or whatever one
109:43 - you want what you're going to do is open
109:47 - up the application and I can't tell you
109:49 - exactly where it is but you'll have to
109:51 - hit add account in your in your app and
109:54 - then from there it will ask you to scan
109:55 - your QR code and so uh once you're ready
109:59 - you hit show The QR code you hit scan
110:01 - the QR code on your phone I'm holding my
110:03 - phone up to my my um uh my computer
110:07 - screen here and it's going to find it
110:10 - and I'm just going to take a moment here
110:11 - to rename the account so I can tell what
110:13 - it is so I'm just naming it a
110:15 - WS sandbox because that's what I call
110:18 - this account
110:21 - and I'm going to go ahead and save that
110:23 - and so now what I can do is enter uh two
110:25 - consecutive MFA codes now this always
110:27 - confuses me what they wanted here but
110:29 - the idea is that you're going to see one
110:31 - code right whatever is on the screen
110:33 - right now so I'm going to type in it it
110:34 - says
110:35 - 734
110:36 - 051 and I'm going to wait until the new
110:40 - code shows up so there's like a timer in
110:42 - all these apps and they go across the
110:44 - screen or they countdown and so you have
110:46 - to wait for that to happen and so I'm
110:48 - just going to wait here a little bit
110:55 - and once I get the new number here this
110:57 - one is
111:00 - 07153 0 I'm going to hit assign MFA and
111:03 - there we go and I can't tell you how
111:05 - many times I like mess that up because I
111:07 - didn't understand the consecutive
111:08 - numbers but you're just waiting for uh
111:10 - the number that's on the screen to
111:11 - entered in and then enter the next one
111:13 - in to turn on MFA and so now your
111:16 - account is protected and every time you
111:17 - log in you're going to have to enter in
111:20 - MFA so let's log out and see what that
111:22 - looks
111:23 - like so we'll go ahead and sign
111:26 - in and uh again we'll put in our root
111:30 - user account here we'll type in 74m
111:35 - 32t
111:36 - submit and I need to go grab my password
111:39 - so that's in my password manager just
111:41 - give me a moment
111:44 - here and now it wants the MFA code so
111:47 - this is in my phone and so I'm going to
111:49 - go enter it in so this one says
111:51 - 475
111:53 - 841 all right we'll hit
111:56 - submit okay and there we go so that's
111:58 - going to happen every single time we
112:00 - want to log in uh I'm going to tell you
112:02 - that if you get one of these they're so
112:04 - much easier to use because you just
112:05 - press the button okay so that's why I
112:07 - have this because I cannot stand
112:09 - entering the code in time and time again
112:12 - um but you know those are your options
112:13 - there
112:15 - [Music]
112:18 - okay hey this is Andrew Brown from exam
112:21 - Pro and we're looking at the concept of
112:23 - innovation waves so when we're talking
112:25 - about Innovation waves we're talking
112:26 - about contracta or k waves which are
112:29 - hypothesized cyclik phenomena in the
112:32 - global World economy and the phenomenon
112:35 - is closely connected with technology
112:36 - life cycles so here is an example where
112:39 - each wave is irreversibly changes the
112:41 - society on a global scale and if you
112:44 - look across the top we can kind of see
112:46 - what they're talking about so we have
112:47 - steam engine cotton uh rail way in steel
112:50 - electric engineering chemistry petrol
112:53 - chemicals automobiles information
112:55 - technology and so the idea is that uh
112:58 - Cloud technology is the latest wave and
113:01 - I'm not sure if you'd fit web 3 in there
113:03 - as well ml AI but maybe they're all part
113:06 - of the same wave or they're separate
113:07 - waves but generally they're broken up
113:09 - based on this
113:11 - prde here where it says perspective
113:14 - recession depression and movement uh
113:16 - Improvement sorry and so this is the
113:18 - common pattern of wave we see a change
113:20 - of supply and demand and so if we're
113:22 - seeing this we know that we are in a
113:24 - wave and where we are in a wave
113:27 - [Music]
113:30 - okay hey this is Andrew Brown from exam
113:33 - Pro and we are looking at the concept of
113:34 - a burning platform so burning platform
113:36 - is a term used when a company abandons
113:38 - old technology for new technology with
113:41 - the uncertainty of success and can be
113:43 - motivated by fear that the
113:44 - organization's future surv uh survival
113:46 - hinges on digital transformation and
113:49 - just to kind of give you visualization
113:50 - here is a Lal burning platform so
113:53 - imagine you have to jump to it jump from
113:55 - it to make a change so um you know
113:58 - burning platform could be you know stop
114:00 - using on-prem and start using cloud or
114:02 - maybe it going from Cloud to web 3 um
114:05 - and that's generally the idea when we
114:06 - talk about a burning
114:09 - [Music]
114:12 - platform so I just want to quickly show
114:15 - you that digital transformation
114:16 - checklist that I mentioned and the way
114:18 - you can get to it is by typing in
114:20 - digital transformation AWS and so it
114:23 - should bring you to the public sector
114:24 - page and here it is so we click there
114:26 - and all it is is a PDF uh so it's not
114:29 - new it's from 2017 but that doesn't mean
114:31 - that it's not uh valid anymore uh it's
114:33 - just that that's when it was made so we
114:35 - scroll on down and we can see
114:36 - transforming vision and so we have a
114:38 - checklist there so if we click into this
114:40 - uh we can see things like communicate a
114:42 - vision of what success looks like Define
114:44 - a clear governance strategy including
114:46 - the framework of achieving goals uh
114:48 - build a cross functional team identify
114:50 - Tech technical uh Partners they talk
114:53 - about Shifting the culture and then down
114:55 - below I assume that this one is related
114:57 - to that one it's unusual because you
114:59 - know they just have a checklist here but
115:01 - then they have a sub checklist which
115:03 - must be clear to that so reorganize
115:05 - staff into smaller teams things like
115:06 - that so it's not super complicated
115:08 - you'll see each category go go Cloud
115:10 - native they'll have a
115:11 - checklist um you know and if you are at
115:14 - at the executive level or the sales
115:16 - level or trying to convince your VPS or
115:18 - stuff like that give this a it might
115:20 - give you something uh useful in the end
115:22 - uh to help better communicate that
115:24 - transformation for you
115:26 - [Music]
115:29 - okay hey this is Andrew Brown from exam
115:32 - Pro and we are looking at the evolution
115:34 - of computing power so what is computing
115:36 - power it's the throughput measured at
115:37 - which a computer complete computational
115:40 - tasks and so uh what we're pretty much
115:42 - used to right as of these days is
115:44 - general computing so a good example here
115:46 - would be a zeeon CPU processor that's
115:49 - more of a high-end processor not
115:51 - something you'd find your home computer
115:53 - but when we're talking about data
115:54 - centers specifically uh um you know
115:56 - inabus data centers Zeon CPU processors
115:59 - or what you're going to come across uh
116:01 - then came along a new type of compute
116:03 - which is GPU Computing um when we're
116:05 - talking about Google uh Cloud they have
116:08 - tensor Computing and so this is where I
116:10 - get the 50 times faster based on that
116:11 - metric and so I didn't have an exact
116:13 - metric here for AWS uh um solution for
116:16 - this mid-tier of computing power so I
116:19 - just that 50 times there but the idea is
116:21 - that GPU Computing or tensor Computing
116:24 - uh is is 50 times faster than
116:27 - traditional CPU and generally that's
116:29 - going to be used for uh very specialized
116:31 - tasks when you're doing machine learning
116:34 - or AI so it's not something you're going
116:35 - to uh be doing for your regular uh web
116:38 - workloads but just understand that all
116:40 - of these uh fits so we're not getting
116:42 - rid of general computing we're just
116:44 - adding uh new levels to compute then
116:46 - there's the latest which is uh Quantum
116:48 - computing and so here we have an example
116:51 - of the
116:53 - rig retti 16q Aspen 4 and so it
116:57 - literally looks like it's out of um
116:59 - science fiction and this thing is like a
117:02 - 100 million times faster it is super
117:05 - Cutting Edge and we don't even know
117:06 - exactly how it works and there's not
117:08 - even anything that's very applicable
117:10 - that we can use this for but the idea is
117:12 - that we're not done with the evolution
117:14 - of of computing power things are going
117:16 - to get a lot faster once we solve this
117:18 - last one here
117:20 - and so ad service offering here would be
117:22 - for general computing you're looking
117:23 - elastic compute Cloud You2 so we have a
117:26 - variety of different uh instance types
117:28 - and they're all going to have different
117:29 - types of Hardware with different types
117:30 - of general computing um for GPU
117:33 - Computing this is a specialized chip
117:36 - that adus has produced called the adus
117:38 - um and I don't know how to say it but
117:40 - we'll just abbreviate it to infer so
117:42 - adus infer chip um and this was designed
117:45 - as a direct competitor to uh gcps uh
117:48 - tensor computing uh unit the T TPU um
117:52 - and so this is intended for AI ml
117:54 - workloads but it works with not just um
117:56 - tensor flow but it works with any
117:59 - machine learning framework so that is
118:01 - one advantage it has over uh tpus um and
118:04 - then the last one here is adus bracket
118:06 - so you can actually use quantum
118:07 - Computing as a service on adus you uh as
118:10 - of even today um the way adus is able to
118:13 - do this is they work with Caltech so
118:15 - that's the California
118:16 - technology um University or Institute
118:19 - I'm sure the name of it there um so it's
118:21 - not exactly adus producing this but adus
118:23 - is doing this as a partnership to give
118:25 - Quantum Computing accessible to you
118:31 - okay so I'm here in the Abus console
118:33 - because I just want to prove to you that
118:35 - you can use quantum Computing on AWS
118:38 - it's that accessible so all you'd have
118:39 - to do is go to the top here type in
118:41 - bracket uh and then you make it over to
118:43 - Amazon bracket and so here uh you can
118:46 - like set up Quantum tasks the first time
118:48 - you set it up you got to go through this
118:50 - process here um and I think I have to go
118:53 - through this onboarding to be able to
118:54 - show you the next steps so I'm going to
118:55 - go ahead and enable bracket in this Abus
118:59 - account okay and I'm not going to launch
119:01 - anything I'm just going to try just kind
119:03 - of show you a little bit of what is
119:05 - accessible to you because it's not super
119:07 - exciting but the fact that you can do it
119:09 - is kind of interesting so here I am on
119:11 - the inside here and we have all these
119:13 - different types of quantum Computing so
119:16 - d-wave I know I I NQ
119:20 - retti things like that and then down
119:22 - below these are the quantum processing
119:24 - units the qpu and then down below you
119:27 - have the simulator so you can kind of
119:29 - simulate uh these things here um so I
119:32 - think that's kind of
119:33 - interesting uh but in terms of the cost
119:36 - like if you scroll on down here um so AB
119:39 - bracket is part of the was free tier it
119:40 - gives you one free hour of quantum
119:42 - circuit simulation time per month during
119:44 - the first 12 months so it's free to do
119:47 - uh a circuit simulation
119:50 - but if you actually want to run it on
119:51 - the actual Hardware you can see the cost
119:53 - there's the per task price the per shot
119:56 - price things like that uh what could you
119:58 - do with this I don't know there's things
120:00 - called like quad bits or something like
120:01 - that and I can't imagine that you're
120:03 - going to be doing anything useful but I
120:04 - think it's just more so like you are
120:06 - sending out quad bits or whatever they
120:08 - are and you're observing them um but
120:10 - what you could do with them I have no
120:11 - idea but it's just exciting that you can
120:13 - do that I didn't have any spend just by
120:16 - activating that I'm just kind of just
120:17 - showing you there okay
120:19 - [Music]
120:24 - hey this is Andrew Brown from exam Pro
120:26 - and we are looking at the benefits of
120:28 - cloud and this is a summary of reasons
120:30 - why an organization would uh consider
120:32 - adopting or migrating to utilizing
120:34 - public cloud and so we'll quickly go
120:36 - through the list here uh because in the
120:38 - followup slides we actually go into them
120:40 - a bit more detailed so we have agility
120:42 - page a go economy of scale Global reach
120:45 - security reliability High availability
120:48 - scalability um um and elasticity so the
120:52 - thing is is that eight of us had this
120:54 - before it was called the six advantages
120:55 - of cloud but they have reworked it to
120:57 - include additional items um and so where
121:00 - you see these uh sub bullets here those
121:03 - are the original six as you see 1 2 3 4
121:06 - five six and so I kind of just put them
121:08 - where they kind of uh fall under the new
121:10 - categories there and you'll notice that
121:12 - aist has included High availability
121:14 - elasticity reliability and security as
121:17 - uh new ones here okay
121:20 - and so the thing is is that um I have
121:23 - always always even in my original uh I
121:26 - think in my original cloud practitioner
121:28 - had Cloud architecture as a separate
121:30 - section and included all these things in
121:32 - here so it's a great thing to see that
121:33 - abis has included it um but in terms of
121:37 - how I organized this course we're not
121:39 - going to cover them in this section
121:40 - because I have the cloud architecture
121:42 - section so just understand that we will
121:44 - come to those eventually and I would
121:45 - just say that adus is still missing
121:47 - something on this list which is fault
121:49 - tolerance so you know my list looks like
121:52 - this except I would add fault tolerance
121:54 - to it so you have everything there um
121:56 - and Disaster Recovery okay so the
121:59 - benefits of cloud is a reworking
122:00 - expansion of the six advantages of the
122:02 - cloud and we will look at the original
122:04 - six advantages um and then look at
122:06 - another one that is more of a
122:08 - generalized one that I I've used across
122:10 - my courses so that we fully understand
122:12 - the benefits
122:13 - [Music]
122:17 - okay all right let's take a look here at
122:19 - these six advantages to Cloud defined by
122:21 - AWS and so these are still uh part of
122:24 - aws's marketing Pages um but you know
122:26 - it's interesting because you can't find
122:28 - the benefits of the cloud in a single
122:30 - page on any at least at the time of
122:31 - making this so there's a bit of
122:33 - Disconnect between the um exam guide and
122:36 - the actual marketing material but that's
122:37 - okay I fill it all in for you so you
122:39 - know I'm just again noting that the six
122:41 - advantage of cloud was the original
122:42 - description for cloud benefits and we'll
122:45 - go through them okay so the first is
122:46 - trade Capital expense for variable
122:48 - variable expense so you can pay on
122:50 - demand meaning that there is no upfront
122:52 - cost and you pay for only what you
122:54 - consume or you pay by the hour minutes
122:56 - or second so instead of paying for
122:58 - upfront costs of data centers and
122:59 - servers the next is benefit from uh
123:02 - massive Eon uh uh economies of scale so
123:05 - you are sharing the cost with other
123:07 - customers to get unbeatable savings
123:09 - hundreds of thousands of customers
123:10 - utilizing a fraction of a server stop
123:12 - guessing capacity so scale up or down to
123:15 - meet the current needs launch and
123:16 - Destroy Services whenever so instead of
123:19 - of paying for idle or underutilized
123:20 - servers we have increased Speed and
123:22 - Agility so launch resources within a few
123:24 - clicks and minutes instead of waiting
123:26 - days or weeks of your it to implement
123:28 - the solution on premise we have stopped
123:30 - spending money on running and
123:32 - maintaining data centers so focus on
123:34 - your customers developing and
123:35 - configuring applications so instead of
123:37 - operations such as racking stacking and
123:40 - powering servers the last is Go Global
123:42 - in minutes so deploy your app in
123:44 - multiple regions around the world with a
123:46 - few clicks provide load latency and a
123:48 - better experience for your customers at
123:49 - minimal cost the six advantage of cloud
123:51 - still apply and um I like to include
123:54 - them here because they just have a
123:56 - different kind of a lens or or or angle
124:01 - when you're looking at this stuff and so
124:03 - we've looked at the six advantages of
124:04 - cloud and now let's take a look at the
124:05 - next slide my reworking of the six
124:08 - advantage of the cloud to be more
124:09 - generalized
124:10 - [Music]
124:13 - okay all right I just wanted to show you
124:15 - where that six advantages of cloud
124:17 - computing comes from it's part of IIs
124:19 - documentation so I typed it in here and
124:21 - you can see that it is still around uh
124:23 - and so it's unusual because this used to
124:25 - be part of the marketing website it had
124:27 - those nice little Graphics um but for
124:29 - whatever reason it's over here now in
124:31 - the overview of Amazon web services and
124:34 - by the way if you're starting starting
124:35 - out with ads this is a very light read
124:37 - but it is a good read uh to get started
124:40 - with we obviously cover all this stuff
124:42 - in the course um but you know maybe
124:43 - you'll get something different here but
124:45 - the idea is that IUS has definitely
124:46 - expanded on this but for whatever reason
124:48 - this documentation hasn't changed so
124:50 - just understand that I've polyfilled
124:52 - that for you in this course
124:54 - [Music]
124:57 - okay all right so this is the seven
125:00 - advantages to Cloud I said six but I
125:02 - meant to say seven and so um you know
125:04 - since I've created fundamental courses
125:06 - for all the clouds providers I started
125:08 - to notice kind of a trend and so what I
125:10 - did is I normalized it into my own seven
125:13 - advantages and this actually Maps up
125:16 - really well to the new benefits of the
125:18 - cloud so it looks like itus was thinking
125:20 - the same as I was um with the exception
125:23 - of those Cloud architect stuff which I
125:24 - keep in a separate section but let's go
125:26 - through it and see what is here so the
125:28 - first is cost effective you pay for what
125:30 - you consume no upfront cost on demand
125:33 - pricing so pay as you go PA YG with
125:35 - thousands of customers sharing the on uh
125:38 - sharing the cost of resources adus used
125:40 - to refer to this always as on demand
125:42 - pricing and Azure always said pay as you
125:44 - go and so it looks like adus now uses
125:47 - both on demand and page you go to
125:49 - describe them which is great um but
125:51 - there you go then we have Global so
125:53 - launch workloads anywhere in the world
125:55 - just choose a region it's secure so
125:57 - cloud provider takes care of physical
125:59 - security cloud services can be secured
126:01 - by default or you have the ability to
126:03 - configure access down to a granular
126:04 - level uh it's reliable so data backup
126:08 - Disaster Recovery data replication fault
126:10 - tolerance it's scalable increase or
126:12 - decrease resources and services based on
126:13 - demand uh elastic so automate scaling
126:16 - during spikes and drop in demand current
126:18 - so the underlying hardware and and
126:20 - managed uh software is patched upgraded
126:23 - and replaced by the cloud provider
126:24 - without interruption to you so I think
126:26 - this is one that isn't on the benefits
126:28 - of the cloud which is a really good one
126:30 - um but uh yeah that's the
126:33 - [Music]
126:36 - seven hey this is Angie Brown and we're
126:38 - taking a look at adus Global
126:40 - infrastructure so what is it well the
126:42 - adus global infrastructure is a globally
126:44 - distributed hardware and data centers
126:47 - that are physically networked together
126:48 - to act as one large resource for the end
126:50 - customers so what does that mean well if
126:52 - you look at the globe on the right hand
126:54 - side and that Globe is really cool
126:55 - because adab us used to have a website
126:57 - where you could uh see a 3D uh globe and
127:00 - see where all their resources are for
127:02 - whatever reason they took it down but I
127:03 - still have the screenshot of it but the
127:05 - idea is that um the global
127:07 - infrastructure represents all that
127:09 - hardware and the connectivity between
127:10 - that Hardware around the world so what
127:13 - kind of resources are we talking about
127:15 - we're talking about regions we're
127:17 - talking about availability zones direct
127:19 - connections uh pops also known as point
127:21 - of presence local zones wavelength zones
127:25 - uh and we should point out that Abus has
127:26 - millions of active users uh or customers
127:29 - and tens of thousands of Partners
127:30 - globally so they really are uh kind of
127:33 - everywhere um and if you're wondering
127:35 - well what are all these resources that's
127:37 - what we're going to get into next we're
127:38 - going to break down uh what all these
127:40 - particular resources are because you
127:41 - definitely need to know what they are
127:43 - but hopefully that gives you at a high
127:45 - level that adus has this thing called
127:47 - Global infrastructure
127:50 - [Music]
127:53 - okay hey this is Andrew Brown and we are
127:55 - on the marketing website for adabs under
127:57 - Global infrastructure and this is a
127:59 - great way if you want to explore more
128:01 - and make sense of that Global
128:03 - infrastructure so we scroll on down here
128:05 - we have a nice map and it's kind of
128:06 - indicating as to where those regions are
128:09 - notice that there is uh ones in red
128:11 - which are coming soon the Canada West
128:13 - they've been talking about that for I
128:14 - think a couple years now so still
128:15 - waiting for those but you know just like
128:17 - every CL provider they're always
128:19 - expanding looks like we can get a full
128:20 - list here um and it should indicate
128:23 - where uh when they launched and if
128:25 - they're launching more things so you
128:27 - know that is a nice little list uh that
128:30 - we can get access to but if we go all
128:32 - the way to the top across the top we can
128:34 - go to Regions and azs uh and this is
128:36 - where we should get better information
128:38 - this is definitely different from before
128:40 - and I don't think the top of candidate
128:41 - is supposed to look like that but uh I
128:43 - guess it's the best that they can do so
128:46 - uh what I want to point out on these
128:47 - pages is uh the terms of uh the number
128:50 - of resources so I'm just going to bump
128:52 - up the font because it's a little bit
128:53 - small even for me if we go on down below
128:56 - here you can see that it's describing um
128:59 - let's say a particular region so here in
129:01 - Canada we can see uh we have three
129:03 - availability zones and when it launched
129:06 - sometimes they have these Asters on here
129:07 - so it says located in the Montreal uh
129:10 - metropolian area so that's a good
129:12 - indicator because central Canada could
129:13 - mean Toronto could mean Winnipeg so
129:15 - that's why they put the asterisk on
129:17 - there um but just notice that what
129:20 - you'll usually see for availability
129:22 - zones you'll never see anything beyond
129:23 - six I'm not sure why but that seems to
129:25 - be the max usually when a region
129:27 - launches it should have three availab
129:29 - availability zones I think in the past
129:31 - there might have been some that did not
129:33 - have um at least three and the reason
129:36 - why it's important to have three in a
129:37 - zone is that is how we get high
129:40 - availability uh the way you do that is
129:42 - you should have um let's say we're
129:43 - talking about compute that compute
129:45 - should be um running redundantly into
129:48 - other data centers in your region to
129:50 - ensure um that you have up time in case
129:53 - the other two go out so just make note
129:55 - of that if you're coming from Azure
129:57 - Azure uh will launch things without
129:59 - having all of their uh zones uh gcp is
130:02 - really good where they'll always at
130:04 - least have three so uh each provider
130:06 - Works a little bit differently there um
130:09 - but yeah you can see here for North
130:11 - America we just scroll through here you
130:12 - can find your particular area and look
130:15 - at the map uh and wonder why it's so
130:19 - distorted but yeah hopefully that gives
130:20 - you kind of an idea there and if you
130:22 - want to explore any of these other uh
130:24 - particular offerings you absolutely can
130:25 - of course we do cover in the course so
130:27 - it's not really necessary to do that but
130:29 - I thought uh it'd be nice to show you
130:31 - this page okay
130:33 - [Music]
130:37 - ciao hey this is Andrew Brown from exam
130:39 - Pro and we are taking a look at a
130:41 - regions and regions are geographically
130:43 - distinct locations consisting of one or
130:45 - more availability Zone and so here is a
130:48 - world map showing you all the regions
130:50 - that AOS has in the world and the blue
130:52 - ones represent regions that are already
130:54 - available to you and the orange ones
130:56 - represent ones that adus is planning to
130:58 - open so adus is always expanding their
131:00 - infrastructure uh in the world so always
131:02 - expect there to be uh more upcoming ones
131:05 - every region is physically isolated from
131:07 - independent of every other region in
131:09 - terms of location Power and Water Supply
131:12 - and the most important region that you
131:13 - should give attention to Is Us East one
131:16 - uh in particular so this is Northern
131:18 - Virginia it was in's first region where
131:20 - we saw the launch of sqs and S3 uh and
131:24 - there are a lot of special use cases
131:26 - where things only work in Us East ones
131:28 - and we'll find that out here in a moment
131:30 - what I do want to show you is what it
131:31 - looks like for an architectural diagram
131:33 - when you are seeing a region so notice
131:36 - that we have this um uh little flag here
131:38 - it says Us East one US West one and
131:41 - inside of it we have an E2 instance so
131:42 - that is going to represent a region in
131:44 - our architectural diagrams uh but let's
131:46 - look at some of the facts here and under
131:48 - understand why Us East or Us East one is
131:50 - so important so each region generally
131:52 - has three availability zones and that is
131:55 - by intention and we will talk about that
131:57 - when we get to the availability Zone
131:58 - section some new users are limited to
132:00 - two or uh to two uh but generally
132:03 - there's always three okay new Services
132:05 - almost always become available first in
132:07 - Us East and specifically Us East one not
132:10 - all services are available in all
132:11 - regions all your billing information
132:13 - appears in us east1 so that's a US east1
132:15 - particular thing uh the cost of AD
132:17 - services vary per region and so if you
132:20 - were on the marketing website or uh for
132:22 - Global infrastructure you can see uh
132:24 - here in North America they will say like
132:26 - when it launched how many availability
132:28 - zones and there might be some conditions
132:29 - so you'll notice there's like Aster uh
132:31 - beside these things here or um in this
132:34 - one particular there's an aster saying
132:36 - hey there are three zones but generally
132:38 - you're limited to two Okay when you
132:40 - choose a region there are four factors
132:42 - you need to consider uh what are the
132:44 - Regulatory Compliance does this region
132:47 - meet what is the cost of this Ina
132:48 - service in this region what Ina services
132:51 - are available in this region and what is
132:52 - the dist distance or latency to my end
132:55 - users and those are those four factors
132:57 - that you should remember
132:58 - [Music]
133:02 - okay all right so we just talked about
133:04 - adus regions now let's talk about uh how
133:07 - that affects our services versus
133:09 - regional and Global Services so Regional
133:12 - services are scoped based on what is set
133:14 - in the adus Management console on the
133:16 - selected region so you have this drop
133:18 - down and that's what you'll do you'll
133:19 - say Okay I want to have resources in
133:21 - Canada or in Europe uh so this will
133:24 - determine where an ad service will be
133:26 - launched and what will be seen within
133:28 - the ad Services console you generally
133:31 - don't explicitly set the region for a
133:33 - service at the time of creation I
133:34 - explicitly mentioned this because when
133:36 - you use something like gcp or Azure when
133:39 - you create the resource that's when you
133:40 - select the region but ads is it has this
133:42 - kind of global thing which is unique to
133:44 - their platform um then there's the
133:46 - concept of Global Services so some a
133:48 - Services operate across multiple regions
133:51 - and the region will be fixed to the word
133:53 - Global and for these that's services
133:55 - like S3 cloudfront R 53 I am so the idea
133:59 - is if you were to go over to cloudfront
134:01 - and go into the cloudfront console
134:03 - you'll notice that it will just say
134:04 - Global and you can't switch out of that
134:06 - uh for these Global Services um at the
134:08 - time of creation it's a bit different so
134:10 - we were saying up here for regional ones
134:12 - that you don't select the region but
134:14 - when you are clearing Global Services if
134:16 - you're using something like I there is
134:18 - no concept of region because they're
134:19 - just globally available so you don't
134:21 - have to determine a subset of regions if
134:24 - you're using S3 bucket that has to be in
134:26 - one region so you actually do have to
134:28 - select a region at time of creation um
134:31 - and then there's something like Cloud
134:32 - distributions where you were choosing a
134:33 - group of regions so you either say all
134:35 - of the world or only North America which
134:37 - is more like geographic distribution so
134:39 - you don't say the region in particular
134:41 - but you know hopefully that gives you a
134:43 - distinction between Regional services
134:44 - and Global
134:46 - Services
134:49 - [Music]
134:51 - hey this is Andrew Brown from exam Pro
134:52 - and we are taking a look at availability
134:54 - zones so availability zones commonly
134:56 - abbreviated as AZ and I'll frequently
134:59 - use be using the term AZ is physical
135:01 - locations made up of one or more data
135:04 - centers so a data center is a secured
135:06 - building that contains hundreds or
135:08 - thousands of computers uh and this is
135:10 - one of my favorite Graphics I like to
135:12 - show of course uh you know ads would
135:14 - never have a dog um in their data center
135:17 - but I just thought that would be fun a
135:18 - region will generally contain three
135:21 - availability zones and I say generally
135:23 - because there are some cases where we
135:25 - will see uh less than three so there
135:27 - might be two um data centers within a
135:29 - region will be isolated from each other
135:31 - um so there will be in different
135:32 - buildings but they will be close enough
135:34 - to provide low latency and that is
135:36 - within the uh 10 milliseconds or less so
135:39 - it's very very low uh it's common
135:41 - practice to run workloads in at least
135:43 - three azs to ensure Services remain
135:45 - available in case one or two data
135:47 - centers fail and this is known as high
135:49 - availability and this generally is
135:51 - driven based on Regulatory Compliance so
135:53 - a lot of companies uh you know they have
135:56 - to at least be running in three azs and
135:58 - that's why iTab us tries to always have
136:00 - at least three azs within a region uh
136:02 - azs are represented by a region code
136:04 - followed by a letter so here you know
136:06 - you'd have us east1 which would be the
136:08 - region and then the a would represent
136:11 - the particular availability Zone in that
136:13 - region um so a subnet which is related
136:17 - to a a ability zones is associated with
136:19 - uh two availability zones so you never
136:21 - choose an a when launching resources you
136:24 - always choose a subnet which is then
136:26 - Associated to an AZ a lot of services um
136:30 - you know don't even require you to
136:31 - choose a subnet because they're fully
136:33 - managed by AWS but in the case of like
136:35 - virtual machines you're always choosing
136:36 - a subnet okay so here is a graphical uh
136:39 - representation or a diagram that's
136:42 - representing two availability zones so
136:45 - here we have the region Us East one and
136:47 - Us West 2 and then we have our two azs
136:49 - so here is 1 a and one b and so these
136:53 - are effectively the subnets okay and so
136:56 - within those subnets then you can see or
136:59 - availability zones you will see that we
137:01 - have uh two virtual machines okay so the
137:03 - US east1 region has six azs and I
137:06 - thought that's just kind of like a fun
137:07 - fact because it is the most out of every
137:09 - single one um I don't think any one
137:12 - comes close to us East one but of course
137:14 - it is the most popular it is the uh
137:16 - first uh um region or so it's not a
137:19 - surprise that that one has that many
137:23 - [Music]
137:26 - a okay so we just covered regions and
137:29 - availability zones but I really want to
137:30 - make it clear uh what they look like so
137:32 - I kind of have a visual representation
137:34 - so let's say we have our adus region and
137:37 - in this particular one we have Canada
137:38 - Central which in particular is Montreal
137:40 - so CA Central one uh and the idea here
137:44 - is that a region has multiple
137:46 - availability zones so here you can see
137:48 - that we have uh 1 a 1 B and 1 D for some
137:52 - reason adus decided to uh not launch 1 C
137:56 - maybe it's haunted who knows you know um
137:58 - and then within your um availability
138:01 - zones they are made up of one or more
138:03 - data center so just understand that an a
138:05 - is not a single data center but could be
138:06 - a collection of buildings and that these
138:08 - azs um are interconnected with high
138:11 - bandwidth low latency networking they're
138:13 - fully redundant dedicated to metrof
138:15 - fiber providing High throughput latency
138:18 - networking between so just very fast
138:19 - Connections in between and all traffic
138:22 - between azs is encrypted and these azs
138:24 - are within 100 km so about 60 miles uh
138:28 - of each other
138:30 - [Music]
138:33 - okay so what I want to do here is just
138:36 - show you uh how regions and availability
138:38 - zones work with some different adus
138:40 - services so you have a general idea when
138:42 - you are selecting a region or a and when
138:45 - you're not so Within when you want to
138:48 - select a region you're going to go up
138:50 - here and change it and this is going to
138:51 - apply to Regional Services a very famous
138:55 - example of a regional service would be
138:56 - ec2 so we go over to ec2 which is
138:59 - elastic uh cloud computing or compute
139:03 - whatever always forget the name of it
139:05 - and what we can do is go over to
139:06 - instances I'm going to launch an
139:08 - instance I'm not going to complete the
139:10 - process I just want to show you what
139:12 - would happen when you go select some
139:13 - things here so I'm going to go with
139:15 - Amazon LX 2 um we're going to just go to
139:18 - uh next here and so here is where we're
139:21 - going to select um our availability zone
139:24 - so up here we have North Virginia that's
139:26 - our region and when I say we're
139:27 - selecting availability Zone we're
139:29 - actually selecting the subnet so so here
139:32 - we are choosing a subnet and a subnet is
139:35 - associated to a availability Zone and
139:38 - every single um region has a default VPC
139:43 - and that VPC has uh subnets set up and
139:46 - the subnets are defaulted to each of the
139:48 - availability zones available so us east1
139:51 - has six of them so this server is going
139:53 - to launch in Us East 1B so this is a
139:57 - regional service okay uh then we have
139:59 - Global Services like S3 so we go over to
140:02 - S3 and it says it's Global right and so
140:06 - we're going to go ahead and create our
140:08 - bucket and so here we choose the region
140:12 - so we go down we're going to say the
140:13 - region we want to be in but we don't
140:15 - choose the availability Zone because
140:18 - there's nothing to um uh choose because
140:21 - adabs is going to run these in a
140:25 - multiple A's and it doesn't matter to
140:27 - you what it's doing there okay um so
140:30 - there's that and then there's something
140:32 - like cloudfront so cloudfronts a little
140:33 - bit uh different here so we go over to
140:36 - cloudfront and we create ourselves a
140:39 - distribution um and so yeah if if you
140:41 - don't have that option there because
140:42 - sometimes databus has like a splash
140:43 - screen just click on the left hand side
140:45 - then go to distributions okay okay and
140:48 - so here well they changed it again on me
140:50 - they're always changing this UI but if
140:52 - we scroll on down it should allow us to
140:56 - change um change where this is going to
140:58 - launch it's like Global stuff like that
141:01 - literally they just recently changed
141:02 - this and that's why I'm
141:04 - confused uh we'll scroll on down
141:07 - here it used to
141:10 - be maybe it's under
141:13 - Legacy
141:15 - additional customized
141:18 - oh it's here sorry okay so notice here
141:20 - the price class that says use the edge
141:22 - locations for best performance North
141:24 - America and Europe North America Europe
141:26 - Asia middle uh Middle East and Africa so
141:29 - we're not choosing a particular region
141:31 - we're picking a geographical area and so
141:34 - those are pretty much the major um uh uh
141:38 - examples of that uh then there's of
141:40 - course things like an IM am where you
141:42 - don't even say where it is so you go
141:44 - into IM am you know and if I create
141:46 - something like a group uh over here a
141:49 - user group
141:50 - whoops here I say create group you know
141:54 - I'm not saying oh this is for this
141:57 - particular region or something like that
141:59 - okay so yeah hopefully that makes
142:02 - [Music]
142:05 - sense hey this is Andrew Brown from exam
142:08 - Pro and let's take a look here at fault
142:10 - tolerance specifically for Global
142:12 - infrastructure and so before we jump
142:13 - into that let's just Define some fault
142:15 - terminology here so let's describe what
142:18 - a fault domain is so a fault domain is a
142:20 - section of a network that is vulnerable
142:22 - to damage if a critical device or system
142:25 - fails and the purpose of a fault domain
142:27 - is that if a failure occurs it will not
142:29 - Cascade outside that domain limiting the
142:31 - possible damage and so uh there's this
142:34 - very popular meme called This is fine
142:36 - where uh there's obviously a serious
142:38 - problem but uh the person's not freaking
142:40 - out and I gave it some context to say
142:42 - well the reason they're not freaking out
142:44 - because they know that is a fault domain
142:45 - and nothing outside of this room is
142:47 - going to be affected okay so you can
142:49 - have fault domains nested inside of
142:51 - other fault domains uh but generally
142:53 - they're grouped in something called
142:54 - fault level so a fault level is a
142:56 - collection of fault domains um and the
142:58 - scoping of a fault domain could be
142:59 - something like a specific specific
143:01 - servers in a rack an entire Rack in a
143:03 - data center an entire room in a data
143:06 - center the entire Data Center building
143:08 - and it's really up to the cloud service
143:09 - provider to define those boundaries of a
143:11 - domain adus abstracts it all way so you
143:13 - don't have to think about it but just to
143:14 - compare it against something else when
143:16 - you're using azure you actually Define
143:18 - your fault domain so you might say like
143:20 - okay uh make sure that this workload is
143:22 - never running on the same VM on the same
143:24 - rack for these things uh and you know
143:26 - you might like to have that level of
143:28 - control but I really like the fact that
143:29 - Abus just abstracts it away I'm not sure
143:31 - how they segment their uh their their
143:33 - fault domains but they they definitely
143:35 - are some broader ones which we'll
143:37 - describe right now so when we're looking
143:39 - at an abis region this would be
143:41 - considered a fault level and then within
143:43 - that fault level you would have your uh
143:45 - availability zones and these would be
143:47 - considered fault domains and of course
143:49 - those data centers can have uh fault
143:51 - domains within them okay like maybe you
143:53 - know they have everything in a
143:54 - particular room and that room is secure
143:56 - so like if there's a fire in that room
143:57 - it's not going to affect the other room
143:58 - things like that um so each Amazon
144:01 - region is designed to be completely
144:02 - isolated from the other Amazon region
144:05 - they uh they achieve this with the
144:07 - greatest possible fault tolerance and
144:08 - stability uh each availab availability
144:11 - zone is also isolated but the
144:13 - availability Zone in a region are
144:14 - connected through low latency links each
144:17 - availability zone is designed as an
144:19 - independent failure Zone and so here we
144:21 - have uh some kind of different language
144:23 - that adus is using um I've never
144:25 - experienced this terminology in other
144:27 - any other cloud service provider so I
144:28 - kind of feel like it's something that ad
144:30 - made up but basically a failure Zone
144:32 - they're just basically saying a fault
144:33 - domain but let's kind of expand on their
144:36 - fault uh failure Zone terminology so
144:38 - availability zones are physically
144:39 - separated within a typical Metropolitan
144:42 - region and are located in lower risk uh
144:44 - flood planes discreet uninterruptible
144:47 - power supply so UPS and an on-site
144:49 - backup uh generation facilities uh Data
144:52 - Centers located in different azs are uh
144:55 - designed to be supplied by independent
144:57 - substations to reduce the risk of an
145:00 - event on the power grid impacting more
145:02 - than one availability Zone availability
145:04 - zones are all redundantly connected to
145:06 - multiple tier one Transit providers and
145:08 - we'll talk about what those are uh in an
145:10 - upcoming slide and just one thing I want
145:13 - to note here is that when you adopt
145:15 - multi-az you get high availability so if
145:17 - an application is partitioned across A's
145:20 - companies are better isolated and
145:22 - protected from issues such as power
145:24 - outages lightning strikes tornadoes
145:26 - earthquakes and more so that's the idea
145:28 - behind you know why we want to run in
145:30 - multi-az okay because of these fault
145:33 - [Music]
145:36 - domains hey this is Andrew Brown from
145:38 - exam Pro and we're talking about the ad
145:40 - Global Network so the global Network
145:42 - represents interconnections between a
145:45 - global infrastructure and and it's
145:47 - commonly referred to as the backbone of
145:49 - AWS so is ec2 so just understand that
145:52 - that could be used in more than one way
145:54 - but think of it as a private Expressway
145:55 - where things can move fast between data
145:58 - centers and uh one thing that is
146:01 - utilized a lot to get data in and out of
146:03 - AWS very quickly is Edge locations they
146:06 - can act as on and off ramps uh to the
146:08 - AWS Global Network of course you can uh
146:10 - get to the network through pops which
146:12 - we'll talk about um you know in the
146:14 - upcoming slides here but let's just talk
146:15 - about Edge locations and what services
146:17 - use them so uh when we're talking about
146:19 - things that are getting on to the adus
146:21 - network we're looking at things like
146:22 - Abus Global accelerator adus S3 transfer
146:26 - acceleration and so uh these use agile
146:29 - locations as an on-ramp to quickly reach
146:31 - a resources in other regions by
146:33 - traversing the fast adus Global Network
146:35 - notice that the names in it say
146:37 - accelerator acceleration so the idea is
146:39 - that they are moving really fast okay on
146:42 - the other side when we talk about like
146:43 - an offramp we're looking at Amazon
146:44 - cloudfront which is a Content
146:46 - distribution Network
146:47 - this uses Edge locations to uh as an
146:49 - offramp to provide at the edge storage
146:52 - and compute near the end user uh and one
146:55 - other thing that is kind of always
146:57 - utilized in the global Network are VPC
146:58 - endpoints now these aren't using Edge
147:00 - locations but the idea here is that this
147:02 - ensures your resources stay within the
147:04 - Aus Network and do not Traverse over the
147:06 - public internet so you know if you have
147:09 - uh you know a resource running in Us
147:10 - East one and one in uh EU it would and
147:13 - they never have to go to the Internet it
147:15 - would make sense to always enforce it to
147:16 - stay within Theus Network cuz it's going
147:18 - to be a lot faster so there you
147:21 - [Music]
147:25 - go hey this is Andrew Brown from exam
147:27 - Pro and we are taking a look at point of
147:29 - presence also known as Pop and this is
147:31 - an intermediate location between an ads
147:33 - region and the end user and this
147:35 - location could be a data center or a
147:37 - collection of Hardware so for AWS a
147:40 - point of presence is a data center owned
147:41 - by AWS or trusted partner that is
147:44 - utilized by AWS Services related for
147:46 - content delivery or expediated upload so
147:49 - a pop resource could be something like
147:50 - an edge location or Regional Edge cache
147:53 - so as an example over here we see an S3
147:55 - bucket and it has to go through Regional
147:57 - Edge cache and then get to an edge
147:59 - location let's go Define what those are
148:01 - so an edge location are data centers
148:03 - that hold cach copies on the most
148:05 - popular files so web pages images and
148:08 - videos so that the delivery of the
148:10 - distance to the end users are reduced
148:12 - then you have Regional Edge locations
148:15 - and these are data centers that hold
148:16 - much larger caches of less popular files
148:18 - to reduce a full round trip and also to
148:21 - reduce the cost of transfer
148:24 - [Music]
148:27 - fees so to kind of help put pops more in
148:30 - presence just in the general sense here
148:33 - is a diagram I got from Wikipedia that
148:35 - kind of just shows a bunch of different
148:37 - networks and notice where the pop is
148:38 - it's on the edge or the intersection of
148:41 - uh two networks so here you know we have
148:44 - um you know tier three and then this
148:46 - tier two and there's this pop that is in
148:48 - between them okay so tier one networks
148:50 - is a network that can reach every other
148:52 - network on the internet without
148:53 - purchasing IP transit or paying for
148:56 - peering and so the anabis availability
148:58 - zones or azs are all redundantly
149:00 - connected to multiple tier one Transit
149:02 - providers
149:03 - [Music]
149:07 - okay all right so let's take a look at
149:09 - somea services that are utilizing pops
149:12 - or Edge locations for Content delivery
149:14 - or expediated upload so Amazon on
149:16 - cloudfront is a Content delivery network
149:18 - service and the idea here is you point
149:20 - your website to cloudfront so that it
149:22 - will route requests to the nearest Edge
149:23 - location cache it's going to allow you
149:25 - to choose an origin so that could be a
149:27 - web server or storage that'll be the
149:29 - source of the cache and cach is the
149:31 - content of what origin would return to
149:33 - various Edge locations around the world
149:35 - then you have Amazon S3 transfer
149:37 - acceleration this allows you to generate
149:38 - a special URL that can be used by the
149:41 - end users to upload files to a nearby
149:43 - Edge location once a file is uploaded to
149:45 - an edge location it can move much faster
149:47 - within the adus network to reach S3 then
149:51 - at the end here you have adus Global
149:52 - accelerator you can find the optimal
149:54 - path from the end user to your web
149:56 - servers so Global accelerators are
149:58 - deployed within Edge location so you
150:00 - send user traffic to an edge location
150:02 - instead of directly to your web
150:03 - application this service is really
150:05 - really great for if let's say you are
150:07 - running a web server in Us East one and
150:10 - you just don't have the time uh to set
150:12 - up infrastructure in other regions you
150:14 - turn this on and you basically get a
150:16 - booster
150:17 - [Music]
150:20 - okay hey this is Andrew Brown from exam
150:23 - Pro and let's take a look at it was
150:24 - direct connect so this is a private or
150:26 - dedicated connection between your data
150:28 - center office collocation and AWS and so
150:31 - the idea here is imagine if you had a
150:33 - fiber optic cable running from your uh
150:36 - data center all the way to your ads so
150:38 - that it feels like uh when you're using
150:40 - your stuff on your data center like your
150:42 - local virtual machines that uh there's
150:44 - like next tendo latency okay so Direct
150:46 - Connect has two very fast network
150:48 - connection options we have the lower
150:50 - bandwidth which is at 50 to 500
150:53 - megabytes per second and then you have
150:54 - the higher bandwidth which is 1 GB to 10
150:58 - GB per second so using Direct Connect
151:01 - helps reduce Network cost increase
151:02 - bandwidth throughput so great for hight
151:04 - trffic networks provides a more
151:06 - consistent Network experience than a
151:08 - typical internet based connection so
151:10 - reliable and secure um I do want to
151:12 - point out the term collocation if you
151:13 - never heard of that before a collocation
151:15 - or a carrier hotel is a data center
151:18 - where equipment space and bandwidth are
151:20 - available for rental uh to retail
151:22 - customers and I do want to also point
151:24 - out that even though it says private up
151:26 - here and this is the language that AWS
151:27 - used I usually just say dedicated but
151:30 - the connection is private but that
151:31 - doesn't necessarily mean it's secure
151:33 - okay so uh we'll talk about that when we
151:35 - reach ads vpns and how we can use that
151:37 - with direct connect to make sure our
151:39 - connections are secure
151:40 - [Music]
151:44 - okay all right so let's take a look at
151:46 - what a direct connect location is so a
151:48 - direct connect location are trusted
151:50 - partner data centers that you can
151:52 - establish a dedicated highspeed low
151:54 - latency connection from your on premise
151:57 - to AWS so an example of a partner data
151:59 - center would be one like here in Toronto
152:01 - the Allied data center so you can tell
152:03 - that's right down in uh the Toronto
152:05 - Center and so you would use this uh uh
152:08 - as part of direct connect service to
152:10 - order and establish a connection
152:15 - okay
152:16 - [Music]
152:17 - hey this is Andrew Brown from exam Pro
152:19 - and we are taking a look at local zones
152:21 - which are Data Centers located very
152:22 - close to densely populated areas to
152:24 - provide single-digit millisecond low
152:26 - latency performance so think like 7even
152:28 - milliseconds for that area so here is a
152:31 - map of uh local zones that exist and
152:33 - ones that are coming out I believe the
152:35 - orange ones are probably ones that are
152:36 - on their way and so to use a local Zone
152:38 - you do need to opt in so you got to go
152:39 - talk to AWS probably open a support
152:41 - ticket to get access to it the first one
152:43 - to ever be launched was uh the LA one uh
152:46 - and so um you know when you want to see
152:49 - it it looks just like a an availability
152:52 - Zone it's going to show up under
152:53 - whatever region that is because these
152:54 - are always tied to existing regions so
152:56 - the la1 is tied to us West uh region and
153:00 - the a would look like us West 2 hyphen
153:04 - LAX hyphen 1 a okay so only specific AA
153:08 - Services have been made available so
153:09 - there's particular ec2 types EBS Amazon
153:13 - FSX application load balancer Amon VPC
153:17 - they probably have extended it to more
153:19 - services do you need to know that for
153:21 - the exam no but you know the point is is
153:23 - that there's a limited subset of things
153:25 - that are available the purpose of local
153:27 - zone is to support highly demanding
153:29 - applications sensitive delcy so media
153:31 - and entertainment electronic design and
153:33 - automation adte machine learning so it
153:36 - kind of makes sense like you look at La
153:37 - they're in the media entertainment and
153:39 - so they're dealing with lots of media
153:41 - content so it has to be really low for
153:43 - them
153:45 - okay
153:48 - hey this is Andrew Brown from exam Pro
153:49 - and we are taking a look at Abus
153:51 - wavelength zones and these allow for
153:53 - Edge Computing on the 5G networks and
153:56 - applications will have ultra low latency
153:58 - being as close as possible to the users
154:00 - so Abus has partnered with various
154:02 - telecom companies to utilize their 5G
154:04 - networks so we're looking at Verizon
154:06 - vone kddi SK Telecom and so the idea
154:10 - here is that you will create a subnet
154:12 - tied to a wavelength Zone and then and
154:15 - just think of it as an availability Zone
154:16 - but it's a wavelength Zone and then you
154:18 - can launch your VMS to the edge of the
154:20 - targeted 5G Network so that's the
154:22 - network you're using uh AWS to uh deploy
154:26 - an ec2 instance and then when users uh
154:29 - connect to you know those radio tower
154:31 - those um the cell towers they're going
154:33 - to be routed to um you know nearby
154:35 - hardware that is running those virtual
154:37 - machines okay and that's all it is it's
154:39 - just it's just uh ec2 instances um but
154:42 - you know the advantage here is that it's
154:44 - like super super low Lane SE
154:47 - [Music]
154:50 - okay hey this is Andrew Brown from exam
154:53 - Pro and we are taking a look at data
154:54 - residency so this is the physical or
154:57 - geographical location of where an
154:59 - organization or Cloud resources reside
155:01 - and then you have the concept of comp uh
155:03 - compliance boundaries so a Regulatory
155:05 - Compliance so legal requirement by
155:07 - government or organization that
155:09 - describes where data and Cloud resources
155:11 - are allowed to reside and then you have
155:13 - the idea of data sovereignty so data
155:15 - sovereignty is the jurisdictional
155:17 - control or legal Authority that can be
155:19 - asserted over data because its physical
155:21 - location is within a uh jurisdictional
155:24 - boundary and so the reason we care about
155:26 - this stuff is that if we want to work
155:27 - with the Canadian government or the US
155:29 - government and they're like hey you got
155:31 - to make sure that you know if you want
155:33 - to work with us all the data has to stay
155:34 - in Canada and you need to give them that
155:36 - guarantee so data residency is not a
155:38 - guarantee it just says where your data
155:40 - is right and compliance boundaries are
155:43 - those U controls that are in place to
155:45 - say okay this this is going to make sure
155:46 - that data stays where we want to be and
155:48 - data of sovereignty is just like the
155:50 - idea of the scope of the the legal the
155:52 - legal stuff that ties in with compliance
155:55 - boundaries so how do we do that on AWS
155:58 - well there's a few different ways but um
155:59 - let's just take a look at some ways that
156:01 - we can meet those compliance boundaries
156:03 - one uh which is very expensive but also
156:05 - very cool is adus outposts so this is a
156:08 - physical rack of servers that you can
156:10 - put in your data center and you'll know
156:12 - exactly where the data resides because
156:14 - you know it's physical if it's in your
156:16 - data center and you're in Canada that's
156:17 - where it's going to be okay uh and I
156:20 - believe that you know there is only a
156:21 - subset of adus services that are
156:23 - available here but you know that is one
156:25 - option to you another is using like um
156:28 - services for governance so like one
156:30 - could be adus config this is a policy as
156:32 - a code service so you can create rules
156:34 - to continuously check adus resource
156:36 - configuration so if they deviate from
156:38 - your expectations you're alerted Oris
156:40 - config can in some cases Auto remediate
156:42 - so if you were expecting you know um you
156:45 - know you had an account and you're
156:47 - saying this account is only to be used
156:48 - for candid resources and somebody
156:50 - launches let's say something in another
156:52 - region then you could get an alert or
156:55 - tell it was config to go delete that
156:57 - resource okay now if you want to prevent
156:59 - people from doing it uh Al together
157:01 - that's where IM am policies come into
157:03 - play so these can be written explicitly
157:04 - to deny access to specific adus regions
157:07 - and you know this is great if you're
157:09 - applying it to users or roles but if you
157:11 - wanted to have it organizational wide
157:13 - across all of your um your a accounts
157:16 - you can use something called a service
157:17 - control policy that is just an IM am
157:19 - policy that is used within it
157:21 - organizations that makes it
157:23 - organizational wide
157:25 - [Music]
157:28 - okay hey this is Andrew Brown from exam
157:31 - Pro and we are looking at 8s for
157:32 - government so to answer that we first
157:34 - have to understand what is public sector
157:37 - so public sector includes public goods
157:39 - and government services such as military
157:41 - law enforcement infrastructure public
157:44 - transit public education Healthcare and
157:46 - the government itself so AOS can be
157:48 - utilized by the public sector or
157:50 - organizations developing Cloud workloads
157:52 - for the public sector and a achiev this
157:54 - by meeting Regulatory Compliance
157:56 - programs along with specific governance
157:58 - and security controls so this could be
158:01 - meeting the requirements with HIPPA
158:03 - fedramp um cjis and fips okay so abis
158:07 - has a special regions or special regions
158:09 - for us regulation called gov Cloud which
158:12 - we'll talk about next
158:14 - okay
158:17 - [Music]
158:18 - hey this is Andrew Brown from exam Pro
158:20 - and we are taking a look at govcloud and
158:21 - to understand what govcloud is we need
158:23 - to know what fedramp is so fedramp
158:25 - stands for federal risk and
158:26 - authorization Management program it's a
158:28 - US government-wide program that provides
158:30 - a standardized approach to security
158:32 - assessment authorization continuous
158:34 - monitoring for cloud products and
158:35 - services so now that we know what fed
158:37 - ramp is what is gocloud well uh and
158:41 - again it's not particular to AWS because
158:43 - Azure has gocloud as well but a cloud
158:45 - service provider like ad or Azure J will
158:48 - offer an isolated region to run fed ramp
158:51 - workloads and so in ads it's called
158:53 - govcloud and these are specialized
158:56 - regions that allow customers to host
158:58 - sensitive controlled unclassified
158:59 - information and other types of regulated
159:01 - workloads so govcloud regions are only
159:03 - operated by you uh by US citizens on us
159:06 - soil they are only accessible to us
159:08 - entries and root account holders who
159:10 - pass a screening process customers can
159:13 - architect secure Cloud solutions that
159:15 - comply with fed ramp uh do the doj's uh
159:19 - criminal justice Information Systems uh
159:22 - security policy the US International
159:25 - traffic and arms regulation uh uh export
159:28 - Administration regulations the
159:30 - Department of Defense cloud computing
159:32 - security requirements and guides so if
159:34 - you want to work with the US government
159:36 - you want to uh engineer and use govcloud
159:40 - [Music]
159:43 - okay hey this is Andrew from exam Pro
159:46 - and we're taking a look at uh running
159:48 - adus in China so adus China is the adus
159:51 - cloud offering in mainland China adus
159:53 - China is completely isolate
159:55 - intentionally from adus Global to meet
159:57 - Regulatory Compliance for mainland China
159:59 - so that means that if you make a
160:00 - workload on the adus global uh you can't
160:03 - uh interact with it within the ads China
160:05 - One okay it's basically treated like a a
160:08 - completely separate service like ads has
160:10 - its own Chinese version uh and so ad
160:13 - China is on its own domain at Amazon
160:15 - ads. CN and for everybody else that's
160:18 - what's considered AB Global so when I'm
160:20 - using adabs from Canada or use it from
160:23 - the US or from India or from Europe or
160:26 - wherever that is the adus global okay so
160:29 - in order to operate in adus China
160:31 - regions you need to have a Chinese
160:33 - business license so ICP license not all
160:36 - services are available in China so uh
160:39 - you will not have the use of Route 53 uh
160:42 - and you might say well why not just run
160:44 - in Singapore ored was Global and you
160:46 - could do that but the advantage of
160:48 - running in mainland China means that you
160:50 - would not have to Traverse the great
160:52 - firewall okay so all your traffic is
160:55 - already within China so you don't have
160:56 - to uh deal with that Abus has two
160:59 - regions in mainland China so uh there's
161:01 - this one here which is the northwest
161:03 - region operated by NS WCF and then you
161:07 - have the one in Beijing North one
161:08 - operated by uh sinnet so you know itus
161:11 - just could not meet the the compliance
161:13 - requirement so they had to partner with
161:15 - local providers or data centers and so
161:18 - that is how that works
161:20 - [Music]
161:23 - okay all right so I want to show you how
161:25 - you get over to the um Chinese adus
161:29 - Management console so this one is adab.
161:31 - amazon.com that is the global one for
161:34 - everyone outside of mainland China but
161:36 - if you want to run resources uh on data
161:39 - centers within mainland China this is at
161:42 - amazon.cn and so it looks very similar
161:44 - if you go to create a free account
161:46 - you're going to fill in this stuff but
161:48 - uh notice that you need to have your
161:50 - business registration certificate uh and
161:52 - additional information in order to run
161:54 - these data centers down below that AWS
161:56 - has partnered with also notice that the
161:58 - logo doesn't say AWS in it and there's a
162:01 - good reason for that if I type in adus
162:03 - trademark
162:04 - China uh adus is actually banned from
162:06 - using the adus logo in China uh for
162:09 - whatever reason it's a weird reason if
162:10 - you ever want to read about it but
162:12 - that's why you don't see AWS here all
162:14 - right
162:16 - um so yeah there you
162:18 - [Music]
162:22 - go hey this is Andrew Brown from exam
162:24 - Pro and we are looking at sustainability
162:26 - for adus Global infrastructure and
162:28 - before we talk about that let's talk
162:29 - about the climate pledge so Amazon
162:31 - co-founded the climate pledge to achieve
162:33 - Net Zero carbon emissions by 2040 across
162:36 - all of Amazon's businesses which
162:38 - includes AWS if youall want to find out
162:40 - more information go to to
162:42 - sustainability. amazon.com there's a a
162:45 - lot of great information there and
162:46 - you'll learn exactly how uh ads is
162:49 - achieving this in particular like their
162:50 - data centers it's very interesting okay
162:53 - so adus Cloud sustainab goals are
162:55 - composed of three parts the first is
162:56 - renewable energy so adus is working
162:58 - towards having their adus Global
163:00 - infrastructure powered by 100% renewable
163:03 - energy by
163:04 - 2025 and AAS purchases and retires
163:07 - environmental attributes to cover the
163:09 - nonrenewable energy for AIS Global
163:11 - infrastructure so they would purchase
163:13 - things like renewable energy credits
163:14 - also known as Rec's guarantees of origin
163:17 - so Go's the second Point here is cloud
163:20 - efficiency so adus infrastructure is 3.6
163:23 - times more energy efficient than the
163:24 - medium of us Enterprises data centers
163:27 - surveyed so that's going to really rely
163:29 - on that survey surveys are not always
163:30 - that great so you know take that with a
163:32 - grain of salt okay then we have water uh
163:35 - stewardship so uh direct evaporative
163:38 - technology to cool our data centers use
163:41 - of non portable uh water for cooling
163:43 - purposes so they're recycling water
163:45 - on-site water treatment allows us to
163:47 - remove us them to remove scale forming
163:50 - minerals and reuse Waters uh for more
163:53 - Cycles water efficiency metrics to
163:55 - determine and monitor optimal water use
163:57 - for each aabus region and you'll find
164:00 - that water plays a large part on uh
164:03 - making these um uh these data centers
164:06 - very efficient
164:08 - [Music]
164:11 - okay so I just wanted to show you where
164:13 - you get to that sustainability
164:15 - information so I just went to itus
164:16 - Global infrastructure you click
164:18 - sustainability and that's going to bring
164:20 - us over to whoops I have my Twitter open
164:23 - there to the sustainability in the cloud
164:24 - so if you want to uh read a bunch of
164:27 - stuff here about things that are going
164:28 - on that itus is up to see uh how they
164:31 - are progressing with renewable energy um
164:34 - there's Cloud efficiency up here so you
164:36 - know how are they being efficient it's
164:38 - worth the read to really understand that
164:40 - there's a lot of water involved like
164:42 - reducing water in data centers I thought
164:43 - that was really interesting um I mean
164:46 - they have theis podcast but I don't
164:48 - think there's really much to it a
164:50 - bi-weekly podcast of bite side stories
164:52 - about how Tech makes the world better
164:55 - that's not necessarily A sustainability
164:57 - podcast it's just the invis podcast in
164:59 - general there's a download Center um
165:02 - Amazon's 2020 sustainability reports so
165:04 - I guess you can download the reports to
165:06 - see what is going on there so we could
165:08 - download the progress here and see what
165:10 - they've been up
165:12 - to okay so there's a bunch of numbers
165:14 - things like that
165:15 - okay very short reports but hey at least
165:17 - you can download them okay so just in
165:19 - case you're uh very interested in
165:21 - sustainability all
165:23 - [Music]
165:26 - right hey this is Andrew Brown from exam
165:29 - Pro and we are taking a look at Abus
165:30 - ground station so this is a fully
165:32 - managed service that lets you control
165:34 - satellite Communications process data
165:37 - and scale your operations without having
165:38 - to worry about building or managing your
165:40 - own ground station infrastructure and so
165:43 - when we're talking about ground station
165:45 - a really good way to cement what the
165:47 - service is is just think of a big anten
165:49 - 10 ey dish that's pointing into the sky
165:51 - trying to communicate with satellites
165:53 - because that's essentially what the
165:54 - service is doing so the use cases here
165:56 - could be for weather forecasting surface
165:58 - Imaging communications video broadcasts
166:02 - and to use ground station the idea is
166:03 - that you would schedule a contact so
166:05 - that's where you're selecting a
166:06 - satellite a start and end time and the
166:08 - ground location and then you use an a
166:11 - ground station ec2 Ami and Amazon
166:13 - machine image to launch e two instances
166:15 - that will Uplink and downlink uh data
166:18 - during the contact or receive downlink
166:20 - data in an Amazon S3 bucket a use case
166:24 - could be something like you are a
166:25 - company you've reached an agreement with
166:27 - a satellite image provider to use their
166:29 - satellites to take photos for a specific
166:31 - region or time or whatever and so the
166:33 - idea is that you are using adus ground
166:35 - station to communicate uh to that
166:37 - company satellite and download that s uh
166:40 - that image data to your S3 bucket
166:44 - okay
166:46 - [Music]
166:50 - hey this is Andrew Brown and we are
166:51 - looking at Aus outposts and this is a
166:53 - fully managed service that offers the
166:55 - same aess infrastructure Services apis
166:57 - tools to virtually any data center
166:59 - cocation space or on premise facility
167:01 - for a truly consistent hybrid experience
167:04 - and just to kind of summarize it it's a
167:05 - rack of servers running adaba stuff on
167:08 - your physical location okay so before we
167:10 - jump into the service or technology
167:13 - itself uh let's talk about what is a
167:15 - rack server or just a rack so it's a
167:17 - frame designed to hold and organize it
167:20 - equipment so here's an example of a 42 U
167:23 - rack uh and there's the concept of rack
167:26 - heights so the U stands for rack units
167:28 - or U spaces uh with it equal to 1.75 in
167:34 - and the industry standard rack is a 48 U
167:37 - um so that is a 7 foot rack so a full
167:42 - size rack cage is commonly the 4 to High
167:46 - okay and uh in it you might have
167:48 - equipment that is of different sizes so
167:49 - there could be one u 2 U 3 U or 4 U high
167:53 - so here's an example of you know of an
167:56 - interior of a rack and notice that like
167:58 - one u 2 U 4 U they're all a little bit
168:00 - shaped differently uh but they give you
168:01 - kind of an idea of um you know what
168:04 - those are so it Outpost comes in three
168:07 - form factors the four2 U the one U and
168:10 - the 2 U so the the first one here the 42
168:13 - U this is basic basically a full rack of
168:16 - servers provided by adus so you're not
168:17 - just getting the frame it actually comes
168:19 - with you know servers uh and so adus
168:22 - delivers it to your Preferred Physical
168:24 - site fully assembled and ready to be
168:25 - rolled into the final position it is
168:27 - installed by adus and the rack needs to
168:29 - be simply plugged in to the power and
168:31 - network and there's a lot of details
168:33 - about um the specs on this on the adus
168:35 - website so you know I'm not going to go
168:37 - through them all here um then there are
168:39 - servers that you can just Place into
168:40 - your existing racks so we have the oneu
168:43 - so this is suitable for 19 in wide 24 in
168:46 - deep cabinets it's using Idis uh
168:48 - Gravitron 2 um CPUs and you can have up
168:52 - to 64 uh virtual CPUs we have 128 gabt
168:57 - uh 4 terabytes of local
168:59 - NVM storage um and then you have the U
169:03 - or sorry the 2 U so suitable for 19in
169:06 - wide 36 in deep Intel processors up to
169:09 - 128 virtual CPUs 256 GB of memory 8 tab
169:14 - of local nvme storage so there you
169:18 - [Music]
169:21 - go let's take a look at Cloud
169:24 - architecture terminologies before we do
169:26 - let's talk about some of the roles that
169:27 - are around uh doing Cloud architecture
169:29 - so the first is Solutions architect this
169:31 - is a role in a technical organization
169:34 - that Architects a technical solution
169:36 - using multiple systems via researching
169:38 - documentation and experimentation and
169:41 - then you have the cloud architect this
169:42 - is a Solutions architect that is focused
169:44 - solely on architecting Technical
169:46 - Solutions using cloud services
169:48 - understand that in the uh actual
169:50 - Marketplace a lot of times Solutions
169:51 - architect is used to describe both a
169:53 - cloud architect and a Solutions
169:55 - architect and you know these are going
169:58 - to highly vary based on your locality
170:00 - and how companies want to use these
170:01 - terms but this is just me broadly
170:03 - defining them here so just don't take
170:04 - them as a perfect word in terms of what
170:07 - they're representing so a cloud
170:09 - architect needs to understand the
170:10 - following terms and factors uh and
170:12 - Factor them into their designed
170:14 - architect based on the business
170:15 - requirements so we have the idea of
170:17 - availability your ability to ensure
170:19 - service remains available scalability
170:21 - your ability to grow rapidly or
170:22 - unimpeded elasticity your ability to
170:24 - shrink and grow to meet the demand fault
170:26 - tolerance your ability to prevent a
170:28 - failure Disaster Recovery your ability
170:29 - to recover from a failure and there are
170:32 - a couple other things that uh that
170:34 - should be considered they're not
170:35 - terminologies but they're definitely
170:37 - important to a Solutions architect or
170:39 - Cloud architect and uh these are things
170:42 - you always need to consider uh as as
170:44 - well and this is just me talking to my
170:46 - Solutions architect friends where
170:47 - they'll always ask me these two
170:49 - questions after presentation they'll say
170:51 - how secure is the solution and how much
170:53 - is this going to cost all right and so
170:56 - for the terminologies up here we're
170:58 - going to Define these right away and
171:00 - we're going to figure these out
171:01 - throughout the course we have two giant
171:03 - sections just on cost and security alone
171:05 - uh so there we
171:06 - [Music]
171:09 - go the first term we're looking at is
171:12 - high availability and this is your
171:13 - ability for your service to remain
171:15 - available by ensuring there is no single
171:17 - point of failure and or you ensure a
171:20 - certain level of performance so the way
171:22 - we're going to do that on ews is you'd
171:24 - want to run your workload across
171:26 - multiple availability zones to ensure
171:28 - that if one or two availability zones
171:30 - became unavailable your servers or
171:32 - applications remain available because
171:34 - those other um those other servers are
171:36 - going to be there and the way we would
171:38 - accomplish that is via elastic load
171:39 - balancer so a load balancer allows you
171:41 - to evenly distribute traffic to multiple
171:43 - servers in one or more data center if a
171:46 - data center or server becomes
171:47 - unavailable or unhealthy the load
171:49 - bouncer will route the traffic to only
171:51 - the available data centers within the
171:53 - server and understand that just because
171:55 - you have additional servers doesn't mean
171:57 - that you are uh you're available you
171:59 - have to you might need to meet a
172:00 - particular threshold of availability so
172:02 - you might need to have at least two
172:04 - servers always running to meet the
172:05 - demand so it's based on the the demand
172:07 - of traffic
172:09 - [Music]
172:12 - okay let's take a look here at high
172:14 - scalability so this is your ability to
172:16 - increase your capacity based on the
172:18 - increasing demand of traffic memory and
172:21 - computing power and we have the terms
172:23 - vertical scaling so scaling up um this
172:26 - is where you upgrade to a bigger server
172:28 - and then there's horizontal scaling
172:29 - scaling out this is where you add more
172:31 - servers of the same size and the great
172:33 - thing about scaling out or adding
172:35 - additional servers is that you're also
172:36 - going to get um High availability so if
172:38 - you do need two servers it's always
172:40 - better to you know add an additional
172:42 - server as opposed to having a larger
172:43 - server but it's going to be very
172:45 - dependent on a lot of factors
172:48 - [Music]
172:51 - okay so scalability and elasticity seem
172:54 - very similar but there is a crucial
172:56 - difference and this is your ability to
172:58 - automatically increase or decrease Your
173:00 - Capacity based on the current demand of
173:02 - traffic memory and computing power again
173:04 - it's the it's the fact that it happens
173:06 - automatically and you can go both ways
173:08 - increase or decrease so for horizontal
173:10 - scaling we have the concept of scaling
173:12 - out so add more servers of the same size
173:15 - and then scaling in removing
173:16 - underutilized servers of the same size
173:20 - and vertical scaling is generally hard
173:21 - for traditional architectures so you'll
173:23 - usually only see horizontal scaling
173:25 - described with elasticity um and the way
173:28 - we would accomplish uh being highly
173:30 - elastic is using autoscaling groups asgs
173:33 - and this is aabus feature that will
173:35 - automatically add or remove servers
173:36 - based on scaling rules you define based
173:39 - on those metrics
173:43 - okay
173:45 - let's talk about being highly fault
173:47 - tolerant so this is your ability for
173:48 - your service to ensure there is no
173:50 - single point of failure preventing the
173:52 - chance of failure and the way we could
173:54 - do that is with fail overs so this is
173:56 - when you have a plan to shift traffic to
173:58 - a redundant system in case the primary
174:00 - system fails a very common example is
174:03 - having a copy or secondary uh uh uh of
174:07 - your database where all ongoing changes
174:09 - are synced the secondary system is not
174:11 - in use until a fail over occurs and it
174:13 - becomes the primary database so when
174:16 - we're talking about databases on ABS
174:18 - this is the concept of RDS multi-az so
174:21 - this is when you run a duplicate standby
174:23 - database in another availability Zone in
174:25 - the case your primary database
174:28 - [Music]
174:31 - fails and last here is high durability
174:34 - so this is your ability to recover from
174:35 - a disaster and to prevent the loss of
174:37 - data so solutions that recover a
174:39 - disaster uh from a disaster is known as
174:41 - disaster recovery so do you have a
174:43 - backup how fast can you restore the
174:45 - backup does your backup still work how
174:46 - do you ensure current live data is not
174:48 - corrupt and so maybe a solution ads
174:50 - would be using Cloud endurer which is a
174:52 - disaster recovery uh service which
174:54 - continuously replicates your machines in
174:56 - a lowcost staging area in your target AB
174:58 - account and preferred region enabling
175:00 - fast and reliable recovery in the case
175:01 - of an IT data center fails
175:05 - [Music]
175:08 - okay so to understand Disaster Recovery
175:11 - we need to know more about uh things
175:14 - around it like business continuity plans
175:17 - BCPS and RTO and rpos so uh a BCP is a
175:22 - document that outlines how a business
175:23 - will continue operating during an
175:24 - unplanned disruption in services so it's
175:27 - basically the plan that you're going to
175:28 - execute uh if that happens and so here
175:32 - we have a disaster and you can see that
175:34 - there's a chance of data loss and
175:35 - downtime and these two um uh factors as
175:39 - RPO and RTO are going to define the
175:41 - length of these durations so recovery
175:43 - Point objective is the maximum
175:45 - acceptable amount of data loss after an
175:47 - unplanned data loss incident Express
175:49 - this amount of time so how much data are
175:50 - you willing to lose and then recovery
175:53 - time objective so the maximum amount of
175:55 - downtime your business can tolerate
175:57 - without inuring a significant financial
175:59 - loss so how much time you're willing to
176:01 - go down okay so those are the two there
176:04 - and now let's go take a look at the
176:06 - disaster recovery options that we can
176:07 - use to define in our our
176:13 - BCP
176:15 - so now let's take a look at our disaster
176:17 - recovery options uh and based on what
176:19 - you choose they're going to be a trade
176:20 - of cost versus time to recover based on
176:22 - the rpos your RTO of course and so
176:25 - sometimes this is rep represented
176:27 - vertically like a a thermostat or you
176:29 - can do it horizontally here um both are
176:32 - valid ways of displaying this
176:33 - information but I just have it
176:34 - horizontally here today and so we have
176:37 - low or high or you could say um even
176:40 - though I don't have it written here this
176:41 - could be cold or this could be hot okay
176:45 - so um on the left hand side we got
176:47 - backup and restore pilot light warm
176:49 - standby multiactive sight notice we're
176:51 - using the like the words like pilot
176:53 - light warm things that are relating to
176:55 - temperature so again cold and hot all
176:58 - right so let's just walk through what
177:00 - each of these things conceptually do uh
177:03 - in terms of architecture so when you're
177:05 - doing a backup and restore you're back
177:07 - you basically back up your data and uh
177:10 - at the time of Disaster Recovery you're
177:11 - just going to restore it to New
177:12 - infrastructure uh for a pilot light the
177:14 - data is replicated to another region
177:16 - with the minimal Services running to
177:18 - keep on replicating that data and so you
177:20 - might have some core Services running a
177:22 - warm standby is a scale down copy of
177:25 - your infrastructure so you basically
177:26 - have everything that you would
177:27 - absolutely need to run an application
177:30 - but the idea is it's not at scale and so
177:32 - at any time when there's an incident
177:33 - you're going to scale up to the capacity
177:35 - that you need and then you have multi
177:37 - sight active active where you you have a
177:40 - scaled up copy of your infrastructure in
177:41 - another region so basically everything
177:43 - you have identically in another region
177:46 - and so in terms of the rpos and the RTO
177:48 - for back and restore you're looking at
177:49 - hours uh with the pilot light you're
177:51 - looking at 10 minutes with a warm
177:53 - standby you're looking at minutes and
177:55 - multi sight uh active active you're
177:57 - looking at uh real time so you know
177:59 - hopefully that gives you an idea of you
178:01 - know the difference in terms of scale
178:03 - but let's just look at more detail so
178:04 - for a backup and restore this is for low
178:06 - priority use cases restore data after
178:09 - event deploy resources after an event
178:11 - and it's very cost effective uh for
178:14 - light this is where you have less
178:16 - stringent RTO and rpos so you're going
178:18 - to be just running your core Services uh
178:20 - you're going to start and scale
178:21 - resources after the event and this is a
178:23 - little bit more expensive this is uh
178:26 - very good for warm standby is good for
178:28 - business critical services so you scale
178:30 - resources after the event uh and it's uh
178:33 - almost very it's very it's costly but
178:35 - it's not as expensive as a multi-site
178:37 - active active so you get zero downtime
178:40 - near zero loss uh you have it's great
178:43 - for mission critical services and it's
178:45 - just as expensive as your original
178:47 - infrastructure so you're basically
178:48 - doubling the cost there
178:50 - [Music]
178:54 - okay so we already defined RTO but let's
178:57 - redefine it again based on what adus
178:59 - describes in their white paper and just
179:02 - look at how it Maps against um the
179:04 - disaster recovery option so re recovery
179:06 - time objective is the maximum acceptable
179:08 - delay between the interruption of
179:10 - service and restoration of service this
179:12 - objective determines the what is
179:14 - considered an acceptable time window
179:16 - when service is unavailable and is
179:17 - defined by the organization and so this
179:19 - is the diagram found in the white paper
179:21 - and so on the left hand side we have
179:23 - cost and complexity here and then
179:26 - lengths of serice interruption and what
179:28 - you can see here is that the cost and
179:30 - complexity for a multi-site active
179:32 - active is very high but the length of
179:34 - service Interruption is zero and then as
179:37 - we go down we have warm standby so it's
179:40 - significantly like at least half uh the
179:42 - complexity of that one
179:44 - then we have our pilot light down here
179:46 - and backup and restore but notice backup
179:48 - restore takes the longest amount of time
179:51 - and notice here we have a recovery time
179:53 - objective so in your BCP you kind of
179:54 - Define where that is based on the cost
179:56 - of business impact so you might have to
179:58 - calculate that saying okay what is our
180:00 - cost over time based on the length of
180:01 - service Interruption where do we want
180:03 - our RTO to be what is the acceptable
180:06 - recovery cost and this is where you're
180:08 - going to decide what you want to do so
180:10 - here we have pilot light and backup and
180:12 - restore and so this company
180:14 - you has to decide whether they want to
180:16 - do a pilot light or they're going to do
180:17 - a backup restore but it sounds like this
180:19 - is where they're going to be which is at
180:20 - the pilot uh light for what is
180:23 - acceptable in their business use case
180:25 - [Music]
180:29 - okay let's do the same for RPO so
180:31 - recovery Point objective is the maximum
180:33 - acceptable amount of time since the last
180:35 - data recovery point the objective
180:36 - determines what is considered an
180:38 - acceptable loss of data between the last
180:40 - recovery point and the interruption of
180:41 - service and it's defined by the
180:42 - organization again we pulled this from
180:44 - the a white paper for disaster recovery
180:47 - and uh we have cost and complexity but
180:50 - this time it's replaced with data loss
180:52 - before service Interruption so uh for
180:56 - multisite again it's going to be very
180:58 - expensive and high up here as you
180:59 - noticed it's not like a perfect um uh
181:03 - curve it's just it's a bit different in
181:04 - terms of what it looks like so here we
181:06 - have warm St standby pilot light um and
181:09 - so you'll see that the data loss is um
181:12 - not a big deal but for back up from
181:14 - store it really juts out there so you
181:16 - can see that you can get pretty good
181:18 - results just with the pilot light and
181:19 - the cost and complexity is very low
181:21 - again we have to look at our cost and
181:23 - business impact so we got to follow that
181:25 - line and we need to see where our
181:27 - acceptable uh recovery cost is and so uh
181:31 - you're going to notice that uh we have a
181:33 - bit of an intersection here okay and so
181:36 - we need to determine you know like are
181:38 - we going to be doing a warm standby
181:40 - looks like we have the cost to do it um
181:43 - uh but you know it just really depends
181:44 - you know do we want to be down here or
181:46 - down there okay so hopefully that helps
181:48 - and visualize that information for
181:50 - [Music]
181:54 - you hey this is Andrew Brown from exam
181:56 - Pro and what I want to show you here is
181:58 - a real world architectural diagram I
181:59 - created this a while ago this is a
182:01 - previous version of the um exam Pro or
182:03 - technically teacher seat platform uh
182:05 - that powers The Learning Experience uh
182:07 - for by class certifications and so I'm
182:09 - hoping that by giving you some exposure
182:11 - you'll absorb some information here uh
182:13 - and that will carry through to really
182:15 - help you cement what these services do
182:16 - and how they work together now you might
182:18 - be asking how did I make this well I'm
182:20 - in Adobe XD it's by Photoshop or sorry
182:22 - Adobe it's free to download but there's
182:24 - a lot of options out there and but the
182:26 - first thing you'll need is those Aus
182:27 - architectural icons so these are free on
182:30 - AWS you can download them in PowerPoint
182:32 - download them as asset as svgs and pgs
182:34 - which is what I have done and start
182:36 - using them in your um uh whatever
182:38 - software you like there's also third
182:40 - party providers out there so like
182:42 - there's Lucid charts I love lucid the
182:43 - charts but I don't use it to make
182:44 - architectural diagrams uh for AWS um but
182:48 - you know you can drag drop and stuff and
182:50 - they already have the library there and
182:51 - there's a bunch of them that you can
182:53 - choose from so uh you know that's
182:55 - interesting but let's take a look at one
182:57 - that we can download maybe everyone's
182:58 - familiar with PowerPoint so here is the
183:01 - adus architectural icons and the reason
183:03 - I'm showing you this is not because it
183:04 - just contains icons but it also suggests
183:07 - how you should build them so if I go
183:09 - through here they'll give you a
183:10 - definition of those system elements uh
183:13 - how they would look like here so we have
183:14 - our group icons or layer group our
183:16 - service icons resource icons where they
183:18 - should go uh and then they have some
183:20 - interesting guidelines of like dos and
183:22 - don'ts so here's like a simple example
183:25 - of a get to an S3 bucket um here's an
183:27 - example of using VPC subnets and things
183:30 - like that on the inside um and then you
183:34 - can see kind of like all the groups that
183:35 - we have and it show all like the uh the
183:39 - um arrows it's a big faux PA to make U
183:43 - diagonal arrows that's just something it
183:45 - us Define but you'll see a lot of people
183:46 - do them anyway and then you'll see all
183:49 - the icons so do you have to make them
183:51 - like ad suggests no but you know if you
183:54 - like the way they look that is fine
183:55 - everyone just does whatever they want
183:57 - honestly so anyway now that we've seen
183:59 - you know how we can go get the resources
184:01 - to make our own I have Adobe XD open up
184:04 - here and so I just kind of want to walk
184:05 - you through what's going on here so
184:06 - again I said this is a a
184:09 - traditional um architecture meaning that
184:12 - it's powered by virtual machines and so
184:14 - what we need to look for uh is ec2
184:17 - because that's where it's going to start
184:18 - that's our virtual machine and you'll
184:19 - notice we have one here so there's a T2
184:22 - um uh that's running over here and then
184:25 - over here we have a T2 okay so uh we
184:27 - have a blue and a green environment so
184:29 - this is our running environment so I'm
184:31 - just going to zoom on in here okay so
184:33 - the web app would be running on this and
184:37 - um and then on the outside here we have
184:38 - an autoscaling group and so autoscaling
184:40 - groups allow us to um manage a group of
184:43 - vc2 instances and they will
184:45 - automatically scale if the demand
184:46 - increases or or or declin so if this
184:50 - machine can't handle it it will just
184:51 - automatically provision a new one and so
184:53 - I've contained it in this environment
184:55 - here because I'm representing a blue
184:56 - green deploy meaning that when I deploy
184:59 - this will get this will be the
185:00 - environment that replaces things and so
185:02 - you can see I have a lot of lines being
185:04 - drawn around here so um over here we
185:07 - have uh um parameter store so parameter
185:10 - store is a place where we can store our
185:12 - environment variable
185:14 - um or application configuration
185:15 - variables and so I have this line going
185:17 - here and it's just saying we're going to
185:20 - take these environment variables and put
185:22 - them into the application okay uh and
185:25 - then there's also uh the database
185:27 - credential so here we are using
185:29 - postgress over here so and then we need
185:31 - the database credentials so we're
185:33 - grabbing those database credentials
185:34 - those are stored in Secrets manager and
185:36 - we're giving to the application so the
185:38 - app knows how to connect to the database
185:40 - and this one knows how to uh configure
185:41 - it okay then we have um a bunch of uh
185:46 - buckets here for different organizations
185:48 - and so you know S3 is for storage so
185:50 - this is a way we're going to um store a
185:53 - variety of things so like user data
185:55 - assets artifacts Cloud information
185:56 - templates so some of this is for the app
185:58 - some of them is for the infrastructure
186:00 - so that's one thing there okay then over
186:03 - here we have u a cicd pipeline so we
186:07 - have code Pipeline and so code pipeline
186:09 - is triggered by GitHub so we put our
186:11 - code in GitHub and when that happens
186:13 - it's going to do a code build so that's
186:15 - going to build out a
186:17 - server um and then from there it's going
186:20 - to run another code build server and
186:22 - then from there it's going to then um uh
186:26 - uh use code deploy and so code deploy is
186:28 - going to trigger a deploy what it will
186:30 - do is create a new environment so it's
186:32 - going to create a copy of this um sorry
186:36 - it's going to create a cop this is
186:37 - actually the environment that's running
186:38 - so we'll copy that and that will be our
186:40 - new environment right okay and so when
186:43 - the deploy is done it will swap and then
186:45 - that environment will become this new
186:47 - one um and so you know again this is
186:50 - actually really the the running server
186:52 - it's just kind of easy to get hung up on
186:53 - this one but the idea here is that um
186:56 - you know that's how deployment works but
186:58 - let's say uh you know we want to get uh
187:01 - traffic to this actual instance this is
187:03 - going to come through the internet and
187:05 - the internet's going to probably go to
187:07 - refy 3 so ref 3 is used for domain names
187:09 - so this be like exam pro. c teacher
187:11 - seat.com we pass that over to our
187:13 - elastic load balcer which in this case
187:16 - is an application load balcer that's why
187:18 - it's called ALB and that's going to
187:20 - distribute the traffic there if we
187:21 - wanted to run the server in another um
187:25 - in another availability zone so that we
187:27 - make it highly available um you know ALB
187:30 - the elastic load balancer application
187:31 - load balancer is going to uh have some
187:34 - traffic go here and some traffic go
187:35 - there so this is just uh the blue
187:37 - environment or whichever the current
187:38 - environment is over here now when we
187:41 - want to deploy new version we're going
187:43 - to use launch templates and launch
187:45 - templates um uh are necessary when using
187:49 - Autos scaling groups so um you know you
187:51 - do have to Define launch template it
187:52 - just says like what is the shape of this
187:54 - instance type like what's its family
187:56 - what should it be and then we need an
187:58 - Amazon machine image so our Amazon
188:00 - machine image is custom built because we
188:02 - are installing all the stuff that we
188:03 - want on it and so in order to automate
188:06 - that process we are using um SSM
188:09 - automation documents so SSM stands for
188:11 - system manager and automation allows you
188:14 - to automate that step so what it's going
188:15 - to do is launch an instance install Ruby
188:17 - install postgress download the codebase
188:19 - then it's going to create that Ami and
188:22 - then um it will do a bunch of other
188:24 - stuff here as well and this is going to
188:27 - run weekly or actually at the time uh it
188:29 - was running nightly so we're doing
188:30 - nightly builds so that we would always
188:32 - get the latest um updates to our server
188:35 - um because it's a virtual machine there
188:37 - could always be uh new updates for that
188:39 - Linux version or Amazon machine Li Linux
188:42 - version we using and then there's a
188:44 - bunch of other stuff here so you know um
188:47 - hopefully that kind of gives you an idea
188:48 - like the complexity of it and you know
188:50 - this is how I like to make my
188:51 - architectural diagrams very in detailed
188:53 - so that we can um look at them but yeah
188:56 - if that was too much that's fine but you
188:58 - know that's just the complexity of it if
188:59 - you build your own you'll start to
189:01 - really grasp this stuff pretty well
189:03 - [Music]
189:06 - okay so what I want to do is just show
189:08 - you how high availability is built into
189:10 - some ad Services where in other cases
189:13 - say you have to explicitly choose that
189:14 - you want something to be highly
189:16 - available uh so what I'm going to do is
189:17 - make my way over to S3 and so with S3
189:21 - this is where you can create S3 buckets
189:22 - and this allows you uh to store things
189:25 - and so the great thing about S3 is that
189:27 - it's basically serverless storage so the
189:29 - idea is that you're just going to choose
189:30 - your region and by default it's going to
189:33 - replicate your data across multiple um
189:36 - uh data centers or azs and so this one's
189:39 - already highly available by default with
189:41 - the standard tier and so that is
189:43 - something that's really nice but other
189:44 - services uh you know like ec2 the idea
189:48 - is that you are going to launch yourself
189:50 - an ec2 instance so we' launch that one
189:52 - and the problem with this is that if you
189:54 - launch a single
189:55 - ec2 that is not highly available because
189:58 - it's a single server running in a single
190:02 - um a so here you know we would choose
190:05 - our subnet our subnet is our
190:06 - availability Zone but you'd have to
190:08 - launch at least two additional servers
190:10 - and then you'd have to Route um uh you'd
190:13 - have to have something that would
190:14 - balance uh the traffic to the to the
190:16 - three which is a load balancer and so in
190:18 - this case you have to construct your
190:20 - high availability then you have services
190:23 - like elastic beanock this is a platform
190:25 - as a service um and we'll go to
190:28 - environments here I'm not sure I wasn't
190:29 - showing up there um and so the idea is
190:31 - that with elastic beant stock I'm just
190:34 - going to click on the main service here
190:35 - you're going to go ahead and uh create
190:38 - your application or create your
190:39 - environment you probably want to create
190:40 - an environment first here okay and so I
190:43 - would choose a web server and then the
190:46 - idea is I just name it so my application
190:49 - here my uh environment and then down
190:52 - below you go configure more options
190:54 - whoops it wants me to choose everything
190:56 - that's totally
190:58 - fine and we say configure more options
191:00 - we're not going to create it because um
191:02 - we don't want to create one but the idea
191:04 - is that uh you you could choose whether
191:07 - you want this to be high highly
191:08 - available or not so see it says single
191:10 - instance so free tier uh and then if you
191:12 - chose this what it's going to do it set
191:15 - up a bunch of stuff for you so it's
191:16 - going to set up an application load
191:17 - balancer for you it's going to set up
191:19 - Auto scaling groups for you to make it
191:21 - highly available it's going to run at
191:22 - least uh between one to four instances
191:25 - so this does everything that uh ec2
191:28 - you'd have to do manually setting up so
191:30 - that's really
191:31 - nice okay so you know some options have
191:34 - that if we make it our way over to RDS
191:36 - and again we're not creating anything
191:37 - we're just looking at the options it
191:39 - gives us when we uh start things these
191:41 - up here
191:43 - we'll make our way over to RDS when it
191:44 - gives us a moment
191:47 - here and if we go ahead and create
191:49 - ourselves a new
191:53 - database and we look at something like a
191:55 - postgress database notice that we have a
191:58 - production option and a Dev test option
192:01 - and so I mean usually it shows us the
192:03 - price down here so even test Dev is $118
192:06 - which is not true can make it cheaper
192:07 - than that but the idea is that when you
192:09 - choose between these two options um it's
192:12 - going to set up uh multi-az it's going
192:15 - to that means that it's going to run an
192:18 - additional um uh database and another
192:20 - availability Zone replicate that data
192:22 - over so that it stays highly available
192:26 - um you know it's going to have
192:27 - autoscaling uh uh part of it and so some
192:30 - Services you just choose it abstractly
192:33 - so you just have to understand what
192:34 - highly availability is going to mean
192:36 - underneath so hopefully that kind of
192:37 - gives you a picture of high availability
192:39 - on
192:41 - AWS
192:43 - [Music]
192:45 - hey this is Andrew Brown from exam Pro
192:47 - and we are looking at adus application
192:49 - programming interface also known as adus
192:51 - API so before we talk about uh the API
192:54 - let's describe what application
192:56 - programming interface is so an API is
192:58 - software that allows two applications or
193:00 - services to talk to each other and the
193:02 - most common type of API is via HTTP
193:05 - requests and so the ads API is actually
193:09 - an htttp API and you can interact with
193:12 - it by sending HPS requests using an
193:15 - application interacting with apis like
193:17 - Postman and so here's kind of an example
193:19 - of what a request would be that would be
193:21 - sent out and so the way it works is that
193:24 - each Ada service generally has a service
193:26 - endpoint so see where it says monitoring
193:28 - that's going to be cloudwatch so
193:30 - sometimes they're named after the
193:31 - services sometimes the name is a bit
193:32 - obscure and of course you can't just
193:35 - call uh call Api request without
193:38 - authenticating or authorizing and so you
193:40 - have to sign your request and so that's
193:42 - a process of making a separate request
193:44 - uh with your adus credentials to get
193:46 - back a a temporary token in order to
193:49 - authorize that and I don't have room to
193:52 - show it but the thing is is that what
193:53 - you'd be uh also going along with those
193:56 - requests would be to provide an action
193:58 - so when you look at um the adus API it
194:02 - will show you a bunch of actions that
194:04 - you can call they're basically the same
194:05 - ones you'll see in the IM policies so it
194:08 - could be like describe ec2 instances Or
194:11 - List buckets um and they can also be
194:13 - accompanied with parameters okay so you
194:16 - know we're probably not going to show
194:18 - you how to uh make an API request
194:20 - directly because that's not something
194:21 - that you would generally do um but what
194:24 - you would do is you'd probably use the
194:27 - abis Management console which is powered
194:29 - by the API use the adus SDK which is
194:31 - powered by the API or using the adus CLI
194:34 - so we'll cover all those three
194:36 - [Music]
194:40 - okay all right so what I want to do is
194:42 - just point you to where you'd find the
194:44 - resources to use the API
194:46 - programmatically uh we're not going to
194:48 - actually use the API because there's a
194:50 - lot more to it uh than what I'm going to
194:52 - show you here but at least you'll be
194:54 - familiar with how the API works so I'm
194:56 - on the aws.amazon.com website if you
194:59 - type in docs the type top there it's
195:01 - going to bring you to the main
195:03 - documentation and what we're looking for
195:05 - if we scroll on down there should be a
195:07 - general reference area where we have
195:08 - service endpoints if we click into here
195:11 - it's going to uh talk about um how a
195:14 - service endpoint is structured and if we
195:16 - go down to abis API we can see some
195:18 - additional information of course to use
195:21 - um the API you're going to have to sign
195:23 - API requests first which is not a super
195:26 - simple process but you have to use an
195:28 - authorization header um and send along
195:31 - uh some credentials and things like that
195:33 - so if you want to know what service
195:34 - endpoints uh are available to you if you
195:37 - search service endpoints list for AWS
195:39 - this is the big list and so if I was to
195:41 - go down here and look for C2 U might be
195:44 - a common example here it's going to tell
195:46 - us what the end points are and as you
195:48 - can see they are Regional based but the
195:50 - idea here is that I could take something
195:52 - like this okay I could grab that and
195:55 - using something like
195:56 - Postman I could go and create a new
195:59 - request and it's probably a post I'm not
196:01 - sure what it's supposed to be it's
196:02 - probably a post and then you'd set your
196:05 - authorization header there might even be
196:06 - one in here for adab us see where it
196:08 - says adab us signature so you can go
196:10 - here and put your access key and secret
196:12 - with in here um so that's something nice
196:14 - about Postman so it's going to do the
196:16 - signing requests for you so it makes
196:18 - your life a lot easier and then from
196:20 - there what you do is you go to your body
196:22 - and you'd want to enter in Json so to do
196:25 - Json would probably be raw you drop down
196:28 - the format Json and then you'd send your
196:30 - payload whatever it is so I again I
196:32 - haven't done this in a while because
196:33 - it's not a very common uh thing that I
196:35 - have to do like describe ec2 instances
196:37 - but there probably is like an action and
196:39 - some additional information that you'd
196:40 - send along um so you know hopefully that
196:43 - gives you kind of an idea how the API
196:46 - works but you know you should never Pro
196:48 - uh in practice ever have to really work
196:50 - with the API this way directly
196:53 - [Music]
196:56 - okay hey this is Andrew Brown from exam
196:59 - Pro and we are looking at the itus
197:00 - Management console so the itus
197:02 - Management console is a web-based
197:03 - unified console to build manage and
197:05 - monitor everything from simple web apps
197:07 - to complex Cloud deployments so when you
197:09 - create your adus account and you log in
197:12 - that is what you're using the adus
197:13 - Management console and I would not be
197:15 - surprised uh if you're watching this
197:17 - video and they've already changed um the
197:19 - default page here since abos loves to
197:21 - change the UI on us all the time uh but
197:24 - uh the way you would access this is via
197:26 - console. ab. amazon.com when you click
197:28 - sign in or go to the console that's the
197:31 - link that it's going to uh and so the
197:33 - idea here is that you can point and
197:35 - click to manually launch and configure
197:36 - adus Resources with limited programming
197:38 - knowledge this is known as click Ops
197:40 - since you can perform all your system
197:42 - operations via clicks
197:44 - [Music]
197:47 - okay let's talk about the adus
197:49 - Management console in brief here so you
197:51 - know of course when you're on the
197:52 - homepage you go to ads Management
197:53 - console and you will end up logging in
197:56 - and from there we will uh make our way
197:58 - over to the ads Management console when
198:00 - I say ads Management console I'm
198:02 - referring to uh this homepage but I'm
198:04 - also referring to anything that I'm
198:06 - doing in this web UI whether it's a
198:09 - subservice or not so you know a lot of
198:11 - times people just call this the
198:12 - dashboard uh or the homepage um but you
198:16 - know it is technically the adus
198:17 - Management console but everything is the
198:19 - adabs Management console you can drop
198:21 - down Services here if there's some that
198:23 - you like you can favorite them on the
198:24 - left hand side I don't find that
198:26 - particularly useful you can see the most
198:28 - recent ones here they'll also Show
198:30 - recently up here as well we have the
198:32 - search at the top notice that there's a
198:33 - hotkey for alt S I don't think I ever
198:35 - use it but if I was to type in a service
198:37 - like ec2 it's going to get me the
198:39 - services and then down below it's the
198:42 - sub features of it so if I just click
198:43 - into that there into this this is the
198:46 - main this is a service console so I
198:48 - would call this the ec2 console or the
198:51 - ec2 service console so if you ever hear
198:54 - me saying go to the ec2 console that's
198:55 - what I'm saying and you'll notice here
198:57 - like there is stuff on the left hand
198:59 - side so I come back here ec2 image
199:01 - Builder ec2 Global views these are
199:03 - considered services but if you drop down
199:05 - it says top features or you go down here
199:07 - it says dashboard limits Amis you go
199:09 - over here um the ec2 dash board limits
199:13 - Amis are here and limits are somewhere
199:15 - here right there so okay so those kind
199:18 - of map over pretty well plls and
199:20 - documentation knowledge based articles
199:21 - Marketplace I don't think I've ever
199:23 - touched those in my life uh this here is
199:25 - the cloud shell so if you click it it
199:26 - will launch a cloud shell will cover
199:28 - that when we get to that section here we
199:30 - have this little bell it tells us about
199:32 - open issues I think this is for the
199:34 - personal health dashboard yeah it says
199:36 - PhD in the bottom left corner or left
199:38 - corner so if I open that up it'll bring
199:40 - up the PHD the personal Health dashboard
199:43 - all right uh our region selector our
199:46 - support so nothing super exciting here
199:49 - but just kind of giving you a bit of a
199:50 - tour so that you know there are some
199:52 - things you can do um can you change the
199:56 - look of this I don't think right now as
199:58 - of yet um there is any way I'm sure Aus
200:01 - is thinking about it because it's been a
200:03 - high uh request that's in demand but uh
200:05 - this is what it looks like as of today
200:10 - okay all right so I just want to
200:13 - describe what a service console is so an
200:15 - an service each have their own
200:17 - customized console and you can access
200:19 - these consoles by searching the service
200:21 - name so you would go ahead and type in
200:22 - ec2 and then what we refer to this
200:24 - screen as as the ec2 console the reason
200:27 - I'm telling you this is that when you're
200:28 - going through a lot of labs or follow
200:30 - alongs you'll hear the instructor say go
200:32 - to the ec2 console go to the stagemaker
200:34 - console go to the RDS console what
200:36 - they're telling you is to go type the
200:38 - the name of the service and go to um
200:41 - that particular Services console okay uh
200:44 - some adus service consoles will act as
200:46 - an umbrella console containing many adus
200:48 - services so uh you know VPC console ec2
200:52 - console systems manager console Sage
200:54 - maker console uh cloudwatch console
200:56 - these all contain multiple services so
200:59 - you know for um for ec2 you might say
201:03 - okay well I need a security group
201:04 - there's no security group console it's
201:06 - under the ec2 console okay uh so just be
201:09 - aware of
201:10 - that
201:13 - [Music]
201:14 - so now I want to show you some of the
201:16 - service consoles to kind of distinguish
201:18 - how they might vary per per service okay
201:21 - so if we were to look up
201:23 - ec2 um and we just did look at this but
201:25 - the interesting thing is that some uh
201:27 - consoles the ec2 console uh is the home
201:30 - for other databus services and you just
201:33 - have to learn this over time to know
201:34 - that so for instance elastic Block store
201:37 - is its own service but it's tightly uh
201:39 - linked to ec2 instances so that's why
201:41 - they always have have it here same thing
201:43 - with Amis uh security groups same thing
201:46 - with that so these are interesting
201:47 - because these are basically part of
201:49 - virtual networking and so you'd think
201:51 - they'd be under the VPC console but they
201:53 - are actually under here with ec2 and so
201:56 - load balancing autoc scan groups tightly
201:58 - coupled to um uh to ec2 if we make our
202:02 - way over to
202:05 - VPC um you know here it's going to
202:07 - contain all the new stuff does it have a
202:09 - new experience no I guess this is the
202:11 - newest one
202:12 - it looks a bit old and a little bit new
202:14 - here but you know we have a lot of
202:15 - different things here like firewalls
202:17 - vpns Transit gateways traffic mirroring
202:20 - we make our way over to
202:23 - cloudwatch okay and cloudwatch has uh
202:26 - very uh focused Services they're all
202:29 - actually named and this is more like a s
202:31 - feels more like a single service where
202:32 - you have these very focused um Services
202:35 - where you have alarms logs metrics
202:37 - events insights right but you're going
202:39 - to notice that like the UI highly VAR
202:42 - so we had looked at cloudwatch and then
202:44 - we had looked at U VPC and it looks like
202:47 - this and then we looked at ec2 and it
202:49 - looked like that and so there is
202:51 - inconsistencies because each um Service
202:55 - uh Team like that work on per service or
202:58 - whatever they have full control over
202:59 - their UI and so some of them are in um
203:03 - uh different states of updating so some
203:04 - people might have updated the left-and
203:06 - column but this part is old or you might
203:08 - click around like under something else
203:10 - like ec2 dashboard um or maybe a better
203:13 - example might be Amis I remember we're
203:15 - in here and something looked old here
203:16 - yeah see these are the old buttons and
203:18 - that's just how it is so everything is
203:20 - very uh modular and so they get updated
203:22 - over time so that is the challenge that
203:24 - you're dealing with you're always having
203:26 - like three different versions that are
203:28 - cobbled together in each uh um UI one
203:32 - thing that I found really interesting is
203:33 - that um VPC has its own console
203:36 - Management console but if you were to
203:37 - look up this in the uh the SDK so if I
203:40 - was to look up um AB
203:42 - SDK
203:44 - ec2 okay I'm just looking up Ruby here
203:46 - as an example because that's what I know
203:48 - how to do um if you look under here
203:51 - let's say you want to pragmatically work
203:52 - with vpcs you think that it would have
203:54 - its own top level VPC because it has in
203:57 - the console its own uh its own
204:00 - Management console but actually VPC is
204:03 - tightly coupled ec2 and so when you want
204:05 - to programmatically use VPC you're going
204:07 - to be um using actually ec2 uh as as was
204:11 - built so the the the what I'm trying to
204:14 - get is the apis don't onetoone match
204:17 - with this kind of stuff and so it's just
204:19 - kind of interesting that there's those
204:20 - kind of uh differences uh but again it's
204:23 - not that big of a deal I'm just trying
204:25 - to say like you know keep your mind open
204:27 - when you're look at the stuff
204:29 - [Music]
204:33 - okay so every ad ofus account has a
204:35 - unique account ID and the account ID can
204:38 - be easily found by dropping down the
204:39 - current user in the global navigation
204:42 - so what I'm going to do is pull my pen
204:43 - tool here and just show you it's right
204:45 - there the ab account ID is composed of
204:47 - 12 digits and so it could look like this
204:50 - or this or this account ID is used when
204:52 - logging in uh with a nonroot user
204:55 - account uh but generally a lot of people
204:57 - like to set their own Alias because it's
204:58 - tiring to remember your account uh ID
205:01 - the uh you use it when you're creating
205:02 - cross account rol so you'd have the
205:04 - target account the source account ID to
205:06 - gain access to resources in another a
205:08 - account when you're uh dealing with a
205:10 - support es a will commonly ask you what
205:14 - your account ID is so they can identify
205:16 - the account that they want to look at
205:19 - and it is generally good to keep your
205:20 - account ID private as it is one of the
205:22 - many components used to identify an
205:24 - account for an attack by malicious actor
205:26 - uh so you don't have to be overly
205:27 - sensitive with it but you know try to
205:29 - hide it when you can when it's easy
205:31 - [Music]
205:35 - okay all right so let's talk about the
205:37 - account ID which appears up here in the
205:40 - top right corner uh where you can get
205:41 - the account ID it also appears in IM am
205:44 - so if we go over to IM am and you look
205:47 - on the right hand side it should show
205:48 - you the example here it keeps on trying
205:51 - to take us to the old dashboard that's
205:52 - fine um but you'll notice that it's over
205:55 - here and I don't have MFA turned on
205:58 - because I'm in my IM user account but it
205:59 - should be turned on on everything that's
206:01 - given but uh you know I just want to
206:03 - show you where it is and also where you
206:05 - might be using it so one example where
206:07 - you would use you would need to know
206:09 - your account ID would be something like
206:11 - creating a cross account policy so I
206:14 - went here and went to policy and went
206:15 - create
206:16 - policy um and we went to maybe it's a
206:22 - roll I think we actually sorry we want a
206:23 - cross account account rle it's not the
206:24 - policy sorry we go here and we say I
206:29 - want to access something in another A's
206:31 - account what we have to do is specify
206:32 - the account ID specify the accounts that
206:35 - can use this role so you give I think
206:37 - the the ID of the other account okay
206:41 - okay and so that is one place where You'
206:43 - use it another place would be when
206:45 - you're creating policies so if I go back
206:48 - to policies here I can create a policy
206:51 - here and I can just choose something
206:54 - like S3
206:56 - okay and I'll just choose a list and
207:00 - under the request
207:01 - conditions I might specify I think the
207:04 - account ID it should be in
207:07 - here um I know I can limit based on
207:11 - account
207:12 - ID principal
207:16 - account so you can do principal account
207:19 - so if I just looked up this here ABS
207:21 - principal
207:24 - account and you just got to get used to
207:26 - Googling things that's always what's
207:28 - happening here and so we should be able
207:30 - to specify an account ID yeah like that
207:33 - so that would be the principle there so
207:36 - if I just took that and doesn't matter
207:38 - what it is we just put the value in here
207:41 - uh um string equals this add I should be
207:45 - able to go over here and now see the
207:46 - full statement no sometimes that happens
207:48 - because we don't have it fully filled
207:52 - out but um yeah so that pretty much
207:55 - that's pretty much how we use it like it
207:57 - would normally show up as that so if I
207:59 - just go ahead and go next the policy
208:01 - contains an error you are required to
208:03 - choose a
208:04 - resource what do you mean the resource
208:06 - is this right oh down here okay sorry uh
208:09 - so we'll just say all resources then we
208:11 - split over now it's valid and so here we
208:12 - can see our condition saying only from
208:15 - this account ID that it is allowed um
208:18 - other places we're going to see account
208:19 - IDs are in um ARS right so if we had an
208:24 - ec2 instance we don't have one launched
208:26 - right now but if I was to go ahead and
208:31 - oh maybe we have some prior ones yeah so
208:32 - if I was to checkbox this
208:35 - here and you might not have any prior
208:37 - ones so there might not be nothing for
208:39 - you to see but if you look for the arm
208:42 - AR where is our
208:47 - AR sometimes it doesn't show the Arn in
208:49 - the services sometimes it does I wish
208:52 - that AB always showed the AR to make our
208:53 - lives a bit easier but it could be
208:55 - because of other reasons why but even
208:58 - though we don't have the AR I think it
208:59 - shows us shows us the owner ID and so
209:03 - that's the account uh the account ID
209:04 - number you can tell because it's 12
209:05 - digits so hopefully that gives you kind
209:07 - of a tour of the account ID and what its
209:10 - purpose is in the out
209:12 - [Music]
209:15 - okay all right let's take a look at it
209:17 - tools for Powershell so what is
209:19 - Powershell Powershell is a task
209:21 - Automation and configuration management
209:23 - framework is a command like shell and a
209:26 - scripting language so here it is over
209:28 - here uh if you are a Windows user you're
209:30 - used to seeing this because it has a big
209:31 - blue window so unlike most shells which
209:34 - accept and return text Powershell is
209:36 - built on top of the net common language
209:38 - runtime CLR accepts and returns the net
209:42 - objects so uh adus has a thing called
209:45 - the itus tools for Powershell and this
209:47 - lets you interact with the itus API via
209:50 - Powershell commandlets commandlets is a
209:52 - special type of command in Powershell in
209:54 - the form of the capitalized verb and
209:56 - noun so in this case it'd be new hyphen
209:59 - S3 bucket so you know we looked at the a
210:02 - CLI and that is generally for bash um uh
210:05 - you know shells and so power shell is
210:08 - just another type of shell that's very
210:09 - popular and I just wanted to highlight
210:11 - it for those people that are uh you know
210:13 - used to using Microsoft workloads or
210:15 - Azure workloads uh that this actually
210:17 - exists
210:18 - [Music]
210:21 - okay all right let's take a look at the
210:23 - Powershell tools um I actually haven't
210:25 - used this one yet so I'm kind of curious
210:27 - I am out a Windows machine so if I was
210:29 - to um open CM or
210:32 - Powershell and you probably can't see
210:34 - this but if I just bring this over here
210:36 - if I type in Powershell on my
210:38 - computer you'll notice that I have it um
210:40 - so that's how You' launch it looks like
210:42 - a blue screen here okay um if you're on
210:45 - a Mac you're not going to have that but
210:46 - that's totally fine we don't need to
210:48 - have a Windows machine to use Powershell
210:50 - because we can go ahead and use cloud
210:51 - shell so make sure you're in a region
210:53 - that supports Cloud shell so I switch
210:55 - back to North Virginia uh this is not
210:58 - important for the exam but it's just
210:59 - kind of fun for me to go through this
211:00 - with you and if you just like want to
211:02 - watch uh here and so I want to change
211:04 - this over to power shell so I imagine
211:06 - that it must be over
211:08 - here um so how do we change change to
211:11 - poers Shell so we'll type in ads power
211:15 - or ads Cloud
211:18 - shell Powers shell like how do we do
211:22 - it okay and so I'm just going to scroll
211:24 - down
211:26 - here so the following shells are
211:28 - pre-installed uh The Bash the power
211:30 - shell the Z shell you can identify them
211:31 - by that yeah of course to switch to New
211:33 - Shell enter the Shell's program name in
211:35 - the command line prompt oh wow that's
211:37 - easy so um if we want
211:39 - pwsh do we just just type pwsh let's
211:42 - find
211:46 - out give it a moment to think oh there
211:49 - we go okay so now we're using Powershell
211:51 - and so I would think that ads would give
211:53 - this pre-installed for us so if we go
211:55 - over here to the instructions and we
211:57 - scroll on down there's probably like oh
211:59 - wait like I don't use Powershell a lot
212:01 - it's very easy to install modules um
212:03 - I've done it before but I never remember
212:05 - how to do it but let's just see what we
212:07 - can find here so I want the
212:10 - documentation for Powershell here and
212:12 - I'm going to go to the um the maybe the
212:16 - reference here because I just want to
212:18 - see some examples for the commandlets
212:20 - and so we'll look for S3 again never
212:22 - done this before but I'm always great at
212:25 - jumping uh into these things and all I
212:27 - want to do is just list out the buckets
212:28 - so I'm going to just search for the word
212:30 - list um and just see if I can find
212:33 - something very simple
212:35 - here and calls to get the list buckets
212:38 - API operation so I think that is what
212:40 - we're going to to be doing here so I'm
212:42 - going to click into that
212:46 - okay and then from there what I'm going
212:49 - to do is just see if I can copy this
212:51 - command so we will go ahead and copy
212:54 - this and paste it in here and I like how
212:56 - we got this little shell here so we can
212:58 - tweak it so we need the bucket name but
213:01 - I don't want to return a list of all the
213:03 - buckets owned by the author so we don't
213:05 - have a bucket name that we want to
213:06 - explicitly set here so it's required
213:08 - false so we can remove that
213:11 - okay we'll look at the next one select
213:13 - required fals use the select command to
213:15 - control the command L output the default
213:16 - is bucket specifying selectable result
213:19 - in returning all the whole
213:22 - buckets for that specifying the name uh
213:26 - but it says it's not required so let's
213:28 - just take that out as well I don't think
213:31 - we need any of these actually let's just
213:32 - go and put that in there and I think
213:35 - that there must be something we need to
213:37 - put in front of that right let's just
213:39 - see what happens
213:43 - uh the term is not recognized as the
213:45 - name of the commandlet function script
213:47 - is operable so I think we're missing
213:49 - something in front of
213:52 - here we'll go to the user guide here
213:55 - quickly and we'll get to the getting
213:59 - started I just want a super simple
214:02 - example
214:03 - here new bucket get bucket well let's
214:07 - try this one here because they have it
214:09 - here and so it should work
214:13 - right I'm change this to us East
214:18 - one the term new bucket is not
214:20 - recognized as the name of the commandlet
214:21 - function so I'm guessing that the
214:23 - commandlet is not installed I would have
214:24 - thought that they would have installed
214:25 - it by default so I guess what we'll do
214:27 - is look at how to install it so
214:31 - installing
214:32 - on Linux I
214:36 - suppose
214:38 - so you can install the modulized version
214:40 - of the Powershell on computers to
214:42 - install adus tools on Linux pwsh to
214:46 - start Powershell core session so I guess
214:47 - that's how you must start it on Linux
214:49 - and then install the module this way so
214:52 - yeah I said it's easy to install these
214:53 - things we'll hit
214:54 - enter cross your fingers hope this works
214:57 - hope this is
215:03 - fast I'm just going to take a look here
215:05 - peek forward here if you are not uh if
215:07 - you're notified the repository is UN
215:08 - trusted you're asked if you want to
215:10 - trust anyway just hit Y so we're waiting
215:12 - for that here um you're installing this
215:15 - module from untrusted repository it's
215:17 - funny that it's untrusted by but it's by
215:19 - AWS maybe that's some kind of drama
215:21 - between Microsoft not letting AWS have
215:23 - an official module there but it looks
215:24 - like it should be installed now so if I
215:26 - type in get S3 bucket
215:29 - here um unless I typed it wrong that
215:32 - still doesn't seem to be working if I go
215:34 - up here and try to create a new bucket
215:36 - still does not recom recognize the
215:38 - command command lit here so there must
215:40 - be more going on
215:41 - here
215:44 - um if you are notified you can now
215:47 - install the module for each
215:49 - service okay well what did we
215:53 - do you're installing the the the modules
215:55 - from unrusted if you trust it change the
215:57 - uh change it installation policy value
215:59 - by running set policy command are you
216:01 - sure you want to install this module
216:02 - from the PS Gallery so I said yes and I
216:06 - gave it a capital Y and it didn't do
216:09 - anything else
216:14 - so oh hold on here so this is the
216:18 - installer and then here is the actual
216:20 - tool that we want to install so it
216:22 - install to oh so we just installed this
216:24 - thing and now we use this thing to
216:25 - install S3 okay great not hard
216:30 - okay and so we'll just say yes to
216:34 - all and so that's going to install I
216:38 - guess everything oh we said ec2 and S3
216:40 - three well we didn't need both but
216:41 - that's fine and so what I'm going to do
216:43 - is go get bucket and so now recognize it
216:45 - it lists out the items here we can go
216:47 - and create ourselves a new bucket so
216:50 - we'll do that okay we'll make our way
216:53 - back over the databas Management console
216:55 - we'll go to S3 just because I don't need
216:57 - all these buckets lying around here and
217:00 - I'm going to go ahead and delete some of
217:02 - these buckets here so we'll say
217:04 - delete my bucket great and we'll go to
217:08 - this one here and say delete
217:11 - my bucket
217:13 - excellent all right and so we have an
217:15 - idea how to use Powershell so Powershell
217:17 - is just really popular because of it's
217:20 - the way you do inputs it's very
217:21 - standardized and the outputs that come
217:23 - so it's very popular um and a very
217:26 - powerful scripting tool that's or CLI
217:28 - tool as well so uh you know hopefully
217:30 - that's that was interesting for you but
217:32 - what we'll do is just close these off
217:34 - here and go back to our our homepage
217:36 - always just clicking that logo there and
217:37 - there we
217:39 - go
217:41 - [Music]
217:43 - so Amazon resource names uniquely
217:45 - identify itus resources and orangs are
217:47 - required to specify resource and
217:49 - Ambiguously across all a of all of AWS
217:52 - so the AR has the following format
217:54 - variations so there's a few different
217:56 - things here but just notice here that
217:58 - sometimes it has a resource ID or it has
218:00 - a path so with a resource type or could
218:02 - be separated by a colon so the partition
218:05 - um could either be ads China or gov
218:08 - Cloud because this is basically the ads
218:11 - uh portal or URL that are completely
218:13 - separated from each other uh as we
218:15 - talked about those earlier in the course
218:17 - uh then there's the service identifier
218:19 - so ec2 S3 IM am pretty much every
218:21 - service has their own uh service that uh
218:25 - name here that would be identified then
218:27 - the region would be pretty obvious Us
218:28 - East one CA Central 1 you'd have a
218:31 - account ID which would be 12 digits uh
218:33 - the resource ID uh could be a name or a
218:35 - pass so like for um IM IM users we have
218:39 - user Bob the this is an E2 instance and
218:42 - most of the IRS are accessible via the
218:44 - Aus Management console and you can
218:46 - usually click the Arn to copy to your
218:48 - clipboard so here is it is for um an S3
218:50 - bucket and notice that it's a little bit
218:52 - different because it is a global Service
218:54 - AWS there's no reason to specify the
218:57 - region or the account ID or uh anything
219:00 - else there like the resource type so
219:02 - straight away we already know it's a
219:03 - bucket so we can just say my bucket so
219:05 - that one's really short but in other
219:06 - cases it's really long so here it is for
219:08 - a load balcer and it has all the
219:10 - information there and notice that like
219:12 - this has a pass load balcer app my
219:14 - server will be and then it has the ID
219:17 - okay for paths and IRS they can also
219:20 - include uh a wild card Aster and we'll
219:23 - see these like with IM policies or or
219:25 - paths these are really useful when you
219:27 - are doing um uh policies where you have
219:30 - to specify n you want to say a group of
219:32 - things and things like that so there you
219:34 - [Music]
219:37 - go all right so now let's take a look at
219:40 - Amazon resource name or also known as AR
219:43 - um and so ARS are used to reference
219:45 - objects they're very commonly used when
219:47 - you're using the CLI or the SDK to
219:49 - reference to something um the easiest
219:51 - example is S3 right so we go over to S3
219:54 - here and we create ourselves a new
219:55 - bucket um so I'll go ahead and create
219:58 - ourselves a new one here we say my new
220:01 - bucket I'm just going to put a bunch of
220:03 - numbers in here doesn't matter we'll hit
220:05 - create bucket and what we will see if we
220:08 - click into this is the AR should be
220:11 - under
220:12 - properties and there it is okay so there
220:15 - are many cases where you might want to
220:18 - use the AR and a lot of times you'll
220:19 - just copy it and uh a very common
220:22 - example would be again with I am
220:24 - policies so we go over to I am policies
220:27 - right and I want to get to policies here
220:30 - just save myself some trouble and we
220:32 - create a
220:33 - policy you know I might want to restrict
220:35 - someone to use only that bucket so I say
220:38 - S3 okay and then I'm going to say um I
220:41 - want to be able to read and write from a
220:43 - particular bucket we go drop down these
220:45 - resources here and so here we have a lot
220:49 - of
220:50 - options um maybe I'll just get rid of
220:52 - the read
220:54 - option and I'm going to actually expand
220:56 - right because it's just creating too
220:58 - much work for me here and I just want to
221:00 - have um put put object that's that's the
221:03 - what we use to put something into a
221:05 - bucket so we expand the resource here
221:07 - and notice this says add the irn so we
221:09 - go here
221:10 - and we could type the bucket name so do
221:13 - that or we just paste it on in here at
221:14 - the top so it's probably easier just to
221:16 - grab it
221:18 - sometimes but if you don't know an AR a
221:20 - lot of times you can just expand this
221:21 - and then fill it in and that's how you
221:22 - get an Arn so put that there let's list
221:25 - oh you can also do it that way which is
221:27 - easier too and so now if I go to Json is
221:30 - it valid there we go so here it's saying
221:33 - um this policy allows somebody to put an
221:35 - object into this particular bucket and
221:37 - so that would be an example where we
221:39 - would use um an AR okay or if you're
221:41 - doing uh if you're using uh ad support
221:44 - you might have to use an AR to um to get
221:48 - help from support saying hey look at
221:49 - this particular resource exactly here
221:51 - and then the the cloud support engineer
221:53 - can help you
221:54 - [Music]
221:57 - okay hey this is Andrew Brown from exam
222:00 - Pro and we are looking at the itus
222:02 - command light interface but before we do
222:03 - that we got to Define some terms so what
222:05 - is a CLI so a command line interface
222:08 - processes commands to a computer program
222:10 - in the form of lines of text operating
222:12 - system Implement a command line
222:14 - interface in a shell okay so then we
222:16 - have a terminal so a terminal is a text
222:18 - only interface so it has input output
222:19 - environment then you have a console this
222:21 - is the physical computer to physically
222:23 - input information into a terminal then
222:26 - you have the shell a shell is the
222:28 - command line program that users interact
222:30 - uh with uh to input commands popular
222:32 - shell programs are bash uh zsh
222:35 - Powershell and you might remember this
222:37 - one MS DOS prompt so
222:40 - this has been around for obviously a
222:41 - very long time so maybe this kind of
222:43 - primes your mind for what is a shell and
222:46 - just so you know people commonly
222:48 - erroneously use terminal shell or
222:49 - console to generally describe
222:51 - interacting with a shell so if we say
222:53 - shell or console or terminal we're just
222:54 - talking about the same thing but there
222:56 - is technically a difference between
222:58 - these three things but most people do
222:59 - not care and I wouldn't worry about it
223:01 - too much okay so now let's take a look
223:03 - at the itus command line interface which
223:05 - allows you to pratically interact with
223:07 - the itus API via entering single or
223:09 - multi line commands into a shell and
223:11 - then here I say or terminal but really
223:13 - it's just the shell okay so uh here is
223:16 - an example of one so we're trying to
223:17 - describe uh ec2 instances and then we're
223:20 - getting the output because we asked to
223:22 - have it back in this table like view so
223:24 - the ab is a python executable program so
223:27 - python is required to install the aw CLI
223:30 - the a CLI can be installed on Windows
223:32 - Mac Linux Unix the name of the ca
223:34 - program is AWS you'll notice that up
223:36 - here in the top left corner there's a
223:38 - lot more to this but this is all we need
223:39 - for now
223:41 - [Music]
223:44 - okay hey this is Andrew Brown from exam
223:47 - Pro and we are taking a look at the abis
223:50 - CLI and the easiest way to get started
223:52 - with this is actually via the cloud
223:53 - shell so you'll notice this little icon
223:55 - here in the top right corner that is
223:57 - cloud shell and it's going to allow us
223:59 - to um uh programmatically do things
224:01 - without having to set up our own
224:03 - environments so if I just click that
224:05 - there okay uh and I say do not show
224:08 - again close and by the way if you don't
224:11 - see Cloud shell here it could be your
224:13 - region so like if I go to Canada Central
224:15 - it doesn't have it there and so if I was
224:18 - to search Cloud shell
224:20 - here okay it's going to say it's only
224:23 - supported in those regions so that's a
224:24 - bit annoying but once Cloud shell loads
224:27 - it already has our uh credentials loaded
224:29 - within our account and so this is going
224:31 - to save us a lot of time in terms of uh
224:34 - you know trying to get set up with the
224:36 - exception that you have to wait for this
224:37 - environment to create so it takes a
224:39 - little bit of time time but it's not
224:40 - that bad um and while that is waiting
224:42 - what I'll do is show you actually how
224:44 - you install the CLI yourself so if we
224:45 - typed in Abus CLI
224:48 - install all right and uh we went here
224:51 - the way you would install I believe it's
224:53 - a python library but if we went to
224:55 - version two and we just said Linux uh
224:57 - you go down here they have instructions
224:59 - so you just curl it unzip it and do
225:02 - that um so you know if it's this and
225:05 - then once it's installed you'll have the
225:07 - of the CLI commands this is still go so
225:10 - you know maybe I can show you what it
225:11 - would be like to install the CLI by hand
225:14 - so if we wanted to do that one easy way
225:16 - to do this is if we just go to GitHub
225:18 - doesn't matter what repository I'm just
225:20 - looking for anything here and if I open
225:22 - up git pod so if we go on the top here
225:23 - and type in git pod
225:26 - uh. maybe
225:29 - that I just want to see
225:32 - whoops maybe just get
225:35 - pods
225:38 - that oh get pod you're not giving me oh
225:41 - you know what it's doio that's why okay
225:42 - so if we go back here sorry and we type
225:45 - in
225:47 - doio what this will do is launch me a
225:49 - temporary environment and so this is
225:51 - outside of AWS so I'd actually have to
225:53 - install the CLI so this would be a great
225:55 - opportunity to show you how to install
225:57 - the CLI I'm just doing it this way
225:58 - because git pod is free to use and um
226:02 - you know it's going to set up an
226:02 - environment and how let us simulate
226:04 - installing the CLI so here is the CLI
226:07 - here I'm going to see if I can bump up
226:08 - the font
226:10 - um let's make the font as large as we
226:11 - can go light or dark dark sounds good to
226:14 - me and so if we type in
226:19 - AWS I give it a moment we can see that
226:21 - we have uh the command here so if I say
226:23 - ABS S3 LS whoops it should be able to
226:28 - list things out in a bucket so this is
226:29 - what's currently in the bucket if you're
226:31 - wondering how do I know what these
226:32 - commands are I can just type in a CLI
226:35 - commands Okay and if we go here um and
226:38 - we go to the CLI reference reference
226:41 - then we have um anything we want here
226:43 - right so we go down here and I just want
226:45 - to see what's running in S3 and I go
226:48 - here and I scroll on down it's going to
226:50 - show me commands like copy move remove
226:53 - sync uh MB RB uh list
226:57 - right and if you're looking for a
227:01 - particular command you go down and say
227:02 - okay I'll look at LS here and it will
227:04 - explain to me all the little options
227:06 - that we can do with it and then it will
227:08 - always give me examples right so I can
227:10 - see examples like that so if I wanted to
227:12 - move something into an S3 bucket so
227:14 - let's say I want to create a new S3
227:15 - bucket um we'll type in a ss3 and just
227:19 - hit enter and it should tell
227:21 - us um the sub commands may if I do like
227:23 - help like
227:28 - this and if we scroll on down so I guess
227:31 - it just pulls up documentation let's
227:33 - hoping it would give us like a tiny
227:37 - summary okay so what we can do here
227:40 - because I want to create a
227:41 - bucket type in like
227:43 - buckets if you don't know something you
227:45 - just go a S3 C create bucket we'll go
227:51 - here um and then what I do is I always
227:53 - just go to examples here so we have a S3
227:57 - API create bucket and I know it's
227:59 - unusual there's an S3 and there's an S3
228:01 - API I don't know why that is but it's
228:03 - always been that way and I I just don't
228:04 - question it anymore and so here I can go
228:07 - ahead and create a new bucket so I'll
228:08 - just go ahead and paste that command in
228:10 - I do want to change it up a bit here
228:12 - because this name could be that has to
228:14 - be unique so just to make sure I get
228:15 - what I want I'm putting random numbers
228:16 - in here we're going to choose the region
228:18 - as us East one if I wanted to do other
228:21 - things here I could scroll up and look
228:23 - at some Flags here
228:26 - so uh it looks all fine to me so I think
228:29 - I'll go back here and just
228:31 - hit uh
228:33 - paste okay and so it created that bucket
228:35 - for me if I go over to S3
228:43 - and we'll wait here a moment we can see
228:46 - that bucket now exists if I wanted to
228:48 - place something in that bucket what I
228:49 - can do is just like touch a file so I'll
228:50 - just say um touch touch is a Linux
228:52 - command to make just an empty file so
228:54 - we'll say um
228:57 - hello.txt and then it would be a S3
229:01 - um it would be SP to copy it and I'm
229:04 - going to give it the local path
229:05 - hello.txt and then I need to give it the
229:08 - bucket address so would be
229:10 - S3 slth bucket name so we named it this
229:15 - I'm not going to try to type that in by
229:17 - hand because it's too hard and then I
229:18 - want to say where I want to put this
229:20 - file so I'm going to say hello.txt and
229:22 - if I'm right that should work as
229:23 - expected and so it says I uploaded that
229:25 - file I make my way back over to S3 I
229:27 - refresh there is the file if I want to
229:30 - copy this file back locally um all I
229:33 - have to do I'm just going to remove I'm
229:35 - going to delete the original hello txt
229:37 - file LS to show you that there's nothing
229:40 - there and what I need to do oops is just
229:44 - revert this so instead of saying the
229:46 - address
229:48 - here we can go and type in
229:53 - hello.txt and if I do LS there's the
229:56 - file if you don't know what the address
229:57 - is of the bucket um a lot of times you
229:59 - can go here and find it so it should be
230:03 - because they're always changing this UI
230:04 - on me but we'll go to properties here
230:06 - and there that's the
230:08 - AR
230:10 - uh usually a good way to find it is if
230:11 - you go into an actual object so if you
230:13 - go here it'll give you the full URL so I
230:15 - could have grabbed that and I could have
230:16 - just pasted that in there um but you
230:19 - know you learn after time it's not hard
230:21 - to remember this S3 Co SL the unique
230:24 - name I do want to show you how to
230:26 - install it by hand so here I'm in git
230:28 - pods um I'm not sure how I can change
230:30 - this to a dark theme so I really don't
230:33 - like this on my eyes we'll go down below
230:35 - here to color
230:36 - theme and we'll say get dark there we go
230:41 - and so this is a temporary workspace so
230:43 - when I close it it'll be gone so that'll
230:44 - be totally fine and so I'm going to type
230:46 - in AWS to see that it's not installed
230:48 - we're going to go over here this runs
230:49 - Linux by default so I already know that
230:52 - I'm going to use Linux we want to use
230:53 - version two here um
230:56 - so for the latest version use this
230:59 - command for a specific version no we
231:01 - just want the generic one so I'm going
231:02 - to go ahead and copy this whoops yes
231:05 - allow we'll paste that in we'll hit
231:07 - enter okay then we'll take the next
231:12 - command paste that in hit enter we'll go
231:15 - take the next command
231:17 - here we'll hit
231:20 - enter you can now run uh AWS so we type
231:24 - AWS and there's the command so uh the
231:27 - only thing is that if we do ads S3 LS
231:30 - it's not going to work because we don't
231:31 - have any credentials set so we'll give
231:34 - it a moment to think so it says unable
231:36 - to locate credentials you can configure
231:38 - credentials by running ads configure so
231:40 - we type in ad
231:41 - configure and by the way if this font is
231:43 - too small I believe I can bump it up
231:46 - like
231:47 - this not a great way to do it but um it
231:52 - works and so it says ads access key ID
231:55 - so what we can do is go over to IM
231:59 - am and what I'm looking for is my
232:02 - particular user over
232:04 - here and if you remember when we first
232:07 - created our account it generated out
232:08 - access keys I go to security credentials
232:10 - and so we have a key here but I need the
232:13 - secret so this key is useless to me so
232:14 - I'm going to go ahead and deactivate
232:17 - it just because I don't even want this
232:20 - key and I'm going to create myself a new
232:22 - key so I'm going to have an access ID in
232:24 - secret when ever you generate these out
232:26 - never ever ever ever ever show anyone
232:28 - what these are these are your yours and
232:31 - yours alone okay so this is cloud shell
232:34 - we're fine we're just going to close
232:35 - that for now and I'm going to go back
232:38 - over to get pods here and hit enter so
232:40 - that's the ID I'm going to go grab the
232:44 - secret hit enter paste and I want it to
232:47 - go to us East one to save myself some
232:49 - trouble uh you can change the output
232:51 - from Json to tables I'm going to leave
232:53 - it as the default here and so now if I
232:55 - type ABS S3
232:58 - LS I get a list and so if I want to grab
233:01 - that file there I'm going to grab that
233:02 - S3 U and we type in a S3 API or sorry
233:07 - it's just LS sorry or sorry C
233:10 - and we're going to paste that link in
233:11 - and we're going to say
233:14 - hello.txt and I must have done the
233:15 - command wrong it's because we're missing
233:17 - S3 here I just hit up on the keyboard to
233:20 - get that command back and so I type in
233:21 - LS for list and I mean I have some other
233:24 - code here so you know again any repo you
233:26 - want on GitHub it doesn't really matter
233:28 - uh but you'll see there is that file
233:30 - probably shouldn't have used this one
233:31 - because it makes a bit of a
233:33 - mess um but yeah it's pretty
233:35 - straightforward just to one thing to
233:37 - show you is where those credal are
233:39 - stored so by default they're going to be
233:41 - stored in um it's going to be in the
233:46 - hidden directory in your root or your
233:48 - home directory called ad. credentials so
233:50 - if I just do like LS here you can see
233:53 - there's a config file and a credentials
233:54 - file cat lets me print out the contents
233:56 - of that file so I go here and it's
233:59 - saying the default region is Us East one
234:01 - this is a tomble file even though it
234:02 - doesn't have a do toml on the end of it
234:04 - I just know by looking at it that's what
234:05 - it is config lets you set uh defaults
234:08 - that are going to apply to all of your
234:09 - credentials and then uh within the
234:11 - credential file here is the actual
234:13 - credentials so if you wanted to just set
234:16 - them you could go in here and just set
234:18 - them in here you can also set multiple
234:20 - credentials so if I go here and I'm
234:22 - going to open up and buy because I'm not
234:24 - sure how to open it up here in the main
234:25 - one but if you wanted multiple accounts
234:27 - you do like exam Pro and then you just
234:30 - repeat these with different keys right
234:33 - and then when you wanted to use an a CLI
234:35 - command actually I'm going to go back
234:36 - here for a
234:37 - second
234:40 - okay and if you want to um and by the
234:45 - way I'm using VI never use Vim it's it's
234:48 - a bit tricky to use uh you might want to
234:50 - use Nano instead if you're if you're
234:51 - kind of new to this um because this will
234:54 - use like regular key key cuts and then
234:56 - down below it shows you what it is so
234:57 - this is like control X or alt X alt X
235:01 - NOP control X there we go um but anyway
235:03 - so if I go into this file and I delete
235:05 - the original one right and now I try to
235:08 - do
235:11 - um this command here even though we
235:14 - already have that file it should either
235:16 - hang or complain I Could Just Kill that
235:19 - by doing control C if I do ads S3
235:23 - LS notice that it's hanging so unable to
235:26 - locate credentials because there's no
235:27 - default one but if I go and I put
235:29 - profile and I say exam
235:33 - Pro all right it it'll now use that
235:36 - profile so that's the way we do it um
235:38 - but hopefully that gives you kind of a a
235:40 - crash course into the CLI um so yeah
235:44 - there you go okay so I'm just going to
235:46 - go ahead and close these off you can
235:48 - delete this bucket if you don't want it
235:51 - it's probably a good idea to delete this
235:53 - here and I'm just going to say
235:55 - permanently delete
235:57 - okay very very good okay close that off
236:01 - and yeah that's the introduction to the
236:02 - CL so yeah there you
236:07 - go
236:09 - [Music]
236:10 - hey this is Andrew Brown from exam Pro
236:12 - and we are taking a look at software
236:14 - development kits uh so a software
236:16 - development kit or SDK is a collection
236:18 - of software development tools and one
236:20 - installable package so you can use the
236:23 - AWS SDK to programmatically create
236:26 - modify delete or interact with aabus
236:28 - resources so the aabus SDK is offered in
236:30 - a variety of programming languages so we
236:33 - have Java python node.js Ruby go.net PHP
236:39 - JavaScript C++ and so here would be an
236:42 - example of some Ruby code where we are
236:45 - creating ourselves um an S3 bucket so
236:48 - we're just uploading a file there
236:50 - [Music]
236:54 - okay okay so now what I'm going to do is
236:56 - show you how to use the itus SDK and so
236:59 - uh to do that uh we're going to need
237:01 - some kind of IDE um a a basically code
237:04 - editor and so we had looked at get pods
237:07 - which is a third party service and
237:08 - that's fine but let's take a look at
237:09 - Cloud9 because that is built into AWS so
237:12 - if I just type in Cloud9 here and go
237:14 - over to IDE I'm going to launch myself a
237:16 - new environment so I'll hit create I'm
237:18 - going just say my SDK
237:22 - environment EnV if you if you have our
237:24 - time typing environment like me and we
237:27 - have some options so create a new C2
237:28 - instance for direct access create it via
237:31 - assistance manager run a remote with SSH
237:33 - I'm going to leave it as the default
237:34 - then we have the option to choose what
237:36 - size I want to leave it on T2 micro
237:38 - because that is the free tier then we're
237:40 - going to scroll on down we have Amazon
237:41 - Linux 2 Linux Ami I'm going to stick
237:44 - with Amazon Linux 2 and we can have it
237:47 - turn off after 30 minutes a great option
237:49 - for us here and we'll go ahead and hit
237:51 - next and we'll hit create
237:53 - environment and so we're going to have
237:55 - to wait a little bit for this to launch
237:57 - it'll take a few minutes as that is
237:59 - going let's go to Google type in adus
238:02 - SDK um to get to the main page and so
238:04 - the idea here is that there are a bunch
238:06 - of different languages you can use C++
238:09 - go Java javascript. net node.js PHP
238:12 - Python and Ruby uh and so I'm a really
238:15 - big fan of Ruby I've been using Ruby
238:17 - since 2005 and so that's what we're
238:18 - going to do it in it's also really easy
238:20 - to use and it's a really great language
238:23 - so um you know down below it's just
238:26 - showing you that there's all these
238:27 - different things but if we go down to
238:28 - the SDK here and we click on
238:31 - Ruby we we have examples where we have
238:33 - the developer guide the API reference
238:36 - and so this tells you how to get started
238:37 - even here it's saying like hey go get
238:39 - started with Cloud9 which is great as
238:41 - well I suppose um and so here it might
238:45 - show you how to install it um and when
238:48 - we open up the API references this is
238:50 - what it looks like so a lot of times
238:52 - when I want to do something I know it's
238:53 - like I want to do something with S3 so I
238:56 - scroll on down here and I look for
238:58 - S3
239:00 - right and then I just kind of like uh
239:03 - scroll around and look you know what I
239:05 - mean sometimes you have to expand it go
239:06 - into the client every API is a slight
239:08 - different so you do have to kind of
239:10 - figure out how to navigate that I'm
239:12 - actually under S3 right now so I'm
239:13 - looking for the client and I just know
239:16 - this for memory that this is where it is
239:17 - so first you create yourself a client
239:19 - and then you can do API operations so if
239:21 - I wanted to like list
239:23 - buckets I just search the word list and
239:25 - I just scroll on down and there it is I
239:27 - click into that and I have an example of
239:29 - how to list a bucket so I'm going to go
239:31 - back to Cloud9 and it is ready and it
239:33 - started in dark mode um if yours is not
239:35 - in dark mode which really honestly why
239:37 - wouldn't you want dark mode mode um if
239:39 - we go up to I think it's like file where
239:42 - is it preferences here got to C the
239:44 - Cloud9 option and I'm just seeing if it
239:48 - like remembers my settings I really like
239:50 - two two soft tabs here but uh there
239:53 - should be something for themes down
239:54 - below and
239:56 - so
239:58 - um that doesn't seem like that's it used
240:01 - to be like a oh here it is if you go
240:03 - here and just choose like whatever you
240:05 - want I'm on jet dark here and so if it's
240:07 - on classic light or something you don't
240:09 - like you can fix that there um but I'm
240:12 - just going to go here and just fiddle
240:13 - with my
240:14 - settings because I really like to use
240:17 - Vim uh keys I don't recommend this if
240:19 - you are uh to change this if you are not
240:22 - a programmer but I'm just going to
240:23 - change it so that I can type here
240:25 - efficiently so I'm just looking for the
240:28 - option
240:29 - here and they moved it on me where did
240:31 - they move
240:32 - it probably be like key
240:35 - bindings ah bin mode there we go again
240:37 - don't do that this is just for me so I
240:39 - can uh move around in a different way so
240:42 - what I want to do and by the way it
240:43 - looks like this default screen we could
240:45 - have just changed it here I just clicked
240:47 - through all that for nothing was here
240:48 - the entire time but um what we need is
240:52 - we need to make sure that we have our
240:53 - credentials so if we type in OS um S3 LS
240:57 - that's like my sanity check that I
240:58 - always like to do to make sure I have
241:00 - credentials notice that we didn't have
241:01 - to set up any credentials it was already
241:03 - on this machine which was really nice
241:06 - and so I'm going to create a new file
241:07 - here and it's okay if you don't know
241:09 - anything about Ruby we're just going to
241:11 - have fun here and just follow along so
241:12 - I'm going to do example. RB I'm going to
241:14 - make sure Ruby's install by doing Ruby
241:16 - Hy and V so it is install which is great
241:18 - uh you need a gem file so say new gem
241:21 - file
241:23 - here and if we go back to the
241:26 - installation guide uh we need the gem
241:29 - SDK
241:30 - here actually I'm going to look at how
241:32 - to generate a gem file gem file because
241:34 - there's some stuff that goes to the top
241:36 - of those files like this
241:39 - here I think we just need this line here
241:41 - so I'm just going to grab that whoops
241:44 - paste that in allow
241:47 - good and uh I you can do gem ads SDK
241:52 - that will install everything but uh we
241:54 - only want to work
241:56 - with S3 and so this is going to vary
241:59 - based on each language but I know that
242:00 - if we type in S3 we'll just get S3 and
242:02 - that's all we really need and so once we
242:05 - have that what we'll need to do is use a
242:06 - bundle install so we're going to make
242:08 - sure we're in the correct directory I'm
242:09 - going to type in LS down below notice
242:11 - the gem file is there and by the way if
242:13 - the fonts are too small I should
242:15 - probably bump those up let's see how we
242:17 - can do
242:19 - that uh editor size font user
242:28 - settings good luck trying to find a
242:31 - day um project
242:35 - no you think it'd have to be under user
242:37 - settings right
242:40 - ah here it is okay so um this is
242:43 - for probably the editor so we'll go to
242:45 - 18 here Co code editor
242:49 - here I'm I'm trying to find the one for
242:51 - the terminal probably over
242:53 - here there we
242:55 - go much easier okay so notice we have
242:58 - example. RB and Gem file so we're in the
243:00 - correct directory make sure I save that
243:02 - I'm going to type in bundle
243:04 - install that's going to install the gems
243:07 - give it a moment there it's going to
243:08 - fetch notice that installed um the ads
243:12 - sdks S3 and everything that it was
243:14 - dependent on and so now if we go over to
243:16 - our example. RB file really when you're
243:18 - coding for the cloud you can pretty much
243:20 - copy paste everything so over here we
243:23 - found this code here for S3 list buckets
243:26 - um so I'm going to go ahead and paste
243:28 - that on in okay and I know it looks
243:31 - really complicated but we can quickly
243:34 - simplify this so I know that this is
243:36 - just the output so I don't need that
243:39 - okay and in Ruby you don't need
243:40 - parentheses or curlies if uh if you
243:43 - don't have any things there and so all I
243:44 - need to do is Define a client so if I
243:47 - click uh if I go to the top here of this
243:50 - file I think we're in the client right
243:51 - now all the way to the top all the way
243:54 - to the top
243:55 - here that's what we need
243:59 - okay and so I'm going to paste that in
244:01 - now uh we can set the region here so I'm
244:04 - going to say Us East
244:05 - one right and then you'd have your cred
244:09 - um because the credentials are on the
244:11 - machine in the um uh credentials file
244:14 - they're going to autoload here I believe
244:16 - so I don't think I need to set them so
244:18 - I'm just going to take that out here for
244:20 - a
244:21 - second okay and I can do this if I want
244:24 - this is just slightly different syntax
244:25 - it might be easier to read if I do it
244:26 - this way for
244:28 - you okay and I don't need double client
244:32 - there so we have the client I like to
244:33 - name this like S3 so I know what it is
244:36 - and I put puts for the response FS I'm
244:39 - going to do
244:40 - inspect and so puts is like print okay
244:43 - and so now if I type in bundle exact
244:46 - let's just make sure that it's in the
244:47 - context of our bundler file Ruby
244:49 - example. RB um we have a syntax error on
244:53 - this line here unexpected thing
244:56 - here oh it's because of this it's
244:59 - because I commented out so I'm just
245:00 - going to do curly parentheses comment
245:02 - out
245:03 - here
245:05 - okay actually to make it a bit easier
245:07 - I'm just going to bring this down like
245:10 - this okay and we'll paste that
245:14 - there okay and we'll try this
245:17 - again un initialized constants ad to oh
245:20 - yeah we have to require it so we have to
245:21 - require ABS SDK S3 I think we'll hit
245:28 - up and uh we got a struck back so it is
245:31 - working we are getting an object back if
245:34 - we want to play around with this a bit
245:35 - more I'm just going toall another gem
245:37 - called pry pry allows us to um inspect
245:40 - code so we're going to do bundle install
245:42 - and I'm going to go back to Ruby here
245:44 - I'm going to put a binding pry in
245:47 - here and then if I hit up and I do
245:51 - bundle EXA Ruby example.
245:53 - RB um I installed it right B install
246:00 - yes undefine method
246:03 - pry oh because I have to require it
246:06 - again bad habit here
246:09 - okay we'll hit up and so now I have an
246:13 - interactive shell and I can kind of
246:14 - analyze that object so we have a
246:15 - response so if I type in RSP here I have
246:18 - the structure object I can type in
246:20 - buckets here okay and it's showing me a
246:22 - bucket I can give it get its
246:25 - name
246:27 - um oh I think it's an array so I think
246:30 - I'd say like I'd say like zero here or I
246:33 - could say first this is just the how the
246:34 - Ruby language works we say name I get
246:36 - the name creation date okay so you get
246:40 - the idea whatever you want to do you
246:43 - know you search for it you just say I
246:44 - want to delete a bucket I want to create
246:46 - a bucket right and you look for it so I
246:48 - say create bucket here I click on this
246:52 - and I can see the options and they are
246:54 - always really good about giving me an
246:55 - example and then down below they always
246:57 - tell you all the parameters that you
246:58 - have there so that's how the SDK Works
247:02 - uh but yeah the credentials were uh soft
247:03 - loaded here but you could easily provide
247:05 - them yourself I should just show you
247:07 - that before anything else just cuz
247:09 - there's some variations there
247:12 - um and I'm just trying to look for it
247:14 - because it is separate
247:18 - code so you could do this this is one
247:20 - way of doing it so you could do it
247:22 - separate from the code so if you only
247:23 - wanted to configure it
247:25 - once right because you could you could
247:27 - have a lot of clients you wouldn't want
247:28 - to keep on like for each client you
247:30 - wouldn't want to put region in every
247:31 - time so I could take this and put this
247:34 - right here
247:36 - okay and this this is the file here
247:38 - where we have the credentials so this
247:40 - would be our um our access key and our
247:43 - ID and so you never want to put your
247:47 - code directly just in here so if I open
247:49 - up if you go cat you would never want to
247:52 - do this but I'm just going to show as an
247:54 - example
247:55 - here uh
247:57 - credentials oops I got to get out of
247:58 - this
248:00 - exits
248:03 - credentials oh do they not even show it
248:05 - on this machine which would be smart we
248:07 - wouldn't really want to see our
248:08 - credentials here uh hit up say
248:11 - LS oh no it's there
248:14 - okay cat
248:17 - whoops
248:20 - credentials there it is okay so you know
248:23 - if we look here we can see that there
248:24 - are credentials set it's a little bit
248:26 - different we have this like session
248:27 - token I guess it's to make sure that
248:29 - this expires over time but if I was to
248:31 - take these okay and I was just to paste
248:34 - them in
248:36 - here
248:42 - that's one way you would do it um you
248:44 - never ever want to do this ever ever
248:46 - ever ever you never want to do this
248:48 - because you'll end up committing that to
248:49 - your code um so this is really dirty to
248:52 - do so I don't ever recommend to do it um
248:55 - if you wanted to have this apply to
248:57 - everything you could put it up here and
248:58 - so now when we call the client we don't
249:01 - have to do it um of course if the
249:04 - they're loaded on the machine you don't
249:05 - have to do it the other thing is like if
249:06 - you if you want you could load them in
249:09 - Via environment variables that's usually
249:11 - what you want to do so you say adabs uh
249:13 - access
249:15 - key right and then we say environment
249:19 - databus access
249:21 - secret and so you'd set those by doing I
249:24 - think it's like an
249:25 - export um environment
249:28 - variables set in Linux you think I know
249:32 - after like 15 years of doing this but I
249:33 - never remember so you type in export so
249:36 - you go down into oops here you type in
249:39 - export and you just say something like
249:41 - I'm going to just show an example to see
249:43 - if it works so I'm going to say hello
249:45 - world okay and if I do uh hello like
249:48 - that Echo see it prints it out so that's
249:52 - how you would set it you'd set those
249:53 - there but there's actually very specific
249:56 - ones that aabus uses for um the API and
249:59 - it's these ones here so you always want
250:01 - to use
250:02 - those okay so you put that in
250:05 - there and that in there but of course
250:09 - you know like if they're already set in
250:10 - your machine you don't have to even
250:11 - specify those cuz it would autoload
250:13 - those environment variables I don't
250:15 - think they're set right now if we type
250:16 - in Echo just take a look here is are
250:18 - they going to get autoloaded
250:20 - here no so but anyway so we could go
250:24 - here just as an
250:27 - example and well actually they just show
250:29 - them right here so you see your access
250:30 - key but we go and we type in um
250:34 - export and I'm going to paste the key in
250:36 - there and I'm going to go to the the
250:37 - front of it we're typee adus access key
250:40 - ID
250:42 - equals enter and so now if I did echo on
250:45 - this ads access key ID okay shows up but
250:50 - I just want to show you how it can kind
250:51 - of vary and those conditions around it
250:53 - so yeah that is the adus SDK um and yeah
250:56 - a lot of times you're just copying
250:57 - pasting code and just kind of tweaking
250:59 - it you're not really writing uh real
251:01 - programming okay so hopefully that is
251:02 - less intimidating so I'm just going to
251:03 - close these off and I want to close down
251:06 - this Cloud9 environment
251:09 - um I might have to reopen this up in
251:11 - another
251:12 - Tab and go to the Management console
251:15 - here and then go over to Cloud9 and just
251:18 - close this tab and then while go ahead
251:20 - as and delete this environment oops I'll
251:22 - just type delete here even if you didn't
251:25 - it would turn off after 30 minutes and
251:26 - you have that free tier so it's not that
251:28 - big of a deal it's up to you whether you
251:30 - want to use Cloud9 or git pods Cloud9 is
251:32 - really good because it allows you to um
251:36 - uh it allows you to uh use it runs on a
251:40 - virtual machine right so you have a a
251:43 - container runtime there and so it's very
251:45 - easy to run containers on it um whereas
251:47 - in like I've had some issues with G pods
251:49 - but um yeah those are the two
251:52 - [Music]
251:55 - okay let's take a look at adus Cloud
251:58 - shell which is a browser based Shell
252:00 - built into the adus Management console
252:02 - and so Cloud shell is scoped per region
252:04 - it has the same credentials as the loged
252:06 - in user and it's a free server so this
252:07 - is what it looks like and the great
252:09 - thing about this is that you know if you
252:11 - have a hard time setting up uh your own
252:14 - shell or terminal on your computer um or
252:17 - maybe you just don't have access or
252:18 - privilege to do so it's just great that
252:20 - Abus makes this uh available to you and
252:23 - so what you can do is click the shell
252:24 - icon up at the top and that will expand
252:26 - this here some things to note about
252:28 - Cloud shell is that it has some
252:29 - pre-installed tools so it has the CLI
252:32 - python nodejs git make pip pseudo tar
252:35 - t-x Vim W get vim and more it includes 1
252:39 - gab of storage free per adus region it
252:42 - will save your files in a home directory
252:44 - available for future sessions for the
252:46 - same Aus region uh and it can support
252:49 - more than a single shell environment so
252:51 - it has bash Powers shell and
252:54 - zsh um and so Adis Cloud shell is
252:56 - available in select regions so when I
252:58 - was in my Canada region I was like
253:00 - where's the little shell icon but I
253:01 - realize it's limited for some areas
253:06 - okay
253:08 - [Music]
253:09 - hey this is Andrew Brown from exam Pro
253:11 - and we are taking a look at
253:12 - infrastructure as code also known as IAC
253:15 - and this allows you to write a
253:16 - configuration script to automate
253:18 - creating updating or destroying your
253:20 - Cloud infrastructure the way you can
253:22 - think of I it's a blueprint of your
253:24 - infrastructure and it allows you to
253:26 - easily share version or inventory your
253:28 - Cloud
253:28 - infrastructure so adus has two different
253:31 - offerings for IAC the first is cloud
253:35 - formation uh a com commonly abbreviated
253:38 - to CFN and this is a declarative IC tool
253:41 - and then you have a cloud development
253:43 - kit commonly known as cdk which is an
253:45 - imperative IAC tool so let's just talk
253:47 - about the difference between declarative
253:49 - and imperative and then we'll look at
253:50 - these tools a little bit closer uh each
253:53 - okay so declarative means what you see
253:55 - is what you get it's explicit it's more
253:57 - verose but uh there is zero chance of
253:59 - misconfiguration unless the file so big
254:01 - that you're missing something uh
254:03 - commonly declarative files are written
254:05 - things like Json yaml X ml so for cloud
254:08 - formation it's just Json and yaml uh and
254:10 - so that's that side there so for
254:12 - imperative you say what you want and the
254:14 - rest is filled in so it's implicit uh
254:16 - it's less forbose you could end up with
254:18 - some misconfiguration that's totally
254:20 - possible uh but it does more than
254:22 - declarative and you get to use your
254:23 - favorite programming language maybe
254:25 - python JavaScript actually cdk does not
254:28 - support Ruby right now but I just have
254:29 - that in there just as a general
254:31 - description of what imperative is
254:36 - okay
254:38 - all right so just a quick look at cloud
254:39 - formation so cloud formation allows you
254:41 - to write infrastructures code as either
254:43 - Json or yaml the reason why was adus
254:45 - started with Json and then everybody got
254:47 - sick of writing Json and so they
254:49 - introduced jaml which is a lot more
254:51 - concise which you see on the right hand
254:52 - side so cloud formation is simple but it
254:55 - can lead to large files or is limited in
254:57 - some regards to creating dynamic or
254:59 - repeal infrastructure compared to cdk
255:01 - Cloud information can be easier for
255:03 - devops engineers who do not have a
255:04 - background in web programming languages
255:06 - a lot of times they just know scripting
255:08 - and this basically is scripting since
255:10 - cdk generates out Cloud information it's
255:12 - still important to be able to read and
255:13 - understand Cloud information in order to
255:15 - debug IAC Stacks knowing cloud formation
255:18 - is kind of a cloud essential when you go
255:21 - into the other tiers of AWS um like
255:23 - Solutions architect associate
255:24 - professional or any of the associates
255:26 - you need to know Cloud information
255:27 - inside and out
255:29 - [Music]
255:33 - okay okay so what I want to do now is
255:36 - introduce you to infrastructure as code
255:39 - and so we're going to take a look at
255:40 - cloud formation and so we were just
255:42 - using Cloud9 for the STK so we're going
255:44 - to go back and create ourselves a new
255:45 - Cloud9 environment because we do have to
255:47 - write uh some code so I'll go ahead and
255:49 - hit create here and I'm going to just
255:51 - say uh CFN that's sort for cloud
255:53 - formation example and we'll hit next
255:56 - step and we'll create ourselves a new
255:58 - environment T2 micro Amazon X2 is
256:01 - totally fine we'll hit next it'll delete
256:03 - after 30 minutes we'll be fine we're
256:05 - within the free tier we're going to give
256:06 - this a moment to load up um and remember
256:09 - you can set your theme your your
256:11 - keyboard mode whatever you want as that
256:13 - loads and as that's going we're going to
256:14 - look up cloud formation and so cloud
256:18 - formation is very intimidating at first
256:21 - but once you get through the motions of
256:22 - it it's not too bad um so we'll go to
256:25 - the user guide here as we always do if
256:27 - you go to the getting
256:29 - started it's going to just tell us some
256:31 - things it's going to read about yaml
256:33 - files um I don't think I really need to
256:35 - read much about this here here so I
256:37 - think we'll just go start looking up
256:38 - some codes so something that might be
256:40 - interesting to launch as an ec2 instance
256:42 - Cloud information so that's what I'll do
256:44 - is I'll type in what I want so in ec2
256:46 - instance and I'll just start pasting in
256:48 - code so if we scroll on down below
256:51 - here going to go to examples because I
256:53 - want a small example here this is
256:55 - something that I might want to do and
256:57 - we're going to give that a moment here
256:59 - it's almost
257:01 - done you can do it ad come on as that is
257:04 - going I'm going to open a new tab
257:07 - I'm going to make my way over to cloud
257:10 - formation
257:14 - okay and um you can see I have some
257:17 - older Stacks here notice Cloud9 when we
257:20 - create an environment actually creates a
257:22 - cloud formation stack which is kind of
257:24 - interesting um but if we go here we can
257:28 - create a stack and we can create a file
257:30 - and uploaded here
257:32 - so okay this is good I'm going to go
257:34 - ahead and make a new file we're going to
257:37 - call it
257:38 - template. yaml um just so you know yaml
257:42 - can be yml or Y ml there's a big debate
257:46 - as to which one you use um I think that
257:48 - adabs likes it when you use the full
257:50 - version so I just stick with
257:54 - yl I'm going to double click into that
257:57 - and so in the cc2 example I'm just going
257:59 - to copy this okay and I'm going to paste
258:02 - this in
258:03 - here and I'm going to type in resources
258:07 - oops
258:10 - capital okay so that's a resource I want
258:12 - to create um when you create Cloud
258:16 - information you always have a template
258:17 - version so I just
258:20 - need a basic example here at the
258:24 - top I guess that's a simple one is like
258:26 - a Hello World
258:29 - Bucket maybe we should do a bucket
258:31 - because it'll be a lot
258:34 - easier we don't have to make our life
258:36 - super hard here okay um but what I'm
258:40 - looking for is the version because
258:42 - that's the first thing that you
258:44 - specify I'm just trying to find it
258:46 - within an example
258:49 - here oh for freak's sakes cloud
258:52 - formation
258:53 - version if I don't have the format
258:55 - version it's going to complain there it
258:56 - is okay so we'll copy that we'll go back
259:00 - over
259:01 - here we'll paste that in there it might
259:04 - be fun to do like an output here so I'm
259:05 - going to do like an out put
259:08 - outputs and uh maybe instead of doing
259:11 - this we'll type in ads
259:13 - S3 C
259:16 - formation because what I'm looking for
259:18 - is what we can set as output so we'll
259:20 - say return values
259:23 - here
259:26 - um maybe we just
259:29 - want Returns the domain
259:31 - name so we'll just say
259:35 - um
259:38 - value ref that that's going to get the
259:40 - reference for it and we have to say
259:42 - hello
259:45 - bucket uh type
259:51 - string say outputs cloud formation
259:55 - example and even though I've written
259:57 - tons of cloud formation it's just like
259:59 - if you're not doing it on day and day
260:00 - out you start to forget what it is so
260:03 - here for outputs we need a logical ID
260:05 - description value and export
260:07 - so um that is what I want so I'm going
260:10 - to go ahead and copy that back
260:12 - here this is just so that when we run it
260:15 - we're going to be able to observe an
260:16 - output from the cloud formation file
260:19 - okay so the logical ID is whatever we
260:20 - want so hello bucket
260:24 - domain it's funny because this is how
260:25 - you do do um kind of that would be the
260:28 - format for terraform I was getting the
260:29 - mixed up so the
260:32 - domain of the bucket the value here is
260:35 - going to be ref
260:39 - hello
260:41 - bucket domain
260:47 - name that's the
260:50 - output export value to
260:56 - export uh can I get an example
261:02 - here B
261:05 - name oh you know what export is for uh
261:08 - cross Stacks we don't need to do that
261:09 - okay so that's fine so what we'll do is
261:11 - set that and we'll take out our old one
261:14 - and so this should create us an S3
261:15 - bucket so with Cloud information you can
261:18 - uh provide a template here by providing
261:20 - a URL or you can upload a file directly
261:23 - so um I'm just trying to decide here how
261:26 - I want to do this you can also use a
261:28 - sample file or create a template in the
261:30 - designer I'm going to go over to the
261:32 - designer because then we can just like
261:34 - paste in what we want so if I go over to
261:36 - yes enel here and we go back over here I
261:39 - copy
261:40 - this I'm just going to paste this in
261:44 - here and we're going to hit the refresh
261:46 - button nobody ever uses the designer but
261:48 - this is just kind of a easy example for
261:50 - me to uh place this in
261:58 - here it's not really working maybe I got
262:01 - to go to template dude here
262:04 - refresh there we go so there's our
262:06 - bucket it's nice to have a little
262:08 - visualization and I believe this is
262:10 - going to work as expected so now that we
262:12 - have our designer template I think if we
262:14 - hit close what's this button say
262:17 - validate template probably a good idea
262:18 - validating the template template
262:21 - contains errors unresolved resource
262:22 - dependency uh in the output block of the
262:24 - template
262:26 - hello domain
262:30 -  seems like it should be
262:34 - fine let's go
262:37 - whoops let's go back over
262:40 - here that's what I did I said reference
262:43 - that
262:45 - value oh uh maybe it's get a trib
262:49 - okay it's get ATT
262:53 - sorry get a tri cloud formation can't
262:57 - remember there's an r on the end of it
262:59 - oh it's just ATT this is if you're
263:00 - trying to get a return intrinsic value
263:03 - so a reference is like what the default
263:05 - one is but when every time we do like a
263:06 - logical name and attribute that's how we
263:08 - get that there so uh what I'm going to
263:10 - do here is just hit refresh and I'm
263:12 - going to validate that one more time now
263:15 - it's valid if I hover over this is going
263:17 - to upload it create the
263:19 - stack we could save this save
263:22 - it oh we can save it an S3 bucket so
263:24 - we'll say
263:26 - hello bucket and so now we have this URL
263:30 - so I'm going to copy it honestly I never
263:32 - use this editor so it's kind of
263:33 - interesting I'm going to leave
263:37 - and we probably could have hit create
263:38 - stack but I just find it a bit easier if
263:39 - we just kind of do it through uh this
263:41 - here so go back create the stack we're
263:43 - going to paste in the URL we're going to
263:45 - say
263:46 - next and we're going to say uh my new
263:50 - stack and I didn't see what the name of
263:52 - the bucket was oh there's no name so
263:55 - it's going to randomize that's perfect
263:57 - so we'll go next we have a bunch of
263:59 - options here we'll H hit
264:01 - next we'll give it a moment here I guess
264:03 - we have to review it create the stack
264:05 - and this the part where we watch so it
264:07 - says create in progress and we wait and
264:09 - we hit
264:11 - refresh and we can see what's happening
264:14 - trying to create a
264:17 - bucket and if we go to resources this is
264:20 - this is a lot easier to track because
264:21 - you can see all the resources that are
264:22 - being
264:29 - created if you notice that when you use
264:31 - the C uh when you're using database
264:33 - management cons and create S3 bucket
264:34 - it's instantaneous but like with cloud
264:36 - there's a bit of delay because there's
264:37 - some communication going on board but
264:39 - here it is and notice if we go to our
264:41 - outputs this is the the value of the
264:43 - bucket domain name if we were to make it
264:45 - with uh self-hosting which is not what
264:47 - we're doing with it we could also have
264:48 - an export name which would be used for
264:50 - cross referencing Stacks which is not
264:51 - something we uh care to do um but yeah
264:54 - that's how you create a stack that way
264:57 - um but you know we can also do it via
264:59 - the SDK here so what I can do um is look
265:05 - up what is the Adis uh CLI cloud
265:08 - formation CU they have their own
265:10 - commands here if I go
265:12 - here there's a new one and there's an
265:14 - old one
265:17 - so if we go create
265:21 - stack yeah there's things like this like
265:23 - create stack
265:24 - update um so if we wanted to do it this
265:30 - way okay and I copied this here just
265:34 - going to put this in my read me here for
265:35 - a second
265:38 - uh so here what you do is you say my new
265:41 - stack and you can provide the template
265:44 - URL or you could specify the local path
265:47 - here so we have like a template body so
265:49 - I'm going to go ahead and grab
265:52 - that okay this would be like
265:55 - yaml and um I need to specify this file
265:59 - here so template.
266:02 - yaml and I'm just going to go PWD here
266:06 - to get the full path
266:09 - okay and I'm going just paste that in
266:11 - there
266:13 - whoops okay I'm going to do LS okay so
266:16 - that gives us the full path to the file
266:18 - we can also specify the template URL um
266:21 - and so this should work as well if I
266:23 - take this and paste that on as a
266:28 - command unable to locate parameter file
266:31 - oh there's three three triple slashes
266:33 - there we'll just fix that
266:35 - there
266:37 - paste unable to load pram file no such
266:41 - file directory and there's a t
266:44 - missing okay be like don't be like me
266:47 - and make sure you don't have spelly
266:49 - mistakes okay I can type clear down here
266:51 - so I can see what I'm doing we'll hit
266:53 - enter
266:55 - whoops unable to load the parameter file
266:57 - no such file or
267:00 - directory home well I you didn't want
267:03 - the for slash so another we can try to
267:06 - do I think it will take it relative so
267:08 - if I do this it should
267:11 - work I don't ever remember having to
267:13 - specify the entire path and error
267:15 - occurred while calling the create stack
267:17 - my stack name already exists if I go
267:19 - back over here give this a refresh oh
267:21 - that's what we named our stack the the
267:23 - one that we did so I'm going to say
267:24 - stack
267:25 - two
267:28 - okay template format unsupported
267:31 - structure when calling the create stack
267:34 - operation
267:36 - are you kidding me I do this all the
267:39 - time template body yaml file cloud
267:48 - formation unsupported structure take a
267:51 - look
267:57 - here oh you know what I think uh this
268:00 - one's out of date that's why so what we
268:02 - can do is go to our old stack here and
268:04 - we can actually see the temp I can go
268:06 - ahead and copy this whoops and we can go
268:08 - ahead and paste that in there and then
268:10 - now what I can
268:12 - do so you know that's that's the reason
268:14 - why it wasn't working okay so we'll hit
268:17 - enter um unsupported
268:20 - structure it should be
268:25 - supported let's see if Cloud information
268:26 - can help us
268:28 - out um apparently there was very
268:30 - unhelpful error message formatting so
268:32 - try the validate template option I
268:35 - wonder if if we could just do
268:37 - this maybe if that would help
268:40 - here I'm just hitting up to try to run
268:42 - it
268:43 - again nope I guess we can try to
268:45 - validate it here it's like I'm not
268:48 - having much luck here
268:50 - today so we'll just say this here maybe
268:53 - it's not even loading that file where it
268:59 - is so there's no
269:04 - errors
269:07 - just going to make this one
269:14 - line okay created so for whatever reason
269:17 - I must have had a a bug there and so
269:19 - putting sometimes putting on one line
269:20 - helps that out because I must have had
269:22 - an obvious mistake there and now we can
269:24 - see the stack is creating it's doing the
269:26 - exact same thing it's creating a
269:28 - different bucket though if we go over to
269:29 - our S3
269:33 - here again you know you don't need need
269:35 - to be able to do this yourself to pass
269:38 - the exam it's just so I'm just trying to
269:40 - show you like what it is so you kind of
269:41 - absorb any kind of knowledge about
269:43 - what's going on here notes down below it
269:45 - uses the stack name followed by uh the
269:47 - re The Logical name of the resource
269:49 - there okay um and what we'll do is wait
269:52 - for that to create once that's created
269:54 - we can go ahead and delete these Stacks
269:56 - we could also use the a cloud
269:57 - information to say like delete stack but
269:59 - I don't want to uh bore you with that
270:02 - today and so we'll hit refresh here wait
270:05 - for those to
270:07 - vanish okay those are gone uh what I'm
270:10 - going to do is kill this Cloud9
270:11 - environment uh if there's a way to do it
270:13 - from here I have never known how to do
270:15 - it go back to your dashboard well that's
270:18 - nice to know we'll go ahead and just
270:19 - delete
270:22 - this okay we'll close that Tab and so
270:25 - now we are all in good shape and so that
270:27 - was our introduction to Cloud
270:30 - information
270:31 - [Music]
270:34 - okay let's take a look here at cdk so
270:37 - cdk allows you to use your favorite
270:39 - programming language to write
270:40 - infrastructure as code and technically
270:42 - that's not true because they don't have
270:44 - Ruby and that's my favorite but anyway
270:46 - uh some of the languages include NOS
270:48 - typescript Python
270:50 - java.net and so here's an example of
270:52 - typescript typescript was the first
270:54 - language that was um introduced for cdk
270:56 - It's usually the most upto-date so not
270:59 - always does cdk reflect exactly what's
271:01 - in cloud formation but I think they're
271:03 - getting better at that okay so cdk is
271:05 - powered by cloud formation it generates
271:07 - out cloud formation templates so there
271:09 - is an intermediate step it does
271:11 - sometimes feel a bit slow so I don't
271:12 - really like that but you know it's up to
271:14 - you uh cdk has a large library of
271:16 - reusable Cloud components called cdk
271:18 - constructs at constructs dodev this is
271:20 - kind of the concept of terraform modules
271:22 - and is really really useful uh and
271:24 - they're really well ridden um and they
271:26 - can just reduce a lot of your effort
271:28 - there CD cdk comes with its own CLI um
271:31 - and I didn't mention this before but
271:33 - cloud formation also has its own uh uh
271:35 - CLI okay cdk pipelines uh are are allow
271:39 - you to quickly set up cicd pipelines for
271:41 - cdk projects that has a big pain point
271:44 - for cloud formation where you have to
271:45 - write a lot of code to do this whereas
271:47 - um this cdk has that off the bat makes
271:50 - it really easy for you cdk also has a
271:53 - testing framework for unit and
271:54 - integration testing I think this might
271:56 - be only limited to typescript because I
271:57 - didn't see any for the rest of the
271:58 - languages but um you know I wasn't 100%
272:01 - sure there uh this one thing about cdk
272:04 - is that it can be easily uh confused
272:06 - with SDK because they both allow you to
272:09 - programmatically work with AWS uh using
272:12 - your favorite language but the key
272:13 - difference is that cdk ensures uh itap
272:16 - poent of your infrastructure so what
272:19 - that means that's such a hard word to
272:21 - say but what that means is that um you
272:25 - know if you use this cdk to say give me
272:28 - an a virtual machine you'll always have
272:30 - a single virtual machine uh because it's
272:33 - trying to manage the state of the file
272:35 - whereas
272:36 - uh when you use SDK if you run it every
272:37 - time you'll end up with more and more
272:39 - servers uh and it's not really managing
272:41 - States so hopefully that is clear
272:42 - between the difference
272:44 - [Music]
272:47 - there okay so we looked at cloud
272:49 - formation but now let's take a look at
272:51 - cdk cloud formation or cloud formation
272:53 - Cloud development kit it's just like
272:55 - cloud formation but you use a a
272:57 - programming language in order to uh
272:59 - Implement your infrastructure as a code
273:01 - I don't use it very often I don't
273:03 - particularly like it but um you know if
273:04 - you are developer and you don't like
273:06 - writing Cloud information files and you
273:08 - want to have something that's more
273:09 - programmatic you might be used to that
273:11 - um this I think should be deleting cuz
273:13 - we were deleting the last one here and
273:14 - notice how it's grayed out I can't
273:15 - select it so don't worry about that
273:17 - create a new one we'll say cdk example
273:20 - we'll hit next T2 micro ec2 instance
273:24 - Amazon X2 you know the drill it's all
273:26 - fine here we're going go ahead and
273:27 - create ourselves a new environment we're
273:29 - going to let that spin up there and as
273:31 - that's going we're going to look up uh
273:33 - adus
273:34 - cdk so it was cdk um and we probably
273:38 - want to go to GitHub for
273:41 - this okay because it is open source and
273:44 - so I want to go to getting
273:47 - started and I have used this before but
273:49 - I never can remember how to use it
273:51 - probably the easiest way to uh use this
273:53 - is by using
273:55 - typescript
273:57 - so here's an example initialize a
273:59 - project make directory cdk oh first we
274:01 - got to install it right so we give that
274:04 - a moment so this is you know how we did
274:06 - like bundle install this is like the
274:08 - same thing but for uh typescript install
274:11 - or update the itus cdk CLI from npm we
274:14 - recommend using this version etc etc so
274:18 - again we're just waiting for that to
274:19 - launch but uh as we wait for that it's
274:22 - very simple we're just going to install
274:24 - it create a directory um go into that
274:27 - directory initialize the example here
274:29 - it's setting up an
274:32 - sqsq which is um that's quite a complex
274:35 - example um but you can see it's code
274:37 - right and then we run cdk deploy and
274:39 - we'll deploy it and then hopefully we'll
274:41 - have that
274:42 - resource so again we're just waiting for
274:48 - Cloud9 there we go so Cloud9 is more or
274:51 - less ready a terminal seems like it's
274:54 - still
274:55 - thinking and we have a JavaScript one
274:57 - which I do not care about there we go
274:59 - there's our environment we're going to
275:00 - make sure we have mpm so we can type in
275:03 - mpm great it says version
275:07 - 8.1.0 and so this is asking for
275:11 - 10 okay I don't know if this gives us
275:13 - like MVM installed MVM it does so what
275:17 - we can do is do MVM list that stands for
275:19 - node version manager Ruby has one as
275:21 - well and so it's telling us what version
275:23 - we're on I want to update um looks like
275:26 - we have a pretty uh pretty new version
275:28 - but what I want is the latest version of
275:31 - oh but that's node version that's not
275:33 - necessarily mpm so we'll do node version
275:35 - Oh 17 okay we're well well in the uh
275:39 - range of the new stuff so what I'm going
275:40 - to do is scroll on down we're going to
275:42 - grab this link here or this uh code here
275:45 - hit enter and that's going to install
275:47 - the adus cdk so it
275:50 - says uh file already exists oh so maybe
275:53 - it's already installed in the
275:57 - machine um cdk we'll type in
276:01 - cdk because of course adus wants to make
276:03 - it very easy for us this soft has not
276:05 - been tested with what was that warning
276:08 - uh with node 1701 you may encounter
276:11 - runtime issues great AWS you're like the
276:13 - one that installed this stuff here so we
276:14 - get a bunch of the commands which is
276:16 - great and so what we'll do is follow
276:18 - their simple instructions we'll say
276:20 - hello
276:21 - cdk we will CD into
276:24 - this and um now what we can do is run
276:29 - cdk andit and this language
276:33 - here and so that's going to do a bunch
276:35 - of stuff creates tons of files it's
276:37 - going to vary based on what you're using
276:40 - like which language because cdk comes
276:43 - available in a variety of languages so
276:45 - if we type in ads
276:46 - cdk um documentation
276:52 - here notice up here python java.net so I
276:57 - think it has more than just those three
276:59 - languages but um you know I wish it
277:02 - supported more like yeah see here is C
277:05 - Java but I I really wish there was a
277:09 - ruby so we'll give this a moment here to
277:12 - get installed and I will see you back
277:14 - here when it is done
277:18 - okay okay uh it turns out I only had to
277:21 - wait like a second there but it says
277:23 - there's a newer version of the cdk you
277:24 - probably should install it but I just
277:27 - want to get going here so as long as I
277:29 - don't run into any issues I do not care
277:31 - um but anyway so looking at this and I
277:34 - again rarely ever look at this but I'm a
277:36 - developer so it's not too hard for me to
277:38 - figure out but under the lib this is our
277:40 - stack that we're creating and here is it
277:42 - is loading in sqs it's loading in SNS
277:46 - and then the core Library it's creating
277:47 - an sqs q and it's setting the visibility
277:50 - of that timeout it's also creating an
277:52 - SNS topic so those are two resources
277:54 - that we expect to be created if we
277:57 - scroll on down to the getting started it
277:59 - just says cdk deploy so what we'll do is
278:02 - go ahead and hit enter
278:05 - and let that do whatever it wants to
278:11 - do and it is thinking there we go so
278:14 - here we have IM statement changes so
278:16 - it's saying this deployment will
278:18 - potentially make potential sensitive
278:19 - changes according to your current
278:21 - security approval options there is there
278:23 - may be security related changes not in
278:25 - this list do you want to deploy sure
278:27 - we'll hit
278:29 - Y deploying creating Cloud information
278:32 - change set so cdk is using cloud
278:34 - confirmation underneath it's not
278:39 - complicated um and as that is going what
278:41 - we'll do is we'll make our way over to
278:43 - our itus amazon.com
278:46 - console and if we go over to cloud
278:49 - formation we'll see if we see anything
278:54 - yet so it's creating a stack here we can
278:56 - click into it we can go over to our
278:58 - events see that things are being created
279:00 - this is always a confusing so I always
279:02 - go to resources to see what is
279:03 - individually being created and they're
279:05 - all done so we go over here and they
279:07 - exist so here it says that we have a
279:11 - queue called this right sometimes they
279:14 - have links you can link through it so
279:16 - notice here I can click on the topic and
279:18 - get to that resource in SNS which is
279:20 - nice for sqs I'm just going to type in
279:22 - sqs
279:25 - enter uh and there it is okay so we
279:28 - don't really understand what those are
279:29 - we could delete the stack this way
279:31 - there's probably a cdk way to delete the
279:33 - stack so uh cdk
279:38 - destroy I assume that's what it
279:41 - is destroy okay so we'll type in cdk
279:50 - Destroy give it a moment we're going to
279:53 - say
279:57 - yes okay it's deleting in progress we
280:00 - can even go back here and double
280:03 - check
280:11 - still
280:19 - thinking and again you know if we
280:21 - deleted these for real it would take
280:22 - like a second but uh you know sometimes
280:25 - they're just
280:28 - slow sometimes it's because a resource
280:30 - can get hung as well um but uh I don't
280:33 - think anything is problem so here we can
280:36 - see what the problem is not not
280:38 - necessarily a problem but it's just the
280:39 - sqs is taking a long longer time to
280:42 - delete where the SNS subscription is a
280:44 - lot
280:52 - faster so I'll just see you back here in
280:54 - a moment okay okay so after a short
280:56 - little wait there it finally finished uh
280:58 - I just kept on refresh until I saw it
281:00 - deleted and so it's out of there and so
281:02 - we'll get rid of our Cloud9 environment
281:03 - since we are done with it so type in
281:06 - Cloud9 up at the
281:08 - top and we'll go ahead and delete and we
281:11 - will go ahead and delete this here thank
281:15 - you and we will go back to our adabs
281:18 - amazon. console here just so we can get
281:20 - our bearing straight here and there we
281:24 - [Music]
281:28 - go all right let's take a look here at
281:30 - the adus toolkit for vs code so adus
281:32 - toolkit is an open source plugin for vs
281:34 - code to create debug deploy itus
281:36 - resources since vs code is such a
281:38 - popular uh editor uh these days I use
281:41 - Vim but it's very popular um I figured I
281:44 - should make sure you're aware of this um
281:46 - plugin so it can do four things you get
281:48 - the Abus Explorer this allows you to
281:50 - explore a wide range of adus resources
281:52 - linked to your adus account uh and
281:55 - sometimes you can view them sometimes
281:56 - you can delete them it's going to vary
281:58 - per service and what's available there
282:00 - then you have the adabs cdk Explorer
282:02 - this allows you to explore your Stacks
282:04 - defined by cdk uh then you have Amazon
282:06 - elastic uh container service ECS this
282:09 - provides intellisense for ECS task
282:12 - definition files intell sense means that
282:14 - when you type uh and you uh you'll get
282:16 - like autoc completion but you'll also
282:17 - get a description as to what it is that
282:19 - you're typing out then there is servess
282:22 - applications and this is pretty much the
282:23 - main reason to have Theus toolkit allows
282:26 - you to create debug deploy Serv
282:28 - applications via S and CFN and so uh
282:31 - there you can see the command pallet and
282:32 - you can kind of access stuff there okay
282:35 - [Music]
282:39 - let's take a look here at access key so
282:41 - an access key is a key and secret
282:43 - required to have programmatic access to
282:45 - adus resources when interacting with the
282:47 - adus API outside of the adus Management
282:50 - console so uh access key is commonly
282:53 - referred to as adus credentials so if
282:55 - someone says adab credentials generally
282:56 - you're talking about the access key not
282:58 - necessarily your um username and
283:01 - password to log in so a user must be
283:04 - granted access to use access key so when
283:06 - you're creating a user you can just
283:08 - checkbox access key um you can always do
283:11 - this after the fact but it's good to do
283:12 - that as you're creating the user and
283:14 - then you can generate an access key and
283:16 - secret so you should never share your
283:18 - access keys with anyone they are yours
283:20 - if you give them to someone else is like
283:22 - giving them the keys to your house it's
283:23 - dangerous uh never commit access keys to
283:26 - a codebase uh because that is a good
283:28 - place uh for it to get leaked at some
283:30 - point you can have uh two active keys at
283:33 - any given time you can deactivate access
283:36 - Keys obviously delete them as well
283:38 - access Keys have whatever access a user
283:40 - has to Aus resources so uh you know if
283:43 - you can do it in databus Management
283:44 - console so can the key so access keys
283:47 - are to be stored in the ads. adabs
283:50 - credentials uh file so um and if you're
283:53 - not familiar with Linux this Tilda here
283:56 - this actually represents your home
283:57 - folder so whether you're on Windows or
283:59 - Linux that's going to be your home
284:01 - folder and then you have this period AWS
284:03 - that means it's hidden folder but you
284:05 - can obviously access it and so in it
284:07 - it's just a toml like file I think it's
284:10 - toml um but I never 100% verified that
284:14 - it's toml it looks just like toml uh and
284:16 - so what you'll have here is your uh
284:18 - default profile and so this is what you
284:21 - would use um or this is what uh any of
284:23 - your tools you use like the CLI or
284:25 - anything else would automatically use if
284:28 - um if you did not specify a profile you
284:31 - can of course store multiple access keys
284:34 - and then give it a profile name um so if
284:37 - you are doing this for the first time
284:38 - you might just want to type in ad config
284:40 - and it'll prompt you and you'll just
284:41 - enter them in there as well I think
284:43 - that's set the default one when you're
284:44 - using the
284:45 - SDK uh you would rather probably use
284:48 - environment variables because this is
284:50 - the safest way to access them when you
284:53 - are writing code all right um so there
284:55 - you
284:56 - [Music]
285:00 - go all right let's talk about access
285:02 - Keys access keys are are very important
285:03 - to your
285:04 - um and so what we'll do is go to IM if
285:06 - you are the root user you can go in and
285:08 - you can uh generate access keys for
285:10 - people um but generally you're doing it
285:13 - yourself for your own account so I go to
285:14 - users I'm going to click into mine here
285:17 - and we'll go over to Security
285:18 - credentials and here you're going to
285:19 - notice access keys and one thing that is
285:22 - interesting is that you can only ever
285:23 - have two access keys at a time so if I
285:25 - hit create I'm just going to close that
285:27 - notice that the button is gray out I can
285:30 - uh uh deactivate them if I feel that I
285:32 - haven't used them in a while and I can
285:35 - make them active again so I can bring
285:36 - them back into access or what I can do
285:39 - is um make them
285:41 - inactive right and then I can delete
285:44 - them and so what I recommend right even
285:48 - if you do not want to programmatically
285:50 - be using your account for anything you
285:52 - always want to fill up both these and
285:54 - the reason why and this is for security
285:56 - reasons is that if somebody wanted to
285:58 - come in and uh uh get into your account
286:02 - what they would do is they would try to
286:03 - find find a user um where they have
286:06 - access to them and then they would try
286:08 - to generate out a key so if both these
286:10 - keys are taken up so if you generate up
286:12 - both these
286:13 - Keys okay and this is the one you want
286:15 - to use you deactivate the other one okay
286:17 - we're not going to use that one and so
286:19 - now there's no way for them to fill up
286:21 - that other slot okay and so that is my
286:24 - strong recommendation to you but there's
286:26 - again only ever two here I'm just going
286:28 - to uh Delete both of these so that when
286:32 - we want to uh do what whatever next in a
286:34 - tutorial we'll go generate that out okay
286:37 - go ahead and clear that
286:39 - out so hopefully that is enough for you
286:43 - to understand what to do with these
286:45 - access Keys okay so I'm going to go back
286:48 - here there you
286:50 - [Music]
286:54 - go let's take a look here at adus
286:57 - documentation which is a large
286:58 - collection of technical documentation on
287:00 - how to use adus Services which we can
287:02 - find at doc. adab. amazon.com uh and so
287:06 - this is kind of like the landing page
287:07 - where you can see all the guides and API
287:09 - references if you expand them in there
287:11 - uh into ec2 and you click on the user
287:13 - guide you can see HTML in PDF format
287:16 - Kindle and you'll notice there's a link
287:18 - to GitHub and that's because all of
287:19 - these docks are open source and you can
287:21 - contribute to them if you choose to do
287:22 - so I've done so multiple times in the
287:25 - past it's quite fun so adus is very good
287:27 - about providing detailed information
287:28 - about every ad service and the basis of
287:31 - this course and any AD certification
287:32 - will derive mostly from
287:34 - uh the adus documentation so I like to
287:37 - say that I'm not really coming up with
287:39 - new information I'm just taking what's
287:41 - in the docs and trying to make it more
287:43 - digestible and I think that's the thing
287:44 - is like the docks are really good you
287:46 - can read them end to end but they are
287:48 - very dense um and so it can be a bit
287:51 - hard to figure out what you should read
287:52 - and what you should not um but uh they
287:54 - are a really great resource and you
287:56 - should spend some time in there
287:58 - [Music]
288:01 - okay so I just want to quickly show you
288:03 - the ads documentation like give you a
288:05 - bit of a tour of it so if we go to ab.
288:08 - amazon.com and type in docs and I'm sure
288:10 - you might have seen this through other
288:12 - tutorials but the idea is that you have
288:14 - basically documentation for basically
288:16 - any possible service that you want and a
288:18 - lot of times you'll click into it and
288:20 - what you'll get are these little boxes
288:21 - and they'll show you different guides
288:23 - and it's going to vary based on service
288:25 - but a lot of times there's a user guide
288:27 - there's an API reference those are the
288:29 - two that you'll see there maybe we go to
288:31 - something simpler like
288:33 - S3 that might be a simple example yeah
288:35 - user guide API API reference and so all
288:38 - of these are on GitHub right if you open
288:40 - these up the documentation is here if
288:42 - you find something you don't like you
288:44 - can submit issues and uh and correct
288:47 - things you can even submit your own
288:48 - examples I have um I have uh committed
288:52 - uh example code to the uh docs
288:55 - specifically for AI services so you
288:57 - might be looking examples that I
288:58 - implemented or even Ruby examples since
289:00 - I really like to promote Ruby on AWS you
289:03 - can as a PDF or you can take it as an
289:05 - HTML a lot of times you're going to the
289:07 - user guide and the way I build the
289:09 - courses here is I actually go through
289:11 - and I read these end to end so you know
289:13 - if you wanted to do that and you wanted
289:14 - to be like me uh you can do that or you
289:16 - can just watch my courses and save
289:18 - yourself the trouble and not worry about
289:20 - everything that is here but generally
289:22 - the documentation is extremely extremely
289:24 - good there are some exceptions like
289:26 - Amazon Cognito where the content is good
289:29 - but it's just not well organized so I
289:31 - would say it best out of every other
289:33 - provider they they have the most
289:35 - complete documentation uh they generally
289:37 - don't keep their examples or like
289:39 - tutorials within here it's usually
289:41 - pretty light they'll have some examples
289:43 - um but like they like they have adus
289:45 - Labs separately so you type Aus Labs
289:47 - GitHub right you go here and a lot of
289:50 - stuff is in here instead so you have a
289:52 - lot of great tutorials and examples over
289:55 - there okay um but yeah pretty much
289:58 - that's all there is to it is there
289:59 - consistency between documentations no
290:01 - they kind of vary um you know but uh
290:04 - it's all there is my point and they're
290:06 - always keeping up to date so yeah that's
290:08 - all you need to know about the inabus
290:11 - [Music]
290:14 - documentation hey this is Andrew Brown
290:16 - from exam Pro and we are taking a look
290:18 - at the Shared responsibility model which
290:20 - is a cloud security framework that
290:22 - defines the security obligations of the
290:24 - customer versus the cloud service
290:26 - provider in this case we're talking
290:27 - about AWS and they have their own shared
290:29 - responsibility model it's this big ugly
290:31 - blob here um and the thing is is that
290:34 - every single CSP has their own variant
290:36 - on the model uh so they're generally all
290:39 - the same but some visualizations make it
290:41 - a little bit uh easier to understand or
290:43 - they kind of uh include a little bit
290:45 - more information at different parts of
290:46 - it and so just to get make sure that you
290:49 - have well rounded knowledge I'm going to
290:50 - go beyond the aws's shared
290:52 - responsibility model and just show you
290:54 - some variants uh there's also variants
290:56 - not just per uh CSP but also the type of
290:59 - cloud deployment model and sometimes
291:01 - these are also scoped uh based on a
291:03 - cloud service category like compute or
291:04 - machine learning and these can result in
291:07 - specialized share responsibility models
291:09 - so that's what we'll look at in this
291:10 - section
291:11 - [Music]
291:15 - okay all right so let's take a look at
291:17 - the ad shared responsibility model and
291:19 - so I've reworked the graphic because it
291:21 - is a bit hard to uh digest and so I'm
291:24 - hoping that this way will be a little
291:25 - bit easier for you I cannot include the
291:27 - in and of here just because we're
291:28 - limited for space but don't worry we'll
291:29 - follow that up with the next slide here
291:31 - so there are two people that are
291:33 - responsible or two um organizations that
291:35 - are responsible the customer and AWS and
291:38 - on aws's side they're going to be
291:39 - responsible for anything that is
291:42 - physical so we're talking about Hardware
291:44 - Global infrastructure so the regions the
291:46 - availability zones The Edge locations
291:48 - the physical security so think of all
291:50 - that Hardware that's there those data
291:52 - centers um everything like that then
291:55 - there's also software the services that
291:57 - they're offering and so um you know this
291:59 - extends to all their services but
292:00 - generally it breaks down to the four
292:02 - core and so we're talking about Compu
292:04 - storage database and networking okay and
292:06 - when we say networking we're talking
292:08 - about like physically setting up the
292:10 - wires and also you know the software to
292:12 - set up the routing and all that kind of
292:13 - stuff there uh now looking at the
292:15 - customer side of it they're responsible
292:17 - for configuration of managed services or
292:19 - thirdparty software so the platforms
292:22 - they use so whether they choose to use a
292:24 - particular type of os uh the
292:26 - applications so if they want to use like
292:28 - Ruby on Rails uh am so identity and
292:31 - access management so if you uh create a
292:34 - user and you grant them permissions if
292:36 - you give them things they're not
292:37 - supposed to have access to that's on you
292:39 - right then there's configuration of
292:40 - virtual infrastructure and systems so
292:42 - that would be choosing your OS that
292:44 - would be uh the networking so there
292:46 - could be networking on the um uh the
292:49 - virtual machines themselves or we could
292:51 - be talking about Cloud networking in
292:53 - this case then there are firewalls so
292:55 - we're talking about virtual firewalls
292:56 - again they could be on the virtual
292:58 - machine or it could be configuring like
293:00 - knackles or security groups on AWS then
293:02 - there's security config ation of data uh
293:05 - and so there is client side data
293:07 - encryption so if you're moving something
293:08 - from S3 from your local machine to S3
293:11 - you might need to encrypt that first
293:12 - before you send it over then there's
293:14 - server side encryption so that might be
293:15 - turning on server side encryption within
293:18 - S3 or turning it encryption on your EBS
293:21 - volume then there's networking traffic
293:23 - protection so you know that's turning on
293:25 - VPC flow log so you can monitor them
293:27 - turning on it was guard Duty so that it
293:30 - can detect anomalies with your traffic
293:32 - or or activities within your um adus
293:36 - account and then there's customer data
293:37 - so that's the data that you upload on
293:39 - the behalf of your customers or yourself
293:42 - and what you decide to um you know like
293:44 - what levels of sensitivity that you want
293:46 - to lock it down do you want to use
293:48 - Amazon Macy to see if there's any public
293:51 - facing uh personally identifi
293:53 - information that's up to you so there's
293:55 - a lot here and honestly it's a lot
293:57 - easier than you think um instead of
293:59 - thinking about this big diagram what I
294:01 - do is I break it down into this and so
294:03 - we have the in and the of and that's
294:04 - what I said I could not fit on the um
294:07 - previous slide there the idea is
294:09 - customers are responsible for the
294:10 - security in the cloud so that's your
294:13 - data and configuration so if it's data
294:15 - that's resigning on there or there
294:17 - something you can configure you are
294:18 - responsible for it on the ad side they
294:21 - are responsible for the security of the
294:23 - cloud so if it's anything physical or
294:25 - Hardware the operation of managed
294:27 - services or Global infrastructure that's
294:29 - going to be on them and this in and of
294:31 - thing is very important for the exam so
294:33 - you should absolutely know the
294:34 - difference between the two this is kind
294:36 - of an adist concept I don't see any
294:38 - other cloud service provider talking
294:39 - about in and of uh so you definitely
294:41 - need to know it
294:43 - [Music]
294:46 - okay so one variant we might see for the
294:50 - uh shared responsibility model would be
294:52 - on the types of cloud computing this
294:54 - could also be applicable to the types of
294:56 - uh deployment models but we're doing
294:58 - types of cloud computing here and so we
295:00 - have the customers responsibility and
295:02 - then the cloud service provid
295:03 - responsibility so we're seeing on
295:05 - premise infrastructure as a service
295:08 - platform as a service and software as a
295:10 - service and so when you are on Prem
295:14 - you're basically responsible for
295:15 - everything apps data runtime middleware
295:18 - OS virtualization servers storage
295:20 - networking basically everything and just
295:23 - by adopting the cloud you're almost
295:26 - cutting your responsibilities in half
295:27 - here so now the cloud service provider
295:30 - is going to be responsible for the
295:31 - physical networking uh the physical
295:34 - storage those physical servers and
295:37 - because they're offering virtual
295:38 - machines to you they're setting up a
295:40 - hypervisor uh on your behalf so
295:42 - virtualization is taking care for you
295:44 - and so um you know if you launch an ec2
295:47 - instance you know you're going to have
295:48 - to choose the OS so that's why you're
295:50 - responsible whatever middleware there
295:52 - the runtime so whatever kind of programs
295:54 - you install on it uh the data that
295:56 - resides on it and any kind of like major
295:58 - applications okay then we have platform
296:01 - as a service uh and so you know the
296:04 - cloud service provider is going to take
296:05 - even more responsibility there so when
296:07 - we're talking about this we're thinking
296:08 - like a elastic beant stock right so you
296:11 - know the you just choose what you want
296:13 - and it's all managed so you might say I
296:14 - want a ruby on rail server but you're
296:16 - not saying what OS you need um you're
296:19 - not uh saying exact you might say what
296:22 - version of Ruby you want but you don't
296:23 - have to manage it if it breaks uh or it
296:25 - might be managed updates and things like
296:27 - that the last thing here is like
296:29 - software as a service and this is
296:31 - something where the CSP is responsible
296:33 - for everything so if you're thinking of
296:35 - a of a software as a service think of
296:37 - like Microsoft Word where uh you're just
296:39 - writing uh you know writing stuff in
296:42 - there and you know you you are
296:44 - responsible for where you might choose
296:46 - to store your data but the data is like
296:49 - still handled by the cloud service fider
296:51 - because you know it's on the cloud so on
296:53 - their servers right um so yeah hopefully
296:55 - that gives you kind of an idea across
296:57 - types of cloud U Computing
297:02 - responsibilities
297:03 - [Music]
297:05 - all right so what I want to do here is
297:07 - just shift the lens a bit and look at
297:09 - the share responsibility model if we
297:10 - were just uh observing a subset of cloud
297:14 - services such as compute and so we're
297:17 - going to see infrastructures of service
297:18 - platform as a service software as a
297:20 - service and now we have function as a
297:22 - service and so that's what I mean when
297:23 - we shift the lens we get new information
297:26 - uh and so you can just see that you
297:27 - really don't want to look at this uh
297:29 - from one perspective okay so starting at
297:31 - the top here we have bare metal uh and
297:33 - so ad's offering is called the ec2 bare
297:36 - metal instance and this is where you
297:38 - basically get the whole machine uh you
297:41 - can configure the entire machine with
297:43 - with the exception of the physical
297:44 - machine itself so as the customer you
297:46 - can install the host OS um uh the host
297:49 - OS so the operating system that runs on
297:51 - the physical machine and then you can
297:53 - install your own hypervisor um and then
297:56 - Aus is going to be responsible for the
297:57 - rest the physical machine now normally
298:00 - The Next Step Up would be dedicated but
298:02 - dedicated doesn't exactly give you more
298:04 - responsibility it gives you more
298:05 - Assurance because it's a single tenant
298:08 - uh virtual machine and that's why I kind
298:10 - of left it out here um but we'll see it
298:12 - in the next slide that it is kind of on
298:13 - the model and shares the same spot as uh
298:16 - ec2 um but ec2 is a virtual machine and
298:19 - so um here the customer is responsible
298:23 - for the guest OS so that means that you
298:25 - can choose what OS you want whether it
298:27 - is Ubuntu or Debian or Windows but
298:31 - that's not the actual OS that is running
298:32 - on the the physical machine and so
298:34 - you're not going to have control of that
298:36 - ads is going to take care of that then
298:38 - there's the container runtime so you
298:40 - know you you can install Docker on this
298:43 - or any kind of container layer that you
298:44 - want um so that's another thing that you
298:47 - can do so ads is going to be responsible
298:48 - for the hypervisor uh the physical
298:50 - machine and the host OS all right then
298:54 - looking at containers it has more than
298:56 - one offering for containers but we'll
298:57 - just look at ECS here and so um this is
299:01 - where you are going to uh have uh you
299:04 - don't you don't install the guest OS
299:06 - right the guest OS is already there for
299:08 - you what you are going to do is choose
299:10 - your configuration of containers you're
299:13 - going to uh deploy your containers
299:15 - you're going to determine where you need
299:17 - to access storage for your containers or
299:20 - attach storage to your containers and
299:22 - databus is going to be responsible for
299:24 - the guest OS it it the and there might
299:27 - not even be a guest OS but there the
299:29 - host OS the guest OS the hypervisor the
299:32 - container runtime uh and you're just
299:34 - responsible for your containers okay
299:37 - then going to the next level here we
299:38 - have platform as a service and so this
299:41 - one also is a little bit odd where it
299:43 - fits um because the thing is is that
299:45 - this could be using anything underneath
299:47 - it could be using containers it could be
299:49 - using virtual machines um and so that's
299:52 - where it doesn't exactly fit well on a
299:54 - linear graph but let's just take a look
299:55 - at some things here so this is where
299:57 - you're just uploading your code uh you
300:00 - have some configuration of the
300:01 - environment you have options of
300:03 - deployment strategies um the
300:05 - configuration of the associated services
300:07 - and then Abus is going to be responsible
300:08 - for the servers the OS the networking
300:10 - the storage the security so it is taking
300:13 - on more responsibility than
300:14 - infrastructures a service um uh whereas
300:17 - you know itus is just going to be
300:19 - responsible for that so if it's a
300:20 - virtual machine that it's being under uh
300:22 - under the use the is going to be
300:24 - responsible for this customer stuff okay
300:26 - you're not if it's containers then AIS
300:28 - is going to be responsible for this but
300:29 - it just depends on how that platform as
300:31 - a service is set up actually the way
300:33 - elastic beanock is set up is that you
300:34 - actually have access to all that
300:36 - infrastructure and you can fiddle with
300:37 - it and so in that case um whereas like
300:40 - if you were to use Heroku which is a a
300:42 - third party provider um you know they
300:44 - would take care of all this stuff up
300:46 - here um and so you would not have to
300:47 - worry about it but on AWS you actually
300:49 - are responsible for uh the underlying
300:52 - infrastructure because you can you can
300:54 - configure it you can touch it so that's
300:56 - where you know again these do not fit
300:58 - perfectly you can't look at platform as
300:59 - a service meaning that um you're not
301:01 - responsible for certain things it really
301:03 - comes down to the service offering okay
301:06 - then we're taking a look at software of
301:07 - service so on AWS um this is going to be
301:10 - something like um Amazon workdocs which
301:12 - is I believe a competitor uh not a very
301:15 - popular competitor but a competitor to
301:18 - Microsoft SharePoint and this is for
301:19 - Content collaboration so as the customer
301:22 - you're responsible for the contents of
301:23 - the document management of the files
301:25 - configuration of sharing access controls
301:27 - and the databas is responsible for the
301:29 - servers the OS networking the the
301:30 - storage the security and everything else
301:33 - so you know if you use a Microsoft Word
301:34 - Doc and you type stuff in it you say
301:36 - where to save it that's what you're
301:37 - responsible for okay the last one here
301:39 - on the list is our uh functions here and
301:42 - so ad's offer is itus Lambda and so as
301:45 - the customer all you're doing is you're
301:46 - uploading your code and itus is going to
301:48 - take care of the rest so deployment
301:50 - container runtime networking Storage
301:51 - security physical machine basically
301:54 - everything um and so you're really just
301:57 - left to uh develop okay so you know
301:59 - hopefully that gives you kind of an idea
302:01 - and again you know we could have thrown
302:02 - in a a few other services like what we
302:04 - could not fit on this slide here was um
302:08 - uh adus fargate which is a serverless
302:11 - container as a function or sorry
302:13 - serverless uh serverless container as a
302:15 - service or container as a service so uh
302:17 - you know that has its own unique
302:19 - properties in the model as well okay so
302:21 - let's just have kind of a visualization
302:23 - on a linear graph here so we have the
302:25 - customers's responsibility on the Le
302:26 - hand side and adus is responsibility on
302:28 - the right and we'll look at our broad
302:29 - category so we got bare metal dedicated
302:32 - virtual machine Mach containers and
302:34 - functions and so no matter uh which uh
302:38 - type of compute you're using you're
302:40 - always responsible for your code for um
302:43 - containers you know if uh you know like
302:46 - uh the functions when you're using
302:47 - functions there are pre-built containers
302:50 - so you say I want to use Ruby and
302:52 - there's a ruby container and you don't
302:54 - have to configure it but obviously um
302:56 - you know when you are using container
302:58 - service you are configuring that
302:59 - container you are responsible for it for
303:01 - um virtual machine you know you're
303:03 - responsible for the runtime so you can
303:05 - install a container runtime on there or
303:07 - install a bunch of different packages
303:09 - like Ruby and stuff like that uh the
303:11 - operating system you have control over
303:13 - in the virtual machines for the
303:14 - dedicated and we saw with bare metal you
303:16 - have both uh controls of the host OS and
303:19 - the guest OS and then only bare metal
303:22 - allows you to have control of the
303:23 - virtualization where you can install
303:25 - that hypervisor so hopefully that gives
303:27 - you an idea of compute and A's offering
303:29 - there and also kind of how there's a lot
303:31 - of little caveats when we're looking at
303:33 - the Shared responsibility model
303:35 - [Music]
303:39 - okay all right so I have one more
303:41 - variant of the share responsibility
303:42 - model and this one is actually what is
303:44 - used by Google so um we're going to
303:46 - apply to AWS and uh see how it works so
303:49 - let's just kind of redefine share
303:50 - responsibility model or just in a
303:52 - slightly different way so we fully
303:53 - understand it so the share
303:55 - responsibility model is a simple
303:56 - visualization that helps determine what
303:58 - the customer is responsible for and what
304:00 - the CSP is responsible for related to
304:02 - AWS and so across the top we have
304:05 - infrastructure as a service platform as
304:07 - a service software as a service but
304:09 - remember there's other ones out there
304:10 - like functions and service it's just not
304:11 - going to fit on here um okay so and then
304:15 - uh along the side here we have content
304:17 - access policies usage deployment web
304:20 - application security identity operations
304:24 - access and authentication network
304:26 - security remember that's Cloud
304:27 - networking security the guest OS data
304:29 - and content audit logging now we have
304:32 - the the actual traditional networking or
304:34 - physical networking storage and
304:35 - encryption and here we're probably
304:37 - talking about the physical storage
304:39 - hardened kernel IPC uh the boot the
304:43 - hardware and so then here we have our
304:46 - bars so we have the csp's responsibility
304:48 - and the customer responsibility so when
304:49 - we're looking at a SAS software as a
304:52 - service uh the customer is going to be
304:54 - responsible for the content remember
304:55 - like think of like a word processor
304:56 - you're writing the content the access
304:58 - policies like say I want to share this
304:59 - document with someone the usage like how
305:02 - you UTI it can you upgrade your plan
305:04 - things like that then next on our list
305:06 - here is platform as a service so
305:08 - generally uh you know platform is a
305:10 - services for developers to De develop
305:12 - and deploy applications and so they will
305:15 - generally have more than one deploy
305:17 - strategy and uh you know there might be
305:19 - some cost-saving measures to choose like
305:22 - uh you might have to pay additional for
305:23 - security uh or you it's up to you to
305:26 - configure in a particular way or you
305:27 - might have to integrate it with other
305:29 - services uh and you know we saw that
305:31 - pass is not a perfect uh definition or
305:34 - fit because you know when we look at
305:35 - elastic bean stock if you have access to
305:37 - those resources and you can change them
305:39 - underneath then you might have more
305:42 - responsibility there than you think that
305:43 - you would okay the next one here is
305:46 - infrastructure the service and so this
305:48 - is extending to Identity so who's
305:50 - allowed to uh you know log into your
305:53 - adabs account uh operations the things
305:56 - that they're allowed to do in the
305:57 - account access and authentication do
305:59 - they have to use MFA uh things like that
306:02 - networ security obviously you can
306:03 - configure the security of your uh Cloud
306:06 - infrastructure or Cloud Network um you
306:08 - know so you know do you isolate
306:10 - everything a single VPC how do you set
306:12 - up your security groups things like that
306:14 - uh we know with virtual machines you can
306:16 - set up the guest OS there's data and
306:18 - content but remember that bare metal is
306:20 - part of the uh infrastructure service
306:22 - offering and so that's where we'd see
306:24 - Hardware or not Hardware but you'd have
306:26 - the host o the host Os or virtualization
306:29 - and so this again is not a perfect
306:31 - representation uh but it generally works
306:33 - okay and then last and list there um or
306:36 - just looking at what the ads is
306:39 - responsible for auto logging so of
306:41 - course adus has cloud trail which is for
306:43 - uh uh logging uh API um events but Auto
306:48 - logging could be things that are uh
306:49 - internally happening with those physical
306:51 - servers then the networking the physical
306:53 - storage uh Harding the kernel ad of us
306:56 - has I think what's called the Nitro
306:57 - system where they have like a security
306:58 - chip that's uh installed on all their
307:01 - servers then it's the the boot OS uh and
307:04 - then the hardware itself okay so just
307:07 - remember the customer is responsible for
307:09 - the data and configuration of access
307:11 - controls that reside in AWS so if you
307:14 - can configure it or you can put data on
307:16 - it you're responsible for it okay the
307:18 - customer is responsible for the
307:20 - configuration of cloud services and
307:21 - granting access to users via permissions
307:23 - right so if you give uh one of your
307:26 - employees access to do it um you know
307:29 - even if it's their fault it's your fault
307:31 - so remember that um and again the CSP is
307:34 - generally responsible for the underlying
307:36 - infrastructure we say generally because
307:37 - you know there's edge cases like bare
307:39 - metal and coming back to adses in the
307:42 - cloud and of the cloud so in the cloud
307:44 - so if you configure it or store it then
307:46 - you the customer are responsible for it
307:48 - and of the cloud if you cannot configure
307:50 - it then the CSP is probably responsible
307:53 - for it
307:55 - [Music]
307:58 - okay hey this is Andrew Brown from exam
308:01 - Pro and we are looking at the share
308:02 - responsibility model from the
308:03 - perspective of architecture and if
308:06 - you're getting sick of share
308:07 - responsibility model don't worry I think
308:08 - this will be the last uh slide in this
308:10 - section but let's take a look here so uh
308:13 - we have uh less responsibility more
308:15 - responsibility at the bottom so what we
308:17 - have down here is traditional or virtual
308:19 - machine architecture so Global Workforce
308:22 - is most familiar with this kind of
308:23 - architecture and there's lots of
308:24 - documentation Frameworks and support so
308:26 - maybe this would be using elastic
308:28 - beanock with platform as a service or
308:30 - using ec2 instances alongside with Auto
308:32 - scaling groups uh code deploy uh load
308:35 - balancers things like that the next
308:37 - level here is microservices or
308:39 - containers this is where you mix and
308:40 - match languages better utilization of
308:42 - resources so maybe you're using fargate
308:44 - which is seress containers or elastic
308:46 - container service or elastic kubernetes
308:48 - service for containers and at the top
308:51 - here we have serverless or commonly with
308:53 - functions as a service so there are no
308:55 - more servers you just worry about the
308:57 - data or uh and the code right so
308:59 - literally just functions of code and so
309:01 - you could be using the amplify serus
309:03 - framework or maybe aess Lambda for
309:05 - creating servess architecture so there
309:07 - you
309:08 - [Music]
309:11 - go hey this is Andrew Brown from exam
309:13 - Pro and we are looking at Computing
309:15 - Services and before we jump into uh the
309:18 - entire Suite of Computing Services they
309:20 - us have let's just talk about ec2 for a
309:22 - moment which allows you to launch
309:24 - virtual machines so what is a virtual
309:26 - machine while a virtual machine or VM is
309:28 - an emulation of a physical computer
309:30 - using software server virtualization
309:33 - allows you to easily create copy resize
309:35 - or migrate your server multiple VMS can
309:37 - run on the same physical server so you
309:39 - can share the cost with other customers
309:41 - so imagine if your server or computer
309:43 - was an executable file on your computer
309:45 - okay so that's the kind of way you want
309:47 - to think about it when we launch a VM uh
309:50 - we call it an instance and so ec2 is
309:52 - highly configurable server where you can
309:54 - choose the Ami so the Amazon machine
309:56 - image that affects options such as
309:58 - amount of CPUs or vcpus virtual CPUs the
310:02 - ount of memory so Ram the amount of
310:04 - network bandwidth the operating system
310:06 - so whether it's Windows Ubuntu Amazon L
310:09 - 2 uh the ability to attach multiple
310:12 - virtual hard drives for storage so
310:14 - elastic Block store um and so the Amazon
310:17 - machine image is a predefined
310:18 - configuration for AVM so just remember
310:21 - that and so ec2 is also considered the
310:24 - backbone of ads because the majority of
310:25 - AD services are using uc2 as the
310:28 - underlying servers whether it's S3 RDS
310:30 - 10B or lambdas that is what it's using
310:33 - so um what I say also it's just because
310:36 - when we talk about the it Network that
310:37 - is the backbone for uh Global
310:39 - infrastructure uh and the networking at
310:42 - large and so ec2 is for the services
310:46 - [Music]
310:50 - okay hey this is Andrew Brown from exam
310:53 - Pro so we just looked at what ec2 is
310:55 - well let's look at more of the broader
310:56 - services for computing and these are the
310:58 - more uh common ones that you'll come
311:00 - across there's definitely more than just
311:02 - what we're going to see on this single
311:03 - slide here so we'll break this down with
311:05 - virtual machines containers and then
311:06 - serverless for for virtual machines
311:08 - remember that's an emulation of a
311:09 - physical computer using software and ec2
311:12 - is the main one uh but for our VM
311:15 - category we have Amazon light sale this
311:17 - is a manage virtual server service it is
311:20 - the friendly version of ec2 virtual
311:21 - machines so when you need to launch a
311:23 - Linux or Windows server but you don't
311:25 - have much Aus knowledge you could launch
311:27 - a WordPress here and uh you could hook
311:29 - up your domain and stuff like that um so
311:32 - this is a very good option for beginners
311:34 - we have containers so virtualizing an
311:36 - operating system or Os to run multiple
311:38 - workloads on a single OS instance so
311:40 - containers are generally used in
311:42 - microservice architecture when you
311:44 - divide your application into smaller
311:46 - applications that talk to each other so
311:48 - here we would have ECS elastic container
311:50 - service this is a container
311:52 - orchestration service that supports
311:54 - Docker containers launches a cluster of
311:56 - servers on these two2 instances with
311:57 - Docker installed so when you need
311:59 - Dockers a service or you need to run
312:01 - containers we have elastic container
312:04 - registry ECR this is a repository of
312:06 - container images so in order to launch a
312:09 - container you need an image an image
312:11 - just means a save copy a repository just
312:14 - means a storage that has Version Control
312:17 - we have ECS fargate or just fargate now
312:21 - people are kind of forgetting that it's
312:22 - it runs on ECS these days that's why I
312:24 - have it in there it is a serverless
312:26 - orchestration container service is the
312:29 - same as ECS ex except you pay pay on
312:32 - demand per running container so with ECS
312:35 - you have to keep a ec2 server running
312:38 - even if you have no containers running
312:39 - so it manages the underlying server so
312:42 - you don't have to scale or upgrade the
312:44 - ec2 server so there's the advantage over
312:46 - ECS okay then we have elastic kubernetes
312:49 - service eks this is a fully managed
312:51 - kubernetes service kuber or so
312:53 - kubernetes commonly abbreviated to K8 is
312:56 - an open-source orchestration software
312:58 - that was created by Google is generally
313:00 - the standard for managing microservices
313:02 - so when you need to run kubernetes as a
313:04 - service then we have serverless category
313:07 - so when the underlying servers are
313:08 - managed by Deus you don't worry or
313:11 - configure servers cus Lambda is a
313:13 - serverless function service you can run
313:15 - code without provisioning or managing
313:17 - servers you upload small pieces of code
313:19 - choose much uh how much memory how how
313:21 - long you want the function to run is
313:23 - allowed to run before timing out and you
313:25 - are charged based on the runtime of the
313:26 - Serv function rounded to the nearest 100
313:28 - milliseconds so there you
313:30 - go
313:33 - [Music]
313:34 - hey this is Andrew Brown from exam Pro
313:36 - and what I want to do is just show you a
313:38 - variety of different Computing Services
313:39 - on AWS so I'm going to try to launch
313:41 - them and uh we're not going to do
313:43 - anything with them just going to Simply
313:44 - launch them okay so the first I want to
313:46 - show you is ec2 and by the way we will
313:48 - go more in depth in ec2 later on in this
313:51 - course here um but what I'm going to do
313:53 - is go ahead and launch the instance
313:54 - don't worry about all this stuff but
313:56 - just choose the Amazon Linux 2 so it's
313:57 - in the free tier all right we're going
313:59 - to choose an instance type of a T2 m so
314:02 - that's part of the free tier it's going
314:03 - to be set as one all these options are
314:06 - fine I want you to go ahead and review
314:07 - and launch we're going to launch and I
314:10 - don't want to generate any key pair I'm
314:11 - going to proceed without a key pair I'm
314:13 - going to acknowledge that because I
314:15 - don't want it and that's all there is to
314:17 - launching an ec2 instance and so I can
314:19 - go here and view my instances and what
314:22 - you'll see is it's pending okay and
314:25 - usually it has like a little spinning
314:27 - icon maybe they've updated it since then
314:30 - so I go here it's hard to see because
314:32 - there's all these terminated ones but I
314:34 - don't need to do anything with it I just
314:35 - wanted to show you the actions that
314:37 - you'd have to do to launch it actually
314:39 - we'll leave it alone maybe we'll see it
314:40 - when it's launched the next one I want
314:41 - to show you is e elastic container
314:45 - service um and wow this this is old
314:48 - let's go let's get the new experience
314:50 - please so old okay checkbox that
314:54 - on and we'll hit get started and we'll
314:57 - say create a
314:58 - cluster and we have some options here
315:01 - networking only ec2 Linux plus
315:03 - networking uh for use with either ads
315:06 - fargate or external Windows
315:10 - um uh this is if you're doing fargate
315:13 - which we're not doing right now fargate
315:14 - is part of elastic container service it
315:16 - used it well used to be it is called ECS
315:19 - fargate but it us markets it as a
315:21 - separate service we'll go to next and
315:23 - say my ECS
315:25 - cluster um we can create an empty
315:27 - cluster but that would make it a fargate
315:29 - cluster which we don't want there's an
315:30 - ond demand server look it's M6 I large
315:34 - if you're very afraid of a lot of spend
315:36 - here you don't have to do this you can
315:37 - just watch me do it and just learn well
315:39 - what I'm going to do is try to find
315:41 - something super cheap so I want a T2
315:43 - micro or a T3 micro T2 micro is part of
315:46 - the uh free tier I don't know if we get
315:48 - to choose T2 anymore in here they might
315:50 - not let
315:52 - you there it is you know T3 mro is great
315:55 - too I just whatever says it's free
315:58 - that's what I'm going to go for number
315:59 - of instances one the Amazon version is
316:02 - fine I don't care about a key pair uh
316:06 - use the existing VPC I don't want to
316:07 - have to make a new one select the
316:09 - existing ones
316:12 - okay uh let it create a new security
316:15 - group that's totally fine allow those to
316:17 - be fine create a new role that's fine
316:21 - create okay and so that's going to
316:24 - create ourselves a
316:26 - cluster um I'm going to just make a new
316:28 - tab here let's just check on our ec2
316:30 - instance
316:32 - and so if we look at our ec2 instance it
316:34 - is running okay great so it has a
316:37 - private IP address it has a public IP
316:40 - address all right um there's not much we
316:43 - can do with it I can't even log into it
316:44 - because we didn't generate out a key
316:45 - pair times you want to name these things
316:47 - so I just go here and name it my server
316:51 - okay go back to our ECS instance and the
316:54 - cluster is ready so we'll go here and oh
316:58 - nice we got a new UI and so if we wanted
317:00 - to deploy something as a service or a
317:03 - task
317:05 - um we would need to create a template
317:09 - like a task definition
317:12 - file uh they don't have a new UI for
317:14 - this you're being redirected to the
317:15 - previous version console because this
317:16 - isn't available in the new experience
317:18 - yet of course it isn't so we can create
317:19 - a new task definition file that's what's
317:21 - used to run it it's basically like a
317:23 - Docker file composed file whatever you
317:25 - want um we have fargate or ec2 we are
317:28 - doing ECS so we're going to have to do
317:29 - ec2 so we'll say my ECS yes uh task def
317:33 - file um task roll opt optional IM roll I
317:37 - don't need one network mode I don't
317:39 - care um and then this is the idea is
317:41 - that because a container allows you to
317:44 - use up a particular amount of the um
317:46 - thing we don't have to use all of the
317:48 - memory so we should look up what a T2
317:50 - micro is because I don't even remember
317:53 - what size it is okay T2 micro AWS so we
317:56 - go here we look at the instance types
317:59 - and we're going to flip over to T2 and
318:01 - it says that it's one
318:03 - vcpu one gigabyte of memory so what I'll
318:06 - do one yeah one okay that's fine so what
318:11 - we want and this is in megabytes so
318:13 - we'll say 500 megabytes and um I don't
318:17 - know if we can do less than one but I'm
318:18 - going to do one
318:20 - here
318:22 - um the task CPU must be an integer
318:25 - greater than or equal to 128 okay fine
318:27 - 128 oh I guess it's 1024 would utilize
318:30 - the whole thing so I could say
318:32 - 512 okay and this is where we would add
318:36 - our
318:37 - container so I don't do this every day
318:40 - so I don't remember how to do this we'll
318:42 - say my
318:43 - container um and I need a repository
318:46 - here so I need like dockerhub Hello
318:51 - World okay I don't care what it is I
318:53 - just need a image that's
318:57 - simple and I'm looking for the address
319:00 - here
319:05 - um I'm hoping that's just
319:08 - this dockerhub
319:14 - URL so it' be something like this right
319:16 - docker.io probably Docker IO Docker
319:19 - image um Docker Hub URL in
319:29 - ECS okay it goes to show how often I'm
319:31 - laun launching these things so
319:34 - repository URL Docker image so I think
319:37 - that what we're going to do
319:43 - here I would really just like the URL
319:46 - please
319:49 - reviews
319:51 - tags where is
319:52 - it where is it it's somewhere here
319:58 - right uh uhuh
320:02 - uh well let's just try it we'll go and
320:05 - we'll type in says image and tag so
320:09 - docker.io
320:11 - hello world I really need an image ID
320:15 - image URL hello
320:17 - world dockerhub
320:20 - they're not making my life easy here
320:27 - today anything I just want to see like a
320:30 - single example
320:31 - docker.io
320:36 - Docker
320:39 - iio URL
320:42 - examples
320:45 - ECS this is what it's like you know this
320:47 - is what you're going to be doing if you
320:49 - are um you know a cloud engineer you're
320:51 - going to be Googling a lot and just
320:52 - trying to find examples
320:55 - here so here it says docker.io the name
320:58 - the host name okay so we'll just try it
321:00 - okay so I think that the the the name
321:04 - here is underscore and then it's hello
321:06 - world and that's what's throwing me off
321:08 - here right docker.io
321:13 - just hold on
321:16 - here repositor URL and then there's the
321:19 - tag I don't know if like is the tag
321:21 - going to be like latest view available
321:24 - tags latest okay so what I'll do
321:28 - here and that's the thing you got to
321:30 - have a lot of confidence to too so hard
321:32 - limit soft limit um do I have to set
321:35 - it do I have to set any of these things
321:37 - can I just go to the bottom and hit
321:40 - add looks like I
321:42 - can okay so we'll scroll on down
321:46 - create we create our task definition
321:48 - file which is fine we're going to go
321:50 - back to our cluster it's going to bring
321:51 - us back to the new experience we're
321:53 - going to click into this
321:55 - cluster holy smokes uh we're going to
321:58 - hit
321:59 - deploy and and we are going to choose
322:02 - service that means it's going to
322:03 - continuously run task means that when
322:04 - it's done running it ends we're going to
322:06 - choose our family our version that's the
322:08 - task definition file there is not
322:10 - compatible with the selected compute
322:15 - strategy my task
322:20 - file what if I just choose task take
322:26 - that okay some maybe some you have to
322:29 - like code it so that it continuously
322:30 - runs I don't care we don't need to run a
322:32 - service here the selected task
322:34 - definition is not compatible with the
322:35 - selected compute
322:38 - strategy okay let's see
322:45 - why uh can you double check if you're
322:47 - using fargate strategy instead of the
322:49 - ec2 uh blog designed for the ec2
322:51 - strategy so probably what it's
322:53 - suggesting is that the the strategy file
322:55 - I made is not for the right one here
322:57 - task
322:59 - definitions go back over
323:02 - here well what's wrong with
323:08 - it task roll none my container so what
323:12 - I'm going to do because I don't trust
323:14 - this just going to go ahead and delete
323:16 - this can I delete this how do I delete
323:21 - this oh boy
323:24 - actions deregister
323:27 - deregister we'll create a new one and so
323:30 - it has tools like it was co-pilot um CLI
323:33 - to make this a lot easier because you
323:35 - can see this is very frustrating but I
323:36 - chose
323:38 - this so my task
323:42 - def requires compatibility of
323:46 - ec2
323:50 - default 512
323:54 - 512 add
323:57 - container we're going
323:59 - to uh was it docker.io
324:05 - uncore what's it called hello
324:10 - world
324:12 - latest I we'll just say hello world
324:17 - here and we'll just say uh 512 which is
324:21 - fine I don't care about any port
324:23 - mappings I'm just reading it carefully
324:25 - here to see what it wants we'll say 512
324:27 - maybe because I didn't specify them it's
324:29 - complaining
324:31 - this looks fine we'll hit
324:34 - add
324:36 - okay constraints type this all looks
324:39 - fine so we'll try this
324:41 - again and so we now have our file let's
324:44 - see if we can just run this task from
324:46 - here you
324:48 - see2 this is just another way to do it
324:50 - so we just choose the cluster this is
324:51 - actually a lot easier to do it this is
324:53 - old old old Eh this is ugly and so now
324:57 - it launches so you know if you have
324:59 - trouble one way then just do it another
325:01 - way and uh sometimes it'll work here so
325:04 - I don't expect this task to really work
325:05 - in any particular way if it's pending
325:08 - that's fine if it fails that's fine if
325:10 - it's successful that's fine I don't
325:12 - care I just want to go through the
325:14 - motion so it was successful it it ran
325:16 - and then it stopped I don't know if we
325:19 - could see like the output anywhere
325:20 - probably what it would do is it would
325:22 - log out something like into somewhere
325:26 - and so I don't know if like there's logs
325:28 - turned on for this if I go over to like
325:30 - cloud watch logs maybe I could see
325:34 - something a lot of these services will
325:36 - automatically create cloudwatch logs so
325:38 - sometimes you can just go look at them
325:39 - there so we'll drop down we'll go to log
325:41 - groups
325:43 - here there is some stuff here um there's
325:46 - a couple that I created from before just
325:48 - go ahead delete
325:51 - those and so what I'm looking for is
325:53 - like ECS so no there's no logging
325:55 - happening here which is totally fine so
325:56 - that is ECS um for fargate it's pretty
325:59 - much uh the the same the difference is
326:01 - that fargate is like it has to start up
326:04 - and run so it's a lot slower to
326:06 - watch okay and now let's go take a look
326:10 - at a
326:11 - Lambda okay so this is our serverless
326:15 - compute so we go ahead and create
326:17 - ourselves a function uh we can start
326:19 - from a blueprint that doesn't sound too
326:22 - bad and I personally like Ruby so no not
326:26 - getting much here but we can do is look
326:28 - for something that do we have like a
326:31 - hello
326:33 - world there we go hello world and we'll
326:36 - click that we'll say my hello
326:39 - world uh it's going to create those
326:41 - permissions that's fine it's showing us
326:43 - the code it's very simple okay it's
326:46 - going to console log out these values
326:48 - not a very good hello world function
326:49 - doesn't even say hello world how can you
326:52 - call it a hello world function if it
326:53 - doesn't say hello world I don't
326:55 - understand so we're going to go ahead
326:57 - and create this function usually doesn't
326:58 - take this long
327:02 - okay so uh here is our function here is
327:05 - our code notice that this is
327:07 - cloud9ine okay and you can even move
327:09 - that over to Cloud9 they didn't have
327:10 - this button here before that's kind of
327:12 - cool I hit test they used to have it up
327:16 - here but I guess they wanted to make it
327:18 - more obvious so they moved it down here
327:19 - which is nice so what I can do is hit
327:22 - this oops my test it's going to send a
327:25 - payload here to the actual function uh
327:28 - and it's going to tell us if it works
327:33 - okay so can I run my test go over here
327:36 - to
327:37 - test they changed it a bit so I guess I
327:39 - created there it succeeded so I have my
327:41 - logs okay so it's it's going to Output
327:44 - those values there so there are the
327:46 - three values which basically is
327:48 - nothing maybe you were supposed to set
327:50 - those an environment variable but you
327:51 - can see you're just uploading uh some
327:53 - code right it's just a bit of code it's
327:56 - not like a full app or anything so we
327:59 - launched an E2 container we did a a um
328:03 - sorry ec2 instance a container we did a
328:05 - seress function there's other things
328:07 - like eks but that is really really hard
328:09 - to set up okay because uh you'd have to
328:12 - use like kubernetes commands and stuff
328:14 - like that and my kubernetes knowledge is
328:16 - always very poor um I'm just taking a
328:18 - peek here to see if they've updated it
328:20 - so yeah you create the cluster but like
328:21 - deploying it is forget it I'm just
328:24 - trying to think if there's anything else
328:25 - I kind of want to show you um no those
328:27 - are the main three I would say so I'm
328:30 - pretty happy with that um what I'm going
328:32 - to do is go and kill all these things so
328:35 - we're going to go over to Lambda
328:38 - okay and I'm going to go ahead and
328:40 - delete
328:42 - this as you saw ECS was the hardest and
328:45 - no matter how many times I've built
328:47 - things on ECS and I've deployed full
328:49 - things on ECS I can't remember I always
328:51 - have so much trouble with task
328:53 - definition files it's unbelievable we'll
328:55 - go over to our cluster
328:58 - here and
329:01 - ECS cluster up here make sure you're not
329:04 - in the fargate cluster I know I'm
329:05 - clicking really fast but there's just so
329:06 - many things to click and I'm going to
329:08 - click into this cluster we're going to
329:10 - go hit edit because this is running an
329:11 - ec2 instance right I need to destroy it
329:16 - um it just took me back to the old one
329:18 - here um I want to delete no I want to
329:20 - delete the cluster click back
329:23 - here where do I delete it up
329:28 - here here
329:30 - I can't checkbox
329:33 - anything uh how do I delete this do I
329:38 - have to delete the task first maybe so
329:40 - we'll go here I mean it's already
329:42 - stopped there's nothing to
329:44 - do
329:48 - edit uh huh account
329:54 - settings wow this is
329:56 - confusing
329:58 - okay how to delete ECS
330:03 - cluster got to be kidding me I have to
330:05 - actually look this up so open the SS
330:07 - console from navigation in the
330:08 - navigation choose clusters and the new
330:12 - turn off the E uh turn off new ECS
330:15 - experience and choose the old console
330:16 - the delete cluster workflow is not
330:18 - supported in the EC ECS console are you
330:21 - serious then
330:23 - why why do you have it like why even let
330:26 - people use the new experience if that
330:27 - you don't have all the functionality
330:28 - there um oh I was going to give it
330:31 - feedback but it didn't let me here it
330:32 - says uh I need to delete an ECS
330:40 - cluster
330:43 - no okay so I'm
330:45 - here there's my big ugly
330:48 - cluster delete
330:50 - cluster okay so yeah it it's a struggle
330:54 - okay like things are always changing on
330:56 - me but uh you just have to have
330:57 - confidence and if you've done it a few
330:59 - times you know that can do it right um
331:02 - and that's one of the biggest Hang-Ups
331:03 - to Cloud I would say so it's going to
331:05 - take a few minutes apparently to delete
331:06 - the cluster as that is going let's go
331:08 - over to ec2 I didn't close it I kept
331:11 - this tab
331:13 - open and uh there's our ec2
331:16 - instance we can go ahead and terminate
331:19 - that instance terminate
331:24 - okay and if this says it's terminating
331:28 - then we're in good shape Terminator
331:29 - shutting down that's fine and notice
331:32 - here that's the ECS instance just make
331:33 - sure you shut down the my server not the
331:36 - um the ECS instance cuz that's going to
331:38 - stop and so this is already terminated
331:40 - but if we go back here notice that it
331:42 - says that it's not done but it
331:45 - clearly clearly has shut
331:48 - down okay so I'm going to wait here for
331:51 - a bit even though I know it's been
331:53 - deleted maybe it's deleting things like
331:54 - the auto scaling group so we go down
331:56 - below
331:57 - here right so that's probably what it's
331:59 - doing it's probably trying destroy the
332:00 - Autos scaling
332:01 - group but it doesn't show any here so it
332:03 - must have already destroyed
332:06 - it yeah so task Services delete so I'll
332:09 - be back here in a bit but I know it's
332:11 - safe it's already deleted but I'll see
332:12 - you back here in a bit okay so I waited
332:14 - literally a second and it's now deleted
332:17 - so we deleted our Lambda we deleted our
332:20 - oh did we delete our
332:22 - Lambda good
332:24 - question now I'm not really worried
332:26 - about the Lambda because I guess we did
332:29 - but I'm not really worried about it
332:30 - because um you know at when it rests at
332:34 - idle it's not costing us anything where
332:37 - the ECS and the ec2 are backed by ec2
332:40 - instances so we do have to shut those
332:42 - down okay and again remember make sure
332:44 - you're in the correct region sometimes
332:46 - that gets flipped over and then you
332:47 - think those resources are gone but
332:49 - they're actually not they're just
332:50 - running in another region so uh there
332:53 - you
332:54 - [Music]
332:57 - go hey this is Andrew Brown from exam
332:59 - Pro and we're taking a look at higher
333:00 - performance Computing Services ons so
333:02 - before we do we got to talk about the
333:04 - Nitro system so this is a combination of
333:06 - dedicated hardware and lightweight
333:08 - hypervisor enabling faster Innovation
333:10 - and enhanced security all new ec2
333:12 - instant types use the nitro system and
333:14 - the Nitro system is designed uh by AWS
333:17 - okay so this is made up of a few things
333:19 - we have Nitro cards these are
333:22 - specialized cards for vpcs EBS instant
333:25 - storage and uh controller cards you have
333:27 - Nitro security chips these are
333:28 - integrated into the mother board
333:30 - protects Hardware resources and we have
333:32 - the Nitro hypervisor this is the
333:33 - lightweight hyper visor memory and CPU
333:35 - allocation bare metal like performance
333:38 - there's also uh Nitro enclaves but you
333:41 - know that's a bit out of scope here but
333:42 - that's has to do with like ec2 isolation
333:44 - Okay uh then we have bare metal
333:46 - instances so you can launch ec2
333:48 - instances that have no hypervisor so you
333:50 - can run workloads directly on the
333:51 - hardware for maximum performance and
333:53 - control we have the M5 the R5 um E2
333:57 - instances that can run bare metal
333:59 - there's other ones I believe I've seen
334:00 - as well but um you know if you are
334:03 - running bare metal you can just go
334:04 - investigate at the time of okay we have
334:06 - bottle rocket this is a Linux based open
334:08 - source operating system that is purpose
334:10 - built by adus for running containers on
334:12 - VMS or bare metal hosts then uh let's
334:15 - just Define what HBC is so it's a
334:17 - cluster of aund of thousands of servers
334:20 - with fast connections between each of
334:22 - them with the purpose of boosting
334:24 - Computing capacity so when you need a
334:26 - supercomputer to perform computational
334:28 - problems too large to run on a standard
334:30 - computer or computers or would take too
334:33 - long this is where you know HBC comes
334:35 - into play one solution here is adus
334:38 - parallel cluster which is uh an ad
334:40 - supported open source cluster management
334:42 - tool that makes it easy for you to
334:44 - deploy and manage high performance
334:46 - Computing HBC clusters and AWS so
334:48 - hopefully that gives you an idea of this
334:50 - stuff
334:51 - [Music]
334:55 - okay all right so let's take a look at
334:57 - HPC or high performance computer
334:59 - Computing on AWS so HPC is for running
335:03 - large complex simulations and deep
335:04 - learning workloads in the cloud with a
335:06 - complete Suite of high performance
335:07 - Computing product Services gains Insight
335:09 - faster and quickly move uh from idea to
335:11 - Market blah blah blah blah blah it's for
335:13 - ML or very complex scientific Computing
335:15 - stuff these run at least on C5 NS okay
335:20 - and the way it works is that you use
335:22 - this um CLI called P cluster or aess
335:25 - parallel compute U or aess parallel
335:28 - cluster stuff and so let's see if we can
335:29 - get get this installed very easily um so
335:33 - what I'm going to
335:34 - do is see how hard it is to install now
335:38 - I don't recommend you running this
335:40 - because I don't know what it's going to
335:41 - cost me and if I make a misconfiguration
335:43 - I don't want you to have that spend here
335:45 - but I don't think it's that dangerous so
335:47 - I'm going to go back over to us East one
335:49 - here I'm going to open up
335:52 - cloudshell and I'm going to give it a
335:54 - moment to load and so as that is loading
335:57 - let's take a look at how we would go
335:59 - ahead and install this so install the
336:00 - current parallel um it was parallel I
336:03 - think we just copy that line
336:05 - okay and so we have to wait for our
336:08 - environment to spin up all right so once
336:10 - it has spun up we will install it and
336:14 - then we will jump over to this tutorial
336:18 - here okay so we'll give this a
336:23 - moment and after waiting a little while
336:25 - here it looks like our shell is ready it
336:27 - looks like it's in bash um I'm just
336:29 - going to type in S3 LS that's a sanity
336:33 - check okay and it works that's great so
336:37 - we go back over here and I'm going to go
336:38 - back up to install for
336:40 - Linux and what I need is that single
336:45 - command where is
336:47 - it so I'm certain that we already have
336:51 - Linux or python installed but I just
336:55 - want the command to install
336:57 - it you saw it a moment go here I'm just
337:00 - going to back out till I can find
337:04 - it uh one more there it is so it's under
337:08 - oh it's this link here and that's what I
337:10 - talk about the documentations being
337:11 - tricky sometimes you have to click these
337:13 - uh headings here to find stuff so this
337:17 - is the first time installing it so we'll
337:18 - grab that usually you're supposed to
337:20 - create in Virtual environments with
337:21 - python I don't care this is my cloud
337:23 - shell it doesn't matter to me so we're
337:25 - going to go ahead and download that and
337:26 - hopefully it is fast and it was super
337:28 - fast which was really nice
337:30 - and so what we'll do is go check out the
337:32 - P cluster
337:35 - version okay and that looks fine to me
337:37 - I'm going to go down below here to run
337:39 - our first job um the returns the it
337:42 - gives outputs I don't think we need to
337:45 - configure it because we already have our
337:46 - CLI so what I'm going to do is go ahead
337:48 - and create ourselves a new cluster um
337:51 - beginning cluster creation configuration
337:53 - file config not found so I guess we do
337:55 - have to configure
337:58 - this
338:01 - configure and it's asking what region do
338:04 - we want to be in um if I have us East
338:06 - one I would choose it for some reason
338:07 - it's all the way for number 13 that is
338:09 - not a lucky number but I'm going to
338:11 - choose it anyway anyway no key pair
338:13 - found in Us East one region please
338:15 - create one of the following um so create
338:18 - an ec2 key
338:20 - pairs uh no options found for ec2 key
338:22 - pairs that's fine so what what I'll do
338:25 - is go over
338:26 - here and we'll go over to ec2
338:33 - and we will go over to key pairs key
338:35 - pairs key pairs key pairs we'll create
338:36 - ourselves a new one here so say um HPC
338:40 - key pair or just my
338:44 - HPC so we know what it is for we have
338:48 - putty or PM we're going to do pem
338:49 - because we're on Linux we'll create that
338:53 - and notice that it downloaded the pem
338:55 - down down here and we're going to need
338:57 - that for later um and so what I'll
339:00 - do is I'll type in P cluster here again
339:03 - configure we'll choose 13 we'll choose
339:05 - number one here uh allowed values for
339:09 - the scheduler I have no idea what these
339:13 - are uh let's choose the number one
339:16 - allowed values for the operating system
339:18 - Amazon L 2 I know what that is minimum
339:21 - cluster size one maximum cluster size
339:26 - two head notice instance oh T2 micro you
339:29 - can do that yeah let's do it I didn't
339:31 - know we could do that enter compute type
339:34 - uh T2 micro sure so I thought that we'd
339:37 - have to use a c5n but I guess apparently
339:40 - not automate VPN uh VPC creation yes of
339:43 - course network configuration so allow
339:45 - values for the network configuration uh
339:47 - head node in a public subnet and and
339:50 - compute Fleet in a private subnet uh
339:52 - head node and compute yeah we'll do it
339:54 - in the both just to make our lives
339:55 - easier I don't care first one sounds
339:57 - more secure of course and so oh it's
340:01 - creting Cloud information sack wow this
340:02 - is easy I thought this was going to be
340:04 - super painful okay so we'll go over here
340:07 - we'll go take a look at what cloud
340:08 - formation's doing all
340:10 - right now I don't care if we actually
340:13 - run a task on here but it was just
340:14 - interesting to go through the process to
340:15 - see how hard it was and we will go look
340:19 - at what resources are being created so
340:21 - it's creating an internet gateway so
340:23 - it's literally creating a isolate VPC
340:25 - for it which is totally fine I guess um
340:27 - it's creating a subnet creating a route
340:29 - table refresh
340:32 - here um I'm not sure how much it wants
340:34 - to create here it just looks like VPC
340:37 - that's all it's creating I thought maybe
340:38 - the ec2 instances would show up here but
340:40 - maybe it's going to launch that on a
340:43 - need B
340:46 - basis okay so that's all created oh now
340:49 - it's doing a VPC
340:52 - Gateway I think VPC gateways cost money
340:55 - let's go take a look here VPC
340:58 - pricing
341:01 - yeah there's a uh transfer fee so just
341:04 - be careful about that you know again you
341:07 - can just watch along here you don't have
341:09 - to do
341:10 - it default route depends on public so
341:14 - now it's creating ec2
341:17 - route I don't know what an ads ec2 route
341:20 - is I've never seen that before sometimes
341:23 - what we can do is go into ec2 and then
341:25 - take a look on the left hand side you
341:27 - see anything in here we don't know what
341:28 - it is we just type in ec2 route cloud
341:30 - formation sometimes cloud formation is
341:32 - great for figuring out what a component
341:34 - is not all components are represented in
341:36 - the um inabus um Management console so
341:40 - specify route in the route table oh it's
341:41 - just a route
341:44 - okay and we'll go back here we'll
341:48 - refresh so that is done is the stack
341:51 - done created complete good we'll go back
341:53 - to our Cloud shell it says you can edit
341:56 - your configuration file or simply do Etc
341:58 - so now let's see if we can create the
342:00 - cluster I assume this would create ec2
342:03 - instances so the job schedule you using
342:06 - is sge this is deprecated in future use
342:09 - parallel cluster well should have told
342:10 - me okay there is a new version of 301
342:15 - parallel available I don't understand
342:16 - because I just installed it right we'll
342:19 - go back to cloud formation just going to
342:20 - probably create nested Stacks which
342:23 - that's what I thought it would do Nest
342:24 - Stacks means that it's Reliant so
342:26 - there's one main one and then there's uh
342:28 - children stack
342:29 - so go here see what resources it's
342:31 - creating oh whole bunch of stuff wow so
342:35 - many things at sqsq
342:38 - SNS uh network interface a Dynamo DB
342:42 - table Yeah you you probably don't want
342:44 - to run this you just want to watch me do
342:46 - it and then we go into here it's
342:48 - creating uh an ec2 volume so that's
342:51 - going to be
342:52 - EBS and then here we
342:55 - have uh a log group I don't know why
342:58 - they separated those out do seem very
343:02 - necessary we are waiting on the elastic
343:05 - IP that always takes forever creating
343:07 - elastic IP root instance profile that is
343:10 - the IM Ru for
343:12 - it that didn't take too long these these
343:15 - take a long time I I never know why
343:18 - create a rooll it's really easy but
343:20 - attaching an I am policy you're always
343:21 - waiting for
343:24 - those um so I'm going to just stop it
343:28 - here I'll be back in a second because I
343:29 - don't want to have to make you watch me
343:32 - stare at the screen here okay all right
343:35 - so after a really really long wait um
343:37 - and it always takes some time there it
343:39 - finally created I'm not sure what it's
343:41 - made I mean we generally saw over here
343:44 - in the outputs but usually the cost that
343:46 - I'm worried about is whatever it's
343:47 - launching under uc2 it might not even
343:50 - have launched any servers here we're
343:52 - going to take a look here see if there's
343:53 - anything so we have a master and a
343:56 - compute and they're T2 micros so seems
343:59 - pretty safe here um this compute is not
344:03 - running yet so I'm assuming that this is
344:06 - like the machine that does the Computing
344:08 - and maybe if you had multiple machines
344:10 - here like that would be the cluster like
344:12 - could manage multiple computes um I'm
344:14 - not particularly sure but let's just
344:16 - keep going through the tutorial and see
344:17 - what we can do the next step is we need
344:19 - to get this PM key in our Cloud shell
344:22 - here so this I don't know where this is
344:24 - but what I'm going to do is I'm going to
344:26 - move it to my desktop I'm doing this off
344:28 - screen by the the way so I'm moving it
344:30 - to my desktop and then I'm just going to
344:31 - go and upload the file okay and there it
344:35 - is so we'll say open and we'll say
344:39 - upload and it's going to upload it here
344:42 - onto this machine and I believe this is
344:44 - on like uh I think this used as an e EFS
344:46 - instance like if you're wondering where
344:48 - the storage for cloud shell is if we go
344:51 - over here I think it's
344:52 - EFS is
344:54 - it h i don't know where it is okay maybe
344:57 - it's just a maybe it's some else okay I
344:59 - can't remember where it is but anyway um
345:02 - so
345:03 - now it's created the cluster can I hit
345:06 - enter
345:08 - here okay can I create a
345:12 - tab like if I quit this is it going to
345:15 - kill it it exited it which is I think
345:18 - it's fine I don't think it stopped
345:19 - running and so now if I do an LS there's
345:22 - my key and so we can go back to our
345:26 - instructions just have too many tabs
345:28 - open here drag this all the way to the
345:30 - left here and so we can try to use our
345:32 - key here to log in so what I'm going to
345:35 - do
345:38 - is go here and we'll say my HPC pm and
345:42 - see if that works we'll say
345:45 - yes and permission denied it is required
345:47 - your private key is not accessible
345:49 - that's because we have to chamod
345:51 - it
345:53 - um I never remember the command anymore
345:56 - CU I rarely ssh in the machine
345:59 - but if we go to connect and we go to SSH
346:03 - client it'll tell us what we need to
346:05 - run chamad 400 okay so that's what we
346:08 - need to do is we need to do a chamad 400
346:11 - just wanted to grab that code
346:13 - there okay and now if we hit up we
346:16 - should SSH into the machine there we
346:19 - are we are in the instance we'll type in
346:23 - exit and so now we want to run our job
346:26 - on this
346:27 - machine and if we go back over to here I
346:32 - guess we can go create our first job so
346:35 - I'm just doing this in
346:38 - v and I'm going to paste that in
346:41 - yep and I don't want the first line oh
346:44 - okay that's perfect
346:46 - great right
346:49 - quit oh there's no file name hold on
346:51 - here so I need to name this file
346:54 - something so I'm going to say job.
346:57 - sh and we're going to paste that again
346:59 - here we'll say
347:01 - paste and I don't know if that's cut off
347:04 - yeah it is okay great is that one
347:09 - okay I don't trust that the first line
347:11 - is
347:12 - there so what I'm going to
347:15 - do is go back to our tutorial here it's
347:19 - shebang
347:21 - forbin
347:23 - bash
347:25 - uh this then that for SL bin
347:29 - SL bash just double check it looks good
347:31 - to me we're going to quit that I'm just
347:34 - going to make sure that it is what it we
347:35 - said it is so job. sh looks correct to
347:38 - me good and so we'll try to run our job
347:41 - here so I'm going to say
347:43 - Q um job.
347:47 - sh
347:49 - LS and I guess it really depends on what
347:51 - we decided to use when we set up that
347:53 - thing I can't remember what we choose as
347:55 - our Q we do
347:57 - qat
347:59 - oh okay okay okay so I think the thing
348:01 - is like you see how we have sge I think
348:03 - that that's what we use to queue up jobs
348:06 - and so we have to have that installed
348:07 - probably so
348:10 - install configure surid
348:15 - engine SG install um
348:23 - Linux oh boy that looks like a lot of
348:26 - work so I don't think we need to to do
348:29 - anything further here but as far as I
348:30 - understand the idea is that you're
348:32 - choosing uh some kind of way to manage
348:35 - these and so I'm not sure what q q sub
348:37 - is let's just go look up what that is
348:38 - what is Q sub oh that is the sun grid
348:41 - engine okay so how do we install
348:50 - that um I'm just going to see if we can
348:53 - install it so I'm going to do I think
348:55 - this is using
348:56 - yum so if I do clear here clear yum
349:01 - install Q sub let's see if I can do
349:05 - it pseudo yum install qm no package
349:09 - available Amazon Linux 2 Q sub because
349:14 - that's probably what we're running in
349:21 - cloudshell Q sub doesn't tell us how to
349:25 - install
349:26 - it that's great
349:29 - so that's probably what it is and so in
349:31 - order to use this we would have to
349:33 - install that sun whatever whatever and
349:37 - then we go through we do Q sub it would
349:38 - queue it up um we could do qat cat hello
349:41 - destroy it that's pretty much all we
349:43 - really need to know to understand this
349:45 - um it would have been nice to queue up a
349:46 - job and see it work but you know we're
349:48 - getting kind of into a hairy territory
349:50 - here and I think that we fundamentally
349:52 - understand how this does work so what
349:54 - I'm going to do is I'm going to go here
349:55 - I'm going to remove the job Dosh here
349:58 - and and I want to destroy this
350:00 - cluster um so I'm going to do pcluster
350:05 - commands to figure out what all the
350:07 - commands are and there's probably a
350:10 - delete command so we'll go back up
350:14 - here B
350:17 - cluster where is our crate so we'll say
350:23 - delete okay and so what that's going to
350:25 - do is just tear down all the stuff
350:27 - now so if we go over to cloud
350:36 - formation okay and it looks like it's
350:40 - destroying so yeah I'll see you here uh
350:43 - back in a bit when it's all destroyed
350:44 - okay all right so after a short little
350:46 - wait there it has destroyed it been so
350:48 - long that I uh my connection vanished
350:50 - but just make sure if you did follow
350:51 - along for whatever reason uh you know
350:53 - make sure that the stuff is deleted and
350:56 - it looks like it did not destroy uh this
350:58 - so I'm going to go ahead and delete that
350:59 - that's just VPC stuff so I'm not too
351:01 - worried about it I know that's going to
351:03 - roll back no problem and so I'm going to
351:04 - consider this done so going to make my
351:06 - way back to the Management console close
351:09 - this stuff up and we are good to go uh
351:11 - for our next
351:13 - [Music]
351:16 - thing hey this is Andrew Brown from exam
351:18 - Pro and we're taking a look at Edge and
351:20 - hybrid Computing Services so what is
351:23 - Edge Computing when you push your
351:25 - Computing workloads outside of your
351:27 - network to run close to the destination
351:29 - location uh so an example would be
351:31 - pushing Computing to run on phones iot
351:33 - devices external servers not within your
351:35 - Cloud Network what is hyber Computing
351:38 - when you're able to run workloads on
351:40 - both your on premise Data Center and the
351:42 - a uh VPC okay so we have a few Services
351:46 - here starting with ad Outpost this is a
351:48 - physical rack of servers that you can
351:49 - put into your data center ads output
351:52 - allows you to use ads API and services
351:55 - uh such as ec2 WR in your data center
351:58 - then we have AIS wavelength this allows
352:00 - you to build and launch your
352:01 - applications in a telecom data center by
352:04 - doing this your applications will have
352:05 - ultra low latency since they will be
352:07 - pushed over the 5G Network and be
352:09 - closest as possible to the end user um
352:12 - so they've partnered with things like
352:14 - Verizon vone uh business and a few
352:16 - others but those are the two noticeable
352:18 - ones okay we have VMware Cloud on AWS so
352:21 - this allows you to manage on premise
352:23 - virtual machines using VMware uh within
352:26 - ec2 instances the data center must uh be
352:29 - using uh VMware for virtualization for
352:31 - this to work okay then we have Aus local
352:34 - zones which are Edge uh Data Centers
352:36 - located outside of the adus region so
352:38 - you can use adus closer to the edge
352:40 - destination when you need faster
352:42 - Computing storage databases in populated
352:44 - areas that are outside of AWS region you
352:46 - could do this there's some other Edge
352:48 - offerings on AWS that aren't listed here
352:50 - like sag maker has what's called like
352:52 - Neo stage maker um let you do Edge
352:54 - Computing with um ml but I mean this is
352:57 - good enough
352:59 - [Music]
353:02 - okay all right so I wanted just to show
353:04 - an example of edge Computing uh because
353:07 - we didn't cover it in our generic uh
353:08 - compute and so there's a variety of
353:10 - services that allow you to do Edge
353:11 - Computing like wavelength and so um I've
353:14 - never actually launched wavelength
353:16 - before and I think that uh you have to
353:19 - request it so if I go over to support
353:22 - here again I've never done this before
353:23 - but I'm sure we can figure it out pretty
353:25 - easily I feel that if we create a case
353:31 - um maybe it's like service
353:33 - limit we type in wavelength here nope
353:36 - not
353:37 - there so how do we get wavelength
353:39 - wavelength AB us
353:46 - request so that's what I'm looking for
353:52 - here okay how do I use wavelength
353:57 - AWS
354:03 - whoops and sometimes what I'll do is go
354:05 - to the doc here opt into wavelength
354:08 - zones before you specify wavelength zone
354:10 - for resource or service you must opt
354:12 - into it to opt in go to the AIS console
354:16 - okay so we'll go to
354:20 - ec2 and then it's going to say use the
354:24 - region selector in the navigation bar to
354:25 - select the region which supports your
354:27 - wavelength
354:29 - l so I know that there's stuff
354:33 - in uh Us West because of Las Vegas right
354:38 - or not Las Vegas but Los Angeles right
354:40 - so if we go over here there's definitely
354:42 - that over there on the navigation pain
354:44 - on the ec2 dashboard under account
354:46 - attributes select
354:49 - zones okay do we see zones
354:53 - here
354:56 - zones oh ec2
355:00 - dashboard zones let's go check here
355:02 - again on the navigation pane choose ec2
355:05 - dashboard we are there
355:09 - right and under account attributes uh
355:12 - settings account
355:15 - attributes oh over here okay oh it's
355:18 - here
355:19 - zones and so there we have two zones and
355:23 - we see switch regions to make uh zones a
355:26 - different region
355:29 - okay so under Zone groups turn on
355:33 - wavelengths Zone
355:36 - groups okay nothing there so I'm just
355:38 - going to switch over to another one
355:40 - here maybe
355:43 - Oregon maybe it's usw 2 oh look at all
355:46 - the stuff we have here I've never seen
355:48 - these before okay so here is the
355:52 - wavelength one so that is the Los
355:54 - Angeles
355:55 - one we can go ahead and enable this
355:57 - before disabling The Zone group I'm not
355:59 - sure what zone groups cost so wavelength
356:03 - Zone pricing again you might just want
356:06 - to watch me do this because it might
356:07 - cost
356:08 - money um and so you might not want to
356:12 - have to spend for
356:13 - that
356:17 - pricing uh provides mobile networks wave
356:21 - lengths are available across whatever
356:23 - learn about the data transfers in price
356:25 - about ec2 instances okay so what's the
356:29 - price we go into
356:33 - here all right so what I'm going to
356:36 - suggest to you is don't do this but I'm
356:37 - going to do it and we're just going to
356:39 - see what the experience is like okay so
356:41 - I'm going to update my zone so now I
356:43 - have this one so we'll say enable I'm
356:45 - going to assume that it has to do with
356:47 - like data transfer
356:49 - costs okay and uh we're going to go over
356:52 - to
356:55 - ec2 and we're going to go over to
356:57 - instances here
356:58 - here we're going to launch an instance
357:01 - and we're going to see if we we have
357:03 - that available now I don't know if we're
357:04 - restricted to to particular uh instances
357:07 - I'm assume we can launch a Linux machine
357:09 - it'd be really weird if we couldn't you
357:11 - know we'll go over to configuration and
357:13 - what we want to do is
357:16 - choose uh the zone so how do we do it so
357:19 - once it's turned
357:20 - on confirmation and confirm it configure
357:22 - your network so create a VPC create a
357:25 - carrier Gateway so you can connect your
357:26 - resources into the the VPC to the
357:28 - telecommunication Network holy smokes
357:31 - This is
357:32 - complicated but it's just kind of
357:34 - interesting to see like the process
357:36 - right you know it's not for our use case
357:38 - but uh carrier Gateway
357:41 - right and as I do this I always check up
357:43 - all the costs here so I say carrier
357:46 - Gateway pricing AWS because maybe that's
357:49 - where the price
357:52 - is okay if you don't get a pricing page
357:54 - then usually that's hard to say
357:56 - logically isolated virtual Network
358:00 - again it's not telling me
358:02 - what um to use carrier you need to opt
358:05 - into at least one wavelength Zone but I
358:07 - did
358:09 - right and sometimes what happens is that
358:11 - it just takes time for the optin to to
358:15 - go so go here manage the Zone settings
358:19 - that was a lot easier way so we have one
358:20 - it's we're opted in right here
358:24 - okay
358:26 - and
358:28 - okay we'll we'll go here again if that
358:30 - one didn't work
358:32 - um we can try so the I guess these are
358:36 - all the regions Denver things like
358:39 - that can I opt opt into this one op
358:46 - in it's not super exciting like all
358:48 - we're going to do is launch an ec2
358:50 - instance but you know we'll go through
358:52 - the process here a
358:53 - bit and I don't know why I can't create
358:55 - one so we'll go back over to the
358:57 - instructions
358:58 - here create so you can connect so create
359:00 - a route table using the VPC to the route
359:02 - table so I think that's as far as we're
359:04 - going to get here because I'm not seeing
359:05 - any options here but the idea was that
359:08 - we would have to create a carrier
359:09 - Gateway we'd update our route tables and
359:11 - all we would be doing is launching an
359:13 - ec2 instance so you know it's no
359:15 - different than launching it you just
359:17 - choose a different subnet so I think
359:19 - you'd have to create a subnet for that
359:20 - zone and launch it in there and that
359:22 - would be Edge Computing another example
359:24 - of edge Computing would be something
359:25 - like via cloudfront which we have uh
359:28 - these um Edge functions or not Edge
359:32 - functions yeah functions here and so
359:34 - these are functions that are deployed to
359:36 - cloudfront so my cloudfront
359:42 - function and these would be deployed to
359:45 - um Edge locations right and all you can
359:48 - use here is Javascript so here's an
359:50 - example of one and um I'm fine with this
359:55 - development live this function is not
359:57 - published we'll go to
359:59 - test test the function it's
360:02 - good publish publish that function and
360:05 - so the advantage of this is that you
360:08 - know if you have functions that are in
360:10 - it was Lambda there's a chance of cold
360:12 - start um whereas if they're deployed on
360:15 - the edge here there's still probably a
360:17 - cold start but it's going to be a lot
360:18 - faster because it's a lot closer to the
360:21 - edge location so um you know it's just a
360:24 - different uh different cases but yeah
360:26 - there was one where we're launching ec2
360:28 - workload into wavelengths which we
360:30 - couldn't complete which is totally fine
360:31 - and then we have these functions on the
360:33 - edge there's other uh Edge Computing
360:35 - Services like within Sage maker you can
360:38 - deploy I think it's called like Neo sag
360:39 - maker and then for iot devices those are
360:42 - obviously on the edge so you can deploy
360:43 - those as well uh but generally that
360:45 - gives you an idea of edge Computing
360:47 - [Music]
360:51 - okay hey it's Andrew Brown from exam Pro
360:53 - and we're looking at cost and capacity
360:55 - management Computing Services so before
360:57 - we talk about them let's define what is
360:59 - cost management so this is how do we
361:01 - save money and we have capacity
361:03 - management how do we meet the demand of
361:05 - traffic and usages through adding or
361:07 - upgrading servers so let's get to it the
361:09 - first are the different types of EC
361:12 - pricing models so you got spot instances
361:14 - reserved instances saving plans these
361:17 - are ways to save on Computing by paying
361:19 - up in full or partially or by committing
361:22 - to a yearly contract or multi-year
361:24 - contract uh or by being flexible about
361:26 - the availability Interruption to
361:28 - Computing Services we have adus batch
361:30 - this plans schedules and executes your
361:32 - batch computer workloads across the full
361:34 - range of adus Computing Services which
361:36 - can utilize spot instances to save money
361:39 - we have aabus compute Optimizer so
361:42 - suggest how to reduce cost and improve
361:44 - performance by using machine learning to
361:46 - analyze uh you uh your previous usage
361:49 - history we have ec2 autoc Scan groups so
361:52 - asgs these automatically add or remove
361:54 - ec2 servers to meet the current demand
361:57 - all of traffic they will save you money
362:00 - and meet capacity since you only run the
362:02 - amount of servers you need then we have
362:04 - elb so elastic load balcer so this
362:07 - distributes traffic to multiple
362:08 - instances we can reroute traffic from
362:10 - unhealthy instances to healthy instances
362:13 - and can Route traffic to ec2 instances
362:15 - running in different availability zones
362:18 - and then we have elastic beant stock
362:19 - here which is easy for deploying web
362:21 - applications without developers having
362:23 - to worry about setting up and
362:25 - understanding the underlying ad services
362:27 - similar to Heroku it's a platform as a
362:29 - service so not all of these are about
362:31 - cost some of them are about capacity
362:33 - management like elb um but yeah there
362:36 - you
362:36 - [Music]
362:40 - go hey this is Andrew Brown from exam
362:42 - Pro and we are looking at the types of
362:44 - storage services and no matter what
362:46 - cloud service provider using they're
362:47 - usually broken down into these three
362:49 - where we have blocks file and um uh
362:52 - object okay so let's take a look at the
362:54 - first so this is going to be for Block
362:56 - storage so for AWS this is called
362:58 - elastic Block store data is split into
363:00 - evenly split blocks directly accessed by
363:03 - the operating system and supports only a
363:05 - single right volume so imagine you have
363:07 - an application uh over here and that
363:10 - application is using a virtual machine
363:12 - that has a specific operating system and
363:14 - then it has a drive mounted to it uh
363:17 - could be using FC or uh scuzzy here um
363:20 - but the idea here is when you need a
363:22 - virtual Drive attached to your VM is
363:23 - when you're going to be using block okay
363:26 - the next one here is for um file or it's
363:29 - just basically a file system so this is
363:31 - Abus elastic file storage so the file is
363:33 - stored with data and metadata multiple
363:36 - connections via a network share supports
363:39 - multiple reads writes locks the file so
363:42 - over here uh we could have an
363:44 - application but it doesn't necessarily
363:45 - have to be an application and so it's
363:47 - using NASA exports as the means to uh
363:50 - communicate and so the protocols here
363:51 - can be NFS or SMB which are very common
363:55 - uh file system protocols
363:57 - and so the idea here is when you need a
363:59 - file share where multiple users or VMS
364:01 - need to access the same drive so this is
364:03 - pretty common where you might have
364:05 - multiple virtual machines and you just
364:06 - want to act as like one uh Drive uh one
364:09 - example that could be like let's say
364:10 - you're running a Minecraft server you're
364:11 - only allowed to have one world on a
364:13 - particular single drive but you want to
364:15 - be able to have multiple virtual
364:17 - machines to maximize that compute that'
364:19 - be a case for that um so there you go
364:22 - then the last one here is like object
364:23 - storage and so for ads this is called
364:26 - Amazon simple storage service or also
364:28 - known as S3 so object is stored with
364:30 - data metadata and a unique ID scales
364:33 - with limited uh with limited no file
364:37 - limit or storage limit so there's really
364:40 - very there's very little limit to this
364:42 - it's just basically scales up supports
364:44 - multiple reads and wrs so there are no
364:46 - locks and so the protocol here we're
364:48 - going to be using htps and API so when
364:51 - you just want to upload files and not
364:53 - have to worry about the underlying
364:54 - infrastructure not intended for high uh
364:57 - IOP so input and outputs per seconds
365:00 - okay so depending on how fast you have
365:01 - to do your read and wrs are going to
365:03 - determine you know whether you're going
365:05 - uh this direction or the other way um or
365:08 - you know how many need to actually
365:10 - connect at at the same time and whether
365:11 - it has to be connected as a mount drive
365:13 - to the virtual machine
365:15 - [Music]
365:18 - okay hey it's Andrew Brown from exam Pro
365:21 - and we're going to do a short
365:22 - introduction into S3 because on the
365:24 - certified Cloud practitioner they ask
365:25 - you a little bit more than they used to
365:28 - and so we need to be a bit familiar with
365:29 - S3 because it is um at least I think
365:32 - that abis considers its Flagship uh
365:35 - storage uh service and it really is one
365:37 - of the earliest Services it was the
365:39 - second one ever launched okay so what is
365:42 - object storage or object based storage
365:43 - so data storage architecture that
365:45 - manages data as objects as opposed to
365:47 - other storage architectures so file
365:49 - systems where uh these are others right
365:51 - so which manages data as files and a
365:53 - hierarchy and block storage which
365:55 - manages data as blocks with with ins
365:57 - sectors and tracks that get stored on an
365:59 - actual uh drive and so uh the idea here
366:02 - is we have S3 which provides basically
366:04 - unlimited storage you don't need to
366:06 - think about the underlying
366:07 - infrastructure the S3 console provides
366:09 - interface for you to upload and access
366:10 - your data okay so we have the concept of
366:12 - S3 objects so objects contain your data
366:16 - they are like files but objects may
366:18 - consist of a key this is the name of the
366:20 - object a value the data itself made up
366:22 - of a sequence of bytes the version ID
366:24 - when versioning enabled the version of
366:26 - the object metadata additional
366:28 - information attached to the object and
366:30 - then you have your S3 buckets so buckets
366:31 - hold objects buckets can also have
366:33 - folders which in turn hold objects S3 is
366:36 - a universal name space so bucket names
366:38 - must be unique it's like having a domain
366:40 - name okay and one other interesting
366:42 - thing is an individual object can be
366:44 - between zero bytes and up to 5 terabytes
366:47 - so you have unlimited storage but you
366:49 - can't have uh files of uh incredible
366:52 - size uh I mean 5 terab is a lot but
366:54 - nothing beyond that for a single file
366:56 - but just understand that you can
366:58 - actually have a zerob byte file uh and
367:01 - for like associate certifications that
367:02 - can be a an actual question so that's
367:05 - why it's
367:06 - [Music]
367:09 - there all right let's take a look at S3
367:12 - storage classes um and so for the
367:14 - certified Cloud practitioner we need to
367:16 - know generally what these are for
367:17 - associate levels we need more detail
367:19 - than we have here but let's get through
367:20 - it so adus offers a range of S3 storage
367:23 - classes that trade retrieval time
367:25 - accessibility durability for for cheaper
367:27 - storage and so the farther down we go
367:29 - here the more cost effective uh it
367:31 - should get uh pending uh you know
367:34 - certain conditions okay so when you put
367:36 - something into S3 it's going to go into
367:37 - the standard uh tier the default tier
367:40 - here and this is uh incredibly fast it
367:43 - has
367:43 - 99.99% availability 119 durability and
367:47 - it's replicated across 3 azs and so uh
367:51 - you know we have this cheaper meter here
367:53 - here on the left hand side and that
367:55 - would apply this is very expensive and
367:56 - it's not actually expensive but it is
367:58 - expensive at scale when you can uh
368:00 - better optimize it with these other
368:01 - tiers so just understand that um then
368:04 - you have the S3 intelligent tiering so
368:06 - this uses ml to analyze objects and
368:08 - usage and determine the appropriate
368:09 - storage class it is moved to the most
368:11 - cost effective access tier without any
368:13 - performance impact or added overhead
368:16 - then you have S3 standard IIA which
368:18 - stands for infrequent access this is
368:20 - just as fast as S3 standard but it's
368:22 - cheaper if you access the files less
368:24 - than once a month there's going to be an
368:26 - additional retrieval fee applied so if
368:28 - you do try to retrieve data as
368:30 - frequently as S3 standard it's going to
368:32 - actually end up costing you more so you
368:34 - don't want to do that okay then you have
368:36 - S3 one zone IIA so as it says it's
368:39 - running in a single zone so it's as fast
368:41 - as S3 standard but it's going to have
368:43 - lowered availability but you're going to
368:44 - save money okay there is one caveat
368:47 - though your data could get destroyed
368:48 - because it's remaining in a single uh AZ
368:51 - so if that a or data centers um suffer a
368:54 - catastrophe you're not going to have uh
368:56 - a duplicate of your data to retrieve it
368:58 - okay um and then you have S3 Glacier so
369:01 - for long-term clothed storage retrieval
369:03 - of data can take minutes to hours but
369:06 - it's very very very cheap and then you
369:08 - have S3 Glacier uh deep archive which is
369:10 - the lowest cost storage class but the
369:12 - data retrieval is 12 hours and so you
369:15 - know um all of these here to here these
369:18 - are all going to be in the same uh ads
369:20 - S3 console or Amazon S3 console S3
369:23 - Glacier is basically like its own
369:24 - service but it's part of S3 so kind of
369:27 - lives in this weird State there's one
369:28 - here that we didn't have on the list
369:30 - here which is S3 outputs because it has
369:31 - its own storage class and doesn't
369:33 - exactly fit well into um this kind of
369:36 - linear cheaper uh thing here
369:39 - [Music]
369:43 - okay hey it's Andrew Brown from exam Pro
369:45 - and we are taking a look at the a snow
369:47 - family so this is storage and compute
369:49 - devices used to physically move data in
369:51 - or out of the cloud when moving data
369:53 - over the Internet or Prov private
369:55 - connection that is too slow difficult or
369:57 - costly so we have snow cone snowball
370:00 - Edge and snow mobile and so there
370:03 - originally was just snowball and then
370:05 - they came out with snowball Edge uh and
370:07 - Edge introduced Edge Computing that's
370:09 - why there's Edge in the name uh but
370:11 - pretty much all of these devices have
370:13 - Edge Computing uh and they do
370:15 - individually come with some variance so
370:17 - with the snowball snow cone it comes in
370:18 - two sizes where it has 8 terabytes of
370:20 - usable storage and then there's one with
370:22 - 14 tabt of usable storage for snowball
370:26 - Edge technically Ally has like four
370:27 - versions but I'm going to break it down
370:28 - to two for you we have storage optimized
370:31 - where we have 80 terab of use um uh of
370:35 - usable storage there and then compute
370:37 - optimize
370:38 - 3.9.5 terabytes and even though it's not
370:41 - here you get a lot of vcpus and
370:43 - increased memory which could be very
370:45 - important if you need to do Edge
370:46 - Computing before you send that over to
370:48 - AWS and then last here we have
370:50 - snowmobile which can store up to 100
370:53 - pedabytes of storage um in the
370:57 - Associates I cover these in a lot more
370:59 - detail because there's so much more
371:00 - about these like the security of them
371:02 - how they're tamperproof like how they
371:04 - have networking built in the the
371:05 - connection to them but you know for this
371:07 - exam that's just too much information um
371:10 - you just need to know that there are
371:11 - three uh three ones in the family and
371:13 - generally what the sizes are and that
371:15 - they're going to be all placed into
371:16 - Amazon S3 what's interesting is that you
371:19 - know snowmobile only does 100 pedabytes
371:21 - but adus markets it as you can move
371:24 - exabytes of of um content because you
371:26 - can order more than one of these devices
371:28 - so uh they'll mark it it saying like
371:30 - snowball Edge is when you want to move
371:32 - pedabytes of data and snowball Mobil is
371:34 - when you want to move exabytes but you
371:36 - can see that a single thing isn't in the
371:38 - exib it's just in the petabyte
371:40 - [Music]
371:44 - okay hey this is Andrew Brown from exam
371:46 - Pro and we are taking a look at all the
371:48 - itaba storage services in brief here so
371:50 - let's get to it so the first is simple
371:52 - storage service S3 this is a servess
371:54 - object storage service you can upload
371:56 - very large files and an unlimited amount
371:58 - of files you pay for what you store you
371:59 - don't worry about the UN file system or
372:01 - upgrading the dis size you have S3
372:03 - Glacier this is a cold storage service
372:05 - it's designed as a lowcost storage
372:07 - solution for archiving and long-term
372:09 - backup it uses previous generation uh
372:11 - HDD drives to get that low cost and it's
372:14 - highly secure and durable we have
372:16 - elastic Block store EBS this is a
372:18 - persistent block storage service it is a
372:20 - virtual hard drive in the cloud and you
372:21 - attach to ec2 instances you can choose
372:24 - different kinds of hard drives so SSD
372:25 - iops SSD throughput HDD and um cold hhd
372:31 - okay we have elastic file storage so EFS
372:34 - it is a cloud native NFS file system
372:36 - service so file storage uh you can mount
372:39 - to multiple ec2 instances at the same
372:41 - time when you need to share files
372:43 - between multiple servers we have storage
372:45 - Gateway this is a hybrid cloud storage
372:46 - service that extends your on premise
372:48 - storage to the cloud we got three
372:50 - offerings to your file Gateway so extend
372:51 - your local storage to Amazon S3 volume
372:54 - Gateway caches your local drive to s
372:56 - three so you have a continuous backup of
372:58 - the local files in the cloud tape
373:00 - Gateway so stores files onto virtual
373:02 - tapes for backing up your files on very
373:05 - cost effective long-term storage we got
373:07 - one more page here because there's a lot
373:08 - of services here we have adab us snow
373:11 - family so these are storage devices used
373:13 - to physically migrate large amounts of
373:15 - data to the cloud and so we have
373:17 - snowball and snowball Edge these are
373:19 - briefcase size data storage devices
373:21 - between 50 to 80 terab I don't believe
373:23 - snowball is available anymore it's just
373:25 - snowball Edge but it's good to have all
373:28 - of them in here so we can see what's
373:29 - going on we have snowmobile this is a
373:31 - cargo container filled with racks of
373:33 - storage and compute that is transported
373:35 - via a semi trailer tractor truck to
373:37 - transfer up to 100 pedabytes of data per
373:39 - trailer I don't think we're going to be
373:41 - ordering that anytime soon cuz that's
373:42 - pretty darn expensive but that's cool we
373:44 - have snow cone this is a very small
373:46 - version of snowball that can transfer 8
373:48 - terabytes of data we have adab us backup
373:50 - a fully managed backup service that
373:52 - makes it easy to centralize and automate
373:54 - the backup of data across multiple a
373:56 - services so ec2 EBS RDS DB EFS storage
374:00 - Gateway you create the backup plans we
374:02 - have Cloud endure disaster recovery so
374:05 - continuously replicates your machine in
374:06 - a lowcost staging area in your target
374:09 - abl account and preferred region
374:11 - enabling fast and reliable recovery in
374:13 - case of it data center failures we have
374:15 - Amazon FSX this is a feature Rich and
374:17 - highly performant fall system that can
374:19 - be used for uh windows so that would be
374:21 - using SMB or Linux which uses luster and
374:25 - so there we have the Amazon FS FSX for
374:27 - Windows file server so use SMB protocol
374:30 - and allow you to mount FSX to Windows
374:32 - servers and then the luster one which
374:34 - uses uh Linux luster file system it
374:37 - allows you to mount F FSX Linux servers
374:40 - are there any storage Services missing
374:41 - here not really I mean you could count
374:43 - elastic container repository as one but
374:46 - um that's kind of something else or you
374:48 - could also count maybe um uh code commit
374:52 - but you know I kind of put those in a
374:53 - separate category where we where those
374:55 - are in our develop tools or our
374:57 - containers
374:58 - [Music]
375:02 - okay all right so what I want to do is
375:04 - show you around S3 so we'll make our way
375:06 - up here and type in
375:09 - S3 and we'll let it load here and what
375:12 - we're going to do is create a new bucket
375:13 - if you do not see the screen just click
375:15 - on the side here go to buckets and we'll
375:17 - create ourselves a new bucket so bucket
375:19 - names are unique so let's say my
375:22 - bucket and we'll just pound in a bunch
375:24 - of numbers I'm sure you're getting used
375:25 - to making buckets in this um in this
375:28 - course so
375:29 - far um so if we scroll on down notice
375:32 - that it says block public access
375:33 - settings for this bucket and this is
375:35 - turned on uh like the blocking is turned
375:37 - on by default because S3 buckets are the
375:40 - number one thing that are a point of
375:43 - entry for malicious actors where people
375:44 - leave their buckets open so if we want
375:46 - to uh Grant access to this bucket for
375:50 - people to see this publicly we'd have to
375:51 - turn this off okay but for now we're
375:53 - going to leave that on you can version
375:55 - things in buckets which is pretty cool
375:57 - you can turn on encryption which you
375:58 - should turn on by default and use the
376:00 - Amazon S3 key on the certified Cloud
376:02 - preder it's going to ask you about
376:04 - client side encryption and server side
376:06 - encryption so you definitely want to
376:07 - know what these are I'm going to turn it
376:09 - off for the time being so we can kind of
376:11 - explore uh here by oursel here um then
376:14 - there's object lock so we can lock files
376:16 - so that um you know there you know
376:18 - people aren't writing to the multiple
376:20 - times so we'll go ahead and create a
376:22 - bucket and it's very quick so here is
376:24 - the new bucket we made and you'll notice
376:27 - we have nothing here which is totally
376:28 - fine if I go to
376:30 - properties um you know we can see that
376:33 - uh we can turn on bucket versioning turn
376:35 - on encryption what I'm going to do is
376:37 - I'm going to go grab some files I
376:39 - remember I saved uh some files recently
376:41 - here I'm just going to make a new folder
376:43 - called Star Trek I just have some
376:45 - graphics you can pull anything off the
376:46 - internet you want to do this
376:48 - yourself um but I'm just going to
376:50 - prepare a folder here it'll take me a
376:53 - moment
376:55 - okay just a
376:58 - moment okay great so now I have my
377:00 - folder prepared and so what I want to do
377:03 - is upload my first file so I can go here
377:05 - and upload and actually I can upload
377:07 - multiple files you can add a folder
377:09 - which is nice and so in here if I want
377:11 - to upload these files here whoops I'll
377:13 - just select multiples I'll hit open
377:15 - it'll cue them up which is really nice
377:17 - we can see the destination details here
377:19 - if we want to turn it uh versioning on
377:21 - we could there uh we could apply
377:23 - permissions for outside access but we
377:24 - have uh things turned on but what's
377:27 - really important is the properties where
377:28 - we have these different tiers and So
377:31 - based on the tier that you use the lower
377:34 - you go at least it should be the cheaper
377:36 - it's going to get uh but it's going to
377:39 - have some trade-offs and we cover that
377:40 - through the course then there's that
377:41 - server side encryption um and I'm going
377:44 - to hit upload we'll just individually
377:45 - turn it on so you're going to see this
377:47 - progress go across the top these have
377:49 - all been uploaded I'm going to cck click
377:50 - on my destination bucket and so what we
377:53 - can do is we can uh open these if
377:56 - they're images they'll show us right
377:58 - here in the browser we can download them
378:01 - so if we need to get them again all
378:04 - right we can create a folder here and
378:06 - just say Star Trek or Enterprise
378:11 - D Enterprise D
378:14 - here okay but it's not really easy it's
378:16 - not like I can drag this into there um I
378:19 - might be able there's no move option so
378:21 - you'd actually have to copy it into the
378:23 - destination and then delete the old one
378:25 - it's not like using a file system you
378:27 - know um there's a lot more work involved
378:30 - but you know it's a great storage
378:32 - solution um so let's look at encryption
378:34 - so I have this selected here if I click
378:36 - into it I can go to permissions I can go
378:40 - to versions see that I'm looking for H
378:43 - encryption here we go so if I turn it on
378:46 - I can enable encryption and I can choose
378:48 - whether I want to use an Amazon S3 key
378:50 - so SS S3 so an encryption key that
378:54 - Amazon S3 creates man uses for you then
378:57 - you have
378:58 - IUS SS KMS and I believe this uses AES
379:02 - up here which is totally fine then you
379:04 - have KMS down here and it's interesting
379:06 - because they're like ads will manage the
379:08 - key for you and then this one ads will
379:09 - manage the key for you it's just
379:10 - slightly different this one of course is
379:12 - a lot simpler there's not many reasons
379:14 - not to turn on encryption but U I'm
379:16 - going to go turn this one so that it is
379:18 - encrypted
379:19 - here and just because it's encrypted
379:21 - doesn't mean we can't access the file I
379:23 - can still download it I can still view
379:24 - it because ads is going going to decrypt
379:26 - it right so if I go and click on this
379:28 - one and I say open okay even though it's
379:31 - encrypted I can still view it right it
379:33 - just means that it's encrypted on the
379:35 - storage right so if somebody were to
379:36 - steal that hard drive whatever hard
379:38 - drive it's sitting on on ads they could
379:40 - even figure it out it's encrypted
379:42 - they're not going to be able to open up
379:43 - the file right so that is the logic
379:45 - there but through here um I can get it
379:48 - something that's really interesting with
379:50 - um um S3 is the ability to um uh have
379:55 - cycle events so I'm just kind of looking
379:57 - where that is it's usually in the bucket
379:59 - so if I go to management up here I can
380:01 - set up a life cycle rule and what I can
380:03 - do is say like move this to deep
380:07 - storage okay and then I can say what it
380:11 - is that I want to filter so maybe it's
380:13 - like data.jpg
380:16 - I can say apply to all objects in the
380:18 - bucket I acknowledge that and we say
380:20 - move current versions of objects between
380:21 - storage classes and I checkbox that on
380:23 - and I can say move them to Glacier after
380:26 - 30 days I think if I go lower it'll
380:29 - complain probably when I save there and
380:31 - so the idea is that we can move things
380:33 - into storage so maybe you have files
380:35 - coming in down below it's showing you
380:36 - here right so a file is uploaded and
380:39 - then after 30 days then move them in the
380:40 - glacier so we save money okay that's a
380:43 - big advantage of S3 there's a lot of
380:45 - things going on in S3 here like you can
380:48 - turn on
380:49 - um uh wherever it is you can turn
380:52 - on web hosting so you can turn this into
380:55 - like a website down below here there's a
380:58 - whole uh whole bunch of things that you
380:59 - can do okay so uh we're not going to get
381:01 - into that because that's just too much
381:02 - work but uh you know we learned the
381:05 - basics of S3 so what I want to do to
381:07 - delete this I have to empty it first
381:08 - watch it'll be like you cannot delete it
381:10 - you need to empty the bucket first so go
381:12 - ahead and empty it and I'll say my
381:14 - bucket
381:18 - empty or sorry I guess I have to type in
381:20 - permanently
381:23 - delete
381:24 - Perma
381:26 - net we delete no they used to oh yeah I
381:31 - can copy it okay great and so once the
381:34 - bucket is emptied I can go back to the
381:38 - bucket and I'll go back one layer and
381:42 - then I'll go ahead and delete my
381:45 - bucket and you can only have so many
381:47 - buckets I think it's like a 100 you have
381:49 - like 100
381:50 - buckets how many buckets can you have in
381:54 - a WS
381:57 - 100 buckets yeah I was
381:58 - right and I think if you wanted to know
382:01 - how many you Pro there's probably like a
382:02 - service limits page service limits
382:05 - service
382:07 - quotas so you go here you say a Services
382:13 - S3 how many buckets 100 right there okay
382:18 - so you know that gives you kind of an
382:19 - idea what's going on there but there you
382:21 - go that's
382:24 - S3 all right so let's go take a look at
382:27 - elastic Block store which is uh virtual
382:30 - hard drives for ec2 so what I'm going to
382:32 - do is make my way over to the ec2
382:33 - console because that is where it's at
382:35 - and on the Le hand side if we scroll on
382:37 - down you'll see elastic block volumes or
382:39 - elastic Block store volumes and so we
382:41 - can go here and the idea is we can go
382:43 - ahead and create ourselves a volume and
382:45 - what you'll notice is that we have a few
382:46 - different options here we have general
382:48 - purpose provisioned iops cold HDD
382:50 - throughput optimized magnetic magnetic
382:54 - being um basically like uh physical tape
382:57 - that you can use to back up like the old
382:58 - school stuff and so you have all these
383:00 - options here and you can choose the size
383:02 - so when you change these options you're
383:04 - going to notice that some things are
383:05 - going to change like the through uh
383:06 - throughput or iops so notice that
383:09 - general purpose is fixed at between 300
383:11 - to 3,000 and notice that it goes from 1
383:14 - Gigabyte to how many ever that is that's
383:16 - a lot there and so it's not too
383:18 - complicated but in practicality I don't
383:20 - really create volumes this way what I do
383:22 - is I'll just go launch an ec2 instance
383:24 - so I'll say launch ec2 instance and
383:27 - we'll choose Amazon alytic 2 and again
383:29 - you know if we haven't done the ec2
383:31 - follow along we'll cover all this stuff
383:33 - in more detail don't worry about it um
383:35 - we go to configure instance then we go
383:37 - to add storage and this is what you're
383:39 - going to be doing when adding EBS
383:41 - volumes um to your ec2 instances and
383:44 - you'll notice we always have a root
383:46 - volume that's attached to the ec2
383:48 - instance that we cannot remove we can
383:50 - change the size up here I believe the oh
383:52 - it shows us right here that we have up
383:53 - to 30 gigabytes so sometimes you might
383:55 - want to Max that out to take advantage
383:57 - of the free tier you notice we can also
384:00 - change uh this there might be some
384:01 - limitations in terms of the root volume
384:03 - so notice that we have a few more
384:05 - options here we can't have a cold HDD or
384:08 - HDD as our root volume uh notice we have
384:13 - a delete on termination so EBS volume
384:15 - persists independently from the running
384:16 - life so you can choose to automatically
384:18 - delete uh EBS volume when the associated
384:21 - instance is terminated so if you take
384:22 - this off if the ec2 instance is deleted
384:24 - the volume still remain which could be
384:26 - something that's important to you uh for
384:28 - encryption here um you might want to
384:30 - turn it on and so generally adus always
384:33 - has a KMS manage key which is free so
384:35 - you checkbox that on it will be
384:37 - encrypted uh you can turn it on later um
384:40 - but you can never turn encryption off
384:41 - but you should always uh turn the
384:43 - encryption on and so just be aware to
384:44 - turn that on you can also add file
384:46 - systems down below here but maybe we'll
384:48 - talk about that later because I think
384:50 - that gets
384:51 - into um e EFS okay so that is a
384:54 - different type of file storage there but
384:56 - that's pretty much all there is to it uh
384:59 - you just go ahead and create uh your
385:01 - volume there and then it would show up
385:02 - under EBS we could take snapshots of
385:05 - them to back them up that goes to S3 but
385:07 - that's all we really need to know here
385:10 - [Music]
385:13 - okay all right let's take a look at
385:15 - elastic file uh system or EFS uh storage
385:19 - manage file storage what does EFS stand
385:22 - for EFS system elastic file system okay
385:25 - sorry and so what we can do is go ahead
385:27 - and create a file system here so I'm
385:29 - going to say my EFS and the great thing
385:31 - is that it's basically a serverless so
385:33 - it's only going to be what you consume
385:35 - right so what you store and what you
385:36 - consume um and I think that's what it's
385:38 - going to be based on we have to choose a
385:40 - VPC I want to launch it in my default
385:42 - VPC and we have the choice of regional
385:45 - or one zone um I guess this is going to
385:48 - be based on what gets backed up to S3
385:51 - possibly so one zone probably is more
385:53 - cost effective but I'm going to choose
385:54 - Regional and that's a new Option I never
385:56 - noticed before I just opened it up to
385:57 - see a few more things here we have
385:59 - General Max iio bursting provision
386:02 - things like that we'll hit
386:03 - next we'll choose our
386:06 - azs and uh then you might have to set up
386:09 - a policy so I'm going to hit next here
386:12 - you'll go ahead and hit create so you
386:14 - know this is really interesting but the
386:16 - trick to it is really mounting it to a
386:19 - dc2 instance and that's kind of the pain
386:22 - okay so if we go into this um you you
386:25 - have to mount it and there are commands
386:28 - for it so like EFS mounting Linux
386:33 - commands okay I've done this in my
386:36 - Solutions architect associate uh but you
386:38 - know again I'm not doing on a regular
386:39 - basis so I don't remember and so if we
386:42 - go here I'm just trying to see if we can
386:44 - see some code that tells us how to mount
386:46 - it so mounting on an E2 uh uh uc2 Linux
386:51 - instance with the EFS Mount helper um so
386:55 - I don't know if they had that before but
386:56 - that sounds interesting so pseudo Mount
386:58 - hyphen T the file system the EFS
387:00 - mounting
387:01 - Point yeah this looks a lot easier than
387:04 - what we had before okay so before I had
387:07 - to enter a bunch of weird commands but
387:09 - now it looks like they've boiled it down
387:10 - to single command but once you have your
387:12 - EFS
387:13 - instance
387:15 - um I'm going to assume that there is an
387:17 - entry point here just clicking around
387:20 - here seeing what we can see I would
387:22 - imagine we have to create an access
387:23 - point so my access
387:27 - point sure I don't know if it's going to
387:30 - let me just do that it did and so I
387:33 - would imagine that you'd probably use an
387:34 - access point let's go back here ifs
387:36 - Mount point I think that's the same
387:38 - thing I think the mount point and the
387:40 - access point you create access points
387:41 - and that's what you use uh we can go
387:44 - here we can attach it so oh yeah here's
387:45 - the command
387:47 - so um Mount via DNS or Mount via IP
387:51 - address
387:53 - so it doesn't look too hard
387:56 - we can try to give it a go I haven't
387:57 - done it in a while it looks like they've
387:59 - made it easier so maybe we'll try it out
388:02 - okay so we go to ec2
388:04 - here and I'm going to launch an instance
388:09 - I'm going to choose Amazon L
388:11 - 2 okay we're going to go and choose that
388:15 - and then we want to choose a file
388:19 - system and
388:22 - so it's going to mount to here
388:25 - okay and storage is fine all this is
388:29 - fine and I'm going to go ahead and
388:30 - launch
388:33 - this and I need a new key pair so create
388:37 - a new key pair um this will be for EFS
388:40 - example
388:42 - okay we're going to download that key
388:44 - pair there we're going to launch this
388:50 - instance okay and then we're going to go
388:53 - view this and as that is launching what
388:55 - I'm going to do is open up my cloud
388:57 - shell and I'm going to want to upload
389:00 - this pen so again like before I'm going
389:03 - to drag it to my desktop off screen and
389:06 - then what I'm going to do is upload this
389:09 - file so I have
389:11 - it EFS
389:13 - example okay we're going to upload
389:16 - it because I just want to see if we can
389:18 - access that EFS volume and so if I do
389:23 - LS that's our old one one which I can
389:25 - delete by the way I'm never going to use
389:27 - that anytime soon
389:28 - yes LS and I'm going just delete the
389:31 - hello text there so it's a bit cleaner
389:33 - for what we're doing and so we need to
389:35 - chod that
389:38 - 400 uh EFS
389:41 - example and we saw that's how like if
389:43 - you want to try to connect to a server
389:45 - remotely that's what you do right so I
389:47 - believe that the drive is
389:50 - mounted if I go to storage does it show
389:52 - up
389:53 - here doesn't show up under
389:56 - here but
389:58 - um what we're waiting for are these two
390:00 - status checks to pass and then we can
390:02 - SSH into this
390:05 - machine and I'm just going to go back
390:07 - here and take a look here so using the
390:09 - EFS Mount helper so pseudo Mount hyphen
390:12 - T EFS TLS this volume to EFS and so I
390:16 - imagine it's going to mount it to EFS
390:18 - here using the NFS client so I guess it
390:20 - just depends on what we're going to have
390:22 - available to us even if the status
390:24 - checks haven't passed I'm going to try
390:25 - to get into this
390:27 - anyway um so what we can do is click on
390:31 - this grab the public IP address we'll
390:34 - type in
390:35 - SSH um ec2 hyphen user at sign paste
390:38 - this in hyphen I EFS example pem I
390:42 - usually don't log in Via
390:44 - SSH um but you know just for this
390:47 - example I will and so I want to see if
390:50 - this drive
390:51 - exists usually be under mount right
390:55 - there it is okay so it already mounted
390:57 - for us so I can do touch hello
391:02 - world.
391:04 - text say pseudo
391:07 - here I can say pseudo VI I'm going to
391:09 - open up the file and say hello from
391:12 - another computer
391:15 - okay and so I've saved that file and
391:17 - what I want to do
391:19 - now
391:21 - oops oh okay sorry I'm in the cloud
391:24 - shell here but what what I want to do
391:25 - now is I want to kill this
391:27 - machine okay and what I'm going to do is
391:29 - spin up another ec2 instance I'm going
391:31 - to see if I when I mount that if that
391:33 - file is there if it actually worked but
391:36 - wow that is so much easier than before I
391:38 - can't tell you how hard it was to attach
391:40 - an EFS volume the last time I did it um
391:42 - so we'll go ahead We'll add that and the
391:45 - storage is fine we're going to go to
391:46 - review here we're going to say launch
391:48 - and I'm just going to stick with the
391:49 - same key pair
391:51 - there we're going to give that moment to
391:54 - to launch and we're going to go to view
391:58 - instances and so now this one is
392:00 - launching as it's launching let's just
392:01 - go peek around and see what we can see
392:03 - so you know I imagine if we didn't add
392:05 - that file system during the the boot um
392:08 - and we were we're adding it after the
392:10 - fact we probably could just ran that
392:11 - line and added it really easily um I'm
392:13 - not going to bother testing that because
392:15 - I just don't want to go through that
392:17 - trouble to do that um I still can't
392:19 - remember what these access points are
392:21 - for um but uh it's okay it's that's kind
392:24 - of out of the scope for the certified
392:25 - Cloud
392:26 - partitioner and then so I'm just curious
392:29 - so we get some nice monitoring here
392:32 - right so that's kind of
392:35 - nice um I guess they're trying to
392:37 - suggest here like inabus backup data
392:39 - sync
392:41 - transfer so that would just be backing
392:43 - up simplify uh automates accelerates
392:46 - moving data okay that's pretty
392:47 - straightforward transfer family fully
392:49 - managed F SFTP okay so nothing exciting
392:53 - there
392:55 - and we're going to refresh that there
392:57 - and this is initializing so let's go see
392:59 - if we can connect to this one so I'm
393:00 - going to go ahead grab that public IP
393:02 - address I'm going to hit up okay I'm
393:05 - going to swap out that IP address and
393:06 - we're going to see if we can connect to
393:07 - that machine yet so we'll say yes and we
393:11 - got into it so that's great and so what
393:12 - I'm going to do is go again into the
393:14 - mount directory EFS FS1 LS and there it
393:17 - is I'm going to do cat hello world and
393:19 - so it works and so that's the cool thing
393:22 - about DFS is that you have a file system
393:24 - that you can share among other um uh ec2
393:28 - instances I'm sure users could connect
393:30 - to it using the NFS protocol I'm not the
393:32 - best at like networking or storage
393:34 - networking so I'm not going to show that
393:36 - here to you today but that gives you a
393:37 - general idea how EFS works again you
393:40 - only pay for what you store it is
393:42 - serverless so we'll go here and type
393:44 - delete because I'm done with this I'll
393:46 - probably uh destroy the instance first
393:48 - so it doesn't get mixed
393:51 - up and just so we clean up a little bit
393:54 - better here I'm going to delete these
393:55 - Keys
393:56 - here uh
394:02 - Delete okay and we'll go ahead and
394:04 - delete this one as
394:07 - well delete I'm done with
394:11 - that uh we'll make sure that that is
394:13 - tearing down that is good and we'll make
394:16 - our way back over here and it says enter
394:19 - probably the ID's name in so we'll enter
394:21 - that in and we hit
394:22 - confirm and we'll see is it deleting I'm
394:25 - not confident with it I'm going to do it
394:26 - one more time confirm that by entering
394:28 - the the file systems ID so we'll put it
394:30 - in
394:35 - again is it destroying I cannot tell
394:38 - there we go so it's destroying we are in
394:40 - good shape it is gone our data is gone
394:43 - um but yeah that is
394:45 - [Music]
394:48 - EFS all right let's take a look at um
394:51 - the snow family in ads so if we type in
394:53 - snow up here and we click into Adis snow
394:56 - family this is where we can probably
394:57 - order ourselves a device um I might not
395:01 - be able to order them at least when I
395:02 - originally looked at this like way back
395:04 - in the day uh it wasn't available in
395:06 - Canada so I'm kind of curious to see
395:07 - what there is but the idea is that
395:09 - you're going to go here and Order and
395:11 - you have some options so you can import
395:12 - into S3 or export from S3 and then down
395:15 - below we have local compute storage so
395:17 - perform local compute storage workloads
395:19 - without transferring data you can order
395:21 - multiple devices and clusters for
395:22 - increased durability and storage Capac
395:24 - so it sounds like you're not you're not
395:26 - um transferring data you're just using
395:29 - it uh locally on to um it's like
395:32 - basically buying renting temporary
395:33 - computers which just kind of interesting
395:35 - I never saw that option before but we're
395:37 - going to choose import into a ss3 and
395:40 - we're just going to read through this
395:41 - stuff and it's not my expectation that
395:42 - we're going to even be able to submit a
395:44 - job here and you probably don't want to
395:46 - because it's going to cost money but I
395:47 - just want to show you the process so we
395:49 - can see what there is here so snow job
395:51 - assistance if you're new to snow family
395:53 - run a pilot of one to two devices so
395:55 - batch file smaller than 1 Megabyte
395:58 - Benchmark and optimize deploy St uh
396:00 - staging
396:01 - workstations discover and remediate
396:03 - environmental uh issues early files and
396:05 - folders name must conform to Amazon S3
396:08 - prepare your Ami once the pilot is
396:10 - completed confirm the number of snow
396:11 - family devices that you can copy devices
396:14 - to simultaneously follow the best
396:16 - practices use the following resources to
396:18 - manage your snow devices so we have adab
396:20 - US Open Hub and then there's the edge
396:22 - client CLI
396:25 - so open Hub is a graphical user
396:26 - interface you can use to manage snow
396:28 - devices so that's kind of cool and then
396:30 - we have the CLI which I imagine is is
396:32 - something that's very useful to use so
396:35 - just close those off here and then we
396:36 - have other things so I can say I
396:37 - acknowledge I know what I'm doing which
396:39 - I don't really but that's okay and then
396:41 - here we are going to enter in our
396:43 - address so we say Andrew Brown and I'm
396:46 - not going to I'm not going to enter this
396:47 - in for real just whatever so it would be
396:50 - Toronto exam Pro um Canada oh see so
396:55 - there's there's the thing you can only
396:56 - ship it to the US and so that's as far
396:59 - as I can get okay um and that's the
397:02 - thing is like if you really want to know
397:04 - any of us inside or not you got to be in
397:06 - the US but let's pretend that we do have
397:08 - an address in the states what's a very
397:10 - famous address so what is the address of
397:14 - the White House
397:16 - okay there it
397:18 - is so I'm just going to copy that
397:22 - in because again we're not going to
397:24 - submit this for real I just want to see
397:27 - what's farther down the line here
397:30 - okay uh what's
397:33 - NW is that the state it's in Washington
397:37 - right is is this part of it NW Northwest
397:39 - is that a thing I'm from Canada so I
397:42 - couldn't tell you um so we'll go down
397:45 - here and we have Washington do we have a
397:47 - second address line it doesn't look like
397:49 - it
397:50 - um we have a zip code I believe this is
397:53 - the zip code
397:56 - and do we need a phone number looks like
397:58 - we do
397:59 - 416 uh 111 11111 okay we have one day or
398:04 - two day shipping why not just have one
398:07 - right and so then we can choose our type
398:09 - of device so we have snow cone snow cone
398:12 - SSD snow cone optimized I'm surprised I
398:15 - never took a screenshot of this earlier
398:17 - um compute optimize things like that so
398:19 - you can choose which one you want it
398:21 - looks like we're gonna see some
398:22 - different options but we'll go with snow
398:23 - cone
398:24 - my snow
398:27 - cone and snow cones do not ship with a
398:30 - power supply or ethernet cable snow cone
398:32 - devices are powered by 45 watt CB C uh
398:36 - USBC power supply I'll provide my own
398:39 - power supply and cable do not ship with
398:41 - a power supply res cable that's fine uh
398:44 - snow con Wireless snow con connect your
398:46 - wireless connection connect the buckets
398:48 - you want there's the bucket we created
398:50 - earlier Computing use compute using E2
398:54 - instance is use a device as a mobile
398:56 - data center by loading ec2 Ami so here's
398:59 - an Ami that I might want to
399:01 - use uh ad iot green grass validated Ami
399:04 - not interested in Remote device
399:05 - management you can use Ops Hub or Etc to
399:08 - monitor reboot your device that's fine
399:11 - and so then we need to choose our
399:14 - security
399:15 - key I don't know if we have to set the
399:17 - service roll we'll see what happens here
399:20 - and uh we'll let it update that's fine
399:23 - and and so then I guess we just hit
399:25 - create job and so I don't really want to
399:27 - order one um so I'm not going to hit
399:29 - that button and also it's going to go to
399:31 - the White House and they're going to be
399:32 - like Andrew Brown why did you do that so
399:34 - that's not something I feel like doing
399:36 - today but at least that gives you an
399:38 - idea of that process there and I imagine
399:40 - that uh if you go the other way it's
399:42 - going to be pretty similar yeah it's
399:43 - just like same stuff I think uh so you
399:47 - it Sav that address it's not a real
399:49 - address and the the options are a little
399:52 - bit uh limited here and it's like NFS
399:55 - Bas S3 Bas so it's slightly different
399:57 - but it's basically the same process just
399:59 - curious we'll take a look at the last
400:00 - one
400:02 - there since there are three options just
400:07 - curious okay Sim similar thing okay so
400:10 - yeah that's pretty much all I want you
400:12 - to know about um the snow family and
400:14 - that's about it
400:15 - [Music]
400:18 - okay hey this is Andrew Brown from exam
400:21 - Pro and we are taking a look at what is
400:22 - a database so a database is a data store
400:26 - that stores semi-structured and
400:28 - structured data and just to emphasize a
400:30 - bit more a database stores more complex
400:33 - data stores because it requires using
400:35 - formal design and modeling techniques so
400:37 - databases can generally be categorized
400:39 - as either being relational so structured
400:41 - data that strongly represents tabular
400:44 - data so we're talking about tables rows
400:46 - and columns so there's a concept of row
400:49 - oriented or column oriented and then we
400:51 - have non relational databases so these
400:54 - are semi-structured that may or may not
400:56 - distinctly resemble tabular data so here
400:59 - is a very uh simple example the idea is
401:01 - that you might use some kind of language
401:03 - like SQL put in your database and you'll
401:05 - get back out tables for relational
401:07 - databases let's just talk about some of
401:08 - the functionality that these databases
401:10 - have so they can be uh using a special
401:13 - specialized language to uh query so
401:15 - retrieve data so in this case SQL
401:17 - specialized modeling strategies to
401:19 - optimize retrieval for different use
401:21 - cases uh more fine tune control over the
401:23 - transformation of the data into useful
401:26 - data structures or reports and normally
401:28 - a database infers uh someone is using
401:30 - using a a relational row oriented data
401:33 - store so um you know just understand
401:35 - that when people say database that's
401:37 - usually what they're talking about like
401:37 - postgress MySQL relational row store is
401:41 - usually the default but obviously
401:42 - there's a lot more broader terms there
401:45 - [Music]
401:48 - okay hey this is Andrew Brown from exam
401:51 - Pro and we are taking a look at what is
401:53 - a data Warehouse so it's a relational
401:55 - data store designed for analytical
401:57 - workloads which is generally column
401:59 - oriented data store okay so companies
402:02 - will have terabytes and millions of rows
402:04 - of data and they'll need a fast way to
402:06 - be able to produce analytics reports so
402:09 - data warehouses generally perform
402:10 - aggregation so aggregation is the idea
402:13 - of grouping data together so find a
402:14 - total or an average uh and data
402:16 - warehouses are optimized around columns
402:19 - since they need to quickly aggregate
402:20 - column data and so here is kind of a
402:23 - diagram
402:24 - of um a data warehouse and so the idea
402:26 - is that it could be ingesting data uh
402:29 - from a regular database here I'm just
402:31 - getting out my pen tool so it could be a
402:32 - regular database or it be coming from a
402:34 - different data source that isn't
402:35 - compatible in terms of the schema and
402:37 - you use like ETL or elt uh or ETL to get
402:41 - that data into that data warehouse so
402:44 - data warehouses are generally designed
402:46 - uh to be hot so hot means that they can
402:48 - return queries very fast even though
402:50 - they have vast amounts of data data
402:52 - warehouses are in free quently access
402:54 - meaning they aren't intended for
402:55 - real-time reporting but maybe once or
402:57 - twice a day uh or once a week to
402:59 - generate business and uh user reports of
403:02 - course it's going to vary based on the
403:04 - um the service that is offering the data
403:06 - warehouse a data warehouse needs to
403:07 - consume data from a relational database
403:09 - on a regular basis and again it can
403:11 - consume it from other places but you'll
403:12 - have to transform it to get it in there
403:15 - [Music]
403:18 - okay hey this is Andrew Brown from exam
403:21 - Pro and we're taking a look at a key
403:22 - value store so a key Value store or
403:24 - database is a type of non-relational
403:26 - database or nosql that uses a simple key
403:28 - Value method to store data and so key
403:31 - value stores are dumb and fast uh but
403:33 - they generally lack features like
403:34 - relationships indexes aggregation of
403:37 - course there are going to be providers
403:38 - out there have managed solutions that
403:40 - might uh po fill some of those uh issues
403:42 - there but I want to show you the
403:44 - underlying way that key value stores
403:45 - work to kind to kind of distinguish them
403:48 - between document stores so a key value
403:50 - stores literally a unique key alongside
403:53 - a value
403:54 - and the reason I'm representing that as
403:55 - zeros and ones is because I want you to
403:57 - understand that that's what it is it's
404:00 - basically just some kind of of data
404:03 - there and how the key value uh store
404:06 - interprets it is going to determine what
404:07 - it is so when you look at a document
404:09 - database that is just a key value store
404:12 - that uh uh interprets the value as being
404:15 - documents right and so key value stores
404:18 - can and do commonly store um uh multiple
404:23 - uh like associate array that's pretty
404:24 - common so even for Dynamo DB that's how
404:27 - it does it and so that's why when you
404:28 - look at a key Value Store it looks like
404:31 - it uh a a table but it's not actually a
404:34 - table it's schema list because
404:36 - underneath it's really just um you know
404:38 - that associative array and so that's why
404:40 - you can have uh columns or sorry rows
404:43 - that have uh different amounts of
404:46 - columns okay so due to the design they
404:49 - are able to scale very well beyond a
404:52 - relational database and they can kind of
404:53 - work like a relational database without
404:55 - all the bells and whistles so hopefully
404:57 - you know that makes sense
404:58 - [Music]
405:02 - okay all right let's take a look at
405:05 - document stores so a document store is a
405:06 - nosql database that stores documents as
405:09 - its primary data structure and a
405:11 - document could be an XML uh type of uh
405:15 - structure but it also could be something
405:17 - like Json or Json like document stores
405:19 - are sub classes of key value stores uh
405:22 - and the components of of a document
405:24 - store are very uh comparable to
405:27 - relational databases so just kind of an
405:29 - example here where in a relational
405:31 - database they'd be called tables now you
405:33 - have collections they were called rows
405:35 - now they're called documents you had
405:36 - columns they had Fields they may have
405:39 - indexes and then joins might be called
405:41 - embedding and linking so you can
405:42 - translate that knowledge over uh you
405:45 - know they they're not as um they don't
405:47 - have the same kind of feature set as a
405:49 - relational database but you have better
405:51 - scalability and honestly document stores
405:53 - are just key value stories with some
405:54 - additional features built on top of it
405:57 - [Music]
406:01 - okay hey it's Andie Brown from exam Pro
406:03 - and we're going to take a look at the
406:04 - nosql database services that are
406:06 - available on AWS so we have Dynamo DB
406:08 - which is a serverless no skill key value
406:10 - and document database it is designed to
406:12 - scale to billions of records with
406:14 - guaranteed consistent data returned in
406:17 - at least a second you do not have to
406:19 - worry about managing shards and Dynamo
406:22 - DB is 's Flagship database service
406:25 - meaning whenever we think of a database
406:27 - service that just scales is cost
406:28 - effective and very fast we should think
406:30 - of Dynamo DB and in 2019 Amazon the
406:33 - online shopping retail uh shut down
406:35 - their last Oracle database and completed
406:37 - their migration to Dynamo DB so they had
406:40 - 7,500 Oracle databases with 75 pedabytes
406:43 - of data and with Dynamo DB they reduced
406:46 - that cost by 60% and reduce the latency
406:48 - by 40% so that's kind of to be like a
406:51 - testimonial between relational and a no
406:53 - escol database so when we want a
406:55 - massively scalable database that is what
406:58 - we want Dynamo db4 and I really just
407:00 - want to put that there because it if you
407:02 - remember that you're going to always be
407:04 - able to pass uh or get those questions
407:06 - right on the exam okay then we have
407:08 - document DB so this is a Noll document
407:10 - database that is mongod DB compatible uh
407:13 - so mongodb is very popular noo among
407:16 - developers there were open source
407:18 - licensing issues around using open
407:19 - source mongodb so ad got around it by
407:21 - just building their own mongodb database
407:23 - basically so when you want a mongod DB
407:26 - like database you're going to be using
407:28 - document DB we have Amazon key spaces
407:31 - this is a fully managed Apachi Cassandra
407:33 - database so Cassandra is an open source
407:35 - no esql key value database similar to
407:37 - Dynamo DB that is column or store
407:39 - database but has some additional
407:41 - functionality so when you want to use
407:42 - apachi Cassandra you're using Amazon
407:45 - keyspaces
407:46 - [Music]
407:50 - hey this is Andrew Brown from exam Pro
407:52 - and we are taking a look at relational
407:53 - database Services starting with
407:55 - relational database service RDS and this
407:57 - is a relational database service that
407:59 - supports multiple SQL engines so
408:02 - relational is synomous with SQL and
408:04 - online transactional processing
408:06 - oltp and relational databases are the
408:08 - most commonly used type of database
408:11 - among tech companies and startups just
408:13 - because they're so easy to use I use
408:15 - them I love them um RDS supports the
408:17 - following SQL engines we first have
408:20 - MySQL so this is the most popular open
408:22 - source SQ database uh and it was
408:24 - purchased and is now owned by Oracle uh
408:27 - and there's an interesting story there
408:29 - because when Oracle purchased it they
408:31 - weren't supposed to have it um Mario DB
408:33 - was or sorry myell was sold to Oracle
408:35 - Sun systems and then within the year um
408:39 - uh Oracle purchased it from them and the
408:42 - original creators never wanted it to go
408:43 - to Oracle um just because of their uh
408:46 - the way they do licensing and things
408:47 - like that and so um the original
408:50 - creators came back and they decided to
408:52 - Fork my
408:53 - and then maintain it as Mario DB just so
408:56 - that uh you know oracle never kind of
408:58 - pushed away the most popular database so
409:01 - that everyone had to go to a paid
409:02 - solution then you have postest so psql
409:05 - as it's commonly known is the most
409:07 - popular open source SQL database among
409:09 - developers this is the one I like to use
409:11 - because it has so many Rich features
409:13 - over my school uh but but it does come
409:15 - with added complexity then Oracle has
409:17 - its own SQL proprietary database which
409:20 - is well used by Enterprise companies but
409:22 - you have to buy a license to use it then
409:24 - you have Microsoft SQL so Microsoft's
409:27 - proprietary SQL database and with this
409:29 - one you have to buy a license to use it
409:31 - uh then you have Aurora so this is a
409:33 - fully managed database uh and there's a
409:36 - lot more to uh going on here with Aurora
409:38 - so we'll talk about it it almost acts as
409:40 - a separate service but it is powered by
409:42 - RDS so Aurora is a fully managed
409:45 - database of either myql so five times
409:47 - faster or postgress SQL three times
409:50 - faster database so when you want a high
409:53 - available durable and scalable and
409:55 - secure relational database for post
409:57 - custom isqu you want to use Aurora uh
410:00 - then you have Aurora serverless so this
410:02 - is a serverless ond demand version of
410:03 - Aurora so when you want the most of the
410:05 - benefits of Aurora but you can trade uh
410:08 - off to have cold starts or you don't
410:10 - have lots of traffic or demand uh this
410:12 - is a way you can use Aurora in a
410:13 - serverless way then you have RDS on
410:16 - VMware so this allows you to deploy RDS
410:18 - supported engines to on premise data
410:20 - centers uh the data center must be using
410:23 - VMware for Server virtualization so when
410:25 - you want databases managed by RDS on
410:27 - your own database Center uh and yeah I
410:30 - realize that this is a small spelling
410:32 - mistake should say just on here but yeah
410:34 - there you
410:35 - [Music]
410:38 - go hey this is Andrew Brown from exam
410:40 - Pro and we're looking at the other
410:42 - database services that abos has because
410:44 - there's just a few loose ones here so
410:45 - let's talk about red shift so it is a
410:47 - petabyte siiz data warehouse and data
410:49 - warehouses uh are for online analytical
410:52 - process procing oap and data warehouses
410:55 - can be expensive because they are
410:56 - keeping data hot meaning that they can
410:58 - run a very complex query and a large
411:01 - amount of data and get that data back
411:02 - very fast so when you need to quickly
411:05 - generate analytics or reports from a
411:06 - large amount of data you're going to be
411:08 - using red shift then you have elastic
411:10 - cache so this is a managed database of
411:12 - an inmemory and caching open source
411:15 - databases such as reddis or memcache so
411:17 - when you need to improve the performance
411:18 - of an application by adding a caching
411:20 - layer in front of your web servers or
411:21 - database you're going to be using
411:23 - elastic cash then you have Neptune this
411:26 - is a managed graph database the data is
411:28 - represented as interconnected nodes I
411:31 - believe that it uses Gremlin as the way
411:33 - to interface with it which is no
411:34 - surprise because that's what it looks
411:36 - like most class providers are using so
411:39 - when you need to understand the
411:40 - connections between data so mapping
411:42 - fraud Rings or social media
411:43 - relationships uh very relational
411:45 - database heavy information you're going
411:47 - to want to use Neptune we have Amazon
411:49 - time streams it's a fully managed time
411:51 - series database so think of devices that
411:53 - send lots of data that are
411:54 - time-sensitive such as iot devices so
411:57 - when you need to measure how things
411:58 - change over time we have Amazon Quantum
412:01 - Ledger database this is a fully managed
412:04 - uh Ledger database that provides
412:05 - transparent immutable cryptographically
412:08 - variable transaction logs so when you
412:10 - need to record a history of financial
412:12 - activities that can be trusted and the
412:15 - last one here is database migration
412:16 - service DMS it's not a database per se
412:19 - but it's a migration service so you can
412:22 - uh migrate from on premise database to
412:24 - adabs from two databases in different or
412:27 - same adabs accounts using different SQL
412:28 - engines and from an SQL to a nosql
412:31 - database and I'm pretty sure we cover
412:32 - this in a bit uh greater detail in this
412:34 - course
412:36 - [Music]
412:39 - okay all right let's go take a look at
412:42 - Dynamo DB uh which is ad's nosql
412:45 - database so we'll go over to Dynamo
412:49 - DB and what we'll do is create ourselves
412:52 - a new table to say my Dynamo DB table
412:58 - and you always have to choose a
412:59 - partition key you don't necessarily have
413:01 - to have a sort key but it could be
413:02 - something
413:03 - like um like you want it to be really
413:07 - unique so it could be like email and
413:09 - this one could be uh created at
413:12 - right and so we have string binary
413:15 - notice that the the types are very
413:17 - simple then for settings we have default
413:19 - settings or customized settings so the
413:20 - default is use provision capacity mode
413:22 - rewrite five rules Etc custom no
413:26 - secondary indexes use KMS so I'm going
413:28 - to just expand that to see what I'm
413:30 - looking at we have two options here on
413:33 - demand uh so simplify billing by paying
413:35 - the actual reads and rights you use or
413:37 - provisioned which is this is where you
413:39 - get a guarantee of performance so if you
413:41 - want to be able to do you know whatever
413:43 - it is a thousand I don't know what it
413:45 - goes up to but like a thousand read
413:47 - writs per second then that's what you're
413:48 - paying for okay you're paying for being
413:51 - a having a guarantee of that um of that
413:55 - capacity okay I'm not going to create
413:56 - any secondary indexes but that's just
413:58 - like another way to uh look at data
414:01 - notice down below that we have a cost of
414:04 - $2.9 uh then we have encryption at rest
414:06 - so you can do owned by Amazon Dynamo DB
414:08 - that's pretty much the same as like adab
414:11 - us has or S3
414:12 - has ssse S3 there you could use uh C
414:18 - actually I guess both of these are
414:19 - probably KMS I would imagine we'll go
414:21 - ahead and create the table here
414:24 - and that's going to create the table
414:25 - this is usually really really
414:28 - fast we'll go here and what we can do is
414:32 - insert some data so as it's just
414:34 - starting up here we can go over
414:36 - to our tables they recently changed its
414:39 - UI so that's why I look a bit
414:42 - confused U view items up here okay and
414:45 - then from here we can create an item so
414:47 - I can add something say so Andrew
414:50 - exampro doco and
414:55 - 2021
414:57 - uh well we'll just do the future so
414:59 - we'll say 20
415:01 - 25 055 I don't want to have to think too
415:03 - hard here but we can add additional
415:05 - information so I can say like uh today
415:11 - true we could say
415:14 - um make like a
415:17 - list uh you know food and then I could
415:22 - go here here and then add a
415:24 - string it is not working oh there we go
415:28 - there we are so we could say like um
415:31 - banana and then we could say pizza right
415:34 - we can go ahead and create that
415:36 - item and so now that item is in our
415:39 - database uh we can do a scan that will
415:41 - return all items we can query we can
415:42 - actually have uh some limitations of
415:44 - what we're choosing there's the party Q
415:46 - editor so we can use SQL to select it um
415:51 - I have not used this
415:53 - before party Q um AWS or party Q Dynamo
416:01 - DB
416:04 - examples I'm hoping I can just find like
416:07 - an example of some of the language
416:08 - getting started here I don't need to I
416:10 - don't need an explanation I just show me
416:12 - an example query here and I will I'll
416:15 - get to it
416:17 - here okay so here's some examples right
416:19 - so maybe we can give this a go uh um so
416:23 - we have our table here so my
416:27 - Dynamo DB
416:30 - table and I just want the email
416:33 - back we don't need a
416:37 - wear we'll run this see if it
416:42 - works there we go I'm not sure if we
416:46 - could select additional data there so I
416:47 - know that we had some other things like
416:49 - uh
416:51 - food
416:53 - there it is okay so that's really nice
416:56 - um addition to it dynb can stream things
417:00 - into a Dynamo DB stream to go to Kinesis
417:02 - and do a lot of fun things so there all
417:04 - sorts of things you can do with Dynamo
417:05 - DB but um I'm pretty much done with this
417:08 - so I'm going to go ahead and delete this
417:11 - table and notice that it also creat some
417:13 - cloudwatch alarm so we want to delete
417:15 - this as well create a backup no we do
417:16 - not care go ahead and delete
417:19 - that and that is Dynamo DB
417:25 - [Music]
417:27 - okay so now I want to show you uh RDS or
417:29 - relational database service so go to the
417:31 - top here type in RDS and we'll make our
417:34 - way over there and so RDS is great
417:37 - because it allows us to launch
417:39 - relational databases um sometimes the UI
417:42 - is slow I'm not sure why it's taking so
417:44 - long to load today but every day is a
417:46 - bit different and so what we're going to
417:48 - do is go ahead and create a new database
417:50 - uh you're going to notice that we're
417:51 - going to have the op between creating a
417:53 - standard or easy I stick with standard
417:55 - just because I don't like how easy hides
417:58 - a lot of stuff from us even here like it
418:01 - says two cents per hour but it's not
418:03 - giving us the full cost so I really
418:05 - don't trust it because if you go down
418:06 - here and you chose their Dev test here
418:09 - look it's like $100 it's not showing the
418:11 - the the cost preview right now maybe
418:13 - because we didn't choose the database
418:15 - type sorry I wanted to chose postgress
418:17 - but before we do that let's look at the
418:19 - engine types we have Amazon Aurora so we
418:21 - have between myell and post postgress
418:22 - MySQL Marb postgress Oracle Microsoft
418:26 - SQL no for Microsoft SQL it comes with a
418:29 - license you don't have to do anything
418:31 - with that it might change based on the
418:33 - addition
418:34 - here uh nope comes with a license for
418:37 - all them which is great uh if you want
418:39 - to bring your own license that's where
418:40 - you need a dedicated host right running
418:42 - uh Microsoft SQL for Oracle uh you have
418:46 - to bring your own license that's going
418:47 - to be based on um importing with the Aus
418:50 - license manager over go over to postest
418:53 - which is what I like to use uh we're
418:55 - going to set it to Dev test to try to
418:56 - get the cheapest cost scroll down look
418:57 - $118 we can get it cheaper we get super
419:00 - cheap so here the password is going to
419:02 - be testing one two three capital on the
419:05 - T so and an exclanation mark on the end
419:08 - okay because it has a bunch of
419:09 - requirements of what it wants here I
419:11 - want a T2 micro so I'm just going to
419:14 - scroll down
419:16 - here what is going on here standard oh
419:19 - look M classes I don't want an m class
419:22 - class I want a burstable class that's
419:23 - the cheap ones and so we go here can we
419:27 - still do a T2 micro or is it now
419:29 - T3 so I don't see
419:32 - T2 so I imagine a T3 micro must be the
419:35 - new it free tier so we go it fre tier
419:38 - here right and if I go
419:42 - to
419:47 - databases um RDS on the t2 micro 750
419:51 - hours but I can't select
419:53 - it
419:55 - so I'm going to assume that the T3 micro
419:59 - must be the new tier if it's not there
420:01 - right unless it's saying include
420:03 - previous
420:04 - generations and then maybe I can see it
420:10 - then okay so I don't see it
420:14 - there I really don't like how they've
420:16 - changed this on
420:19 - me okay so the oldest I can choose is a
420:21 - T3 micro which is fine I just I just
420:24 - know T2 being the free tier that's all
420:26 - uh this is fine we don't want Auto
420:28 - scaling turned on for our example here
420:30 - we do not want a multi-az so do not
420:33 - create a standby that's going to really
420:35 - jump up our cost we don't need Public
420:37 - Access it will create a VPC that is fine
420:40 - password authentication is fine we have
420:42 - to go in here which I don't know why
420:43 - they just don't keep that expanded
420:44 - because you always have to come in here
420:46 - name your database so my database we
420:49 - choose your postest version here I'm
420:51 - going to turn backups off
420:52 - uh because if we don't if we don't it's
420:55 - going to take forever to launch this
420:56 - thing encryption is turned on you can
420:59 - turn it off but generally it's not
421:01 - recommended we can have performance
421:03 - insights turned on I'm going to turn the
421:05 - retention oh we'll leave it to seven
421:07 - days because we can't turn that off we
421:09 - don't need enhanced monitoring so I'm
421:10 - just going to turn that
421:12 - off and uh that's fine we're not going
421:15 - to enable delete protection here and so
421:19 - we are good we can now go ahead and
421:21 - create our dat
421:26 - database and what we'll do here is wait
421:29 - for that database to be created so the
421:31 - thing is is like if we're doing the
421:33 - solutions architect or the developer
421:36 - social stuff I'd actually show you how
421:37 - to connect to the database um it's not
421:40 - that hard to do like you just have to
421:41 - connect uh grab all the database
421:44 - information so it's going to have an
421:45 - endpoint a port stuff like that and you
421:47 - use something like table Plus or
421:49 - something to connect to the database but
421:51 - that's out of scope of the certified
421:53 - Cloud partitioner I'm just going through
421:54 - the motions to show you that you can
421:56 - create an RDS database very easily but
421:59 - not how to connect to it and actually
422:01 - utilize it okay and so that would spin
422:03 - up and we would have a server and after
422:06 - that we can just go ahead and delete the
422:07 - server here so to say delete me
422:12 - okay and that's all there really is to
422:15 - it there is the special type of um
422:17 - database like Aurora doesn't have its
422:19 - own like console page it's part of RDS
422:21 - so if you want to spend up Aurora you
422:23 - just choose the compatibility you want
422:25 - you can choose between provisioned or
422:27 - serverless um and serverless is supposed
422:29 - to be really good for um scaling to zero
422:32 - cost so that's something there so you
422:34 - fill that all out but the initial cost
422:36 - is a lot more expensive you can't choose
422:37 - a T2 micro here um unless it lets you
422:41 - now it is
422:43 - for provision it's
422:46 - uh oh T2 T3 medium is the smallest you
422:50 - can go Okay so if you reach to the point
422:52 - where using a a medium-sized database
422:55 - then you might consider moving over to
422:56 - Aurora just because it's going to be
422:58 - highly scalable Etc like that um so
423:01 - that's a consideration there there's
423:02 - also something called Babble fish um
423:04 - that it was announced last year when I
423:06 - when I shot this um or when I'm shooting
423:09 - this as of now and the idea was to make
423:11 - it compatible with MyQ SQL Server to
423:13 - migrate over to Aurora post SQL which is
423:16 - kind of interesting um but that's about
423:18 - it so if our database is destroying I
423:20 - think it is just going to go back over
423:21 - over here to
423:25 - RDS it's taking a long time to load
423:32 - today and uh I think it's already
423:34 - deleted maybe we go to databases here
423:36 - it's deleting so I'm confident it's
423:38 - going to delete so there we
423:40 - [Music]
423:43 - go all right let's take a look at Red
423:46 - shift so red shift is a data warehouse
423:48 - and it's generally really expensive so
423:50 - it's not something that you're going to
423:51 - want to launch uh day to-day here but
423:53 - let's see how far we can get with it um
423:55 - just by running through it so what we'll
423:58 - do is go ahead and create a cluster and
423:59 - again you can just watch me do this you
424:00 - don't have to create uh you don't have
424:01 - to create one yourself uh so free trial
424:03 - configure for learning that sounds good
424:05 - to me uh is free for limited time if
424:07 - your organization has never created a
424:09 - cluster why rarely ever create these so
424:11 - when the trial ends delete your cluster
424:12 - to avoid the charges of on demand okay
424:15 - that sounds fair um so here we're going
424:18 - to have two vpcu it's going to launch a
424:20 - d a DC to
424:24 - large so let's look that up for
424:30 - pricing show me prices please please
424:36 - please
424:39 - um I think it's loading right here okay
424:42 - so I don't know how much it is but I
424:44 - know it is not cheap and down below we
424:47 - have sample data is loaded into your red
424:49 - shift cluster that sounds good to me
424:51 - ticket is the sample data
424:53 - okay ticket sample
424:56 - data red shift I just imagine they
424:59 - probably have like a tutorial for it
425:01 - here they do right
425:04 - here and so because I want to know what
425:06 - we need to do to query it right if we
425:08 - can even query it via the interface here
425:10 - so the admin user is adus user um and
425:13 - the password is going to be capital T
425:14 - testing 123 4 5 6 exclamation and we'll
425:18 - hit create
425:20 - cluster oh cool we can query the data
425:22 - right in here so that's what I wasn't
425:23 - sure about whether we would be able to
425:26 - just query it in line because before
425:28 - you'd have to use Java with j jdbc or an
425:31 - odbc driver and download the jar and
425:35 - it's not as fun as it sounds of course
425:38 - but it looks like we can query data once
425:39 - the data is
425:41 - loaded so that looks really good I guess
425:44 - we can pull data in from um the
425:46 - marketplace so that's looks pretty nice
425:49 - too and I guess we could probably integr
425:51 - into other things like quick site
425:53 - because you probably want to adjust your
425:54 - data over
425:55 - there again I usually don't spend a lot
425:58 - of time in red shift um but it looks
426:00 - like it's a lot easier to use I'm very
426:01 - impressed with this so I don't know how
426:03 - long it takes to uh launch a red shift
426:05 - cluster I mean it is 160 gigabytes uh of
426:09 - of of storage there it's uh even at the
426:12 - smallest it's pretty large so what I'm
426:14 - going to do is to stop the video and
426:15 - I'll be back when this is done
426:17 - okay okay so after a short little wait
426:20 - here um it was lot lot faster than I was
426:22 - expecting but uh it's available and so
426:24 - looks like here it says to query the
426:25 - sample data use red shift version two so
426:28 - I'm going to click that and I'm sure
426:29 - there's tons of buttons to get here and
426:31 - it'd be great if it just populated the
426:33 - query for me um it doesn't but this
426:35 - looks really nice really nice UI I
426:38 - wonder if it has like some existing
426:40 - queries no that's okay so what I'm going
426:43 - to do here is I'm going to go ahead and
426:47 - pull out this query and see if we can
426:49 - get this to work here never found out
426:51 - what those prices were
426:53 - though okay and what we'll do is hit run
426:57 - I like how there's like a limit of 100
426:59 - but here it has that so we'll go ahead
427:00 - and hit run and see what data we get so
427:03 - relation sales does not exist okay
427:08 - so what's going on
427:13 - here um we'll go up here so most of the
427:15 - examples in the red shift documentation
427:17 - uses uh a sample database call ticket
427:19 - this sample uh this small database
427:21 - consists of seven tables you can load
427:23 - the ticket data set by following the
427:25 - this
427:27 - here okay so to load the sample data
427:30 - from Amazon
427:35 - S3 okay
427:38 - so I would have thought it already had
427:40 - the data in there I could have swore it
427:42 - would
427:44 - have
427:46 - Dev
427:50 - public
427:53 - tables zero
427:55 - tables okay so I don't think there's any
427:58 - data in here and so we're going to have
428:00 - to load it
428:01 - ourselves I really thought it would have
428:03 - added it for us uh let's go ahead and
428:05 - create these tables and see if this is
428:07 - as easy as we think so run that create
428:10 - that
428:12 - table cool okay we got it down
428:16 - here we'll run that we just run each at
428:19 - a
428:20 - time I think there's seven of them
428:32 - so date already exists okay that's fine
428:35 - event already exists saying all these
428:37 - tables
428:39 - exist maybe I just wasn't
428:47 - patient
428:49 - okay um
428:52 - interesting all right so maybe we'll go
428:54 - back and uh run that query maybe we just
428:56 - had to wait a little while for that data
428:58 - to
428:59 - load
429:02 - run okay so you know what I think it was
429:05 - doing this for us like if if the if it
429:07 - did not create it for us we would have
429:09 - to go through all these steps which is
429:11 - fine because we're learning a little bit
429:12 - about um uh red shift but um uh looks
429:17 - like we just had to wait there so it
429:18 - looks like you would run those you
429:19 - download that you use the copy command
429:22 - to bring it over there um it looks like
429:24 - you can do all of this via the uh this
429:26 - interface here and we've done a query so
429:28 - that's kind of
429:29 - cool um I imagine you probably could
429:32 - like save it or export it what if we
429:33 - chart it what happens okay you can chart
429:36 - it that's kind of
429:39 - fun can we export it out to oh just we
429:42 - can save it I thought maybe it could
429:43 - export out to Quick site but I I suppose
429:45 - you'd rebuild it in quick site a but
429:47 - yeah I guess that's it right there so
429:49 - that's pretty darn simple so so what I'm
429:51 - going to do is make my way back over to
429:53 - Red shift because we are done for this
429:58 - example and we will go over to clusters
430:01 - here and I'm going to go ahead
430:04 - and delete my
430:09 - cluster
430:11 - delete create file snapshot
430:14 - nope
430:16 - delete delete the cluster there we go so
430:20 - I'm pretty sure that will succeed no
430:21 - problem there and we are done with red
430:23 - shift and red shift is super expensive
430:25 - so just make sure that thing deletes
430:28 - [Music]
430:31 - okay hey this is Andrew Brown from exam
430:34 - Pro and we are taking a look here at
430:35 - Cloud native networking Services um and
430:38 - so I have this architectural diagram I
430:40 - created which has a lot of networking
430:41 - components uh when people create
430:43 - networking diagrams for adws they don't
430:45 - always include all these things here
430:47 - even though they're there so we're just
430:48 - being a little bit verbo so you can see
430:50 - okay the first thing is our VPC our
430:52 - virtual private Cloud this is a
430:54 - logically isolated section of the adus
430:56 - cloud where you can launch adus
430:57 - resources that's where your uh resources
431:00 - are going to reside not all services uh
431:02 - require you to select a VPC um because
431:05 - they're managed by AWS but I wouldn't be
431:07 - surprised if under the hood they are in
431:08 - their own VPC Okay then if you want uh
431:12 - the internet to reach your services
431:13 - you're going to need an internet gateway
431:15 - um then you need to figure out a way to
431:17 - Route things to your various subnets and
431:20 - that's where route tables uh come in
431:23 - then we need to Def Define a region that
431:26 - it's going to be which is a geographical
431:28 - location on your network then you have
431:30 - your availability zones which are
431:32 - basically your data centers where your a
431:33 - resources are going to reside then you
431:35 - have subnets which is a logical
431:37 - partition of an IP network into multiple
431:39 - smaller Network segments um and these
431:42 - pretty much map to your uh availability
431:44 - zones if you're making one per a and
431:47 - then we have knackles these act as a
431:49 - firewall at the subnet level then we we
431:51 - have security groups that act as a
431:52 - firewall at the instance level so
431:54 - hopefully that gives you a good overview
431:56 - [Music]
432:00 - okay all right so now let's take a look
432:02 - at Enterprise or hybrid networking so we
432:04 - have our on premise uh environment or
432:06 - your private cloud and then we have our
432:08 - ads account or our public Cloud so
432:10 - there's a couple Services here that we
432:11 - can Bridge them together the first is
432:13 - ADS virtual private Network VPN it's a
432:16 - secure connection between on premise
432:18 - remote offices and mobile employees then
432:21 - you have direct connect this is a
432:22 - dedicated gigabit connection from on
432:24 - premise data center to ads so it's a
432:26 - very fast connection a lot of times the
432:28 - direct connect we say it's a a private
432:30 - connection but that doesn't necessarily
432:31 - mean secure it's not encrypting uh the
432:33 - data in transit so very commonly these
432:36 - services are used together not just
432:38 - singular okay um and then uh we have
432:41 - private links and so this is where you
432:43 - already uh are using ads but you want to
432:46 - keep it all within ads never going out
432:47 - to the internet okay so these are
432:49 - generally called VPC interface endpoints
432:52 - and then the marketing Pages call them
432:53 - private links which is a bit confusing
432:55 - but you know it just keeps traffic
432:57 - within the aabus network so it does not
432:58 - transverse out to the internet
433:00 - [Music]
433:04 - okay hey this is Andrew Brown from exam
433:07 - Pro and we are taking a look at vpcs and
433:09 - subnets so a VPC is a logically isolated
433:11 - section of the adus network where you
433:13 - launch your adus resources and you
433:15 - choose a range of ips using a cider
433:17 - range so a cider range is an IP address
433:20 - followed by this uh net mask or sub
433:23 - submask and that's going to determine
433:24 - how many IP addresses there are um and
433:26 - there's a bunch of math behind that
433:28 - which we're not going to get into um but
433:31 - anyway so here is an architectural
433:32 - diagram just showing a VPC with a couple
433:34 - subnets so subnets is a logical
433:37 - partition of an IP network into multiple
433:40 - uh smaller Network segments and so
433:42 - you're essentially breaking up your IP
433:43 - ranges for vpcs into smaller networks so
433:46 - just thinking about cutting up a pie
433:48 - okay so subnets need to have a smaller
433:50 - cider range uh to uh the vpcs represent
433:54 - for their portion so uh 4/24 is actually
433:58 - smaller which is interesting the the
434:00 - higher the number gets the smaller it
434:01 - gets and so this would allocate 256 IP
434:04 - addresses and so that's well smaller
434:07 - than 16 okay we have the concept of a
434:10 - public subnet so this is one that can
434:11 - reach the internet and a private subnet
434:13 - the one that cannot reach the internet
434:15 - and um these are not uh strictly
434:18 - enforced by AWS so the idea is that when
434:20 - you have a subnet you can just say don't
434:23 - by default assign publicly assignable IP
434:26 - addresses but it's totally possible to
434:28 - launch an ec2 instance into your private
434:31 - subnet and then turn on um uh the IP
434:35 - address so you got to do other things to
434:36 - ensure that they stay private or public
434:39 - [Music]
434:42 - okay hey it's Andrew Brown from exam Pro
434:45 - and we are comparing security groups
434:46 - versus knackles so I have this nice
434:48 - architectural diagram that has both
434:50 - knackles and security groups in them and
434:52 - we'll just kind of talk about these two
434:54 - so knackles stand for network access
434:56 - control lists and they act as a virtual
434:57 - firewall at the subnet level and so here
435:00 - you can create an allow uh and deny
435:03 - rules and this is really useful if you
435:05 - want to block a specific IP address
435:07 - known for abuse and and I'm going to
435:09 - just kind of um compare that against
435:11 - security groups because that's going to
435:12 - be a very important difference okay so
435:14 - security security groups act as a
435:16 - firewall at the instance level and they
435:18 - implicitly deny all traffic so you
435:20 - create only allow rules so you can allow
435:23 - an ec2 instance to access port on uh
435:26 - Port 22 for SSH but you cannot block a
435:29 - single IP address and the reason I say
435:31 - that is because in order for you to
435:33 - block a single IP address in Security
435:35 - Group you would literally have to block
435:36 - or you literally have to allow
435:38 - everything but that IP address and
435:40 - that's just not feasible okay so if you
435:42 - can remember that one particular example
435:44 - you'll always be able to remember the
435:46 - difference between these two one other
435:48 - thing that um any of us likes to do is
435:50 - is ask which which ones are stateless
435:51 - which ones are stateful but at the uh
435:53 - Cloud partitioner level they're not
435:55 - going to be asking you that
435:56 - [Music]
435:59 - okay all right let's learn a bit about U
436:02 - networking with AWS so what I want you
436:04 - to do is go to the top and type in VPC
436:07 - which stands for virtual private cloud
436:08 - and what we'll do is set up our own VPC
436:10 - it's not so important that you remember
436:12 - all the little bit of details but you
436:13 - get through this so that you can
436:15 - remember the major components so what
436:17 - I'll do is create a new VPC I'm going to
436:18 - call this my VPC
436:21 - uh tutorial and here I'm going to say
436:23 - 10.0.0.0
436:25 - sl16 the reason you're wondering why I'm
436:27 - doing that if we go to
436:30 - xyxy Z here um this tells you the size
436:34 - of it so I go here and I put 16 so you
436:36 - can see we have a lot of room if we do
436:38 - 24 it takes up it it it's smaller see so
436:41 - this is basically the size of it right
436:43 - the empty blocks over here so we're
436:45 - going to have a lot of room so we do 10
436:47 - 00 16 we don't need IPv6 we're going to
436:51 - go ahead and create that and once we
436:53 - have that we can go ahead and create a
436:54 - subnet which we will need so we're going
436:56 - to choose our VPC we'll go down here and
436:59 - say my Subnet
437:01 - tutorial and we'll choose the first a z
437:04 - you can leave it blank and it'll choose
437:05 - it random and then we need to choose a
437:07 - block that is smaller than the current
437:08 - one so 16 would be definitely um uh well
437:13 - 16 is the size that we have now so we
437:15 - can match that size but
437:17 - 10.0.0.0 sl24 would be absolutely small
437:21 - okay so we go ahead and create that
437:24 - subnet and so that is all set up now um
437:30 - let's see if our route table is hooked
437:31 - up so our route table says where it
437:33 - links to and it says to local so it's
437:36 - not going anywhere and that's because we
437:37 - need to attach a u internet gateway that
437:41 - allows us to reach the internet so if we
437:43 - go over here and create a new internet
437:45 - gateway we'll say my
437:47 - igw and we'll go ahead and create that
437:51 - and what we'll do is associate that with
437:54 - our VPC we created here okay and so now
437:59 - that we have the internet gateway
438:00 - attached we want that subnet to make its
438:03 - way out to the Internet so if we go to
438:05 - the route table we can edit the uh route
438:08 - table Association here I like how it
438:10 - keeps on showing me this as if I don't
438:12 - know what I'm doing um but I do and
438:16 - so this would change that particular
438:19 - Association but I want to add to that
438:21 - route table so I thought when I click
438:24 - that it would allow me to add more but
438:25 - apparently I got to go to Route tables
438:26 - over
438:27 - here and I'm looking for the one that is
438:30 - ours we can see that it's over here we
438:32 - could even name it if we wanted to like
438:34 - my rote
438:36 - table notice then we apply uh uh uh
438:39 - names it's actually just applying a tag
438:41 - see over here it's always what that
438:43 - is so we'll go over to routes and we
438:46 - want to edit the routes and we want to
438:48 - add a route and we want this to go to
438:51 - and we're going to choose the internet
438:52 - gateway
438:54 - okay we're going to say save
438:57 - changes and what that's going to allow
438:59 - us to do is to reach the
439:03 - internet um and so what I want to do is
439:05 - go back to subnet I was just curious
439:07 - about this I've never used this
439:09 - before um so looks like we can just
439:12 - choose some options here I'm not too
439:14 - concerned about that but I assume like
439:16 - that's used for debugging azers had
439:18 - those kind of services for a long time
439:19 - and so it has been starting to add those
439:21 - so you can easily debug your network
439:23 - which is nice so we have a subnet the
439:27 - subnet uh can reach the internet because
439:29 - there's a there's
439:31 - um uh an internet gateway and it's
439:34 - hooked up via the route table one thing
439:35 - that matters is will it assign a public
439:38 - IP address um so that is something that
439:41 - we might want to look into it's not the
439:44 - default subnet which is totally fine so
439:46 - it says Auto assign is no so that might
439:49 - be something that you might want to
439:50 - change
439:51 - so here we go to edit the r table
439:53 - Association no it's not there they
439:56 - changed it on me used to be part of the
439:58 - uh setup instructions us to just
439:59 - checkbox it now they moved it modify the
440:02 - auto assign so we'll say enable so that
440:04 - means it's always going to give it a
440:05 - public IP address on
440:08 - launch and while we're here I'm just
440:10 - going to double check if I have any
440:11 - elastic IPS I did not release okay just
440:13 - double checking here and
440:15 - so this is all set up and we should be
440:18 - able to launch a um ec2 now within our
440:21 - our new VPC so I'll go over here to
440:25 - ec2
440:27 - okay and I'm going to launch a new
440:30 - instance say Amazon El
440:33 - 2 we're going to choose this tier
440:36 - Here and Now what we should be able to
440:38 - do is Select
440:40 - that and that is our subnet there
440:44 - okay go ahead and launch that I don't
440:46 - care if we use a key whatsoever so I'm
440:48 - going to go ahead and launch that there
440:52 - okay we'll go
440:56 - back and so there you go it is launching
440:58 - so we created our VPC and we launched uh
441:00 - in it no problem
441:02 - whatsoever so hopefully that is pretty
441:04 - darn
441:05 - clear um so yeah uh what I'm going to do
441:08 - is I'm going to let that launch because
441:10 - I want to show you security groups So
441:13 - within AWS you can set security groups
441:15 - and knackles and that's going to allow
441:17 - or deny access based on stuff and when
441:20 - we launched this ECU instance it has a
441:22 - default security group that was assigned
441:24 - we could have created a new one but what
441:25 - I might want to do is create myself a
441:27 - new Security Group
441:28 - here okay and you can end up with a lot
441:32 - really fast like here's a bunch and I
441:34 - can't even tell what's what so like
441:36 - there's Bunch for load balancers and
441:38 - things like that and so I might just go
441:40 - ahead and delete a bunch of these
441:41 - because I cannot tell what is going on
441:44 - here and um we'll delete these security
441:49 - groups and sometimes they won't let you
441:51 - delete them because they're associated
441:52 - with something like a network interface
441:53 - or
441:58 - something all right but um we need to
442:01 - find out which one we're using right now
442:03 - so the one that we are using is the
442:05 - launch wizard 4 so we'll go into
442:08 - here and I don't know if you can rename
442:11 - them after they've been created I don't
442:12 - think so which is kind of frustrating
442:14 - because if you want to rename it it's
442:15 - like I don't want that to be the name so
442:18 - what's interesting is you can go here
442:19 - and you can edit the
442:21 - routes uh the rules sorry the inbound
442:24 - rules and the outbound rules and so here
442:25 - it's open on Port 22 so that allows us
442:28 - to ssh in we could drop this down and
442:30 - choose different things so if we want
442:32 - people to access a website we go Port 80
442:34 - and we say from anywhere ipv 46 so now
442:37 - anyone can access it um you might want
442:40 - to do something like give it access to
442:43 - postgress that runs on Port 5432 things
442:46 - like that um could be something else
442:49 - like maybe you need to connect to Red
442:50 - shift that's on that Port you can go
442:52 - ahead and save those rules we're just
442:54 - going to say uh from anywhere you can
442:56 - even say my IP so maybe only I'm allowed
442:58 - to connect to it right so you added
443:01 - inbound rules you don't really ever have
443:03 - to touch outbound rules it's set for all
443:05 - traffic so it's stuff that's
443:07 - leaving uh the that there one
443:10 - interesting thing to note about uh
443:12 - security groups is
443:14 - that you don't have a deny option right
443:18 - so let's say you only wanted a
443:20 - particular IP address you only wanted um
443:22 - let's say what's my IP my IP
443:25 - address so that is my IP address and
443:27 - let's
443:28 - say I wanted to block it right so I go
443:32 - here and I say okay I want to
443:35 - block on all TCP I want to block this
443:38 - number right but I can't do that all I
443:41 - can say is I allow this number so in
443:43 - order to do it I would have to enter
443:44 - everything but this number in here and
443:46 - you can enter ranges in with like these
443:49 - forward slashes and stuff like that but
443:50 - you would imagine that'd be really hard
443:51 - because you have to start and go like
443:53 - you'd have to start and go through every
443:54 - single IP address in the world to get it
443:56 - out of here and that's almost impossible
443:58 - and that's the key thing I want to
443:59 - remember about security
444:01 - groups um so that's security groups and
444:03 - there's also
444:06 - knackles knackles um they're associated
444:09 - with subnet so they probably show up
444:10 - under VPC I rarely touch knackles rarely
444:13 - ever have
444:14 - to um I mean they're great tools but you
444:18 - know for me I I just don't ever need
444:19 - them so knackles are associated with
444:23 - subnets so we can go here and try to see
444:26 - my Subnet tutorial so we created our
444:28 - subnet we got a knle for free and we can
444:30 - set inbound and outbound rules and so
444:33 - here here is where we could say Okay I
444:36 - want to add a new
444:37 - rule and I want to and I want to make
444:40 - the rule number
444:41 - 150 you always do these in hundreds okay
444:44 - or the power of 10 so that you can move
444:45 - them around easily and I can say all
444:48 - traffic that comes from this IP address
444:53 - I'm going to put the for/ Z that just
444:54 - means a single IP address and I say deny
444:58 - right and so
444:59 - now uh this my address I can't access
445:03 - that ec2 instance okay if I try to go
445:05 - there's nothing running on the server
445:06 - but if I was to try to use it I wouldn't
445:07 - be able to do it and and this applies to
445:10 - anything for that subnet it's not for a
445:12 - particular instance it's for anything in
445:13 - that subnet so hopefully that is is
445:15 - pretty clear there um but that's pretty
445:18 - much all you really need to know I mean
445:19 - there's lots of other stuff like Network
445:21 - firewalls all these other things it gets
445:23 - pretty
445:24 - complicated um it's well beyond what we
445:26 - need to learn here but uh what we'll do
445:28 - is tear down that ec2
445:31 - instance okay we'll terminate
445:35 - that and once that instance is destroyed
445:37 - we can get rid of our security group and
445:38 - a bunch of other
445:41 - stuff and there's always a bunch of
445:43 - these darn
445:46 - things so we'll say
445:48 - delete
445:52 - One Security Group
445:56 - Associated so we go here this is the one
445:58 - we are using but I want to get rid of
445:59 - all these other
446:05 - ones okay if I go here it could be
446:07 - because like of inbound
446:09 - rules so see this one because you can
446:12 - reference another Security Group within
446:14 - a security group so I'm just going to go
446:15 - save that there say any my IP there
446:18 - whoops
446:21 - it's set to n uh NFS so that might have
446:23 - been set up for our access
446:28 - point or I could just delete it that'
446:30 - probably be
446:32 - easier okay so that's one that's kind of
446:35 - of a
446:36 - pain so I'm just looking for rules that
446:39 - might be referencing other security
446:43 - groups to get rid of
446:46 - them okay let's try this again
446:56 - we'll go ahead and delete I'm leaving
446:58 - the
447:00 - um I'm leaving the uh the defaults alone
447:03 - because those come with your vpcs and
447:05 - you don't want to get rid of
447:08 - those so it won't let me delete this one
447:12 - so I'm going to go edit that
447:13 - rule delete it save it you might not
447:17 - have this kind of clean up to do it's
447:19 - just might be me here you
447:22 - know um outbound
447:25 - inbound let's try this again
447:33 - here
447:37 - delete and I'll open this one
447:42 - up must be this one that is referencing
447:45 - the other
447:48 - one
447:51 - I'm just going to delete the
447:56 - rule and this is something that's just
447:58 - kind of frustrating with AWS but it's
448:00 - just how it is where sometimes it's hard
448:02 - to get rid of resources because you have
448:04 - to click through stuff so it's not
448:05 - always a clean you might have like
448:07 - lingering resources and this isn't going
448:09 - to cost us anything but it's just the
448:10 - fact that
448:12 - um that it just makes things harder to
448:16 - see what you're doing you
448:18 - know
448:20 - this last one really doesn't want to go
448:25 - away so I'm just trying to delete all
448:27 - the rules out of here get rid of
448:29 - it can I delete this one
448:33 - now one group associate it will not show
448:36 - me what it's talking about okay here it
448:38 - is
448:42 - um okay this is referencing
448:45 - it I think it was the one there was an
448:47 - old one I don't know what this is
448:57 - we'll go down
448:59 - here and we'll go here and delete that
449:02 - and while I've been cleaning all these
449:04 - up now we can go over to our inst
449:05 - instance make sure that it's terminated
449:07 - it is good because if our instance is
449:09 - not terminated we cannot destroy the VPC
449:12 - uh prior the VPC could not be destroyed
449:13 - unless you detach the internet gateway I
449:15 - wonder if it's going to still complain
449:16 - about
449:18 - that we'll say yes it actually looks
449:20 - like it includes it in the
449:23 - cleanup typ delete
449:29 - here there we go so we're all good we're
449:32 - all cleaned up there you
449:34 - [Music]
449:37 - are hey this is angre Brown from exam
449:39 - Pro and in this video I just want to
449:41 - show you cloudfront so let's make our
449:42 - way over to cloudfront cloudfront is a
449:45 - Content delivery Network and it's used
449:47 - to cash your data all over the place as
449:49 - you can see I have some older ones here
449:51 - if you have a splash screen what you can
449:53 - do is just look for the left hand side
449:54 - there might be a hamburger menu open
449:56 - that up and then click on distributions
449:58 - and what we're going to do is create a
449:59 - new distribution if you don't want to
450:01 - create one because these do take forever
450:03 - to create um you can just kind of watch
450:05 - along I don't even feel like I'm going
450:06 - to hit the um the create distribution
450:09 - button because I just hate waiting for
450:10 - so long but the idea is that you have to
450:12 - choose an origin and so the origin could
450:13 - be something like an S3 bucket load
450:15 - balancer media store this is where um
450:18 - the the content distribution network is
450:20 - going to Source its content right so if
450:23 - I say this bucket here um and I just it
450:27 - probably default to the root path the
450:29 - idea is that it's going to be able to
450:30 - pull content from there and then cach it
450:32 - everywhere and then down below you can
450:34 - say okay set the type of protocol
450:37 - redirect to here you can set up uh
450:40 - caching rules or like how often do you
450:42 - want it to uh cash like cash a lot don't
450:45 - cash a lot the great thing is like you
450:47 - have these Edge or these um l Edge
450:49 - function so you can uh read and modify
450:53 - the request and response to the CDN
450:55 - which is very powerful but what I'm
450:57 - going to do is I'm just going to go look
450:58 - at what we already have because again I
450:59 - said they take forever to spin up and
451:02 - we're not going to see too much if we do
451:04 - so once it's spun up um this is what it
451:06 - looks like so you'll have an origin it
451:09 - says where it's poting to you can create
451:10 - multiple Origins group them uh you can
451:13 - modify your behavior so that was
451:15 - basically what we were looking at before
451:16 - as you can see we have our Behavior
451:17 - there nothing super exciting
451:19 - we can set up error Pages you can
451:21 - restrict based on geographical locations
451:24 - so if you're for whatever reason if you
451:25 - if you're not allowed to serve content
451:28 - in UK you could say exclude this
451:30 - geographical region right so you have an
451:32 - allow list or a block list saying like
451:34 - Okay we can't do UK because like let's
451:36 - say you just don't want to do um let say
451:39 - England you don't want to do um uh gdpr
451:42 - for whatever reason you could block out
451:44 - I don't know why I'm having a hard time
451:45 - here Britain England it's England right
451:48 - United Kingdom there we go so you just
451:51 - say okay forget United Kingdom I don't
451:53 - have to do gdpr now uh for invalidations
451:56 - the idea is that you know it is a cache
451:57 - so things can get stale or just persist
452:00 - and so here you can just type in say I
452:02 - want to get rid of image.jpg and then
452:05 - you create that invalidation and then it
452:07 - will go delete it out of the cache and
452:09 - so the next time someone requests
452:11 - they'll get the the fresh content this
452:12 - usually doesn't take that long but
452:14 - that's pretty much cloudfront in a
452:15 - nutshell
452:18 - okay
452:20 - [Music]
452:21 - hey this is Andrew Brown from exam Pro
452:22 - and we are taking a look at ec2 also
452:24 - known as elastic compute cloud and so
452:26 - this is a highly uh configurable virtual
452:28 - server or it's also known as a virtual
452:31 - machine and that's what we're going to
452:32 - generally refer to it uh ec2 is
452:35 - resizable compute capacity it takes
452:37 - minutes to launch new instances and
452:39 - anything and everything on adabas uses
452:41 - ec2 instances underneath that's why we
452:43 - generally call it the backbone to all
452:44 - the adab services and uh you're going to
452:47 - just have to choose a few options here
452:48 - so the first thing you'll need to do is
452:50 - choose your OS via your Amazon machine
452:53 - image so that's where you get red hat
452:55 - Ubuntu Windows Amazon Linux Seuss it
452:58 - might also come with pre-installed
452:59 - libraries and things like that then
453:01 - you're going to choose your instance
453:02 - type that's going to determine things
453:03 - like your vcpus your memory so here you
453:06 - can see how many there are and you'll
453:08 - have like a monthly cost and that's the
453:11 - name of the instance type then you have
453:12 - to add storage so very commonly you're
453:15 - attaching elastic block storage or
453:17 - elastic files system system or service
453:20 - uh and so you know if you do choose your
453:22 - EBS uh you are going to have to
453:24 - determine what type it is so whether
453:26 - it's a solid state drive a hard disk
453:29 - drive a virtual Magnetic Tape or even
453:31 - attaching multiple volumes not just a
453:33 - single one and the last thing is
453:34 - configuring your instance so this is
453:36 - configuring the security groups the key
453:38 - pairs user data IM roles placement
453:40 - groups all sorts of things so we will
453:42 - experience in that because we will show
453:44 - you how to launch it an ec2 instance and
453:46 - it'll make a lot of sense if it does not
453:47 - make sense right now okay
453:49 - [Music]
453:53 - all right let's take a look here at ec2
453:55 - instance fames so what are instance
453:57 - families well instance families are
453:58 - different combinations of CPU memory
454:01 - storage and networking capacity and
454:03 - instance families allow you to choose
454:05 - the appropriate combination of capacity
454:08 - to meet your application's unique
454:09 - requirements different instance families
454:11 - are different because of the varying
454:13 - Hardware used to give them their unique
454:15 - properties and we do talk about this
454:17 - thing about uh capacity reservation
454:20 - where adus can actually run out of a
454:21 - particular type of instance family
454:23 - because they just don't have enough
454:24 - Hardware in that data center and so you
454:26 - have to reserve it but let's go through
454:27 - the different types of instance families
454:29 - the first is general purpose and these
454:31 - are the names of the different families
454:33 - uh very popular ones is the t2 um the t2
454:37 - and one that's really interesting is the
454:39 - Mac which actually allows you to run um
454:42 - a a Mac server so these are great
454:44 - balance of compute memory and network
454:46 - resources so you're going to be using
454:48 - these most of the time the use cases
454:50 - here would be web servers code
454:51 - repositories things like that then you
454:53 - have compute optimize so um they all
454:56 - start with C uh no surprise there
454:58 - they're ideal for compute bound
454:59 - applications that benefit from high
455:01 - performance processor their edge cases
455:03 - here are scientific modeling dedicated
455:04 - gaming servers ad server engines things
455:06 - like that then you have memory optimized
455:09 - um and so there's a variety here these
455:11 - are fast performance for workloads that
455:13 - process large data sets in memory um
455:16 - they're great for in-memory caches
455:17 - inmemory databases real time big data
455:19 - analytics then you have accelerated
455:21 - optimize so this is your P2 P3 P4 things
455:24 - like that these are Hardware
455:26 - accelerators or co-processors these are
455:29 - great for machine learning computational
455:30 - Finance seismic analysis speech
455:33 - recognition if you're doing um uh ML on
455:36 - AWS you you'll start coming across these
455:38 - types AWS technically has a separate
455:40 - page on sagemaker ML machines but
455:42 - they're all pulling from these instance
455:44 - families okay then you have storage
455:46 - optimize so I3 i3n things like that
455:49 - these are highly High sequential read
455:51 - and write access to very large data sets
455:53 - on local storage the use cases here
455:55 - would be no SQL in memory or
455:56 - transactional databases data warehousing
455:59 - for the certified Cloud practitioner you
456:01 - just need to generally know these five
456:02 - categories not the names of the instance
456:05 - families if you're doing um Associates
456:07 - or above you definitely want to know
456:09 - these things in a bit more detail and I
456:11 - want to say that commonly instance
456:12 - families are called instance types but
456:14 - an instance type is a combination of
456:15 - size and family but even aws's do
456:18 - mentation doesn't make this family
456:20 - distinction clear but I know this
456:22 - because you know in Azure they make that
456:24 - very clear and and gcp and so I'm
456:26 - bringing that language over here to just
456:27 - kind of normalize it for you
456:30 - [Music]
456:33 - okay let's take a look at what ec2
456:36 - instance types are so an instance type
456:38 - is a particular instance size and
456:40 - instance family and a common pattern for
456:42 - instance sizes you'll see is things like
456:44 - Nano micro small uh medium large xlarge
456:49 - 2x large 4X large 8X large and you know
456:52 - generally they're to the power of twos
456:55 - but sometimes it'll be like 12 14 16 or
456:57 - it's even uh and so when you go to
456:59 - launcher ec2 instance you're going to
457:01 - have to choose that instance type and so
457:03 - here you can see you know here is our T2
457:06 - micro and then we have um the small the
457:09 - medium the large the x large okay but
457:13 - there are exceptions to this pattern for
457:14 - sizes so you know there is one
457:17 - particular one called uh Dot metal and
457:19 - so that's going to indicate that this is
457:20 - a bare metal machine and then sometimes
457:22 - you get these Oddball ones like 9x large
457:25 - so you know the rule of power of two or
457:27 - even numbers is not always the case uh
457:29 - but generally it'll be pretty even for
457:31 - you know the start here okay uh just
457:34 - talking about instance sizes so the easy
457:36 - to instance sizes generally double in
457:38 - price and attribute so uh just bringing
457:40 - up these numbers a little bit closer
457:42 - starting at the small here you're going
457:43 - to notice one two doesn't maybe double
457:46 - there but four and here we see 12 2 4 uh
457:50 - almost doubles there almost doubles
457:52 - there but I want to show you that the
457:54 - price is generally almost double so 16
457:56 - 33 67 135 and so a lot of times like you
458:01 - always have the option to say okay do I
458:02 - want to go to the next instance size up
458:04 - or have uh an additional instance of the
458:06 - same size and sometimes it's a better
458:08 - approach to get an additional instance
458:10 - because then you can distribute it
458:12 - across another a uh but then you also
458:14 - meet additional capacity so there you
458:17 - go
458:20 - [Music]
458:22 - so we talked about dedicated instances
458:24 - and hosts a little bit but let's just
458:25 - make that distinction very clear so
458:27 - dedicated hosts are single tenant ec2
458:29 - instances designed to let you bring your
458:31 - own license so Bol based on machine
458:34 - characteristics and so we'll compare the
458:36 - dedicated instance to the dedicated host
458:38 - across isolation billing uh physical
458:41 - characteristics visibility Affinity
458:42 - between a host and instance targeted
458:45 - instance placement automatic instance
458:47 - placement and add Capac using allocation
458:50 - request so for isolation for dedicated
458:52 - instance you're going to get instance
458:54 - isolation so you can have the same
458:56 - customer on the same physical machine
458:58 - but there is virtualization there for
459:00 - them and there's a guarantee of that um
459:02 - for a dedicated host you have physical
459:04 - server isolation so you get the whole
459:05 - server for billing uh on a dedicated
459:09 - instance it's per instance billing and
459:10 - it's going to have an additional fee of
459:12 - $2 per region and for dedicated host
459:14 - it's per host billing so it's a lot more
459:16 - expensive but you get the whole machine
459:18 - uh for visibility of physical
459:20 - characteristics you're not going to get
459:21 - any of that information for a dedicated
459:23 - instance for dedicated host you are such
459:25 - as sockets core host host ID and this is
459:28 - really important when you have a bring
459:30 - your own license and they're saying this
459:32 - license is for x amount of corers or x
459:35 - amount of sockets then we have Affinity
459:38 - so there's no affinity for dedicated
459:39 - instance for dedicated hosts you'll have
459:41 - consistency with deoy to the same
459:43 - instance to the same physical server uh
459:45 - there's no control of Target instance
459:47 - placement for dedicated instance you do
459:49 - have control on a dedicated host for
459:52 - auto automatic instance placements you
459:53 - have it for both and to add capacity
459:56 - using allocation requests it's a no for
459:59 - dedicated instance and it's a yes for
460:00 - dedicated host so I want to come back to
460:03 - the main point that's what's highlighted
460:05 - here is that on a dedicated host you
460:06 - have visibility of sockets core host ID
460:09 - and this is really really important when
460:11 - you're bringing your own licens byol
460:14 - such as um you know Microsoft SQL
460:17 - servers where you have to specify the
460:20 - menac cores and things like that
460:22 - [Music]
460:25 - okay so we've been talking about uh
460:28 - tendency and I just wanted to make it
460:29 - very clear uh the difference between the
460:32 - different levels of tendency on AWS so
460:34 - we have three okay so we got dedicated
460:37 - host so your server lives here and you
460:39 - have control of the physical attribute
460:41 - so basically the whole server okay uh
460:44 - then we have dedicated instances so your
460:46 - server is on the same uh a physical
460:48 - machine as other customers but the
460:51 - actual slot that you have the dedicated
460:53 - instance will always be the same uh and
460:56 - then we have uh the default so your
460:58 - instance will live somewhere on the
461:00 - server uh and when you reboot it it's
461:02 - going to be somewhere else so there's no
461:04 - guarantee that it's going to be in the
461:05 - same place every single time
461:07 - [Music]
461:10 - okay hey this is Andrew Brown from exam
461:13 - Pro and in this follow along we're going
461:14 - to be looking at ec2 and also um
461:17 - services that are adjacent to it so like
461:18 - Auto scaling groups load balancers
461:20 - elastic IPS things like that so we fully
461:23 - understand ec2 um you don't have to know
461:25 - tons for the exam but you should be able
461:27 - to go through the motions of this with
461:29 - me so that you can cement that knowledge
461:31 - um for some of those deeper Concepts
461:33 - like working with key Pairs and things
461:34 - like that so let's make our way over to
461:37 - the ec2 console and learn what we can
461:39 - learn um and generally when you go to
461:42 - the ec2 console it'll bring you to the
461:44 - dashboard for whatever reason it didn't
461:46 - bring me there and then the idea here is
461:48 - that on left hand side we can make our
461:49 - way over to
461:50 - instances okay and this is where we can
461:53 - launch our first instance so if we go
461:56 - here and launch our instance the first
461:57 - thing we're going to be presented with
461:59 - is to choose our am or Amazon machine
462:02 - image and so that is a template that
462:04 - contains the software configuration so
462:06 - the operating system applications and
462:08 - other binaries that would be installed
462:10 - on that OS by default all right and so
462:13 - we have a variety that we can choose
462:14 - from in the quick starts and generally
462:16 - the ones that you're going to see first
462:17 - are the ones that ad support so there
462:20 - are uh um Amis or operating systems that
462:23 - ads will support when you contact them
462:25 - and then there's ones that are outside
462:26 - that where uh they'll still help you
462:28 - with but they might not have the
462:29 - knowledge on so just understand that if
462:31 - you pick from these core ones you're
462:32 - going to be in good shape uh the most
462:34 - popular is the Amazon Linux 2 because
462:36 - it's part of the free tier and it is is
462:39 - very minimal and well hardened by AWS so
462:41 - it's a very good choice there but you
462:42 - can see you can install a bunch of
462:44 - things so like if you want to launch a
462:46 - Mac OS server you can absolutely do that
462:48 - a red hat uh Suzie Ubuntu a Windows
462:52 - Server you name it they have it um if
462:55 - you wanted something more farther out
462:57 - there you can go to the marketplace and
463:00 - uh subscribe to one that is managed by
463:02 - company basically everything exists
463:04 - Under the Sun here or you could get a
463:06 - community Ami so these are ones that are
463:08 - contributed by the community for free
463:10 - but we're going to go back to quick
463:11 - start here and what I want you to notice
463:13 - is that there is this Ami ID that's how
463:15 - we can uniquely identify what we are
463:17 - using IF if we were to change region
463:19 - even with the same Amazon L 2 instance
463:22 - this thing will change so just
463:23 - understand that it is regional based and
463:25 - it comes in a 64bit variant and a arm
463:28 - variant and so we're going to be using
463:29 - the x86 here you can notice here you can
463:32 - change it on the right hand side we're
463:34 - going to stick with x86 I'm going to go
463:36 - ahead and hit next so now we're going to
463:38 - choose our instance type and so this is
463:40 - going to decide um uh greatly how much
463:43 - we're going to be spending because the
463:45 - larger it is the more we're going to
463:46 - spend so see this T2 micro if we
463:48 - wandered into the pricing for that we go
463:49 - to
463:50 - ec2 pricing
463:53 - AWS and once we get to ec2
463:57 - pricing we want to go to on
464:00 - demand and from here this will
464:02 - load and so down below we can kind of go
464:05 - find our price it should show us it
464:08 - should show us the list ah here it is
464:10 - okay so I can say a T2
464:12 - micro and we can see the On Demand is
464:15 - this so it seems really cheap what you
464:17 - got to do is do the math so so if you do
464:18 - time 7:30 that's how many hours there
464:20 - are in a month if we launch a T2 micro
464:23 - and let's say we didn't have the free
464:25 - tier we you do if you first made your
464:27 - account you're going to have 700 750
464:30 - hours for free with the free tier but if
464:32 - you didn't it would only cost you $8 and
464:34 - and 46 USD okay so just be aware of that
464:39 - if you ever need to figure something out
464:40 - go there copy it do the math 7:30 it's
464:42 - pretty easy so here we have a T2 micro
464:45 - and the t2 family it's going to have one
464:47 - V VC CPU notice that it has a V for
464:49 - virtual so there could be more than a
464:52 - single CPU on the underlying Hardware
464:55 - but we're only going to have access to
464:56 - one virtual CPU we have one gigabyte of
465:00 - memory it's for low to moderate Network
465:03 - performance so that's a factor that can
465:04 - change if you need like uh uh gigabit
465:06 - stuff like really fast connections for
465:08 - on Prem hybrid connections and you have
465:10 - specialized servers for that but for
465:12 - this this is fine the TT micro is great
465:15 - uh if you want you can also search uh
465:17 - this way to see all the instance
465:18 - families and things like that you can
465:20 - filter for current Generations all
465:21 - generations so this is fine okay so from
465:24 - there we're going to go to configure our
465:26 - instance type you can say let's launch
465:28 - multiples of these instances let's turn
465:30 - on spot to uh save money and try to bid
465:33 - for a particular price we can change our
465:35 - VPC it's going to default to the default
465:38 - VPC um if you have no subnets just going
465:41 - to pick one at random here which is fine
465:43 - um whether to Auto assign a public IP
465:45 - address if you do not have an IP address
465:47 - you cannot reach the internet so
465:49 - generally you want this to be enabled
465:51 - this is dependent on the subnet whether
465:53 - it will default to enabled but doesn't
465:55 - matter if you have an ec2 instance in a
465:58 - private or public subnet you can always
465:59 - override this and give it a public IP
466:01 - address you have placement groups which
466:03 - allows you to play servers together
466:05 - closely not something for the certified
466:06 - Cloud partitioner there's capacity
466:08 - reservations so if you're worried about
466:10 - any us running out of this you can
466:12 - reserve capacity so that's kind of
466:14 - interesting domain join directory this
466:16 - isn't something that I've done much with
466:18 - but I imagine that has something to do
466:19 - with um a direct active directory or
466:21 - something like that to join information
466:24 - then you need to uh have an IM roll and
466:27 - we absolutely do need an IM roll here so
466:28 - what I want you to do is create a new Ro
466:31 - just going to close off these other tabs
466:32 - here and we will go wait a moment create
466:36 - a new role here and we want to do this
466:38 - for ec2 so we say ec2 is what we're
466:41 - creating the rule for we'll hit next and
466:44 - um I don't know if I have a policy but
466:46 - I'm going to go ahead and um well I
466:48 - don't need to make a new policy but I
466:49 - just want SSM and the reason I want SSM
466:52 - is so that I can um uh use sessions
466:56 - manager to log in so we don't have to
466:58 - use key pairs we will use key pairs but
467:00 - if we didn't want to use it that's what
467:01 - we could do and this used to be the old
467:03 - Ro and'll tell you hey go use this new
467:05 - one here so I just want to make sure I
467:07 - know which one it is and so we'll just
467:09 - checkbox that on we'll hit next we can
467:11 - add tags right here it' be uh well
467:14 - actually we don't need to add any tags
467:15 - here so that's fine we'll hit next and
467:17 - then I'll just say uh my SSM ec2 roll
467:21 - okay and we'll create that
467:23 - rooll and now that we have created that
467:26 - Ro we can go back to our first tab here
467:28 - and give this a refresh and then drop
467:30 - down and it should show up
467:32 - here if we go down here a little bit we
467:34 - could turn on extra monitoring there is
467:36 - monitoring built in but if you wanted to
467:39 - uh monitor it to a lower uh like it more
467:42 - frequently you could do that as well we
467:44 - want share tendency right this is where
467:46 - you change the dedicated instance or
467:48 - dedicated host obviously these class
467:49 - more but we're going to stick with
467:50 - shared elastic inference so this is for
467:53 - um uh attaching a a fractional GPU great
467:57 - for ML not something that we want
467:59 - there's credit specification I don't
468:01 - remember seeing this before selecting
468:02 - unlimited for credit specification
468:04 - allows for to burst beyond the Baseline
468:06 - so it's for bursting here you can attach
468:08 - an uh EFS uh so if you need a file
468:11 - system that you want to mount or attach
468:13 - um then there's the Enclave option so
468:15 - Nitro Enclave enables you to create is
468:18 - compute environments to further protect
468:19 - your uh and securely processed highly
468:21 - sensitive data so it might be something
468:23 - you might want to checkbox on um based
468:25 - on your use case and then down below our
468:28 - we have our ability to enter our user
468:29 - data and this is something we want to do
468:31 - because we want to install aachi so that
468:35 - we have something to work with here so
468:36 - what I'm going to do is make a shebang
468:38 - so that is a pound and an exclamation
468:40 - mark I know that's really small so I'll
468:42 - try to bump up my font here so you can
468:43 - see what I'm doing and we're going to do
468:45 - a forward SL bin and a for bash on the
468:48 - next line here we're going to do yum
468:50 - install hyphen y
468:51 - httpd um that's going to install Apachi
468:55 - and why it's not called Apache I don't
468:56 - know why but they call it
468:59 - httpd there's no Apachi in the name
469:01 - there and so we'll say system CTL start
469:04 - httpd system CTL enable httpd so we're
469:08 - saying start up Apachi and then make
469:10 - sure that it stays running if we restart
469:12 - our machine very simple so from there we
469:16 - will go to our our storage we'll say add
469:18 - our storage and this is at 8 gbes by
469:21 - default we could uh uh turn that up to
469:23 - 30 if we like so you can go all the way
469:25 - up to 30 if you like um and you might
469:27 - want to do that but I'm going to leave
469:28 - it at 8 we could change our volume type
469:30 - I'm fine with gp2 because it's very cost
469:33 - effective and if we want to turn on
469:35 - encryption and you should always turn on
469:36 - encryption there's no reason not to and
469:38 - so we'll turn that on it's not like it's
469:39 - going to cost you more it's going to be
469:41 - the same clost it's just your choice
469:43 - there if do want to add a tag yes we're
469:45 - going to add a name and we're going to
469:46 - say my ec2 instance
469:50 - okay and so that's going to give us a
469:52 - name which is something we would really
469:54 - like to have then we have a security
469:55 - group I'm going to just create a new
469:57 - security group called my um ec2 SG here
470:01 - and just say my ec2 SG something you
470:04 - cannot do is rename a security group
470:06 - once you've made it so make sure you
470:07 - don't make a spelling mistake up here
470:10 - and we want to be uh accessing that httt
470:14 - HTT or it's going to launch a website so
470:17 - in order to do that we need to make sure
470:18 - we have HTTP as a type with the port ad
470:21 - open and we want it from anywhere so
470:23 - we'll say anywhere and that will be
470:25 - 0.0.0.0 for size0 and that's for the
470:28 - ipv4 this is for the IPv6 okay so we'll
470:32 - just say
470:34 - internet and this is for SSH right and
470:37 - for this um I would probably suggest to
470:39 - say my IP but since we might be using a
470:42 - cloud shell to do that we're going to
470:43 - leave it as anywhere so that we don't
470:45 - have any issues connecting so from here
470:47 - we'll r and launch and you can review
470:51 - what it is that's going on here it's
470:53 - going to say here hey you have an open
470:55 - port that's okay we we want the internet
470:57 - to see our website because that's the
470:59 - whole point there and we'll go ahead and
471:01 - launch it it's going to ask for a key
471:02 - pair we can go down and say proceed
471:04 - without key pair but what I'm going to
471:05 - do is I'm going to create a new key pair
471:07 - because I want to show you how those
471:08 - work and I'm sure we've already done in
471:10 - this course once but we'll do it again
471:12 - and so I'm going to just name this as my
471:14 - ec2 instance here and then we're going
471:16 - to go download that key pair it's going
471:18 - to download a pem file there and so now
471:22 - we can go ahead and launch that
471:25 - instance and while that is launching so
471:27 - I'm going to just close this other tab
471:28 - here we're going to click on The View
471:30 - instances and so here is that instance
471:33 - that's how we put the tag so we could
471:34 - have a name there we're going to wait
471:35 - for that to start but as that's going
471:37 - I'm going to make a new tab by just
471:38 - right clicking here on the logo click
471:41 - anywhere pretty much to do that and uh
471:43 - once we do that we'll click on cloud
471:46 - shell
471:48 - and as that is going what I want to do
471:50 - is take this pen down below I'm going to
471:52 - move it to my desktop to make it easier
471:54 - for me to upload I'm doing this off
471:56 - screen
471:59 - okay and uh once this environment is
472:02 - running I'm going to go ahead and upload
472:04 - that okay so we'll just give it a moment
472:07 - to do that we're also waiting for the
472:10 - server to spin up as you'll notice there
472:12 - is a public IP address here it says it's
472:15 - running so if we want we can copy it
472:17 - we're looking for those two checks to
472:19 - pass so the server could be available
472:21 - but generally you want to wait for those
472:23 - two system checks because one says Hey
472:25 - the hardware is fine the Network's fine
472:27 - things like that okay but if I take that
472:28 - IP address paste it on it up here we
472:31 - have the web page so that is working uh
472:33 - no problem there so that's great and
472:36 - we'll go over to Cloud shell and that is
472:38 - still starting uh it's not the fastest
472:40 - but that's just how it is and um you
472:43 - know we'll get going here in a second as
472:47 - soon as this decides to
472:50 - load there we go so it's loaded I can
472:53 - type clear here just to clear that
472:54 - screen out and so what I want to do is
472:57 - upload that PM file so I'm going to go
472:58 - and upload that file we're going to go
473:00 - ahead and select it I'm going to go to
473:01 - my desktop here whoops my desktop and we
473:04 - are going to choose my ec2 instance pem
473:07 - all right and from there we'll hit
473:08 - upload and that's going to upload that
473:10 - pem
473:12 - file once that is uploaded we're going
473:14 - to do
473:16 - LS okay and so uh this is from a
473:18 - previous tutorial so I'm going to go
473:19 - ahead and just delete that other one
473:20 - there we'll say remove EFS example pem
473:25 - yes okay we'll type
473:28 - clear and then what we can do here is
473:30 - Type in chamod and um I believe it's 400
473:34 - and what do we call this my ec2 instance
473:37 - PM if you hit tab it will autocomplete
473:38 - which is nice and if you do lsen la we
473:41 - can take a look at that file and see it
473:44 - should look like this should have only
473:46 - one R here here so the idea is you're
473:48 - locking it down so it's not writable or
473:50 - executable it's just readable because
473:52 - that's what you have to have it if you
473:53 - want to SSH and so if we want to ssh
473:56 - what we'll do is hit the connect button
473:58 - here and we have four options they just
474:01 - give you too many options it's going to
474:02 - be a fifth one for sure soon but right
474:04 - now we're talking about SSH so for SSH
474:07 - um we had to chamod our file which we
474:09 - did and then we need to use this DNS to
474:11 - connect to it and so this is the full
474:13 - line here if you click on this copy that
474:15 - over and paste it in
474:17 - that should be everything and notice
474:18 - we're doing ec2 user followed by this
474:21 - you could put the IP address in here
474:23 - instead if you preferred so if you were
474:26 - over
474:27 - here you could go and take that IP
474:30 - address which is I think shorter nicer
474:32 - but um you know if you just click that
474:34 - one button it works that's fine you
474:36 - always have to accept the uh the
474:38 - fingerprint then you'll be inside the
474:40 - instance you can type who I to see which
474:42 - user you are you're the ec2 user that's
474:44 - the user that ads creates for their
474:46 - Amazon Linux instances um it's going to
474:49 - vary per um Ami so not all Amis have an
474:53 - ec2 user it might be something else but
474:55 - that's generally the ones that a US uses
474:56 - for their supported ones and so if we do
474:59 - um an LS again we're in the server right
475:01 - now we can tell because it says right
475:03 - here or we do a PWD we can kind of just
475:06 - kind of look around so I think it's
475:07 - going to be at VAR ww that's where HT
475:10 - httpd or Apache always uh puts their
475:13 - files here so if I go in here whoops I'm
475:16 - just looking looking for um the index
475:19 - file so I thought the index file was
475:23 - in cdar
475:28 - WW
475:30 - HTML well where the heck is it so I'm G
475:32 - to just touch a file here and see if it
475:34 - overrides
475:36 - it oh I don't care I'll just type
475:39 - Pudo and what we can do is just try to
475:41 - restart this system CTL um there's a
475:46 - very similar command that's like uh
475:47 - service and so I always forget the order
475:49 - of it so I think it'd be I'm just
475:51 - checking um probably uh restart
475:57 - httpd and so failed to restart the
476:00 - policy was not provided as the name
476:02 - service um
476:09 - Service uh maybe
476:12 - pseudo there we go and so if we go back
476:15 - here I'm going to see if it changed
476:17 - because it will take whatever is in the
476:18 - index HTML file so if there's no file
476:20 - there it's going to uh show that there
476:22 - and so what I can do is I can edit this
476:25 - file I'm going to type VI index HTML and
476:28 - um I'm going to hit I for insert mode oh
476:31 - says it's readon so what we have to do Q
476:34 - uh colon Q
476:36 - quit oops uh clear LS and so what we
476:40 - need to do is do pseudo VI index HTML
476:45 - and so Vim every single key is a hotkey
476:48 - okay um and I'm not teaching Vim here
476:50 - but I'm going to teach you the basics
476:51 - but the idea is that when you're here
476:53 - notice that the cursor is blinking when
476:55 - I hit I it enters insert mode now I can
476:58 - type normally so I'd say hello uh hello
477:02 - Cloud okay and I'm going to hit escape
477:04 - to go back to um navigation mode
477:07 - whatever you want to call it I'm going
477:08 - to hit colon so it brings up the command
477:11 - I'm going to type in uh write and quit
477:14 - Okay and hit enter and so I'll type
477:17 - clear and so whoops clear and so we'll
477:20 - hit up till we get that command pseudo
477:23 - system CTL restart hbd we'll hit that
477:26 - hit
477:28 - enter okay and it should restart pretty
477:32 - fast there it is it says hello Cloud I
477:35 - probably didn't even have to restart it
477:36 - to do that but anyway so now that
477:38 - instance uh you can see how we're
477:40 - updating that so what I want to do is
477:42 - just do a sanity check and make sure
477:44 - that if we restart this instance that
477:46 - we're going to be able to um have a poy
477:49 - running that's something you should
477:50 - always do if you have an app and you or
477:52 - anything and you install it restart your
477:53 - server make sure that everything works
477:55 - so what I'm going to do is uh just hit
477:58 - exit here so we go back to the top level
478:00 - cloud shell type clear I'm going to go
478:03 - back over to my ec2
478:04 - instance might have to click around to
478:06 - find it here and what I want to do is
478:08 - reboot it okay and if I reboot the
478:11 - machine the IP address is going to stay
478:13 - the same okay so if I reboot it the IP
478:16 - address is going to to stay the same and
478:17 - the reboot is going to happen really
478:19 - fast if we want to observe that reboot
478:21 - we could go over to um here on the right
478:25 - hand side go to the system log and it
478:27 - would show us that it it had
478:29 - rebooted I think so yeah it does cloud
478:31 - in knit there I think it
478:33 - rebooted not sure um but anyway if it's
478:36 - rebooted then we can go ahead and
478:38 - connect and make sure everything's fine
478:39 - so let's just go here and hit enter and
478:42 - let's see if the what the web page is
478:45 - here
478:47 - notice that it's hanging right so it's
478:49 - probably because it's still
478:51 - restarting even though it doesn't look
478:53 - like it is and that's something that you
478:54 - have to understand about the cloud is
478:56 - that you have to think about what you're
478:58 - doing and have confidence that it is
479:00 - happening and also just double check it
479:02 - but uh that's something that can be kind
479:04 - of frustrating because these are
479:06 - globally available Services uh uh
479:08 - they're massively scalable and so one of
479:10 - the trade-offs is that you don't always
479:11 - have the most uh responsive uh uis ads
479:15 - has one of the most responsive uis out
479:16 - of all the major providers but even
479:18 - still like sometimes I have to second
479:19 - guess myself but the page uh right now
479:22 - is not working now it is so it's fine so
479:24 - it just took time for that to reboot and
479:26 - so um what I want to do is connect a
479:28 - different way so we're going to go here
479:30 - and we're going to hit um we're going to
479:32 - checkbox that on we're going to hit
479:33 - connect and instead of using SSH client
479:35 - we're just going to go to sessions
479:36 - manager and hit
479:37 - connect and this is the preferred way of
479:39 - connecting because you don't have to
479:42 - have this this SSH key and that's a lot
479:45 - more secure because if someone has that
479:47 - key and you you know you hand it to
479:48 - someone they could hand it to somebody
479:49 - else and then you have a big problem on
479:51 - your hands so here this looks very
479:53 - similar but if you type who am I it
479:55 - actually logs in as the SSM user which
479:56 - is kind of annoying so I type in sudo Su
480:00 - I have to do this hyphen here and then
480:01 - I'm going to say the user I want to be
480:02 - which is E2 user and then if I type who
480:05 - am I we are the correct user you can't
480:07 - do anything in that SSM hyphen user or
480:09 - or SSM user so you got to switch that
480:11 - over and I can bump this up to make it a
480:13 - bit larger so this is obviously not as
480:15 - nice as working over here or even in
480:17 - your own terminal but it's a lot more
480:19 - secure and it's tracked and all these
480:21 - other things so we really should be
480:23 - using it
480:24 - okay and um I really don't like having
480:27 - to bump this up with my HTML I'm going
480:29 - just go back to zero there there's
480:30 - probably like a way to configure that
480:32 - but anyway uh let's just go and take a
480:35 - look at our
480:36 - file I'm going to type VI again and
480:38 - we're going to do VAR www HTML index
480:42 - HTML I'm going to put pseudo in front of
480:44 - there and again remember you have to hit
480:47 - I to go into insert
480:49 - mode and uh what I'm going to do is just
480:52 - take capitalize that hello Cloud give
480:54 - that exclamation mark colon WQ to quit
480:57 - WR quit going to go back here refresh
480:59 - okay so we don't have to restart our
481:01 - server which is nice all right so um
481:05 - that's that that's pretty clear so I'll
481:07 - hit terminate
481:08 - here and I don't think we need Cloud
481:10 - shell for anything so I'm just going to
481:11 - close that and so that's pretty much it
481:14 - when it when it comes to working with an
481:17 - an ec2 instance and so the next thing I
481:18 - want to show you is elastic IP
481:21 - [Music]
481:24 - okay okay so now I want to show you
481:26 - elastic IP uh commonly abbreviated to
481:29 - EIP and so all that is it's just a um a
481:33 - static IP and IP that does not change
481:35 - because this ec2 instance here notice
481:37 - that it's 54 163
481:39 - 4104 and what would happen if we were to
481:42 - stop this instance not reboot it but
481:43 - stop it because for whatever reason we
481:45 - had to or
481:47 - or um for whatever reason and if we were
481:50 - to stop this instance and we were to
481:52 - restart
481:54 - it
481:55 - okay uh and we have to wait for it to
481:58 - stop but that IP address is going to
482:00 - change
482:02 - okay so 54 1634 104 hopefully we can
482:06 - observe that I'm just going to write
482:08 - that down so we do not forget so I can
482:11 - prove to you that it does
482:15 - change and now that it it's still
482:18 - stopping here so as that's stopping
482:20 - we're just going to go ahead and get our
482:22 - elastic IP and I will'll prove that as
482:25 - we go here so I'm going to go over to
482:26 - here and so what I want to do is Reserve
482:29 - or allocate an elastic IP address and so
482:31 - I'm going to say us
482:32 - east1 and it's going to say from the
482:35 - Amazon Pool of ipv4 addresses so ads has
482:38 - a bunch of IP addresses they're holding
482:40 - on to and so you can just allocate one
482:43 - and once you've allocated that's your IP
482:45 - address so coming back to here okay this
482:48 - is stopped notice there is no public IP
482:51 - address we're going to start it
482:56 - again okay and then we'll just checkbox
482:58 - it on and we just have to wait a little
483:00 - while to see what the IP address is
483:02 - going to be I'm going to tell you it's
483:04 - going to be something
483:06 - else so if I go back here this is
483:09 - 54235 12 110 and our original one was 54
483:13 - 163 4 104 so the the reason why it's
483:17 - important to have the same address is
483:18 - that if uh you have a load balancer well
483:21 - not a load balancer but if you have a
483:23 - domain pointing to your uh your server
483:26 - and you reboot then the rout you have a
483:28 - dang a dangling um path or route where
483:32 - uh Revenue 3 was going to be pointing to
483:34 - nothing and so Aus does have things to
483:36 - mitigate that like aliases and things
483:38 - like that but um in general you know
483:40 - there's cases where you just have to
483:41 - have a static IP address and so we had
483:44 - allocated one over here and if we want
483:46 - to assign it we're going to associate
483:48 - that elastic IP address we're going to
483:50 - drop it down choose the cc2 instance um
483:53 - I suppose the private IP as well and
483:56 - then we're going to go ahead and hit
483:57 - allocate or
483:59 - associate and once it's Associated it
484:01 - should now have 34 199 121 116 so we go
484:06 - over
484:08 - here and we're going to take a look here
484:11 - and that's its IP address we can pull it
484:13 - up okay and that's that so yeah that's
484:17 - the lastic
484:18 - [Music]
484:22 - IP okay so now that we um have our
484:24 - lastic IP we have our ec2 instance
484:26 - running let's say um you know we lose
484:28 - the server we terminate it so we would
484:30 - lose all of our configuration so if we
484:31 - wanted to bake this Ami to save it for
484:34 - later what we'd have to do is go and
484:35 - create an image so to do that we go to
484:37 - the top here and we go to images and
484:39 - templates and we can create an image or
484:41 - we can create a a a template which is a
484:43 - lot better but for the time being we're
484:44 - going just go ahead and create an image
484:45 - and when you create an image you're
484:46 - basically creating an Ami and so here
484:49 - I'm just going to say uh my
484:51 - ec2 and I'm going to go 0 to just kind
484:54 - of like number it so that's a very
484:55 - common numbering just do three zeros and
484:57 - then increment by one and so here I can
484:59 - just say my Apachi server and so it's
485:02 - going to save some settings like the
485:04 - fact that there is a a volume you could
485:07 - uh save some tags there and so I might
485:09 - go ahead and add a tag and you'll say
485:10 - name and we'll just say my ec2 server or
485:14 - so that it remembers that
485:17 - okay and then what we'll do is go ahead
485:19 - and create our image and so this can
485:21 - take a little bit of time if we go over
485:23 - to uh images
485:26 - here it's going to be spinning for a
485:28 - while and uh we'll just wait until it's
485:30 - done okay all right so after waiting a
485:32 - little while here our Ami is ready so
485:34 - we're just waiting for it to go
485:35 - available if you do not see it just make
485:36 - sure you hit the refresh um because
485:39 - sometimes ads will just been forever um
485:41 - and so that's just something you'll have
485:42 - to do so you know hopefully that makes
485:45 - sense what we'll do is is go make our
485:47 - way back over to instances here and we
485:49 - can launch one this way well actually we
485:51 - can do it over from um the Ami page so
485:55 - what I'm going to do is just terminate
485:56 - this instance we're all done with it
485:59 - okay and we'll hit terminate it's
486:01 - totally fine and it had a message about
486:03 - elastic IPS about releasing them so when
486:05 - it does that the elastic IP is still
486:07 - over here so it did not release it so
486:10 - what we're going to do is go ahead and
486:12 - disassociate the elastic
486:14 - IP okay and then we're also going to
486:17 - release the IP address because if we
486:19 - don't we're going to have this IP
486:20 - address that's sticking around that
486:21 - we're not using it this is going to
486:23 - charge us a dollar month over month so
486:24 - just be aware of those because that's
486:26 - just kind of like a hidden cost there
486:27 - but what we're going to do is go over to
486:30 - Ami and we're going to select it here
486:32 - we're going to go to actions we're going
486:33 - to go ahead and
486:34 - launch and what it's going to do is make
486:36 - us fill out all this other stuff again
486:38 - so if you had made a launch template uh
486:40 - we wouldn't have to fill out all this
486:42 - stuff it'd be part of it but that's what
486:43 - I'm trying to show you with this Ami
486:45 - stuff so um instead of filling out all
486:47 - this what I'm going to do is now go
486:49 - create a launch template just to kind of
486:51 - show you that that would be a much
486:53 - easier way to
486:55 - work so we go over to E2 instances and
486:58 - then left- hand side we're looking for a
487:01 - launch template launch launch
487:02 - configurations is the old thing um
487:05 - launch templates here we go so what
487:08 - we'll do is create ourselves a launch
487:09 - template we'll just say my apachi
487:13 - server and then down below we need to
487:16 - choose our Ami so we're going to go here
487:18 - and we need to type it in so what would
487:20 - we call it my
487:24 - ec2 I really don't like this uh search
487:26 - here it's very slow and frustrating but
487:28 - once we find it whoops that's why I
487:30 - don't like it because a lot of times
487:31 - it'll be loading and you'll end up
487:33 - clicking the wrong
487:34 - thing okay
487:37 - so I don't like this okay we'll type in
487:42 - my give it a
487:45 - second
487:47 - there it is just wait because it will
487:48 - keep loading and then once it's loaded
487:50 - hit
487:52 - enter and so it has that instance
487:54 - selected and then from there uh don't
487:56 - include in the launch template so here
487:59 - we could be explicit I would say I want
488:01 - this to be two T2 micro but we could
488:03 - exclude it if we wanted to we could
488:05 - specify the key pair here um not that we
488:08 - really want to use key pairs we'll say
488:09 - my ec2 instance then down down here for
488:12 - the networking we can specify uh that
488:14 - security group we created so we created
488:15 - one here called my ec2
488:17 - SG um storage is fine it's going to be
488:21 - encrypted network interface is fine
488:23 - Advanced details what I want to do is
488:25 - set the IM instance profile that's
488:27 - really important because we don't want
488:28 - to have to figure out that roll every
488:30 - single time so we'll put that there and
488:34 - that should be everything and we could
488:36 - put user data in there but it's already
488:37 - baked into our Ami so we don't have to
488:39 - worry about anything so what I'm going
488:40 - to do here is go ahead and create this
488:42 - launch template and then we're going to
488:45 - view this launch template temp plate and
488:46 - so now what we can do is then use it to
488:49 - launch an instance okay and so we're
488:53 - going to look here and it's very similar
488:54 - to dc2 except it's vertical so we're
488:57 - going to have one instance it's going to
488:58 - use that Ami that instance type so you
489:00 - can see how you can override them which
489:02 - is nice we're going to check the
489:03 - advanced details make sure that I am
489:05 - profile is set and we'll go ahead and
489:07 - launch this from a
489:09 - template so from there we can go ahead
489:11 - and click the instance value there and
489:14 - just be aware that when you do click
489:16 - through links like that you'll end up
489:17 - with the search so I was just checkbox
489:18 - that off so I can see what I'm doing and
489:20 - so we're just waiting for this instance
489:22 - to show up and the only thing I noticed
489:23 - is it didn't said are darn tags so I
489:26 - wanted the name in there and I think
489:27 - it's because we said it in the Ami but
489:29 - it didn't carry over to the launch
489:30 - template so I'd have to go back to the
489:32 - launch template and update it probably
489:34 - so if I go into here into the launch
489:37 - template um we can probably modify
489:40 - create a new
489:42 - version and then add tags there we say
489:47 - name uh my uh Apachi
489:51 - server I realize I'm changing it between
489:54 - them and so that should allow us to have
489:56 - a version two so we'll create that and
489:59 - but anyway that will be for the next
490:01 - time we launch it okay and so this
490:03 - instance is running I'm going to go grab
490:05 - the IP
490:06 - address the server may or may not be
490:08 - ready we'll take a look here and so it's
490:11 - just spinning if it's spinning it's
490:13 - either the server is not ready or um um
490:16 - our ports not open so it was just
490:18 - getting ready to work there so it is
490:19 - working now so that is our launch
490:21 - template so now you know we don't have
490:24 - to worry about losing our stuff and if
490:25 - we need to make new versions We can just
490:28 - bake new Amis and increment them at uh
490:31 - Inc and attach them as new versions of
490:33 - that launch template
490:34 - [Music]
490:38 - okay all right so what I want to show
490:40 - you in this follow along is to set up an
490:42 - auto scaling group for our ec2 instance
490:45 - and the idea behind this is that um
490:47 - we'll be able to always ensure that a
490:49 - single server is running or uh increase
490:52 - the capacity if the demand requires it
490:54 - so in order to create an Autos scaling
490:56 - group we can go all the way down below
490:58 - to here um and so you know I really
491:01 - don't like the Autos scaling group form
491:03 - but it's okay we'll work our way through
491:04 - it so the first thing is we'll have to
491:06 - create our or name our Autos scaling
491:08 - group so we'll just say my ASG and then
491:10 - we'll have to select a launch template
491:12 - which is great because we already have
491:13 - one and then we'll have to select the
491:14 - version I'm going to select version
491:15 - version two so that it applies that tag
491:17 - name and we'll go to next and so here um
491:21 - it's going to need to select a VPC and
491:24 - then we need some subnets so we're going
491:26 - to choose three just because to have
491:28 - high availability you have to be running
491:30 - in at least three different availability
491:32 - zones so that's why we have three
491:33 - different subnets and then down below we
491:35 - have the instance type requirements so
491:37 - uh T2 micro launch template looks good
491:41 - to me so we'll go ahead and hit
491:44 - next and then from here we can choose to
491:46 - do a load balancer and so I want to do
491:48 - the load balancer separate so we won't
491:50 - do it as of yet but very often if you're
491:52 - going to have an H group you're going to
491:54 - usually have a load balancer but we'll
491:56 - talk about that when we get to that
491:58 - point there so we'll just go to the
492:00 - bottom here and hit next and so this is
492:02 - what's important so how many do you want
492:04 - to be always running and so we always
492:06 - want to have one and maybe the maximum
492:08 - capacity is two and you want the desired
492:10 - cast capacity be to be around a
492:12 - particular number so if you had three
492:14 - and you said the desired is two um there
492:15 - are things that could try to work to
492:17 - always make sure there's two but we just
492:18 - want to have one for this example we can
492:21 - set up uh scaling policy so I do Target
492:23 - tracking scaling policy and so here we
492:25 - could do it based on a bunch of
492:26 - different things so if the CPU
492:27 - utilization when were 50% it would
492:30 - launch another server so that might be
492:32 - something we might want to set so I'll
492:33 - we're not going to uh try to trigger the
492:35 - scaling policy but we might as well just
492:37 - apply because it's not too hard then you
492:39 - can also do a scaling uh scale in
492:41 - protection policy so if you want to make
492:43 - sure it does not um uh reduce the amount
492:46 - of servers that's something you could do
492:48 - we can add a notification to say hey
492:50 - there's a scaling policy happening here
492:52 - which is fine we don't have to worry
492:53 - about that um and there's tags so add
492:55 - tags to help you search filter Etc um so
492:58 - I'm going to put a tag here I'm going to
493:00 - say name I'm just wondering if this is
493:02 - going to attach to the ec2 in or this is
493:04 - for the auto scaling group you can
493:05 - optionally choose to add tags to
493:07 - instances by specifying tags in your
493:09 - launch templates so we already did that
493:10 - so I don't need to put a tag here and so
493:13 - we can review our um Auto scaling group
493:17 - and go ahead and create that auto
493:18 - scaling
493:19 - group okay and so that auto scaling
493:23 - group expects there to be a single
493:24 - instance so what it's going to do is
493:26 - it's going to start launching an
493:28 - instance and so what I'm going to do is
493:29 - just get rid of this old server because
493:31 - we don't need it anymore this old one
493:33 - here
493:35 - okay and you can already see okay that
493:38 - the load balancer is launching this new
493:41 - one here and remember we updated our
493:43 - version two to have that name so that's
493:44 - how we know that it is so if we go back
493:46 - over to our autoscaling
493:50 - group okay it's now saying there's an
493:53 - instance we don't have a status as of
493:56 - yet and so there are ways of doing a
493:59 - status checks to for to determine
494:01 - whether or not the server is
494:03 - working um because if the server is
494:05 - unhealthy what it would do is it would
494:07 - actually kill it and then start up a new
494:09 - one right so if I go down below it's
494:10 - right now doing an ec2 health check and
494:12 - the ec2 health check just means that is
494:14 - the server working right um is it
494:16 - running it doesn't necessarily mean like
494:18 - hey can I load this web app um but you
494:20 - know it's very simple so we'll give it a
494:22 - moment here to start up and just make
494:25 - sure that it's
494:30 - working okay and I think it's ready so
494:32 - if I take that public IP address here
494:34 - and paste it in there it is okay so if
494:37 - we were to tell it to increase the
494:40 - capacity to three then what it would do
494:41 - is it would launch three and then it
494:43 - should probably launch it all evenly to
494:46 - those other it should evenly launch it
494:49 - to all those other uh availability zones
494:51 - and then we'll have something that is
494:52 - highly available okay so that's pretty
494:55 - much it for this and then we'll move on
494:56 - to Auto scaling
494:57 - [Music]
495:01 - groups all right so we have our uh ec2
495:04 - instance now managed by an Autos scaling
495:06 - group and the great thing is that if we
495:07 - terminate this instance this Autos SC
495:10 - group will launch another uh instance to
495:12 - meet our particular capacity um the only
495:15 - thing though is that if we were to have
495:17 - multiple E2 instances running like three
495:19 - of them um how would you distribute
495:22 - traffic to the allall right so you know
495:24 - you have an IP address coming in from
495:26 - the internet uh but let's say you want
495:28 - to evenly distribute it and that's where
495:30 - a load balcer comes into play and even
495:32 - if you have a single server you should
495:34 - always have a load balancer because it
495:35 - just makes it a lot easier for you to
495:37 - scale when you need to and you it acts
495:40 - as an intermediate layer where you can
495:41 - attach a web application firewall you
495:43 - can attach an SSL certificate for free
495:46 - so there's a lot of reasons to have a
495:49 - load balancer so what we'll do is go
495:51 - down below on the left hand side and
495:52 - we're going to make our way over to load
495:53 - balancers and we're going to create
495:55 - ourselves a new load balancer so I'm
495:57 - going to hit create load balancer here
496:00 - and you're going to see we have a lot of
496:01 - options application load balcer Network
496:03 - load balcer Gateway load balcer and then
496:05 - the classic load balcer and so we are uh
496:08 - running an application so I'm going to
496:10 - create an application load Bouncer and
496:12 - here I'm going to say my ALB um for an
496:15 - application load balancer this is going
496:16 - to be internet facing it's going to be
496:18 - ipv4 um we're going to let it launch in
496:21 - the default um subnet and we're going to
496:23 - choose the same the same uh uh azs right
496:29 - so that we get the same subnets as our
496:32 - that are in our Autos scan group and
496:33 - that's really important okay and then
496:36 - here um you know we need to have a
496:39 - security group and I just feel like
496:41 - selecting the same one here because that
496:42 - should work no problem there and we want
496:46 - to make sure that we can listen on Port
496:48 - 80 and that it's going to forward it to
496:50 - a a um a Target group it looks like I
496:52 - might have a Target group there from
496:54 - before so just to reduce that confusion
496:57 - you won't have this problem I'm just
496:58 - going to double check if that's true so
497:01 - do I have a Target group from there from
497:02 - before yes I do that came
497:06 - from I'm not sure it might have been
497:08 - created by um elastic bean stock and
497:11 - wasn't deleted okay so I'll go back over
497:14 - to here just so there's less confusion
497:18 - and we were selecting our Target group
497:20 - so we're going to have to create a new
497:21 - Target group so we go over here and here
497:24 - you can choose whether it's instance IP
497:27 - Lambda application load balancer so you
497:29 - could point it specifically to an IP
497:31 - address and so if it was a static IP
497:33 - address that would make sense uh
497:35 - apparently you can Port uh point it
497:37 - directly to instances I don't remember
497:39 - seen that option before I guess that
497:41 - makes sense yeah no sorry that makes
497:43 - sense because that would go to uh vpcs
497:45 - okay or sorry U asgs Autos scaling
497:47 - groups it's just that you are pointing
497:50 - them to Auto scaling groups you're not
497:51 - pointing them to instances so that's why
497:52 - that's confusing so I'm going to say my
497:55 - um Target group it'll be for Port 80
497:57 - here um protocol http1 is fine we want
498:01 - to be in the same U VPC so that's fine
498:04 - as well and down below we have our
498:06 - health check and so the for slash means
498:08 - that it's going to hit the index HTML
498:10 - page and so if it gets back um something
498:13 - healthy and that that something healthy
498:14 - is going going to be um uh Port 80 then
498:18 - it's going to be considered good and
498:20 - then we can say the threshold of check
498:22 - so I'm just going to reduce this so it's
498:23 - not so crazy so we'll say three uh two
498:26 - and then 10 okay and then it expects
498:30 - back A200 which I think that's what
498:32 - we'll get back so we'll go ahead and hit
498:34 - next and so now we have our Target group
498:38 - and it should register instances so it's
498:40 - saying hey we detected this and this
498:42 - fits the requirements for this so this
498:44 - is now
498:45 - uh this e two instance is now in this
498:47 - target group okay so we can go back over
498:49 - here and we can now drop down and choose
498:52 - whoops hit the refresh
498:54 - button and choose our Target
498:57 - group so I'm not seeing it here so I'm
499:00 - going to go back over here oh we didn't
499:03 - create it
499:04 - okay and now we can go back hit refresh
499:07 - and there it
499:10 - is and yeah that looks all good so we'll
499:12 - go ahead and hit create load balcer
499:15 - we can view the load balancers and these
499:17 - create really fast if we scroll on up
499:20 - what we can do is now access our server
499:23 - through this DNS name okay so we copy
499:25 - that paste that on in
499:27 - there does it
499:33 - work not as of yet so if it's not
499:36 - working there because we did say look at
499:38 - these instances another way is to
499:40 - directly associate your Autos scaling
499:41 - group with the load balancer so if I go
499:44 - into here and we hit uh
499:48 - edit there is a way aha load bouncer
499:53 - so we want to associate this way and we
499:55 - want to say this target group
499:58 - here and also while we're here we might
500:00 - as well set it to elb so it's going to
500:02 - use the elb check so that makes it so
500:04 - the Autos scaling group if it wants to
500:06 - uh restart a server it's going to use
500:07 - the elb's check which is a lot more
500:09 - sophisticated and then what we'll do is
500:11 - go hit
500:12 - update okay
500:16 - and now if we go back over to our load
500:19 - balancer we just going to close some of
500:20 - these tabs so it's less
500:23 - confusing uh load balcer
500:27 - here I think we should be able to see
500:29 - through here whether it is seeing it
500:33 - let's go down below listeners monitoring
500:36 - integrated Services no it's going to be
500:38 - through the target
500:41 - group
500:43 - okay
500:46 - I mean it already had it there so maybe
500:48 - it's just that it hasn't finished the
500:49 - check so over here it has a health
500:51 - status check oh now it's healthy okay so
500:54 - if it's healthy in the Target group and
500:55 - the load bouncer is pointing to it then
500:57 - it should technically work so we're
500:59 - going to go ahead
501:01 - and uh copy the DNS again here make a
501:05 - new tab paste it
501:08 - in and there it is okay so that's how
501:12 - you're going to access um all your all
501:14 - your instances that are within your
501:15 - autoc scaning groups you're going to
501:17 - always go through the DNS and so if you
501:19 - had a row 53 uh domain like you had your
501:21 - domain managed by AWS you just point to
501:24 - the load balancer and that's how you
501:25 - hook it up so that's pretty much it so
501:28 - yeah there you
501:29 - [Music]
501:32 - go all right so there you go we learned
501:34 - everything we wanted to know about ec2
501:36 - so the the last thing to do is to tear
501:38 - everything down so we have a load balcer
501:40 - we have an autoc scanner group um and
501:42 - those are the two things we'll have to
501:44 - pull on down so the first thing would be
501:46 - to take down the autoscaling group and
501:48 - when you delete an Autos scaling group
501:49 - it's going to delete all the ec2
501:51 - instances so we'll do it that way if you
501:53 - tried to delete the ec2 it would just
501:55 - keep on spinning up so you have to
501:57 - delete that first and so as that's
501:59 - deleting then we'll be able to delete
502:00 - our load balancer I'm going to try
502:02 - anyway to see if I can delete it at the
502:03 - same
502:05 - time and so I'll go up here I'm going to
502:08 - go ahead and delete that uh load
502:09 - balancer actually it did work no
502:12 - problem going to make sure I don't have
502:14 - any elastic
502:15 - IPS I'm going to also make sure I don't
502:18 - have any key pairs you can keep your key
502:20 - pairs around but like I just want to
502:22 - kind of clean this up
502:25 - so
502:36 - okay okay and that instance should be
502:40 - terminating got to go back to the Autos
502:42 - scan group
502:43 - here
502:47 - if we click into it we can check um its
502:50 - activity
502:52 - here so it's just saying successful so
502:55 - it is waiting on elb connection draining
502:58 - which is kind of annoying because we
503:00 - deleted elb so there's nothing to
503:02 - drain um draining is just to make sure
503:05 - that uh you know there's no
503:07 - interruptions when terminating services
503:09 - so just trying to be smart about
503:13 - it
503:21 - and all I want to see is that it's just
503:22 - saying terminating over here and then I
503:24 - think we're
503:25 - done okay so we'll just have to wait a
503:27 - little while here okay and I'll see you
503:30 - back in a moment okay all right so after
503:33 - waiting a very long time it did destroy
503:35 - so if I go down over to uh my load
503:38 - balcer here you're going to see that it
503:40 - does not exist so there was that
503:41 - connection draining thing which was kind
503:43 - of annoying it's probably because I
503:44 - deleted the load balancer first and then
503:46 - the um the uh the Autos scaling group
503:50 - second and probably connection draining
503:51 - was turned on but it's not a big deal we
503:53 - just waited it and it did eventually
503:54 - delete so we're pretty much all done
503:57 - here so there you
503:58 - [Music]
504:01 - go hey this is Andrew Brown from exam
504:03 - Pro and we are taking a look at ec2
504:05 - pricing models and there are five
504:06 - different ways to pay with ec2 remember
504:08 - ec2 are virtual machine so we have on
504:10 - demand spot reserved dedicated and AD us
504:14 - save savings plans so what we'll do is
504:16 - look at these in summary here and then
504:18 - we'll dive deep onto each of these
504:20 - different pricing models so for on
504:22 - demand you are paying the a low cost and
504:24 - also you have a lot of flexibility with
504:26 - this plan uh you are paying per hour so
504:28 - this is a pay as you go model uh or you
504:30 - could be paying uh down to the second
504:32 - which we'll talk about uh the caveats
504:34 - there when we get to the on demand
504:36 - section this is suitable for workloads
504:38 - that are going to be short-term spiky
504:40 - unpredictable workloads uh that cannot
504:42 - be interrupted and it's great for
504:43 - firsttime application
504:45 - and the on demand pricing model is great
504:47 - when you need the least amount of
504:48 - commitment for spot pricing you can see
504:50 - we can save up to 90% which is the
504:52 - greatest Savings of out of all these
504:53 - models here uh the idea here is you're
504:55 - requesting spare Computing capacity that
504:57 - adus is not using and that's where
504:59 - you're going to get that savings you
505:00 - have flexible start and end times uh but
505:02 - your workloads have to be able to handle
505:04 - interruptions because these servers can
505:06 - be stopped at any time to be giving to
505:08 - more priority customers uh and this is
505:10 - great for non-critical background jobs
505:12 - very common for like scientific
505:14 - computing
505:15 - uh where jobs can be started and stopped
505:16 - at any given time this has the greatest
505:18 - amount of savings then you have Reserve
505:20 - or reserved instances this allows you to
505:22 - save up to 75% this is great for steady
505:25 - state or predictable usage you're
505:27 - committing uh with AWS uh for ec2 usage
505:30 - over a period of one or threee terms you
505:33 - can resell un uh unused reserved
505:36 - instances so you not totally stuck with
505:38 - this if you buy them this is great for
505:40 - the best long-term savings then you have
505:43 - dedicated so these are just dedicated
505:44 - servers and technically not a pricing
505:46 - model but more so that the fact that it
505:48 - can be utilized with pricing models um
505:51 - but the idea here is it can be used with
505:53 - on demand reserved or even spot this is
505:55 - great when you need to uh have a
505:57 - guarantee of isolate hardware for
505:59 - Enterprise requirements and this is
506:00 - going to be the most expensive uh so
506:03 - yeah there you go and we'll dive deep
506:04 - here
506:05 - [Music]
506:10 - okay so the on demand pricing model is a
506:13 - pay as you go model where you consume
506:15 - compute and then you pay later so when
506:18 - you launch an ec2 instance by default
506:20 - you are using that on demand pricing and
506:23 - On Demand has no upfront payment and no
506:26 - long-term commitment you are charged by
506:28 - the second up to a minimum of 60 seconds
506:31 - so technically a minute or the hour so
506:33 - let's just talk about the difference
506:35 - between those uh per second billing and
506:37 - those per hour billing so per second are
506:40 - for Linux windows windows with SQL
506:42 - Enterprise windows with SQL standard
506:45 - windows with SQL web instances that do
506:47 - not have a separate hourly charge and
506:50 - then everything else is going to be um
506:52 - per hour and so you know when I'm
506:54 - launching ec2 instance I can't even tell
506:56 - when something's per second or per hour
506:58 - you just have to know that it has a
506:59 - separate hourly charge but generally you
507:01 - know if you're just launching things
507:03 - it's going to probably be the per second
507:04 - billing when you look up the hourly or
507:07 - the uh the pricing it's always shown in
507:09 - the hourly rate so even if it is using
507:12 - uh per second billing when you look up
507:14 - that pricing it's always going to show
507:16 - it to you like that but on your bill
507:17 - you'll see it down to the second okay up
507:20 - to the first 60 seconds in on demand is
507:22 - great for workloads that are short-term
507:24 - spiky or unpredictable uh but when you
507:27 - have a new app development this is where
507:29 - you want to experiment and then when
507:31 - you're ready to uh start saving because
507:33 - you know exactly what that workload is
507:34 - going to be over the span of a year or
507:36 - three that's where we're going to get
507:37 - into reserved instances which we'll
507:39 - cover
507:43 - next
507:45 - hey this is Andrew Brown from exam Pro
507:46 - and we are taking a look at reserved
507:48 - instances also known as RI and this is
507:51 - um a bit of a complex topic but uh you
507:53 - know if we do get through it it's going
507:55 - to serve you well through uh multiple
507:57 - adaa certifications so let's give it a
507:59 - bit of attention here so RI is designed
508:02 - for applications that have a steady
508:03 - state predictable usage or required
508:06 - Reserve capacity so the idea is that you
508:08 - are saying to ads I'm going to make a
508:09 - guaranteed commitment uh saying this is
508:12 - what I'm going to use and I'm going to
508:13 - get savings uh because abos knows that
508:15 - you're going to be spending that money
508:17 - okay so the idea here is that the
508:19 - reduced pricing is based on this kind of
508:21 - formula where we have term class
508:23 - offering the ra attributes and payment
508:25 - options technically the ra attributes
508:27 - don't exactly factor into it other the
508:29 - fact that they an our attribute could be
508:31 - like the instance type size uh but I'm
508:33 - going to put that in the formula there
508:34 - just because it is an important
508:35 - component so let's take a look at each
508:37 - of these components of the formula to
508:40 - understand how we're going to save so
508:41 - the first is the term so the term uh the
508:44 - idea here is the longer the term the
508:45 - greater the savings so you're committing
508:47 - to a one-year or threeyear contract with
508:50 - AWS um and one thing you need to know is
508:53 - that these do not renew so at the end of
508:56 - the year the idea is that you have to
508:58 - purchase again and when they do expire
509:00 - your instances are just going to flip
509:02 - back over to On Demand with no
509:03 - interruptions to service then you have
509:06 - class offerings and so the idea here is
509:08 - the less flexible the offering the
509:10 - greater the savings so the first is
509:11 - standard and this is up to a 75
509:14 - reduction in the price compared to on
509:16 - demand and the idea here is you can
509:18 - modify some ra attributes which we'll
509:20 - we'll talk about when we get to the um R
509:23 - tribute section there then you have
509:25 - convertible so you save up to 54%
509:27 - reduced pricing compared to on demand
509:29 - and you can exchange uh RIS based on the
509:32 - r attributes if the value is greater or
509:34 - equal in value and there used to be a
509:37 - third class called schedule but this no
509:38 - longer exists so if you do come across
509:40 - it just know that ads is not planning on
509:42 - offering this uh again for whatever
509:44 - reason I'm not sure why uh then there
509:46 - are the payment options so the greater
509:48 - upfront the greater the savings so here
509:50 - we have all upfront so full payment is
509:52 - made at the start of the term partial
509:54 - upfront so a portion of the cost must be
509:57 - paid upfront and the remaining hours in
509:59 - the terms are build at a discounted rate
510:01 - and then there's no upfront so you are
510:02 - build at a discounted hourly rate for
510:05 - every hour within the term regardless of
510:07 - whether the reserv is being used and
510:09 - this is really great this last option
510:11 - here because basically you're saying to
510:12 - AWS you're saying like I'm just going to
510:14 - pay my bill as usual but I'm going to
510:16 - just tell you what it's going to be and
510:17 - I'm going to save money so if you know
510:19 - uh that you're going to be using a T2
510:21 - medium for the next year uh you can do
510:24 - that and you're just going to save money
510:25 - okay so RIS can be shared between
510:28 - multiple accounts within an organization
510:30 - and unused RIS can be sold in the
510:32 - reserved instance Marketplace but we'll
510:33 - talk about the limitations around that
510:35 - when we get a bit deeper in here just to
510:37 - kind of show you what it would look like
510:38 - in adus console and they updated it I
510:40 - love this new uh UI here the idea here
510:42 - is you're going to filter BAS on your
510:44 - requirements and that's going to show
510:45 - you RIS that are available and then
510:47 - you'll just choose the desired quantity
510:49 - you can see the pricing stuff there
510:50 - you're going to add it to cart you're
510:52 - going to check out and that's how you're
510:53 - going to purchase it
510:55 - [Music]
510:58 - okay so another factor to that formula
511:01 - were RI attributes and sometimes the
511:03 - documentation calls them RI attributes
511:05 - sometimes they call them instance
511:06 - attributes but these are limited based
511:08 - on class offering and can be uh uh can
511:11 - affect the final price of the r instance
511:13 - and there are four R attributes so the
511:16 - first is the instance type so this could
511:17 - be like an M4 large and this is composed
511:20 - of an instance family so the M4 and then
511:22 - the instance size so large okay then you
511:25 - have the region so this is where the
511:27 - reserved instance is purchased then you
511:29 - have the tendency whether your instance
511:31 - runs on shared so the default which uh
511:33 - would be multi-tenant or a single tenant
511:35 - which would be dedicated hardware and
511:37 - then you have the platform whether
511:38 - you're using Windows or Linux even if
511:41 - you're using on demand of course this
511:42 - would just affect your pricing but there
511:44 - are some limitations around here which
511:45 - we'll get into as we dive a bit deeper
511:47 - here with RI
511:49 - [Music]
511:53 - okay all right let's compare Regional
511:55 - and zonal Ri so when you purchase an RI
511:58 - you have to determine the scope uh for
512:00 - it okay so this is not going to affect
512:02 - your price but it's going to affect the
512:03 - flexibility of the instance uh so this
512:06 - is something you have to decide so we're
512:07 - going to talk about Regional RI which is
512:09 - when you purchase it for a regional and
512:10 - zonal RI when you purchase it for an
512:12 - availability Zone so when you purchase
512:15 - it for regional RI it does not Reserve
512:18 - capacity meaning that there's no
512:19 - guarantee that those servers will be
512:21 - available so if ads runs out of those
512:23 - servers uh you're just not going to have
512:24 - them but when it's zonal uh you are
512:27 - reserving capacity so there's a
512:29 - guarantee that those will be there when
512:30 - you need them um in terms of uh AZ
512:34 - flexibility uh you can use the regional
512:36 - RI for any AZ within that region but for
512:39 - the zonal ri you can only use it for
512:42 - that particular region we're talking but
512:44 - instance flexibility um you can apply
512:46 - the discount to uh any instance in the
512:49 - family regardless of the size uh but
512:52 - then when we're looking at a there is no
512:54 - instance flexibility okay so you're just
512:55 - going to use it for exactly what you
512:57 - defined you can cue purchases for
512:59 - regional RI you cannot cue purchases for
513:02 - zonal Ri so there you
513:05 - [Music]
513:08 - go let's talk about some ra limits here
513:10 - so there's a limit to the number of
513:12 - reserved instances that you can purch
513:13 - purchase per month and so uh the idea
513:16 - here is that you can purchase 20
513:17 - Regional reserved instances per region
513:20 - and then 20 zonal reserved instances per
513:23 - a so if you have a region that has three
513:25 - azs you can have uh 60 um zonal reserved
513:29 - instances in that region okay there are
513:32 - some other limitations here so for
513:34 - regional limits you cannot exceed the
513:36 - running on demand instance limit by
513:38 - purchasing Regional reserved instances
513:40 - the default for on demand limit is 20 so
513:43 - before for purchasing your RI ensure on
513:45 - demand limit is equal to or greater than
513:48 - your RI you intend to purchase you might
513:49 - even want to open up a service uh limit
513:52 - increase just to make sure you don't hit
513:54 - that wall for zonal limits you can
513:56 - exceed your running on demand uh
513:58 - instance limit by purchasing zonal
514:00 - reserved instances if you're already uh
514:02 - have 20 on demand instances and you
514:04 - purchase 20 zonal reserved instances you
514:07 - can launch a further 20 on demand
514:08 - instances that match the specification
514:10 - of your zonal reserved instances so
514:12 - there you go
514:16 - [Music]
514:18 - let's talk about capacity reservation so
514:20 - ec2 instances are backed by different
514:22 - kinds of hardware and so there is a
514:24 - finite amount of servers available
514:26 - within an availability Zone per instance
514:28 - type of family remember an availability
514:29 - zone is just a data center or a
514:31 - collection of data centers and they only
514:33 - have so many servers in there so if they
514:35 - run out because the demand is too great
514:37 - you just cannot spin anything up and so
514:39 - that's what's happening you go to launch
514:40 - specific ec2 instant type but Abus is
514:42 - like sorry we don't have any right now
514:44 - and so the solution to that is capacity
514:46 - reservation so it is a service of ec2
514:49 - that allows you to request uh a reserve
514:51 - of VCU instance type for a specific
514:54 - region and a so here you would see that
514:56 - you just select the instance type
514:58 - platform AZ tendency the quantity and
515:01 - then here you might manually do it
515:03 - specify time or you might say okay I
515:05 - can't get exactly what I want but can
515:07 - give me something generally around uh
515:09 - that kind of stuff or that type that I
515:11 - want so the reserve capacity is charged
515:13 - at the selected instance type on demand
515:15 - rate whether an instance is running in
515:17 - it or not and you can also use Regional
515:19 - reserved instances With Your Capacity
515:21 - reservations to benefit from billing
515:24 - discounts so there you
515:26 - [Music]
515:29 - go so there are some key differences
515:32 - between standard and convertible Ri so
515:34 - let's take a look at it here so the
515:36 - first is that with standard RI you can
515:37 - modify your tributes so you can change
515:40 - the a within the same region you can
515:42 - change the scope uh from a zonal RI to
515:45 - original RI or vice versa you can change
515:47 - the instance size uh as long as it's a
515:50 - Linux and it has the default tendency
515:52 - you can change the network from ec2
515:54 - classic to VPC and vice versa but when
515:56 - you're looking at convertible you you
515:58 - don't modify R tributes you perform an
516:01 - exchange okay and so standard RIS cannot
516:03 - do exchanges where convertible RI you
516:06 - can uh exchange during the term for
516:09 - another convertible r with new R
516:10 - attributes and this includes instance
516:12 - family in in type platform scope and
516:16 - tendency um in terms of the marketplace
516:19 - you C uh they can be bought in standard
516:21 - RI uh in the marketplace or you can sell
516:23 - your RI if you uh don't need them
516:25 - anymore uh but for convertible RI they
516:28 - cannot be sold or bought in the
516:30 - marketplace you're just dealing with ads
516:31 - directly
516:33 - [Music]
516:36 - okay hey this is Andrew Brown from exam
516:39 - Pro and we are taking a look at the
516:40 - reserved instance Marketplace we had
516:42 - mentioned a R so let's give it a little
516:44 - more attention here so it allows you to
516:45 - sell your unused standard RI to recoup
516:48 - your spend for RI you do not intend or
516:51 - cannot use so reserved instances can be
516:53 - sold after they have been active for at
516:55 - least 30 days and once databus has
516:57 - received the upfront payment you must
516:59 - have a US bank account to sell RI on the
517:01 - ri Marketplace there must be at least
517:03 - one month remaining in the term for the
517:05 - ri you are listing you will retain the
517:08 - pricing and capacity benefit of your
517:10 - reservation until it's sold and the
517:11 - transaction is complete your company
517:13 - name and address upon requests will be
517:15 - shared with the buyer for tax purposes a
517:18 - seller can set Only The Upfront price of
517:20 - an RI the usage price and other
517:22 - configurations such as instance type
517:24 - availability Zone platform will remain
517:26 - the same as when the ri was initially
517:28 - purchased the term length will be
517:30 - rounded down to the nearest month for
517:31 - example a reservation with 9 months and
517:33 - 15 days remaining will appear as 9
517:35 - months on the R Market you can sell up
517:38 - to 20,000 USD in reserved instances per
517:41 - year if you need to sell more RI
517:43 - reserved instances in the gov Cloud uh
517:45 - region cannot be sold on the ra
517:47 - Marketplace so there you
517:49 - [Music]
517:53 - go hey it's Andrew Brown from exam Pro
517:55 - and we are taking a look at spot
517:57 - instances so adus has unused compute
517:59 - capacity that they want to maximize the
518:01 - utility of their idle servers all right
518:04 - so the idea is just like when a hotel
518:06 - offers booking discounts to fill vacant
518:08 - Suites or planes offer discounts to fill
518:11 - vacant seats all right so spot instances
518:14 - provide a discount of 98% compared to On
518:16 - Demand pricing spot instances can be
518:19 - terminated if the Computing capacity is
518:21 - needed by other on demand customers but
518:23 - from what I hear rarely rarely does spot
518:25 - instances ever get terminated um it's
518:28 - designed for applications that have
518:29 - flexible start and end times or
518:31 - applications that are only feasible at
518:33 - very low compute cost so you see some
518:35 - options here like load balancing
518:36 - workloads flexible workloads Big Data
518:38 - workloads things like that um there is
518:40 - another service called abis batch which
518:42 - is for doing batch processing and this
518:44 - is very common what you use um spot WID
518:47 - and so you know if you find the spot
518:48 - interface too complicated you're doing
518:50 - batch processing you want to use this
518:51 - service instead um there are some
518:54 - termination conditions so instances can
518:56 - be terminated by adus at any time if
518:58 - your instance is terminated by ads you
519:00 - don't get charged for a partial uh hour
519:02 - of usage if you terminate an instance
519:04 - you will be still charged for an hour uh
519:07 - that it ran so there you
519:12 - go
519:14 - hey this is Andrew Brown from exam Pro
519:15 - and we are taking a look here at
519:17 - dedicated instances so dedicated
519:19 - instances is designed to help meet
519:21 - regulatory requirements inabus also has
519:23 - this concept called dedicated hosts and
519:25 - this is more for when you have strict
519:27 - server bound licensing that won't
519:28 - support multi- tendency or cloud
519:30 - deployments and we'll definitely
519:31 - distinguish that in this course but just
519:33 - not in this slide in particular um and
519:35 - so to understand uh dedicated instances
519:38 - or hosts we need to understand the
519:39 - difference between multi- tendency and
519:40 - single tendency so multi- tendency you
519:42 - can think of like everyone living in the
519:44 - same apartment and single tendency you
519:46 - can think of it everyone having their
519:47 - own house so the idea here is that you
519:50 - have a server I'm just going to get my
519:52 - uh cursor or my pen out here to say
519:54 - server and you have multiple customers
519:56 - running workloads on the same hardware
519:58 - and the idea is that they are separated
520:00 - via virtual isolation so they're using
520:02 - the same server but it's just software
520:04 - that might be separating them okay and
520:07 - then we have the idea of single tency so
520:09 - we have a single customer that has
520:11 - dedicated Hardware so the physical
520:13 - location is what separates customers um
520:17 - and the idea here is that dedicated can
520:18 - be offered via on demand reserved and
520:21 - spot so that's why we're talking about
520:23 - dedicated here in the pricing model just
520:24 - so you know that you know even though
520:26 - these are a lot more expensive than on
520:27 - demand uh you can still save by using
520:30 - reserved and also spot which I was very
520:32 - surprised about um and when you want to
520:35 - choose dedicated you're just going to
520:37 - launch your ec2 and you'll have a drop
520:39 - down where you have that shared so
520:40 - that's the default dedicated so you have
520:42 - dedicated and dedicated host again we'll
520:44 - talk about dedicated host later when we
520:46 - need to here um and so again the reason
520:49 - why um you know Enterprises or large
520:52 - organizations may want to use dedicated
520:54 - instances is because they have a sec uh
520:56 - a security concern or obligation about
520:58 - uh against sharing the same Hardware
521:01 - with other adus customers
521:03 - [Music]
521:07 - okay hey this is Andrew Brown from exam
521:09 - Pro and we are taking a look at adus
521:11 - savings plans and this is similar to to
521:13 - reserved instances but simplifies the
521:15 - purchasing process so it's going to look
521:16 - a lot like RI at the start here but I'll
521:19 - tell you how it's a bit different okay
521:20 - so there are three types of saving plans
521:22 - you have compute Savings Plan ec2
521:24 - instance saving plans and sagemaker
521:26 - saving plans uh and so you just go ahead
521:28 - and choose that you can choose two
521:30 - different terms so one year threee so it
521:33 - be simple as that and then you choose
521:34 - the following payment options so you
521:36 - have all upfront partial payment and no
521:38 - upfront and then you're going to choose
521:40 - that hour of the commitment you're not
521:41 - having to think about standard versus
521:43 - convertible uh Regional versus zonal RI
521:47 - attributes it's a lot simpler uh and
521:50 - let's just talk about the three
521:51 - different saving plans or types in a bit
521:53 - more detail so you have compute so
521:55 - compute savings plans provides the most
521:57 - flexibility and helps to reduce your
521:59 - cost by 66% these plans automatically
522:01 - apply to ec2 instances usage ads fargate
522:04 - ads Lambda service usage regardless of
522:07 - the instance family size AZ region Os or
522:09 - tency then you have ec2 instances so
522:12 - this provides the lowest prices offering
522:14 - saving up to 72% in exchange for
522:16 - commitment to usage of instance uh
522:19 - individual instance families in a region
522:21 - so automatically reduce uh your cost on
522:23 - the selected instance family in the
522:25 - region regardless of AZ size OS tendency
522:28 - gives you the flexibility to change your
522:29 - usage between instances with a within a
522:32 - family in that region and the last is
522:34 - Sag maker so helps you reduce Sage maker
522:36 - cost by uh up to 64% automatically apply
522:39 - to sagemaker usage regardless of
522:41 - instance family size component adus
522:44 - region if you don't know what sagemaker
522:46 - is that's ad's ml service and it uses
522:49 - ec2 instances or specifically ml ec2
522:52 - instances so everything's basically
522:53 - using ec2 here um but there you
522:56 - [Music]
522:59 - go all right let's take a look at the
523:01 - zero trust model and the zero trust
523:03 - model is a security uh model which
523:05 - operates on the principle of trust no
523:07 - one and verify everything so what I mean
523:09 - by that is malicious actors being able
523:11 - to bypass conventional access controls
523:14 - demonstrates traditional security
523:15 - measures are no longer sufficient and
523:17 - that's where the zero trust model comes
523:19 - into play so with the zero trust model
523:22 - identity becomes the primary security
523:24 - perimeter uh and so you might be asking
523:27 - what do we mean by primary security
523:28 - perimeter the primary or new security
523:30 - perimeter defines the first line of
523:32 - defense and its security controls that
523:34 - protect a company's Cloud resources and
523:37 - assets um if this still doesn't make
523:39 - sense we do cover a part of the defense
523:41 - and depth where you see the layers of
523:44 - Defense from data all the way to
523:46 - physical and so you can kind of see you
523:48 - know what we're talking about in that
523:49 - model there but the old way that we used
523:52 - to do things is Network Centric so we
523:54 - had traditional security focused on
523:55 - firewalls and VPN since there were few
523:57 - employees or workstations outside the
523:59 - office or they were in a specific remote
524:02 - office so we treated the network uh the
524:04 - network as kind of like the the boundary
524:06 - so if you're in in office there's
524:08 - nothing to worry about but we don't
524:09 - think like that anymore because
524:11 - everything is identity Centric so this
524:14 - is where we have bring your own device
524:15 - remote workstations which are becoming
524:17 - more common uh we can't always trust
524:19 - that the employee is in a secure
524:20 - location we have uh identity based
524:22 - security controls like MFA we're
524:24 - providing provisional access based on
524:26 - the level risk from where when and what
524:28 - a user wants to access and identity
524:31 - Centric does not replace uh but it
524:33 - augments Network Centric security so
524:34 - it's just an additional layer of
524:36 - consideration for uh security when we're
524:39 - thinking about our Adas Cloud workloads
524:41 - okay
524:46 - all right so we just Loosely defined
524:47 - what the zero trust model is so let's
524:49 - talk about how we would do Zer Trust on
524:51 - AWS and so zero trust has to do a lot
524:54 - with identity security controls and so
524:56 - let's talk about what is at our disposal
524:58 - on AWS so on ads we have identity and
525:01 - access management IM this is where we
525:02 - create our users or groups or policies
525:04 - so IM am policy is a set of permissions
525:07 - that allow you to say okay this user is
525:09 - allowed to use uh these services with
525:11 - these particular action
525:13 - uh then you have the concept of
525:14 - permission boundaries and so these are
525:16 - saying okay um these aren't the
525:18 - permissions the user has currently but
525:20 - these are the boundaries to which we
525:21 - want them to have so they should never
525:23 - have access to um uh ml services and if
525:27 - someone's to uh apply them uh uh
525:30 - permissions it'll always be within these
525:32 - boundaries then you have service control
525:34 - policies and these are organization-wide
525:36 - policies so if you have a policy where
525:37 - you don't want anyone to run anything in
525:39 - the Canada region you can apply that
525:41 - policy at the organiz level and it will
525:43 - be enforced then within an policy there
525:46 - are the concept of conditions and so
525:48 - these are all the kind of like uh little
525:50 - knobs you can uh tweak to say how do I
525:53 - uh control based on a bunch of different
525:55 - factors so there is Source IP so
525:57 - restrict where the IP address is coming
525:58 - from a requested region so a restrict
526:01 - based on the region as we were just
526:03 - mentioned as an example uh multiactor
526:05 - off presence so restrict if MFA is
526:08 - turned off uh current time so restrict
526:10 - access based on time a day maybe your
526:13 - your employees should never be really
526:14 - using things at night and so that could
526:16 - be an indicator that someone is doing
526:17 - something malicious so you know only
526:19 - give them access during a certain time a
526:21 - day and so that's where we're going to
526:23 - figure out you know based on all these
526:25 - type of controls security controls uh to
526:27 - our adus resources we can kind of
526:29 - enforce the zero trust model adabs ads
526:32 - does not have a ready to use identity
526:34 - controls that are intelligent which is
526:36 - why adus is considered not to have a
526:38 - zero trust offering for customers and
526:39 - third-party services need to be used so
526:42 - what I'm saying is that technically you
526:44 - know this checkbox is this thing saying
526:46 - okay we can kind of do zero trust on AWS
526:50 - but the there's a lot of manual work and
526:52 - you know if I was to say okay um I don't
526:56 - want anyone using this at nighttime it
526:59 - doesn't really detect you know what I'm
527:00 - saying it's not going to say oh I think
527:02 - this time is suspicious andalicious so
527:05 - then restrict access only to these core
527:06 - services and anything outside of the
527:08 - services can't be used it just can't
527:10 - exactly do that without a lot of um work
527:12 - yourself and that's what I'm talking
527:13 - about here where we have a collection of
527:15 - a services that can be set up in an
527:17 - intelligence intelligent is detection
527:20 - way for identity concerns but requires
527:21 - expert knowledge so the way you might do
527:23 - that AWS is that everything all the API
527:26 - calls go through a cloud trail and so
527:28 - what you could do is feed those into
527:30 - Amazon guard Duty and guard duty is an
527:32 - intrusion uh uh intrusion detection and
527:35 - protection system so it could detect
527:37 - suspicious or malicious activity on
527:39 - those cloud trail logs and you could
527:41 - follow that up with mediation or you
527:43 - could pass that on to Amazon detective
527:45 - that could analyze investigate and
527:46 - quickly identify security issues uh that
527:49 - it could ingest from guard duty but I'm
527:51 - telling you that this stuff here is not
527:54 - as easy um for the consumer and so you
527:58 - of course you can do zero trust model
527:59 - but it's going to take a lot of work
528:00 - here and there are some limitations
528:02 - which we'll talk about next
528:03 - [Music]
528:07 - here so now let's see how we would do
528:09 - zero trust on adus with third parties so
528:11 - adus does does technically Implement a
528:13 - zero trust model but does not allow for
528:15 - intelligent identity security controls
528:17 - which you know you can do it but it's a
528:20 - lot of work so uh let's kind of compare
528:22 - it against kind of a third party where
528:24 - we would get the controls that we would
528:25 - not necessarily get with AWS so for
528:27 - example Azure active directory has a
528:29 - realtime and calculated risk detection
528:31 - Based on data points than AWS and this
528:34 - is based on device and application time
528:36 - of day location whether MFA is turned on
528:39 - what is being accessed and the security
528:41 - controls verification or logic
528:43 - restriction is much more robust so you
528:46 - know just as one particular example like
528:48 - device and application is not something
528:50 - that ads factors in uh with the existing
528:53 - controls or at least not in a way that
528:55 - is consumer friendly and you know I
528:57 - can't say on adus okay when you think
529:00 - that this is the type of threat only
529:02 - allow them access to these things or if
529:04 - you think they're in a risky area or
529:05 - risky uh location only give them access
529:08 - to you know these things where there's
529:10 - not sensitive data you can't exactly do
529:12 - that adus very easily and so this is
529:14 - where third party Solutions are going to
529:15 - come into play so you have Azure active
529:17 - directory Google Beyond Corp jump Cloud
529:20 - uh all these have more intelligent
529:21 - security controls for Real Time
529:22 - detection um and so the way you would
529:25 - use these is these would be your primary
529:26 - directories uh for Google Beyond Corp is
529:29 - just a zero trust framework so I guess
529:31 - you'd use uh Google's uh Cloud directory
529:35 - but the idea anyway here is that You'
529:37 - use single sign on to connect those
529:39 - directories to your adus account and
529:41 - that's how you access access those uh
529:43 - adus resources and you get this more
529:45 - robust functionality
529:50 - okay hey it's Andrew Brown from exam Pro
529:53 - and we're looking at identity now we
529:55 - need to know a bunch of Concepts before
529:56 - we talk about identity on AWS so let's
529:58 - jump into it the first is a directory
530:00 - service so what is directory service
530:02 - well it's a service that Maps the names
530:05 - of network resources to network
530:06 - addresses and a directory servic is
530:08 - shared uh infrastructure or information
530:11 - in infrastructure for locating managing
530:13 - administrating and organizing resources
530:15 - such as volumes folders files printers
530:18 - users groups devices telephone numbers
530:20 - and other objects a directory service is
530:23 - a critical component of a network
530:25 - operating system and a directory server
530:27 - or a name server is a server which
530:30 - provides a directory service so each
530:32 - resource on the network is considered an
530:34 - object by the directory server
530:36 - information about a particular resource
530:38 - is stored as a collection of attributes
530:40 - associated with that resource or op
530:42 - project uh well-known directory Services
530:44 - would be a domain name service um so the
530:48 - directory service for the internet
530:50 - Microsoft active directory and uh they
530:53 - have a cloud hosted one called Azure
530:55 - active directory we have aachi directory
530:58 - service Oracle inter internet directory
531:01 - so o ID uh open ldap uh Cloud end
531:06 - identity and jump Cloud
531:08 - [Music]
531:11 - okay hey this is Andrew Brown from exam
531:13 - Pro and we are taking a look at active
531:15 - directory now you might say well we're
531:16 - doing adabs why are we looking at this
531:18 - well no matter what cloud provider
531:20 - you're using you should know what active
531:22 - directory is uh especially when it comes
531:24 - to identity because you can use it with
531:25 - AWS um so let's talk about it so
531:28 - Microsoft introduced active directory
531:30 - domain services in Windows 2000 to give
531:32 - organizations the ability to manage
531:33 - multiple on- premise infrastructure
531:35 - components and systems using a single
531:37 - identity per user and since then it's uh
531:40 - involved uh evolved obviously it's uh
531:42 - running Beyond Windows 2000 as of today
531:45 - and uh they even have a managed one
531:47 - called Azure ad which is on Microsoft
531:49 - Azure but just to kind of give you an
531:51 - architectural diagram here the idea is
531:53 - that you would have your domain servers
531:55 - here uh and they might have child
531:57 - domains and the idea is that you have
531:59 - these running on multile machines so
532:00 - that you have redundant ability to log
532:02 - in from various places when you have a
532:04 - bunch of domains it's called a forest
532:06 - and then within a domain you actually
532:08 - have organizational units and when then
532:10 - within organizational units you have all
532:11 - your objects look like your users your
532:12 - printers your computers your servers uh
532:14 - all things like that
532:16 - [Music]
532:20 - okay hey it's Andrew Brown from exam Pro
532:22 - and we're talking about identity
532:23 - providers or ipds
532:40 - so
533:03 - hey this is Andrew Brown from exam Pro
533:05 - and we are talking about identity
533:06 - providers also known as
533:09 - idps so an identity provider is a system
533:12 - entity that creates maintains and
533:13 - manages identity information for
533:15 - principles and also provides
533:16 - authentication services to Applications
533:18 - with a federation or distributor Network
533:21 - a trusted provider of your user identity
533:23 - that lets you use authent uh lets you
533:24 - authenticate to access other service
533:27 - identity providers so this could be like
533:28 - Facebook Amazon Google Twitter GitHub
533:31 - LinkedIn uh Federate identity is a
533:33 - method of linking a user's identity
533:35 - across multiple separate identity
533:37 - management systems and so some things
533:39 - that uh we can use for that is like open
533:41 - ID so this is an open standard and
533:43 - decentralized Authentication Protocol
533:45 - allows you to be able to log in to
533:47 - different social media platforms using
533:49 - Google or Facebook account open ideas
533:51 - about providing who you are then we have
533:53 - ooth 2.0 this is an industry standard
533:56 - protocol for authorization oo doesn't
533:58 - share password data but instead uses
534:01 - authorization tokens to prove an
534:03 - identity between consumers and service
534:05 - providers o is about granting access to
534:08 - functionality and then we have samles
534:10 - security assertion markup language which
534:13 - is an open standard for exchanging
534:15 - authentication and authorization between
534:16 - an identity provider and a service
534:18 - provider and this is important use for
534:21 - samle which we use for single sign on
534:23 - via the web browser
534:26 - [Music]
534:30 - okay hey this is Andrew Brown from exam
534:32 - Pro we're looking at the concept of
534:34 - single sign on so SSO is an
534:36 - authentication scheme that allows a user
534:37 - to log in with a single ID and password
534:39 - to different systems and software as so
534:42 - allows it departments to administer a
534:43 - single identity that can access many
534:45 - machines and cloud services so the idea
534:47 - is you have as your active directory
534:48 - this is just an example of a very
534:50 - popular one You' use samle to do SSO and
534:52 - you can connect to All Things slacks
534:54 - Google workspaces Salesforce or your
534:57 - computer uh the idea here is uh once you
535:00 - uh log in um you don't have to log in
535:03 - multiple times so you log into your
535:04 - primary directory and then after that
535:06 - you're not going to be presented with a
535:07 - login screen some Services might show an
535:09 - intermediate screen but the idea is
535:10 - you're not entering your credentials in
535:13 - multiple times so it's
535:14 - [Music]
535:17 - seamless all right let's talk about ldap
535:20 - so lightweight directory access protocol
535:22 - is an open vendor neutral industry
535:24 - standard application protocol for
535:26 - accessing and maintaining distributed
535:27 - directory information Services over uh
535:30 - IP network so a common use of ldap is to
535:34 - provide a central place to store
535:36 - usernames and passwords ldap enables for
535:39 - same sign on so same sign on allows us
535:41 - to uh use a single ID and password but
535:44 - they have to enter it every single time
535:45 - they want to log in so maybe you have
535:47 - your on premise active directory and
535:50 - then it's going to store it in that ldap
535:52 - directory and so the idea is that um you
535:55 - know all these services like Google
535:57 - kubernetes um jenings is going to uh
536:00 - deal with that ldap server so why would
536:02 - you use ldap over SSO which is more
536:05 - convenient or seamless so most SSO
536:08 - systems are using ldap under the hood
536:10 - but ldap was not designed aily to work
536:12 - with web applications so some systems
536:14 - only support integration with ldap and
536:17 - not SSO so you got to take what you can
536:19 - get
536:20 - [Music]
536:23 - okay let's take a look here at
536:24 - multifactor authentication also known as
536:27 - MFA and this is a security control where
536:29 - after you fill in your user's name an
536:31 - email password you have to use a second
536:34 - device such as a phone to confirm that
536:36 - it's you that is logging in so MFA
536:38 - protects against people who have stolen
536:40 - your password MFA is an option in most
536:42 - Cloud providers and even social media
536:44 - websites such as Facebook so the idea is
536:47 - I have my uh username or email and
536:49 - password I'm going to try to log in this
536:51 - is the first factor and the second
536:53 - factor or multiactor is I'm going to use
536:55 - a secondary device so maybe my phone
536:57 - we're going to enter in different codes
536:59 - or maybe it's passwordless so I just
537:01 - have to press a button to confirm that
537:02 - it's me and then I'll get access so in
537:04 - the context to AWS it's strongly
537:07 - recommended that you turn on MFA for all
537:09 - your accounts especially the adus root
537:11 - account uh we'll see that when we do the
537:13 - follow
537:14 - [Music]
537:18 - alongs let's take a look at security
537:20 - keys so a security key is a second
537:22 - device used as a second step in
537:24 - authentication process to gain access to
537:25 - a device workstation or application a
537:28 - security key can resemble a memory stick
537:30 - and when your finger makes contact with
537:32 - a button of exposed metal on the device
537:34 - it will generate an autofill a security
537:35 - token a popular brand of security Keys
537:38 - is the UB key and this is the one I use
537:40 - and is looks exactly like the one that's
537:41 - right beside my desk it works out of the
537:43 - box with Gmail Facebook and hundreds
537:45 - more supports PH2 web offn uh u2f it's
537:51 - waterproof and Crush resistance it uh
537:53 - has variations like usba us uh NFC dual
537:57 - connectors on a single key can do a
537:59 - variety of things so when you turn on
538:01 - MFA on your adabs account you'll have
538:03 - virtual MFA device so that's when you're
538:05 - using something like a phone or using
538:07 - software on your phone to do that then
538:09 - there's the u2f security key ke so this
538:11 - is what we're talking about right now
538:13 - and there's even other kinds of Hardware
538:15 - MFA devices um which we're not really
538:17 - going to talk about but um you know just
538:20 - security Keys tie into MFA and this is a
538:23 - lot better way than using a phone
538:25 - because you know you can have it on your
538:26 - desk and press it um and you know you
538:28 - don't have to worry about your phone
538:29 - being not charged
538:31 - [Music]
538:34 - okay hey this is Andrew Brown from exam
538:36 - Pro and we are taking a look at itus
538:38 - identity and access management also
538:40 - known as I am and you can use this
538:42 - service to create and manage adus users
538:44 - groups uh use permissions to allow and
538:47 - deny their access to adus resources so
538:49 - there's quite a few components here
538:51 - let's get to it so the first is I am
538:53 - policies so these are Json documents
538:55 - which Grant permissions for specific
538:56 - users groups or a role to access
538:59 - services and policies are attached to IM
539:01 - identities then you have IM permissions
539:03 - or a permission and this is an API
539:06 - action that can or cannot be performed
539:08 - and they represented in the IM policy
539:11 - document
539:12 - then there's the IM identities so we
539:14 - have IM users these are end users who
539:16 - log into the console or interact with ad
539:18 - resources programmatically or via
539:20 - clicking UI interfaces you have IM
539:22 - groups so these these uh group up your
539:24 - users so they all share the same
539:26 - permission levels so maybe it's admins
539:28 - developers or Auditors then you have IM
539:31 - roles so these roles Grant ads resources
539:33 - uh permissions to specific ads API
539:35 - actions and Associate policies to a role
539:38 - and then assign it to an adus resource
539:40 - so just understand that roles are when
539:42 - you're attaching these to uh resources
539:44 - so like if you have an ec2 instance and
539:46 - you say it has to access S3 you're going
539:48 - to be attaching a a rooll not a policy
539:51 - directly
539:53 - [Music]
539:56 - okay hey this is Andrew Brown from exam
539:58 - Pro and we are looking at IM policies a
540:01 - little bit closer here and they are
540:03 - written in Json and contain the
540:04 - permissions which determine the API
540:06 - actions that are allowed or denied um
540:08 - and rarely do I write these out by hand
540:11 - uh because they have a a little wizard
540:13 - that you can use to write out the code
540:15 - for you but if you want to you
540:17 - absolutely can write it out by hand but
540:18 - we should know the contents of it and
540:20 - how these Json files work so the first
540:22 - thing is the version uh which is the
540:24 - policy language version and it's been
540:26 - 2012 for a very long time I don't see
540:28 - that changing anytime soon if they
540:30 - happen to change uh what or what the
540:33 - structure of the Json is then you have
540:35 - the statements and these are for policy
540:37 - elements uh and you're allowed to have
540:39 - multiples of them so the idea is that
540:41 - this is the the policies or permissions
540:43 - we should say uh that you uh plan on
540:46 - applying then you have the Sid this is a
540:48 - way of labeling your statements um this
540:51 - is useful for like visualization or for
540:53 - referencing it for later on but a lot of
540:55 - times you don't have to have a sid um
540:57 - then there's the effect it's either
540:59 - allow or deny then you have the action
541:01 - so here we're saying give access to S3
541:05 - for all actions under it there's another
541:07 - action down below where it's saying give
541:10 - access I'm going get my pen tool out
541:11 - here just to create a service link role
541:13 - so that's a cross account role there
541:15 - then there's the principal so this is
541:17 - the account user role or Federated user
541:19 - to which you would like to allow access
541:21 - or deny so we're specifically saying uh
541:24 - this IM am user named Barkley um in our
541:27 - adus account there uh then there are the
541:29 - resources so the resources to which the
541:31 - action applies um so in this one up here
541:34 - we are specifying a specific adus bucket
541:36 - here we're saying all possible resources
541:38 - in in adus account and then the
541:40 - condition so so there's all sorts of
541:42 - different kinds of conditions so this is
541:43 - a string like one and it's saying look
541:45 - at the service name and if it starts
541:47 - with this or that then they'll have
541:48 - access to that so this person even
541:50 - though it says all resources they're
541:51 - really only going to have access to RDS
541:54 - [Music]
541:57 - okay so in this follow along we're going
541:59 - to take a closer look at I am policies
542:01 - so go to the top and type in I and what
542:04 - we'll do is make our way over here uh
542:07 - all the way over to policies and what I
542:09 - want to do is create a new policy that
542:11 - only has access to uh um limited
542:14 - resources so um let's say we want to
542:17 - create an Amazon ec2 instance and that
542:19 - E2 instance has access to a very
542:22 - particular S3 bucket so what I want you
542:24 - to do is make your way over to S3 and
542:26 - we're going to create ourselves a new
542:30 - bucket and I'm going to go ahead and
542:32 - create a bucket here we're going to call
542:34 - this
542:35 - um policy
542:38 - tutorial and I'm going to just put a
542:40 - bunch of numbers here
542:42 - you'll have to randomize it for your use
542:44 - case and so now that we have our bucket
542:47 - what we're going to do is go ahead and
542:48 - create a
542:51 - policy and the policy is going to choose
542:54 - a service we're going to say S3 and what
542:56 - I want to do is only be able to list out
542:58 - actions I'm going to expand this so I
543:00 - don't want everything so we're just
543:01 - going to say list
543:02 - buckets okay and then what we'll do is
543:07 - uh expand this here and I want to save
543:08 - for a particular bucket so we'll go back
543:11 - back over here click into our
543:13 - bucket and uh we're going to go ahead
543:16 - and set those
543:18 - permissions by finding that Arn we're
543:22 - going to paste
543:23 - that we're going to paste that Arn up
543:25 - there sometimes it's a bit tricky it
543:26 - vanishes on
543:27 - you and we could set other conditions if
543:30 - we wanted to but this is pretty simple
543:32 - as it
543:33 - is and so that's our rule here right so
543:36 - we're saying this policy allows us to
543:38 - list this bucket for that okay so what
543:41 - we'll do is go ahead and hit next we'll
543:43 - hit review and we'll just say my bucket
543:48 - policy and we'll create that
543:54 - policy okay so there's a few other
543:57 - things I think that I'd like to do with
543:58 - this policy I'm going to pull it back up
544:00 - here so if we want to find it uh used to
544:03 - be able to filter these based on the
544:04 - ones that you
544:06 - created but
544:08 - um yeah they show like the little I so
544:11 - these are ones that I've created up here
544:14 - and so there's my bucket
544:16 - policy and I feel like I want to update
544:19 - this policy to have a bit of extra
544:22 - information here so I'm going to go edit
544:24 - this
544:25 - policy no you know what I think this is
544:27 - fine so what I want to do is now create
544:29 - a
544:32 - ro and we're going to create a new Ro
544:34 - and I'm going to call this
544:36 - um well before I do I need to choose
544:38 - what it's for so it's going to be for
544:39 - ec2 so we're going to go ahead and hit
544:41 - next we're going to choose our policy so
544:43 - my bucket policy there it is and I want
544:46 - to add another one here because I want
544:48 - to be able to use sessions manager
544:49 - because I really don't want to use an
544:50 - SSH key to check that this works and
544:54 - so um for this I I need to use SSM so
545:00 - I'm going to type in SSM
545:02 - here and I'm just make sure this is the
545:04 - new one so this policy will soon be
545:06 - deprecated use Amazon SSM manag core
545:09 - instance should always open these up and
545:10 - read them and see what they do and so
545:13 - that's the one that's going to allow us
545:14 - to access uh Simpson manager so we can
545:16 - use um sessions manager okay and so
545:19 - we're going to say my ec2 roll for
545:23 - S3 and we're going go ahead and create
545:25 - ourselves a
545:28 - roll so now that we have our roll I'm
545:31 - going to go over to
545:33 - ec2 and I'm going to go ahead and launch
545:35 - myself a new
545:37 - instance we're going to choose Amazon
545:39 - ltic 2 we're going to stick with T2
545:42 - micro I'm going to go over to
545:43 - configuration here everything is fine
545:46 - here um I'm fine with all that storage
545:48 - is fine we'll go to Security Group and I
545:51 - don't want any ports open because I'm
545:54 - not going to be using
545:56 - SSH we're going to launch this instance
545:58 - I don't even want to keep
546:00 - pair
546:03 - okay and then we're going to go over
546:05 - here and so what we're waiting for is
546:07 - this instance to launch as that is going
546:09 - what I want to do is go over to my S3
546:11 - bucket and I want to place something in
546:13 - this bucket so I do have some files here
546:17 - um so what I'm going to
546:18 - do let's create a new folder here whoops
546:22 - I'm going to go back and I'm just going
546:24 - to create a folder first create a folder
546:26 - Enterprise
546:32 - D and I'm going to click into this and
546:34 - then I'm going to upload all my images
546:36 - here so you'll have to find your own
546:38 - images off the internet this is just the
546:40 - ones I have and we'll go ahead and
546:43 - upload
546:44 - those give that a
546:50 - moment okay and so we don't have access
546:53 - to read those files we'll adjust our
546:55 - policy as we go so that we can do that
546:58 - okay so this instance should be running
547:01 - um it has doesn't have the two status
547:03 - checks pass we should be able to uh
547:05 - connect to it so click on connect here
547:07 - and so we have options like easy to
547:08 - instance connect sessions manager SSH
547:10 - client I want you to go to sessions
547:11 - manager it says we weren't able to
547:13 - connect to your instance common reasons
547:15 - SSM agent wasn't installed we absolutely
547:17 - have that installed the required I am
547:19 - profile oh right so we were supposed to
547:22 - attach I forgot to do we were supposed
547:24 - to attach an I am profile right so an I
547:26 - profile is the role uh it or the it
547:30 - holds the role uh that's going to give
547:32 - the permissions to that instance and
547:34 - since we didn't add it we have to go
547:36 - retroactively add it after the
547:39 - fact and so I'm going to have to modify
547:41 - the IM roll and we're going to choose my
547:45 - ec2 roll for S3 and we're going to save
547:48 - that and actually when that happens you
547:50 - have to reboot the machine you only have
547:53 - to do that if you have no Ro attached
547:55 - like prior no profile attach and you're
547:57 - attaching it for the first time but
547:59 - after that you never have to reboot the
548:00 - machine this is the only case where
548:01 - you'd have to do
548:03 - that that's why when I launch an ec2
548:05 - instance I always at least have the SSM
548:07 - R attached the managed one that gets
548:09 - sessions manager so that I don't don't
548:10 - ever have to do a reboot in case I have
548:12 - to update the
548:14 - policy and so we will give that a moment
548:18 - there it says initializing so I'm going
548:21 - to try again to connect to it
548:26 - okay and we still don't have that option
548:28 - there um so I'm going to go back to my
548:30 - instances I'm going to check to see if
548:32 - the role the rule or policy is
548:35 - attached or profile I should
548:39 - say
548:41 - so I'm just looking for it
548:45 - here there it
548:47 - is and so if I click into this into the
548:50 - r we can see that we have the Amazon SSM
548:54 - managed instance core there so that's
548:56 - set up and then my uh bucket policy so
549:00 - this has everything that it should be
549:03 - able to do it no
549:07 - problem okay so I'm going to try that
549:09 - again
549:11 - okay so now the connect shows up ads is
549:13 - finicky like that you just have to have
549:15 - confidence in knowing what you're doing
549:17 - is correct okay we'll go ahead and hit
549:20 - connect and I didn't have to use SSH
549:23 - keys or anything and this is a lot more
549:25 - secure way to connect your instances
549:27 - when it logs Us in it's going to set us
549:28 - as the SSM user but we want to be
549:32 - the um the ec2 user
549:35 - okay that's uh ads always makes their am
549:39 - like their Linux version as the ec2 user
549:41 - and that's what you're supposed to use
549:43 - but it's just you just that's how you
549:45 - have to get to that you just have to
549:46 - type that pseudo suyen ec2 user okay
549:49 - just once and if you type who am I
549:52 - that's who you are if you type exit
549:53 - you'll go back to that user so I type
549:55 - exit and I type who am I I'm now this
549:57 - person so I'm going to go back hit up go
549:59 - back in there type clear so now I want
550:02 - to see if I have access to S3 so I have
550:04 - to do OS S3 LS want's see if I can list
550:08 - buckets it says access deny
550:12 - so I mean that kind of makes sense
550:14 - because if you have list buckets and
550:16 - we're just saying only that bucket that
550:17 - might not make a whole lot of
550:19 - sense so I'm going to go back to my
550:22 - policy I might just written a a crummy
550:24 - policy but we'll say I am here if we
550:26 - have that one open we should just go
550:28 - here and click on this policy
550:34 - here I'm going to edit that
550:36 - policy so what I'm going to do is I'm
550:38 - just going to change it and we all
550:40 - resources review the policy save changes
550:43 - and we'll see how fast that
550:46 - propagates
550:55 - okay because I'm pretty sure I don't
550:57 - have to do anything here it should just
550:59 - now give me full access to
551:01 - S3 just going to keep on hitting up
551:04 - here so what I'm going to do is I'm just
551:06 - going to take like a three four minute
551:07 - break going to get a drink I'm going to
551:09 - come back here and see if this
551:10 - propagates I'm pretty sure I don't have
551:12 - to do anything for that to propagate and
551:15 - I think that I've attached everything
551:16 - correctly here
551:19 - okay okay so I haven't had much luck
551:21 - here it's still having the same issue so
551:23 - if that is happening what I'm going to
551:25 - do um is I'm just going to reboot it
551:28 - because maybe I didn't give it a good
551:30 - opportunity to reboot there again I
551:32 - don't think we should have to reboot it
551:33 - every time when we we're changing um uh
551:36 - things there but we will give it another
551:38 - go here and see if if that fixes that
551:41 - problem there so no sessions matter is
551:43 - going to time out here which is totally
551:46 - fine it's going to kill that session
551:48 - there um and so what we'll have to do is
551:51 - close this out because there's not much
551:53 - we can do with
551:54 - that and we're going to go ahead and go
551:56 - back to connect and so we're waiting for
551:58 - this button to appear because it is
552:00 - rebooting so if we want to monitor that
552:03 - stuff usually there is an option here to
552:07 - monitor where it'll show us the system
552:09 - logs of what it's doing doing so here
552:11 - it's just like restarting the
552:21 - machine I'm not sure if we expect to see
552:23 - something after
552:25 - this so I can click that
552:31 - there and uh yeah it's easy to get
552:33 - turned around this so I can connect to
552:35 - it again
552:39 - now we'll type in pseudo Su hyphen ec2
552:42 - user ads S3
552:46 - LS and we still
552:48 - have access deny for list buckets so if
552:52 - that's the case it could be that um
552:55 - sometimes you need other permissions
552:57 - when doing list policy like uh list
552:59 - buckets so if that's the case we're
553:01 - going to do a sanity check I'm just
553:03 - going to say all permissions here okay
553:05 - and this way there's no way that I've
553:06 - set this
553:07 - incorrectly um it just has to work now
553:10 - type this
553:12 - in there we go okay so there has to be
553:15 - something more to it so just because you
553:16 - say list buckets you know like means
553:19 - there must be more to it right so if I
553:21 - go here to this right and I say
553:24 - whoops and I say uh list buckets here
553:27 - we'll say
553:29 - copy paste
553:38 - okay here it's saying maybe I need get
553:40 - object as well so I just know from using
553:45 - a long time that that's the case that it
553:47 - could be more than one thing so you know
553:49 - that was in the back of my mind that
553:50 - that could be happening and I guess that
553:52 - is but notice I didn't have to restart
553:54 - my uh my server boot my server to get
553:56 - those to work um uh but anyway let's go
553:59 - lock that down and see if we can just
554:00 - kind of make this uh more focused so
554:03 - let's say um all resources I'm going to
554:07 - specify the condition
554:11 - so I might want to just say for
554:12 - particular
554:14 - buckets we say specific when you
554:17 - checkbox everything then you have to do
554:18 - this so for storage accounts these are
554:20 - fine any for
554:25 - objects that could be something we'll
554:28 - say multi- region access bucket any
554:31 - bucket but what I'm going to say is I
554:33 - want to only allow them to access things
554:35 - in a particular bucket and so if I go to
554:37 - Arn
554:39 - here um what is our bucket
554:47 - name our bucket name is policy tutorial
554:52 - 3414 whatever right and so we can
554:57 - actually give it a wild card or we can
554:58 - say
555:00 - Enterprise
555:03 - D and we learned this in the course that
555:05 - uh you can provide orangs with
555:08 - randomize things there I don't know know
555:10 - if I spelled it wrong over here so I
555:11 - should really double check I should
555:13 - probably just copy
555:19 - it
555:21 - oops I just don't want to type it wrong
555:23 - and so
555:25 - this
555:27 - okay means that we should only be able
555:29 - to get stuff from there I'm going to
555:31 - review the policy see if it takes save
555:33 - the
555:35 - changes and if I just view the Json
555:38 - here notice it says anything from here
555:42 - right so allow S3 anything as long as
555:46 - it's within here and then it also broke
555:47 - it up into sub one4 here okay um so
555:51 - anyway what I want to see is what
555:53 - happens if I upload something into the
555:56 - loose area here so I'm to say
555:58 - upload and I'm going to just say add a
556:02 - file we're just going to grab data here
556:05 - and upload
556:06 - it go back to our bucket there there's
556:10 - our file we have that stuff in there and
556:11 - so if I go back over to my ec2 instance
556:13 - which I'm still connected
556:15 - to uh who am I okay great clear um so
556:19 - I'm going to say ads S3 LS see if that
556:22 - works still it does good and so what I
556:25 - want to do is see if I can copy a file
556:26 - locally so I'm going to do Abus S3
556:31 - copy I think it was S3 no it's just S3
556:34 - copy polic uh S3 SL SL policy
556:42 - tutorial
556:45 - 34 141 whoops
556:48 - 34 tutorial
556:51 - hyphen
556:54 - 34141
556:56 - slash Enterprise
556:59 - D data.jpg I think it's a JPG let's go
557:03 - double check yeah it is okay and then I
557:06 - just want to say data.jpg
557:10 - and it downloaded it right so I'm going
557:12 - to remove that one and so now what I'm
557:14 - going to do is I'm just going to see if
557:16 - my policy is working or maybe my
557:18 - permissions aren't exactly what I think
557:19 - they are and I was able to download it
557:22 - so it's these policies can get kind of
557:25 - tricky because like this one says allow
557:27 - all actions for these but then these say
557:29 - all actions and
557:32 - so that makes it hard because I want get
557:38 - object
557:41 - so another thing we can
557:42 - do and if that one doesn't work really
557:44 - well I'm just going to write one by hand
557:47 - it's not that scary to write these by
557:48 - hand you just get used to it so I'm
557:50 - going to say
557:53 - effect um is it disallow or maybe it's
557:59 - deny
558:01 - deny
558:06 - action S3 get off object I believe
558:11 - that's what it
558:13 - is
558:15 - resource and then I'm going to specify
558:17 - exactly the resource I don't want it to
558:18 - allow so we're going to say
558:20 - R AWS S3 three
558:24 - colons policy
558:29 - tutorial
558:33 - 34141 uh and just say data.jpg
558:37 - now if this is not valid it's going to
558:39 - complain and say hey you didn't write
558:40 - this right and it and it's fine okay
558:44 - so we'll save those
558:47 - changes and so that should deny access
558:50 - to that
558:51 - right hopefully I got the policy
558:56 - right okay so that one doesn't work
558:59 - which is
559:00 - fine and that one's fine so that worked
559:03 - we were able to deny that but you can
559:05 - see there's a little bit of an art to
559:06 - creating these policies uh as you make
559:08 - more of them it becomes comes a lot
559:10 - easier so hopefully it's not too scary
559:12 - but uh that's all there really is uh to
559:14 - it that I want to show you today so what
559:16 - we're going to do is clear out this
559:18 - bucket we're done with this bucket here
559:19 - so we'll say delete whoops we got to
559:21 - empty it
559:24 - first and we'll just say permanently
559:26 - delete
559:27 - here okay and we will exit that out
559:31 - we're going to go ahead and delete that
559:35 - bucket grab its name
559:38 - here
559:40 - and uh we'll go back over
559:42 - here I think I forgot to delete this
559:44 - Bucket from earlier I'm just going to
559:46 - delete that because I don't need that
559:47 - bucket so that's okay with you just
559:49 - going to go ahead and delete
559:52 - that and we have that ec2 instance
559:54 - running so we want to stop
559:59 - that go ahead and we're going to
560:01 - terminate that yes
560:04 - please and then we'll go to IM and do
560:06 - some clean
560:08 - up
560:10 - I have some custom roles I've been
560:11 - creating um you know from prior things a
560:14 - lot of those usually there's a way to uh
560:17 - We've redesigned it okay where's the
560:19 - redesign this is the redesign that can't
560:21 - be it because there'll be like rolls
560:23 - that ads makes I think these are all
560:24 - rolls that I've
560:27 - made um I don't want to delete service
560:32 - roles but I want to get rid of some of
560:34 - these CU I just have too many you know
560:36 - it's getting out of hand for me and I'm
560:39 - going to just see if it will let
560:42 - me
560:46 - delete all of these let's delete
560:56 - those there we go just clean up a bit I
560:58 - still have a lot here but there's like
561:00 - service roles that adus crates once and
561:02 - you really don't want to delete those
561:05 - because you
561:07 - don't um and then I have a bunch of
561:09 - these like like I'm never going to use
561:10 - these so I might as well detach them
561:12 - delete
561:16 - detach you really don't want to keep
561:18 - like rolls that you're never going to
561:19 - use
561:21 - around things like that like gauze we
561:23 - going to be using that
561:25 - again
561:33 - delete there's that bucket we just
561:38 - created
561:41 - but anyway you get the idea so uh yeah
561:43 - that's uh that's I am
561:45 - [Music]
561:48 - okay principal of lease privilege PP is
561:52 - the computer security concept of
561:53 - providing a user roll or application the
561:55 - least amount of permissions to perform
561:57 - an operation or an action and the way we
562:00 - can look at it is that we have just
562:01 - enough axis so Jaa permitting only the
562:04 - exact actions for the identity perform a
562:07 - task and then we have just in time jit
562:09 - permitting the smallest length of
562:11 - duration an identity can use permission
562:13 - so usually when we're talking about PLP
562:15 - it's usually a focus on here uh but now
562:18 - these days uh there's a larger focus on
562:20 - jit as well and so jit is the difference
562:23 - between having long lived um uh
562:25 - permissions or access Keys versus
562:27 - short-lived ones and the most
562:29 - Progressive thing in PP is now
562:31 - risk-based adaptive policies so each
562:33 - attempt to access a resource generates a
562:35 - risk score of How likely the request is
562:37 - to be from a compromised source so the
562:39 - risk score could be based on many
562:41 - factors such as device user location IP
562:43 - address what service is being accessed
562:45 - and when did they use MFA did they use
562:47 - Biometrics things like that and right
562:49 - now as of this time it just does not
562:52 - have a risk-based adaptive policies
562:54 - built into I am you can roll your own um
562:57 - what's interesting is Cognito has
563:00 - risk-based adaptive policies they call
563:01 - like um adaptive authentication but
563:03 - that's for user pools and not identity
563:05 - pools user pools is for getting access
563:08 - to an app uh that you have built through
563:10 - an ipd where identity pools in cognito
563:14 - is about getting access to adus
563:16 - resources so uh you know I'm sure abos
563:19 - will get it eventually but they just
563:20 - don't have it right now and you have to
563:21 - rely on thirdparty um identity Solutions
563:24 - uh to get risk-based adaptive policies
563:27 - now talking about just enough access and
563:29 - just in time just in time is like you
563:31 - think how would you do that with ads you
563:32 - just add and remove permissions manually
563:34 - well one thing you could do is use
563:35 - something like console me so this is an
563:37 - open source Netflix project to selfer
563:39 - short-lived I am policies so an end user
563:42 - can access it of his resources while
563:43 - enforcing Jaa and jit and so there's a
563:46 - repo there as well um but the idea is
563:48 - they have like this self- serve wizard
563:50 - so you say I want these things and then
563:52 - the machine decides okay you can have
563:53 - them or you you don't need them and it
563:56 - just freezes you up asking people and
563:58 - worrying about the length and stuff like
564:00 - that
564:01 - [Music]
564:04 - okay hey this is Andrew Brown from exam
564:06 - Pro and we are taking a look at the IUS
564:08 - route user uh and this gets confusing
564:11 - because there's an account root user and
564:13 - regular user so let's distinguish what
564:15 - those three things are so here we have
564:17 - an AB account and the account which
564:19 - holds all the adus resources including
564:21 - the different types of users then you
564:23 - have the root user this is a special
564:25 - account with full access that cannot be
564:26 - deleted and then you have just a user
564:29 - and this is a user for common tasks that
564:32 - is assigned permissions so just
564:34 - understand that sometimes people say it
564:35 - was account they're actually referring
564:36 - to the user and sometimes when they're
564:38 - saying it was account they're actually
564:39 - referring to the ads account that holds
564:41 - the users I know it's confusing it just
564:43 - it's based on what people decide the
564:45 - context is when they're speaking so the
564:47 - ads account user is a special user who's
564:49 - created at the time of the ads account
564:51 - creation and they can do uh they have a
564:54 - lot of conditions around them so the re
564:56 - user account uses an email and password
564:58 - to log in as opposed to the regular user
565:01 - who's going to provide their account ID
565:02 - Alias username and password the root
565:05 - user account cannot be deleted the root
565:07 - user account has full permissions to the
565:09 - the account and its permissions and
565:10 - cannot be limited and when we say it
565:12 - cannot be limited we're saying that if
565:13 - you take an IM policy to explicitly deny
565:15 - the user access to resources it's not
565:17 - something you can do however you can do
565:20 - it in the case of adus organizations
565:22 - with service control policies because a
565:24 - service control policy applies to a
565:26 - bunch of accounts so it just it's one
565:28 - level above and so that is a way of
565:30 - limiting root users but generally you
565:31 - can't limit them within their own
565:33 - account uh there can only be one root
565:35 - user uh per ad of us account the root
565:37 - user is instead for very spec specific
565:40 - and specialized tasks that are
565:42 - infrequently or rarely performed and
565:43 - there's a big list and we'll get into
565:45 - that here in a moment and the root uh
565:47 - account should uh not be used for daily
565:49 - or common tasks it's strongly
565:51 - recommended to never use the root users
565:53 - access keys because you can generate
565:55 - those and use them it's strongly
565:57 - recommended to turn on MFA for the root
565:59 - user and adus will bug you to no ends to
566:01 - tell you to turn it on so let's talk
566:04 - about the uh tasks that you should be
566:06 - performing with a root user and only the
566:08 - root user can perform so changing your
566:10 - account settings this includes account
566:12 - name email address root user password
566:14 - root user access Keys other account
566:16 - settings such as contact information
566:18 - payment currency preference regions do
566:20 - not require the root user credentials so
566:22 - not everything um restore IM user
566:25 - permissions so if there's an i IM admin
566:29 - so just a user that has admin access who
566:31 - actually revokes their own permissions
566:32 - you can sign into the root user to edit
566:34 - policies and restore those permissions
566:36 - um so you can also activate IM access to
566:39 - the billing and cost Management console
566:41 - you can view certain tax invoices you
566:44 - can close your ad's account you can
566:46 - change or cancel your adus support plan
566:48 - register as a seller in the reserved
566:50 - instance Marketplace enable MFA uh
566:52 - Delete on S3 buckets edit or delete an
566:56 - Amazon S3 bucket policy that includes an
566:58 - invalid VPC ID or VPC endpoint ID sign
567:02 - up for govcloud and something that's not
567:04 - in here which this I took this from the
567:06 - documentation but uh you can use the
567:08 - adus uh account user to create the
567:10 - organization you can't create that with
567:12 - any other user so um you know the ones I
567:14 - highlighted in red are very likely to
567:16 - show up your exam and that's uh why I
567:18 - highlighted them there for you but there
567:20 - you
567:20 - [Music]
567:24 - go hey this is Andrew Brown from exam
567:26 - Pro and we are taking a look at adus
567:28 - single sign on also known as adus SSO
567:31 - and so this is where you create or
567:33 - connect your Workforce identities in ads
567:35 - once and manage access centrally across
567:37 - your ads organization
567:39 - so the idea here is you're going to
567:40 - choose your identity Source whether it's
567:42 - it SSO itself active directory SLE 2.0
567:45 - IDP you're going to man manage user
567:48 - permission centrally to ads accounts
567:50 - applications samle applications and it
567:53 - uses uh it can you get single click
567:55 - access to all these things so you know
567:56 - just to kind of zoom in on this graphic
567:58 - here uh you know you have your on
568:01 - premise active directory it's
568:04 - establishing a ad trust connection over
568:06 - to Able single sign on you're going to
568:09 - be able to apply permissions to access
568:11 - resources within your adus account so
568:13 - via adus organizations in your
568:15 - organizational units down to your
568:17 - resources you can also use ads SSO to
568:20 - access custom samle based applications
568:23 - so you know if I built a web app and I
568:25 - uh like the exam Pro platform and I
568:27 - wanted to use sample based uh
568:30 - connections for single sign on there I
568:32 - could do that as well and you can
568:34 - connect out SSO access to your business
568:36 - Cloud application so Office 365 Dropbox
568:39 - slack things like that so there you
568:44 - go well let's take a look here at
568:46 - application integration so this is the
568:49 - process of letting to Independent
568:51 - applications to communicate and work
568:52 - with each other commonly facilitated by
568:55 - an intermediate system so Cloud
568:58 - workloads uh strongly encourage systems
568:59 - and services to be Loosely coupled and
569:01 - so inabus has many services for the
569:04 - specific purpose of application
569:05 - integration and these are based around
569:08 - common system systems or design patterns
569:10 - that utilize application integration and
569:12 - this would be things like queuing
569:14 - streaming pubsub API gateways State
569:18 - machines event buses and I'm sure there
569:20 - are more but that's what I could uh
569:22 - think about that are the most common
569:24 - ones
569:25 - [Music]
569:28 - okay so to understand queuing we need to
569:31 - know what is a messaging system so this
569:34 - is used to provide asynchronous
569:35 - communication and decouple processes via
569:37 - messages and events from a sender
569:39 - receiver or a producer and a consumer so
569:42 - a queing system is a messaging system
569:45 - that generally will delete messages once
569:46 - they are consumed it's for simple
569:48 - communication it's not real time you
569:50 - have to pull the data it's not reactive
569:53 - and uh a good analogy would be imagining
569:55 - people that are queuing in a line to go
569:57 - do something so for ads it's called
570:01 - Simple queuing service sqs it's a fully
570:03 - managed queing service that enables you
570:05 - to decouple and scale microservices
570:07 - distributed systems and serverless
570:09 - applications so a very common use case
570:11 - in a web application would be to queue
570:13 - up transactional emails to be sent like
570:16 - sign up reset password and the reason
570:18 - why we have queing to decouple uh those
570:20 - kind of actions is that if you had a
570:22 - long running task um and you had too
570:25 - many of them it could hang your
570:26 - application so by decoupling them and
570:29 - letting a separate compute uh service
570:31 - take care of that um that would be
570:33 - something that would be very useful
570:37 - okay
570:39 - let's take a look here at streaming and
570:41 - so this is a different kind of messaging
570:44 - system um but the idea here is you have
570:46 - multiple cons consumers that can react
570:48 - to events and so in streaming we call
570:51 - messages events and then in a queing
570:52 - system we just call them messages but
570:54 - events live in the Stream for long
570:56 - periods of time so complex operations
570:58 - can be applied and generally streaming
571:00 - is used for realtime stuff whereas
571:02 - queing is not necessarily real time and
571:06 - so ad's solution here is Amazon kinesis
571:09 - you could also use Kafka but we'll focus
571:10 - on Kinesis here so Amazon Kinesis is the
571:13 - aist fully managed solution for
571:14 - collecting processing and analyzing
571:16 - streaming data in the cloud so the idea
571:18 - is that you have these producers so that
571:21 - are producing events could be ec2
571:22 - instances mobile
571:24 - devices could be a computer or
571:26 - traditional server they're going to go
571:28 - into the data stream there's a bunch of
571:30 - shards that scale and there's consumers
571:32 - on the other side so maybe red shift
571:33 - wants that data Dynamo DB S3 or EMR okay
571:37 - but the thing you have to remember is
571:38 - that streaming Is For Real Time data and
571:41 - as you can imagine because it's real
571:43 - time and it's doing a lot more work than
571:45 - um a queuing system it's going to cost
571:48 - more
571:49 - [Music]
571:52 - okay so we have another type of
571:54 - messaging system known as Pub sub so
571:58 - this stands for publish subscribe
572:00 - pattern commonly implemented in
572:01 - messaging systems and a pub sub system
572:03 - the sender of messages the Publishers do
572:05 - not send their message directly to
572:07 - receivers they instead send their
572:09 - messages to an event bus the event bus
572:12 - categorizes their messages into groups
572:14 - then receivers of messages subscribers
572:16 - subscribe to these groups whenever new
572:18 - messages appear within their
572:20 - subscriptions the messages are
572:22 - immediately delivered to them so the
572:24 - idea is you have Publishers event bus
572:25 - subscribers and event buses appear more
572:28 - than once so it actually appears in
572:29 - streaming appears in this Pub sub model
572:32 - and then it can appear in other
572:34 - variations so you're going to hear it
572:35 - more than once the word event bus um so
572:37 - the idea here is the publisher has no
572:39 - knowledge of who the subscribers are
572:41 - subscribers do not pull for messages
572:42 - messages are instead automatically
572:44 - immediately pushed to the subscribers
572:46 - and messages and events are
572:47 - interchangeable terms in Pub sub all
572:50 - right and so you know the idea here with
572:53 - Publisher subscribers just imagine
572:54 - getting like a um a magazine
572:57 - subscription right if you think of that
572:58 - you kind of think of the mechanisms that
573:00 - are going here in terms of practicality
573:02 - it's very common to use these as a
573:04 - real-time chat system or a web hook
573:07 - system so you know hopefully that gives
573:09 - you an idea there in terms of aws's
573:10 - solution we're using simple notification
573:12 - service SNS this is a highly available
573:15 - durable secure fully managed Pub sub
573:17 - messaging service that enables you to
573:20 - decouple microservices distributed
573:22 - systems and serverless applications so
573:25 - here we have a variety of Publishers
573:27 - like the SDK the CLI cloudwatch Aid with
573:30 - Services you'll have your SNS topic you
573:33 - can uh filter things fan them out and
573:35 - then you have your subscribers so Lambda
573:36 - sqs emails PS looks very similar to
573:40 - streaming but again you know um you know
573:42 - there's not a lot of communication going
573:44 - back between it it's just Publishers and
573:46 - subscribers and it's limited to you know
573:50 - these things here so it's a very managed
573:52 - service right whereas uh Kinesis you can
573:55 - do a lot more with it
573:57 - [Music]
574:01 - okay so what is API Gateway well it is a
574:05 - program that sits between a single entry
574:07 - point and a and multiple backends API
574:09 - Gateway allows for throttling logging
574:11 - routing logic or formatting of the
574:13 - requests and response when we say
574:15 - request and response we're talking about
574:17 - https uh requests and responses and so
574:21 - the service for ads is called Amazon API
574:23 - Gateway so API Gateway is just a type of
574:25 - pattern and this is the few cases where
574:28 - ADS has named the thing after what it is
574:32 - and so we have Amazon API Gateway which
574:34 - is a solution for creating secure apis
574:36 - in your Cloud environment at any scale
574:39 - create apis that act as a front door for
574:41 - applications to access data B is logic
574:43 - or functionality from backend services
574:46 - so the idea is that you have data coming
574:47 - in from uh mobile apps web apps iot
574:50 - devices and you actually Define the API
574:53 - calls and then you say where do you want
574:55 - them to go so maybe tasks are going to
574:56 - go to your lambdas um and then other
574:59 - routes are going to go to RDS Kinesis
575:01 - ec2 uh or your web application and so
575:05 - these are really great for having um
575:07 - this uh being able to Define your API
575:10 - routes and change them on the Fly and
575:12 - then and always route them to the same
575:14 - place
575:15 - [Music]
575:19 - okay so what is a state machine it is an
575:22 - abstract model which decides how one
575:24 - state moves to another based on a series
575:25 - of conditions think of a state machine
575:28 - like a flowchart and for AWS the
575:30 - solution here is AWS step function so
575:32 - coordinate multiple a Services into a
575:34 - servess workflow a graphical console to
575:37 - visualize the component of your
575:38 - application as a series of steps
575:40 - automatically trigger and track each
575:42 - step and retries when there are errors
575:45 - so your application executes in order as
575:47 - expected every time logs the state of
575:50 - each step so when things go wrong you
575:52 - can diagnose and debug problems quickly
575:55 - and so here's an example of using a
575:57 - bunch of um uh steps together on the uh
576:02 - the aabus step functions service and so
576:05 - you know this is generally applied for
576:06 - servess workflows but it is something
576:08 - something that is very useful in
576:09 - application integration
576:11 - [Music]
576:15 - okay so what is an event bus an event
576:18 - bus receives events from a source and
576:19 - routes events to a Target based on rules
576:22 - so I'll get my pen tool out here so we
576:24 - have an event it enters the event bus we
576:25 - have a rules tell it to go to the Target
576:27 - it's that simple and we have been seeing
576:30 - event buses in other things like uh
576:33 - streaming and uh Pub sub but Abus has
576:37 - this kind of event offering uh that is
576:39 - kind of high level it's called event
576:41 - bridge and it's a service event bus
576:43 - service that is used for application
576:44 - integration by streaming real-time data
576:46 - to your applications the service was
576:48 - formerly known as event Amazon
576:50 - cloudwatch events they gave it a
576:51 - renaming to give it uh a better um
576:54 - opportunity for users to know that it's
576:56 - there to use uh and they also extended
576:59 - its
577:00 - capabilities and so the thing is that a
577:02 - lot of AD services are always admitting
577:04 - events and they're already going into
577:05 - this bus and so if you utilize this
577:07 - service um it's it's a lot easier than
577:08 - having to roll your own thing uh with
577:11 - other services so Amazon event bridge
577:13 - will just Define an event bus so there
577:15 - is an event bus holds event data defines
577:17 - the rules on event bus to react to
577:19 - events you always get a default event
577:21 - for every single Aus account you can
577:22 - create custom event buses scope to
577:24 - multiple accounts or other adus accounts
577:26 - you have a SAS event bus scope to
577:28 - thirdparty SAS providers you have
577:30 - producers these are adus services that
577:31 - emit events you have events these are
577:33 - data emitted by Services they're jent
577:35 - objects that uh travel the stream Within
577:38 - the event bus you have partnered sources
577:39 - these are thirdparty apps that can emit
577:42 - events to event buses you have rules
577:44 - these determine what events to capture
577:45 - and pass to targets and then targets
577:47 - which are Ada services that consume
577:49 - events so yeah it's all just this great
577:52 - built-in um uh uh stuff that's going on
577:55 - here and so you know there there might
577:57 - be a case where you can use event bridge
577:59 - and save your time uh a lot of time and
578:01 - effort uh doing application integration
578:06 - okay
578:08 - hey this is Andrew Brown from exam Pro
578:10 - and we are taking a look at application
578:12 - integration services at a glance here so
578:14 - let's get through them so the first is
578:15 - simple notification service SNS this is
578:18 - a pub sub messaging system sends
578:20 - notifications via various formats such
578:22 - as plain text email https web hooks SMS
578:26 - text messages sqs and Lambda pushes
578:29 - messages which are then sent to
578:31 - subscribers you have sqs this is a
578:33 - queuing messaging system or service that
578:37 - sends a events to a queue other
578:39 - applications pull the queue for messages
578:40 - commonly used for background jobs we
578:42 - have step functions this is a state
578:44 - machine service it is it coordinates
578:46 - multiple a Services into a servess
578:48 - workflow easily share data among lambdas
578:51 - have a group of lambdas wait for each
578:53 - other create logical steps also works
578:55 - with fargate tasks we have event Bridge
578:57 - formerly known as cloudwatch events it
578:59 - is a service event bus that makes it
579:01 - easy to connect applications together
579:03 - from your own application third party
579:04 - services and adus services then there's
579:06 - Kinesis a real realtime streaming data
579:08 - service creates producers which send
579:10 - data to a stream multiple consumers can
579:12 - consume data within a stream used for
579:15 - real-time analytics clickstreams
579:16 - ingesting data from a fleet of iot
579:18 - devices you have Amazon mq this is a
579:21 - manage message broker service that uses
579:23 - aachi active mq so if you want to use
579:26 - aachi active mq there it is manage kofka
579:29 - service and this gets me every time
579:32 - because it says
579:33 - msk and that is the proper
579:35 - initialization but you'd think it'd be
579:36 - MKS
579:38 - it is a fully managed Apachi Kafka
579:40 - service Kafka is an open source platform
579:42 - for building realtime streaming data
579:44 - pipelines and applications similar to
579:45 - conis but more robust very popular by
579:48 - the way we have API Gateway a fully
579:50 - managed service for developers to create
579:52 - publish maintain Monitor and secure apis
579:54 - you can create API endpoints and rote
579:56 - them to ad Services we have appsync this
579:58 - is a fully managed graphql service
580:01 - graphql is an open source agnostic query
580:03 - adapter that allows you to query data
580:05 - from many different data sources so
580:07 - there you
580:08 - [Music]
580:12 - go hey this is Andrew Brown from exam
580:15 - Pro and we are comparing virtual
580:16 - machines to Containers so I know we
580:19 - covered this prior but I just want to do
580:20 - it one more time just to make sure that
580:22 - we fundamentally understand the
580:23 - difference before we jump into
580:25 - containers so the idea is that if you
580:27 - were to request an ec2 instance it has a
580:29 - host operating system that we don't
580:31 - really know much about but we don't
580:33 - really need to know uh and then the idea
580:35 - is you have a hypervisor which allows
580:37 - you to deploy virtual
580:38 - machines and so when you launch an ec2
580:41 - instance you're actually launching a VM
580:43 - on top of a hypervisor on a server uh
580:45 - with on uh within the adabs uh data
580:47 - centers servers there and you're going
580:49 - to choose an operating system so like
580:51 - Ubuntu and it might come with some
580:52 - pre-installed packages or you're going
580:54 - to install your own libraries packages
580:55 - and binaries and then you're going to
580:57 - decide what kind of workloads you want
580:58 - to run on there so it could be D Jango
581:00 - uh mongodb so your database and some
581:03 - kind of queing system like rabit mq the
581:06 - difficulties with virtual machines
581:07 - you're always going to end up with some
581:09 - unused space because you're going to
581:10 - want to have some Headroom uh to make
581:13 - sure that uh you know if you know Dango
581:15 - needs more memory or or mongod DB needs
581:18 - more storage that you have that room
581:19 - that you can grow into but the idea is
581:22 - that you're always paying for that even
581:24 - when you're not utilizing it and so you
581:26 - know that can be uh not as cost
581:29 - effective as you'd like it to be so when
581:31 - we're looking at um doing this again and
581:33 - we are using containers um instead of
581:37 - the provisor we have container
581:38 - virtualization a very common one would
581:40 - be called Docker Damon for Docker of
581:42 - course and so now you're launching
581:44 - containers and so maybe you have Alpine
581:46 - and this is for your web app and then
581:48 - you install exactly the libraries
581:49 - packages and binaries you need for that
581:51 - and then for uh mongodb you want to have
581:53 - a different OS different packages and
581:56 - same thing with Rabbid mq maybe you want
581:58 - to run it on FreeBSD and the idea is
582:00 - that uh you know you're not going to
582:02 - have this waste because it it's kind of
582:05 - changed the sense that these containers
582:07 - are Flex ible so they can expand or
582:09 - decrease based on the the use case of
582:11 - what they need uh and you know if you
582:13 - use particular services like ad fargate
582:16 - you know you're paying like for running
582:18 - the containers not necessarily uh for uh
582:21 - over provisioning okay so VMS do not
582:23 - make best use of space apps are not
582:25 - isolated which could cause uh config
582:27 - conflict security problems or resource
582:30 - hogging containers allow you to run
582:32 - multiple apps which are virtually
582:33 - isolated from each other launch new
582:35 - containers configure OS uh dependencies
582:37 - per container
582:38 - [Music]
582:42 - okay hey this is Andrew Brown from exam
582:44 - Pro and we are taking a look at the
582:46 - concept of microservices and to
582:48 - understand microservices we first need
582:50 - to understand monoliths or monolithic
582:52 - architecture and the idea here is that
582:54 - we have one app which is responsible for
582:56 - everything and the functionality is
582:57 - tightly coupled so I'm going to get my
582:59 - pen tool out here and just to highlight
583:01 - notice that there is a server and
583:03 - everything is running on a single server
583:05 - whether it's load balancing caching the
583:07 - database um maybe the marketing website
583:10 - the front-end JavaScript framework the
583:12 - back end with its API uh the uh
583:15 - orm connected to background tasks things
583:18 - like that and that's the idea of a
583:19 - monolith and that's what um a lot of
583:21 - people are used to doing but the idea
583:23 - with microservice architecture is that
583:25 - you have multiple apps which are
583:26 - responsible for one uh one thing and the
583:28 - functionality is isolate and stateless
583:31 - and so just by uh leveraging um various
583:34 - cloud services or bolting it onto your
583:36 - service um you know you are technically
583:38 - using microservice architecture so maybe
583:41 - your web app is all hosted in containers
583:44 - so you have your apis your or your orm
583:46 - your reports maybe you've abstracted out
583:49 - some particular functions into Lambda
583:51 - functions you have your um marketing
583:54 - website hosted on S3 you have your
583:56 - frontend JavaScript hosted on S3 You're
583:58 - Now using elastic load balancer uh
584:01 - elasticache
584:03 - RDS sqs and that's the idea between
584:06 - monoliths and microservices
584:09 - [Music]
584:12 - okay let's take a look here at
584:14 - kubernetes which is an open-source
584:16 - container orchestration system for
584:18 - automating deployment scaling and
584:20 - management of containers it was
584:21 - originally created by Google and now
584:23 - maintained by the cloud native Computing
584:25 - foundation so the
584:26 - cncf kubernetes is commonly called K8
584:30 - the 8 represents the remaining letters
584:31 - for kuti which is odd because everyone
584:34 - calls it kues with the S on there but
584:36 - that's just what is the advantage of
584:38 - kubernetes over Docker is the ability to
584:40 - run containers distributed across
584:42 - multiple VMS a unique component of
584:44 - kubernetes are pods a pod is a group of
584:47 - one or more containers with with shared
584:49 - storage network resources and other
584:51 - shared settings so here is kind of an
584:53 - example where you have your kubernetes
584:55 - master it has a schedule controller etcd
584:58 - you might be using it uses an API server
585:00 - to run nodes within the nodes we have
585:03 - pods and within the pods we have
585:05 - containers kubernetes is ideally for
585:07 - microservice architectures where company
585:09 - has tens to hundreds of services they
585:13 - need to manage I need to really
585:14 - emphasize that tens to hundreds of
585:17 - services all right so you know crion is
585:19 - great but just understand that it is
585:21 - really designed uh to be used for
585:23 - massive amounts of microservices if you
585:25 - don't have that need you might want to
585:28 - look at something just easier to use
585:30 - [Music]
585:34 - okay all right let's take a look here at
585:36 - docker which is a set of platforms of
585:38 - service products that use OS level
585:40 - virtualization to deliver software in
585:42 - packages called containers so Docker was
585:45 - the earliest popularized open source
585:48 - container platform meaning there's lots
585:49 - of tutorials there's a lot of services
585:52 - that uh integrate with Docker or make it
585:54 - really easy to use and so when people
585:55 - think of containers they generally think
585:57 - of Docker there's of course a lot more
585:59 - options out there than Docker to run
586:01 - containers but this is what people think
586:03 - of and so we said it's a suite of tools
586:05 - so the idea is you have this Docker CLI
586:07 - so these are C commands to download
586:09 - upload build run and debug containers a
586:11 - Docker file a configuration file on how
586:13 - to provision a container Docker compose
586:16 - uh which is a tool and configuration
586:18 - file when working with multiple
586:19 - containers Docker swarm an orchestration
586:22 - tool for managing deployed
586:23 - multicontainer architectures Docker Hub
586:26 - a public online repository for
586:28 - containers published by the community
586:29 - for download and one really interesting
586:31 - thing uh that came out of Docker was the
586:33 - open container initiative oci which is
586:36 - an open governance for creating open
586:38 - industry standards around container
586:40 - formats and runtimes so Docker
586:42 - established the O oci and it is now
586:44 - maintained by the Linux foundation and
586:47 - so the idea is that you can write a
586:49 - Docker file or or do things very
586:51 - similarly and use different types of um
586:54 - uh technologies that can use containers
586:56 - as long as they're oci compatible you
586:58 - can use them so Docker has been losing
587:00 - favor with developers due to their
587:02 - handling of introducing a paid open
587:03 - source model and Alternatives like
587:05 - podman are growing and that's why we're
587:07 - going to talk about podman next
587:09 - [Music]
587:12 - okay so let's take a quick look here at
587:15 - podman which is a container engine that
587:17 - is oci compliant and is a drop in
587:19 - replacement for Docker I just want to
587:21 - get you exposure here because I want you
587:22 - to know about this um and that you can
587:25 - uh use it as opposed to using Docker um
587:27 - there are a few differences or
587:29 - advantages that podman has so podman is
587:31 - Damon list where Docker uses a container
587:33 - D Damon pman allows you to create pods
587:35 - like crew brunetes where Docker does not
587:37 - have pods podman only replaces one part
587:39 - of Docker podman is is to be used
587:42 - alongside builda and uh scopio so you
587:45 - know Docker is an all-in-one kind of
587:47 - tool uh everything is done via single
587:49 - CLI and everything is there but you know
587:51 - they just wanted to make it more module
587:53 - and so uh these other tools anytime you
587:55 - say podman it usually means we're
587:56 - talking about podman builda and scopio
587:59 - so builda is a tool used to build the
588:01 - oci images and scopio is a tool for
588:03 - moving container images between
588:05 - different types of container storages p
588:07 - is not going to show up in your exam but
588:08 - you should practically know it um just
588:11 - for your own benefit
588:12 - [Music]
588:16 - okay let's take a look here at the
588:18 - container services offered on AWS so we
588:21 - have primary services that actually run
588:23 - containers provisioning and deployment
588:24 - on you know tooling around provisioning
588:26 - deployment and supporting services so
588:29 - the first here is elastic container
588:30 - service ECS um and the advantage of this
588:33 - service is that it has no cold starts
588:36 - but it is a manage dc2 so that means
588:38 - that you're going to be always paying
588:40 - for the resource as it is running all
588:42 - right then you have ads fargate so this
588:44 - is more robust than uh using adus Lambda
588:47 - it can scale to zero cost um and it's uh
588:51 - being managed by adus managed ec2
588:53 - however it does have cold starts so you
588:55 - know if you need containers launching
588:56 - really fast you might be wanting to use
588:58 - ECS then you have elastic kubernetes
589:01 - service eks this is uh open source it
589:04 - runs kubernetes um and this is really
589:06 - useful if you want to avoid vendor
589:09 - lockin um which is not really a problem
589:12 - but uh that or it's just you want to run
589:14 - kubernetes then you have itus Lambda so
589:16 - you only think about the code uh it's
589:18 - designed for short running tasks uh if
589:20 - you need something that runs longer you
589:22 - want to use that is serverless you'd use
589:24 - adus fargate which is serverless
589:26 - containers you can deploy custom
589:28 - containers so prior adus Lambda just had
589:31 - um pre-built run times which were
589:32 - containers but now you can create any
589:34 - kind of container and uh use that uh on
589:36 - a was Lambda for provisioning deployment
589:39 - you can use elastic Bean sock so um it
589:42 - can uh deploy elastic container service
589:45 - for you um which is very useful there
589:48 - now there's app Runner which kind of
589:50 - overlaps on what elastic beanock does
589:51 - but it specializes it specializes for
589:54 - containers um and I believe that it can
589:57 - actually I don't know what it uses
589:58 - underneath because it is a managed
589:59 - service so elastic beanock is um open
590:02 - you can see what is running underneath
590:04 - an app Runner I don't believe you can
590:05 - see what is running underneath it's just
590:07 - taken care of by AWS then there's AWS
590:10 - co-pilot CLI so this allows you to build
590:13 - release operate production ready
590:14 - containerize applications on app Runner
590:16 - ECS and Abus fargate for supporting
590:19 - services you have elastic container
590:20 - registry this is reple for your
590:22 - containers not necessarily just Docker
590:23 - containers but containers in general
590:25 - probably oci compliant containers x-ray
590:27 - so analyze and debug between uh
590:29 - microservices so you know it's
590:31 - distributed tracing then you have step
590:33 - functions so stitch together lambdas and
590:35 - ECS tasks to to uh create um um a state
590:40 - machine and the only thing I don't have
590:41 - on here would be you know being able to
590:43 - launch an ec2 instance from the
590:45 - marketplace that has um a uh a container
590:49 - runtime installed like Docker um I just
590:51 - don't feel that that's very relevant for
590:53 - the exam but it is another option for
590:55 - containers not something that people do
590:56 - very often but there you
590:58 - [Music]
591:01 - go hey this is Angie Brown from exam Pro
591:04 - and we are taking a look here at
591:05 - organizations and accounts so adus
591:07 - organizations allow the creation of new
591:09 - adus accounts and allows you to
591:11 - centrally manage billing control access
591:13 - compliance security and share resources
591:15 - across your adus accounts so here's kind
591:18 - of a bit of a structure of um the
591:21 - architecture of adus organizations and
591:23 - we'll just kind of walk through the
591:24 - components so the first thing you have
591:26 - is a root account user this is a single
591:29 - signin identity that has complete access
591:31 - to all ad services and resources in an
591:33 - account and each account has a root
591:35 - account user so generally you will have
591:37 - a master or root account and even within
591:40 - that you'll have a root account user and
591:42 - for every additional account that you
591:44 - have you'll notice over here we have a
591:46 - root account
591:47 - user then there's the concept of
591:49 - organizational units uh these are
591:51 - commonly abbreviated to ous so they are
591:54 - a group of adus accounts within an
591:55 - organization which can contain other
591:57 - organizational units creating a
591:59 - hierarchy so here is one where we have
592:02 - called Starfleet and here's one called
592:04 - Federation planets and underneath we
592:05 - have multiple
592:07 - accounts it accounts within that
592:09 - organizational unit and even though it
592:11 - does not show it here you can create an
592:13 - organizational unit within an
592:14 - organizational unit then we have service
592:17 - control policies scps and these give uh
592:19 - central control over the allowed
592:21 - permissions for all A's accounts in your
592:23 - organization helping to ensure your
592:25 - accounts stay within your organization's
592:27 - guidelines what they're trying to say
592:29 - here is that um there's this concept of
592:31 - adus I am policies and all you're doing
592:35 - is you're creating a policy that's going
592:37 - to be uh organizational uniwide or
592:40 - organizational wide or for select
592:42 - accounts so it's just a way of applying
592:44 - I am policies across multiple accounts
592:46 - adus organizations must be turned on and
592:48 - once it's turned on it cannot be turned
592:50 - off it's generally recommended that you
592:52 - do turn it on um because basically when
592:55 - if you're going to run any kind of
592:56 - serious workload you're going to be
592:57 - using adus organizations to uh isolate
593:00 - your adus accounts based on workloads
593:02 - you can create as many adus accounts as
593:03 - you like One account will be the master
593:06 - or root account um and I say root
593:08 - account here because this is the new
593:09 - language here and some of the
593:11 - documentation still calls it master
593:12 - account so do understand this is the
593:14 - root account not to be confused with the
593:17 - root account user so another
593:20 - clarification I want to make is an ads
593:22 - account is not the same as a user
593:24 - account which is another thing that is
593:26 - confusing so when you sign up for AWS
593:29 - you get um an adus account and then it
593:31 - creates you a user account which happens
593:33 - to be a root user account so hopefully
593:35 - that is clear
593:36 - [Music]
593:41 - so adus control tower helps Enterprises
593:43 - quickly set up a secure adus multic
593:45 - count it provides you with a baseline
593:47 - environment to get started with a
593:48 - multi-count architecture so it does this
593:51 - a few uh a few different ways the first
593:53 - thing is it provides you a landing Zone
593:55 - this is a baseline environment following
593:56 - well architected and best practices to
593:59 - start launching production ready
594:01 - workload so imagine you wanted to go
594:03 - have um you know the perfect environment
594:05 - that you know sec cure um is correctly
594:08 - configured and has good logging in place
594:11 - that's what a landing zone is and so 's
594:13 - Landing zone for control tower is going
594:15 - to have SSO enabled by default so it's
594:17 - very easy to move between it accounts it
594:19 - will have centralized logging for adus
594:21 - cloud trail so that you know they're
594:23 - going to be tamper evident or tamper
594:24 - proof away from your workloads where
594:26 - they can't be affected it'll have cross
594:28 - account security auditing um so yeah
594:31 - Landing zones are really great to have
594:32 - then there's the account Factory they
594:34 - used to call this um uh a vending
594:37 - machine but uh they changed it to
594:38 - account Factory the idea is that it
594:40 - automates provisioning of new accounts
594:41 - in your organization it standardizes the
594:44 - provisioning of new accounts with
594:45 - pre-approved account configuration you
594:48 - can configure account Factory with
594:49 - pre-approved network configuration and
594:51 - region selections uh enable sell service
594:53 - for your Builders to configure and
594:55 - provision to accounts using a service
594:57 - catalog a service catalog is just
594:59 - preapproved uh workloads uh via Cloud
595:01 - information templates that you created
595:03 - to say okay you're allowed to launch
595:04 - This Server these resources
595:07 - um and the third and most important
595:08 - thing that a control tower comes with is
595:10 - guard rails so these are prepackaged
595:12 - governance rules for security operations
595:14 - compliance the customers can select and
595:16 - apply Enterprise wide or to specific
595:18 - groups of accounts so adus control tower
595:21 - is the replacement of the retired adus
595:24 - Landing zone so if you remember adus
595:26 - Landing zones which was never a self-
595:29 - serve easy thing to sign for it required
595:31 - a lot of money and uh stuff to go in
595:33 - there they just don't really have it
595:35 - anymore and it was control Tower is the
595:37 - new offering um there
595:39 - [Music]
595:42 - okay hey this is Andrew Brown from exam
595:45 - Pro and we are taking a look at 's
595:46 - config and to understand adus config we
595:49 - need to know what compliance as code is
595:51 - and to understand compliances code we
595:53 - need to understand what change
595:54 - management is so change management in
595:56 - the context of cloud infrastructure is
595:59 - when we have a formal process to monitor
596:01 - changes enforce changes and remediate
596:04 - changes and compliance is code also
596:06 - known as CAC is when we utilize
596:09 - programming to automate the monitoring
596:11 - enforcing and remediating changes to
596:13 - stay compliant with the compliance
596:15 - program or expected configuration so
596:18 - what is adus config well it's a
596:20 - compliances code framework that allows
596:22 - us to manage change in your adus
596:25 - accounts on a per region basis meaning
596:28 - that you have to turn this on for every
596:30 - region that you need it for and so here
596:32 - is a very simple example where let's say
596:35 - we create a config rule and we have an
596:37 - ec2 instance and we expect it to be in a
596:39 - particular State and then in the other
596:41 - case we have a an RDS instance and it's
596:44 - in a state that we do not like so the
596:46 - idea is that we try to remediate it to
596:48 - put it in the state that we want it to
596:49 - be and those config rules are just
596:51 - powered by lambdas as you can see based
596:53 - on the Lambda icon there so when should
596:56 - you use itus config well this is when I
596:58 - want this resource to say configured a
597:00 - specific way for compliance I want to
597:03 - keep track of configuration changes to
597:05 - resources I want a list of all resources
597:07 - within a region and I want to use uh
597:11 - analyze potential security weaknesses
597:13 - and you need detailed historical
597:15 - information so there you
597:17 - [Music]
597:20 - go hey this is Andre Brown from exam Pro
597:23 - and in this follow along we're going to
597:24 - take a look at adus config so adus
597:26 - config is a tool that allows you to
597:28 - ensure that your services are configured
597:29 - as expected so I've already activated it
597:32 - in my North Virginia region so what I'm
597:34 - going to do is just go over to Ohio here
597:37 - uh because it is per region activated
597:39 - and I'll go over to config and then what
597:41 - we'll have to do is set it up so there
597:44 - is this oneclick setup and it did Skip
597:46 - me to the review step because it's kind
597:47 - of piggybacking on the configuration of
597:49 - my original one here but the idea is
597:51 - that you'll just say uh record all
597:54 - resources in this region or things like
597:56 - that you'll have to create a service
597:58 - roll link if you have not done so so
598:00 - this will look a little bit different
598:01 - but here it's using existing one you'll
598:03 - have to choose a bucket so or create a
598:06 - bucket uh it's not super complicated so
598:08 - you get through there you hit confirm
598:10 - and basically you're going to end up
598:12 - with this so the inventory um lets you
598:14 - see all the the resources that or not
598:18 - all of them but most resources that are
598:19 - in your adus account in this particular
598:21 - region it this will not populate uh
598:23 - right away so you will have to wait a
598:25 - little bit of time for that to appear
598:28 - one really nice thing our conformance
598:29 - packs I really love these things when
598:32 - any of us first brought these out there
598:33 - was only like a couple but now they have
598:35 - tons and tons and tons of conformance
598:37 - packs so you can go deploy a conformance
598:39 - pack and you can open up the templates I
598:42 - just want to show you look at how many
598:43 - they have so there some you might
598:46 - recognize like
598:47 - nist uh CIS things like that well
598:49 - architected uh stuff and all these are
598:53 - um and I'm not sure if it's easy to open
598:54 - these up but all these are if we open
598:56 - them up they're on GitHub is these are
598:58 - just cloudformation templates to set up
599:00 - configuration rules so there's a variety
599:03 - of suggested rules uh like around IM
599:06 - best practices and things like that that
599:07 - we can load in um but the idea is that
599:10 - you're just going to create rules so you
599:11 - go here and you add a rule and they have
599:12 - a bunch of manag rules here um that we
599:15 - can look at but I think it might be fun
599:17 - to actually run a um a conformance pack
599:20 - I'll just show you what it looks like to
599:21 - add a rule first so let's say we wanted
599:23 - to do something for
599:25 - S3 um and it was making sure that we are
599:28 - blocking Public Access so we go next
599:30 - here generally you'll have a trigger
599:32 - type you can choose whether it's uh
599:34 - configured when it happens or it's
599:36 - periodic this is disabled in this case
599:38 - here and you just scroll on down um and
599:40 - then once you've added the rule what you
599:44 - can
599:45 - do is also manage remediation so if this
599:50 - rule said hey this thing is
599:52 - non-compliant we want you to take a
599:54 - particular action and you have all these
599:56 - databus actions that you can perform and
599:58 - you can notify the right people to
600:00 - correct it or have it auto correct if
600:02 - you choose to do so um for rules you can
600:05 - also make your own custom one so that's
600:07 - just you providing your own Lambda
600:09 - functions you're providing that Lambda
600:10 - Arn and so basically you can have it do
600:13 - anything that you want whatever you want
600:14 - to put in a Lambda you can make adus
600:16 - config check for okay so it's not super
600:19 - complicated here but um this one here is
600:22 - just going to go ahead and check and so
600:24 - if we go and
600:26 - re-evaluate it might just take some time
600:27 - to show up either going to say that it's
600:29 - compliant or non-compliant okay and I it
600:32 - should be compliant but while we're
600:33 - waiting for that to happen let's just
600:35 - see how hard it is to deploy a
600:36 - conformance pack because I feel like
600:37 - that's something that's really important
600:39 - oh you can just drop them down and
600:40 - choose them that's great so we might
600:41 - want to go to I am here oops identity
600:44 - and access
600:46 - management and hit next and say uh my
600:51 - um uh I am best practices and you might
600:55 - not want to do this because it does have
600:57 - spend and when I say spend it's not
600:58 - going to happen instantly but the idea
601:00 - is that if you turn this on and forget
601:01 - to remove it uh you will see some kind
601:04 - of charges over time because it does
601:05 - check check based on the rules it's not
601:07 - super expensive but it is something to
601:09 - consider about um but anyway so it looks
601:11 - like we created that conformance pack so
601:12 - if I refresh it looks like it's in
601:15 - progress I wonder if that's going to set
601:16 - up a cloud formation template I'm kind
601:18 - of curious about that so we'll make our
601:20 - way over to cloud
601:23 - formation and it is so that's really
601:26 - nice because once that is done what we
601:28 - can do is just tear it down by deleting
601:30 - the stack so I'm going to go back over
601:31 - to our conformance pack
601:34 - here let's take a look here
601:36 - and so it still says it's in progress
601:38 - but it is completed and we can click
601:40 - into
601:41 - it and we can see all the things that
601:44 - it's doing so it says item groups have
601:46 - user check informance pack um and so it
601:49 - looks like there's a bunch of uh cool
601:50 - rules uh here so what we'll do is we'll
601:55 - just wait a little while and we'll come
601:56 - back here and then just see if um this
601:59 - updates and see how compliant we are
602:01 - from a uh a basic account okay all right
602:04 - so after waiting a little while there it
602:06 - looks like some of them are being set so
602:07 - I just gave it a hard refresh here uh
602:10 - and here you can see that it's saying is
602:11 - rooe account um whoops we'll give it a
602:13 - moment here to refresh but uh is the
602:15 - root account MFA applied yes have we
602:18 - done a password policy no and actually I
602:20 - never did a password policy which is
602:22 - something I forgot to do but here
602:23 - they're just talking about the minimums
602:25 - and maximums of things that you can
602:27 - do okay so that's a conformance pack um
602:30 - but if we go to rules actually I guess
602:32 - it's all the rules here I can't really
602:34 - tell the difference between the
602:35 - conformance pack rules and our plane
602:37 - rules kind it's kind of all mixed
602:39 - together here I
602:42 - think yeah so it's a bit hard to see
602:44 - what's going on there if we go to the
602:46 - performance pack and click in again it
602:48 - might show the rules yeah there we go so
602:50 - here's the rules there we're seeing a
602:51 - little bit more information so use a
602:53 - hardware MFA so you know how they're
602:55 - talking about using a security key like
602:57 - what I showed you that I had earlier in
602:59 - the course things like that um I am
603:02 - password policy things like that so you
603:04 - know not too complicated but um I think
603:07 - I'm all done here so what I'm going to
603:09 - do is I'm going to go over to cloud
603:10 - formation and tear that on down but you
603:12 - get the
603:13 - idea well I might want to show you uh
603:16 - drift so there used to be a way it's CU
603:19 - I keep changing things on me here but
603:21 - there's a way to see uh history over
603:24 - time and so that was
603:27 - something that they used to show and I'm
603:30 - just trying to like find where they put
603:32 - it because it is like somewhere else
603:36 - resources
603:39 - maybe ah resource timeline okay so they
603:41 - moved it over into the resource
603:43 - inventory and so if we were to take a
603:45 - look at something anything maybe this
603:47 - here resource timeline um and there
603:50 - might not be much here but the idea is
603:52 - it will show you over time how things
603:53 - have changed so the idea is that not
603:55 - only can you say with a was config is
603:57 - something compliant but when was it
603:59 - compliant and that is something that is
604:00 - really important to know okay so very
604:02 - simple example maybe not the best but
604:04 - the idea is that we can see when it was
604:06 - and was not compliant based on uh
604:08 - changes to our stuff but uh anyway that
604:11 - looks all good to me here so I'm going
604:13 - to make my way over to cloud formation
604:14 - actually already already have it open
604:16 - over here we're going to go ahead and
604:17 - delete that
604:18 - stack um termination protection is
604:21 - enabled you must first disable it so
604:24 - we'll edit it disable it
604:27 - whatever okay we'll hit delete there and
604:29 - as that's deleting I'm going to go look
604:30 - for and config my
604:33 - original rule there
604:36 - again I'm not really worried about it I
604:37 - don't think it's going to really cost me
604:38 - anything but uh I also just kind of
604:40 - clear the house here just so you're
604:42 - you're okay as well and so if we go over
604:45 - to our rules um the one that I spun up
604:48 - that was custom I think was this one
604:51 - here CU these are all grayed out right
604:52 - so I can go ahead there delete that rule
604:54 - type in
604:56 - delete and we are good so there you
604:59 - go that
605:01 - is it all
605:04 - right
605:07 - [Music]
605:08 - adabs quick starts are pre-built
605:09 - templates by adabs and adus partners to
605:12 - help deploy a wide range of stacks it
605:14 - reduces hundreds of manual uh procedures
605:16 - into just a few steps the uh quick start
605:19 - is composed of three parts it has a
605:21 - reference architecture for the
605:22 - deployment an adus cloud formation
605:24 - templates that automate and configure
605:27 - the deployment a deployment guide
605:28 - explain the architecture implementation
605:30 - and detail so here's an example of one
605:32 - that you might want to launch like the
605:33 - adus Q&A bot and then you will get an
605:36 - architectural diagram and a lot of
605:37 - information about it and from there you
605:39 - can just go press the button and launch
605:42 - this infrastructure most quick start
605:44 - reference deployments enable you to
605:45 - spend up a fully functional architecture
605:47 - in less than an hour and there is a lot
605:50 - as we will see here when we take a look
605:52 - for
605:53 - [Music]
605:56 - ourselves all right so here is uh adabs
605:59 - quick starts where we have a bunch of
606:01 - cloudformation templates uh built by
606:03 - adabs or Amazon or for adab best partner
606:06 - networks APM partners and uh there's a
606:09 - variety of different things here so I'm
606:10 - just going to try to find something like
606:11 - Q&A
606:13 - bot Q&A bot just type in bot here and I
606:17 - don't know why it was here the other day
606:19 - now it's not showing up which is totally
606:21 - fine but um you know I just want
606:23 - anything to deploy just to kind of show
606:24 - you what we can do with it so you scroll
606:27 - on down we have uh this graphic here
606:29 - that's representing what will get
606:31 - deployed so we have cloudfront S3 Dynamo
606:33 - DB assistance manager Le poly all these
606:36 - kind of fun stuff um and there's some
606:39 - information about how it is architected
606:41 - and the idea is you can go ahead and
606:43 - launch in the console or view the
606:44 - implementation guide let's go take a
606:46 - look here um and there's a bunch of
606:49 - stuff so we have Solutions and things
606:51 - like that conversational things like
606:53 - that but what I'm going to do is go
606:55 - ahead and see how far I can get to
606:57 - launching with this it doesn't really
606:59 - matter if we do launch it it's just the
607:00 - fact that um I want to just show you
607:02 - what you can do with it so if we go to
607:04 - the designer it's always fun fun to look
607:06 - at it in there because then we can kind
607:08 - of visualize all the resources that are
607:10 - available and I thought that that would
607:12 - populate over there but maybe we did the
607:15 - wrong thing so I'm just going to go back
607:16 - and
607:18 - click I'm just going to click out of
607:21 - this oops cancel let's close that leave
607:25 - yes and we will launch that
607:29 - again and so this oh View and the
607:32 - designer I hit the wrong button okay
607:37 - and so now this should show us the
607:39 - template might just be
607:43 - loading there we go so this is what it's
607:45 - going to launch and you can see there's
607:46 - a lot going on here just going to shrink
607:48 - that there uh and I don't know if you
607:50 - can make any sense of it but clearly
607:53 - it's doing a lot and so if we were happy
607:55 - with this and we wanted to launch it I
607:57 - know I keep backing out of this but
607:58 - we're going to go back into it one more
608:01 - time we can go here and we can go next
608:04 - and then we we would just fill in what
608:06 - we want so you name it put the language
608:08 - in and this is stuff that they set up so
608:09 - maybe you want a mail voice set the ab
608:12 - in and stuff like that and it's that
608:14 - simple really um and every stack is
608:17 - going to be different so they're all
608:18 - going to have different configuration
608:19 - options but hopefully that gives you
608:21 - kind of an idea of what you can do with
608:23 - quick starts
608:25 - [Music]
608:29 - okay let's take a look at the concept of
608:31 - tagging within AWS so a tag is a key and
608:34 - value pair that you can assign to aabus
608:37 - Resource so as you are creating a
608:39 - resource it's going to prompt you to say
608:41 - hey what tags do you want to add you're
608:43 - going to give a key you're going to give
608:44 - a value and so some examples could be
608:46 - something like based on Department the
608:49 - status the team the environment uh the
608:52 - project as we have the example here the
608:54 - location um and so tags allow you to
608:56 - organize your resources in the following
608:58 - way for resource management so specific
609:00 - workload so you can say you know
609:02 - developer environments cost management
609:04 - and optimization so cost tracking
609:06 - budgets and alerts operations management
609:08 - so business commitments SLA operations
609:10 - Mission critical Services security so
609:13 - classification of data security impact
609:15 - governance and Regulatory Compliance
609:17 - automation workload Automation and so
609:20 - it's important to understand that
609:21 - tagging can be used in Junction with um
609:24 - IM policy so that you can restrict
609:26 - access or things like that based on
609:28 - those tags
609:29 - [Music]
609:33 - okay all right I just want to show you
609:35 - one interesting thing about tags um and
609:38 - it's just the fact that it's used as the
609:40 - name for some services so when you go to
609:43 - ec2 and you launch an instance uh the
609:45 - way you set the name is by giving it a
609:47 - tag called name and I just want to prove
609:49 - that to you just like one of those
609:52 - little exceptions here so we choose an
609:53 - instance
609:54 - here we go to configure storage and then
609:57 - what we do is we add a tag and we say
610:00 - name um and my server name okay and then
610:04 - we go ahead and review and launch we're
610:06 - going to launch this I don't need a key
610:08 - pair so we'll just say proceed without
610:09 - key pair I
610:12 - acknowledge
610:15 - okay and we will go view the instances
610:18 - and you'll see that is the name so um
610:20 - that's just like one of those exceptions
610:22 - or things that you can do with tags if
610:24 - there's other things with tags I have no
610:26 - idea that's just like a a basic one that
610:29 - everybody should know and that's why I'm
610:31 - shown to you with the tags but there you
610:33 - go
610:38 - so we just looked at tags now let's see
610:40 - what we can do with resource groups
610:41 - which are a collection of resources that
610:43 - share one or more tags or another way to
610:45 - look at it it it's a way for you to take
610:48 - multiple tags and organize them uh into
610:51 - resource groups so it helps you organize
610:53 - and consolidate information based on
610:55 - your project and the resources that you
610:57 - use resource groups can display details
610:59 - about a group of resources based on
611:01 - metrics alarms configuration settings
611:04 - and in any any time you can modify the
611:06 - settings of your resource groups to
611:07 - change what resources appear resource
611:10 - groups appear in the global console
611:12 - header uh which is over here and under
611:15 - the systems manager so technically it's
611:17 - part of AD simple systems manager or
611:20 - systems manager interface but it's also
611:22 - part of the global interface so
611:24 - sometimes that's a bit confusing but uh
611:26 - that's where you can find it
611:27 - [Music]
611:30 - okay all right so what I want to do is
611:33 - explore resource groups and and also um
611:36 - tagging so what I want you to do is type
611:38 - in resource groups at the top here and
611:41 - it used to be
611:42 - accessible not sure where they put it
611:44 - but it used to be accessible here at the
611:45 - top but they might have moved it over to
611:47 - systems manager so I'm going to go to
611:48 - SSM here not sure why I can't seem to
611:51 - find it today and on the left hand side
611:54 - we're going to look
611:56 - for resource
612:03 - groups
612:33 - for
613:03 - for
613:33 - for
613:45 - all right so what I want to do is take a
613:47 - look at resource groups and I'm really
613:49 - surprised because it used to be
613:50 - somewhere in the global now but I think
613:53 - they might have changed it um and what's
613:56 - also frustrating is if I go over to
613:58 - systems manager it was over here as well
614:01 - and so on the left hand side I'm looking
614:03 - for resource groups it's not showing up
614:06 - so I don't know best you keep moving
614:08 - things around on me and I'm I can only
614:10 - update things so quickly in my courses
614:12 - but if you type in resource groups and
614:14 - tag editor it's actually over here um I
614:17 - guess it's its own Standalone service
614:19 - now why they keep changing things I
614:20 - don't know but uh the idea is we want to
614:23 - create a resource Group so you can
614:25 - create unlimited single region groups in
614:28 - your A's account use the group to view
614:30 - related insights things like that so I'm
614:32 - going to go ahead and create a resource
614:33 - Group you can see it can be tag based or
614:35 - cloud formation based but I don't have
614:37 - any tags I don't really have anything
614:39 - tags so what I'm going to do is make my
614:41 - way over to S3 we're just going to
614:42 - create some resources or a couple
614:44 - resources here with some tags so that we
614:46 - can do some filtration so I can go ahead
614:48 - and create a bucket going say my bucket
614:52 - uh this like that
614:54 - whoops and then down below I'm going to
614:56 - go down to tags and we're going to say
614:58 - project and we're going to say um RG for
615:02 - Resource
615:03 - Group
615:05 - okay and then I can go back over here
615:07 - and then I'm going to just say I can say
615:09 - exactly what type I want I'm going to
615:11 - support all resource
615:12 - types and I'm going to say
615:16 - project RG see how it
615:19 - autocompletes and we'll go down below
615:22 - we'll just
615:23 - say my
615:25 - RG a test
615:28 - RG we'll create
615:31 - that and so now we have a resource Group
615:34 - and we can see them all in one place uh
615:36 - resource groups are probably useful for
615:38 - using in um policies so I can say say
615:41 - like Resource Group IM
615:44 - policies that's probably what they're
615:46 - used
615:49 - for okay so before you use IM am manag
615:51 - to access resource groups you should
615:52 - understand IM am features things like
615:55 - that and so administrators can use Json
615:59 - policies to specify who has access to
616:01 - what and so a policy action a resource
616:04 - Group is is used following the prefix
616:05 - resource groups so my thought process
616:09 - there is that if you want to say okay
616:12 - you have access to a resource you can
616:14 - just specify a resource Group and it
616:16 - will include all the resources within
616:18 - there and so that might be um a better
616:21 - way to apply permissions at a per
616:23 - project basis um and that could save you
616:26 - a lot of time writing out IM policies so
616:29 - that's basically all there really is to
616:30 - it also you kind of get an overview of
616:33 - of the resources that are there so that
616:36 - can be kind of useful as well there's
616:38 - the tag editor here I can't remember
616:41 - what you use this for you can set up tag
616:44 - policies um tag policies help you
616:46 - standardize tags on resource groups in
616:47 - your accounts used uh to Define tag
616:49 - policies and Abus or to attach them to
616:51 - the entire organization um we're not in
616:54 - the OR account so I'm not going to show
616:55 - you this and it's not that important um
616:57 - but just understand that resource groups
616:59 - can be created and they are used within
617:01 - IM policies in order to um uh Grant or
617:04 - deny access to stuff you go ahead and
617:07 - delete that Resource Group and really ad
617:09 - stop moving that on me if you move it
617:11 - one more time I'm just never going to
617:12 - talk about resource groups again
617:14 - [Music]
617:17 - okay hey this is Andie Brown from exam
617:20 - Pro and we are taking a look at business
617:21 - Centric services and you might say well
617:24 - why because in the exam guide It's
617:25 - explicitly says that these are not
617:27 - covered but the thing is is that when
617:29 - you're taking the exam some of the uh
617:31 - choices might be some of these Services
617:34 - as distractors and if you know what they
617:36 - are it's going to help make sure that
617:38 - you um uh guess correctly and the thing
617:41 - is that some of these services are
617:42 - useful and you should know about them so
617:44 - that's another reason why I'm talking
617:46 - about them here so the first one is
617:48 - Amazon connect this is a virtual call
617:49 - center you can create workflows to Route
617:51 - callers you can record phone calls
617:53 - manage a queue of callers based on the
617:55 - same proven system used by Amazon
617:57 - customer service teams we have
617:59 - workspaces this is a virtual Remote
618:00 - Desktop Service secure manage service
618:02 - for provision either windows or Linux
618:04 - desktops in just a few minutes which
618:06 - quickly scales up to thousands of
618:07 - desktops we have work docs which is a
618:09 - shared collaboration service a
618:11 - centralized storage to share content in
618:13 - files it is similar to Microsoft
618:14 - SharePoint think of it as a shared
618:16 - folder where the company has ownership
618:18 - we have chime which is a video
618:20 - conference service it is similar to zoom
618:22 - or Skype you can screen share have
618:24 - multiple people on the on the same call
618:26 - it is secure by default and can show you
618:28 - a calendar of upcoming calls we have
618:30 - workmail this is a manag business uh
618:32 - email contacts calendar service with
618:34 - support of existing desktop and mobile
618:36 - email client applications that can
618:38 - handle things like IMAP similar to Gmail
618:41 - or exchange we have pinpoint this is a
618:43 - marketing campaign Management Service
618:45 - pinpoint is for sending targeted emails
618:47 - Via SMS push notifications voice
618:50 - messages you can perform um A to B
618:53 - testing or create Journey so complex
618:55 - email response workflows we have SCS
618:58 - this is a transactional email service
619:00 - you can integrate SCS into your
619:02 - application to send emails you can
619:04 - create common templates track open rates
619:06 - keep track of your reputation we have
619:08 - quick site this is a business
619:09 - intelligence uh service connect multiple
619:11 - data sources and quickly visualize data
619:13 - in the form of graphs with little to no
619:15 - knowledge definitely you want to
619:16 - remember quick site sces pinpoint uh
619:19 - because those definitely will show up in
619:20 - the exam the rest probably not but they
619:22 - could show up as distractors
619:25 - [Music]
619:28 - okay hey this is Andrew Brown from exam
619:30 - Pro and we are taking a look at
619:32 - provisioning services so let's first
619:34 - what is provisioning so provisioning is
619:35 - the allocation or creation of resources
619:37 - and services to a customer and
619:39 - provisioning services are responsible
619:41 - for setting up and managing those Ada
619:43 - Services we have a lot of services that
619:45 - do provisioning most of them are just
619:47 - using cloud formation underneath which
619:48 - we'll mention here but let's get to it
619:50 - the first is elastic beanock this is a
619:52 - platform as a service to easily deploy
619:54 - web apps EB will provision various a
619:56 - services like ec2 S3 SNS cloudwatch E2
619:59 - Auto scaling groups load balancers uh
620:02 - and you can think of it as the Heroku
620:04 - equivalent to AWS then you have opsworks
620:07 - this is a configuration Management
620:08 - Service that also provides managed
620:09 - instances of Open Source configuration
620:11 - managed software such as chef and p
620:13 - puppet so you'll say I want to have a
620:16 - load balancer or I want to have servers
620:18 - and it will provision those for you uh
620:20 - indirectly then you have Cloud
620:22 - information itself this is an
620:23 - infrastructure modeling and provisioning
620:25 - service it automates the provisioning of
620:26 - AD Services by writing Cloud information
620:28 - templates in either Json or yaml and
620:30 - this is known as IAC or infrastructures
620:32 - a code you have quick starts these are
620:34 - pre-made packages that can uh be
620:36 - launched and configure your a compute
620:38 - network storage and other services
620:40 - required to deploy a workload ons we do
620:43 - cover this in this course but quick
620:44 - starts is basically just Cloud
620:46 - information templates that are authored
620:47 - by the community or um by um Amazon
620:51 - partner Network okay then we have abis
620:53 - Marketplace this is a digital catalog
620:55 - for thousands of software listings of
620:56 - independent software vendors that you
620:57 - can use defined by intes and deploy
620:59 - software so the idea is that um you know
621:02 - you can go there and provision whatever
621:03 - kind of resource you want we have Abus
621:05 - amplify this is a mobile web app
621:07 - framework that will provision multiple
621:09 - Abus Services as your backend it's
621:10 - specifically for serverless services I
621:13 - don't know why I didn't write that in
621:14 - there um but you know like Dynamo DB um
621:17 - things like uh whatever the graphql
621:20 - service is called API Gateway things
621:22 - like that uh then we have app
621:24 - Runner this is a fully managed service
621:26 - that makes it easy for developers to
621:27 - quickly deploy containerized web apps
621:30 - and apis at scale with no prior
621:31 - information experience required it's
621:33 - basically a platform as a service but
621:35 - for containers we have AIS co-pilot this
621:38 - is a command line interface that enables
621:40 - customers to quickly launch and manage
621:41 - containerize applications any us it
621:44 - basically is a a CLI tool that sets up a
621:47 - bunch of scripts to set up pipelines for
621:49 - you makes things super easy we have Adis
621:51 - code start this provides a unified user
621:53 - interface enabling you to manage your
621:54 - software development activities in one
621:56 - place usually launch common types of
621:58 - stacks like lamp then we have a cdk and
622:01 - so this is infastructure as a code tool
622:03 - allows you to use your favorite
622:04 - programming language generates out Cloud
622:05 - information templates as a means of I so
622:08 - there you
622:09 - [Music]
622:12 - go hey this is Andrew Brown from exam
622:15 - Pro and we are taking a look at ad
622:16 - elastic beant stock before we do let's
622:18 - just Define what passes so platform as a
622:21 - service allows customers to develop run
622:23 - and manage applications without uh the
622:25 - complexity of building and maintaining
622:26 - the infrastructure typically associated
622:28 - with developing and launching an app and
622:30 - so elastic beanock is a pass for
622:33 - deploying apps with little to no uh
622:35 - knowledge of the underlying
622:36 - infrastructure so you can focus on
622:38 - writing application code instead of
622:40 - setting up an automated deployment
622:41 - pipeline or devops tasks the idea here
622:44 - is you choose a platform upload your
622:46 - code and it runs with little uh
622:48 - knowledge of the infrastructure and
622:49 - adabs will say that it's generally not
622:51 - recommended for production apps but just
622:53 - understand that they are saying this for
622:54 - Enterprises and large companies if
622:56 - you're a small to medium company you can
622:58 - run elastic beanock for quite a long
623:00 - time it'll work out great elastic
623:02 - beanock is powered by Cloud information
623:03 - temp templates and it sets up for you
623:05 - elastic load balancer asgs RDS ec2
623:09 - instances preconfigured for particular
623:11 - platforms uh monitoring integration with
623:14 - cloudwatch SNS uh deployment strategies
623:17 - like in place blue green uh deployment
623:19 - has security built in so it could rotate
623:21 - out your passwords for your databases
623:24 - and it can run dockerized environments
623:25 - and so when we talk about platforms you
623:27 - can see we have Docker multicontainer
623:29 - Docker uh go.net Java nodejs Ruby PHP
623:33 - python tom cat go a bunch of stuff and
623:36 - just to kind of give you that
623:37 - architectural diagram to show you that
623:39 - it it can launch of multiple things
623:42 - [Music]
623:45 - okay hey it's Andre Brown from exam Pro
623:48 - and in this follow along we're going to
623:49 - learn all about elastic beanock maybe
623:51 - not everything but we're going to
623:53 - definitely know how to at least um use
623:56 - the service so elastic beanock is a
623:58 - platform as a service and what it does
624:00 - is it allows you to uh deploy web
624:02 - applications very easily so here I've
624:05 - made my way over to elastic beanock I
624:06 - mean environment and app and then we set
624:09 - up our application we have two tiers a
624:11 - web server environment a worker
624:12 - environment worker environment is great
624:14 - for long running workloads performing uh
624:17 - background jobs and things like that and
624:18 - then you have your web server which is
624:20 - your web server and you can have both
624:22 - and it's generally recommended to do so
624:25 - um but anyway what we'll do is create a
624:27 - new application so let's say my app here
624:30 - and uh there's some tags we can do and
624:32 - then it will name based on the
624:33 - environment
624:34 - then we need to choose an environment
624:36 - name so say my environment and just put
624:37 - a bunch of numbers in there hit the
624:39 - check availability scroll on down and we
624:41 - have two options manage platform custom
624:43 - platform and I'm not sure why custom is
624:46 - blanked out but it would allow you to um
624:49 - it would allow you to I think use your
624:51 - own containers so I'm a big fan of Ruby
624:53 - so I'm going to drop down to Ruby and
624:56 - here we have a bunch of different
624:57 - versions and so 2.7 is pretty pretty new
625:00 - which is pretty good and then there's
625:02 - the platform version which is fine and
625:03 - the great thing is it comes with a
625:05 - sample application now you could hit
625:07 - create environment but you'd be missing
625:08 - on a lot if you don't hit this configure
625:10 - more options I don't know why they put
625:12 - it there it's a not very good UI but um
625:15 - if you click here you actually get to
625:16 - see everything possible and so up here
625:18 - we have some presets where we can have a
625:20 - single instance so this is where it's
625:23 - literally running a single E2 instance
625:24 - so it's very cost effective you can have
625:26 - it with spot uh spot pricing so you save
625:28 - money um there's High availability so
625:31 - you know if you want it set up with a
625:33 - load balance an auto scaling group it
625:34 - will scale very well or you can do
625:36 - custom configuration we scroll on down
625:39 - here you can enable Amazon x-ray you can
625:42 - rotate out logs you can do log
625:45 - streaming um there's a lot of stuff here
625:48 - and basically it's just like it sets up
625:50 - most for you but you can pretty much
625:52 - configure what you want as well if we
625:54 - had the load bouncer set if I go here go
625:56 - to High availability now we'll be able
625:58 - to change our load balancer options you
626:01 - have different ways of deploying so you
626:02 - can go here and and then change it from
626:04 - all at once rolling immutable traffic
626:06 - splitting depends on what your use case
626:09 - is um we can set up a key pair to be
626:12 - able to log into the
626:14 - machine there's a whole variety of
626:16 - things you can connect your database as
626:18 - well so it can create the database
626:20 - alongside with it and then it can
626:22 - actually rotate out the key so you don't
626:23 - have to worry about it which is really
626:25 - nice what I'm going to do is go to the
626:27 - top here and just choose a single
626:28 - instance because I want this to be very
626:29 - cost- effective we're going to go ahead
626:31 - and hit create environment
626:34 - and so we are just going to wait for
626:36 - that to start up and I'll see you back
626:38 - when it's done
626:40 - okay okay so it's been uh quite a while
626:43 - here and it says a few minutes so if it
626:45 - does do this what you can do is just
626:47 - give it a hard refresh I have a feeling
626:48 - that it's already done is it done yeah
626:51 - it's already done so and here it says on
626:53 - September 2020 elastic be talk Etc
626:56 - default default I don't care um but
626:58 - anyway so this application I guess it's
627:00 - in a pending State um I'm not sure why
627:03 - let's go take a look here causes
627:05 - instance has not sent any data since
627:08 - launch uh none of the instances are
627:10 - sending data so that's kind of
627:11 - interesting because um I shouldn't have
627:14 - any problems you know what I mean so
627:16 - what I'm going to do is just reboot this
627:18 - machine and see if that fixes the issue
627:19 - there but usually it's not that
627:21 - difficult because it's the sample
627:22 - application it's not up to me um as to
627:26 - how to fix this you know what I mean
627:28 - so I'm not sure but um what we'll do is
627:33 - we will let the machine reboot and see
627:35 - if that makes any difference okay all
627:37 - right so after rebooting that machine
627:38 - now it looks like the server is healthy
627:39 - so it's not all that bad right if you do
627:42 - run into issues that is something that
627:43 - you can do and so uh let's go see if
627:47 - this is actually working so the top here
627:49 - we have a link and so I can just right
627:51 - click here it says congratulations your
627:53 - first 8us elastic uh beanock Ruby
627:55 - application is now running so it's all
627:58 - in good shape um there's a lot of stuff
628:00 - that's going on here in elastic beanock
628:02 - that we can do uh we we can go back to
628:03 - our configuration and change any of our
628:06 - options here so there's a lot of stuff
628:08 - as you can see uh we get logging uh so
628:11 - click the request log so if we click on
628:13 - this and say last 100
628:15 - lines we should be able to get uh
628:17 - logging data we have to download it I
628:20 - wish it was kind of in line but here you
628:21 - can kind of see what's going on so we
628:23 - have STD access logs error logs Puma
628:26 - logs elastic beam stock engine so you
628:28 - could use that to debug very common to
628:31 - take that over to uh support if you do
628:33 - have issues uh for Health it monitors
628:36 - the health of the instances which is
628:37 - great then we have some uh monitoring uh
628:41 - data here so it gives you like a built
628:43 - dashboard so that's kind of nice you can
628:45 - set up alarms um you have not defined
628:48 - any alarms you can add them via the
628:49 - monitoring dashboard so I guess you'd
628:51 - have
628:52 - to you'd have to somehow add them um I
628:55 - don't think I've ever added alarms for
628:57 - um classic beanock but it's nice to know
628:59 - that they have them you can set up
629:01 - schedules for managed events then this
629:04 - is event data so it's just kind of
629:05 - telling you it's kind of like logs it
629:07 - just tells you of things that have
629:09 - changed so there's stuff like that what
629:11 - I'm looking for is to see how I can
629:13 - download the existing
629:16 - application because there's a version
629:18 - uploaded here oh the source is over here
629:21 - okay
629:23 - so I think it's probably over here the
629:25 - one that's
629:26 - running so that's
629:29 - it if it was easy to find what I
629:31 - probably would do is just modify it and
629:33 - oh yeah it's over here so if we go here
629:35 - and download the
629:39 - zip I wonder if it'd be even worth um
629:42 - playing with this so let's I'm just
629:43 - going to see if we can go over to
629:45 - Cloud9 and give this a go
629:48 - quickly so if we go over and launch a
629:50 - Cloud9 environment maybe we can tweak it
629:52 - and upload a revised version so we say
629:55 - create new we'll say EB
629:59 - um uh environment for elastic bean stock
630:03 - uh we'll set it all the defaults that's
630:05 - all fine it's all within the free tier
630:06 - we'll create that environment what I'm
630:08 - going to do is just take this uh Ruby
630:10 - zip file and move it to my
630:12 - desktop and as that is loading we'll
630:14 - give it a moment here I'm just going to
630:16 - go back and I was just curious does it
630:18 - let you download it directly from here
630:20 - no so only thing is that you know if you
630:23 - download that application elastic
630:25 - beanock usually has a configuration file
630:27 - with it and so I don't know if they
630:29 - would have given that to us but if they
630:32 - did that would be really great
630:34 - but we just have to wait for that to uh
630:36 - launch there as well I guess you can
630:38 - save configurations and roll back on
630:40 - those as
630:43 - well um but we will just wait a moment
630:47 - here while it's going I might just peek
630:49 - inside of this file to see what it is
630:52 - this ZIP
630:53 - contains just going to go to my desktop
630:55 - here open up that
630:57 - zip so it looks pretty simple it doesn't
631:00 - even look like a rails app it looks like
631:01 - maybe it's a Sinatra app I thought
631:03 - before that it would it would have
631:04 - deployed a Ruby on Rails application but
631:06 - maybe they keep it really simple
631:10 - um I don't see usually it's like yamell
631:13 - files they use for configuration I don't
631:16 - see that
631:17 - there so it might be that the default
631:20 - settings will work fine uh there's a
631:22 - king fig. Ru and stuff like that but
631:24 - once Cloud9 is up here we will upload
631:26 - this and see what we can do with it okay
631:29 - so there we go uh Cloud9 is ready to go
631:31 - and so if we right click here whoops
631:33 - right click here we should be up be able
631:35 - to upload a file if not we can go up
631:37 - here to the
631:38 - top or it's here or
631:41 - there where is the upload I've I've
631:44 - uploaded things in here so I absolutely
631:45 - know we can I just got to find
631:50 - it is that the
631:55 - upload upload files
632:02 - Cloud9
632:06 - oh boy that's not helpful that's not
632:09 - helpful at all so let me just click
632:11 - around a little bit here I mean worst
632:13 - case I can always just bring it in Via a
632:14 - curl oh upload local files there it is I
632:17 - was just not um being patient okay so
632:20 - we'll drag that on in there and we
632:23 - will did it upload yep it's right there
632:26 - okay great so we need to unzip it so
632:28 - what I'll do is just drag this on up
632:29 - here I'll do an LS and we'll say unzip
632:34 - rubyzip and so that unzipped the
632:36 - contents there I think the readme was
632:39 - part of Cloud9 so I'm going to go ahead
632:41 - and delete that out not that it's going
632:43 - to hurt anything and so now what we can
632:46 - do and we'll delete the
632:48 - original original zip
632:50 - there um and let's see if we can make a
632:53 - change here so I'm just going to open up
632:55 - see what it is so yeah it's running
632:57 - Sinatra so that's pretty clear there we
632:59 - have a proc file to say how it runs we
633:01 - have a worker sample sample so that just
633:03 - tells how the requests go you don't need
633:06 - to know any of this I'm just kind of
633:07 - clicking through it because I know Ruby
633:08 - very well we have a cron yamel file so
633:11 - that could be something that gets loaded
633:12 - in here so I think basically a Sinatra
633:15 - app probably just works off the bat here
633:17 - but if we want to make a change we
633:19 - probably just make a change over to here
633:21 - so I'll go down here and this is
633:24 - your second ads elastic beanock
633:27 - application so the next thing we need to
633:29 - do is actually zip the contents here I
633:31 - don't know if it would let us zip it
633:33 - with in here but I'll have to look like
633:35 - Zip the contents of a
633:38 - directory Linux this goes to
633:42 - show Google is
633:44 - everything so the easiest way to zip a
633:49 - folder
633:56 - um
633:57 - zip everything in the current
634:01 - directory
634:07 - Linux okay that's easy so we'll go back
634:10 - over here and we will type in
634:14 - zip and it wants hyphen R for recursive
634:17 - which makes sense and then the name of
634:20 - the zip so
634:23 - um uh Ruby 2.zip and we'll do
634:30 - period zip warning found is who is
634:37 - zip
634:39 - oh uh yum install zip maybe we have to
634:43 - install uh ZIP but maybe it's not
634:46 - installed pseudo yum install
634:49 - zip since it's Amazon El 2 it uses
634:52 - yum and so package already installed so
634:55 - I'm going to type zip again so zip is
634:56 - there now great oops don't need to
634:58 - install
635:01 - twice
635:03 - zip warning Ruby 2 zip not found or
635:14 - empty okay so install zip and use zip
635:17 - hyphen R you can use the flag to best
635:23 - compensate so if that's not working what
635:25 - I'm going to do is just go up a
635:31 - directory why is it saying not found or
635:44 - [Music]
635:50 - empty maybe I need to
635:56 - use okay so I think the problem was is I
635:58 - was using the wrong flag so I put F
636:00 - instead of R I don't know why I did that
636:03 - so I probably should have done this okay
636:05 - and so that should have copied all the
636:06 - contents of that file so what I'm going
636:08 - to do is go ahead whoops make sure I
636:10 - have that select it and download that
636:12 - file and once I have downloaded that
636:14 - file I'm going to just open the contents
636:16 - to make sure it is what I expect it to
636:18 - be so we're going to open that up and
636:22 - whoops get out of here when RAR and it
636:23 - looks like everything I want so what I'm
636:26 - going to do is go back over to here I'm
636:29 - going to make sure I have my Ruby 2 on
636:31 - my desktop and we're going to see if we
636:33 - can upload another version here so
636:35 - upload and deploy choose the file we're
636:38 - going to go all the way to my desktop
636:39 - here and we're going to choose Ruby 2
636:42 - and um like Ruby 2 will be the version
636:45 - name or we'll just say two and we'll
636:47 - deploy and we'll see if that works okay
636:50 - but there are like uh elastic be
636:52 - configuration files like gamble files
636:54 - that can sit in the root directory and
636:56 - so generally you're used to seeing them
636:57 - there but you know I imagine that a US
637:00 - probably engineered these examples so
637:01 - that it uses all the default settings
637:03 - but uh once this is deployed I'll see
637:05 - you back here in a moment okay after a
637:07 - short little wait it looks like it has
637:09 - deployed so what I'm going to do is just
637:10 - close my other tabs here and open this
637:12 - up and see if it's worked it says your
637:15 - second ads elastic being stock Ruby
637:17 - application so uh we were successful uh
637:20 - deploying that out which is really great
637:22 - so what we can do now is just close that
637:24 - tab there and uh since we have that
637:26 - cloud environment it will shut down on
637:28 - its own but you know just for your
637:30 - benefit I think that we should shut it
637:32 - off right now so go ahead and delete
637:34 - that I'm going to go back over to
637:36 - elastic beanock here and I just want to
637:39 - destroy all of it so we'll see if we can
637:41 - just do that from here terminate the
637:44 - application enter the name so I think we
637:47 - probably have to enter that in
637:49 - there and so I think that oh a problem
637:53 - occurred rate
637:56 - exceeded what that's AWS for you so it's
638:00 - not a big deal I would just go and check
638:02 - it
638:03 - again and maybe what we'll do is just
638:05 - delete the application
638:10 - first okay so that one is possibly
638:17 - deleting let's go in here is anything
638:22 - changing can't even tell we'll go ahead
638:26 - oh can't take that one
638:31 - out
638:40 - delete application
638:42 - again if it takes you a couple times
638:44 - it's not a big
638:46 - deal it's AWS 4 yes so there's a lot of
638:50 - moving parts so it looks like it is
638:51 - terminating the instance and so we just
638:54 - have to wait for that to complete uh
638:56 - once that is done we might have to just
638:57 - tear down the environment so I'll see
638:58 - you back here when it has finished
639:00 - tearing this down okay all right and so
639:02 - after a short little wait here I think
639:03 - it's been destroyed we'll just double
639:05 - check by going to the applications going
639:06 - to the environments yeah and it's all
639:08 - gone probably cuz I initially deleted
639:10 - that environment and then took the
639:11 - application with it so I probably didn't
639:13 - have to delete the app separately um but
639:16 - uh yeah so there you go and just make
639:17 - sure your Cloud9 environment's gone and
639:19 - you are a okay there'll probably be some
639:21 - like lingering S3 buckets so if you do
639:23 - want to get rid of those you can it's
639:24 - not going to hurt anything having those
639:26 - around uh but they do tend to stack up
639:29 - after a while which is kind of annoying
639:30 - so if you don't like them you can just
639:32 - empty them out as I am doing here whoops
639:37 - oh just permanently
639:40 - delete copy that text
639:42 - there we can go
639:46 - back to here and then just go take out
639:50 - that bucket let's delete that
639:56 - there oh if you get this this is kind of
639:58 - annoying but uh elastic beanock liks to
640:00 - put in an i permission or policy here so
640:03 - if you go down here there's a bucket
640:04 - policy you just have to delete it out it
640:06 - prevents it from being
640:09 - deleted and we'll go back over here and
640:12 - then we will delete
640:15 - it okay and yeah there we go that's
640:19 - [Music]
640:23 - it so let's take a look at serverless
640:25 - services on AWS and this is not
640:27 - including all of them because we're
640:29 - looking at the most purely serverless
640:31 - services
640:32 - uh if we tried to include all the
640:34 - serverless services it would just be too
640:35 - long of a list uh but let's take a look
640:38 - here so um before we do let's just
640:40 - redefine what is serverless so when the
640:42 - underlying servers infrastructure and
640:43 - operating system is taken care of by the
640:44 - CSP serverless is generally by default
640:47 - highly available scalable cost effective
640:49 - you pay for what you use the first one
640:51 - is Dynamo DB which is a serverless nosql
640:54 - key value and document database it's
640:56 - designed to scale to billions of records
640:58 - with guaranteed consistent data return
641:00 - in at least a second you do not have to
641:02 - worry about managing chards you have
641:04 - simple storage service S3 which is a
641:06 - seress object storage service you can
641:08 - upload very large and unlimited amounts
641:10 - of files you can pay for what you store
641:13 - you don't worry about the underlying
641:14 - file system or upgrading the disk size
641:16 - we have ECS fargate which is a servess
641:18 - orchestration container service is the
641:20 - same as ECS except you pay on demand per
641:24 - running container with ECS you have to
641:26 - keep a ec2 server running even if you
641:29 - have no containers running where adus
641:30 - manages the underlying server so you
641:32 - don't have to scale or upgrade the ec2
641:35 - server we have adus Lambda which is a
641:37 - serverless function service you can run
641:40 - code without provisioning or managing
641:41 - servers you upload a small piece of code
641:44 - choose uh how much memory you want how
641:46 - long you want the function is allowed to
641:48 - run before timing out your charge based
641:50 - on the runtime of the service function
641:52 - rounded to the nearest 100 milliseconds
641:54 - we have step functions this is the state
641:56 - machine service it coordinates multiple
642:00 - Services into serverless workflows
642:02 - easily share data among lambdas have a
642:05 - group of lambdas wait for each other
642:07 - create logical steps also work with
642:09 - fargate tasks we have Aurora servus this
642:11 - is a serous on demand version of Aurora
642:14 - so when you want most of the benefits of
642:16 - Aurora but trade you have to trade off
642:18 - those cold starts or you don't have lots
642:20 - of traffic or demand so things Ser
642:23 - services that we could have put in here
642:24 - as well is like API Gateway Apps sync a
642:28 - amplify um and those are like the the
642:31 - first two were app Integrations you
642:33 - could say sqs SNS those are all serous
642:36 - services but you know again we'd be here
642:38 - all day if I I I list to the all
642:40 - [Music]
642:44 - right all right let's take a look at
642:46 - what is serverless and we did look at it
642:49 - from a server perspective earlier in the
642:51 - course but let's just try to abstractly
642:53 - Define it and talk about the
642:54 - architecture so serverless architecture
642:56 - generally describes fully managed cloud
642:58 - services and the classification of a
643:01 - cloud service being being serverless is
643:03 - not a Boolean answer it's it's not a yes
643:05 - or no but an answer on a scale where a
643:08 - cloud service has a degree of serverless
643:10 - and I do have to point out that this
643:12 - definition might not be accepted by um
643:15 - everybody because serverless is one of
643:17 - those uh terms where um we've had a
643:21 - bunch of different cloud service
643:22 - providers Define it differently and then
643:24 - we have thought leaders that have a
643:26 - particular concept of what it is so you
643:28 - know I just do my best to try to make
643:30 - this practical here for you but a
643:32 - serverless service could have all or
643:35 - most of the following characteristics
643:36 - and so it could be highly elastic and
643:38 - scalable highly available highly durable
643:41 - secure by default it abstracts away the
643:44 - underlying infrastructure and are build
643:46 - based on the execution of your business
643:48 - tasks a lot of times that uh that cost
643:51 - is not uh is not always represented as
643:54 - something that is like I'm paying X for
643:57 - compute it could be abstracted out into
643:59 - some kind of um credit that uh doesn't
644:02 - necessarily map to something physical
644:05 - then we have serus can scale to zero
644:06 - meaning when it's not in use the
644:08 - serverless resources cost nothing uh and
644:12 - these two last topics basically pull
644:14 - into pay for Value so you don't pay for
644:16 - idle servers you're paying for the value
644:19 - uh that your service
644:21 - provides and uh my friend Daniel who
644:24 - runs the serverless Toronto group he
644:26 - likes to describe serverless as being
644:28 - similar to like energy efficient rating
644:30 - so an analogy of serus could be similar
644:32 - to energy rating labels which allows
644:34 - consumers to compare the Energy
644:35 - Efficiency of a product so some services
644:38 - are more servoless than others and again
644:41 - you know some people might not agree
644:42 - with that where there's a a definitive
644:44 - yes or no answer but I think that's the
644:46 - best way to look at it
644:48 - [Music]
644:51 - okay hey it's Angie Brown from exam Pro
644:54 - and we're taking a look at windows on
644:56 - ads so adabs has multiple cloud services
644:58 - and tools to make it easy for you to run
645:00 - window workloads on ads so let's get to
645:02 - it so the first is Windows servers on
645:04 - ec2 so you can select from a number of
645:06 - Windows Server versions including the
645:08 - latest version like Windows Server 2019
645:11 - uh for uh databases we have SQL server
645:14 - on RDS you can select from a number of
645:16 - SQL Server database versions then we
645:18 - have adabs directory service which lets
645:20 - you run Microsoft active directory ad as
645:23 - a managed service we have adus license
645:25 - manager which makes it easier to manage
645:27 - your software licenses from software
645:29 - vendors such as Microsoft we have have
645:32 - Amazon FSX for Windows file server which
645:34 - is a fully managed scalable storage
645:36 - built for Windows we have the ads SDK
645:39 - which allows you to write code in your
645:41 - favorite language to interact with adus
645:42 - API but it specifically has support forn
645:45 - net a language favorite for Windows
645:47 - developers we have Amazon workspaces so
645:50 - this allows you to run a virtual desktop
645:52 - you can launch a Windows 10 desktop to
645:54 - provide secure and durable workstations
645:57 - that is accessible from wherever you
645:59 - have an internet connection a Lambda
646:01 - supports power shell is a programming
646:02 - language to write your serverless
646:04 - functions and we have Aus migration
646:06 - acceleration program map for Windows is
646:10 - a migration methodology for moving large
646:12 - Enterprises it us has Amazon partners
646:15 - that specialize in providing
646:16 - Professional Services for map this is
646:18 - not just everything for Windows on AWS
646:21 - like if you want to move your SQL Server
646:24 - over to RDS postest I believe they've
646:27 - like they created an adapter to do that
646:31 - um but yeah hopefully that gives you an
646:32 - idea what you can do with windowss on
646:33 - AWS
646:34 - [Music]
646:38 - okay hey this is Andre Brown from exam
646:40 - Pro and I want to show you how you can
646:41 - launch a Windows uh server on AWS so
646:45 - what you're going to do is go to the top
646:46 - here and we are going to type in ec2 and
646:49 - from here uh what we'll do is we'll go
646:52 - ahead and launch ourselves a new ec2
646:55 - instance and we are going to have um a
646:58 - selection of instances that we can
647:00 - launch and so we're looking for for the
647:02 - Microsoft Windows server and this is
647:05 - interesting there's actually a free tier
647:08 - eligible that is crazy because if you go
647:10 - over to Azure they don't have a free
647:12 - tier Windows
647:13 - Server does so that's pretty crazy um
647:17 - and it runs on a T2 micro no that can't
647:20 - be right there's no way it can run a T2
647:23 - micro that seems like that's too small
647:25 - let's try it okay I just don't believe
647:28 - it because when you use Azure you have
647:29 - to choose a particular size of instance
647:31 - by default and it's a lot more expensive
647:33 - and there is no free tiar so we'll go
647:36 - here there are free tiar just not really
647:38 - for Windows in particular so we'll go
647:41 - here this looks good security groups
647:43 - this opens up RDP so we can get into
647:45 - that machine we're going to go next here
647:47 - and launch this
647:49 - machine says if you plan to use Ami the
647:52 - benefits the Microsoft license Mobility
647:54 - check out this form that's not something
647:57 - we're worried about today and I mean I
648:00 - guess we can create a key pair
648:02 - I'm not sure what we would use a key
648:04 - pair for here um for Windows Amis the
648:07 - private key file is required to obtain
648:08 - the password used to log into the
648:10 - instance okay so I guess we're going to
648:11 - need it
648:12 - so Windows
648:16 - key great we'll launch that
648:19 - instance and uh I'll see you back here
648:22 - when it launches but I just don't
648:23 - believe that it would launch that fast
648:25 - you know all right so after a short
648:27 - little wait here the server is ready and
648:30 - so let's see if we can actually go ahead
648:31 - and connect to this so I'm going to hit
648:33 - connect here and we're go over to rdb
648:35 - client so you connect to your windows
648:37 - instance using a remote desktop client
648:39 - of your choice and downloading and
648:40 - running the RDP shortcut below so I'm
648:43 - going to go ahead and download this and
648:45 - you're going to have to be on a um
648:49 - Windows machine to be able to do this or
648:50 - have an rdb client installed I think
648:52 - there's one for Mac that you can get
648:53 - from the Apple Store um but all I'm
648:55 - going to do is just double click the
648:58 - file
648:59 - so you probably can't see it here I'm
649:01 - just going to expand this trying to oh
649:05 - my computer is being silly but anyway
649:07 - there we go we moved it over there I'm
649:08 - just going to drag over here and just
649:10 - double click this image so you can see
649:12 - that I'm doing it I'm saying
649:14 - connect
649:16 - okay and it's going to ask for a
649:18 - password so I'm going to hope that I can
649:20 - just click that and get the password so
649:22 - to decrypt the password you will need
649:24 - your key PA instance you'll have to
649:25 - upload that and I don't know if I
649:27 - remember having to do that before but
649:29 - it's a great security measure so I'm
649:32 - fine with it I'm going to drag my key to
649:33 - my desktop so I can see what's going on
649:35 - there as
649:36 - well and we're going to go grab that and
649:39 - decrypt the password and so
649:42 - now um where's our password oh it's
649:46 - right here okay so we're going to grab
649:48 - that password
649:49 - there we will paste that in said
649:54 - okay say yes and see if we can connect
649:57 - to this instance and if this is running
649:59 - on a T2 micro I'm going to lose it
650:01 - because that is just
650:07 - cheap it just just doesn't seem possible
650:10 - to me because again on Azure you have to
650:12 - launch an instance with a lot of stuff
650:14 - and it just uh seems uh crazy what's
650:16 - also interesting is that iTab us uh on
650:19 - Windows like launches so fast it's
650:21 - unbelievable how fast these servers uh
650:23 - spin up and it's just very unusual but
650:26 - yeah so we are in
650:27 - here
650:30 - um it's not asking me to activate or
650:32 - anything so I guess there's already a
650:34 - Windows license
650:37 - here and um I'm not sure if there's any
650:40 - kind of like games installed like do we
650:42 - have mind sweeper can I play mind
650:44 - sweeper on
650:46 - here it's a data center server so I'm
650:48 - assuming not um but yeah so this is a
650:51 - Windows server and it's pretty
650:52 - impressive that this works I'm not sure
650:54 - if this is going to have an outbound
650:55 - connection here um just because we
650:57 - probably would have to configure it let
650:59 - just say okay I just I really don't
651:01 - think it's going to go to the Internet
651:03 - by
651:07 - default yeah so You' probably have
651:10 - to do some stuff you
651:15 - know oh no there we go so yeah we got to
651:17 - the Internet so it's totally possible
651:19 - but uh yeah that's about it that's all I
651:21 - really wanted to show you so what I'm
651:23 - going to do is just go back to ec2 and
651:25 - we're going to shut down the server here
651:27 - just expand that
651:30 - there
651:32 - and we will go here and we will
651:35 - terminate that
651:37 - instance good we'll give that a refresh
651:39 - that's shutting down and we are
651:42 - [Music]
651:45 - done hey this is Andrew Brown from exam
651:48 - Pro and we are taking a look at Abus
651:50 - license manager and before we do let's
651:52 - talk about what b y l or bring your own
651:55 - license mean so this is the process of
651:57 - reusing an existing software license to
651:59 - run vendor software on a cloud vendor
652:01 - Computing service byol allows companies
652:04 - to save money since they may have
652:05 - purchased the license in bulk or the
652:07 - time that provided a greater discount
652:09 - than if purchased again and so an
652:11 - example of this could be the license
652:12 - Mobility provided by Microsoft's volume
652:15 - licensing to customers with eligible
652:17 - server applications covered by the
652:19 - Microsoft software Assurance program uh
652:21 - and I don't know what I was trying to do
652:22 - there I guess maybe it's just essay and
652:23 - I missed the parentheses there on the
652:25 - end no big big deal um but Aus license
652:28 - manager is a service that makes it
652:29 - easier for you to manage your software
652:32 - licenses from software vendors centrally
652:34 - across ads in your on- premise
652:35 - environments ads license manager
652:38 - software uh that is licensed based on
652:40 - Virtual cores uh physical cores sockets
652:43 - or a number of machines this includes a
652:44 - variety of software products for
652:46 - Microsoft IBM sap Oracle and other
652:49 - vendors so that's the idea you say what
652:51 - is my license type it's it's bound to
652:53 - this amount of CPUs AAS license manager
652:56 - works with ec2 with dedicated instances
652:58 - dedicated hosts and even spot instances
653:01 - and for RDS there's only for Oracle
653:03 - databases so you can import that license
653:05 - for your Oracle server um just
653:08 - understand that um if you're doing
653:10 - Microsoft Windows servers or Microsoft
653:12 - SQL Server license you're generally
653:14 - going to need a dedicated host because
653:16 - of the Assurance program uh and this can
653:18 - really show up on your exam so even
653:20 - though a license manager works on
653:22 - dedicated instances and spot instances
653:24 - just try to gravitate towards dedicated
653:27 - hosts on the server or on the exam okay
653:33 - [Music]
653:34 - all right let's take a look at the
653:35 - logging services that we have available
653:37 - in AWS so the first one here is cloud
653:40 - trail and this logs all API calls
653:42 - whether it's SDK or the CLI so if it's
653:45 - making a call to the API it's going to
653:46 - get tracked between adaa services and
653:48 - this is really useful to say who can we
653:50 - blame who was the person that did this
653:52 - so who created this bucket who spent up
653:54 - that expense of vc2 instance who
653:56 - launched the stagemaker notebook um and
653:58 - the idea here is you can detect
654:00 - developer misconfiguration detect
654:01 - malicious actors or automate responses
654:04 - through the system then you have
654:06 - cloudwatch which is a collection of
654:07 - multiple Services I commonly say this is
654:09 - like an umbrella service because it has
654:10 - so many things underneath it so we have
654:12 - cloudwatch logs which is a centralized
654:14 - place to store your cloud services log
654:16 - data application logs metrics which
654:18 - represents a Time ordered set of data
654:20 - points a variable uh to monitor uh event
654:23 - Bridge or previously known as cloudwatch
654:25 - events triggers an event based on a
654:27 - condition so every hour take a snapshot
654:29 - of the server alarms triggers
654:31 - notifications based on metrics
654:33 - dashboards creates visualizations based
654:35 - on metrics and that's not all of the
654:37 - things that are under cloudwatch but
654:38 - those are the core five ones you should
654:40 - always know um absolutely there then we
654:43 - have adus x-ray this is for a
654:44 - distributed tracing system so you can
654:46 - use it to pinpoint issues within your
654:48 - microservices so you see how data moves
654:50 - from one app to another how long it took
654:52 - to move and if it failed uh to move
654:54 - forward
654:56 - [Music]
654:59 - okay let's take a close CL look here at
655:01 - Aus cloud trail because it's a very
655:02 - important service so it's a service that
655:05 - enables governance compliance
655:06 - operational auditing and risk auditing
655:08 - of your Aus account and the idea is that
655:10 - every time you make an API call it's
655:12 - going to show up as some kind of
655:13 - structured data that you can uh interact
655:15 - with or read through so abis cloud trail
655:17 - is used to monitor API calls and actions
655:19 - made on the AWS account easily identify
655:21 - which users and accounts made the call
655:23 - to AWS so you might have the WHERE so
655:25 - the source IP address the when the event
655:27 - time the who the user agent uh and the
655:31 - what the region resource in action so
655:33 - I'm just going to get my pen tool out
655:34 - here for a moment and just notice you
655:36 - have the event time so when it happened
655:37 - the source the name the region The
655:40 - Source IP address the user agent uh who
655:42 - was doing it so here was LE Forge the
655:45 - response element so you know it's very
655:46 - clear what is going on here um and then
655:49 - you know Cloud tra is already logging by
655:51 - default and will collect logs for the uh
655:53 - for the last 90 days via event history
655:55 - if you need more than 90 days you need
655:57 - to create a trail which is very common
655:58 - you'll go into AWS and make one right
656:00 - away trails are outputed to S3 and do
656:02 - not have guy like event history to
656:05 - analyze a trail you have to use Amazon
656:07 - Athena and I'm sure there are other ways
656:09 - to analyze it within AWS but here's just
656:11 - what the event history looks like so
656:13 - right off the bat you can already see
656:15 - that there are information there I'm not
656:16 - sure if they've updated the UI there
656:18 - they might have uh as even when I'm
656:20 - recording this I kind of feel like if we
656:22 - go into the follow along which we will
656:24 - um I bet they might have updated that
656:25 - the idea here is that you know you can
656:27 - browse the last 90 days but anything
656:30 - outside of that you're going to have to
656:31 - do a little bit of work yourself
656:32 - [Music]
656:36 - okay so we're not going to cover all the
656:38 - cloudwatch services there's just too
656:39 - many but let's look at the most
656:40 - important ones and one of that those
656:42 - important ones is cloudwatch alarms so
656:44 - cloudwatch alarms monitors a cloudwatch
656:46 - metric based on a defined threshold uh
656:48 - so here you can see there's kind of a
656:50 - condition being set there so if the
656:51 - network in is greater than 300 for one
656:53 - data points within 5 minutes it's going
656:55 - to breach an alarm so uh that's when it
656:57 - goes outside it's defin threshold and so
657:00 - the state's going to either be something
657:01 - like okay so the metric or expression is
657:03 - within the defined threshold so do
657:04 - nothing alarm the metric or expression
657:06 - is outside of the defined threshold so
657:08 - do something or insufficient data the
657:10 - alarm has just started the metric is not
657:12 - available not enough data is available
657:15 - and so when the state has change you can
657:17 - Define actions that it should take and
657:19 - so that could be doing a notification
657:21 - autoscaling group or any C2 action um so
657:24 - cloudwatch alarms are really useful for
657:25 - a variety of reasons the one that we
657:27 - will come across right away will be
657:28 - setting up a bilding alarm
657:31 - [Music]
657:35 - so let's take a look here at the
657:36 - autonomy of an alarm and so I have this
657:38 - nice graphic here to kind of explain
657:39 - that there and so the first thing is we
657:41 - have our threshold condition uh and so
657:43 - here you can just set a value and say
657:45 - okay the value is a TH or 100 whatever
657:48 - you want it to be and this is going to
657:50 - be for a particular metric the actual
657:52 - data we are measuring so maybe in this
657:54 - case we're measuring Network in so the
657:56 - volume of incoming Network traffic
657:57 - measured in bytes so when using 5minute
657:59 - monitoring divide by 3 00 we get bytes
658:01 - per second if you're trying to figure
658:02 - out that calculation there you have data
658:04 - points so these represent the metrics
658:06 - measurement at a given point then you
658:08 - have the period how often it checks to
658:10 - evaluate the alarm so we could say every
658:12 - five minutes uh you have the evaluation
658:14 - period so the number of previous periods
658:16 - and the data points to alarm so you can
658:18 - say one data point is breached and
658:20 - evaluation period going back four
658:22 - periods so this is what triggers the
658:24 - alarm uh the thing I just want you to
658:26 - know is that you can set a value right
658:28 - and that it's based on a particular
658:29 - metric and there is a bit of logic here
658:32 - in terms of uh the alarm so it's not as
658:34 - simple as just it's breached but there's
658:36 - this period thing happening
658:38 - [Music]
658:41 - okay let's take a look at cloudwatch
658:43 - logs so to understand that we have log
658:46 - streams and log groups so a log stream
658:48 - is uh a stream that represents a
658:50 - sequence of events from an application
658:52 - or instance being monitored so imagine
658:54 - you have an ec2 instance running a web
658:56 - application and you want those logs to
658:58 - be streamed to cloudwatch logs that's
659:00 - what we're talking about about here so
659:01 - you can create log streams manually uh
659:03 - but generally this is automatically done
659:04 - by the service you are using uh unless
659:06 - you were collecting application logs on
659:08 - any2 instance as I just described here
659:10 - is a log group of a Lambda function you
659:12 - can see the log streams are named after
659:14 - the running instance lambda's frequency
659:16 - run on New instances so the stream
659:18 - contains timestamps so what I'm trying
659:20 - to say here is that there's a variety of
659:22 - different Services Lambda RDS what have
659:25 - you and they already send their logs to
659:27 - cloudwatch logs and they're and they're
659:29 - going to vary Okay so here's a log group
659:31 - of an application log running on uc2 you
659:33 - can see here the log streams are named
659:35 - after the running instance ID here is
659:37 - the log group for Adis glue you can see
659:38 - that the log streams are named after the
659:40 - glue jobs um and so you know we have the
659:43 - streams but let's talk about the actual
659:45 - data that's made up of it the log events
659:47 - so this represents a single event in a
659:48 - log file log events can be seen within
659:51 - the log stream and so here's an example
659:53 - of you would open this up in cloudwatch
659:56 - logs and you can actually see what what
659:57 - was being reported back by your server
659:59 - you can filter these events to filter
660:01 - out uh logs based on simple or pattern
660:03 - matching uh syntax so here I'm just
660:05 - typing in saying give me all those debug
660:07 - stuff and you know this isn't very
660:09 - robust but adus does have a better way
660:11 - of analyzing your logs which is log
660:12 - insights which we'll look at here in a
660:17 - moment so we were just looking at uh
660:20 - cloudwatch log events and how those were
660:21 - collected but there's an easier way to
660:23 - analyze them and that's with log
660:24 - insights so you can interactively search
660:27 - and analyze your cloudwatch log data and
660:28 - it has the following advantages more
660:30 - robust filtering than using the simple
660:32 - filter in the in a log stream less
660:34 - burdensome than having to export logs to
660:36 - S3 and analyze them via Athena
660:38 - cloudwatch log Insight supports all
660:39 - types of logs so cloudwatch log insights
660:42 - is commonly used via the console to do
660:44 - ad hoc queries against log groups so
660:47 - that's just kind of an example of Solon
660:49 - writing a query and cloudwatch log
660:51 - insights uses a query syntax so a single
660:54 - request can query up to 20 logs query
660:57 - time out after 50 minutes if not
660:59 - completed and queries result are
661:01 - available for 7 days so abis provides
661:04 - sample queries that you can get started
661:06 - for common tasks and uh and ease the
661:08 - learning into the query syntax a good
661:10 - example is filtering VPC flow logs so
661:12 - you go there you click it and you start
661:13 - to getting some data you can create and
661:15 - save your own queries uh to make future
661:17 - repetitive tasks easier on the certified
661:19 - Cloud preder they're not going to ask
661:20 - you all these details about this stuff
661:22 - but I just conceptually want you to
661:24 - understand that in login sites you can
661:26 - use it to uh robustly filter your logs
661:29 - based on this query syntax language you
661:31 - get this kind of visual and it's really
661:32 - really
661:36 - useful let's take a look here at
661:38 - cloudwatch metrics which represents a
661:39 - Time ordered set of data points it's a
661:41 - variable that is monitored over time so
661:43 - cloudwatch comes with many predefined
661:45 - metrics that are generally named spaced
661:46 - by adus Services uh so the idea is that
661:49 - like if we were to look at the ec2 it
661:51 - has these particular metric so we have
661:53 - CPU utilization disre Ops dis write Ops
661:57 - disre bytes disr bytes Network in
662:00 - Network out Network packet in uh Network
662:03 - packets out and the idea is that you can
662:05 - just like click there into ec2 and then
662:07 - kind of get that data there and so Cloud
662:10 - metrics are leveraged by other things
662:11 - like Cloud watch events Cloud watch
662:13 - alarms cloudwatch dashboards so just
662:16 - understand that
662:17 - [Music]
662:20 - okay all right so what I want to do in
662:22 - this follow along is show you a bit
662:24 - about cloud trail so we're going to go
662:26 - to the top here and type in cloud trail
662:28 - the great thing about cloud trail is
662:29 - it's already turned turned on by default
662:31 - so it's already kind of collecting some
662:33 - information and so here it says now use
662:36 - I access analyzer on cloud trail trails
662:38 - that sounds pretty cool to me but uh we
662:40 - shouldn't have to create a trail right
662:42 - off the bat because we'll have some
662:43 - event history and the event history
662:44 - allows us to see things that are
662:46 - happening within our account in the last
662:48 - 90 days um but the thing is if you want
662:50 - something Beyond 90 days you're going to
662:52 - have to create a trail but if we just
662:54 - take a look here we can kind of see uh
662:56 - as we've been doing a lot of things all
662:58 - the kind of actions that's been
662:59 - happening so here we have an that I
663:00 - terminated so if I go in here and and
663:03 - look at it I can kind of see uh more
663:06 - information about it so we can see when
663:08 - it terminated who had done that what
663:11 - access key they had used the Event
663:12 - Source the request
663:14 - ID um The Source IP what whether it was
663:17 - readon what was the event type that was
663:20 - called the resource there and this is
663:22 - the actual raw record so this is
663:24 - generally how I would look at it or this
663:25 - is how you had to look at it back in the
663:27 - day um but the idea is that you would
663:29 - have that uh user identity described the
663:31 - event time the source the event name the
663:33 - region The Source IP the uh the agent
663:36 - all the information there okay and so
663:38 - this is a great way to kind of find
663:40 - stuff so you can go through here and try
663:42 - to debug things this way so you can go
663:44 - to the event name and so if you if you
663:47 - go here you can kind of get uh see a bit
663:49 - of stuff here so if I was just trying to
663:51 - say like maybe create I'm just trying to
663:54 - find something that I know that I've
663:55 - been doing like create access keys I can
663:57 - see the access keys that going be
663:58 - created within this uh sandbox account
664:01 - here for the user and things like that
664:03 - so it's a great way to kind of find
664:05 - things but generally you're going to
664:06 - always want to turn on uh or create your
664:09 - own trail so if you go here and hit
664:11 - create Trail say my new Trail and um
664:14 - you're going to need an S3 bucket for
664:16 - that you'll probably want encryption
664:17 - turned
664:18 - on which sounds good to me you'll
664:20 - absolutely want log file validation and
664:23 - generally you don't want to store your
664:24 - your cloud trail logs within the
664:26 - existing account you want to have a
664:28 - isolated hardened account that that is
664:32 - uh infrequently accessed or only by your
664:35 - your Cloud security Engineers um away
664:37 - from here because you don't want people
664:38 - tampering with it deleting it or
664:39 - changing stuff but um we'll just take an
664:42 - existing one here I don't want a
664:45 - customer manage don't I have one that is
664:47 - managed by ads here new
664:52 - custom uh we'll choose that one I don't
664:55 - know which one that is we'll just hit
664:56 - next usually adab us gives you a manage
664:58 - key there so I was kind of surprised um
665:00 - you can also include additional data so
665:02 - if you do data events this would collect
665:03 - information from S3 um but the thing is
665:06 - you might not want to track everything
665:08 - because if you track to everything it
665:09 - can get very expensive very quickly uh
665:12 - but if you don't you just leave on
665:13 - management events it'll save you more
665:14 - money there's inside events uh this is
665:16 - new I haven't seen this yet so ident I
665:18 - identify unusual activity errors users
665:20 - behavior that sounds really good but
665:22 - these could come also at additional
665:24 - charges but I'm going to hit next anyway
665:25 - for fun I'm going to create that
665:28 - trail okay
665:31 - and uh the key policy does not Grant
665:33 - sufficient access to etc etc so I'm
665:36 - going to go turn that off even though I
665:37 - should really have a turned on but I
665:39 - just want to be able to show you
665:41 - this okay so we have this new
665:43 - Trail and so this Trail is being dumped
665:46 - to S3 so we might not be able to see
665:49 - anything in here as of yet but I'm just
665:51 - going to pop over here and just see
665:54 - right I probably have one in my other
665:56 - account but it's not um it's not that
665:59 - important and we basically saw what the
666:01 - data would look like so we go into here
666:03 - there's a digest I don't remember there
666:04 - being a digest so that's nice so there's
666:07 - no data yet but when there is it will
666:09 - pop into there um I'm not sure if we're
666:12 - going to be able to do anything with
666:12 - insights here at least not in this
666:15 - account insights are events that are
666:16 - show unusual API activity and things
666:19 - like that so that's kind of cool I don't
666:21 - know what cloudwatch insights looks
666:25 - like uh inside events are shown in the
666:27 - table for 90 days okay so I'm just uh
666:30 - curious if we can see kind of a
666:32 - screenshot of what that looks like
666:35 - whoops well we're at least on the
666:37 - article here so I guess you get kind of
666:39 - get like some kind of graphs or
666:40 - something saying like hey this looks
666:43 - unusual and they might select it so not
666:45 - pretty clear in terms of what that looks
666:47 - like but I mean sounds like a cool
666:49 - feature and I'm sure when I when working
666:51 - on my uh security certification course
666:53 - I'll will definitely include in there
666:55 - but that's pretty much all there is to
666:56 - it um I'm going to go ahead and delete
666:59 - um that Trail because I I just don't
667:01 - really need in this account but
667:03 - generally you always want to go in and
667:05 - create a trail um and what you can do is
667:07 - if you're in your root account I'm not
667:09 - this is actually a an account that's
667:10 - part of an organization but if you're at
667:12 - that organization level you can create a
667:14 - trail that that spands all the regions
667:17 - that spans all the ad accounts with an
667:18 - organization and that's what you should
667:20 - be doing okay but uh that's about
667:23 - [Music]
667:26 - it hey this is Andrew Brown from exam
667:29 - Pro we're looking at ML and AI services
667:31 - on AWS but let's first just Define what
667:33 - is AI ML and deep learning so AI also
667:38 - known as artificial intelligence is when
667:39 - machines that perform jobs that may make
667:41 - human behavior ml or machine learning
667:44 - are machines that get better at a task
667:45 - without explicit programming and deep
667:48 - learning or DL are machines that are
667:51 - have an artificial neural network
667:52 - inspired by the human brain to solve
667:54 - complex problems and a lot of times
667:56 - you'll see this kind of onion where
667:57 - they're showing you that um you know AI
668:01 - uh can be using ml or deep learning and
668:03 - then deep learning is definitely using
668:05 - machine learning but it's using neural
668:06 - networks and so for AWS their Flagship
668:09 - product here is Amazon sagemaker it is a
668:11 - fully managed service to build train
668:13 - deploy machine learning models at scale
668:16 - um and there's a bunch of different kind
668:17 - of Open Source Frameworks you can use
668:18 - with it like apachi mxnet ons which is
668:22 - an open source deep learning framework
668:23 - that is the one that abis decided to say
668:25 - hey we are going to back this one and so
668:27 - you'll see a lot of example code for
668:29 - that one we have tensor flow that you
668:31 - can use pie torch uh hugging face other
668:34 - things as well okay um and so there's a
668:38 - lot of uh Services underneath some that
668:40 - might be of interest to mention right
668:42 - away is like Amazon sagemaker ground
668:44 - truth which is a data labeling service
668:46 - where you have humans that label a data
668:48 - set that will be used to train machine
668:49 - learning models or maybe something like
668:51 - Amazon uh augmented AI so human
668:54 - intervention review Services when
668:56 - sagemaker uses machine learning to make
668:58 - a prediction that is not confident uh
669:00 - and it has the right answer cue up to
669:02 - the predict for a human review and these
669:04 - are all about just labeling data um you
669:07 - know when you're using supervised um
669:10 - supervised learning but there are a lot
669:12 - of Services Under sagemaker itself and
669:14 - just AI services in general so we'll
669:16 - look at that next
669:17 - [Music]
669:21 - okay all right let's take a look at all
669:23 - the ML and AI services and there's a lot
669:25 - on AWS so the first is Amazon code Guru
669:28 - this is a machine learning code anal
669:29 - service and cod Guru performs code
669:31 - reviews and will suggest to improve the
669:33 - code quality of your code it can show
669:36 - visual code profiles to show the
669:37 - internals of your code to pinpoint
669:39 - performance next we have Amazon Lex this
669:41 - is a conversation interface service with
669:44 - Lex you can build Voice and text chat
669:46 - Bots we have Amazon personalized this is
669:48 - a real-time recommendation service it's
669:50 - the same technology used to make product
669:52 - recommendations to customer shopping on
669:54 - the Amazon platform then we have Amazon
669:57 - poly this is a text to speech service
669:59 - upload your text and an audio file
670:01 - spoken by synthe synthesized voice uh
670:04 - and that will be generated you have
670:06 - Amazon recognition this is an image and
670:09 - video recognition Service uh analyze
670:12 - image and videos to detect and label
670:14 - objects peoples and celebrities then we
670:16 - have Amazon transcribe this is a speech
670:18 - to text service so you upload your audio
670:21 - and that'll be converted into text we
670:23 - have Amazon text extract this is an OCR
670:26 - tool so it extracts text from scan
670:28 - documents when you have uh paper forms
670:31 - and you want to digitally extract that
670:33 - data we have Amazon translate this is a
670:36 - neural machine learning translation
670:38 - service so use deep learning mod models
670:41 - to deliver more accurate and natural
670:43 - sounding translations we have Amazon
670:46 - comprehend this is an NLP so natural
670:48 - language processing service find
670:50 - relationships between text to produce
670:52 - insights looks at data such as customer
670:55 - email support tickets social media and
670:57 - makes
670:58 - predictions then we we have Amazon
671:00 - forecast this is a Time series
671:02 - forecasting service and it's you know uh
671:05 - I mean technically I guess it's a bit of
671:06 - a database but the idea here is that it
671:08 - can forecast business outcome such as
671:10 - product demand resource needs or
671:12 - financial uh performance and it's
671:14 - powered by ml or AI if you want to call
671:16 - it we have adabs deep learning Ami so
671:19 - these are Amazon ec2 instances they're
671:20 - pre-installed with popular deep learning
671:22 - Frameworks and interfaces such as
671:24 - tensorflow pytorch apachi mxnet chainer
671:28 - GL uh glue on uh horovod and
671:32 - kirz we have adabs deep learning
671:34 - containers so Docker images instances
671:36 - pre-installed with popular deep learning
671:38 - Frameworks and interfaces such as
671:40 - tensorflow pytorch Apachi mxnet uh we
671:44 - have adus deep composer this is machine
671:46 - learning enabled musical keyboard uh I
671:48 - don't know many people using this but it
671:49 - sounds like fun it was deep lens is a
671:51 - video camera that uses deep learning
671:53 - it's more of like a learning tool so
671:55 - again we don't see many people using
671:56 - this adus deep racer is a toy race card
671:58 - that can be powered with machine
671:59 - learning to perform autonomous driving
672:01 - again this is another learning tool for
672:03 - learning ml they like to do these at
672:05 - reinvent to have like these racing
672:07 - competitions Amazon elastic interface so
672:09 - this allows you to attach lowcost GPU
672:11 - perform uh powered acceleration to ec2
672:14 - instances to reduce the cost of running
672:15 - deep learning interfaces by
672:17 - 75% we have Amazon fraud detector so
672:20 - this is a fully managed fraud detection
672:22 - uh as a service uh it identifies
672:25 - potentially fraudulent uh online
672:26 - activities such as online payment fraud
672:28 - and the creation of fake accounts
672:30 - Amazon Kendra so this is an Enterprise
672:32 - machine learning search engine service
672:34 - it uses natural language to suggest
672:36 - answers to questions instead of just
672:38 - simple keyword matching so there you
672:40 - [Music]
672:44 - go hey it's Andie Brown from exam Pro
672:46 - and we're going to do a quick review
672:48 - here of the big data and analytic
672:49 - services that are on AWS but before we
672:52 - do let's just Define what big data is so
672:55 - it's a term used to describe massive
672:57 - volumes of structured or unstructured
672:58 - data that is so large it is difficult to
673:01 - move and process using traditional
673:04 - database and software techniques so the
673:06 - first here we have is Amazon Athena this
673:09 - is a serverless interactive query
673:11 - service it can take a bunch of CSV or
673:14 - Json files in an S3 bucket and load them
673:16 - into a temporary SQL table and so you
673:19 - can run SQL queries so it's when you
673:21 - want to quate CSV or Json files if
673:24 - you've ever heard of um apachi Presto
673:27 - it's basically that okay then we have
673:29 - Amazon Cloud search so this is a fully
673:31 - managed full teex search service so when
673:33 - you want to add search to your website
673:36 - we have Amazon elastic search service um
673:39 - commonly abbreviated to es and this is a
673:42 - manage elastic search cluster and
673:44 - elastic search is an open source full
673:46 - Tech search engine it is more robust
673:48 - than Cloud search but requires more
673:49 - server and operational maintenance then
673:52 - we have Amazon elastic map produce
673:54 - commonly known as EMR and this is for
673:57 - data processing and Analysis it can be
673:59 - used for creating reports just like red
674:01 - shift but is more suited when you need
674:02 - to transform unstructured data into
674:04 - structured data on the Fly and it
674:06 - leverages opsource um technology so like
674:09 - spark um Hive Pig things like
674:13 - that then we have Kinesis data Stream So
674:15 - This is a real-time streaming data
674:17 - service it creates producers uh which
674:19 - sends data to a stream it has multiple
674:22 - consumers that can consume data within a
674:24 - stream and use uh it for realtime
674:26 - analytics click streams ingestion data
674:28 - from Fleet of iot
674:30 - devices then we have Kinesis fire hose
674:33 - this is a serverless and a simple
674:35 - version of a data stream and you pay on
674:38 - demand based on how much data is
674:40 - consumed through the stream and you
674:41 - don't worry about the underlying
674:43 - servers then you have Amazon Kinesis
674:45 - data analytics this allows you to run
674:48 - queries against data that is flowing
674:49 - through your real-time stream so you can
674:51 - create reports and Analysis on emerging
674:53 - data and last on the Kinesis side here
674:56 - we have Amazon Kinesis video streams
674:58 - this allows you to analyze or apply
675:00 - processing on real-time streaming videos
675:02 - onto the second page here we have manage
675:05 - kofka service
675:06 - msk um and it might be MKS um now that
675:10 - I'm looking at it here so just be aware
675:12 - that that might be incorrect but a fully
675:14 - manage Apachi kofka service kofka is an
675:17 - open-source platform for building
675:19 - real-time streaming data pipelines and
675:21 - applications it is similar to Kinesis
675:23 - but with more robust functionality then
675:25 - we have red shift which is um a with is
675:28 - flagship
675:29 - uh Big Data tool it's a petabyte size
675:32 - data warehouse the data warehouses are
675:34 - for online uh online analytical
675:38 - processing olap so data warehouses can
675:40 - be expensive because they are keeping
675:41 - data hot meaning that we can run a very
675:43 - complex query in a large amount of data
675:45 - and get that data back very fast but
675:47 - this is great when you need to quickly
675:48 - generate analytics or reports from a
675:50 - large amount of data we have Amazon
675:52 - quick site this is a business
675:53 - intelligence tool or a business
675:55 - intelligence dashboard bi for short you
675:57 - can use it to create business dashboard
675:59 - to power business decisions it requires
676:01 - little to no programming and connect and
676:03 - adjust to many different types of
676:04 - databases if you ever heard of Tableau
676:06 - or powerbi this is just the adus
676:09 - equivalent we have adus data pipelines
676:11 - this automates the movement of data you
676:14 - can reliably move data between compute
676:15 - storage and services we have adus glue
676:19 - this is an ETL service so it allows you
676:21 - to move data from one location to
676:22 - another where you need to perform
676:24 - Transformations before the Final
676:25 - Destination it's simar similar to DMS
676:27 - but it's more robust
676:29 - we have AB Lake formation this is a
676:32 - centralized curated and secured
676:34 - repository that stores all your data so
676:35 - it's a data Lake it uh is a storage
676:37 - repository that holds a vast amount of
676:39 - raw data in its native format until it
676:41 - is needed and then last on here we have
676:43 - adab data exchange this is a catalog of
676:45 - third-party data sets you can download
676:47 - for free uh or subscribe or purchase
676:49 - data sets so they might have like the
676:51 - covid-19 foot traffic data the IMDb TV
676:54 - movie data historical weather data and
676:57 - sometimes this is really great if you're
676:58 - just trying to learn how to to work with
676:59 - these tools
677:00 - [Music]
677:04 - okay hey this is Andrew Brown from exam
677:06 - Pro and we are taking a look here at
677:07 - Amazon quick site which is a business
677:09 - intelligence dashboard or bi dashboard
677:11 - that allows you to ingest data from
677:13 - various databus storage or database
677:14 - services to quickly visualize business
677:16 - data with minimal programming or data
677:18 - formula knowledge so here's an example
677:21 - of a quick site dashboard um and so the
677:25 - way quick site is able to make these
677:27 - dashboards super fast is if you have
677:28 - spice the super fast parallel inmemory
677:30 - calculation engine um and the thing is
677:33 - you don't have to use spice um but
677:35 - generally it is good to use it uh and
677:37 - there are some caveats when getting your
677:39 - data into Quick site sometimes it can't
677:41 - ingest data directly from a particular
677:43 - uh data store so you might have to dump
677:45 - it to S3 first but it's not too bad
677:47 - because you can use AIS glue to
677:48 - transform that data over um there are
677:51 - additional features sometimes Market is
677:52 - services but we have quick site ml
677:55 - insights this detects anomalies perform
677:57 - accurate uh forecasting it can generate
677:59 - natural language narrative so basically
678:01 - like you know describe it as if you're
678:03 - going to read it out as a business
678:04 - report you know then there's Amazon
678:06 - quick site Q this allows you to ask
678:08 - questions using natural language on all
678:10 - your data and receive answers in seconds
678:12 - so there you
678:13 - [Music]
678:16 - go hey this is Andrew Brown from exam
678:19 - Pro and let's go take a look at Amazon
678:21 - quick sites which is a or quick site
678:23 - which is um a business intelligence tool
678:26 - so when you go here you have to uh sign
678:28 - up because it's kind of part of ads but
678:31 - on its own separate thing and then you
678:33 - have to choose what you want so we have
678:34 - Enterprise and standard um I do not want
678:39 - to pay that much so I'm going to go to
678:40 - standard over here I'm not really sure
678:42 - what the difference is it's not really
678:43 - telling me what um between standard and
678:48 - Enterprise but I'm going to assume
678:49 - standard is more cost effective but here
678:52 - we it says user use I am Federated
678:55 - identities which is fine use I am
678:58 - Federate enties only um we can stick
679:01 - with the top one there that seems fine
679:03 - to me we need to enter a name so just
679:06 - say my quick site
679:10 - account and we probably have to fill
679:13 - something in there so let's say Andrew
679:14 - exam pro. and these are the services
679:16 - that are going to integrate with Athena
679:18 - S3 RDS things like that I guess we could
679:20 - select some of those buckets I'm not too
679:22 - worried about doing that right now the
679:23 - provided account name is not available
679:25 - that is a terrible UI but that's AWS for
679:28 - you I'm just going to dump some numbers
679:30 - there going put my email in here
679:33 - again um we probably want some S3
679:36 - buckets I'm going
679:39 - to make a new
679:41 - bucket because I think that's how we're
679:43 - going to do this we're going to have to
679:44 - make a bucket here and say uh quick
679:47 - site
679:50 - data okay and we're going to create
679:52 - ourselves a bucket here I'm going to go
679:55 - back and hopefully that shows
679:57 - up
679:59 - uh it does not so what I'll have to do
680:01 - is just back
680:04 - out and I'm just going to give it a hard
680:06 - refresh here and we're hit quick sign up
680:08 - for quicksite again and we'll choose
680:11 - standard and we'll say my quick site
680:14 - account a bunch of numbers there Andrew
680:17 - exam pro. I don't really care about
680:19 - adjusting data from everywhere else I
680:20 - just want it from
680:22 - S3 there's my
680:24 - data uh sure we'll give it right
680:26 - permissions even though I don't plan to
680:27 - do anything with Athena here today
680:34 - he and we'll give it a moment to
680:39 - load so what I'm thinking
680:45 - is so what I'm thinking is just making
680:47 - like an Excel spreadsheet here and just
680:50 - filling in some data so oh says our
680:52 - account is set up here so we'll go to
680:54 - Quick site because I bet it can import
680:56 - like a CSV or something
680:59 - um I'm more of a tableau or powerbi kind
681:01 - of person um but uh you know for the
681:04 - purpose of the cloud practitioner I am
681:05 - going to show you this Amazon quick set
681:07 - lets you easily visualize data and Etc
681:10 - that sounds great next next next I know
681:12 - what I'm doing oh do we have some
681:14 - examples great so I don't even have to
681:15 - make a spreadsheet okay so what we'll do
681:17 - is just click on
681:20 - that and we have stuff it looks like
681:23 - they've really improved this since the
681:24 - last time I've seen it which is quite
681:27 - nice
681:29 - um but I could try and make my
681:33 - own I'm just trying to think how do we
681:36 - do this
681:38 - again yeah we have the spice there so
681:40 - it's a lot easier from starting from
681:41 - scratch I'm just going to say
681:42 - close
681:44 - and user analysis we want data sets in
681:47 - here oh we already have some data sets
681:50 - these are coming from S3 I think that's
681:52 - the old S3 logo I'm not sure why they're
681:54 - using that one we can go here and create
681:56 - a new data set oh we can upload directly
681:57 - so I don't even have to use use S3
681:59 - that's great so what I'm going to do is
682:00 - just have some values in here so I'm
682:02 - going to just say
682:05 - um uh type value so we'll say
682:11 - banana 125 123 we'll say
682:15 - apple
682:17 - 11
682:18 - orange nobody likes
682:21 - oranges I shouldn't say I'm sure it's
682:23 - like lots of people like
682:24 - oranges oh we got to put pairs on
682:27 - there
682:29 - I actually really like pairs people
682:30 - think I like bananas which is not true I
682:32 - actually like pears that's what I like
682:35 - so I'm going to go ahead and save this
682:37 - save
682:39 - as and I'm just going to save this to my
682:42 - desktop here so just give me a moment
682:43 - just doing this offc
682:46 - screen and I'm just save this uh data
682:50 - set quick
682:51 - site CSV it can even take an XLS so I
682:55 - don't have to save it as a uh I'll just
682:58 - save it as a an
682:59 - XLS okay and so we're going to just
683:01 - upload that so there is that data
683:04 - set it's going to scan that file it's
683:07 - going to see that sheet you even preview
683:11 - it there's the information we're going
683:13 - to add that
683:15 - data uh I get add it as a data data
683:20 - set well how do I where where do I it's
683:24 - like it says add the data I just want to
683:26 - add it as a data set so they said up
683:28 - here save and visualize up
683:31 - here and is it autographing yet maybe if
683:35 - I drag in is it working is it thinking
683:37 - okay it's at 100% so I'm going to just
683:40 - drag that onto
683:43 - there and it says pear orange
683:48 - banana just kind of trying to make sense
683:50 - of this here is it taking and count the
683:52 - value maybe put the value down there wow
683:55 - that's so much easier I hav't used this
683:57 - for like a year and and um I'm going to
683:59 - tell you this has gotten a lot easier to
684:00 - use so I'm quite impressed with this but
684:03 - yeah I mean this is pretty much what
684:04 - quick site is if you want to visualize
684:06 - things in different types you can drag
684:07 - them out you can probably like click on
684:09 - the the wheel here and change
684:11 - it again I'm not
684:13 - sure exactly how all the uh the dials
684:18 - and knobs work here but I mean another
684:20 - thing we could do is just drag out like
684:21 - another object and do the same thing so
684:23 - maybe I'd want a pie
684:25 - chart um
684:27 - so uh a
684:30 - visual yeah it's not as nice as powerbi
684:33 - but like it's still great that it's here
684:34 - you know type
684:37 - value so we got a nice pie chart
684:40 - there uh let's try something weird let's
684:43 - give this one a
684:45 - go doesn't color it which is not very
684:47 - nice um there's probably some kind of
684:49 - way to color it but focus on banana only
684:53 - I don't know I don't know what the point
684:54 - of there but anyway that's quick sight
684:56 - so um I really don't want to pay for
684:58 - this this so what I'm going to do is go
685:00 - up
685:01 - here um there's you have to deactivate
685:04 - I'm just trying to remember
685:05 - how because they change the interface
685:08 - again they change everything on
685:10 - you so maybe we go I'm on a trial for
685:13 - four days here maybe quantity for just
685:16 - the four 29 day trial so if I want to
685:19 - get out of this trial what do I do I
685:22 - don't want to use it anymore um
685:26 - so how to delete AWS quick
685:32 - site canceling your subscription so
685:35 - before you can unsubscribe uh you're
685:37 - signed in the IM account you're quick
685:39 - site administrator you're the root IM
685:41 - administrator sure uh you deleted any
685:44 - secondary name spaces to find the
685:46 - existing name space Etc so choose your
685:49 - username in the application bars manage
685:51 - quick site account settings
685:53 - unsubscribe so I was almost there I
685:56 - thought I was in the right place
686:00 - uh this one
686:02 - no I was just
686:05 - there manage quick
686:07 - site your
686:11 - subscriptions
686:13 - edit there's no unsubscribe
686:15 - option so I'm not
686:18 - sure can I
686:24 - cancel
686:27 - unsubscribe
686:30 - button does not appear in quick
686:45 - site and it could just be because we're
686:47 - on trial and so maybe after the end of
686:48 - the trial it will uh it will vanish
686:52 - there they are not making this easy for
686:54 - me account settings ah delete accounts
686:57 - so this is what we're probably want to
686:58 - do permanently delete the account
687:00 - yes I mean that has to get rid of the
687:02 - subcription because it gets rid of
687:04 - everything there we
687:06 - go we'll say
687:09 - confirm delete
687:12 - account unless you're using them in the
687:14 - services blah blah blah blah blah um
687:17 - successful okay great so now I should go
687:19 - back to ads. amazon.com and just to
687:22 - confirm that it's gone I'm going
687:25 - to go to quicksite again and just see if
687:29 - it's trying to ask me to sign again so
687:31 - it is so I've gotten R of my account so
687:33 - we're all in good shape and uh yeah that
687:35 - is that is quick
687:39 - site all right let's take a look at some
687:42 - more machine learning AI Services
687:44 - because eight of us won't stop making
687:45 - these things um and basically last time
687:48 - I made uh the videos all this generative
687:50 - stuff did not exist so we need to cover
687:52 - it the first is Amazon Bedrock so the uh
687:55 - this uses large language models and
687:57 - makes it a cloud service is offering to
687:58 - generate text and images responses if
688:00 - you know what chat GPT is you know what
688:02 - Bedrock is we have Amazon code Whisperer
688:05 - it's an AI code generator that will
688:06 - predict code to meet your use case uh so
688:09 - if youve heard ever heard of GitHub
688:10 - co-pilot it's the same thing basically
688:13 - uh it's going to write code for you or
688:16 - along with you I should say uh we have
688:18 - Amazon devops Guru this uses ml or
688:21 - machine learning to analyze your
688:22 - operational data and application metrics
688:24 - and the vents to detect operational
688:26 - abnormalities um imagine if you had kind
688:30 - of like a junior devops person digging
688:32 - into your metrics to figure out if
688:34 - there's something wrong then we have
688:36 - Amazon Lookout this is actually three
688:38 - different um offerings we have Amazon
688:39 - lookout for equipment Amazon uh lookout
688:41 - for metrics and Amazon lookout for
688:44 - vision they all seem to have to do
688:46 - something with quality control and
688:48 - Performing automated inspection so
688:50 - vision of course would use Vision to
688:52 - detect anomalies uh one would be for
688:54 - equipment to detect if there's anything
688:56 - wrong with operational equipment uh and
688:58 - then metrics would be you know with
689:00 - metric data so something probably more
689:03 - for um the hard Industries uh to
689:05 - utilized and you have Amazon monotron so
689:08 - this uses machine learning models to
689:10 - predict unplanned equipment downtime and
689:12 - so the way they do that is they have
689:13 - these uh iot sensors that's going to
689:16 - capture vibrations and sensor data from
689:19 - your Hardware then we also have adus
689:21 - neuron this is an ad SDK used to run
689:24 - deep learning workloads on adus uh infer
689:28 - I can't say that word but I know what it
689:29 - is it's basically um it's a machine
689:33 - learning acceleration on gpus that you
689:35 - can attach and adus train
689:39 - trainum so yeah I wish the words weren't
689:41 - so hard there's actually more um stuff
689:44 - that Aus has for machine learning I
689:46 - didn't include them because they were
689:47 - just too far out there and they're
689:49 - definitely not going to show up in your
689:50 - exam you'll definitely never see them
689:52 - but we now have better coverage what I
689:54 - really wanted to show was Bedrock H
689:56 - Whisperer because I feel like those two
689:59 - uh will show up on future exam so I'm
690:01 - just trying to get those in front of you
690:02 - now even if they're not on the exam uh
690:05 - at the time of this recording okay
690:08 - [Music]
690:11 - ciao all right so you probably already
690:14 - know what generative AI is but just in
690:16 - case you don't I want to just quickly
690:18 - cover it and show a very tiny example uh
690:21 - so generative AI which also can be
690:23 - shorten to gen AI though most people
690:26 - don't say that uh is a type of
690:28 - artificial intelligence capable capable
690:30 - of generating new content such as text
690:32 - images music or other forms of media so
690:36 - an example would be something like a
690:37 - software that I like to use called mid
690:39 - Journey uh where you can put in a prompt
690:42 - and so it will then go ahead and
690:43 - generate out an image um so all the
690:47 - cloud service providers have some kind
690:48 - of offering with both image and text um
690:52 - but yeah hopefully that makes sense the
690:53 - idea is that you can plug stuff in and
690:56 - you get stuff out okay
690:58 - [Music]
691:03 - Let's us take a look here at machine
691:04 - learning and deep learning Frameworks
691:06 - and so these are Frameworks that can be
691:09 - used with sagemaker or have direct
691:10 - support for them I just want to get you
691:12 - some uh exposure and to uh get you some
691:16 - context in terms of these because
691:18 - machine learning and Ai and all this
691:20 - stuff is becoming more popular so you
691:21 - should at least have heard of these
691:23 - things so I have all the logos on the
691:25 - left hand side and we'll go through them
691:27 - the first is Apachi mxnet so this is a
691:31 - machine learning framework adopted by
691:33 - AWS basically um every single cloud
691:36 - service provider backs their own kind of
691:38 - open- source framework and they try to
691:41 - make that the one that they suggest you
691:43 - to use but in practice uh there's ones
691:45 - that are good and there's ones that
691:46 - people just don't want to use and apach
691:48 - mxnet is not fun to use whatsoever um
691:51 - and so you'll see it all over in the
691:53 - marketing and pushed everywhere but
691:54 - really people want to use things like
691:56 - curus tensorflow but anyway I just
691:58 - wanted to point that out that it was has
692:00 - a bias because they've invested energy
692:02 - into uh their team of machine learning
692:05 - Frameworks you got pytorch uh optimized
692:08 - for tensor Library uh for deep learning
692:10 - using GPU and CPU it's created by
692:12 - Facebook Facebook does not necessarily
692:15 - um have its own cloud service provider
692:17 - offering so it's kind of out there and
692:19 - so you'll see good support for pytorch
692:22 - and all the major providers U the next
692:24 - is tensorflow this is made by Google
692:27 - what's in with tensor flow is Google
692:29 - made uh their own um GPU or TPU they
692:33 - call it a tensor Processing Unit so
692:36 - tensor is a a unit of thing in tensor
692:39 - flow and it they have optimized hardware
692:41 - for it I personally find tensorflow the
692:44 - easy to use or I should say cires so um
692:47 - cures is a highlevel machine learning
692:49 - framework built on top of tensorflow
692:51 - because these lower level ones were just
692:53 - really hard to use and so basically
692:54 - pytorch came along and it was much
692:56 - easier to use and then then everyone
692:58 - noticed how easier pytorch was and so
693:01 - that's where curus came from was to be
693:04 - competitive with pytorch and be easier
693:06 - to use then you have Apachi spark which
693:08 - is a unified analytics engine for large
693:10 - scale data processing but they do have
693:12 - ml offerings within it called spark ml
693:15 - um so there's definitely things you can
693:16 - do there uh there's a piece of software
693:18 - called chainer um and it's for it's a
693:21 - deep learning framework that supports
693:22 - Cuda then there's hugging face which is
693:25 - not exactly a framework or tool it's
693:27 - just a way of accessing a lot of models
693:30 - online and data sets and quickly
693:32 - launching them for whatever reason I uh
693:35 - adus has uh strong synergies with
693:37 - hugging face I've seen like developer
693:39 - Advocates and other uh folks that worked
693:41 - at AOS go over to hugging face and so
693:43 - there seems to be strong uh
693:45 - relationships between hugging face and
693:48 - adabs for whatever reason there's a lot
693:50 - of ml Frameworks out there but because
693:52 - uh ml is uh just uh
693:56 - progressively um are rapidly innovating
693:59 - you'll see Frameworks come and go and so
694:01 - I remember when I researched this and I
694:02 - was just trying to understand all the
694:03 - Frameworks out there there's just a lot
694:06 - and I just kept digging into them
694:07 - finding oh they're not active anymore
694:08 - they're not active anymore so I just
694:10 - want to point out that we have all these
694:11 - ones up on screen if they become
694:13 - unactive tomorrow I would not be
694:15 - surprised but uh for the most part all
694:17 - of these seem to be very popular uh and
694:20 - uh they're being well supported uh but
694:22 - yeah hopefully that gives you an idea of
694:23 - these Frameworks okay
694:26 - ciao
694:28 - [Music]
694:30 - all right let's take a look here at
694:31 - Apachi mxnet a little bit more in detail
694:34 - because this is the framework that iTab
694:35 - us wants you to use whether you want to
694:37 - use it or not is a different story uh
694:39 - but you'll see it all over in their
694:41 - marketing pages and things like that so
694:43 - apoi mxnet is a deep learning machine
694:45 - learning framework which supports many
694:46 - many different programming languages so
694:48 - that is one advantage of it uh the key
694:51 - features uh is that it's scalable it's
694:53 - flexible it's portable it's it supports
694:55 - multiple programming language iTab has
694:58 - made Apachi mxnet their framework of
695:00 - choice so there's lots of support for it
695:03 - within ad sagemaker and the ad ml
695:05 - containers but I have noticed that
695:06 - they've been increasing support for p
695:08 - torch so maybe you know they're just
695:10 - trying to meet the customer where they
695:12 - are but anyway um there is a lot of
695:15 - stuff for mxnet mxnet has two highlevel
695:18 - interfaces uh one's called glue on and
695:22 - there is module API so uh depending on
695:24 - which one you use one is imperative
695:26 - programming one's symbolic programming
695:28 - uh this is more of a deeper concept for
695:30 - machine learning but I'm going to tell
695:31 - you one is really easy one is really
695:33 - hard um but uh let's look at a very
695:36 - simple example of uh some code for using
695:39 - the gluon API so it kind of looks like
695:41 - that you can see that they are using
695:42 - python so hopefully that gives you an
695:44 - idea of uh mxnet and its offering the
695:47 - key thing is that it offers it in a lot
695:49 - of different programming languages will
695:51 - this appear on your exam absolutely not
695:53 - but should you know it you absolutely
695:55 - should um just so you have good context
695:57 - with adabs and ml so there you
696:00 - [Music]
696:03 - go I want to talk a little bit about
696:05 - Intel because I think it's very
696:07 - important to remember the hardware that
696:08 - is running with these um cloud service
696:11 - providers because it really does matter
696:14 - um and there's a couple terms you might
696:16 - see when using a compute that you're not
696:19 - aware of and I want to make sure you
696:20 - know what they are so let's talk about
696:21 - what is Intel so Intel is a
696:22 - multinational corporation is one of the
696:25 - world's largest semiconductor chip
696:27 - manufacturers Intel is the inventor of
696:29 - the
696:30 - x86 instruction set so basically uh they
696:34 - released this chip back in 1978 this
696:36 - one's called the Intel 88086 chip and
696:39 - the idea is that um they came up with an
696:41 - instruction set um it's basically a
696:43 - bunch of words that you can use um to
696:46 - program the chip and it's a lower level
696:48 - language so um that lower level language
696:50 - would be an assembly um if if that makes
696:53 - any sense so the idea is that you have
696:56 - this um
696:57 - instruction set and you have to write an
697:00 - assembly and so basically most modern
697:02 - programs like when you use uh
697:03 - programming languages like uh C it will
697:06 - actually compile down to assembly um or
697:09 - other languages will compile down to
697:11 - assembly because that is what the chip
697:13 - understands and then assembly is turned
697:14 - into machine code like the zeros and
697:17 - ones and the reason I'm mentioning this
697:19 - is that when you go and you uh launch uh
697:22 - a compute uh instance let's say on ads
697:25 - uh you're launching a E2 instance you
697:28 - have to choose uh whether it's x86 or a
697:31 - different instruction set or
697:32 - architecture and so the other one is arm
697:35 - and they're both really really good it
697:36 - just depends on whether uh uh your stuff
697:39 - can support it but for the most part
697:41 - Intel has arm chips as well so um there
697:44 - is no company that produces armed chips
697:46 - per se it's just an architecture and uh
697:49 - the way it works is that it just has
697:51 - fewer instruction sets so there's fewer
697:53 - uh rules that you can write in so it's a
697:56 - more limited writing it in assembly but
697:58 - at the end of the day it doesn't matter
697:59 - because your programming language is
698:00 - going to compile it down so you don't
698:02 - have to worry about those fewer
698:03 - instructions but because it has fewer
698:05 - instructions it generally results in a
698:07 - better uh Power efficiency and so it can
698:10 - have better performance or better or
698:12 - better cost to you the customer so when
698:15 - I can I try to run arm and for the most
698:18 - part it's always great to run arm but uh
698:20 - it really depends on if your software is
698:22 - going to be able to run on arm um and
698:24 - stuff like that so I just wanted to
698:25 - point out those two things
698:27 - there about uh at least Intel and then
698:30 - instruction sets
698:32 - [Music]
698:35 - okay all right I want to talk about two
698:37 - things um that Intel has with ads and
698:40 - the first is Intel xon scalable
698:42 - processor and the second is Intel Gotti
698:44 - um so it of course does work with or
698:47 - purchases um Hardware from other um uh
698:50 - other companies like they use AMD and
698:52 - Nvidia but I think it's worth mentioning
698:55 - Intel in a little bit more detail here
698:57 - here because every time I go to reinvent
699:00 - Intel has a big giant booth and you can
699:03 - go scour the ads website and it just
699:05 - looks like ADS works more closely with
699:07 - Intel as opposed to the other uh
699:10 - providers not to say that Intel is not
699:12 - being utilized on gcp and Azure and
699:15 - others but uh I just noticed something
699:17 - more going on there with AWS but let's
699:19 - first talk about Intel xon scalable
699:21 - processors these are high performance
699:22 - CPUs designed for Enterprise and server
699:24 - applications commonly used in ESS
699:26 - instances
699:27 - um that scalable part makes them very
699:29 - good for machine learning so you often
699:32 - are going to be be using Intel xon
699:34 - processors whether you know or not on
699:36 - ads the Intel is the Intel uh Habana
699:40 - Gotti processor so this is a uh
699:43 - processor specialized for AI training uh
699:46 - you could say that this is a direct
699:48 - competitor to Nvidia or a similar
699:50 - competitor because uh they uh they uh do
699:54 - something very similar um I believe that
699:57 - Intel Gotti has their own SDK called
699:59 - synapse AI uh that you can use to
700:02 - interact with it so you launch up Sage
700:05 - maker and then use uh that uh that API
700:08 - or SDK in order to uh best utilize uh
700:12 - that Hardware there but both of these um
700:14 - pieces of Hardware are offered uh on a
700:18 - and I think it's just good to know them
700:19 - at least to name uh what they are
700:22 - [Music]
700:25 - okay hey this is angrew brown and let's
700:28 - talk about gpus I'm sure most people
700:30 - know what gpus are here but I'm going to
700:32 - talk about it anyway because I want to
700:33 - talk about cudas so a GPU stands for
700:36 - General processing unit and it's a
700:38 - processor that is specialized to quickly
700:40 - render high resolution images and videos
700:42 - concurrently if you've ever played video
700:45 - games you know you need a good GPU
700:47 - because it's all about those images
700:49 - however gpus can perform parallel
700:52 - operations on multiple sets of data so
700:54 - they can also be used for non-graphical
700:56 - tasks and this makes it really good for
700:58 - machine learning and scientific
701:00 - computation so if you're trying to uh
701:03 - convince your significant other that you
701:05 - need a better graphics card you can just
701:06 - tell them it's for work I need it for
701:07 - machine learning and scientific comp
701:09 - computation it's not your fault that you
701:11 - can also play video games with it and so
701:14 - we have like a graphic there on the
701:15 - right hand side I think I got that from
701:17 - Nvidia and so they're kind of trying to
701:19 - demonstrate the difference between uh
701:21 - the paralyzation with GPU versus serial
701:24 - tasks with CPU but let's go and just
701:26 - read a littleit more so CPUs can have an
701:28 - average of four to 16 processor cores
701:30 - gpus can have thousands of processor
701:33 - cores how that works I have no idea but
701:36 - I just know that that's how it works uh
701:39 - so we have 48 gpus can provide as many
701:41 - as 40,000 cores so that is a lot gpus
701:46 - are best suited for repetitive and
701:47 - highly parallel Computing tasks such as
701:49 - rendering Graphics cryptocurrency mining
701:52 - if people are even still doing that and
701:54 - deep learning and machine learning so
701:56 - you know there you go that's
702:00 - [Music]
702:03 - gpus all right let's take a look here at
702:05 - Cuda but before we do let's talk about
702:07 - Nvidia so Nvidia is a company that
702:10 - manufactures graphical processing units
702:12 - for gaming and professional markets if
702:14 - you have ever played video games and you
702:16 - build your own rig um a lot of people
702:19 - like to choose Nvidia but Nvidia can do
702:21 - things other than video games and this
702:24 - is due to their framework uh called Cuda
702:27 - which stands for compute unified device
702:29 - architecture so it's a parallel
702:31 - Computing platform and API I said
702:33 - framework but I guess it's an API by a
702:35 - video that allows developers to use Cuda
702:37 - enable gpus for general purpose
702:39 - Computing gpus and it says GP GPU
702:43 - because it's saying general purpose gpus
702:45 - I know that's a mouthful there um so
702:48 - over on AWS they have a bunch of
702:51 - instances that um can utilize uh Nvidia
702:55 - GPU so I adus is always changing the
702:58 - instances so these could be old but you
703:01 - can see we have a P3 which has the Tesla
703:04 - Tesla V100 you have the G3 with a Tesla
703:07 - M M60 the G4 with the T4 uh the P4 with
703:11 - the Tesla a 100 so there's probably
703:15 - these are probably old ones there's new
703:16 - instances with newer Nvidia cards but my
703:19 - point is is that adus has uh gpus that
703:22 - you can utilize another thing I want to
703:24 - point out with Cuda is that all major
703:26 - deep learning Frameworks are integrated
703:28 - with Nvidia deep learning sdks there's a
703:31 - big fight or War over um uh these
703:34 - companies that make uh gpus and CPUs
703:37 - because they really want the uh Theirs
703:39 - to be used for machine learning so you
703:41 - can definitely be sure that AMD probably
703:43 - has some kind of similar offering or
703:45 - something uh and definitely Intel as
703:47 - well um but Nvidia has done a very good
703:50 - job in uh making sure that theirs is the
703:52 - most popular um so EnV deep learning SDK
703:55 - is a collection of uh Nvidia libraries
703:58 - for deep learning so this is something
704:00 - that this is the SDK you can use with
704:01 - Cuda to interact with their API uh so
704:04 - one of those libraries are called cuda
704:06 - deep neural network library so that's
704:09 - something you can use with it and it's
704:11 - uh tuned for a bunch of stuff if it
704:13 - looks like it's getting a little bit too
704:15 - um uh technical it's because this slide
704:18 - was was for my machine learning uh
704:21 - inabus specialty and I didn't do a whole
704:23 - lot to change it and Brad it over uh so
704:25 - you don't don't really need to know that
704:27 - last part there but just understand what
704:28 - Cuda is and that it's uh very important
704:32 - uh for working with machine learning and
704:34 - AD us has uh good offerings uh for
704:36 - instances with it
704:39 - [Music]
704:42 - okay hey this is Andrew Brown from exam
704:45 - Pro and we are taking a look at the ads
704:47 - well architectur framework so this is a
704:49 - white paper created by AWS to help
704:51 - customers build using best practices
704:53 - defined by AWS you can find this at AWS
704:57 - amazon.com architecture forwell
704:59 - architected this idea is not unique to
705:01 - AWS the other providers have it but I
705:03 - believe AWS was the first one to Define
705:05 - this and they have a really good uh a
705:08 - good approach to this and this is pretty
705:11 - much Essential Knowledge that you have
705:12 - to have uh four certifications when
705:14 - we're looking at the cloud practitioner
705:16 - the soci architect associate and
705:17 - professional because um there's a lot of
705:20 - principles here best practices that adus
705:22 - uses themselves to architect their
705:24 - infrastructure okay so the framew is
705:26 - divided into five sections called
705:28 - pillars which address different aspects
705:30 - or lenses that can be applied to a cloud
705:33 - workload so imagine you have your Cloud
705:35 - workload you're going to want to adopt
705:36 - an aable architect framework some things
705:39 - that you know people don't consider
705:40 - outside the Five Pillars is that you
705:42 - need to know General definitions uh
705:44 - General design principles and the review
705:46 - process um and then from there you have
705:48 - your five pillars so you have
705:49 - operational excellence security
705:51 - reliability performance efficiency and
705:54 - cost optimization and all of these have
705:55 - major SE sections in this uh white paper
705:58 - but outside of just the main white paper
706:01 - each of these have their own white
706:02 - papers that go even into farther detail
706:05 - so if you really want to uh really focus
706:07 - on security and get a lot more
706:08 - information they have that as well
706:11 - [Music]
706:15 - okay let's take a look at the general
706:17 - definitions for the well architecture
706:19 - framework starting with the pillars so
706:20 - the operational excellent pillar is
706:22 - there to run and monitor systems the
706:25 - security pillar is to protect data and
706:27 - systems to mitigate risk the reliability
706:29 - pillar is to mitigate and recover from
706:32 - uh disruptions the performance
706:34 - efficiency pillar is about using
706:36 - Computing resources efficiently or
706:38 - effectively and the cost optimization
706:40 - pillar is about getting the lowest price
706:42 - and this is where you're going to find
706:43 - all the business value and I put an
706:45 - aster there because uh you know you
706:48 - might obsess saying we need to meet the
706:50 - requirements for all these pillars and
706:51 - that's not the case you can trade off
706:53 - pillars based on the business context so
706:55 - you know don't take it as uh literally
706:58 - Implement every single thing but just
707:00 - consider that uh you know you might have
707:02 - to adapt it based on your workloads then
707:04 - we have some general definitions that we
707:05 - will come across so there's components
707:07 - so code configuration itless resources
707:09 - against the requirement a workload so a
707:11 - set of components that work together to
707:13 - deliver business value mileston so key
707:16 - changes of your architecture through the
707:18 - product life cycle then there's
707:19 - architecture itself so how components
707:21 - work together in a workload and then we
707:23 - have technology portfolio so a
707:25 - collection of workloads required for the
707:28 - business to operate
707:30 - [Music]
707:34 - okay so the well architected framework
707:36 - is designed around a different kind of
707:38 - team structure so when you're looking at
707:40 - Enterprises they generally have a
707:42 - centralized team with specific roles
707:45 - where ADS structures their teams as
707:47 - being distributed with flexible roles
707:49 - and so this new kind of methodology of
707:51 - distributed teams uh has some major
707:54 - advantages but it does come with some
707:55 - risks and so adus has baked in some uh
707:58 - practices or uh things that they do to
708:00 - mitigate these issues okay so let's
708:02 - compare on premise Enterprise uh to what
708:04 - databus is proposing for your team
708:06 - structure so on premise what we'd see is
708:09 - a centralized team consisting of
708:10 - technical Architects solution Architects
708:13 - data Architects Network Architects
708:15 - security Architects and you kind of see
708:17 - that they all have a specialized
708:19 - vertical and they are usually managed by
708:21 - either to GF or Zack man framework so
708:26 - those are just ways of structuring your
708:27 - teams those are very popular and so what
708:29 - aabus is proposing here is that you have
708:31 - a distribute team and uh the way you're
708:33 - going to make that team work because
708:35 - obviously just thinking about distribute
708:36 - team they're going to be a lot more
708:38 - agile but to make sure that they
708:39 - effectively work you have practices like
708:41 - team experts who raise the bar uh making
708:43 - sure that you know uh in any areas we
708:45 - can always say how can we do this better
708:47 - uh then there are mechanisms in place
708:49 - for automated checks for standards so
708:51 - that's the great thing about Cloud can
708:52 - all be automated to say hey does it meet
708:54 - our Regulatory Compliance or or or what
708:56 - have you and then there's the concept of
708:58 - the Amazon leadership principles which
709:00 - we will cover on in the next slide in
709:02 - detail and so um you know itus is not
709:05 - obviously using uh these other
709:06 - Frameworks because it has its own which
709:08 - is this one here but the the mechanism
709:11 - to which they stay organized and up to
709:13 - date is they are supported by a virtual
709:15 - community of subject matter experts
709:17 - principal Engineers so that what they'll
709:19 - do is they'll engineer things like
709:20 - lunchtime talks and then recycle that
709:21 - into their onboarding material or into
709:23 - this framework itself okay
709:26 - [Music]
709:31 - so we're taking a look here at Amazon's
709:33 - leadership principles and these are a
709:34 - set of principles used during the
709:36 - company's decision- making problem
709:38 - solving simple brainstorming and hiring
709:40 - all right um and so I can't say that I
709:42 - like all of these but definitely some of
709:44 - them really stand out as being great
709:46 - especially the first one which is
709:47 - customer Obsession so instead of
709:49 - worrying about what your competitors are
709:50 - doing think about what the customer
709:52 - wants work your way back and uh you know
709:54 - really focus on the customer needs needs
709:56 - then there's ownership so if you're
709:57 - going to go do something uh you know try
709:59 - to be your own mini boss uh and take
710:02 - responsibility for whatever it is you're
710:03 - building event and simplify so you know
710:06 - always look for the simplest solution
710:07 - don't try to engineer something super
710:08 - complicated if it's not necessary uh or
710:11 - right a lot so you know try to be right
710:15 - uh learn and be curious so that's pretty
710:17 - self-explanatory hire and develop the
710:19 - best insist on the high standards adus
710:21 - always refers to this as raising the bar
710:23 - think big buys for Action fr it andus is
710:27 - really Frugal if you didn't know that
710:29 - but not just for like themselves but
710:31 - also for their customers they want
710:32 - customers to uh spend the least amount
710:34 - of money possible when using their
710:36 - infrastructure earn trust uh dive deep
710:39 - have a backbone disagree and commit
710:41 - deliver results strive to be the earth's
710:43 - best employer success and scale bring
710:45 - broad responsibility and if you want to
710:47 - read these in detail because they have a
710:49 - big block of text for each of these uh
710:51 - you can go to amazon. jobs uhen
710:55 - principles and read all about it
710:57 - [Music]
711:01 - okay all right let's talk about some
711:03 - general design principles uh that you
711:05 - should be considering when you are
711:06 - designing your infrastructure no matter
711:08 - what pillar that you are looking to
711:10 - adopt the first is stop guessing your
711:12 - capacity needs so the great thing with
711:13 - cloud computing is you use as little or
711:15 - much based on demand whereas on premise
711:17 - you would have to purchase a machine and
711:19 - you'd have to make sure you have
711:21 - additional capacity so that you could
711:22 - grow into it right and so here with uh
711:25 - cloud you do not have to worry about
711:26 - that uh test systems at production scale
711:29 - so be able to clone your production
711:30 - environment to testing tear down testing
711:33 - while not in use to save money so a lot
711:35 - of people will have a staging server
711:36 - that they run all the time but the great
711:38 - thing here is that with Cloud you know
711:40 - it's you can just spin it up and have it
711:42 - right away and then tear it down and
711:43 - save money um there's automating to make
711:46 - architectural experimentation easier
711:48 - this is talking about using
711:49 - infrastructure as a code so for ads this
711:51 - to be using cloud formation creating
711:52 - change sets which kind of um uh say
711:55 - exactly what is going to change stack
711:57 - updates drift detection to see if your
711:58 - stuff is uh being changed over time by
712:01 - developers through manual configuration
712:03 - things like that then we have allow for
712:05 - evolutionary architectures so this is
712:07 - about adapting cicd um doing nightly
712:10 - releases or if you're using serverless
712:13 - if you adopted lambdas they deprecate
712:15 - over time forcing you to use the latest
712:17 - version uh and so that is evolutionary
712:20 - architectures then we have drive
712:22 - architectures using data so um when
712:24 - you're using Cloud there's a lot of
712:26 - Tooling in there to automatically start
712:27 - collecting data so Cloud watch will be
712:30 - collecting some things by default and
712:31 - cloud trail will as well so you know
712:34 - that is another thing and then improving
712:36 - things through game days so this is
712:38 - about stimulating traffic on production
712:40 - or purposely killing ec2 instances or or
712:42 - messing with your services to see how
712:44 - well they recover all
712:46 - [Music]
712:50 - right before we jump into each of the
712:52 - pillars let's go open them up and take a
712:55 - look at what structure we should expect
712:57 - to see so we have design principles
712:59 - definition best practices and resources
713:01 - all the pillars follow this to a t so
713:04 - let's just talk about what these are so
713:05 - the design principles are a list of
713:07 - design principles that needs to be
713:09 - considered during implementation and
713:11 - that's where we're going to focus a lot
713:12 - of our energy then you have definition
713:15 - so this is an overview of the best
713:16 - practice categories then you have the
713:18 - best practices themselves these are
713:20 - detailed information about each practice
713:22 - with uh various a services and then you
713:24 - have resources these are additional
713:26 - documentation white papers uh and videos
713:28 - to implement this pillar and I just want
713:31 - to tell you that if you're doing the
713:32 - certified Cloud practitioner we're
713:34 - really just going to cover the design
713:35 - principles but for the solutions
713:37 - architect associate or anything uh
713:39 - that's associate or above that's where
713:40 - we're going to actually dive deep into
713:42 - the implementation of the best practices
713:44 - because there is a lot of stuff there so
713:47 - uh yeah there we
713:48 - [Music]
713:52 - go let's take a look here at the design
713:54 - principles for operational excellence so
713:56 - the first here is perform operations as
713:58 - code so apply the same engineering
714:00 - discipline you would to application code
714:02 - to your infrastructure so by training
714:04 - your operations as code you can limit
714:06 - human error and enable consistent
714:08 - responses to events generally we're
714:10 - talking about infrastru infrastructure
714:11 - as a code here so this would probably be
714:13 - like things like cloud formation there's
714:14 - other things you could do like policy as
714:16 - a code and a bunch of other ones then we
714:18 - have make frequent small reversible
714:20 - changes so design your workloads to
714:22 - allow components to be updated regularly
714:25 - uh this could be talking about doing
714:26 - roll backs incremental changes Blu green
714:28 - deployments having a cicd pipeline
714:30 - refined operations procedures frequently
714:33 - so look for continuous opportunities to
714:34 - improve your operations uh here you use
714:37 - game days to simulate traffic or event
714:39 - failure on your production workloads
714:41 - anticipate failures to perform post
714:42 - modems on system failures to better
714:45 - improve write test code kill production
714:47 - servers um there's a small spelling
714:49 - mistake it should have an R here so
714:51 - servers to test recovery learn from all
714:54 - operational failure so share Lessons
714:56 - Learned in a knowledge base for
714:58 - operational events and failures across
715:00 - your entire organization but you know if
715:01 - you can just remember these headings
715:03 - here uh and be able to categorize what
715:05 - would be under operational excellence
715:06 - you'll be okay all
715:08 - [Music]
715:11 - right all right let's take a look at the
715:13 - design principles for the security
715:15 - pillar so the first here is Implement a
715:17 - strong identity foundation so implement
715:20 - the principle of lease privilege or PP
715:23 - that's a very popular concept meaning
715:25 - give people only the permissions that
715:26 - they need use centralized identity so
715:29 - that would be using adus am avoid longl
715:32 - credentials then we have enable
715:34 - traceability so monitor alerts and audit
715:36 - actions and changes to your environment
715:38 - in real time integrate log and Metric
715:40 - collection and automate investigations
715:42 - and Remediation then we have apply
715:45 - security at all layers so take defense
715:48 - in depth approach with multiple security
715:50 - controls for everything from Edge
715:52 - networks vbcs load balancing instances
715:54 - OS application code we might have a
715:57 - slide in this course on defense into
715:59 - depth where basically you see like a
716:01 - ring of things and you can kind of see
716:03 - how like there's layers that go from
716:05 - outward to Inward and that's what
716:06 - they're talking about when they're
716:07 - listing out all these things here
716:09 - automate security best practices uh
716:11 - protect your data in transit at rest uh
716:14 - keep people away from your data the
716:17 - reason I don't have descriptions there
716:18 - is because those are pretty self-evident
716:19 - prepare for security events so Incident
716:21 - Management systems and investigation
716:23 - policies and processes tools to detect
716:25 - investigate and recovery from incidences
716:28 - and uh there are a lot of security tools
716:30 - out there and they all have funny
716:31 - initialisms I didn't put any of them in
716:32 - here but I'm sure there are some there
716:34 - um but yeah there you go for
716:36 - [Music]
716:40 - security all right let's take a look at
716:42 - design principles for reliability and
716:44 - the first here is automatically recover
716:45 - from failure so Monitor kpis and Trigger
716:48 - automations when the threshold is breach
716:50 - test recovery procedures so test how
716:52 - your workload fails and you validate
716:54 - your recovery procedures you can use
716:56 - automation to simulate different
716:58 - failures or to recreate scenarios that
717:00 - led to failures before scale
717:01 - horizontally to increase aggregate
717:03 - system availability so replace one large
717:05 - resource with multiple small resources
717:07 - to reduce the impact of a single failure
717:09 - on the over overall workload distribute
717:12 - requests across multiple smaller
717:14 - resources to ensure that they don't
717:15 - share a common point of failure so we're
717:17 - talking about multi-az uh High
717:19 - availability okay stop guessing capacity
717:21 - we've seen this multiple times so in on
717:23 - premise it takes a lot of guess work to
717:25 - determine the elasticity of your
717:26 - workloads uh workload demands with Cloud
717:28 - you don't need to guess how much you
717:29 - need because you can request the right
717:31 - size of resources on demand that's going
717:34 - to give you better reliability okay
717:35 - manage change and automation so making
717:37 - changes via infrastructure as a code
717:39 - will allow for a formal process to track
717:40 - and review infrastructure you're going
717:42 - to see IC show up a lot in this
717:44 - framework
717:45 - [Music]
717:48 - okay let's take a look at design
717:50 - principles for performance efficiency so
717:52 - the first here is democratize advanced
717:55 - techn technology so focus on product
717:56 - development rather than procurement
717:58 - provisioning and management of services
718:00 - because if you're on Prem you'd have to
718:01 - order those machines set them up and so
718:03 - take advantage of advanced technology
718:05 - specialized and optimized for your use
718:06 - case with on demand cloud services
718:08 - because again if you're using on Prem uh
718:10 - you you know you might not have the
718:12 - option to have Sage maker right it's
718:14 - just going to be a VM and you're going
718:15 - to have to do all the work yourselves
718:16 - whereas ads has all these specialized
718:18 - things so you can move quickly uh Go
718:20 - Global in minutes so deploying your
718:22 - workload in multiple abis regions around
718:24 - the world allows you to provide lower
718:26 - latency and a better experience for your
718:27 - customers at a minimal cost we have used
718:29 - seress architecture so servess
718:31 - architecture removes the need for you to
718:33 - run and maintain physical servers for
718:34 - traditional Computing activities removes
718:37 - the operational burden of managing
718:38 - physical servers and can lower
718:39 - transaction costs because manage
718:40 - services operate at Cloud scale and it
718:42 - us can be a lot better at um running
718:45 - them efficiently than you will uh
718:47 - experiment more often so with virtual
718:49 - and automatable uh resources you can
718:51 - quickly carry out comparative testing
718:53 - using different types of instan and
718:54 - Storage or configurations to make the
718:56 - best choice we call this right sizing
718:58 - choosing the right size consider
719:01 - mechanical sympathy so understand how
719:03 - cloud services are consumed and always
719:05 - use technology approach that aligns best
719:07 - with your workload goals for example
719:09 - consider data access patterns when you
719:11 - select database or storage
719:13 - [Music]
719:17 - approaches let's take a look here at
719:19 - design principles for cost optimization
719:21 - so the first one here is Implement Cloud
719:23 - financial management so dedicate time
719:25 - and resources to build capacity uh via
719:27 - Cloud financial management and cost
719:29 - optimization tooling stus is saying hey
719:31 - take advantage of all our tooling they
719:33 - makes it easy for you to know exactly
719:34 - what you're spending adopt a consumption
719:36 - model so pay only for computing
719:38 - resources that you require uh an
719:40 - increase or decrease using uh depending
719:43 - on the business requirements we're
719:44 - talking about on demand pricing measure
719:46 - overall efficiency so measure the
719:47 - business output of the workload and the
719:49 - cost associ associated with delivering
719:52 - use this measure to know the gains you
719:54 - make from increasing inreasing output
719:55 - and reducing costs so stop spending
719:58 - money on
719:59 - undifferentiated that's a hard word to
720:01 - say
720:02 - undifferentiated heavy lifting so adus
720:05 - does the heavy lifting of the data
720:06 - center operations like racking stacking
720:08 - and power servers it also removes the
720:10 - operational burden of managing operating
720:12 - systems and applications with managed
720:14 - services this allows you to focus on
720:16 - your customers and business projects
720:17 - rather than your it infrastructure and
720:20 - the last one here is analyze and
720:22 - attribute expenditure so the cloud makes
720:24 - it e easier to uh accurately identify
720:26 - the usage and cost of systems which then
720:28 - allow transparent uh attribution of it
720:31 - cost to individualize workload owners
720:34 - this helps measure return on investment
720:36 - and gives workload owners an opportunity
720:37 - to optimize the resources and reduce
720:39 - costs so there you
720:41 - [Music]
720:44 - go hey this is Andrew Brown from exam
720:46 - Pro and we are taking a look at the adus
720:48 - well architected tool so this is an
720:50 - auditing tool to be used to assess your
720:52 - Cloud workloads for alignment with the a
720:55 - well architected framework and so what
720:57 - it is it's essentially a checklist uh
720:59 - but it also has nearby references so you
721:02 - know as you're reading through it it
721:03 - will show you information uh and
721:06 - resources so that it can help you with
721:08 - this checklist here and the idea is when
721:10 - you're done you can generate out a
721:11 - report and then you can provide that
721:13 - report to your Executives and key
721:15 - stakeholders to prove uh you know how
721:17 - well architected your workload is on AWS
721:20 - [Music]
721:23 - okay hey this is angre Brown from exam
721:26 - Pro and in this video I want to show you
721:27 - two things the well architected
721:29 - framework and the well architected tool
721:31 - so first let's go look for the well
721:33 - architected framework so we're going to
721:35 - look up white papers uh
721:37 - AWS and so if we go here to AWS
721:40 - amazon.com white papers we have a bunch
721:42 - of pages here and so I'm going to just
721:44 - checkbox on white papers so that we can
721:45 - kind of reduce the amount there and then
721:48 - I'm going to checkbox well architected
721:49 - framework if we scroll all the way top
721:51 - here one of these you think it'd be
721:53 - right at the top but one of these is the
721:56 - well architected framework and here it
721:58 - is and so if we open it up used to just
722:00 - directly open up as a PDF I'm sure you
722:02 - can still download it as is but
722:04 - generally you're going to open up as
722:06 - this HTML page and you can basically
722:08 - read through it see all the stuff see
722:10 - the multiple pillars we can click into
722:13 - here see the design principles read the
722:16 - definitions and then start reading about
722:18 - uh the best practices and they have
722:20 - these things at the bottom of each one
722:23 - uh very boring very very boring but but
722:25 - um you know when you get to the
722:26 - solutions architect and things like that
722:27 - you're going to need to know this stuff
722:28 - inside and out it's going to really help
722:30 - you out this Cloud practitioner we only
722:32 - need to know surface level information
722:35 - um but that's the little architect
722:36 - framework let's take a look at the well
722:38 - architected tool so we going type in
722:40 - well here we'll get the well architected
722:43 - tool and if we go here you can see that
722:45 - I've created a couple before probably
722:48 - demos for um our videos and so I'm going
722:51 - to go Define a new workload I'm going to
722:53 - say my my workload Lo here uh my
722:58 - workload whoops my workload it is
723:02 - messing up because I probably have
723:03 - grammarly installed so it does not like
723:05 - grammarly so I'm just going to turn it
723:07 - off for now so my
723:12 - workload and it's still not typing
723:14 - correctly so I have to kill out kill out
723:16 - grammarly here which is kind of
723:18 - frustrating so that's a bug that that's
723:20 - not grammarly's fault that's adab Us's
723:21 - fault for not playing well with grammar
723:25 - and that's something I will definitely
723:26 - report to them because it's very
723:28 - annoying so I'm going to go ahead and
723:30 - refresh this
723:33 - page my workload my
723:37 - workload um and this is Andrew
723:41 - Brown production or pre-production
723:43 - doesn't matter pick your regions Us East
723:47 - or Us East 2
723:49 - sure I'm selecting
723:52 - it there we go uh optional optional
723:56 - optional optional you go to next and
723:58 - then you can choose your lens serus lens
724:00 - FTR lens so that's the foundational
724:02 - technical review SAS lens we can go with
724:04 - architected framework and then once that
724:07 - is there we can start
724:10 - reviewing okay and then we get this big
724:12 - checklist and so we can go through this
724:14 - and read each one so we say Ops one how
724:17 - do you determine what your priori are
724:18 - and all these things like Ops and stuff
724:20 - like that these are all the summaries in
724:21 - each of the well architected framework
724:23 - sections so you pretty much don't need
724:25 - to really read the dock you just go
724:26 - through this so everyone needs to
724:28 - understand their part in enabling
724:29 - business success have shared goals in
724:32 - order to set priorities of resources
724:34 - this will maximize the benefit of your
724:35 - efforts so select from the following
724:38 - evaluate the customers's external needs
724:41 - external customer needs evaluate
724:43 - internal customer needs if you click
724:44 - info it's going to highlight each one
724:46 - here so evolve key stakeholders
724:48 - including Business Development
724:49 - operations teams this will ensure Etc
724:52 - and so you just go through this and uh
724:54 - you know you know once you have that and
724:56 - you save an
724:58 - exit Okay uh you'll have uh the
725:01 - questions that are answered it'll say
725:02 - what's high risk what's not things like
725:04 - that very simplistic it's really just a
725:07 - way of making a very organized report or
725:09 - checklist and proving that you went
725:11 - through it uh to the executive level or
725:14 - to the management level there so
725:16 - hopefully that makes sense to you um
725:17 - it's not too complicated but there you
725:19 - [Music]
725:23 - go hey it's Angie Brown from exam Pro
725:25 - and we are looking at the ads
725:27 - architecture Center so the architecture
725:29 - Center is a web portal that contains
725:31 - best practices and reference
725:33 - architectures for a variety of different
725:35 - workloads and you can find this at adab.
725:37 - amazon.com architecture so if you're
725:40 - looking for best practices in terms of
725:41 - security they have a huge section on
725:43 - that and they have it for pretty much
725:45 - every kind of category on AWS or if
725:47 - you're looking for uh practical examples
725:50 - you can view the large library of
725:52 - reference architectures so here's one to
725:54 - make an ads Q&A bot and it will have an
725:57 - architectural diagram but you can also
726:00 - uh deploy via cloud formation or
726:02 - possibly cdk um and this way you can get
726:05 - a working example and then tweak it for
726:06 - your use case so this is a really great
726:09 - tool um when you are done the adus well
726:11 - architect framework and you're saying
726:12 - okay how do we apply it can we get more
726:14 - concrete examples and I wouldn't be
726:16 - surprised if a lot of the resources
726:18 - within the well architectur framework
726:19 - white paper are just pointing to the
726:20 - center
726:23 - okay
726:25 - [Music]
726:26 - hey this is Andrew Brown from exam Pro
726:28 - and we are taking a look at the concept
726:29 - of total cost of ownership also known as
726:31 - TCO so what is TCO well it is a
726:34 - financial estimate intended to help
726:36 - buyers and owners determine the direct
726:38 - and indirect cost of a product or
726:40 - service so here is an example of you
726:42 - know TCO for maybe like a data center so
726:45 - we have Hardware monitoring installation
726:47 - IT personnel training software uh
726:50 - security licensing and taxes but that's
726:53 - not just the limit of it it's just kind
726:54 - of the examples we show here uh the idea
726:56 - of creating TCO is useful when your
726:58 - company's looking to migrate from on
727:00 - Prem to cloud and we will have a better
727:03 - uh kind of visual here to kind of
727:04 - understand how you would contrast
727:06 - against on Prem to Cloud but let's just
727:08 - talk about how it actually works in
727:09 - practicality which I think gets kind of
727:11 - overlooked when cloud service providers
727:13 - are selling you on TCO so the idea is a
727:16 - gardener um you know they uh they were
727:20 - they wrote this article based on This
727:21 - research where an organization had moved
727:24 - 2,500 virtual machines over to Amazon
727:27 - dc2 and so what you're seeing here is
727:30 - that there is a an additional cost that
727:32 - we're not considering which is the
727:33 - migration cost See This Bar up here um
727:36 - so the idea is that the company was
727:38 - paying around 400,000 and so they
727:40 - started to move over and as you see uh
727:43 - their costs initially went up for a
727:44 - short period of time here uh but then
727:47 - once that migration cost was over uh you
727:49 - can notice that they had a 55% reduction
727:51 - so it's uh totally possible to save
727:54 - money
727:55 - uh and clearly there is great savings uh
727:57 - now is it exactly what AWS promises
728:00 - probably not and that's that could be
728:01 - the reason why they update their TCO
728:03 - calculator but let's now just do that
728:05 - contrast against the two so we have on
728:07 - premise on the left and adus on the
728:09 - right or any class service provider and
728:11 - what I want to do is help you think
728:13 - about what cost do people generally
728:14 - think about because if we have like
728:16 - Iceberg the idea here is that these are
728:18 - the costs that we always think about
728:19 - above the iceberg and then there's these
728:21 - hidden costs that we just don't consider
728:23 - when factoring are move and that's the
728:25 - idea of T TCO is to consider all the
728:27 - costs not just the superficial ones and
728:29 - so people say these look like teeth and
728:31 - that's why I add penguins and a whale
728:33 - here um and so when we're talking about
728:35 - on premise what we generally think are
728:36 - software license fees and subscription
728:39 - fees but when you compare those against
728:41 - each other they might look the same um
728:43 - ad us might just look slightly cheaper
728:44 - or even more and so the idea is you need
728:47 - to then factor in everything so on on
728:49 - premise there's implementation
728:50 - configuration training physical security
728:52 - Hardware IT personnel maintenance and on
728:54 - the adus side you know you are you don't
728:57 - have to do as much of that stuff so you
728:58 - just have implementation configuration
729:00 - and training and so adus with their TCO
729:03 - calculator their old one used to make a
729:05 - promise of 75% in savings um again you
729:08 - know this is going to really vary based
729:11 - on what your migration strategy looks
729:12 - like um but you know it's totally
729:14 - possible you could save 75% or you could
729:17 - save 50% over a third year a three-year
729:20 - period And there's a an initial Spike so
729:23 - that's just something you have to
729:24 - consider but the nice thing though is
729:25 - that once you've moved over all the
729:27 - stuff over here on the left hand side
729:28 - will be ais's responsibility
729:31 - [Music]
729:34 - okay all right so let's take a look at
729:36 - Capital versus operational expenditure
729:39 - so there's capex and Opex so on the
729:41 - capex side the idea here is you're
729:43 - spending money upfront on physical
729:44 - infrastructure deducting that expenses
729:46 - from your tax bill over time uh a lot of
729:49 - companies that are running their own
729:50 - data centers uh or have a lot of on-
729:53 - premise stuff understand what capex is
729:55 - because um it's something that a lot of
729:57 - times they get tax breakes on and that's
729:59 - why we see a lot of people that have a
730:00 - hard time moving away from the cloud
730:02 - because you know they keep on thinking
730:03 - about that money they save from the
730:05 - government but capex costs would be
730:07 - things like server costs storage Network
730:09 - costs backups and archives Disaster
730:11 - Recovery costs data center costs
730:14 - technical Personnel so the idea is with
730:17 - capital exp expenses you have to guess
730:19 - upfront what you plan to spend okay with
730:22 - operational expenditure the idea here is
730:23 - the cost associated with an on- premise
730:25 - data center that has shifted the cost to
730:27 - the service provider the customer only
730:29 - has to be concerned with non-physical
730:31 - costs so leasing software and
730:32 - customizing features uh training
730:34 - employees and cloud services paying for
730:36 - cloud support uh billing based on cloud
730:39 - metrics so compute usage storage usage
730:42 - and so the idea here is with operational
730:44 - expenses you can try a product or
730:46 - service without investing in equipment
730:49 - so basically kex is what we think about
730:51 - when we think of on premise and then
730:53 - Opex is what we think think about um you
730:55 - know when we're thinking about cloud or
730:56 - AWS
730:58 - [Music]
731:02 - okay all right let's ask a very
731:04 - important question about Cloud migration
731:05 - so does cloud make it Personnel
731:08 - redundant so a company is considering
731:10 - migrating their workloads from on-
731:11 - premise to the cloud to take advantage
731:12 - of the savings there is a concern among
731:15 - the staff that there will be Mass
731:17 - layoffs does cloud make it Personnel
731:20 - redundant and that's a very important
731:22 - question to to have an answer to and
731:24 - this all talks about shifting your it
731:26 - team into different responsibilities so
731:29 - a company needs it Personnel during the
731:31 - migration phase as we saw with that
731:32 - Gardener research report that there was
731:34 - a period at least like a year where they
731:37 - needed that for you know depending on
731:38 - the size of your company so you're still
731:40 - going to need those people around a
731:42 - company can transition some roles to new
731:43 - Cloud roles so a very traditional
731:45 - example would be you have your
731:47 - traditional networking roles where
731:48 - people have like their CCNA and now
731:50 - they're moving over to Cloud networking
731:52 - uh they have a reduced workload but
731:54 - there's other things uh that they could
731:56 - be doing in the cloud um a company may
731:59 - decide to take a hybrid approach so
732:00 - they'll always need to have a
732:01 - traditional it team and a cloud uh it
732:04 - team um and the last one and this one
732:07 - You' actually see on the exam which is a
732:09 - company can change employees activities
732:11 - from managing infrastructure to re
732:13 - Revenue generating activities okay so
732:15 - the idea is that you know if you're a
732:17 - company why would you get rid of all
732:18 - your staff when you can just put them
732:19 - all into Revenue generation I suppose
732:22 - you know you could uh you know uh lay
732:24 - them off and some companies might do
732:25 - that um or you know you could just
732:27 - retrain them because uh if that IT
732:30 - personnel team has uh technical
732:31 - expertise I'm sure they can translate
732:33 - that to the
732:34 - [Music]
732:37 - cloud let's talk about the adus pricing
732:40 - calculator and this is a free cost
732:42 - estimate tool that can be used within
732:43 - your web browser without the need of an
732:45 - adus account to estimate the cost of a
732:47 - various IT services and this is um
732:50 - available at calculator. AWS and the
732:53 - reason we're bringing this up is because
732:54 - there used to be a TCO calculator but
732:57 - now this is the calculator that you use
732:59 - so the adabs pricing calculator contains
733:01 - 100 plus services that you configure for
733:03 - cost estimate and so you can just click
733:05 - through a bunch of knobs and uh boxes to
733:09 - uh you know uh exactly figure out a very
733:13 - accurate cost so the idea here is that
733:15 - to calculate your TCO an organization
733:18 - needs to compare that existing cost
733:20 - against their adus costs and so the adus
733:22 - pricing calculator can be used to deter
733:23 - DET uh you know the adus costs and
733:26 - obviously the organization knows its
733:27 - cost so it can compare it against that
733:30 - um and the way you can get data out of
733:32 - this is you can export it as a final
733:34 - estimate to AC CSV
733:36 - [Music]
733:39 - okay hey this is Andrew Brown from exam
733:42 - Pro and we are taking a look at the AWS
733:43 - pricing calculator so to get there it's
733:45 - calculator. AWS what you're going to do
733:47 - is hit create estimate and then here you
733:49 - have a bunch of services so you just
733:51 - choose what you want so you type in ec2
733:53 - we're going to configure that and from
733:55 - there we can do a quick estimate or an
733:57 - advanced estimate so choose this option
733:58 - for fast and easy route to Ballpark and
734:01 - estimate choose this option for detailed
734:03 - estimate for accounts workloads and
734:04 - stuff so notice down below very
734:06 - simplistic we hit
734:08 - Advanced and we get all sorts of stuff
734:11 - okay so you know it's really up to you
734:13 - I'm very comfortable with the advanced
734:15 - options so I might be running a Linux
734:17 - machine what is my usage it's going to
734:21 - have uh daily spikes of traffic because
734:24 - of the use cases you could say it's not
734:26 - busy on Saturday and Sunday that it has
734:28 - a baseline of one a peak of two eight
734:30 - things like that then you can choose
734:32 - what you're using um t4g I don't even
734:35 - know what that is uh but we'll just say
734:37 - like
734:38 - t uh T2 micro which is not that big T3
734:43 - micro and you can say we're doing on
734:45 - demand because a lot of people would be
734:47 - doing that and you see like $7 a month
734:50 - it's not a lot of money then you're
734:52 - looking at your storage data in data
734:55 - out okay so we can add that another
734:58 - thing that we might see is something
735:00 - like
735:02 - RDS so we go to RDS and we add postest
735:06 - and not all of them have the simple and
735:08 - complex sometimes they're simple so
735:09 - production
735:11 - database we'll have one here and we're
735:14 - just going to be say a dbt2 micro T T3
735:19 - micro there we go uh 100 that's fine
735:22 - we're not going to have multi a will
735:24 - have single a on demand show the
735:26 - calculation $13 a month add that to our
735:29 - estimate so you're kind of getting the
735:31 - idea there
735:32 - right um and so you know we have our
735:35 - summary that's our monthly
735:38 - $391 um oh sorry over 12 months our
735:41 - monthly cost is
735:42 - $32 okay you can go back there clone the
735:44 - service edit it stuff like that you can
735:47 - export the estimate I think it goes out
735:49 - as a CSV you can also hit
735:52 - share uh and then hit agree and so then
735:55 - you have a public link and if I have
735:58 - that link we can just see what happens
736:00 - if I paste it okay it just brings them
736:03 - to the same estimate so there you
736:05 - [Music]
736:09 - go hey this is Andrew Brown from exam
736:11 - Pro and we are taking a look at
736:13 - migration evaluator so it was formerly
736:15 - known as TCL logic and then abis
736:18 - acquired the company and it is an
736:19 - estimate tool used to determine an
736:21 - organization existing on premise costs
736:23 - so it can compare it against its adabs
736:25 - cost for Planned Cloud migration uh so
736:28 - the idea is that you can get a very very
736:31 - detailed information and the way it
736:33 - collects information is via an agentless
736:36 - collector to collect data from your on
736:37 - premise infrastructure to extract from
736:39 - your own on premise costs I don't know
736:41 - if you can see there but you can see
736:42 - that it works with a lot of different
736:43 - kinds of on- premise technology like
736:46 - VMware Microsoft uh tsql all sorts of
736:50 - things
736:52 - okay
736:55 - [Music]
736:56 - one migration tool that we can use with
736:58 - AWS is the VM import export and this
737:01 - allows us to import virtual machines
737:03 - into ec2 so inabus has import
737:06 - instructions for VMware Citrix Microsoft
737:09 - hyperv Windows vhd from Azure and also
737:13 - Linux vhd from Azure and so the way this
737:15 - works is that you prepare your virtual
737:17 - image for upload and adus has a bunch of
737:19 - instructions for that once it is ready
737:21 - you're going to upload that to an S3
737:23 - bucket and once it's uploaded to an S3
737:26 - bucket then what you can do is use the
737:28 - ad CLI to import your image um and so
737:31 - that is the CLI command down below and
737:35 - once it is produced it will generate out
737:37 - an Amazon machine image and so from an
737:39 - Ami you can then go launch your ec2
737:42 - [Music]
737:46 - okay hey this is Andrew Brown from exam
737:48 - Pro and we are taking a look at the
737:50 - database migration service which allows
737:52 - you to quickly and securely migrate one
737:53 - database to another DMS can be used to
737:55 - migrate your on- premise database to ads
737:57 - and that's why we're talking about it uh
737:59 - and so here's a general diagram where
738:00 - you have your Source database which
738:02 - connects to a source endpoint goes
738:04 - through a replication instance so that's
738:05 - a ec2 instance that's going to replicate
738:08 - the data to the Target endpoint onto the
738:10 - target database uh and so we have a
738:13 - bunch of possible sources so we have
738:15 - Oracle database Microsoft SQL MySQL
738:18 - Mario DB post SQL mongodb Sapa ASC
738:24 - IMDb db2 Azure SQL database Amazon RDS
738:29 - Amazon S3 and I'm assuming these are
738:31 - database dumps Amazon Aurora Amazon
738:35 - document DB and so for possible targets
738:37 - it's very similar we got Oracle database
738:39 - Microsoft SQL MySQL Mario DB post SQL
738:44 - reddis saps SE Amazon redshift Amazon
738:48 - RDS Amazon Dynamo DB Amazon S3 Amazon
738:51 - Aurora Amazon open search service Amazon
738:55 - elasticache for reddis Amazon document
738:57 - DB Amazon Neptune Apachi Kafka I'm just
739:01 - showing you the list to give you an idea
739:02 - of how flexible this service is uh but
739:05 - you can tell that these are very
739:06 - different databases so how can it uh
739:09 - move them over right and so in not all
739:11 - cases can it easily do it like it's very
739:13 - easy to go from myql to postrest um but
739:16 - you know for ones that are like
739:17 - relational to uh nosql uh this is where
739:21 - the adabas schema conversion tool comes
739:22 - into play it's used in many cases to
739:24 - automatically convert a source database
739:26 - schema to a Target database schema or
739:29 - semi-automate it so that you can kind of
739:31 - like uh you know uh figure out how to
739:33 - map the new schema uh each migration
739:35 - path requires a bit of research since
739:37 - not all combinations of sources and
739:38 - targets are possible and it really comes
739:41 - down to even versions of these things so
739:43 - but I just want you to know about that
739:44 - it's an option as a database migration
739:46 - service and I've migrated a very large
739:48 - database before and it's super fast uh
739:51 - so and it's not that hard to use so
739:53 - something you definitely want to
739:54 - remember when you're
739:56 - [Music]
739:59 - migrating hey this is Andrew Brown from
740:01 - exam Pro and we are taking a look at the
740:03 - cloud adoption framework so this is a
740:05 - white paper to help you plan your
740:06 - migration from on- premise to AWS at the
740:09 - highest level the adus CAF organizes
740:11 - guidance into six Focus areas we got
740:14 - business people governance platform
740:16 - security and operations and this white
740:18 - paper is pretty high level uh so you
740:21 - know it doesn't get into uh granular
740:23 - details on how that migration should
740:24 - work uh but gives you kind of a holistic
740:26 - approach and I believe that probably
740:28 - through the adus uh Amazon partner
740:31 - Network there's people that specialize
740:33 - in using this particular framework to
740:34 - help organizations move over and I
740:36 - believe that Abus has Professional
740:38 - Services through the APN but let's just
740:40 - kind of break down what these six
740:41 - categories are we're not going to go too
740:42 - deep into this um but let's do it so the
740:45 - first is the business perspective so
740:47 - these are business managers Finance
740:49 - managers budget owners strategy
740:50 - stakeholders so it's how to up update
740:53 - the staff skills and organizational
740:55 - processes to optimize business value as
740:57 - they move Ops to the cloud you have
740:59 - people perspectives so Human Resources
741:00 - Staffing people managers so how to
741:03 - update the staff skills and
741:04 - organizational processes to optimize and
741:06 - maintain the workforce and ensure
741:08 - competencies are in place at the
741:09 - appropriate time you have governance
741:11 - perspective so cios program managers
741:14 - project managers Enterprise Architects
741:16 - business analysts so how to update the
741:18 - staff skills and organizational
741:20 - processes that are necessary to ensure
741:22 - business governance in the cloud and
741:23 - manage and measure Cloud Investments to
741:26 - evaluate the business outcomes we have
741:28 - platform perspectives so CTO it managers
741:30 - solution Architects so how to update the
741:32 - staff skills and organizational
741:34 - processes that are necessary to deliver
741:36 - and optimize Cloud Solutions and
741:37 - services security perspective so ciso it
741:40 - security managers it security analysts
741:43 - so how to update the staff skills and
741:44 - organizational processes that are
741:46 - necessary to ensure that the
741:47 - architecture deployed in in the cloud
741:50 - aligns to the organization security
741:51 - control requirements resilience
741:53 - and compliance requirements we have
741:55 - operational or operations perspective so
741:57 - it operations managers it support
742:00 - managers so how to update the staff
742:02 - skills and organizational processes that
742:04 - are necessary to ensure system health
742:06 - and reliability during the move of
742:08 - operations to the cloud and then to
742:10 - operate operate using agile ongoing
742:12 - cloud computing best practices so this
742:14 - just Taps the surface of what the CAF is
742:18 - uh and I think for each of these they
742:19 - actually have a more detailed breakdown
742:21 - so you know business is going to break
742:22 - down to even more uh uh finite things
742:25 - there
742:26 - [Music]
742:30 - okay so itus has free services that are
742:33 - free forever unlike the free tier that
742:35 - are up to a point of usage or time um
742:38 - and so there are a lot here this is not
742:40 - even the full list there's definitely
742:41 - more and we have IM am Amazon VPC Auto
742:44 - scaling cloud formation elastic bean
742:46 - stock Ops Works amplify appsync code
742:48 - star organizations Consolidated building
742:51 - a was cost Explorer uh Sage maker
742:53 - systems manager there's a lot of them
742:56 - okay um but the thing is is that uh
742:58 - these services are free but some of
743:00 - these um can spin up other resources so
743:03 - the services are free themselves however
743:05 - ones that provision Services May cost
743:07 - you money so cloud formation which is an
743:09 - infrastructure is a code tool could
743:10 - launch virtual machines those virtual
743:12 - machines will cost money right opsworks
743:14 - can launch servers that can cost money
743:16 - amplifly can launch um lambdas that can
743:19 - cost money so that's something you just
743:21 - have to consider um but yeah there you
743:24 - [Music]
743:28 - go hey this is Andrew Brown from exam
743:30 - Pro and we are taking a look at the adus
743:32 - support plans so we got basic developer
743:35 - business and Enterprise and you
743:37 - absolutely absolutely need to need to
743:39 - know this stuff inside and out for your
743:40 - exam they will ask you questions on this
743:42 - okay so basic is for email support only
743:46 - uh such as billing and account so if you
743:49 - think it got over bu and that's
743:50 - something you should do if if you''ve uh
743:52 - uh misconfigured something and you end
743:54 - up with a big Bill just go Um open up a
743:57 - support ticket under basic for billing
743:59 - and they're likely to refund you but if
744:01 - you do have questions about billing
744:02 - accounts that's what we're going to be
744:03 - using for everything else that is for
744:05 - tech support um and so for developer
744:07 - business Enterprise you're going to get
744:08 - email support which they'll uh roughly
744:11 - reply within 24 hours I believe this is
744:14 - business hours so if you message them on
744:17 - Friday um or sorry Saturday you might be
744:20 - waiting till Monday for it okay um um in
744:23 - terms of thirdparty support the only one
744:26 - that doesn't have third party support is
744:28 - developer so if you are using something
744:30 - like Ruby on Rails or Azure or something
744:33 - that has interruptibility between AD and
744:35 - something else business Enterprise will
744:37 - absolutely help you out with it same
744:39 - with Enterprise but the developer one
744:40 - not so much uh if you like to use the
744:44 - phone or you like to chat with people um
744:47 - that's available at the business
744:48 - Enterprise tier this is the way I end up
744:50 - talking to people if you are um you know
744:53 - like if you're in North America and
744:55 - you're calling between 9 to 5 and a
744:56 - Monday and Friday you're likely to get
744:57 - somebody that is within North America if
745:00 - not it'll be one of uh one of the
745:03 - supports from some other area so just be
745:06 - aware of that that can also affect the
745:07 - time they pick up uh sometimes it's 5
745:09 - minutes sometimes it's 30 minutes to to
745:11 - an hour uh you know it just depends on
745:14 - what service you're asking for and you
745:16 - know what time a day okay um in terms of
745:21 - responsiveness uh for General guidance
745:24 - everything is 24 hours or less for
745:26 - developer business Enterprise if your
745:27 - system is impaired it's within 12 hours
745:30 - or less with production system impaired
745:32 - it's four hours or less with production
745:34 - system down it's 1 hour or less and if
745:36 - you're for Enterprise um it's going to
745:39 - be business critical system down less
745:41 - than 50 minutes so just notice who has
745:43 - what for these things um I've definitely
745:46 - waited like three days on General
745:48 - guidance before so just take these with
745:50 - a grain of salt that they're not you
745:52 - know they don't really stick to these
745:54 - that or maybe I'm just not paying enough
745:55 - for them to care okay um in terms of uh
745:58 - getting actual people assigned to you
746:00 - this only happens at the Enterprise
746:01 - level where they have their coner team
746:04 - so they uh help your um organization uh
746:07 - learn how to use datab best asking them
746:08 - any questions personally and then you
746:10 - have a tam a technical account manager
746:12 - that is somebody that knows um aide
746:15 - inside and out and they'll help you
746:16 - architect things and make correct
746:18 - choices or they'll check your bill and
746:19 - help you try to reduce that bill things
746:21 - like that okay in terms of trusted
746:23 - advisory checks at the basic developer
746:25 - you get seven advisory checks once
746:27 - you're paying for business you get all
746:29 - the checks the cost here for business is
746:31 - zero um for developer it's starting at
746:34 - $29 a month for business it's starting
746:36 - at $100 a month and then for Enterprise
746:39 - it's 15,000 a month so I said starting
746:42 - at because it's dependent on your usage
746:44 - okay so let's just look at developer
746:46 - business and Enterprise here because
746:48 - basic's not going to be applicable here
746:50 - so for developers $29 us a month or 3%
746:54 - of the monthly adus usage which
746:56 - whichever is greater on the exam they're
746:58 - only going to ask you like is it $2,900
747:00 - like generally do you know the tier of
747:02 - expensiveness but they're not going to
747:04 - ask you the percentage of usage okay
747:05 - there's not going to be formulas here um
747:07 - when you get into business it's a little
747:09 - bit uh different where they have it in
747:10 - different brackets so it's going to be
747:12 - 10% for the first uh 10,000 and the next
747:15 - is going to be the next 7,000 stuff like
747:17 - that similar for Enterprise as well so
747:20 - let's just do some math so we know that
747:22 - we understand how this works so if you
747:25 - if you had a monthly spend of $500 at
747:27 - the developer tier that's 3% of $500 is
747:30 - $1 so they go okay what is greater $29
747:33 - or $15 so you're paying $29 if you're
747:36 - spent is $1,000 that comes up to $30 uh
747:39 - so you're going to end up paying $30
747:41 - because that's greater than 29 okay for
747:44 - business uh if your monthly spend is a
747:45 - th000 that's 10% of ,000 that's $100 if
747:48 - your spend is $5,000 then you're going
747:50 - to be paying $500 if your monthly spend
747:52 - is 12,000 then the first 10% of a of
747:57 - 10,000 is a th000 and then the next is
747:59 - 7% of 2,000 so your total bill is 140
748:03 - USD we're not going to do a calculation
748:04 - for Enterprise because it's the same for
748:06 - business but hopefully that gives you an
748:07 - idea there
748:09 - [Music]
748:12 - okay hey it's Andrew Brown from exam Pro
748:14 - and we are taking a look at a technical
748:16 - account manager also known as a tam and
748:18 - these provide both proactive guidance
748:20 - and reactive support to help you succeed
748:22 - with your adus journey so what does a
748:26 - tam do and this is straight from an adus
748:28 - job
748:29 - posting what they would do is build
748:31 - Solutions provide technical guidance and
748:33 - advocate for the customer ensure ad
748:35 - environments remain operationally
748:37 - healthy while reducing cost and
748:40 - complexity develop trusting
748:41 - relationships with customers
748:43 - understanding their business needs and
748:44 - Technical challenges using your
748:46 - technical uh Acumen and customer
748:49 - Obsession you'll drive technical
748:50 - discussions regarding incidents
748:52 - tradeoffs risk management consult with a
748:54 - range of Partners from developers
748:56 - through the seite executives collaborat
748:59 - with a Solutions architect business
749:01 - developers Professional Service
749:02 - consultants and sales account managers
749:05 - proactively find opportunities for
749:07 - customers to gain additional value from
749:09 - AWS provide detailed reviews of service
749:12 - disruptions metrics detailed pre-launch
749:14 - planning being uh part of a wider
749:16 - Enterprise support team providing post
749:18 - scale cons uh uh consultative expertise
749:22 - solve a variety of problems across
749:24 - different customers as they migrate
749:26 - their workloads to the cloud uplift
749:28 - customer uh capabilities by running
749:30 - workshops Brown Bag sessions Brown Bag
749:32 - sessions being sessions that occur at
749:34 - lunchtime something you can learn in 30
749:36 - minutes an hour and so one thing that's
749:38 - really important to understand is that
749:40 - Tams follow the Amazon leadership
749:42 - principles especially about customer uh
749:44 - being customer obsessed and we do cover
749:46 - the Amazon leadership principle
749:48 - somewhere in this course and Tams are
749:50 - only available at the Enterprise support
749:52 - tier so hopefully that gives you an idea
749:53 - what a
749:55 - [Music]
749:58 - does hey this is Andrew Brown from exam
750:00 - Pro in this fall along I'm going to show
750:02 - you um adus support and in order to use
750:05 - adus support or to change your level
750:07 - support you're going to need to be
750:09 - logged into the root account I should
750:10 - say you can use support with IM users
750:13 - but if you want to change the support
750:15 - plan you're going to have to be the root
750:16 - user so in the top right corner I'm
750:17 - going to support and notice here on the
750:20 - left hand side right now I have a basic
750:22 - plan
750:23 - and so before we look at changing our
750:25 - plan I'm just going to go create a case
750:28 - and we're going to uh just take a look
750:30 - at some of the options that are open to
750:32 - us so we have account billing support
750:34 - service limit increase technical support
750:36 - notice this is gray out so we cannot
750:38 - select anything here I can go to here
750:41 - and increase our service limit and this
750:44 - is something that you might have to do
750:45 - uh pretty soon early in your account you
750:47 - might say hey I need more of something
750:49 - like ec2 or um a very common thing is
750:51 - SCS
750:52 - so for SC you might say hey um I need to
750:56 - have this amount of emails for ETC okay
750:59 - so um if we go over to count and billing
751:02 - support uh we can go here and ask
751:04 - anything we want so if it's about the
751:05 - free tier I could say ask a general
751:08 - question getting started and saying uh
751:11 - what is free on
751:14 - AWS um I want to know what is free on
751:20 - AWS and you can attach uh three
751:23 - attachments there you can choose via uh
751:24 - web and phone which is really nice um
751:27 - but today I'm just going to do web here
751:29 - and submit that just to kind of show you
751:31 - that as an example and so what that is
751:33 - going to do is open a case and then we
751:34 - will see probably respond in 24 hours to
751:38 - 48 hours just depends on um whether it's
751:41 - the weekend or not because it's based on
751:42 - business hours of course so now that we
751:46 - have an understanding of basic let's go
751:47 - take a look at what the other tiers look
751:50 - like so we have basic developer business
751:51 - and ENT enterprise Enterprise being
751:53 - extremely expensive developer being
751:55 - affordable and then business being um
751:57 - you know affordable for businesses so I
752:00 - would say developer is okay it gives you
752:03 - um uh it gives you a better support but
752:05 - it's all via email and so you know if
752:08 - you really want good support you're
752:09 - going to have to pay the business one
752:11 - and that's the one that I use quite a
752:12 - bit so if I change my plan I'm going to
752:14 - go over to business and this is going to
752:16 - cost me 93 bucks just to do to show you
752:18 - here today so I'm going to go ahead and
752:20 - click that and so it's now processing it
752:24 - and so what's going to happen is I'm G
752:26 - to have to wait for this basic to switch
752:28 - to business so if I go to the case here
752:30 - it hasn't happened as of yet so noce I
752:33 - cannot select this so I'm going to see
752:35 - you back here in maybe like four or five
752:37 - minutes or however long it takes and
752:38 - we'll take a look then okay great so
752:40 - after a few minutes it says my plan is
752:42 - now business and what I can do is go
752:44 - ahead and create a new case and so I can
752:45 - go over to technical support and ask a
752:47 - question so if I was having issues with
752:49 - anything it doesn't matter what I could
752:51 - go over to ec2
752:52 - Linux and then I could choose my
752:54 - category so I could say I'm having an
752:56 - issue with um systems
753:00 - manager and a lot of times they like you
753:02 - to provide the instance ID it's going to
753:04 - change based on what service you choose
753:06 - here um but you'll get different
753:07 - information I'll just say I need
753:10 - help with um logging into my ec2
753:16 - instance managed by SSM so I can say I
753:20 - created an ec2 instance
753:22 - and I am attempting to access uh the
753:27 - instance
753:28 - via sessions
753:30 - manager but it is not
753:33 - working I think I have a rooll issue and
753:37 - then I'm just going to go down here and
753:38 - say this is not a real
753:42 - question I am filming a demo video for
753:47 - or tutorial
753:50 - video on how to use support okay and so
753:54 - once we do that we have the option of
753:56 - web chat and phone so if you use phone
753:58 - you're going to enter your phone number
754:00 - in and they're going to call you back uh
754:02 - usually you will be on hold for anywhere
754:05 - for 5 minutes to an hour it just depends
754:08 - usually it's within 15 minutes so it's
754:09 - very good of course it depends on the
754:11 - time of day and your location things
754:12 - like that and the service because
754:14 - there's different uh support Engineers
754:16 - for different types of services and the
754:18 - the balance of those are different but
754:20 - generally chat is pretty good so I can
754:22 - go here and I'm just going to hit submit
754:24 - and it's going to open a chat box and so
754:26 - you just wait okay and sometimes it's
754:30 - super fast and sometimes it takes uh
754:33 - minutes okay so we are going to just sit
754:36 - here for a bit and um you know I'll just
754:39 - pop back here when there is somebody to
754:41 - talk to
754:42 - okay okay so after waiting a little
754:44 - while looks like uh we've been connected
754:46 - here so it took a bit of time so we're
754:49 - just going to say hello hi um uh this
754:52 - this is Andrew
754:53 - Brown um I am recording a video to teach
754:58 - people how to use
755:00 - AWS and I wanted to show them how AWS
755:05 - support
755:08 - works so I'm just showing them how the
755:12 - chat system
755:15 - works say
755:20 - hello
755:23 - and hopefully they'll appreciate or they
755:25 - won't it just doesn't really
755:36 - matter we'll give them a
755:49 - moment there we go
755:54 - that's
755:56 - it thanks for your
755:59 - help okay and so that's pretty much it
756:02 - um so you know there's nothing really uh
756:05 - uh special about that but the idea is
756:06 - when you are typing with them it will
756:08 - appear in the correspondence there so
756:10 - I'm just going to end the chat okay uh
756:13 - and then I'm just going to mark that
756:14 - case as resolve sometimes they will ask
756:16 - you to resolve it if I go to cases I
756:19 - probably have some previous ones here um
756:21 - I have a lot but I don't know why they
756:23 - don't all show up here so you can see
756:25 - this one is pending this one is resolved
756:27 - I go back to this one you can kind of
756:29 - see that the uh history of a
756:31 - conversation is kept and you can go back
756:32 - and forth uh with the people there um
756:36 - yeah that's pretty much it uh you can
756:37 - also do screen sharing so they might
756:39 - send you request to go on Zoom or
756:42 - download this piece of software that
756:43 - shares your screen and so that is
756:45 - another option as well so they can get
756:47 - pretty handson to help you uh with your
756:50 - problems there but that's pretty much
756:51 - all I want to to show you with support
756:53 - I'm going to downgrade this and I'm not
756:54 - sure if they're going to give me back my
756:55 - money sometimes they'll prate it for you
756:57 - but I'm go here and go back to basic um
757:00 - so we will also refund your credit card
757:02 - directly in the month's remaining fees
757:04 - on your old plan which you previously
757:06 - paid you're obligated to pay a minimum
757:08 - of 30 days of support each time you
757:10 - register so I'm not going to get any
757:11 - money back which is totally fine because
757:13 - I just wanted to show you how that works
757:14 - but business support is definitely worth
757:16 - it and uh you know that's
757:20 - it
757:22 - [Music]
757:24 - so the anabis marketplace is a curated
757:26 - digital catalog with thousands of
757:28 - software listings from independent
757:30 - software vendors uh easily find buy test
757:33 - and deploy software that already runs an
757:34 - ads the product can be free to use or
757:37 - can have an Associated charge the charge
757:39 - becomes part of your adus bill and once
757:41 - you pay adus Market pays the provider
757:44 - the sales channel for isv and Consulting
757:46 - Partners allow you to sell your
757:47 - solutions to other adus customers
757:49 - products can be offered such as Ami
757:52 - a CL information templates software of
757:54 - service offerings web ACLS ABS WAFF and
757:57 - rules so it sounds great um if you want
757:59 - to sell here I think you need like a US
758:01 - bank account to do it um and you know
758:05 - sometimes Aus Marketplace is just part
758:06 - of AWS so like when you're using the ec2
758:09 - marketplace you are technically using
758:10 - the itus marketplace um but they also
758:12 - have like a dedicated page for it so
758:14 - it's integrated with some services and
758:16 - it's also Standalone
758:20 - okay
758:21 - [Music]
758:23 - hey this is Andrew Brown from exam Pro
758:24 - and in this follow along we're going to
758:25 - take a look at the adus marketplace so
758:27 - what I want you to do is go on the top
758:29 - and type in Marketplace and that will
758:31 - bring us over to here the marketplace
758:33 - can be found in a variety of different
758:34 - places on the platform here you can see
758:36 - that uh previously it was using
758:38 - something called guacamole Bastian host
758:40 - to launch a server um but the idea is
758:43 - that um you can discover products and
758:44 - subscriptions that you might want to
758:46 - utilize so if I go over here there's a
758:49 - variety of different things
758:52 - and so it could be like I want to have
758:54 - something like a firewall that might be
758:57 - something that we might be interested in
758:59 - so we could search there and there's
759:00 - like bring your own license firewall so
759:02 - maybe you have a license with this and
759:03 - you want to run it on an ect2 instance
759:06 - something like that again it's not like
759:08 - super complicated U what's going on here
759:11 - but a lot of times you know when you're
759:12 - using Services you're accessing the
759:14 - marketplace anyway so like when I'm
759:16 - launching an ec2
759:18 - instance notice on the left hand side
759:20 - says ABS Marketplace and so I don't have
759:22 - to go to the marketplace there I can
759:23 - just kind of like check out the thing I
759:25 - want um and that's pretty much all there
759:27 - really is to it okay so you know
759:29 - hopefully that makes
759:33 - sense let's take a look here at
759:35 - Consolidated billing so this is a
759:36 - feature of Abus organizations that
759:38 - allows you to pay for multiple accounts
759:40 - via one bill so the idea here is we have
759:43 - a master account and we have member
759:45 - accounts and I I'm pretty sure that we
759:47 - probably call this root account now I
759:48 - don't think uh master account might be a
759:49 - data term but it's still showing up in
759:51 - the document mentation the idea is that
759:53 - if you have member accounts within your
759:54 - organization they're all going to be
759:56 - Consolidated under the single account if
759:58 - you have an account outside of your
759:59 - organization um you know this is not
760:02 - going to give you uh this is going to be
760:03 - basically a separate bill um as if it's
760:06 - like a standalone organization or what
760:08 - have you okay so uh for billing adus
760:11 - treats all accounts in an organization
760:13 - as if they were one account you can
760:15 - designate one uh uh master or root
760:18 - account that pays the charges for all
760:20 - the other member accounts consolidate
760:22 - billing is offered at no additional cost
760:24 - you can use uh cost Explorer to
760:26 - visualize usage for Consolidated billing
760:29 - which we can see I have the icon here uh
760:31 - you can combine the usage across all
760:33 - accounts in the organization to uh to
760:35 - share the volume pricing discount which
760:37 - we did Cover in this course separately
760:39 - if you want an account to be able to
760:41 - leave the organization you do have to
760:43 - attach it to a new payment method so if
760:46 - let's say you had an account and you
760:47 - want to give it to your friend or
760:48 - whatever they're have to hook up their
760:49 - uh their credit card but you can totally
760:51 - have have uh an account leave an
760:53 - organization but you have to deal with
760:54 - that billing aspect
760:56 - [Music]
761:00 - okay all right so there's a really cool
761:03 - way to save an ads and that's through
761:04 - volume discounts and it's available for
761:06 - many services the more you use the more
761:08 - you save is the idea behind it um and so
761:11 - consolidating building lets you take
761:12 - advantage of volume discounts this is a
761:14 - particular feature of adus organization
761:16 - so if you do not have the or turn on
761:18 - you're not going to be able to take
761:19 - advantage of that okay so example would
761:22 - be something like data transfer where it
761:24 - is build uh for the first 10 terabytes
761:26 - at at 17 cents or sorry 17 cents and
761:31 - then the next 40 terabytes it will be
761:33 - AT3 cents okay so if we had two accounts
761:37 - um such as Odo and Dax and they're not
761:39 - within an abl organization we can
761:41 - calculate those and see what they are
761:43 - unconsolidated and just so you know one
761:45 - terab equals 1024 gabes and that's what
761:48 - you're going to see in these
761:48 - calculations so for Odo uh you know if
761:51 - you has 4 terabytes and that is uh we
761:54 - calculate the gigabytes there we times
761:55 - it by uh the um scent value there we're
761:59 - going to get
762:00 - $696 okay for Dax we're going to end up
762:03 - with uh about $ 1392 there and so if we
762:07 - were to add those up the bill would come
762:09 - out to
762:11 - $2,088 okay so the idea is that there's
762:14 - an organization and they like a your
762:16 - company and they created two accounts
762:18 - but they're just not within an
762:19 - organization by having them in the
762:21 - organization you're going to save um
762:23 - about almost $80 there so um that is a
762:28 - reason why you'd want to use volume
762:29 - discounts
762:30 - [Music]
762:33 - okay hey this is Andrew Brown from exam
762:36 - Pro and we're taking a look at Abus
762:37 - trusted advisor so trusted advisor is a
762:39 - recommendation tool which automatically
762:41 - and actively monitors your adus accounts
762:43 - to provide actional recommendations
762:46 - across a series of categories so this is
762:48 - what it looks like I personally prefer
762:50 - the older dashboard but this is what
762:52 - they have now and you can see along the
762:54 - side we have a bunch of categories and
762:56 - then we have some checks here saying uh
762:58 - you know what are we meeting what are we
762:59 - not and you can go in and read each one
763:02 - and they'll tell you so much information
763:04 - they'll even show you like what things
763:06 - are not meeting that requirements in
763:08 - some case you can easily remediate by
763:10 - pressing a button not in all cases but
763:12 - the thing with ad trust advisor is think
763:14 - of AD trust advisor like an automated
763:16 - checklist of best practices on AWS and
763:19 - they kind of map to the pillars of the
763:21 - well architecture framework not exactly
763:23 - but pretty close but there are five
763:25 - categories of adus trusted advisor so we
763:28 - have cost optimation how much money can
763:30 - we save performance so how can uh we
763:33 - improve performance security how can we
763:35 - improve security fall tolerance how we
763:37 - can we prevent a disaster or data loss
763:41 - and service limits so are we going to
763:43 - hit the maximum limit for a service and
763:46 - so uh the next thing we need to discuss
763:48 - is um there's a VAR creation of the
763:51 - amount of checks that are available to
763:53 - you based on your support plan so you
763:55 - know if you're using basic or developer
763:56 - you have seven trusted advisor checks
763:59 - and if you have business Enterprise you
764:00 - have all the trusted advisor checks so
764:03 - uh if we're talking about just the ones
764:04 - that are available to you the ones that
764:06 - come for free is MFA on root account
764:08 - security groups specified ports of
764:10 - unrestricted Amazon S3 bucket
764:11 - permissions Amazon EBS public snapshots
764:14 - Amazon RDS public snapshots I amus so
764:18 - this is just about alerting you about
764:19 - discouraging the use of the root account
764:21 - service limits so all service limit
764:24 - checks are free um it's weird cuz they
764:26 - call it the like seven Security checks
764:28 - but if you counted all the service
764:30 - limits it obviously be too large of a
764:32 - number but notice that 1 through six are
764:34 - all Security checks so you're not
764:36 - getting anything from the other tiers
764:38 - just the security tier and what I want
764:40 - to do is just go over a bunch of
764:43 - available checks out there it's probably
764:45 - not the full list because I couldn't
764:46 - even be bothered to update it if they've
764:48 - added more but it will give you a
764:49 - general idea of what you could expect
764:51 - under each category so for cost
764:53 - optimization um it could be things like
764:55 - looking at idle load bouncers so you
764:58 - know if you have load bouncers you're
764:59 - not using you're paying for them so get
765:01 - rid of them unassociated elastic IP
765:03 - addresses so for every IP that's not
765:05 - associated you're paying for as well
765:07 - maybe under performance you have um High
765:09 - utilization of Amazon ec2 instances so
765:12 - maybe you can save money by switching to
765:14 - smaller instances under security we saw
765:16 - MFA on rout account very popular one
765:19 - making sure you turn on key rotation
765:21 - could be something as well there under
765:23 - fault tolerance um it could be making
765:26 - sure that you're using backups on your
765:27 - Amazon RDS database maybe that's turned
765:29 - off uh for service limits there's just a
765:32 - ton of them and so uh one that that you
765:35 - know might be PR to use vpcs or ec2
765:38 - limits so there you
765:39 - [Music]
765:43 - go hey this is Andrew Brown from exam
765:45 - Pro and we're going to take a look at
765:46 - trusted advisor so what I want you to do
765:48 - is go to the top and type in trusted
765:50 - advisor
765:52 - and once you're there you're going to
765:53 - notice on the left hand side we have
765:54 - cost optimization performance security
765:56 - fault tolerance and service limits right
765:58 - now there are no recommended actions
766:00 - because there's not much going on this
766:01 - account and when you uh have the uh Free
766:05 - level of support the basic support
766:06 - you're not going to have all these
766:07 - checks but if we go in here we can still
766:09 - see kind of what they do um so we have
766:12 - like performance security things like
766:14 - that so these are the ones that we
766:16 - actually can see and they generally work
766:18 - all the same way if you expand here it's
766:20 - going to say
766:21 - Amazon EBS public snapshot so check the
766:23 - permission settings for the EBS volume
766:25 - snapshots and alert you if the any
766:28 - snapshots are marked as public and so if
766:31 - you scroll on down if there were ones
766:32 - that were an issue it would tell you
766:34 - right here okay then down below here we
766:38 - see like check buckets in Amazon S3 that
766:40 - have open access permissions or allow
766:43 - access to authenticated adist users so
766:46 - yellow the ACL allows uh list access for
766:49 - everyone uh a bucket policy allows for
766:52 - any kind of Open Access bucket policy
766:54 - statements have public Grant access so
766:56 - maybe what we can do is to see if we can
766:58 - get this to
766:59 - trigger and so what I'm going to do here
767:01 - is go over to S3 and what we're going to
767:04 - do is make a B bucket that has a full
767:07 - axis okay so I'm going to create a new
767:09 - bucket and it'll say my exposed
767:12 - bucket we'll scroll on down here and
767:15 - we'll just checkbox that off and create
767:16 - the bucket we say I acknowledge that is
767:19 - totally fine
767:22 - okay so now I have a bucket that is 100%
767:25 - exposed if we go back to trust advisor
767:27 - give this a
767:28 - refresh I'm not sure how fast it will
767:30 - show up here but if I
767:32 - expand so it says the bucket ACL allows
767:36 - upload delete for everyone The Trusted
767:38 - adviser does not have permissions to
767:39 - check the policy uh bucket policy has
767:42 - statements that Grant Public
767:44 - Access so what we could try to do is
767:48 - make a
767:49 - policy
767:54 - and try to Grant all access here so I'm
767:57 - not writing these every single day but
767:58 - I'm sure we could try to figure this
768:02 - out
768:05 - um we'll say S3 bucket policy Public
768:09 - Access public
768:18 - read and so that one might be a good
768:20 - example so I'm going to go ahead and
768:21 - copy this one granting readon permission
768:23 - to anomymous
768:25 - users I don't recommend you doing this
768:27 - I'm just doing this to show you to see
768:28 - if we can get the trusted advisor to
768:30 - check because I don't want you to uh do
768:32 - this and forget about it and then have a
768:34 - serious issue but the principle is set
768:35 - to anybody so anyone can read it here
768:38 - it's saying get object Etc then it's
768:40 - saying what particular resource so this
768:42 - one is going to be for uh the bucket in
768:45 - question here which is my
768:47 - exposed
768:49 - bucket we're going to scroll on down
768:52 - save the
768:53 - changes okay so this bucket is publicly
768:56 - accessible we're going to go back over
768:57 - here refresh and see what we can
769:03 - see okay so checks buckets in S3 Etc so
769:07 - it should appear under
769:09 - here and it could be that it's just
769:11 - going to take some time so what I'm
769:13 - going to do is I'm just going to hang
769:14 - tight for a little bit oh there we go
769:17 - okay so it's showing up and I guess it
769:19 - just took some time top poate and so
769:21 - here we can see we have a a yellow
769:23 - symbol it's a warning saying hey there's
769:25 - a problem here if we go back to the
769:27 - dashboard I wonder if that shows up so
769:28 - this one's for investigation and
769:31 - recommendation so you know hopefully
769:33 - that kind of makes sense to you I think
769:34 - in some cases you can do remediation
769:36 - from from here or at least you can go
769:39 - and check box and say okay um
769:43 - ignore could of swore there was
769:44 - remediation for some of
769:47 - these but in any case you know that's
769:49 - generally what trusted advisor does um I
769:52 - think that you probably can have it so
769:54 - it gives you alerts so yeah you could
769:56 - set recipients for particular things
769:58 - like if there's a security issue then I
770:00 - could email a particular person on your
770:02 - team and they could deal with it but
770:04 - that's pretty much it so what I'm going
770:05 - to do is go ahead and delete this bucket
770:06 - I'm all done with
770:08 - it we'll go
770:11 - delete and say my delete uh my exposed
770:14 - bucket here to delete it and that is it
770:19 - okay
770:20 - [Music]
770:25 - let's cover the concepts of service
770:26 - level agreements also known as SLA so an
770:29 - SLA is a formal commitment about the
770:31 - expected level of service between a
770:32 - customer and provider when a service
770:34 - level is not met and if customer meets
770:36 - its obligation under the SLA customer
770:38 - will be eligible to receive compensation
770:40 - so Financial or service credits and so
770:43 - when we talk about slas then we talk
770:44 - about SLI so SLI service level indicator
770:47 - is a metric or measurement that
770:49 - indicates what measure per performance
770:50 - the customer is receiving at a given
770:52 - time a SLI metric could be uptime
770:55 - performance availability throughput
770:56 - latency error rate durability
770:58 - correctness and if we're talking about
771:00 - sis then we're talking about slos
771:02 - service level objectives so the
771:03 - objective that that the provider has
771:05 - agreed to meet SLS are represented as a
771:07 - specific Target percentage over a period
771:09 - of time and so an example of a Target
771:13 - percentage would be something that says
771:15 - an availability SLA of
771:17 - 99.99% in a period of three months all
771:20 - right
771:21 - and let's just talk about Target
771:22 - percentages and the way they can be
771:23 - represented very common ones we will see
771:25 - is
771:27 - 99.95%
771:30 - 99.99% uh then we have 99 followed by
771:34 - 99 and so commonly we just say we call
771:37 - this 99 okay and then there's one 911s
771:41 - so if somebody says we have an SLA
771:42 - guarantee of of 9911 it's going to be
771:45 - the 99 followed by 911s all
771:49 - right
771:52 - [Music]
771:53 - let's take a look at Abus service level
771:55 - agreements and so there are a lot of
771:57 - them and I just wanted to just show you
771:59 - a few services to give you an idea how
772:01 - they work uh on the exam they're not
772:03 - going to ask you like oh what's dnb's
772:05 - SLA for Global tables um but generally
772:09 - we should just go through this because
772:10 - it's good practice so let's take a look
772:11 - at dynamodb SLA so adus will use
772:14 - commercially reasonable efforts to make
772:15 - dyab to be available with a monthly
772:17 - uptime percentage of each adus region
772:19 - during any monthly billing cycle uh so
772:22 - for a at least
772:24 - 99.999% if Global tables slas applies or
772:29 - 99.99% if the standard SLA applies and
772:32 - the event Dynamo DB does not meet the
772:33 - service commitment you'll be eligible to
772:35 - receive service credits described below
772:38 - so we have monthly uptime percentage and
772:40 - the service credit percentage we get
772:41 - Global tables standard tables so let's
772:44 - take a look here so if less than
772:47 - 99.999% but equal to or greater than 9
772:50 - 9.0% is met so if if the service ends up
772:54 - being this you'll get 10% back of what
772:57 - you spent as service credits if it drops
772:59 - between U 99.0 and 95.0 you get 25% back
773:04 - if it's less than 95 uh percent um then
773:08 - it's 100% back okay and you get the
773:11 - general idea here SLA is going to be
773:13 - slightly different with their drops now
773:15 - let's take a look at um a compute and so
773:17 - compute is going to apply across a bunch
773:19 - of compute services
773:21 - probably because they're all using ec2
773:23 - underneath so that's probably the reason
773:24 - for it so we have ec2 EBS ECS eks and
773:29 - Abus uh makes two SLA commitments uh for
773:32 - the included services so we have a
773:34 - region level SLA that uh governs
773:36 - included Services deployed across
773:38 - multiple azs or regions and an instance
773:40 - level SLA that governs Amazon ec2
773:42 - instances individually and again we have
773:45 - our monthly up up time percentage our
773:47 - service C percentage region and instance
773:49 - level so you can just see the same thing
773:51 - it's like it's going to change based on
773:54 - uh what it can meet then we'll take a
773:56 - look at one more like RDS so a
773:58 - relational database service so it will
774:02 - use commercially reasonable efforts to
774:03 - make multi- a instances available with
774:05 - monthly uptime percentage of 99.95%
774:08 - during any monthly billing cycle and
774:10 - again you know if if they don't meet
774:12 - those requirements you're going to get
774:13 - service credits back which basically
774:14 - equal USD dollars on the platform and so
774:17 - for this it looks like that so just
774:19 - notice that you know with like compute
774:21 - it was for a a bunch of services for
774:23 - Dynamo DB it was based on uh particular
774:26 - features like global standard tables SLA
774:28 - it's very straightforward uh we didn't
774:30 - do S3 because I just did not want to
774:32 - show you that one it was just too
774:33 - complicated but my point is is that it's
774:35 - going to vary so you have to look up per
774:37 - service
774:38 - [Music]
774:42 - okay hey this is Andrew Brown from exam
774:44 - Pro and we are taking a look at Amazon's
774:46 - service level agreements and so the way
774:48 - you find slas is you pretty much just
774:51 - type in SLA for whatever it is so if
774:53 - you're looking for compute you type in
774:54 - SLA or you look for a particular service
774:56 - so maybe you say sage maker SLA AWS I
775:00 - don't think there's like a generic SLA
775:02 - page at least I don't know where it is I
775:04 - always just type in SLA to find what it
775:05 - is and through that you can just kind of
775:07 - read through and try to find out uh the
775:10 - things that that matter to you for your
775:12 - business
775:13 - [Music]
775:16 - okay let's take a look here at the
775:19 - service Health dat board and so the
775:21 - service Health dashboard shows General
775:23 - status of adus services and it's really
775:25 - simple the idea is that you can uh check
775:27 - based on the geographic area so you'd
775:30 - say North America Europe Etc and what
775:33 - you'll see is an icon that says whether
775:34 - the service is in in good standing and
775:37 - the details whether the service is
775:38 - operating normally Etc notice they also
775:40 - have an RSS feed the reason I'm talking
775:42 - about service Health dashboards is
775:44 - because I want to talk about personal
775:45 - health dashboards and because they're
775:47 - both called Health dashboards it's
775:49 - confusing so I wanted to to tell you
775:50 - about this one first so now we'll jump
775:52 - into the adus personal health
775:57 - dashboard so we saw the service Health
776:00 - dashboard now let's take a look at the
776:02 - adus personal health dashboard so this
776:04 - is what it looks like and it provides
776:06 - alerts and guidance for adus events that
776:08 - might affect your environment all adus
776:10 - customers can access the personal health
776:12 - dashboard the personal health dashboard
776:14 - shows recent events to help you manage
776:16 - active events and show proactive
776:18 - notifications so that you can plan for
776:20 - scheduled activities you uh you can use
776:22 - these alerts to get notified about
776:24 - changes that can affect your aess
776:25 - resources and then follow the guidance
776:27 - to diagnose and resolve the issue so
776:30 - this is very similar to the service
776:32 - Health dashboard but it's personalized
776:34 - for you um and it's uh you know I I
776:37 - don't see it crop up very often but if
776:39 - you had to create alerts or be reactive
776:42 - to uh things that are happening within
776:44 - your bus this is where you do it
776:49 - okay
776:50 - so there's a team called adus trust and
776:53 - safety that specifically deals with
776:54 - abuses occurring on the adus platform
776:57 - and so I'm going to just list of all the
776:58 - cases where you'd want to be contacting
777:00 - them as opposed to support so the first
777:02 - is Spam so you're receiving unwanted
777:04 - emails from an Abus owned IP address or
777:06 - adus resources are used to spam websites
777:08 - or forms Port scanning your log show
777:11 - that one or more adus owned IP addresses
777:13 - are sending packets to multiple ports on
777:15 - your server uh you also believe uh this
777:17 - is an attempt to discover unsecured
777:19 - ports
777:20 - uh dos attack so your logs show that one
777:22 - or more itus owned IP addresses are used
777:24 - to flood ports on your resources with
777:26 - packets you also believe this is an
777:27 - attempt to overwhelm or crash your
777:29 - server or the software running on your
777:31 - server intrusion attempts so your logs
777:33 - show that one or more ad owned IP
777:35 - addresses are used to attempt to log
777:36 - into your resources hosting prohibited
777:39 - content so you have evidence that adus
777:41 - resources are used to host distribute
777:42 - prohibited content such as illegal
777:44 - content or copyrighted content without
777:46 - the consent of the copyright holder
777:48 - Distributing malware so you you have
777:50 - evidence that abis resources are used to
777:51 - distribute software that was knowingly
777:53 - created to compromise or cause harm to
777:56 - computers machines that it's installed
777:58 - on and so in any of these cases you're
778:00 - not going to adus support you're going
778:02 - to open up an abuse ticket and so you
778:04 - got to contact abuse at Amazon
778:07 - aus.com or fill out the uh uh Amazon
778:11 - abuse uh form so and this is whether
778:14 - it's coming from uh an outside AOS
778:16 - account or even you're internally if you
778:18 - think that some someone is compromise
778:20 - your account and it's being used in any
778:21 - of these ways uh this is what you're
778:23 - going to do
778:24 - [Music]
778:28 - okay hey this is Andrew Brown from exam
778:30 - Pro and we're looking at ads abuse so uh
778:33 - we were saying that ads has the ads
778:34 - trust and safety team and what you'll
778:37 - want to do is if you uh find that
778:39 - there's an issue you're going to report
778:40 - it to this email at abuse Amazon.com or
778:43 - you're going to use this form which is
778:45 - the report Amazon a abuse so you'll go
778:47 - down here you'll sign in you'll put your
778:49 - email email in your first name last name
778:51 - or phone number um The Source IP the the
778:54 - details uh uh in uh here you can even
778:57 - select the type of abuse so you say if
778:59 - it's this kind or that kind things like
779:01 - that it's very straightforward um and
779:03 - that's pretty much it
779:04 - [Music]
779:08 - okay hey this is Andrew Brown from exam
779:10 - Pro and we are taking a look at the itus
779:12 - free tier and this allows you to use
779:14 - adus at no cost um and when we say free
779:16 - tier there there there's the idea of the
779:19 - first 12 months of sign up there's going
779:20 - to be special offerings or it's free
779:23 - usage up to a certain monthly Limit
779:25 - Forever um and then there's just
779:27 - services that are inherently free which
779:29 - we have a total separate slide on but
779:30 - let's talk about just the free tier
779:32 - stuff and this is absolutely not the
779:34 - full list um but uh it's a good ide like
779:37 - it gives you a good um overview of stuff
779:39 - that is free so for ec2 which you use a
779:42 - web server you get a T2 micro for 750
779:44 - hours per month for one year and so
779:48 - there's about 730 hours
779:50 - um in a month and so that means you
779:52 - could have a server
779:54 - running uh the entire month for free uh
779:58 - and an additional server for a bit as
780:00 - well so for RDS which is a relational
780:03 - database service for either my school or
780:05 - postgress we can do it T2 DB micro for
780:08 - 750 hours for free so there we get our
780:11 - free database and you would be surprised
780:13 - how far you can get with a uh a T2 DB
780:16 - micro um you know even for a mediumsized
780:19 - startup you can run it on uh a T2 DB
780:21 - micro with no problems then you have
780:23 - your elasic load balancer you get 750
780:25 - hours per month for one year um so that
780:28 - is a really good thing uh load balancers
780:30 - usually cost $15 a month so that's great
780:32 - actually all these pretty much cost $15
780:34 - a month so that's about um 1530 $45
780:38 - month over month for a year that's uh
780:40 - free then you have Amazon cloudfront
780:42 - this is where you'd have your homepage
780:44 - caching your videos things like that so
780:45 - you get 50 GB data transfer out for the
780:48 - total of year then there's Amon connect
780:50 - you get your total free number there 90
780:51 - minutes of a call time per month for one
780:53 - month or for one year sorry Amazon
780:55 - allows to cash so you could launch a
780:57 - redis or elastic cach server you get 70
781:00 - hours on a cash T3 micro for a year um
781:04 - elastic search service so this is full
781:06 - Tech search so again 750 hours per month
781:09 - for one year pinpoint campaign markting
781:11 - email so you can send out 5,000 targeted
781:13 - users per month for one year SC so um
781:16 - simple email uh service so this is for
781:19 - um transactional emails um so that you
781:21 - send out from your web app so 62,000
781:23 - emails per month forever it those code
781:25 - pipeline so one pipeline free it was
781:28 - code build so uh this is for building
781:30 - out projects or things like that so 100
781:33 - build minutes per month forever it was
781:36 - Lambda service compute 1 million free
781:38 - requests per month 3.2 million uh
781:41 - million seconds of compute time per
781:42 - month for free uh and you know I like to
781:45 - highlight these ones because for
781:46 - traditional architecture you're always
781:47 - going to have a web server a database a
781:50 - load balancer um and you might even have
781:52 - cloudfront in there as well but uh yeah
781:55 - again there's a huge list and this does
781:57 - not even tap the surface of what's free
781:59 - on
782:00 - [Music]
782:03 - AWS hey this is Andrew Brown from exam
782:05 - Pro and we are taking a look at adus
782:07 - promotional credits and these are the
782:08 - equivalent to USD dollars on adus
782:10 - platform adus credits can be earned
782:12 - several ways this could be joining ad
782:15 - activate startup program winning a
782:16 - hackathon participating surveys and any
782:19 - other reason that ad us wants to give
782:20 - credits out uh once you uh have um a
782:24 - promotional code you click the redeem
782:25 - credit button in the billing console you
782:27 - enter it in and then your credits will
782:29 - be shown there you can monitor them via
782:31 - it budgets or uh via cost Explorer and
782:34 - probably even building alarms itus
782:36 - credits generally have an expired dat
782:37 - tax them could be a few months uh to a
782:39 - year itus credits can be used for most
782:41 - services but there are exceptions where
782:42 - itus credits cannot be used like
782:44 - purchasing a domain via row 53 because
782:47 - uh that domain costs money outside of
782:49 - adses cost like for their infrastructure
782:51 - and virtual stuff and so for things like
782:54 - that uh you know they're not going to be
782:55 - you're not going to be able to use
782:56 - credits for that
782:57 - [Music]
783:01 - okay the adabas partner Network also
783:04 - know as APN is a global partner program
783:06 - for ad best so joining the APN will open
783:09 - your organization up to business
783:10 - opportunities and allow exclusive
783:12 - training and marketing events so when
783:14 - joining the APN you can either be a
783:16 - Consulting partner so you help companies
783:18 - utilize datab bus or a technology
783:20 - partner you build technology on top of
783:22 - ABS as a service offering and a partner
783:24 - belongs to a specific tier so it's
783:26 - either going to be select advance or
783:28 - Premiere when you sign up it's free to
783:30 - sign up but you're not going to be able
783:31 - to do much until you start uh committing
783:33 - to an annual fee so that's it's like a
783:36 - certain amount of money to uh be able to
783:39 - be part of that tier and it starts in
783:40 - the thousands okay so I think the first
783:42 - tier is like something like a th000 or
783:43 - $2,000 and it gets uh more expensive as
783:46 - you go up as a tier and you also have to
783:48 - have particular knowledge requirements
783:50 - so this could be holding uh particular
783:52 - adus certifications at the at the
783:55 - foundational level at the associate
783:57 - level things like that um or it could be
784:00 - adus APN exclusive certification so
784:02 - training that um is not adus
784:04 - certifications but there's
784:05 - certifications that are only available
784:07 - to Partners saying like how do you it
784:09 - could be like something like how do you
784:11 - uh talk to customers or communication
784:13 - things like that you can get back
784:15 - promotional Abus credits so you know if
784:18 - you say Oham I spent uh
784:20 - $22,000 on just being able to uh get
784:23 - into the APN at least the idea is that
784:26 - you can generally get back that uh that
784:28 - spend on AWS so it's like you committing
784:31 - if you give like $2,000 it's like you're
784:33 - going to commit to keep using AWS I'm
784:35 - not showing the annual fee commitments
784:37 - here and the promotional credits that
784:39 - you get back just because they've
784:40 - changed it a couple times on me and I
784:42 - just don't want this slide to go stale
784:44 - in case they happen to change it again
784:45 - so you'll have to look that up to find
784:47 - out what they actually are right now uh
784:49 - you can have unique speak speaking
784:50 - opportunities in the official adus
784:52 - marketing channels like the blogs or
784:53 - webinars being part of the APN is a
784:56 - requirement to be a sponsor with a
784:57 - vendor booth at ads event so when you
784:59 - when you go to reinvent or any ads um
785:02 - event all the vendors are part of the
785:04 - APN all right so they've paid their fee
785:06 - and now they paid an additional fee to
785:07 - get their Booth but um yeah AB partner
785:10 - network uh is very good for uh uh
785:13 - helping you find new business and
785:15 - connecting with other people that are
785:16 - building workloads on AWS but hopefully
785:18 - that gives you an idea of how works
785:20 - [Music]
785:23 - okay hey this is Andrew Brown from exam
785:25 - Pro and we are taking a look at abis
785:27 - budgets so Abus budgets gives you the
785:29 - ability to set up alerts if you exceed
785:31 - or approaching your defined budget
785:33 - create cost usage or reservation budgets
785:36 - it can be tracked at the monthly
785:38 - quarterly or yearly levels with
785:40 - customizable start and end dates alert
785:42 - support ec2 RDS red shift elastic cast
785:46 - reservations uh and so the idea here is
785:48 - you can choose your budget amount so it
785:50 - could be like $100 it'll even show you
785:52 - what was the last amount if you're uh
785:54 - resetting the budget there something new
785:57 - you can choose based on a different kind
785:59 - of unit so if you wanted to be based on
786:01 - running hours on ec2 you could totally
786:04 - do that is budgets can be used to
786:06 - forecast costs but is limited compared
786:07 - to cost Explorer or doing your own
786:09 - analysis related with cost and usage
786:11 - reports along with business intelligence
786:13 - tools budgets uh based on a fixed cost
786:16 - or or you can plan your cost uh UPF
786:18 - front based on your chosen level can be
786:21 - easily managed from the ads budgets
786:23 - dashboard via the ads budgets API get
786:26 - notified by providing email or chatbot
786:28 - and threshold uh how close to the
786:30 - current or forecasted budget um so you'd
786:32 - see a list of budgets here uh current
786:34 - versus forecasted the amount used things
786:36 - like that you can see your budget
786:38 - history you can download a CSV uh it'll
786:41 - show you the cost history right in line
786:42 - there which I can't show you it it's
786:44 - hard to see there you get the first two
786:46 - budgets are free so there's no reason
786:48 - not to set a budget when you first first
786:49 - get into AWS and each budget costs about
786:52 - uh 002 cents a day so it's like 60 cents
786:55 - um uh USD per month for budget so
786:57 - they're very cheap to use and you got a
786:58 - limit of 20,000 budgets you're going to
787:00 - be in good shape
787:02 - [Music]
787:05 - okay let's take a look here at Abus
787:07 - budget reports which is used alongside
787:09 - abos budgets to create and send daily
787:11 - weekly or monthly reports to monitor the
787:13 - performance of your Aus budgets it will
787:15 - be emailed to specific emails so it's
787:17 - not too complicated here you say create
787:18 - the report budget choose your frequency
787:21 - uh the emails you want um and budget
787:24 - report serves as a more convenient way
787:25 - of staying on top of report since
787:27 - they're delivered to your email instead
787:28 - of logging into the abis Management
787:30 - console so it's just for those people
787:31 - that just can't be bothered to log in
787:33 - [Music]
787:36 - okay let's take a look here at abis cost
787:39 - and uses report so generate a detailed
787:41 - spreadsheet enabling you to better
787:43 - analyze and understand your Aus cost so
787:44 - this is kind of what it looks like and
787:46 - when you turn this feature on it will
787:48 - place it into an S3 bucket you could use
787:50 - something like Athena to turn the report
787:51 - into a queriable database since it's
787:53 - very easy to consume S3 csvs into Athena
787:56 - you could use Quick site to visualize
787:58 - your building data as grass so quick
788:00 - site is a business intelligence tool
788:03 - similar to Tableau or powerbi you could
788:06 - also ingest this into red shift um but
788:10 - the idea here is when you turn it on you
788:11 - can choose how granular you want the
788:13 - data to be hourly daily or monthly if
788:15 - you turn on daily you'll be able to even
788:17 - see spikes of uh of of of costs for uc2
788:21 - instances which is kind of nice the
788:23 - report will contain cost allocation tags
788:26 - um which I think we have a separate
788:27 - slide on that type of tags and the data
788:30 - is stored in e as either a CSV it'll be
788:33 - zipped or it will be a parket format it
788:35 - just depends on how you want it um uh
788:38 - for that
788:39 - [Music]
788:42 - okay let's talk about cost allocation
788:45 - tags so these are optional metadata that
788:47 - can be attached to adus resour resources
788:49 - so when you generate out a cost and uses
788:51 - report you can use that data to better
788:53 - analyze your data so what you'd have to
788:56 - do is make your way over to cost
788:57 - allocation tags and need to activate the
789:00 - tags you want to show up there are two
789:02 - types of tags so we have user Define so
789:04 - whatever you've previously tagged will
789:06 - show up probably there you turn it on so
789:08 - if you made one with project you turn on
789:10 - project and there's a lot of adus
789:11 - generated ones that you can turn on so
789:14 - there's a huge list there but uh yeah
789:17 - that's particular with cost um usage and
789:20 - reports if it says like cost allocation
789:22 - reports it's just that's what cost and
789:23 - usage reports used to be called um and
789:26 - some of the documentations a bit old
789:27 - there but yep there you
789:28 - [Music]
789:32 - go so you can create your own alarms in
789:35 - cloudwatch alarms to monitor spend and
789:37 - they're commonly called building alarms
789:39 - uh and so it's just a regular alarm but
789:41 - it's just focused on spend but in order
789:43 - to do this you have to turn on building
789:45 - alerts first in order to uh be able to
789:47 - use it uh and then you'll go to
789:49 - cloudwatch alarms and you can choose
789:51 - billing as your metric and then you just
789:53 - set your alarm however you'd want
789:55 - billing alarms are much more flexible
789:56 - than abess budgets and are ideal for
789:58 - more complex use cases for monitoring
790:00 - spend and usage in terms of alerting so
790:04 - you just have to decide what you want to
790:05 - do uh before it those budgets this was
790:07 - the only way to do it and so this is the
790:09 - way I'm used to doing it and I still do
790:11 - it this way today but uh you know both
790:13 - options are valid and just have to
790:14 - decide what is your use case
790:17 - okay
790:20 - let's take a look at Abus cost Explorer
790:22 - which lets you visualize understand and
790:24 - manage your Abus cost and usage over
790:26 - time so uh here's a big graphic of Adis
790:29 - cost Explorer and you can specify time
790:31 - and range and aggregation and it has a
790:33 - lot of robust filtering um what's really
790:36 - nice is that they have a bunch of
790:37 - default reports for you so I'm just
790:39 - going to get my pen tool just to show
790:40 - you where that button is it's over uh
790:43 - here uh if you can see my marker there
790:45 - but but you know you can look at things
790:47 - like monthly cost by service monthly
790:49 - cost by linked account daily cost a this
790:51 - Marketplace R utilization so there's a
790:54 - bunch there you can also notice you can
790:55 - create your own report so if you do find
790:58 - something that you like you can save it
790:59 - for later um you can you could have
791:02 - access to forecasting here so you get an
791:03 - idea of the future costs and whether
791:05 - it's been it's gone up or down just to
791:07 - kind of zoom in on some of those
791:08 - filtration options you can choose um
791:11 - either monthly or daily level of of how
791:14 - you want the data to be grouped together
791:17 - and you have a lot of filter control so
791:19 - if I want to just have ec2 instances for
791:21 - a particular region then I can get that
791:23 - filtered information over here and you
791:25 - can see you have a breakdown of the
791:26 - different types so it's very detailed
791:29 - and class Explorer shows up in Us East
791:31 - one I'm pretty sure if you click on
791:32 - class Explorer it will just switch you
791:33 - over to that region but just understand
791:35 - that's where it lives
791:37 - [Music]
791:40 - okay hey this is Andrew Brown from
791:42 - exampro and in this video I want to show
791:44 - you ad cost Explorer so what we'll do is
791:47 - go to the top here and and actually on
791:49 - the right hand side we're going to click
791:50 - on the right and go to my billing
791:52 - dashboard and from there on the left
791:54 - hand side we're going to look for cost
791:55 - Explorer and then click launch cost
791:58 - Explorer and this is where we're going
791:59 - to get to the ad ofs cost management
792:01 - dashboard where this is where we find
792:02 - savings plans reservations things like
792:04 - that on the left hand side click on cost
792:06 - Explorer and you can get this nice chart
792:08 - and so the idea is you can change it
792:09 - from monthly to daily if you if you uh
792:13 - prefer okay you can change the scope
792:15 - here maybe we don't need six months we
792:17 - can just go back
792:20 - um three months here so there's less
792:25 - data it is a bit delayed when I'm
792:28 - clicking here so it also could be just
792:30 - because I'm doing the daily instead of
792:31 - monthly so you just have to be a little
792:33 - bit patient when uh using this interface
792:37 - you can change it to stack line graph
792:39 - you can kind of see the details there
792:40 - it's not always clear like what others
792:42 - is or things like that and so uh you can
792:45 - drill down and there's like ways of
792:47 - applying fil filters and things like
792:50 - that I always forget how to uh do this
792:53 - it's because it's it's bringing
792:54 - everything in so you have to hit clear
792:55 - all first I
792:57 - think and
793:01 - um oh you have to click into it so like
793:04 - if you wanted to click into it and pick
793:05 - a particular service we could go here
793:07 - and type in
793:08 - ec2 and say ec2 instances and then apply
793:13 - that filter so now we can just see
793:15 - exactly that cost or if we want to
793:18 - choose use like maybe just
793:21 - RDS okay so you know that could be
793:25 - useful for you to see but yeah sometimes
793:27 - it's not always clear and so what I
793:29 - recommend is just go back to your
793:31 - billing dashboard and from there just go
793:33 - to bills okay bills is really really
793:36 - useful because here it shows you exactly
793:39 - every single little service that you're
793:40 - being built for you can expand it and
793:42 - see exactly where if you have other
793:44 - accounts you can go into this side here
793:46 - as well and find spend that way um but
793:48 - cost Explorer is very useful just it's
793:51 - useful in a different way okay so there
793:53 - you
793:54 - [Music]
793:57 - go hey this is Andrew Brown from exam
793:59 - Pro and we are taking a look at the adus
794:01 - pricing API so with adus you can
794:03 - programmatically access pricing
794:05 - information to get the latest pricing
794:07 - offerings for services this makes sense
794:09 - because databus can change them at any
794:11 - time and so uh you know you might want
794:13 - to know exactly what the current price
794:14 - is uh there are two versions of this API
794:17 - so we have the career API known as the
794:19 - pricing service API and you access this
794:21 - via Json and then there's the batch API
794:24 - also known as the price uh list API via
794:27 - HTML what's odd is that um the batch API
794:30 - returns Json but you're accessing it via
794:32 - HTML so you can literally paste those
794:35 - links in your browser for the query API
794:37 - you're actually sending an an
794:38 - application Json request so you'd have
794:41 - to use something like Postman or
794:42 - something uh you can also subscribe to
794:45 - SNS uh notifications to get alerts when
794:47 - pricing for the Services change adabs
794:49 - prices change periodically such as when
794:51 - adabs Cuts prices when new instance
794:53 - types are launched or when new services
794:55 - are introduced so there you
794:57 - [Music]
795:00 - go hey this is Angie Brown from exam Pro
795:03 - and what I want to do here is show you
795:05 - savings plans and so savings plan is
795:07 - going to be found under the a cost
795:08 - Explorer so just type in cost Explorer
795:10 - at the top here or if you want you can
795:12 - type in savings plan as well and once we
795:14 - are here on the left hand side we are
795:16 - going to have uh savings plans options
795:18 - so we're going to go to the overview and
795:20 - here it just describes um what are
795:22 - savings plans if you want to read
795:24 - through it but down below if you have
795:25 - already some spend happening it's going
795:27 - to make some suggestions and in this
795:29 - particular account it's saying that I
795:30 - could save some money on compute before
795:33 - we take a look here I'm just going to go
795:34 - to the form here and see what we can see
795:36 - so up here we can say a commitment
795:38 - through three years by the way you have
795:40 - compute savings which applies to ec2
795:42 - fargate or Lambda then you have the ec2
795:45 - specific one where uh we can select a
795:47 - very particular type of instance family
795:49 - and then there's the sage maker savings
795:51 - plans um but if we go here and we just
795:54 - enter in like
795:56 - $2 all up front uh I don't really
796:00 - understand it from here because it
796:00 - doesn't make it clear what the savings
796:02 - are um but uh I what it does make it
796:05 - very easy is probably if we go over here
796:07 - and then click down on the compute so I
796:10 - kind of feel like here would autofill it
796:11 - in for you and so here I filled it in uh
796:14 - or sorry it's filled in for me and so
796:16 - here it's saying with a one-year plan
796:18 - all up front for based on the past 30
796:21 - days that it's going to see that I'm
796:23 - going to see a monthly savings of
796:26 - $25 36 and then I can add it to the cart
796:29 - that way and I kind of feel like that is
796:31 - the easiest way to um figure that out
796:34 - where with um with how it was going to
796:37 - that form I just configured out myself
796:39 - what the savings were uh there are some
796:41 - utilization reports and coverage reports
796:44 - honestly I've never really looked at
796:45 - these before um but uh I'm just curious
796:48 - like what we're looking at monthly
796:51 - daily the
796:53 - last let's go a few months here I've
796:55 - been running stuff in this account for a
796:56 - while so there should be
796:58 - something
797:01 - apply so nothing nothing of interest but
797:05 - um I mean I guess you have a lot of use
797:07 - and coverage report and utilization
797:09 - report could be interesting but I
797:11 - imagine it's maybe you have to be using
797:13 - you have to have a savings plan before
797:14 - you can see this so that's probably the
797:16 - reason why um but yeah hopefully that
797:18 - gives you a clear idea that you know you
797:19 - can just go down to those
797:21 - recommendations and and see exactly what
797:23 - you can save and you just add it to your
797:25 - cart and then once you want to pay for
797:27 - it you just choose to submit that order
797:29 - and you're all good to go all right so
797:31 - that's savings
797:33 - [Music]
797:37 - plans let's take a look here at defense
797:39 - in depth to understand the layers of
797:41 - security ads has to consider uh for
797:44 - their data centers for their uh virtual
797:46 - workloads and things that you also have
797:47 - to consider when you are uh thinking
797:50 - about security for your Cloud resources
797:53 - so in the most interior we have data so
797:56 - this is access to business and customer
797:58 - data and encryption to protect your data
798:00 - then we have applications so
798:02 - applications are secure and free of
798:04 - security vulnerabilities then you have
798:06 - comput so access to Virtual machines
798:08 - ports on premise and Cloud you have the
798:10 - network layer so this limits
798:12 - communication between resources using
798:14 - segmentation and access controls you
798:16 - have the perimeter itself so distributed
798:18 - denial of service protection to filter
798:20 - large scale attacks before they can
798:22 - cause denial of service of users you
798:24 - could say that's part of the network
798:25 - layer and that's what I say there are
798:27 - variants on this but we're just
798:28 - separating it out uh explicitly there we
798:31 - have identity and access so controlling
798:33 - access to infrastructure and change
798:35 - control and then there's the physical
798:37 - layer so limiting access to data centers
798:40 - to only authorized Personnel you'll
798:42 - notice I highlighted identity and access
798:45 - in yellow it's because that is
798:46 - considered the new primary
798:48 - um perimeter from the customer's
798:51 - perspective of course ad has concern
798:53 - about the physical perimeter and things
798:54 - like that but as it as a customer that's
798:57 - what you're going to be thinking about
798:58 - especially with the zero trust model and
799:01 - when you see these depths the idea is
799:03 - that in order to get here you have to
799:05 - pass through all this stuff so if this
799:07 - um if this outward one is protected
799:09 - pretty well then you generally don't
799:11 - have to worry about the Interiors but of
799:12 - course you should um but yeah there you
799:16 - go
799:19 - let's take a look here at
799:21 - confidentiality integrity and
799:23 - availability also known as the CIA Triad
799:27 - is a model describing the foundation to
799:29 - security principles and their trade-off
799:30 - relationships so here is our Triad so we
799:34 - have confidentiality so confidentiality
799:36 - is a component of privacy that
799:38 - implements to protect our data from
799:39 - unauthorized viewers in practice this
799:41 - can be using cryptographic keys to
799:44 - encrypt our data and using keys to
799:46 - encrypt our keys so envelope encryption
799:48 - then we have integrity so maintaining
799:50 - and ensuring the accuracy and
799:51 - completeness of data over its entire
799:53 - life cycle in practice utilizing asset
799:55 - compliant databases for valid
799:56 - transactions utilizing tamper evident or
799:59 - tamper proof Hardware security modules
800:01 - hsms availability so information needs
800:04 - to be available when needed in practice
800:06 - so high availability mitigating dos uh
800:09 - decryption access so the CIA Triad was
800:12 - first mentioned in N publication in 1977
800:15 - there have been efforts to expand and
800:17 - modernize or Alternatives the CIA triab
800:20 - so one was in 1998 for the six Atomic
800:22 - elements of information uh or in 2004 we
800:25 - have the N engineering principles for uh
800:27 - for information technology security so
800:29 - has 33 security principles but this is
800:31 - still a very popular um model for
800:35 - security uh and it's just to kind of
800:37 - tell you like you know you don't always
800:39 - get everything you don't get all three
800:40 - of them sometimes you have to trade off
800:42 - in your scenario um you know and
800:44 - hopefully some of the terminology here
800:45 - will uh resonate as we go through more
800:47 - security
800:48 - [Music]
800:51 - content what I want to do here is just
800:53 - Define the term vulnerability so a
800:55 - vulnerability is a whole or weakness in
800:57 - an application which can be designed a
800:59 - design flaw or implementation bug that
801:01 - allows an attacker to cause harm to
801:03 - stakeholders or applications and uh
801:06 - there's a lot of great definitions of
801:08 - vulnerabilities but OAS has a ton of
801:10 - them and we talked about OAS when we
801:12 - talk about Abus Waf uh but it's an
801:14 - organization that creates security
801:16 - projects that help you know what you
801:18 - should protect uh or gives you a working
801:20 - examples so that you can understand how
801:22 - to get better at security and so they
801:24 - have a lot of ones here but maybe you'll
801:27 - might notice some here like using a
801:28 - broken or risky cryptographic algorithm
801:31 - maybe there's a memory leak least
801:33 - privilege violation so that's um uh
801:36 - lease privilege is something that is a
801:38 - thing that you're always worried about
801:39 - insecurity improper data validation
801:41 - buffer overflows so you know just to
801:43 - kind of set the tone of what a
801:45 - vulnerability is and things you should
801:47 - be thinking about
801:48 - [Music]
801:52 - okay let's understand what encryption is
801:54 - but before we do we need to understand
801:56 - what is cryptography so this is the
801:58 - practice and study of techniques for
801:59 - secure communication in the presence of
802:01 - third parties called adversaries and
802:03 - encryption is the process of encoding or
802:05 - scrambling information using a key and a
802:08 - cipher to store sensitive data in an
802:10 - unintelligible format as a means of
802:12 - protection uh an encryption takes in
802:14 - plain text and produces produces a
802:16 - cipher text
802:18 - so here's an example of a very old um
802:20 - encryption machine this is the igma
802:23 - machine used during World War II and it
802:25 - has a different key for each day that it
802:27 - was used to set the position of the
802:28 - rotors and it relied on simple Cipher
802:32 - substitution and so you might be asking
802:34 - what is a cipher and that's what we're
802:35 - going to look at
802:36 - [Music]
802:40 - next so what is a cipher it is an
802:42 - algorithm that performs encryption or
802:44 - decryption so Cipher is synomous with
802:47 - code uh and the idea is that you use the
802:49 - code to either unlock or or lock up the
802:53 - information that you have so what is a
802:55 - cipher text a cyer text is the result of
802:57 - encryption performed on Plain text via
803:00 - an algorithm so you lock that up you
803:03 - scramble it it doesn't make sense and
803:04 - you need that code to unlock it to get
803:07 - the information so a good practical
803:09 - example back in the day was a code book
803:11 - and this was a type of document used for
803:13 - Gathering and storing cryptographic
803:15 - codes or ciphers so the idea is if we
803:17 - zoomed up on here notice where we have
803:20 - cannot so uh and it would be 0 0 and
803:24 - then there would be give them Authority
803:26 - so the idea
803:28 - is0 0 or if you had the word cannot it
803:31 - would translate to z0 and then you use
803:33 - z0 to match that up to say what does
803:36 - that actually mean and so that is kind
803:37 - of a very practical example of ciphers
803:39 - in
803:40 - [Music]
803:43 - action so we just took a look at
803:45 - encryption but what are cryptographic
803:48 - keys so a c a cryptographic key an easy
803:51 - way to think of it is a variable used in
803:54 - conjunction with an encryption algorithm
803:56 - in order to encrypt or decrypt data and
804:00 - there are different kinds of um ones we
804:03 - have so we have symmetric encryption so
804:05 - this is where we have the same key that
804:07 - is used for encoding and decoding uh and
804:10 - a very popular one and the one you will
804:11 - see on AWS is called Advanced encryption
804:14 - standard AES so just take a look at that
804:17 - graphic very closely so we have one key
804:20 - and it is used to encrypt so it produces
804:23 - the cipher and then or Cipher text we
804:26 - should say and then it will uh decrypt
804:28 - and we will get our plain text so one
804:30 - single key then we have a symetric
804:33 - encryption so two keys are used one to
804:36 - encode and one to decode and a very
804:39 - popular one here is RSA if you're
804:41 - wondering what those uh those words are
804:43 - it's three people's names put together
804:45 - who helped uh invent this type type of
804:48 - algorithm and so here we have uh one key
804:51 - for encrypt and one key for decrypt and
804:54 - they're two different Keys all
804:56 - [Music]
805:00 - right all right let's look at the
805:02 - concept of hashing and salting so for
805:04 - hashing we have a hashing function and
805:06 - this accepts arbitrary size values and
805:07 - Maps it to a fixed size data structure
805:10 - hashing can reduce the size of a store
805:12 - value and hashing is a one-way process
805:14 - and is deterministic so a deterministic
805:17 - function always returns the same output
805:19 - output for the same input so if we have
805:21 - something like John Smith and we pass it
805:23 - to the hash function it's going to
805:25 - create something that is not human
805:26 - readable but it'll say something like 02
805:28 - Fae X XY whatever um and it will always
805:32 - produce the same thing if the same key
805:34 - or you know value is being inputed there
805:37 - so the reason we use hashing functions
805:39 - or hashing General is to Hash passwords
805:41 - so hash functions are used to store
805:43 - passwords in a database so that the
805:44 - password does not reside in a plain text
805:46 - format so you've heard about all these
805:48 - data breaches where they've stored the
805:50 - password in plain text this is the thing
805:52 - that helps us avoid that issue um and
805:55 - the thing again is it because it's one
805:56 - way you can't take that hash and unhash
805:59 - it um well there are some conditions to
806:01 - it but so to authenticate a user when a
806:03 - user inputs their password it is then
806:05 - hash so the one that was inputed at the
806:07 - time of you know login and then that
806:09 - hash is compared to the stored hash in
806:11 - the database and if they match the user
806:14 - is successfully logged in so in that
806:16 - case we never ever had to know what the
806:18 - original password looked like uh popular
806:20 - hashing functions are md5 Shaw 256 or
806:23 - bcrypt uh if an attacker knows the
806:26 - function you are using uh and uh and
806:29 - stole your database they could enumerate
806:30 - a dictionary of passwords to determine
806:32 - the password so they'll never see it but
806:34 - they could just keep on going through
806:35 - that so that's why we salt our passwords
806:38 - so a salt is a random string not known
806:40 - to the attacker that the hash function
806:42 - accepts to mitigate the deterministic
806:44 - nature of a hashing function so there
806:46 - you go
806:50 - [Music]
806:52 - let's take a look here at digital
806:53 - signatures and signing so what is a
806:55 - digital signature it is a mathematical
806:57 - scheme for verifying the authenticity of
806:59 - digital messages or documents and a
807:01 - digital signature gives us tamper
807:02 - evidence so did someone mess or modify
807:04 - the data is this data from uh someone we
807:07 - did not expect it to be is it from the
807:09 - actual sender and so we kind of have
807:11 - this diagram where we have a person who
807:12 - sends or is going to send a message so
807:14 - they sign it and then uh Bob ver ifies
807:18 - that it was for the person who it's from
807:20 - so there are three algorithms to a
807:21 - digital signature the key generation so
807:24 - generates a public and private key um
807:27 - then there is signing the process of
807:29 - generating a digital signature with a
807:31 - private key and the inputed value so
807:33 - signing which is what is happening up
807:35 - here signing verification verifies the
807:37 - authenticity of the message with a
807:39 - public key so remember the private key
807:41 - is used for signing and the public key
807:42 - is used for verifying SSH uses a public
807:46 - and private key to authorize remote
807:48 - access into a remote machine such as a
807:51 - virtual machine it is common to use RSA
807:54 - and we saw that RSA is a type of
807:56 - algorithm earlier and so SSH hyphen
807:59 - keyen is a well-known command to
808:01 - generate a public and private key on
808:03 - Linux I know this one off the top of my
808:05 - head I always know to do this um and so
808:08 - what is code signing so when you use a
808:10 - digital signature to ensure computer
808:12 - code has not been tampered and so that's
808:14 - just a like subset of digital signatur
808:17 - so you can use this as a means to get
808:19 - into a virtual machine or you can use
808:21 - signing as a means to make sure that the
808:22 - code being committed to your repository
808:25 - is who you expect it to be from so there
808:27 - you
808:27 - [Music]
808:31 - go let's talk about intransit versus at
808:34 - rest encryption so encryption and
808:36 - Transit this is data that is secure when
808:38 - moving between locations and the
808:40 - algorithms here are TLS and SSL then you
808:43 - have encryption at rest so this is data
808:45 - that is secure when residing on storage
808:47 - or within a database so we're looking at
808:49 - AES or RSA which we both covered
808:52 - previously these algorithms so ones that
808:55 - we did not cover was TLS and SSL so
808:58 - we'll cover them now so TLS transport
809:00 - layer security is an encryption protocol
809:02 - for data Integrity between two or more
809:04 - commun communicating Computer
809:06 - Applications so 1.0 and 1.1 are no
809:10 - longer used but TLS 1.2 and 1.3 is the
809:14 - current best practice then we have SS
809:17 - cell secure socket layers so an
809:19 - encrypted protocol for data Integrity
809:20 - between two or more communicating uh
809:22 - Computer Applications so 1.0 2.0 and 3.0
809:27 - are deprecated um and honestly I always
809:30 - get these two mixed up and I always fig
809:31 - fig uh uh get confused which is being
809:34 - used but um you know they're always
809:36 - changing on us but just understand
809:38 - generally what these concepts are and
809:39 - that you're familiar with the terms
809:41 - [Music]
809:45 - okay hey this is Andrew Brown for
809:47 - exampro and we are taking a look at
809:48 - common compliance programs so these are
809:50 - a set of internal policies and
809:52 - procedures for a company to comply with
809:54 - laws rules and regulations or to uphold
809:56 - business reputation so here we have a
809:59 - bunch of different compliance programs
810:01 - and so some popular ones are like Hippa
810:03 - or um PCI DSS the question is should you
810:07 - know these yes you should generally know
810:09 - the most popular ones because you're
810:11 - going to see them throughout your Cloud
810:12 - career um and so just getting familiar
810:14 - now is a good time uh so let's jump into
810:17 - it okay so the first one I want to
810:19 - introduce you to is for I ISO and they
810:21 - have a bunch of different ones so ISO is
810:23 - the international organization of
810:25 - standardization and there uh other one
810:27 - called IEC which is the international
810:30 - electrotechnical commission One deals
810:32 - with uh you know like uh virtual things
810:34 - the other one deals with Hardware things
810:36 - but they have a lot of overlapping um
810:38 - compliance programs okay and so the most
810:41 - popular absolutely most popular one that
810:43 - I know of is the 27100 I know a lot of
810:46 - organizations that are going for the 271
810:49 - this is for control implementation
810:51 - guidance you have the
810:53 - 277 this is enhanced focus on cloud
810:55 - security the 27018 this is protection of
810:58 - personal data in the cloud then you have
811:01 - the 2771 this is Privacy Information
811:04 - Management System so pims framework this
811:06 - outlines controls and processes to
811:08 - manage data privacy and protect pii so
811:11 - that's personally identifi information
811:13 - then you have system and organization
811:15 - control sock and this is a very popular
811:17 - thing that organizations go for
811:19 - especially the sock 2 so sock one is 18
811:21 - standards and report on the
811:22 - effectiveness of internal controls at
811:24 - the service organization relevant to the
811:27 - client's internal control over financial
811:28 - reporting we have sock 2 evaluates
811:30 - internal controls policies and
811:32 - procedures that directly relate to the
811:34 - security of the system at a service
811:36 - organization and sock three a report
811:38 - based on the trust uh service Services
811:41 - criteria that can be freely
811:42 - distributed then we have PCI DSS a set
811:46 - of security standards designed to ensure
811:48 - that all companies that accept process
811:50 - store and transmit credit card
811:52 - information maintains in a secure
811:55 - environment we have a federal
811:57 - information procedure standards or fips
811:59 - so 140 hyphen 2 This Is Us and Canadian
812:02 - government standard that specifies the
812:04 - security requirements for cryptographic
812:05 - modules that protect sensitive
812:08 - information then we have uh phipa this
812:11 - is more relevant to me because I'm
812:13 - actually in Ontario in Canada but it's
812:15 - also very uh wellknown
812:17 - um uh went out there outside of HIPPA so
812:19 - this regulates patient protected health
812:21 - information then you actually have Hippa
812:24 - this is the US federal law that
812:26 - regulates patient procedure health
812:27 - information then we have uh Cloud
812:30 - security Alliance so CSA star
812:33 - certification independent third-party
812:35 - assessment of a cloud provider security
812:38 - posture if you've never heard of CSA
812:39 - they have a very uh well-known
812:41 - fundamental uh security certification
812:43 - called the cssk or ccsk I always get
812:46 - that that mixed up then we have uh fed
812:48 - ramp which we covered earlier in this
812:50 - course or in the future depending on
812:51 - where we put it but um fed ramp stands
812:54 - for federal risk and authorization
812:55 - Management program it's a US Government
812:57 - standardization approach to security
812:59 - authorizations for cloud service
813:00 - offerings if you want to work with the
813:02 - US government or places that sell the US
813:05 - government you need fed ramp that
813:07 - similar to criminal justice Information
813:09 - Services any US state or local agency
813:11 - that wants to access the FBI's cgis
813:14 - database is required to adhere to the C
813:16 - GIS security policy then we have gdpr uh
813:21 - the general data protection regulation
813:23 - everyone knows what this is in Europe
813:25 - maybe not so much in North America or
813:26 - other places a European Privacy Law
813:29 - imposes new rules on companies
813:31 - governments agencies nonprofits and
813:32 - other organizations that offer goods and
813:34 - services to people in the European Union
813:37 - or that collect analyze data triy tied
813:40 - to EU residents there's a lot of
813:42 - compliance programs out there one that's
813:44 - also very popular is fips but we'll get
813:45 - to that when we talk about camp Ms um
813:47 - but yeah there you
813:49 - [Music]
813:53 - go so I just wanted to quickly show you
813:55 - here the adus compliance programs page
813:57 - where they list out all the types of
813:59 - compliance programs that adus is uh
814:01 - working with and that it has different
814:03 - types of certification and attestment
814:05 - which we can use itus artifact or Amazon
814:08 - artifact whichever prefix they decide to
814:10 - use for the name there um to uh ensure
814:13 - that it was has in order to meet those
814:16 - regulatory compliance so you can see
814:17 - them all there and if you want to know a
814:20 - little bit more about any of these you
814:21 - just go ahead and click them and you can
814:23 - read and they have additional
814:24 - information so you have a better idea
814:29 - [Music]
814:32 - okay let's talk about pen testing so pen
814:35 - testing is an authorized simulated Cyber
814:37 - attack on a computer system performed to
814:39 - evaluate the security of the system and
814:41 - on AWS you are allowed to perform uh pen
814:44 - testing but um there are some
814:46 - restrictions so permitted services are
814:48 - ec2 instances KN gateways elbs RDS so
814:52 - that's relational database service
814:54 - cloudfront Aurora API gateways Lambda
814:57 - Lambda Edge functions light cell
814:59 - resources elastic beanock environments
815:01 - things you cannot do or you should not
815:03 - be doing is DNS Zone walking via row 53
815:06 - hosted zones then there's dos simulation
815:09 - testing so you should not be doing do or
815:11 - dos
815:12 - doses or simulated Doss or simulated
815:15 - doses okay and that doesn't mean that
815:18 - you can't necessarily do them uh again
815:20 - there's a lot of exceptions to the pen
815:22 - testing they have a whole page on this
815:23 - but generally you're not allowed to do
815:25 - dsing uh Port flooding protocol flooding
815:28 - request flooding can't do any of those
815:30 - things for other simulated events you
815:32 - need to submit a request to bus a reply
815:34 - could take up to seven days uh you know
815:37 - again there's a lot of uh uh little
815:39 - intricacies here so you'd have to really
815:40 - read up on it if you're interested in
815:42 - doing this
815:45 - okay
815:47 - hey this is Andrew Brown from exam Pro
815:49 - and we are taking a look at pen testing
815:51 - on the adus platform so they have this
815:53 - page here that tells you what you're
815:54 - allowed to do what you're not allowed to
815:56 - do um and there's some additional things
815:58 - you can read into like the stress test
815:59 - policy the Dos simulate simulation
816:02 - testing policy which I didn't cover in
816:04 - detail uh in the course content but if
816:06 - for whatever reason you're interested in
816:08 - it I just want you to be aware of that
816:10 - kind of stuff if you want to simulate
816:12 - events there is a simulate events form
816:14 - that you have to fill out so you open it
816:16 - up up and you can kind of read about it
816:18 - and it gives ad us a heads up of what
816:20 - you're going to be doing stress test
816:21 - fishing malware analysis other so that
816:24 - way that if you are doing it you're not
816:25 - going to get in trouble they're aware of
816:27 - what you are doing okay so that's pretty
816:29 - much
816:30 - [Music]
816:33 - it hey this is Andrew Brown from exam
816:36 - Pro and we are taking a look at itus
816:37 - artifact which is a self serve portal
816:39 - for ond demand access to adus compliance
816:42 - reports so here's an example of a a
816:44 - bunch of different compliance reports
816:45 - that adus could be meeting and the idea
816:48 - is that when you go to this portal
816:49 - within the adus Management console
816:51 - you'll have a huge list of reports that
816:53 - you can go and access so here I'm
816:55 - searching for Canada to get the
816:57 - government of Canada partner package and
817:00 - then I go ahead and I download that
817:01 - report as a PDF and then within the PDF
817:04 - we can click a link to get the
817:05 - downloadable Excel and that's pretty
817:07 - much what it is it's just if you want to
817:09 - see that databus is being compliant for
817:11 - different
817:15 - programs
817:16 - hey this is Andrew Brown from exam Pro
817:18 - and we're going to take a look at Aus
817:20 - artifact so in the top here we're going
817:21 - to type in
817:23 - artifact and not be confused with code
817:25 - artifact which I guess is a new service
817:27 - there's just always releasing new
817:28 - Services e and so here we have a video
817:32 - and some things but uh it's not too hard
817:34 - all we got to do is go to view
817:37 - reports and from here we have all the
817:39 - types of compliance programs or
817:41 - Regulatory Compliance programs that ads
817:44 - is uh meeting and we can do is search
817:47 - for something so we type in Canada and
817:49 - that's the government of Canada partner
817:51 - package and I can go ahead and download
817:53 - that report so when you download it you
817:55 - really want to open this up
817:57 - in um you're going to really want to
817:59 - open this up in um uh Adobe Acrobat
818:03 - because if you don't open up an Adobe
818:05 - Acrobat you're not going to be able to
818:07 - access the
818:13 - downloadblack reader and once to have it
818:17 - open and I'm just moving it over here
818:20 - this is what you're going to see and um
818:22 - it's going to say like hey um oops no I
818:25 - don't want to do that so please scroll
818:27 - to the next page to view the artifact
818:29 - download and so I think that if we go
818:33 - here you know they say scroll to the
818:35 - next page but I'm pretty sure we can
818:36 - just go here on the left hand side and
818:38 - this is what we're looking for that
818:39 - Excel spreadsheet so we're going to save
818:42 - that
818:43 - attachment or actually we just going to
818:45 - open it up
818:47 - open this
818:48 - file okay and we'll give it a moment I
818:50 - have Excel
818:52 - installed and there we
818:54 - go there it is okay so I know it's a
818:58 - little bit odd way to get to those um
819:01 - certificates or reports but that's just
819:03 - how it works um but yeah I mean that's
819:06 - the idea is like if you need to prove
819:07 - that ABS is meeting whatever those
819:09 - standards are you can just type them in
819:11 - whatever it is I maybe there like fed
819:12 - ramp right whatever it is and download
819:14 - those certificate attestment whatever um
819:17 - and just double check that ads is
819:19 - Meeting those standards
819:21 - [Music]
819:24 - okay hey this is Andrew Brown from exam
819:27 - Pro and we are taking a look at AIS
819:29 - inspector but before we can answer what
819:31 - it does let's talk about hardening so
819:32 - hardening is the act of eliminating as
819:34 - many security risks as possible
819:36 - hardening is common for virtual machines
819:38 - where you run a collection of C Security
819:39 - checks known as a security Benchmark so
819:43 - abis inspector runs a security Benchmark
819:45 - against specific spefic ec2 instances
819:47 - and you can run a variety of security
819:49 - benchmarks and you can perform Network
819:51 - and host assessments and so here's an
819:53 - example of those two check boxes there
819:55 - which you'd say which assessments you
819:57 - want to do so the idea is you have to
819:58 - install the edus agent on your ec2
820:00 - instance you run an assessment for your
820:02 - assessment Target you review your
820:04 - findings and remediate security issues
820:06 - and one very popular Benchmark you can
820:08 - run is the CIS which has 699 checks so
820:12 - if you don't know what CIS it stands for
820:14 - the center of Internet Security uh and
820:16 - so they are this organization that has a
820:18 - bunch of um uh security controls or
820:21 - check marks uh that are published that
820:23 - they suggest that you should check on
820:24 - your
820:25 - [Music]
820:28 - machine hey this is Andrew Brown from
820:30 - exam PR and we're looking at dos so dos
820:33 - is a type of malicious attack to disrupt
820:36 - normal traffic by flooding a website
820:37 - with a large amount of fake traffic so
820:40 - the idea is we have an attacker and the
820:41 - victim the victim is us and it could be
820:44 - our virtual machines our cloud services
820:47 - the idea is that it's some kind of uh
820:49 - resource which um can take in uh
820:52 - incoming requests over the Internet so
820:54 - the idea is the attacker is utilizing
820:56 - the internet and so they may control a
820:58 - bunch of uh virtual machines or servers
821:00 - that are loaded up with malicious
821:02 - software and the idea is that the
821:04 - attacker is going to tell them all to
821:06 - send a flood of traffic over the
821:08 - Internet uh at your uh Computing
821:11 - resource and uh this is where your
821:14 - website is going to either start to
821:16 - stall or it's going to become
821:17 - unavailable for your users and so the
821:20 - idea here is that you know if you want
821:22 - to protect against CS you need some kind
821:24 - of Dos protection traditionally those
821:26 - used to be like third party services
821:27 - that you uh would have to pay for and
821:30 - and it would sit in front of uh your
821:32 - load balancer or your uh end server but
821:35 - now the great thing with cloud service
821:37 - providers is that generally their
821:38 - networks have built in DOS protection so
821:41 - the idea is just by having your compute
821:43 - or your resources on AWS you're going to
821:45 - get uh built-in protection for free via
821:48 - ad shield and we'll talk about that
821:51 - [Music]
821:54 - next hey this is Andrew Brown from exam
821:57 - Pro and we are taking a look at it
821:59 - Shield which is a managed dos Protection
822:01 - Service that safeguards applications
822:04 - running on AWS so when you route your
822:06 - traffic through R 53 or cloudfront you
822:09 - are using a shield standard so here's a
822:12 - diagram to kind of show you that it's
822:13 - not just those services but these are
822:15 - the most common ones where you'll have a
822:17 - point of entry into AWS so here we could
822:19 - also be including elastic IP it Global
822:22 - accelerator but the idea is that when
822:24 - you uh go through these Services into
822:26 - the Aus Network it has Shield built in
822:29 - and so you're going to get that
822:30 - protection before those uh before that
822:32 - traffic reaches your uh cloud services
822:35 - and in this case we're showing uh ec2
822:37 - instances so ad Shield protects against
822:39 - layers three four and seven attacks uh
822:42 - layer three four and seven is based off
822:45 - the The OSI model which is a um a
822:48 - fundamental networking concept so seven
822:51 - is for the application layer four is the
822:54 - transport Layer Three is the network
822:57 - layer um there are two different types
822:59 - of plans for you to Shield we have
823:01 - Shield standard which is free and then
823:03 - Shield Advance which starts at 3,000 USD
823:06 - per year plus some additional uh costs
823:09 - based on usage of the size of the tack
823:11 - or what services you're using how much
823:13 - traffic is moving in and out so
823:15 - protection against the most common dos
823:17 - attacks is what Shield standard does uh
823:20 - you have access to tools and best
823:22 - practices to build dos resiling
823:24 - architecture it's automatically
823:25 - available on all services for additional
823:28 - protection against larger and more
823:30 - sophisticated attacks that's where
823:31 - Shield Advance comes into play it's
823:33 - available for specific adus services so
823:36 - R 53 cloudfront elb adus Global
823:40 - accelerator elastic IP uh and some
823:43 - notable features here is visibility
823:45 - reporting on layer three four and seven
823:47 - you're only going to get seven if you
823:49 - are using idwa with it uh you have
823:52 - access to team and support so these are
823:53 - DOs experts but you're only going to get
823:55 - it if you're paying for business or
823:57 - Enterprise support as you're paying for
823:59 - this as well uh you also get dodos cost
824:02 - protection just ensure that you know
824:03 - your bills don't go crazy uh and it
824:05 - comes with an SLA so you have a
824:07 - guarantee that it's going to work both
824:09 - plants integrate with itless web
824:12 - application firewall so w to give you
824:15 - that layer set application protection so
824:17 - understand that if you're not using Waf
824:19 - you're not going to be having that layer
824:20 - 7 protection
824:21 - [Music]
824:25 - okay hey this is Andre Brown from exam
824:27 - Pro and we are looking at Amazon guard
824:29 - Duty so before we look at that we need
824:31 - to understand what is an IDs IPS so an
824:35 - intrusion detection system and intrusion
824:37 - protection system is used as a device or
824:41 - software application that monitors and
824:42 - network or systems for malicious
824:45 - activity or policy violations so guard
824:48 - duty is a threat detection service which
824:50 - is IDs IPS that continuously monitors
824:53 - for malicious and suspicious activity
824:56 - and unauthorized Behavior it uses
824:58 - machine learning to analyze the
824:59 - following adus logs your cloud trail
825:02 - logs your VPC flow logs your DNS logs
825:05 - and what it will do is report back to
825:08 - you and say hey um there's this issue
825:11 - here and this is actually one that's
825:12 - very easy to replicate it's just saying
825:14 - somebody is using the root credentials
825:17 - and it's suggesting that you should not
825:18 - be doing that right because you're never
825:20 - supposed to be uh invoking API calls
825:22 - with the root credentials or you should
825:24 - be limiting that you'll might also
825:26 - notice that if you want to investigate
825:27 - you can kind of follow up that with uh
825:30 - Amazon detective or adus detective
825:32 - whichever uh prefix they decided to put
825:34 - on that service it will alert you of
825:37 - findings which you can automate an
825:38 - incident uh response via cloudwatch
825:40 - events which this uh it's been renamed
825:43 - to event Bridge so you know or third
825:45 - party service services so you can follow
825:47 - up a remediation action um and here is a
825:50 - graphic of Amazon guard Duty just a bit
825:53 - up closer so you can see all the
825:55 - findings and you can just see you have a
825:57 - lot of detailed information there
825:59 - [Music]
826:03 - okay hey this is Andre Brown from exam
826:05 - Pro and we're going to take a look at
826:06 - guard Duty so guard duty is um an
826:09 - intrusion protection and detection uh
826:11 - service and so what I've done is I've um
826:14 - I've done some bad practices purposely
826:16 - so that I can show you um some
826:17 - information in there so I'm going to go
826:19 - over to guard Duty okay and you do have
826:21 - to turn guard Duty on and so once guard
826:24 - duty is on you're going to start getting
826:26 - reports coming in so notice here that we
826:28 - have some anomalous Behavior 8 days ago
826:31 - and so uh that's B he's uh my co-founder
826:34 - he's also named Andrew as well and so we
826:36 - can kind of see some details here about
826:37 - who's accessing what and what they were
826:39 - doing he's not doing anything malicious
826:41 - but we can have an idea where they're
826:43 - from even shows generally where he is
826:45 - which he is near Thunder Bay and his his
826:47 - provider would be
826:48 - TB um and you can see that he is making
826:52 - uh API calls to describe account
826:54 - attributes and things like that then the
826:56 - other issue is the root account so
826:58 - there's MFA I turned it off so that we
827:00 - can or maybe this just usage here I
827:01 - actually do have it turned on I suppose
827:03 - here we see root credential usage and so
827:05 - it's saying hey you used it 77 times
827:08 - because sometimes I go in and and use uh
827:11 - the root account for tutorials but
827:13 - saying you're using this way too much
827:15 - you got stop doing that okay so that's
827:17 - something that is uh pretty interesting
827:19 - with guard Duty um and it's really cost
827:21 - effective and easy to turn on so you can
827:23 - turn it on looks like they have a new
827:25 - thing for S3 um have not looked at that
827:27 - as of yet but that's kind of cool kind
827:29 - of feels like that would overlap with uh
827:31 - Amazon Macy but whatever and here we get
827:34 - a breakdown of cost so we see cloud
827:35 - trail VPC flow logs DS logs and this is
827:38 - where it would be ingesting data if you
827:40 - want to use that S3 protection you'd
827:42 - have to probably be turning or creating
827:43 - a custom cloudwatch Trail that has data
827:46 - events to consume that information um
827:49 - you know so you know hopefully that
827:50 - gives you kind of an idea of things you
827:52 - can do and you can also centralize guard
827:54 - Duty uh into one account so you can have
827:56 - one thing that takes care of everything
827:58 - and and move all the data across all
827:59 - your accounts into a single place so
828:02 - that's kind of interesting and you can
828:03 - set up follow follow-ups um it's
828:06 - possible that uh I'm not see in this
828:10 - this here but generally it would show
828:13 - you uh it would show show you a way of
828:16 - like triggering into Cloud watch
828:17 - probably you can do it pragmatically
828:18 - this is something interesting like the
828:20 - list management you can add trusted IPS
828:22 - or threat list so if there's people that
828:24 - you know are fine you can just Whit list
828:25 - them or if there's people that you know
828:27 - that are bad make sure that they are
828:29 - never allowed to get through so that's
828:30 - pretty much it with guard Duty
828:32 - [Music]
828:35 - okay let's take a look here at Amazon
828:38 - Macy so Macy is a fully managed service
828:40 - that continuously monitors S3 data
828:42 - access activity for anomalies and
828:44 - generates detailed alerts when it
828:46 - detects risks of unauthorized access or
828:48 - inadvertent data leaks so Macy works by
828:51 - using machine learning to analyze your
828:53 - cloud trail logs and Macy has a variety
828:55 - of alerts so we have anomaly access
828:58 - config compliance credential loss data
829:01 - compliance file hosting identity
829:03 - numeration information loss um location
829:06 - anomaly open permissions privilege
829:08 - escalation ransomware service disruption
829:12 - suspicious access andac will identify
829:15 - your most at risk users which could lead
829:18 - to compromise so here's just one little
829:20 - kind of uh tidbit from the um app itself
829:24 - where you have the total users and they
829:26 - categorize them into different uh risks
829:28 - I can't remember which flag means what
829:29 - in here uh Amazon Macy is an okay
829:32 - Service uh it's it's very important if
829:34 - you're storing things in
829:36 - S3 but uh I don't I don't use it very
829:38 - often to be
829:40 - [Music]
829:43 - honest hey this is Andie Brown from exam
829:46 - Pro and we are taking a look at adus
829:48 - virtual private Network also known as
829:50 - VPN so adus VPN lets you establish a
829:53 - secure and private tunnel from your
829:56 - network or device to the itus global
829:58 - Network it's very important to emphasize
830:00 - the word secure here uh because when
830:02 - you're using Direct Connect that will
830:04 - establish a private connection but it's
830:06 - not using any kind of protocol to secure
830:09 - that data in transit whereas a VPN will
830:12 - be using a secure protocol there are two
830:15 - options here we have itus sight to site
830:17 - VPN so securely connect on premise
830:19 - Network or branch office site to VPC and
830:22 - itus cvpn that securely connect users to
830:25 - adabs or on premises
830:27 - networks one thing that we need to
830:29 - understand alongside vpns is IPC this
830:34 - stands for Internet Protocol security
830:36 - and is a secure network protocol Suite
830:38 - that authenticates and encrypts the
830:39 - packets of data to provide secure
830:41 - encrypted communication between two
830:44 - computers over Internet Protocol Network
830:46 - and it is used in vpns and Abus
830:49 - definitely uses it
830:51 - [Music]
830:54 - okay hey this is Andrew Brown from exam
830:57 - Pro and we are taking a look at Abus web
830:59 - application firewall also known as WF
831:02 - which protects you uh protects your web
831:04 - application from common web exploits so
831:07 - the idea here is you write your own
831:09 - rules to allow or deny traffic based on
831:11 - the contents of an HTP requests you use
831:14 - a rol set from a trusted Abus security
831:17 - partner in the Abus Waf rule Marketplace
831:20 - Waf can be attached to either cloudfront
831:22 - or an application load balancer so here
831:25 - is that diagram the idea is you see
831:27 - cloudfront with the Waf or ALB with the
831:30 - WAFF and what it does is it can protect
831:33 - uh web applications from attacks covered
831:35 - and the OAS 10 uh top 10 most dangerous
831:39 - attacks if you don't know OAS they're
831:41 - the open web application security
831:43 - project and they basically have all
831:45 - these uh security projects which are
831:48 - things to say hey these are things that
831:50 - you should commonly protect against or
831:52 - they might have like example
831:53 - applications that uh serve as a means to
831:56 - learn security so when we look at the
831:58 - top 10 it's injection broken
832:00 - authentication sensitive data exposure
832:03 - XML external entities so xxe broken
832:07 - Access Control security
832:09 - misconfigurations cross-site scripting
832:11 - so xss uh insecure deserialization using
832:15 - components with known vulnerabilities
832:17 - and insufficient logging and monitoring
832:19 - so there you
832:21 - [Music]
832:24 - go hey this is Andrew Brown from exam
832:26 - Pro and we are going to take a quick
832:28 - look at adus web application firewall
832:31 - also known as WF and so um in this
832:33 - account I happen to have a Waf running
832:36 - uh so we don't have to create one uh we
832:37 - already have something we can take a
832:39 - look here so I'm going to go to Waf and
832:40 - shield and then on the left hand side
832:43 - you'll notice it's a global Service but
832:44 - on the left hand side we're going to be
832:46 - looking for our web acl's and so the
832:49 - idea is that when you want a w you
832:50 - create a web ACL and then within within
832:53 - that web ACL you have uh the overview
832:57 - and then you have it can kind of show
832:58 - you kind of the traffic that's going on
833:00 - here we can have our rules and so um
833:03 - there's a lot of different kind of
833:04 - manage rule groups that you can use so
833:06 - these are ones that are provided by AWS
833:09 - so and a lot of these some of these can
833:11 - be paid some of these are free so you
833:12 - see there's these free rule groups where
833:14 - you're like hey hey I don't want any
833:17 - nominus IPS you checkbox that on you
833:19 - know or I want to protect against SQL
833:22 - injection now the interesting thing is
833:23 - that abis has this capacity unit so um
833:26 - you can't add all of these you can add a
833:29 - certain amount of capacity before you
833:30 - have to um um uh pay for more or
833:34 - something like that it's just kind of a
833:35 - way to um uh kind of cap the amount of
833:39 - stuff that you can put in in terms of
833:41 - rules um but there's a lot of other um
833:44 - rule groups from third party services
833:46 - like security companies that know what
833:48 - they're doing so if you like Fort Net's
833:51 - OS top 10 you can uh subscribe to that
833:53 - in the marketplace and be able to use it
833:56 - but uh yeah so that's how you apply
833:59 - rules there's something called bot
834:01 - control I've never used this before get
834:02 - real-time visibility into bot activity
834:04 - on your resource and controllers what
834:06 - Bots allow and block from your resources
834:08 - that sounds really cool I cannot stand
834:11 - bots so I might turn that on myself or
834:14 - take a look at the cost there and see
834:15 - what we can find out but that's pretty
834:17 - much it with WAFF um one thing I would
834:20 - say is that you can block out specific
834:22 - IP addresses or Whit list specific IP
834:25 - addresses and you might do that through
834:27 - rules I'm just going to see yeah like
834:29 - maybe the bypass here and so these IP
834:32 - addresses are some of our um Cloud
834:35 - support Engineers where they're using
834:37 - our admid panel and um uh WF is being
834:40 - too aggressive in terms of protection
834:43 - and so sometimes you have to uh say hey
834:45 - allow this IP address and let my um you
834:48 - know let my cloud support engineer be
834:51 - able to use the mid panel because
834:52 - they're not malicious okay so that's one
834:54 - little exception there but that's pretty
834:55 - much it
835:10 - [Music]
835:13 - okay hey this is Andrew Brown from exam
835:15 - Pro and we are taking a look at Hardware
835:17 - security modules also known as HSM and
835:20 - it's a piece of Hardware designed to
835:21 - store encryption keys and it holds keys
835:24 - in memory and never writes on the dis so
835:26 - the idea is that if the HSM was shut
835:28 - down uh that key would be gone and that
835:30 - would be a guarantee of protection
835:32 - because nobody could you know take the
835:34 - drive and steal it so here is an example
835:37 - of an HSM uh these are extremely
835:39 - expensive so you definitely don't want
835:40 - to have to buy them yourselves uh they
835:43 - generally follow fips so fips is the
835:45 - federal information processing standard
835:48 - so it's a us and Canadian government
835:50 - standard that specifies the security
835:51 - requirements for cryptographic modules
835:53 - that protect sensitive information fips
835:55 - is something you want to definitely
835:57 - remember um and there are two different
836:01 - um protocols here there's actually a
836:03 - bunch of different uh fips versions but
836:04 - we have fips 142 level two and then fips
836:09 - 143 level three so let's talk about the
836:12 - difference here so hsms that are multi
836:14 - tenant are going to be using fips 142
836:17 - hyphen 2 level two compliant where you
836:21 - have multiple customers virtually
836:22 - isolated on the
836:24 - HSM and then there are hsms that are
836:26 - single tenant and so they're going to be
836:28 - utilizing fips 140 hyphen to level three
836:31 - compliant so a single customer on a
836:33 - dedicated
836:34 - HSM and so the reason why we have these
836:37 - two levels is that when you have
836:39 - multiple tenants you can say all right
836:42 - this thing is uh has temperate evidence
836:44 - evence so we can see that somebody was
836:46 - trying to break into it but there's no
836:48 - guarantee of uh T it being tamper proof
836:51 - where level three is tamper proof
836:54 - there's also uh fips 140 hyphen 3 which
836:57 - is the new uh the newer um standard but
837:01 - not all uh Cloud resources uh can meet
837:03 - that standard just because of how they
837:05 - offer the service uh so again fips 142
837:09 - is really good but just understand that
837:10 - there are other ones out there and it's
837:12 - very easy to get fips 142 level three
837:15 - mixed up with pips 140 hyphen 3
837:17 - something that I always had um a hard
837:20 - time remembering the distinguishing
837:21 - between those two so for multi-tenant
837:24 - this is where we're using adus Key
837:26 - Management Service and for single tenant
837:28 - we're using adus Cloud HSM and the only
837:31 - time you're really using Cloud HSM is if
837:32 - you're a large Enterprise and you need
837:34 - that Regulatory Compliance of getting
837:36 - fips 14052 Level 3
837:39 - [Music]
837:43 - okay hey this is Andrew Brown from exam
837:45 - Pro and we are taking a look at Key
837:47 - Management Service also known as KMS and
837:49 - it is a managed service that makes it
837:51 - easy for you to create and control the
837:53 - encryption Keys you use to encrypt your
837:55 - data so KMS is a multi-tenant HSM so
837:58 - it's a Hardware security module and many
838:01 - adaba services are integrated to use KMS
838:03 - to encrypt your data with a simple
838:05 - checkbox and K KMS uses envelope
838:08 - encryption so here's that example of a
838:10 - simple checkbox in this case it's for
838:12 - RDS and what you'll do is choose a
838:14 - master key A lot of times ads will have
838:16 - a default for uh key for you that's
838:18 - managed by them that is free to use
838:20 - which is really great uh so for KMS it's
838:23 - using envelope encryption so when you
838:25 - encrypt your data your data is protected
838:27 - but you have to protect your encryption
838:29 - key when you encrypt your data key with
838:31 - a master key as an additional layer of
838:33 - security so that's how it works so just
838:35 - to make this really clear I have my data
838:38 - I use this key to encrypt this data and
838:40 - now I need to protect this key so I use
838:42 - another key to encrypt uh this key which
838:47 - forms an envelope and then I store this
838:50 - uh master key in KMS and this one's
838:52 - considered the data key all
838:55 - [Music]
838:59 - right hey this is Andrew Brown from exam
839:01 - Pro and we're going to take a look at
839:03 - Key Management Service also known as KMS
839:05 - so type in KMS on the top here and we'll
839:08 - pop over here and KMS is a way for you
839:10 - to create your own keys or you can use
839:13 - adus manage keys so up here and not all
839:15 - these appear right away but as you use
839:17 - Services um you will it us will generate
839:19 - out manage keys for you and these are
839:22 - free you can uh create your own Keys um
839:25 - and these cost a dollar each so if I go
839:27 - ahead here and create a key I can choose
839:28 - whether it's symmetric or asymmetric
839:29 - which we definitely learned in the
839:31 - course which is nice for asymmetric you
839:32 - can make it encrypt and decrypt sign and
839:34 - verify and they're just kind of
839:35 - narrowing down the type of key would use
839:39 - um for this you know if I went to
839:40 - symmetric I go here I'm just kind of
839:43 - seeing if if I can enter the uh actual
839:46 - material into the key here um so I'm
839:49 - just going to keep clicking through here
839:50 - U my custom key generally you don't
839:53 - really need to do this but um you know
839:55 - if it's interesting you can set up
839:56 - administrators to say who's allowed to
839:58 - administer the key and then you have
840:00 - someone that um is allowed to use the
840:03 - key and you usually want to keep those
840:04 - two accounts separate you don't want to
840:06 - have the same person administrating and
840:07 - using the key okay keep those two
840:09 - separate and so we would have a key
840:11 - policy so you can change this to say the
840:13 - rule tools that is allowed to use um and
840:17 - then we can go here and hit finish and
840:19 - so there we now have our own custom key
840:23 - and one thing we can
840:26 - do is it's possible to rotate out these
840:28 - Keys when you need to be um but anyway
840:32 - when we want to use CS it's built into
840:34 - basically everything and we've seen it
840:36 - multiple times throughout this course
840:37 - when we gone over to ec2 we'll just go
840:40 - take a peek at a few different places
840:42 - here so when we've gone to go launch an
840:44 - ec2 instance and we go over to uh
840:47 - storage so we say
840:49 - select and review or next and we go over
840:53 - to storage notice that here this is
840:56 - using encryption right so I can choose
840:58 - that or even my custom key if you're in
841:00 - Dynamo DB or anywhere else it's always
841:02 - something like a checkbox and you choose
841:03 - your key so that's pretty much all there
841:05 - really is to KMS it's very easy to use
841:07 - and there you
841:08 - [Music]
841:11 - go hey this is Andrew Brown from exam
841:14 - Pro and we are going to take a look here
841:15 - at Cloud HSM it is a single tenant uh
841:19 - HSM as a service that automates Hardware
841:22 - provisioning software patching High
841:24 - availability and backups so here's the
841:26 - idea is that you have your ads Cloud HSM
841:29 - you have your developers interacting
841:30 - with it your application interacting
841:32 - with it you have an HSM client installed
841:35 - in your uh ec2 instance so that it can
841:37 - access uh the cloud HSM keys so adus
841:41 - Cloud HSM enables you to generate and
841:43 - use your encryption keys on fips 140
841:45 - hyphen 2 level 3 validated Hardware it's
841:48 - built on open HSM industry standards to
841:50 - integrate with things like PK uh
841:54 - cs1 Java cryptography uh extension so
841:58 - jce Microsoft crypto and G libraries you
842:02 - can transfer your keys to other
842:04 - commercial commercial HSM Solutions to
842:06 - make it easy for you to migrate keys on
842:08 - or off AWS configure a KMS to use ads
842:12 - Cloud HSM uh cluster as a custom uh key
842:16 - store rather than the default KMS key
842:18 - store uh so Cloud HSM is way more
842:22 - expensive than KMS KMS is like free or a
842:25 - dollar per key where Cloud HSM is a
842:27 - fixed cost per month because you are
842:30 - getting a dedicated piece of Hardware um
842:33 - and there's not a lot of stuff around it
842:35 - so other than the ad KMS integration a
842:38 - lot of times it can be really hard to
842:39 - use this as well so the only time you're
842:41 - really going to be using Cloud HSM is if
842:43 - you're an ENT prise and you need to meet
842:45 - fips 140 hyphen 2 level three compliancy
842:49 - [Music]
842:52 - okay hey this is Andrew Brown from exam
842:55 - Pro and we are taking a look at know
842:57 - your initialism so a lot of AD services
843:00 - and Concepts and Cloud Technologies use
843:03 - initialisms to just kind of shorten uh
843:06 - common things that we need to use on a
843:08 - frequent basis and it's going to really
843:10 - help if you learn these because then
843:12 - what you can do is substitute them when
843:14 - you are uh seeing a service name or
843:17 - something particular and that's going to
843:18 - get you through content a lot faster um
843:22 - and in the wild you're going to see
843:23 - these all over the place because people
843:25 - aren't going to say the full name
843:26 - they're going to say the initialism so
843:28 - let's go through them so for I am it's
843:31 - identity and access management for S3
843:33 - that's simple storage for S swf it's uh
843:36 - swf that's simple workflow service SNS
843:40 - is simple notification service sqs is
843:43 - simple Q service SCS is simple email
843:45 - service SSM is simple systems manager
843:49 - but uh you know when we see the name
843:51 - it's usually just systems manager but we
843:53 - still use the uh initialism SSM then
843:56 - there's RDS relational database service
843:58 - VPC virtual private Cloud VPN virtual
844:01 - private Network CFN cloud formation WF
844:05 - web application firewall and that is a
844:07 - very common initialism not just adabs
844:10 - but outside of it as well mq for Amazon
844:13 - active m Q ASG for Autos scaling groups
844:16 - Tam for technical account manager elb
844:19 - for elastic load bouncer ALB for the
844:22 - application load bouncer NLB for the
844:24 - network load bouncer G wlb for the
844:27 - Gateway load balcer clb for the classic
844:29 - load bouncer ec2 for elastic cloud or
844:32 - Cloud compute ECS for elastic container
844:34 - service ECR for elastic container
844:37 - repository EBS for elastic block storage
844:40 - EMR for elastic map produce EFS for
844:43 - elastic FAL store EB or EB for elastic
844:46 - beant stock es for elastic search eks
844:50 - for elastic kuber netti service msk for
844:54 - managed kofka service and if you think I
844:55 - got the SNK backwards I did not for
844:58 - whatever reason it's mskk uh then uh
845:01 - there's abis resource manager which is
845:03 - known as RAM ACM for Amazon certificate
845:05 - manager Pol for principal of lease
845:08 - privilege which is a concept not a
845:09 - service iot internet of things this is
845:12 - not a service but is a Tech concept or
845:15 - Cloud concept RI for reserved instances
845:17 - and I'm sure there are more but these
845:19 - are the ones that I know off the top of
845:21 - my head uh and they're in my uh usual
845:23 - use case uh for what I'm doing dayto day
845:26 - but a lot of times you'll probably just
845:27 - end up needing to remember ASG
845:30 - elb um ec2 S3 things like that
845:34 - [Music]
845:38 - okay all right let's compare adus config
845:41 - and app config which both have config in
845:43 - the name but there are two completely
845:45 - different services so adus config and
845:48 - app config so Adis config is a
845:49 - governance tool for compliance as code
845:52 - you can create rules that will check to
845:53 - see if resources are configured the way
845:55 - you expect them to be if a resource
845:57 - drifts from the expected configuration
845:59 - you are notified or adus config can auto
846:01 - remediate correct the configuration back
846:03 - to the expected state for app config it
846:06 - is used to automate the process of
846:08 - deploying application configuration
846:09 - variable changes to your web application
846:12 - you can write a valid Val Ator to ensure
846:15 - the changed variable will not break your
846:16 - web app uh you can monitor deployments
846:18 - and automate Integrations to catch
846:20 - errors or roll backs so config is for
846:22 - compliance governance app config is for
846:25 - conf application configur configuration
846:27 - variables so there you
846:29 - [Music]
846:32 - go let us take a look at SNS versus sqs
846:36 - and uh these things have something in
846:38 - common and it's they both connect apps
846:40 - via messages uh so they're for
846:43 - application integration so let's take a
846:45 - look at SNS so simple notification
846:48 - service and then simple Q service okay
846:50 - so SNS is intended to pass along
846:53 - messages via a pub sub model whereas sqs
846:56 - cues up messages and has a guaranteed
846:58 - delivery so the idea with SNS you send
847:01 - notifications to subscribers of topics
847:03 - via multiple protocols so it could be H
847:06 - HTTP email sqs smns and SNS is generally
847:10 - used for sending plain text emails which
847:12 - is triggered via other adab services the
847:15 - best example here is billing alarms I
847:16 - know we mentioned this but I like to
847:17 - repeat it so that you absolutely know uh
847:20 - it can retry sending in the case of
847:22 - failur of https so it does have a retry
847:25 - attempt but that doesn't mean there's a
847:27 - guarantee of delivery it's really good
847:29 - for web hooks simple internal emails
847:30 - triggering Lambda functions if you had
847:32 - to compare these to thirdparty Services
847:34 - it's similar to Pusher or uh pubnub so
847:37 - sqs is uh the idea here is that messages
847:40 - are placed into a queue applications
847:42 - pull the queue using the itus SDK you
847:44 - can uh uh retain a message for up to 14
847:47 - days you can send them in sequential
847:49 - order sequential order or in parallel
847:52 - you can ensure only one message is sent
847:55 - you can ensure messages are delivered at
847:57 - least once it's really good for delayed
847:59 - task queuing up emails um comparable uh
848:02 - stuff would be something like rabbit mq
848:04 - or uh Ruby on Rails sidekick
848:07 - [Music]
848:10 - okay hey this is Andy Brown from exam
848:12 - Pro and we're doing variation study with
848:14 - SNS versus SC versus pinpoint versus
848:17 - workmail and so SNS and SCS get confused
848:21 - quite often but all of these Services uh
848:23 - have something in common they all send
848:26 - emails but uh the utility of email is
848:28 - completely different for each one so the
848:30 - first one is simple notification service
848:33 - is for practical and internal emails so
848:36 - you send notifications to subscribers of
848:38 - topics via multiple protocols so it's
848:40 - not just for email it can handle HTTP it
848:43 - can send sqs it can send SNS me or SMS
848:46 - messages so um messages to your phone um
848:50 - but uh it does send emails and so SNS is
848:53 - generally used for sending plain text
848:55 - emails which is triggered via other a
848:57 - Services the best example of this is a
849:00 - building alarm so most exam questions
849:02 - are going to be talking about SNS
849:04 - because lots of services can trigger um
849:07 - SNS for notifications and so that's the
849:10 - idea it's like oh um you know did
849:12 - somebody spend server send off an email
849:15 - through via SNS uh did we spend too much
849:18 - money here you know all sorts of things
849:20 - can go through SNS to send out emails
849:22 - and you need to know what are topics and
849:24 - subscriptions regarding SNS then you
849:27 - have sces so simple email service and
849:30 - this is for transactional emails and
849:34 - when I say transactional emails I'm
849:35 - talking about emails that should be
849:36 - triggered based on inapp action so sign
849:39 - up reset password invoices um so a
849:42 - cloud-based email service that is
849:44 - similar to this would be like send grid
849:46 - sces sends HTML emails uh SNS cannot so
849:50 - that is the distinction is that SCS can
849:52 - do HTML and pl text but SNS just do does
849:55 - plain text and you would not use SNS for
849:58 - transactional emails SCS can receive
850:00 - inbound emails uh SCS uh can create
850:03 - email templates custom uh domain name
850:07 - emails so when you use SNS it's whatever
850:10 - Amazon gives you it's going to be some
850:11 - weird address but sces is whatever
850:13 - custom domain you want you can also
850:15 - monitor your email reputation for SCS
850:18 - then you have Amazon pinpoint and so
850:21 - this is for promotional emails so these
850:24 - uh when we say promotional we're talking
850:25 - about emails for marketing so you can
850:26 - create email campaigns you can segment
850:28 - your contacts you can create customer
850:30 - Journeys via emails um it can do a Tob
850:33 - email testing and so sces and pinpoint
850:37 - get mixed up because a lot of people
850:38 - think well can I just use my transaction
850:40 - emails for promotion emails absolutely
850:42 - you can it's not recommended because um
850:46 - you know pinpoint has a lot more
850:47 - functionality around promotional emails
850:49 - they're built differently uh and so you
850:52 - know just understand that those two have
850:54 - overlapping responsibilities but
850:56 - generally you should use them for what
850:57 - they're for then you have Amazon
850:59 - workmail and this is just an email web
851:00 - client so it's similar to Gmail or
851:02 - Outlook you can create company emails
851:04 - read write and send emails from a web
851:06 - client within the adus Management
851:07 - console so there you
851:09 - [Music]
851:12 - go let us compare Amazon inspector
851:15 - versus adus trusted advisor so both of
851:17 - these are security tools and they both
851:20 - perform audits but what they do is
851:22 - slightly different so Amazon inspector
851:24 - audits a single ec2 instance that you've
851:27 - selected or I suppose you could select a
851:29 - multiple e2s it generates a report from
851:31 - a long list of Security checks um and so
851:34 - trusted advisor has checks but uh the
851:37 - the key difference here is that it
851:38 - doesn't generate out a PDF report though
851:40 - I'm sure you could export CSV data if
851:42 - you wanted to and then then turn that
851:43 - into a report uh it it gives you a
851:45 - holistic view of recommendations across
851:47 - multiple services and best practices so
851:49 - for example if you have an open port on
851:51 - the security groups I can tell you about
851:53 - about that you should enable MFA on your
851:55 - root account when using trusted adviser
851:57 - things like that um one thing though is
852:00 - that trust advisor isn't just for
852:02 - security does checks across um uh five
852:05 - different things um but they both do
852:07 - security and they both technically do
852:08 - checks
852:12 - okay
852:14 - so there are a few services that have
852:17 - connected the name you'd think they' be
852:18 - related in some way but they absolutely
852:20 - are not and they don't even have similar
852:22 - functionality but let's take a look here
852:23 - so we know the difference the first is
852:25 - direct connect it is a dedicated fiber
852:27 - optics connection from your data center
852:29 - DWS it's intended for large Enterprises
852:32 - with their own Data Center and they need
852:34 - an insanely fast and private connection
852:36 - directly uh to AWS and you'll notice
852:38 - they give private and enthesis because
852:40 - if you need a secure connection you need
852:42 - to apply
852:43 - uh an adus virtual private network
852:45 - connection on top of direct connect then
852:47 - you have Amazon connect this is a call
852:49 - center as a service get a toll-free
852:51 - number accept inbound and outbound calls
852:53 - set up automated phone systems uh so if
852:56 - you ever heard of an interactive voice
852:57 - system at IVs this is basically what
852:59 - Amazon connect is you have media connect
853:02 - this is the new version of elastic trans
853:04 - coder it it converts videos to different
853:06 - video types so if you have let's say a
853:08 - th videos you need to transcode them
853:09 - into different video formats maybe you
853:11 - need to apply watermarks insert
853:13 - introduction videos in in front of each
853:15 - one uh this is what you use media
853:16 - connect for
853:17 - [Music]
853:21 - okay just in case you see elastic
853:23 - transcoder as an option I just want you
853:26 - to know what it is compar it to Media
853:27 - connect so both these services are used
853:29 - for transcoding and technically elastic
853:32 - transcoder is the old way and it us
853:34 - Elemental media convert or just media
853:37 - convert is the new way so elastic
853:39 - transcoder was the original transcoding
853:41 - service it may still have promatic apis
853:43 - or workflows not available in media
853:45 - convert so this could be reasons why we
853:47 - see Legacy customers still using it or
853:49 - you know it's just too much effort for
853:50 - them to uh upgrade to the new one it
853:53 - transcodes videos to streaming formats
853:55 - uh media convert is more robust
853:57 - transcoding service that can perform
853:59 - various operations during transcoding so
854:01 - it also transcodes videos to streaming
854:03 - different streaming formats but it
854:04 - overlays images it inserts uh video
854:07 - clips extracts captions data it has a
854:09 - robust UI so generally it's recommended
854:12 - to use the uh media convert terms of
854:14 - costs are basically the same so there's
854:15 - no reason not to use media convert
854:18 - [Music]
854:21 - okay so itus artifact versus Amazon
854:24 - inspector get commonly mixed up all the
854:26 - time but both artifact inspector compile
854:29 - out PDF reports so that's where the
854:31 - confusion comes from but let's talk
854:33 - about what is different about the
854:34 - reports so abis artifact and Abus
854:36 - inspector so for artifact you're
854:38 - answering why should an Enterprise trust
854:40 - AWS it generates a security report
854:43 - that's based on global compliance
854:44 - framework such as sock or PCI or a
854:47 - variety of others where Amazon inspector
854:49 - is all about how do we know this ec2
854:51 - instance is secure can you prove it so
854:53 - it runs a script that analyzes your ec2
854:56 - instance then generates a PDF report
854:58 - telling you which Security checks had
854:59 - passed um so the idea here is it's an
855:01 - audit tool for security of ec2 instances
855:03 - so there you
855:05 - [Music]
855:08 - go so let us compare elb versus ALB
855:12 - versus lb versus J wlb versus clb uh
855:16 - because you know when I was first
855:17 - learning AWS I was getting confused
855:19 - because there was elastic load balcer
855:21 - but there was these other ones so what
855:23 - gives right so what's happening here is
855:25 - that there is a main service called
855:26 - elastic load balcer elb and it has four
855:30 - different types of possible load balcers
855:33 - so we'll go through all the types so the
855:35 - first is application load balcer
855:37 - commonly uh initialized as ALB and so
855:40 - this operates on layer 7 for htps this
855:43 - makes sense because that is the
855:44 - application layer and it has some
855:47 - special powers in terms of routing rules
855:49 - so the idea here is you can create rules
855:51 - to change routing based on information
855:53 - found within the htps request so let's
855:56 - say you wanted some uh routes to go that
855:59 - have a particular subdomain to this
856:01 - server and a different subdomain to
856:03 - another one you could do that and
856:05 - because it is an application load
856:07 - balancer uh you can attach a web
856:10 - application firewall for protection you
856:12 - can attach on the NLB or other ones
856:14 - because they're not application based so
856:16 - that is just a little caveat there then
856:18 - you have Network load bouncer uh
856:20 - commonly abbreviated to NLB this
856:23 - operates on layer three and four so
856:24 - we're talking TCP UDP this is great for
856:27 - when you have Extreme Performance that
856:29 - that requires T TCP and TLS traffic it's
856:32 - capable of handling millions of requests
856:34 - per seconds uh while maintaining ultra
856:37 - low latency it's optimized for sudden
856:39 - and volatile traffic patterns while
856:41 - using a single St static IP address per
856:44 - availability Zone uh if you're making
856:46 - video games this is what they like to
856:47 - use is the network load balcer but it
856:49 - has other utilities outside of that then
856:52 - you have Gateway load bouncer G wlb this
856:55 - is when you need to deploy a fleet of
856:56 - third-party virtual appliances that
856:58 - support uh I don't know how to say that
857:00 - in abbreviation but I'll just uh say
857:02 - it's GE NE v um and there's not much we
857:06 - need to know outside of that okay then
857:08 - there is the classic load balancer uh
857:11 - commonly initializes C B this operates
857:13 - on layer 3 4 and 7 it's intended for
857:16 - applications that were built within the
857:17 - ec2 classic Network it doesn't support
857:20 - Target groups so albs nlbs uh use Target
857:23 - groups which is just an easier way of
857:25 - grouping together um a bunch of uh
857:28 - Target resources like compute uh that
857:30 - we're going to load balance to and with
857:32 - classic load balcer you just directly
857:33 - assign ec2 instances uh and it's going
857:35 - to be retired on August 15th of 2022 so
857:39 - yeah it looks like it can do a lot of
857:40 - stuff but um it also doesn't have any of
857:42 - the superpowers of these specialized
857:44 - ones and so there's no reason to keep it
857:46 - around and generally you should not be
857:48 - using it um and so yeah that's about it

Cleaned transcript:

hey this is Andrew Brown over here on free Camp bringing you another free Cloud certification study course and this time we are looking at the ads Cloud practitioner also known as the CF C02 and the way we're going to achieve ads certification is through lectur content HandsOn labs and as always I provide you a full free practice exam the best way to support uh more free study courses like this one is to purchase the optional paid additional materials it's going to help you on your exam and it's going to allow me to produce more of these uh great Cloud uh certification study courses if you don't know me I'm Andrew Brown and this is the fourth time I've taught this uh certification so it's really refined at this point and I've taught a bit of everything in the cloud so we've looked at adabs Azure gcp terraform kuber dedes you name it I've taught it uh but that's about it and I will see you in class in the next video ciao hey this is Angie Brown and we are at the start of our journey asking the most important question first which is what is the adus cloud practitioner well it's ad's entry level certification that's going to teach you things like the cloud fundamentals so we're talking cloud Concepts architectures deployment models it's a close look at adus core Services which would be our compute our storage our Network our databases and it's a quick look at the vast amount of adus services and functionality around adus so we're looking at identity security billing pricing support and a lot more stuff and we'll get into that in the course and we'll even look at the exam guide outline but uh yeah there is a lot of stuff um the course code for this certification is now the clf C02 the old one was the c01 uh the way to know if there is a new course is if this becomes the c03 if you see that then this course um may be out of date um but uh yeah right now it's a C02 um often people refer to this certification as the CCP to stand for the certified clock practitioner how you want to refer to it is up to you but uh there are a few ways of describing this certification I want to point out that adus is the leading cloud service provider in the world and the cloud practitioner is the most common starting point for people breaking into the cloud so even if you're going to uh utilize another cloud service provider I'm just going to say that you're going to get a really good uh Foundation with this certification even if it's not the uh same provider uh so who is the certification for well consider the cloud practitioner if you are new to cloud and you're learning the fundamentals you are at the executive management or sales level and you need to acquire strategic information about Cloud for adoption or migration or you are a senior Cloud engineer or Solutions architect who needs to reset or refresh their adus knowledge after working uh with cloud services or adus for multiple years um it's always a surprise that when I come back and I refresh this course uh the things that have changed and it's very easy to uh miss those things so yeah this this certification is for everybody so what is the value of the certification well this uh certification provides the most expansive view possible of cloud architecture and ads it uh we I would describe this as having a bird's eye view or the 50,000 ft view so with that in mind uh the idea here is to promote big pictures thinking we're zooming out and assessing the cloud or itus landscape for things like changes Trends opportunities um and it's important to understand about being strategic about the approach and process for your journey and that's why I like the certification so much and I strongly uh recommend it for everybody's Journey so what is the value of the certification well it's not a difficult exam uh it's it's not going to validate that you can build Cloud workloads so if you are trying to obtain a technical te implementation role like develop Cloud developer Cloud engineer devops engineer uh it's not going to be enough to attain those technical Cloud roles um but it could help short list your resume for interviews um the exam covers content not found in other certifications so it is recommended as an essential study guide uh for your adus journey do not skip this one uh some people like to go straight to the solution to architect and then they realize that they didn't set a good foundation or they just have gaps uh in their knowledge which could really help out in their careers so really do not skip this one um I like to make these road maps to give you an idea uh in terms of where you can go after this certification so here is uh all the certifications currently that AOS has notice that I have the data engineer it's a really small one it just became uh came out as a baa exam it's not as hard as the professionals it's just where I place it on this diagram um but the idea is that we have a lot of different ways that we can navigate or uh work through these certifications and these can generally map to particular roles in the cloud so uh very often people go right to the uh Solutions architect I'm just getting my pen out here but very often this is the approach that'll go straight to here uh right after the solution architect because they're very similar um in terms of uh scope and Challenge and difficulty where the solution architect is a broad certification just like the cloud pratitioner but it's more focused on the technical knowledge uh whereas this one of course is much more broad the cloud and then after that people will generally go for the developer or the CIS office administrator in my personal opinion I really do think that people should study all three Associates and do all three Associates at the same time uh because really I don't find that uh it makes sense to leave out the ssops admin or developer knowledge um it's just the way that itus Engineers their certifications but when you go to other ones like let's say Google they only have one associate and they have all the um they call Cloud engineer and it has everything in it and so again I just feel like you should take all three but you decide what works for you um and you know you can see that there are various routes but I want to just make it very clear that certifications do not validate programming they do not uh make you do technical diagramming they don't necessarily make you do code management and there's many other technical skills that are required for obtaining technical roles like these roles um and that is not the purpose of certification certification is supposed to give you knowledge specifically on AWS and so just understand that you need to make sure you get those skills uh somewhere else I do try to uh slot in a lot of these uh technical skills uh where I can and so if you're uh if we're doing something in the course and you're wondering why are we doing this when it's not on the certification it's because I'm trying to give you those adjacent skills uh so that you are successful um in the future okay so how long does it take to uh study to pass this exam well depends right it depends but if you're a beginner we're probably looking at 30 hours so this is someone who's never used databus or cloud provider before uh you've never written code or had a technical role if you're experienced uh your study time is going to be very low like as low as 6 hours even lower uh if possible um especially if you've already taken the certification I sat it um uh blind right I didn't look up anything and I passed it no problem um but uh so it says here you know if we've practiced we have experience working with ads if we have an equivalent experience in another cloud service provider some people are coming over from Azure or gcp so they can kind of map their knowledge over to Ada of us or if they have a strong background in technology uh you might really be already familiar with these kind of offerings from another uh like from another discipline and so your study time can be really low but I would say that um you know the average study time is probably 24 hours so yes it's closer to the beginner level but that's the average study time that we found in and so it's basically a split between 50 lectures and Labs so labs are HandsOn skills and 50% with practice exams uh a lot of people forget that practice exams are part of the study process so make sure that you do do that uh we do recommend a study a study time of one to two hours a day uh for 14 days uh what does it take to pass the exam we're still going on with this here but you know you have to watch those lecture videos and memorize key information this is a knowledge based exam it's not a uh it does not test your skills so knowledge is key here uh you should do HandsOn Labs we call those follow alongs within your own account uh this is just going to help uh cement the knowledge in your head it really makes a a huge difference so really do those HandsOn labs and get practice exams to simulate the real exam you absolutely need to do this because if you don't you're going to find that you did all the study materials and then uh the exam is its own uh Beast so make sure that you go get some practice exams there's a lot lot of places that you can get get them from uh we offer a full free practice exam I think we're the only provider that does this but um we give you like a full free practice exam and we also have some paid ones so the best way to support this this content that we produce is to purchase our additional paid materials uh if you don't have the money that's okay we still have at least one full free practice exam to help you out you can find that over at exam pro. cfy C02 it looks like but it's a zero uh let's talk about the content outline so there are four domains and you have to understand that each domain has its own waiting this is going to determine how many questions in that domain will show up on your exam the first one is cloud Concepts so that's for 24% so we're looking at between 15 to 16 questions domain two is about security and compliance so that's 30% it's a a quite high up there so we have about 1920 questions for cloud Technologies and services it's 34% so understanding the offerings of adss is the most important thing in the exam it's the highest percentage here so we're going to definitely get 22 questions and then uh we have domain four so billing pricing and support where it's at 12% so we have eight questions not a lot for billing pricing support definitely important because it's very easy to get overbuild in the stuff but just you know point out that you need to know a wide range of adus services you need to know about core Services more in depth so where do you take this exam well you can take it at the um at an inperson test center or online from the convenience of your own home I personally like to take it in a test center if there is one near me I used to live in Toronto now I don't so there's no test centers near me and so I have to do it online it's just so much less stressful walking into a building and everything is uh controlled whereas at home you might have a lot of things going on and that can cause a lot of stress but you know do what makes sense for you so adus delivers the exams via Pearson View and so uh there's Pearson view they have the online system which you do uh you install on your computer and then they also have a network of test centers they partner with uh previously adabs also offered it via PSI um they don't do this anymore I'm not sure why they changed this before it was only PSI then they added Pearson and now they've dropped PSI so your only option is Pearson view I just want to point out what a prct exam means it means that it's it's someone is supervising uh your um your exam while you're taking it so you're not cheating so it's very common that when you check in they're going to ask to look around your room you might even have to talk to them uh and it's just again to make sure that what you do is um your exam was legit legit so when they issue your badge you know it's for real anyway let's talk about grading here so the passing grade here is 700 out of a a th000 points and so you need to get around 70% to pass ad of us like many other Cloud providers use scaled scoring so um that doesn't mean if you get exactly 70% that you'll pass but uh I mean more or less it works out to to be that okay so the response types uh we have here well first of all we have 65 questions and there are 50 questions that are scored and then there's 15 that are unscored and if that sounds bizarre I mean I I agree with you I think it's odd that they give you 15 unscored questions but the reason ads will do this is that they want to introduce new questions um to help test against the difficulty of the exam um because you know maybe some people know more than uh what they're expecting so they can adjust the difficulty of the exam I think that they use it as an antiche mechanism as well but from the test taker it can get a bit stressful because you can get 15 really crazy wild questions that were not in your um uh course studies and it's just adab us testing things out and so I just want to point out don't get stressed out when you take this exam and you get a really funny question it's probably one of those unscored questions but on top of that you know there are 15 scored questions you can get wrong so you can get a total of 30 questions wrong on this exam and pass I just want to make that uh really clear there there is no penalty for wrong questions so absolutely always submit an answer and take your best guess the format of the questions are multiple choice and multiple answer so you know it's not too stressful in terms of the formatting of questions um there are again 15 unscored questions of the exam they will not count towards your final score why are there unscored questions uh they're there to evaluate the introduction of new questions they're there to determine if the exam is too easy and the passing score of the question difficulty needs to be increased to discover users who are attempting to cheat the exam or steal dump exam questions if you encounter questions you've never studied for uh that seem really hard keep your cool and remember that they may be unscored questions just really want to emphasize that there in terms of the duration you get 1.5 hours so you have about 1.5 minutes per question your exam time is 90 minutes your seat time is20 minutes what are we saying when we say seat time this is the time it takes uh or that you should allocate for the full exam uh that includes uh things like reviewing the instructions uh showing on uh showing the online Proctor your workspace reading accepting the NDA completing the exam provide the feedback at the exam so a lot of people go okay my exam starting or I have 90 or 90 minutes exam but really you want to show up 30 minutes prior uh because that checkin process can be really really stressful so you know just consider that uh the full scope of time you need to dedicate for these exams this uh certification is valid for 36 months so that's 3 years before recertification some other providers uh like Azure if you do the fundamentals it's forever um other ones have require you to refresh every year other ones um you don't have to take the full exam you have a reassessment that is free inabus likes to do it this way the nice thing though is that when you do pass a certification um somewhere ads allows you to get the next exam half off uh so at least there are cost saving mechanisms if you do pass an exam for the next followup certification but yeah uh that is pretty much a breakdown of uh the exam guide we will go and take a look at the actual exam guide so we can uh understand the full scope of what's in there uh but yeah we'll see you in the next one okay ciao hey everybody it's Andrew Brown and we are here on the training and certification page on the adus website and what I want to do here is I want to pull up the exam guide so that we can um make sure that we know exactly what it is that we're getting ourselves into uh we did cover this in summary in the previous video but uh I think it's always useful for you to know exactly where these things are adabs is always changing their marketing pages and I've already noticed a few changes here so um just understand that's the nature of cloud notice here that it's talking about the uh beta exam certification so even earlier we talked about the data engineer or we at least showed it on our journey map and it's not even it's not even 100% out beta so you can see we're kind of prepping for the future here I also want to point out that they have this like certifications path uh thing and I I don't really like it because I don't think it's very accurate so the first thing they show is Solutions architect and they don't even say you need to get the other two associate certifications which you absolutely should do if before you go for your Solutions architect professional the data analytics is no longer a uh certification that adus is producing so this is an outofdate document so I just want you to understand that these are marketing Pages they're here to maximize the amount of certifications you need to obtain my goal is not to make you take every certification my goal is to make sure that you are prepared uh to do the job and um I just want to you know help you avoid going down the certification route and getting too many certifications that aren't going to benefit you so just take these with a grain of salt when you're reading them okay so anyway what I want to do is drop this down and go to Cloud partitioner um and here on the cloud cloud practitioner page if we scroll on down we got prepare for the exam and here we'll click the exam guide and it'll open up a PDF and it'll give us all the information we need to know this is what AB has been doing for a long time is making these um examp guide PDFs which I really like uh but anyway the first thing we should do is confirm the course code so this one says CF CO2 so we know we are on the right track and then down below here it says this exam validates the candidates ability to complete the following task I want to highlight some key wordss explain understand describe and identify so understand that this certification is not checking whether you know how to do Cloud it's more if you understand Cloud um and the majority of aable certification in fact all of them are multiple choice and multiple answers so they can't really check if you were able to do something in Cloud so just understand the limits of certifications at least eight of the certifications based on their testing mechanisms so when it says Target candidate it's saying uh where you should be in order to pass this exam and so they're suggesting that if you had six months of exposure to adabs uh with Cloud design implementation operate operation then uh you should be able to pass it it's just weird uh worded strangely because it makes it sound like you should have this experience um before you even start studying which is not true they just mean like if you want to pass it you don't need six months to pass this exam that's crazy you just need what we recommended which was um uh the amount of hours we said the average hours is 24 hours so um I'm not sure why they put six months I guess it's just they're for those who are really having a hard time with Cloud they give you a lot of uh um scope or room there but you can see they're pointing out from nonit backgrounds recommended us knowledge Cloud concept security core Services economics that's that's just a repeating of the domains um notice it says job tasks that are out of scope is coding um Cloud architecture design load performance and testing I'm highlighting these three because I just want to point out that in associate level professional and Specialty they actually do ask questions around troubleshooting mation and I suppose they do architectural design but they never ever ever No certification in ads is going to test your coding skills architectural diagram skills and they're not really good about load and performance testing they have like use case scenarios but um just understand again the limits of these certifications coming down below to the response types we got our multiple choice our multiple response um so that's pretty clear there there is uh 50 scored questions there's 15 unscored questions so that is very clear C the uh the the the point system is based out of a th to th000 points the lowest you can get is 100 points I don't know how that works why like why can't you get zero points I don't know the passing score is 700 so that's what we need to score there then down below here it's just talking about the course outline and it actually has a comparison of the old clf co1 so we can take a look there and see what actually has changed so down below here we have our Cloud cont Concepts as security compliance our Cloud technology services our bilding pricing support and then it comes in and starts describing all this stuff now I need to make it very clear how IUS makes their exams they give you a huge list of things you need to learn but if you learn um each one of these things you can end up overstudying or you'll find that the like the exam guide outline is not one to one I'll give you an example we'll look at something else so I'm going to go to Hashi Corp here for a second Hashi Corp terraform certification as a as an example of how different adab certifications are so for hashicorp they will this is their exam guide they'll give you each of these items and you can be 100% sure that every single thing every one one of these things will show up on the exam one to one so it's very easy to know exactly what you need to study for um and uh if you know all these things you'll you will pass in us they list all these things but they won't all show up they they're pulling from a very large pool so to kind of narrow down what you need to study you need to have a good sense of um overall everything and and you're just going to get some things wrong but um anyway coming back here the first Cloud Concepts they're talking about the benefits of cloud so we have a section on benefits of cloud and so they talk about the value proposition so there's like six or nine of them I forget we have a multiple slides on that and so we're talking about economics scale benefits of global infrastructure advantages of high availability elasticity and uh agility I think we call these Cloud architecture terminologies because they're not really benefits I mean they are benefits of cloud but I I like to group them a little bit differently then we have identified design principles for abis Cloud so we have the well architect framework this uh was for the most part never in the clf1 for 90% of its history and then they decided last year or something to add it in um and it and uh before even wasn't even the solution architect associate but now it's even at this level and that's totally fine you only need to know it at a very high level so um it's not too difficult to learn but it it's a white paper it's a PDF that um you know just describes how adus thinks that you should design uh your architecture then we have understand the benefits of strategies and migration to the cloud so we have Cloud adoption strategies uh Cloud adoption framework so um this was this was not in the last exam but uh luckily I included it because I thought it was something that was very important and so I already have it in the certification course even from the last one they actually do ask quite a few questions around the cloud adoption framework but when you look at and again this one's like a white paper just like this one above here and we'll talk about what white white papers are if you if you never heard that term uh it'll make sense in the course but the cloud adoption framework um there's not a lot to it but on the exam they'll ask you a lot of questions around it so you just have to have good common sense um about choosing those answers if that makes sense um identifying appropriate migration strategies sure I guess so I never got any snowball questions um they they say snowball here we go down below here understand concepts of cloud economics so cost Savings of moving to Cloud aspects of cloud economics uh fixed costs compared with VAR able costs they're talking about U Opex Opex and capex understanding the associate of on premise environments uh understand the difference between licensing strategies and adabs never ever really ever mentioned uh bring your own licenses ever in their certification courses and I never got this on the exam and other people I sat for the new exam never uh encountered this still good to know but I'm just saying that I don't know why it's listed in here because it's definitely not on the exam but it is a good thing to note the basic level understand the concept of right sizing um and maybe I'll go back and make a slide on that cuz I don't think I actually make a deliberate slide on that but I think what they mean there is understanding uh like how horizontal scaling and stuff uh stuff like that works but um again no questions on the exam for right sizing at least not from its technical definition like that identify benefits of automation I think there might have been one question of saying like hey which one lets you automate stuff and you just chose Cloud information but they really don't talk a whole they don't ask a lot of questions on the exam about iic infrastructure as a code identifying uh managed a services this is something they do a lot in exams like describe a service you pick it we have security and compliance so we have the Ed shared responsibility model you absolutely need to know that that for sure always always appears on the exam um customers responsibility they'll do this a lot they'll say like they'll give you a scenario of um of like a typical workload or resource and then you have to uh determine if it's the customers's responsibility or adab Us's responsibility describing responsibility of the customer itus share so again this is just all the share responsibility model still here describing how the itus respons responsibilities and customer responsibilities can shift depending on the the service used so yeah this is basically the sh responsibility model understand the it Cloud security governs compliance so uh compliance governments Concepts benefits of Cloud security they don't really talk about that uh they really directly ask that in the exam but yes we do cover that where to capture and locate logs that are associated with Cloud security they absolutely do not ask that on the exam I'm not sure why that's here um identify where to find A's compliance information that will absolutely be on the exam understanding compliance needs among Geographic locations and industries um sure I mean they're talking about we have a slide in this in the um Global infrastructure but it's um like data sovereignty and like gov cloud and things like that describing how customers secure resources for ads so just generally knowing the security services y that absolutely is on the exam identifying different encryption options I never got this on my exam I never heard of anyone else getting this but um if they are going to talk about this they're probably going to talk about it around S3 recognizing services that Aid in governance and compliance absolutely absolutely for sure that the you will get questions around uh things like fips or Hippa or like common common compliance certifications not specific datab best but just in general um here they're just talking about specific Security Services this is kind of a repeat of what they're talking about up here um but there's the say there's identity service governance service it's all the same thing here recognizing compliance requirements that uh vary among adus Services sure identify adus management capabilities so they're talking about IM am um the adus root account we got a separate slide on that uh principal of leas privilege absolutely absolutely will they will ask that there a single sign on also known as it identity Center I don't know anyone who's gotten this as a question on their exam but uh it's we got a slide for it understanding access Keys yep we cover that PO uh password policies credential storage Secrets manager systems manager um just a bunch of stuff identify components and resources of security describing a security features so ACL a wff security groups they really don't ask these on the exam so I'm just trying to make a point that they're asking for all this stuff and they don't even it doesn't even show up in the exam so um and you know we can just keep going and going through this and I can keep telling you what is and isn't but if you go down below it gets even crazier because they go any of this stuff could show up in the exam it's just like a big list it's crazy so you know I know that seems stressful but you know just follow follow me uh in this course and I you will absolutely pass if you go through my content you'll have no issue there and we'll avoid all the stuff that doesn't show up and don't stress out about this exam guide now let's go take a look here and see where the rebalance has changed so notice here that this went from 26% to 24% they never used to do this so I really appreciate this is now in the exam guide but we got 25 to 30% 33 to 34% 16 to 12% why they would reduce this one I don't know but it is a shuffle whatever um they of course increased uh the technology section more and did some basic rewarding support should have always been in there so it was always under that section but uh it's nice that they labeled it as such um so notice here it says no content was deleted from the exam and um this was the largest struggle for me for the certification because I already made all the content for the last one my old one is not spired and I was struggling because I already had this as well this is the only thing that they added that was new to the certification and then they just rework these numbers here and so um you know I just I added I did add more I add more Labs I added more um other stuff there but I'm just going to say like I don't know why they did an update from co1 to CO2 because barely anything changed now I shouldn't say that the exam questions did change I noticed that the exam questions um the quality of them kind of uh have dropped I'm wondering if they're using generative AI to generate out questions or or something but um there's something the quality of questions are are definitely um different and I would say that they're more uh they're not worded as clearly as they used to be for whatever reason um but anyway you'll still be okay it's totally fine uh recategorization of clf CO2 and so they just did a shuffle of um of these points and I again I really don't think that the the new one is better how useful is this exam guide I should probably give them uh survey feedback but anyway just give you an idea how much stuff there is in here do not stress out just stick with the course you'll absolutely pass uh and uh you know hopefully that gives you uh some better confidence there but we'll see you in the next one uh chiao chiao hey this is Andrew Brown from exam Pro and what we're looking at here is a free practice exam that I provide with you uh for this course and all you have to do is sign up on exam Pro you don't even need a credit card and you can redeem uh the free available content here and this is really up to date and very well simulates what you will see on the actual exam and it's a full set full 65 questions so you're getting a real simulation here but what I'm going to do is just start it off here we're not going to do the whole thing I'm just going to click through and show you a couple of them so you have an idea um the level of difficulty these questions are so the first question we got presented with here is which a support plans provide access to the seven core trusted advisor checks and so that is a question that you might need to answer I don't want to spoil this for you so I'm not going to tell you the answer we'll go to the next one so a large accounting firm wants to utilize OS to store customer accounting information in archive storage and must store this information for 7 years due to Regulatory Compliance which dat service meets this requirement so the first one you'll notice this one is multiple choice or sorry multiple answers so you have to select multiples before you can submit your answer and the the next one here is just a single choice so those are the two types of questions you will see on the exam they're not going to ask you anything about coding you're not going to see any kind of code um in terms of length that's pretty much what we'll see in terms of the uh questions I think in many cases I wrote a little bit more more like um in the style the solutions architect associate to make it slightly more difficult just so that you're a little bit overprepared so if you do well on these practice exams you're going to do uh well on the exam okay so I just wanted to kind of get you that exposure there okay hey everyone it's angrew brown and I have opened our exam simulator this is on the exam Pro platform and this is the free Set uh that I promised uh folks in the course so no cost to go get this one you just have to sign up and and access it but the reason I have it open is because I really want to talk about a very specific type of question that we've included in here that will not appear on your exam so uh for those who are familiar with Azure certifications um at the associate level or higher there's this question type called a case study and what a case study is I'll I'll just pull it up here but I believe uh in this randomization of this practice exam set I think it's this one here but what a case study is it gives you a scenario that you have to read through or a a case study about a company so you read about the company you look at the objective its requirements constraints this St can all be different there could be diagrams all sorts of stuff in here but the idea is that you are contextualizing a business use case and they're going to be asked a series of questions uh multiple choice multiple select and it all ties back to that case study so the reason we included this is that um we believe that this is going to give you better comprehension and a higher chance of passing so it's not going to appear in your exam but we include it as an extra challenge to you so that you have um a higher chance of passing now if you don't like this we do have other practice exams they of course are paid that uh that are just the normal style which is all multiple choice multiple select for um this this course the cloud partitioner um but you know we do have them in half of the practice exam sets because uh again I think that it's going to be good for you so hopefully you see that as a bonus but I just wanted to give you a heads up um about this uh because you'll counter me like what the heck is this um the other thing I want to point out is that when you enter a case study it's like having a mini exam within your exam so once you've answered all these questions uh you can't go back and and um you can while you're within the case study but if you get to the end of this and submit the case study you can't go back and update it so just be aware of that um and you know again hopefully you like this we love feedback to hear what people like but it's just they always appeared in Azure exams and uh we want to see them in 8 us ones as well because I think they're just really good for uh testing your knowledge but anyway we'll see you in the next one okay ciao hey everyone it's Andrew Brown your favorite Cloud instructor and what I want to do in this video is to show you um a unique feature that is in our platform um just in case you come across it while you're while you're uh doing the materials I can't remember if it's in the free or paid tier I believe it's in the paid tier so I'm not trying to upsell anyone but I just want to make sure people are aware of that while they are um taking this course but sometimes what you'll see in the follow along so like for example we have S3 down here which is for uh Cloud simple storage uh and I don't have them always included in the videos but um at some point I might do that but the idea is that um we have these validators and validators what they can do is they can verify uh whether you actually have uh the resources uh deployed in your cloud account um so it's like an additional check to make sure that you did it right so for example we have this one for S3 so it says setup an S3 bucket it is account validation so so this tool performs an automated check on your personal cloud infrastructure to confirm its alignment with the build project requirements make sure you input precise values for your infrastructure components so let's go through that and show you this I'm showing this as an example but you know you'll see them in other in other fongs and lookout for for that stuff I believe in the todo it'll even show it uh here so if you watch the video and you watched it to the end or you press that button there but you'll get your your uh your star uh for that but the way it works let's go through it so the first thing is I want to uh click on this new run button and then what we'll do is we'll have an agreement so this agreement is confirming that you understand that you are using your own cloud account uh and we are going to uh need to get readon access to it and just understand that you are using uh you're providing us access to account that is your own account and it's not your company's account because obviously we don't want to get in trouble for accessing data that we're not supposed to have and you don't want to get in trouble for that so that's just a a friendly reminder so I'm going to click the I agree and the accept the next thing it's going to ask for is your itus account ID the region that you're deploying in and then it there might be additional uh parameters that it wants to know so that we can test against it so what I'm going to do is just log into my adus account it'll just take me a moment and we'll fill this out for real okay now of course I'm filling out this example here but I just want to point out that um uh you know you're just going to have to follow this procedure and it'll be slightly different for each one uh for that okay be back in just a second all right so I'm logged into and uh one of my ad's accounts I have a lot of them uh I think this one is my developers one so uh for this particular follow along you would have created an S3 bucket right and so um what I'm going to do here is go to S3 and I already know what to do so it's not too hard for me but I'm going to go ahead and create myself a new bucket I'm going to make note of the region that I'm deploying in so S3 is a bit unique because it shows Global but you are still deploying to a specific region so we'll go ahead and create that bucket I'm just going to say my validator bucket as a test notice where it's deploying Us East one I could change that to anything else like ca Central um I am in Canada so doesn't hurt to deploy where I am and we'll go here and go all the way down and I'm going to go and create this bucket okay so um that bucket name was I forget it was like something like validator and so what I need to do is copy that name we'll go back over here and so it's asking for the bucket name so there's the bucket name we need to it account ID that always appears in the top right corner and they have a nice um clipboard button there to get that in there and the region so we deploy that in CA Central 1 so it says there CA Central one you're always using this uh programmer's name not the full name but this this fun handle you can see them all here on the right hand side if you're not sure about that but what we'll do is go back over here we'll paste in that user region and so what this is going to do is create a um a cloud formation template that's going to give access to us to uh your account so we'll go ahead and hit save and continue and so now we uh We've inputed our parameters those have been saved and now it's saying we need to access your Cloud resources so we want you to generate this cloud formation template we're going to press the button we'll wait a moment and we can either download this template or use the adab CLI to run it um the CLI command is a lot easier to use and I'm going to recommend that you always do that and uh so what we're going to do is generate out this CLI command and we're going to get this oneline command and I'm going to go back over to AWS sorry I know I'm going really fast but it's just how it is and at the top left corner we have this little button here that's for cloud shell we're going to open it up I know coding scary but it's really important to get as much coding experience or scripting as you can so strongly recommend you follow along here but uh it's going to open up and once it's it's open we can paste that in now sometimes this wants to have some kind of EBS storage so you might have to say yes and wait a little bit um that's just the norm for cloud storage but I'm going to go back here I'm going to copy this command okay and we're going go back over here I'm going to right click and paste and this always happens when there's a multitext line we got a pop up here and we're just going to review it looks good so notice it has a template URL so that's the template it's pulling in um there's temporary credentials to uh to allow that uh it's going to create a stack name called exam Pro validation and it's going to say capability named I am now this might fail because I've done it before but we'll go ahead and paste it in I'm going to hit enter and it looks like it's creating the stack so we'll go over to cloud formation and uh we'll go here and I'll just get this out of the way I don't want that open right now and so I'm just going to give this a refresh and did that create that right now that was the name of the stack right exam Pro validation that is correct and if I go over here uh what's the date today I don't even know because that might be an older date I mean it's November so I I don't think that one worked because I already had it uh working there before um so what I'm going to do here I'm going to go ahead and delete this one okay so I just want to point out like if you're doing multiple validators in the system you always have to roll it back tear it down okay like the old one so I'll delete that one again cuz I just don't have a strong confidence that it was actually deployed so I'll be back here in just a moment it tears down all right it actually did uh finish tearing down so that is um there but I'm going to go back here I'm going to attempt to run this command again so go ahead and copy this and I will paste it in again we'll say paste and I'll hit enter and uh it says already existed in the sack well what are you talking about it's definitely uh definitely not there that's what I thought I would get as an error the first time around so this is CA Central 1 oh oh you know what it is I'm in North Virginia so you got to be very careful with your um your regions so I go over here so I I I did delete one that was from another one that's why I was confused because I thought it already existed I have to delete it out th this is normal in Cloud right so just understand that when I do follow alongs I don't edit out the tricky Parts because I know it makes it a little bit confusing but it really does help to demonstrate uh how confusing Cloud can be and how to work through those proc but over here CA Central so this is deployed 1115 that's the date that I've deployed this on so that makes sense uh here so we just got to be very uh aware of that so this is in C Central one uh but we'll go back over here and so this is done so we know that it's done because it's here it's in the region that we expect it to be in so now the uh the permissions are done we can run the polar so what the polar is going to do is it's now going to pull data from your account uh uh and that way we're going to to uh be able to then validate whether things are correct so we'll go ahead and run the pull and notice it says S3 API list buckets it flashed it really quickly but the way this tool works is it's actually using the adab CLI underneath so I'm just going to go ahead and just show you what this is uh and just show you a quick reference here so the ad C is a pragmatic way to um uh access uh information uh for eight of us we probably show that somewhere in this course and so the command it was running I believe was I should know I coded this was S3 API and then it was like list buckets uh list buckets so that's the command it ran so really what the validator did it it did ads S3 API list buckets okay and if you notice this it returns back Json so we get back the payload that's what we are story in our own adus account which by the way we delete after a period of time I don't remember how much time but we we don't hold on to your data for long cuz we don't really want it um but yeah so here it's returning back that data and so somewhere in here that there the the buckets in here right so we've pulled that data and it's there and so now we can run the validator we'll click run validator and it's super fast because we already have the data downloaded and it's doing one check here so it says should have bucket matching name so you can see it's it's doing it's loading from a Json file that's called S3 API list buckets we always name our the Json files app after the commands and it's looking through buckets so if we go over here all the top here for a moment you can see buckets so it's looking within this array and it's trying to match a name called my validator bucket which which which you provided to us so somewhere in here I have a lot of buckets in this account somewhere in here uh there it is it's there and so that's how that works um but yeah just look out for those validators um and uh try to run them and and validate that uh you are able to uh do this stuff okay but we'll see you in the next one okay ciao oh wait wait wait wait wait wait wait I didn't show you how to clean up I'm just running off screen here so once you're done uh what you can do is you can go over to Cloud information here and you should do this is go ahead and delete the stack okay um because that's going to tear down the permissions so that we no longer have access to your account um so that's kind of an important thing to do um but uh we'll go ahead and the other thing about these permissions is that we're only asking for exactly what we need access to so in this in this uh permissions it only generate out to get access to uh the S3 bucket specifically what we're accessing for so even if you left it up it's usually okay it's safe but um you know if there's no reason for us to have access anymore you should all obviously delete it um but yeah that one is now gone and so now we are absolutely done I'm going to go ahead and just close this out here but yeah hopefully uh that makes it pretty clear how validators working in our system and you see the benefit to getting that uh check in your real account ciao hey this is Andrew Brown from exam Pro and we are at the start of our journey asking the most important question first which is what is cloud computing so cloud computing is the practice of using a network of remote servers hosted on the internet to store manage and process data rather than a local server or personal computer and so when we're talking about on premise you own the servers you hire the IT people you pay or rent the real estate you take all the risks but with a cloud provider uh someone else owns the servers someone else hires the IT people someone else pays or rents the real estate and you are responsible for configuring cloud services and code and someone takes care of the rest of it for you okay so to understand cloud computing we need to look at the evolution of cloud hosting going all the way back to 19 1995 where if you wanted to host your website or web app you'd have to get a dedicated server so that would be one physical machine dedicated to a single business running a single project a site or an app and as you can imagine these are expensive because you have to uh buy out write the hardware have a place to store it the network connection having a person to maintain it um but it did give you a guarantee of high security um and they still do as of today so this model hasn't gone away but it's been specialized for a particular use case then came along the virtual private server so the idea is we still had one physical machine but now we were able to subdivide um our machine into submachines via virtualization and so essentially you're running a machine within a machine and so you had better utilization of that machine um running multiple web apps as opposed to having a physical machine per project so you got better utilization and isolation of resources and so uh these two options still requireed you to purchase a machine a dedicated machine and so that was still kind of expensive but then came along shared hosting and so if you remember uh the mid 2000s like with GoDaddy or HostGator or any of those sites where you had really cheap hosting the idea is that you had this one physical machine shared by hundreds of businesses and the way this worked it relied on uh tenants underutilizing their resources so you know you wouldn't have a submachine in there but you'd have a folder with permissions that you could use um and so you would really share the cost and this was very very cheap um but you were limited to whatever that machine could do and you were very restricted in terms of the functionality you had and there was just poor isolation meaning that you know if one person decided to utilize the server more they could hang up all the all the websites on that single server then came along Cloud hosting and the idea is that you have um multiple physical machines that act as one system so this is distributed computing and so the system is abstracted into mult multiple cloud services and the idea is that you basically get the advantages of a lot of the things above so it's flexible you can just add more servers um it's scalable it's very secure because you get that uh virtual isolation you get it extremely at a low cost because you're sharing that cost with the users where in the shared hosting it might be hundreds of businesses we're looking at thousands of businesses and it was also highly configurable because it was a full virtual machine now uh Cloud actually uh still includes all of these types of Hosting they haven't gone away uh but it's just the idea that you now have more of a selection for your use case uh but hopefully that gives you an idea what cloud hosting looks like and it really has to come down to distributed computing okay hey this is Andrew Brown from exam Pro and before we talk about ads we need to know what is Amazon so Amazon is an American multinational computer technology corporation headquarted in Seattle Washington and so this is the Seattle skyline with the Space Needle and Amazon was founded in 1994 by Jeff Bezos and the company started as an online store for books and expanded to other products so as you can see this is Jeff Bezos a long time ago and he has this interesting spray painted sign and his desk is held up by cinder blocks and it looks like his uh desk is like an old uh table or something and he's working really late and he used to be a millionaire at this time and he would be driving into work his Honda Accord because you know he just his motivation was always to put all the money back into the company so he really shows that he worked really hard and it did pay off because Amazon has expanded uh Beyond just an online Ecommerce store into a lot of different things such as cloud computing which is Amazon web services Digital streaming such as Amazon Prime video Prime music they bought twitch.tv they owned the Whole Foods Market grocery store they have all this artificials intelligence they own low orbit satellites and a lot more stuff it's hard to list at all and so Jeff Bezos today is not the um the CEO it's actually Andy jasse is the current CEO of Amazon he was previously the CEO of AWS so Jeff Bezos can focus on space travel so there you go hey this is Andrew Brown from xampro and we are taking a look at Amazon web services and this is the name that Amazon calls their provider service and it's commonly referred to just as AWS so here is the old logo where we see the full name and here is the new logo but I like showing the old logo because it has these cubes which best represent what AWS is and it is a collection of cloud services that can be used together under a single unified API uh to build uh a lot of different kinds of workloads so adus was launched in 2006 and is the leading cloud service provider in the world I put an aster there because technically adus existed before 2006 and a cloud service provider uh which is what adus is is often initialized as CSP so if you hear me saying CSP I'm just saying cloud service provider okay so just time to look at the timeline of when Services rolled out the first one came out in uh 2004 it was simple Q service sqs and this service still exists as of today but at the time it was the only service that was publicly available so it wasn't exactly a cloud service provider at this time and it was neither ads it was just sqs but then a couple years later we had simple storage service also known as S3 which was launched uh in March of 2006 and then a couple months later we had elastic compute Cloud also known as ec2 um and ec2 is still uh like the most used service within AWS and is like the backbone for pretty much everything there then in 2010 it was reported that all of amazon.com's retail sites had migrated to to AWS so even Amazon was using AWS uh Full Steam and to support industrywide training and and skill standardization itus began offering a certification program for computer Engineers on April 2013 uh and this is the type of certifications that we are doing as we speak um so I just want you to know that ad us was the one leading uh Cloud certifications if we just want to take a look here at the executive level as of today the CEO is Adam he's the former CTO of tableau and he spent a decade with adus as a VP of Marketing sales and support so he was there he had left for a bit and now he is back then we have uh wner and he's the CTO of AWS he's been uh the CTO for pretty much the entire time ad was existed with the exception of sometime of the first year he's famous for uh quoting everything fails all the time and then there's Jeff bar who's the chief evangelist so um if you're ever wondering who is writing all the blog posts and talking about ad bus it's it's always Jeff bar okay all right so what I want to do here is expand on what is a cloud service provider also known as a CSP just because there's a lot of things out in the market there that might look like a CSP uh but they actually are not so let's go through this list and see what makes a CSP so this is a company which provides multiple cloud services ranging from tens to hundreds of services those cloud services can be chained together to create CL architectures those cloud services are accessible via a single unified API so in ad's cases that is the adus API um and from that you can access the CLI the SDK the Management console those cloud services utilize metered building based on usage so this could be per second per hour uh vpcu memory storage things like that those cloud services have Rich monitoring built in so you know every API action is tracked and you have access to that so in A's case it's Aus cloud trail and the idea here is those cloud services have infrastructure as a service offering so IAS that means they have networking compute uh storage databases things like that those cloud services offers automation via infrastructure as code so you can write code to set everything up and so here's just kind of a example of an architecture where we have a very simple uh web application running on ec2 behind a load bouncer with the domain with r 53 but the idea is just to show you that you know you're changing these things together if a company offers multiple cloud services under a single UI but do not meet most of or all of these requirements it would just be referred to as a cloud platform so when you hear about twio or hashy Corp or data bricks those are Cloud platforms and adabs Azure gcp are cloud service providers okay all right let's take a look here at the landscape of cloud service providers this is generally broken down into tier one tier 2 tier three but I've modified it to give each tier its own name as I don't like to think of them as rankings and more so that uh these cloud service providers are specialized for a particular thing um and I've also added a fourth tier because you know the internet has always talked about three tiers but there really is a fourth tier and I wanted to make sure we had uh the full scope here included so in the top tier you're going to recognize uh some common names there Amazon web service Microsoft Azure Google Cloud platform and Alibaba cloud in North America and Europe uh adab us Azure and gcp are known as The Big Three um but Alibaba cloud is huge as well if you're in the Asia region specifically China so it's really just going to be dependent on where you live where uh which are considered the most um commonly known or popular uh but we'll talk about that here in a moment but the reason um I call tier one top tier is that these are you know very wellknown providers they're ear early to Market they have strong synergies between their services um they're just really good cloud service providers you cannot go wrong with uh these providers then we have our tier two or I would call our midtier uh these are backed by really wellknown tech companies but I would just say that um their ability to become top tier uh did not work out the way they planned so IBM at one point was looking to be a top tier provider um but they just did not keep up with um AWS and they just slipped into this mid tier and kind of specialized at least for a while into ml AI services and now they're just more like very expensive um Enterprise U managed infrastructure for their existing clientele Oracle um very very inexpensive that's their play they try to uh be the cheapest but their uh service um overall is not uh fun to use interestingly enough I believe Microsoft Azure was just signing a contract to use Oracle Cloud so it's not unusual for some of these cloud service providers or these organizations to use other providers because they want to use their Global infrastructure but uh yeah Oracle cloud is uh not doing that great there are other ones in the Asia region like uh Hawaii cloud and tensent Cloud I honestly don't know a whole lot about them but they do show up on the magic quadrant so it's possible the Asia region that these are the big three and uh AWS Azure and gcp do not play a larger role but from our perspective I put them into that mid tier because they just don't have Global uh awareness or Global um market dominance like the other three uh up there looking at the light tier uh these were traditionally virtual private servers so they just specialized in that and they turn to offer more core infrastructure service offerings so we we have a vulture I always thought it was pronounced Vol but it's actually vulture digital ocean and aimi connected Cloud which was formerly known as Leno or Leno um so they merg their companies together and I mean they want to be like a cloud service providers but they're very very light in terms of their offering so um you know they'll have things like serverless and being able to run a kubernetes cluster and some cloud storage and stuff but they won't have things like uh the the same level of event driven metered billing or or other kinds of functional that you you come to expect in the top tiers but you know if you're working with a smaller organization they are a lot simpler to uh to utilize so they are a great introduction to Cloud for companies that find the top tier uh too complex and then looking at the fourth tier I call this the private tier this is uh basically software that you can deploy onto your own uh machines in your data centers to get the same kind of um functionality that you would if you were using let's say adabs or any of these other providers and um you know previously I would put open stack into the mid tier because in a sense that it was kind of like a cloud service provider that was using uh quite a bit but I didn't feel like it had had good fit there so that's why we made this a fourth tier and we have a few different softwares we have open stack Apache Cloud stack those are both open source and there's VMware vpar I have an aster there because it's not really the same thing but it is used a lot everywhere to manage a lot of virtual machines and so I I kind of feel like it should fit in there but that gives you kind of an idea of the landscape of cloud and we'll see you in the next one so how do we determine who is the leader in Cloud well one way of indicating that is the gardener magic quadrant for cloud so the magic quadrant is a series of market research reports published by the IT consulting firm Garder that rely on proprietary qualitative qualitative data analysis methods to demonstrate market trends such as Direction maturity and participants so it says a series of reports uh but the only thing I've ever seen are these Graphics where they show um a uh the quadrant it's a it's a diagram that summarizes all the information so I think you have to you might have to pay to access uh the reports um because it's definitely not just uh publicly accessible knowledge and I don't think they would show all of uh how this stuff is calculated but uh let's just take a look at this graphic here so notice we have challengers in the top left corner leaders in the top right corner in the bottom left corner we have Niche players and then in the bottom right corner we have Visionaries so the idea here is that The Closer you are to this top Corner uh the better you are doing and the one that is closest to it is Amazon web services followed with Microsoft pretty close uh in second Google to the left Alibaba cloud X Oracle and then we have IBM 10cent and Hawaii and there are other players but they are so small that they are not showing up there and we showed that in the landscape of csps or um maybe this is only for first they consider what uh we call First tier or top tier cloud service providers it's really useful to look at last year's uh mq and to see how things have moved so it looks like uh it uh Microsoft has shifted a little bit forward here and gone a little bit closer to AWS Google has significally moved up and um Alibaba Cloud it seems to be moving more uh to the right um and again I'm just showing what their movements were from this year to that year so they are over here now Oracle is way over here now and for whatever reason Huawei cloud is on the board so it's interesting to see how they move another thing that's um interesting here is that this one is 2022 of June and this one is July of 2021 and right now as the time I'm recording this video it's 2023 near the end of the year um and I could not find a 2023 one so even if it says June or July they will release these out in October November Etc way later in the year and so for whatever reason they have yet to make um the latest one available so I'm still curious to see what that is here so I'm just giving you the information that we have but you can look at this stuff um basically on the The Gardener website if you want to see um any of these magic quadrants for any of the industries there and what I find is is that if uh companies doing really well they'll always post it on their website so it's very easy to find the uh Magic quadrant for cloud on the ads website because they're the leader so they definitely want to show that there U but yeah there you go so a cloud service provider can have hundreds of cloud services that are grouped into various types of services but the four most common types of cloud services for infrastructures of service uh and I call these the four core would be compute so imagine having a virtual computer that can run applications programs and code networking so imagine having virtual Network defining internet connections or network isolation between services or outbound to the internet storage so imagine having a virtual hard drive that can store files databases so imagine a virtual database for storing reporting data or a database for general purpose web applications and uh AWS in particular has 200 plus cloud services and I want to clarify what cloud computing means because notice that we have cloud computing Cloud networking cloud storage Cloud databases but the industry often just says cloud computing to refer to all categories even though uh it has computer in the name so just understand when someone says cloud computing uh they don't just generally mean the subcategory they're talking about all of cloud okay so adus has a lot of different cloud services and I just want to kind of go quickly over the types of categories that we can encounter here and just mention the four core so any CSP that has IAS will always have these four core service offerings we have computes so Nat this would be ec2 VMS storage this could be something like EBS virtual hard drives database so that could be RDS SQL databases networking and content delivery but really it's networking uh and this would be VPC so private Cloud Network okay so uh let's just look at all the categories that are outside the four core so there could be analytics application integration arvr a cost management blockchain business application containers customer engagement developer tools and user Computing game Tech iot Machine learning management and governance Media Services migration uh and transfer most mobile Quantum Technologies robotics satellites security identity and compliance if there was more I would not be surprised but you can see there's a lot of stuff that's going on here so let's take a look at all the itaba services that are available to us so if you're on the marketing website which is adab. amazon.com what you'll see in the top left corner is products and so these are all the categories and for whatever we want if it's like ec2 we can go into here and we can read all about it so usually we'll have our overview all right and that's not very useful and then we'll go over to features and so this is can be kind of useful to get some basic information and pricing which is something you'll do a lot in adabs is you're always going to be going to a service looking up its price and so you'll make your way over uh here every single one is different a very important page would be like getting started so this will give you basic information but what I do is I like to go all the way down to the bottom here and find my way over to the documentation so I'll go here to documentation to get that deeper knowledge about that service and as you can see things get pretty deep with AWS in terms of the information they have so hopefully that gives you an idea of the scope also when you're logged into databus and this will be when we create our account uh you can explore all the services this way as well so these are all the adus services uh but you just notice that there's two ways to uh explore them where this is actually you just actually utilizing the services is and then the marketing website is you reading about them and learning all about them okay hey this is Andrew Brown from exam Pro and we are looking at the evolution of computing your cloud service provider has all of these offerings and the idea is that you need to choose the one that meets your use case a lot of times this all has to come around the utilization of space that's what we're trying to illustrate here in this section here and the tradeoffs of why you might want to use some of these offerings okay for dedicated we're talking about a uh a physically uh a physical server wholly utilized by single customer that's considered single tenant and uh for Google Cloud we're talking about um single node clusters and bare metal machines where you have control of the virtualization so you can install any kind of hypervisor or virtualization you want in the system the tradeoff here though is that you have to guess upfront what your capacity is going to be and you're never going to 100% utilize that machine cuz it's going to have to be a bit under in case the utilization goes up that's you're choosing the CPUs and the memories you're going to end up overpaying because you're uh you'll have under underutilized server uh it's not going to be easy to vertically scale it's not like you can just say resize it because the machine you have is what you have right you can't add more I mean I suppose they can insert more memory for you but that's a manual migration uh so it's very difficult um and replacing the server is also very difficult okay so you're limited by the host operating system it's not virtualized so whatever is on there is is on there um and that's what your apps are going to have access to uh if you decide to run more than one app which is not a good practice for these kind of machines uh you're going to end up with a resource sharing where one machine might utilize more than the others technically with a dedicated machine you have a guarantee of security privacy and full utility of the underlying resources I put an aster there because yes it's more secure but uh but it's up to you to make sure that it's more secure so you have that's up to your skills of security right whereas if you had a virtual machine or anything above that there's more responsibility on the cloud service provider to just provide a secure machine and they can do a better job than you so why would you use a dedicated machine well maybe you're doing high performance Computing where you need these machines like very close together and you have to choose what kind of virtualization you need to have okay so then we're looking at virtual machines the idea here is you can run a machine within a machine the way that works is we have a hypervisor this is a software layer that lets you run the virtual machine uh the idea here is now it's multitenant you can share the cost with multiple customers you're paying for a fraction of the server uh you'll still end up overpaying for the underutilized virtual machine because a virtual machine is just like you have to still say how many V vcpus how much memory and your app is you know you don't want an app that uses 100% right you want to use exactly the amount you need but you can see here you know there's still going to be some underutilization uh you limited by the guest operating system now but now it's virtualized so at least it's very easy to uh possibly migrate away if you choose to run uh more than one app on a virtual machine it it can still run into resource sharing conflicts uh it's easier to export or import images for migration it's easier to vertically or horizontally scale okay and virtual machines are the most common and popular offering for compute because people are just very comfortable with those then you have containers and the idea is you have a virtual machine running these things called containers the way they do that is similar to a hypervisor but in instead you have um like here is a Docker demon so it's just a um a container software layer okay to run those containers there's different kinds Docker is the most popular uh and the great thing is you can maximize the uh the the capacity because you can easily add new containers resize those containers use up the rest of the space it's a lot more flexible okay uh your containers will share the same underlying OS but they are more efficient than multiple VMS uh multiple apps can run Side by without being limited uh by the same OS requirements and not cause conflicts during resource sharing so containers are really good but you know the tradeoff is there a lot more work to maintain then you have functions functions go even step further and the idea is that you uh the the containers where we where we talked about that's a lot of work to maintain now the cloud service provider is taking care of those containers generally sometimes not it depends if it's servers or not but the idea is that you don't even think about and this is called servess compute but you don't even think about uh the OS or anything you just know that what your runtime is you run Ruby or python or node and you just upload your code and you just say uh I want this to be able to run uh uh for this long uh and use this amount of memory okay you're only responsible for your code and data nothing else it's very cost effective you only pay for the time the code is running uh and VMS only run when there is code to be executed but because of that there is this concept of cold starts and this is uh where the virtual machine has to spin up and so sometimes requests can be a bit slow so there's a bit of tradeoff there but functions or serverless compute is generally one of the best offerings as of today but most people are still getting kind of comfortable with that Paradigm okay hey this is Andrew Brown from exam Pro and we are taking a look at the types of cloud computing and the best way to represent this is a stacked pyramid and we'll start our way at the top with SAS also known as software as a service so this is a product that is run and managed by the cloud service provider you don't have to worry about how the service is maintained it just works and remains available so examples of this and actually uh the first uh company to coin this was actually Salesforce um then there's things like Gmail Office 365 so think Microsoft Word Excel things like that and they run the cloud okay and SAS is generally designed for customers in mind then came along platforms of service um also known as and these focus on the development or sorry the deployment and management of your apps so you don't worry about provisioning configuring or understanding the hardware or operating system and so here we' have things like elastic beant stock Heroku which is very popular among developers that just want to launch their code or Google app engine and that is the old logo but that's the logo I like to use because I think it looks cool and so these are intended for developers the idea is that you just deploy your code um and the platform does the rest then there is infrastructure as a service um there's no way to say that like it's easy to say SAS or pass but there's no easy way to say IAS so this is the basic building blocks for cloud it it provides access to networking features computers and data storage space and the idea here is you don't worry about the IT staff data centers and hardware and so that would be like Microsoft Azure AWS Oracle Cloud things like that and these are for admin Traders okay so there you go hey this is Andrew Brown from exam Pro and we are taking a look at cloud computing deployment models starting with public cloud and the idea here is that everything when I say everything I'm talking about the workloads the projects the code is built on the cloud service provider so here is a diagram where we have a ec2 instance a virtual machine running her application and then we have our database in RDS and we have the internet coming into our adus account and so everything is contained all of our infrastructure is within AWS all right uh and so this is known as being Cloud native or Cloud first and I put an aster beside Cloud native because that was a term uh that was uh used prior to Cloud Serv providers to refer to Containers or open Source um uh models being deployed and being mobile other places so just understand that it has two meanings but uh in the context of this cloud of just being like native to the cloud like using Cloud to begin with okay then we have private Cloud so everything built on a company's data center uh and being built on a data center is known as being on premise because that is where the data center resides near where you work and so here you could be using Cloud but you'd be using openstack which would be a private Cloud so here we have our on premise Data Center and uh the internet's coming into our data center and we're running on open stack where we can launch virtual machines and a database okay then there's the concept of a hybrid Cloud so using both on premise and a cloud service provider together and so the idea here is we have our on premise Data Center and then we have an established connection maybe it's a VPN connection maybe it is a direct connection um but the idea is that we're bridging that connection and uh utilizing both our private and our public uh stuff to uh create a cloud workload then there is a fourth one called cross Cloud um sometimes it's known as multicloud and sometimes it's erroneously referred to as hybrid Cloud but it generally is not uh hybrid Cloud okay the idea here is when you're using multiple Cloud providers and so one example here could be using services like Azure Arc so Azure Arc allows you to extend your um control plane uh so that you can deploy containers for kubernetes in um Azure within Amazon eks Within gcp n's engine but you know being cross Cloud doesn't necessarily mean that you're running a using a service that use Works across the cloud and manages it it could just mean using multiple providers at the same time another service that is similar to Azure Arch but is for Google Cloud uh platform is also known as anthos um adab us has traditionally not been um cross Cloud uh friendly and so we haven't seen any kind of developments there where we see these other services that are or CL Prov behind AWS trying to promote it to uh grab more of the market share okay so let's talk about the different deployment models and what kind of companies or organizations are still utilizing uh for these particular categories so for cloud again this is where we're Fally utilizing cloud computing hybrid is a combination of public cloud and on Prem or private cloud and then on Prem is deploying resources on premise using virtualization resource management tools sometimes called private cloud or could be utilizing something like open stack so for companies that are starting out today or are small enough to make the leap from virtual private server to a cloud service provider this is where we're looking at Cloud so we're looking at startups SAS offerings new projects and companies um so maybe this would be like base camp Dropbox Squarespace then for hybrid these are organizations that started with their own data center but can't fully move to Cloud due to the effort or migration or security compliance so we're talking about Banks fintech investment management large professional service providers Legacy on Prem so maybe CIBC which is a bank deoe uh the CCP or CPP investment board and then for on premise these are organizations that cannot run on cloud due to strict Regulatory Compliance or the sheer size of the organization or they just have like an outdated uh idea of what cloud is so they just have a lot of uh difficulties in terms of politics adopting Cloud um so this would be public sector like government super sens of data like hospitals large Enterprise with heavy regulation insurance companies um so again hospitals maybe AIG the government of Canada and so I shouldn't say that they aren't using Cloud but um you know because uh adabs and all the cloud service providers have um uh public sector offering so um you know I'm just trying to Stage as an example of things that could be still using on premise so you know I know the government of Canada definitely uses uh cloud in a lot of ways same with AIG and hospitals but you know generally these are the the last holdouts of on Prem because there really isn't a a good reason to be fully on premise anymore uh but again there are some things that are still doing that okay hey this is Andrew Brown from exam Pro and we are at the start of our journey creating ourselves an adus account so what you need to do is go to ads. amazon.com if you don't have a lot of confidence how to get there just type in adabs into Google and then click here on the L link where it says adus amazon.com it'll take you to the same place now notice we have a big orange button in the top right corner so this says sign into the adus console um it's the if it's the first time you've ever been to this website so if I go to adab. amazon.com Incognito it will have the create an Abus Account button um I don't know why they don't keep this consistent across the board but I wish they did but if you are on the screen you can click here or there um but if you do see something that doesn't say uh you know create an account account or or Etc you can just sign in okay and then down below you can hit create a new a account so that's the way you're going to get in there and so you're going to put an email a password and create an adist account name um I've created this so many times and it's so hard to set up new emails I'm not going to do this again it's not complicated but one thing I need to tell you is that you do need to have a credit card you cannot create an account without a credit card um and for those who are in places where maybe you don't have a traditional credit card card maybe you can get a prepaid one so up here in Canada we have a company called coo and so coo is um a Visa debit card and so it's basically a virtual prepaid credit card and so these do work on the platform as well so if you have a traditional credit card or possibly could find one of these uh you still have to load up with money but it does give you a bit more flexibility to create that account so what I want you to do is go through that process yourself it's not complicated and I'll see you on the other end okay so once you finished creating your account you should be within the adus Management console and this is the page you're always going to see when you log in it's always going to show the most recent Services here um and you'll notice in the top right corner that I have my account called exam Pro if you're wondering how do you change that name what you do is to go to my accounts here and once there you'll have your account settings up here if you go to edit uh you can change that name here okay so you know sometimes when you create your account you don't like the account name that you gave it and so that's your opportunity to fix it um but once we're in our account what I want you to do is immediately log out because I want you to get familiar with the way you log into AWS because it is a bit um different than other providers and so I don't want you to uh get hung up later on with your account so I've logged out I'm going to go ahead and log back in so you can click the orange button or what I like to do is drop down my account and go to itus Management console it's a lot more clear and you notice we're going to have two options root user and I am user so this is what I'm talking about for the confusion so when you log into your root user account you all are always using an email and when you're logging as an IM user you're actually going to be entering the account ID or account Alias but what we'll do is go to the root user and this is the email you use to sign up with the account so for me uh I called this one Andrew plus sandbox exampro . Co I'm going to go to next sometimes you get this character box it's very annoying but it happens time to time and so what I'm going to do is just go ahead and type that in okay and hopefully it likes it and then I'm just going to enter in my password all right and I'll be back into my account and so notice it takes me back to ABS Management console so the root account is not something we want to be generally using uh except for um very particular use cases and we do cover that in the course uh but what I want you to do is go set yourself up with a proper account and so what we'll do is go to the top here and type in am and this stands for identity and access management and we'll click on am here and on the left hand side we're going to see a bunch of options here um and so notice right away we get to the I IM dashboard where it's going to start to make some recommendations for us the first one is always to add MFA multiactor authentication another thing you can do is set an account account Alias so you can see that I've set one here prior so if I just go ahead and remove it the way we'd have to log in is via the account Alias uh which is the same as the account ID and so I don't really like that so I'm going to just rename it to Deep Space 9 and uh these are unique so you have to pick something that is unique to you so it could be your company name or things like that it's going to make it a lot easier to log in uh when we create our additional user here so we'll come back to MFA at some point here what I want you to do is go over to users and go ahead and make yourself a new user and so I'm going to call this one Andrew Brown and I'm going to enable programmatic access I'm going to enable ads Management console so this one's going to allow me to use the apis to programmatically work with ads and this one here is going to allow me to just log into the console which is uh pretty fair here so now that I have this we can autogenerate or give it a custom password I'm just going to autogenerate for the time being and here it says You must create a new password at the next sign in which sounds fair to me and we go ahead and create ourselves a new group so it's pretty common to create a group called admin and notice here this is where we're going to have a bunch of different policies so the first one here which is admin and access provides full access to a services and resources and this pretty much gives you almost nearly almost the same capabilities as the um AWS root user account uh and so that's going to be okay because we are an admin in our account so I'll checkbox that on but I just want to show you here if you drop down filter policies and you went to adus manage job functions these are a bunch of uh premade uh adus uh policies that you could apply uh to different users so what's really popular after the administrator access is to usually give the power user access and so this one allows um a user to do basically anything they want with the exception of management of users and groups so you know it could be that that's something that you'd want to do for some of your users I just don't want to have any trouble so I'm going to give us um admin access here and we're going to go ahead and create this group and so here is the group that we are creating we're going to go next we can apply our tags if we want I'm not going to bother we're going hit next review and then hit create user all right and so now what it's doing is it's showing us the access ID and the access uh key secret that we can use to programmatically access AWS and then there's a password here so I'm going to go ahead and show it and what I'm going to do is just copy this into a clipboard anywhere and so I'm just copying that off screen here because I'm going to need it to log in and I'm just going to remember my username as well all right and so what we'll do is go ahead and hit close so what I'll do is go back to my dashboard here and remember I set my account Alias as Deep Space 9 but we could also use the account ID to log in I'm just going to grab my account ID off screen here and what I want to do now is go ahead and log out and now log into this I user and this is the one that you should always be using within your 's account you shouldn't be using your root user account so what I'll do is go over to I am user here and notice now that it says account ID so 12 digits or the account Alias so here I can enter in uh these numbers here or I can enter in my Alias which is Deep Space 9 and again you'll have to come up with your own creative uh one there for yourself and we'll go ahead and hit next and so notice what it's going to do is now ask me what my IM username is so I Define mine as Andrew Brown and then uh we had an autogenerated a password there so that we had saw and so I'm going to place that in there we'll go ahead and hit sign in and so now right away it's going to ask me to reset the password so I'm going to put the old password in there and so now I need a new password I strongly recommend that you generate out uh your passwords to be very strong I like to go to password generator and I'll drop this down and I'll do something really long like 48 characters and um if you don't like weird characters you can take those out there sometimes it loads here so you got to try it twice um and I'm going to go down to whoops 48 there we go and so that's pretty darn long so I'm going to copy that off screen here so I do not forget and you probably would want to put this in a password manager something like Dashlane or some sort of thing like that and we'll go ahead and we will paste that in and we'll see whoops I don't want uh Google to save it uh and we'll see if it takes it and so there we go so what I'll do is now log out and I'll make sure my new password works because you really don't want to have problems later so we'll type in Deep Space 9 Andrew Brown again this is going to be based on what your uh what you have set and we'll go ahead and log in and there I am and so now notice there doesn't say um exam Pro or whatever it says Andrew Brown at Deep Space 9 so it's using the county alias and showing the name and that's how I'm going to know whether I'm the root account user or whether I'm logged in as an I am user all right so there we go okay so now that we have the proper user account to log in I just want to point out uh about regions so in the top right corner you'll notice it says North Virginia here it possibly will say something completely else for you but what you'll do is you'll click and drop that down and you you'll see a big list of regions and so sometimes when I log in ads it likes to default me to U East uh Us East Ohio but I honestly like to launch all my stuff in Us East North Virginia even though I'm in Canada I probably should be using the Canada central region down here um but the default region is going to be based on your locality okay so just understand that it might be different I strongly recommend for um all of our follow alongs you run in Us East one because Us East one is the original um the original region and it also has the most access to Ada services and some Ada Services um such as like billing and and cost and things like that are only going to show up in Us East uh North Virginia so just to make our lives a lot easier we're going to set it there but I want you to understand that some services are Global Services meaning that it doesn't matter what region you're in it's going to default to Global and one example could be cloudfront so if I jump over to cloudfront here for a moment and uh we do seem to have uh some CLR distributions here from a prior uh follow along but notice up here that it now says Global so CLR does not require a region selection let's make our way over to S3 all right and this one's also Global so again this one does not require a region selection but if you go over to something like ec2 okay this has a a region dependency so just be really careful about that because a lot of times you'll be doing a follow along and you'll be like why aren't these resources here or whatever and it's because this got switched on you and it can happen at any time so just be uh cautious or aware of that okay so one of the major advantages of using ads or any cloud service provider is that it utilizes metered billing so that is different from a fixed cost where you'd say Okay I want a server for x amount of dollars every month but the way us works is that it's going to bill you on the hour on the second based on a bunch of factors and so you're going to be able to get services at a lower cost however if you choose an expensive service and you forget about it or there's misconfiguration where you thought you were launching something that was cost effective but turned out to be very expensive you could end up with a very large Bill very very quickly and so uh that is a major concern for a lot of people utilizing Cloud but there's a lot of great toolings built into adabs to allow you to catch yourself if you happen to make that mistake and before we go ahead and learn how to do that I want to show you uh some place where you could end up having excessive spend without knowing it so one example and this is actually happened to me when I first started using AWS uh before I even knew about all the billing tools is I wanted to launch a reddis instance and so you you just have to watch you don't have to do this but um elasticache is a service that allow you to launch either a mcash or reddis uh database and I just wanted to store a single value and so I went here and I scrolled down it looked all good and I hit create but I wasn't paying attention because apparently itus likes to default the no type here to the cash r6g dolar all right and you know you might think that Abus has your best interest in play and most services are pretty good they they make sure that they're either free or very low spend but some of these and elastic cash is an older service where they just have these weird defaults so um you know if we were to go look up this the RG6 uh large all right and look at it spend all right and we would go over here whoops I think I went to the China One but if we were to go over here and look for that instance I'm just trying to find it here for cost this one down below um this doesn't say pricing does it say our pricing here here it is so this one cost um this one costs about 2 cents per hour it doesn't sound like a lot but if we go here and we do the math we say 730 730 is the amount of hours in a month that is $150 okay so if you don't know about that and forget about that that's going to be $150 and I'm going to tell you that it used to be a lot higher I'm pretty sure they used to have it defaulted to something like like this or that because I remember I did this and I had a bill that came in that was like $3,000 USD and I'm in Canada so like $3,000 USD is like a million dollars up here and so I remember um it was a big concern and I freaked out but that was okay because all I had to do was go to support and what I had done is I went to the support center and I had opened a support case and I just said hey I had this really big bill so you go here right and you look for billing and uh you look for something like charging query or misspend and you say you know um you know like help my bill's too high and you just say like you explain the problem saying hey you know I was using elastic cash and it was set to a large default and I wasn't aware about it can you please give me back the money and the great thing is that ads is going to to give you a free pass if it's your first time where you've had a misspending they generally will say Okay um you know don't do it again and if it happens again you will get build but go ahead and learn how to set up building alerts or things like that okay so just so you know don't freak out if you do have a really high Bill you're going to get a single free pass but now that we know that let's go learn uh how to set up a budget okay all right so now that we've had a bit of a story about um over spend for misconfiguration let's learn how to protect ourselves against it and we're going to go ahead and set up a budget so go to the top here and type in budget and what that will do is bring us over to the billing dashboard another way to get here is to go click at the top here and go to my billing dashboard and then you'll see the leftand menu here and so the great thing about budgets is that the first two are free it says there is no additional charge for any those budgets you pay for configured us us Mage but I'm pretty sure that that's not true because it used to be ABS budget reports okay so that cost something it used to be that Abus budgets um after success enabled will Ur 10 cents daily so in addition to budget monitor you can add actions to your budgets the first two action enable budgets are free okay so just be aware that just because it says there's no additional charge read into it because sometimes the the Fine Line will tell you it does something but I know that the first two are free what we'll do is go ahead and create a budget just going to close these other tabs here since we have no need for them and we're going to be presented with a bunch of budget types uh we're considered about cost today so we're going to go with a cost budget and notice we can change the period from monthly to daily to quarterly to annually if you change it to daily um you won't get forecasting so I don't want that today but a monthly is pretty good you can have a reoccurring which is strongly recommended and then you can put a fixed cost notice that I already have some spend on this account so it was like 25 bucks last month I'm going to set my uh budget here to $100 and you can add filters here to um uh filter that cost out so if you want to say only for this region or things like that you could do that uh notice that this is my spend over here um so this is my budget and that's the actual cost notice my cost has been going up the last few months because I've been doing things with this account and so what I'll do is say simple budget here we'll hit next and so now it's asking us if we want to configure alerts we probably do so you'd hit ADD alert and then you'd set a threshold like 80% or you could say an absolute value and then You' put in your emails like Andrew exampro doco and I want to point out that this is using um itus SNS or it should be anyway so Amazon SNS has no upfront cost based on your stuff here so even though you're filling out an email you know and maybe it doesn't show it but I'm pretty sure that this would create an SNS topic but what we'll do is hit next here we have an alert so we're just uh reviewing actually this is for attaching any action so maybe we want some kind of followup thing to happen here so we say add action and uh requires specific I in permissions on your behalf okay sure so I guess you could follow up actions that's no different than um a building alarm but we're not really worried about that right now now I'm not going to bother with an action and we'll go ahead and create a budget and so here it's going to say that our budget is $100 it's going to show us the amount used forecast amount current budget sometimes this takes time to uh show up so I'm going to hit refresh and see if it shows up yet there we go so notice we have forecast amount $23 current budget Etc forecasted budget uh forecasted versus budget so it's pretty straightforward on how that works um I'm just curious if it actually created an SNS event so I'm going to go over here because a lot of services utilize SNS so if I go over here default Cloud watch alarm um so I think this is something I had created before so I'm going to go ahead and just delete it says default Cloud watch alarms I'm going to just click into here and see what I have confirmed so I think it might have used this when we created it but um the reason I'm bringing up SNS is that there's a lot of services that allow you to uh email yourself for alerts and it always integrates with this service and so I just want kind of want to point that out so that you remember what SNS is for um but yeah so setting up a budget is not too hard so there you go all right so now that we've set a budget what I want to talk to you about is the free tier and the free tier is something that available to you uh for the first 12 months of a new adus account and allows you to utilize adus services without incurring any cost to you and so it's in your advantage to utilize this free tier um as you are experimenting and learning cloud so if you want to learn about all the offerings what you do is go to Google type in adus free tier and you'll get this page that explains all the sorts of things here so you can get uh 750 hours on ec2 RDS things like that there are stipulations in terms of what it would be so here this is a T2 or T3 micel mic uh micro running Linux Red Hat um or other type of os's okay so there are uh details you have to read the fine print some services are only available for the first two months things like that so it's going to highly vary based on service but it's worth giving this a read in areas that you are interested in now the thing is is how do you know that you are still in the free tier or you go outside of it and that's what I want to talk to you about right now so I am actually in another adist account so notice in the top right corner it says brown. laap or hyphen laptop exampro doco sometimes I will switch into different AIS accounts during these follow alongs so I can best show you um you know the settings so if you make your way over to billing and actually I should show you up here if we go to my dealing B dashboard just trying to be consistent here and you go to the left hand side to billing preferences what you can do is enable receive free tier usage alerts and then put your email in there and save that and so turn on this feature to receive email alerts when your adus service usage is approaching or deleted data was free tier usage limits if you wish to receive these alerts etc etc etc right and while you're there I want you to also checkbox receive billing alerts so I can show you how to set a bing uh a billing alert and ITA says you know budgets are a new thing but billing alerts are still something that we use as of today so if you checkbox that on we'll be able to see your cost if we go back here uh it should show you um it's because I'm out of the free tier on this account but but it would show you in the alerts you know your usage there so example here is if we scroll down this is the documentation tracking your a free tier usage you would see like a box like this and would say hey your free tier usage limit is here and you're over it okay so that generally would show up on this panel here but again I'm outside of the free tier so I'm not seeing it here um today okay so you know hopefully that is clear um but yeah there you go all right so we created ourselves a budget we're monitoring our free tier but there's another way that we can monitor our spend and that is through building alerts or alarms and it is the old way before uh we had abis budgets this was the only way you could do it but I still recommend it because there is a bit more flexibility here with this service and so I wanted to teach you early on so that you know it's available to you or if you want to play around with it in the future so what you'll do is go to the top here and type in cloudwatch and cloudwatch is one of those Services where it's actually a collection of services so there's cloudwatch alarms cloudwatch logs cloudwatch metrics those are all Individual Services and aabus loves to update their interface so sometimes you'll be presented with this option to uh change the latest interface I'm going to try out the new interface here um and that is one challenge with datab is you always have to expect that they're going to change the UI on you and you're going have to work through it so just understand that I try to keep my videos up toate as best I can but part of the challenge is getting used to that so this is what they have today I don't know if they're going to stick with this but this is what it looks like but what I want you to do is make your way over to alarms on the left hand side and notice that we actually have a section just for billing which is interesting I don't remember them having that before so it's new so uh here it says it was cloudwatch help can help you monitor the charges of Bill remember that we had to turn that on get 10 free alarms with 1,000 free email notifications each month as part of the free tier so understand that if you create billing LS they do cost money um as well if you go over that limit but you sure get a lot 10 free alarms is quite a bit what we'll do is go ahead here and create ourselves alarm we are going to go and choose a metric and so here are the options we could choose from and so we I think would like um billing and see we can do buy service or total estimated charge we're going to do a total estimated charge we can only select USD I've never seen any other currency ever there and so here we kind of get this little graph where we can see stuff um but this is a lot more powerful than budgets because you can do anomaly detection uh so like here it will actually check base between a range as opposed to just going through a particular value but what I'll do is just set a value here like uh $50 right so notice that it sets the line up here and this is my current spend here right and so back to anomaly detection this is a lot smarter so so uh the idea is that if something is outside this band of a certain amounts um then it would alert okay but I'm going to go back here I'm just going to set this to $50 and that looks okay to me you can change the period 6 hours is fine um and there's additional configuration that's fine as well we're going to go ahead and hit next uh and so the idea is that um you know if it passes that red line it will go to an in alarm State and then what it will do is uh we want to uh have it to trigger an SNS topic so I would generally just create a new one here we'll just say my billing alarm Okay and then here we'll just set the email Andre exam pro. and we'll go ahead and create that topic and so that is now set I don't know if it would uh confirm it we might have to go to our email to confirm it so notice it says pending confirmation so what it has done is it sent me out an email and it wants me to click that link to confirm term um that I want to subscribe to it so I might just do that off screen to show you here okay so I'm just going to pull up my email here just give me a moment okay and so if I come back here this is the email that came in so I'm just going to confirm that subscription says I'm confirmed good and if I refresh this page we can now see that that that is confirmed all right so we'll scroll down here so we can uh trigger an auto scaling AC so maybe you know if you have too many servers you say hey the cost is too much shut down those servers there's ec2 actions things like that so these are kind of similar to um budgets right there's system manager actions I imagine all these things are available in budgets as well but budgets just makes it a little bit easier to look at so I'm going just say my simple building alarm here we'll hit next all right we'll hit create alarm and there you go so bilding alarms don't have like four forecasting and things like that um but you know they are they do have their own kind of special utility and so I utilize both okay so there we go we'll just go back to our Management console and move on to the next one so one of the strongest recommendations that adus gives you is to say to set MFA on your adus root user account so that's something we're going to do right now so make sure you're logged into the root user account so I'm going to go log out as my IM user I'm going to go back and log in and I'm going to log in as my uh root user here so to do that no sometimes it will be expanded as the I am user click and sign into root user here we'll have root user I'm going to go ahead and enter my email that I used and if you do switch accounts frequently they will ask you these silly captures which drive me crazy but uh you know it happens you probably won't encounter it as much as I do and so I'm going to go ahead and grab my password here and paste it on in and so now that I'm in what I want to do is make my way over to am and I'm going to go and look for users actually sorry just right here add an MFA root user we're going to go ahead and hit add MFA all right and so that's going to bring us to this screen and so here we can activate our MFA and so we have a few options here so we have virtual MFA device u2f security key other Hardware like a uh J galto token so you know I generally use this because I have a security key and I want to show you what I'm talking about so this is how I log into my machine or my ad account this is a security key an UB key that sits on my desk I tape it so it doesn't fall fall off the cord but the idea is that when I log in I have to press this little button here to double confirm before I get into my account uh but if you don't have a security key you can just use a virtual MFA and all that means is you're going to um use something on your phone to log in so we'll click continue here and so it says install a compatible app on your mobile phone or device and so if you click and open this what it will do is tell you about some things that you can use um so if we scroll down to Virtual here they suggest uh if you have Android iPhone so aie dual mobile last path Microsoft authenticator Google Authenticator so Google Authenticator Microsoft authenticator and a here I have all those three installed um honestly aie has the the nicest simplest um UI but I'm using Microsoft authentic authenticator quite a bit so anyway whichever you want to do it's fine but what we'll have to do is go back here and then it says use your virtual MFA app on your device camera to scan your QR code so once you have one of those apps installed like aie or whatever one you want what you're going to do is open up the application and I can't tell you exactly where it is but you'll have to hit add account in your in your app and then from there it will ask you to scan your QR code and so uh once you're ready you hit show The QR code you hit scan the QR code on your phone I'm holding my phone up to my my um uh my computer screen here and it's going to find it and I'm just going to take a moment here to rename the account so I can tell what it is so I'm just naming it a WS sandbox because that's what I call this account and I'm going to go ahead and save that and so now what I can do is enter uh two consecutive MFA codes now this always confuses me what they wanted here but the idea is that you're going to see one code right whatever is on the screen right now so I'm going to type in it it says 734 051 and I'm going to wait until the new code shows up so there's like a timer in all these apps and they go across the screen or they countdown and so you have to wait for that to happen and so I'm just going to wait here a little bit and once I get the new number here this one is 07153 0 I'm going to hit assign MFA and there we go and I can't tell you how many times I like mess that up because I didn't understand the consecutive numbers but you're just waiting for uh the number that's on the screen to entered in and then enter the next one in to turn on MFA and so now your account is protected and every time you log in you're going to have to enter in MFA so let's log out and see what that looks like so we'll go ahead and sign in and uh again we'll put in our root user account here we'll type in 74m 32t submit and I need to go grab my password so that's in my password manager just give me a moment here and now it wants the MFA code so this is in my phone and so I'm going to go enter it in so this one says 475 841 all right we'll hit submit okay and there we go so that's going to happen every single time we want to log in uh I'm going to tell you that if you get one of these they're so much easier to use because you just press the button okay so that's why I have this because I cannot stand entering the code in time and time again um but you know those are your options there okay hey this is Andrew Brown from exam Pro and we're looking at the concept of innovation waves so when we're talking about Innovation waves we're talking about contracta or k waves which are hypothesized cyclik phenomena in the global World economy and the phenomenon is closely connected with technology life cycles so here is an example where each wave is irreversibly changes the society on a global scale and if you look across the top we can kind of see what they're talking about so we have steam engine cotton uh rail way in steel electric engineering chemistry petrol chemicals automobiles information technology and so the idea is that uh Cloud technology is the latest wave and I'm not sure if you'd fit web 3 in there as well ml AI but maybe they're all part of the same wave or they're separate waves but generally they're broken up based on this prde here where it says perspective recession depression and movement uh Improvement sorry and so this is the common pattern of wave we see a change of supply and demand and so if we're seeing this we know that we are in a wave and where we are in a wave okay hey this is Andrew Brown from exam Pro and we are looking at the concept of a burning platform so burning platform is a term used when a company abandons old technology for new technology with the uncertainty of success and can be motivated by fear that the organization's future surv uh survival hinges on digital transformation and just to kind of give you visualization here is a Lal burning platform so imagine you have to jump to it jump from it to make a change so um you know burning platform could be you know stop using onprem and start using cloud or maybe it going from Cloud to web 3 um and that's generally the idea when we talk about a burning platform so I just want to quickly show you that digital transformation checklist that I mentioned and the way you can get to it is by typing in digital transformation AWS and so it should bring you to the public sector page and here it is so we click there and all it is is a PDF uh so it's not new it's from 2017 but that doesn't mean that it's not uh valid anymore uh it's just that that's when it was made so we scroll on down and we can see transforming vision and so we have a checklist there so if we click into this uh we can see things like communicate a vision of what success looks like Define a clear governance strategy including the framework of achieving goals uh build a cross functional team identify Tech technical uh Partners they talk about Shifting the culture and then down below I assume that this one is related to that one it's unusual because you know they just have a checklist here but then they have a sub checklist which must be clear to that so reorganize staff into smaller teams things like that so it's not super complicated you'll see each category go go Cloud native they'll have a checklist um you know and if you are at at the executive level or the sales level or trying to convince your VPS or stuff like that give this a it might give you something uh useful in the end uh to help better communicate that transformation for you okay hey this is Andrew Brown from exam Pro and we are looking at the evolution of computing power so what is computing power it's the throughput measured at which a computer complete computational tasks and so uh what we're pretty much used to right as of these days is general computing so a good example here would be a zeeon CPU processor that's more of a highend processor not something you'd find your home computer but when we're talking about data centers specifically uh um you know inabus data centers Zeon CPU processors or what you're going to come across uh then came along a new type of compute which is GPU Computing um when we're talking about Google uh Cloud they have tensor Computing and so this is where I get the 50 times faster based on that metric and so I didn't have an exact metric here for AWS uh um solution for this midtier of computing power so I just that 50 times there but the idea is that GPU Computing or tensor Computing uh is is 50 times faster than traditional CPU and generally that's going to be used for uh very specialized tasks when you're doing machine learning or AI so it's not something you're going to uh be doing for your regular uh web workloads but just understand that all of these uh fits so we're not getting rid of general computing we're just adding uh new levels to compute then there's the latest which is uh Quantum computing and so here we have an example of the rig retti 16q Aspen 4 and so it literally looks like it's out of um science fiction and this thing is like a 100 million times faster it is super Cutting Edge and we don't even know exactly how it works and there's not even anything that's very applicable that we can use this for but the idea is that we're not done with the evolution of of computing power things are going to get a lot faster once we solve this last one here and so ad service offering here would be for general computing you're looking elastic compute Cloud You2 so we have a variety of different uh instance types and they're all going to have different types of Hardware with different types of general computing um for GPU Computing this is a specialized chip that adus has produced called the adus um and I don't know how to say it but we'll just abbreviate it to infer so adus infer chip um and this was designed as a direct competitor to uh gcps uh tensor computing uh unit the T TPU um and so this is intended for AI ml workloads but it works with not just um tensor flow but it works with any machine learning framework so that is one advantage it has over uh tpus um and then the last one here is adus bracket so you can actually use quantum Computing as a service on adus you uh as of even today um the way adus is able to do this is they work with Caltech so that's the California technology um University or Institute I'm sure the name of it there um so it's not exactly adus producing this but adus is doing this as a partnership to give Quantum Computing accessible to you okay so I'm here in the Abus console because I just want to prove to you that you can use quantum Computing on AWS it's that accessible so all you'd have to do is go to the top here type in bracket uh and then you make it over to Amazon bracket and so here uh you can like set up Quantum tasks the first time you set it up you got to go through this process here um and I think I have to go through this onboarding to be able to show you the next steps so I'm going to go ahead and enable bracket in this Abus account okay and I'm not going to launch anything I'm just going to try just kind of show you a little bit of what is accessible to you because it's not super exciting but the fact that you can do it is kind of interesting so here I am on the inside here and we have all these different types of quantum Computing so dwave I know I I NQ retti things like that and then down below these are the quantum processing units the qpu and then down below you have the simulator so you can kind of simulate uh these things here um so I think that's kind of interesting uh but in terms of the cost like if you scroll on down here um so AB bracket is part of the was free tier it gives you one free hour of quantum circuit simulation time per month during the first 12 months so it's free to do uh a circuit simulation but if you actually want to run it on the actual Hardware you can see the cost there's the per task price the per shot price things like that uh what could you do with this I don't know there's things called like quad bits or something like that and I can't imagine that you're going to be doing anything useful but I think it's just more so like you are sending out quad bits or whatever they are and you're observing them um but what you could do with them I have no idea but it's just exciting that you can do that I didn't have any spend just by activating that I'm just kind of just showing you there okay hey this is Andrew Brown from exam Pro and we are looking at the benefits of cloud and this is a summary of reasons why an organization would uh consider adopting or migrating to utilizing public cloud and so we'll quickly go through the list here uh because in the followup slides we actually go into them a bit more detailed so we have agility page a go economy of scale Global reach security reliability High availability scalability um um and elasticity so the thing is is that eight of us had this before it was called the six advantages of cloud but they have reworked it to include additional items um and so where you see these uh sub bullets here those are the original six as you see 1 2 3 4 five six and so I kind of just put them where they kind of uh fall under the new categories there and you'll notice that aist has included High availability elasticity reliability and security as uh new ones here okay and so the thing is is that um I have always always even in my original uh I think in my original cloud practitioner had Cloud architecture as a separate section and included all these things in here so it's a great thing to see that abis has included it um but in terms of how I organized this course we're not going to cover them in this section because I have the cloud architecture section so just understand that we will come to those eventually and I would just say that adus is still missing something on this list which is fault tolerance so you know my list looks like this except I would add fault tolerance to it so you have everything there um and Disaster Recovery okay so the benefits of cloud is a reworking expansion of the six advantages of the cloud and we will look at the original six advantages um and then look at another one that is more of a generalized one that I I've used across my courses so that we fully understand the benefits okay all right let's take a look here at these six advantages to Cloud defined by AWS and so these are still uh part of aws's marketing Pages um but you know it's interesting because you can't find the benefits of the cloud in a single page on any at least at the time of making this so there's a bit of Disconnect between the um exam guide and the actual marketing material but that's okay I fill it all in for you so you know I'm just again noting that the six advantage of cloud was the original description for cloud benefits and we'll go through them okay so the first is trade Capital expense for variable variable expense so you can pay on demand meaning that there is no upfront cost and you pay for only what you consume or you pay by the hour minutes or second so instead of paying for upfront costs of data centers and servers the next is benefit from uh massive Eon uh uh economies of scale so you are sharing the cost with other customers to get unbeatable savings hundreds of thousands of customers utilizing a fraction of a server stop guessing capacity so scale up or down to meet the current needs launch and Destroy Services whenever so instead of of paying for idle or underutilized servers we have increased Speed and Agility so launch resources within a few clicks and minutes instead of waiting days or weeks of your it to implement the solution on premise we have stopped spending money on running and maintaining data centers so focus on your customers developing and configuring applications so instead of operations such as racking stacking and powering servers the last is Go Global in minutes so deploy your app in multiple regions around the world with a few clicks provide load latency and a better experience for your customers at minimal cost the six advantage of cloud still apply and um I like to include them here because they just have a different kind of a lens or or or angle when you're looking at this stuff and so we've looked at the six advantages of cloud and now let's take a look at the next slide my reworking of the six advantage of the cloud to be more generalized okay all right I just wanted to show you where that six advantages of cloud computing comes from it's part of IIs documentation so I typed it in here and you can see that it is still around uh and so it's unusual because this used to be part of the marketing website it had those nice little Graphics um but for whatever reason it's over here now in the overview of Amazon web services and by the way if you're starting starting out with ads this is a very light read but it is a good read uh to get started with we obviously cover all this stuff in the course um but you know maybe you'll get something different here but the idea is that IUS has definitely expanded on this but for whatever reason this documentation hasn't changed so just understand that I've polyfilled that for you in this course okay all right so this is the seven advantages to Cloud I said six but I meant to say seven and so um you know since I've created fundamental courses for all the clouds providers I started to notice kind of a trend and so what I did is I normalized it into my own seven advantages and this actually Maps up really well to the new benefits of the cloud so it looks like itus was thinking the same as I was um with the exception of those Cloud architect stuff which I keep in a separate section but let's go through it and see what is here so the first is cost effective you pay for what you consume no upfront cost on demand pricing so pay as you go PA YG with thousands of customers sharing the on uh sharing the cost of resources adus used to refer to this always as on demand pricing and Azure always said pay as you go and so it looks like adus now uses both on demand and page you go to describe them which is great um but there you go then we have Global so launch workloads anywhere in the world just choose a region it's secure so cloud provider takes care of physical security cloud services can be secured by default or you have the ability to configure access down to a granular level uh it's reliable so data backup Disaster Recovery data replication fault tolerance it's scalable increase or decrease resources and services based on demand uh elastic so automate scaling during spikes and drop in demand current so the underlying hardware and and managed uh software is patched upgraded and replaced by the cloud provider without interruption to you so I think this is one that isn't on the benefits of the cloud which is a really good one um but uh yeah that's the seven hey this is Angie Brown and we're taking a look at adus Global infrastructure so what is it well the adus global infrastructure is a globally distributed hardware and data centers that are physically networked together to act as one large resource for the end customers so what does that mean well if you look at the globe on the right hand side and that Globe is really cool because adab us used to have a website where you could uh see a 3D uh globe and see where all their resources are for whatever reason they took it down but I still have the screenshot of it but the idea is that um the global infrastructure represents all that hardware and the connectivity between that Hardware around the world so what kind of resources are we talking about we're talking about regions we're talking about availability zones direct connections uh pops also known as point of presence local zones wavelength zones uh and we should point out that Abus has millions of active users uh or customers and tens of thousands of Partners globally so they really are uh kind of everywhere um and if you're wondering well what are all these resources that's what we're going to get into next we're going to break down uh what all these particular resources are because you definitely need to know what they are but hopefully that gives you at a high level that adus has this thing called Global infrastructure okay hey this is Andrew Brown and we are on the marketing website for adabs under Global infrastructure and this is a great way if you want to explore more and make sense of that Global infrastructure so we scroll on down here we have a nice map and it's kind of indicating as to where those regions are notice that there is uh ones in red which are coming soon the Canada West they've been talking about that for I think a couple years now so still waiting for those but you know just like every CL provider they're always expanding looks like we can get a full list here um and it should indicate where uh when they launched and if they're launching more things so you know that is a nice little list uh that we can get access to but if we go all the way to the top across the top we can go to Regions and azs uh and this is where we should get better information this is definitely different from before and I don't think the top of candidate is supposed to look like that but uh I guess it's the best that they can do so uh what I want to point out on these pages is uh the terms of uh the number of resources so I'm just going to bump up the font because it's a little bit small even for me if we go on down below here you can see that it's describing um let's say a particular region so here in Canada we can see uh we have three availability zones and when it launched sometimes they have these Asters on here so it says located in the Montreal uh metropolian area so that's a good indicator because central Canada could mean Toronto could mean Winnipeg so that's why they put the asterisk on there um but just notice that what you'll usually see for availability zones you'll never see anything beyond six I'm not sure why but that seems to be the max usually when a region launches it should have three availab availability zones I think in the past there might have been some that did not have um at least three and the reason why it's important to have three in a zone is that is how we get high availability uh the way you do that is you should have um let's say we're talking about compute that compute should be um running redundantly into other data centers in your region to ensure um that you have up time in case the other two go out so just make note of that if you're coming from Azure Azure uh will launch things without having all of their uh zones uh gcp is really good where they'll always at least have three so uh each provider Works a little bit differently there um but yeah you can see here for North America we just scroll through here you can find your particular area and look at the map uh and wonder why it's so distorted but yeah hopefully that gives you kind of an idea there and if you want to explore any of these other uh particular offerings you absolutely can of course we do cover in the course so it's not really necessary to do that but I thought uh it'd be nice to show you this page okay ciao hey this is Andrew Brown from exam Pro and we are taking a look at a regions and regions are geographically distinct locations consisting of one or more availability Zone and so here is a world map showing you all the regions that AOS has in the world and the blue ones represent regions that are already available to you and the orange ones represent ones that adus is planning to open so adus is always expanding their infrastructure uh in the world so always expect there to be uh more upcoming ones every region is physically isolated from independent of every other region in terms of location Power and Water Supply and the most important region that you should give attention to Is Us East one uh in particular so this is Northern Virginia it was in's first region where we saw the launch of sqs and S3 uh and there are a lot of special use cases where things only work in Us East ones and we'll find that out here in a moment what I do want to show you is what it looks like for an architectural diagram when you are seeing a region so notice that we have this um uh little flag here it says Us East one US West one and inside of it we have an E2 instance so that is going to represent a region in our architectural diagrams uh but let's look at some of the facts here and under understand why Us East or Us East one is so important so each region generally has three availability zones and that is by intention and we will talk about that when we get to the availability Zone section some new users are limited to two or uh to two uh but generally there's always three okay new Services almost always become available first in Us East and specifically Us East one not all services are available in all regions all your billing information appears in us east1 so that's a US east1 particular thing uh the cost of AD services vary per region and so if you were on the marketing website or uh for Global infrastructure you can see uh here in North America they will say like when it launched how many availability zones and there might be some conditions so you'll notice there's like Aster uh beside these things here or um in this one particular there's an aster saying hey there are three zones but generally you're limited to two Okay when you choose a region there are four factors you need to consider uh what are the Regulatory Compliance does this region meet what is the cost of this Ina service in this region what Ina services are available in this region and what is the dist distance or latency to my end users and those are those four factors that you should remember okay all right so we just talked about adus regions now let's talk about uh how that affects our services versus regional and Global Services so Regional services are scoped based on what is set in the adus Management console on the selected region so you have this drop down and that's what you'll do you'll say Okay I want to have resources in Canada or in Europe uh so this will determine where an ad service will be launched and what will be seen within the ad Services console you generally don't explicitly set the region for a service at the time of creation I explicitly mentioned this because when you use something like gcp or Azure when you create the resource that's when you select the region but ads is it has this kind of global thing which is unique to their platform um then there's the concept of Global Services so some a Services operate across multiple regions and the region will be fixed to the word Global and for these that's services like S3 cloudfront R 53 I am so the idea is if you were to go over to cloudfront and go into the cloudfront console you'll notice that it will just say Global and you can't switch out of that uh for these Global Services um at the time of creation it's a bit different so we were saying up here for regional ones that you don't select the region but when you are clearing Global Services if you're using something like I there is no concept of region because they're just globally available so you don't have to determine a subset of regions if you're using S3 bucket that has to be in one region so you actually do have to select a region at time of creation um and then there's something like Cloud distributions where you were choosing a group of regions so you either say all of the world or only North America which is more like geographic distribution so you don't say the region in particular but you know hopefully that gives you a distinction between Regional services and Global Services hey this is Andrew Brown from exam Pro and we are taking a look at availability zones so availability zones commonly abbreviated as AZ and I'll frequently use be using the term AZ is physical locations made up of one or more data centers so a data center is a secured building that contains hundreds or thousands of computers uh and this is one of my favorite Graphics I like to show of course uh you know ads would never have a dog um in their data center but I just thought that would be fun a region will generally contain three availability zones and I say generally because there are some cases where we will see uh less than three so there might be two um data centers within a region will be isolated from each other um so there will be in different buildings but they will be close enough to provide low latency and that is within the uh 10 milliseconds or less so it's very very low uh it's common practice to run workloads in at least three azs to ensure Services remain available in case one or two data centers fail and this is known as high availability and this generally is driven based on Regulatory Compliance so a lot of companies uh you know they have to at least be running in three azs and that's why iTab us tries to always have at least three azs within a region uh azs are represented by a region code followed by a letter so here you know you'd have us east1 which would be the region and then the a would represent the particular availability Zone in that region um so a subnet which is related to a a ability zones is associated with uh two availability zones so you never choose an a when launching resources you always choose a subnet which is then Associated to an AZ a lot of services um you know don't even require you to choose a subnet because they're fully managed by AWS but in the case of like virtual machines you're always choosing a subnet okay so here is a graphical uh representation or a diagram that's representing two availability zones so here we have the region Us East one and Us West 2 and then we have our two azs so here is 1 a and one b and so these are effectively the subnets okay and so within those subnets then you can see or availability zones you will see that we have uh two virtual machines okay so the US east1 region has six azs and I thought that's just kind of like a fun fact because it is the most out of every single one um I don't think any one comes close to us East one but of course it is the most popular it is the uh first uh um region or so it's not a surprise that that one has that many a okay so we just covered regions and availability zones but I really want to make it clear uh what they look like so I kind of have a visual representation so let's say we have our adus region and in this particular one we have Canada Central which in particular is Montreal so CA Central one uh and the idea here is that a region has multiple availability zones so here you can see that we have uh 1 a 1 B and 1 D for some reason adus decided to uh not launch 1 C maybe it's haunted who knows you know um and then within your um availability zones they are made up of one or more data center so just understand that an a is not a single data center but could be a collection of buildings and that these azs um are interconnected with high bandwidth low latency networking they're fully redundant dedicated to metrof fiber providing High throughput latency networking between so just very fast Connections in between and all traffic between azs is encrypted and these azs are within 100 km so about 60 miles uh of each other okay so what I want to do here is just show you uh how regions and availability zones work with some different adus services so you have a general idea when you are selecting a region or a and when you're not so Within when you want to select a region you're going to go up here and change it and this is going to apply to Regional Services a very famous example of a regional service would be ec2 so we go over to ec2 which is elastic uh cloud computing or compute whatever always forget the name of it and what we can do is go over to instances I'm going to launch an instance I'm not going to complete the process I just want to show you what would happen when you go select some things here so I'm going to go with Amazon LX 2 um we're going to just go to uh next here and so here is where we're going to select um our availability zone so up here we have North Virginia that's our region and when I say we're selecting availability Zone we're actually selecting the subnet so so here we are choosing a subnet and a subnet is associated to a availability Zone and every single um region has a default VPC and that VPC has uh subnets set up and the subnets are defaulted to each of the availability zones available so us east1 has six of them so this server is going to launch in Us East 1B so this is a regional service okay uh then we have Global Services like S3 so we go over to S3 and it says it's Global right and so we're going to go ahead and create our bucket and so here we choose the region so we go down we're going to say the region we want to be in but we don't choose the availability Zone because there's nothing to um uh choose because adabs is going to run these in a multiple A's and it doesn't matter to you what it's doing there okay um so there's that and then there's something like cloudfront so cloudfronts a little bit uh different here so we go over to cloudfront and we create ourselves a distribution um and so yeah if if you don't have that option there because sometimes databus has like a splash screen just click on the left hand side then go to distributions okay okay and so here well they changed it again on me they're always changing this UI but if we scroll on down it should allow us to change um change where this is going to launch it's like Global stuff like that literally they just recently changed this and that's why I'm confused uh we'll scroll on down here it used to be maybe it's under Legacy additional customized oh it's here sorry okay so notice here the price class that says use the edge locations for best performance North America and Europe North America Europe Asia middle uh Middle East and Africa so we're not choosing a particular region we're picking a geographical area and so those are pretty much the major um uh uh examples of that uh then there's of course things like an IM am where you don't even say where it is so you go into IM am you know and if I create something like a group uh over here a user group whoops here I say create group you know I'm not saying oh this is for this particular region or something like that okay so yeah hopefully that makes sense hey this is Andrew Brown from exam Pro and let's take a look here at fault tolerance specifically for Global infrastructure and so before we jump into that let's just Define some fault terminology here so let's describe what a fault domain is so a fault domain is a section of a network that is vulnerable to damage if a critical device or system fails and the purpose of a fault domain is that if a failure occurs it will not Cascade outside that domain limiting the possible damage and so uh there's this very popular meme called This is fine where uh there's obviously a serious problem but uh the person's not freaking out and I gave it some context to say well the reason they're not freaking out because they know that is a fault domain and nothing outside of this room is going to be affected okay so you can have fault domains nested inside of other fault domains uh but generally they're grouped in something called fault level so a fault level is a collection of fault domains um and the scoping of a fault domain could be something like a specific specific servers in a rack an entire Rack in a data center an entire room in a data center the entire Data Center building and it's really up to the cloud service provider to define those boundaries of a domain adus abstracts it all way so you don't have to think about it but just to compare it against something else when you're using azure you actually Define your fault domain so you might say like okay uh make sure that this workload is never running on the same VM on the same rack for these things uh and you know you might like to have that level of control but I really like the fact that Abus just abstracts it away I'm not sure how they segment their uh their their fault domains but they they definitely are some broader ones which we'll describe right now so when we're looking at an abis region this would be considered a fault level and then within that fault level you would have your uh availability zones and these would be considered fault domains and of course those data centers can have uh fault domains within them okay like maybe you know they have everything in a particular room and that room is secure so like if there's a fire in that room it's not going to affect the other room things like that um so each Amazon region is designed to be completely isolated from the other Amazon region they uh they achieve this with the greatest possible fault tolerance and stability uh each availab availability zone is also isolated but the availability Zone in a region are connected through low latency links each availability zone is designed as an independent failure Zone and so here we have uh some kind of different language that adus is using um I've never experienced this terminology in other any other cloud service provider so I kind of feel like it's something that ad made up but basically a failure Zone they're just basically saying a fault domain but let's kind of expand on their fault uh failure Zone terminology so availability zones are physically separated within a typical Metropolitan region and are located in lower risk uh flood planes discreet uninterruptible power supply so UPS and an onsite backup uh generation facilities uh Data Centers located in different azs are uh designed to be supplied by independent substations to reduce the risk of an event on the power grid impacting more than one availability Zone availability zones are all redundantly connected to multiple tier one Transit providers and we'll talk about what those are uh in an upcoming slide and just one thing I want to note here is that when you adopt multiaz you get high availability so if an application is partitioned across A's companies are better isolated and protected from issues such as power outages lightning strikes tornadoes earthquakes and more so that's the idea behind you know why we want to run in multiaz okay because of these fault domains hey this is Andrew Brown from exam Pro and we're talking about the ad Global Network so the global Network represents interconnections between a global infrastructure and and it's commonly referred to as the backbone of AWS so is ec2 so just understand that that could be used in more than one way but think of it as a private Expressway where things can move fast between data centers and uh one thing that is utilized a lot to get data in and out of AWS very quickly is Edge locations they can act as on and off ramps uh to the AWS Global Network of course you can uh get to the network through pops which we'll talk about um you know in the upcoming slides here but let's just talk about Edge locations and what services use them so uh when we're talking about things that are getting on to the adus network we're looking at things like Abus Global accelerator adus S3 transfer acceleration and so uh these use agile locations as an onramp to quickly reach a resources in other regions by traversing the fast adus Global Network notice that the names in it say accelerator acceleration so the idea is that they are moving really fast okay on the other side when we talk about like an offramp we're looking at Amazon cloudfront which is a Content distribution Network this uses Edge locations to uh as an offramp to provide at the edge storage and compute near the end user uh and one other thing that is kind of always utilized in the global Network are VPC endpoints now these aren't using Edge locations but the idea here is that this ensures your resources stay within the Aus Network and do not Traverse over the public internet so you know if you have uh you know a resource running in Us East one and one in uh EU it would and they never have to go to the Internet it would make sense to always enforce it to stay within Theus Network cuz it's going to be a lot faster so there you go hey this is Andrew Brown from exam Pro and we are taking a look at point of presence also known as Pop and this is an intermediate location between an ads region and the end user and this location could be a data center or a collection of Hardware so for AWS a point of presence is a data center owned by AWS or trusted partner that is utilized by AWS Services related for content delivery or expediated upload so a pop resource could be something like an edge location or Regional Edge cache so as an example over here we see an S3 bucket and it has to go through Regional Edge cache and then get to an edge location let's go Define what those are so an edge location are data centers that hold cach copies on the most popular files so web pages images and videos so that the delivery of the distance to the end users are reduced then you have Regional Edge locations and these are data centers that hold much larger caches of less popular files to reduce a full round trip and also to reduce the cost of transfer fees so to kind of help put pops more in presence just in the general sense here is a diagram I got from Wikipedia that kind of just shows a bunch of different networks and notice where the pop is it's on the edge or the intersection of uh two networks so here you know we have um you know tier three and then this tier two and there's this pop that is in between them okay so tier one networks is a network that can reach every other network on the internet without purchasing IP transit or paying for peering and so the anabis availability zones or azs are all redundantly connected to multiple tier one Transit providers okay all right so let's take a look at somea services that are utilizing pops or Edge locations for Content delivery or expediated upload so Amazon on cloudfront is a Content delivery network service and the idea here is you point your website to cloudfront so that it will route requests to the nearest Edge location cache it's going to allow you to choose an origin so that could be a web server or storage that'll be the source of the cache and cach is the content of what origin would return to various Edge locations around the world then you have Amazon S3 transfer acceleration this allows you to generate a special URL that can be used by the end users to upload files to a nearby Edge location once a file is uploaded to an edge location it can move much faster within the adus network to reach S3 then at the end here you have adus Global accelerator you can find the optimal path from the end user to your web servers so Global accelerators are deployed within Edge location so you send user traffic to an edge location instead of directly to your web application this service is really really great for if let's say you are running a web server in Us East one and you just don't have the time uh to set up infrastructure in other regions you turn this on and you basically get a booster okay hey this is Andrew Brown from exam Pro and let's take a look at it was direct connect so this is a private or dedicated connection between your data center office collocation and AWS and so the idea here is imagine if you had a fiber optic cable running from your uh data center all the way to your ads so that it feels like uh when you're using your stuff on your data center like your local virtual machines that uh there's like next tendo latency okay so Direct Connect has two very fast network connection options we have the lower bandwidth which is at 50 to 500 megabytes per second and then you have the higher bandwidth which is 1 GB to 10 GB per second so using Direct Connect helps reduce Network cost increase bandwidth throughput so great for hight trffic networks provides a more consistent Network experience than a typical internet based connection so reliable and secure um I do want to point out the term collocation if you never heard of that before a collocation or a carrier hotel is a data center where equipment space and bandwidth are available for rental uh to retail customers and I do want to also point out that even though it says private up here and this is the language that AWS used I usually just say dedicated but the connection is private but that doesn't necessarily mean it's secure okay so uh we'll talk about that when we reach ads vpns and how we can use that with direct connect to make sure our connections are secure okay all right so let's take a look at what a direct connect location is so a direct connect location are trusted partner data centers that you can establish a dedicated highspeed low latency connection from your on premise to AWS so an example of a partner data center would be one like here in Toronto the Allied data center so you can tell that's right down in uh the Toronto Center and so you would use this uh uh as part of direct connect service to order and establish a connection okay hey this is Andrew Brown from exam Pro and we are taking a look at local zones which are Data Centers located very close to densely populated areas to provide singledigit millisecond low latency performance so think like 7even milliseconds for that area so here is a map of uh local zones that exist and ones that are coming out I believe the orange ones are probably ones that are on their way and so to use a local Zone you do need to opt in so you got to go talk to AWS probably open a support ticket to get access to it the first one to ever be launched was uh the LA one uh and so um you know when you want to see it it looks just like a an availability Zone it's going to show up under whatever region that is because these are always tied to existing regions so the la1 is tied to us West uh region and the a would look like us West 2 hyphen LAX hyphen 1 a okay so only specific AA Services have been made available so there's particular ec2 types EBS Amazon FSX application load balancer Amon VPC they probably have extended it to more services do you need to know that for the exam no but you know the point is is that there's a limited subset of things that are available the purpose of local zone is to support highly demanding applications sensitive delcy so media and entertainment electronic design and automation adte machine learning so it kind of makes sense like you look at La they're in the media entertainment and so they're dealing with lots of media content so it has to be really low for them okay hey this is Andrew Brown from exam Pro and we are taking a look at Abus wavelength zones and these allow for Edge Computing on the 5G networks and applications will have ultra low latency being as close as possible to the users so Abus has partnered with various telecom companies to utilize their 5G networks so we're looking at Verizon vone kddi SK Telecom and so the idea here is that you will create a subnet tied to a wavelength Zone and then and just think of it as an availability Zone but it's a wavelength Zone and then you can launch your VMS to the edge of the targeted 5G Network so that's the network you're using uh AWS to uh deploy an ec2 instance and then when users uh connect to you know those radio tower those um the cell towers they're going to be routed to um you know nearby hardware that is running those virtual machines okay and that's all it is it's just it's just uh ec2 instances um but you know the advantage here is that it's like super super low Lane SE okay hey this is Andrew Brown from exam Pro and we are taking a look at data residency so this is the physical or geographical location of where an organization or Cloud resources reside and then you have the concept of comp uh compliance boundaries so a Regulatory Compliance so legal requirement by government or organization that describes where data and Cloud resources are allowed to reside and then you have the idea of data sovereignty so data sovereignty is the jurisdictional control or legal Authority that can be asserted over data because its physical location is within a uh jurisdictional boundary and so the reason we care about this stuff is that if we want to work with the Canadian government or the US government and they're like hey you got to make sure that you know if you want to work with us all the data has to stay in Canada and you need to give them that guarantee so data residency is not a guarantee it just says where your data is right and compliance boundaries are those U controls that are in place to say okay this this is going to make sure that data stays where we want to be and data of sovereignty is just like the idea of the scope of the the legal the legal stuff that ties in with compliance boundaries so how do we do that on AWS well there's a few different ways but um let's just take a look at some ways that we can meet those compliance boundaries one uh which is very expensive but also very cool is adus outposts so this is a physical rack of servers that you can put in your data center and you'll know exactly where the data resides because you know it's physical if it's in your data center and you're in Canada that's where it's going to be okay uh and I believe that you know there is only a subset of adus services that are available here but you know that is one option to you another is using like um services for governance so like one could be adus config this is a policy as a code service so you can create rules to continuously check adus resource configuration so if they deviate from your expectations you're alerted Oris config can in some cases Auto remediate so if you were expecting you know um you know you had an account and you're saying this account is only to be used for candid resources and somebody launches let's say something in another region then you could get an alert or tell it was config to go delete that resource okay now if you want to prevent people from doing it uh Al together that's where IM am policies come into play so these can be written explicitly to deny access to specific adus regions and you know this is great if you're applying it to users or roles but if you wanted to have it organizational wide across all of your um your a accounts you can use something called a service control policy that is just an IM am policy that is used within it organizations that makes it organizational wide okay hey this is Andrew Brown from exam Pro and we are looking at 8s for government so to answer that we first have to understand what is public sector so public sector includes public goods and government services such as military law enforcement infrastructure public transit public education Healthcare and the government itself so AOS can be utilized by the public sector or organizations developing Cloud workloads for the public sector and a achiev this by meeting Regulatory Compliance programs along with specific governance and security controls so this could be meeting the requirements with HIPPA fedramp um cjis and fips okay so abis has a special regions or special regions for us regulation called gov Cloud which we'll talk about next okay hey this is Andrew Brown from exam Pro and we are taking a look at govcloud and to understand what govcloud is we need to know what fedramp is so fedramp stands for federal risk and authorization Management program it's a US governmentwide program that provides a standardized approach to security assessment authorization continuous monitoring for cloud products and services so now that we know what fed ramp is what is gocloud well uh and again it's not particular to AWS because Azure has gocloud as well but a cloud service provider like ad or Azure J will offer an isolated region to run fed ramp workloads and so in ads it's called govcloud and these are specialized regions that allow customers to host sensitive controlled unclassified information and other types of regulated workloads so govcloud regions are only operated by you uh by US citizens on us soil they are only accessible to us entries and root account holders who pass a screening process customers can architect secure Cloud solutions that comply with fed ramp uh do the doj's uh criminal justice Information Systems uh security policy the US International traffic and arms regulation uh uh export Administration regulations the Department of Defense cloud computing security requirements and guides so if you want to work with the US government you want to uh engineer and use govcloud okay hey this is Andrew from exam Pro and we're taking a look at uh running adus in China so adus China is the adus cloud offering in mainland China adus China is completely isolate intentionally from adus Global to meet Regulatory Compliance for mainland China so that means that if you make a workload on the adus global uh you can't uh interact with it within the ads China One okay it's basically treated like a a completely separate service like ads has its own Chinese version uh and so ad China is on its own domain at Amazon ads. CN and for everybody else that's what's considered AB Global so when I'm using adabs from Canada or use it from the US or from India or from Europe or wherever that is the adus global okay so in order to operate in adus China regions you need to have a Chinese business license so ICP license not all services are available in China so uh you will not have the use of Route 53 uh and you might say well why not just run in Singapore ored was Global and you could do that but the advantage of running in mainland China means that you would not have to Traverse the great firewall okay so all your traffic is already within China so you don't have to uh deal with that Abus has two regions in mainland China so uh there's this one here which is the northwest region operated by NS WCF and then you have the one in Beijing North one operated by uh sinnet so you know itus just could not meet the the compliance requirement so they had to partner with local providers or data centers and so that is how that works okay all right so I want to show you how you get over to the um Chinese adus Management console so this one is adab. amazon.com that is the global one for everyone outside of mainland China but if you want to run resources uh on data centers within mainland China this is at amazon.cn and so it looks very similar if you go to create a free account you're going to fill in this stuff but uh notice that you need to have your business registration certificate uh and additional information in order to run these data centers down below that AWS has partnered with also notice that the logo doesn't say AWS in it and there's a good reason for that if I type in adus trademark China uh adus is actually banned from using the adus logo in China uh for whatever reason it's a weird reason if you ever want to read about it but that's why you don't see AWS here all right um so yeah there you go hey this is Andrew Brown from exam Pro and we are looking at sustainability for adus Global infrastructure and before we talk about that let's talk about the climate pledge so Amazon cofounded the climate pledge to achieve Net Zero carbon emissions by 2040 across all of Amazon's businesses which includes AWS if youall want to find out more information go to to sustainability. amazon.com there's a a lot of great information there and you'll learn exactly how uh ads is achieving this in particular like their data centers it's very interesting okay so adus Cloud sustainab goals are composed of three parts the first is renewable energy so adus is working towards having their adus Global infrastructure powered by 100% renewable energy by 2025 and AAS purchases and retires environmental attributes to cover the nonrenewable energy for AIS Global infrastructure so they would purchase things like renewable energy credits also known as Rec's guarantees of origin so Go's the second Point here is cloud efficiency so adus infrastructure is 3.6 times more energy efficient than the medium of us Enterprises data centers surveyed so that's going to really rely on that survey surveys are not always that great so you know take that with a grain of salt okay then we have water uh stewardship so uh direct evaporative technology to cool our data centers use of non portable uh water for cooling purposes so they're recycling water onsite water treatment allows us to remove us them to remove scale forming minerals and reuse Waters uh for more Cycles water efficiency metrics to determine and monitor optimal water use for each aabus region and you'll find that water plays a large part on uh making these um uh these data centers very efficient okay so I just wanted to show you where you get to that sustainability information so I just went to itus Global infrastructure you click sustainability and that's going to bring us over to whoops I have my Twitter open there to the sustainability in the cloud so if you want to uh read a bunch of stuff here about things that are going on that itus is up to see uh how they are progressing with renewable energy um there's Cloud efficiency up here so you know how are they being efficient it's worth the read to really understand that there's a lot of water involved like reducing water in data centers I thought that was really interesting um I mean they have theis podcast but I don't think there's really much to it a biweekly podcast of bite side stories about how Tech makes the world better that's not necessarily A sustainability podcast it's just the invis podcast in general there's a download Center um Amazon's 2020 sustainability reports so I guess you can download the reports to see what is going on there so we could download the progress here and see what they've been up to okay so there's a bunch of numbers things like that okay very short reports but hey at least you can download them okay so just in case you're uh very interested in sustainability all right hey this is Andrew Brown from exam Pro and we are taking a look at Abus ground station so this is a fully managed service that lets you control satellite Communications process data and scale your operations without having to worry about building or managing your own ground station infrastructure and so when we're talking about ground station a really good way to cement what the service is is just think of a big anten 10 ey dish that's pointing into the sky trying to communicate with satellites because that's essentially what the service is doing so the use cases here could be for weather forecasting surface Imaging communications video broadcasts and to use ground station the idea is that you would schedule a contact so that's where you're selecting a satellite a start and end time and the ground location and then you use an a ground station ec2 Ami and Amazon machine image to launch e two instances that will Uplink and downlink uh data during the contact or receive downlink data in an Amazon S3 bucket a use case could be something like you are a company you've reached an agreement with a satellite image provider to use their satellites to take photos for a specific region or time or whatever and so the idea is that you are using adus ground station to communicate uh to that company satellite and download that s uh that image data to your S3 bucket okay hey this is Andrew Brown and we are looking at Aus outposts and this is a fully managed service that offers the same aess infrastructure Services apis tools to virtually any data center cocation space or on premise facility for a truly consistent hybrid experience and just to kind of summarize it it's a rack of servers running adaba stuff on your physical location okay so before we jump into the service or technology itself uh let's talk about what is a rack server or just a rack so it's a frame designed to hold and organize it equipment so here's an example of a 42 U rack uh and there's the concept of rack heights so the U stands for rack units or U spaces uh with it equal to 1.75 in and the industry standard rack is a 48 U um so that is a 7 foot rack so a full size rack cage is commonly the 4 to High okay and uh in it you might have equipment that is of different sizes so there could be one u 2 U 3 U or 4 U high so here's an example of you know of an interior of a rack and notice that like one u 2 U 4 U they're all a little bit shaped differently uh but they give you kind of an idea of um you know what those are so it Outpost comes in three form factors the four2 U the one U and the 2 U so the the first one here the 42 U this is basic basically a full rack of servers provided by adus so you're not just getting the frame it actually comes with you know servers uh and so adus delivers it to your Preferred Physical site fully assembled and ready to be rolled into the final position it is installed by adus and the rack needs to be simply plugged in to the power and network and there's a lot of details about um the specs on this on the adus website so you know I'm not going to go through them all here um then there are servers that you can just Place into your existing racks so we have the oneu so this is suitable for 19 in wide 24 in deep cabinets it's using Idis uh Gravitron 2 um CPUs and you can have up to 64 uh virtual CPUs we have 128 gabt uh 4 terabytes of local NVM storage um and then you have the U or sorry the 2 U so suitable for 19in wide 36 in deep Intel processors up to 128 virtual CPUs 256 GB of memory 8 tab of local nvme storage so there you go let's take a look at Cloud architecture terminologies before we do let's talk about some of the roles that are around uh doing Cloud architecture so the first is Solutions architect this is a role in a technical organization that Architects a technical solution using multiple systems via researching documentation and experimentation and then you have the cloud architect this is a Solutions architect that is focused solely on architecting Technical Solutions using cloud services understand that in the uh actual Marketplace a lot of times Solutions architect is used to describe both a cloud architect and a Solutions architect and you know these are going to highly vary based on your locality and how companies want to use these terms but this is just me broadly defining them here so just don't take them as a perfect word in terms of what they're representing so a cloud architect needs to understand the following terms and factors uh and Factor them into their designed architect based on the business requirements so we have the idea of availability your ability to ensure service remains available scalability your ability to grow rapidly or unimpeded elasticity your ability to shrink and grow to meet the demand fault tolerance your ability to prevent a failure Disaster Recovery your ability to recover from a failure and there are a couple other things that uh that should be considered they're not terminologies but they're definitely important to a Solutions architect or Cloud architect and uh these are things you always need to consider uh as as well and this is just me talking to my Solutions architect friends where they'll always ask me these two questions after presentation they'll say how secure is the solution and how much is this going to cost all right and so for the terminologies up here we're going to Define these right away and we're going to figure these out throughout the course we have two giant sections just on cost and security alone uh so there we go the first term we're looking at is high availability and this is your ability for your service to remain available by ensuring there is no single point of failure and or you ensure a certain level of performance so the way we're going to do that on ews is you'd want to run your workload across multiple availability zones to ensure that if one or two availability zones became unavailable your servers or applications remain available because those other um those other servers are going to be there and the way we would accomplish that is via elastic load balancer so a load balancer allows you to evenly distribute traffic to multiple servers in one or more data center if a data center or server becomes unavailable or unhealthy the load bouncer will route the traffic to only the available data centers within the server and understand that just because you have additional servers doesn't mean that you are uh you're available you have to you might need to meet a particular threshold of availability so you might need to have at least two servers always running to meet the demand so it's based on the the demand of traffic okay let's take a look here at high scalability so this is your ability to increase your capacity based on the increasing demand of traffic memory and computing power and we have the terms vertical scaling so scaling up um this is where you upgrade to a bigger server and then there's horizontal scaling scaling out this is where you add more servers of the same size and the great thing about scaling out or adding additional servers is that you're also going to get um High availability so if you do need two servers it's always better to you know add an additional server as opposed to having a larger server but it's going to be very dependent on a lot of factors okay so scalability and elasticity seem very similar but there is a crucial difference and this is your ability to automatically increase or decrease Your Capacity based on the current demand of traffic memory and computing power again it's the it's the fact that it happens automatically and you can go both ways increase or decrease so for horizontal scaling we have the concept of scaling out so add more servers of the same size and then scaling in removing underutilized servers of the same size and vertical scaling is generally hard for traditional architectures so you'll usually only see horizontal scaling described with elasticity um and the way we would accomplish uh being highly elastic is using autoscaling groups asgs and this is aabus feature that will automatically add or remove servers based on scaling rules you define based on those metrics okay let's talk about being highly fault tolerant so this is your ability for your service to ensure there is no single point of failure preventing the chance of failure and the way we could do that is with fail overs so this is when you have a plan to shift traffic to a redundant system in case the primary system fails a very common example is having a copy or secondary uh uh uh of your database where all ongoing changes are synced the secondary system is not in use until a fail over occurs and it becomes the primary database so when we're talking about databases on ABS this is the concept of RDS multiaz so this is when you run a duplicate standby database in another availability Zone in the case your primary database fails and last here is high durability so this is your ability to recover from a disaster and to prevent the loss of data so solutions that recover a disaster uh from a disaster is known as disaster recovery so do you have a backup how fast can you restore the backup does your backup still work how do you ensure current live data is not corrupt and so maybe a solution ads would be using Cloud endurer which is a disaster recovery uh service which continuously replicates your machines in a lowcost staging area in your target AB account and preferred region enabling fast and reliable recovery in the case of an IT data center fails okay so to understand Disaster Recovery we need to know more about uh things around it like business continuity plans BCPS and RTO and rpos so uh a BCP is a document that outlines how a business will continue operating during an unplanned disruption in services so it's basically the plan that you're going to execute uh if that happens and so here we have a disaster and you can see that there's a chance of data loss and downtime and these two um uh factors as RPO and RTO are going to define the length of these durations so recovery Point objective is the maximum acceptable amount of data loss after an unplanned data loss incident Express this amount of time so how much data are you willing to lose and then recovery time objective so the maximum amount of downtime your business can tolerate without inuring a significant financial loss so how much time you're willing to go down okay so those are the two there and now let's go take a look at the disaster recovery options that we can use to define in our our BCP so now let's take a look at our disaster recovery options uh and based on what you choose they're going to be a trade of cost versus time to recover based on the rpos your RTO of course and so sometimes this is rep represented vertically like a a thermostat or you can do it horizontally here um both are valid ways of displaying this information but I just have it horizontally here today and so we have low or high or you could say um even though I don't have it written here this could be cold or this could be hot okay so um on the left hand side we got backup and restore pilot light warm standby multiactive sight notice we're using the like the words like pilot light warm things that are relating to temperature so again cold and hot all right so let's just walk through what each of these things conceptually do uh in terms of architecture so when you're doing a backup and restore you're back you basically back up your data and uh at the time of Disaster Recovery you're just going to restore it to New infrastructure uh for a pilot light the data is replicated to another region with the minimal Services running to keep on replicating that data and so you might have some core Services running a warm standby is a scale down copy of your infrastructure so you basically have everything that you would absolutely need to run an application but the idea is it's not at scale and so at any time when there's an incident you're going to scale up to the capacity that you need and then you have multi sight active active where you you have a scaled up copy of your infrastructure in another region so basically everything you have identically in another region and so in terms of the rpos and the RTO for back and restore you're looking at hours uh with the pilot light you're looking at 10 minutes with a warm standby you're looking at minutes and multi sight uh active active you're looking at uh real time so you know hopefully that gives you an idea of you know the difference in terms of scale but let's just look at more detail so for a backup and restore this is for low priority use cases restore data after event deploy resources after an event and it's very cost effective uh for light this is where you have less stringent RTO and rpos so you're going to be just running your core Services uh you're going to start and scale resources after the event and this is a little bit more expensive this is uh very good for warm standby is good for business critical services so you scale resources after the event uh and it's uh almost very it's very it's costly but it's not as expensive as a multisite active active so you get zero downtime near zero loss uh you have it's great for mission critical services and it's just as expensive as your original infrastructure so you're basically doubling the cost there okay so we already defined RTO but let's redefine it again based on what adus describes in their white paper and just look at how it Maps against um the disaster recovery option so re recovery time objective is the maximum acceptable delay between the interruption of service and restoration of service this objective determines the what is considered an acceptable time window when service is unavailable and is defined by the organization and so this is the diagram found in the white paper and so on the left hand side we have cost and complexity here and then lengths of serice interruption and what you can see here is that the cost and complexity for a multisite active active is very high but the length of service Interruption is zero and then as we go down we have warm standby so it's significantly like at least half uh the complexity of that one then we have our pilot light down here and backup and restore but notice backup restore takes the longest amount of time and notice here we have a recovery time objective so in your BCP you kind of Define where that is based on the cost of business impact so you might have to calculate that saying okay what is our cost over time based on the length of service Interruption where do we want our RTO to be what is the acceptable recovery cost and this is where you're going to decide what you want to do so here we have pilot light and backup and restore and so this company you has to decide whether they want to do a pilot light or they're going to do a backup restore but it sounds like this is where they're going to be which is at the pilot uh light for what is acceptable in their business use case okay let's do the same for RPO so recovery Point objective is the maximum acceptable amount of time since the last data recovery point the objective determines what is considered an acceptable loss of data between the last recovery point and the interruption of service and it's defined by the organization again we pulled this from the a white paper for disaster recovery and uh we have cost and complexity but this time it's replaced with data loss before service Interruption so uh for multisite again it's going to be very expensive and high up here as you noticed it's not like a perfect um uh curve it's just it's a bit different in terms of what it looks like so here we have warm St standby pilot light um and so you'll see that the data loss is um not a big deal but for back up from store it really juts out there so you can see that you can get pretty good results just with the pilot light and the cost and complexity is very low again we have to look at our cost and business impact so we got to follow that line and we need to see where our acceptable uh recovery cost is and so uh you're going to notice that uh we have a bit of an intersection here okay and so we need to determine you know like are we going to be doing a warm standby looks like we have the cost to do it um uh but you know it just really depends you know do we want to be down here or down there okay so hopefully that helps and visualize that information for you hey this is Andrew Brown from exam Pro and what I want to show you here is a real world architectural diagram I created this a while ago this is a previous version of the um exam Pro or technically teacher seat platform uh that powers The Learning Experience uh for by class certifications and so I'm hoping that by giving you some exposure you'll absorb some information here uh and that will carry through to really help you cement what these services do and how they work together now you might be asking how did I make this well I'm in Adobe XD it's by Photoshop or sorry Adobe it's free to download but there's a lot of options out there and but the first thing you'll need is those Aus architectural icons so these are free on AWS you can download them in PowerPoint download them as asset as svgs and pgs which is what I have done and start using them in your um uh whatever software you like there's also third party providers out there so like there's Lucid charts I love lucid the charts but I don't use it to make architectural diagrams uh for AWS um but you know you can drag drop and stuff and they already have the library there and there's a bunch of them that you can choose from so uh you know that's interesting but let's take a look at one that we can download maybe everyone's familiar with PowerPoint so here is the adus architectural icons and the reason I'm showing you this is not because it just contains icons but it also suggests how you should build them so if I go through here they'll give you a definition of those system elements uh how they would look like here so we have our group icons or layer group our service icons resource icons where they should go uh and then they have some interesting guidelines of like dos and don'ts so here's like a simple example of a get to an S3 bucket um here's an example of using VPC subnets and things like that on the inside um and then you can see kind of like all the groups that we have and it show all like the uh the um arrows it's a big faux PA to make U diagonal arrows that's just something it us Define but you'll see a lot of people do them anyway and then you'll see all the icons so do you have to make them like ad suggests no but you know if you like the way they look that is fine everyone just does whatever they want honestly so anyway now that we've seen you know how we can go get the resources to make our own I have Adobe XD open up here and so I just kind of want to walk you through what's going on here so again I said this is a a traditional um architecture meaning that it's powered by virtual machines and so what we need to look for uh is ec2 because that's where it's going to start that's our virtual machine and you'll notice we have one here so there's a T2 um uh that's running over here and then over here we have a T2 okay so uh we have a blue and a green environment so this is our running environment so I'm just going to zoom on in here okay so the web app would be running on this and um and then on the outside here we have an autoscaling group and so autoscaling groups allow us to um manage a group of vc2 instances and they will automatically scale if the demand increases or or or declin so if this machine can't handle it it will just automatically provision a new one and so I've contained it in this environment here because I'm representing a blue green deploy meaning that when I deploy this will get this will be the environment that replaces things and so you can see I have a lot of lines being drawn around here so um over here we have uh um parameter store so parameter store is a place where we can store our environment variable um or application configuration variables and so I have this line going here and it's just saying we're going to take these environment variables and put them into the application okay uh and then there's also uh the database credential so here we are using postgress over here so and then we need the database credentials so we're grabbing those database credentials those are stored in Secrets manager and we're giving to the application so the app knows how to connect to the database and this one knows how to uh configure it okay then we have um a bunch of uh buckets here for different organizations and so you know S3 is for storage so this is a way we're going to um store a variety of things so like user data assets artifacts Cloud information templates so some of this is for the app some of them is for the infrastructure so that's one thing there okay then over here we have u a cicd pipeline so we have code Pipeline and so code pipeline is triggered by GitHub so we put our code in GitHub and when that happens it's going to do a code build so that's going to build out a server um and then from there it's going to run another code build server and then from there it's going to then um uh uh use code deploy and so code deploy is going to trigger a deploy what it will do is create a new environment so it's going to create a copy of this um sorry it's going to create a cop this is actually the environment that's running so we'll copy that and that will be our new environment right okay and so when the deploy is done it will swap and then that environment will become this new one um and so you know again this is actually really the the running server it's just kind of easy to get hung up on this one but the idea here is that um you know that's how deployment works but let's say uh you know we want to get uh traffic to this actual instance this is going to come through the internet and the internet's going to probably go to refy 3 so ref 3 is used for domain names so this be like exam pro. c teacher seat.com we pass that over to our elastic load balcer which in this case is an application load balcer that's why it's called ALB and that's going to distribute the traffic there if we wanted to run the server in another um in another availability zone so that we make it highly available um you know ALB the elastic load balancer application load balancer is going to uh have some traffic go here and some traffic go there so this is just uh the blue environment or whichever the current environment is over here now when we want to deploy new version we're going to use launch templates and launch templates um uh are necessary when using Autos scaling groups so um you know you do have to Define launch template it just says like what is the shape of this instance type like what's its family what should it be and then we need an Amazon machine image so our Amazon machine image is custom built because we are installing all the stuff that we want on it and so in order to automate that process we are using um SSM automation documents so SSM stands for system manager and automation allows you to automate that step so what it's going to do is launch an instance install Ruby install postgress download the codebase then it's going to create that Ami and then um it will do a bunch of other stuff here as well and this is going to run weekly or actually at the time uh it was running nightly so we're doing nightly builds so that we would always get the latest um updates to our server um because it's a virtual machine there could always be uh new updates for that Linux version or Amazon machine Li Linux version we using and then there's a bunch of other stuff here so you know um hopefully that kind of gives you an idea like the complexity of it and you know this is how I like to make my architectural diagrams very in detailed so that we can um look at them but yeah if that was too much that's fine but you know that's just the complexity of it if you build your own you'll start to really grasp this stuff pretty well okay so what I want to do is just show you how high availability is built into some ad Services where in other cases say you have to explicitly choose that you want something to be highly available uh so what I'm going to do is make my way over to S3 and so with S3 this is where you can create S3 buckets and this allows you uh to store things and so the great thing about S3 is that it's basically serverless storage so the idea is that you're just going to choose your region and by default it's going to replicate your data across multiple um uh data centers or azs and so this one's already highly available by default with the standard tier and so that is something that's really nice but other services uh you know like ec2 the idea is that you are going to launch yourself an ec2 instance so we' launch that one and the problem with this is that if you launch a single ec2 that is not highly available because it's a single server running in a single um a so here you know we would choose our subnet our subnet is our availability Zone but you'd have to launch at least two additional servers and then you'd have to Route um uh you'd have to have something that would balance uh the traffic to the to the three which is a load balancer and so in this case you have to construct your high availability then you have services like elastic beanock this is a platform as a service um and we'll go to environments here I'm not sure I wasn't showing up there um and so the idea is that with elastic beant stock I'm just going to click on the main service here you're going to go ahead and uh create your application or create your environment you probably want to create an environment first here okay and so I would choose a web server and then the idea is I just name it so my application here my uh environment and then down below you go configure more options whoops it wants me to choose everything that's totally fine and we say configure more options we're not going to create it because um we don't want to create one but the idea is that uh you you could choose whether you want this to be high highly available or not so see it says single instance so free tier uh and then if you chose this what it's going to do it set up a bunch of stuff for you so it's going to set up an application load balancer for you it's going to set up Auto scaling groups for you to make it highly available it's going to run at least uh between one to four instances so this does everything that uh ec2 you'd have to do manually setting up so that's really nice okay so you know some options have that if we make it our way over to RDS and again we're not creating anything we're just looking at the options it gives us when we uh start things these up here we'll make our way over to RDS when it gives us a moment here and if we go ahead and create ourselves a new database and we look at something like a postgress database notice that we have a production option and a Dev test option and so I mean usually it shows us the price down here so even test Dev is $118 which is not true can make it cheaper than that but the idea is that when you choose between these two options um it's going to set up uh multiaz it's going to that means that it's going to run an additional um uh database and another availability Zone replicate that data over so that it stays highly available um you know it's going to have autoscaling uh uh part of it and so some Services you just choose it abstractly so you just have to understand what highly availability is going to mean underneath so hopefully that kind of gives you a picture of high availability on AWS hey this is Andrew Brown from exam Pro and we are looking at adus application programming interface also known as adus API so before we talk about uh the API let's describe what application programming interface is so an API is software that allows two applications or services to talk to each other and the most common type of API is via HTTP requests and so the ads API is actually an htttp API and you can interact with it by sending HPS requests using an application interacting with apis like Postman and so here's kind of an example of what a request would be that would be sent out and so the way it works is that each Ada service generally has a service endpoint so see where it says monitoring that's going to be cloudwatch so sometimes they're named after the services sometimes the name is a bit obscure and of course you can't just call uh call Api request without authenticating or authorizing and so you have to sign your request and so that's a process of making a separate request uh with your adus credentials to get back a a temporary token in order to authorize that and I don't have room to show it but the thing is is that what you'd be uh also going along with those requests would be to provide an action so when you look at um the adus API it will show you a bunch of actions that you can call they're basically the same ones you'll see in the IM policies so it could be like describe ec2 instances Or List buckets um and they can also be accompanied with parameters okay so you know we're probably not going to show you how to uh make an API request directly because that's not something that you would generally do um but what you would do is you'd probably use the abis Management console which is powered by the API use the adus SDK which is powered by the API or using the adus CLI so we'll cover all those three okay all right so what I want to do is just point you to where you'd find the resources to use the API programmatically uh we're not going to actually use the API because there's a lot more to it uh than what I'm going to show you here but at least you'll be familiar with how the API works so I'm on the aws.amazon.com website if you type in docs the type top there it's going to bring you to the main documentation and what we're looking for if we scroll on down there should be a general reference area where we have service endpoints if we click into here it's going to uh talk about um how a service endpoint is structured and if we go down to abis API we can see some additional information of course to use um the API you're going to have to sign API requests first which is not a super simple process but you have to use an authorization header um and send along uh some credentials and things like that so if you want to know what service endpoints uh are available to you if you search service endpoints list for AWS this is the big list and so if I was to go down here and look for C2 U might be a common example here it's going to tell us what the end points are and as you can see they are Regional based but the idea here is that I could take something like this okay I could grab that and using something like Postman I could go and create a new request and it's probably a post I'm not sure what it's supposed to be it's probably a post and then you'd set your authorization header there might even be one in here for adab us see where it says adab us signature so you can go here and put your access key and secret with in here um so that's something nice about Postman so it's going to do the signing requests for you so it makes your life a lot easier and then from there what you do is you go to your body and you'd want to enter in Json so to do Json would probably be raw you drop down the format Json and then you'd send your payload whatever it is so I again I haven't done this in a while because it's not a very common uh thing that I have to do like describe ec2 instances but there probably is like an action and some additional information that you'd send along um so you know hopefully that gives you kind of an idea how the API works but you know you should never Pro uh in practice ever have to really work with the API this way directly okay hey this is Andrew Brown from exam Pro and we are looking at the itus Management console so the itus Management console is a webbased unified console to build manage and monitor everything from simple web apps to complex Cloud deployments so when you create your adus account and you log in that is what you're using the adus Management console and I would not be surprised uh if you're watching this video and they've already changed um the default page here since abos loves to change the UI on us all the time uh but uh the way you would access this is via console. ab. amazon.com when you click sign in or go to the console that's the link that it's going to uh and so the idea here is that you can point and click to manually launch and configure adus Resources with limited programming knowledge this is known as click Ops since you can perform all your system operations via clicks okay let's talk about the adus Management console in brief here so you know of course when you're on the homepage you go to ads Management console and you will end up logging in and from there we will uh make our way over to the ads Management console when I say ads Management console I'm referring to uh this homepage but I'm also referring to anything that I'm doing in this web UI whether it's a subservice or not so you know a lot of times people just call this the dashboard uh or the homepage um but you know it is technically the adus Management console but everything is the adabs Management console you can drop down Services here if there's some that you like you can favorite them on the left hand side I don't find that particularly useful you can see the most recent ones here they'll also Show recently up here as well we have the search at the top notice that there's a hotkey for alt S I don't think I ever use it but if I was to type in a service like ec2 it's going to get me the services and then down below it's the sub features of it so if I just click into that there into this this is the main this is a service console so I would call this the ec2 console or the ec2 service console so if you ever hear me saying go to the ec2 console that's what I'm saying and you'll notice here like there is stuff on the left hand side so I come back here ec2 image Builder ec2 Global views these are considered services but if you drop down it says top features or you go down here it says dashboard limits Amis you go over here um the ec2 dash board limits Amis are here and limits are somewhere here right there so okay so those kind of map over pretty well plls and documentation knowledge based articles Marketplace I don't think I've ever touched those in my life uh this here is the cloud shell so if you click it it will launch a cloud shell will cover that when we get to that section here we have this little bell it tells us about open issues I think this is for the personal health dashboard yeah it says PhD in the bottom left corner or left corner so if I open that up it'll bring up the PHD the personal Health dashboard all right uh our region selector our support so nothing super exciting here but just kind of giving you a bit of a tour so that you know there are some things you can do um can you change the look of this I don't think right now as of yet um there is any way I'm sure Aus is thinking about it because it's been a high uh request that's in demand but uh this is what it looks like as of today okay all right so I just want to describe what a service console is so an an service each have their own customized console and you can access these consoles by searching the service name so you would go ahead and type in ec2 and then what we refer to this screen as as the ec2 console the reason I'm telling you this is that when you're going through a lot of labs or follow alongs you'll hear the instructor say go to the ec2 console go to the stagemaker console go to the RDS console what they're telling you is to go type the the name of the service and go to um that particular Services console okay uh some adus service consoles will act as an umbrella console containing many adus services so uh you know VPC console ec2 console systems manager console Sage maker console uh cloudwatch console these all contain multiple services so you know for um for ec2 you might say okay well I need a security group there's no security group console it's under the ec2 console okay uh so just be aware of that so now I want to show you some of the service consoles to kind of distinguish how they might vary per per service okay so if we were to look up ec2 um and we just did look at this but the interesting thing is that some uh consoles the ec2 console uh is the home for other databus services and you just have to learn this over time to know that so for instance elastic Block store is its own service but it's tightly uh linked to ec2 instances so that's why they always have have it here same thing with Amis uh security groups same thing with that so these are interesting because these are basically part of virtual networking and so you'd think they'd be under the VPC console but they are actually under here with ec2 and so load balancing autoc scan groups tightly coupled to um uh to ec2 if we make our way over to VPC um you know here it's going to contain all the new stuff does it have a new experience no I guess this is the newest one it looks a bit old and a little bit new here but you know we have a lot of different things here like firewalls vpns Transit gateways traffic mirroring we make our way over to cloudwatch okay and cloudwatch has uh very uh focused Services they're all actually named and this is more like a s feels more like a single service where you have these very focused um Services where you have alarms logs metrics events insights right but you're going to notice that like the UI highly VAR so we had looked at cloudwatch and then we had looked at U VPC and it looks like this and then we looked at ec2 and it looked like that and so there is inconsistencies because each um Service uh Team like that work on per service or whatever they have full control over their UI and so some of them are in um uh different states of updating so some people might have updated the leftand column but this part is old or you might click around like under something else like ec2 dashboard um or maybe a better example might be Amis I remember we're in here and something looked old here yeah see these are the old buttons and that's just how it is so everything is very uh modular and so they get updated over time so that is the challenge that you're dealing with you're always having like three different versions that are cobbled together in each uh um UI one thing that I found really interesting is that um VPC has its own console Management console but if you were to look up this in the uh the SDK so if I was to look up um AB SDK ec2 okay I'm just looking up Ruby here as an example because that's what I know how to do um if you look under here let's say you want to pragmatically work with vpcs you think that it would have its own top level VPC because it has in the console its own uh its own Management console but actually VPC is tightly coupled ec2 and so when you want to programmatically use VPC you're going to be um using actually ec2 uh as as was built so the the the what I'm trying to get is the apis don't onetoone match with this kind of stuff and so it's just kind of interesting that there's those kind of uh differences uh but again it's not that big of a deal I'm just trying to say like you know keep your mind open when you're look at the stuff okay so every ad ofus account has a unique account ID and the account ID can be easily found by dropping down the current user in the global navigation so what I'm going to do is pull my pen tool here and just show you it's right there the ab account ID is composed of 12 digits and so it could look like this or this or this account ID is used when logging in uh with a nonroot user account uh but generally a lot of people like to set their own Alias because it's tiring to remember your account uh ID the uh you use it when you're creating cross account rol so you'd have the target account the source account ID to gain access to resources in another a account when you're uh dealing with a support es a will commonly ask you what your account ID is so they can identify the account that they want to look at and it is generally good to keep your account ID private as it is one of the many components used to identify an account for an attack by malicious actor uh so you don't have to be overly sensitive with it but you know try to hide it when you can when it's easy okay all right so let's talk about the account ID which appears up here in the top right corner uh where you can get the account ID it also appears in IM am so if we go over to IM am and you look on the right hand side it should show you the example here it keeps on trying to take us to the old dashboard that's fine um but you'll notice that it's over here and I don't have MFA turned on because I'm in my IM user account but it should be turned on on everything that's given but uh you know I just want to show you where it is and also where you might be using it so one example where you would use you would need to know your account ID would be something like creating a cross account policy so I went here and went to policy and went create policy um and we went to maybe it's a roll I think we actually sorry we want a cross account account rle it's not the policy sorry we go here and we say I want to access something in another A's account what we have to do is specify the account ID specify the accounts that can use this role so you give I think the the ID of the other account okay okay and so that is one place where You' use it another place would be when you're creating policies so if I go back to policies here I can create a policy here and I can just choose something like S3 okay and I'll just choose a list and under the request conditions I might specify I think the account ID it should be in here um I know I can limit based on account ID principal account so you can do principal account so if I just looked up this here ABS principal account and you just got to get used to Googling things that's always what's happening here and so we should be able to specify an account ID yeah like that so that would be the principle there so if I just took that and doesn't matter what it is we just put the value in here uh um string equals this add I should be able to go over here and now see the full statement no sometimes that happens because we don't have it fully filled out but um yeah so that pretty much that's pretty much how we use it like it would normally show up as that so if I just go ahead and go next the policy contains an error you are required to choose a resource what do you mean the resource is this right oh down here okay sorry uh so we'll just say all resources then we split over now it's valid and so here we can see our condition saying only from this account ID that it is allowed um other places we're going to see account IDs are in um ARS right so if we had an ec2 instance we don't have one launched right now but if I was to go ahead and oh maybe we have some prior ones yeah so if I was to checkbox this here and you might not have any prior ones so there might not be nothing for you to see but if you look for the arm AR where is our AR sometimes it doesn't show the Arn in the services sometimes it does I wish that AB always showed the AR to make our lives a bit easier but it could be because of other reasons why but even though we don't have the AR I think it shows us shows us the owner ID and so that's the account uh the account ID number you can tell because it's 12 digits so hopefully that gives you kind of a tour of the account ID and what its purpose is in the out okay all right let's take a look at it tools for Powershell so what is Powershell Powershell is a task Automation and configuration management framework is a command like shell and a scripting language so here it is over here uh if you are a Windows user you're used to seeing this because it has a big blue window so unlike most shells which accept and return text Powershell is built on top of the net common language runtime CLR accepts and returns the net objects so uh adus has a thing called the itus tools for Powershell and this lets you interact with the itus API via Powershell commandlets commandlets is a special type of command in Powershell in the form of the capitalized verb and noun so in this case it'd be new hyphen S3 bucket so you know we looked at the a CLI and that is generally for bash um uh you know shells and so power shell is just another type of shell that's very popular and I just wanted to highlight it for those people that are uh you know used to using Microsoft workloads or Azure workloads uh that this actually exists okay all right let's take a look at the Powershell tools um I actually haven't used this one yet so I'm kind of curious I am out a Windows machine so if I was to um open CM or Powershell and you probably can't see this but if I just bring this over here if I type in Powershell on my computer you'll notice that I have it um so that's how You' launch it looks like a blue screen here okay um if you're on a Mac you're not going to have that but that's totally fine we don't need to have a Windows machine to use Powershell because we can go ahead and use cloud shell so make sure you're in a region that supports Cloud shell so I switch back to North Virginia uh this is not important for the exam but it's just kind of fun for me to go through this with you and if you just like want to watch uh here and so I want to change this over to power shell so I imagine that it must be over here um so how do we change change to poers Shell so we'll type in ads power or ads Cloud shell Powers shell like how do we do it okay and so I'm just going to scroll down here so the following shells are preinstalled uh The Bash the power shell the Z shell you can identify them by that yeah of course to switch to New Shell enter the Shell's program name in the command line prompt oh wow that's easy so um if we want pwsh do we just just type pwsh let's find out give it a moment to think oh there we go okay so now we're using Powershell and so I would think that ads would give this preinstalled for us so if we go over here to the instructions and we scroll on down there's probably like oh wait like I don't use Powershell a lot it's very easy to install modules um I've done it before but I never remember how to do it but let's just see what we can find here so I want the documentation for Powershell here and I'm going to go to the um the maybe the reference here because I just want to see some examples for the commandlets and so we'll look for S3 again never done this before but I'm always great at jumping uh into these things and all I want to do is just list out the buckets so I'm going to just search for the word list um and just see if I can find something very simple here and calls to get the list buckets API operation so I think that is what we're going to to be doing here so I'm going to click into that okay and then from there what I'm going to do is just see if I can copy this command so we will go ahead and copy this and paste it in here and I like how we got this little shell here so we can tweak it so we need the bucket name but I don't want to return a list of all the buckets owned by the author so we don't have a bucket name that we want to explicitly set here so it's required false so we can remove that okay we'll look at the next one select required fals use the select command to control the command L output the default is bucket specifying selectable result in returning all the whole buckets for that specifying the name uh but it says it's not required so let's just take that out as well I don't think we need any of these actually let's just go and put that in there and I think that there must be something we need to put in front of that right let's just see what happens uh the term is not recognized as the name of the commandlet function script is operable so I think we're missing something in front of here we'll go to the user guide here quickly and we'll get to the getting started I just want a super simple example here new bucket get bucket well let's try this one here because they have it here and so it should work right I'm change this to us East one the term new bucket is not recognized as the name of the commandlet function so I'm guessing that the commandlet is not installed I would have thought that they would have installed it by default so I guess what we'll do is look at how to install it so installing on Linux I suppose so you can install the modulized version of the Powershell on computers to install adus tools on Linux pwsh to start Powershell core session so I guess that's how you must start it on Linux and then install the module this way so yeah I said it's easy to install these things we'll hit enter cross your fingers hope this works hope this is fast I'm just going to take a look here peek forward here if you are not uh if you're notified the repository is UN trusted you're asked if you want to trust anyway just hit Y so we're waiting for that here um you're installing this module from untrusted repository it's funny that it's untrusted by but it's by AWS maybe that's some kind of drama between Microsoft not letting AWS have an official module there but it looks like it should be installed now so if I type in get S3 bucket here um unless I typed it wrong that still doesn't seem to be working if I go up here and try to create a new bucket still does not recom recognize the command command lit here so there must be more going on here um if you are notified you can now install the module for each service okay well what did we do you're installing the the the modules from unrusted if you trust it change the uh change it installation policy value by running set policy command are you sure you want to install this module from the PS Gallery so I said yes and I gave it a capital Y and it didn't do anything else so oh hold on here so this is the installer and then here is the actual tool that we want to install so it install to oh so we just installed this thing and now we use this thing to install S3 okay great not hard okay and so we'll just say yes to all and so that's going to install I guess everything oh we said ec2 and S3 three well we didn't need both but that's fine and so what I'm going to do is go get bucket and so now recognize it it lists out the items here we can go and create ourselves a new bucket so we'll do that okay we'll make our way back over the databas Management console we'll go to S3 just because I don't need all these buckets lying around here and I'm going to go ahead and delete some of these buckets here so we'll say delete my bucket great and we'll go to this one here and say delete my bucket excellent all right and so we have an idea how to use Powershell so Powershell is just really popular because of it's the way you do inputs it's very standardized and the outputs that come so it's very popular um and a very powerful scripting tool that's or CLI tool as well so uh you know hopefully that's that was interesting for you but what we'll do is just close these off here and go back to our our homepage always just clicking that logo there and there we go so Amazon resource names uniquely identify itus resources and orangs are required to specify resource and Ambiguously across all a of all of AWS so the AR has the following format variations so there's a few different things here but just notice here that sometimes it has a resource ID or it has a path so with a resource type or could be separated by a colon so the partition um could either be ads China or gov Cloud because this is basically the ads uh portal or URL that are completely separated from each other uh as we talked about those earlier in the course uh then there's the service identifier so ec2 S3 IM am pretty much every service has their own uh service that uh name here that would be identified then the region would be pretty obvious Us East one CA Central 1 you'd have a account ID which would be 12 digits uh the resource ID uh could be a name or a pass so like for um IM IM users we have user Bob the this is an E2 instance and most of the IRS are accessible via the Aus Management console and you can usually click the Arn to copy to your clipboard so here is it is for um an S3 bucket and notice that it's a little bit different because it is a global Service AWS there's no reason to specify the region or the account ID or uh anything else there like the resource type so straight away we already know it's a bucket so we can just say my bucket so that one's really short but in other cases it's really long so here it is for a load balcer and it has all the information there and notice that like this has a pass load balcer app my server will be and then it has the ID okay for paths and IRS they can also include uh a wild card Aster and we'll see these like with IM policies or or paths these are really useful when you are doing um uh policies where you have to specify n you want to say a group of things and things like that so there you go all right so now let's take a look at Amazon resource name or also known as AR um and so ARS are used to reference objects they're very commonly used when you're using the CLI or the SDK to reference to something um the easiest example is S3 right so we go over to S3 here and we create ourselves a new bucket um so I'll go ahead and create ourselves a new one here we say my new bucket I'm just going to put a bunch of numbers in here doesn't matter we'll hit create bucket and what we will see if we click into this is the AR should be under properties and there it is okay so there are many cases where you might want to use the AR and a lot of times you'll just copy it and uh a very common example would be again with I am policies so we go over to I am policies right and I want to get to policies here just save myself some trouble and we create a policy you know I might want to restrict someone to use only that bucket so I say S3 okay and then I'm going to say um I want to be able to read and write from a particular bucket we go drop down these resources here and so here we have a lot of options um maybe I'll just get rid of the read option and I'm going to actually expand right because it's just creating too much work for me here and I just want to have um put put object that's that's the what we use to put something into a bucket so we expand the resource here and notice this says add the irn so we go here and we could type the bucket name so do that or we just paste it on in here at the top so it's probably easier just to grab it sometimes but if you don't know an AR a lot of times you can just expand this and then fill it in and that's how you get an Arn so put that there let's list oh you can also do it that way which is easier too and so now if I go to Json is it valid there we go so here it's saying um this policy allows somebody to put an object into this particular bucket and so that would be an example where we would use um an AR okay or if you're doing uh if you're using uh ad support you might have to use an AR to um to get help from support saying hey look at this particular resource exactly here and then the the cloud support engineer can help you okay hey this is Andrew Brown from exam Pro and we are looking at the itus command light interface but before we do that we got to Define some terms so what is a CLI so a command line interface processes commands to a computer program in the form of lines of text operating system Implement a command line interface in a shell okay so then we have a terminal so a terminal is a text only interface so it has input output environment then you have a console this is the physical computer to physically input information into a terminal then you have the shell a shell is the command line program that users interact uh with uh to input commands popular shell programs are bash uh zsh Powershell and you might remember this one MS DOS prompt so this has been around for obviously a very long time so maybe this kind of primes your mind for what is a shell and just so you know people commonly erroneously use terminal shell or console to generally describe interacting with a shell so if we say shell or console or terminal we're just talking about the same thing but there is technically a difference between these three things but most people do not care and I wouldn't worry about it too much okay so now let's take a look at the itus command line interface which allows you to pratically interact with the itus API via entering single or multi line commands into a shell and then here I say or terminal but really it's just the shell okay so uh here is an example of one so we're trying to describe uh ec2 instances and then we're getting the output because we asked to have it back in this table like view so the ab is a python executable program so python is required to install the aw CLI the a CLI can be installed on Windows Mac Linux Unix the name of the ca program is AWS you'll notice that up here in the top left corner there's a lot more to this but this is all we need for now okay hey this is Andrew Brown from exam Pro and we are taking a look at the abis CLI and the easiest way to get started with this is actually via the cloud shell so you'll notice this little icon here in the top right corner that is cloud shell and it's going to allow us to um uh programmatically do things without having to set up our own environments so if I just click that there okay uh and I say do not show again close and by the way if you don't see Cloud shell here it could be your region so like if I go to Canada Central it doesn't have it there and so if I was to search Cloud shell here okay it's going to say it's only supported in those regions so that's a bit annoying but once Cloud shell loads it already has our uh credentials loaded within our account and so this is going to save us a lot of time in terms of uh you know trying to get set up with the exception that you have to wait for this environment to create so it takes a little bit of time time but it's not that bad um and while that is waiting what I'll do is show you actually how you install the CLI yourself so if we typed in Abus CLI install all right and uh we went here the way you would install I believe it's a python library but if we went to version two and we just said Linux uh you go down here they have instructions so you just curl it unzip it and do that um so you know if it's this and then once it's installed you'll have the of the CLI commands this is still go so you know maybe I can show you what it would be like to install the CLI by hand so if we wanted to do that one easy way to do this is if we just go to GitHub doesn't matter what repository I'm just looking for anything here and if I open up git pod so if we go on the top here and type in git pod uh. maybe that I just want to see whoops maybe just get pods that oh get pod you're not giving me oh you know what it's doio that's why okay so if we go back here sorry and we type in doio what this will do is launch me a temporary environment and so this is outside of AWS so I'd actually have to install the CLI so this would be a great opportunity to show you how to install the CLI I'm just doing it this way because git pod is free to use and um you know it's going to set up an environment and how let us simulate installing the CLI so here is the CLI here I'm going to see if I can bump up the font um let's make the font as large as we can go light or dark dark sounds good to me and so if we type in AWS I give it a moment we can see that we have uh the command here so if I say ABS S3 LS whoops it should be able to list things out in a bucket so this is what's currently in the bucket if you're wondering how do I know what these commands are I can just type in a CLI commands Okay and if we go here um and we go to the CLI reference reference then we have um anything we want here right so we go down here and I just want to see what's running in S3 and I go here and I scroll on down it's going to show me commands like copy move remove sync uh MB RB uh list right and if you're looking for a particular command you go down and say okay I'll look at LS here and it will explain to me all the little options that we can do with it and then it will always give me examples right so I can see examples like that so if I wanted to move something into an S3 bucket so let's say I want to create a new S3 bucket um we'll type in a ss3 and just hit enter and it should tell us um the sub commands may if I do like help like this and if we scroll on down so I guess it just pulls up documentation let's hoping it would give us like a tiny summary okay so what we can do here because I want to create a bucket type in like buckets if you don't know something you just go a S3 C create bucket we'll go here um and then what I do is I always just go to examples here so we have a S3 API create bucket and I know it's unusual there's an S3 and there's an S3 API I don't know why that is but it's always been that way and I I just don't question it anymore and so here I can go ahead and create a new bucket so I'll just go ahead and paste that command in I do want to change it up a bit here because this name could be that has to be unique so just to make sure I get what I want I'm putting random numbers in here we're going to choose the region as us East one if I wanted to do other things here I could scroll up and look at some Flags here so uh it looks all fine to me so I think I'll go back here and just hit uh paste okay and so it created that bucket for me if I go over to S3 and we'll wait here a moment we can see that bucket now exists if I wanted to place something in that bucket what I can do is just like touch a file so I'll just say um touch touch is a Linux command to make just an empty file so we'll say um hello.txt and then it would be a S3 um it would be SP to copy it and I'm going to give it the local path hello.txt and then I need to give it the bucket address so would be S3 slth bucket name so we named it this I'm not going to try to type that in by hand because it's too hard and then I want to say where I want to put this file so I'm going to say hello.txt and if I'm right that should work as expected and so it says I uploaded that file I make my way back over to S3 I refresh there is the file if I want to copy this file back locally um all I have to do I'm just going to remove I'm going to delete the original hello txt file LS to show you that there's nothing there and what I need to do oops is just revert this so instead of saying the address here we can go and type in hello.txt and if I do LS there's the file if you don't know what the address is of the bucket um a lot of times you can go here and find it so it should be because they're always changing this UI on me but we'll go to properties here and there that's the AR uh usually a good way to find it is if you go into an actual object so if you go here it'll give you the full URL so I could have grabbed that and I could have just pasted that in there um but you know you learn after time it's not hard to remember this S3 Co SL the unique name I do want to show you how to install it by hand so here I'm in git pods um I'm not sure how I can change this to a dark theme so I really don't like this on my eyes we'll go down below here to color theme and we'll say get dark there we go and so this is a temporary workspace so when I close it it'll be gone so that'll be totally fine and so I'm going to type in AWS to see that it's not installed we're going to go over here this runs Linux by default so I already know that I'm going to use Linux we want to use version two here um so for the latest version use this command for a specific version no we just want the generic one so I'm going to go ahead and copy this whoops yes allow we'll paste that in we'll hit enter okay then we'll take the next command paste that in hit enter we'll go take the next command here we'll hit enter you can now run uh AWS so we type AWS and there's the command so uh the only thing is that if we do ads S3 LS it's not going to work because we don't have any credentials set so we'll give it a moment to think so it says unable to locate credentials you can configure credentials by running ads configure so we type in ad configure and by the way if this font is too small I believe I can bump it up like this not a great way to do it but um it works and so it says ads access key ID so what we can do is go over to IM am and what I'm looking for is my particular user over here and if you remember when we first created our account it generated out access keys I go to security credentials and so we have a key here but I need the secret so this key is useless to me so I'm going to go ahead and deactivate it just because I don't even want this key and I'm going to create myself a new key so I'm going to have an access ID in secret when ever you generate these out never ever ever ever ever show anyone what these are these are your yours and yours alone okay so this is cloud shell we're fine we're just going to close that for now and I'm going to go back over to get pods here and hit enter so that's the ID I'm going to go grab the secret hit enter paste and I want it to go to us East one to save myself some trouble uh you can change the output from Json to tables I'm going to leave it as the default here and so now if I type ABS S3 LS I get a list and so if I want to grab that file there I'm going to grab that S3 U and we type in a S3 API or sorry it's just LS sorry or sorry C and we're going to paste that link in and we're going to say hello.txt and I must have done the command wrong it's because we're missing S3 here I just hit up on the keyboard to get that command back and so I type in LS for list and I mean I have some other code here so you know again any repo you want on GitHub it doesn't really matter uh but you'll see there is that file probably shouldn't have used this one because it makes a bit of a mess um but yeah it's pretty straightforward just to one thing to show you is where those credal are stored so by default they're going to be stored in um it's going to be in the hidden directory in your root or your home directory called ad. credentials so if I just do like LS here you can see there's a config file and a credentials file cat lets me print out the contents of that file so I go here and it's saying the default region is Us East one this is a tomble file even though it doesn't have a do toml on the end of it I just know by looking at it that's what it is config lets you set uh defaults that are going to apply to all of your credentials and then uh within the credential file here is the actual credentials so if you wanted to just set them you could go in here and just set them in here you can also set multiple credentials so if I go here and I'm going to open up and buy because I'm not sure how to open it up here in the main one but if you wanted multiple accounts you do like exam Pro and then you just repeat these with different keys right and then when you wanted to use an a CLI command actually I'm going to go back here for a second okay and if you want to um and by the way I'm using VI never use Vim it's it's a bit tricky to use uh you might want to use Nano instead if you're if you're kind of new to this um because this will use like regular key key cuts and then down below it shows you what it is so this is like control X or alt X alt X NOP control X there we go um but anyway so if I go into this file and I delete the original one right and now I try to do um this command here even though we already have that file it should either hang or complain I Could Just Kill that by doing control C if I do ads S3 LS notice that it's hanging so unable to locate credentials because there's no default one but if I go and I put profile and I say exam Pro all right it it'll now use that profile so that's the way we do it um but hopefully that gives you kind of a a crash course into the CLI um so yeah there you go okay so I'm just going to go ahead and close these off you can delete this bucket if you don't want it it's probably a good idea to delete this here and I'm just going to say permanently delete okay very very good okay close that off and yeah that's the introduction to the CL so yeah there you go hey this is Andrew Brown from exam Pro and we are taking a look at software development kits uh so a software development kit or SDK is a collection of software development tools and one installable package so you can use the AWS SDK to programmatically create modify delete or interact with aabus resources so the aabus SDK is offered in a variety of programming languages so we have Java python node.js Ruby go.net PHP JavaScript C++ and so here would be an example of some Ruby code where we are creating ourselves um an S3 bucket so we're just uploading a file there okay okay so now what I'm going to do is show you how to use the itus SDK and so uh to do that uh we're going to need some kind of IDE um a a basically code editor and so we had looked at get pods which is a third party service and that's fine but let's take a look at Cloud9 because that is built into AWS so if I just type in Cloud9 here and go over to IDE I'm going to launch myself a new environment so I'll hit create I'm going just say my SDK environment EnV if you if you have our time typing environment like me and we have some options so create a new C2 instance for direct access create it via assistance manager run a remote with SSH I'm going to leave it as the default then we have the option to choose what size I want to leave it on T2 micro because that is the free tier then we're going to scroll on down we have Amazon Linux 2 Linux Ami I'm going to stick with Amazon Linux 2 and we can have it turn off after 30 minutes a great option for us here and we'll go ahead and hit next and we'll hit create environment and so we're going to have to wait a little bit for this to launch it'll take a few minutes as that is going let's go to Google type in adus SDK um to get to the main page and so the idea here is that there are a bunch of different languages you can use C++ go Java javascript. net node.js PHP Python and Ruby uh and so I'm a really big fan of Ruby I've been using Ruby since 2005 and so that's what we're going to do it in it's also really easy to use and it's a really great language so um you know down below it's just showing you that there's all these different things but if we go down to the SDK here and we click on Ruby we we have examples where we have the developer guide the API reference and so this tells you how to get started even here it's saying like hey go get started with Cloud9 which is great as well I suppose um and so here it might show you how to install it um and when we open up the API references this is what it looks like so a lot of times when I want to do something I know it's like I want to do something with S3 so I scroll on down here and I look for S3 right and then I just kind of like uh scroll around and look you know what I mean sometimes you have to expand it go into the client every API is a slight different so you do have to kind of figure out how to navigate that I'm actually under S3 right now so I'm looking for the client and I just know this for memory that this is where it is so first you create yourself a client and then you can do API operations so if I wanted to like list buckets I just search the word list and I just scroll on down and there it is I click into that and I have an example of how to list a bucket so I'm going to go back to Cloud9 and it is ready and it started in dark mode um if yours is not in dark mode which really honestly why wouldn't you want dark mode mode um if we go up to I think it's like file where is it preferences here got to C the Cloud9 option and I'm just seeing if it like remembers my settings I really like two two soft tabs here but uh there should be something for themes down below and so um that doesn't seem like that's it used to be like a oh here it is if you go here and just choose like whatever you want I'm on jet dark here and so if it's on classic light or something you don't like you can fix that there um but I'm just going to go here and just fiddle with my settings because I really like to use Vim uh keys I don't recommend this if you are uh to change this if you are not a programmer but I'm just going to change it so that I can type here efficiently so I'm just looking for the option here and they moved it on me where did they move it probably be like key bindings ah bin mode there we go again don't do that this is just for me so I can uh move around in a different way so what I want to do and by the way it looks like this default screen we could have just changed it here I just clicked through all that for nothing was here the entire time but um what we need is we need to make sure that we have our credentials so if we type in OS um S3 LS that's like my sanity check that I always like to do to make sure I have credentials notice that we didn't have to set up any credentials it was already on this machine which was really nice and so I'm going to create a new file here and it's okay if you don't know anything about Ruby we're just going to have fun here and just follow along so I'm going to do example. RB I'm going to make sure Ruby's install by doing Ruby Hy and V so it is install which is great uh you need a gem file so say new gem file here and if we go back to the installation guide uh we need the gem SDK here actually I'm going to look at how to generate a gem file gem file because there's some stuff that goes to the top of those files like this here I think we just need this line here so I'm just going to grab that whoops paste that in allow good and uh I you can do gem ads SDK that will install everything but uh we only want to work with S3 and so this is going to vary based on each language but I know that if we type in S3 we'll just get S3 and that's all we really need and so once we have that what we'll need to do is use a bundle install so we're going to make sure we're in the correct directory I'm going to type in LS down below notice the gem file is there and by the way if the fonts are too small I should probably bump those up let's see how we can do that uh editor size font user settings good luck trying to find a day um project no you think it'd have to be under user settings right ah here it is okay so um this is for probably the editor so we'll go to 18 here Co code editor here I'm I'm trying to find the one for the terminal probably over here there we go much easier okay so notice we have example. RB and Gem file so we're in the correct directory make sure I save that I'm going to type in bundle install that's going to install the gems give it a moment there it's going to fetch notice that installed um the ads sdks S3 and everything that it was dependent on and so now if we go over to our example. RB file really when you're coding for the cloud you can pretty much copy paste everything so over here we found this code here for S3 list buckets um so I'm going to go ahead and paste that on in okay and I know it looks really complicated but we can quickly simplify this so I know that this is just the output so I don't need that okay and in Ruby you don't need parentheses or curlies if uh if you don't have any things there and so all I need to do is Define a client so if I click uh if I go to the top here of this file I think we're in the client right now all the way to the top all the way to the top here that's what we need okay and so I'm going to paste that in now uh we can set the region here so I'm going to say Us East one right and then you'd have your cred um because the credentials are on the machine in the um uh credentials file they're going to autoload here I believe so I don't think I need to set them so I'm just going to take that out here for a second okay and I can do this if I want this is just slightly different syntax it might be easier to read if I do it this way for you okay and I don't need double client there so we have the client I like to name this like S3 so I know what it is and I put puts for the response FS I'm going to do inspect and so puts is like print okay and so now if I type in bundle exact let's just make sure that it's in the context of our bundler file Ruby example. RB um we have a syntax error on this line here unexpected thing here oh it's because of this it's because I commented out so I'm just going to do curly parentheses comment out here okay actually to make it a bit easier I'm just going to bring this down like this okay and we'll paste that there okay and we'll try this again un initialized constants ad to oh yeah we have to require it so we have to require ABS SDK S3 I think we'll hit up and uh we got a struck back so it is working we are getting an object back if we want to play around with this a bit more I'm just going toall another gem called pry pry allows us to um inspect code so we're going to do bundle install and I'm going to go back to Ruby here I'm going to put a binding pry in here and then if I hit up and I do bundle EXA Ruby example. RB um I installed it right B install yes undefine method pry oh because I have to require it again bad habit here okay we'll hit up and so now I have an interactive shell and I can kind of analyze that object so we have a response so if I type in RSP here I have the structure object I can type in buckets here okay and it's showing me a bucket I can give it get its name um oh I think it's an array so I think I'd say like I'd say like zero here or I could say first this is just the how the Ruby language works we say name I get the name creation date okay so you get the idea whatever you want to do you know you search for it you just say I want to delete a bucket I want to create a bucket right and you look for it so I say create bucket here I click on this and I can see the options and they are always really good about giving me an example and then down below they always tell you all the parameters that you have there so that's how the SDK Works uh but yeah the credentials were uh soft loaded here but you could easily provide them yourself I should just show you that before anything else just cuz there's some variations there um and I'm just trying to look for it because it is separate code so you could do this this is one way of doing it so you could do it separate from the code so if you only wanted to configure it once right because you could you could have a lot of clients you wouldn't want to keep on like for each client you wouldn't want to put region in every time so I could take this and put this right here okay and this this is the file here where we have the credentials so this would be our um our access key and our ID and so you never want to put your code directly just in here so if I open up if you go cat you would never want to do this but I'm just going to show as an example here uh credentials oops I got to get out of this exits credentials oh do they not even show it on this machine which would be smart we wouldn't really want to see our credentials here uh hit up say LS oh no it's there okay cat whoops credentials there it is okay so you know if we look here we can see that there are credentials set it's a little bit different we have this like session token I guess it's to make sure that this expires over time but if I was to take these okay and I was just to paste them in here that's one way you would do it um you never ever want to do this ever ever ever ever you never want to do this because you'll end up committing that to your code um so this is really dirty to do so I don't ever recommend to do it um if you wanted to have this apply to everything you could put it up here and so now when we call the client we don't have to do it um of course if the they're loaded on the machine you don't have to do it the other thing is like if you if you want you could load them in Via environment variables that's usually what you want to do so you say adabs uh access key right and then we say environment databus access secret and so you'd set those by doing I think it's like an export um environment variables set in Linux you think I know after like 15 years of doing this but I never remember so you type in export so you go down into oops here you type in export and you just say something like I'm going to just show an example to see if it works so I'm going to say hello world okay and if I do uh hello like that Echo see it prints it out so that's how you would set it you'd set those there but there's actually very specific ones that aabus uses for um the API and it's these ones here so you always want to use those okay so you put that in there and that in there but of course you know like if they're already set in your machine you don't have to even specify those cuz it would autoload those environment variables I don't think they're set right now if we type in Echo just take a look here is are they going to get autoloaded here no so but anyway so we could go here just as an example and well actually they just show them right here so you see your access key but we go and we type in um export and I'm going to paste the key in there and I'm going to go to the the front of it we're typee adus access key ID equals enter and so now if I did echo on this ads access key ID okay shows up but I just want to show you how it can kind of vary and those conditions around it so yeah that is the adus SDK um and yeah a lot of times you're just copying pasting code and just kind of tweaking it you're not really writing uh real programming okay so hopefully that is less intimidating so I'm just going to close these off and I want to close down this Cloud9 environment um I might have to reopen this up in another Tab and go to the Management console here and then go over to Cloud9 and just close this tab and then while go ahead as and delete this environment oops I'll just type delete here even if you didn't it would turn off after 30 minutes and you have that free tier so it's not that big of a deal it's up to you whether you want to use Cloud9 or git pods Cloud9 is really good because it allows you to um uh it allows you to uh use it runs on a virtual machine right so you have a a container runtime there and so it's very easy to run containers on it um whereas in like I've had some issues with G pods but um yeah those are the two okay let's take a look at adus Cloud shell which is a browser based Shell built into the adus Management console and so Cloud shell is scoped per region it has the same credentials as the loged in user and it's a free server so this is what it looks like and the great thing about this is that you know if you have a hard time setting up uh your own shell or terminal on your computer um or maybe you just don't have access or privilege to do so it's just great that Abus makes this uh available to you and so what you can do is click the shell icon up at the top and that will expand this here some things to note about Cloud shell is that it has some preinstalled tools so it has the CLI python nodejs git make pip pseudo tar tx Vim W get vim and more it includes 1 gab of storage free per adus region it will save your files in a home directory available for future sessions for the same Aus region uh and it can support more than a single shell environment so it has bash Powers shell and zsh um and so Adis Cloud shell is available in select regions so when I was in my Canada region I was like where's the little shell icon but I realize it's limited for some areas okay hey this is Andrew Brown from exam Pro and we are taking a look at infrastructure as code also known as IAC and this allows you to write a configuration script to automate creating updating or destroying your Cloud infrastructure the way you can think of I it's a blueprint of your infrastructure and it allows you to easily share version or inventory your Cloud infrastructure so adus has two different offerings for IAC the first is cloud formation uh a com commonly abbreviated to CFN and this is a declarative IC tool and then you have a cloud development kit commonly known as cdk which is an imperative IAC tool so let's just talk about the difference between declarative and imperative and then we'll look at these tools a little bit closer uh each okay so declarative means what you see is what you get it's explicit it's more verose but uh there is zero chance of misconfiguration unless the file so big that you're missing something uh commonly declarative files are written things like Json yaml X ml so for cloud formation it's just Json and yaml uh and so that's that side there so for imperative you say what you want and the rest is filled in so it's implicit uh it's less forbose you could end up with some misconfiguration that's totally possible uh but it does more than declarative and you get to use your favorite programming language maybe python JavaScript actually cdk does not support Ruby right now but I just have that in there just as a general description of what imperative is okay all right so just a quick look at cloud formation so cloud formation allows you to write infrastructures code as either Json or yaml the reason why was adus started with Json and then everybody got sick of writing Json and so they introduced jaml which is a lot more concise which you see on the right hand side so cloud formation is simple but it can lead to large files or is limited in some regards to creating dynamic or repeal infrastructure compared to cdk Cloud information can be easier for devops engineers who do not have a background in web programming languages a lot of times they just know scripting and this basically is scripting since cdk generates out Cloud information it's still important to be able to read and understand Cloud information in order to debug IAC Stacks knowing cloud formation is kind of a cloud essential when you go into the other tiers of AWS um like Solutions architect associate professional or any of the associates you need to know Cloud information inside and out okay okay so what I want to do now is introduce you to infrastructure as code and so we're going to take a look at cloud formation and so we were just using Cloud9 for the STK so we're going to go back and create ourselves a new Cloud9 environment because we do have to write uh some code so I'll go ahead and hit create here and I'm going to just say uh CFN that's sort for cloud formation example and we'll hit next step and we'll create ourselves a new environment T2 micro Amazon X2 is totally fine we'll hit next it'll delete after 30 minutes we'll be fine we're within the free tier we're going to give this a moment to load up um and remember you can set your theme your your keyboard mode whatever you want as that loads and as that's going we're going to look up cloud formation and so cloud formation is very intimidating at first but once you get through the motions of it it's not too bad um so we'll go to the user guide here as we always do if you go to the getting started it's going to just tell us some things it's going to read about yaml files um I don't think I really need to read much about this here here so I think we'll just go start looking up some codes so something that might be interesting to launch as an ec2 instance Cloud information so that's what I'll do is I'll type in what I want so in ec2 instance and I'll just start pasting in code so if we scroll on down below here going to go to examples because I want a small example here this is something that I might want to do and we're going to give that a moment here it's almost done you can do it ad come on as that is going I'm going to open a new tab I'm going to make my way over to cloud formation okay and um you can see I have some older Stacks here notice Cloud9 when we create an environment actually creates a cloud formation stack which is kind of interesting um but if we go here we can create a stack and we can create a file and uploaded here so okay this is good I'm going to go ahead and make a new file we're going to call it template. yaml um just so you know yaml can be yml or Y ml there's a big debate as to which one you use um I think that adabs likes it when you use the full version so I just stick with yl I'm going to double click into that and so in the cc2 example I'm just going to copy this okay and I'm going to paste this in here and I'm going to type in resources oops capital okay so that's a resource I want to create um when you create Cloud information you always have a template version so I just need a basic example here at the top I guess that's a simple one is like a Hello World Bucket maybe we should do a bucket because it'll be a lot easier we don't have to make our life super hard here okay um but what I'm looking for is the version because that's the first thing that you specify I'm just trying to find it within an example here oh for freak's sakes cloud formation version if I don't have the format version it's going to complain there it is okay so we'll copy that we'll go back over here we'll paste that in there it might be fun to do like an output here so I'm going to do like an out put outputs and uh maybe instead of doing this we'll type in ads S3 C formation because what I'm looking for is what we can set as output so we'll say return values here um maybe we just want Returns the domain name so we'll just say um value ref that that's going to get the reference for it and we have to say hello bucket uh type string say outputs cloud formation example and even though I've written tons of cloud formation it's just like if you're not doing it on day and day out you start to forget what it is so here for outputs we need a logical ID description value and export so um that is what I want so I'm going to go ahead and copy that back here this is just so that when we run it we're going to be able to observe an output from the cloud formation file okay so the logical ID is whatever we want so hello bucket domain it's funny because this is how you do do um kind of that would be the format for terraform I was getting the mixed up so the domain of the bucket the value here is going to be ref hello bucket domain name that's the output export value to export uh can I get an example here B name oh you know what export is for uh cross Stacks we don't need to do that okay so that's fine so what we'll do is set that and we'll take out our old one and so this should create us an S3 bucket so with Cloud information you can uh provide a template here by providing a URL or you can upload a file directly so um I'm just trying to decide here how I want to do this you can also use a sample file or create a template in the designer I'm going to go over to the designer because then we can just like paste in what we want so if I go over to yes enel here and we go back over here I copy this I'm just going to paste this in here and we're going to hit the refresh button nobody ever uses the designer but this is just kind of a easy example for me to uh place this in here it's not really working maybe I got to go to template dude here refresh there we go so there's our bucket it's nice to have a little visualization and I believe this is going to work as expected so now that we have our designer template I think if we hit close what's this button say validate template probably a good idea validating the template template contains errors unresolved resource dependency uh in the output block of the template hello domain seems like it should be fine let's go whoops let's go back over here that's what I did I said reference that value oh uh maybe it's get a trib okay it's get ATT sorry get a tri cloud formation can't remember there's an r on the end of it oh it's just ATT this is if you're trying to get a return intrinsic value so a reference is like what the default one is but when every time we do like a logical name and attribute that's how we get that there so uh what I'm going to do here is just hit refresh and I'm going to validate that one more time now it's valid if I hover over this is going to upload it create the stack we could save this save it oh we can save it an S3 bucket so we'll say hello bucket and so now we have this URL so I'm going to copy it honestly I never use this editor so it's kind of interesting I'm going to leave and we probably could have hit create stack but I just find it a bit easier if we just kind of do it through uh this here so go back create the stack we're going to paste in the URL we're going to say next and we're going to say uh my new stack and I didn't see what the name of the bucket was oh there's no name so it's going to randomize that's perfect so we'll go next we have a bunch of options here we'll H hit next we'll give it a moment here I guess we have to review it create the stack and this the part where we watch so it says create in progress and we wait and we hit refresh and we can see what's happening trying to create a bucket and if we go to resources this is this is a lot easier to track because you can see all the resources that are being created if you notice that when you use the C uh when you're using database management cons and create S3 bucket it's instantaneous but like with cloud there's a bit of delay because there's some communication going on board but here it is and notice if we go to our outputs this is the the value of the bucket domain name if we were to make it with uh selfhosting which is not what we're doing with it we could also have an export name which would be used for cross referencing Stacks which is not something we uh care to do um but yeah that's how you create a stack that way um but you know we can also do it via the SDK here so what I can do um is look up what is the Adis uh CLI cloud formation CU they have their own commands here if I go here there's a new one and there's an old one so if we go create stack yeah there's things like this like create stack update um so if we wanted to do it this way okay and I copied this here just going to put this in my read me here for a second uh so here what you do is you say my new stack and you can provide the template URL or you could specify the local path here so we have like a template body so I'm going to go ahead and grab that okay this would be like yaml and um I need to specify this file here so template. yaml and I'm just going to go PWD here to get the full path okay and I'm going just paste that in there whoops okay I'm going to do LS okay so that gives us the full path to the file we can also specify the template URL um and so this should work as well if I take this and paste that on as a command unable to locate parameter file oh there's three three triple slashes there we'll just fix that there paste unable to load pram file no such file directory and there's a t missing okay be like don't be like me and make sure you don't have spelly mistakes okay I can type clear down here so I can see what I'm doing we'll hit enter whoops unable to load the parameter file no such file or directory home well I you didn't want the for slash so another we can try to do I think it will take it relative so if I do this it should work I don't ever remember having to specify the entire path and error occurred while calling the create stack my stack name already exists if I go back over here give this a refresh oh that's what we named our stack the the one that we did so I'm going to say stack two okay template format unsupported structure when calling the create stack operation are you kidding me I do this all the time template body yaml file cloud formation unsupported structure take a look here oh you know what I think uh this one's out of date that's why so what we can do is go to our old stack here and we can actually see the temp I can go ahead and copy this whoops and we can go ahead and paste that in there and then now what I can do so you know that's that's the reason why it wasn't working okay so we'll hit enter um unsupported structure it should be supported let's see if Cloud information can help us out um apparently there was very unhelpful error message formatting so try the validate template option I wonder if if we could just do this maybe if that would help here I'm just hitting up to try to run it again nope I guess we can try to validate it here it's like I'm not having much luck here today so we'll just say this here maybe it's not even loading that file where it is so there's no errors just going to make this one line okay created so for whatever reason I must have had a a bug there and so putting sometimes putting on one line helps that out because I must have had an obvious mistake there and now we can see the stack is creating it's doing the exact same thing it's creating a different bucket though if we go over to our S3 here again you know you don't need need to be able to do this yourself to pass the exam it's just so I'm just trying to show you like what it is so you kind of absorb any kind of knowledge about what's going on here notes down below it uses the stack name followed by uh the re The Logical name of the resource there okay um and what we'll do is wait for that to create once that's created we can go ahead and delete these Stacks we could also use the a cloud information to say like delete stack but I don't want to uh bore you with that today and so we'll hit refresh here wait for those to vanish okay those are gone uh what I'm going to do is kill this Cloud9 environment uh if there's a way to do it from here I have never known how to do it go back to your dashboard well that's nice to know we'll go ahead and just delete this okay we'll close that Tab and so now we are all in good shape and so that was our introduction to Cloud information okay let's take a look here at cdk so cdk allows you to use your favorite programming language to write infrastructure as code and technically that's not true because they don't have Ruby and that's my favorite but anyway uh some of the languages include NOS typescript Python java.net and so here's an example of typescript typescript was the first language that was um introduced for cdk It's usually the most uptodate so not always does cdk reflect exactly what's in cloud formation but I think they're getting better at that okay so cdk is powered by cloud formation it generates out cloud formation templates so there is an intermediate step it does sometimes feel a bit slow so I don't really like that but you know it's up to you uh cdk has a large library of reusable Cloud components called cdk constructs at constructs dodev this is kind of the concept of terraform modules and is really really useful uh and they're really well ridden um and they can just reduce a lot of your effort there CD cdk comes with its own CLI um and I didn't mention this before but cloud formation also has its own uh uh CLI okay cdk pipelines uh are are allow you to quickly set up cicd pipelines for cdk projects that has a big pain point for cloud formation where you have to write a lot of code to do this whereas um this cdk has that off the bat makes it really easy for you cdk also has a testing framework for unit and integration testing I think this might be only limited to typescript because I didn't see any for the rest of the languages but um you know I wasn't 100% sure there uh this one thing about cdk is that it can be easily uh confused with SDK because they both allow you to programmatically work with AWS uh using your favorite language but the key difference is that cdk ensures uh itap poent of your infrastructure so what that means that's such a hard word to say but what that means is that um you know if you use this cdk to say give me an a virtual machine you'll always have a single virtual machine uh because it's trying to manage the state of the file whereas uh when you use SDK if you run it every time you'll end up with more and more servers uh and it's not really managing States so hopefully that is clear between the difference there okay so we looked at cloud formation but now let's take a look at cdk cloud formation or cloud formation Cloud development kit it's just like cloud formation but you use a a programming language in order to uh Implement your infrastructure as a code I don't use it very often I don't particularly like it but um you know if you are developer and you don't like writing Cloud information files and you want to have something that's more programmatic you might be used to that um this I think should be deleting cuz we were deleting the last one here and notice how it's grayed out I can't select it so don't worry about that create a new one we'll say cdk example we'll hit next T2 micro ec2 instance Amazon X2 you know the drill it's all fine here we're going go ahead and create ourselves a new environment we're going to let that spin up there and as that's going we're going to look up uh adus cdk so it was cdk um and we probably want to go to GitHub for this okay because it is open source and so I want to go to getting started and I have used this before but I never can remember how to use it probably the easiest way to uh use this is by using typescript so here's an example initialize a project make directory cdk oh first we got to install it right so we give that a moment so this is you know how we did like bundle install this is like the same thing but for uh typescript install or update the itus cdk CLI from npm we recommend using this version etc etc so again we're just waiting for that to launch but uh as we wait for that it's very simple we're just going to install it create a directory um go into that directory initialize the example here it's setting up an sqsq which is um that's quite a complex example um but you can see it's code right and then we run cdk deploy and we'll deploy it and then hopefully we'll have that resource so again we're just waiting for Cloud9 there we go so Cloud9 is more or less ready a terminal seems like it's still thinking and we have a JavaScript one which I do not care about there we go there's our environment we're going to make sure we have mpm so we can type in mpm great it says version 8.1.0 and so this is asking for 10 okay I don't know if this gives us like MVM installed MVM it does so what we can do is do MVM list that stands for node version manager Ruby has one as well and so it's telling us what version we're on I want to update um looks like we have a pretty uh pretty new version but what I want is the latest version of oh but that's node version that's not necessarily mpm so we'll do node version Oh 17 okay we're well well in the uh range of the new stuff so what I'm going to do is scroll on down we're going to grab this link here or this uh code here hit enter and that's going to install the adus cdk so it says uh file already exists oh so maybe it's already installed in the machine um cdk we'll type in cdk because of course adus wants to make it very easy for us this soft has not been tested with what was that warning uh with node 1701 you may encounter runtime issues great AWS you're like the one that installed this stuff here so we get a bunch of the commands which is great and so what we'll do is follow their simple instructions we'll say hello cdk we will CD into this and um now what we can do is run cdk andit and this language here and so that's going to do a bunch of stuff creates tons of files it's going to vary based on what you're using like which language because cdk comes available in a variety of languages so if we type in ads cdk um documentation here notice up here python java.net so I think it has more than just those three languages but um you know I wish it supported more like yeah see here is C Java but I I really wish there was a ruby so we'll give this a moment here to get installed and I will see you back here when it is done okay okay uh it turns out I only had to wait like a second there but it says there's a newer version of the cdk you probably should install it but I just want to get going here so as long as I don't run into any issues I do not care um but anyway so looking at this and I again rarely ever look at this but I'm a developer so it's not too hard for me to figure out but under the lib this is our stack that we're creating and here is it is loading in sqs it's loading in SNS and then the core Library it's creating an sqs q and it's setting the visibility of that timeout it's also creating an SNS topic so those are two resources that we expect to be created if we scroll on down to the getting started it just says cdk deploy so what we'll do is go ahead and hit enter and let that do whatever it wants to do and it is thinking there we go so here we have IM statement changes so it's saying this deployment will potentially make potential sensitive changes according to your current security approval options there is there may be security related changes not in this list do you want to deploy sure we'll hit Y deploying creating Cloud information change set so cdk is using cloud confirmation underneath it's not complicated um and as that is going what we'll do is we'll make our way over to our itus amazon.com console and if we go over to cloud formation we'll see if we see anything yet so it's creating a stack here we can click into it we can go over to our events see that things are being created this is always a confusing so I always go to resources to see what is individually being created and they're all done so we go over here and they exist so here it says that we have a queue called this right sometimes they have links you can link through it so notice here I can click on the topic and get to that resource in SNS which is nice for sqs I'm just going to type in sqs enter uh and there it is okay so we don't really understand what those are we could delete the stack this way there's probably a cdk way to delete the stack so uh cdk destroy I assume that's what it is destroy okay so we'll type in cdk Destroy give it a moment we're going to say yes okay it's deleting in progress we can even go back here and double check still thinking and again you know if we deleted these for real it would take like a second but uh you know sometimes they're just slow sometimes it's because a resource can get hung as well um but uh I don't think anything is problem so here we can see what the problem is not not necessarily a problem but it's just the sqs is taking a long longer time to delete where the SNS subscription is a lot faster so I'll just see you back here in a moment okay okay so after a short little wait there it finally finished uh I just kept on refresh until I saw it deleted and so it's out of there and so we'll get rid of our Cloud9 environment since we are done with it so type in Cloud9 up at the top and we'll go ahead and delete and we will go ahead and delete this here thank you and we will go back to our adabs amazon. console here just so we can get our bearing straight here and there we go all right let's take a look here at the adus toolkit for vs code so adus toolkit is an open source plugin for vs code to create debug deploy itus resources since vs code is such a popular uh editor uh these days I use Vim but it's very popular um I figured I should make sure you're aware of this um plugin so it can do four things you get the Abus Explorer this allows you to explore a wide range of adus resources linked to your adus account uh and sometimes you can view them sometimes you can delete them it's going to vary per service and what's available there then you have the adabs cdk Explorer this allows you to explore your Stacks defined by cdk uh then you have Amazon elastic uh container service ECS this provides intellisense for ECS task definition files intell sense means that when you type uh and you uh you'll get like autoc completion but you'll also get a description as to what it is that you're typing out then there is servess applications and this is pretty much the main reason to have Theus toolkit allows you to create debug deploy Serv applications via S and CFN and so uh there you can see the command pallet and you can kind of access stuff there okay let's take a look here at access key so an access key is a key and secret required to have programmatic access to adus resources when interacting with the adus API outside of the adus Management console so uh access key is commonly referred to as adus credentials so if someone says adab credentials generally you're talking about the access key not necessarily your um username and password to log in so a user must be granted access to use access key so when you're creating a user you can just checkbox access key um you can always do this after the fact but it's good to do that as you're creating the user and then you can generate an access key and secret so you should never share your access keys with anyone they are yours if you give them to someone else is like giving them the keys to your house it's dangerous uh never commit access keys to a codebase uh because that is a good place uh for it to get leaked at some point you can have uh two active keys at any given time you can deactivate access Keys obviously delete them as well access Keys have whatever access a user has to Aus resources so uh you know if you can do it in databus Management console so can the key so access keys are to be stored in the ads. adabs credentials uh file so um and if you're not familiar with Linux this Tilda here this actually represents your home folder so whether you're on Windows or Linux that's going to be your home folder and then you have this period AWS that means it's hidden folder but you can obviously access it and so in it it's just a toml like file I think it's toml um but I never 100% verified that it's toml it looks just like toml uh and so what you'll have here is your uh default profile and so this is what you would use um or this is what uh any of your tools you use like the CLI or anything else would automatically use if um if you did not specify a profile you can of course store multiple access keys and then give it a profile name um so if you are doing this for the first time you might just want to type in ad config and it'll prompt you and you'll just enter them in there as well I think that's set the default one when you're using the SDK uh you would rather probably use environment variables because this is the safest way to access them when you are writing code all right um so there you go all right let's talk about access Keys access keys are are very important to your um and so what we'll do is go to IM if you are the root user you can go in and you can uh generate access keys for people um but generally you're doing it yourself for your own account so I go to users I'm going to click into mine here and we'll go over to Security credentials and here you're going to notice access keys and one thing that is interesting is that you can only ever have two access keys at a time so if I hit create I'm just going to close that notice that the button is gray out I can uh uh deactivate them if I feel that I haven't used them in a while and I can make them active again so I can bring them back into access or what I can do is um make them inactive right and then I can delete them and so what I recommend right even if you do not want to programmatically be using your account for anything you always want to fill up both these and the reason why and this is for security reasons is that if somebody wanted to come in and uh uh get into your account what they would do is they would try to find find a user um where they have access to them and then they would try to generate out a key so if both these keys are taken up so if you generate up both these Keys okay and this is the one you want to use you deactivate the other one okay we're not going to use that one and so now there's no way for them to fill up that other slot okay and so that is my strong recommendation to you but there's again only ever two here I'm just going to uh Delete both of these so that when we want to uh do what whatever next in a tutorial we'll go generate that out okay go ahead and clear that out so hopefully that is enough for you to understand what to do with these access Keys okay so I'm going to go back here there you go let's take a look here at adus documentation which is a large collection of technical documentation on how to use adus Services which we can find at doc. adab. amazon.com uh and so this is kind of like the landing page where you can see all the guides and API references if you expand them in there uh into ec2 and you click on the user guide you can see HTML in PDF format Kindle and you'll notice there's a link to GitHub and that's because all of these docks are open source and you can contribute to them if you choose to do so I've done so multiple times in the past it's quite fun so adus is very good about providing detailed information about every ad service and the basis of this course and any AD certification will derive mostly from uh the adus documentation so I like to say that I'm not really coming up with new information I'm just taking what's in the docs and trying to make it more digestible and I think that's the thing is like the docks are really good you can read them end to end but they are very dense um and so it can be a bit hard to figure out what you should read and what you should not um but uh they are a really great resource and you should spend some time in there okay so I just want to quickly show you the ads documentation like give you a bit of a tour of it so if we go to ab. amazon.com and type in docs and I'm sure you might have seen this through other tutorials but the idea is that you have basically documentation for basically any possible service that you want and a lot of times you'll click into it and what you'll get are these little boxes and they'll show you different guides and it's going to vary based on service but a lot of times there's a user guide there's an API reference those are the two that you'll see there maybe we go to something simpler like S3 that might be a simple example yeah user guide API API reference and so all of these are on GitHub right if you open these up the documentation is here if you find something you don't like you can submit issues and uh and correct things you can even submit your own examples I have um I have uh committed uh example code to the uh docs specifically for AI services so you might be looking examples that I implemented or even Ruby examples since I really like to promote Ruby on AWS you can as a PDF or you can take it as an HTML a lot of times you're going to the user guide and the way I build the courses here is I actually go through and I read these end to end so you know if you wanted to do that and you wanted to be like me uh you can do that or you can just watch my courses and save yourself the trouble and not worry about everything that is here but generally the documentation is extremely extremely good there are some exceptions like Amazon Cognito where the content is good but it's just not well organized so I would say it best out of every other provider they they have the most complete documentation uh they generally don't keep their examples or like tutorials within here it's usually pretty light they'll have some examples um but like they like they have adus Labs separately so you type Aus Labs GitHub right you go here and a lot of stuff is in here instead so you have a lot of great tutorials and examples over there okay um but yeah pretty much that's all there is to it is there consistency between documentations no they kind of vary um you know but uh it's all there is my point and they're always keeping up to date so yeah that's all you need to know about the inabus documentation hey this is Andrew Brown from exam Pro and we are taking a look at the Shared responsibility model which is a cloud security framework that defines the security obligations of the customer versus the cloud service provider in this case we're talking about AWS and they have their own shared responsibility model it's this big ugly blob here um and the thing is is that every single CSP has their own variant on the model uh so they're generally all the same but some visualizations make it a little bit uh easier to understand or they kind of uh include a little bit more information at different parts of it and so just to get make sure that you have well rounded knowledge I'm going to go beyond the aws's shared responsibility model and just show you some variants uh there's also variants not just per uh CSP but also the type of cloud deployment model and sometimes these are also scoped uh based on a cloud service category like compute or machine learning and these can result in specialized share responsibility models so that's what we'll look at in this section okay all right so let's take a look at the ad shared responsibility model and so I've reworked the graphic because it is a bit hard to uh digest and so I'm hoping that this way will be a little bit easier for you I cannot include the in and of here just because we're limited for space but don't worry we'll follow that up with the next slide here so there are two people that are responsible or two um organizations that are responsible the customer and AWS and on aws's side they're going to be responsible for anything that is physical so we're talking about Hardware Global infrastructure so the regions the availability zones The Edge locations the physical security so think of all that Hardware that's there those data centers um everything like that then there's also software the services that they're offering and so um you know this extends to all their services but generally it breaks down to the four core and so we're talking about Compu storage database and networking okay and when we say networking we're talking about like physically setting up the wires and also you know the software to set up the routing and all that kind of stuff there uh now looking at the customer side of it they're responsible for configuration of managed services or thirdparty software so the platforms they use so whether they choose to use a particular type of os uh the applications so if they want to use like Ruby on Rails uh am so identity and access management so if you uh create a user and you grant them permissions if you give them things they're not supposed to have access to that's on you right then there's configuration of virtual infrastructure and systems so that would be choosing your OS that would be uh the networking so there could be networking on the um uh the virtual machines themselves or we could be talking about Cloud networking in this case then there are firewalls so we're talking about virtual firewalls again they could be on the virtual machine or it could be configuring like knackles or security groups on AWS then there's security config ation of data uh and so there is client side data encryption so if you're moving something from S3 from your local machine to S3 you might need to encrypt that first before you send it over then there's server side encryption so that might be turning on server side encryption within S3 or turning it encryption on your EBS volume then there's networking traffic protection so you know that's turning on VPC flow log so you can monitor them turning on it was guard Duty so that it can detect anomalies with your traffic or or activities within your um adus account and then there's customer data so that's the data that you upload on the behalf of your customers or yourself and what you decide to um you know like what levels of sensitivity that you want to lock it down do you want to use Amazon Macy to see if there's any public facing uh personally identifi information that's up to you so there's a lot here and honestly it's a lot easier than you think um instead of thinking about this big diagram what I do is I break it down into this and so we have the in and the of and that's what I said I could not fit on the um previous slide there the idea is customers are responsible for the security in the cloud so that's your data and configuration so if it's data that's resigning on there or there something you can configure you are responsible for it on the ad side they are responsible for the security of the cloud so if it's anything physical or Hardware the operation of managed services or Global infrastructure that's going to be on them and this in and of thing is very important for the exam so you should absolutely know the difference between the two this is kind of an adist concept I don't see any other cloud service provider talking about in and of uh so you definitely need to know it okay so one variant we might see for the uh shared responsibility model would be on the types of cloud computing this could also be applicable to the types of uh deployment models but we're doing types of cloud computing here and so we have the customers responsibility and then the cloud service provid responsibility so we're seeing on premise infrastructure as a service platform as a service and software as a service and so when you are on Prem you're basically responsible for everything apps data runtime middleware OS virtualization servers storage networking basically everything and just by adopting the cloud you're almost cutting your responsibilities in half here so now the cloud service provider is going to be responsible for the physical networking uh the physical storage those physical servers and because they're offering virtual machines to you they're setting up a hypervisor uh on your behalf so virtualization is taking care for you and so um you know if you launch an ec2 instance you know you're going to have to choose the OS so that's why you're responsible whatever middleware there the runtime so whatever kind of programs you install on it uh the data that resides on it and any kind of like major applications okay then we have platform as a service uh and so you know the cloud service provider is going to take even more responsibility there so when we're talking about this we're thinking like a elastic beant stock right so you know the you just choose what you want and it's all managed so you might say I want a ruby on rail server but you're not saying what OS you need um you're not uh saying exact you might say what version of Ruby you want but you don't have to manage it if it breaks uh or it might be managed updates and things like that the last thing here is like software as a service and this is something where the CSP is responsible for everything so if you're thinking of a of a software as a service think of like Microsoft Word where uh you're just writing uh you know writing stuff in there and you know you you are responsible for where you might choose to store your data but the data is like still handled by the cloud service fider because you know it's on the cloud so on their servers right um so yeah hopefully that gives you kind of an idea across types of cloud U Computing responsibilities all right so what I want to do here is just shift the lens a bit and look at the share responsibility model if we were just uh observing a subset of cloud services such as compute and so we're going to see infrastructures of service platform as a service software as a service and now we have function as a service and so that's what I mean when we shift the lens we get new information uh and so you can just see that you really don't want to look at this uh from one perspective okay so starting at the top here we have bare metal uh and so ad's offering is called the ec2 bare metal instance and this is where you basically get the whole machine uh you can configure the entire machine with with the exception of the physical machine itself so as the customer you can install the host OS um uh the host OS so the operating system that runs on the physical machine and then you can install your own hypervisor um and then Aus is going to be responsible for the rest the physical machine now normally The Next Step Up would be dedicated but dedicated doesn't exactly give you more responsibility it gives you more Assurance because it's a single tenant uh virtual machine and that's why I kind of left it out here um but we'll see it in the next slide that it is kind of on the model and shares the same spot as uh ec2 um but ec2 is a virtual machine and so um here the customer is responsible for the guest OS so that means that you can choose what OS you want whether it is Ubuntu or Debian or Windows but that's not the actual OS that is running on the the physical machine and so you're not going to have control of that ads is going to take care of that then there's the container runtime so you know you you can install Docker on this or any kind of container layer that you want um so that's another thing that you can do so ads is going to be responsible for the hypervisor uh the physical machine and the host OS all right then looking at containers it has more than one offering for containers but we'll just look at ECS here and so um this is where you are going to uh have uh you don't you don't install the guest OS right the guest OS is already there for you what you are going to do is choose your configuration of containers you're going to uh deploy your containers you're going to determine where you need to access storage for your containers or attach storage to your containers and databus is going to be responsible for the guest OS it it the and there might not even be a guest OS but there the host OS the guest OS the hypervisor the container runtime uh and you're just responsible for your containers okay then going to the next level here we have platform as a service and so this one also is a little bit odd where it fits um because the thing is is that this could be using anything underneath it could be using containers it could be using virtual machines um and so that's where it doesn't exactly fit well on a linear graph but let's just take a look at some things here so this is where you're just uploading your code uh you have some configuration of the environment you have options of deployment strategies um the configuration of the associated services and then Abus is going to be responsible for the servers the OS the networking the storage the security so it is taking on more responsibility than infrastructures a service um uh whereas you know itus is just going to be responsible for that so if it's a virtual machine that it's being under uh under the use the is going to be responsible for this customer stuff okay you're not if it's containers then AIS is going to be responsible for this but it just depends on how that platform as a service is set up actually the way elastic beanock is set up is that you actually have access to all that infrastructure and you can fiddle with it and so in that case um whereas like if you were to use Heroku which is a a third party provider um you know they would take care of all this stuff up here um and so you would not have to worry about it but on AWS you actually are responsible for uh the underlying infrastructure because you can you can configure it you can touch it so that's where you know again these do not fit perfectly you can't look at platform as a service meaning that um you're not responsible for certain things it really comes down to the service offering okay then we're taking a look at software of service so on AWS um this is going to be something like um Amazon workdocs which is I believe a competitor uh not a very popular competitor but a competitor to Microsoft SharePoint and this is for Content collaboration so as the customer you're responsible for the contents of the document management of the files configuration of sharing access controls and the databas is responsible for the servers the OS networking the the storage the security and everything else so you know if you use a Microsoft Word Doc and you type stuff in it you say where to save it that's what you're responsible for okay the last one here on the list is our uh functions here and so ad's offer is itus Lambda and so as the customer all you're doing is you're uploading your code and itus is going to take care of the rest so deployment container runtime networking Storage security physical machine basically everything um and so you're really just left to uh develop okay so you know hopefully that gives you kind of an idea and again you know we could have thrown in a a few other services like what we could not fit on this slide here was um uh adus fargate which is a serverless container as a function or sorry serverless uh serverless container as a service or container as a service so uh you know that has its own unique properties in the model as well okay so let's just have kind of a visualization on a linear graph here so we have the customers's responsibility on the Le hand side and adus is responsibility on the right and we'll look at our broad category so we got bare metal dedicated virtual machine Mach containers and functions and so no matter uh which uh type of compute you're using you're always responsible for your code for um containers you know if uh you know like uh the functions when you're using functions there are prebuilt containers so you say I want to use Ruby and there's a ruby container and you don't have to configure it but obviously um you know when you are using container service you are configuring that container you are responsible for it for um virtual machine you know you're responsible for the runtime so you can install a container runtime on there or install a bunch of different packages like Ruby and stuff like that uh the operating system you have control over in the virtual machines for the dedicated and we saw with bare metal you have both uh controls of the host OS and the guest OS and then only bare metal allows you to have control of the virtualization where you can install that hypervisor so hopefully that gives you an idea of compute and A's offering there and also kind of how there's a lot of little caveats when we're looking at the Shared responsibility model okay all right so I have one more variant of the share responsibility model and this one is actually what is used by Google so um we're going to apply to AWS and uh see how it works so let's just kind of redefine share responsibility model or just in a slightly different way so we fully understand it so the share responsibility model is a simple visualization that helps determine what the customer is responsible for and what the CSP is responsible for related to AWS and so across the top we have infrastructure as a service platform as a service software as a service but remember there's other ones out there like functions and service it's just not going to fit on here um okay so and then uh along the side here we have content access policies usage deployment web application security identity operations access and authentication network security remember that's Cloud networking security the guest OS data and content audit logging now we have the the actual traditional networking or physical networking storage and encryption and here we're probably talking about the physical storage hardened kernel IPC uh the boot the hardware and so then here we have our bars so we have the csp's responsibility and the customer responsibility so when we're looking at a SAS software as a service uh the customer is going to be responsible for the content remember like think of like a word processor you're writing the content the access policies like say I want to share this document with someone the usage like how you UTI it can you upgrade your plan things like that then next on our list here is platform as a service so generally uh you know platform is a services for developers to De develop and deploy applications and so they will generally have more than one deploy strategy and uh you know there might be some costsaving measures to choose like uh you might have to pay additional for security uh or you it's up to you to configure in a particular way or you might have to integrate it with other services uh and you know we saw that pass is not a perfect uh definition or fit because you know when we look at elastic bean stock if you have access to those resources and you can change them underneath then you might have more responsibility there than you think that you would okay the next one here is infrastructure the service and so this is extending to Identity so who's allowed to uh you know log into your adabs account uh operations the things that they're allowed to do in the account access and authentication do they have to use MFA uh things like that networ security obviously you can configure the security of your uh Cloud infrastructure or Cloud Network um you know so you know do you isolate everything a single VPC how do you set up your security groups things like that uh we know with virtual machines you can set up the guest OS there's data and content but remember that bare metal is part of the uh infrastructure service offering and so that's where we'd see Hardware or not Hardware but you'd have the host o the host Os or virtualization and so this again is not a perfect representation uh but it generally works okay and then last and list there um or just looking at what the ads is responsible for auto logging so of course adus has cloud trail which is for uh uh logging uh API um events but Auto logging could be things that are uh internally happening with those physical servers then the networking the physical storage uh Harding the kernel ad of us has I think what's called the Nitro system where they have like a security chip that's uh installed on all their servers then it's the the boot OS uh and then the hardware itself okay so just remember the customer is responsible for the data and configuration of access controls that reside in AWS so if you can configure it or you can put data on it you're responsible for it okay the customer is responsible for the configuration of cloud services and granting access to users via permissions right so if you give uh one of your employees access to do it um you know even if it's their fault it's your fault so remember that um and again the CSP is generally responsible for the underlying infrastructure we say generally because you know there's edge cases like bare metal and coming back to adses in the cloud and of the cloud so in the cloud so if you configure it or store it then you the customer are responsible for it and of the cloud if you cannot configure it then the CSP is probably responsible for it okay hey this is Andrew Brown from exam Pro and we are looking at the share responsibility model from the perspective of architecture and if you're getting sick of share responsibility model don't worry I think this will be the last uh slide in this section but let's take a look here so uh we have uh less responsibility more responsibility at the bottom so what we have down here is traditional or virtual machine architecture so Global Workforce is most familiar with this kind of architecture and there's lots of documentation Frameworks and support so maybe this would be using elastic beanock with platform as a service or using ec2 instances alongside with Auto scaling groups uh code deploy uh load balancers things like that the next level here is microservices or containers this is where you mix and match languages better utilization of resources so maybe you're using fargate which is seress containers or elastic container service or elastic kubernetes service for containers and at the top here we have serverless or commonly with functions as a service so there are no more servers you just worry about the data or uh and the code right so literally just functions of code and so you could be using the amplify serus framework or maybe aess Lambda for creating servess architecture so there you go hey this is Andrew Brown from exam Pro and we are looking at Computing Services and before we jump into uh the entire Suite of Computing Services they us have let's just talk about ec2 for a moment which allows you to launch virtual machines so what is a virtual machine while a virtual machine or VM is an emulation of a physical computer using software server virtualization allows you to easily create copy resize or migrate your server multiple VMS can run on the same physical server so you can share the cost with other customers so imagine if your server or computer was an executable file on your computer okay so that's the kind of way you want to think about it when we launch a VM uh we call it an instance and so ec2 is highly configurable server where you can choose the Ami so the Amazon machine image that affects options such as amount of CPUs or vcpus virtual CPUs the ount of memory so Ram the amount of network bandwidth the operating system so whether it's Windows Ubuntu Amazon L 2 uh the ability to attach multiple virtual hard drives for storage so elastic Block store um and so the Amazon machine image is a predefined configuration for AVM so just remember that and so ec2 is also considered the backbone of ads because the majority of AD services are using uc2 as the underlying servers whether it's S3 RDS 10B or lambdas that is what it's using so um what I say also it's just because when we talk about the it Network that is the backbone for uh Global infrastructure uh and the networking at large and so ec2 is for the services okay hey this is Andrew Brown from exam Pro so we just looked at what ec2 is well let's look at more of the broader services for computing and these are the more uh common ones that you'll come across there's definitely more than just what we're going to see on this single slide here so we'll break this down with virtual machines containers and then serverless for for virtual machines remember that's an emulation of a physical computer using software and ec2 is the main one uh but for our VM category we have Amazon light sale this is a manage virtual server service it is the friendly version of ec2 virtual machines so when you need to launch a Linux or Windows server but you don't have much Aus knowledge you could launch a WordPress here and uh you could hook up your domain and stuff like that um so this is a very good option for beginners we have containers so virtualizing an operating system or Os to run multiple workloads on a single OS instance so containers are generally used in microservice architecture when you divide your application into smaller applications that talk to each other so here we would have ECS elastic container service this is a container orchestration service that supports Docker containers launches a cluster of servers on these two2 instances with Docker installed so when you need Dockers a service or you need to run containers we have elastic container registry ECR this is a repository of container images so in order to launch a container you need an image an image just means a save copy a repository just means a storage that has Version Control we have ECS fargate or just fargate now people are kind of forgetting that it's it runs on ECS these days that's why I have it in there it is a serverless orchestration container service is the same as ECS ex except you pay pay on demand per running container so with ECS you have to keep a ec2 server running even if you have no containers running so it manages the underlying server so you don't have to scale or upgrade the ec2 server so there's the advantage over ECS okay then we have elastic kubernetes service eks this is a fully managed kubernetes service kuber or so kubernetes commonly abbreviated to K8 is an opensource orchestration software that was created by Google is generally the standard for managing microservices so when you need to run kubernetes as a service then we have serverless category so when the underlying servers are managed by Deus you don't worry or configure servers cus Lambda is a serverless function service you can run code without provisioning or managing servers you upload small pieces of code choose much uh how much memory how how long you want the function to run is allowed to run before timing out and you are charged based on the runtime of the Serv function rounded to the nearest 100 milliseconds so there you go hey this is Andrew Brown from exam Pro and what I want to do is just show you a variety of different Computing Services on AWS so I'm going to try to launch them and uh we're not going to do anything with them just going to Simply launch them okay so the first I want to show you is ec2 and by the way we will go more in depth in ec2 later on in this course here um but what I'm going to do is go ahead and launch the instance don't worry about all this stuff but just choose the Amazon Linux 2 so it's in the free tier all right we're going to choose an instance type of a T2 m so that's part of the free tier it's going to be set as one all these options are fine I want you to go ahead and review and launch we're going to launch and I don't want to generate any key pair I'm going to proceed without a key pair I'm going to acknowledge that because I don't want it and that's all there is to launching an ec2 instance and so I can go here and view my instances and what you'll see is it's pending okay and usually it has like a little spinning icon maybe they've updated it since then so I go here it's hard to see because there's all these terminated ones but I don't need to do anything with it I just wanted to show you the actions that you'd have to do to launch it actually we'll leave it alone maybe we'll see it when it's launched the next one I want to show you is e elastic container service um and wow this this is old let's go let's get the new experience please so old okay checkbox that on and we'll hit get started and we'll say create a cluster and we have some options here networking only ec2 Linux plus networking uh for use with either ads fargate or external Windows um uh this is if you're doing fargate which we're not doing right now fargate is part of elastic container service it used it well used to be it is called ECS fargate but it us markets it as a separate service we'll go to next and say my ECS cluster um we can create an empty cluster but that would make it a fargate cluster which we don't want there's an ond demand server look it's M6 I large if you're very afraid of a lot of spend here you don't have to do this you can just watch me do it and just learn well what I'm going to do is try to find something super cheap so I want a T2 micro or a T3 micro T2 micro is part of the uh free tier I don't know if we get to choose T2 anymore in here they might not let you there it is you know T3 mro is great too I just whatever says it's free that's what I'm going to go for number of instances one the Amazon version is fine I don't care about a key pair uh use the existing VPC I don't want to have to make a new one select the existing ones okay uh let it create a new security group that's totally fine allow those to be fine create a new role that's fine create okay and so that's going to create ourselves a cluster um I'm going to just make a new tab here let's just check on our ec2 instance and so if we look at our ec2 instance it is running okay great so it has a private IP address it has a public IP address all right um there's not much we can do with it I can't even log into it because we didn't generate out a key pair times you want to name these things so I just go here and name it my server okay go back to our ECS instance and the cluster is ready so we'll go here and oh nice we got a new UI and so if we wanted to deploy something as a service or a task um we would need to create a template like a task definition file uh they don't have a new UI for this you're being redirected to the previous version console because this isn't available in the new experience yet of course it isn't so we can create a new task definition file that's what's used to run it it's basically like a Docker file composed file whatever you want um we have fargate or ec2 we are doing ECS so we're going to have to do ec2 so we'll say my ECS yes uh task def file um task roll opt optional IM roll I don't need one network mode I don't care um and then this is the idea is that because a container allows you to use up a particular amount of the um thing we don't have to use all of the memory so we should look up what a T2 micro is because I don't even remember what size it is okay T2 micro AWS so we go here we look at the instance types and we're going to flip over to T2 and it says that it's one vcpu one gigabyte of memory so what I'll do one yeah one okay that's fine so what we want and this is in megabytes so we'll say 500 megabytes and um I don't know if we can do less than one but I'm going to do one here um the task CPU must be an integer greater than or equal to 128 okay fine 128 oh I guess it's 1024 would utilize the whole thing so I could say 512 okay and this is where we would add our container so I don't do this every day so I don't remember how to do this we'll say my container um and I need a repository here so I need like dockerhub Hello World okay I don't care what it is I just need a image that's simple and I'm looking for the address here um I'm hoping that's just this dockerhub URL so it' be something like this right docker.io probably Docker IO Docker image um Docker Hub URL in ECS okay it goes to show how often I'm laun launching these things so repository URL Docker image so I think that what we're going to do here I would really just like the URL please reviews tags where is it where is it it's somewhere here right uh uhuh uh well let's just try it we'll go and we'll type in says image and tag so docker.io hello world I really need an image ID image URL hello world dockerhub they're not making my life easy here today anything I just want to see like a single example docker.io Docker iio URL examples ECS this is what it's like you know this is what you're going to be doing if you are um you know a cloud engineer you're going to be Googling a lot and just trying to find examples here so here it says docker.io the name the host name okay so we'll just try it okay so I think that the the the name here is underscore and then it's hello world and that's what's throwing me off here right docker.io just hold on here repositor URL and then there's the tag I don't know if like is the tag going to be like latest view available tags latest okay so what I'll do here and that's the thing you got to have a lot of confidence to too so hard limit soft limit um do I have to set it do I have to set any of these things can I just go to the bottom and hit add looks like I can okay so we'll scroll on down create we create our task definition file which is fine we're going to go back to our cluster it's going to bring us back to the new experience we're going to click into this cluster holy smokes uh we're going to hit deploy and and we are going to choose service that means it's going to continuously run task means that when it's done running it ends we're going to choose our family our version that's the task definition file there is not compatible with the selected compute strategy my task file what if I just choose task take that okay some maybe some you have to like code it so that it continuously runs I don't care we don't need to run a service here the selected task definition is not compatible with the selected compute strategy okay let's see why uh can you double check if you're using fargate strategy instead of the ec2 uh blog designed for the ec2 strategy so probably what it's suggesting is that the the strategy file I made is not for the right one here task definitions go back over here well what's wrong with it task roll none my container so what I'm going to do because I don't trust this just going to go ahead and delete this can I delete this how do I delete this oh boy actions deregister deregister we'll create a new one and so it has tools like it was copilot um CLI to make this a lot easier because you can see this is very frustrating but I chose this so my task def requires compatibility of ec2 default 512 512 add container we're going to uh was it docker.io uncore what's it called hello world latest I we'll just say hello world here and we'll just say uh 512 which is fine I don't care about any port mappings I'm just reading it carefully here to see what it wants we'll say 512 maybe because I didn't specify them it's complaining this looks fine we'll hit add okay constraints type this all looks fine so we'll try this again and so we now have our file let's see if we can just run this task from here you see2 this is just another way to do it so we just choose the cluster this is actually a lot easier to do it this is old old old Eh this is ugly and so now it launches so you know if you have trouble one way then just do it another way and uh sometimes it'll work here so I don't expect this task to really work in any particular way if it's pending that's fine if it fails that's fine if it's successful that's fine I don't care I just want to go through the motion so it was successful it it ran and then it stopped I don't know if we could see like the output anywhere probably what it would do is it would log out something like into somewhere and so I don't know if like there's logs turned on for this if I go over to like cloud watch logs maybe I could see something a lot of these services will automatically create cloudwatch logs so sometimes you can just go look at them there so we'll drop down we'll go to log groups here there is some stuff here um there's a couple that I created from before just go ahead delete those and so what I'm looking for is like ECS so no there's no logging happening here which is totally fine so that is ECS um for fargate it's pretty much uh the the same the difference is that fargate is like it has to start up and run so it's a lot slower to watch okay and now let's go take a look at a Lambda okay so this is our serverless compute so we go ahead and create ourselves a function uh we can start from a blueprint that doesn't sound too bad and I personally like Ruby so no not getting much here but we can do is look for something that do we have like a hello world there we go hello world and we'll click that we'll say my hello world uh it's going to create those permissions that's fine it's showing us the code it's very simple okay it's going to console log out these values not a very good hello world function doesn't even say hello world how can you call it a hello world function if it doesn't say hello world I don't understand so we're going to go ahead and create this function usually doesn't take this long okay so uh here is our function here is our code notice that this is cloud9ine okay and you can even move that over to Cloud9 they didn't have this button here before that's kind of cool I hit test they used to have it up here but I guess they wanted to make it more obvious so they moved it down here which is nice so what I can do is hit this oops my test it's going to send a payload here to the actual function uh and it's going to tell us if it works okay so can I run my test go over here to test they changed it a bit so I guess I created there it succeeded so I have my logs okay so it's it's going to Output those values there so there are the three values which basically is nothing maybe you were supposed to set those an environment variable but you can see you're just uploading uh some code right it's just a bit of code it's not like a full app or anything so we launched an E2 container we did a a um sorry ec2 instance a container we did a seress function there's other things like eks but that is really really hard to set up okay because uh you'd have to use like kubernetes commands and stuff like that and my kubernetes knowledge is always very poor um I'm just taking a peek here to see if they've updated it so yeah you create the cluster but like deploying it is forget it I'm just trying to think if there's anything else I kind of want to show you um no those are the main three I would say so I'm pretty happy with that um what I'm going to do is go and kill all these things so we're going to go over to Lambda okay and I'm going to go ahead and delete this as you saw ECS was the hardest and no matter how many times I've built things on ECS and I've deployed full things on ECS I can't remember I always have so much trouble with task definition files it's unbelievable we'll go over to our cluster here and ECS cluster up here make sure you're not in the fargate cluster I know I'm clicking really fast but there's just so many things to click and I'm going to click into this cluster we're going to go hit edit because this is running an ec2 instance right I need to destroy it um it just took me back to the old one here um I want to delete no I want to delete the cluster click back here where do I delete it up here here I can't checkbox anything uh how do I delete this do I have to delete the task first maybe so we'll go here I mean it's already stopped there's nothing to do edit uh huh account settings wow this is confusing okay how to delete ECS cluster got to be kidding me I have to actually look this up so open the SS console from navigation in the navigation choose clusters and the new turn off the E uh turn off new ECS experience and choose the old console the delete cluster workflow is not supported in the EC ECS console are you serious then why why do you have it like why even let people use the new experience if that you don't have all the functionality there um oh I was going to give it feedback but it didn't let me here it says uh I need to delete an ECS cluster no okay so I'm here there's my big ugly cluster delete cluster okay so yeah it it's a struggle okay like things are always changing on me but uh you just have to have confidence and if you've done it a few times you know that can do it right um and that's one of the biggest HangUps to Cloud I would say so it's going to take a few minutes apparently to delete the cluster as that is going let's go over to ec2 I didn't close it I kept this tab open and uh there's our ec2 instance we can go ahead and terminate that instance terminate okay and if this says it's terminating then we're in good shape Terminator shutting down that's fine and notice here that's the ECS instance just make sure you shut down the my server not the um the ECS instance cuz that's going to stop and so this is already terminated but if we go back here notice that it says that it's not done but it clearly clearly has shut down okay so I'm going to wait here for a bit even though I know it's been deleted maybe it's deleting things like the auto scaling group so we go down below here right so that's probably what it's doing it's probably trying destroy the Autos scaling group but it doesn't show any here so it must have already destroyed it yeah so task Services delete so I'll be back here in a bit but I know it's safe it's already deleted but I'll see you back here in a bit okay so I waited literally a second and it's now deleted so we deleted our Lambda we deleted our oh did we delete our Lambda good question now I'm not really worried about the Lambda because I guess we did but I'm not really worried about it because um you know at when it rests at idle it's not costing us anything where the ECS and the ec2 are backed by ec2 instances so we do have to shut those down okay and again remember make sure you're in the correct region sometimes that gets flipped over and then you think those resources are gone but they're actually not they're just running in another region so uh there you go hey this is Andrew Brown from exam Pro and we're taking a look at higher performance Computing Services ons so before we do we got to talk about the Nitro system so this is a combination of dedicated hardware and lightweight hypervisor enabling faster Innovation and enhanced security all new ec2 instant types use the nitro system and the Nitro system is designed uh by AWS okay so this is made up of a few things we have Nitro cards these are specialized cards for vpcs EBS instant storage and uh controller cards you have Nitro security chips these are integrated into the mother board protects Hardware resources and we have the Nitro hypervisor this is the lightweight hyper visor memory and CPU allocation bare metal like performance there's also uh Nitro enclaves but you know that's a bit out of scope here but that's has to do with like ec2 isolation Okay uh then we have bare metal instances so you can launch ec2 instances that have no hypervisor so you can run workloads directly on the hardware for maximum performance and control we have the M5 the R5 um E2 instances that can run bare metal there's other ones I believe I've seen as well but um you know if you are running bare metal you can just go investigate at the time of okay we have bottle rocket this is a Linux based open source operating system that is purpose built by adus for running containers on VMS or bare metal hosts then uh let's just Define what HBC is so it's a cluster of aund of thousands of servers with fast connections between each of them with the purpose of boosting Computing capacity so when you need a supercomputer to perform computational problems too large to run on a standard computer or computers or would take too long this is where you know HBC comes into play one solution here is adus parallel cluster which is uh an ad supported open source cluster management tool that makes it easy for you to deploy and manage high performance Computing HBC clusters and AWS so hopefully that gives you an idea of this stuff okay all right so let's take a look at HPC or high performance computer Computing on AWS so HPC is for running large complex simulations and deep learning workloads in the cloud with a complete Suite of high performance Computing product Services gains Insight faster and quickly move uh from idea to Market blah blah blah blah blah it's for ML or very complex scientific Computing stuff these run at least on C5 NS okay and the way it works is that you use this um CLI called P cluster or aess parallel compute U or aess parallel cluster stuff and so let's see if we can get get this installed very easily um so what I'm going to do is see how hard it is to install now I don't recommend you running this because I don't know what it's going to cost me and if I make a misconfiguration I don't want you to have that spend here but I don't think it's that dangerous so I'm going to go back over to us East one here I'm going to open up cloudshell and I'm going to give it a moment to load and so as that is loading let's take a look at how we would go ahead and install this so install the current parallel um it was parallel I think we just copy that line okay and so we have to wait for our environment to spin up all right so once it has spun up we will install it and then we will jump over to this tutorial here okay so we'll give this a moment and after waiting a little while here it looks like our shell is ready it looks like it's in bash um I'm just going to type in S3 LS that's a sanity check okay and it works that's great so we go back over here and I'm going to go back up to install for Linux and what I need is that single command where is it so I'm certain that we already have Linux or python installed but I just want the command to install it you saw it a moment go here I'm just going to back out till I can find it uh one more there it is so it's under oh it's this link here and that's what I talk about the documentations being tricky sometimes you have to click these uh headings here to find stuff so this is the first time installing it so we'll grab that usually you're supposed to create in Virtual environments with python I don't care this is my cloud shell it doesn't matter to me so we're going to go ahead and download that and hopefully it is fast and it was super fast which was really nice and so what we'll do is go check out the P cluster version okay and that looks fine to me I'm going to go down below here to run our first job um the returns the it gives outputs I don't think we need to configure it because we already have our CLI so what I'm going to do is go ahead and create ourselves a new cluster um beginning cluster creation configuration file config not found so I guess we do have to configure this configure and it's asking what region do we want to be in um if I have us East one I would choose it for some reason it's all the way for number 13 that is not a lucky number but I'm going to choose it anyway anyway no key pair found in Us East one region please create one of the following um so create an ec2 key pairs uh no options found for ec2 key pairs that's fine so what what I'll do is go over here and we'll go over to ec2 and we will go over to key pairs key pairs key pairs key pairs we'll create ourselves a new one here so say um HPC key pair or just my HPC so we know what it is for we have putty or PM we're going to do pem because we're on Linux we'll create that and notice that it downloaded the pem down down here and we're going to need that for later um and so what I'll do is I'll type in P cluster here again configure we'll choose 13 we'll choose number one here uh allowed values for the scheduler I have no idea what these are uh let's choose the number one allowed values for the operating system Amazon L 2 I know what that is minimum cluster size one maximum cluster size two head notice instance oh T2 micro you can do that yeah let's do it I didn't know we could do that enter compute type uh T2 micro sure so I thought that we'd have to use a c5n but I guess apparently not automate VPN uh VPC creation yes of course network configuration so allow values for the network configuration uh head node in a public subnet and and compute Fleet in a private subnet uh head node and compute yeah we'll do it in the both just to make our lives easier I don't care first one sounds more secure of course and so oh it's creting Cloud information sack wow this is easy I thought this was going to be super painful okay so we'll go over here we'll go take a look at what cloud formation's doing all right now I don't care if we actually run a task on here but it was just interesting to go through the process to see how hard it was and we will go look at what resources are being created so it's creating an internet gateway so it's literally creating a isolate VPC for it which is totally fine I guess um it's creating a subnet creating a route table refresh here um I'm not sure how much it wants to create here it just looks like VPC that's all it's creating I thought maybe the ec2 instances would show up here but maybe it's going to launch that on a need B basis okay so that's all created oh now it's doing a VPC Gateway I think VPC gateways cost money let's go take a look here VPC pricing yeah there's a uh transfer fee so just be careful about that you know again you can just watch along here you don't have to do it default route depends on public so now it's creating ec2 route I don't know what an ads ec2 route is I've never seen that before sometimes what we can do is go into ec2 and then take a look on the left hand side you see anything in here we don't know what it is we just type in ec2 route cloud formation sometimes cloud formation is great for figuring out what a component is not all components are represented in the um inabus um Management console so specify route in the route table oh it's just a route okay and we'll go back here we'll refresh so that is done is the stack done created complete good we'll go back to our Cloud shell it says you can edit your configuration file or simply do Etc so now let's see if we can create the cluster I assume this would create ec2 instances so the job schedule you using is sge this is deprecated in future use parallel cluster well should have told me okay there is a new version of 301 parallel available I don't understand because I just installed it right we'll go back to cloud formation just going to probably create nested Stacks which that's what I thought it would do Nest Stacks means that it's Reliant so there's one main one and then there's uh children stack so go here see what resources it's creating oh whole bunch of stuff wow so many things at sqsq SNS uh network interface a Dynamo DB table Yeah you you probably don't want to run this you just want to watch me do it and then we go into here it's creating uh an ec2 volume so that's going to be EBS and then here we have uh a log group I don't know why they separated those out do seem very necessary we are waiting on the elastic IP that always takes forever creating elastic IP root instance profile that is the IM Ru for it that didn't take too long these these take a long time I I never know why create a rooll it's really easy but attaching an I am policy you're always waiting for those um so I'm going to just stop it here I'll be back in a second because I don't want to have to make you watch me stare at the screen here okay all right so after a really really long wait um and it always takes some time there it finally created I'm not sure what it's made I mean we generally saw over here in the outputs but usually the cost that I'm worried about is whatever it's launching under uc2 it might not even have launched any servers here we're going to take a look here see if there's anything so we have a master and a compute and they're T2 micros so seems pretty safe here um this compute is not running yet so I'm assuming that this is like the machine that does the Computing and maybe if you had multiple machines here like that would be the cluster like could manage multiple computes um I'm not particularly sure but let's just keep going through the tutorial and see what we can do the next step is we need to get this PM key in our Cloud shell here so this I don't know where this is but what I'm going to do is I'm going to move it to my desktop I'm doing this off screen by the the way so I'm moving it to my desktop and then I'm just going to go and upload the file okay and there it is so we'll say open and we'll say upload and it's going to upload it here onto this machine and I believe this is on like uh I think this used as an e EFS instance like if you're wondering where the storage for cloud shell is if we go over here I think it's EFS is it h i don't know where it is okay maybe it's just a maybe it's some else okay I can't remember where it is but anyway um so now it's created the cluster can I hit enter here okay can I create a tab like if I quit this is it going to kill it it exited it which is I think it's fine I don't think it stopped running and so now if I do an LS there's my key and so we can go back to our instructions just have too many tabs open here drag this all the way to the left here and so we can try to use our key here to log in so what I'm going to do is go here and we'll say my HPC pm and see if that works we'll say yes and permission denied it is required your private key is not accessible that's because we have to chamod it um I never remember the command anymore CU I rarely ssh in the machine but if we go to connect and we go to SSH client it'll tell us what we need to run chamad 400 okay so that's what we need to do is we need to do a chamad 400 just wanted to grab that code there okay and now if we hit up we should SSH into the machine there we are we are in the instance we'll type in exit and so now we want to run our job on this machine and if we go back over to here I guess we can go create our first job so I'm just doing this in v and I'm going to paste that in yep and I don't want the first line oh okay that's perfect great right quit oh there's no file name hold on here so I need to name this file something so I'm going to say job. sh and we're going to paste that again here we'll say paste and I don't know if that's cut off yeah it is okay great is that one okay I don't trust that the first line is there so what I'm going to do is go back to our tutorial here it's shebang forbin bash uh this then that for SL bin SL bash just double check it looks good to me we're going to quit that I'm just going to make sure that it is what it we said it is so job. sh looks correct to me good and so we'll try to run our job here so I'm going to say Q um job. sh LS and I guess it really depends on what we decided to use when we set up that thing I can't remember what we choose as our Q we do qat oh okay okay okay so I think the thing is like you see how we have sge I think that that's what we use to queue up jobs and so we have to have that installed probably so install configure surid engine SG install um Linux oh boy that looks like a lot of work so I don't think we need to to do anything further here but as far as I understand the idea is that you're choosing uh some kind of way to manage these and so I'm not sure what q q sub is let's just go look up what that is what is Q sub oh that is the sun grid engine okay so how do we install that um I'm just going to see if we can install it so I'm going to do I think this is using yum so if I do clear here clear yum install Q sub let's see if I can do it pseudo yum install qm no package available Amazon Linux 2 Q sub because that's probably what we're running in cloudshell Q sub doesn't tell us how to install it that's great so that's probably what it is and so in order to use this we would have to install that sun whatever whatever and then we go through we do Q sub it would queue it up um we could do qat cat hello destroy it that's pretty much all we really need to know to understand this um it would have been nice to queue up a job and see it work but you know we're getting kind of into a hairy territory here and I think that we fundamentally understand how this does work so what I'm going to do is I'm going to go here I'm going to remove the job Dosh here and and I want to destroy this cluster um so I'm going to do pcluster commands to figure out what all the commands are and there's probably a delete command so we'll go back up here B cluster where is our crate so we'll say delete okay and so what that's going to do is just tear down all the stuff now so if we go over to cloud formation okay and it looks like it's destroying so yeah I'll see you here uh back in a bit when it's all destroyed okay all right so after a short little wait there it has destroyed it been so long that I uh my connection vanished but just make sure if you did follow along for whatever reason uh you know make sure that the stuff is deleted and it looks like it did not destroy uh this so I'm going to go ahead and delete that that's just VPC stuff so I'm not too worried about it I know that's going to roll back no problem and so I'm going to consider this done so going to make my way back to the Management console close this stuff up and we are good to go uh for our next thing hey this is Andrew Brown from exam Pro and we're taking a look at Edge and hybrid Computing Services so what is Edge Computing when you push your Computing workloads outside of your network to run close to the destination location uh so an example would be pushing Computing to run on phones iot devices external servers not within your Cloud Network what is hyber Computing when you're able to run workloads on both your on premise Data Center and the a uh VPC okay so we have a few Services here starting with ad Outpost this is a physical rack of servers that you can put into your data center ads output allows you to use ads API and services uh such as ec2 WR in your data center then we have AIS wavelength this allows you to build and launch your applications in a telecom data center by doing this your applications will have ultra low latency since they will be pushed over the 5G Network and be closest as possible to the end user um so they've partnered with things like Verizon vone uh business and a few others but those are the two noticeable ones okay we have VMware Cloud on AWS so this allows you to manage on premise virtual machines using VMware uh within ec2 instances the data center must uh be using uh VMware for virtualization for this to work okay then we have Aus local zones which are Edge uh Data Centers located outside of the adus region so you can use adus closer to the edge destination when you need faster Computing storage databases in populated areas that are outside of AWS region you could do this there's some other Edge offerings on AWS that aren't listed here like sag maker has what's called like Neo stage maker um let you do Edge Computing with um ml but I mean this is good enough okay all right so I wanted just to show an example of edge Computing uh because we didn't cover it in our generic uh compute and so there's a variety of services that allow you to do Edge Computing like wavelength and so um I've never actually launched wavelength before and I think that uh you have to request it so if I go over to support here again I've never done this before but I'm sure we can figure it out pretty easily I feel that if we create a case um maybe it's like service limit we type in wavelength here nope not there so how do we get wavelength wavelength AB us request so that's what I'm looking for here okay how do I use wavelength AWS whoops and sometimes what I'll do is go to the doc here opt into wavelength zones before you specify wavelength zone for resource or service you must opt into it to opt in go to the AIS console okay so we'll go to ec2 and then it's going to say use the region selector in the navigation bar to select the region which supports your wavelength l so I know that there's stuff in uh Us West because of Las Vegas right or not Las Vegas but Los Angeles right so if we go over here there's definitely that over there on the navigation pain on the ec2 dashboard under account attributes select zones okay do we see zones here zones oh ec2 dashboard zones let's go check here again on the navigation pane choose ec2 dashboard we are there right and under account attributes uh settings account attributes oh over here okay oh it's here zones and so there we have two zones and we see switch regions to make uh zones a different region okay so under Zone groups turn on wavelengths Zone groups okay nothing there so I'm just going to switch over to another one here maybe Oregon maybe it's usw 2 oh look at all the stuff we have here I've never seen these before okay so here is the wavelength one so that is the Los Angeles one we can go ahead and enable this before disabling The Zone group I'm not sure what zone groups cost so wavelength Zone pricing again you might just want to watch me do this because it might cost money um and so you might not want to have to spend for that pricing uh provides mobile networks wave lengths are available across whatever learn about the data transfers in price about ec2 instances okay so what's the price we go into here all right so what I'm going to suggest to you is don't do this but I'm going to do it and we're just going to see what the experience is like okay so I'm going to update my zone so now I have this one so we'll say enable I'm going to assume that it has to do with like data transfer costs okay and uh we're going to go over to ec2 and we're going to go over to instances here here we're going to launch an instance and we're going to see if we we have that available now I don't know if we're restricted to to particular uh instances I'm assume we can launch a Linux machine it'd be really weird if we couldn't you know we'll go over to configuration and what we want to do is choose uh the zone so how do we do it so once it's turned on confirmation and confirm it configure your network so create a VPC create a carrier Gateway so you can connect your resources into the the VPC to the telecommunication Network holy smokes This is complicated but it's just kind of interesting to see like the process right you know it's not for our use case but uh carrier Gateway right and as I do this I always check up all the costs here so I say carrier Gateway pricing AWS because maybe that's where the price is okay if you don't get a pricing page then usually that's hard to say logically isolated virtual Network again it's not telling me what um to use carrier you need to opt into at least one wavelength Zone but I did right and sometimes what happens is that it just takes time for the optin to to go so go here manage the Zone settings that was a lot easier way so we have one it's we're opted in right here okay and okay we'll we'll go here again if that one didn't work um we can try so the I guess these are all the regions Denver things like that can I opt opt into this one op in it's not super exciting like all we're going to do is launch an ec2 instance but you know we'll go through the process here a bit and I don't know why I can't create one so we'll go back over to the instructions here create so you can connect so create a route table using the VPC to the route table so I think that's as far as we're going to get here because I'm not seeing any options here but the idea was that we would have to create a carrier Gateway we'd update our route tables and all we would be doing is launching an ec2 instance so you know it's no different than launching it you just choose a different subnet so I think you'd have to create a subnet for that zone and launch it in there and that would be Edge Computing another example of edge Computing would be something like via cloudfront which we have uh these um Edge functions or not Edge functions yeah functions here and so these are functions that are deployed to cloudfront so my cloudfront function and these would be deployed to um Edge locations right and all you can use here is Javascript so here's an example of one and um I'm fine with this development live this function is not published we'll go to test test the function it's good publish publish that function and so the advantage of this is that you know if you have functions that are in it was Lambda there's a chance of cold start um whereas if they're deployed on the edge here there's still probably a cold start but it's going to be a lot faster because it's a lot closer to the edge location so um you know it's just a different uh different cases but yeah there was one where we're launching ec2 workload into wavelengths which we couldn't complete which is totally fine and then we have these functions on the edge there's other uh Edge Computing Services like within Sage maker you can deploy I think it's called like Neo sag maker and then for iot devices those are obviously on the edge so you can deploy those as well uh but generally that gives you an idea of edge Computing okay hey it's Andrew Brown from exam Pro and we're looking at cost and capacity management Computing Services so before we talk about them let's define what is cost management so this is how do we save money and we have capacity management how do we meet the demand of traffic and usages through adding or upgrading servers so let's get to it the first are the different types of EC pricing models so you got spot instances reserved instances saving plans these are ways to save on Computing by paying up in full or partially or by committing to a yearly contract or multiyear contract uh or by being flexible about the availability Interruption to Computing Services we have adus batch this plans schedules and executes your batch computer workloads across the full range of adus Computing Services which can utilize spot instances to save money we have aabus compute Optimizer so suggest how to reduce cost and improve performance by using machine learning to analyze uh you uh your previous usage history we have ec2 autoc Scan groups so asgs these automatically add or remove ec2 servers to meet the current demand all of traffic they will save you money and meet capacity since you only run the amount of servers you need then we have elb so elastic load balcer so this distributes traffic to multiple instances we can reroute traffic from unhealthy instances to healthy instances and can Route traffic to ec2 instances running in different availability zones and then we have elastic beant stock here which is easy for deploying web applications without developers having to worry about setting up and understanding the underlying ad services similar to Heroku it's a platform as a service so not all of these are about cost some of them are about capacity management like elb um but yeah there you go hey this is Andrew Brown from exam Pro and we are looking at the types of storage services and no matter what cloud service provider using they're usually broken down into these three where we have blocks file and um uh object okay so let's take a look at the first so this is going to be for Block storage so for AWS this is called elastic Block store data is split into evenly split blocks directly accessed by the operating system and supports only a single right volume so imagine you have an application uh over here and that application is using a virtual machine that has a specific operating system and then it has a drive mounted to it uh could be using FC or uh scuzzy here um but the idea here is when you need a virtual Drive attached to your VM is when you're going to be using block okay the next one here is for um file or it's just basically a file system so this is Abus elastic file storage so the file is stored with data and metadata multiple connections via a network share supports multiple reads writes locks the file so over here uh we could have an application but it doesn't necessarily have to be an application and so it's using NASA exports as the means to uh communicate and so the protocols here can be NFS or SMB which are very common uh file system protocols and so the idea here is when you need a file share where multiple users or VMS need to access the same drive so this is pretty common where you might have multiple virtual machines and you just want to act as like one uh Drive uh one example that could be like let's say you're running a Minecraft server you're only allowed to have one world on a particular single drive but you want to be able to have multiple virtual machines to maximize that compute that' be a case for that um so there you go then the last one here is like object storage and so for ads this is called Amazon simple storage service or also known as S3 so object is stored with data metadata and a unique ID scales with limited uh with limited no file limit or storage limit so there's really very there's very little limit to this it's just basically scales up supports multiple reads and wrs so there are no locks and so the protocol here we're going to be using htps and API so when you just want to upload files and not have to worry about the underlying infrastructure not intended for high uh IOP so input and outputs per seconds okay so depending on how fast you have to do your read and wrs are going to determine you know whether you're going uh this direction or the other way um or you know how many need to actually connect at at the same time and whether it has to be connected as a mount drive to the virtual machine okay hey it's Andrew Brown from exam Pro and we're going to do a short introduction into S3 because on the certified Cloud practitioner they ask you a little bit more than they used to and so we need to be a bit familiar with S3 because it is um at least I think that abis considers its Flagship uh storage uh service and it really is one of the earliest Services it was the second one ever launched okay so what is object storage or object based storage so data storage architecture that manages data as objects as opposed to other storage architectures so file systems where uh these are others right so which manages data as files and a hierarchy and block storage which manages data as blocks with with ins sectors and tracks that get stored on an actual uh drive and so uh the idea here is we have S3 which provides basically unlimited storage you don't need to think about the underlying infrastructure the S3 console provides interface for you to upload and access your data okay so we have the concept of S3 objects so objects contain your data they are like files but objects may consist of a key this is the name of the object a value the data itself made up of a sequence of bytes the version ID when versioning enabled the version of the object metadata additional information attached to the object and then you have your S3 buckets so buckets hold objects buckets can also have folders which in turn hold objects S3 is a universal name space so bucket names must be unique it's like having a domain name okay and one other interesting thing is an individual object can be between zero bytes and up to 5 terabytes so you have unlimited storage but you can't have uh files of uh incredible size uh I mean 5 terab is a lot but nothing beyond that for a single file but just understand that you can actually have a zerob byte file uh and for like associate certifications that can be a an actual question so that's why it's there all right let's take a look at S3 storage classes um and so for the certified Cloud practitioner we need to know generally what these are for associate levels we need more detail than we have here but let's get through it so adus offers a range of S3 storage classes that trade retrieval time accessibility durability for for cheaper storage and so the farther down we go here the more cost effective uh it should get uh pending uh you know certain conditions okay so when you put something into S3 it's going to go into the standard uh tier the default tier here and this is uh incredibly fast it has 99.99% availability 119 durability and it's replicated across 3 azs and so uh you know we have this cheaper meter here here on the left hand side and that would apply this is very expensive and it's not actually expensive but it is expensive at scale when you can uh better optimize it with these other tiers so just understand that um then you have the S3 intelligent tiering so this uses ml to analyze objects and usage and determine the appropriate storage class it is moved to the most cost effective access tier without any performance impact or added overhead then you have S3 standard IIA which stands for infrequent access this is just as fast as S3 standard but it's cheaper if you access the files less than once a month there's going to be an additional retrieval fee applied so if you do try to retrieve data as frequently as S3 standard it's going to actually end up costing you more so you don't want to do that okay then you have S3 one zone IIA so as it says it's running in a single zone so it's as fast as S3 standard but it's going to have lowered availability but you're going to save money okay there is one caveat though your data could get destroyed because it's remaining in a single uh AZ so if that a or data centers um suffer a catastrophe you're not going to have uh a duplicate of your data to retrieve it okay um and then you have S3 Glacier so for longterm clothed storage retrieval of data can take minutes to hours but it's very very very cheap and then you have S3 Glacier uh deep archive which is the lowest cost storage class but the data retrieval is 12 hours and so you know um all of these here to here these are all going to be in the same uh ads S3 console or Amazon S3 console S3 Glacier is basically like its own service but it's part of S3 so kind of lives in this weird State there's one here that we didn't have on the list here which is S3 outputs because it has its own storage class and doesn't exactly fit well into um this kind of linear cheaper uh thing here okay hey it's Andrew Brown from exam Pro and we are taking a look at the a snow family so this is storage and compute devices used to physically move data in or out of the cloud when moving data over the Internet or Prov private connection that is too slow difficult or costly so we have snow cone snowball Edge and snow mobile and so there originally was just snowball and then they came out with snowball Edge uh and Edge introduced Edge Computing that's why there's Edge in the name uh but pretty much all of these devices have Edge Computing uh and they do individually come with some variance so with the snowball snow cone it comes in two sizes where it has 8 terabytes of usable storage and then there's one with 14 tabt of usable storage for snowball Edge technically Ally has like four versions but I'm going to break it down to two for you we have storage optimized where we have 80 terab of use um uh of usable storage there and then compute optimize 3.9.5 terabytes and even though it's not here you get a lot of vcpus and increased memory which could be very important if you need to do Edge Computing before you send that over to AWS and then last here we have snowmobile which can store up to 100 pedabytes of storage um in the Associates I cover these in a lot more detail because there's so much more about these like the security of them how they're tamperproof like how they have networking built in the the connection to them but you know for this exam that's just too much information um you just need to know that there are three uh three ones in the family and generally what the sizes are and that they're going to be all placed into Amazon S3 what's interesting is that you know snowmobile only does 100 pedabytes but adus markets it as you can move exabytes of of um content because you can order more than one of these devices so uh they'll mark it it saying like snowball Edge is when you want to move pedabytes of data and snowball Mobil is when you want to move exabytes but you can see that a single thing isn't in the exib it's just in the petabyte okay hey this is Andrew Brown from exam Pro and we are taking a look at all the itaba storage services in brief here so let's get to it so the first is simple storage service S3 this is a servess object storage service you can upload very large files and an unlimited amount of files you pay for what you store you don't worry about the UN file system or upgrading the dis size you have S3 Glacier this is a cold storage service it's designed as a lowcost storage solution for archiving and longterm backup it uses previous generation uh HDD drives to get that low cost and it's highly secure and durable we have elastic Block store EBS this is a persistent block storage service it is a virtual hard drive in the cloud and you attach to ec2 instances you can choose different kinds of hard drives so SSD iops SSD throughput HDD and um cold hhd okay we have elastic file storage so EFS it is a cloud native NFS file system service so file storage uh you can mount to multiple ec2 instances at the same time when you need to share files between multiple servers we have storage Gateway this is a hybrid cloud storage service that extends your on premise storage to the cloud we got three offerings to your file Gateway so extend your local storage to Amazon S3 volume Gateway caches your local drive to s three so you have a continuous backup of the local files in the cloud tape Gateway so stores files onto virtual tapes for backing up your files on very cost effective longterm storage we got one more page here because there's a lot of services here we have adab us snow family so these are storage devices used to physically migrate large amounts of data to the cloud and so we have snowball and snowball Edge these are briefcase size data storage devices between 50 to 80 terab I don't believe snowball is available anymore it's just snowball Edge but it's good to have all of them in here so we can see what's going on we have snowmobile this is a cargo container filled with racks of storage and compute that is transported via a semi trailer tractor truck to transfer up to 100 pedabytes of data per trailer I don't think we're going to be ordering that anytime soon cuz that's pretty darn expensive but that's cool we have snow cone this is a very small version of snowball that can transfer 8 terabytes of data we have adab us backup a fully managed backup service that makes it easy to centralize and automate the backup of data across multiple a services so ec2 EBS RDS DB EFS storage Gateway you create the backup plans we have Cloud endure disaster recovery so continuously replicates your machine in a lowcost staging area in your target abl account and preferred region enabling fast and reliable recovery in case of it data center failures we have Amazon FSX this is a feature Rich and highly performant fall system that can be used for uh windows so that would be using SMB or Linux which uses luster and so there we have the Amazon FS FSX for Windows file server so use SMB protocol and allow you to mount FSX to Windows servers and then the luster one which uses uh Linux luster file system it allows you to mount F FSX Linux servers are there any storage Services missing here not really I mean you could count elastic container repository as one but um that's kind of something else or you could also count maybe um uh code commit but you know I kind of put those in a separate category where we where those are in our develop tools or our containers okay all right so what I want to do is show you around S3 so we'll make our way up here and type in S3 and we'll let it load here and what we're going to do is create a new bucket if you do not see the screen just click on the side here go to buckets and we'll create ourselves a new bucket so bucket names are unique so let's say my bucket and we'll just pound in a bunch of numbers I'm sure you're getting used to making buckets in this um in this course so far um so if we scroll on down notice that it says block public access settings for this bucket and this is turned on uh like the blocking is turned on by default because S3 buckets are the number one thing that are a point of entry for malicious actors where people leave their buckets open so if we want to uh Grant access to this bucket for people to see this publicly we'd have to turn this off okay but for now we're going to leave that on you can version things in buckets which is pretty cool you can turn on encryption which you should turn on by default and use the Amazon S3 key on the certified Cloud preder it's going to ask you about client side encryption and server side encryption so you definitely want to know what these are I'm going to turn it off for the time being so we can kind of explore uh here by oursel here um then there's object lock so we can lock files so that um you know there you know people aren't writing to the multiple times so we'll go ahead and create a bucket and it's very quick so here is the new bucket we made and you'll notice we have nothing here which is totally fine if I go to properties um you know we can see that uh we can turn on bucket versioning turn on encryption what I'm going to do is I'm going to go grab some files I remember I saved uh some files recently here I'm just going to make a new folder called Star Trek I just have some graphics you can pull anything off the internet you want to do this yourself um but I'm just going to prepare a folder here it'll take me a moment okay just a moment okay great so now I have my folder prepared and so what I want to do is upload my first file so I can go here and upload and actually I can upload multiple files you can add a folder which is nice and so in here if I want to upload these files here whoops I'll just select multiples I'll hit open it'll cue them up which is really nice we can see the destination details here if we want to turn it uh versioning on we could there uh we could apply permissions for outside access but we have uh things turned on but what's really important is the properties where we have these different tiers and So based on the tier that you use the lower you go at least it should be the cheaper it's going to get uh but it's going to have some tradeoffs and we cover that through the course then there's that server side encryption um and I'm going to hit upload we'll just individually turn it on so you're going to see this progress go across the top these have all been uploaded I'm going to cck click on my destination bucket and so what we can do is we can uh open these if they're images they'll show us right here in the browser we can download them so if we need to get them again all right we can create a folder here and just say Star Trek or Enterprise D Enterprise D here okay but it's not really easy it's not like I can drag this into there um I might be able there's no move option so you'd actually have to copy it into the destination and then delete the old one it's not like using a file system you know um there's a lot more work involved but you know it's a great storage solution um so let's look at encryption so I have this selected here if I click into it I can go to permissions I can go to versions see that I'm looking for H encryption here we go so if I turn it on I can enable encryption and I can choose whether I want to use an Amazon S3 key so SS S3 so an encryption key that Amazon S3 creates man uses for you then you have IUS SS KMS and I believe this uses AES up here which is totally fine then you have KMS down here and it's interesting because they're like ads will manage the key for you and then this one ads will manage the key for you it's just slightly different this one of course is a lot simpler there's not many reasons not to turn on encryption but U I'm going to go turn this one so that it is encrypted here and just because it's encrypted doesn't mean we can't access the file I can still download it I can still view it because ads is going going to decrypt it right so if I go and click on this one and I say open okay even though it's encrypted I can still view it right it just means that it's encrypted on the storage right so if somebody were to steal that hard drive whatever hard drive it's sitting on on ads they could even figure it out it's encrypted they're not going to be able to open up the file right so that is the logic there but through here um I can get it something that's really interesting with um um S3 is the ability to um uh have cycle events so I'm just kind of looking where that is it's usually in the bucket so if I go to management up here I can set up a life cycle rule and what I can do is say like move this to deep storage okay and then I can say what it is that I want to filter so maybe it's like data.jpg I can say apply to all objects in the bucket I acknowledge that and we say move current versions of objects between storage classes and I checkbox that on and I can say move them to Glacier after 30 days I think if I go lower it'll complain probably when I save there and so the idea is that we can move things into storage so maybe you have files coming in down below it's showing you here right so a file is uploaded and then after 30 days then move them in the glacier so we save money okay that's a big advantage of S3 there's a lot of things going on in S3 here like you can turn on um uh wherever it is you can turn on web hosting so you can turn this into like a website down below here there's a whole uh whole bunch of things that you can do okay so uh we're not going to get into that because that's just too much work but uh you know we learned the basics of S3 so what I want to do to delete this I have to empty it first watch it'll be like you cannot delete it you need to empty the bucket first so go ahead and empty it and I'll say my bucket empty or sorry I guess I have to type in permanently delete Perma net we delete no they used to oh yeah I can copy it okay great and so once the bucket is emptied I can go back to the bucket and I'll go back one layer and then I'll go ahead and delete my bucket and you can only have so many buckets I think it's like a 100 you have like 100 buckets how many buckets can you have in a WS 100 buckets yeah I was right and I think if you wanted to know how many you Pro there's probably like a service limits page service limits service quotas so you go here you say a Services S3 how many buckets 100 right there okay so you know that gives you kind of an idea what's going on there but there you go that's S3 all right so let's go take a look at elastic Block store which is uh virtual hard drives for ec2 so what I'm going to do is make my way over to the ec2 console because that is where it's at and on the Le hand side if we scroll on down you'll see elastic block volumes or elastic Block store volumes and so we can go here and the idea is we can go ahead and create ourselves a volume and what you'll notice is that we have a few different options here we have general purpose provisioned iops cold HDD throughput optimized magnetic magnetic being um basically like uh physical tape that you can use to back up like the old school stuff and so you have all these options here and you can choose the size so when you change these options you're going to notice that some things are going to change like the through uh throughput or iops so notice that general purpose is fixed at between 300 to 3,000 and notice that it goes from 1 Gigabyte to how many ever that is that's a lot there and so it's not too complicated but in practicality I don't really create volumes this way what I do is I'll just go launch an ec2 instance so I'll say launch ec2 instance and we'll choose Amazon alytic 2 and again you know if we haven't done the ec2 follow along we'll cover all this stuff in more detail don't worry about it um we go to configure instance then we go to add storage and this is what you're going to be doing when adding EBS volumes um to your ec2 instances and you'll notice we always have a root volume that's attached to the ec2 instance that we cannot remove we can change the size up here I believe the oh it shows us right here that we have up to 30 gigabytes so sometimes you might want to Max that out to take advantage of the free tier you notice we can also change uh this there might be some limitations in terms of the root volume so notice that we have a few more options here we can't have a cold HDD or HDD as our root volume uh notice we have a delete on termination so EBS volume persists independently from the running life so you can choose to automatically delete uh EBS volume when the associated instance is terminated so if you take this off if the ec2 instance is deleted the volume still remain which could be something that's important to you uh for encryption here um you might want to turn it on and so generally adus always has a KMS manage key which is free so you checkbox that on it will be encrypted uh you can turn it on later um but you can never turn encryption off but you should always uh turn the encryption on and so just be aware to turn that on you can also add file systems down below here but maybe we'll talk about that later because I think that gets into um e EFS okay so that is a different type of file storage there but that's pretty much all there is to it uh you just go ahead and create uh your volume there and then it would show up under EBS we could take snapshots of them to back them up that goes to S3 but that's all we really need to know here okay all right let's take a look at elastic file uh system or EFS uh storage manage file storage what does EFS stand for EFS system elastic file system okay sorry and so what we can do is go ahead and create a file system here so I'm going to say my EFS and the great thing is that it's basically a serverless so it's only going to be what you consume right so what you store and what you consume um and I think that's what it's going to be based on we have to choose a VPC I want to launch it in my default VPC and we have the choice of regional or one zone um I guess this is going to be based on what gets backed up to S3 possibly so one zone probably is more cost effective but I'm going to choose Regional and that's a new Option I never noticed before I just opened it up to see a few more things here we have General Max iio bursting provision things like that we'll hit next we'll choose our azs and uh then you might have to set up a policy so I'm going to hit next here you'll go ahead and hit create so you know this is really interesting but the trick to it is really mounting it to a dc2 instance and that's kind of the pain okay so if we go into this um you you have to mount it and there are commands for it so like EFS mounting Linux commands okay I've done this in my Solutions architect associate uh but you know again I'm not doing on a regular basis so I don't remember and so if we go here I'm just trying to see if we can see some code that tells us how to mount it so mounting on an E2 uh uh uc2 Linux instance with the EFS Mount helper um so I don't know if they had that before but that sounds interesting so pseudo Mount hyphen T the file system the EFS mounting Point yeah this looks a lot easier than what we had before okay so before I had to enter a bunch of weird commands but now it looks like they've boiled it down to single command but once you have your EFS instance um I'm going to assume that there is an entry point here just clicking around here seeing what we can see I would imagine we have to create an access point so my access point sure I don't know if it's going to let me just do that it did and so I would imagine that you'd probably use an access point let's go back here ifs Mount point I think that's the same thing I think the mount point and the access point you create access points and that's what you use uh we can go here we can attach it so oh yeah here's the command so um Mount via DNS or Mount via IP address so it doesn't look too hard we can try to give it a go I haven't done it in a while it looks like they've made it easier so maybe we'll try it out okay so we go to ec2 here and I'm going to launch an instance I'm going to choose Amazon L 2 okay we're going to go and choose that and then we want to choose a file system and so it's going to mount to here okay and storage is fine all this is fine and I'm going to go ahead and launch this and I need a new key pair so create a new key pair um this will be for EFS example okay we're going to download that key pair there we're going to launch this instance okay and then we're going to go view this and as that is launching what I'm going to do is open up my cloud shell and I'm going to want to upload this pen so again like before I'm going to drag it to my desktop off screen and then what I'm going to do is upload this file so I have it EFS example okay we're going to upload it because I just want to see if we can access that EFS volume and so if I do LS that's our old one one which I can delete by the way I'm never going to use that anytime soon yes LS and I'm going just delete the hello text there so it's a bit cleaner for what we're doing and so we need to chod that 400 uh EFS example and we saw that's how like if you want to try to connect to a server remotely that's what you do right so I believe that the drive is mounted if I go to storage does it show up here doesn't show up under here but um what we're waiting for are these two status checks to pass and then we can SSH into this machine and I'm just going to go back here and take a look here so using the EFS Mount helper so pseudo Mount hyphen T EFS TLS this volume to EFS and so I imagine it's going to mount it to EFS here using the NFS client so I guess it just depends on what we're going to have available to us even if the status checks haven't passed I'm going to try to get into this anyway um so what we can do is click on this grab the public IP address we'll type in SSH um ec2 hyphen user at sign paste this in hyphen I EFS example pem I usually don't log in Via SSH um but you know just for this example I will and so I want to see if this drive exists usually be under mount right there it is okay so it already mounted for us so I can do touch hello world. text say pseudo here I can say pseudo VI I'm going to open up the file and say hello from another computer okay and so I've saved that file and what I want to do now oops oh okay sorry I'm in the cloud shell here but what what I want to do now is I want to kill this machine okay and what I'm going to do is spin up another ec2 instance I'm going to see if I when I mount that if that file is there if it actually worked but wow that is so much easier than before I can't tell you how hard it was to attach an EFS volume the last time I did it um so we'll go ahead We'll add that and the storage is fine we're going to go to review here we're going to say launch and I'm just going to stick with the same key pair there we're going to give that moment to to launch and we're going to go to view instances and so now this one is launching as it's launching let's just go peek around and see what we can see so you know I imagine if we didn't add that file system during the the boot um and we were we're adding it after the fact we probably could just ran that line and added it really easily um I'm not going to bother testing that because I just don't want to go through that trouble to do that um I still can't remember what these access points are for um but uh it's okay it's that's kind of out of the scope for the certified Cloud partitioner and then so I'm just curious so we get some nice monitoring here right so that's kind of nice um I guess they're trying to suggest here like inabus backup data sync transfer so that would just be backing up simplify uh automates accelerates moving data okay that's pretty straightforward transfer family fully managed F SFTP okay so nothing exciting there and we're going to refresh that there and this is initializing so let's go see if we can connect to this one so I'm going to go ahead grab that public IP address I'm going to hit up okay I'm going to swap out that IP address and we're going to see if we can connect to that machine yet so we'll say yes and we got into it so that's great and so what I'm going to do is go again into the mount directory EFS FS1 LS and there it is I'm going to do cat hello world and so it works and so that's the cool thing about DFS is that you have a file system that you can share among other um uh ec2 instances I'm sure users could connect to it using the NFS protocol I'm not the best at like networking or storage networking so I'm not going to show that here to you today but that gives you a general idea how EFS works again you only pay for what you store it is serverless so we'll go here and type delete because I'm done with this I'll probably uh destroy the instance first so it doesn't get mixed up and just so we clean up a little bit better here I'm going to delete these Keys here uh Delete okay and we'll go ahead and delete this one as well delete I'm done with that uh we'll make sure that that is tearing down that is good and we'll make our way back over here and it says enter probably the ID's name in so we'll enter that in and we hit confirm and we'll see is it deleting I'm not confident with it I'm going to do it one more time confirm that by entering the the file systems ID so we'll put it in again is it destroying I cannot tell there we go so it's destroying we are in good shape it is gone our data is gone um but yeah that is EFS all right let's take a look at um the snow family in ads so if we type in snow up here and we click into Adis snow family this is where we can probably order ourselves a device um I might not be able to order them at least when I originally looked at this like way back in the day uh it wasn't available in Canada so I'm kind of curious to see what there is but the idea is that you're going to go here and Order and you have some options so you can import into S3 or export from S3 and then down below we have local compute storage so perform local compute storage workloads without transferring data you can order multiple devices and clusters for increased durability and storage Capac so it sounds like you're not you're not um transferring data you're just using it uh locally on to um it's like basically buying renting temporary computers which just kind of interesting I never saw that option before but we're going to choose import into a ss3 and we're just going to read through this stuff and it's not my expectation that we're going to even be able to submit a job here and you probably don't want to because it's going to cost money but I just want to show you the process so we can see what there is here so snow job assistance if you're new to snow family run a pilot of one to two devices so batch file smaller than 1 Megabyte Benchmark and optimize deploy St uh staging workstations discover and remediate environmental uh issues early files and folders name must conform to Amazon S3 prepare your Ami once the pilot is completed confirm the number of snow family devices that you can copy devices to simultaneously follow the best practices use the following resources to manage your snow devices so we have adab US Open Hub and then there's the edge client CLI so open Hub is a graphical user interface you can use to manage snow devices so that's kind of cool and then we have the CLI which I imagine is is something that's very useful to use so just close those off here and then we have other things so I can say I acknowledge I know what I'm doing which I don't really but that's okay and then here we are going to enter in our address so we say Andrew Brown and I'm not going to I'm not going to enter this in for real just whatever so it would be Toronto exam Pro um Canada oh see so there's there's the thing you can only ship it to the US and so that's as far as I can get okay um and that's the thing is like if you really want to know any of us inside or not you got to be in the US but let's pretend that we do have an address in the states what's a very famous address so what is the address of the White House okay there it is so I'm just going to copy that in because again we're not going to submit this for real I just want to see what's farther down the line here okay uh what's NW is that the state it's in Washington right is is this part of it NW Northwest is that a thing I'm from Canada so I couldn't tell you um so we'll go down here and we have Washington do we have a second address line it doesn't look like it um we have a zip code I believe this is the zip code and do we need a phone number looks like we do 416 uh 111 11111 okay we have one day or two day shipping why not just have one right and so then we can choose our type of device so we have snow cone snow cone SSD snow cone optimized I'm surprised I never took a screenshot of this earlier um compute optimize things like that so you can choose which one you want it looks like we're gonna see some different options but we'll go with snow cone my snow cone and snow cones do not ship with a power supply or ethernet cable snow cone devices are powered by 45 watt CB C uh USBC power supply I'll provide my own power supply and cable do not ship with a power supply res cable that's fine uh snow con Wireless snow con connect your wireless connection connect the buckets you want there's the bucket we created earlier Computing use compute using E2 instance is use a device as a mobile data center by loading ec2 Ami so here's an Ami that I might want to use uh ad iot green grass validated Ami not interested in Remote device management you can use Ops Hub or Etc to monitor reboot your device that's fine and so then we need to choose our security key I don't know if we have to set the service roll we'll see what happens here and uh we'll let it update that's fine and and so then I guess we just hit create job and so I don't really want to order one um so I'm not going to hit that button and also it's going to go to the White House and they're going to be like Andrew Brown why did you do that so that's not something I feel like doing today but at least that gives you an idea of that process there and I imagine that uh if you go the other way it's going to be pretty similar yeah it's just like same stuff I think uh so you it Sav that address it's not a real address and the the options are a little bit uh limited here and it's like NFS Bas S3 Bas so it's slightly different but it's basically the same process just curious we'll take a look at the last one there since there are three options just curious okay Sim similar thing okay so yeah that's pretty much all I want you to know about um the snow family and that's about it okay hey this is Andrew Brown from exam Pro and we are taking a look at what is a database so a database is a data store that stores semistructured and structured data and just to emphasize a bit more a database stores more complex data stores because it requires using formal design and modeling techniques so databases can generally be categorized as either being relational so structured data that strongly represents tabular data so we're talking about tables rows and columns so there's a concept of row oriented or column oriented and then we have non relational databases so these are semistructured that may or may not distinctly resemble tabular data so here is a very uh simple example the idea is that you might use some kind of language like SQL put in your database and you'll get back out tables for relational databases let's just talk about some of the functionality that these databases have so they can be uh using a special specialized language to uh query so retrieve data so in this case SQL specialized modeling strategies to optimize retrieval for different use cases uh more fine tune control over the transformation of the data into useful data structures or reports and normally a database infers uh someone is using using a a relational row oriented data store so um you know just understand that when people say database that's usually what they're talking about like postgress MySQL relational row store is usually the default but obviously there's a lot more broader terms there okay hey this is Andrew Brown from exam Pro and we are taking a look at what is a data Warehouse so it's a relational data store designed for analytical workloads which is generally column oriented data store okay so companies will have terabytes and millions of rows of data and they'll need a fast way to be able to produce analytics reports so data warehouses generally perform aggregation so aggregation is the idea of grouping data together so find a total or an average uh and data warehouses are optimized around columns since they need to quickly aggregate column data and so here is kind of a diagram of um a data warehouse and so the idea is that it could be ingesting data uh from a regular database here I'm just getting out my pen tool so it could be a regular database or it be coming from a different data source that isn't compatible in terms of the schema and you use like ETL or elt uh or ETL to get that data into that data warehouse so data warehouses are generally designed uh to be hot so hot means that they can return queries very fast even though they have vast amounts of data data warehouses are in free quently access meaning they aren't intended for realtime reporting but maybe once or twice a day uh or once a week to generate business and uh user reports of course it's going to vary based on the um the service that is offering the data warehouse a data warehouse needs to consume data from a relational database on a regular basis and again it can consume it from other places but you'll have to transform it to get it in there okay hey this is Andrew Brown from exam Pro and we're taking a look at a key value store so a key Value store or database is a type of nonrelational database or nosql that uses a simple key Value method to store data and so key value stores are dumb and fast uh but they generally lack features like relationships indexes aggregation of course there are going to be providers out there have managed solutions that might uh po fill some of those uh issues there but I want to show you the underlying way that key value stores work to kind to kind of distinguish them between document stores so a key value stores literally a unique key alongside a value and the reason I'm representing that as zeros and ones is because I want you to understand that that's what it is it's basically just some kind of of data there and how the key value uh store interprets it is going to determine what it is so when you look at a document database that is just a key value store that uh uh interprets the value as being documents right and so key value stores can and do commonly store um uh multiple uh like associate array that's pretty common so even for Dynamo DB that's how it does it and so that's why when you look at a key Value Store it looks like it uh a a table but it's not actually a table it's schema list because underneath it's really just um you know that associative array and so that's why you can have uh columns or sorry rows that have uh different amounts of columns okay so due to the design they are able to scale very well beyond a relational database and they can kind of work like a relational database without all the bells and whistles so hopefully you know that makes sense okay all right let's take a look at document stores so a document store is a nosql database that stores documents as its primary data structure and a document could be an XML uh type of uh structure but it also could be something like Json or Json like document stores are sub classes of key value stores uh and the components of of a document store are very uh comparable to relational databases so just kind of an example here where in a relational database they'd be called tables now you have collections they were called rows now they're called documents you had columns they had Fields they may have indexes and then joins might be called embedding and linking so you can translate that knowledge over uh you know they they're not as um they don't have the same kind of feature set as a relational database but you have better scalability and honestly document stores are just key value stories with some additional features built on top of it okay hey it's Andie Brown from exam Pro and we're going to take a look at the nosql database services that are available on AWS so we have Dynamo DB which is a serverless no skill key value and document database it is designed to scale to billions of records with guaranteed consistent data returned in at least a second you do not have to worry about managing shards and Dynamo DB is 's Flagship database service meaning whenever we think of a database service that just scales is cost effective and very fast we should think of Dynamo DB and in 2019 Amazon the online shopping retail uh shut down their last Oracle database and completed their migration to Dynamo DB so they had 7,500 Oracle databases with 75 pedabytes of data and with Dynamo DB they reduced that cost by 60% and reduce the latency by 40% so that's kind of to be like a testimonial between relational and a no escol database so when we want a massively scalable database that is what we want Dynamo db4 and I really just want to put that there because it if you remember that you're going to always be able to pass uh or get those questions right on the exam okay then we have document DB so this is a Noll document database that is mongod DB compatible uh so mongodb is very popular noo among developers there were open source licensing issues around using open source mongodb so ad got around it by just building their own mongodb database basically so when you want a mongod DB like database you're going to be using document DB we have Amazon key spaces this is a fully managed Apachi Cassandra database so Cassandra is an open source no esql key value database similar to Dynamo DB that is column or store database but has some additional functionality so when you want to use apachi Cassandra you're using Amazon keyspaces hey this is Andrew Brown from exam Pro and we are taking a look at relational database Services starting with relational database service RDS and this is a relational database service that supports multiple SQL engines so relational is synomous with SQL and online transactional processing oltp and relational databases are the most commonly used type of database among tech companies and startups just because they're so easy to use I use them I love them um RDS supports the following SQL engines we first have MySQL so this is the most popular open source SQ database uh and it was purchased and is now owned by Oracle uh and there's an interesting story there because when Oracle purchased it they weren't supposed to have it um Mario DB was or sorry myell was sold to Oracle Sun systems and then within the year um uh Oracle purchased it from them and the original creators never wanted it to go to Oracle um just because of their uh the way they do licensing and things like that and so um the original creators came back and they decided to Fork my and then maintain it as Mario DB just so that uh you know oracle never kind of pushed away the most popular database so that everyone had to go to a paid solution then you have postest so psql as it's commonly known is the most popular open source SQL database among developers this is the one I like to use because it has so many Rich features over my school uh but but it does come with added complexity then Oracle has its own SQL proprietary database which is well used by Enterprise companies but you have to buy a license to use it then you have Microsoft SQL so Microsoft's proprietary SQL database and with this one you have to buy a license to use it uh then you have Aurora so this is a fully managed database uh and there's a lot more to uh going on here with Aurora so we'll talk about it it almost acts as a separate service but it is powered by RDS so Aurora is a fully managed database of either myql so five times faster or postgress SQL three times faster database so when you want a high available durable and scalable and secure relational database for post custom isqu you want to use Aurora uh then you have Aurora serverless so this is a serverless ond demand version of Aurora so when you want the most of the benefits of Aurora but you can trade uh off to have cold starts or you don't have lots of traffic or demand uh this is a way you can use Aurora in a serverless way then you have RDS on VMware so this allows you to deploy RDS supported engines to on premise data centers uh the data center must be using VMware for Server virtualization so when you want databases managed by RDS on your own database Center uh and yeah I realize that this is a small spelling mistake should say just on here but yeah there you go hey this is Andrew Brown from exam Pro and we're looking at the other database services that abos has because there's just a few loose ones here so let's talk about red shift so it is a petabyte siiz data warehouse and data warehouses uh are for online analytical process procing oap and data warehouses can be expensive because they are keeping data hot meaning that they can run a very complex query and a large amount of data and get that data back very fast so when you need to quickly generate analytics or reports from a large amount of data you're going to be using red shift then you have elastic cache so this is a managed database of an inmemory and caching open source databases such as reddis or memcache so when you need to improve the performance of an application by adding a caching layer in front of your web servers or database you're going to be using elastic cash then you have Neptune this is a managed graph database the data is represented as interconnected nodes I believe that it uses Gremlin as the way to interface with it which is no surprise because that's what it looks like most class providers are using so when you need to understand the connections between data so mapping fraud Rings or social media relationships uh very relational database heavy information you're going to want to use Neptune we have Amazon time streams it's a fully managed time series database so think of devices that send lots of data that are timesensitive such as iot devices so when you need to measure how things change over time we have Amazon Quantum Ledger database this is a fully managed uh Ledger database that provides transparent immutable cryptographically variable transaction logs so when you need to record a history of financial activities that can be trusted and the last one here is database migration service DMS it's not a database per se but it's a migration service so you can uh migrate from on premise database to adabs from two databases in different or same adabs accounts using different SQL engines and from an SQL to a nosql database and I'm pretty sure we cover this in a bit uh greater detail in this course okay all right let's go take a look at Dynamo DB uh which is ad's nosql database so we'll go over to Dynamo DB and what we'll do is create ourselves a new table to say my Dynamo DB table and you always have to choose a partition key you don't necessarily have to have a sort key but it could be something like um like you want it to be really unique so it could be like email and this one could be uh created at right and so we have string binary notice that the the types are very simple then for settings we have default settings or customized settings so the default is use provision capacity mode rewrite five rules Etc custom no secondary indexes use KMS so I'm going to just expand that to see what I'm looking at we have two options here on demand uh so simplify billing by paying the actual reads and rights you use or provisioned which is this is where you get a guarantee of performance so if you want to be able to do you know whatever it is a thousand I don't know what it goes up to but like a thousand read writs per second then that's what you're paying for okay you're paying for being a having a guarantee of that um of that capacity okay I'm not going to create any secondary indexes but that's just like another way to uh look at data notice down below that we have a cost of $2.9 uh then we have encryption at rest so you can do owned by Amazon Dynamo DB that's pretty much the same as like adab us has or S3 has ssse S3 there you could use uh C actually I guess both of these are probably KMS I would imagine we'll go ahead and create the table here and that's going to create the table this is usually really really fast we'll go here and what we can do is insert some data so as it's just starting up here we can go over to our tables they recently changed its UI so that's why I look a bit confused U view items up here okay and then from here we can create an item so I can add something say so Andrew exampro doco and 2021 uh well we'll just do the future so we'll say 20 25 055 I don't want to have to think too hard here but we can add additional information so I can say like uh today true we could say um make like a list uh you know food and then I could go here here and then add a string it is not working oh there we go there we are so we could say like um banana and then we could say pizza right we can go ahead and create that item and so now that item is in our database uh we can do a scan that will return all items we can query we can actually have uh some limitations of what we're choosing there's the party Q editor so we can use SQL to select it um I have not used this before party Q um AWS or party Q Dynamo DB examples I'm hoping I can just find like an example of some of the language getting started here I don't need to I don't need an explanation I just show me an example query here and I will I'll get to it here okay so here's some examples right so maybe we can give this a go uh um so we have our table here so my Dynamo DB table and I just want the email back we don't need a wear we'll run this see if it works there we go I'm not sure if we could select additional data there so I know that we had some other things like uh food there it is okay so that's really nice um addition to it dynb can stream things into a Dynamo DB stream to go to Kinesis and do a lot of fun things so there all sorts of things you can do with Dynamo DB but um I'm pretty much done with this so I'm going to go ahead and delete this table and notice that it also creat some cloudwatch alarm so we want to delete this as well create a backup no we do not care go ahead and delete that and that is Dynamo DB okay so now I want to show you uh RDS or relational database service so go to the top here type in RDS and we'll make our way over there and so RDS is great because it allows us to launch relational databases um sometimes the UI is slow I'm not sure why it's taking so long to load today but every day is a bit different and so what we're going to do is go ahead and create a new database uh you're going to notice that we're going to have the op between creating a standard or easy I stick with standard just because I don't like how easy hides a lot of stuff from us even here like it says two cents per hour but it's not giving us the full cost so I really don't trust it because if you go down here and you chose their Dev test here look it's like $100 it's not showing the the the cost preview right now maybe because we didn't choose the database type sorry I wanted to chose postgress but before we do that let's look at the engine types we have Amazon Aurora so we have between myell and post postgress MySQL Marb postgress Oracle Microsoft SQL no for Microsoft SQL it comes with a license you don't have to do anything with that it might change based on the addition here uh nope comes with a license for all them which is great uh if you want to bring your own license that's where you need a dedicated host right running uh Microsoft SQL for Oracle uh you have to bring your own license that's going to be based on um importing with the Aus license manager over go over to postest which is what I like to use uh we're going to set it to Dev test to try to get the cheapest cost scroll down look $118 we can get it cheaper we get super cheap so here the password is going to be testing one two three capital on the T so and an exclanation mark on the end okay because it has a bunch of requirements of what it wants here I want a T2 micro so I'm just going to scroll down here what is going on here standard oh look M classes I don't want an m class class I want a burstable class that's the cheap ones and so we go here can we still do a T2 micro or is it now T3 so I don't see T2 so I imagine a T3 micro must be the new it free tier so we go it fre tier here right and if I go to databases um RDS on the t2 micro 750 hours but I can't select it so I'm going to assume that the T3 micro must be the new tier if it's not there right unless it's saying include previous generations and then maybe I can see it then okay so I don't see it there I really don't like how they've changed this on me okay so the oldest I can choose is a T3 micro which is fine I just I just know T2 being the free tier that's all uh this is fine we don't want Auto scaling turned on for our example here we do not want a multiaz so do not create a standby that's going to really jump up our cost we don't need Public Access it will create a VPC that is fine password authentication is fine we have to go in here which I don't know why they just don't keep that expanded because you always have to come in here name your database so my database we choose your postest version here I'm going to turn backups off uh because if we don't if we don't it's going to take forever to launch this thing encryption is turned on you can turn it off but generally it's not recommended we can have performance insights turned on I'm going to turn the retention oh we'll leave it to seven days because we can't turn that off we don't need enhanced monitoring so I'm just going to turn that off and uh that's fine we're not going to enable delete protection here and so we are good we can now go ahead and create our dat database and what we'll do here is wait for that database to be created so the thing is is like if we're doing the solutions architect or the developer social stuff I'd actually show you how to connect to the database um it's not that hard to do like you just have to connect uh grab all the database information so it's going to have an endpoint a port stuff like that and you use something like table Plus or something to connect to the database but that's out of scope of the certified Cloud partitioner I'm just going through the motions to show you that you can create an RDS database very easily but not how to connect to it and actually utilize it okay and so that would spin up and we would have a server and after that we can just go ahead and delete the server here so to say delete me okay and that's all there really is to it there is the special type of um database like Aurora doesn't have its own like console page it's part of RDS so if you want to spend up Aurora you just choose the compatibility you want you can choose between provisioned or serverless um and serverless is supposed to be really good for um scaling to zero cost so that's something there so you fill that all out but the initial cost is a lot more expensive you can't choose a T2 micro here um unless it lets you now it is for provision it's uh oh T2 T3 medium is the smallest you can go Okay so if you reach to the point where using a a mediumsized database then you might consider moving over to Aurora just because it's going to be highly scalable Etc like that um so that's a consideration there there's also something called Babble fish um that it was announced last year when I when I shot this um or when I'm shooting this as of now and the idea was to make it compatible with MyQ SQL Server to migrate over to Aurora post SQL which is kind of interesting um but that's about it so if our database is destroying I think it is just going to go back over over here to RDS it's taking a long time to load today and uh I think it's already deleted maybe we go to databases here it's deleting so I'm confident it's going to delete so there we go all right let's take a look at Red shift so red shift is a data warehouse and it's generally really expensive so it's not something that you're going to want to launch uh day today here but let's see how far we can get with it um just by running through it so what we'll do is go ahead and create a cluster and again you can just watch me do this you don't have to create uh you don't have to create one yourself uh so free trial configure for learning that sounds good to me uh is free for limited time if your organization has never created a cluster why rarely ever create these so when the trial ends delete your cluster to avoid the charges of on demand okay that sounds fair um so here we're going to have two vpcu it's going to launch a d a DC to large so let's look that up for pricing show me prices please please please um I think it's loading right here okay so I don't know how much it is but I know it is not cheap and down below we have sample data is loaded into your red shift cluster that sounds good to me ticket is the sample data okay ticket sample data red shift I just imagine they probably have like a tutorial for it here they do right here and so because I want to know what we need to do to query it right if we can even query it via the interface here so the admin user is adus user um and the password is going to be capital T testing 123 4 5 6 exclamation and we'll hit create cluster oh cool we can query the data right in here so that's what I wasn't sure about whether we would be able to just query it in line because before you'd have to use Java with j jdbc or an odbc driver and download the jar and it's not as fun as it sounds of course but it looks like we can query data once the data is loaded so that looks really good I guess we can pull data in from um the marketplace so that's looks pretty nice too and I guess we could probably integr into other things like quick site because you probably want to adjust your data over there again I usually don't spend a lot of time in red shift um but it looks like it's a lot easier to use I'm very impressed with this so I don't know how long it takes to uh launch a red shift cluster I mean it is 160 gigabytes uh of of of storage there it's uh even at the smallest it's pretty large so what I'm going to do is to stop the video and I'll be back when this is done okay okay so after a short little wait here um it was lot lot faster than I was expecting but uh it's available and so looks like here it says to query the sample data use red shift version two so I'm going to click that and I'm sure there's tons of buttons to get here and it'd be great if it just populated the query for me um it doesn't but this looks really nice really nice UI I wonder if it has like some existing queries no that's okay so what I'm going to do here is I'm going to go ahead and pull out this query and see if we can get this to work here never found out what those prices were though okay and what we'll do is hit run I like how there's like a limit of 100 but here it has that so we'll go ahead and hit run and see what data we get so relation sales does not exist okay so what's going on here um we'll go up here so most of the examples in the red shift documentation uses uh a sample database call ticket this sample uh this small database consists of seven tables you can load the ticket data set by following the this here okay so to load the sample data from Amazon S3 okay so I would have thought it already had the data in there I could have swore it would have Dev public tables zero tables okay so I don't think there's any data in here and so we're going to have to load it ourselves I really thought it would have added it for us uh let's go ahead and create these tables and see if this is as easy as we think so run that create that table cool okay we got it down here we'll run that we just run each at a time I think there's seven of them so date already exists okay that's fine event already exists saying all these tables exist maybe I just wasn't patient okay um interesting all right so maybe we'll go back and uh run that query maybe we just had to wait a little while for that data to load run okay so you know what I think it was doing this for us like if if the if it did not create it for us we would have to go through all these steps which is fine because we're learning a little bit about um uh red shift but um uh looks like we just had to wait there so it looks like you would run those you download that you use the copy command to bring it over there um it looks like you can do all of this via the uh this interface here and we've done a query so that's kind of cool um I imagine you probably could like save it or export it what if we chart it what happens okay you can chart it that's kind of fun can we export it out to oh just we can save it I thought maybe it could export out to Quick site but I I suppose you'd rebuild it in quick site a but yeah I guess that's it right there so that's pretty darn simple so so what I'm going to do is make my way back over to Red shift because we are done for this example and we will go over to clusters here and I'm going to go ahead and delete my cluster delete create file snapshot nope delete delete the cluster there we go so I'm pretty sure that will succeed no problem there and we are done with red shift and red shift is super expensive so just make sure that thing deletes okay hey this is Andrew Brown from exam Pro and we are taking a look here at Cloud native networking Services um and so I have this architectural diagram I created which has a lot of networking components uh when people create networking diagrams for adws they don't always include all these things here even though they're there so we're just being a little bit verbo so you can see okay the first thing is our VPC our virtual private Cloud this is a logically isolated section of the adus cloud where you can launch adus resources that's where your uh resources are going to reside not all services uh require you to select a VPC um because they're managed by AWS but I wouldn't be surprised if under the hood they are in their own VPC Okay then if you want uh the internet to reach your services you're going to need an internet gateway um then you need to figure out a way to Route things to your various subnets and that's where route tables uh come in then we need to Def Define a region that it's going to be which is a geographical location on your network then you have your availability zones which are basically your data centers where your a resources are going to reside then you have subnets which is a logical partition of an IP network into multiple smaller Network segments um and these pretty much map to your uh availability zones if you're making one per a and then we have knackles these act as a firewall at the subnet level then we we have security groups that act as a firewall at the instance level so hopefully that gives you a good overview okay all right so now let's take a look at Enterprise or hybrid networking so we have our on premise uh environment or your private cloud and then we have our ads account or our public Cloud so there's a couple Services here that we can Bridge them together the first is ADS virtual private Network VPN it's a secure connection between on premise remote offices and mobile employees then you have direct connect this is a dedicated gigabit connection from on premise data center to ads so it's a very fast connection a lot of times the direct connect we say it's a a private connection but that doesn't necessarily mean secure it's not encrypting uh the data in transit so very commonly these services are used together not just singular okay um and then uh we have private links and so this is where you already uh are using ads but you want to keep it all within ads never going out to the internet okay so these are generally called VPC interface endpoints and then the marketing Pages call them private links which is a bit confusing but you know it just keeps traffic within the aabus network so it does not transverse out to the internet okay hey this is Andrew Brown from exam Pro and we are taking a look at vpcs and subnets so a VPC is a logically isolated section of the adus network where you launch your adus resources and you choose a range of ips using a cider range so a cider range is an IP address followed by this uh net mask or sub submask and that's going to determine how many IP addresses there are um and there's a bunch of math behind that which we're not going to get into um but anyway so here is an architectural diagram just showing a VPC with a couple subnets so subnets is a logical partition of an IP network into multiple uh smaller Network segments and so you're essentially breaking up your IP ranges for vpcs into smaller networks so just thinking about cutting up a pie okay so subnets need to have a smaller cider range uh to uh the vpcs represent for their portion so uh 4/24 is actually smaller which is interesting the the higher the number gets the smaller it gets and so this would allocate 256 IP addresses and so that's well smaller than 16 okay we have the concept of a public subnet so this is one that can reach the internet and a private subnet the one that cannot reach the internet and um these are not uh strictly enforced by AWS so the idea is that when you have a subnet you can just say don't by default assign publicly assignable IP addresses but it's totally possible to launch an ec2 instance into your private subnet and then turn on um uh the IP address so you got to do other things to ensure that they stay private or public okay hey it's Andrew Brown from exam Pro and we are comparing security groups versus knackles so I have this nice architectural diagram that has both knackles and security groups in them and we'll just kind of talk about these two so knackles stand for network access control lists and they act as a virtual firewall at the subnet level and so here you can create an allow uh and deny rules and this is really useful if you want to block a specific IP address known for abuse and and I'm going to just kind of um compare that against security groups because that's going to be a very important difference okay so security security groups act as a firewall at the instance level and they implicitly deny all traffic so you create only allow rules so you can allow an ec2 instance to access port on uh Port 22 for SSH but you cannot block a single IP address and the reason I say that is because in order for you to block a single IP address in Security Group you would literally have to block or you literally have to allow everything but that IP address and that's just not feasible okay so if you can remember that one particular example you'll always be able to remember the difference between these two one other thing that um any of us likes to do is is ask which which ones are stateless which ones are stateful but at the uh Cloud partitioner level they're not going to be asking you that okay all right let's learn a bit about U networking with AWS so what I want you to do is go to the top and type in VPC which stands for virtual private cloud and what we'll do is set up our own VPC it's not so important that you remember all the little bit of details but you get through this so that you can remember the major components so what I'll do is create a new VPC I'm going to call this my VPC uh tutorial and here I'm going to say 10.0.0.0 sl16 the reason you're wondering why I'm doing that if we go to xyxy Z here um this tells you the size of it so I go here and I put 16 so you can see we have a lot of room if we do 24 it takes up it it it's smaller see so this is basically the size of it right the empty blocks over here so we're going to have a lot of room so we do 10 00 16 we don't need IPv6 we're going to go ahead and create that and once we have that we can go ahead and create a subnet which we will need so we're going to choose our VPC we'll go down here and say my Subnet tutorial and we'll choose the first a z you can leave it blank and it'll choose it random and then we need to choose a block that is smaller than the current one so 16 would be definitely um uh well 16 is the size that we have now so we can match that size but 10.0.0.0 sl24 would be absolutely small okay so we go ahead and create that subnet and so that is all set up now um let's see if our route table is hooked up so our route table says where it links to and it says to local so it's not going anywhere and that's because we need to attach a u internet gateway that allows us to reach the internet so if we go over here and create a new internet gateway we'll say my igw and we'll go ahead and create that and what we'll do is associate that with our VPC we created here okay and so now that we have the internet gateway attached we want that subnet to make its way out to the Internet so if we go to the route table we can edit the uh route table Association here I like how it keeps on showing me this as if I don't know what I'm doing um but I do and so this would change that particular Association but I want to add to that route table so I thought when I click that it would allow me to add more but apparently I got to go to Route tables over here and I'm looking for the one that is ours we can see that it's over here we could even name it if we wanted to like my rote table notice then we apply uh uh uh names it's actually just applying a tag see over here it's always what that is so we'll go over to routes and we want to edit the routes and we want to add a route and we want this to go to and we're going to choose the internet gateway okay we're going to say save changes and what that's going to allow us to do is to reach the internet um and so what I want to do is go back to subnet I was just curious about this I've never used this before um so looks like we can just choose some options here I'm not too concerned about that but I assume like that's used for debugging azers had those kind of services for a long time and so it has been starting to add those so you can easily debug your network which is nice so we have a subnet the subnet uh can reach the internet because there's a there's um uh an internet gateway and it's hooked up via the route table one thing that matters is will it assign a public IP address um so that is something that we might want to look into it's not the default subnet which is totally fine so it says Auto assign is no so that might be something that you might want to change so here we go to edit the r table Association no it's not there they changed it on me used to be part of the uh setup instructions us to just checkbox it now they moved it modify the auto assign so we'll say enable so that means it's always going to give it a public IP address on launch and while we're here I'm just going to double check if I have any elastic IPS I did not release okay just double checking here and so this is all set up and we should be able to launch a um ec2 now within our our new VPC so I'll go over here to ec2 okay and I'm going to launch a new instance say Amazon El 2 we're going to choose this tier Here and Now what we should be able to do is Select that and that is our subnet there okay go ahead and launch that I don't care if we use a key whatsoever so I'm going to go ahead and launch that there okay we'll go back and so there you go it is launching so we created our VPC and we launched uh in it no problem whatsoever so hopefully that is pretty darn clear um so yeah uh what I'm going to do is I'm going to let that launch because I want to show you security groups So within AWS you can set security groups and knackles and that's going to allow or deny access based on stuff and when we launched this ECU instance it has a default security group that was assigned we could have created a new one but what I might want to do is create myself a new Security Group here okay and you can end up with a lot really fast like here's a bunch and I can't even tell what's what so like there's Bunch for load balancers and things like that and so I might just go ahead and delete a bunch of these because I cannot tell what is going on here and um we'll delete these security groups and sometimes they won't let you delete them because they're associated with something like a network interface or something all right but um we need to find out which one we're using right now so the one that we are using is the launch wizard 4 so we'll go into here and I don't know if you can rename them after they've been created I don't think so which is kind of frustrating because if you want to rename it it's like I don't want that to be the name so what's interesting is you can go here and you can edit the routes uh the rules sorry the inbound rules and the outbound rules and so here it's open on Port 22 so that allows us to ssh in we could drop this down and choose different things so if we want people to access a website we go Port 80 and we say from anywhere ipv 46 so now anyone can access it um you might want to do something like give it access to postgress that runs on Port 5432 things like that um could be something else like maybe you need to connect to Red shift that's on that Port you can go ahead and save those rules we're just going to say uh from anywhere you can even say my IP so maybe only I'm allowed to connect to it right so you added inbound rules you don't really ever have to touch outbound rules it's set for all traffic so it's stuff that's leaving uh the that there one interesting thing to note about uh security groups is that you don't have a deny option right so let's say you only wanted a particular IP address you only wanted um let's say what's my IP my IP address so that is my IP address and let's say I wanted to block it right so I go here and I say okay I want to block on all TCP I want to block this number right but I can't do that all I can say is I allow this number so in order to do it I would have to enter everything but this number in here and you can enter ranges in with like these forward slashes and stuff like that but you would imagine that'd be really hard because you have to start and go like you'd have to start and go through every single IP address in the world to get it out of here and that's almost impossible and that's the key thing I want to remember about security groups um so that's security groups and there's also knackles knackles um they're associated with subnet so they probably show up under VPC I rarely touch knackles rarely ever have to um I mean they're great tools but you know for me I I just don't ever need them so knackles are associated with subnets so we can go here and try to see my Subnet tutorial so we created our subnet we got a knle for free and we can set inbound and outbound rules and so here here is where we could say Okay I want to add a new rule and I want to and I want to make the rule number 150 you always do these in hundreds okay or the power of 10 so that you can move them around easily and I can say all traffic that comes from this IP address I'm going to put the for/ Z that just means a single IP address and I say deny right and so now uh this my address I can't access that ec2 instance okay if I try to go there's nothing running on the server but if I was to try to use it I wouldn't be able to do it and and this applies to anything for that subnet it's not for a particular instance it's for anything in that subnet so hopefully that is is pretty clear there um but that's pretty much all you really need to know I mean there's lots of other stuff like Network firewalls all these other things it gets pretty complicated um it's well beyond what we need to learn here but uh what we'll do is tear down that ec2 instance okay we'll terminate that and once that instance is destroyed we can get rid of our security group and a bunch of other stuff and there's always a bunch of these darn things so we'll say delete One Security Group Associated so we go here this is the one we are using but I want to get rid of all these other ones okay if I go here it could be because like of inbound rules so see this one because you can reference another Security Group within a security group so I'm just going to go save that there say any my IP there whoops it's set to n uh NFS so that might have been set up for our access point or I could just delete it that' probably be easier okay so that's one that's kind of of a pain so I'm just looking for rules that might be referencing other security groups to get rid of them okay let's try this again we'll go ahead and delete I'm leaving the um I'm leaving the uh the defaults alone because those come with your vpcs and you don't want to get rid of those so it won't let me delete this one so I'm going to go edit that rule delete it save it you might not have this kind of clean up to do it's just might be me here you know um outbound inbound let's try this again here delete and I'll open this one up must be this one that is referencing the other one I'm just going to delete the rule and this is something that's just kind of frustrating with AWS but it's just how it is where sometimes it's hard to get rid of resources because you have to click through stuff so it's not always a clean you might have like lingering resources and this isn't going to cost us anything but it's just the fact that um that it just makes things harder to see what you're doing you know this last one really doesn't want to go away so I'm just trying to delete all the rules out of here get rid of it can I delete this one now one group associate it will not show me what it's talking about okay here it is um okay this is referencing it I think it was the one there was an old one I don't know what this is we'll go down here and we'll go here and delete that and while I've been cleaning all these up now we can go over to our inst instance make sure that it's terminated it is good because if our instance is not terminated we cannot destroy the VPC uh prior the VPC could not be destroyed unless you detach the internet gateway I wonder if it's going to still complain about that we'll say yes it actually looks like it includes it in the cleanup typ delete here there we go so we're all good we're all cleaned up there you are hey this is angre Brown from exam Pro and in this video I just want to show you cloudfront so let's make our way over to cloudfront cloudfront is a Content delivery Network and it's used to cash your data all over the place as you can see I have some older ones here if you have a splash screen what you can do is just look for the left hand side there might be a hamburger menu open that up and then click on distributions and what we're going to do is create a new distribution if you don't want to create one because these do take forever to create um you can just kind of watch along I don't even feel like I'm going to hit the um the create distribution button because I just hate waiting for so long but the idea is that you have to choose an origin and so the origin could be something like an S3 bucket load balancer media store this is where um the the content distribution network is going to Source its content right so if I say this bucket here um and I just it probably default to the root path the idea is that it's going to be able to pull content from there and then cach it everywhere and then down below you can say okay set the type of protocol redirect to here you can set up uh caching rules or like how often do you want it to uh cash like cash a lot don't cash a lot the great thing is like you have these Edge or these um l Edge function so you can uh read and modify the request and response to the CDN which is very powerful but what I'm going to do is I'm just going to go look at what we already have because again I said they take forever to spin up and we're not going to see too much if we do so once it's spun up um this is what it looks like so you'll have an origin it says where it's poting to you can create multiple Origins group them uh you can modify your behavior so that was basically what we were looking at before as you can see we have our Behavior there nothing super exciting we can set up error Pages you can restrict based on geographical locations so if you're for whatever reason if you if you're not allowed to serve content in UK you could say exclude this geographical region right so you have an allow list or a block list saying like Okay we can't do UK because like let's say you just don't want to do um let say England you don't want to do um uh gdpr for whatever reason you could block out I don't know why I'm having a hard time here Britain England it's England right United Kingdom there we go so you just say okay forget United Kingdom I don't have to do gdpr now uh for invalidations the idea is that you know it is a cache so things can get stale or just persist and so here you can just type in say I want to get rid of image.jpg and then you create that invalidation and then it will go delete it out of the cache and so the next time someone requests they'll get the the fresh content this usually doesn't take that long but that's pretty much cloudfront in a nutshell okay hey this is Andrew Brown from exam Pro and we are taking a look at ec2 also known as elastic compute cloud and so this is a highly uh configurable virtual server or it's also known as a virtual machine and that's what we're going to generally refer to it uh ec2 is resizable compute capacity it takes minutes to launch new instances and anything and everything on adabas uses ec2 instances underneath that's why we generally call it the backbone to all the adab services and uh you're going to just have to choose a few options here so the first thing you'll need to do is choose your OS via your Amazon machine image so that's where you get red hat Ubuntu Windows Amazon Linux Seuss it might also come with preinstalled libraries and things like that then you're going to choose your instance type that's going to determine things like your vcpus your memory so here you can see how many there are and you'll have like a monthly cost and that's the name of the instance type then you have to add storage so very commonly you're attaching elastic block storage or elastic files system system or service uh and so you know if you do choose your EBS uh you are going to have to determine what type it is so whether it's a solid state drive a hard disk drive a virtual Magnetic Tape or even attaching multiple volumes not just a single one and the last thing is configuring your instance so this is configuring the security groups the key pairs user data IM roles placement groups all sorts of things so we will experience in that because we will show you how to launch it an ec2 instance and it'll make a lot of sense if it does not make sense right now okay all right let's take a look here at ec2 instance fames so what are instance families well instance families are different combinations of CPU memory storage and networking capacity and instance families allow you to choose the appropriate combination of capacity to meet your application's unique requirements different instance families are different because of the varying Hardware used to give them their unique properties and we do talk about this thing about uh capacity reservation where adus can actually run out of a particular type of instance family because they just don't have enough Hardware in that data center and so you have to reserve it but let's go through the different types of instance families the first is general purpose and these are the names of the different families uh very popular ones is the t2 um the t2 and one that's really interesting is the Mac which actually allows you to run um a a Mac server so these are great balance of compute memory and network resources so you're going to be using these most of the time the use cases here would be web servers code repositories things like that then you have compute optimize so um they all start with C uh no surprise there they're ideal for compute bound applications that benefit from high performance processor their edge cases here are scientific modeling dedicated gaming servers ad server engines things like that then you have memory optimized um and so there's a variety here these are fast performance for workloads that process large data sets in memory um they're great for inmemory caches inmemory databases real time big data analytics then you have accelerated optimize so this is your P2 P3 P4 things like that these are Hardware accelerators or coprocessors these are great for machine learning computational Finance seismic analysis speech recognition if you're doing um uh ML on AWS you you'll start coming across these types AWS technically has a separate page on sagemaker ML machines but they're all pulling from these instance families okay then you have storage optimize so I3 i3n things like that these are highly High sequential read and write access to very large data sets on local storage the use cases here would be no SQL in memory or transactional databases data warehousing for the certified Cloud practitioner you just need to generally know these five categories not the names of the instance families if you're doing um Associates or above you definitely want to know these things in a bit more detail and I want to say that commonly instance families are called instance types but an instance type is a combination of size and family but even aws's do mentation doesn't make this family distinction clear but I know this because you know in Azure they make that very clear and and gcp and so I'm bringing that language over here to just kind of normalize it for you okay let's take a look at what ec2 instance types are so an instance type is a particular instance size and instance family and a common pattern for instance sizes you'll see is things like Nano micro small uh medium large xlarge 2x large 4X large 8X large and you know generally they're to the power of twos but sometimes it'll be like 12 14 16 or it's even uh and so when you go to launcher ec2 instance you're going to have to choose that instance type and so here you can see you know here is our T2 micro and then we have um the small the medium the large the x large okay but there are exceptions to this pattern for sizes so you know there is one particular one called uh Dot metal and so that's going to indicate that this is a bare metal machine and then sometimes you get these Oddball ones like 9x large so you know the rule of power of two or even numbers is not always the case uh but generally it'll be pretty even for you know the start here okay uh just talking about instance sizes so the easy to instance sizes generally double in price and attribute so uh just bringing up these numbers a little bit closer starting at the small here you're going to notice one two doesn't maybe double there but four and here we see 12 2 4 uh almost doubles there almost doubles there but I want to show you that the price is generally almost double so 16 33 67 135 and so a lot of times like you always have the option to say okay do I want to go to the next instance size up or have uh an additional instance of the same size and sometimes it's a better approach to get an additional instance because then you can distribute it across another a uh but then you also meet additional capacity so there you go so we talked about dedicated instances and hosts a little bit but let's just make that distinction very clear so dedicated hosts are single tenant ec2 instances designed to let you bring your own license so Bol based on machine characteristics and so we'll compare the dedicated instance to the dedicated host across isolation billing uh physical characteristics visibility Affinity between a host and instance targeted instance placement automatic instance placement and add Capac using allocation request so for isolation for dedicated instance you're going to get instance isolation so you can have the same customer on the same physical machine but there is virtualization there for them and there's a guarantee of that um for a dedicated host you have physical server isolation so you get the whole server for billing uh on a dedicated instance it's per instance billing and it's going to have an additional fee of $2 per region and for dedicated host it's per host billing so it's a lot more expensive but you get the whole machine uh for visibility of physical characteristics you're not going to get any of that information for a dedicated instance for dedicated host you are such as sockets core host host ID and this is really important when you have a bring your own license and they're saying this license is for x amount of corers or x amount of sockets then we have Affinity so there's no affinity for dedicated instance for dedicated hosts you'll have consistency with deoy to the same instance to the same physical server uh there's no control of Target instance placement for dedicated instance you do have control on a dedicated host for auto automatic instance placements you have it for both and to add capacity using allocation requests it's a no for dedicated instance and it's a yes for dedicated host so I want to come back to the main point that's what's highlighted here is that on a dedicated host you have visibility of sockets core host ID and this is really really important when you're bringing your own licens byol such as um you know Microsoft SQL servers where you have to specify the menac cores and things like that okay so we've been talking about uh tendency and I just wanted to make it very clear uh the difference between the different levels of tendency on AWS so we have three okay so we got dedicated host so your server lives here and you have control of the physical attribute so basically the whole server okay uh then we have dedicated instances so your server is on the same uh a physical machine as other customers but the actual slot that you have the dedicated instance will always be the same uh and then we have uh the default so your instance will live somewhere on the server uh and when you reboot it it's going to be somewhere else so there's no guarantee that it's going to be in the same place every single time okay hey this is Andrew Brown from exam Pro and in this follow along we're going to be looking at ec2 and also um services that are adjacent to it so like Auto scaling groups load balancers elastic IPS things like that so we fully understand ec2 um you don't have to know tons for the exam but you should be able to go through the motions of this with me so that you can cement that knowledge um for some of those deeper Concepts like working with key Pairs and things like that so let's make our way over to the ec2 console and learn what we can learn um and generally when you go to the ec2 console it'll bring you to the dashboard for whatever reason it didn't bring me there and then the idea here is that on left hand side we can make our way over to instances okay and this is where we can launch our first instance so if we go here and launch our instance the first thing we're going to be presented with is to choose our am or Amazon machine image and so that is a template that contains the software configuration so the operating system applications and other binaries that would be installed on that OS by default all right and so we have a variety that we can choose from in the quick starts and generally the ones that you're going to see first are the ones that ad support so there are uh um Amis or operating systems that ads will support when you contact them and then there's ones that are outside that where uh they'll still help you with but they might not have the knowledge on so just understand that if you pick from these core ones you're going to be in good shape uh the most popular is the Amazon Linux 2 because it's part of the free tier and it is is very minimal and well hardened by AWS so it's a very good choice there but you can see you can install a bunch of things so like if you want to launch a Mac OS server you can absolutely do that a red hat uh Suzie Ubuntu a Windows Server you name it they have it um if you wanted something more farther out there you can go to the marketplace and uh subscribe to one that is managed by company basically everything exists Under the Sun here or you could get a community Ami so these are ones that are contributed by the community for free but we're going to go back to quick start here and what I want you to notice is that there is this Ami ID that's how we can uniquely identify what we are using IF if we were to change region even with the same Amazon L 2 instance this thing will change so just understand that it is regional based and it comes in a 64bit variant and a arm variant and so we're going to be using the x86 here you can notice here you can change it on the right hand side we're going to stick with x86 I'm going to go ahead and hit next so now we're going to choose our instance type and so this is going to decide um uh greatly how much we're going to be spending because the larger it is the more we're going to spend so see this T2 micro if we wandered into the pricing for that we go to ec2 pricing AWS and once we get to ec2 pricing we want to go to on demand and from here this will load and so down below we can kind of go find our price it should show us it should show us the list ah here it is okay so I can say a T2 micro and we can see the On Demand is this so it seems really cheap what you got to do is do the math so so if you do time 730 that's how many hours there are in a month if we launch a T2 micro and let's say we didn't have the free tier we you do if you first made your account you're going to have 700 750 hours for free with the free tier but if you didn't it would only cost you $8 and and 46 USD okay so just be aware of that if you ever need to figure something out go there copy it do the math 730 it's pretty easy so here we have a T2 micro and the t2 family it's going to have one V VC CPU notice that it has a V for virtual so there could be more than a single CPU on the underlying Hardware but we're only going to have access to one virtual CPU we have one gigabyte of memory it's for low to moderate Network performance so that's a factor that can change if you need like uh uh gigabit stuff like really fast connections for on Prem hybrid connections and you have specialized servers for that but for this this is fine the TT micro is great uh if you want you can also search uh this way to see all the instance families and things like that you can filter for current Generations all generations so this is fine okay so from there we're going to go to configure our instance type you can say let's launch multiples of these instances let's turn on spot to uh save money and try to bid for a particular price we can change our VPC it's going to default to the default VPC um if you have no subnets just going to pick one at random here which is fine um whether to Auto assign a public IP address if you do not have an IP address you cannot reach the internet so generally you want this to be enabled this is dependent on the subnet whether it will default to enabled but doesn't matter if you have an ec2 instance in a private or public subnet you can always override this and give it a public IP address you have placement groups which allows you to play servers together closely not something for the certified Cloud partitioner there's capacity reservations so if you're worried about any us running out of this you can reserve capacity so that's kind of interesting domain join directory this isn't something that I've done much with but I imagine that has something to do with um a direct active directory or something like that to join information then you need to uh have an IM roll and we absolutely do need an IM roll here so what I want you to do is create a new Ro just going to close off these other tabs here and we will go wait a moment create a new role here and we want to do this for ec2 so we say ec2 is what we're creating the rule for we'll hit next and um I don't know if I have a policy but I'm going to go ahead and um well I don't need to make a new policy but I just want SSM and the reason I want SSM is so that I can um uh use sessions manager to log in so we don't have to use key pairs we will use key pairs but if we didn't want to use it that's what we could do and this used to be the old Ro and'll tell you hey go use this new one here so I just want to make sure I know which one it is and so we'll just checkbox that on we'll hit next we can add tags right here it' be uh well actually we don't need to add any tags here so that's fine we'll hit next and then I'll just say uh my SSM ec2 roll okay and we'll create that rooll and now that we have created that Ro we can go back to our first tab here and give this a refresh and then drop down and it should show up here if we go down here a little bit we could turn on extra monitoring there is monitoring built in but if you wanted to uh monitor it to a lower uh like it more frequently you could do that as well we want share tendency right this is where you change the dedicated instance or dedicated host obviously these class more but we're going to stick with shared elastic inference so this is for um uh attaching a a fractional GPU great for ML not something that we want there's credit specification I don't remember seeing this before selecting unlimited for credit specification allows for to burst beyond the Baseline so it's for bursting here you can attach an uh EFS uh so if you need a file system that you want to mount or attach um then there's the Enclave option so Nitro Enclave enables you to create is compute environments to further protect your uh and securely processed highly sensitive data so it might be something you might want to checkbox on um based on your use case and then down below our we have our ability to enter our user data and this is something we want to do because we want to install aachi so that we have something to work with here so what I'm going to do is make a shebang so that is a pound and an exclamation mark I know that's really small so I'll try to bump up my font here so you can see what I'm doing and we're going to do a forward SL bin and a for bash on the next line here we're going to do yum install hyphen y httpd um that's going to install Apachi and why it's not called Apache I don't know why but they call it httpd there's no Apachi in the name there and so we'll say system CTL start httpd system CTL enable httpd so we're saying start up Apachi and then make sure that it stays running if we restart our machine very simple so from there we will go to our our storage we'll say add our storage and this is at 8 gbes by default we could uh uh turn that up to 30 if we like so you can go all the way up to 30 if you like um and you might want to do that but I'm going to leave it at 8 we could change our volume type I'm fine with gp2 because it's very cost effective and if we want to turn on encryption and you should always turn on encryption there's no reason not to and so we'll turn that on it's not like it's going to cost you more it's going to be the same clost it's just your choice there if do want to add a tag yes we're going to add a name and we're going to say my ec2 instance okay and so that's going to give us a name which is something we would really like to have then we have a security group I'm going to just create a new security group called my um ec2 SG here and just say my ec2 SG something you cannot do is rename a security group once you've made it so make sure you don't make a spelling mistake up here and we want to be uh accessing that httt HTT or it's going to launch a website so in order to do that we need to make sure we have HTTP as a type with the port ad open and we want it from anywhere so we'll say anywhere and that will be 0.0.0.0 for size0 and that's for the ipv4 this is for the IPv6 okay so we'll just say internet and this is for SSH right and for this um I would probably suggest to say my IP but since we might be using a cloud shell to do that we're going to leave it as anywhere so that we don't have any issues connecting so from here we'll r and launch and you can review what it is that's going on here it's going to say here hey you have an open port that's okay we we want the internet to see our website because that's the whole point there and we'll go ahead and launch it it's going to ask for a key pair we can go down and say proceed without key pair but what I'm going to do is I'm going to create a new key pair because I want to show you how those work and I'm sure we've already done in this course once but we'll do it again and so I'm going to just name this as my ec2 instance here and then we're going to go download that key pair it's going to download a pem file there and so now we can go ahead and launch that instance and while that is launching so I'm going to just close this other tab here we're going to click on The View instances and so here is that instance that's how we put the tag so we could have a name there we're going to wait for that to start but as that's going I'm going to make a new tab by just right clicking here on the logo click anywhere pretty much to do that and uh once we do that we'll click on cloud shell and as that is going what I want to do is take this pen down below I'm going to move it to my desktop to make it easier for me to upload I'm doing this off screen okay and uh once this environment is running I'm going to go ahead and upload that okay so we'll just give it a moment to do that we're also waiting for the server to spin up as you'll notice there is a public IP address here it says it's running so if we want we can copy it we're looking for those two checks to pass so the server could be available but generally you want to wait for those two system checks because one says Hey the hardware is fine the Network's fine things like that okay but if I take that IP address paste it on it up here we have the web page so that is working uh no problem there so that's great and we'll go over to Cloud shell and that is still starting uh it's not the fastest but that's just how it is and um you know we'll get going here in a second as soon as this decides to load there we go so it's loaded I can type clear here just to clear that screen out and so what I want to do is upload that PM file so I'm going to go and upload that file we're going to go ahead and select it I'm going to go to my desktop here whoops my desktop and we are going to choose my ec2 instance pem all right and from there we'll hit upload and that's going to upload that pem file once that is uploaded we're going to do LS okay and so uh this is from a previous tutorial so I'm going to go ahead and just delete that other one there we'll say remove EFS example pem yes okay we'll type clear and then what we can do here is Type in chamod and um I believe it's 400 and what do we call this my ec2 instance PM if you hit tab it will autocomplete which is nice and if you do lsen la we can take a look at that file and see it should look like this should have only one R here here so the idea is you're locking it down so it's not writable or executable it's just readable because that's what you have to have it if you want to SSH and so if we want to ssh what we'll do is hit the connect button here and we have four options they just give you too many options it's going to be a fifth one for sure soon but right now we're talking about SSH so for SSH um we had to chamod our file which we did and then we need to use this DNS to connect to it and so this is the full line here if you click on this copy that over and paste it in that should be everything and notice we're doing ec2 user followed by this you could put the IP address in here instead if you preferred so if you were over here you could go and take that IP address which is I think shorter nicer but um you know if you just click that one button it works that's fine you always have to accept the uh the fingerprint then you'll be inside the instance you can type who I to see which user you are you're the ec2 user that's the user that ads creates for their Amazon Linux instances um it's going to vary per um Ami so not all Amis have an ec2 user it might be something else but that's generally the ones that a US uses for their supported ones and so if we do um an LS again we're in the server right now we can tell because it says right here or we do a PWD we can kind of just kind of look around so I think it's going to be at VAR ww that's where HT httpd or Apache always uh puts their files here so if I go in here whoops I'm just looking looking for um the index file so I thought the index file was in cdar WW HTML well where the heck is it so I'm G to just touch a file here and see if it overrides it oh I don't care I'll just type Pudo and what we can do is just try to restart this system CTL um there's a very similar command that's like uh service and so I always forget the order of it so I think it'd be I'm just checking um probably uh restart httpd and so failed to restart the policy was not provided as the name service um Service uh maybe pseudo there we go and so if we go back here I'm going to see if it changed because it will take whatever is in the index HTML file so if there's no file there it's going to uh show that there and so what I can do is I can edit this file I'm going to type VI index HTML and um I'm going to hit I for insert mode oh says it's readon so what we have to do Q uh colon Q quit oops uh clear LS and so what we need to do is do pseudo VI index HTML and so Vim every single key is a hotkey okay um and I'm not teaching Vim here but I'm going to teach you the basics but the idea is that when you're here notice that the cursor is blinking when I hit I it enters insert mode now I can type normally so I'd say hello uh hello Cloud okay and I'm going to hit escape to go back to um navigation mode whatever you want to call it I'm going to hit colon so it brings up the command I'm going to type in uh write and quit Okay and hit enter and so I'll type clear and so whoops clear and so we'll hit up till we get that command pseudo system CTL restart hbd we'll hit that hit enter okay and it should restart pretty fast there it is it says hello Cloud I probably didn't even have to restart it to do that but anyway so now that instance uh you can see how we're updating that so what I want to do is just do a sanity check and make sure that if we restart this instance that we're going to be able to um have a poy running that's something you should always do if you have an app and you or anything and you install it restart your server make sure that everything works so what I'm going to do is uh just hit exit here so we go back to the top level cloud shell type clear I'm going to go back over to my ec2 instance might have to click around to find it here and what I want to do is reboot it okay and if I reboot the machine the IP address is going to stay the same okay so if I reboot it the IP address is going to to stay the same and the reboot is going to happen really fast if we want to observe that reboot we could go over to um here on the right hand side go to the system log and it would show us that it it had rebooted I think so yeah it does cloud in knit there I think it rebooted not sure um but anyway if it's rebooted then we can go ahead and connect and make sure everything's fine so let's just go here and hit enter and let's see if the what the web page is here notice that it's hanging right so it's probably because it's still restarting even though it doesn't look like it is and that's something that you have to understand about the cloud is that you have to think about what you're doing and have confidence that it is happening and also just double check it but uh that's something that can be kind of frustrating because these are globally available Services uh uh they're massively scalable and so one of the tradeoffs is that you don't always have the most uh responsive uh uis ads has one of the most responsive uis out of all the major providers but even still like sometimes I have to second guess myself but the page uh right now is not working now it is so it's fine so it just took time for that to reboot and so um what I want to do is connect a different way so we're going to go here and we're going to hit um we're going to checkbox that on we're going to hit connect and instead of using SSH client we're just going to go to sessions manager and hit connect and this is the preferred way of connecting because you don't have to have this this SSH key and that's a lot more secure because if someone has that key and you you know you hand it to someone they could hand it to somebody else and then you have a big problem on your hands so here this looks very similar but if you type who am I it actually logs in as the SSM user which is kind of annoying so I type in sudo Su I have to do this hyphen here and then I'm going to say the user I want to be which is E2 user and then if I type who am I we are the correct user you can't do anything in that SSM hyphen user or or SSM user so you got to switch that over and I can bump this up to make it a bit larger so this is obviously not as nice as working over here or even in your own terminal but it's a lot more secure and it's tracked and all these other things so we really should be using it okay and um I really don't like having to bump this up with my HTML I'm going just go back to zero there there's probably like a way to configure that but anyway uh let's just go and take a look at our file I'm going to type VI again and we're going to do VAR www HTML index HTML I'm going to put pseudo in front of there and again remember you have to hit I to go into insert mode and uh what I'm going to do is just take capitalize that hello Cloud give that exclamation mark colon WQ to quit WR quit going to go back here refresh okay so we don't have to restart our server which is nice all right so um that's that that's pretty clear so I'll hit terminate here and I don't think we need Cloud shell for anything so I'm just going to close that and so that's pretty much it when it when it comes to working with an an ec2 instance and so the next thing I want to show you is elastic IP okay okay so now I want to show you elastic IP uh commonly abbreviated to EIP and so all that is it's just a um a static IP and IP that does not change because this ec2 instance here notice that it's 54 163 4104 and what would happen if we were to stop this instance not reboot it but stop it because for whatever reason we had to or or um for whatever reason and if we were to stop this instance and we were to restart it okay uh and we have to wait for it to stop but that IP address is going to change okay so 54 1634 104 hopefully we can observe that I'm just going to write that down so we do not forget so I can prove to you that it does change and now that it it's still stopping here so as that's stopping we're just going to go ahead and get our elastic IP and I will'll prove that as we go here so I'm going to go over to here and so what I want to do is Reserve or allocate an elastic IP address and so I'm going to say us east1 and it's going to say from the Amazon Pool of ipv4 addresses so ads has a bunch of IP addresses they're holding on to and so you can just allocate one and once you've allocated that's your IP address so coming back to here okay this is stopped notice there is no public IP address we're going to start it again okay and then we'll just checkbox it on and we just have to wait a little while to see what the IP address is going to be I'm going to tell you it's going to be something else so if I go back here this is 54235 12 110 and our original one was 54 163 4 104 so the the reason why it's important to have the same address is that if uh you have a load balancer well not a load balancer but if you have a domain pointing to your uh your server and you reboot then the rout you have a dang a dangling um path or route where uh Revenue 3 was going to be pointing to nothing and so Aus does have things to mitigate that like aliases and things like that but um in general you know there's cases where you just have to have a static IP address and so we had allocated one over here and if we want to assign it we're going to associate that elastic IP address we're going to drop it down choose the cc2 instance um I suppose the private IP as well and then we're going to go ahead and hit allocate or associate and once it's Associated it should now have 34 199 121 116 so we go over here and we're going to take a look here and that's its IP address we can pull it up okay and that's that so yeah that's the lastic IP okay so now that we um have our lastic IP we have our ec2 instance running let's say um you know we lose the server we terminate it so we would lose all of our configuration so if we wanted to bake this Ami to save it for later what we'd have to do is go and create an image so to do that we go to the top here and we go to images and templates and we can create an image or we can create a a a template which is a lot better but for the time being we're going just go ahead and create an image and when you create an image you're basically creating an Ami and so here I'm just going to say uh my ec2 and I'm going to go 0 to just kind of like number it so that's a very common numbering just do three zeros and then increment by one and so here I can just say my Apachi server and so it's going to save some settings like the fact that there is a a volume you could uh save some tags there and so I might go ahead and add a tag and you'll say name and we'll just say my ec2 server or so that it remembers that okay and then what we'll do is go ahead and create our image and so this can take a little bit of time if we go over to uh images here it's going to be spinning for a while and uh we'll just wait until it's done okay all right so after waiting a little while here our Ami is ready so we're just waiting for it to go available if you do not see it just make sure you hit the refresh um because sometimes ads will just been forever um and so that's just something you'll have to do so you know hopefully that makes sense what we'll do is is go make our way back over to instances here and we can launch one this way well actually we can do it over from um the Ami page so what I'm going to do is just terminate this instance we're all done with it okay and we'll hit terminate it's totally fine and it had a message about elastic IPS about releasing them so when it does that the elastic IP is still over here so it did not release it so what we're going to do is go ahead and disassociate the elastic IP okay and then we're also going to release the IP address because if we don't we're going to have this IP address that's sticking around that we're not using it this is going to charge us a dollar month over month so just be aware of those because that's just kind of like a hidden cost there but what we're going to do is go over to Ami and we're going to select it here we're going to go to actions we're going to go ahead and launch and what it's going to do is make us fill out all this other stuff again so if you had made a launch template uh we wouldn't have to fill out all this stuff it'd be part of it but that's what I'm trying to show you with this Ami stuff so um instead of filling out all this what I'm going to do is now go create a launch template just to kind of show you that that would be a much easier way to work so we go over to E2 instances and then left hand side we're looking for a launch template launch launch configurations is the old thing um launch templates here we go so what we'll do is create ourselves a launch template we'll just say my apachi server and then down below we need to choose our Ami so we're going to go here and we need to type it in so what would we call it my ec2 I really don't like this uh search here it's very slow and frustrating but once we find it whoops that's why I don't like it because a lot of times it'll be loading and you'll end up clicking the wrong thing okay so I don't like this okay we'll type in my give it a second there it is just wait because it will keep loading and then once it's loaded hit enter and so it has that instance selected and then from there uh don't include in the launch template so here we could be explicit I would say I want this to be two T2 micro but we could exclude it if we wanted to we could specify the key pair here um not that we really want to use key pairs we'll say my ec2 instance then down down here for the networking we can specify uh that security group we created so we created one here called my ec2 SG um storage is fine it's going to be encrypted network interface is fine Advanced details what I want to do is set the IM instance profile that's really important because we don't want to have to figure out that roll every single time so we'll put that there and that should be everything and we could put user data in there but it's already baked into our Ami so we don't have to worry about anything so what I'm going to do here is go ahead and create this launch template and then we're going to view this launch template temp plate and so now what we can do is then use it to launch an instance okay and so we're going to look here and it's very similar to dc2 except it's vertical so we're going to have one instance it's going to use that Ami that instance type so you can see how you can override them which is nice we're going to check the advanced details make sure that I am profile is set and we'll go ahead and launch this from a template so from there we can go ahead and click the instance value there and just be aware that when you do click through links like that you'll end up with the search so I was just checkbox that off so I can see what I'm doing and so we're just waiting for this instance to show up and the only thing I noticed is it didn't said are darn tags so I wanted the name in there and I think it's because we said it in the Ami but it didn't carry over to the launch template so I'd have to go back to the launch template and update it probably so if I go into here into the launch template um we can probably modify create a new version and then add tags there we say name uh my uh Apachi server I realize I'm changing it between them and so that should allow us to have a version two so we'll create that and but anyway that will be for the next time we launch it okay and so this instance is running I'm going to go grab the IP address the server may or may not be ready we'll take a look here and so it's just spinning if it's spinning it's either the server is not ready or um um our ports not open so it was just getting ready to work there so it is working now so that is our launch template so now you know we don't have to worry about losing our stuff and if we need to make new versions We can just bake new Amis and increment them at uh Inc and attach them as new versions of that launch template okay all right so what I want to show you in this follow along is to set up an auto scaling group for our ec2 instance and the idea behind this is that um we'll be able to always ensure that a single server is running or uh increase the capacity if the demand requires it so in order to create an Autos scaling group we can go all the way down below to here um and so you know I really don't like the Autos scaling group form but it's okay we'll work our way through it so the first thing is we'll have to create our or name our Autos scaling group so we'll just say my ASG and then we'll have to select a launch template which is great because we already have one and then we'll have to select the version I'm going to select version version two so that it applies that tag name and we'll go to next and so here um it's going to need to select a VPC and then we need some subnets so we're going to choose three just because to have high availability you have to be running in at least three different availability zones so that's why we have three different subnets and then down below we have the instance type requirements so uh T2 micro launch template looks good to me so we'll go ahead and hit next and then from here we can choose to do a load balancer and so I want to do the load balancer separate so we won't do it as of yet but very often if you're going to have an H group you're going to usually have a load balancer but we'll talk about that when we get to that point there so we'll just go to the bottom here and hit next and so this is what's important so how many do you want to be always running and so we always want to have one and maybe the maximum capacity is two and you want the desired cast capacity be to be around a particular number so if you had three and you said the desired is two um there are things that could try to work to always make sure there's two but we just want to have one for this example we can set up uh scaling policy so I do Target tracking scaling policy and so here we could do it based on a bunch of different things so if the CPU utilization when were 50% it would launch another server so that might be something we might want to set so I'll we're not going to uh try to trigger the scaling policy but we might as well just apply because it's not too hard then you can also do a scaling uh scale in protection policy so if you want to make sure it does not um uh reduce the amount of servers that's something you could do we can add a notification to say hey there's a scaling policy happening here which is fine we don't have to worry about that um and there's tags so add tags to help you search filter Etc um so I'm going to put a tag here I'm going to say name I'm just wondering if this is going to attach to the ec2 in or this is for the auto scaling group you can optionally choose to add tags to instances by specifying tags in your launch templates so we already did that so I don't need to put a tag here and so we can review our um Auto scaling group and go ahead and create that auto scaling group okay and so that auto scaling group expects there to be a single instance so what it's going to do is it's going to start launching an instance and so what I'm going to do is just get rid of this old server because we don't need it anymore this old one here okay and you can already see okay that the load balancer is launching this new one here and remember we updated our version two to have that name so that's how we know that it is so if we go back over to our autoscaling group okay it's now saying there's an instance we don't have a status as of yet and so there are ways of doing a status checks to for to determine whether or not the server is working um because if the server is unhealthy what it would do is it would actually kill it and then start up a new one right so if I go down below it's right now doing an ec2 health check and the ec2 health check just means that is the server working right um is it running it doesn't necessarily mean like hey can I load this web app um but you know it's very simple so we'll give it a moment here to start up and just make sure that it's working okay and I think it's ready so if I take that public IP address here and paste it in there it is okay so if we were to tell it to increase the capacity to three then what it would do is it would launch three and then it should probably launch it all evenly to those other it should evenly launch it to all those other uh availability zones and then we'll have something that is highly available okay so that's pretty much it for this and then we'll move on to Auto scaling groups all right so we have our uh ec2 instance now managed by an Autos scaling group and the great thing is that if we terminate this instance this Autos SC group will launch another uh instance to meet our particular capacity um the only thing though is that if we were to have multiple E2 instances running like three of them um how would you distribute traffic to the allall right so you know you have an IP address coming in from the internet uh but let's say you want to evenly distribute it and that's where a load balcer comes into play and even if you have a single server you should always have a load balancer because it just makes it a lot easier for you to scale when you need to and you it acts as an intermediate layer where you can attach a web application firewall you can attach an SSL certificate for free so there's a lot of reasons to have a load balancer so what we'll do is go down below on the left hand side and we're going to make our way over to load balancers and we're going to create ourselves a new load balancer so I'm going to hit create load balancer here and you're going to see we have a lot of options application load balcer Network load balcer Gateway load balcer and then the classic load balcer and so we are uh running an application so I'm going to create an application load Bouncer and here I'm going to say my ALB um for an application load balancer this is going to be internet facing it's going to be ipv4 um we're going to let it launch in the default um subnet and we're going to choose the same the same uh uh azs right so that we get the same subnets as our that are in our Autos scan group and that's really important okay and then here um you know we need to have a security group and I just feel like selecting the same one here because that should work no problem there and we want to make sure that we can listen on Port 80 and that it's going to forward it to a a um a Target group it looks like I might have a Target group there from before so just to reduce that confusion you won't have this problem I'm just going to double check if that's true so do I have a Target group from there from before yes I do that came from I'm not sure it might have been created by um elastic bean stock and wasn't deleted okay so I'll go back over to here just so there's less confusion and we were selecting our Target group so we're going to have to create a new Target group so we go over here and here you can choose whether it's instance IP Lambda application load balancer so you could point it specifically to an IP address and so if it was a static IP address that would make sense uh apparently you can Port uh point it directly to instances I don't remember seen that option before I guess that makes sense yeah no sorry that makes sense because that would go to uh vpcs okay or sorry U asgs Autos scaling groups it's just that you are pointing them to Auto scaling groups you're not pointing them to instances so that's why that's confusing so I'm going to say my um Target group it'll be for Port 80 here um protocol http1 is fine we want to be in the same U VPC so that's fine as well and down below we have our health check and so the for slash means that it's going to hit the index HTML page and so if it gets back um something healthy and that that something healthy is going going to be um uh Port 80 then it's going to be considered good and then we can say the threshold of check so I'm just going to reduce this so it's not so crazy so we'll say three uh two and then 10 okay and then it expects back A200 which I think that's what we'll get back so we'll go ahead and hit next and so now we have our Target group and it should register instances so it's saying hey we detected this and this fits the requirements for this so this is now uh this e two instance is now in this target group okay so we can go back over here and we can now drop down and choose whoops hit the refresh button and choose our Target group so I'm not seeing it here so I'm going to go back over here oh we didn't create it okay and now we can go back hit refresh and there it is and yeah that looks all good so we'll go ahead and hit create load balcer we can view the load balancers and these create really fast if we scroll on up what we can do is now access our server through this DNS name okay so we copy that paste that on in there does it work not as of yet so if it's not working there because we did say look at these instances another way is to directly associate your Autos scaling group with the load balancer so if I go into here and we hit uh edit there is a way aha load bouncer so we want to associate this way and we want to say this target group here and also while we're here we might as well set it to elb so it's going to use the elb check so that makes it so the Autos scaling group if it wants to uh restart a server it's going to use the elb's check which is a lot more sophisticated and then what we'll do is go hit update okay and now if we go back over to our load balancer we just going to close some of these tabs so it's less confusing uh load balcer here I think we should be able to see through here whether it is seeing it let's go down below listeners monitoring integrated Services no it's going to be through the target group okay I mean it already had it there so maybe it's just that it hasn't finished the check so over here it has a health status check oh now it's healthy okay so if it's healthy in the Target group and the load bouncer is pointing to it then it should technically work so we're going to go ahead and uh copy the DNS again here make a new tab paste it in and there it is okay so that's how you're going to access um all your all your instances that are within your autoc scaning groups you're going to always go through the DNS and so if you had a row 53 uh domain like you had your domain managed by AWS you just point to the load balancer and that's how you hook it up so that's pretty much it so yeah there you go all right so there you go we learned everything we wanted to know about ec2 so the the last thing to do is to tear everything down so we have a load balcer we have an autoc scanner group um and those are the two things we'll have to pull on down so the first thing would be to take down the autoscaling group and when you delete an Autos scaling group it's going to delete all the ec2 instances so we'll do it that way if you tried to delete the ec2 it would just keep on spinning up so you have to delete that first and so as that's deleting then we'll be able to delete our load balancer I'm going to try anyway to see if I can delete it at the same time and so I'll go up here I'm going to go ahead and delete that uh load balancer actually it did work no problem going to make sure I don't have any elastic IPS I'm going to also make sure I don't have any key pairs you can keep your key pairs around but like I just want to kind of clean this up so okay okay and that instance should be terminating got to go back to the Autos scan group here if we click into it we can check um its activity here so it's just saying successful so it is waiting on elb connection draining which is kind of annoying because we deleted elb so there's nothing to drain um draining is just to make sure that uh you know there's no interruptions when terminating services so just trying to be smart about it and all I want to see is that it's just saying terminating over here and then I think we're done okay so we'll just have to wait a little while here okay and I'll see you back in a moment okay all right so after waiting a very long time it did destroy so if I go down over to uh my load balcer here you're going to see that it does not exist so there was that connection draining thing which was kind of annoying it's probably because I deleted the load balancer first and then the um the uh the Autos scaling group second and probably connection draining was turned on but it's not a big deal we just waited it and it did eventually delete so we're pretty much all done here so there you go hey this is Andrew Brown from exam Pro and we are taking a look at ec2 pricing models and there are five different ways to pay with ec2 remember ec2 are virtual machine so we have on demand spot reserved dedicated and AD us save savings plans so what we'll do is look at these in summary here and then we'll dive deep onto each of these different pricing models so for on demand you are paying the a low cost and also you have a lot of flexibility with this plan uh you are paying per hour so this is a pay as you go model uh or you could be paying uh down to the second which we'll talk about uh the caveats there when we get to the on demand section this is suitable for workloads that are going to be shortterm spiky unpredictable workloads uh that cannot be interrupted and it's great for firsttime application and the on demand pricing model is great when you need the least amount of commitment for spot pricing you can see we can save up to 90% which is the greatest Savings of out of all these models here uh the idea here is you're requesting spare Computing capacity that adus is not using and that's where you're going to get that savings you have flexible start and end times uh but your workloads have to be able to handle interruptions because these servers can be stopped at any time to be giving to more priority customers uh and this is great for noncritical background jobs very common for like scientific computing uh where jobs can be started and stopped at any given time this has the greatest amount of savings then you have Reserve or reserved instances this allows you to save up to 75% this is great for steady state or predictable usage you're committing uh with AWS uh for ec2 usage over a period of one or threee terms you can resell un uh unused reserved instances so you not totally stuck with this if you buy them this is great for the best longterm savings then you have dedicated so these are just dedicated servers and technically not a pricing model but more so that the fact that it can be utilized with pricing models um but the idea here is it can be used with on demand reserved or even spot this is great when you need to uh have a guarantee of isolate hardware for Enterprise requirements and this is going to be the most expensive uh so yeah there you go and we'll dive deep here okay so the on demand pricing model is a pay as you go model where you consume compute and then you pay later so when you launch an ec2 instance by default you are using that on demand pricing and On Demand has no upfront payment and no longterm commitment you are charged by the second up to a minimum of 60 seconds so technically a minute or the hour so let's just talk about the difference between those uh per second billing and those per hour billing so per second are for Linux windows windows with SQL Enterprise windows with SQL standard windows with SQL web instances that do not have a separate hourly charge and then everything else is going to be um per hour and so you know when I'm launching ec2 instance I can't even tell when something's per second or per hour you just have to know that it has a separate hourly charge but generally you know if you're just launching things it's going to probably be the per second billing when you look up the hourly or the uh the pricing it's always shown in the hourly rate so even if it is using uh per second billing when you look up that pricing it's always going to show it to you like that but on your bill you'll see it down to the second okay up to the first 60 seconds in on demand is great for workloads that are shortterm spiky or unpredictable uh but when you have a new app development this is where you want to experiment and then when you're ready to uh start saving because you know exactly what that workload is going to be over the span of a year or three that's where we're going to get into reserved instances which we'll cover next hey this is Andrew Brown from exam Pro and we are taking a look at reserved instances also known as RI and this is um a bit of a complex topic but uh you know if we do get through it it's going to serve you well through uh multiple adaa certifications so let's give it a bit of attention here so RI is designed for applications that have a steady state predictable usage or required Reserve capacity so the idea is that you are saying to ads I'm going to make a guaranteed commitment uh saying this is what I'm going to use and I'm going to get savings uh because abos knows that you're going to be spending that money okay so the idea here is that the reduced pricing is based on this kind of formula where we have term class offering the ra attributes and payment options technically the ra attributes don't exactly factor into it other the fact that they an our attribute could be like the instance type size uh but I'm going to put that in the formula there just because it is an important component so let's take a look at each of these components of the formula to understand how we're going to save so the first is the term so the term uh the idea here is the longer the term the greater the savings so you're committing to a oneyear or threeyear contract with AWS um and one thing you need to know is that these do not renew so at the end of the year the idea is that you have to purchase again and when they do expire your instances are just going to flip back over to On Demand with no interruptions to service then you have class offerings and so the idea here is the less flexible the offering the greater the savings so the first is standard and this is up to a 75 reduction in the price compared to on demand and the idea here is you can modify some ra attributes which we'll we'll talk about when we get to the um R tribute section there then you have convertible so you save up to 54% reduced pricing compared to on demand and you can exchange uh RIS based on the r attributes if the value is greater or equal in value and there used to be a third class called schedule but this no longer exists so if you do come across it just know that ads is not planning on offering this uh again for whatever reason I'm not sure why uh then there are the payment options so the greater upfront the greater the savings so here we have all upfront so full payment is made at the start of the term partial upfront so a portion of the cost must be paid upfront and the remaining hours in the terms are build at a discounted rate and then there's no upfront so you are build at a discounted hourly rate for every hour within the term regardless of whether the reserv is being used and this is really great this last option here because basically you're saying to AWS you're saying like I'm just going to pay my bill as usual but I'm going to just tell you what it's going to be and I'm going to save money so if you know uh that you're going to be using a T2 medium for the next year uh you can do that and you're just going to save money okay so RIS can be shared between multiple accounts within an organization and unused RIS can be sold in the reserved instance Marketplace but we'll talk about the limitations around that when we get a bit deeper in here just to kind of show you what it would look like in adus console and they updated it I love this new uh UI here the idea here is you're going to filter BAS on your requirements and that's going to show you RIS that are available and then you'll just choose the desired quantity you can see the pricing stuff there you're going to add it to cart you're going to check out and that's how you're going to purchase it okay so another factor to that formula were RI attributes and sometimes the documentation calls them RI attributes sometimes they call them instance attributes but these are limited based on class offering and can be uh uh can affect the final price of the r instance and there are four R attributes so the first is the instance type so this could be like an M4 large and this is composed of an instance family so the M4 and then the instance size so large okay then you have the region so this is where the reserved instance is purchased then you have the tendency whether your instance runs on shared so the default which uh would be multitenant or a single tenant which would be dedicated hardware and then you have the platform whether you're using Windows or Linux even if you're using on demand of course this would just affect your pricing but there are some limitations around here which we'll get into as we dive a bit deeper here with RI okay all right let's compare Regional and zonal Ri so when you purchase an RI you have to determine the scope uh for it okay so this is not going to affect your price but it's going to affect the flexibility of the instance uh so this is something you have to decide so we're going to talk about Regional RI which is when you purchase it for a regional and zonal RI when you purchase it for an availability Zone so when you purchase it for regional RI it does not Reserve capacity meaning that there's no guarantee that those servers will be available so if ads runs out of those servers uh you're just not going to have them but when it's zonal uh you are reserving capacity so there's a guarantee that those will be there when you need them um in terms of uh AZ flexibility uh you can use the regional RI for any AZ within that region but for the zonal ri you can only use it for that particular region we're talking but instance flexibility um you can apply the discount to uh any instance in the family regardless of the size uh but then when we're looking at a there is no instance flexibility okay so you're just going to use it for exactly what you defined you can cue purchases for regional RI you cannot cue purchases for zonal Ri so there you go let's talk about some ra limits here so there's a limit to the number of reserved instances that you can purch purchase per month and so uh the idea here is that you can purchase 20 Regional reserved instances per region and then 20 zonal reserved instances per a so if you have a region that has three azs you can have uh 60 um zonal reserved instances in that region okay there are some other limitations here so for regional limits you cannot exceed the running on demand instance limit by purchasing Regional reserved instances the default for on demand limit is 20 so before for purchasing your RI ensure on demand limit is equal to or greater than your RI you intend to purchase you might even want to open up a service uh limit increase just to make sure you don't hit that wall for zonal limits you can exceed your running on demand uh instance limit by purchasing zonal reserved instances if you're already uh have 20 on demand instances and you purchase 20 zonal reserved instances you can launch a further 20 on demand instances that match the specification of your zonal reserved instances so there you go let's talk about capacity reservation so ec2 instances are backed by different kinds of hardware and so there is a finite amount of servers available within an availability Zone per instance type of family remember an availability zone is just a data center or a collection of data centers and they only have so many servers in there so if they run out because the demand is too great you just cannot spin anything up and so that's what's happening you go to launch specific ec2 instant type but Abus is like sorry we don't have any right now and so the solution to that is capacity reservation so it is a service of ec2 that allows you to request uh a reserve of VCU instance type for a specific region and a so here you would see that you just select the instance type platform AZ tendency the quantity and then here you might manually do it specify time or you might say okay I can't get exactly what I want but can give me something generally around uh that kind of stuff or that type that I want so the reserve capacity is charged at the selected instance type on demand rate whether an instance is running in it or not and you can also use Regional reserved instances With Your Capacity reservations to benefit from billing discounts so there you go so there are some key differences between standard and convertible Ri so let's take a look at it here so the first is that with standard RI you can modify your tributes so you can change the a within the same region you can change the scope uh from a zonal RI to original RI or vice versa you can change the instance size uh as long as it's a Linux and it has the default tendency you can change the network from ec2 classic to VPC and vice versa but when you're looking at convertible you you don't modify R tributes you perform an exchange okay and so standard RIS cannot do exchanges where convertible RI you can uh exchange during the term for another convertible r with new R attributes and this includes instance family in in type platform scope and tendency um in terms of the marketplace you C uh they can be bought in standard RI uh in the marketplace or you can sell your RI if you uh don't need them anymore uh but for convertible RI they cannot be sold or bought in the marketplace you're just dealing with ads directly okay hey this is Andrew Brown from exam Pro and we are taking a look at the reserved instance Marketplace we had mentioned a R so let's give it a little more attention here so it allows you to sell your unused standard RI to recoup your spend for RI you do not intend or cannot use so reserved instances can be sold after they have been active for at least 30 days and once databus has received the upfront payment you must have a US bank account to sell RI on the ri Marketplace there must be at least one month remaining in the term for the ri you are listing you will retain the pricing and capacity benefit of your reservation until it's sold and the transaction is complete your company name and address upon requests will be shared with the buyer for tax purposes a seller can set Only The Upfront price of an RI the usage price and other configurations such as instance type availability Zone platform will remain the same as when the ri was initially purchased the term length will be rounded down to the nearest month for example a reservation with 9 months and 15 days remaining will appear as 9 months on the R Market you can sell up to 20,000 USD in reserved instances per year if you need to sell more RI reserved instances in the gov Cloud uh region cannot be sold on the ra Marketplace so there you go hey it's Andrew Brown from exam Pro and we are taking a look at spot instances so adus has unused compute capacity that they want to maximize the utility of their idle servers all right so the idea is just like when a hotel offers booking discounts to fill vacant Suites or planes offer discounts to fill vacant seats all right so spot instances provide a discount of 98% compared to On Demand pricing spot instances can be terminated if the Computing capacity is needed by other on demand customers but from what I hear rarely rarely does spot instances ever get terminated um it's designed for applications that have flexible start and end times or applications that are only feasible at very low compute cost so you see some options here like load balancing workloads flexible workloads Big Data workloads things like that um there is another service called abis batch which is for doing batch processing and this is very common what you use um spot WID and so you know if you find the spot interface too complicated you're doing batch processing you want to use this service instead um there are some termination conditions so instances can be terminated by adus at any time if your instance is terminated by ads you don't get charged for a partial uh hour of usage if you terminate an instance you will be still charged for an hour uh that it ran so there you go hey this is Andrew Brown from exam Pro and we are taking a look here at dedicated instances so dedicated instances is designed to help meet regulatory requirements inabus also has this concept called dedicated hosts and this is more for when you have strict server bound licensing that won't support multi tendency or cloud deployments and we'll definitely distinguish that in this course but just not in this slide in particular um and so to understand uh dedicated instances or hosts we need to understand the difference between multi tendency and single tendency so multi tendency you can think of like everyone living in the same apartment and single tendency you can think of it everyone having their own house so the idea here is that you have a server I'm just going to get my uh cursor or my pen out here to say server and you have multiple customers running workloads on the same hardware and the idea is that they are separated via virtual isolation so they're using the same server but it's just software that might be separating them okay and then we have the idea of single tency so we have a single customer that has dedicated Hardware so the physical location is what separates customers um and the idea here is that dedicated can be offered via on demand reserved and spot so that's why we're talking about dedicated here in the pricing model just so you know that you know even though these are a lot more expensive than on demand uh you can still save by using reserved and also spot which I was very surprised about um and when you want to choose dedicated you're just going to launch your ec2 and you'll have a drop down where you have that shared so that's the default dedicated so you have dedicated and dedicated host again we'll talk about dedicated host later when we need to here um and so again the reason why um you know Enterprises or large organizations may want to use dedicated instances is because they have a sec uh a security concern or obligation about uh against sharing the same Hardware with other adus customers okay hey this is Andrew Brown from exam Pro and we are taking a look at adus savings plans and this is similar to to reserved instances but simplifies the purchasing process so it's going to look a lot like RI at the start here but I'll tell you how it's a bit different okay so there are three types of saving plans you have compute Savings Plan ec2 instance saving plans and sagemaker saving plans uh and so you just go ahead and choose that you can choose two different terms so one year threee so it be simple as that and then you choose the following payment options so you have all upfront partial payment and no upfront and then you're going to choose that hour of the commitment you're not having to think about standard versus convertible uh Regional versus zonal RI attributes it's a lot simpler uh and let's just talk about the three different saving plans or types in a bit more detail so you have compute so compute savings plans provides the most flexibility and helps to reduce your cost by 66% these plans automatically apply to ec2 instances usage ads fargate ads Lambda service usage regardless of the instance family size AZ region Os or tency then you have ec2 instances so this provides the lowest prices offering saving up to 72% in exchange for commitment to usage of instance uh individual instance families in a region so automatically reduce uh your cost on the selected instance family in the region regardless of AZ size OS tendency gives you the flexibility to change your usage between instances with a within a family in that region and the last is Sag maker so helps you reduce Sage maker cost by uh up to 64% automatically apply to sagemaker usage regardless of instance family size component adus region if you don't know what sagemaker is that's ad's ml service and it uses ec2 instances or specifically ml ec2 instances so everything's basically using ec2 here um but there you go all right let's take a look at the zero trust model and the zero trust model is a security uh model which operates on the principle of trust no one and verify everything so what I mean by that is malicious actors being able to bypass conventional access controls demonstrates traditional security measures are no longer sufficient and that's where the zero trust model comes into play so with the zero trust model identity becomes the primary security perimeter uh and so you might be asking what do we mean by primary security perimeter the primary or new security perimeter defines the first line of defense and its security controls that protect a company's Cloud resources and assets um if this still doesn't make sense we do cover a part of the defense and depth where you see the layers of Defense from data all the way to physical and so you can kind of see you know what we're talking about in that model there but the old way that we used to do things is Network Centric so we had traditional security focused on firewalls and VPN since there were few employees or workstations outside the office or they were in a specific remote office so we treated the network uh the network as kind of like the the boundary so if you're in in office there's nothing to worry about but we don't think like that anymore because everything is identity Centric so this is where we have bring your own device remote workstations which are becoming more common uh we can't always trust that the employee is in a secure location we have uh identity based security controls like MFA we're providing provisional access based on the level risk from where when and what a user wants to access and identity Centric does not replace uh but it augments Network Centric security so it's just an additional layer of consideration for uh security when we're thinking about our Adas Cloud workloads okay all right so we just Loosely defined what the zero trust model is so let's talk about how we would do Zer Trust on AWS and so zero trust has to do a lot with identity security controls and so let's talk about what is at our disposal on AWS so on ads we have identity and access management IM this is where we create our users or groups or policies so IM am policy is a set of permissions that allow you to say okay this user is allowed to use uh these services with these particular action uh then you have the concept of permission boundaries and so these are saying okay um these aren't the permissions the user has currently but these are the boundaries to which we want them to have so they should never have access to um uh ml services and if someone's to uh apply them uh uh permissions it'll always be within these boundaries then you have service control policies and these are organizationwide policies so if you have a policy where you don't want anyone to run anything in the Canada region you can apply that policy at the organiz level and it will be enforced then within an policy there are the concept of conditions and so these are all the kind of like uh little knobs you can uh tweak to say how do I uh control based on a bunch of different factors so there is Source IP so restrict where the IP address is coming from a requested region so a restrict based on the region as we were just mentioned as an example uh multiactor off presence so restrict if MFA is turned off uh current time so restrict access based on time a day maybe your your employees should never be really using things at night and so that could be an indicator that someone is doing something malicious so you know only give them access during a certain time a day and so that's where we're going to figure out you know based on all these type of controls security controls uh to our adus resources we can kind of enforce the zero trust model adabs ads does not have a ready to use identity controls that are intelligent which is why adus is considered not to have a zero trust offering for customers and thirdparty services need to be used so what I'm saying is that technically you know this checkbox is this thing saying okay we can kind of do zero trust on AWS but the there's a lot of manual work and you know if I was to say okay um I don't want anyone using this at nighttime it doesn't really detect you know what I'm saying it's not going to say oh I think this time is suspicious andalicious so then restrict access only to these core services and anything outside of the services can't be used it just can't exactly do that without a lot of um work yourself and that's what I'm talking about here where we have a collection of a services that can be set up in an intelligence intelligent is detection way for identity concerns but requires expert knowledge so the way you might do that AWS is that everything all the API calls go through a cloud trail and so what you could do is feed those into Amazon guard Duty and guard duty is an intrusion uh uh intrusion detection and protection system so it could detect suspicious or malicious activity on those cloud trail logs and you could follow that up with mediation or you could pass that on to Amazon detective that could analyze investigate and quickly identify security issues uh that it could ingest from guard duty but I'm telling you that this stuff here is not as easy um for the consumer and so you of course you can do zero trust model but it's going to take a lot of work here and there are some limitations which we'll talk about next here so now let's see how we would do zero trust on adus with third parties so adus does does technically Implement a zero trust model but does not allow for intelligent identity security controls which you know you can do it but it's a lot of work so uh let's kind of compare it against kind of a third party where we would get the controls that we would not necessarily get with AWS so for example Azure active directory has a realtime and calculated risk detection Based on data points than AWS and this is based on device and application time of day location whether MFA is turned on what is being accessed and the security controls verification or logic restriction is much more robust so you know just as one particular example like device and application is not something that ads factors in uh with the existing controls or at least not in a way that is consumer friendly and you know I can't say on adus okay when you think that this is the type of threat only allow them access to these things or if you think they're in a risky area or risky uh location only give them access to you know these things where there's not sensitive data you can't exactly do that adus very easily and so this is where third party Solutions are going to come into play so you have Azure active directory Google Beyond Corp jump Cloud uh all these have more intelligent security controls for Real Time detection um and so the way you would use these is these would be your primary directories uh for Google Beyond Corp is just a zero trust framework so I guess you'd use uh Google's uh Cloud directory but the idea anyway here is that You' use single sign on to connect those directories to your adus account and that's how you access access those uh adus resources and you get this more robust functionality okay hey it's Andrew Brown from exam Pro and we're looking at identity now we need to know a bunch of Concepts before we talk about identity on AWS so let's jump into it the first is a directory service so what is directory service well it's a service that Maps the names of network resources to network addresses and a directory servic is shared uh infrastructure or information in infrastructure for locating managing administrating and organizing resources such as volumes folders files printers users groups devices telephone numbers and other objects a directory service is a critical component of a network operating system and a directory server or a name server is a server which provides a directory service so each resource on the network is considered an object by the directory server information about a particular resource is stored as a collection of attributes associated with that resource or op project uh wellknown directory Services would be a domain name service um so the directory service for the internet Microsoft active directory and uh they have a cloud hosted one called Azure active directory we have aachi directory service Oracle inter internet directory so o ID uh open ldap uh Cloud end identity and jump Cloud okay hey this is Andrew Brown from exam Pro and we are taking a look at active directory now you might say well we're doing adabs why are we looking at this well no matter what cloud provider you're using you should know what active directory is uh especially when it comes to identity because you can use it with AWS um so let's talk about it so Microsoft introduced active directory domain services in Windows 2000 to give organizations the ability to manage multiple on premise infrastructure components and systems using a single identity per user and since then it's uh involved uh evolved obviously it's uh running Beyond Windows 2000 as of today and uh they even have a managed one called Azure ad which is on Microsoft Azure but just to kind of give you an architectural diagram here the idea is that you would have your domain servers here uh and they might have child domains and the idea is that you have these running on multile machines so that you have redundant ability to log in from various places when you have a bunch of domains it's called a forest and then within a domain you actually have organizational units and when then within organizational units you have all your objects look like your users your printers your computers your servers uh all things like that okay hey it's Andrew Brown from exam Pro and we're talking about identity providers or ipds so hey this is Andrew Brown from exam Pro and we are talking about identity providers also known as idps so an identity provider is a system entity that creates maintains and manages identity information for principles and also provides authentication services to Applications with a federation or distributor Network a trusted provider of your user identity that lets you use authent uh lets you authenticate to access other service identity providers so this could be like Facebook Amazon Google Twitter GitHub LinkedIn uh Federate identity is a method of linking a user's identity across multiple separate identity management systems and so some things that uh we can use for that is like open ID so this is an open standard and decentralized Authentication Protocol allows you to be able to log in to different social media platforms using Google or Facebook account open ideas about providing who you are then we have ooth 2.0 this is an industry standard protocol for authorization oo doesn't share password data but instead uses authorization tokens to prove an identity between consumers and service providers o is about granting access to functionality and then we have samles security assertion markup language which is an open standard for exchanging authentication and authorization between an identity provider and a service provider and this is important use for samle which we use for single sign on via the web browser okay hey this is Andrew Brown from exam Pro we're looking at the concept of single sign on so SSO is an authentication scheme that allows a user to log in with a single ID and password to different systems and software as so allows it departments to administer a single identity that can access many machines and cloud services so the idea is you have as your active directory this is just an example of a very popular one You' use samle to do SSO and you can connect to All Things slacks Google workspaces Salesforce or your computer uh the idea here is uh once you uh log in um you don't have to log in multiple times so you log into your primary directory and then after that you're not going to be presented with a login screen some Services might show an intermediate screen but the idea is you're not entering your credentials in multiple times so it's seamless all right let's talk about ldap so lightweight directory access protocol is an open vendor neutral industry standard application protocol for accessing and maintaining distributed directory information Services over uh IP network so a common use of ldap is to provide a central place to store usernames and passwords ldap enables for same sign on so same sign on allows us to uh use a single ID and password but they have to enter it every single time they want to log in so maybe you have your on premise active directory and then it's going to store it in that ldap directory and so the idea is that um you know all these services like Google kubernetes um jenings is going to uh deal with that ldap server so why would you use ldap over SSO which is more convenient or seamless so most SSO systems are using ldap under the hood but ldap was not designed aily to work with web applications so some systems only support integration with ldap and not SSO so you got to take what you can get okay let's take a look here at multifactor authentication also known as MFA and this is a security control where after you fill in your user's name an email password you have to use a second device such as a phone to confirm that it's you that is logging in so MFA protects against people who have stolen your password MFA is an option in most Cloud providers and even social media websites such as Facebook so the idea is I have my uh username or email and password I'm going to try to log in this is the first factor and the second factor or multiactor is I'm going to use a secondary device so maybe my phone we're going to enter in different codes or maybe it's passwordless so I just have to press a button to confirm that it's me and then I'll get access so in the context to AWS it's strongly recommended that you turn on MFA for all your accounts especially the adus root account uh we'll see that when we do the follow alongs let's take a look at security keys so a security key is a second device used as a second step in authentication process to gain access to a device workstation or application a security key can resemble a memory stick and when your finger makes contact with a button of exposed metal on the device it will generate an autofill a security token a popular brand of security Keys is the UB key and this is the one I use and is looks exactly like the one that's right beside my desk it works out of the box with Gmail Facebook and hundreds more supports PH2 web offn uh u2f it's waterproof and Crush resistance it uh has variations like usba us uh NFC dual connectors on a single key can do a variety of things so when you turn on MFA on your adabs account you'll have virtual MFA device so that's when you're using something like a phone or using software on your phone to do that then there's the u2f security key ke so this is what we're talking about right now and there's even other kinds of Hardware MFA devices um which we're not really going to talk about but um you know just security Keys tie into MFA and this is a lot better way than using a phone because you know you can have it on your desk and press it um and you know you don't have to worry about your phone being not charged okay hey this is Andrew Brown from exam Pro and we are taking a look at itus identity and access management also known as I am and you can use this service to create and manage adus users groups uh use permissions to allow and deny their access to adus resources so there's quite a few components here let's get to it so the first is I am policies so these are Json documents which Grant permissions for specific users groups or a role to access services and policies are attached to IM identities then you have IM permissions or a permission and this is an API action that can or cannot be performed and they represented in the IM policy document then there's the IM identities so we have IM users these are end users who log into the console or interact with ad resources programmatically or via clicking UI interfaces you have IM groups so these these uh group up your users so they all share the same permission levels so maybe it's admins developers or Auditors then you have IM roles so these roles Grant ads resources uh permissions to specific ads API actions and Associate policies to a role and then assign it to an adus resource so just understand that roles are when you're attaching these to uh resources so like if you have an ec2 instance and you say it has to access S3 you're going to be attaching a a rooll not a policy directly okay hey this is Andrew Brown from exam Pro and we are looking at IM policies a little bit closer here and they are written in Json and contain the permissions which determine the API actions that are allowed or denied um and rarely do I write these out by hand uh because they have a a little wizard that you can use to write out the code for you but if you want to you absolutely can write it out by hand but we should know the contents of it and how these Json files work so the first thing is the version uh which is the policy language version and it's been 2012 for a very long time I don't see that changing anytime soon if they happen to change uh what or what the structure of the Json is then you have the statements and these are for policy elements uh and you're allowed to have multiples of them so the idea is that this is the the policies or permissions we should say uh that you uh plan on applying then you have the Sid this is a way of labeling your statements um this is useful for like visualization or for referencing it for later on but a lot of times you don't have to have a sid um then there's the effect it's either allow or deny then you have the action so here we're saying give access to S3 for all actions under it there's another action down below where it's saying give access I'm going get my pen tool out here just to create a service link role so that's a cross account role there then there's the principal so this is the account user role or Federated user to which you would like to allow access or deny so we're specifically saying uh this IM am user named Barkley um in our adus account there uh then there are the resources so the resources to which the action applies um so in this one up here we are specifying a specific adus bucket here we're saying all possible resources in in adus account and then the condition so so there's all sorts of different kinds of conditions so this is a string like one and it's saying look at the service name and if it starts with this or that then they'll have access to that so this person even though it says all resources they're really only going to have access to RDS okay so in this follow along we're going to take a closer look at I am policies so go to the top and type in I and what we'll do is make our way over here uh all the way over to policies and what I want to do is create a new policy that only has access to uh um limited resources so um let's say we want to create an Amazon ec2 instance and that E2 instance has access to a very particular S3 bucket so what I want you to do is make your way over to S3 and we're going to create ourselves a new bucket and I'm going to go ahead and create a bucket here we're going to call this um policy tutorial and I'm going to just put a bunch of numbers here you'll have to randomize it for your use case and so now that we have our bucket what we're going to do is go ahead and create a policy and the policy is going to choose a service we're going to say S3 and what I want to do is only be able to list out actions I'm going to expand this so I don't want everything so we're just going to say list buckets okay and then what we'll do is uh expand this here and I want to save for a particular bucket so we'll go back back over here click into our bucket and uh we're going to go ahead and set those permissions by finding that Arn we're going to paste that we're going to paste that Arn up there sometimes it's a bit tricky it vanishes on you and we could set other conditions if we wanted to but this is pretty simple as it is and so that's our rule here right so we're saying this policy allows us to list this bucket for that okay so what we'll do is go ahead and hit next we'll hit review and we'll just say my bucket policy and we'll create that policy okay so there's a few other things I think that I'd like to do with this policy I'm going to pull it back up here so if we want to find it uh used to be able to filter these based on the ones that you created but um yeah they show like the little I so these are ones that I've created up here and so there's my bucket policy and I feel like I want to update this policy to have a bit of extra information here so I'm going to go edit this policy no you know what I think this is fine so what I want to do is now create a ro and we're going to create a new Ro and I'm going to call this um well before I do I need to choose what it's for so it's going to be for ec2 so we're going to go ahead and hit next we're going to choose our policy so my bucket policy there it is and I want to add another one here because I want to be able to use sessions manager because I really don't want to use an SSH key to check that this works and so um for this I I need to use SSM so I'm going to type in SSM here and I'm just make sure this is the new one so this policy will soon be deprecated use Amazon SSM manag core instance should always open these up and read them and see what they do and so that's the one that's going to allow us to access uh Simpson manager so we can use um sessions manager okay and so we're going to say my ec2 roll for S3 and we're going go ahead and create ourselves a roll so now that we have our roll I'm going to go over to ec2 and I'm going to go ahead and launch myself a new instance we're going to choose Amazon ltic 2 we're going to stick with T2 micro I'm going to go over to configuration here everything is fine here um I'm fine with all that storage is fine we'll go to Security Group and I don't want any ports open because I'm not going to be using SSH we're going to launch this instance I don't even want to keep pair okay and then we're going to go over here and so what we're waiting for is this instance to launch as that is going what I want to do is go over to my S3 bucket and I want to place something in this bucket so I do have some files here um so what I'm going to do let's create a new folder here whoops I'm going to go back and I'm just going to create a folder first create a folder Enterprise D and I'm going to click into this and then I'm going to upload all my images here so you'll have to find your own images off the internet this is just the ones I have and we'll go ahead and upload those give that a moment okay and so we don't have access to read those files we'll adjust our policy as we go so that we can do that okay so this instance should be running um it has doesn't have the two status checks pass we should be able to uh connect to it so click on connect here and so we have options like easy to instance connect sessions manager SSH client I want you to go to sessions manager it says we weren't able to connect to your instance common reasons SSM agent wasn't installed we absolutely have that installed the required I am profile oh right so we were supposed to attach I forgot to do we were supposed to attach an I am profile right so an I profile is the role uh it or the it holds the role uh that's going to give the permissions to that instance and since we didn't add it we have to go retroactively add it after the fact and so I'm going to have to modify the IM roll and we're going to choose my ec2 roll for S3 and we're going to save that and actually when that happens you have to reboot the machine you only have to do that if you have no Ro attached like prior no profile attach and you're attaching it for the first time but after that you never have to reboot the machine this is the only case where you'd have to do that that's why when I launch an ec2 instance I always at least have the SSM R attached the managed one that gets sessions manager so that I don't don't ever have to do a reboot in case I have to update the policy and so we will give that a moment there it says initializing so I'm going to try again to connect to it okay and we still don't have that option there um so I'm going to go back to my instances I'm going to check to see if the role the rule or policy is attached or profile I should say so I'm just looking for it here there it is and so if I click into this into the r we can see that we have the Amazon SSM managed instance core there so that's set up and then my uh bucket policy so this has everything that it should be able to do it no problem okay so I'm going to try that again okay so now the connect shows up ads is finicky like that you just have to have confidence in knowing what you're doing is correct okay we'll go ahead and hit connect and I didn't have to use SSH keys or anything and this is a lot more secure way to connect your instances when it logs Us in it's going to set us as the SSM user but we want to be the um the ec2 user okay that's uh ads always makes their am like their Linux version as the ec2 user and that's what you're supposed to use but it's just you just that's how you have to get to that you just have to type that pseudo suyen ec2 user okay just once and if you type who am I that's who you are if you type exit you'll go back to that user so I type exit and I type who am I I'm now this person so I'm going to go back hit up go back in there type clear so now I want to see if I have access to S3 so I have to do OS S3 LS want's see if I can list buckets it says access deny so I mean that kind of makes sense because if you have list buckets and we're just saying only that bucket that might not make a whole lot of sense so I'm going to go back to my policy I might just written a a crummy policy but we'll say I am here if we have that one open we should just go here and click on this policy here I'm going to edit that policy so what I'm going to do is I'm just going to change it and we all resources review the policy save changes and we'll see how fast that propagates okay because I'm pretty sure I don't have to do anything here it should just now give me full access to S3 just going to keep on hitting up here so what I'm going to do is I'm just going to take like a three four minute break going to get a drink I'm going to come back here and see if this propagates I'm pretty sure I don't have to do anything for that to propagate and I think that I've attached everything correctly here okay okay so I haven't had much luck here it's still having the same issue so if that is happening what I'm going to do um is I'm just going to reboot it because maybe I didn't give it a good opportunity to reboot there again I don't think we should have to reboot it every time when we we're changing um uh things there but we will give it another go here and see if if that fixes that problem there so no sessions matter is going to time out here which is totally fine it's going to kill that session there um and so what we'll have to do is close this out because there's not much we can do with that and we're going to go ahead and go back to connect and so we're waiting for this button to appear because it is rebooting so if we want to monitor that stuff usually there is an option here to monitor where it'll show us the system logs of what it's doing doing so here it's just like restarting the machine I'm not sure if we expect to see something after this so I can click that there and uh yeah it's easy to get turned around this so I can connect to it again now we'll type in pseudo Su hyphen ec2 user ads S3 LS and we still have access deny for list buckets so if that's the case it could be that um sometimes you need other permissions when doing list policy like uh list buckets so if that's the case we're going to do a sanity check I'm just going to say all permissions here okay and this way there's no way that I've set this incorrectly um it just has to work now type this in there we go okay so there has to be something more to it so just because you say list buckets you know like means there must be more to it right so if I go here to this right and I say whoops and I say uh list buckets here we'll say copy paste okay here it's saying maybe I need get object as well so I just know from using a long time that that's the case that it could be more than one thing so you know that was in the back of my mind that that could be happening and I guess that is but notice I didn't have to restart my uh my server boot my server to get those to work um uh but anyway let's go lock that down and see if we can just kind of make this uh more focused so let's say um all resources I'm going to specify the condition so I might want to just say for particular buckets we say specific when you checkbox everything then you have to do this so for storage accounts these are fine any for objects that could be something we'll say multi region access bucket any bucket but what I'm going to say is I want to only allow them to access things in a particular bucket and so if I go to Arn here um what is our bucket name our bucket name is policy tutorial 3414 whatever right and so we can actually give it a wild card or we can say Enterprise D and we learned this in the course that uh you can provide orangs with randomize things there I don't know know if I spelled it wrong over here so I should really double check I should probably just copy it oops I just don't want to type it wrong and so this okay means that we should only be able to get stuff from there I'm going to review the policy see if it takes save the changes and if I just view the Json here notice it says anything from here right so allow S3 anything as long as it's within here and then it also broke it up into sub one4 here okay um so anyway what I want to see is what happens if I upload something into the loose area here so I'm to say upload and I'm going to just say add a file we're just going to grab data here and upload it go back to our bucket there there's our file we have that stuff in there and so if I go back over to my ec2 instance which I'm still connected to uh who am I okay great clear um so I'm going to say ads S3 LS see if that works still it does good and so what I want to do is see if I can copy a file locally so I'm going to do Abus S3 copy I think it was S3 no it's just S3 copy polic uh S3 SL SL policy tutorial 34 141 whoops 34 tutorial hyphen 34141 slash Enterprise D data.jpg I think it's a JPG let's go double check yeah it is okay and then I just want to say data.jpg and it downloaded it right so I'm going to remove that one and so now what I'm going to do is I'm just going to see if my policy is working or maybe my permissions aren't exactly what I think they are and I was able to download it so it's these policies can get kind of tricky because like this one says allow all actions for these but then these say all actions and so that makes it hard because I want get object so another thing we can do and if that one doesn't work really well I'm just going to write one by hand it's not that scary to write these by hand you just get used to it so I'm going to say effect um is it disallow or maybe it's deny deny action S3 get off object I believe that's what it is resource and then I'm going to specify exactly the resource I don't want it to allow so we're going to say R AWS S3 three colons policy tutorial 34141 uh and just say data.jpg now if this is not valid it's going to complain and say hey you didn't write this right and it and it's fine okay so we'll save those changes and so that should deny access to that right hopefully I got the policy right okay so that one doesn't work which is fine and that one's fine so that worked we were able to deny that but you can see there's a little bit of an art to creating these policies uh as you make more of them it becomes comes a lot easier so hopefully it's not too scary but uh that's all there really is uh to it that I want to show you today so what we're going to do is clear out this bucket we're done with this bucket here so we'll say delete whoops we got to empty it first and we'll just say permanently delete here okay and we will exit that out we're going to go ahead and delete that bucket grab its name here and uh we'll go back over here I think I forgot to delete this Bucket from earlier I'm just going to delete that because I don't need that bucket so that's okay with you just going to go ahead and delete that and we have that ec2 instance running so we want to stop that go ahead and we're going to terminate that yes please and then we'll go to IM and do some clean up I have some custom roles I've been creating um you know from prior things a lot of those usually there's a way to uh We've redesigned it okay where's the redesign this is the redesign that can't be it because there'll be like rolls that ads makes I think these are all rolls that I've made um I don't want to delete service roles but I want to get rid of some of these CU I just have too many you know it's getting out of hand for me and I'm going to just see if it will let me delete all of these let's delete those there we go just clean up a bit I still have a lot here but there's like service roles that adus crates once and you really don't want to delete those because you don't um and then I have a bunch of these like like I'm never going to use these so I might as well detach them delete detach you really don't want to keep like rolls that you're never going to use around things like that like gauze we going to be using that again delete there's that bucket we just created but anyway you get the idea so uh yeah that's uh that's I am okay principal of lease privilege PP is the computer security concept of providing a user roll or application the least amount of permissions to perform an operation or an action and the way we can look at it is that we have just enough axis so Jaa permitting only the exact actions for the identity perform a task and then we have just in time jit permitting the smallest length of duration an identity can use permission so usually when we're talking about PLP it's usually a focus on here uh but now these days uh there's a larger focus on jit as well and so jit is the difference between having long lived um uh permissions or access Keys versus shortlived ones and the most Progressive thing in PP is now riskbased adaptive policies so each attempt to access a resource generates a risk score of How likely the request is to be from a compromised source so the risk score could be based on many factors such as device user location IP address what service is being accessed and when did they use MFA did they use Biometrics things like that and right now as of this time it just does not have a riskbased adaptive policies built into I am you can roll your own um what's interesting is Cognito has riskbased adaptive policies they call like um adaptive authentication but that's for user pools and not identity pools user pools is for getting access to an app uh that you have built through an ipd where identity pools in cognito is about getting access to adus resources so uh you know I'm sure abos will get it eventually but they just don't have it right now and you have to rely on thirdparty um identity Solutions uh to get riskbased adaptive policies now talking about just enough access and just in time just in time is like you think how would you do that with ads you just add and remove permissions manually well one thing you could do is use something like console me so this is an open source Netflix project to selfer shortlived I am policies so an end user can access it of his resources while enforcing Jaa and jit and so there's a repo there as well um but the idea is they have like this self serve wizard so you say I want these things and then the machine decides okay you can have them or you you don't need them and it just freezes you up asking people and worrying about the length and stuff like that okay hey this is Andrew Brown from exam Pro and we are taking a look at the IUS route user uh and this gets confusing because there's an account root user and regular user so let's distinguish what those three things are so here we have an AB account and the account which holds all the adus resources including the different types of users then you have the root user this is a special account with full access that cannot be deleted and then you have just a user and this is a user for common tasks that is assigned permissions so just understand that sometimes people say it was account they're actually referring to the user and sometimes when they're saying it was account they're actually referring to the ads account that holds the users I know it's confusing it just it's based on what people decide the context is when they're speaking so the ads account user is a special user who's created at the time of the ads account creation and they can do uh they have a lot of conditions around them so the re user account uses an email and password to log in as opposed to the regular user who's going to provide their account ID Alias username and password the root user account cannot be deleted the root user account has full permissions to the the account and its permissions and cannot be limited and when we say it cannot be limited we're saying that if you take an IM policy to explicitly deny the user access to resources it's not something you can do however you can do it in the case of adus organizations with service control policies because a service control policy applies to a bunch of accounts so it just it's one level above and so that is a way of limiting root users but generally you can't limit them within their own account uh there can only be one root user uh per ad of us account the root user is instead for very spec specific and specialized tasks that are infrequently or rarely performed and there's a big list and we'll get into that here in a moment and the root uh account should uh not be used for daily or common tasks it's strongly recommended to never use the root users access keys because you can generate those and use them it's strongly recommended to turn on MFA for the root user and adus will bug you to no ends to tell you to turn it on so let's talk about the uh tasks that you should be performing with a root user and only the root user can perform so changing your account settings this includes account name email address root user password root user access Keys other account settings such as contact information payment currency preference regions do not require the root user credentials so not everything um restore IM user permissions so if there's an i IM admin so just a user that has admin access who actually revokes their own permissions you can sign into the root user to edit policies and restore those permissions um so you can also activate IM access to the billing and cost Management console you can view certain tax invoices you can close your ad's account you can change or cancel your adus support plan register as a seller in the reserved instance Marketplace enable MFA uh Delete on S3 buckets edit or delete an Amazon S3 bucket policy that includes an invalid VPC ID or VPC endpoint ID sign up for govcloud and something that's not in here which this I took this from the documentation but uh you can use the adus uh account user to create the organization you can't create that with any other user so um you know the ones I highlighted in red are very likely to show up your exam and that's uh why I highlighted them there for you but there you go hey this is Andrew Brown from exam Pro and we are taking a look at adus single sign on also known as adus SSO and so this is where you create or connect your Workforce identities in ads once and manage access centrally across your ads organization so the idea here is you're going to choose your identity Source whether it's it SSO itself active directory SLE 2.0 IDP you're going to man manage user permission centrally to ads accounts applications samle applications and it uses uh it can you get single click access to all these things so you know just to kind of zoom in on this graphic here uh you know you have your on premise active directory it's establishing a ad trust connection over to Able single sign on you're going to be able to apply permissions to access resources within your adus account so via adus organizations in your organizational units down to your resources you can also use ads SSO to access custom samle based applications so you know if I built a web app and I uh like the exam Pro platform and I wanted to use sample based uh connections for single sign on there I could do that as well and you can connect out SSO access to your business Cloud application so Office 365 Dropbox slack things like that so there you go well let's take a look here at application integration so this is the process of letting to Independent applications to communicate and work with each other commonly facilitated by an intermediate system so Cloud workloads uh strongly encourage systems and services to be Loosely coupled and so inabus has many services for the specific purpose of application integration and these are based around common system systems or design patterns that utilize application integration and this would be things like queuing streaming pubsub API gateways State machines event buses and I'm sure there are more but that's what I could uh think about that are the most common ones okay so to understand queuing we need to know what is a messaging system so this is used to provide asynchronous communication and decouple processes via messages and events from a sender receiver or a producer and a consumer so a queing system is a messaging system that generally will delete messages once they are consumed it's for simple communication it's not real time you have to pull the data it's not reactive and uh a good analogy would be imagining people that are queuing in a line to go do something so for ads it's called Simple queuing service sqs it's a fully managed queing service that enables you to decouple and scale microservices distributed systems and serverless applications so a very common use case in a web application would be to queue up transactional emails to be sent like sign up reset password and the reason why we have queing to decouple uh those kind of actions is that if you had a long running task um and you had too many of them it could hang your application so by decoupling them and letting a separate compute uh service take care of that um that would be something that would be very useful okay let's take a look here at streaming and so this is a different kind of messaging system um but the idea here is you have multiple cons consumers that can react to events and so in streaming we call messages events and then in a queing system we just call them messages but events live in the Stream for long periods of time so complex operations can be applied and generally streaming is used for realtime stuff whereas queing is not necessarily real time and so ad's solution here is Amazon kinesis you could also use Kafka but we'll focus on Kinesis here so Amazon Kinesis is the aist fully managed solution for collecting processing and analyzing streaming data in the cloud so the idea is that you have these producers so that are producing events could be ec2 instances mobile devices could be a computer or traditional server they're going to go into the data stream there's a bunch of shards that scale and there's consumers on the other side so maybe red shift wants that data Dynamo DB S3 or EMR okay but the thing you have to remember is that streaming Is For Real Time data and as you can imagine because it's real time and it's doing a lot more work than um a queuing system it's going to cost more okay so we have another type of messaging system known as Pub sub so this stands for publish subscribe pattern commonly implemented in messaging systems and a pub sub system the sender of messages the Publishers do not send their message directly to receivers they instead send their messages to an event bus the event bus categorizes their messages into groups then receivers of messages subscribers subscribe to these groups whenever new messages appear within their subscriptions the messages are immediately delivered to them so the idea is you have Publishers event bus subscribers and event buses appear more than once so it actually appears in streaming appears in this Pub sub model and then it can appear in other variations so you're going to hear it more than once the word event bus um so the idea here is the publisher has no knowledge of who the subscribers are subscribers do not pull for messages messages are instead automatically immediately pushed to the subscribers and messages and events are interchangeable terms in Pub sub all right and so you know the idea here with Publisher subscribers just imagine getting like a um a magazine subscription right if you think of that you kind of think of the mechanisms that are going here in terms of practicality it's very common to use these as a realtime chat system or a web hook system so you know hopefully that gives you an idea there in terms of aws's solution we're using simple notification service SNS this is a highly available durable secure fully managed Pub sub messaging service that enables you to decouple microservices distributed systems and serverless applications so here we have a variety of Publishers like the SDK the CLI cloudwatch Aid with Services you'll have your SNS topic you can uh filter things fan them out and then you have your subscribers so Lambda sqs emails PS looks very similar to streaming but again you know um you know there's not a lot of communication going back between it it's just Publishers and subscribers and it's limited to you know these things here so it's a very managed service right whereas uh Kinesis you can do a lot more with it okay so what is API Gateway well it is a program that sits between a single entry point and a and multiple backends API Gateway allows for throttling logging routing logic or formatting of the requests and response when we say request and response we're talking about https uh requests and responses and so the service for ads is called Amazon API Gateway so API Gateway is just a type of pattern and this is the few cases where ADS has named the thing after what it is and so we have Amazon API Gateway which is a solution for creating secure apis in your Cloud environment at any scale create apis that act as a front door for applications to access data B is logic or functionality from backend services so the idea is that you have data coming in from uh mobile apps web apps iot devices and you actually Define the API calls and then you say where do you want them to go so maybe tasks are going to go to your lambdas um and then other routes are going to go to RDS Kinesis ec2 uh or your web application and so these are really great for having um this uh being able to Define your API routes and change them on the Fly and then and always route them to the same place okay so what is a state machine it is an abstract model which decides how one state moves to another based on a series of conditions think of a state machine like a flowchart and for AWS the solution here is AWS step function so coordinate multiple a Services into a servess workflow a graphical console to visualize the component of your application as a series of steps automatically trigger and track each step and retries when there are errors so your application executes in order as expected every time logs the state of each step so when things go wrong you can diagnose and debug problems quickly and so here's an example of using a bunch of um uh steps together on the uh the aabus step functions service and so you know this is generally applied for servess workflows but it is something something that is very useful in application integration okay so what is an event bus an event bus receives events from a source and routes events to a Target based on rules so I'll get my pen tool out here so we have an event it enters the event bus we have a rules tell it to go to the Target it's that simple and we have been seeing event buses in other things like uh streaming and uh Pub sub but Abus has this kind of event offering uh that is kind of high level it's called event bridge and it's a service event bus service that is used for application integration by streaming realtime data to your applications the service was formerly known as event Amazon cloudwatch events they gave it a renaming to give it uh a better um opportunity for users to know that it's there to use uh and they also extended its capabilities and so the thing is that a lot of AD services are always admitting events and they're already going into this bus and so if you utilize this service um it's it's a lot easier than having to roll your own thing uh with other services so Amazon event bridge will just Define an event bus so there is an event bus holds event data defines the rules on event bus to react to events you always get a default event for every single Aus account you can create custom event buses scope to multiple accounts or other adus accounts you have a SAS event bus scope to thirdparty SAS providers you have producers these are adus services that emit events you have events these are data emitted by Services they're jent objects that uh travel the stream Within the event bus you have partnered sources these are thirdparty apps that can emit events to event buses you have rules these determine what events to capture and pass to targets and then targets which are Ada services that consume events so yeah it's all just this great builtin um uh uh stuff that's going on here and so you know there there might be a case where you can use event bridge and save your time uh a lot of time and effort uh doing application integration okay hey this is Andrew Brown from exam Pro and we are taking a look at application integration services at a glance here so let's get through them so the first is simple notification service SNS this is a pub sub messaging system sends notifications via various formats such as plain text email https web hooks SMS text messages sqs and Lambda pushes messages which are then sent to subscribers you have sqs this is a queuing messaging system or service that sends a events to a queue other applications pull the queue for messages commonly used for background jobs we have step functions this is a state machine service it is it coordinates multiple a Services into a servess workflow easily share data among lambdas have a group of lambdas wait for each other create logical steps also works with fargate tasks we have event Bridge formerly known as cloudwatch events it is a service event bus that makes it easy to connect applications together from your own application third party services and adus services then there's Kinesis a real realtime streaming data service creates producers which send data to a stream multiple consumers can consume data within a stream used for realtime analytics clickstreams ingesting data from a fleet of iot devices you have Amazon mq this is a manage message broker service that uses aachi active mq so if you want to use aachi active mq there it is manage kofka service and this gets me every time because it says msk and that is the proper initialization but you'd think it'd be MKS it is a fully managed Apachi Kafka service Kafka is an open source platform for building realtime streaming data pipelines and applications similar to conis but more robust very popular by the way we have API Gateway a fully managed service for developers to create publish maintain Monitor and secure apis you can create API endpoints and rote them to ad Services we have appsync this is a fully managed graphql service graphql is an open source agnostic query adapter that allows you to query data from many different data sources so there you go hey this is Andrew Brown from exam Pro and we are comparing virtual machines to Containers so I know we covered this prior but I just want to do it one more time just to make sure that we fundamentally understand the difference before we jump into containers so the idea is that if you were to request an ec2 instance it has a host operating system that we don't really know much about but we don't really need to know uh and then the idea is you have a hypervisor which allows you to deploy virtual machines and so when you launch an ec2 instance you're actually launching a VM on top of a hypervisor on a server uh with on uh within the adabs uh data centers servers there and you're going to choose an operating system so like Ubuntu and it might come with some preinstalled packages or you're going to install your own libraries packages and binaries and then you're going to decide what kind of workloads you want to run on there so it could be D Jango uh mongodb so your database and some kind of queing system like rabit mq the difficulties with virtual machines you're always going to end up with some unused space because you're going to want to have some Headroom uh to make sure that uh you know if you know Dango needs more memory or or mongod DB needs more storage that you have that room that you can grow into but the idea is that you're always paying for that even when you're not utilizing it and so you know that can be uh not as cost effective as you'd like it to be so when we're looking at um doing this again and we are using containers um instead of the provisor we have container virtualization a very common one would be called Docker Damon for Docker of course and so now you're launching containers and so maybe you have Alpine and this is for your web app and then you install exactly the libraries packages and binaries you need for that and then for uh mongodb you want to have a different OS different packages and same thing with Rabbid mq maybe you want to run it on FreeBSD and the idea is that uh you know you're not going to have this waste because it it's kind of changed the sense that these containers are Flex ible so they can expand or decrease based on the the use case of what they need uh and you know if you use particular services like ad fargate you know you're paying like for running the containers not necessarily uh for uh over provisioning okay so VMS do not make best use of space apps are not isolated which could cause uh config conflict security problems or resource hogging containers allow you to run multiple apps which are virtually isolated from each other launch new containers configure OS uh dependencies per container okay hey this is Andrew Brown from exam Pro and we are taking a look at the concept of microservices and to understand microservices we first need to understand monoliths or monolithic architecture and the idea here is that we have one app which is responsible for everything and the functionality is tightly coupled so I'm going to get my pen tool out here and just to highlight notice that there is a server and everything is running on a single server whether it's load balancing caching the database um maybe the marketing website the frontend JavaScript framework the back end with its API uh the uh orm connected to background tasks things like that and that's the idea of a monolith and that's what um a lot of people are used to doing but the idea with microservice architecture is that you have multiple apps which are responsible for one uh one thing and the functionality is isolate and stateless and so just by uh leveraging um various cloud services or bolting it onto your service um you know you are technically using microservice architecture so maybe your web app is all hosted in containers so you have your apis your or your orm your reports maybe you've abstracted out some particular functions into Lambda functions you have your um marketing website hosted on S3 you have your frontend JavaScript hosted on S3 You're Now using elastic load balancer uh elasticache RDS sqs and that's the idea between monoliths and microservices okay let's take a look here at kubernetes which is an opensource container orchestration system for automating deployment scaling and management of containers it was originally created by Google and now maintained by the cloud native Computing foundation so the cncf kubernetes is commonly called K8 the 8 represents the remaining letters for kuti which is odd because everyone calls it kues with the S on there but that's just what is the advantage of kubernetes over Docker is the ability to run containers distributed across multiple VMS a unique component of kubernetes are pods a pod is a group of one or more containers with with shared storage network resources and other shared settings so here is kind of an example where you have your kubernetes master it has a schedule controller etcd you might be using it uses an API server to run nodes within the nodes we have pods and within the pods we have containers kubernetes is ideally for microservice architectures where company has tens to hundreds of services they need to manage I need to really emphasize that tens to hundreds of services all right so you know crion is great but just understand that it is really designed uh to be used for massive amounts of microservices if you don't have that need you might want to look at something just easier to use okay all right let's take a look here at docker which is a set of platforms of service products that use OS level virtualization to deliver software in packages called containers so Docker was the earliest popularized open source container platform meaning there's lots of tutorials there's a lot of services that uh integrate with Docker or make it really easy to use and so when people think of containers they generally think of Docker there's of course a lot more options out there than Docker to run containers but this is what people think of and so we said it's a suite of tools so the idea is you have this Docker CLI so these are C commands to download upload build run and debug containers a Docker file a configuration file on how to provision a container Docker compose uh which is a tool and configuration file when working with multiple containers Docker swarm an orchestration tool for managing deployed multicontainer architectures Docker Hub a public online repository for containers published by the community for download and one really interesting thing uh that came out of Docker was the open container initiative oci which is an open governance for creating open industry standards around container formats and runtimes so Docker established the O oci and it is now maintained by the Linux foundation and so the idea is that you can write a Docker file or or do things very similarly and use different types of um uh technologies that can use containers as long as they're oci compatible you can use them so Docker has been losing favor with developers due to their handling of introducing a paid open source model and Alternatives like podman are growing and that's why we're going to talk about podman next okay so let's take a quick look here at podman which is a container engine that is oci compliant and is a drop in replacement for Docker I just want to get you exposure here because I want you to know about this um and that you can uh use it as opposed to using Docker um there are a few differences or advantages that podman has so podman is Damon list where Docker uses a container D Damon pman allows you to create pods like crew brunetes where Docker does not have pods podman only replaces one part of Docker podman is is to be used alongside builda and uh scopio so you know Docker is an allinone kind of tool uh everything is done via single CLI and everything is there but you know they just wanted to make it more module and so uh these other tools anytime you say podman it usually means we're talking about podman builda and scopio so builda is a tool used to build the oci images and scopio is a tool for moving container images between different types of container storages p is not going to show up in your exam but you should practically know it um just for your own benefit okay let's take a look here at the container services offered on AWS so we have primary services that actually run containers provisioning and deployment on you know tooling around provisioning deployment and supporting services so the first here is elastic container service ECS um and the advantage of this service is that it has no cold starts but it is a manage dc2 so that means that you're going to be always paying for the resource as it is running all right then you have ads fargate so this is more robust than uh using adus Lambda it can scale to zero cost um and it's uh being managed by adus managed ec2 however it does have cold starts so you know if you need containers launching really fast you might be wanting to use ECS then you have elastic kubernetes service eks this is uh open source it runs kubernetes um and this is really useful if you want to avoid vendor lockin um which is not really a problem but uh that or it's just you want to run kubernetes then you have itus Lambda so you only think about the code uh it's designed for short running tasks uh if you need something that runs longer you want to use that is serverless you'd use adus fargate which is serverless containers you can deploy custom containers so prior adus Lambda just had um prebuilt run times which were containers but now you can create any kind of container and uh use that uh on a was Lambda for provisioning deployment you can use elastic Bean sock so um it can uh deploy elastic container service for you um which is very useful there now there's app Runner which kind of overlaps on what elastic beanock does but it specializes it specializes for containers um and I believe that it can actually I don't know what it uses underneath because it is a managed service so elastic beanock is um open you can see what is running underneath an app Runner I don't believe you can see what is running underneath it's just taken care of by AWS then there's AWS copilot CLI so this allows you to build release operate production ready containerize applications on app Runner ECS and Abus fargate for supporting services you have elastic container registry this is reple for your containers not necessarily just Docker containers but containers in general probably oci compliant containers xray so analyze and debug between uh microservices so you know it's distributed tracing then you have step functions so stitch together lambdas and ECS tasks to to uh create um um a state machine and the only thing I don't have on here would be you know being able to launch an ec2 instance from the marketplace that has um a uh a container runtime installed like Docker um I just don't feel that that's very relevant for the exam but it is another option for containers not something that people do very often but there you go hey this is Angie Brown from exam Pro and we are taking a look here at organizations and accounts so adus organizations allow the creation of new adus accounts and allows you to centrally manage billing control access compliance security and share resources across your adus accounts so here's kind of a bit of a structure of um the architecture of adus organizations and we'll just kind of walk through the components so the first thing you have is a root account user this is a single signin identity that has complete access to all ad services and resources in an account and each account has a root account user so generally you will have a master or root account and even within that you'll have a root account user and for every additional account that you have you'll notice over here we have a root account user then there's the concept of organizational units uh these are commonly abbreviated to ous so they are a group of adus accounts within an organization which can contain other organizational units creating a hierarchy so here is one where we have called Starfleet and here's one called Federation planets and underneath we have multiple accounts it accounts within that organizational unit and even though it does not show it here you can create an organizational unit within an organizational unit then we have service control policies scps and these give uh central control over the allowed permissions for all A's accounts in your organization helping to ensure your accounts stay within your organization's guidelines what they're trying to say here is that um there's this concept of adus I am policies and all you're doing is you're creating a policy that's going to be uh organizational uniwide or organizational wide or for select accounts so it's just a way of applying I am policies across multiple accounts adus organizations must be turned on and once it's turned on it cannot be turned off it's generally recommended that you do turn it on um because basically when if you're going to run any kind of serious workload you're going to be using adus organizations to uh isolate your adus accounts based on workloads you can create as many adus accounts as you like One account will be the master or root account um and I say root account here because this is the new language here and some of the documentation still calls it master account so do understand this is the root account not to be confused with the root account user so another clarification I want to make is an ads account is not the same as a user account which is another thing that is confusing so when you sign up for AWS you get um an adus account and then it creates you a user account which happens to be a root user account so hopefully that is clear so adus control tower helps Enterprises quickly set up a secure adus multic count it provides you with a baseline environment to get started with a multicount architecture so it does this a few uh a few different ways the first thing is it provides you a landing Zone this is a baseline environment following well architected and best practices to start launching production ready workload so imagine you wanted to go have um you know the perfect environment that you know sec cure um is correctly configured and has good logging in place that's what a landing zone is and so 's Landing zone for control tower is going to have SSO enabled by default so it's very easy to move between it accounts it will have centralized logging for adus cloud trail so that you know they're going to be tamper evident or tamper proof away from your workloads where they can't be affected it'll have cross account security auditing um so yeah Landing zones are really great to have then there's the account Factory they used to call this um uh a vending machine but uh they changed it to account Factory the idea is that it automates provisioning of new accounts in your organization it standardizes the provisioning of new accounts with preapproved account configuration you can configure account Factory with preapproved network configuration and region selections uh enable sell service for your Builders to configure and provision to accounts using a service catalog a service catalog is just preapproved uh workloads uh via Cloud information templates that you created to say okay you're allowed to launch This Server these resources um and the third and most important thing that a control tower comes with is guard rails so these are prepackaged governance rules for security operations compliance the customers can select and apply Enterprise wide or to specific groups of accounts so adus control tower is the replacement of the retired adus Landing zone so if you remember adus Landing zones which was never a self serve easy thing to sign for it required a lot of money and uh stuff to go in there they just don't really have it anymore and it was control Tower is the new offering um there okay hey this is Andrew Brown from exam Pro and we are taking a look at 's config and to understand adus config we need to know what compliance as code is and to understand compliances code we need to understand what change management is so change management in the context of cloud infrastructure is when we have a formal process to monitor changes enforce changes and remediate changes and compliance is code also known as CAC is when we utilize programming to automate the monitoring enforcing and remediating changes to stay compliant with the compliance program or expected configuration so what is adus config well it's a compliances code framework that allows us to manage change in your adus accounts on a per region basis meaning that you have to turn this on for every region that you need it for and so here is a very simple example where let's say we create a config rule and we have an ec2 instance and we expect it to be in a particular State and then in the other case we have a an RDS instance and it's in a state that we do not like so the idea is that we try to remediate it to put it in the state that we want it to be and those config rules are just powered by lambdas as you can see based on the Lambda icon there so when should you use itus config well this is when I want this resource to say configured a specific way for compliance I want to keep track of configuration changes to resources I want a list of all resources within a region and I want to use uh analyze potential security weaknesses and you need detailed historical information so there you go hey this is Andre Brown from exam Pro and in this follow along we're going to take a look at adus config so adus config is a tool that allows you to ensure that your services are configured as expected so I've already activated it in my North Virginia region so what I'm going to do is just go over to Ohio here uh because it is per region activated and I'll go over to config and then what we'll have to do is set it up so there is this oneclick setup and it did Skip me to the review step because it's kind of piggybacking on the configuration of my original one here but the idea is that you'll just say uh record all resources in this region or things like that you'll have to create a service roll link if you have not done so so this will look a little bit different but here it's using existing one you'll have to choose a bucket so or create a bucket uh it's not super complicated so you get through there you hit confirm and basically you're going to end up with this so the inventory um lets you see all the the resources that or not all of them but most resources that are in your adus account in this particular region it this will not populate uh right away so you will have to wait a little bit of time for that to appear one really nice thing our conformance packs I really love these things when any of us first brought these out there was only like a couple but now they have tons and tons and tons of conformance packs so you can go deploy a conformance pack and you can open up the templates I just want to show you look at how many they have so there some you might recognize like nist uh CIS things like that well architected uh stuff and all these are um and I'm not sure if it's easy to open these up but all these are if we open them up they're on GitHub is these are just cloudformation templates to set up configuration rules so there's a variety of suggested rules uh like around IM best practices and things like that that we can load in um but the idea is that you're just going to create rules so you go here and you add a rule and they have a bunch of manag rules here um that we can look at but I think it might be fun to actually run a um a conformance pack I'll just show you what it looks like to add a rule first so let's say we wanted to do something for S3 um and it was making sure that we are blocking Public Access so we go next here generally you'll have a trigger type you can choose whether it's uh configured when it happens or it's periodic this is disabled in this case here and you just scroll on down um and then once you've added the rule what you can do is also manage remediation so if this rule said hey this thing is noncompliant we want you to take a particular action and you have all these databus actions that you can perform and you can notify the right people to correct it or have it auto correct if you choose to do so um for rules you can also make your own custom one so that's just you providing your own Lambda functions you're providing that Lambda Arn and so basically you can have it do anything that you want whatever you want to put in a Lambda you can make adus config check for okay so it's not super complicated here but um this one here is just going to go ahead and check and so if we go and reevaluate it might just take some time to show up either going to say that it's compliant or noncompliant okay and I it should be compliant but while we're waiting for that to happen let's just see how hard it is to deploy a conformance pack because I feel like that's something that's really important oh you can just drop them down and choose them that's great so we might want to go to I am here oops identity and access management and hit next and say uh my um uh I am best practices and you might not want to do this because it does have spend and when I say spend it's not going to happen instantly but the idea is that if you turn this on and forget to remove it uh you will see some kind of charges over time because it does check check based on the rules it's not super expensive but it is something to consider about um but anyway so it looks like we created that conformance pack so if I refresh it looks like it's in progress I wonder if that's going to set up a cloud formation template I'm kind of curious about that so we'll make our way over to cloud formation and it is so that's really nice because once that is done what we can do is just tear it down by deleting the stack so I'm going to go back over to our conformance pack here let's take a look here and so it still says it's in progress but it is completed and we can click into it and we can see all the things that it's doing so it says item groups have user check informance pack um and so it looks like there's a bunch of uh cool rules uh here so what we'll do is we'll just wait a little while and we'll come back here and then just see if um this updates and see how compliant we are from a uh a basic account okay all right so after waiting a little while there it looks like some of them are being set so I just gave it a hard refresh here uh and here you can see that it's saying is rooe account um whoops we'll give it a moment here to refresh but uh is the root account MFA applied yes have we done a password policy no and actually I never did a password policy which is something I forgot to do but here they're just talking about the minimums and maximums of things that you can do okay so that's a conformance pack um but if we go to rules actually I guess it's all the rules here I can't really tell the difference between the conformance pack rules and our plane rules kind it's kind of all mixed together here I think yeah so it's a bit hard to see what's going on there if we go to the performance pack and click in again it might show the rules yeah there we go so here's the rules there we're seeing a little bit more information so use a hardware MFA so you know how they're talking about using a security key like what I showed you that I had earlier in the course things like that um I am password policy things like that so you know not too complicated but um I think I'm all done here so what I'm going to do is I'm going to go over to cloud formation and tear that on down but you get the idea well I might want to show you uh drift so there used to be a way it's CU I keep changing things on me here but there's a way to see uh history over time and so that was something that they used to show and I'm just trying to like find where they put it because it is like somewhere else resources maybe ah resource timeline okay so they moved it over into the resource inventory and so if we were to take a look at something anything maybe this here resource timeline um and there might not be much here but the idea is it will show you over time how things have changed so the idea is that not only can you say with a was config is something compliant but when was it compliant and that is something that is really important to know okay so very simple example maybe not the best but the idea is that we can see when it was and was not compliant based on uh changes to our stuff but uh anyway that looks all good to me here so I'm going to make my way over to cloud formation actually already already have it open over here we're going to go ahead and delete that stack um termination protection is enabled you must first disable it so we'll edit it disable it whatever okay we'll hit delete there and as that's deleting I'm going to go look for and config my original rule there again I'm not really worried about it I don't think it's going to really cost me anything but uh I also just kind of clear the house here just so you're you're okay as well and so if we go over to our rules um the one that I spun up that was custom I think was this one here CU these are all grayed out right so I can go ahead there delete that rule type in delete and we are good so there you go that is it all right adabs quick starts are prebuilt templates by adabs and adus partners to help deploy a wide range of stacks it reduces hundreds of manual uh procedures into just a few steps the uh quick start is composed of three parts it has a reference architecture for the deployment an adus cloud formation templates that automate and configure the deployment a deployment guide explain the architecture implementation and detail so here's an example of one that you might want to launch like the adus Q&A bot and then you will get an architectural diagram and a lot of information about it and from there you can just go press the button and launch this infrastructure most quick start reference deployments enable you to spend up a fully functional architecture in less than an hour and there is a lot as we will see here when we take a look for ourselves all right so here is uh adabs quick starts where we have a bunch of cloudformation templates uh built by adabs or Amazon or for adab best partner networks APM partners and uh there's a variety of different things here so I'm just going to try to find something like Q&A bot Q&A bot just type in bot here and I don't know why it was here the other day now it's not showing up which is totally fine but um you know I just want anything to deploy just to kind of show you what we can do with it so you scroll on down we have uh this graphic here that's representing what will get deployed so we have cloudfront S3 Dynamo DB assistance manager Le poly all these kind of fun stuff um and there's some information about how it is architected and the idea is you can go ahead and launch in the console or view the implementation guide let's go take a look here um and there's a bunch of stuff so we have Solutions and things like that conversational things like that but what I'm going to do is go ahead and see how far I can get to launching with this it doesn't really matter if we do launch it it's just the fact that um I want to just show you what you can do with it so if we go to the designer it's always fun fun to look at it in there because then we can kind of visualize all the resources that are available and I thought that that would populate over there but maybe we did the wrong thing so I'm just going to go back and click I'm just going to click out of this oops cancel let's close that leave yes and we will launch that again and so this oh View and the designer I hit the wrong button okay and so now this should show us the template might just be loading there we go so this is what it's going to launch and you can see there's a lot going on here just going to shrink that there uh and I don't know if you can make any sense of it but clearly it's doing a lot and so if we were happy with this and we wanted to launch it I know I keep backing out of this but we're going to go back into it one more time we can go here and we can go next and then we we would just fill in what we want so you name it put the language in and this is stuff that they set up so maybe you want a mail voice set the ab in and stuff like that and it's that simple really um and every stack is going to be different so they're all going to have different configuration options but hopefully that gives you kind of an idea of what you can do with quick starts okay let's take a look at the concept of tagging within AWS so a tag is a key and value pair that you can assign to aabus Resource so as you are creating a resource it's going to prompt you to say hey what tags do you want to add you're going to give a key you're going to give a value and so some examples could be something like based on Department the status the team the environment uh the project as we have the example here the location um and so tags allow you to organize your resources in the following way for resource management so specific workload so you can say you know developer environments cost management and optimization so cost tracking budgets and alerts operations management so business commitments SLA operations Mission critical Services security so classification of data security impact governance and Regulatory Compliance automation workload Automation and so it's important to understand that tagging can be used in Junction with um IM policy so that you can restrict access or things like that based on those tags okay all right I just want to show you one interesting thing about tags um and it's just the fact that it's used as the name for some services so when you go to ec2 and you launch an instance uh the way you set the name is by giving it a tag called name and I just want to prove that to you just like one of those little exceptions here so we choose an instance here we go to configure storage and then what we do is we add a tag and we say name um and my server name okay and then we go ahead and review and launch we're going to launch this I don't need a key pair so we'll just say proceed without key pair I acknowledge okay and we will go view the instances and you'll see that is the name so um that's just like one of those exceptions or things that you can do with tags if there's other things with tags I have no idea that's just like a a basic one that everybody should know and that's why I'm shown to you with the tags but there you go so we just looked at tags now let's see what we can do with resource groups which are a collection of resources that share one or more tags or another way to look at it it it's a way for you to take multiple tags and organize them uh into resource groups so it helps you organize and consolidate information based on your project and the resources that you use resource groups can display details about a group of resources based on metrics alarms configuration settings and in any any time you can modify the settings of your resource groups to change what resources appear resource groups appear in the global console header uh which is over here and under the systems manager so technically it's part of AD simple systems manager or systems manager interface but it's also part of the global interface so sometimes that's a bit confusing but uh that's where you can find it okay all right so what I want to do is explore resource groups and and also um tagging so what I want you to do is type in resource groups at the top here and it used to be accessible not sure where they put it but it used to be accessible here at the top but they might have moved it over to systems manager so I'm going to go to SSM here not sure why I can't seem to find it today and on the left hand side we're going to look for resource groups for for for all right so what I want to do is take a look at resource groups and I'm really surprised because it used to be somewhere in the global now but I think they might have changed it um and what's also frustrating is if I go over to systems manager it was over here as well and so on the left hand side I'm looking for resource groups it's not showing up so I don't know best you keep moving things around on me and I'm I can only update things so quickly in my courses but if you type in resource groups and tag editor it's actually over here um I guess it's its own Standalone service now why they keep changing things I don't know but uh the idea is we want to create a resource Group so you can create unlimited single region groups in your A's account use the group to view related insights things like that so I'm going to go ahead and create a resource Group you can see it can be tag based or cloud formation based but I don't have any tags I don't really have anything tags so what I'm going to do is make my way over to S3 we're just going to create some resources or a couple resources here with some tags so that we can do some filtration so I can go ahead and create a bucket going say my bucket uh this like that whoops and then down below I'm going to go down to tags and we're going to say project and we're going to say um RG for Resource Group okay and then I can go back over here and then I'm going to just say I can say exactly what type I want I'm going to support all resource types and I'm going to say project RG see how it autocompletes and we'll go down below we'll just say my RG a test RG we'll create that and so now we have a resource Group and we can see them all in one place uh resource groups are probably useful for using in um policies so I can say say like Resource Group IM policies that's probably what they're used for okay so before you use IM am manag to access resource groups you should understand IM am features things like that and so administrators can use Json policies to specify who has access to what and so a policy action a resource Group is is used following the prefix resource groups so my thought process there is that if you want to say okay you have access to a resource you can just specify a resource Group and it will include all the resources within there and so that might be um a better way to apply permissions at a per project basis um and that could save you a lot of time writing out IM policies so that's basically all there really is to it also you kind of get an overview of of the resources that are there so that can be kind of useful as well there's the tag editor here I can't remember what you use this for you can set up tag policies um tag policies help you standardize tags on resource groups in your accounts used uh to Define tag policies and Abus or to attach them to the entire organization um we're not in the OR account so I'm not going to show you this and it's not that important um but just understand that resource groups can be created and they are used within IM policies in order to um uh Grant or deny access to stuff you go ahead and delete that Resource Group and really ad stop moving that on me if you move it one more time I'm just never going to talk about resource groups again okay hey this is Andie Brown from exam Pro and we are taking a look at business Centric services and you might say well why because in the exam guide It's explicitly says that these are not covered but the thing is is that when you're taking the exam some of the uh choices might be some of these Services as distractors and if you know what they are it's going to help make sure that you um uh guess correctly and the thing is that some of these services are useful and you should know about them so that's another reason why I'm talking about them here so the first one is Amazon connect this is a virtual call center you can create workflows to Route callers you can record phone calls manage a queue of callers based on the same proven system used by Amazon customer service teams we have workspaces this is a virtual Remote Desktop Service secure manage service for provision either windows or Linux desktops in just a few minutes which quickly scales up to thousands of desktops we have work docs which is a shared collaboration service a centralized storage to share content in files it is similar to Microsoft SharePoint think of it as a shared folder where the company has ownership we have chime which is a video conference service it is similar to zoom or Skype you can screen share have multiple people on the on the same call it is secure by default and can show you a calendar of upcoming calls we have workmail this is a manag business uh email contacts calendar service with support of existing desktop and mobile email client applications that can handle things like IMAP similar to Gmail or exchange we have pinpoint this is a marketing campaign Management Service pinpoint is for sending targeted emails Via SMS push notifications voice messages you can perform um A to B testing or create Journey so complex email response workflows we have SCS this is a transactional email service you can integrate SCS into your application to send emails you can create common templates track open rates keep track of your reputation we have quick site this is a business intelligence uh service connect multiple data sources and quickly visualize data in the form of graphs with little to no knowledge definitely you want to remember quick site sces pinpoint uh because those definitely will show up in the exam the rest probably not but they could show up as distractors okay hey this is Andrew Brown from exam Pro and we are taking a look at provisioning services so let's first what is provisioning so provisioning is the allocation or creation of resources and services to a customer and provisioning services are responsible for setting up and managing those Ada Services we have a lot of services that do provisioning most of them are just using cloud formation underneath which we'll mention here but let's get to it the first is elastic beanock this is a platform as a service to easily deploy web apps EB will provision various a services like ec2 S3 SNS cloudwatch E2 Auto scaling groups load balancers uh and you can think of it as the Heroku equivalent to AWS then you have opsworks this is a configuration Management Service that also provides managed instances of Open Source configuration managed software such as chef and p puppet so you'll say I want to have a load balancer or I want to have servers and it will provision those for you uh indirectly then you have Cloud information itself this is an infrastructure modeling and provisioning service it automates the provisioning of AD Services by writing Cloud information templates in either Json or yaml and this is known as IAC or infrastructures a code you have quick starts these are premade packages that can uh be launched and configure your a compute network storage and other services required to deploy a workload ons we do cover this in this course but quick starts is basically just Cloud information templates that are authored by the community or um by um Amazon partner Network okay then we have abis Marketplace this is a digital catalog for thousands of software listings of independent software vendors that you can use defined by intes and deploy software so the idea is that um you know you can go there and provision whatever kind of resource you want we have Abus amplify this is a mobile web app framework that will provision multiple Abus Services as your backend it's specifically for serverless services I don't know why I didn't write that in there um but you know like Dynamo DB um things like uh whatever the graphql service is called API Gateway things like that uh then we have app Runner this is a fully managed service that makes it easy for developers to quickly deploy containerized web apps and apis at scale with no prior information experience required it's basically a platform as a service but for containers we have AIS copilot this is a command line interface that enables customers to quickly launch and manage containerize applications any us it basically is a a CLI tool that sets up a bunch of scripts to set up pipelines for you makes things super easy we have Adis code start this provides a unified user interface enabling you to manage your software development activities in one place usually launch common types of stacks like lamp then we have a cdk and so this is infastructure as a code tool allows you to use your favorite programming language generates out Cloud information templates as a means of I so there you go hey this is Andrew Brown from exam Pro and we are taking a look at ad elastic beant stock before we do let's just Define what passes so platform as a service allows customers to develop run and manage applications without uh the complexity of building and maintaining the infrastructure typically associated with developing and launching an app and so elastic beanock is a pass for deploying apps with little to no uh knowledge of the underlying infrastructure so you can focus on writing application code instead of setting up an automated deployment pipeline or devops tasks the idea here is you choose a platform upload your code and it runs with little uh knowledge of the infrastructure and adabs will say that it's generally not recommended for production apps but just understand that they are saying this for Enterprises and large companies if you're a small to medium company you can run elastic beanock for quite a long time it'll work out great elastic beanock is powered by Cloud information temp templates and it sets up for you elastic load balancer asgs RDS ec2 instances preconfigured for particular platforms uh monitoring integration with cloudwatch SNS uh deployment strategies like in place blue green uh deployment has security built in so it could rotate out your passwords for your databases and it can run dockerized environments and so when we talk about platforms you can see we have Docker multicontainer Docker uh go.net Java nodejs Ruby PHP python tom cat go a bunch of stuff and just to kind of give you that architectural diagram to show you that it it can launch of multiple things okay hey it's Andre Brown from exam Pro and in this follow along we're going to learn all about elastic beanock maybe not everything but we're going to definitely know how to at least um use the service so elastic beanock is a platform as a service and what it does is it allows you to uh deploy web applications very easily so here I've made my way over to elastic beanock I mean environment and app and then we set up our application we have two tiers a web server environment a worker environment worker environment is great for long running workloads performing uh background jobs and things like that and then you have your web server which is your web server and you can have both and it's generally recommended to do so um but anyway what we'll do is create a new application so let's say my app here and uh there's some tags we can do and then it will name based on the environment then we need to choose an environment name so say my environment and just put a bunch of numbers in there hit the check availability scroll on down and we have two options manage platform custom platform and I'm not sure why custom is blanked out but it would allow you to um it would allow you to I think use your own containers so I'm a big fan of Ruby so I'm going to drop down to Ruby and here we have a bunch of different versions and so 2.7 is pretty pretty new which is pretty good and then there's the platform version which is fine and the great thing is it comes with a sample application now you could hit create environment but you'd be missing on a lot if you don't hit this configure more options I don't know why they put it there it's a not very good UI but um if you click here you actually get to see everything possible and so up here we have some presets where we can have a single instance so this is where it's literally running a single E2 instance so it's very cost effective you can have it with spot uh spot pricing so you save money um there's High availability so you know if you want it set up with a load balance an auto scaling group it will scale very well or you can do custom configuration we scroll on down here you can enable Amazon xray you can rotate out logs you can do log streaming um there's a lot of stuff here and basically it's just like it sets up most for you but you can pretty much configure what you want as well if we had the load bouncer set if I go here go to High availability now we'll be able to change our load balancer options you have different ways of deploying so you can go here and and then change it from all at once rolling immutable traffic splitting depends on what your use case is um we can set up a key pair to be able to log into the machine there's a whole variety of things you can connect your database as well so it can create the database alongside with it and then it can actually rotate out the key so you don't have to worry about it which is really nice what I'm going to do is go to the top here and just choose a single instance because I want this to be very cost effective we're going to go ahead and hit create environment and so we are just going to wait for that to start up and I'll see you back when it's done okay okay so it's been uh quite a while here and it says a few minutes so if it does do this what you can do is just give it a hard refresh I have a feeling that it's already done is it done yeah it's already done so and here it says on September 2020 elastic be talk Etc default default I don't care um but anyway so this application I guess it's in a pending State um I'm not sure why let's go take a look here causes instance has not sent any data since launch uh none of the instances are sending data so that's kind of interesting because um I shouldn't have any problems you know what I mean so what I'm going to do is just reboot this machine and see if that fixes the issue there but usually it's not that difficult because it's the sample application it's not up to me um as to how to fix this you know what I mean so I'm not sure but um what we'll do is we will let the machine reboot and see if that makes any difference okay all right so after rebooting that machine now it looks like the server is healthy so it's not all that bad right if you do run into issues that is something that you can do and so uh let's go see if this is actually working so the top here we have a link and so I can just right click here it says congratulations your first 8us elastic uh beanock Ruby application is now running so it's all in good shape um there's a lot of stuff that's going on here in elastic beanock that we can do uh we we can go back to our configuration and change any of our options here so there's a lot of stuff as you can see uh we get logging uh so click the request log so if we click on this and say last 100 lines we should be able to get uh logging data we have to download it I wish it was kind of in line but here you can kind of see what's going on so we have STD access logs error logs Puma logs elastic beam stock engine so you could use that to debug very common to take that over to uh support if you do have issues uh for Health it monitors the health of the instances which is great then we have some uh monitoring uh data here so it gives you like a built dashboard so that's kind of nice you can set up alarms um you have not defined any alarms you can add them via the monitoring dashboard so I guess you'd have to you'd have to somehow add them um I don't think I've ever added alarms for um classic beanock but it's nice to know that they have them you can set up schedules for managed events then this is event data so it's just kind of telling you it's kind of like logs it just tells you of things that have changed so there's stuff like that what I'm looking for is to see how I can download the existing application because there's a version uploaded here oh the source is over here okay so I think it's probably over here the one that's running so that's it if it was easy to find what I probably would do is just modify it and oh yeah it's over here so if we go here and download the zip I wonder if it'd be even worth um playing with this so let's I'm just going to see if we can go over to Cloud9 and give this a go quickly so if we go over and launch a Cloud9 environment maybe we can tweak it and upload a revised version so we say create new we'll say EB um uh environment for elastic bean stock uh we'll set it all the defaults that's all fine it's all within the free tier we'll create that environment what I'm going to do is just take this uh Ruby zip file and move it to my desktop and as that is loading we'll give it a moment here I'm just going to go back and I was just curious does it let you download it directly from here no so only thing is that you know if you download that application elastic beanock usually has a configuration file with it and so I don't know if they would have given that to us but if they did that would be really great but we just have to wait for that to uh launch there as well I guess you can save configurations and roll back on those as well um but we will just wait a moment here while it's going I might just peek inside of this file to see what it is this ZIP contains just going to go to my desktop here open up that zip so it looks pretty simple it doesn't even look like a rails app it looks like maybe it's a Sinatra app I thought before that it would it would have deployed a Ruby on Rails application but maybe they keep it really simple um I don't see usually it's like yamell files they use for configuration I don't see that there so it might be that the default settings will work fine uh there's a king fig. Ru and stuff like that but once Cloud9 is up here we will upload this and see what we can do with it okay so there we go uh Cloud9 is ready to go and so if we right click here whoops right click here we should be up be able to upload a file if not we can go up here to the top or it's here or there where is the upload I've I've uploaded things in here so I absolutely know we can I just got to find it is that the upload upload files Cloud9 oh boy that's not helpful that's not helpful at all so let me just click around a little bit here I mean worst case I can always just bring it in Via a curl oh upload local files there it is I was just not um being patient okay so we'll drag that on in there and we will did it upload yep it's right there okay great so we need to unzip it so what I'll do is just drag this on up here I'll do an LS and we'll say unzip rubyzip and so that unzipped the contents there I think the readme was part of Cloud9 so I'm going to go ahead and delete that out not that it's going to hurt anything and so now what we can do and we'll delete the original original zip there um and let's see if we can make a change here so I'm just going to open up see what it is so yeah it's running Sinatra so that's pretty clear there we have a proc file to say how it runs we have a worker sample sample so that just tells how the requests go you don't need to know any of this I'm just kind of clicking through it because I know Ruby very well we have a cron yamel file so that could be something that gets loaded in here so I think basically a Sinatra app probably just works off the bat here but if we want to make a change we probably just make a change over to here so I'll go down here and this is your second ads elastic beanock application so the next thing we need to do is actually zip the contents here I don't know if it would let us zip it with in here but I'll have to look like Zip the contents of a directory Linux this goes to show Google is everything so the easiest way to zip a folder um zip everything in the current directory Linux okay that's easy so we'll go back over here and we will type in zip and it wants hyphen R for recursive which makes sense and then the name of the zip so um uh Ruby 2.zip and we'll do period zip warning found is who is zip oh uh yum install zip maybe we have to install uh ZIP but maybe it's not installed pseudo yum install zip since it's Amazon El 2 it uses yum and so package already installed so I'm going to type zip again so zip is there now great oops don't need to install twice zip warning Ruby 2 zip not found or empty okay so install zip and use zip hyphen R you can use the flag to best compensate so if that's not working what I'm going to do is just go up a directory why is it saying not found or empty maybe I need to use okay so I think the problem was is I was using the wrong flag so I put F instead of R I don't know why I did that so I probably should have done this okay and so that should have copied all the contents of that file so what I'm going to do is go ahead whoops make sure I have that select it and download that file and once I have downloaded that file I'm going to just open the contents to make sure it is what I expect it to be so we're going to open that up and whoops get out of here when RAR and it looks like everything I want so what I'm going to do is go back over to here I'm going to make sure I have my Ruby 2 on my desktop and we're going to see if we can upload another version here so upload and deploy choose the file we're going to go all the way to my desktop here and we're going to choose Ruby 2 and um like Ruby 2 will be the version name or we'll just say two and we'll deploy and we'll see if that works okay but there are like uh elastic be configuration files like gamble files that can sit in the root directory and so generally you're used to seeing them there but you know I imagine that a US probably engineered these examples so that it uses all the default settings but uh once this is deployed I'll see you back here in a moment okay after a short little wait it looks like it has deployed so what I'm going to do is just close my other tabs here and open this up and see if it's worked it says your second ads elastic being stock Ruby application so uh we were successful uh deploying that out which is really great so what we can do now is just close that tab there and uh since we have that cloud environment it will shut down on its own but you know just for your benefit I think that we should shut it off right now so go ahead and delete that I'm going to go back over to elastic beanock here and I just want to destroy all of it so we'll see if we can just do that from here terminate the application enter the name so I think we probably have to enter that in there and so I think that oh a problem occurred rate exceeded what that's AWS for you so it's not a big deal I would just go and check it again and maybe what we'll do is just delete the application first okay so that one is possibly deleting let's go in here is anything changing can't even tell we'll go ahead oh can't take that one out delete application again if it takes you a couple times it's not a big deal it's AWS 4 yes so there's a lot of moving parts so it looks like it is terminating the instance and so we just have to wait for that to complete uh once that is done we might have to just tear down the environment so I'll see you back here when it has finished tearing this down okay all right and so after a short little wait here I think it's been destroyed we'll just double check by going to the applications going to the environments yeah and it's all gone probably cuz I initially deleted that environment and then took the application with it so I probably didn't have to delete the app separately um but uh yeah so there you go and just make sure your Cloud9 environment's gone and you are a okay there'll probably be some like lingering S3 buckets so if you do want to get rid of those you can it's not going to hurt anything having those around uh but they do tend to stack up after a while which is kind of annoying so if you don't like them you can just empty them out as I am doing here whoops oh just permanently delete copy that text there we can go back to here and then just go take out that bucket let's delete that there oh if you get this this is kind of annoying but uh elastic beanock liks to put in an i permission or policy here so if you go down here there's a bucket policy you just have to delete it out it prevents it from being deleted and we'll go back over here and then we will delete it okay and yeah there we go that's it so let's take a look at serverless services on AWS and this is not including all of them because we're looking at the most purely serverless services uh if we tried to include all the serverless services it would just be too long of a list uh but let's take a look here so um before we do let's just redefine what is serverless so when the underlying servers infrastructure and operating system is taken care of by the CSP serverless is generally by default highly available scalable cost effective you pay for what you use the first one is Dynamo DB which is a serverless nosql key value and document database it's designed to scale to billions of records with guaranteed consistent data return in at least a second you do not have to worry about managing chards you have simple storage service S3 which is a seress object storage service you can upload very large and unlimited amounts of files you can pay for what you store you don't worry about the underlying file system or upgrading the disk size we have ECS fargate which is a servess orchestration container service is the same as ECS except you pay on demand per running container with ECS you have to keep a ec2 server running even if you have no containers running where adus manages the underlying server so you don't have to scale or upgrade the ec2 server we have adus Lambda which is a serverless function service you can run code without provisioning or managing servers you upload a small piece of code choose uh how much memory you want how long you want the function is allowed to run before timing out your charge based on the runtime of the service function rounded to the nearest 100 milliseconds we have step functions this is the state machine service it coordinates multiple Services into serverless workflows easily share data among lambdas have a group of lambdas wait for each other create logical steps also work with fargate tasks we have Aurora servus this is a serous on demand version of Aurora so when you want most of the benefits of Aurora but trade you have to trade off those cold starts or you don't have lots of traffic or demand so things Ser services that we could have put in here as well is like API Gateway Apps sync a amplify um and those are like the the first two were app Integrations you could say sqs SNS those are all serous services but you know again we'd be here all day if I I I list to the all right all right let's take a look at what is serverless and we did look at it from a server perspective earlier in the course but let's just try to abstractly Define it and talk about the architecture so serverless architecture generally describes fully managed cloud services and the classification of a cloud service being being serverless is not a Boolean answer it's it's not a yes or no but an answer on a scale where a cloud service has a degree of serverless and I do have to point out that this definition might not be accepted by um everybody because serverless is one of those uh terms where um we've had a bunch of different cloud service providers Define it differently and then we have thought leaders that have a particular concept of what it is so you know I just do my best to try to make this practical here for you but a serverless service could have all or most of the following characteristics and so it could be highly elastic and scalable highly available highly durable secure by default it abstracts away the underlying infrastructure and are build based on the execution of your business tasks a lot of times that uh that cost is not uh is not always represented as something that is like I'm paying X for compute it could be abstracted out into some kind of um credit that uh doesn't necessarily map to something physical then we have serus can scale to zero meaning when it's not in use the serverless resources cost nothing uh and these two last topics basically pull into pay for Value so you don't pay for idle servers you're paying for the value uh that your service provides and uh my friend Daniel who runs the serverless Toronto group he likes to describe serverless as being similar to like energy efficient rating so an analogy of serus could be similar to energy rating labels which allows consumers to compare the Energy Efficiency of a product so some services are more servoless than others and again you know some people might not agree with that where there's a a definitive yes or no answer but I think that's the best way to look at it okay hey it's Angie Brown from exam Pro and we're taking a look at windows on ads so adabs has multiple cloud services and tools to make it easy for you to run window workloads on ads so let's get to it so the first is Windows servers on ec2 so you can select from a number of Windows Server versions including the latest version like Windows Server 2019 uh for uh databases we have SQL server on RDS you can select from a number of SQL Server database versions then we have adabs directory service which lets you run Microsoft active directory ad as a managed service we have adus license manager which makes it easier to manage your software licenses from software vendors such as Microsoft we have have Amazon FSX for Windows file server which is a fully managed scalable storage built for Windows we have the ads SDK which allows you to write code in your favorite language to interact with adus API but it specifically has support forn net a language favorite for Windows developers we have Amazon workspaces so this allows you to run a virtual desktop you can launch a Windows 10 desktop to provide secure and durable workstations that is accessible from wherever you have an internet connection a Lambda supports power shell is a programming language to write your serverless functions and we have Aus migration acceleration program map for Windows is a migration methodology for moving large Enterprises it us has Amazon partners that specialize in providing Professional Services for map this is not just everything for Windows on AWS like if you want to move your SQL Server over to RDS postest I believe they've like they created an adapter to do that um but yeah hopefully that gives you an idea what you can do with windowss on AWS okay hey this is Andre Brown from exam Pro and I want to show you how you can launch a Windows uh server on AWS so what you're going to do is go to the top here and we are going to type in ec2 and from here uh what we'll do is we'll go ahead and launch ourselves a new ec2 instance and we are going to have um a selection of instances that we can launch and so we're looking for for the Microsoft Windows server and this is interesting there's actually a free tier eligible that is crazy because if you go over to Azure they don't have a free tier Windows Server does so that's pretty crazy um and it runs on a T2 micro no that can't be right there's no way it can run a T2 micro that seems like that's too small let's try it okay I just don't believe it because when you use Azure you have to choose a particular size of instance by default and it's a lot more expensive and there is no free tiar so we'll go here there are free tiar just not really for Windows in particular so we'll go here this looks good security groups this opens up RDP so we can get into that machine we're going to go next here and launch this machine says if you plan to use Ami the benefits the Microsoft license Mobility check out this form that's not something we're worried about today and I mean I guess we can create a key pair I'm not sure what we would use a key pair for here um for Windows Amis the private key file is required to obtain the password used to log into the instance okay so I guess we're going to need it so Windows key great we'll launch that instance and uh I'll see you back here when it launches but I just don't believe that it would launch that fast you know all right so after a short little wait here the server is ready and so let's see if we can actually go ahead and connect to this so I'm going to hit connect here and we're go over to rdb client so you connect to your windows instance using a remote desktop client of your choice and downloading and running the RDP shortcut below so I'm going to go ahead and download this and you're going to have to be on a um Windows machine to be able to do this or have an rdb client installed I think there's one for Mac that you can get from the Apple Store um but all I'm going to do is just double click the file so you probably can't see it here I'm just going to expand this trying to oh my computer is being silly but anyway there we go we moved it over there I'm just going to drag over here and just double click this image so you can see that I'm doing it I'm saying connect okay and it's going to ask for a password so I'm going to hope that I can just click that and get the password so to decrypt the password you will need your key PA instance you'll have to upload that and I don't know if I remember having to do that before but it's a great security measure so I'm fine with it I'm going to drag my key to my desktop so I can see what's going on there as well and we're going to go grab that and decrypt the password and so now um where's our password oh it's right here okay so we're going to grab that password there we will paste that in said okay say yes and see if we can connect to this instance and if this is running on a T2 micro I'm going to lose it because that is just cheap it just just doesn't seem possible to me because again on Azure you have to launch an instance with a lot of stuff and it just uh seems uh crazy what's also interesting is that iTab us uh on Windows like launches so fast it's unbelievable how fast these servers uh spin up and it's just very unusual but yeah so we are in here um it's not asking me to activate or anything so I guess there's already a Windows license here and um I'm not sure if there's any kind of like games installed like do we have mind sweeper can I play mind sweeper on here it's a data center server so I'm assuming not um but yeah so this is a Windows server and it's pretty impressive that this works I'm not sure if this is going to have an outbound connection here um just because we probably would have to configure it let just say okay I just I really don't think it's going to go to the Internet by default yeah so You' probably have to do some stuff you know oh no there we go so yeah we got to the Internet so it's totally possible but uh yeah that's about it that's all I really wanted to show you so what I'm going to do is just go back to ec2 and we're going to shut down the server here just expand that there and we will go here and we will terminate that instance good we'll give that a refresh that's shutting down and we are done hey this is Andrew Brown from exam Pro and we are taking a look at Abus license manager and before we do let's talk about what b y l or bring your own license mean so this is the process of reusing an existing software license to run vendor software on a cloud vendor Computing service byol allows companies to save money since they may have purchased the license in bulk or the time that provided a greater discount than if purchased again and so an example of this could be the license Mobility provided by Microsoft's volume licensing to customers with eligible server applications covered by the Microsoft software Assurance program uh and I don't know what I was trying to do there I guess maybe it's just essay and I missed the parentheses there on the end no big big deal um but Aus license manager is a service that makes it easier for you to manage your software licenses from software vendors centrally across ads in your on premise environments ads license manager software uh that is licensed based on Virtual cores uh physical cores sockets or a number of machines this includes a variety of software products for Microsoft IBM sap Oracle and other vendors so that's the idea you say what is my license type it's it's bound to this amount of CPUs AAS license manager works with ec2 with dedicated instances dedicated hosts and even spot instances and for RDS there's only for Oracle databases so you can import that license for your Oracle server um just understand that um if you're doing Microsoft Windows servers or Microsoft SQL Server license you're generally going to need a dedicated host because of the Assurance program uh and this can really show up on your exam so even though a license manager works on dedicated instances and spot instances just try to gravitate towards dedicated hosts on the server or on the exam okay all right let's take a look at the logging services that we have available in AWS so the first one here is cloud trail and this logs all API calls whether it's SDK or the CLI so if it's making a call to the API it's going to get tracked between adaa services and this is really useful to say who can we blame who was the person that did this so who created this bucket who spent up that expense of vc2 instance who launched the stagemaker notebook um and the idea here is you can detect developer misconfiguration detect malicious actors or automate responses through the system then you have cloudwatch which is a collection of multiple Services I commonly say this is like an umbrella service because it has so many things underneath it so we have cloudwatch logs which is a centralized place to store your cloud services log data application logs metrics which represents a Time ordered set of data points a variable uh to monitor uh event Bridge or previously known as cloudwatch events triggers an event based on a condition so every hour take a snapshot of the server alarms triggers notifications based on metrics dashboards creates visualizations based on metrics and that's not all of the things that are under cloudwatch but those are the core five ones you should always know um absolutely there then we have adus xray this is for a distributed tracing system so you can use it to pinpoint issues within your microservices so you see how data moves from one app to another how long it took to move and if it failed uh to move forward okay let's take a close CL look here at Aus cloud trail because it's a very important service so it's a service that enables governance compliance operational auditing and risk auditing of your Aus account and the idea is that every time you make an API call it's going to show up as some kind of structured data that you can uh interact with or read through so abis cloud trail is used to monitor API calls and actions made on the AWS account easily identify which users and accounts made the call to AWS so you might have the WHERE so the source IP address the when the event time the who the user agent uh and the what the region resource in action so I'm just going to get my pen tool out here for a moment and just notice you have the event time so when it happened the source the name the region The Source IP address the user agent uh who was doing it so here was LE Forge the response element so you know it's very clear what is going on here um and then you know Cloud tra is already logging by default and will collect logs for the uh for the last 90 days via event history if you need more than 90 days you need to create a trail which is very common you'll go into AWS and make one right away trails are outputed to S3 and do not have guy like event history to analyze a trail you have to use Amazon Athena and I'm sure there are other ways to analyze it within AWS but here's just what the event history looks like so right off the bat you can already see that there are information there I'm not sure if they've updated the UI there they might have uh as even when I'm recording this I kind of feel like if we go into the follow along which we will um I bet they might have updated that the idea here is that you know you can browse the last 90 days but anything outside of that you're going to have to do a little bit of work yourself okay so we're not going to cover all the cloudwatch services there's just too many but let's look at the most important ones and one of that those important ones is cloudwatch alarms so cloudwatch alarms monitors a cloudwatch metric based on a defined threshold uh so here you can see there's kind of a condition being set there so if the network in is greater than 300 for one data points within 5 minutes it's going to breach an alarm so uh that's when it goes outside it's defin threshold and so the state's going to either be something like okay so the metric or expression is within the defined threshold so do nothing alarm the metric or expression is outside of the defined threshold so do something or insufficient data the alarm has just started the metric is not available not enough data is available and so when the state has change you can Define actions that it should take and so that could be doing a notification autoscaling group or any C2 action um so cloudwatch alarms are really useful for a variety of reasons the one that we will come across right away will be setting up a bilding alarm so let's take a look here at the autonomy of an alarm and so I have this nice graphic here to kind of explain that there and so the first thing is we have our threshold condition uh and so here you can just set a value and say okay the value is a TH or 100 whatever you want it to be and this is going to be for a particular metric the actual data we are measuring so maybe in this case we're measuring Network in so the volume of incoming Network traffic measured in bytes so when using 5minute monitoring divide by 3 00 we get bytes per second if you're trying to figure out that calculation there you have data points so these represent the metrics measurement at a given point then you have the period how often it checks to evaluate the alarm so we could say every five minutes uh you have the evaluation period so the number of previous periods and the data points to alarm so you can say one data point is breached and evaluation period going back four periods so this is what triggers the alarm uh the thing I just want you to know is that you can set a value right and that it's based on a particular metric and there is a bit of logic here in terms of uh the alarm so it's not as simple as just it's breached but there's this period thing happening okay let's take a look at cloudwatch logs so to understand that we have log streams and log groups so a log stream is uh a stream that represents a sequence of events from an application or instance being monitored so imagine you have an ec2 instance running a web application and you want those logs to be streamed to cloudwatch logs that's what we're talking about about here so you can create log streams manually uh but generally this is automatically done by the service you are using uh unless you were collecting application logs on any2 instance as I just described here is a log group of a Lambda function you can see the log streams are named after the running instance lambda's frequency run on New instances so the stream contains timestamps so what I'm trying to say here is that there's a variety of different Services Lambda RDS what have you and they already send their logs to cloudwatch logs and they're and they're going to vary Okay so here's a log group of an application log running on uc2 you can see here the log streams are named after the running instance ID here is the log group for Adis glue you can see that the log streams are named after the glue jobs um and so you know we have the streams but let's talk about the actual data that's made up of it the log events so this represents a single event in a log file log events can be seen within the log stream and so here's an example of you would open this up in cloudwatch logs and you can actually see what what was being reported back by your server you can filter these events to filter out uh logs based on simple or pattern matching uh syntax so here I'm just typing in saying give me all those debug stuff and you know this isn't very robust but adus does have a better way of analyzing your logs which is log insights which we'll look at here in a moment so we were just looking at uh cloudwatch log events and how those were collected but there's an easier way to analyze them and that's with log insights so you can interactively search and analyze your cloudwatch log data and it has the following advantages more robust filtering than using the simple filter in the in a log stream less burdensome than having to export logs to S3 and analyze them via Athena cloudwatch log Insight supports all types of logs so cloudwatch log insights is commonly used via the console to do ad hoc queries against log groups so that's just kind of an example of Solon writing a query and cloudwatch log insights uses a query syntax so a single request can query up to 20 logs query time out after 50 minutes if not completed and queries result are available for 7 days so abis provides sample queries that you can get started for common tasks and uh and ease the learning into the query syntax a good example is filtering VPC flow logs so you go there you click it and you start to getting some data you can create and save your own queries uh to make future repetitive tasks easier on the certified Cloud preder they're not going to ask you all these details about this stuff but I just conceptually want you to understand that in login sites you can use it to uh robustly filter your logs based on this query syntax language you get this kind of visual and it's really really useful let's take a look here at cloudwatch metrics which represents a Time ordered set of data points it's a variable that is monitored over time so cloudwatch comes with many predefined metrics that are generally named spaced by adus Services uh so the idea is that like if we were to look at the ec2 it has these particular metric so we have CPU utilization disre Ops dis write Ops disre bytes disr bytes Network in Network out Network packet in uh Network packets out and the idea is that you can just like click there into ec2 and then kind of get that data there and so Cloud metrics are leveraged by other things like Cloud watch events Cloud watch alarms cloudwatch dashboards so just understand that okay all right so what I want to do in this follow along is show you a bit about cloud trail so we're going to go to the top here and type in cloud trail the great thing about cloud trail is it's already turned turned on by default so it's already kind of collecting some information and so here it says now use I access analyzer on cloud trail trails that sounds pretty cool to me but uh we shouldn't have to create a trail right off the bat because we'll have some event history and the event history allows us to see things that are happening within our account in the last 90 days um but the thing is if you want something Beyond 90 days you're going to have to create a trail but if we just take a look here we can kind of see uh as we've been doing a lot of things all the kind of actions that's been happening so here we have an that I terminated so if I go in here and and look at it I can kind of see uh more information about it so we can see when it terminated who had done that what access key they had used the Event Source the request ID um The Source IP what whether it was readon what was the event type that was called the resource there and this is the actual raw record so this is generally how I would look at it or this is how you had to look at it back in the day um but the idea is that you would have that uh user identity described the event time the source the event name the region The Source IP the uh the agent all the information there okay and so this is a great way to kind of find stuff so you can go through here and try to debug things this way so you can go to the event name and so if you if you go here you can kind of get uh see a bit of stuff here so if I was just trying to say like maybe create I'm just trying to find something that I know that I've been doing like create access keys I can see the access keys that going be created within this uh sandbox account here for the user and things like that so it's a great way to kind of find things but generally you're going to always want to turn on uh or create your own trail so if you go here and hit create Trail say my new Trail and um you're going to need an S3 bucket for that you'll probably want encryption turned on which sounds good to me you'll absolutely want log file validation and generally you don't want to store your your cloud trail logs within the existing account you want to have a isolated hardened account that that is uh infrequently accessed or only by your your Cloud security Engineers um away from here because you don't want people tampering with it deleting it or changing stuff but um we'll just take an existing one here I don't want a customer manage don't I have one that is managed by ads here new custom uh we'll choose that one I don't know which one that is we'll just hit next usually adab us gives you a manage key there so I was kind of surprised um you can also include additional data so if you do data events this would collect information from S3 um but the thing is you might not want to track everything because if you track to everything it can get very expensive very quickly uh but if you don't you just leave on management events it'll save you more money there's inside events uh this is new I haven't seen this yet so ident I identify unusual activity errors users behavior that sounds really good but these could come also at additional charges but I'm going to hit next anyway for fun I'm going to create that trail okay and uh the key policy does not Grant sufficient access to etc etc so I'm going to go turn that off even though I should really have a turned on but I just want to be able to show you this okay so we have this new Trail and so this Trail is being dumped to S3 so we might not be able to see anything in here as of yet but I'm just going to pop over here and just see right I probably have one in my other account but it's not um it's not that important and we basically saw what the data would look like so we go into here there's a digest I don't remember there being a digest so that's nice so there's no data yet but when there is it will pop into there um I'm not sure if we're going to be able to do anything with insights here at least not in this account insights are events that are show unusual API activity and things like that so that's kind of cool I don't know what cloudwatch insights looks like uh inside events are shown in the table for 90 days okay so I'm just uh curious if we can see kind of a screenshot of what that looks like whoops well we're at least on the article here so I guess you get kind of get like some kind of graphs or something saying like hey this looks unusual and they might select it so not pretty clear in terms of what that looks like but I mean sounds like a cool feature and I'm sure when I when working on my uh security certification course I'll will definitely include in there but that's pretty much all there is to it um I'm going to go ahead and delete um that Trail because I I just don't really need in this account but generally you always want to go in and create a trail um and what you can do is if you're in your root account I'm not this is actually a an account that's part of an organization but if you're at that organization level you can create a trail that that spands all the regions that spans all the ad accounts with an organization and that's what you should be doing okay but uh that's about it hey this is Andrew Brown from exam Pro we're looking at ML and AI services on AWS but let's first just Define what is AI ML and deep learning so AI also known as artificial intelligence is when machines that perform jobs that may make human behavior ml or machine learning are machines that get better at a task without explicit programming and deep learning or DL are machines that are have an artificial neural network inspired by the human brain to solve complex problems and a lot of times you'll see this kind of onion where they're showing you that um you know AI uh can be using ml or deep learning and then deep learning is definitely using machine learning but it's using neural networks and so for AWS their Flagship product here is Amazon sagemaker it is a fully managed service to build train deploy machine learning models at scale um and there's a bunch of different kind of Open Source Frameworks you can use with it like apachi mxnet ons which is an open source deep learning framework that is the one that abis decided to say hey we are going to back this one and so you'll see a lot of example code for that one we have tensor flow that you can use pie torch uh hugging face other things as well okay um and so there's a lot of uh Services underneath some that might be of interest to mention right away is like Amazon sagemaker ground truth which is a data labeling service where you have humans that label a data set that will be used to train machine learning models or maybe something like Amazon uh augmented AI so human intervention review Services when sagemaker uses machine learning to make a prediction that is not confident uh and it has the right answer cue up to the predict for a human review and these are all about just labeling data um you know when you're using supervised um supervised learning but there are a lot of Services Under sagemaker itself and just AI services in general so we'll look at that next okay all right let's take a look at all the ML and AI services and there's a lot on AWS so the first is Amazon code Guru this is a machine learning code anal service and cod Guru performs code reviews and will suggest to improve the code quality of your code it can show visual code profiles to show the internals of your code to pinpoint performance next we have Amazon Lex this is a conversation interface service with Lex you can build Voice and text chat Bots we have Amazon personalized this is a realtime recommendation service it's the same technology used to make product recommendations to customer shopping on the Amazon platform then we have Amazon poly this is a text to speech service upload your text and an audio file spoken by synthe synthesized voice uh and that will be generated you have Amazon recognition this is an image and video recognition Service uh analyze image and videos to detect and label objects peoples and celebrities then we have Amazon transcribe this is a speech to text service so you upload your audio and that'll be converted into text we have Amazon text extract this is an OCR tool so it extracts text from scan documents when you have uh paper forms and you want to digitally extract that data we have Amazon translate this is a neural machine learning translation service so use deep learning mod models to deliver more accurate and natural sounding translations we have Amazon comprehend this is an NLP so natural language processing service find relationships between text to produce insights looks at data such as customer email support tickets social media and makes predictions then we we have Amazon forecast this is a Time series forecasting service and it's you know uh I mean technically I guess it's a bit of a database but the idea here is that it can forecast business outcome such as product demand resource needs or financial uh performance and it's powered by ml or AI if you want to call it we have adabs deep learning Ami so these are Amazon ec2 instances they're preinstalled with popular deep learning Frameworks and interfaces such as tensorflow pytorch apachi mxnet chainer GL uh glue on uh horovod and kirz we have adabs deep learning containers so Docker images instances preinstalled with popular deep learning Frameworks and interfaces such as tensorflow pytorch Apachi mxnet uh we have adus deep composer this is machine learning enabled musical keyboard uh I don't know many people using this but it sounds like fun it was deep lens is a video camera that uses deep learning it's more of like a learning tool so again we don't see many people using this adus deep racer is a toy race card that can be powered with machine learning to perform autonomous driving again this is another learning tool for learning ml they like to do these at reinvent to have like these racing competitions Amazon elastic interface so this allows you to attach lowcost GPU perform uh powered acceleration to ec2 instances to reduce the cost of running deep learning interfaces by 75% we have Amazon fraud detector so this is a fully managed fraud detection uh as a service uh it identifies potentially fraudulent uh online activities such as online payment fraud and the creation of fake accounts Amazon Kendra so this is an Enterprise machine learning search engine service it uses natural language to suggest answers to questions instead of just simple keyword matching so there you go hey it's Andie Brown from exam Pro and we're going to do a quick review here of the big data and analytic services that are on AWS but before we do let's just Define what big data is so it's a term used to describe massive volumes of structured or unstructured data that is so large it is difficult to move and process using traditional database and software techniques so the first here we have is Amazon Athena this is a serverless interactive query service it can take a bunch of CSV or Json files in an S3 bucket and load them into a temporary SQL table and so you can run SQL queries so it's when you want to quate CSV or Json files if you've ever heard of um apachi Presto it's basically that okay then we have Amazon Cloud search so this is a fully managed full teex search service so when you want to add search to your website we have Amazon elastic search service um commonly abbreviated to es and this is a manage elastic search cluster and elastic search is an open source full Tech search engine it is more robust than Cloud search but requires more server and operational maintenance then we have Amazon elastic map produce commonly known as EMR and this is for data processing and Analysis it can be used for creating reports just like red shift but is more suited when you need to transform unstructured data into structured data on the Fly and it leverages opsource um technology so like spark um Hive Pig things like that then we have Kinesis data Stream So This is a realtime streaming data service it creates producers uh which sends data to a stream it has multiple consumers that can consume data within a stream and use uh it for realtime analytics click streams ingestion data from Fleet of iot devices then we have Kinesis fire hose this is a serverless and a simple version of a data stream and you pay on demand based on how much data is consumed through the stream and you don't worry about the underlying servers then you have Amazon Kinesis data analytics this allows you to run queries against data that is flowing through your realtime stream so you can create reports and Analysis on emerging data and last on the Kinesis side here we have Amazon Kinesis video streams this allows you to analyze or apply processing on realtime streaming videos onto the second page here we have manage kofka service msk um and it might be MKS um now that I'm looking at it here so just be aware that that might be incorrect but a fully manage Apachi kofka service kofka is an opensource platform for building realtime streaming data pipelines and applications it is similar to Kinesis but with more robust functionality then we have red shift which is um a with is flagship uh Big Data tool it's a petabyte size data warehouse the data warehouses are for online uh online analytical processing olap so data warehouses can be expensive because they are keeping data hot meaning that we can run a very complex query in a large amount of data and get that data back very fast but this is great when you need to quickly generate analytics or reports from a large amount of data we have Amazon quick site this is a business intelligence tool or a business intelligence dashboard bi for short you can use it to create business dashboard to power business decisions it requires little to no programming and connect and adjust to many different types of databases if you ever heard of Tableau or powerbi this is just the adus equivalent we have adus data pipelines this automates the movement of data you can reliably move data between compute storage and services we have adus glue this is an ETL service so it allows you to move data from one location to another where you need to perform Transformations before the Final Destination it's simar similar to DMS but it's more robust we have AB Lake formation this is a centralized curated and secured repository that stores all your data so it's a data Lake it uh is a storage repository that holds a vast amount of raw data in its native format until it is needed and then last on here we have adab data exchange this is a catalog of thirdparty data sets you can download for free uh or subscribe or purchase data sets so they might have like the covid19 foot traffic data the IMDb TV movie data historical weather data and sometimes this is really great if you're just trying to learn how to to work with these tools okay hey this is Andrew Brown from exam Pro and we are taking a look here at Amazon quick site which is a business intelligence dashboard or bi dashboard that allows you to ingest data from various databus storage or database services to quickly visualize business data with minimal programming or data formula knowledge so here's an example of a quick site dashboard um and so the way quick site is able to make these dashboards super fast is if you have spice the super fast parallel inmemory calculation engine um and the thing is you don't have to use spice um but generally it is good to use it uh and there are some caveats when getting your data into Quick site sometimes it can't ingest data directly from a particular uh data store so you might have to dump it to S3 first but it's not too bad because you can use AIS glue to transform that data over um there are additional features sometimes Market is services but we have quick site ml insights this detects anomalies perform accurate uh forecasting it can generate natural language narrative so basically like you know describe it as if you're going to read it out as a business report you know then there's Amazon quick site Q this allows you to ask questions using natural language on all your data and receive answers in seconds so there you go hey this is Andrew Brown from exam Pro and let's go take a look at Amazon quick sites which is a or quick site which is um a business intelligence tool so when you go here you have to uh sign up because it's kind of part of ads but on its own separate thing and then you have to choose what you want so we have Enterprise and standard um I do not want to pay that much so I'm going to go to standard over here I'm not really sure what the difference is it's not really telling me what um between standard and Enterprise but I'm going to assume standard is more cost effective but here we it says user use I am Federated identities which is fine use I am Federate enties only um we can stick with the top one there that seems fine to me we need to enter a name so just say my quick site account and we probably have to fill something in there so let's say Andrew exam pro. and these are the services that are going to integrate with Athena S3 RDS things like that I guess we could select some of those buckets I'm not too worried about doing that right now the provided account name is not available that is a terrible UI but that's AWS for you I'm just going to dump some numbers there going put my email in here again um we probably want some S3 buckets I'm going to make a new bucket because I think that's how we're going to do this we're going to have to make a bucket here and say uh quick site data okay and we're going to create ourselves a bucket here I'm going to go back and hopefully that shows up uh it does not so what I'll have to do is just back out and I'm just going to give it a hard refresh here and we're hit quick sign up for quicksite again and we'll choose standard and we'll say my quick site account a bunch of numbers there Andrew exam pro. I don't really care about adjusting data from everywhere else I just want it from S3 there's my data uh sure we'll give it right permissions even though I don't plan to do anything with Athena here today he and we'll give it a moment to load so what I'm thinking is so what I'm thinking is just making like an Excel spreadsheet here and just filling in some data so oh says our account is set up here so we'll go to Quick site because I bet it can import like a CSV or something um I'm more of a tableau or powerbi kind of person um but uh you know for the purpose of the cloud practitioner I am going to show you this Amazon quick set lets you easily visualize data and Etc that sounds great next next next I know what I'm doing oh do we have some examples great so I don't even have to make a spreadsheet okay so what we'll do is just click on that and we have stuff it looks like they've really improved this since the last time I've seen it which is quite nice um but I could try and make my own I'm just trying to think how do we do this again yeah we have the spice there so it's a lot easier from starting from scratch I'm just going to say close and user analysis we want data sets in here oh we already have some data sets these are coming from S3 I think that's the old S3 logo I'm not sure why they're using that one we can go here and create a new data set oh we can upload directly so I don't even have to use use S3 that's great so what I'm going to do is just have some values in here so I'm going to just say um uh type value so we'll say banana 125 123 we'll say apple 11 orange nobody likes oranges I shouldn't say I'm sure it's like lots of people like oranges oh we got to put pairs on there I actually really like pairs people think I like bananas which is not true I actually like pears that's what I like so I'm going to go ahead and save this save as and I'm just going to save this to my desktop here so just give me a moment just doing this offc screen and I'm just save this uh data set quick site CSV it can even take an XLS so I don't have to save it as a uh I'll just save it as a an XLS okay and so we're going to just upload that so there is that data set it's going to scan that file it's going to see that sheet you even preview it there's the information we're going to add that data uh I get add it as a data data set well how do I where where do I it's like it says add the data I just want to add it as a data set so they said up here save and visualize up here and is it autographing yet maybe if I drag in is it working is it thinking okay it's at 100% so I'm going to just drag that onto there and it says pear orange banana just kind of trying to make sense of this here is it taking and count the value maybe put the value down there wow that's so much easier I hav't used this for like a year and and um I'm going to tell you this has gotten a lot easier to use so I'm quite impressed with this but yeah I mean this is pretty much what quick site is if you want to visualize things in different types you can drag them out you can probably like click on the the wheel here and change it again I'm not sure exactly how all the uh the dials and knobs work here but I mean another thing we could do is just drag out like another object and do the same thing so maybe I'd want a pie chart um so uh a visual yeah it's not as nice as powerbi but like it's still great that it's here you know type value so we got a nice pie chart there uh let's try something weird let's give this one a go doesn't color it which is not very nice um there's probably some kind of way to color it but focus on banana only I don't know I don't know what the point of there but anyway that's quick sight so um I really don't want to pay for this this so what I'm going to do is go up here um there's you have to deactivate I'm just trying to remember how because they change the interface again they change everything on you so maybe we go I'm on a trial for four days here maybe quantity for just the four 29 day trial so if I want to get out of this trial what do I do I don't want to use it anymore um so how to delete AWS quick site canceling your subscription so before you can unsubscribe uh you're signed in the IM account you're quick site administrator you're the root IM administrator sure uh you deleted any secondary name spaces to find the existing name space Etc so choose your username in the application bars manage quick site account settings unsubscribe so I was almost there I thought I was in the right place uh this one no I was just there manage quick site your subscriptions edit there's no unsubscribe option so I'm not sure can I cancel unsubscribe button does not appear in quick site and it could just be because we're on trial and so maybe after the end of the trial it will uh it will vanish there they are not making this easy for me account settings ah delete accounts so this is what we're probably want to do permanently delete the account yes I mean that has to get rid of the subcription because it gets rid of everything there we go we'll say confirm delete account unless you're using them in the services blah blah blah blah blah um successful okay great so now I should go back to ads. amazon.com and just to confirm that it's gone I'm going to go to quicksite again and just see if it's trying to ask me to sign again so it is so I've gotten R of my account so we're all in good shape and uh yeah that is that is quick site all right let's take a look at some more machine learning AI Services because eight of us won't stop making these things um and basically last time I made uh the videos all this generative stuff did not exist so we need to cover it the first is Amazon Bedrock so the uh this uses large language models and makes it a cloud service is offering to generate text and images responses if you know what chat GPT is you know what Bedrock is we have Amazon code Whisperer it's an AI code generator that will predict code to meet your use case uh so if youve heard ever heard of GitHub copilot it's the same thing basically uh it's going to write code for you or along with you I should say uh we have Amazon devops Guru this uses ml or machine learning to analyze your operational data and application metrics and the vents to detect operational abnormalities um imagine if you had kind of like a junior devops person digging into your metrics to figure out if there's something wrong then we have Amazon Lookout this is actually three different um offerings we have Amazon lookout for equipment Amazon uh lookout for metrics and Amazon lookout for vision they all seem to have to do something with quality control and Performing automated inspection so vision of course would use Vision to detect anomalies uh one would be for equipment to detect if there's anything wrong with operational equipment uh and then metrics would be you know with metric data so something probably more for um the hard Industries uh to utilized and you have Amazon monotron so this uses machine learning models to predict unplanned equipment downtime and so the way they do that is they have these uh iot sensors that's going to capture vibrations and sensor data from your Hardware then we also have adus neuron this is an ad SDK used to run deep learning workloads on adus uh infer I can't say that word but I know what it is it's basically um it's a machine learning acceleration on gpus that you can attach and adus train trainum so yeah I wish the words weren't so hard there's actually more um stuff that Aus has for machine learning I didn't include them because they were just too far out there and they're definitely not going to show up in your exam you'll definitely never see them but we now have better coverage what I really wanted to show was Bedrock H Whisperer because I feel like those two uh will show up on future exam so I'm just trying to get those in front of you now even if they're not on the exam uh at the time of this recording okay ciao all right so you probably already know what generative AI is but just in case you don't I want to just quickly cover it and show a very tiny example uh so generative AI which also can be shorten to gen AI though most people don't say that uh is a type of artificial intelligence capable capable of generating new content such as text images music or other forms of media so an example would be something like a software that I like to use called mid Journey uh where you can put in a prompt and so it will then go ahead and generate out an image um so all the cloud service providers have some kind of offering with both image and text um but yeah hopefully that makes sense the idea is that you can plug stuff in and you get stuff out okay Let's us take a look here at machine learning and deep learning Frameworks and so these are Frameworks that can be used with sagemaker or have direct support for them I just want to get you some uh exposure and to uh get you some context in terms of these because machine learning and Ai and all this stuff is becoming more popular so you should at least have heard of these things so I have all the logos on the left hand side and we'll go through them the first is Apachi mxnet so this is a machine learning framework adopted by AWS basically um every single cloud service provider backs their own kind of open source framework and they try to make that the one that they suggest you to use but in practice uh there's ones that are good and there's ones that people just don't want to use and apach mxnet is not fun to use whatsoever um and so you'll see it all over in the marketing and pushed everywhere but really people want to use things like curus tensorflow but anyway I just wanted to point that out that it was has a bias because they've invested energy into uh their team of machine learning Frameworks you got pytorch uh optimized for tensor Library uh for deep learning using GPU and CPU it's created by Facebook Facebook does not necessarily um have its own cloud service provider offering so it's kind of out there and so you'll see good support for pytorch and all the major providers U the next is tensorflow this is made by Google what's in with tensor flow is Google made uh their own um GPU or TPU they call it a tensor Processing Unit so tensor is a a unit of thing in tensor flow and it they have optimized hardware for it I personally find tensorflow the easy to use or I should say cires so um cures is a highlevel machine learning framework built on top of tensorflow because these lower level ones were just really hard to use and so basically pytorch came along and it was much easier to use and then then everyone noticed how easier pytorch was and so that's where curus came from was to be competitive with pytorch and be easier to use then you have Apachi spark which is a unified analytics engine for large scale data processing but they do have ml offerings within it called spark ml um so there's definitely things you can do there uh there's a piece of software called chainer um and it's for it's a deep learning framework that supports Cuda then there's hugging face which is not exactly a framework or tool it's just a way of accessing a lot of models online and data sets and quickly launching them for whatever reason I uh adus has uh strong synergies with hugging face I've seen like developer Advocates and other uh folks that worked at AOS go over to hugging face and so there seems to be strong uh relationships between hugging face and adabs for whatever reason there's a lot of ml Frameworks out there but because uh ml is uh just uh progressively um are rapidly innovating you'll see Frameworks come and go and so I remember when I researched this and I was just trying to understand all the Frameworks out there there's just a lot and I just kept digging into them finding oh they're not active anymore they're not active anymore so I just want to point out that we have all these ones up on screen if they become unactive tomorrow I would not be surprised but uh for the most part all of these seem to be very popular uh and uh they're being well supported uh but yeah hopefully that gives you an idea of these Frameworks okay ciao all right let's take a look here at Apachi mxnet a little bit more in detail because this is the framework that iTab us wants you to use whether you want to use it or not is a different story uh but you'll see it all over in their marketing pages and things like that so apoi mxnet is a deep learning machine learning framework which supports many many different programming languages so that is one advantage of it uh the key features uh is that it's scalable it's flexible it's portable it's it supports multiple programming language iTab has made Apachi mxnet their framework of choice so there's lots of support for it within ad sagemaker and the ad ml containers but I have noticed that they've been increasing support for p torch so maybe you know they're just trying to meet the customer where they are but anyway um there is a lot of stuff for mxnet mxnet has two highlevel interfaces uh one's called glue on and there is module API so uh depending on which one you use one is imperative programming one's symbolic programming uh this is more of a deeper concept for machine learning but I'm going to tell you one is really easy one is really hard um but uh let's look at a very simple example of uh some code for using the gluon API so it kind of looks like that you can see that they are using python so hopefully that gives you an idea of uh mxnet and its offering the key thing is that it offers it in a lot of different programming languages will this appear on your exam absolutely not but should you know it you absolutely should um just so you have good context with adabs and ml so there you go I want to talk a little bit about Intel because I think it's very important to remember the hardware that is running with these um cloud service providers because it really does matter um and there's a couple terms you might see when using a compute that you're not aware of and I want to make sure you know what they are so let's talk about what is Intel so Intel is a multinational corporation is one of the world's largest semiconductor chip manufacturers Intel is the inventor of the x86 instruction set so basically uh they released this chip back in 1978 this one's called the Intel 88086 chip and the idea is that um they came up with an instruction set um it's basically a bunch of words that you can use um to program the chip and it's a lower level language so um that lower level language would be an assembly um if if that makes any sense so the idea is that you have this um instruction set and you have to write an assembly and so basically most modern programs like when you use uh programming languages like uh C it will actually compile down to assembly um or other languages will compile down to assembly because that is what the chip understands and then assembly is turned into machine code like the zeros and ones and the reason I'm mentioning this is that when you go and you uh launch uh a compute uh instance let's say on ads uh you're launching a E2 instance you have to choose uh whether it's x86 or a different instruction set or architecture and so the other one is arm and they're both really really good it just depends on whether uh uh your stuff can support it but for the most part Intel has arm chips as well so um there is no company that produces armed chips per se it's just an architecture and uh the way it works is that it just has fewer instruction sets so there's fewer uh rules that you can write in so it's a more limited writing it in assembly but at the end of the day it doesn't matter because your programming language is going to compile it down so you don't have to worry about those fewer instructions but because it has fewer instructions it generally results in a better uh Power efficiency and so it can have better performance or better or better cost to you the customer so when I can I try to run arm and for the most part it's always great to run arm but uh it really depends on if your software is going to be able to run on arm um and stuff like that so I just wanted to point out those two things there about uh at least Intel and then instruction sets okay all right I want to talk about two things um that Intel has with ads and the first is Intel xon scalable processor and the second is Intel Gotti um so it of course does work with or purchases um Hardware from other um uh other companies like they use AMD and Nvidia but I think it's worth mentioning Intel in a little bit more detail here here because every time I go to reinvent Intel has a big giant booth and you can go scour the ads website and it just looks like ADS works more closely with Intel as opposed to the other uh providers not to say that Intel is not being utilized on gcp and Azure and others but uh I just noticed something more going on there with AWS but let's first talk about Intel xon scalable processors these are high performance CPUs designed for Enterprise and server applications commonly used in ESS instances um that scalable part makes them very good for machine learning so you often are going to be be using Intel xon processors whether you know or not on ads the Intel is the Intel uh Habana Gotti processor so this is a uh processor specialized for AI training uh you could say that this is a direct competitor to Nvidia or a similar competitor because uh they uh they uh do something very similar um I believe that Intel Gotti has their own SDK called synapse AI uh that you can use to interact with it so you launch up Sage maker and then use uh that uh that API or SDK in order to uh best utilize uh that Hardware there but both of these um pieces of Hardware are offered uh on a and I think it's just good to know them at least to name uh what they are okay hey this is angrew brown and let's talk about gpus I'm sure most people know what gpus are here but I'm going to talk about it anyway because I want to talk about cudas so a GPU stands for General processing unit and it's a processor that is specialized to quickly render high resolution images and videos concurrently if you've ever played video games you know you need a good GPU because it's all about those images however gpus can perform parallel operations on multiple sets of data so they can also be used for nongraphical tasks and this makes it really good for machine learning and scientific computation so if you're trying to uh convince your significant other that you need a better graphics card you can just tell them it's for work I need it for machine learning and scientific comp computation it's not your fault that you can also play video games with it and so we have like a graphic there on the right hand side I think I got that from Nvidia and so they're kind of trying to demonstrate the difference between uh the paralyzation with GPU versus serial tasks with CPU but let's go and just read a littleit more so CPUs can have an average of four to 16 processor cores gpus can have thousands of processor cores how that works I have no idea but I just know that that's how it works uh so we have 48 gpus can provide as many as 40,000 cores so that is a lot gpus are best suited for repetitive and highly parallel Computing tasks such as rendering Graphics cryptocurrency mining if people are even still doing that and deep learning and machine learning so you know there you go that's gpus all right let's take a look here at Cuda but before we do let's talk about Nvidia so Nvidia is a company that manufactures graphical processing units for gaming and professional markets if you have ever played video games and you build your own rig um a lot of people like to choose Nvidia but Nvidia can do things other than video games and this is due to their framework uh called Cuda which stands for compute unified device architecture so it's a parallel Computing platform and API I said framework but I guess it's an API by a video that allows developers to use Cuda enable gpus for general purpose Computing gpus and it says GP GPU because it's saying general purpose gpus I know that's a mouthful there um so over on AWS they have a bunch of instances that um can utilize uh Nvidia GPU so I adus is always changing the instances so these could be old but you can see we have a P3 which has the Tesla Tesla V100 you have the G3 with a Tesla M M60 the G4 with the T4 uh the P4 with the Tesla a 100 so there's probably these are probably old ones there's new instances with newer Nvidia cards but my point is is that adus has uh gpus that you can utilize another thing I want to point out with Cuda is that all major deep learning Frameworks are integrated with Nvidia deep learning sdks there's a big fight or War over um uh these companies that make uh gpus and CPUs because they really want the uh Theirs to be used for machine learning so you can definitely be sure that AMD probably has some kind of similar offering or something uh and definitely Intel as well um but Nvidia has done a very good job in uh making sure that theirs is the most popular um so EnV deep learning SDK is a collection of uh Nvidia libraries for deep learning so this is something that this is the SDK you can use with Cuda to interact with their API uh so one of those libraries are called cuda deep neural network library so that's something you can use with it and it's uh tuned for a bunch of stuff if it looks like it's getting a little bit too um uh technical it's because this slide was was for my machine learning uh inabus specialty and I didn't do a whole lot to change it and Brad it over uh so you don't don't really need to know that last part there but just understand what Cuda is and that it's uh very important uh for working with machine learning and AD us has uh good offerings uh for instances with it okay hey this is Andrew Brown from exam Pro and we are taking a look at the ads well architectur framework so this is a white paper created by AWS to help customers build using best practices defined by AWS you can find this at AWS amazon.com architecture forwell architected this idea is not unique to AWS the other providers have it but I believe AWS was the first one to Define this and they have a really good uh a good approach to this and this is pretty much Essential Knowledge that you have to have uh four certifications when we're looking at the cloud practitioner the soci architect associate and professional because um there's a lot of principles here best practices that adus uses themselves to architect their infrastructure okay so the framew is divided into five sections called pillars which address different aspects or lenses that can be applied to a cloud workload so imagine you have your Cloud workload you're going to want to adopt an aable architect framework some things that you know people don't consider outside the Five Pillars is that you need to know General definitions uh General design principles and the review process um and then from there you have your five pillars so you have operational excellence security reliability performance efficiency and cost optimization and all of these have major SE sections in this uh white paper but outside of just the main white paper each of these have their own white papers that go even into farther detail so if you really want to uh really focus on security and get a lot more information they have that as well okay let's take a look at the general definitions for the well architecture framework starting with the pillars so the operational excellent pillar is there to run and monitor systems the security pillar is to protect data and systems to mitigate risk the reliability pillar is to mitigate and recover from uh disruptions the performance efficiency pillar is about using Computing resources efficiently or effectively and the cost optimization pillar is about getting the lowest price and this is where you're going to find all the business value and I put an aster there because uh you know you might obsess saying we need to meet the requirements for all these pillars and that's not the case you can trade off pillars based on the business context so you know don't take it as uh literally Implement every single thing but just consider that uh you know you might have to adapt it based on your workloads then we have some general definitions that we will come across so there's components so code configuration itless resources against the requirement a workload so a set of components that work together to deliver business value mileston so key changes of your architecture through the product life cycle then there's architecture itself so how components work together in a workload and then we have technology portfolio so a collection of workloads required for the business to operate okay so the well architected framework is designed around a different kind of team structure so when you're looking at Enterprises they generally have a centralized team with specific roles where ADS structures their teams as being distributed with flexible roles and so this new kind of methodology of distributed teams uh has some major advantages but it does come with some risks and so adus has baked in some uh practices or uh things that they do to mitigate these issues okay so let's compare on premise Enterprise uh to what databus is proposing for your team structure so on premise what we'd see is a centralized team consisting of technical Architects solution Architects data Architects Network Architects security Architects and you kind of see that they all have a specialized vertical and they are usually managed by either to GF or Zack man framework so those are just ways of structuring your teams those are very popular and so what aabus is proposing here is that you have a distribute team and uh the way you're going to make that team work because obviously just thinking about distribute team they're going to be a lot more agile but to make sure that they effectively work you have practices like team experts who raise the bar uh making sure that you know uh in any areas we can always say how can we do this better uh then there are mechanisms in place for automated checks for standards so that's the great thing about Cloud can all be automated to say hey does it meet our Regulatory Compliance or or or what have you and then there's the concept of the Amazon leadership principles which we will cover on in the next slide in detail and so um you know itus is not obviously using uh these other Frameworks because it has its own which is this one here but the the mechanism to which they stay organized and up to date is they are supported by a virtual community of subject matter experts principal Engineers so that what they'll do is they'll engineer things like lunchtime talks and then recycle that into their onboarding material or into this framework itself okay so we're taking a look here at Amazon's leadership principles and these are a set of principles used during the company's decision making problem solving simple brainstorming and hiring all right um and so I can't say that I like all of these but definitely some of them really stand out as being great especially the first one which is customer Obsession so instead of worrying about what your competitors are doing think about what the customer wants work your way back and uh you know really focus on the customer needs needs then there's ownership so if you're going to go do something uh you know try to be your own mini boss uh and take responsibility for whatever it is you're building event and simplify so you know always look for the simplest solution don't try to engineer something super complicated if it's not necessary uh or right a lot so you know try to be right uh learn and be curious so that's pretty selfexplanatory hire and develop the best insist on the high standards adus always refers to this as raising the bar think big buys for Action fr it andus is really Frugal if you didn't know that but not just for like themselves but also for their customers they want customers to uh spend the least amount of money possible when using their infrastructure earn trust uh dive deep have a backbone disagree and commit deliver results strive to be the earth's best employer success and scale bring broad responsibility and if you want to read these in detail because they have a big block of text for each of these uh you can go to amazon. jobs uhen principles and read all about it okay all right let's talk about some general design principles uh that you should be considering when you are designing your infrastructure no matter what pillar that you are looking to adopt the first is stop guessing your capacity needs so the great thing with cloud computing is you use as little or much based on demand whereas on premise you would have to purchase a machine and you'd have to make sure you have additional capacity so that you could grow into it right and so here with uh cloud you do not have to worry about that uh test systems at production scale so be able to clone your production environment to testing tear down testing while not in use to save money so a lot of people will have a staging server that they run all the time but the great thing here is that with Cloud you know it's you can just spin it up and have it right away and then tear it down and save money um there's automating to make architectural experimentation easier this is talking about using infrastructure as a code so for ads this to be using cloud formation creating change sets which kind of um uh say exactly what is going to change stack updates drift detection to see if your stuff is uh being changed over time by developers through manual configuration things like that then we have allow for evolutionary architectures so this is about adapting cicd um doing nightly releases or if you're using serverless if you adopted lambdas they deprecate over time forcing you to use the latest version uh and so that is evolutionary architectures then we have drive architectures using data so um when you're using Cloud there's a lot of Tooling in there to automatically start collecting data so Cloud watch will be collecting some things by default and cloud trail will as well so you know that is another thing and then improving things through game days so this is about stimulating traffic on production or purposely killing ec2 instances or or messing with your services to see how well they recover all right before we jump into each of the pillars let's go open them up and take a look at what structure we should expect to see so we have design principles definition best practices and resources all the pillars follow this to a t so let's just talk about what these are so the design principles are a list of design principles that needs to be considered during implementation and that's where we're going to focus a lot of our energy then you have definition so this is an overview of the best practice categories then you have the best practices themselves these are detailed information about each practice with uh various a services and then you have resources these are additional documentation white papers uh and videos to implement this pillar and I just want to tell you that if you're doing the certified Cloud practitioner we're really just going to cover the design principles but for the solutions architect associate or anything uh that's associate or above that's where we're going to actually dive deep into the implementation of the best practices because there is a lot of stuff there so uh yeah there we go let's take a look here at the design principles for operational excellence so the first here is perform operations as code so apply the same engineering discipline you would to application code to your infrastructure so by training your operations as code you can limit human error and enable consistent responses to events generally we're talking about infrastru infrastructure as a code here so this would probably be like things like cloud formation there's other things you could do like policy as a code and a bunch of other ones then we have make frequent small reversible changes so design your workloads to allow components to be updated regularly uh this could be talking about doing roll backs incremental changes Blu green deployments having a cicd pipeline refined operations procedures frequently so look for continuous opportunities to improve your operations uh here you use game days to simulate traffic or event failure on your production workloads anticipate failures to perform post modems on system failures to better improve write test code kill production servers um there's a small spelling mistake it should have an R here so servers to test recovery learn from all operational failure so share Lessons Learned in a knowledge base for operational events and failures across your entire organization but you know if you can just remember these headings here uh and be able to categorize what would be under operational excellence you'll be okay all right all right let's take a look at the design principles for the security pillar so the first here is Implement a strong identity foundation so implement the principle of lease privilege or PP that's a very popular concept meaning give people only the permissions that they need use centralized identity so that would be using adus am avoid longl credentials then we have enable traceability so monitor alerts and audit actions and changes to your environment in real time integrate log and Metric collection and automate investigations and Remediation then we have apply security at all layers so take defense in depth approach with multiple security controls for everything from Edge networks vbcs load balancing instances OS application code we might have a slide in this course on defense into depth where basically you see like a ring of things and you can kind of see how like there's layers that go from outward to Inward and that's what they're talking about when they're listing out all these things here automate security best practices uh protect your data in transit at rest uh keep people away from your data the reason I don't have descriptions there is because those are pretty selfevident prepare for security events so Incident Management systems and investigation policies and processes tools to detect investigate and recovery from incidences and uh there are a lot of security tools out there and they all have funny initialisms I didn't put any of them in here but I'm sure there are some there um but yeah there you go for security all right let's take a look at design principles for reliability and the first here is automatically recover from failure so Monitor kpis and Trigger automations when the threshold is breach test recovery procedures so test how your workload fails and you validate your recovery procedures you can use automation to simulate different failures or to recreate scenarios that led to failures before scale horizontally to increase aggregate system availability so replace one large resource with multiple small resources to reduce the impact of a single failure on the over overall workload distribute requests across multiple smaller resources to ensure that they don't share a common point of failure so we're talking about multiaz uh High availability okay stop guessing capacity we've seen this multiple times so in on premise it takes a lot of guess work to determine the elasticity of your workloads uh workload demands with Cloud you don't need to guess how much you need because you can request the right size of resources on demand that's going to give you better reliability okay manage change and automation so making changes via infrastructure as a code will allow for a formal process to track and review infrastructure you're going to see IC show up a lot in this framework okay let's take a look at design principles for performance efficiency so the first here is democratize advanced techn technology so focus on product development rather than procurement provisioning and management of services because if you're on Prem you'd have to order those machines set them up and so take advantage of advanced technology specialized and optimized for your use case with on demand cloud services because again if you're using on Prem uh you you know you might not have the option to have Sage maker right it's just going to be a VM and you're going to have to do all the work yourselves whereas ads has all these specialized things so you can move quickly uh Go Global in minutes so deploying your workload in multiple abis regions around the world allows you to provide lower latency and a better experience for your customers at a minimal cost we have used seress architecture so servess architecture removes the need for you to run and maintain physical servers for traditional Computing activities removes the operational burden of managing physical servers and can lower transaction costs because manage services operate at Cloud scale and it us can be a lot better at um running them efficiently than you will uh experiment more often so with virtual and automatable uh resources you can quickly carry out comparative testing using different types of instan and Storage or configurations to make the best choice we call this right sizing choosing the right size consider mechanical sympathy so understand how cloud services are consumed and always use technology approach that aligns best with your workload goals for example consider data access patterns when you select database or storage approaches let's take a look here at design principles for cost optimization so the first one here is Implement Cloud financial management so dedicate time and resources to build capacity uh via Cloud financial management and cost optimization tooling stus is saying hey take advantage of all our tooling they makes it easy for you to know exactly what you're spending adopt a consumption model so pay only for computing resources that you require uh an increase or decrease using uh depending on the business requirements we're talking about on demand pricing measure overall efficiency so measure the business output of the workload and the cost associ associated with delivering use this measure to know the gains you make from increasing inreasing output and reducing costs so stop spending money on undifferentiated that's a hard word to say undifferentiated heavy lifting so adus does the heavy lifting of the data center operations like racking stacking and power servers it also removes the operational burden of managing operating systems and applications with managed services this allows you to focus on your customers and business projects rather than your it infrastructure and the last one here is analyze and attribute expenditure so the cloud makes it e easier to uh accurately identify the usage and cost of systems which then allow transparent uh attribution of it cost to individualize workload owners this helps measure return on investment and gives workload owners an opportunity to optimize the resources and reduce costs so there you go hey this is Andrew Brown from exam Pro and we are taking a look at the adus well architected tool so this is an auditing tool to be used to assess your Cloud workloads for alignment with the a well architected framework and so what it is it's essentially a checklist uh but it also has nearby references so you know as you're reading through it it will show you information uh and resources so that it can help you with this checklist here and the idea is when you're done you can generate out a report and then you can provide that report to your Executives and key stakeholders to prove uh you know how well architected your workload is on AWS okay hey this is angre Brown from exam Pro and in this video I want to show you two things the well architected framework and the well architected tool so first let's go look for the well architected framework so we're going to look up white papers uh AWS and so if we go here to AWS amazon.com white papers we have a bunch of pages here and so I'm going to just checkbox on white papers so that we can kind of reduce the amount there and then I'm going to checkbox well architected framework if we scroll all the way top here one of these you think it'd be right at the top but one of these is the well architected framework and here it is and so if we open it up used to just directly open up as a PDF I'm sure you can still download it as is but generally you're going to open up as this HTML page and you can basically read through it see all the stuff see the multiple pillars we can click into here see the design principles read the definitions and then start reading about uh the best practices and they have these things at the bottom of each one uh very boring very very boring but but um you know when you get to the solutions architect and things like that you're going to need to know this stuff inside and out it's going to really help you out this Cloud practitioner we only need to know surface level information um but that's the little architect framework let's take a look at the well architected tool so we going type in well here we'll get the well architected tool and if we go here you can see that I've created a couple before probably demos for um our videos and so I'm going to go Define a new workload I'm going to say my my workload Lo here uh my workload whoops my workload it is messing up because I probably have grammarly installed so it does not like grammarly so I'm just going to turn it off for now so my workload and it's still not typing correctly so I have to kill out kill out grammarly here which is kind of frustrating so that's a bug that that's not grammarly's fault that's adab Us's fault for not playing well with grammar and that's something I will definitely report to them because it's very annoying so I'm going to go ahead and refresh this page my workload my workload um and this is Andrew Brown production or preproduction doesn't matter pick your regions Us East or Us East 2 sure I'm selecting it there we go uh optional optional optional optional you go to next and then you can choose your lens serus lens FTR lens so that's the foundational technical review SAS lens we can go with architected framework and then once that is there we can start reviewing okay and then we get this big checklist and so we can go through this and read each one so we say Ops one how do you determine what your priori are and all these things like Ops and stuff like that these are all the summaries in each of the well architected framework sections so you pretty much don't need to really read the dock you just go through this so everyone needs to understand their part in enabling business success have shared goals in order to set priorities of resources this will maximize the benefit of your efforts so select from the following evaluate the customers's external needs external customer needs evaluate internal customer needs if you click info it's going to highlight each one here so evolve key stakeholders including Business Development operations teams this will ensure Etc and so you just go through this and uh you know you know once you have that and you save an exit Okay uh you'll have uh the questions that are answered it'll say what's high risk what's not things like that very simplistic it's really just a way of making a very organized report or checklist and proving that you went through it uh to the executive level or to the management level there so hopefully that makes sense to you um it's not too complicated but there you go hey it's Angie Brown from exam Pro and we are looking at the ads architecture Center so the architecture Center is a web portal that contains best practices and reference architectures for a variety of different workloads and you can find this at adab. amazon.com architecture so if you're looking for best practices in terms of security they have a huge section on that and they have it for pretty much every kind of category on AWS or if you're looking for uh practical examples you can view the large library of reference architectures so here's one to make an ads Q&A bot and it will have an architectural diagram but you can also uh deploy via cloud formation or possibly cdk um and this way you can get a working example and then tweak it for your use case so this is a really great tool um when you are done the adus well architect framework and you're saying okay how do we apply it can we get more concrete examples and I wouldn't be surprised if a lot of the resources within the well architectur framework white paper are just pointing to the center okay hey this is Andrew Brown from exam Pro and we are taking a look at the concept of total cost of ownership also known as TCO so what is TCO well it is a financial estimate intended to help buyers and owners determine the direct and indirect cost of a product or service so here is an example of you know TCO for maybe like a data center so we have Hardware monitoring installation IT personnel training software uh security licensing and taxes but that's not just the limit of it it's just kind of the examples we show here uh the idea of creating TCO is useful when your company's looking to migrate from on Prem to cloud and we will have a better uh kind of visual here to kind of understand how you would contrast against on Prem to Cloud but let's just talk about how it actually works in practicality which I think gets kind of overlooked when cloud service providers are selling you on TCO so the idea is a gardener um you know they uh they were they wrote this article based on This research where an organization had moved 2,500 virtual machines over to Amazon dc2 and so what you're seeing here is that there is a an additional cost that we're not considering which is the migration cost See This Bar up here um so the idea is that the company was paying around 400,000 and so they started to move over and as you see uh their costs initially went up for a short period of time here uh but then once that migration cost was over uh you can notice that they had a 55% reduction so it's uh totally possible to save money uh and clearly there is great savings uh now is it exactly what AWS promises probably not and that's that could be the reason why they update their TCO calculator but let's now just do that contrast against the two so we have on premise on the left and adus on the right or any class service provider and what I want to do is help you think about what cost do people generally think about because if we have like Iceberg the idea here is that these are the costs that we always think about above the iceberg and then there's these hidden costs that we just don't consider when factoring are move and that's the idea of T TCO is to consider all the costs not just the superficial ones and so people say these look like teeth and that's why I add penguins and a whale here um and so when we're talking about on premise what we generally think are software license fees and subscription fees but when you compare those against each other they might look the same um ad us might just look slightly cheaper or even more and so the idea is you need to then factor in everything so on on premise there's implementation configuration training physical security Hardware IT personnel maintenance and on the adus side you know you are you don't have to do as much of that stuff so you just have implementation configuration and training and so adus with their TCO calculator their old one used to make a promise of 75% in savings um again you know this is going to really vary based on what your migration strategy looks like um but you know it's totally possible you could save 75% or you could save 50% over a third year a threeyear period And there's a an initial Spike so that's just something you have to consider but the nice thing though is that once you've moved over all the stuff over here on the left hand side will be ais's responsibility okay all right so let's take a look at Capital versus operational expenditure so there's capex and Opex so on the capex side the idea here is you're spending money upfront on physical infrastructure deducting that expenses from your tax bill over time uh a lot of companies that are running their own data centers uh or have a lot of on premise stuff understand what capex is because um it's something that a lot of times they get tax breakes on and that's why we see a lot of people that have a hard time moving away from the cloud because you know they keep on thinking about that money they save from the government but capex costs would be things like server costs storage Network costs backups and archives Disaster Recovery costs data center costs technical Personnel so the idea is with capital exp expenses you have to guess upfront what you plan to spend okay with operational expenditure the idea here is the cost associated with an on premise data center that has shifted the cost to the service provider the customer only has to be concerned with nonphysical costs so leasing software and customizing features uh training employees and cloud services paying for cloud support uh billing based on cloud metrics so compute usage storage usage and so the idea here is with operational expenses you can try a product or service without investing in equipment so basically kex is what we think about when we think of on premise and then Opex is what we think think about um you know when we're thinking about cloud or AWS okay all right let's ask a very important question about Cloud migration so does cloud make it Personnel redundant so a company is considering migrating their workloads from on premise to the cloud to take advantage of the savings there is a concern among the staff that there will be Mass layoffs does cloud make it Personnel redundant and that's a very important question to to have an answer to and this all talks about shifting your it team into different responsibilities so a company needs it Personnel during the migration phase as we saw with that Gardener research report that there was a period at least like a year where they needed that for you know depending on the size of your company so you're still going to need those people around a company can transition some roles to new Cloud roles so a very traditional example would be you have your traditional networking roles where people have like their CCNA and now they're moving over to Cloud networking uh they have a reduced workload but there's other things uh that they could be doing in the cloud um a company may decide to take a hybrid approach so they'll always need to have a traditional it team and a cloud uh it team um and the last one and this one You' actually see on the exam which is a company can change employees activities from managing infrastructure to re Revenue generating activities okay so the idea is that you know if you're a company why would you get rid of all your staff when you can just put them all into Revenue generation I suppose you know you could uh you know uh lay them off and some companies might do that um or you know you could just retrain them because uh if that IT personnel team has uh technical expertise I'm sure they can translate that to the cloud let's talk about the adus pricing calculator and this is a free cost estimate tool that can be used within your web browser without the need of an adus account to estimate the cost of a various IT services and this is um available at calculator. AWS and the reason we're bringing this up is because there used to be a TCO calculator but now this is the calculator that you use so the adabs pricing calculator contains 100 plus services that you configure for cost estimate and so you can just click through a bunch of knobs and uh boxes to uh you know uh exactly figure out a very accurate cost so the idea here is that to calculate your TCO an organization needs to compare that existing cost against their adus costs and so the adus pricing calculator can be used to deter DET uh you know the adus costs and obviously the organization knows its cost so it can compare it against that um and the way you can get data out of this is you can export it as a final estimate to AC CSV okay hey this is Andrew Brown from exam Pro and we are taking a look at the AWS pricing calculator so to get there it's calculator. AWS what you're going to do is hit create estimate and then here you have a bunch of services so you just choose what you want so you type in ec2 we're going to configure that and from there we can do a quick estimate or an advanced estimate so choose this option for fast and easy route to Ballpark and estimate choose this option for detailed estimate for accounts workloads and stuff so notice down below very simplistic we hit Advanced and we get all sorts of stuff okay so you know it's really up to you I'm very comfortable with the advanced options so I might be running a Linux machine what is my usage it's going to have uh daily spikes of traffic because of the use cases you could say it's not busy on Saturday and Sunday that it has a baseline of one a peak of two eight things like that then you can choose what you're using um t4g I don't even know what that is uh but we'll just say like t uh T2 micro which is not that big T3 micro and you can say we're doing on demand because a lot of people would be doing that and you see like $7 a month it's not a lot of money then you're looking at your storage data in data out okay so we can add that another thing that we might see is something like RDS so we go to RDS and we add postest and not all of them have the simple and complex sometimes they're simple so production database we'll have one here and we're just going to be say a dbt2 micro T T3 micro there we go uh 100 that's fine we're not going to have multi a will have single a on demand show the calculation $13 a month add that to our estimate so you're kind of getting the idea there right um and so you know we have our summary that's our monthly $391 um oh sorry over 12 months our monthly cost is $32 okay you can go back there clone the service edit it stuff like that you can export the estimate I think it goes out as a CSV you can also hit share uh and then hit agree and so then you have a public link and if I have that link we can just see what happens if I paste it okay it just brings them to the same estimate so there you go hey this is Andrew Brown from exam Pro and we are taking a look at migration evaluator so it was formerly known as TCL logic and then abis acquired the company and it is an estimate tool used to determine an organization existing on premise costs so it can compare it against its adabs cost for Planned Cloud migration uh so the idea is that you can get a very very detailed information and the way it collects information is via an agentless collector to collect data from your on premise infrastructure to extract from your own on premise costs I don't know if you can see there but you can see that it works with a lot of different kinds of on premise technology like VMware Microsoft uh tsql all sorts of things okay one migration tool that we can use with AWS is the VM import export and this allows us to import virtual machines into ec2 so inabus has import instructions for VMware Citrix Microsoft hyperv Windows vhd from Azure and also Linux vhd from Azure and so the way this works is that you prepare your virtual image for upload and adus has a bunch of instructions for that once it is ready you're going to upload that to an S3 bucket and once it's uploaded to an S3 bucket then what you can do is use the ad CLI to import your image um and so that is the CLI command down below and once it is produced it will generate out an Amazon machine image and so from an Ami you can then go launch your ec2 okay hey this is Andrew Brown from exam Pro and we are taking a look at the database migration service which allows you to quickly and securely migrate one database to another DMS can be used to migrate your on premise database to ads and that's why we're talking about it uh and so here's a general diagram where you have your Source database which connects to a source endpoint goes through a replication instance so that's a ec2 instance that's going to replicate the data to the Target endpoint onto the target database uh and so we have a bunch of possible sources so we have Oracle database Microsoft SQL MySQL Mario DB post SQL mongodb Sapa ASC IMDb db2 Azure SQL database Amazon RDS Amazon S3 and I'm assuming these are database dumps Amazon Aurora Amazon document DB and so for possible targets it's very similar we got Oracle database Microsoft SQL MySQL Mario DB post SQL reddis saps SE Amazon redshift Amazon RDS Amazon Dynamo DB Amazon S3 Amazon Aurora Amazon open search service Amazon elasticache for reddis Amazon document DB Amazon Neptune Apachi Kafka I'm just showing you the list to give you an idea of how flexible this service is uh but you can tell that these are very different databases so how can it uh move them over right and so in not all cases can it easily do it like it's very easy to go from myql to postrest um but you know for ones that are like relational to uh nosql uh this is where the adabas schema conversion tool comes into play it's used in many cases to automatically convert a source database schema to a Target database schema or semiautomate it so that you can kind of like uh you know uh figure out how to map the new schema uh each migration path requires a bit of research since not all combinations of sources and targets are possible and it really comes down to even versions of these things so but I just want you to know about that it's an option as a database migration service and I've migrated a very large database before and it's super fast uh so and it's not that hard to use so something you definitely want to remember when you're migrating hey this is Andrew Brown from exam Pro and we are taking a look at the cloud adoption framework so this is a white paper to help you plan your migration from on premise to AWS at the highest level the adus CAF organizes guidance into six Focus areas we got business people governance platform security and operations and this white paper is pretty high level uh so you know it doesn't get into uh granular details on how that migration should work uh but gives you kind of a holistic approach and I believe that probably through the adus uh Amazon partner Network there's people that specialize in using this particular framework to help organizations move over and I believe that Abus has Professional Services through the APN but let's just kind of break down what these six categories are we're not going to go too deep into this um but let's do it so the first is the business perspective so these are business managers Finance managers budget owners strategy stakeholders so it's how to up update the staff skills and organizational processes to optimize business value as they move Ops to the cloud you have people perspectives so Human Resources Staffing people managers so how to update the staff skills and organizational processes to optimize and maintain the workforce and ensure competencies are in place at the appropriate time you have governance perspective so cios program managers project managers Enterprise Architects business analysts so how to update the staff skills and organizational processes that are necessary to ensure business governance in the cloud and manage and measure Cloud Investments to evaluate the business outcomes we have platform perspectives so CTO it managers solution Architects so how to update the staff skills and organizational processes that are necessary to deliver and optimize Cloud Solutions and services security perspective so ciso it security managers it security analysts so how to update the staff skills and organizational processes that are necessary to ensure that the architecture deployed in in the cloud aligns to the organization security control requirements resilience and compliance requirements we have operational or operations perspective so it operations managers it support managers so how to update the staff skills and organizational processes that are necessary to ensure system health and reliability during the move of operations to the cloud and then to operate operate using agile ongoing cloud computing best practices so this just Taps the surface of what the CAF is uh and I think for each of these they actually have a more detailed breakdown so you know business is going to break down to even more uh uh finite things there okay so itus has free services that are free forever unlike the free tier that are up to a point of usage or time um and so there are a lot here this is not even the full list there's definitely more and we have IM am Amazon VPC Auto scaling cloud formation elastic bean stock Ops Works amplify appsync code star organizations Consolidated building a was cost Explorer uh Sage maker systems manager there's a lot of them okay um but the thing is is that uh these services are free but some of these um can spin up other resources so the services are free themselves however ones that provision Services May cost you money so cloud formation which is an infrastructure is a code tool could launch virtual machines those virtual machines will cost money right opsworks can launch servers that can cost money amplifly can launch um lambdas that can cost money so that's something you just have to consider um but yeah there you go hey this is Andrew Brown from exam Pro and we are taking a look at the adus support plans so we got basic developer business and Enterprise and you absolutely absolutely need to need to know this stuff inside and out for your exam they will ask you questions on this okay so basic is for email support only uh such as billing and account so if you think it got over bu and that's something you should do if if you''ve uh uh misconfigured something and you end up with a big Bill just go Um open up a support ticket under basic for billing and they're likely to refund you but if you do have questions about billing accounts that's what we're going to be using for everything else that is for tech support um and so for developer business Enterprise you're going to get email support which they'll uh roughly reply within 24 hours I believe this is business hours so if you message them on Friday um or sorry Saturday you might be waiting till Monday for it okay um um in terms of thirdparty support the only one that doesn't have third party support is developer so if you are using something like Ruby on Rails or Azure or something that has interruptibility between AD and something else business Enterprise will absolutely help you out with it same with Enterprise but the developer one not so much uh if you like to use the phone or you like to chat with people um that's available at the business Enterprise tier this is the way I end up talking to people if you are um you know like if you're in North America and you're calling between 9 to 5 and a Monday and Friday you're likely to get somebody that is within North America if not it'll be one of uh one of the supports from some other area so just be aware of that that can also affect the time they pick up uh sometimes it's 5 minutes sometimes it's 30 minutes to to an hour uh you know it just depends on what service you're asking for and you know what time a day okay um in terms of responsiveness uh for General guidance everything is 24 hours or less for developer business Enterprise if your system is impaired it's within 12 hours or less with production system impaired it's four hours or less with production system down it's 1 hour or less and if you're for Enterprise um it's going to be business critical system down less than 50 minutes so just notice who has what for these things um I've definitely waited like three days on General guidance before so just take these with a grain of salt that they're not you know they don't really stick to these that or maybe I'm just not paying enough for them to care okay um in terms of uh getting actual people assigned to you this only happens at the Enterprise level where they have their coner team so they uh help your um organization uh learn how to use datab best asking them any questions personally and then you have a tam a technical account manager that is somebody that knows um aide inside and out and they'll help you architect things and make correct choices or they'll check your bill and help you try to reduce that bill things like that okay in terms of trusted advisory checks at the basic developer you get seven advisory checks once you're paying for business you get all the checks the cost here for business is zero um for developer it's starting at $29 a month for business it's starting at $100 a month and then for Enterprise it's 15,000 a month so I said starting at because it's dependent on your usage okay so let's just look at developer business and Enterprise here because basic's not going to be applicable here so for developers $29 us a month or 3% of the monthly adus usage which whichever is greater on the exam they're only going to ask you like is it $2,900 like generally do you know the tier of expensiveness but they're not going to ask you the percentage of usage okay there's not going to be formulas here um when you get into business it's a little bit uh different where they have it in different brackets so it's going to be 10% for the first uh 10,000 and the next is going to be the next 7,000 stuff like that similar for Enterprise as well so let's just do some math so we know that we understand how this works so if you if you had a monthly spend of $500 at the developer tier that's 3% of $500 is $1 so they go okay what is greater $29 or $15 so you're paying $29 if you're spent is $1,000 that comes up to $30 uh so you're going to end up paying $30 because that's greater than 29 okay for business uh if your monthly spend is a th000 that's 10% of ,000 that's $100 if your spend is $5,000 then you're going to be paying $500 if your monthly spend is 12,000 then the first 10% of a of 10,000 is a th000 and then the next is 7% of 2,000 so your total bill is 140 USD we're not going to do a calculation for Enterprise because it's the same for business but hopefully that gives you an idea there okay hey it's Andrew Brown from exam Pro and we are taking a look at a technical account manager also known as a tam and these provide both proactive guidance and reactive support to help you succeed with your adus journey so what does a tam do and this is straight from an adus job posting what they would do is build Solutions provide technical guidance and advocate for the customer ensure ad environments remain operationally healthy while reducing cost and complexity develop trusting relationships with customers understanding their business needs and Technical challenges using your technical uh Acumen and customer Obsession you'll drive technical discussions regarding incidents tradeoffs risk management consult with a range of Partners from developers through the seite executives collaborat with a Solutions architect business developers Professional Service consultants and sales account managers proactively find opportunities for customers to gain additional value from AWS provide detailed reviews of service disruptions metrics detailed prelaunch planning being uh part of a wider Enterprise support team providing post scale cons uh uh consultative expertise solve a variety of problems across different customers as they migrate their workloads to the cloud uplift customer uh capabilities by running workshops Brown Bag sessions Brown Bag sessions being sessions that occur at lunchtime something you can learn in 30 minutes an hour and so one thing that's really important to understand is that Tams follow the Amazon leadership principles especially about customer uh being customer obsessed and we do cover the Amazon leadership principle somewhere in this course and Tams are only available at the Enterprise support tier so hopefully that gives you an idea what a does hey this is Andrew Brown from exam Pro in this fall along I'm going to show you um adus support and in order to use adus support or to change your level support you're going to need to be logged into the root account I should say you can use support with IM users but if you want to change the support plan you're going to have to be the root user so in the top right corner I'm going to support and notice here on the left hand side right now I have a basic plan and so before we look at changing our plan I'm just going to go create a case and we're going to uh just take a look at some of the options that are open to us so we have account billing support service limit increase technical support notice this is gray out so we cannot select anything here I can go to here and increase our service limit and this is something that you might have to do uh pretty soon early in your account you might say hey I need more of something like ec2 or um a very common thing is SCS so for SC you might say hey um I need to have this amount of emails for ETC okay so um if we go over to count and billing support uh we can go here and ask anything we want so if it's about the free tier I could say ask a general question getting started and saying uh what is free on AWS um I want to know what is free on AWS and you can attach uh three attachments there you can choose via uh web and phone which is really nice um but today I'm just going to do web here and submit that just to kind of show you that as an example and so what that is going to do is open a case and then we will see probably respond in 24 hours to 48 hours just depends on um whether it's the weekend or not because it's based on business hours of course so now that we have an understanding of basic let's go take a look at what the other tiers look like so we have basic developer business and ENT enterprise Enterprise being extremely expensive developer being affordable and then business being um you know affordable for businesses so I would say developer is okay it gives you um uh it gives you a better support but it's all via email and so you know if you really want good support you're going to have to pay the business one and that's the one that I use quite a bit so if I change my plan I'm going to go over to business and this is going to cost me 93 bucks just to do to show you here today so I'm going to go ahead and click that and so it's now processing it and so what's going to happen is I'm G to have to wait for this basic to switch to business so if I go to the case here it hasn't happened as of yet so noce I cannot select this so I'm going to see you back here in maybe like four or five minutes or however long it takes and we'll take a look then okay great so after a few minutes it says my plan is now business and what I can do is go ahead and create a new case and so I can go over to technical support and ask a question so if I was having issues with anything it doesn't matter what I could go over to ec2 Linux and then I could choose my category so I could say I'm having an issue with um systems manager and a lot of times they like you to provide the instance ID it's going to change based on what service you choose here um but you'll get different information I'll just say I need help with um logging into my ec2 instance managed by SSM so I can say I created an ec2 instance and I am attempting to access uh the instance via sessions manager but it is not working I think I have a rooll issue and then I'm just going to go down here and say this is not a real question I am filming a demo video for or tutorial video on how to use support okay and so once we do that we have the option of web chat and phone so if you use phone you're going to enter your phone number in and they're going to call you back uh usually you will be on hold for anywhere for 5 minutes to an hour it just depends usually it's within 15 minutes so it's very good of course it depends on the time of day and your location things like that and the service because there's different uh support Engineers for different types of services and the the balance of those are different but generally chat is pretty good so I can go here and I'm just going to hit submit and it's going to open a chat box and so you just wait okay and sometimes it's super fast and sometimes it takes uh minutes okay so we are going to just sit here for a bit and um you know I'll just pop back here when there is somebody to talk to okay okay so after waiting a little while looks like uh we've been connected here so it took a bit of time so we're just going to say hello hi um uh this this is Andrew Brown um I am recording a video to teach people how to use AWS and I wanted to show them how AWS support works so I'm just showing them how the chat system works say hello and hopefully they'll appreciate or they won't it just doesn't really matter we'll give them a moment there we go that's it thanks for your help okay and so that's pretty much it um so you know there's nothing really uh uh special about that but the idea is when you are typing with them it will appear in the correspondence there so I'm just going to end the chat okay uh and then I'm just going to mark that case as resolve sometimes they will ask you to resolve it if I go to cases I probably have some previous ones here um I have a lot but I don't know why they don't all show up here so you can see this one is pending this one is resolved I go back to this one you can kind of see that the uh history of a conversation is kept and you can go back and forth uh with the people there um yeah that's pretty much it uh you can also do screen sharing so they might send you request to go on Zoom or download this piece of software that shares your screen and so that is another option as well so they can get pretty handson to help you uh with your problems there but that's pretty much all I want to to show you with support I'm going to downgrade this and I'm not sure if they're going to give me back my money sometimes they'll prate it for you but I'm go here and go back to basic um so we will also refund your credit card directly in the month's remaining fees on your old plan which you previously paid you're obligated to pay a minimum of 30 days of support each time you register so I'm not going to get any money back which is totally fine because I just wanted to show you how that works but business support is definitely worth it and uh you know that's it so the anabis marketplace is a curated digital catalog with thousands of software listings from independent software vendors uh easily find buy test and deploy software that already runs an ads the product can be free to use or can have an Associated charge the charge becomes part of your adus bill and once you pay adus Market pays the provider the sales channel for isv and Consulting Partners allow you to sell your solutions to other adus customers products can be offered such as Ami a CL information templates software of service offerings web ACLS ABS WAFF and rules so it sounds great um if you want to sell here I think you need like a US bank account to do it um and you know sometimes Aus Marketplace is just part of AWS so like when you're using the ec2 marketplace you are technically using the itus marketplace um but they also have like a dedicated page for it so it's integrated with some services and it's also Standalone okay hey this is Andrew Brown from exam Pro and in this follow along we're going to take a look at the adus marketplace so what I want you to do is go on the top and type in Marketplace and that will bring us over to here the marketplace can be found in a variety of different places on the platform here you can see that uh previously it was using something called guacamole Bastian host to launch a server um but the idea is that um you can discover products and subscriptions that you might want to utilize so if I go over here there's a variety of different things and so it could be like I want to have something like a firewall that might be something that we might be interested in so we could search there and there's like bring your own license firewall so maybe you have a license with this and you want to run it on an ect2 instance something like that again it's not like super complicated U what's going on here but a lot of times you know when you're using Services you're accessing the marketplace anyway so like when I'm launching an ec2 instance notice on the left hand side says ABS Marketplace and so I don't have to go to the marketplace there I can just kind of like check out the thing I want um and that's pretty much all there really is to it okay so you know hopefully that makes sense let's take a look here at Consolidated billing so this is a feature of Abus organizations that allows you to pay for multiple accounts via one bill so the idea here is we have a master account and we have member accounts and I I'm pretty sure that we probably call this root account now I don't think uh master account might be a data term but it's still showing up in the document mentation the idea is that if you have member accounts within your organization they're all going to be Consolidated under the single account if you have an account outside of your organization um you know this is not going to give you uh this is going to be basically a separate bill um as if it's like a standalone organization or what have you okay so uh for billing adus treats all accounts in an organization as if they were one account you can designate one uh uh master or root account that pays the charges for all the other member accounts consolidate billing is offered at no additional cost you can use uh cost Explorer to visualize usage for Consolidated billing which we can see I have the icon here uh you can combine the usage across all accounts in the organization to uh to share the volume pricing discount which we did Cover in this course separately if you want an account to be able to leave the organization you do have to attach it to a new payment method so if let's say you had an account and you want to give it to your friend or whatever they're have to hook up their uh their credit card but you can totally have have uh an account leave an organization but you have to deal with that billing aspect okay all right so there's a really cool way to save an ads and that's through volume discounts and it's available for many services the more you use the more you save is the idea behind it um and so consolidating building lets you take advantage of volume discounts this is a particular feature of adus organization so if you do not have the or turn on you're not going to be able to take advantage of that okay so example would be something like data transfer where it is build uh for the first 10 terabytes at at 17 cents or sorry 17 cents and then the next 40 terabytes it will be AT3 cents okay so if we had two accounts um such as Odo and Dax and they're not within an abl organization we can calculate those and see what they are unconsolidated and just so you know one terab equals 1024 gabes and that's what you're going to see in these calculations so for Odo uh you know if you has 4 terabytes and that is uh we calculate the gigabytes there we times it by uh the um scent value there we're going to get $696 okay for Dax we're going to end up with uh about $ 1392 there and so if we were to add those up the bill would come out to $2,088 okay so the idea is that there's an organization and they like a your company and they created two accounts but they're just not within an organization by having them in the organization you're going to save um about almost $80 there so um that is a reason why you'd want to use volume discounts okay hey this is Andrew Brown from exam Pro and we're taking a look at Abus trusted advisor so trusted advisor is a recommendation tool which automatically and actively monitors your adus accounts to provide actional recommendations across a series of categories so this is what it looks like I personally prefer the older dashboard but this is what they have now and you can see along the side we have a bunch of categories and then we have some checks here saying uh you know what are we meeting what are we not and you can go in and read each one and they'll tell you so much information they'll even show you like what things are not meeting that requirements in some case you can easily remediate by pressing a button not in all cases but the thing with ad trust advisor is think of AD trust advisor like an automated checklist of best practices on AWS and they kind of map to the pillars of the well architecture framework not exactly but pretty close but there are five categories of adus trusted advisor so we have cost optimation how much money can we save performance so how can uh we improve performance security how can we improve security fall tolerance how we can we prevent a disaster or data loss and service limits so are we going to hit the maximum limit for a service and so uh the next thing we need to discuss is um there's a VAR creation of the amount of checks that are available to you based on your support plan so you know if you're using basic or developer you have seven trusted advisor checks and if you have business Enterprise you have all the trusted advisor checks so uh if we're talking about just the ones that are available to you the ones that come for free is MFA on root account security groups specified ports of unrestricted Amazon S3 bucket permissions Amazon EBS public snapshots Amazon RDS public snapshots I amus so this is just about alerting you about discouraging the use of the root account service limits so all service limit checks are free um it's weird cuz they call it the like seven Security checks but if you counted all the service limits it obviously be too large of a number but notice that 1 through six are all Security checks so you're not getting anything from the other tiers just the security tier and what I want to do is just go over a bunch of available checks out there it's probably not the full list because I couldn't even be bothered to update it if they've added more but it will give you a general idea of what you could expect under each category so for cost optimization um it could be things like looking at idle load bouncers so you know if you have load bouncers you're not using you're paying for them so get rid of them unassociated elastic IP addresses so for every IP that's not associated you're paying for as well maybe under performance you have um High utilization of Amazon ec2 instances so maybe you can save money by switching to smaller instances under security we saw MFA on rout account very popular one making sure you turn on key rotation could be something as well there under fault tolerance um it could be making sure that you're using backups on your Amazon RDS database maybe that's turned off uh for service limits there's just a ton of them and so uh one that that you know might be PR to use vpcs or ec2 limits so there you go hey this is Andrew Brown from exam Pro and we're going to take a look at trusted advisor so what I want you to do is go to the top and type in trusted advisor and once you're there you're going to notice on the left hand side we have cost optimization performance security fault tolerance and service limits right now there are no recommended actions because there's not much going on this account and when you uh have the uh Free level of support the basic support you're not going to have all these checks but if we go in here we can still see kind of what they do um so we have like performance security things like that so these are the ones that we actually can see and they generally work all the same way if you expand here it's going to say Amazon EBS public snapshot so check the permission settings for the EBS volume snapshots and alert you if the any snapshots are marked as public and so if you scroll on down if there were ones that were an issue it would tell you right here okay then down below here we see like check buckets in Amazon S3 that have open access permissions or allow access to authenticated adist users so yellow the ACL allows uh list access for everyone uh a bucket policy allows for any kind of Open Access bucket policy statements have public Grant access so maybe what we can do is to see if we can get this to trigger and so what I'm going to do here is go over to S3 and what we're going to do is make a B bucket that has a full axis okay so I'm going to create a new bucket and it'll say my exposed bucket we'll scroll on down here and we'll just checkbox that off and create the bucket we say I acknowledge that is totally fine okay so now I have a bucket that is 100% exposed if we go back to trust advisor give this a refresh I'm not sure how fast it will show up here but if I expand so it says the bucket ACL allows upload delete for everyone The Trusted adviser does not have permissions to check the policy uh bucket policy has statements that Grant Public Access so what we could try to do is make a policy and try to Grant all access here so I'm not writing these every single day but I'm sure we could try to figure this out um we'll say S3 bucket policy Public Access public read and so that one might be a good example so I'm going to go ahead and copy this one granting readon permission to anomymous users I don't recommend you doing this I'm just doing this to show you to see if we can get the trusted advisor to check because I don't want you to uh do this and forget about it and then have a serious issue but the principle is set to anybody so anyone can read it here it's saying get object Etc then it's saying what particular resource so this one is going to be for uh the bucket in question here which is my exposed bucket we're going to scroll on down save the changes okay so this bucket is publicly accessible we're going to go back over here refresh and see what we can see okay so checks buckets in S3 Etc so it should appear under here and it could be that it's just going to take some time so what I'm going to do is I'm just going to hang tight for a little bit oh there we go okay so it's showing up and I guess it just took some time top poate and so here we can see we have a a yellow symbol it's a warning saying hey there's a problem here if we go back to the dashboard I wonder if that shows up so this one's for investigation and recommendation so you know hopefully that kind of makes sense to you I think in some cases you can do remediation from from here or at least you can go and check box and say okay um ignore could of swore there was remediation for some of these but in any case you know that's generally what trusted advisor does um I think that you probably can have it so it gives you alerts so yeah you could set recipients for particular things like if there's a security issue then I could email a particular person on your team and they could deal with it but that's pretty much it so what I'm going to do is go ahead and delete this bucket I'm all done with it we'll go delete and say my delete uh my exposed bucket here to delete it and that is it okay let's cover the concepts of service level agreements also known as SLA so an SLA is a formal commitment about the expected level of service between a customer and provider when a service level is not met and if customer meets its obligation under the SLA customer will be eligible to receive compensation so Financial or service credits and so when we talk about slas then we talk about SLI so SLI service level indicator is a metric or measurement that indicates what measure per performance the customer is receiving at a given time a SLI metric could be uptime performance availability throughput latency error rate durability correctness and if we're talking about sis then we're talking about slos service level objectives so the objective that that the provider has agreed to meet SLS are represented as a specific Target percentage over a period of time and so an example of a Target percentage would be something that says an availability SLA of 99.99% in a period of three months all right and let's just talk about Target percentages and the way they can be represented very common ones we will see is 99.95% 99.99% uh then we have 99 followed by 99 and so commonly we just say we call this 99 okay and then there's one 911s so if somebody says we have an SLA guarantee of of 9911 it's going to be the 99 followed by 911s all right let's take a look at Abus service level agreements and so there are a lot of them and I just wanted to just show you a few services to give you an idea how they work uh on the exam they're not going to ask you like oh what's dnb's SLA for Global tables um but generally we should just go through this because it's good practice so let's take a look at dynamodb SLA so adus will use commercially reasonable efforts to make dyab to be available with a monthly uptime percentage of each adus region during any monthly billing cycle uh so for a at least 99.999% if Global tables slas applies or 99.99% if the standard SLA applies and the event Dynamo DB does not meet the service commitment you'll be eligible to receive service credits described below so we have monthly uptime percentage and the service credit percentage we get Global tables standard tables so let's take a look here so if less than 99.999% but equal to or greater than 9 9.0% is met so if if the service ends up being this you'll get 10% back of what you spent as service credits if it drops between U 99.0 and 95.0 you get 25% back if it's less than 95 uh percent um then it's 100% back okay and you get the general idea here SLA is going to be slightly different with their drops now let's take a look at um a compute and so compute is going to apply across a bunch of compute services probably because they're all using ec2 underneath so that's probably the reason for it so we have ec2 EBS ECS eks and Abus uh makes two SLA commitments uh for the included services so we have a region level SLA that uh governs included Services deployed across multiple azs or regions and an instance level SLA that governs Amazon ec2 instances individually and again we have our monthly up up time percentage our service C percentage region and instance level so you can just see the same thing it's like it's going to change based on uh what it can meet then we'll take a look at one more like RDS so a relational database service so it will use commercially reasonable efforts to make multi a instances available with monthly uptime percentage of 99.95% during any monthly billing cycle and again you know if if they don't meet those requirements you're going to get service credits back which basically equal USD dollars on the platform and so for this it looks like that so just notice that you know with like compute it was for a a bunch of services for Dynamo DB it was based on uh particular features like global standard tables SLA it's very straightforward uh we didn't do S3 because I just did not want to show you that one it was just too complicated but my point is is that it's going to vary so you have to look up per service okay hey this is Andrew Brown from exam Pro and we are taking a look at Amazon's service level agreements and so the way you find slas is you pretty much just type in SLA for whatever it is so if you're looking for compute you type in SLA or you look for a particular service so maybe you say sage maker SLA AWS I don't think there's like a generic SLA page at least I don't know where it is I always just type in SLA to find what it is and through that you can just kind of read through and try to find out uh the things that that matter to you for your business okay let's take a look here at the service Health dat board and so the service Health dashboard shows General status of adus services and it's really simple the idea is that you can uh check based on the geographic area so you'd say North America Europe Etc and what you'll see is an icon that says whether the service is in in good standing and the details whether the service is operating normally Etc notice they also have an RSS feed the reason I'm talking about service Health dashboards is because I want to talk about personal health dashboards and because they're both called Health dashboards it's confusing so I wanted to to tell you about this one first so now we'll jump into the adus personal health dashboard so we saw the service Health dashboard now let's take a look at the adus personal health dashboard so this is what it looks like and it provides alerts and guidance for adus events that might affect your environment all adus customers can access the personal health dashboard the personal health dashboard shows recent events to help you manage active events and show proactive notifications so that you can plan for scheduled activities you uh you can use these alerts to get notified about changes that can affect your aess resources and then follow the guidance to diagnose and resolve the issue so this is very similar to the service Health dashboard but it's personalized for you um and it's uh you know I I don't see it crop up very often but if you had to create alerts or be reactive to uh things that are happening within your bus this is where you do it okay so there's a team called adus trust and safety that specifically deals with abuses occurring on the adus platform and so I'm going to just list of all the cases where you'd want to be contacting them as opposed to support so the first is Spam so you're receiving unwanted emails from an Abus owned IP address or adus resources are used to spam websites or forms Port scanning your log show that one or more adus owned IP addresses are sending packets to multiple ports on your server uh you also believe uh this is an attempt to discover unsecured ports uh dos attack so your logs show that one or more itus owned IP addresses are used to flood ports on your resources with packets you also believe this is an attempt to overwhelm or crash your server or the software running on your server intrusion attempts so your logs show that one or more ad owned IP addresses are used to attempt to log into your resources hosting prohibited content so you have evidence that adus resources are used to host distribute prohibited content such as illegal content or copyrighted content without the consent of the copyright holder Distributing malware so you you have evidence that abis resources are used to distribute software that was knowingly created to compromise or cause harm to computers machines that it's installed on and so in any of these cases you're not going to adus support you're going to open up an abuse ticket and so you got to contact abuse at Amazon aus.com or fill out the uh uh Amazon abuse uh form so and this is whether it's coming from uh an outside AOS account or even you're internally if you think that some someone is compromise your account and it's being used in any of these ways uh this is what you're going to do okay hey this is Andrew Brown from exam Pro and we're looking at ads abuse so uh we were saying that ads has the ads trust and safety team and what you'll want to do is if you uh find that there's an issue you're going to report it to this email at abuse Amazon.com or you're going to use this form which is the report Amazon a abuse so you'll go down here you'll sign in you'll put your email email in your first name last name or phone number um The Source IP the the details uh uh in uh here you can even select the type of abuse so you say if it's this kind or that kind things like that it's very straightforward um and that's pretty much it okay hey this is Andrew Brown from exam Pro and we are taking a look at the itus free tier and this allows you to use adus at no cost um and when we say free tier there there there's the idea of the first 12 months of sign up there's going to be special offerings or it's free usage up to a certain monthly Limit Forever um and then there's just services that are inherently free which we have a total separate slide on but let's talk about just the free tier stuff and this is absolutely not the full list um but uh it's a good ide like it gives you a good um overview of stuff that is free so for ec2 which you use a web server you get a T2 micro for 750 hours per month for one year and so there's about 730 hours um in a month and so that means you could have a server running uh the entire month for free uh and an additional server for a bit as well so for RDS which is a relational database service for either my school or postgress we can do it T2 DB micro for 750 hours for free so there we get our free database and you would be surprised how far you can get with a uh a T2 DB micro um you know even for a mediumsized startup you can run it on uh a T2 DB micro with no problems then you have your elasic load balancer you get 750 hours per month for one year um so that is a really good thing uh load balancers usually cost $15 a month so that's great actually all these pretty much cost $15 a month so that's about um 1530 $45 month over month for a year that's uh free then you have Amazon cloudfront this is where you'd have your homepage caching your videos things like that so you get 50 GB data transfer out for the total of year then there's Amon connect you get your total free number there 90 minutes of a call time per month for one month or for one year sorry Amazon allows to cash so you could launch a redis or elastic cach server you get 70 hours on a cash T3 micro for a year um elastic search service so this is full Tech search so again 750 hours per month for one year pinpoint campaign markting email so you can send out 5,000 targeted users per month for one year SC so um simple email uh service so this is for um transactional emails um so that you send out from your web app so 62,000 emails per month forever it those code pipeline so one pipeline free it was code build so uh this is for building out projects or things like that so 100 build minutes per month forever it was Lambda service compute 1 million free requests per month 3.2 million uh million seconds of compute time per month for free uh and you know I like to highlight these ones because for traditional architecture you're always going to have a web server a database a load balancer um and you might even have cloudfront in there as well but uh yeah again there's a huge list and this does not even tap the surface of what's free on AWS hey this is Andrew Brown from exam Pro and we are taking a look at adus promotional credits and these are the equivalent to USD dollars on adus platform adus credits can be earned several ways this could be joining ad activate startup program winning a hackathon participating surveys and any other reason that ad us wants to give credits out uh once you uh have um a promotional code you click the redeem credit button in the billing console you enter it in and then your credits will be shown there you can monitor them via it budgets or uh via cost Explorer and probably even building alarms itus credits generally have an expired dat tax them could be a few months uh to a year itus credits can be used for most services but there are exceptions where itus credits cannot be used like purchasing a domain via row 53 because uh that domain costs money outside of adses cost like for their infrastructure and virtual stuff and so for things like that uh you know they're not going to be you're not going to be able to use credits for that okay the adabas partner Network also know as APN is a global partner program for ad best so joining the APN will open your organization up to business opportunities and allow exclusive training and marketing events so when joining the APN you can either be a Consulting partner so you help companies utilize datab bus or a technology partner you build technology on top of ABS as a service offering and a partner belongs to a specific tier so it's either going to be select advance or Premiere when you sign up it's free to sign up but you're not going to be able to do much until you start uh committing to an annual fee so that's it's like a certain amount of money to uh be able to be part of that tier and it starts in the thousands okay so I think the first tier is like something like a th000 or $2,000 and it gets uh more expensive as you go up as a tier and you also have to have particular knowledge requirements so this could be holding uh particular adus certifications at the at the foundational level at the associate level things like that um or it could be adus APN exclusive certification so training that um is not adus certifications but there's certifications that are only available to Partners saying like how do you it could be like something like how do you uh talk to customers or communication things like that you can get back promotional Abus credits so you know if you say Oham I spent uh $22,000 on just being able to uh get into the APN at least the idea is that you can generally get back that uh that spend on AWS so it's like you committing if you give like $2,000 it's like you're going to commit to keep using AWS I'm not showing the annual fee commitments here and the promotional credits that you get back just because they've changed it a couple times on me and I just don't want this slide to go stale in case they happen to change it again so you'll have to look that up to find out what they actually are right now uh you can have unique speak speaking opportunities in the official adus marketing channels like the blogs or webinars being part of the APN is a requirement to be a sponsor with a vendor booth at ads event so when you when you go to reinvent or any ads um event all the vendors are part of the APN all right so they've paid their fee and now they paid an additional fee to get their Booth but um yeah AB partner network uh is very good for uh uh helping you find new business and connecting with other people that are building workloads on AWS but hopefully that gives you an idea of how works okay hey this is Andrew Brown from exam Pro and we are taking a look at abis budgets so Abus budgets gives you the ability to set up alerts if you exceed or approaching your defined budget create cost usage or reservation budgets it can be tracked at the monthly quarterly or yearly levels with customizable start and end dates alert support ec2 RDS red shift elastic cast reservations uh and so the idea here is you can choose your budget amount so it could be like $100 it'll even show you what was the last amount if you're uh resetting the budget there something new you can choose based on a different kind of unit so if you wanted to be based on running hours on ec2 you could totally do that is budgets can be used to forecast costs but is limited compared to cost Explorer or doing your own analysis related with cost and usage reports along with business intelligence tools budgets uh based on a fixed cost or or you can plan your cost uh UPF front based on your chosen level can be easily managed from the ads budgets dashboard via the ads budgets API get notified by providing email or chatbot and threshold uh how close to the current or forecasted budget um so you'd see a list of budgets here uh current versus forecasted the amount used things like that you can see your budget history you can download a CSV uh it'll show you the cost history right in line there which I can't show you it it's hard to see there you get the first two budgets are free so there's no reason not to set a budget when you first first get into AWS and each budget costs about uh 002 cents a day so it's like 60 cents um uh USD per month for budget so they're very cheap to use and you got a limit of 20,000 budgets you're going to be in good shape okay let's take a look here at Abus budget reports which is used alongside abos budgets to create and send daily weekly or monthly reports to monitor the performance of your Aus budgets it will be emailed to specific emails so it's not too complicated here you say create the report budget choose your frequency uh the emails you want um and budget report serves as a more convenient way of staying on top of report since they're delivered to your email instead of logging into the abis Management console so it's just for those people that just can't be bothered to log in okay let's take a look here at abis cost and uses report so generate a detailed spreadsheet enabling you to better analyze and understand your Aus cost so this is kind of what it looks like and when you turn this feature on it will place it into an S3 bucket you could use something like Athena to turn the report into a queriable database since it's very easy to consume S3 csvs into Athena you could use Quick site to visualize your building data as grass so quick site is a business intelligence tool similar to Tableau or powerbi you could also ingest this into red shift um but the idea here is when you turn it on you can choose how granular you want the data to be hourly daily or monthly if you turn on daily you'll be able to even see spikes of uh of of of costs for uc2 instances which is kind of nice the report will contain cost allocation tags um which I think we have a separate slide on that type of tags and the data is stored in e as either a CSV it'll be zipped or it will be a parket format it just depends on how you want it um uh for that okay let's talk about cost allocation tags so these are optional metadata that can be attached to adus resour resources so when you generate out a cost and uses report you can use that data to better analyze your data so what you'd have to do is make your way over to cost allocation tags and need to activate the tags you want to show up there are two types of tags so we have user Define so whatever you've previously tagged will show up probably there you turn it on so if you made one with project you turn on project and there's a lot of adus generated ones that you can turn on so there's a huge list there but uh yeah that's particular with cost um usage and reports if it says like cost allocation reports it's just that's what cost and usage reports used to be called um and some of the documentations a bit old there but yep there you go so you can create your own alarms in cloudwatch alarms to monitor spend and they're commonly called building alarms uh and so it's just a regular alarm but it's just focused on spend but in order to do this you have to turn on building alerts first in order to uh be able to use it uh and then you'll go to cloudwatch alarms and you can choose billing as your metric and then you just set your alarm however you'd want billing alarms are much more flexible than abess budgets and are ideal for more complex use cases for monitoring spend and usage in terms of alerting so you just have to decide what you want to do uh before it those budgets this was the only way to do it and so this is the way I'm used to doing it and I still do it this way today but uh you know both options are valid and just have to decide what is your use case okay let's take a look at Abus cost Explorer which lets you visualize understand and manage your Abus cost and usage over time so uh here's a big graphic of Adis cost Explorer and you can specify time and range and aggregation and it has a lot of robust filtering um what's really nice is that they have a bunch of default reports for you so I'm just going to get my pen tool just to show you where that button is it's over uh here uh if you can see my marker there but but you know you can look at things like monthly cost by service monthly cost by linked account daily cost a this Marketplace R utilization so there's a bunch there you can also notice you can create your own report so if you do find something that you like you can save it for later um you can you could have access to forecasting here so you get an idea of the future costs and whether it's been it's gone up or down just to kind of zoom in on some of those filtration options you can choose um either monthly or daily level of of how you want the data to be grouped together and you have a lot of filter control so if I want to just have ec2 instances for a particular region then I can get that filtered information over here and you can see you have a breakdown of the different types so it's very detailed and class Explorer shows up in Us East one I'm pretty sure if you click on class Explorer it will just switch you over to that region but just understand that's where it lives okay hey this is Andrew Brown from exampro and in this video I want to show you ad cost Explorer so what we'll do is go to the top here and and actually on the right hand side we're going to click on the right and go to my billing dashboard and from there on the left hand side we're going to look for cost Explorer and then click launch cost Explorer and this is where we're going to get to the ad ofs cost management dashboard where this is where we find savings plans reservations things like that on the left hand side click on cost Explorer and you can get this nice chart and so the idea is you can change it from monthly to daily if you if you uh prefer okay you can change the scope here maybe we don't need six months we can just go back um three months here so there's less data it is a bit delayed when I'm clicking here so it also could be just because I'm doing the daily instead of monthly so you just have to be a little bit patient when uh using this interface you can change it to stack line graph you can kind of see the details there it's not always clear like what others is or things like that and so uh you can drill down and there's like ways of applying fil filters and things like that I always forget how to uh do this it's because it's it's bringing everything in so you have to hit clear all first I think and um oh you have to click into it so like if you wanted to click into it and pick a particular service we could go here and type in ec2 and say ec2 instances and then apply that filter so now we can just see exactly that cost or if we want to choose use like maybe just RDS okay so you know that could be useful for you to see but yeah sometimes it's not always clear and so what I recommend is just go back to your billing dashboard and from there just go to bills okay bills is really really useful because here it shows you exactly every single little service that you're being built for you can expand it and see exactly where if you have other accounts you can go into this side here as well and find spend that way um but cost Explorer is very useful just it's useful in a different way okay so there you go hey this is Andrew Brown from exam Pro and we are taking a look at the adus pricing API so with adus you can programmatically access pricing information to get the latest pricing offerings for services this makes sense because databus can change them at any time and so uh you know you might want to know exactly what the current price is uh there are two versions of this API so we have the career API known as the pricing service API and you access this via Json and then there's the batch API also known as the price uh list API via HTML what's odd is that um the batch API returns Json but you're accessing it via HTML so you can literally paste those links in your browser for the query API you're actually sending an an application Json request so you'd have to use something like Postman or something uh you can also subscribe to SNS uh notifications to get alerts when pricing for the Services change adabs prices change periodically such as when adabs Cuts prices when new instance types are launched or when new services are introduced so there you go hey this is Angie Brown from exam Pro and what I want to do here is show you savings plans and so savings plan is going to be found under the a cost Explorer so just type in cost Explorer at the top here or if you want you can type in savings plan as well and once we are here on the left hand side we are going to have uh savings plans options so we're going to go to the overview and here it just describes um what are savings plans if you want to read through it but down below if you have already some spend happening it's going to make some suggestions and in this particular account it's saying that I could save some money on compute before we take a look here I'm just going to go to the form here and see what we can see so up here we can say a commitment through three years by the way you have compute savings which applies to ec2 fargate or Lambda then you have the ec2 specific one where uh we can select a very particular type of instance family and then there's the sage maker savings plans um but if we go here and we just enter in like $2 all up front uh I don't really understand it from here because it doesn't make it clear what the savings are um but uh I what it does make it very easy is probably if we go over here and then click down on the compute so I kind of feel like here would autofill it in for you and so here I filled it in uh or sorry it's filled in for me and so here it's saying with a oneyear plan all up front for based on the past 30 days that it's going to see that I'm going to see a monthly savings of $25 36 and then I can add it to the cart that way and I kind of feel like that is the easiest way to um figure that out where with um with how it was going to that form I just configured out myself what the savings were uh there are some utilization reports and coverage reports honestly I've never really looked at these before um but uh I'm just curious like what we're looking at monthly daily the last let's go a few months here I've been running stuff in this account for a while so there should be something apply so nothing nothing of interest but um I mean I guess you have a lot of use and coverage report and utilization report could be interesting but I imagine it's maybe you have to be using you have to have a savings plan before you can see this so that's probably the reason why um but yeah hopefully that gives you a clear idea that you know you can just go down to those recommendations and and see exactly what you can save and you just add it to your cart and then once you want to pay for it you just choose to submit that order and you're all good to go all right so that's savings plans let's take a look here at defense in depth to understand the layers of security ads has to consider uh for their data centers for their uh virtual workloads and things that you also have to consider when you are uh thinking about security for your Cloud resources so in the most interior we have data so this is access to business and customer data and encryption to protect your data then we have applications so applications are secure and free of security vulnerabilities then you have comput so access to Virtual machines ports on premise and Cloud you have the network layer so this limits communication between resources using segmentation and access controls you have the perimeter itself so distributed denial of service protection to filter large scale attacks before they can cause denial of service of users you could say that's part of the network layer and that's what I say there are variants on this but we're just separating it out uh explicitly there we have identity and access so controlling access to infrastructure and change control and then there's the physical layer so limiting access to data centers to only authorized Personnel you'll notice I highlighted identity and access in yellow it's because that is considered the new primary um perimeter from the customer's perspective of course ad has concern about the physical perimeter and things like that but as it as a customer that's what you're going to be thinking about especially with the zero trust model and when you see these depths the idea is that in order to get here you have to pass through all this stuff so if this um if this outward one is protected pretty well then you generally don't have to worry about the Interiors but of course you should um but yeah there you go let's take a look here at confidentiality integrity and availability also known as the CIA Triad is a model describing the foundation to security principles and their tradeoff relationships so here is our Triad so we have confidentiality so confidentiality is a component of privacy that implements to protect our data from unauthorized viewers in practice this can be using cryptographic keys to encrypt our data and using keys to encrypt our keys so envelope encryption then we have integrity so maintaining and ensuring the accuracy and completeness of data over its entire life cycle in practice utilizing asset compliant databases for valid transactions utilizing tamper evident or tamper proof Hardware security modules hsms availability so information needs to be available when needed in practice so high availability mitigating dos uh decryption access so the CIA Triad was first mentioned in N publication in 1977 there have been efforts to expand and modernize or Alternatives the CIA triab so one was in 1998 for the six Atomic elements of information uh or in 2004 we have the N engineering principles for uh for information technology security so has 33 security principles but this is still a very popular um model for security uh and it's just to kind of tell you like you know you don't always get everything you don't get all three of them sometimes you have to trade off in your scenario um you know and hopefully some of the terminology here will uh resonate as we go through more security content what I want to do here is just Define the term vulnerability so a vulnerability is a whole or weakness in an application which can be designed a design flaw or implementation bug that allows an attacker to cause harm to stakeholders or applications and uh there's a lot of great definitions of vulnerabilities but OAS has a ton of them and we talked about OAS when we talk about Abus Waf uh but it's an organization that creates security projects that help you know what you should protect uh or gives you a working examples so that you can understand how to get better at security and so they have a lot of ones here but maybe you'll might notice some here like using a broken or risky cryptographic algorithm maybe there's a memory leak least privilege violation so that's um uh lease privilege is something that is a thing that you're always worried about insecurity improper data validation buffer overflows so you know just to kind of set the tone of what a vulnerability is and things you should be thinking about okay let's understand what encryption is but before we do we need to understand what is cryptography so this is the practice and study of techniques for secure communication in the presence of third parties called adversaries and encryption is the process of encoding or scrambling information using a key and a cipher to store sensitive data in an unintelligible format as a means of protection uh an encryption takes in plain text and produces produces a cipher text so here's an example of a very old um encryption machine this is the igma machine used during World War II and it has a different key for each day that it was used to set the position of the rotors and it relied on simple Cipher substitution and so you might be asking what is a cipher and that's what we're going to look at next so what is a cipher it is an algorithm that performs encryption or decryption so Cipher is synomous with code uh and the idea is that you use the code to either unlock or or lock up the information that you have so what is a cipher text a cyer text is the result of encryption performed on Plain text via an algorithm so you lock that up you scramble it it doesn't make sense and you need that code to unlock it to get the information so a good practical example back in the day was a code book and this was a type of document used for Gathering and storing cryptographic codes or ciphers so the idea is if we zoomed up on here notice where we have cannot so uh and it would be 0 0 and then there would be give them Authority so the idea is0 0 or if you had the word cannot it would translate to z0 and then you use z0 to match that up to say what does that actually mean and so that is kind of a very practical example of ciphers in action so we just took a look at encryption but what are cryptographic keys so a c a cryptographic key an easy way to think of it is a variable used in conjunction with an encryption algorithm in order to encrypt or decrypt data and there are different kinds of um ones we have so we have symmetric encryption so this is where we have the same key that is used for encoding and decoding uh and a very popular one and the one you will see on AWS is called Advanced encryption standard AES so just take a look at that graphic very closely so we have one key and it is used to encrypt so it produces the cipher and then or Cipher text we should say and then it will uh decrypt and we will get our plain text so one single key then we have a symetric encryption so two keys are used one to encode and one to decode and a very popular one here is RSA if you're wondering what those uh those words are it's three people's names put together who helped uh invent this type type of algorithm and so here we have uh one key for encrypt and one key for decrypt and they're two different Keys all right all right let's look at the concept of hashing and salting so for hashing we have a hashing function and this accepts arbitrary size values and Maps it to a fixed size data structure hashing can reduce the size of a store value and hashing is a oneway process and is deterministic so a deterministic function always returns the same output output for the same input so if we have something like John Smith and we pass it to the hash function it's going to create something that is not human readable but it'll say something like 02 Fae X XY whatever um and it will always produce the same thing if the same key or you know value is being inputed there so the reason we use hashing functions or hashing General is to Hash passwords so hash functions are used to store passwords in a database so that the password does not reside in a plain text format so you've heard about all these data breaches where they've stored the password in plain text this is the thing that helps us avoid that issue um and the thing again is it because it's one way you can't take that hash and unhash it um well there are some conditions to it but so to authenticate a user when a user inputs their password it is then hash so the one that was inputed at the time of you know login and then that hash is compared to the stored hash in the database and if they match the user is successfully logged in so in that case we never ever had to know what the original password looked like uh popular hashing functions are md5 Shaw 256 or bcrypt uh if an attacker knows the function you are using uh and uh and stole your database they could enumerate a dictionary of passwords to determine the password so they'll never see it but they could just keep on going through that so that's why we salt our passwords so a salt is a random string not known to the attacker that the hash function accepts to mitigate the deterministic nature of a hashing function so there you go let's take a look here at digital signatures and signing so what is a digital signature it is a mathematical scheme for verifying the authenticity of digital messages or documents and a digital signature gives us tamper evidence so did someone mess or modify the data is this data from uh someone we did not expect it to be is it from the actual sender and so we kind of have this diagram where we have a person who sends or is going to send a message so they sign it and then uh Bob ver ifies that it was for the person who it's from so there are three algorithms to a digital signature the key generation so generates a public and private key um then there is signing the process of generating a digital signature with a private key and the inputed value so signing which is what is happening up here signing verification verifies the authenticity of the message with a public key so remember the private key is used for signing and the public key is used for verifying SSH uses a public and private key to authorize remote access into a remote machine such as a virtual machine it is common to use RSA and we saw that RSA is a type of algorithm earlier and so SSH hyphen keyen is a wellknown command to generate a public and private key on Linux I know this one off the top of my head I always know to do this um and so what is code signing so when you use a digital signature to ensure computer code has not been tampered and so that's just a like subset of digital signatur so you can use this as a means to get into a virtual machine or you can use signing as a means to make sure that the code being committed to your repository is who you expect it to be from so there you go let's talk about intransit versus at rest encryption so encryption and Transit this is data that is secure when moving between locations and the algorithms here are TLS and SSL then you have encryption at rest so this is data that is secure when residing on storage or within a database so we're looking at AES or RSA which we both covered previously these algorithms so ones that we did not cover was TLS and SSL so we'll cover them now so TLS transport layer security is an encryption protocol for data Integrity between two or more commun communicating Computer Applications so 1.0 and 1.1 are no longer used but TLS 1.2 and 1.3 is the current best practice then we have SS cell secure socket layers so an encrypted protocol for data Integrity between two or more communicating uh Computer Applications so 1.0 2.0 and 3.0 are deprecated um and honestly I always get these two mixed up and I always fig fig uh uh get confused which is being used but um you know they're always changing on us but just understand generally what these concepts are and that you're familiar with the terms okay hey this is Andrew Brown for exampro and we are taking a look at common compliance programs so these are a set of internal policies and procedures for a company to comply with laws rules and regulations or to uphold business reputation so here we have a bunch of different compliance programs and so some popular ones are like Hippa or um PCI DSS the question is should you know these yes you should generally know the most popular ones because you're going to see them throughout your Cloud career um and so just getting familiar now is a good time uh so let's jump into it okay so the first one I want to introduce you to is for I ISO and they have a bunch of different ones so ISO is the international organization of standardization and there uh other one called IEC which is the international electrotechnical commission One deals with uh you know like uh virtual things the other one deals with Hardware things but they have a lot of overlapping um compliance programs okay and so the most popular absolutely most popular one that I know of is the 27100 I know a lot of organizations that are going for the 271 this is for control implementation guidance you have the 277 this is enhanced focus on cloud security the 27018 this is protection of personal data in the cloud then you have the 2771 this is Privacy Information Management System so pims framework this outlines controls and processes to manage data privacy and protect pii so that's personally identifi information then you have system and organization control sock and this is a very popular thing that organizations go for especially the sock 2 so sock one is 18 standards and report on the effectiveness of internal controls at the service organization relevant to the client's internal control over financial reporting we have sock 2 evaluates internal controls policies and procedures that directly relate to the security of the system at a service organization and sock three a report based on the trust uh service Services criteria that can be freely distributed then we have PCI DSS a set of security standards designed to ensure that all companies that accept process store and transmit credit card information maintains in a secure environment we have a federal information procedure standards or fips so 140 hyphen 2 This Is Us and Canadian government standard that specifies the security requirements for cryptographic modules that protect sensitive information then we have uh phipa this is more relevant to me because I'm actually in Ontario in Canada but it's also very uh wellknown um uh went out there outside of HIPPA so this regulates patient protected health information then you actually have Hippa this is the US federal law that regulates patient procedure health information then we have uh Cloud security Alliance so CSA star certification independent thirdparty assessment of a cloud provider security posture if you've never heard of CSA they have a very uh wellknown fundamental uh security certification called the cssk or ccsk I always get that that mixed up then we have uh fed ramp which we covered earlier in this course or in the future depending on where we put it but um fed ramp stands for federal risk and authorization Management program it's a US Government standardization approach to security authorizations for cloud service offerings if you want to work with the US government or places that sell the US government you need fed ramp that similar to criminal justice Information Services any US state or local agency that wants to access the FBI's cgis database is required to adhere to the C GIS security policy then we have gdpr uh the general data protection regulation everyone knows what this is in Europe maybe not so much in North America or other places a European Privacy Law imposes new rules on companies governments agencies nonprofits and other organizations that offer goods and services to people in the European Union or that collect analyze data triy tied to EU residents there's a lot of compliance programs out there one that's also very popular is fips but we'll get to that when we talk about camp Ms um but yeah there you go so I just wanted to quickly show you here the adus compliance programs page where they list out all the types of compliance programs that adus is uh working with and that it has different types of certification and attestment which we can use itus artifact or Amazon artifact whichever prefix they decide to use for the name there um to uh ensure that it was has in order to meet those regulatory compliance so you can see them all there and if you want to know a little bit more about any of these you just go ahead and click them and you can read and they have additional information so you have a better idea okay let's talk about pen testing so pen testing is an authorized simulated Cyber attack on a computer system performed to evaluate the security of the system and on AWS you are allowed to perform uh pen testing but um there are some restrictions so permitted services are ec2 instances KN gateways elbs RDS so that's relational database service cloudfront Aurora API gateways Lambda Lambda Edge functions light cell resources elastic beanock environments things you cannot do or you should not be doing is DNS Zone walking via row 53 hosted zones then there's dos simulation testing so you should not be doing do or dos doses or simulated Doss or simulated doses okay and that doesn't mean that you can't necessarily do them uh again there's a lot of exceptions to the pen testing they have a whole page on this but generally you're not allowed to do dsing uh Port flooding protocol flooding request flooding can't do any of those things for other simulated events you need to submit a request to bus a reply could take up to seven days uh you know again there's a lot of uh uh little intricacies here so you'd have to really read up on it if you're interested in doing this okay hey this is Andrew Brown from exam Pro and we are taking a look at pen testing on the adus platform so they have this page here that tells you what you're allowed to do what you're not allowed to do um and there's some additional things you can read into like the stress test policy the Dos simulate simulation testing policy which I didn't cover in detail uh in the course content but if for whatever reason you're interested in it I just want you to be aware of that kind of stuff if you want to simulate events there is a simulate events form that you have to fill out so you open it up up and you can kind of read about it and it gives ad us a heads up of what you're going to be doing stress test fishing malware analysis other so that way that if you are doing it you're not going to get in trouble they're aware of what you are doing okay so that's pretty much it hey this is Andrew Brown from exam Pro and we are taking a look at itus artifact which is a self serve portal for ond demand access to adus compliance reports so here's an example of a a bunch of different compliance reports that adus could be meeting and the idea is that when you go to this portal within the adus Management console you'll have a huge list of reports that you can go and access so here I'm searching for Canada to get the government of Canada partner package and then I go ahead and I download that report as a PDF and then within the PDF we can click a link to get the downloadable Excel and that's pretty much what it is it's just if you want to see that databus is being compliant for different programs hey this is Andrew Brown from exam Pro and we're going to take a look at Aus artifact so in the top here we're going to type in artifact and not be confused with code artifact which I guess is a new service there's just always releasing new Services e and so here we have a video and some things but uh it's not too hard all we got to do is go to view reports and from here we have all the types of compliance programs or Regulatory Compliance programs that ads is uh meeting and we can do is search for something so we type in Canada and that's the government of Canada partner package and I can go ahead and download that report so when you download it you really want to open this up in um you're going to really want to open this up in um uh Adobe Acrobat because if you don't open up an Adobe Acrobat you're not going to be able to access the downloadblack reader and once to have it open and I'm just moving it over here this is what you're going to see and um it's going to say like hey um oops no I don't want to do that so please scroll to the next page to view the artifact download and so I think that if we go here you know they say scroll to the next page but I'm pretty sure we can just go here on the left hand side and this is what we're looking for that Excel spreadsheet so we're going to save that attachment or actually we just going to open it up open this file okay and we'll give it a moment I have Excel installed and there we go there it is okay so I know it's a little bit odd way to get to those um certificates or reports but that's just how it works um but yeah I mean that's the idea is like if you need to prove that ABS is meeting whatever those standards are you can just type them in whatever it is I maybe there like fed ramp right whatever it is and download those certificate attestment whatever um and just double check that ads is Meeting those standards okay hey this is Andrew Brown from exam Pro and we are taking a look at AIS inspector but before we can answer what it does let's talk about hardening so hardening is the act of eliminating as many security risks as possible hardening is common for virtual machines where you run a collection of C Security checks known as a security Benchmark so abis inspector runs a security Benchmark against specific spefic ec2 instances and you can run a variety of security benchmarks and you can perform Network and host assessments and so here's an example of those two check boxes there which you'd say which assessments you want to do so the idea is you have to install the edus agent on your ec2 instance you run an assessment for your assessment Target you review your findings and remediate security issues and one very popular Benchmark you can run is the CIS which has 699 checks so if you don't know what CIS it stands for the center of Internet Security uh and so they are this organization that has a bunch of um uh security controls or check marks uh that are published that they suggest that you should check on your machine hey this is Andrew Brown from exam PR and we're looking at dos so dos is a type of malicious attack to disrupt normal traffic by flooding a website with a large amount of fake traffic so the idea is we have an attacker and the victim the victim is us and it could be our virtual machines our cloud services the idea is that it's some kind of uh resource which um can take in uh incoming requests over the Internet so the idea is the attacker is utilizing the internet and so they may control a bunch of uh virtual machines or servers that are loaded up with malicious software and the idea is that the attacker is going to tell them all to send a flood of traffic over the Internet uh at your uh Computing resource and uh this is where your website is going to either start to stall or it's going to become unavailable for your users and so the idea here is that you know if you want to protect against CS you need some kind of Dos protection traditionally those used to be like third party services that you uh would have to pay for and and it would sit in front of uh your load balancer or your uh end server but now the great thing with cloud service providers is that generally their networks have built in DOS protection so the idea is just by having your compute or your resources on AWS you're going to get uh builtin protection for free via ad shield and we'll talk about that next hey this is Andrew Brown from exam Pro and we are taking a look at it Shield which is a managed dos Protection Service that safeguards applications running on AWS so when you route your traffic through R 53 or cloudfront you are using a shield standard so here's a diagram to kind of show you that it's not just those services but these are the most common ones where you'll have a point of entry into AWS so here we could also be including elastic IP it Global accelerator but the idea is that when you uh go through these Services into the Aus Network it has Shield built in and so you're going to get that protection before those uh before that traffic reaches your uh cloud services and in this case we're showing uh ec2 instances so ad Shield protects against layers three four and seven attacks uh layer three four and seven is based off the The OSI model which is a um a fundamental networking concept so seven is for the application layer four is the transport Layer Three is the network layer um there are two different types of plans for you to Shield we have Shield standard which is free and then Shield Advance which starts at 3,000 USD per year plus some additional uh costs based on usage of the size of the tack or what services you're using how much traffic is moving in and out so protection against the most common dos attacks is what Shield standard does uh you have access to tools and best practices to build dos resiling architecture it's automatically available on all services for additional protection against larger and more sophisticated attacks that's where Shield Advance comes into play it's available for specific adus services so R 53 cloudfront elb adus Global accelerator elastic IP uh and some notable features here is visibility reporting on layer three four and seven you're only going to get seven if you are using idwa with it uh you have access to team and support so these are DOs experts but you're only going to get it if you're paying for business or Enterprise support as you're paying for this as well uh you also get dodos cost protection just ensure that you know your bills don't go crazy uh and it comes with an SLA so you have a guarantee that it's going to work both plants integrate with itless web application firewall so w to give you that layer set application protection so understand that if you're not using Waf you're not going to be having that layer 7 protection okay hey this is Andre Brown from exam Pro and we are looking at Amazon guard Duty so before we look at that we need to understand what is an IDs IPS so an intrusion detection system and intrusion protection system is used as a device or software application that monitors and network or systems for malicious activity or policy violations so guard duty is a threat detection service which is IDs IPS that continuously monitors for malicious and suspicious activity and unauthorized Behavior it uses machine learning to analyze the following adus logs your cloud trail logs your VPC flow logs your DNS logs and what it will do is report back to you and say hey um there's this issue here and this is actually one that's very easy to replicate it's just saying somebody is using the root credentials and it's suggesting that you should not be doing that right because you're never supposed to be uh invoking API calls with the root credentials or you should be limiting that you'll might also notice that if you want to investigate you can kind of follow up that with uh Amazon detective or adus detective whichever uh prefix they decided to put on that service it will alert you of findings which you can automate an incident uh response via cloudwatch events which this uh it's been renamed to event Bridge so you know or third party service services so you can follow up a remediation action um and here is a graphic of Amazon guard Duty just a bit up closer so you can see all the findings and you can just see you have a lot of detailed information there okay hey this is Andre Brown from exam Pro and we're going to take a look at guard Duty so guard duty is um an intrusion protection and detection uh service and so what I've done is I've um I've done some bad practices purposely so that I can show you um some information in there so I'm going to go over to guard Duty okay and you do have to turn guard Duty on and so once guard duty is on you're going to start getting reports coming in so notice here that we have some anomalous Behavior 8 days ago and so uh that's B he's uh my cofounder he's also named Andrew as well and so we can kind of see some details here about who's accessing what and what they were doing he's not doing anything malicious but we can have an idea where they're from even shows generally where he is which he is near Thunder Bay and his his provider would be TB um and you can see that he is making uh API calls to describe account attributes and things like that then the other issue is the root account so there's MFA I turned it off so that we can or maybe this just usage here I actually do have it turned on I suppose here we see root credential usage and so it's saying hey you used it 77 times because sometimes I go in and and use uh the root account for tutorials but saying you're using this way too much you got stop doing that okay so that's something that is uh pretty interesting with guard Duty um and it's really cost effective and easy to turn on so you can turn it on looks like they have a new thing for S3 um have not looked at that as of yet but that's kind of cool kind of feels like that would overlap with uh Amazon Macy but whatever and here we get a breakdown of cost so we see cloud trail VPC flow logs DS logs and this is where it would be ingesting data if you want to use that S3 protection you'd have to probably be turning or creating a custom cloudwatch Trail that has data events to consume that information um you know so you know hopefully that gives you kind of an idea of things you can do and you can also centralize guard Duty uh into one account so you can have one thing that takes care of everything and and move all the data across all your accounts into a single place so that's kind of interesting and you can set up follow followups um it's possible that uh I'm not see in this this here but generally it would show you uh it would show show you a way of like triggering into Cloud watch probably you can do it pragmatically this is something interesting like the list management you can add trusted IPS or threat list so if there's people that you know are fine you can just Whit list them or if there's people that you know that are bad make sure that they are never allowed to get through so that's pretty much it with guard Duty okay let's take a look here at Amazon Macy so Macy is a fully managed service that continuously monitors S3 data access activity for anomalies and generates detailed alerts when it detects risks of unauthorized access or inadvertent data leaks so Macy works by using machine learning to analyze your cloud trail logs and Macy has a variety of alerts so we have anomaly access config compliance credential loss data compliance file hosting identity numeration information loss um location anomaly open permissions privilege escalation ransomware service disruption suspicious access andac will identify your most at risk users which could lead to compromise so here's just one little kind of uh tidbit from the um app itself where you have the total users and they categorize them into different uh risks I can't remember which flag means what in here uh Amazon Macy is an okay Service uh it's it's very important if you're storing things in S3 but uh I don't I don't use it very often to be honest hey this is Andie Brown from exam Pro and we are taking a look at adus virtual private Network also known as VPN so adus VPN lets you establish a secure and private tunnel from your network or device to the itus global Network it's very important to emphasize the word secure here uh because when you're using Direct Connect that will establish a private connection but it's not using any kind of protocol to secure that data in transit whereas a VPN will be using a secure protocol there are two options here we have itus sight to site VPN so securely connect on premise Network or branch office site to VPC and itus cvpn that securely connect users to adabs or on premises networks one thing that we need to understand alongside vpns is IPC this stands for Internet Protocol security and is a secure network protocol Suite that authenticates and encrypts the packets of data to provide secure encrypted communication between two computers over Internet Protocol Network and it is used in vpns and Abus definitely uses it okay hey this is Andrew Brown from exam Pro and we are taking a look at Abus web application firewall also known as WF which protects you uh protects your web application from common web exploits so the idea here is you write your own rules to allow or deny traffic based on the contents of an HTP requests you use a rol set from a trusted Abus security partner in the Abus Waf rule Marketplace Waf can be attached to either cloudfront or an application load balancer so here is that diagram the idea is you see cloudfront with the Waf or ALB with the WAFF and what it does is it can protect uh web applications from attacks covered and the OAS 10 uh top 10 most dangerous attacks if you don't know OAS they're the open web application security project and they basically have all these uh security projects which are things to say hey these are things that you should commonly protect against or they might have like example applications that uh serve as a means to learn security so when we look at the top 10 it's injection broken authentication sensitive data exposure XML external entities so xxe broken Access Control security misconfigurations crosssite scripting so xss uh insecure deserialization using components with known vulnerabilities and insufficient logging and monitoring so there you go hey this is Andrew Brown from exam Pro and we are going to take a quick look at adus web application firewall also known as WF and so um in this account I happen to have a Waf running uh so we don't have to create one uh we already have something we can take a look here so I'm going to go to Waf and shield and then on the left hand side you'll notice it's a global Service but on the left hand side we're going to be looking for our web acl's and so the idea is that when you want a w you create a web ACL and then within within that web ACL you have uh the overview and then you have it can kind of show you kind of the traffic that's going on here we can have our rules and so um there's a lot of different kind of manage rule groups that you can use so these are ones that are provided by AWS so and a lot of these some of these can be paid some of these are free so you see there's these free rule groups where you're like hey hey I don't want any nominus IPS you checkbox that on you know or I want to protect against SQL injection now the interesting thing is that abis has this capacity unit so um you can't add all of these you can add a certain amount of capacity before you have to um um uh pay for more or something like that it's just kind of a way to um uh kind of cap the amount of stuff that you can put in in terms of rules um but there's a lot of other um rule groups from third party services like security companies that know what they're doing so if you like Fort Net's OS top 10 you can uh subscribe to that in the marketplace and be able to use it but uh yeah so that's how you apply rules there's something called bot control I've never used this before get realtime visibility into bot activity on your resource and controllers what Bots allow and block from your resources that sounds really cool I cannot stand bots so I might turn that on myself or take a look at the cost there and see what we can find out but that's pretty much it with WAFF um one thing I would say is that you can block out specific IP addresses or Whit list specific IP addresses and you might do that through rules I'm just going to see yeah like maybe the bypass here and so these IP addresses are some of our um Cloud support Engineers where they're using our admid panel and um uh WF is being too aggressive in terms of protection and so sometimes you have to uh say hey allow this IP address and let my um you know let my cloud support engineer be able to use the mid panel because they're not malicious okay so that's one little exception there but that's pretty much it okay hey this is Andrew Brown from exam Pro and we are taking a look at Hardware security modules also known as HSM and it's a piece of Hardware designed to store encryption keys and it holds keys in memory and never writes on the dis so the idea is that if the HSM was shut down uh that key would be gone and that would be a guarantee of protection because nobody could you know take the drive and steal it so here is an example of an HSM uh these are extremely expensive so you definitely don't want to have to buy them yourselves uh they generally follow fips so fips is the federal information processing standard so it's a us and Canadian government standard that specifies the security requirements for cryptographic modules that protect sensitive information fips is something you want to definitely remember um and there are two different um protocols here there's actually a bunch of different uh fips versions but we have fips 142 level two and then fips 143 level three so let's talk about the difference here so hsms that are multi tenant are going to be using fips 142 hyphen 2 level two compliant where you have multiple customers virtually isolated on the HSM and then there are hsms that are single tenant and so they're going to be utilizing fips 140 hyphen to level three compliant so a single customer on a dedicated HSM and so the reason why we have these two levels is that when you have multiple tenants you can say all right this thing is uh has temperate evidence evence so we can see that somebody was trying to break into it but there's no guarantee of uh T it being tamper proof where level three is tamper proof there's also uh fips 140 hyphen 3 which is the new uh the newer um standard but not all uh Cloud resources uh can meet that standard just because of how they offer the service uh so again fips 142 is really good but just understand that there are other ones out there and it's very easy to get fips 142 level three mixed up with pips 140 hyphen 3 something that I always had um a hard time remembering the distinguishing between those two so for multitenant this is where we're using adus Key Management Service and for single tenant we're using adus Cloud HSM and the only time you're really using Cloud HSM is if you're a large Enterprise and you need that Regulatory Compliance of getting fips 14052 Level 3 okay hey this is Andrew Brown from exam Pro and we are taking a look at Key Management Service also known as KMS and it is a managed service that makes it easy for you to create and control the encryption Keys you use to encrypt your data so KMS is a multitenant HSM so it's a Hardware security module and many adaba services are integrated to use KMS to encrypt your data with a simple checkbox and K KMS uses envelope encryption so here's that example of a simple checkbox in this case it's for RDS and what you'll do is choose a master key A lot of times ads will have a default for uh key for you that's managed by them that is free to use which is really great uh so for KMS it's using envelope encryption so when you encrypt your data your data is protected but you have to protect your encryption key when you encrypt your data key with a master key as an additional layer of security so that's how it works so just to make this really clear I have my data I use this key to encrypt this data and now I need to protect this key so I use another key to encrypt uh this key which forms an envelope and then I store this uh master key in KMS and this one's considered the data key all right hey this is Andrew Brown from exam Pro and we're going to take a look at Key Management Service also known as KMS so type in KMS on the top here and we'll pop over here and KMS is a way for you to create your own keys or you can use adus manage keys so up here and not all these appear right away but as you use Services um you will it us will generate out manage keys for you and these are free you can uh create your own Keys um and these cost a dollar each so if I go ahead here and create a key I can choose whether it's symmetric or asymmetric which we definitely learned in the course which is nice for asymmetric you can make it encrypt and decrypt sign and verify and they're just kind of narrowing down the type of key would use um for this you know if I went to symmetric I go here I'm just kind of seeing if if I can enter the uh actual material into the key here um so I'm just going to keep clicking through here U my custom key generally you don't really need to do this but um you know if it's interesting you can set up administrators to say who's allowed to administer the key and then you have someone that um is allowed to use the key and you usually want to keep those two accounts separate you don't want to have the same person administrating and using the key okay keep those two separate and so we would have a key policy so you can change this to say the rule tools that is allowed to use um and then we can go here and hit finish and so there we now have our own custom key and one thing we can do is it's possible to rotate out these Keys when you need to be um but anyway when we want to use CS it's built into basically everything and we've seen it multiple times throughout this course when we gone over to ec2 we'll just go take a peek at a few different places here so when we've gone to go launch an ec2 instance and we go over to uh storage so we say select and review or next and we go over to storage notice that here this is using encryption right so I can choose that or even my custom key if you're in Dynamo DB or anywhere else it's always something like a checkbox and you choose your key so that's pretty much all there really is to KMS it's very easy to use and there you go hey this is Andrew Brown from exam Pro and we are going to take a look here at Cloud HSM it is a single tenant uh HSM as a service that automates Hardware provisioning software patching High availability and backups so here's the idea is that you have your ads Cloud HSM you have your developers interacting with it your application interacting with it you have an HSM client installed in your uh ec2 instance so that it can access uh the cloud HSM keys so adus Cloud HSM enables you to generate and use your encryption keys on fips 140 hyphen 2 level 3 validated Hardware it's built on open HSM industry standards to integrate with things like PK uh cs1 Java cryptography uh extension so jce Microsoft crypto and G libraries you can transfer your keys to other commercial commercial HSM Solutions to make it easy for you to migrate keys on or off AWS configure a KMS to use ads Cloud HSM uh cluster as a custom uh key store rather than the default KMS key store uh so Cloud HSM is way more expensive than KMS KMS is like free or a dollar per key where Cloud HSM is a fixed cost per month because you are getting a dedicated piece of Hardware um and there's not a lot of stuff around it so other than the ad KMS integration a lot of times it can be really hard to use this as well so the only time you're really going to be using Cloud HSM is if you're an ENT prise and you need to meet fips 140 hyphen 2 level three compliancy okay hey this is Andrew Brown from exam Pro and we are taking a look at know your initialism so a lot of AD services and Concepts and Cloud Technologies use initialisms to just kind of shorten uh common things that we need to use on a frequent basis and it's going to really help if you learn these because then what you can do is substitute them when you are uh seeing a service name or something particular and that's going to get you through content a lot faster um and in the wild you're going to see these all over the place because people aren't going to say the full name they're going to say the initialism so let's go through them so for I am it's identity and access management for S3 that's simple storage for S swf it's uh swf that's simple workflow service SNS is simple notification service sqs is simple Q service SCS is simple email service SSM is simple systems manager but uh you know when we see the name it's usually just systems manager but we still use the uh initialism SSM then there's RDS relational database service VPC virtual private Cloud VPN virtual private Network CFN cloud formation WF web application firewall and that is a very common initialism not just adabs but outside of it as well mq for Amazon active m Q ASG for Autos scaling groups Tam for technical account manager elb for elastic load bouncer ALB for the application load bouncer NLB for the network load bouncer G wlb for the Gateway load balcer clb for the classic load bouncer ec2 for elastic cloud or Cloud compute ECS for elastic container service ECR for elastic container repository EBS for elastic block storage EMR for elastic map produce EFS for elastic FAL store EB or EB for elastic beant stock es for elastic search eks for elastic kuber netti service msk for managed kofka service and if you think I got the SNK backwards I did not for whatever reason it's mskk uh then uh there's abis resource manager which is known as RAM ACM for Amazon certificate manager Pol for principal of lease privilege which is a concept not a service iot internet of things this is not a service but is a Tech concept or Cloud concept RI for reserved instances and I'm sure there are more but these are the ones that I know off the top of my head uh and they're in my uh usual use case uh for what I'm doing dayto day but a lot of times you'll probably just end up needing to remember ASG elb um ec2 S3 things like that okay all right let's compare adus config and app config which both have config in the name but there are two completely different services so adus config and app config so Adis config is a governance tool for compliance as code you can create rules that will check to see if resources are configured the way you expect them to be if a resource drifts from the expected configuration you are notified or adus config can auto remediate correct the configuration back to the expected state for app config it is used to automate the process of deploying application configuration variable changes to your web application you can write a valid Val Ator to ensure the changed variable will not break your web app uh you can monitor deployments and automate Integrations to catch errors or roll backs so config is for compliance governance app config is for conf application configur configuration variables so there you go let us take a look at SNS versus sqs and uh these things have something in common and it's they both connect apps via messages uh so they're for application integration so let's take a look at SNS so simple notification service and then simple Q service okay so SNS is intended to pass along messages via a pub sub model whereas sqs cues up messages and has a guaranteed delivery so the idea with SNS you send notifications to subscribers of topics via multiple protocols so it could be H HTTP email sqs smns and SNS is generally used for sending plain text emails which is triggered via other adab services the best example here is billing alarms I know we mentioned this but I like to repeat it so that you absolutely know uh it can retry sending in the case of failur of https so it does have a retry attempt but that doesn't mean there's a guarantee of delivery it's really good for web hooks simple internal emails triggering Lambda functions if you had to compare these to thirdparty Services it's similar to Pusher or uh pubnub so sqs is uh the idea here is that messages are placed into a queue applications pull the queue using the itus SDK you can uh uh retain a message for up to 14 days you can send them in sequential order sequential order or in parallel you can ensure only one message is sent you can ensure messages are delivered at least once it's really good for delayed task queuing up emails um comparable uh stuff would be something like rabbit mq or uh Ruby on Rails sidekick okay hey this is Andy Brown from exam Pro and we're doing variation study with SNS versus SC versus pinpoint versus workmail and so SNS and SCS get confused quite often but all of these Services uh have something in common they all send emails but uh the utility of email is completely different for each one so the first one is simple notification service is for practical and internal emails so you send notifications to subscribers of topics via multiple protocols so it's not just for email it can handle HTTP it can send sqs it can send SNS me or SMS messages so um messages to your phone um but uh it does send emails and so SNS is generally used for sending plain text emails which is triggered via other a Services the best example of this is a building alarm so most exam questions are going to be talking about SNS because lots of services can trigger um SNS for notifications and so that's the idea it's like oh um you know did somebody spend server send off an email through via SNS uh did we spend too much money here you know all sorts of things can go through SNS to send out emails and you need to know what are topics and subscriptions regarding SNS then you have sces so simple email service and this is for transactional emails and when I say transactional emails I'm talking about emails that should be triggered based on inapp action so sign up reset password invoices um so a cloudbased email service that is similar to this would be like send grid sces sends HTML emails uh SNS cannot so that is the distinction is that SCS can do HTML and pl text but SNS just do does plain text and you would not use SNS for transactional emails SCS can receive inbound emails uh SCS uh can create email templates custom uh domain name emails so when you use SNS it's whatever Amazon gives you it's going to be some weird address but sces is whatever custom domain you want you can also monitor your email reputation for SCS then you have Amazon pinpoint and so this is for promotional emails so these uh when we say promotional we're talking about emails for marketing so you can create email campaigns you can segment your contacts you can create customer Journeys via emails um it can do a Tob email testing and so sces and pinpoint get mixed up because a lot of people think well can I just use my transaction emails for promotion emails absolutely you can it's not recommended because um you know pinpoint has a lot more functionality around promotional emails they're built differently uh and so you know just understand that those two have overlapping responsibilities but generally you should use them for what they're for then you have Amazon workmail and this is just an email web client so it's similar to Gmail or Outlook you can create company emails read write and send emails from a web client within the adus Management console so there you go let us compare Amazon inspector versus adus trusted advisor so both of these are security tools and they both perform audits but what they do is slightly different so Amazon inspector audits a single ec2 instance that you've selected or I suppose you could select a multiple e2s it generates a report from a long list of Security checks um and so trusted advisor has checks but uh the the key difference here is that it doesn't generate out a PDF report though I'm sure you could export CSV data if you wanted to and then then turn that into a report uh it it gives you a holistic view of recommendations across multiple services and best practices so for example if you have an open port on the security groups I can tell you about about that you should enable MFA on your root account when using trusted adviser things like that um one thing though is that trust advisor isn't just for security does checks across um uh five different things um but they both do security and they both technically do checks okay so there are a few services that have connected the name you'd think they' be related in some way but they absolutely are not and they don't even have similar functionality but let's take a look here so we know the difference the first is direct connect it is a dedicated fiber optics connection from your data center DWS it's intended for large Enterprises with their own Data Center and they need an insanely fast and private connection directly uh to AWS and you'll notice they give private and enthesis because if you need a secure connection you need to apply uh an adus virtual private network connection on top of direct connect then you have Amazon connect this is a call center as a service get a tollfree number accept inbound and outbound calls set up automated phone systems uh so if you ever heard of an interactive voice system at IVs this is basically what Amazon connect is you have media connect this is the new version of elastic trans coder it it converts videos to different video types so if you have let's say a th videos you need to transcode them into different video formats maybe you need to apply watermarks insert introduction videos in in front of each one uh this is what you use media connect for okay just in case you see elastic transcoder as an option I just want you to know what it is compar it to Media connect so both these services are used for transcoding and technically elastic transcoder is the old way and it us Elemental media convert or just media convert is the new way so elastic transcoder was the original transcoding service it may still have promatic apis or workflows not available in media convert so this could be reasons why we see Legacy customers still using it or you know it's just too much effort for them to uh upgrade to the new one it transcodes videos to streaming formats uh media convert is more robust transcoding service that can perform various operations during transcoding so it also transcodes videos to streaming different streaming formats but it overlays images it inserts uh video clips extracts captions data it has a robust UI so generally it's recommended to use the uh media convert terms of costs are basically the same so there's no reason not to use media convert okay so itus artifact versus Amazon inspector get commonly mixed up all the time but both artifact inspector compile out PDF reports so that's where the confusion comes from but let's talk about what is different about the reports so abis artifact and Abus inspector so for artifact you're answering why should an Enterprise trust AWS it generates a security report that's based on global compliance framework such as sock or PCI or a variety of others where Amazon inspector is all about how do we know this ec2 instance is secure can you prove it so it runs a script that analyzes your ec2 instance then generates a PDF report telling you which Security checks had passed um so the idea here is it's an audit tool for security of ec2 instances so there you go so let us compare elb versus ALB versus lb versus J wlb versus clb uh because you know when I was first learning AWS I was getting confused because there was elastic load balcer but there was these other ones so what gives right so what's happening here is that there is a main service called elastic load balcer elb and it has four different types of possible load balcers so we'll go through all the types so the first is application load balcer commonly uh initialized as ALB and so this operates on layer 7 for htps this makes sense because that is the application layer and it has some special powers in terms of routing rules so the idea here is you can create rules to change routing based on information found within the htps request so let's say you wanted some uh routes to go that have a particular subdomain to this server and a different subdomain to another one you could do that and because it is an application load balancer uh you can attach a web application firewall for protection you can attach on the NLB or other ones because they're not application based so that is just a little caveat there then you have Network load bouncer uh commonly abbreviated to NLB this operates on layer three and four so we're talking TCP UDP this is great for when you have Extreme Performance that that requires T TCP and TLS traffic it's capable of handling millions of requests per seconds uh while maintaining ultra low latency it's optimized for sudden and volatile traffic patterns while using a single St static IP address per availability Zone uh if you're making video games this is what they like to use is the network load balcer but it has other utilities outside of that then you have Gateway load bouncer G wlb this is when you need to deploy a fleet of thirdparty virtual appliances that support uh I don't know how to say that in abbreviation but I'll just uh say it's GE NE v um and there's not much we need to know outside of that okay then there is the classic load balancer uh commonly initializes C B this operates on layer 3 4 and 7 it's intended for applications that were built within the ec2 classic Network it doesn't support Target groups so albs nlbs uh use Target groups which is just an easier way of grouping together um a bunch of uh Target resources like compute uh that we're going to load balance to and with classic load balcer you just directly assign ec2 instances uh and it's going to be retired on August 15th of 2022 so yeah it looks like it can do a lot of stuff but um it also doesn't have any of the superpowers of these specialized ones and so there's no reason to keep it around and generally you should not be using it um and so yeah that's about it
