00:00 - the really cool thing about working with
00:02 - threads in Python is you already
00:05 - understand the concept of it you create
00:06 - a bunch of workers and give them a bunch
00:08 - of jobs but the awesome thing is you
00:11 - don't need to specify hey this thread
00:14 - needs to do that job that thread needs
00:16 - to do this job all you do is you create
00:18 - like x amount of workers let's say we're
00:20 - going to have eight and then as long as
00:23 - they have jobs they're going to start
00:24 - doing those jobs automatically it's
00:26 - freaking fantastic and I'll show you
00:28 - guys how awesome it is so we say create
00:31 - uh worker
00:32 - threads and these threads by the way
00:35 - they're going to die uh I'll say will
00:38 - die when main
00:40 - exits so again you know how whenever
00:43 - you're running your program it's going
00:44 - to take like one or 2 minutes depending
00:47 - on the size of your website if you're
00:49 - like all right well something went wrong
00:51 - and I'm just going to close out of this
00:54 - but crap now I got a bunch of threads
00:55 - running in the background have to
00:57 - probably go into the command line and
00:59 - stop those well the cool thing is I'm
01:01 - going to set this up where if you ever
01:03 - want to terminate your main program then
01:05 - it's going to call all the spiders as
01:07 - well so pretty cool so Dev
01:11 - [Music]
01:13 - create
01:15 - workers and you can name this create
01:17 - spiders or create threads or whatever
01:19 - you want to do and the reason I like
01:21 - naming it create workers is because I
01:24 - like just giving it a generic name
01:25 - because then whenever I making other
01:28 - programs I can just copy out of these
01:30 - and pretty much just paste them in and
01:31 - change like one line of code so you know
01:33 - pretty much just for laziness so all
01:36 - we're doing in this is we're creating
01:37 - eight generic spiders so I'll say 4ore
01:43 - in
01:45 - range number of threads so if you want
01:47 - to create eight write eight if you want
01:49 - to create 16 write
01:51 - 16 since we're going to let the user
01:53 - specify earlier I'm just going to write
01:55 - number of threads right there and if you
01:57 - guys are like whoa whoa whoa why did you
01:58 - write your variable as a underscore
02:00 - instead of like X or num or anything
02:04 - like that well usually you have a
02:06 - variable right here like X whenever you
02:08 - want to do something with this value so
02:10 - this is just going to be equal to 0 1 2
02:12 - 3 4 5 6 7 however I'm not using that
02:15 - number in like a formula or an algorithm
02:17 - or anything I just want to Loop through
02:19 - eight times and create my threads I
02:21 - really don't care what that is so the
02:23 - convention is whenever you need to do
02:25 - that just write an underscore and it
02:27 - kind of disregards that value and it
02:29 - lets to you know continue using a range
02:31 - for Loop whatever you want to call it so
02:34 - we're going to Loop through this eight
02:35 - times and what do we want to do each
02:37 - time well we just want to create a
02:38 - thread so I'm going to make a variable
02:40 - called T and how do you create a thread
02:43 - just call the threading module thread
02:46 - and whenever you call this thread class
02:49 - the one thing that you need to pass in
02:51 - is a target so you're making a worker
02:54 - what is this worker supposed to do and
02:56 - that's the last function that we're
02:57 - going to create and that's just going to
02:59 - say work now again we didn't create it
03:02 - yet so that's why it's giving us error
03:04 - but all we're doing is we're going to
03:05 - create eight
03:07 - workers and the only thing that they can
03:09 - do is this function right here which is
03:12 - work so whatever we put in there is
03:14 - actually going to be the job of the
03:15 - thread so pretty cool now this is
03:20 - optional but I actually want to make it
03:21 - a
03:22 - demon and again that is just ensuring
03:25 - that it runs as a demon process and it's
03:28 - going to die whenever the main exit
03:30 - and the last thing you need to call for
03:32 - your thread whenever you create it is
03:35 - start so now we have one more function
03:37 - to create which is actually work because
03:40 - right now what essentially we did is we
03:43 - created like eight workers and they're
03:45 - just standing in the factory and are
03:47 - like uh what am I supposed to do now and
03:50 - of course we have the to-do list in our
03:51 - hand but you know we need to back like
03:53 - hey do these things so that's what we're
03:55 - going to
03:56 - do so all this work function is going to
03:59 - do is do the next job in the
04:05 - que one day I will learn how to type Q
04:07 - without having any typos
04:10 - so work is going to be really
04:14 - simple we're just going to set this
04:16 - equal to
04:17 - true and what do you want each spider to
04:21 - do well this is actually really easy
04:23 - just go ahead and grab one of these
04:25 - items from the list and that's actually
04:28 - in your thread Que now so
04:30 - URL equals
04:33 - q.g so it's going to get the next item
04:37 - from the thread que which is essentially
04:39 - one of these links and now once you have
04:41 - those links that need to be crawled just
04:43 - call
04:44 - spider do crawl page and as you see
04:49 - whenever I um call Crawl page it takes
04:52 - two pieces of information the the first
04:54 - one is just the name of the thread and
04:57 - that's just so whenever you're running
04:58 - this program we can display the user
05:00 - thread five is cing the Forum thread 8
05:03 - is cing the Buy's profile page whatever
05:07 - and the second one is just the URL so
05:09 - how do we get the name of the thread
05:11 - well it's actually um a cool piece of
05:14 - python that's already built in to the
05:15 - threading module
05:17 - threading current thread name so each
05:21 - thread already comes with a name and you
05:23 - can name it something special if you
05:24 - want but just keep the default name and
05:27 - the
05:28 - URL is the page that we want you to
05:31 - crawl and the last thing the last line
05:33 - of code for this entire program is
05:37 - Q task done now again whenever you have
05:42 - a spider you give it some work and
05:46 - whenever it's done with that job it just
05:48 - needs to say hey I'm done working on it
05:51 - and again that just tells your operating
05:54 - systems that says hey I'm ready for the
05:56 - next job now and it helps free up some
05:58 - memory if there aren't any more jobs and
06:01 - again all of this is taken care of
06:03 - behind the scenes with the threading and
06:06 - Q modules but there you go essentially
06:09 - all this program does multi-threading
06:12 - wise is it creates a bunch of
06:14 - workers and then it creates a bunch of
06:17 - jobs and these are the jobs and as long
06:21 - as there are more items in the list then
06:24 - your workers or threads are going to
06:25 - keep crawling all right now check it out
06:28 - actually said that that was the last
06:29 - line but we have two more lines because
06:32 - if we just run this right now we created
06:34 - all these functions but we didn't even
06:36 - call them yet so we just need to rate
06:38 - first what do you need to do we need to
06:41 - create workers because who the heck is
06:43 - going
06:43 - to craw who the heck is going to do our
06:46 - work if we don't have any workers and
06:48 - crawl which pretty much means create
06:50 - your jobs or make your to-do list
06:52 - whatever and you can even even keep this
06:55 - right now but let me just go ahead and
06:57 - delete
06:58 - it so check it out right now I don't
07:01 - have any project directory I don't have
07:03 - any of those files nothing like that
07:06 - however when I run
07:08 - main that first spider let me go ahead
07:11 - and stop this right now so that's what
07:13 - that first spider did it cwed my
07:15 - homepage right here and it said hey all
07:17 - right I got 20 links in the queue and
07:19 - then we created a bunch of little
07:21 - threads and as long as we had jobs item
07:25 - in the items in the queue they went and
07:27 - they did their thing so each one got an
07:30 - item from the waiting list crawled that
07:32 - page and added it to the queue so look
07:35 - at that and now in like what was that it
07:38 - was running for like 4 seconds
07:41 - maybe all of these Pages have already
07:44 - been crawled so it already crawled 15
07:47 - pages on my website and it already
07:49 - discovered all of these links man I
07:52 - can't even scroll with my middle wheel
07:55 - all right
07:56 - 861 more pages to look at so this bad
08:00 - boy is fast and it looks like it is
08:02 - working beautifully and
08:05 - also I posted all of this source code on
08:09 - my GitHub page so if you guys just go to
08:13 - github.com buuy Roberts make sure you
08:16 - follow me I don't know it's going to be
08:17 - somewhere around here it's not there for
08:18 - me because I'm already logged in can't
08:20 - really follow myself but if you click
08:22 - spider right here or you can just type
08:24 - in this URL then what you're going to
08:26 - see is here is all of the source code
08:29 - let me bump that down a little bit you
08:32 - guys might be able to see a little bit
08:34 - better and uh yeah so I already have a
08:36 - bunch of people working um if you guys
08:39 - are like you know what this can be
08:40 - improved that can be improved then
08:42 - submit a poll request and I'll review it
08:44 - and you know it'll help out so it's a
08:47 - pretty cool Community project it's
08:49 - actually getting really popular I did I
08:51 - had no idea that you know a WebCrawler
08:54 - so many people would actually use this
08:56 - and it would be this popular but I just
09:00 - posted this a few days ago and it
09:01 - already has like 68 Stars 23 Forks bunch
09:05 - of people working on it so yeah uh thank
09:07 - you for everyone who's contributed thank
09:09 - you for everyone that will contribute in
09:11 - the future and uh yeah let's go ahead
09:13 - and make the best spider ever