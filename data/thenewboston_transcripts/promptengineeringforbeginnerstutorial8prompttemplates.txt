00:00 - hey what's up everybody welcome back
00:02 - this is Ian bringing you another video
00:04 - in this AI series with the New Boston so
00:07 - in today's video I'm going to show you
00:09 - some more cool stuff that we can do with
00:10 - prompt player specifically we're going
00:13 - to create something called a prompt
00:14 - template so prompt templates are kind of
00:17 - what they sound like we can create
00:19 - templates for our prompts there's more
00:22 - to it than that we're going to show you
00:23 - in this video but essentially you know
00:26 - when we're creating a prompt we can have
00:28 - like messages we can have our arguments
00:30 - to our API calls like the temperature
00:33 - and the max tokens and which model to
00:35 - use all that stuff can be predefined so
00:38 - that we can use it over and over again
00:40 - also there's a really powerful feature
00:41 - where we can inject variables into
00:44 - placeholder values using something
00:46 - called an FST string in Python and it's
00:49 - going to make it to where it's super
00:51 - easy for us to take a prepackage
00:54 - template modify it with just a couple
00:57 - little clicks and changes of our code so
00:59 - so let's go ahead and see what we can
01:01 - see over here on the dashboard interface
01:04 - and then take a look at it in our code
01:07 - so if you're logged in to prompt layer
01:10 - then you should be able to go up to
01:12 - registry at the top here you'll see all
01:14 - of your prompt templates I only have one
01:17 - and then you have a blue button here
01:18 - where you can create a new one so if we
01:20 - click on create a new one it defaults to
01:22 - the completions API we've been using the
01:25 - chat completions API so if you want to
01:27 - toggle that over you'll notice that the
01:29 - interface changes a little bit
01:31 - essentially it's going to give us the
01:32 - ability to create templates for the
01:34 - system Ro if we click new message we can
01:37 - create a template for the user Ro if we
01:39 - click it again we can do another one for
01:40 - the assistant role we can input the name
01:42 - of a function if we're doing function
01:44 - calls down here at the bottom where it
01:46 - says functions we can actually input the
01:48 - information about our functions if you
01:51 - aren't familiar with function calls we
01:52 - made a video for that previously so feel
01:54 - free to check that out down here for
01:56 - parameters we can set parameters for
01:58 - everything from our model name whether
02:01 - we're using three and a half turbo or
02:03 - we're using four or we're using CLA
02:05 - instead of open AI uh we can change the
02:07 - temperature the maximum tokens all these
02:09 - other parameters we can go in here and
02:11 - modify them that way we have like a
02:14 - preset defined template with the
02:16 - specific parameters that we use and we
02:18 - can just use that across our different
02:20 - programs we have metadata which is a
02:22 - feature specific to prompt layer so
02:24 - metadata just allows you to add
02:26 - additional meta information to your
02:28 - requests we also have tags you can go in
02:31 - here and add new tags so this makes it
02:32 - really easy for you to search through
02:34 - your different promt templates or your
02:35 - different requests that you made with
02:37 - prom templates we also have scoring for
02:39 - individual requests we'll talk more
02:41 - about scoring in a later video but lots
02:44 - of powerful stuff here now I'm not going
02:46 - to use the user role and I'm not going
02:49 - to use the assistant role I'm just going
02:50 - to use the system role over here so the
02:53 - title of course is important we'll just
02:55 - do something like
02:58 - assistant type I already have one called
03:00 - that so I'll make it two and then the
03:03 - system here is where we want to put in
03:05 - our actual template our actual text
03:07 - anyway now we're going to use the F
03:10 - string uh formatting which is just
03:12 - single curly brackets for our
03:13 - placeholder values you can see an
03:15 - example of that down here but you can
03:18 - drop down with this little carrot and
03:20 - you can choose Ginger 2 if you prefer
03:22 - Ginger 2 is going to give you the
03:24 - ability to use the Ginger 2 syntax which
03:26 - I believe is just double curly brackets
03:28 - instead of single curly brackets
03:30 - so whichever you prefer you can use that
03:32 - option there so here in the assistant
03:35 - you know the default is uh you are
03:37 - helpful assistant here in the system
03:39 - role now we can modify that to anything
03:41 - we want so we can say you are a helpful
03:46 - math assistant and then we can go a step
03:49 - further we can say you know you only
03:51 - answer math related
03:54 - questions uh so on and so forth we can
03:57 - direct it we can say hey if someone ask
03:58 - something that's not math related then
04:01 - you just don't answer them or you
04:02 - politely decline to answer and this will
04:05 - set the context for all of our
04:07 - interactions with the chat completion
04:09 - API now we can dynamically inject values
04:12 - into this text right here which is
04:14 - really powerful so we have math repeated
04:18 - twice here but also what if we want to
04:20 - change it to something else what if we
04:22 - want it to be a helpful coding assistant
04:24 - or a helpful theme park assistant or
04:26 - whatever it may be so we can actually
04:28 - change this using the curly bracket
04:30 - syntax so we'll select math and we'll do
04:32 - open close curly brackets and then we
04:34 - can put whatever variable name we want
04:36 - inside here so in this case I'm just
04:37 - going to call this one type and I'm
04:39 - going to borrow that and I'm going to go
04:41 - find where I have math again and I'm
04:43 - going to replace it and so now when we
04:45 - get over to our code and we're actually
04:47 - using this template we're just going to
04:49 - pass in a variable called type with
04:51 - whatever value we want it could be math
04:53 - it could be any of those other things we
04:55 - mentioned and it'll dynamically update
04:58 - the string before we pass it to our
05:00 - actual API call so this is going to be
05:02 - really powerful we're going to show you
05:03 - a practical example here in a moment uh
05:06 - you can go ahead and click create
05:08 - template down here and it'll add it to
05:09 - your registry now I already have one
05:11 - over my registry so I'm not going to use
05:13 - that one here you can see if I click on
05:15 - this it's similar to what we just had U
05:18 - helpful type assistant you only answer
05:20 - type related questions anything that
05:22 - isn't related to type will be poly
05:23 - declined and you will gently correct the
05:25 - user now if you go down here you can see
05:27 - the input variable is typed so it recog
05:29 - recn that that was the variable if we
05:31 - had more than one it would show us what
05:33 - other variables we had uh you can see
05:35 - the metadata the parameters your average
05:37 - score if you're using the scoring
05:38 - feature how much it cost to make this
05:41 - request you know how many times you've
05:43 - used this template uh the average
05:45 - latency for the use of this template and
05:48 - the requests that you made using it
05:50 - here's the actual requests and then all
05:52 - the information associated with them now
05:54 - being able to get this tracked over here
05:57 - uh we have to take a couple steps in our
05:59 - our code I'm going to show you exactly
06:00 - how to do that so the first thing we
06:02 - have to do is take it from here use it
06:04 - in our code and then in our code we take
06:06 - the responses and we link them back to
06:08 - our dashboard so pretty easy back and
06:11 - forth I'm going to show you everything
06:12 - in our Python program but I just want to
06:14 - show you how simple it is to be able to
06:16 - create prompt templates from the promp
06:18 - layer dashboard before we jump out of
06:20 - here I just want to show you that if you
06:22 - edit this template or any one of your
06:24 - templates and then you update it it's
06:26 - going to ask you to create a commit
06:28 - message this is very similar to like if
06:31 - you were using git or some type of
06:33 - Version Control it's just going to be a
06:35 - little comment that indicates to you you
06:37 - know which changes were made in this
06:39 - specific version so I'm going to cancel
06:41 - that head back over to my registry click
06:43 - on assistant type if I click on the
06:44 - versions you can see this little comment
06:46 - box down here it's got update Title for
06:49 - version two and it's got init commit for
06:51 - version one so you can see that those
06:53 - are the two changes and if you were to
06:55 - edit and update and add a new commit
06:57 - message you would get a new version this
06:59 - is is important because you don't have
07:00 - to create delete create anything like
07:03 - that a new prompt template every time
07:05 - you want to change a specific template
07:07 - you can just edit it update it and have
07:09 - a whole history of all the versions so
07:10 - if you want to toggle back and forth
07:12 - between different versions and see how
07:13 - each one performs you can do that we'll
07:16 - show you how to change between versions
07:17 - in your code so that should be
07:19 - everything with the basics of creating
07:21 - prompt templates over here in your
07:22 - prompt layer dashboard now let's head
07:24 - over to our code editor and I'll show
07:25 - you how we can get access to the prompt
07:27 - templates in our code all right here we
07:29 - are are in our code editor we're in our
07:31 - AI playground repository Link in the
07:33 - description below we're inside of the
07:36 - open AI examples folder the subfolder 07
07:39 - prompt templates and then the file
07:42 - main.py so at the top here we just have
07:45 - our boiler plate we're just importing OS
07:47 - so that we can get our environment
07:49 - variable for our promp layer API key and
07:52 - then we're bringing in prompt layer
07:53 - we're setting the API key for prompt
07:56 - layer and then we're bringing in open AI
07:58 - now because we're layering prompt layer
08:00 - on top of open AI the way that we import
08:02 - open AI is that we actually bring it in
08:04 - from prompt layer so that's why we bring
08:06 - in prompt layer first and then open AI
08:08 - second now you'll notice the syntax is a
08:10 - little bit different for open AI we're
08:12 - now using this capital O Capital AI open
08:15 - a as opposed to the import openai that
08:18 - we used
08:19 - previously that's because we're using
08:21 - the newer version of the openai library
08:24 - and this is how it's done in the most
08:25 - recent version so open AI is equal to
08:29 - prompt layer. openai doop and then
08:32 - client is equal to openai open close
08:35 - parenthesis the client is what we're
08:36 - going to actually use to make the calls
08:38 - to the chat completions API we'll see
08:41 - that here in a minute okay so we have a
08:42 - comment here that says prompt templates
08:44 - are customizable prompt strings with
08:46 - placeholders for variables so if we go
08:48 - down we first want to bring in the
08:51 - entire template that we just created we
08:53 - called it assistant unor type so we can
08:55 - use prompt layer. promps doget pass in
08:58 - that name as a string and the resulting
09:01 - object that comes back will be assigned
09:03 - to this assistant unor type variable now
09:05 - it's going to have a lot more
09:06 - information than just that system roll
09:09 - message that we created but there is a
09:11 - way for us to easily Traverse down into
09:13 - this dictionary and pull out that
09:15 - template that we want to use in addition
09:18 - to the promp layer. promps doget with
09:20 - the string argument you can actually add
09:22 - a comma and then a keyword variable
09:24 - called version and set it equal to
09:26 - whichever version you want so that's
09:28 - what I mentioned a moment AG go if you
09:29 - have multiple versions and you want to
09:31 - use a specific version just pass that in
09:33 - to your prompts doget call and then
09:36 - you'll be able to use whichever version
09:38 - you specify all right so we have a
09:41 - variable called type and that's our
09:43 - placeholder variable that we want to
09:45 - inject something into in this case you
09:48 - could have multiple variables and you
09:50 - could store them in a dictionary called
09:52 - variables we only have one but just for
09:54 - the sake of showing you how you probably
09:56 - want to do it we'll go ahead and store
09:58 - the type type key in its current value
10:01 - of web development inside of this
10:03 - variable's dictionary you'll see how we
10:05 - use that here in a second so we need to
10:08 - go down inside of the assistant type
10:10 - dictionary and pull out the actual
10:12 - template so the template is the one you
10:15 - actually have multiple templates if you
10:17 - use multiple different roles like I
10:19 - mentioned you can use the user role the
10:21 - assistant role any number of those
10:22 - actually in this case we just used the
10:25 - system R and just like in our messages
10:28 - list where the system always comes first
10:30 - the system roll object that's the same
10:33 - format here so when we go down into
10:35 - assistant type there's going to be a
10:37 - messages key that's going to point to a
10:39 - list of message objects the first one
10:42 - the zeroth one is always going to be the
10:45 - system roll so we use bracket zero to
10:47 - get access to that object and then it
10:49 - has a key call Prompt and then that has
10:52 - a key called template and the template
10:54 - key is actually going to return to us
10:55 - the string with the curly bracket syntax
10:58 - for the type variable and then we're
11:00 - going to actually format that and inject
11:03 - web development down into it so now that
11:05 - we have the template assigned to
11:07 - assistant type template on the next line
11:09 - we're going to create a new variable
11:10 - called content and we're going to set it
11:12 - equal to the assistant type template
11:14 - variable and because it's a string we're
11:16 - going to call the format method on it
11:18 - and we're going to replace all of the
11:21 - instances of curly bracket type with web
11:24 - development the way that we do that is
11:26 - we call. format and then we pass in type
11:29 - is equal to web development now because
11:32 - we have a variable's dictionary and
11:34 - because the variable's dictionary could
11:35 - have more than one key value pair for
11:37 - example we could have another one here
11:39 - called name and that could be something
11:41 - like Jane we are going to use the double
11:44 - asterisk variable syntax and what this
11:46 - will do is it'll just take this
11:48 - dictionary take all of its key value
11:50 - Pairs and it'll pass them in here as
11:53 - keyword arguments pretty simple so if
11:55 - there's a key called type it'll pass it
11:58 - in
11:59 - like this and if we had another one
12:02 - called name it would pass it in like
12:05 - that now in this case we only have our
12:09 - type key so we'll leave that like that
12:12 - and then here just so we can make it
12:13 - Dynamic we'll go ahead and go back to
12:16 - the double asterisk variable syntax but
12:18 - that's what's happening behind the
12:19 - scenes with the syntax right here it's
12:21 - going to take that string and it's going
12:23 - to replace any instance of the curly
12:25 - bracket type with the word web
12:27 - development the resulting string is
12:29 - going to be assigned to the content
12:31 - variable and we're going to use that
12:32 - down here whenever we actually make a
12:34 - request to the chat completions API all
12:37 - right so let's take a look at this
12:39 - syntax right here it's pretty similar to
12:41 - what we've done in the past with some
12:43 - slight modifications so you'll know that
12:45 - we've already updated our Syntax for the
12:47 - open AI Library if you watched our
12:49 - previous video with those syntax changes
12:51 - but essentially instead of doing open a.
12:54 - chat completion. create we do client.
12:57 - chat. completions all lowercase doc
13:00 - create then we pass in our arguments so
13:02 - our model gbt 3 and2 Turbo in this case
13:05 - we're using the most recent release
13:08 - 1106 and then we have our messages list
13:10 - it always starts with the system roll
13:12 - and then it has the content normally we
13:15 - would hardcode this but now because
13:16 - we're pulling it from our prompt
13:18 - template and we've assigned it to this
13:20 - content variable we can pass in the
13:22 - variable here so this will be that text
13:25 - that we assigned over in the dashboard
13:27 - from prompt layer where we say you are a
13:29 - helpful blah blah assistant you only
13:31 - answer blah blah related questions yada
13:33 - yada and so in this case it's going to
13:36 - be a helpful web development assistant
13:39 - now when we run it here in a second I'll
13:41 - show you why this is powerful but it's
13:43 - really useful that we can just change it
13:44 - one time here and then it's going to
13:47 - change everywhere else in our template
13:49 - the next thing that we have here is
13:51 - return PL ID is equal to Boolean value
13:54 - of true we haven't seen this before this
13:56 - is a prompt layer feature and it's just
13:58 - saying hey return back to me a prompt
14:00 - layer ID now remember we're using open
14:02 - AI but we're using it with prompt layer
14:05 - layered on top of it and so we have some
14:07 - additional features and functionality
14:09 - and that's where this argument comes
14:11 - from so what's going to happen is
14:12 - instead of just getting back a response
14:15 - object with some stuff inside of it
14:17 - we're actually going to get back a tuple
14:20 - so a tuple is kind of like a list except
14:23 - it's
14:24 - immutable meaning it can't be
14:27 - changed and
14:29 - that's the main difference here is that
14:31 - it is an immutable list and in this case
14:34 - what we're going to get back is two
14:35 - things the first argument of our tupal
14:38 - is going to be the response object from
14:40 - the chat completion call and then the
14:43 - second one is going to be the ID the pl
14:46 - request ID that we asked it to return so
14:49 - we'll just say something random like 1 2
14:51 - 3 4 so we've got all of our information
14:54 - inside of the dictionary for the
14:57 - response to the chat comp completion
14:59 - call and then we've got the pl request
15:01 - ID now because we use this syntax
15:04 - response comma plore request uncore ID
15:07 - is equal to this API call and because
15:10 - this is our response the first thing
15:13 - gets assigned to the first variable
15:15 - response and the second thing gets
15:18 - assigned to the second variable plore
15:21 - request ID so now we can use these
15:24 - variables later on in our code so down
15:26 - here we're going to Traverse through the
15:28 - response we've done this previously
15:30 - where we have our choices we look at the
15:31 - first choice we go to the message object
15:34 - the message object is going to be for
15:35 - the assistant role and it's going to
15:37 - have a Content key which is going to be
15:38 - the string which is essentially the
15:40 - answer from the API to our question from
15:43 - our user role in this case we've
15:45 - hardcoded it here what is HTML so this
15:48 - is going to be the answer to that
15:49 - question so we're going to print that
15:51 - answer and we can see what the API is
15:53 - telling us back now mind you we also got
15:55 - that plore request ID we're going to use
15:58 - that that down here so that we can
16:00 - associate the request that we just made
16:03 - to the open a API with the prompt
16:06 - template that we used from prompt player
16:09 - so we say prompt layer. track. prompt it
16:11 - takes three arguments the first one is
16:13 - going to be the request ID and we assign
16:16 - that to the plore request ID that's the
16:19 - one that we got back right
16:21 - here and then the next one is the prompt
16:23 - name this is just the name of the prompt
16:25 - template that we used for the request in
16:27 - this case assistant underscore type and
16:30 - then the prompt input variables that's
16:32 - going to be set equal to our variables
16:34 - dictionary so we have our variables
16:36 - dictionary right here and of course we
16:38 - use assistant type here and we use the
16:41 - same name here if you want to put those
16:42 - into a variable so that you don't have
16:44 - to type it twice that might be a smart
16:46 - thing to do I haven't done that here but
16:48 - I would probably do that in a production
16:49 - application so the next thing we want to
16:51 - do is attach some meta information as
16:53 - key value pairs to our request so we can
16:56 - do that with prompt layer by doing promp
16:57 - layer. track
16:59 - metadata and it takes two arguments the
17:01 - first one is the request ID so again we
17:03 - pass in that plore requestor ID and the
17:06 - next thing is a argument called metadata
17:08 - set equal to a dictionary of key value
17:10 - pairs of any type of meta information
17:12 - that we want to include so this is just
17:14 - some madeup stuff that I have here you
17:16 - could put whatever you want anything
17:17 - that's relevant to the request that you
17:19 - want tracked all right so now that we've
17:21 - gone through the code let's go ahead and
17:23 - run it and see what the output is and
17:25 - then we can make some changes to it and
17:26 - see if it does what we want it to do so
17:29 - if we remember our variable type is web
17:32 - development and therefore our system
17:34 - role is set to a helpful web development
17:37 - assistant who only answers web
17:38 - development related questions our first
17:40 - question is what is HTML so if we run
17:43 - our code it should actually answer our
17:45 - question and sure enough it says HTML
17:49 - stands for hypertext markup language Etc
17:51 - so it's actually answering our question
17:53 - in a helpful way at the very end it says
17:55 - if you have any more specific questions
17:57 - about HTML feel free to ask great that's
17:59 - just what we expected it to do now if we
18:02 - change it to where it's no longer a web
18:04 - development assistant and let's just say
18:07 - you're a math
18:08 - assistant and we leave the hard-coded
18:11 - question from the user as what is HTML
18:14 - then we should expect for it to give us
18:16 - a different response so the response
18:19 - from the API is I'm here to assist with
18:21 - math related questions if you have any
18:23 - math queries feel free to ask and I'd be
18:25 - happy to help so this is showing us that
18:27 - it actually
18:28 - used our prompt template and it changed
18:32 - it to math and now because we told it
18:34 - you know if it's if you are asked any
18:37 - questions that are not related to
18:38 - whatever the type is in this case math
18:40 - then you won't answer them now the other
18:43 - question was answered because it was
18:45 - related to the type however there is
18:47 - some room for error here and this is
18:49 - where this kind of thing gets helpful
18:51 - because you can track which one of these
18:53 - prompts is working and which ones need
18:55 - to be tweaked and modified so if we go
18:57 - back here and we change type to English
19:00 - not English language or anything like
19:02 - that we just say English then there's a
19:05 - chance that it might misinterpret it and
19:07 - actually answer the question about HTML
19:10 - even though we meant you know you're
19:12 - like a English language Professor or
19:14 - something like that that's not what we
19:16 - explicitly said and sure enough you can
19:19 - see it actually answered the question
19:21 - about HTML even though we didn't tell it
19:24 - that it was a web development assistant
19:27 - so this is helpful because you can run
19:29 - these and you can track these and you
19:31 - can see which ones work and which ones
19:33 - need to be modified so that they get you
19:35 - the type of responses that you're
19:36 - expecting so before we go let's head
19:39 - back over here and if we look at
19:41 - assistant type on the left you can see
19:43 - all of your requests have updated in
19:44 - real time on the right you can see these
19:48 - have not updated in real time so let me
19:49 - refresh this
19:51 - page here we go so here we have this was
19:55 - a few seconds ago 2 minutes 2 minutes
19:57 - Etc and and you can see all of the
19:59 - different responses and when you Mouse
20:01 - over the type you can see this is the
20:03 - one for English you can see this is the
20:05 - one for Math and this is the one for web
20:08 - development now if you click on any one
20:10 - of these like we click on this one for
20:12 - example it's going to take us over here
20:14 - to this interface and now we can see
20:17 - which model we used we can see what the
20:19 - latency was how many tokens what the
20:21 - cost was we can open it in the
20:22 - playground we can see what the system
20:24 - prompt was what the initial user prompt
20:26 - was what the assistant prompt was we can
20:29 - check the metadata and this is where the
20:31 - metadata was attached to so remember
20:33 - that information I put you know client
20:35 - type is browser username is Ian that's
20:38 - all included here so that's it for using
20:40 - prompt templates with prompt layer again
20:42 - there's a lot more to be explored so
20:44 - feel free to check out the documentation
20:45 - or ask us questions in the comments
20:47 - below thanks a lot for tuning in and we
20:49 - will catch you all in the next video