what is up guys welcome to the python ai tutorial 2021 for beginners all right so i'm aaron if you haven't seen me before i'm on the channel a little bit i'm not cozy um i look different than cozy but uh this is gonna be a crazy tutorial we're looking around on youtube a few months back and we didn't see that much ai stuff so i started dropping these cool tutorials um i was doing some face detection and everything and we kind of lumped all these projects together into one so that you guys can learn how to actually start your ai journey and take the first steps towards being a actual data scientist so this is very beginner friendly it's not too advanced if you've never coded in um anything related to artificial intelligence before that's totally okay this is built for you uh i explain everything in detail me and then there's some other instructors too i think nas and kazi and sunny also teach a little bit in here but i'm throughout the whole thing so i hope you like me because if you don't then um all right so we're gonna be building four amazing projects okay four of them the first one is gonna be the face detector app so this is very useful for things like instagram or snapchat where people you know that you have your phone and you're like hey you have like the the face filters so this is actually what they're using to be able to like detect your face and like superimpose something over so that's really cool the second project is actually going to be a selfdriving car app um so it's gonna be like car detection and pedestrian detection in real time and this is the kind of stuff that tesla uses and companies like lyft and uber are actually starting to implement over time because computer vision is the way that they want to go forward with selfdriving cars okay so elon musk has even said that um it's all it's all computer vision no no weird sensors and stuff it's just complete ai okay so we're gonna be doing that as well the last one is smile detection that's pretty cool because it can actually like distinguish uh two different expressions on your face and we're going to be detecting that in real time and the fourth project is we're actually going to be doing a intro to tensorflow which is a pretty much the most popular machine learning platform library framework whatever you want to call it out there that's available for python and a few other languages but we're going to be doing an intro to that pretty much building a our own neural network from scratch and actually having a cool image classification out that can actually like classify different types of images so if you're excited for this please let us know in the comments below yeah guys and that's really it so i handpicked these four projects for you because i feel like they're just really like a good bitesized project for beginner to go from complete beginner to maybe like beginner intermediate um in ai and really get you started okay other than that you guys i hope you enjoyed the video but if you're interested in actually excelling your skills on python and actually making a real income from it a real living then um please click on the link below to check out our course profitwood python which does just that it pretty much assumes you're a beginner and takes you through the complete roadmap from beginner to actually making an income from beginning to end using python and to actually become a fullfledged python developer all right you guys i know we've been sleeping on python for a long time we've been doing all the javascript stuff you know this might have been plugged in by the way but we've we've been doing javascript react merge stack all that stuff but don't sleep on python because python is huge okay from the back end pretty much everything uses python python's everywhere so you really need to know python as well make sure you know your python so other than that i hope you guys are excited let's get started bernap what's up you guys guys for the python tutorial and by the way guys i want to kind of show you what we're going to be working on today look at the screen yo aaron what are we looking at right now uh this is uh robert downey jr's glorious face with his uh going to be learning real time face detection with python if you are excited please drop it in the comments below and let us know that you are excited about this this took us forever to put together i apologize we were late today to the stream we're 45 minutes behind but get a lot of things set up for you guys and make sure that you guys get a great experience now that we're here guys take a look at this here is aaron's face and it is actually what's up right now right so look at that he can move around right it detects his face uh with a pretty high level of confidence and this is all real time you guys this is with python and today the biggest thing we want to do for you is show you how you can do this yourself with a few lines of code and we want to make it as simple as possible because um there's so many different places to show you how to do this but they don't make it simple right aaron yeah a lot of the other tutorials like they added a bunch of unnecessary code to get up and working like this is actually a pretty small app to be honest there's not that much code but there's a lot going on behind the scenes and we're gonna build it first because that's the fun part we're gonna get it all going you guys can have it on your own computer running you can detect your own face and whatever other embarrassing videos you have of yourself um but then i'm also going to explain it at the end of actually what's going on instead of just like a bunch of like code in your face i'm going to explain in layman's terms so it's going to be interesting a different approach than what you've probably seen before but it's going to be good you guys excited awesome okay beautiful we are pumped so i think at this point um what should we take a look at now aaron should we go ahead and look at like how the algorithm works yeah so oh first of all here's the robert downey jr photo i i caught from the internet just to prove that it's uh what didn't already have the green square yeah but yeah i have this little presentation here okay so let's just start this up first just to give you a little debriefing before you jump into the code you guys yeah so first thing here uh in a super simplified way but just to give everybody context because i know a lot of you guys are beginners um we are all beginners ones me quasi all of us yeah and i just want to give you a a short stepbystep thing of how like face detection actually works with python all right so first step um the first thing you want to do is of course this is going to be a machine learning thing that's the really the only way or the most popular way to do this kind of thing is you have to train it on what a face actually is and then from there then you're able to classify faces down the road so step one get a crapload of faces clear good yeah and from there um we actually um don't need it to be colored so step two we're just gonna just real quick go back to step one i wanna highlight what you're saying because you're saying something really awesome there and i wanna make sure everybody truly really understands this you guys so this is awesome how aaron is putting this together for you take a look at that like the first thing we do is like we give our algebra like we want to give it tons of faces so it knows how to detect a face so we're just giving a ton of faces you can see george w bush in the middle and then you can see like their thousands of faces around it so that's our first thing that we're doing get all of the faces right um so what are we doing then on step two so after you have all the faces uh we actually don't need to be color uh the reason being for this is because what defines a face isn't so much the color it's more so the composition of like this set of pixels like okay there's two eyes and nose and then there's like some reddish or like dark color or lighter colored lips depending on maybe some teeth or something like that um so we get rid of the colors because it it it um hurts the the performance of the algorithm i believe but the way opencv does it which we're going to be using it opencv if you if you don't know what opencv is opencv is an open source computer vision library um that some people put together i don't know who put it together but it's called opencv we're going to be using that and they have a lot of cool computer vision functions that we can use to build our app so the first step we're going to do is we're going to turn everything black and white all of those faces that we had at the beginning here the very first step and we turned them black and white because the computer the only way that algorithm knows how to look at a face is in black and white so you want to give it that it's not going to be looking at it in color so we turn it into what we call grayscale grayscale that's the word yeah and then from here once we have all of our gray uh our black and white images our face images we can pump those into the algorithm and it will eventually learn how to detect faces so as you can see here it's detecting all these different faces here whether you have glasses open mouth frowning smiling eyes closed hair i mean the hair is all similar here but you get the idea if you train it on enough data it can it can recognize babies females um males uh even monkeys so uh that's that's pretty much the oversimplified threestep thing you just get a bunch of faces you change them to black and white and then you train it and then you run your class your face classification um code and it will find all the faces in your image awesome so that's a pretty simple threestep formula right so step one just go to step one real quick step one get a crapload of faces step two turn them black and white step three train the algorithm that's it guys it's just simple three steps okay hopefully you guys understand that so again get lots of faces two turn in black and white and then three just train the freaking algorithm and now you're good to go now it's gonna start detecting everything so like to actually use it you guys is stupid simple it's like ten lines of code and then boom your webcam is working and everything is working so like step one get away from the fear of like what it means to actually use these types of algorithms first use them play with them and then go deeper into the complexity and everything so you can start to understand and make your own models wow we have 664 people live that is awesome what's up that is awesome welcome you guys anybody just coming in we're making a face detector if you came in a little bit late but yeah so um with that said this simple threestep process let's just jump straight into the code you guys okay let me give one more quick demo in case there's anybody um you know aaron and what i was actually even thinking of maybe you could have code on the left hand side so you could actually like make your code like on the left hand side on the right hand side you could have the webcam open the entire time ah you see what i'm saying yeah the thing is the way this is implemented oh yeah yeah it's kind of you have to keep running it you have to keep running it yeah that's okay that's okay no worries let's keep going so we'll just keep it this way is the code is big enough for you guys to see right i think that's that's big and by the way you guys if you are enjoying this video erin open up your face detection again just so we can see it unless you comment so guys if you guys are enjoying this and if you think this is cool i think this is so freaking cool that we're doing this with python right now make sure to hit that like button it's free it doesn't cost you anything it helps us get the video out to so many places so please go down below and like smash that like button subscribe to the channel if you want to learn from aaron myself and all of us that we just give you so much value so please please please hit that like button and let's keep it rolling by the way puge says i read this comment there and he says aaron taught me how to code in python today i finally completed my titanic data set thank you titanic dataset titanic probably something you like he probably learned from you and then went and like applied it on something else right on i don't know what that means but it sounds like something i wouldn't understand so keep that that is awesome all right you guys there's 826 people live 826 what's up you guys let me okay let me just keep this running it seems like people keep flooding in where is the here we go you guys okay we're this is what we're building you guys let's just jump into the code i think we're almost at a thousand so let's just get started all right so let me comment out all the code that is preexisting here um so we can start from scratch for all you guys and actually just all of it okay so the very first thing that we're gonna have to do is obviously install opencv so if you're following along with me then please install opencv and you can do that with the command wait i gotta quit out of this one second it should be uh pip if you're on linux or unix system do me a favor a few things aaron do me a favor take your terminal put in the middle one and then also hit command plus multiple times hit command plus just to zoom in and make your screen smaller and then it's easier to see for everybody terrible habit is that that's big enough right that's really good that's really good it's easier to see for everybody all right you guys so the first thing you wanna gonna um gonna want to run is pip install python dash open cv okay i've already installed it uh oh also maybe add headless here if you're getting errors this is optional but like if you're getting weird errors try running this as well and it might work but this dash headless is optional but point is install opencv that's the very first step um honestly there's no way i can help you install it i forget there's an endless amount of errors you could get but you're going to have probably google it and look on opencv so like if you are getting issues let me just do that let's see opencv installing issues or something i'll just give like a brief thing um find the stack overflow here opencv installation problems you probably come into here and there's no answers on this one but uh i mean point is yeah i just installed opencv and hopefully that that command should work for you the one that we were just looking at here and um once that's installed then you're pretty much ready to go all right so from here you can come into our code and the first thing we're going to want to do is simply well first you're going to want to make a face detector.pi file of course so start with making your first uh python file phase detector there and just to make sure that it's running let's just do this this is a little big shot just a real quick shout out to pratik uh he says today i had an interview and i showed yesterday's project of amazon price detector and i got selected holy crap that is amazing guys go team jacob yo we literally built the price detector exactly we built the price detector yesterday you guys with jacob so that is huge that is awesome all right let's keep it going yeah that is so sick all right you guys so once uh you have your python file created face detector.pi then let's just make sure it's working correctly okay so the first thing you're going to want to do is just run pi well make sure you're in the right directory so you want to make sure that the face detector.pi file is in my um in in the in the same directory and then from there then you can just run python and run face detector.pi just like that okay nice and then hit enter and as you can see it says code completed here which is the print statement so everything is hooked up and working correctly that's the very first step and i like personally when i'm coding i like to keep this at the end of my program because then i know that if this shows up everything in my code ran and no errors popped up so i leave this at the end so that's just kind of an errand convention that you can adopt if you like but um now that we have opencv installed the first thing you you're going to want to do is actually import that library so that library is called cv2 this is i think the 2 just means version 2. it's been cb2 for a long time but just it's called cb2 you have no choice just type it in and from here go again and then let's see if we get any errors run the same command and as you can see it says code completed which means it ran this in imported library without any issues because it reached this line so from here now we can actually start coding with open cv so coming back down here um one thing you're gonna have to do is here actually let me let me go here so opencv like i mentioned earlier is a open source computer vision library provided by some people um and they provide a lot of preexisting code of course it's a library so they have code that we can use that we're going to be using that we just imported but they also have some data files for us so what this is here is actually pretrained data so if you look here there's uh what okay so har cascade is an algorithm we'll get into that a little bit but just ignore this big scary word heart cascade and then it might say this is the one we're gonna be using the front frontal face default because this uh they provided us with a bunch of data and they actually trained um this on a bunch of face images like the ones i showed you in the presentation before like this but they're basically like that yeah so that data is actually trained on tons and tons of faces like frontal faces right just like this one hundreds yeah like all of these like all ages all that kind of stuff but frontals you know so there's no like blockages there's no side faces yep um none of that just just front faces yeah um so from there they they provide all that so what you're gonna have to do is actually download this so if you can just go to this url okay github slash opencv slash opencv slash tree blah blah blah and just go to the default front this one frontal face.default.exe and download it it'll be right here and it's just a big xml file and all this is this is basically a machine learning um machine and when you pump an image through all of these all of these numbers it'll tell us and find if there's a face in the image or not and as you can see this goes on forever so this is actually what was already trained on like thousands of images so um you want to download this because openc provides it for you training it yourself is a gargantuan task of its own so we're not doing that in this video we're just using what they're providing for us maybe we can do that in a future video but point is download this from this url and then we can continue on from there so any comments quasi awesome no i love it uh basically guys to summarize it all we did so far is literally just downloaded that file that's it um so it's really simple just hard cascade frontal faces i think default or whatever and then download it put it in the same directory that you're in and that's all we've really done so far and i have mine right here see right parallel to here along with my uh robert downey junior photos and stuff oops not not this one so once you have this installed then we can go and import it into our app so the first thing is uh well first first of all i like i called my variable trained face data because that's what the heck it is and um this is the name of the file we just downloaded an xml file i'd actually don't i think i forgot what xml stands for but it just looks like it looks like this with all these tags from here you're gonna want to call the opencv library and call this function to make a classifier so all the classifier is it's a fancy word for um detectors so uh detector so we're making a face detector app a classifier can classify something as a face that's all really is and then cascade is again the algorithm the hard cascade i was talking about uh we'll get into that later just ignore the scary word but what we're going to do is we're just going to pass in that training data and create a classifier for this and since this is the frontfacing training data then this classifier now will be able to detect front uh front frontwardfacing faces and that's what we have here okay so as you can see i put a comment here to load some pretrained data on face frontals from opencv from there we can continue to um choose an image or a video stream or our webcam and then we can actually pass that um into this classifier and be able to find the location of faces and then we can put the rectangle around it and you have to like draw the rectangle on the image or the video and we'll get to all of that but moving on the first thing we're going to do let's just do the robert downey jr uh photo i'm just going to copy and paste it just so i have to type it out but i'll go slowly so you guys can type it out yourself so uh the thing we're going to want to do is choose an image to detect the faces in so mine is the robert downey jr photo so the way you do this is you want to call the image read function from opencv so very sim very simple the image you're going to read it in and it's going to be um the the photo that i just had of robert downey so that should be this one okay so it's on my desktop here and once you have it over there somebody just donated to us bro that is awesome uh really really yeah hashtag yo garage i can buy lunch today yeah finally thank you appreciate that uh so that's awesome thank you so much for that it's like please make a uber or ola clone app using react native so we might not be using react native but we're going to be making a bunch of clones with react so uber is not on our list yet we might think about putting it on our list we are definitely going to be doing tick tock and i think spotify and stuff like that and then uber we might do it at some point as well i'm not sure what ola is yeah i'm not sure i'll look that up later but anyways this is how you import an image into opencv okay so this is actually i mean an image is just an array like a big matrix of a bunch of numbers you know pixels are just numbers so really what this is you're just reading the image into a big like double um twodimensional array so a big image a bunch of numbers and bits from there um now we can actually um change it to grayscale so again if i let me see if i can actually show this yeah so let's let's just go one step before xml file link so maybe you want to just go to that github real quick and maybe just show the url and then they can pause it on there so just go there and show the url so you guys can pause it here and type that in um and then go to it okay maybe we should put in the description or something that might help yeah we'll put in the description too at some point for sure after okay here and make sure you're downloading the frontal face default this one okay there's also cat faces and stuff i mean you could actually use all these other ones like lower body upper body the just the profile of the face you can detect smile all this stuff cool yeah just eyes um yeah what's cool about this is you can detect anything pretty much you could you could detect cocacola cans and stuff but we're just doing faces like the same algorithm works for anything like it's very generic and robust i don't know what that is oh probably like a car license probably a license plate right yeah like for russian cars yep but anyways yep so here again url download this one okay and once you have that then we can continue on so let me just show uh this this image first so i imported the robert downey jr image and um so image read we read it in and then to show this image there's another opencv function called image show i am show and um this string here is just going to be the name of the window that pops up and then this is the image you want to display so let's just save this and run this to show you that the robert downey jr stuff is going to pop up and what is wrong oh i forgot you you also need this thing uh let me just make sure it works first before i because the weight key basically waits for it yep so the weight key you it because otherwise it just closes instantly go ahead yeah so what this does is it actually pauses the execution of your code so it will show the image and then it will continue on to the end of the program and it'll it'll terminate the program because they got they got to the last line here and it's like okay i'm done so it'll open this for a split second you won't even see it then it'll close it immediately so what this means is this will wait until a key is pressed so you can press any key to continue in the execution so it gets here and it waits and it keeps this open so that you can um view the image that does that that's just the way opencv is implemented um i mean if you like it or hate it it's just how it is but once you have that then you can run the program and of course robert downey jr pops up here in color just like i said okay and of course you can hit any any button on the keyboard i just hit spacebar and it just closes it and then it's of course it says code completed and i'm back to the terminal so i'll show you step by step as we're going uh what it looks like so we'll just keep these two together okay at the very bottom and okay so we have a robert downey jr image in here next we are going to like we said in the presentation we got to make it black and white because the algorithm that we're going to be using the the har cascade algorithm the way it's implemented only takes grayscale images because we can still identify faces in grayscale we don't need the color i mean you can do color but that's a much more complicated like if you want to classify like skin color or race or even like actually identify people that's even more advanced that's what facebook does you know how you can like tag your friends it automatically knows their face um that's way more you need way more training of like one person to do that so we're not going to be doing that here but i just want to mention that so aaron one real quick uh side note uh what can they do if they want to learn not only these types of skills but also learn how to make an income with these skills where can they go uh yeah so if you like coding in python and you want to learn how to actually make a living from it so if you want to start coding and landing clients or land a job and just like get your skills and your confidence up and have projects on our portfolio and all those things and really just do this for a living then we have a course called profit python formerly a profitable programmer so if you hear either name or either name they're the same and the link is in the description if you want to join that yep um we can actually and i'm showing it on the screen actually so i don't know if you you can probably not see my screen but yeah i'm showing it on the screen so guys the program is called profit with python so in this program we show you all of these things that you're going to be learning today you know whether it's like detecting faces or building ecommerce stores or any kind of project that you can take from upwork web scraping as advanced as you can think it and then we show you how to actually land those clients our biggest one of the biggest things we focus on is like how can you actually earn a killing with python that's huge for us we have dedicated python success coaches and really one of the most important things in this program is the fact that you get weekly live python training calls now aaron like what do you think is a benefit um of those like live calls uh you know for for the python like live training calls um live training calls i mean humans learn live that's how you've been learning all throughout history so having somebody there to give you realtime feedback and answer your questions right then and there is like evolutionarily the that's even a word the best way to learn um so it's pretty much like you're in a college course you know but i mean but a cool one because you have a cool teacher and you can show up and do whatever you want but there's live calls where you build apps together and you can ask all your questions yeah directly to a python expert you guys are literally building traffic projects every week so like jacob is building an ecommerce store like you guys think we're building live projects on our youtube wait till you get inside of the program because there the conversation turns over to you and you are the one building all these projects and then we're giving you personal video feedback on each of your projects that you build and we get tons and tons of submissions from people like even right now you know if i show you guys here like we have tons of projects that people are sending in that they're building with python that they're building like people are building covet trackers and all kinds of stuff so here's an example of a project uh boom here's something that was built and i can switch it up into any different country and you can see that it pulls the queries it shows all this data and people are using these skills to freelance so if you guys want to learn these skills you want to you want to be able to make an income with python then definitely go and check out in the description below the program is called profit with python and we would love to see you inside of there yeah so because coding is fun you know building projects like this this is all fun but i mean if it's fun then it's just a hobby if you can make a living from it uh i mean i say why not because then you can have your fun and make a living from it and do it more so that's why we provide um these courses we love helping people like do what they love be that being coding and just live the lifestyle they want instead of you know slaving away at a job they hate whether it be like retail or fast food or whatever it is yeah so that's worth mentioning that um optional for you but definitely there we would highly recommend it and just check it out let me just keep going for the for the viewers yep where was i i was i imported the image so like i said we need to make it grayscale because the algorithm requires to be grayscale because it's just easier to only deal with one number on each pixel the the color there's it's like on a range from like black to white instead of like our there's no rgb in each pixel it's just one one number instead of three numbers across red green blue channels so we got to change it to grayscale so of course opencv allows us to do that too and let me just go grab that code down here and i will just paste it and you guys can type it out yourself as well so as i as i said here in the comment you must convert it to grayscale and so i just called the variable grayscaled image because it's the same image but grayscale and the function that you want to call is convert color so opencv dot convert color and then you give it the image you want is the first argument and then the second one is what kind of conversion you want to do because this function actually you can do a lot of different things why don't we pull the documentation i'll just show you a little bit really quick convert color so open cv documentation and let's just go here not this one uh this one should look ugly yeah it is i got out of there quick we just lost 600 people in 10 milliseconds um where is it probably i guess there's a bunch uh gray basics thresholding options is this the right documentation open cv twopoint okay once here we go okay cb2.com color awesome yeah so here uh convert color you have a bunch so the first one is the source image which is the robert downey jr image that we had first and then there's a bunch of different things you can do so for us we're going to be using uh grayscale but you can also change like you can change the gray you could change color to just the red channel or just a blue channel or you could like dim the whole thing pretty much you can convert the image to whatever you want there's a bunch of stuff in here to definitely check out documentation but just wanted to show you guys that because this is actually where you would find how to do that instead of just like oh aaron told me to type it no the documentation has all the information you need so you can go check it out you can play with it but for now we're just going to do the very simple one cv2.color bgr to gray one caveat to or one little quirk to opencv is i'm sure everybody knows what rgb is red green blue that's how each pixel can like mix those three channels colors together and make any color on for each pixel uh but an open cv the channels are actually backwards so instead of rgb it's bgr and that was very frustrating when i was first learning it but just be aware of that and that's why it is bgr to gray because it's taking this image and then turning it to gray so let's just show you uh what that looks like so instead of displaying the color image i'm going to display the grayscale image let's go back to our terminal and type in python face detector dot pi again enter and voila we have a grayscale robert downey jr beautiful looks just as sexy that is nice that is nice all right you guys and then of course any button to quit out and we are back to our terminal and now we can continue so once so that's pretty simple straightforward i'm sure you guys all understand at that point again go check out these different settings there's a bunch you can do and of course you could even convert it from gr from gray back to rgb and it would be considered an rgb but the thing is when you lose the color and it's gray then it actually is just gray so you won't actually get the color back but it'll technically be a color image but it's not actually going to look like it but i'm getting off topic there um from here uh the thing we're going to want to do next is going back to our our little presentation here is we want to train the algorithm right but that already happened opencv was already able to do that so all we want to do now is to plug that gray image into our algorithm that we're given by opencv the xml file we downloaded and from there it'll be able to open up all these or detect all of these faces so like this is actually one image and it detected all eight and um that's what we're going to be doing next so let's just quit out of here go back and let's just detect faces so yes yes some of you guys are probably like oh maybe this this is kind of fake it's just one liner that is technically faces that is true but like i said at the end of this video i'm actually going to go through the whole algorithm and explain it in layman's terms so that you can actually understand um how this is working and why it's working and all of that because then you have a full understanding um and there's no point of coding yourself if it already exists so this is actually a better approach because you can understand it you can get the result and that's all you need once you have those two things then you can innovate further and go on and optimize or create your own algorithms for your own problems so yes this is just one land to defeat um the face to detect the faces uh but i mean shorter code is better right quasi shorter code is better because like look here what was that but shorter shorter code is always better less errors i hate having a lot of code i even try to get my functions never to be more than like four lines of code um or i'll refactor it yeah nice having nice encapsulated code that's the word for it like if your function is just it does one thing and one tiny thing then you want to encapsulate it in one thing and keep keep your code very modular so you can plug and play uh functions all over the place so then says you guys are amazing you guys are putting so much effort to make us understand things like python and you were doing this at midnight as well so amazing you guys love you all thank you so much johnson we are not doing this at midnight it's my time for me yeah really early for aaron but uh thank you we appreciate the support guys and thank you for the positivity that really keeps us going yeah guys you wouldn't be doing we wouldn't be doing this if it wasn't for you guys like there's no there's no reason if nobody's watching them what's the point so yeah thanks for thanks for sticking around and putting up with us um all right so here uh what this is what what's happening here is before we we created our classifier the trained face data that opencv supplied for us within this xml document that we downloaded and from there we're going to call a function called detect multiscale okay so this probably sounds a little bit maybe scary maybe not to others but all this means is whatever this classifier is which is a face face classifier since that's what we trained it on the train face data then we want to detect all of the faces with a multiscale thing so all that means is no matter the scale of the face if it gets smaller or bigger then if it's small or big then it'll detect it anyways it's just looking for the overall composition like the relations of the eyes to the nose to the mouth whether it's smaller up close or if there's multiple of them then it just wants to detect all of them so that's what detect multiscale is too why don't i actually pull this up on the um documentation quick question aaron prakar says can we use phone camera for detecting the face in real time um phone camera i mean you would have to somehow connect your phone camera to your laptop so that you could run opencv on there uh i think opencv has mobile support or to some extent i actually i've never done opencv on mobile but they might take a look at it and do it yeah but uh you would have to somehow hook up your phone camera i mean i'm sure it's possible somehow i haven't personally done it but you'd have to hook up your phone camera to your laptop and then pipe that into opencv somehow like maybe you make it your default camera i actually think yeah i'll take i'll take a look at that you don't have to worry about that i'll take a look look at it and see if something like that exists but uh if you guys do understand how to use it this way then you'll be able to even use it later for phone camera and things like that yeah we're focused on teaching a thorough understanding of the basics the basic building blocks like all encompassing everything so that when you learn this then you're equipped to actually go to your own innovation your implement your own creativity and do those kinds of things because that's where the real learning happens and then you can be original like i'm just gonna be like hey here's this project it's like oh here's the skill now you can go do what you want with it awesome all right let's keep going so let's just open up this detect multiscale here we go cascade classifier and here we go so detect multiscale uh this one it basically detects objects of different sizes in the input image so objects is just faces in our case because that's what we trained it with we could have trained it with dogs we could have trained it with cars with houses but in our case it's faces and from there the detected objects are returned as a list of rectangles so pretty much it just returns the coordinates of those green rectangles and once we have those coordinates we're able to actually draw those rectangles on our image so that's what we're going to be doing next okay so from here detect multiscale we feed in the grayscale image which is a robert downey jr image and like like we said this returns the this returns the the coordinates of the rectangles so that's why i call that face coordinates because it'll give us the coordinates of the rectangles surrounding the face and then from here once we have these coordinates it's it's very simple to just draw rectangles onto the image or the the current frame of the video if we're doing a video and it just runs on every frame so from here why don't we actually print out first of all we don't need to display robert downey jr anymore but why don't we actually print out the coordinates okay so face coordinates did i spell that correctly yeah and let's just run the code okay so the the coordinates of robert downey jr's face should be displayed in the terminal and can you make your can you do me a favor can you make your terminal like wider that way your line of code can show on one line instead of wrapping perfect perfect perfect yeah my dirty coding habits right i've gotten bad habits beaten into me but all right you guys so this is the location of robert downey's face in the image is it possible aaron is it is it possible to also later show the face coordinates but with your face with the webcam open and so then as you move it like actually prints out the console logs in the terminal yes actually yeah okay so let's do it like that let's do that yeah let's do that once we get to the webcam but right now we're going to focus on getting one single image up and running got it so i'll explain this so what this is like i said it returns the coordinates of a um of the face so all this is is the upper left coordinate of the face and this is the bottom right coordinate so just a bounding rectangle that's all it is can you just show it visually like can you open up the dot robert donnie jr uh robert donnie jr's photo and then like show what you mean yeah so like i was saying um of course this is going to be gray scaled in within our app right now but just for demonstration purposes the face is about right here okay so this 307 115 would probably be right around here the upper left hand of the um face and then this 336 uh 336 would be right around here the bottom right corner bottom right so you have a bounding rectangle and then from here it's very easy to just actually draw the green um the green box surrounding the face and that's how it happens okay we're doing all that manually we're actually drawing we're finding the location of the face and then we're drawing the rectangle around the face and then we're displaying that new image with so that's exactly what's happening with it and the rectangle that we're drawing we're drawing it from a module an open cv lets you draw as well yes got it wait how do i get rid of yo tony how's it going uh awesome this is tony that was actually yeah you you know him right here yeah yeah tony orbis what's up man yeah this is awesome um dang it i think my terminal bugged out let me just terminate and open a new one cool terminal and that's desktop and clear and again python is going to be face detector you're not in that file i think you have to go in that file why don't you open up your terminal in uh visual studio code um i could do that is it command j yep all right and go to my bash you can you can be in your so that's my desktop and from here we can run python um i think it was face detector or dot pi and there we go awesome i actually haven't run it from here let's see if it actually displays the image i haven't actually hmm swipe up no no it's it's running it's running so use your four fingers to swipe up on your mouse pad um and then it'll like yeah and then it'll show oh it doesn't have yeah it's i thought it would visually show up it's because i'm printing the coordinates and then the weight key but it's not um displaying something it's just bugging out so got it just let's just terminate this is how you terminate it yeah just open up a new yeah perfect you can just open up a new terminal if you want yeah oh stick to this one because then i can um because i like having the full code open the whole thing at one time okay got it so okay back to desktop python face detector not pi okay there we go so from here then we can continue yeah the weight the weight key bugged out because there was nothing popping up there there was nothing to close so nothing to actually capture a key and then continue but that's not that important oh hello kazi hi guys and yeah so those are the coordinates now from there now like i said we want to superimpose a rectangle over the image so that we can display it back and of course we want to do it with the color image again so once we have the coordinate we can go back to the color image and draw the rectangle on the color image once we get the coordinate from the grayscale image in the algorithm so let's just comment this out and the next thing is we're just going to draw rectangles and of course if there's multiple faces then it'll draw rectangles around all of them so we have a loop um but actually let's just let's just delete that for now let's just start with one rectangle so to draw a rectangle uh this is the function so opencv again allows us to just call something called rectangle and what it takes is an image that you want to draw a rectangle on so of course we'll use our color image originally then it the next one it takes a tuple of the upper left hand um the upper left hand coordinate got it this is the lower right hand coordinate so this x y and x this doesn't work because i had the loop so let's actually just delete this for now and like i said the face coordinates is what we want so the upper left hand would be whatever this gives us yeah so phase coordinates gave us like that that uh 305 thing right like 305 116 whatever we had in the command line earlier for the robert downey junior's face yeah so actually why don't we yeah just yeah run it type that out perfect like actually just like manually put in the numbers just to show you guys that it actually works okay so i'm just gonna show visually what we're doing here you might not be able to see my screen for a second okay so just hold on and i'm gonna just explain this also visually um all right guys so basically you know if you guys are with us so far what aaron is about to do right now is we're going to have robert donny jr's face like this okay and um i don't know if he's smiling or whatever and then around this we're going to draw a rectangle now what we need is the top left so aaron the 307 and then the 116 do both of those coordinates refer to like x and y pixels x and y pixels okay so one is like okay the top so basically just two points right one is the top left point and one is the bottom right point yep that's it okay so this is going to be and what are the first two numbers aaron is it 305 comma one what are they can you tell me 307 and 115. okay so guys that's that point over there okay then we have the second point here and what are what is the coordinates for the second point three three six three three six okay so it's three three six three three six all right so here are the two tuples this is tuple one this says tuple two right over here and that's how we're gonna draw the rectangle around somebody's face we need those two points once we get those two points cv2 allows us to actually make a rectangle around the face okay so that's what aaron the line of code that aaron has if we go look at his screen right now right here yep so that's those coordinates that he's referring to um these right here yep and that's what we're gonna do i just hard coded them in just to show you guys for now exactly and then i imagine the zero two five five or whatever that's the color like it's gonna make a green color or something i choose green so this of course opencv is backwards so this is bgr instead of rgb so if this was 255 this would be blue if this was 255 this would be red if i zeroed this one out but i like green so i just chose green but you could you could even make it white you can make it black that's why the heck you want now what's the last two at the end the thickness of the rectangle okay perfect how thin that's all it is so of course if it's 10 it's going to be really thick but two is a nice it's a nice thin line awesome so this is guys this is a cartoon way of looking more cartoony way of looking at it how is it drawn here you saw aaron's lot what the one line of code that he has right over there so now let's go ahead and actually run it got it so here we have the the rectangle being drawn on image okay and then down here we have an image show and here we still have the grayscale image so all we got to do is just change this back to image because now image has the green rectangle drawn on it around his face let's give it a save let's go to the terminal and let's run it and something is wrong um might have these backwards um yeah that's pop i'm trying to think uh dude let's just get right angle documentation what it does is it adds them so if we actually look at the code that we had earlier and the one we commented out or whatever it's like uh x plus w and then y plus h so you want to take the x coordinate exactly so you want to take the x coordinate and add the width to it and then you want to take the ycoordinate add the height to it and that will give you what you're looking for so just add the width and add the height whatever yeah you're right i forgot that detail it's so this is actually the upper lefthand point let's go back to there let's let's um confirm that so the whoever developed opencv decided to implement it this way probably because it was smarter in the long term instead of having the top left point and bottom right point they actually have the top left point and then the width and height of the rectangle so that you can just add this to these points to get the bottom right point so i guess equally effective it's the same data just in a different way so actually what this would be would be 307 plus 336 and that would make sense why it's 336 because it's a square it's the same number because the width and height of a square is the same so now now let's try it now it should run correctly back to the terminal oops yeah and ah much better nice okay so that bug was fixed and there we go so this is a solution is it still true that the top left point is um is 307 and 115 is that still true and the bottom bottom right point is 336 comma 336 no the bottom right point this is the width and height of the square because it's a square so width and height is the same so so what's the bottom right point then that would have to be this point um to get the i mean it's just some some coordinate math so 307 is the x is the x uh location of the top left point so this is 307 this way uh okay and then the bottom right bottom right is just one one five yeah and then this is this is one one five no no no you have to come on quasi you got to add the you got to add the 336 to um the width and the height to this point and once you add 336 it'll come out here and go down so that's how you get the rectangle got it get the offset so from there uh we have robert downey jr's face okay the problem with this though is of course we hardcoded it in so we do not want to do that okay uh what we do want to do is actually just get the points dynamically and then print those out so like we just did it's going to be like this nice the thing is we are going to want to make sure we are getting the coordinates from the face coordinates correctly so x y width and height like we said in the terminal okay so this is x y width and height here and we can do that using a four tuple and just set this equal to phase coordinates okay and this will automatically assign each of those four numbers one two three four to these four variables one two three four another two nice and a two pole then we can just pull those x y and the x y um wh out just like this and this should work unless i got my math wrong again which could be very awesome we just broke a thousand likes i heard on the video that is amazing thank you guys thank you one more value to unpack what is the last coordinate wait what was it complaining about face and line equals face coordinates value error need more than uh you never differ oh yeah you actually did define um buggy maybe wait hold on isn't it face coordinates of zero or something because it's an array with that it's a list within a list so you might have to like the double brackets there right yeah i don't know what that is but yeah that'll probably work so let's give this a shot there we go yeah oh that i guess that makes sense because it's a list of here that would make sense because if there's multiple faces then you want a list of lists yeah yeah okay that's why that's like that makes sense yeah um but there you go there you go guys so now we have it dynamically getting the the face with the coordinates here that is so cool that is so cool can you turn it red real quick just like in just real quick like that's awesome so there we go sunny was telling me you have like scary amount of knowledge on color oh yeah i worked at a i worked at a i had a data science gig for eight months doing opencv stuff like exclusively like four years back oops oh i killed the terminal guys this is the right person uh keep opening it up and once you open it up do let me know but guys this is the right person to learn opencv stuff from like he just was doing this for almost a whole year yeah edge detection motion detection background like you can you can do a lot of cool stuff but right now we're just doing face detection so desktop and again let's go python face detector yo aaron maybe like upcoming few weeks just like go crazy edge detection like bring all of that back so yeah you guys look at that we just turned it red super fast super easy green yeah it's awesome change the color i mean minor detail but yeah let's change it back to green because i like green better and although of course this is the thickness so let's let's just do a quick yeah change it to real thick like five or ten that would be awesome kaboom nice that looks that actually looks great i like that level of thickness like it all right let's keep it there yeah so we'll keep that there that is so cool like we're detecting a face in real time and drawing the circle dynamically around it and this code already works on any image you give it that is mindblowing you could even you could even have a circle instead of a rectangle but it's only gonna but right now it's only gonna make draw it on the first person it sees you guys so if there are two people it'll only draw it on one person's face but once we write a loop it's so cool we're looping through humans like that blows like you literally are looping through human beings that is insane it kind of blows my mind i almost want to take a picture i almost want to take a picture of us right now and send it can i do that can i just take a picture of both of us split side by side and then you open that image up and run it on it or is that just go for it no it should work okay cool yeah this this algorithm isn't 100 accurate they um the algorithm the hard cascade algorithm is more concerned with speed than accuracy so it might not 100 work but like 90 percent it'll work so let's okay just make sure you have good lighting and then it should work fine yeah i got good lighting let's uh detect it right now so i pulled it from our live stream and i'm sending it over to you in slack so what you can do in the meantime is uh just go ahead and pop it in to your like it's so cool to me so just go in slack and then pop it into your image see what i'm saying okay cool but like guys this is so mindblowing to me the fact that you can actually like detect images so like what i'm talking about looping through human faces here right if i can just draw it out for you guys so let's go over here and i'm gonna draw it out but let's say that we had i'm gonna clean this up but let's say the image i gave aaron has two people in it so if you have actually two human beings here like this right what we're about to do right now which is mindblowing is for right now our code all it's going to do is draw a circle around like one person's face it's going to decide who whether it's aaron or me and that's it but then once we write a for loop it's actually going to make a square around aaron so that's person one and then it's gonna loop through find me right this is causie it's gonna find me and then it's gonna make a circle around my face like a for loop that loops through human beings that is just cool like that's the power of you know being able to actually do like face detection and uh ai with python or really any language like it's so freaking cool to me you know if you guys think it's cool go ahead and smash that like button but to me it's kind of mindblowing and then whenever you're ready aaron just let me know got it yeah so i got the picture of me and qazi here on my desktop and instead of reading the robert downey jr photo i just want to read in this photo so i just named it qazi aaron okay and i'm gonna comment is it in the same directory okay yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah just on my desktop it's kind of cool cool that's fine but that's why i just uh keep it there just to get it up and running can you show the image first can you show the image first by itself so they don't think i sent it to you with green squares around it there we go so this is the image okay um i wonder no i think yeah it'll detect my face there yeah maybe we'll see so that is the um image now we're using that instead yeah and from there we want to um detect the all the faces so right now we only gonna detect one so let's run it and see who it detects first aaron or kazi yeah just give it a shot or if it breaks we'll see we'll find out and hey whoa that is so cool and for that reason it probably goes i think it gets me first because it it scans from the bottom yeah can you can you do me a favor and change that in like dude this is an array of us two like in one array like i'm sorry guys excuse the language but like in one list it's two human beings can you index that array can you index it list with one so then it puts me maybe let's take a look yeah so because you're second in the list so if you did yes then it would oh dude this is about to blow my freaking mind right now i'm so pumped oh my god dude that is cool like that is so cool let's see if there's a three let's see if i got your shirt let's see oh if it got oh my god maybe it did yeah maybe maybe maybe it detects my face this is so cool this is so cool i can't get over it i cannot get over it i don't care if people think it's cool or not i think it's so freaking oh my god that's what i was talking about you guys when it says multiscale it's what it's doing is it's taking the train data and it's checking for all sizes so it's starting big or starting small and then it's iterating so it's called a sliding window so it'll like slide the window all the way across tiny did nothing nothing nothing nothing bing found a match they go a little bit bigger nothing good that is sick it's an array with it's array of three items of three human beings in a little list three human beings in a list how does it make you feel um yo that is so cool like i'm blowing like logan is like damn paulo is like insane i know right and all we did is copy and paste like six lines of code it's amazing it's so crazy it's six lines of code that's right uh people are like oh we got somebody's like that's actually epic um dude can you can you now can we loop through it and draw the squares around all of us i don't know about that man i don't know if my skills are up to par for that but i mean i mean you know we had the loop you wrote the loop earlier yeah okay all right all right we got you guys so now we're just gonna have this be a loop so we have a list and a list of three of three faces that we detected in that image and now we just want to loop over them instead of just doing it one by one of course we could probably do this this is a sloppy way to do it but why don't we do it just for um sake so this is actually like running a loop three times but just manually yeah it's just listing it out okay got it and run it and kaboom oh man that is nice so this is just manually doing it yeah and let's make this nice and big purl nice nice thumbnail you know wow oh that should have been the thumbnail of the video nah i mean robert jenny jr is too sexy man justin timberlake that's true that's true that's true you're right or ugly bro yeah six lines of code man like that is so cool to me yeah even logan is going he's like bro just literally input in the six lines of code what the hell it'd be cool if you can change the color you know like you even like like label them and stuff but anyways let's go back and make this actually loop the proper way so uh the way we're gonna do that is oh yeah change uh also yeah once you write the loop let's also like change the colors between 0 and 255 it just picks randomly so then it'll be different colors oh that's fun all right yeah okay dude on the on the webcam when we're doing a live webcam it's going to be like rainbow it's going to be like going crazy it's going to be pretty cool yeah yeah yeah yeah but all right so let me just go in here so i'm going to type it out here's the loop all right and we're just going to replace this top line this one we're going to replace it with this okay so instead of manually getting it here and getting the first the first face in this list of faces and then assigning it we're just actually going to loop through all of them so because this is a list we can loop over it using the word in so for this tuple in this list which means it's going to iterate over everything then um it's going to have the same functionality okay so do this make sure you tab correctly so for this tuple x y uh with height in phase coordinates then this is unchanged okay because we have the variables exactly the same so this is actually going to work uh minus the randomization of the colors but let's just give this a run and see what happens and it might even pick up extra stuff if it if it failed there might be like a fourth phase somewhere no there is none but there we go you guys so this is functioning so far that loop worked yeah it did we're looping through three human beings right now or two human beings beings in one cartoon man this is so crazy to me wow why do you look so dirty we have the same glasses this is awesome yo okay i got you with the i got you with the different colors so aaron go all the way to the top of the file and um and just do um do hold on import so do from random import rand range although at the top like that yep um i am so you misspelled import yep and then um where you have that 255 you can you see where you have zero comma 255. so just do ran range uh no no no no don't do that don't do that don't do that don't do that just the 255 just wrap the 255 in the function rand range got it and right you can do 250 yeah 256 because it's going to go up to but not including okay so now it should be randomly like making the colors so now if you hit save and run it everybody should have like a different uh color hopefully it would be really unlucky if all three of them were randomly generated well this is just the green this is just the green channel so it's going to be different scales of green but not different colors oh so then you can actually just do rand range for all of them like for all of the coordinates you could do so go back you could do for like for zero you could do that and all three of them you could do the same thing there we go and yeah now let's run it and now it should be random colors that is so cool and green damn okay awesome that would be useful for identification like if you ever actually trained if you got enough of your images enough of my images and enough of this little shirt we could uh we could actually like train it and be like okay it's red aaron's blue i just can't get over that we're in a list we are in a list right now in a python like that okay dude i can't get over that all right let's keep going we know uh one thing i do want to try though is i feel like those colors a little bit dark but if we keep the the range in the upper half of the 256 then they won't be so dull all the time so let's actually go um 128 to 256. okay oh i try this and then i think the colors the colors will always be brighter color science oh i mean it kind of looks it's fine but that's fine you can remove the one yeah just so it's less confusing for them but yeah ran range is awesome right guys it's pretty cool quasi logan goes kazia 20 20. i'm in a list for you getting excited coronavirus got us all screwed up you know like we're getting excited about a list like awesome all right thank you guys we just broke a thousand likes thank you guys so much really appreciate you guys uh we our team just notified us frankie just notifies like thousand likes on this video frankie's pumped awesome you guys thanks for all the support we appreciate it uh i don't know how long we've been going for like almost an hour already right yeah way longer than one hour for six lines this is so fun this is so fun i think everybody's pumped i think everybody's totally like what do you guys think but in my i honestly think that everybody's freaking pumped out of their minds because i think this is the coolest freaking tutorial that's out there on face detection everything else is like so boring every time i try to learn it i go to fall asleep wait wait till wait till i explain actually how it works like mathematically like it's not complicated but like that'll blow your mind because right here we're just calling a piece of code anybody can copy and paste this but if you actually understand how it works that's the mindblowing part so stay tuned to the end for that okay guys uh we're almost done so we're gonna move on to um video now because actually our our image is done so we are have already gotten the image and we're displaying it here and then we did i would display it here so we display the image here play the image with the faces and then we have the wait key of course which is just waiting until we press a key to close and once it closes then code says code completed and we are done so okay we are detecting faces on a single image but what if we want to detect faces in a video but what if we want to detect faces in a video well all a video is is a bunch of images one after another so um we can actually just run this code on every single frame of an image of a video i mean whether it be a video file or our webcam stream we're going to be using the webcam stream and that will basically give us realtime face detection so it's pretty much the same exact code with just a loop added on the outside so let's do that now okay i'm just going to mod i'm just going to continue modifying this code so let's go down here and the first thing we're gonna have to do is actually instead of capturing an image we're gonna want to capture the webcam so let's start from here let's comment out the image and instead let's paste in this okay so instead of calling image read on an image file to wait um to get an image like this we instead are going to call cd2 video capture so all video capture means is you're going to capture a video if you put a zero in here it's gonna get your default webcam so for the person asking about your iphone if you can make your iphone the default cam i think using xero would actually work you just have to like specify it on your computer assistantly i went unfortunately i went and checked and opencv does not work with ios but i honestly think that if you figure out how to make this work you can easily make something with javascript and then host it online and then people can go and use it but the most important thing is to get experience using it learn how this technology works and then it you can go and implement it in any language you want on any system absolutely so i mean i i think it might be possible like look into it maybe uh it won't work natively on the iphone but you could use your iphone camera hook it up your computer and then use your iphone and look around and have that being in this app but the point i was saying was if you have zero it automatically goes to your default webcam um but if you put a file name in here then you could have like you know video.np4 or something if that was on my desktop it doesn't exist um well actually i do have a video here or is it it was a funny detective face that's actually cool lol memes so let's just do this oh nice i didn't know you could give it a video that is so nice yeah you can oh it's actually not going to work because we haven't coded it all out so let's actually do this later but first step is calling video capture which allows you to get the webcam or a video file with the same function which is nice so thank you opencv for being smart and efficient so ahmed asks where's the training part the training part is on line six that's where we trained it the that's where we train the data but keep going yeah we actually didn't train opencv because training takes a lot of time like we would be sitting here for anywhere from probably like half an hour to multiple days depending on what kind of data you're training um so that's why we didn't do that here we just we stole the training the train data that opencv already trained for us like years ago and then they just supplied supplied this machine learning network for us to use and we just downloaded that which is right here so this is actually the train data so all these numbers the negative four the negative two and all these crazy numbers if you pump an image through all these crazy numbers it just filters through and it finds the faces magically you know the same way your eye can find a face when you look at a picture this is doing something remotely similar that your brain is doing but in a different like in a computer computerized way so that's what that's what this is so yes the training is happening um in here in essence hope that's clear quasi i cannot hear anybody no you're good you're good to go keep going got it so um let's just get this going and then actually display the webcam okay um i believe we need weight key as well yeah pretty sure we need weight key and webcam release let's see if this works and this is awesome we still have 685 people live this just tells us we got to be doing a lot more of this aaron because it seems like everybody loves this stuff because most of the times by now we drop to like 100 live people watching this is awesome yeah people are loving it right oh says yeah well it's not gonna work because we need the loop so this is a little bit confusing um what i so if i was if i were to do this and display what this gave us it would only give us the first frame so we're gonna have to kind of do a big chunk of um logic together guys we're gonna have to cut up the whole loop and get it going as one um so just bear with me and and we'll get that going so uh once you get the the webcam here uh what you're gonna want to do is um get a a while loop okay so this loop is going to go right here and what this does is we just want it to loop over all the frames in the video forever until the video ends or until we kill the webcam so for the webcam we just want to run forever because it's just gonna is a real time until we tell it to stop so that's why we want a while loop running forever and then from here now we can actually go and fetch the current frame and display the current frame so um let's go down and get this so this is the next um call so this is actually how you would get the image out from the video you could technically run this outside the loop but then like i said it would only get the first frame and it's essentially just an image again which is kind of the same as what we did before so i'm just jumping into the loop so uh there is this webcam that we made okay from the video capture we called it webcam and webcam allows you to read from it so you just call the read function here and what this returns is two things uh tuples so the first thing it returns is if the reading the frame was successful or not this is just a boolean it'll be true or false and then this is the actual image so the frame that is being read currently from the from the the webcam uh this we actually don't need but we need we need to be there just to like for placeholder but we're never gonna use this this should always be true okay but this is all we want we just want the frame so once we have the frame now we can actually take the frame and instead of frame um use the frame instead of image so before we're using image with robert downey jr and everything and being causey and all that but now we just want to actually change the image to frame because this is the the image we're using it's the current frame so why don't we actually do that and let's comment this out and um just show the webcam in grayscale okay so we're not going to do any detecting yet let's take this paste that in here and show this okay remembered yeah so um the one thing about weight key is actually let me demonstrate it first and i think that'll be better so let me just run this and see what pops up i don't think anything's gonna there we go so as you can see this is just a single frame it's not moving because uh the wait key is is waiting on something and i got a little bit screwed up so actually what we need to do if i had an image though you can see it skips to the next frame so i can move around and then when i hit my space bar then it automatically goes to that frame because it's waiting for the key so one way to get um out of this i gotta force quit this because there's no way out of it forks quit force quit python there we go we are um going to put a delay in here so um wait key here if there's nothing in here it'll wait infinitely until you hit a key for it to quit or to go to the next frame like we did but if you put a number in here it'll wait this amount of milliseconds before it automatically hits a key for yourself so we can wait one millisecond then it'll auto hit a key which means each frame will be um happening every millisecond so let's try this all right and this should actually be live webcam footage um in grayscale from our webcam so as you can see it's just grayscale there's no face detection yet or anything i'm just doing this and then the wait key every millisecond is um it keeps just keeps pressing a key every millisecond already wait it so hold on one second so that's so sick that already has you in great scale in real time like from python i did not know you could do that that is so cool um and what are you saying about this one millisecond thing i'm not understanding it like what is it what is it doing it's a little no no no no just show your show your screen show your camera so like okay so what's happening like without it would it close would the window close no so wait key what weight key does in opencv the ways it's coded the way it's implemented is um it's going to wait for a key press to execute code so the code will just wait at wait key that's why it's called weight key it's waiting for a key to be pressed i'm just i'm just trying to understand in english like what happens if it's not there or you don't do it the right way like does the code break like does the video stop playing does the next frame not load like just in pure english like what is it that it actually does weight key um it's stuck if it's not there then it just won't work okay what's great is it's like like you need you need weight key to actually display something like you cannot just in opencv the way the way it's designed is you cannot display something if you don't call way key okay that's it that's all that's the most important thing i care about like if i just want to use this like all that's for me that's really important so okay so if i don't have weight it won't display it's not actually what it is but that's the behavior that okay beautiful beautiful got it okay so yeah because if it's not here then it'll just it won't work so let's quit this um again you gotta force quit we'll fix that in a bit you guys will be able to like hit the q button and it'll it'll it'll quit instead of having the force quit uh but here if i run this then i don't think it's gonna work it'll like pop up for a second or something and then disappear yes it just freezes up and there's nothing over here yeah so it gets there and then it gets stuck in an infinite loop so that's not a good idea nothing pops up you need weight key because you want it to wait here and you want to show a frame and then wait at that frame that's what you want got it okay uh so let's close see python not responding because if we're stuck in this infinite loop with no way to get out so it just just bugged out all right continuing on now so let's put this back you can think of it as display but what i was saying was if it's if there's nothing in here it'll wait forever and wait for you to actually press a button for it to continue to the next iteration of the loop so if you go back to the code this is a while loop right and it's going to run over and over and over again and each time it runs it's getting the current frame and then displaying it in grayscale to the screen okay it's getting it's turning at the grayscale and then displaying it with image show right here the current frame then it waits here forever until a key is pressed so that's why the behavior is weird it's frozen it's the current frame and then when i hit a key then it goes to the next iteration of the loop the next one next one and if i spam it then you can see that i'm kind of like moving but then if i stop then it breaks so what weight key does is it waits for a key infinitely but if you put a number in here then it'll only wait for that many milliseconds before it automatically just continues on and goes here so that's why we're saying then i don't have to press any buttons it'll wait for one millisecond then automatically go to the next iteration aka the next frame and so we're getting one frame every millisecond i mean i mean the the camera rate will be lower but that that's uh that's what it does so we'll quit out of this again one last time force quit this and run this to get the correct behavior and there we go so we're in real time every millisecond the loop is automatically restarting with the weight key because we put a one here you could even put like a thousand in here and then every 10 seconds it would go automatically so but we'll leave it at one because we want to be real time now moving on from here we have the grayscale but now we want to plug in the face detection into this so just the same as before um we are going to want to take the detect uh detect faces and of course we want to apply it to the grayscaled frame so instead of just displaying the grayscale image we want to find the coordinates of that and then display it display um display over it so the grayscale image this is all the same code the face coordinates are going to be using the trained face data and then of course the detect multiscale and then we're giving it the grayscale image from right here just the same as the image then we need to draw the rectangle so this is the same thing again let's just steal this loop that we wrote earlier and pop it in right there and this should work as well so let's just double check image actually this won't work because image was the image before this actually needs to be frame instead okay and um i think that is it it's just the frame has to change so what we're doing is we're detecting oh i see it's pulling the frame just to be clear because i got confused at this i'm sure people are going to get sometimes confused it's pulling the frame from line 18 when webcam.read unpacks okay cool the the current frame of this loop every millisecond the current frame is called frame so you want to we want to detect the face in this frame grayscale and then we want to draw the rectangle on the frame not on the robert downey image that we had before but on the current frame of the webcam because we have webcam now so that's how that works now let's um just run this and see how it goes i think i think it's everything so of course you're going to need to force quit this again and go to terminal and why is it not working ah because i am displaying the grayscale image not the um colored colored one one second i must got a bug somewhere so yeah so the image show it's showing the grayscaled image what we want to show is actually frame okay because that's where that's the colored frame going back to color and then we color we put the rectangle on top of it so we want to display that instead of grayscale so now it should work but knowing my luck probably won't there we go and there's the rand range oh nice and the colors changing every second look at that that is so nice so you can so you can see that you can see the one million the one millisecond refresh rate that's actually pretty cool the color you can see like in real time yeah actually you can see every time so cool every time the loop uh iterates it's getting my face it's not perfect though because this is actually a pretty lean algorithm there's there's more powerful algorithms but of course there's always a tradeoff of um speed and accuracy whenever you're doing algorithms for everything in like computer science and data science there's always multiple algorithms you can use to solve a problem this one we're using har cascade um specifically because this is the most commonly used one like this like on your little camera's digital cameras your iphone is probably using this that's so cool that we're you like we're looping through on your face and like drawing like looping through and making new colors like that is just the coolest thing and we're gonna have to force quit this wow okay and let's continue on so we can actually get rid of this stuff and keep code completed so uh oh i forgot one more thing so i i kept having the force quit which is pretty pretty dang annoying to be honest um so i threw in this thing uh earlier today of giving us the ability to oh we gotta clean up after two but of being able to actually quit using a key a specific key so did i copy the right one yeah this one so if i pop this in here um all this means is um oh first of all i screwed this up so actually when you're getting the wake key you can actually capture which key was pressed on the keyboard so it's waiting for a key and then you can actually get it so if if if if i don't press a key then this is probably like zero or null or something or none in in python um but if you press a key then it'll go into this so what i decided was i um if you press the q key then q for quit then it'll quit out so i looked up the ascii characters for q very simple you can just type in ascii if you didn't know every every keyboard character has its own ascii code ascii is just a sci i don't know what it actually stands for but every every letter has its own number so if you go to q you can see q is 113. lowercase q is 113. uppercase q is 81. so 113 and 81 that's where i got these numbers from 113 and 81. so uppercase or lowercase q will actually break out of this infinite loop and that allows us to exit the realtime face detection without needing to force quit the way i was doing it all this time okay so let's give this a shot and see what happens run it and it's going good and let me hit the q key q are you connected q unless i had a bug let me um let me go double check what is wrong oh yeah i forgot the webcam release i always forgot these things uh good things like especially when you're doing um memory allocation or any any kind of like streams of data you should always clean up your code afterwards so in this case you're going to have to release so i think this might be the case um let me see the yeah let's try let's try it again there we go now let's hit q i think it's lagging i think it was actually working but it's just taking a long time to actually there we go okay so what's working i think i think the color maybe the random color was um doing some stuff uh i don't know it's just being laggy but pretty much it has the the working functionality i'm actually curious let me just try to change this and see if this is actually what is holding it up and let's run this again go here so it's just green back to what i had before and then hit q nope my computer is just slow i think it's just bogged down from the live streaming and everything at once i think that's why it's slow really slow anyways it'll close after a few seconds not important but let's change this back to the multicolors because that was cool and um that there guys is pretty much the completed uh realtime face detector app okay uh we have the ability to detect faces in images to detect faces in webcam and even video so actually let's uh i have a video here um called lol memes that you guys have probably seen before and let's pop this in so instead of reading from the webcam we're going to be reading a a video file on my desktop so if you give it if you give it an argument of zero it reads it from your webcam but if you give it all and if you give it a name it actually looks for that file path it's just capturing video from somewhere you've got to tell it where to cap your video from awesome that's all it's doing so now let's try to run this and we can see it work whoa what is going on whoa that is crazy it's getting that guy a little bit now you can see it's not perfect i mean it's really difficult like this is a crazy video and it's already pulling it like that's insane wow i pulled this this video and you can see it's getting his face at the end there people are like wow it's amazing very nice awesome and then of course if you hit q it will quit and that one happened a lot faster can you oh i see okay interesting um i'm trying to think okay cool is there any other videos you have on your computer that it can pull from yeah i have this funny baby that i got okay let's see so yeah right there i was testing these earlier nice and there's no audio but here's another oh my god that is so cute that is so cute i love that i love that the dad is basically like tormenting the baby by making them say stuff but yeah logan says super impressive aaron logan's super impressive aaron thank you for the content absolutely we haven't even gotten to the interesting part yet this is the fun part but the interesting part is about to happen so this is working here again i'm going to try capital q this time and it should quit wow our loop is still working and going through the random colors i love that yeah i think i think we're giving the baby epilepsy that's what's happening here he's going crazy you know what you can even do is like like right next to it draw random captions like draw like random you know so like how have that people have that like speech thinking bubble next to them uh yeah something like that so we could even exactly so you can detect faces and automatically put like speech bubbles in real time next to it that like writes out text or or morty i think we could superimpose our i don't know i don't know about that rick yeah we're thinking doing that we're gonna superimpose rick and morty's faces over our faces but uh it was too hard to do that with the stream at the same time we couldn't technically figure it out the stream oh oh geez i mean i mean we could we could probably do that you guys you you would really you would really have to just let us know if that's something you're going to like i mean i mean you you can go ahead i mean oh geez just go ahead and smash that like button that that'll be so awesome yeah morty i didn't actually had a i didn't actually know you had a head on your shoulders morty but i'm proud of you today people are loving it they're like this is amazing they're like i wish i could code like this i still hate you morgan you piece of logan is laughing yeah i love rick and morty man i love brick and morty yeah awesome anyways um that is that and that completes the app but now i mean this is a lot of hand wavy woowoo stuff we just called this detect multiscale and downloaded this file and it just kind of magically started detecting faces like cool like a fiveyearold could have done this which is true but which is also awesome because i mean you got this up and running with like minimal work but i do want to give you guys understanding of how the algorithm is actually doing it but i do want to give you guys understanding of how the algorithm is actually doing it like how the heck is a computer looking at an image and how does it know what a face looks like and actually understand it so um that's where i want to actually go to here okay so let's just look at this for now i put together a little presentation um to actually transition people over into thinking like a data scientist because um most data scientists are coders but not all coders are data scientists like you can be a coder you can be a frontend developer which is amazing web developer and stuff but like if if you don't actually understand like some of the underlying algorithms and stuff you you can't actually pursue anything in data science if that's what you want to do and that's what python is known for so that's why i want to touch on it so um instead of being a coder and just like copy pasting what i just i taught you now you need to actually understand what's happening behind the scenes so that in all the little tricks that are happening so that you can actually innovate on that and continue forward and actually come up with like new and faster and better face detection down the road so but you got to understand the basics before so let's continue on okay um face detection so what the hell is har cascade that's the big question because if we go back to the code then um all this stuff was like hard cascade hard cascade what like what the heck is hard cascade why does it say har cascade and we just downloaded this thing um well this is just an algorithm okay so har is the name of a dude who invented the algorithm and cascade is just the word cascade so cascade is like a chain of events pretty much and you're just going down like you're going down a funnel so what it's doing is it's like it's going down a funnel until it finds a face at the bottom of the funnel and then it's like here's one face and it keeps doing it over and over again for every phase you're cascading down um that's the one paragraph explanation but let's actually go to one second and real quick uh if you want to cue me to show your face just you know just be like his you know camera one or something like that and i'll switch over to your face or you can just tell me so right now i'm i'm i have the camera on both of us so now when you're drawing like moving your hands physically it'll show and now i'll hit two and it'll go back to the screen got it yeah we'll just show me really quick while i'm explaining it so um like i was saying the hard cascade is just like a chain of machine learning things that that the image is being passed through and then it's going to funnel it down to until it finds the exact square where there where there's a face it kind of looks at like every square of every size on the image and it passes each of those squares through this machine learning thing and then it cascades down eventually it's like okay if you pass all of the cascades and you get to the bottom it's like okay this is close enough to a face to actually be considered a face and that's why it's called cascade horror is just a name you can kind of ignore that but hopefully this makes it seem a little less scary you can't understand but now it's time to reveal the magic trick of face detection okay it's pretty mindblowing like honestly i wouldn't have been able to figure this out on my own like these geniuses did it but i learned it in my in my schooling at georgia tech when i took computer vision and i'm just gonna share it with you okay so yep time to reveal the magic trick uh don't be this guy um i have this gif here so it's actually it's actually pretty simple how it works and i want you to understand instead of being like this guy like how the hell does faces section work i want you to just know like how it works because it actually is this simple you can see it from the third one like once you understand it's that simple i love that that is awesome let's continue on yeah so as you know the algorithm is called har cascade so let's start with haar so what heart cascade does you can also by the way you can full screen this you can just hit command enter and it'll full screen it so everybody can see it in a better way and and you can actually use a pointer so at the bottom left click pointer and then when you actually move your mouse around like people you can yeah so it's easier to know what what you're talking about okay see i'm just i'm just a coder i don't know all this fancy google google side stuff but anyways so these are har features so this is the first part of the hard cascade algorithm it's a very very simple thing um what you can think of hard features as as rudimentary building blocks so this is a one heart feature this is another hard feature this is in the hard feature this is one and this is one all this really is is a little block so what we're going to be doing is we're going to be placing this over a portion of an image that has a face in it or it doesn't have a face in it and all it's doing is it's kind of showing the relationship from the white portion to the black portion and then what this allows us to do is it kind of allows us to approximate the relationship of these pixels within this box so if we overlay this over um somebody's face then we could be like okay um down here in relation to the pixels up here there's some kind of relationship and then um or or this way you could be like okay the pixels on the left have some kind of relationship to the pixels on the right or like this um you can do the three thing like okay there's there's a relationship a threeway here or um a diagonal and this is like the the most elementary ones that you don't have to go any bigger because you can just kind of chain them together but these starting blocks is what you start with and if you chain these together over and over again and you layer enough you can actually some combination of these five things will actually give you a template for a face it'll look like a face and then that's how they actually find faces by layering this over and over again and cascading all the way down these different layers um and then actually finding one that matches the face and though the way it does that is you give it faces so it finds out the combination of these things to know what a face is and then you can just filter through it again so that's kind of the um the idea of of heart features so far so these are hard features and uh let's continue on to the next slide i think i'll make more sense when i show this one so this is how a hard feature is applied to an image so like these let's say these are blank images or background images i have no faces in them um one heart feature is here and um here's another one different a different type where it has three um three columns another one is here and as you can see this is uh how you would overlay it on an image so this is the raw image but then if you have the heart the heart feature here what we're looking for here is oh the relationship of this black box to this white box and um what's cool is if you look on this face here you can kind of tell that this rectangle here of his eyes is a little bit darker than his cheeks and his nose and you see how that corresponds to the black and the white here so we can actually say that this heart feature is closer to a face than something else like placing this like all the way on the bottom left where it's kind of like not because there's kind of like a black bar here in the white part here so white so the white one means that that is more like a face and then the black the area that's black is like that's less like a face the the black is like you can think of it as like it being darker and the white is it being lighter so you're saying that there's some kind of like going from light to dark in this direction or dark to light to dark in this direction so oh wow so like the electric so like bar going to a light bar you see right here is exactly what this okay so one second so i'm so basically the face detection it's literally it doesn't look for facial features it's just looking for like how dark and light it usually is around faces and that's why you only need greyscale crap that is well this is this is only one algorithm there's like there's a bunch of different ones but this is the most well known and most widely used like literally just looking at so for this one specifically it's just looking at like yo here are 100 different faces you'll frank you bring your face in real quick so like it's like it'll like have like a certain thing for like dark and light for his face versus a dark and light yeah so then it's just looking for white and black like okay okay cool like if you if we went back like this would even be a better match because you have forehead then eyes then cheeks you see what i mean if we had that here you could also have a white bar up here you can kind of see it's like white then dark than white so we're basically saying there's some kind of three layered relationship of this block of pixels and this is only one layer of hard cascades basically we're going to layer a thousand of these little matches together and eventually those added up will add add up to a face wow you can see the second one here you can kind of see like okay the eyes are darker and the bridge of the nose is lighter see the eyes are dark and the bridge of the nose is darker so this heart feature plus this heart feature is even closer to what the heck of faces yeah this is what this is what logan is saying he's like ah he goes this is why we use grayscale right aaron and he goes because color is irrelevant we're actually just looking for brightness yes exactly well you can you can start using color when you want to get like really like if you want to like profile like race or skin color or if somebody has freckles or not you could even start doing that if but it would of course you would need more data and longer time to train but this is the most generic case but i want to teach you guys from the ground up so that you understand how this works because this is the prerequisite to everything else okay yeah um so this is how a hard feature is applied to an image and of course you would just take this box and you just drag it all the way around the image you would even resize it like um because again you could have like this similar thing might be like it might match on the mouth a little bit but let's move on okay so these are hard features these are the five rudimentary heart har features and this is how hard features are applied to an image and if it's like this then there's no match you know there's like it's just a white but like flat background or if it was like a landscape or like your wall or something then there's gonna probably be nothing there um but let's go on there's a little bit more nuances but that's the general idea so far so now actually how did opencv train that face detector that we downloaded that xml file because that's where the magic is we just called we just downloaded it and just like called a few lines of code which is kind of like okay cool but how do they actually do it because from here if you understand it then you can actually start thinking correctly and do some real data science stuff like you're not a data scientist unless you actually understand the algorithms so step one like we mentioned the very beginning of the call you want to start out with your training data so in machine learning the the way it works is you have positive images and negative images and all these are are just labels so this would be labeled as face label as face labeled as face this would be labeled as not face not face not face that's all it is you just need faces labeled as faces so just to contrast just to just to contrast that guys so here is a face right but here is like this would be a negative image right a phone would be a nonface so like it's not a face so again nonface is happy cup of coffee this is a nonface when it sees it this is a face when it sees it right and this was through supervised learning so it fed the data to the hurricane cascade right and it told it yo these are all faces and these are all nonfaces yeah so this is yeah yeah so this is called supervised learning we're probably not going to go too much into unsupervised supervised but like at a high level it's like a human being's telling it what is a face and what isn't and then feeding it like lots and lots of data yeah uh another way maybe another way to explain if somebody didn't catch that is there's two fields of machine learning there's supervised machine learning and unsupervised machine learning which is what causes just said supervised means you know these are all faces and you know these are all nonfaces it's supervised you're supervising the actual data and you can tell it like these are faces okay that's what it faces these are not phases okay that's not what a face not is um but if you're doing unsupervised you're literally just given a bunch of stuff and you have no labels and then you can just at the end be like oh was it right or wrong so you have even less data but that also is a lot better because when you're gathering photos from the real world or data from the real world usually it's not labeled you'd have to go in there and manually label it by human because how else would you know these are faces so there's kind of two fields of thought supervised is better to learn first but unsupervised gets very very messy and just kind of like the cutting edge right now yeah yeah that's where like you really get into ai and all that like deep deep neural nets and all that stuff deep deep girl nets awesome this is just yeah machine learning so uh star one start out with training your data so you have a bunch of labeled images and from here you'll go to um the next thing so after you have all of your images so you have face images and then also nonface images you want to find um the winning har features so like i said this heart feature matches nicely with the eyes and the cheek and then even if we had like the other heart feature with the with the lighter bar on the forehead that would even be a better match but for this one is we're just using this this is a fairly good match and this one is also a good match okay so basically what we want to do is we just want to chain together all the hard features that kind of match and add them together sum them up until we get a face template these are like little lego blocks to like doing it and this is why it works for nothing because they're rudimentary building blocks this can work for a cocacola can you can distinguish a cocacola can from a pepsi can eventually because it looks different and like the the brightness and the brightness relationships within these boxes and sizes of boxes is all different that's why there's you just start with like plain old boxes and you add them up i have insane that you can tell the difference of everything based on brightness like this is where algorithms are so freaking cool because i mean it's what your brain is doing right like what is your brain doing it's doing the exact same thing it recognizes a face versus not a face and we're just teaching the computer how to do the same thing dang damn so it blows your like selfdriving cars this is this is absolutely like essential like tesla you know tesla stock is going up like crazy elon musk just passed warren buffett and his net worth as of like three days ago like go elon are you serious protect yeah he's 70 billion warren buffett is 69 billion whoa but he's now elon musk is now number seven in the world he's exploding bro but um but yeah the tesla selfdriving cars they use this heavily um it like with other things but there's a lot of computer vision so like you could like um you could detect pedestrians whoa i am showing that on my screen using the same heart function that is insane i just um i have an ad blocker on so i have to turn that off real quick but um i'm just showing them on the screen that elon musk actually passed oh my god is this website annoying holy crap jesus christ okay i'm out of here they can they can keep their we don't need to look at that business insider yeah elon musk just passed them officially that is insane yeah elon musk is my guy man like daniel works at blue origin right that's like the competitor of elon musk's spacex well we have a guy here a programmer who works at a competitor jeff yeah he worked for jeff bezos company and he works on an actual rocket ship at clever he's gonna actually be here next week and he's gonna be teaching everybody algorithms and maybe even some stuff with python yeah he makes me look like a baby yeah awesome so keep going but yes so after we have all of the images the face images and the nonface images we want to find the winning heart feature so which har features um align with a face and then on the reverse for non feet um for non um nonhard features we want to see which heart features don't match so like you're doing the reverse you want to make you want to find heart features that like do the antimatch and then eventually if you do enough reps then you can kind of understand the heart feature that determines the face versus not a face so this is how it works so we have if we go back to this you have a bunch of faces and a bunch of nonfaces so the way the algorithm actually works is i'm actually going to come out of here for now and can i zoom in no this is big enough though so we have to test every heart feature okay that's pretty much it there's only five but of course we can scale the size so what we want to do is you literally want to start here and check check check check check check and then go down check check check check check of course and do this across the entire thing and then again do it with a smaller one check check check check check blah blah blah and then go to the second heart feature and the third the fourth and fifth and you keep doing this on every single image until you can find which ones actually match your face so after um yeah every like i said every type of heart feature every size of our feature and every location cause you there's a lot of background noise my bad there's a um and every location of every image okay and each heart feature after it goes through the whole thing it'll give you a number and um this number tells you whether it is a face or not a face like what this heart feature will say so after this heart feature goes through this entire image okay or let's make a little bit bigger like there so this is this is the good matching one so after this goes through the entire image um each of these spots it's going to get a number so um the way it does this number is it takes all the pixels in the black and adds them up to one number then takes all the pixels in the white this box adds them up into one number again grayscale is useful because we only have to deal with one number instead of rgb and from there um you have a white number and a black number then you just minus them to get the difference like how far away are these numbers from each other like if this was if this was 0 and this was 100 then the difference would be 100 or this was 20 this was 70 the difference would be 50 they're 50 apart from each other so this would be a 50 and we could say okay this match is 50. so this this horror feature in this location on this image has the number 50 and then we give it a threshold of saying okay if if it's 50 or higher say it matches good for a face if it's 50 or lower then say it's not good for a face and so that's what we do so you say okay this hard feature goes all the way through and here and then at the end it gets a it gets a final number for itself and you and then you can say at the end of this you're like okay this hard feature in this location was really good let's keep this okay this is level one this was the best performing par feature um let's keep this because it was the highest like maybe it was like like closer to 100 or something and then um after you do that that was just one heart feature on one image you'd have to do this on every single image to um find it because it would also find the same kind of pattern on other people's faces because you know their eyes are going to be dark and their cheeks are going to be light too because that's what a face is and then after that you could be like okay this this is the winner that's cascade one that's level one so whichever heart feature matches the training images closest is our first winner so if you go back here um it matched this one like her eyes are darker than her cheeks and you can say okay that's a match that's the first winner then we would go to the second one and go here and and then see that this is another good match because the light nose plus the dark eyes and um we would do that too but of course you would have to iterate through the whole thing and then of course all the different sizes too you'd even go like tiny on every single image and all the background images too but that's how that works and eventually at the end because if you take this black segment add it to this black segment and then subtract it from this white segment you get a number at the end again and then if it's above 50 or closer to 100 that's the idea then you can say okay this is a pretty good match versus here where it would be like not a very good match and you just do this over and over again and you want to get like a thousand hearts harf on features that match right now we're only looking at two but you want to do this over and over again that's why computer's so powerful and that's how you actually train the cascade object detector or in our case the face detector but you can detect any object depending on this on the on the training data so that's how that works you have to test every cart um har feature and then after that after you've gotten a thousand winner har features you can take that and then put it all together into a big um machine learning algorithm for face detection so that's what this diagram here is so step three this is the cascade which is just the chain of heart features a chain of heart features this was the first best match this was second best third best fourth best all the up to a thousand a thousandth best and you would go through an order and if a picture passes all a thousand then you can definitively say hey this is a face if it only passes 900 it doesn't get to a thousand you'd be like ah it's not good enough to be a face so that's the kind of the the mark there that's how that would work so you take all the images that are faces all the images that are not faces um then you train it with uh these hard features you find the one thousand one or it can be any number is you can kind of decide like when it's close enough but you choose let's just say a thousand winner heart features in order and then we can chain them together into our face detector which is called a cascade classifier because you cascade from stage one to stage two to stage three all the way down to stage 1000 and then that is stored as an xml file which is exactly the data that is stored in here so in here it probably has a thousand of these little things so this here is one heart feature could be one heart feature like from this tag to this tag is one single heart feature that's the idea okay and then all these numbers are actually the heart feature we're looking at has the the brightness and the color and the location and the size of it and um you would go through and then of course there's like a thousand so you just fish the the image through here and then it looks for every single um thing in the image until it finds faces so that's why it's called a cascade classifier you or a hard cascade because using hard figures and then you're cascading down all the matches hard figures until you find a face okay so that's the explanation of how it actually works one final thing i want to um do is uh the way it actually will actually continue on in the slides can you full screen it please yeah so the nice thing about that is opencv does the hard work for us okay um opencv provides all the pretrained classifier um data that has the chain of heart features that best match the frontal face which is exactly what we downloaded remember when we were at the github i said download har cascade frontal face default they have all of that data for us they trained it already and they have that data um and then from there then after uh it's classified we can just pass a sliding window so a sliding window is just a window over the image or the current frame or whatever into the and pump it into this classifier and run it through all 1000 hard cascades and if it makes it past all 1000 it's a face if it only gets to 999 it's not a face that's the threshold and so yeah if it gets all the way to the end it's a face but if it doesn't then it's not so that's why it's called a cascade because you're like funneling down into what a face actually is uh one last thing let me just explain how that actually works so what you what we would be doing is you would have a have like a sliding window so you would have or let me make this full screen or actually i can actually just add a square can't i shape nice so let's just say we have a square here a question by evil namekian he said is it possible to use face detection into a flask application absolutely yeah i've never done it personally but i mean yeah you can you can tie you can tie this into web development you can take this and then you can somehow call the opencv code in your flask application um i mean you would like you could use flask like house something or house a web page but you would need some way to get the um opencv code running on your flask but it's definitely possible django might be better but flash might be cleaner but look into it but it's definitely possible just got it beautiful check it out that's homework for you but uh the way this works is you would take this little square pass it through all a thousand hearts it's like oh no this is not a face not a face not a face not a face not a face not a face and this is so tiny this would be not a face the entire time and eventually then you would check a little bit bigger not a face not if it's not if it's not a face but eventually when you got this big you'd be like okay not a face not a face match is 900 um blah blah blah matches nine um 950 not quite a thousand yet matches 950 but 950 boom and then boom it matches a thousand and then that's when you get the face so that's how it would work and then it says ding ding ding that's a face and if there's multiple faces then it'll find all of them in the current frame and that's kind of the full algorithm of how the face detection actually works in practice and actually like threw it through with the method numbers okay so now i want to show you the romano one interesting thing romano says you can adjust the sensitivity of face detection and he basically says that that phase classifier detect multiscale thing you have the last argument is actually for sensitivity so you can actually yeah change the scent sensitivity you're looking for yeah you can go here detect multiscale so you will have all of these parameters you can do um min neighbors scale factor so you can say like okay how many faces can be close to each other like do the faces have to be far away you know how we're getting random little squares here and there you can say oh if there's a little square next to a big square um prioritize that big score and just omit those little squares to kind of clean it up so you can kind of finetune it um that's the nature of algorithms you want to finetune things until they're working nicely but you just want to get it really close to working effectively and of course there's always a tradeoff of speed and accuracy that's always the case that's just how the universe works um there's always going to be that tradeoff so but yes you're correct go check it out you can play with all of these um things like scale factor is one by one by 1.1 by default midnight versus three and it explains what all these things do and there's even other things like set image that i didn't go over there's a bunch i mean it would take forever to go over everything but definitely look at the documentation for opencv but good catch that that that is correct uh now let's go to this um video so this is actually hard code visualization happening live so everything i just explained and everything we just coded this is what's happening after the har code is trained um this is actually how the algorithm goes forward okay so let's start here we have a lady here and as you can see like i said though the window will go across right and as you can see whenever the red the current red red square will run a bunch it through a bunch of har features so you can see it's spamming a bunch and it's saying okay all those a thousand heart features within this red square did this red square pass through all those hard features yes or no and it's saying no no no because it's not the face obviously the face is down here so it's saying okay is this box's face no is this face no is this a face no is this a face no by running through all these crazy hard features for each of these red boxes that's why it's going so freaking fast and it'll keep doing this um at for every for every face at every size until it finds the face so let's just speed this up and um we're getting close so as you can see the stage let's see it says 100 match here features 16 of 135 it's matching there's 135 instead of a thousand in this case and you can see that this is what makes up a face you can see the match is pretty close oh there's 22 stages so see how it's seeing seeing these red squares are a match and then at the end it probably averages all those red scares and the red squares to find the actual face and that's where those tweaking things that's where those tweaking those tweaking numbers come into play because you can be like okay if all these squares are so close together you can kind of approximate and just make it one square instead of six faces that's the same phase just be like math this is just one face with a bunch of square matches damn so this is cool it happening in real time and of course if it's multiple faces then it'll catch all of us people want to go people want to see the video they're like can you share the link of the video maybe you can just uh uh show us our description yeah just um just no but hit just hit escape for now so you can show the url and hold on give me one second just show the url and so you guys can pause search this up anchor divi car visualization yeah there you go and you guys can also just type in the url at the top there you go and that's that's really it you guys so that's the entire algorithm you guys coded it up you guys followed along with how it actually works mathematically why it works and how effective it works and the efficiency and all that and the tradeoffs and then also the extensions of it like you could do um actually start like recognizing people like we could distinguish like jeff bezos from elon musk or you could distinguish from coke cans and stuff like that if you if you do it enough depends how much you want to train the data um i mean train the algorithm how much data you want to do it but as you can see this is getting pretty see how it got bigger the red square is getting bigger because it's a sliding window algorithm which is how most of like selfdriving cars same stuff it's very very similar kind of idea and that's really it you guys so it's getting close to the end here and boom there at the end it got all the boxes and it approximated that that is the face um in the huge i love that that all of that is happening in literally milliseconds like that to me is insane can you open up the webcam again like i want to just see it happening in real time that is crazy yeah i did omit one optimization so um i didn't get into the nitty gritty math i'm just explaining the general idea because the math is really simple once you like if you know one plus one you'll understand the math i just didn't bother because it would it gets really indepth if you want to read it you can read the paper i'll link that in the description too but let's go back to the to the code and then you can actually see it happening with the um camp for this one so you might have to go at the top and change the mp uh for ah yeah yeah you're right you're right zero save that and run this and get that going and quasi text me a picture um text me a picture there we go to my phone to my phone because i'm going to pull up my phone i'm going to hold it up uh send you is it the webcam oh i see okay i'll send it to your slack right now got it okay cool so it's working in real time every single frame it's doing the sliding window thing all the way across the entire thing and it's doing it's doing the entire har cascade of all the har features that it was trained to within each of these squares until it finds this square at this size and finds my face and it's doing that in real time just because the computer is so dang fast so all right about okay i'm having trouble actually i got different ones so we can actually so real time we can oh wow my face and all of my faces it's kind of not getting cozy but see there we go it got me i want to close yeah dude it is looping through in real time that is insane it is literally looping through in real time every frame every size square across the entire image with all the thousands of heart functions and it's just like number crunching you know fast enough that's all it is wow it's really it's really cool and you get an appreciation once you understand how it works aaron this is how we gotta demo it next time we gotta just have like you holding like three phones one with your foot and then just like showing the three phones in your face at the same time that's like mindblowing one issue is going sideways doesn't work so it's not super robust but you can do that there's also side profile like there's different like this looks different than a frontal but you could like get your you could combine a frontal um machine learning algorithm with a with a side you can be like oh if it matches either of them then detect it you know then you can be like okay this or even a back hit you could even be like okay if it matches any like any anything and of course like different hairstyles mine might be different than a girl or a bald guy um but i mean eventually you could you could really detect anything and damn that's really it you guys face detection with open cv and python with the entire theory and math behind it so you guys understand it through and through uh hope hope you guys had your curiosity spiked and maybe you're inspired to go learn how to do selfdriving cars and work at tesla because that's what i want to do that is so exciting that was awesome dude thank you so much for that demonstration guys if you enjoyed this so far you know first of all drop it in the comments and like let us know if you enjoyed this and also go ahead and smash that like button because if you enjoyed this chances are somebody else will get value out of it somebody else will also enjoy it all you gotta do is smash that like button to get this video out as many people as possible and if you haven't already subscribed to the channel yup awesome i think that's it guys thank you hopefully this gave you value uh and taught you guys something new this was a mindblowing experience for me hopefully it was also a mindblowing experience for you with that said guys we love your face this is qazi and this is aaron what's up you see me yep and that's it with that said we'll see you guys in the next video peace out guys bye okay let's check out what we are going to do what's up guys so this is the app we're going to be building i just let this demo running so what we got here is uh some urban city driving some guy on a motorcycle there's some cars and pedestrians these guys are about to get hit and yeah as you can see the pedestrians are outlined in yellow and the car is in red and blue so yep this organ building you guys are python super excited as you can see here the cars in the background some girls crossing the street here it's it's doing a decent job it's not perfect but you know it's good enough so this is some guys this is some tesla right here i'm not kidding i'm gonna take a take a look at this right it's able to detect pedestrians it is able to detect cars which is just crazy right i mean it's like imagine basically you know you got your new tesla right and you have to figure out you know what cars in front of you right you need to figure out when to stop you need to figure out when to go this is a system that something that tesla would build for their cars like who is up to build a system like that guys huh tesla autopilot man elon we're coming for you guys elon exactly we're building our own startup company to compete with you elon there we go that's how we're doing it i mean that's that's the hope that's the hope exactly exactly so guys yeah it's like i said who's excited who's excited to build this drop that in the comments below this is an epic system again we are building an ai for detecting what detecting pedestrians and cars with bikes and car tracking tracking exactly pedestrian car tracking and this is what this is beginner friendly right this is beginner friendly yeah beginner friendly the app is not hard at all if you're a beginner you should be able to follow along pretty easily we're gonna be using python and opencv so opencv is an open source computer vision uh library so that's it just python opencv and that should get this entire app finished yep guys now before we get going guys so here's what you do i want you to make sure that we defeat the youtube algorithm system help us defeat the ai of youtube by smashing the like button subscribing to this youtube channel and of course of course sharing the video is that right yep yep that's it so if you want to see more stuff like this in your in your feed then help the youtube algorithm like this video and then youtube will show you more coding stuff and that's what you want right so yeah definitely do that yeah guys i mean look look how cool this is such an awesome tutorial look at this guys it's just like it's making boxes around the actual cars and right and it's able to detect them like in real time we're talking like split seconds we're talking milliseconds this is i mean maybe not milliseconds like it's pretty good it's not quite milliseconds i mean i mean i mean life is happening really fast right so it needs to detect really fast right yeah it's good like even like pretty like you can like see that pedestrian the distance for a split second at least yeah but yeah i'll just let this demo keep running it's pretty dope um i'll probably probably move forward uh oh by the way guys if you're interested if you guys like coding and um i mean to assume you guys are because you're watching this video then here clever programmer we um what we do is we teach people how to become developers like we teach them how to make a living from coding pretty much so we have we offer courses we have a python course called profitwood python that gives you a whole 15week roadmap of becoming a big beginner to expert and landing your first job or client with python so um check that out if not uh feel free to watch the free content youtube this is this video is free and we also have a free training if you wanna check it out too in the description they're both down there yeah other than that yeah that's that's really good we have a master master class training in the description below if you want to check that out and one thing i really want to mention we we recently had a really an amazing store from our students how about you tell this aaron huh oh yeah yeah this morning so or this morning or yesterday morning i think yesterday uh we had a student land a 90 000 a year ago um ninety five ninety ninety thousand dollar a year job uh so the story is she she lost her job through the covid she enrolled in our course she got a forty five thousand dollar at your job um through by being in the course lost that job and then a couple days later just happened just just yesterday she got a call randomly um for a job offer for 90k so twice as much really awesome there but just shows that yeah we do get our students results but check it out um but other than that let's get into the code not because that's what we've got here do it guys who's excited who's excited to build an ai system like this drop that in the comment below and we're gonna be doing this together guys we're gonna be learning this together so make sure to smash that like button subscribe and let's get into it aaron heck yeah man okay so um yep i think it's been going on long enough let me just cut this and clear my terminal and let's go to a presentation so i just want to give you guys a quick quick presentation a little bit of context before we actually start coding if you want to skip this and just skip right to the code feel free to jump to the time stamp the link will be in description uh this will take like five or ten minutes it's fine i'm just explaining um how the algorithm works and stuff so let's get started so card tracking with python okay uh with a couple of cute little emojis there so first of all we're only using computer vision so you guys might have seen some selfdriving cars that have like this weird radar thing on the roof of the car and like spins and stuff it's like like the google one like the google one yeah like the google one and i mean that's like using lasers and radar and stuff and it kind of sucks uh but we're not doing that we're only using computer vision because that's how human works you just use your eyeballs you don't have like a laser sensor okay so only computer vision yeah um and the reason we're doing that the reason we're doing that is because says so okay elon musk he's uh he's a my dad i coined him as my daddy daddy elon but i'll show you sure sure okay sure computer science only and damn tesla stock is up tesla stock is up so this this don't smoke though but not encourage smoking okay yeah none of us smoke anything exactly exactly uh anyways so yeah this is the little article that i found there's actually a video of elon saying it he's kind of cursed about it he's like anyone using uh lidar is doomed and pretty much the reason for that is it's bulky it's expensive it's not effective and humans can do it with just her eyes so a car can too okay so we're gonna be using computer vision just like this and not like this all right beautiful beautiful that's really it so let's explain how this works okay yeah let's do it man i'm i'm very curious oh what the slide didn't load oh there you go anderson now okay let's keep going all right so let me get rid of this zoom thing is in the way all right so step one so how does this actually work good question this is gone one second guys there we go what happened there that's all right guys that's okay we got we got we got you know there we go but anyways so step one is to get a a bunch of car images so what's supposed to be here is actually this image but in color okay so just pretend that that's there so step one get a bunch of car images that look like this step two you want to make them all black and white so that's what it'll look like and the reason we do that i believe nazi asked earlier is because when it's black and white it just makes the algorithm faster because there's less data you don't have to worry about color data it's just relationships and you can still tell that it's a car even though it's black and white am i right that's that no that is true they can still take a lot of things but yeah i mean yeah and if you have rgb color right so you have to have colors i'm guessing it's going to take a lot longer to process because it's just so much more data in there and so we kind of kind of scrap that and be like nope no we don't do that and actually enough actually if you look deeper i think tesla does the same thing so tesla when they actually go ahead and process their videos they process there you know the video that comes to cameras they turn that into black and white guys and we are doing the exact same thing like how epic is that you know yeah i think so i mean yeah it's the first step you've got to turn black and white because it makes things faster and tesla's all about being fast but and then step three once we have the um all the images in black and white like you get a bunch of car images make them black and white just like tesla then you're able to detect and track cars all right and basically the same thing pedestrians but i'm just using cars as the example here yeah so that's kind of the brief explanation of how it works like overall i'm going to go into a little bit more detail here for some context and then we'll get into the code shortly so so how does the computer train the algorithm like how does it go from this to knowing what a car is in each of these images how come it didn't put the red like square like over here where it was incorrect it's actually correcting all of these yeah how does it do that so very good yeah i mean the computer algorithm behind it we're just gonna explain it um in simple terms for people to understand so very simple we use these so these little box shape things are called a heart features and pretty much what they are are like little building blocks like little lego blocks that you can you can use to define um something and that doesn't make any sense but on the next slide i'll show you how it works so pretty much we just do this let me zoom here so i can show you guys so as you can see this is a picture of a car here okay a rear end view and as you can see this little window is is like a dark patch right and this little thing down here is a little bit lighter like this area is lighter and then again the shadow is a little bit darker so what we can actually do is we can take one of these hard features like we have right here this one like this one but inverted and we can actually say that this kind of matches right over here because it's kind of darker up here and lighter down here so we can say that this hard feature matches this location on a car better than it would match here where it's just flat or flat green up here okay so right and the way it does that is it just takes all of the pixels it just takes all the pixels in that black square and adds them up and then all the pixels in this white square and adds them up to one number which is just like a um the way to really boil down like to a single number how dark or how light that entire box as a whole is and then you can compare those two numbers to be like if those two numbers are far enough away from each other you can be like okay this this rectangle is a lot darker than this rectangle or this rectangle is a lot lighter than this rectangle and that's what exactly what's happening here because this rectangle is and so so it almost creates like a shape it also creates like a shape basically because if it basically if it knows right darker up top white at the bottom and then i can continue on doing with that it creates like a shape and and it remembers that shape basically right it'll just find that this match is pretty good when you're training the data and you're like okay this heart feature um of this size kind of matches the car pretty good right okay and then we can also say likewise like i said there's a shadow down here um and this one's a little bit bigger and there's a white strip you can kind of say that this heart feature would match down here because if you cover the shadow it's kind of darker on the shadow and lighter on the bumper so you can actually see that this is also a good match for a car and then these two in added together you can actually see that this dark window and the bumper and then this dark shadow and the bumper are kind of like these two hard features together kind of define a car even better than any of them by themselves yeah so you guys want to take a look at the shuttle at the shuttle below and if you look if you look at all the other cars guys they have a shadow below as well right so that's kind of how it kind of starts to recognize that so that that honestly is so interesting like guys who's like who's who's excited to learn something like this because honestly applying this into your real world into your life is so extremely important mainly because like like you know with tesla with gm with all these companies if they are going towards this they are going towards either autopilot so just imagine right so let's just imagine the amount of jobs that this will create right like it's just jobs with python with machine learning that's going to create in the future in the coming future and already is is insane bro yeah yeah the uber uber's going out of business man like ilama said that there's going to be robo taxi soon so i might have already said this but if you're if you're an uber driver you're going to lose your job so you should probably become a programmer instead because then you can program the cars instead of driving exactly like exactly profit with python descriptions maybe 10 years max and then your job is done so well okay we don't know about that but let's not be let's not be so harsh but let's continue on bro i got faith in elon man like what are you doing my daddy don't do that bro end this stream right now but anyways so that's how it works the idea is these two hard features match nicely for a car um and you can chain like thousands of these together and all added up all of those hard features added up will kind of match to what a car is so these are just two examples and um same thing works for detecting pedestrians so i'll show that next okay okay let's go to the next slide real quick so yeah the same exact idea with pedestrians you get a bunch of images okay of pedestrians you make them all black and white you want to run all of these hard features over all these images to find which ones match in which locations and then eventually you'll train it enough for it to be able to detect actual pedestrians so for example like if you look at this pedestrian here then maybe this hard feature will be really good like if you took this hard feature and stretched it taller and put it over you can kind of say that like maybe here is like a darker person or here is a darker person darker person darker person um and then you have the white the lighter areas on the sides okay so you can kind of use that that's kind of a good match also you can see her her pants are very dark here they're basically like dark blue or black or something you could say that this heart feature if it was a little bit stretched taller too and skinnier then you can say okay this our feature matches good and same here because usually people are wearing pants and shirts of different colors so you could say that that also matches a human yeah a pedestrian so and so and so again it basically it almost like creates a shape again you know it creates it uses all those black and white boxes it counts them in and it creates a shape and knows okay so if this this kind of shape matches right this kind of shape is created it matches a human if this kind of a shape is created it matches a car or a match as a pedestrian right so that is the interior what about this or a coat can yeah you know or or an apple i don't know whatever you want anything anything you know yeah but this is distinguishing apples from pears like that's a little bit trickier and then you probably need to keep the color in there at that point but i mean this is just a generalized explanation of course you there's always a tradeoff of accuracy and speed so yeah um it takes a lot more work to distinguish an apple from a pair than it does from a human to a car because they're just very different things sure that show that sweet man all right let's continue on yep that's it so let's just jump into the code let's code it up hey let's go guys we're probably like 12 15 minutes in but um again timestamps in the description if you rewatch stuff or skip anything yeah but let's get into the code okay guys are we still alive nice maybe we are alive we're all good we're all good we're all good we're all good let's continue on guys who's pumped to build who's pumped to build an ai system like this who's pumped to build an is system for a car and pedestrian tracking i'll jump put in the comments below and we're gonna we're going to get started right now got it all right guys so i got the code up here and running this is what was running the the demo code it's actually not that long as you can see it's just a few lines all this here was doing all of that it was taking in the image um not the image it was taking in the um the video of the the guy the dash cam and the pedestrians and then it was finding everything detecting everything and displaying it to the screen that's all happening right here right okay okay so let's just jump into it we're going to start with just an image and then we'll go to video a second but yeah feel free to follow along so if you guys don't have vs code you're going to want to download vs code you're probably going to want to pause this video and download it because i'm going to be going a little bit faster but download vs code get it all set up and that's it next what you're going to want to do is you're going to want to create a python file um you can call it whatever you want but i call the car and pedestrian tracking dot pi okay this is the one i had before i'm just going to be copying pasting code um over to show you guys how it works i don't want to have to type it out it's the same thing pretty much but you want to start here okay next thing you want to do is install opencv so you can do that through the command pip install opencv dash python okay and if that doesn't work then try running pip install the same thing but just add headless at the end okay there might be an issue there um one of those should work if you're running on a mac or a linux computer if using linux you're probably already a badass programmer so you don't even need to you need to know this stuff but again you can just do a google search like how to how to install opencv on your computer if if these don't work you're going to kind of have to figure it out yourself because i can't help with every error but like i said we're about to cost 100 likes so let's keep liking the video guys about to cost 100 likes like the video let's and let's continue on yeah uh where was i uh yeah oh yeah install opencv so once you have that installed you should be good okay um the way you can the way you can test that is you can just put python okay and you have your little python of arm here in your terminal and um oh if you know what this is this is terminal so you wanna go you can do command space on mac and then this little spotlight thing pops up and type in terminal and just hit enter and then it'll pop this up and this kind of tells you um gives you access to your computer so if you type in python then you can do stuff like hello okay yeah and then it'll print hello whatever says there or you know nice nice nice nice daddy oh my god elon is not your dad bro come on man you look very different no no no don't even think about it don't even think about it no no aaron you think about it back on track so to make sure you have opencv installed you can just import cv2 which is short for computer vision 2. and if you hit enter then you this will happen nothing will happen it'll be fine if you get an error it means it installed incorrectly so just make sure that when you run this it just goes to the next line there's nothing happens that means it's installed correctly then you're good to get out of python you can just do control d and it'll go back here and i'm just going to type clear so that we're back to the terminal uh but once you have open cv installed and you have your python file created and you have it open in vs code we are ready to start coding okay okay so now guys guys looks like edwin edwin uh just gave us a one euro super chat edwin thanks so much appreciate it and let's continue on yeah i think my lunch now right now i know right i know anyway so let's just start with a simple um code completed so this is a little thing i like to do i put this print statement at the end of my program so that i know if it prints that the whole program completed without any errors so let's just run this first so this is the first thing that i'm going to run go to the terminal make sure you are in your desktop so pwd stands for present working directory and as you can see i'm on my desktop if you're not then um like if you're not if i'm not my desktop let's say just i'm at my user's user file then you want to put in cd which is change directory and then just type desktop just like that with a capital d okay and then once i do that then i am in desktop okay then once you're in desktop that's where i have my files housed or if it's on if you're if you have all your files housed in a folder then you got to go there instead of desktop but for me i just have it on desktop right here that's that's that's that that's a messy messy file structure bro but anyway are you teaching them how to code like i don't know how to keep my computer organized this is free free content you know all right all right all right okay this is aaron's stream rogue off the stream knives i need you to help me anyway so let's run this code so the way we do that is we just write python because this is a python program and then we wants to run um car i think i gotta put dashes car there we go so car and pedestrian tracking dot pi okay these little slashes and it's a space because it's kind of silly when it when there's actual spaces like i had underscores in the other file but ignore that yeah and then and the way by the way and the way aaron was able to get that is he simply started with so he typed in car and then he pressed tab right away right so he pressed tab and that's basically right away it autofilled because you know we got autofocus yeah it tried to auto find any any files that has car at the beginning and then it gives you all the options exactly you can just type it all the way out maybe just use underscores because then it gets sort of this nasty complicated thing with this stuff if you just use underscores and all your file names and you can just type out this exact thing and then you won't have all this weird stuff it'll just look like it'll look like like that yeah yeah okay it looks nicer nice but uh this video will just use this okay that's fine so when i run this because it says code completed then we should see code completed pop up here and voila it does so that then okay surprisingly because there's just a print statement but like i said when you're running opencv you want to run import cv2 make sure you save and if we run this now then and this prints out we know that this is working correctly if this doesn't print out and that means there's an error here importing and then we'll see it but i mean i think it's going to work so you can press the up arrow key to repeat your last command and just hit enter again and as you can see no errors so guys and that's it our program has been completed thank you very much no no i'm kidding get out of here all right so let's start with just detecting cars and images all right so i have a little mini program up here let me just comment this out it's a comment out in python um you can just use triple quotations like that and everything everything between will be commented out and these and there we go save this and here we go so it's even shorter for just an image but we're going to go through all of them one by one and explain how it works okay so let's start with this all right so first thing we're gonna do is we're gonna want to um decide on an image of course if we're gonna be detecting cars we need an image that has a car in it to detect okay so i just have a image on my desktop called car image.jpg right here car image.jpg this is the same one that was in the slides i was using i just cropped it out yeah the same exact image and we literally and we literally and we literally got guys we really just got these images from the internet so don't think it's anything special it's just an image from the internet and we're going to yeah yeah yeah yeah kind of videos i'm actually using in this in this tutorial the links to the youtube videos i stole them from are in the description so credit to those people the guy on the motorcycle he has like 2 million subscribers for riding his motorcycle around cities and like revving his engine at hot chicks like it's pretty cool but all right all right okay i use a video from him and that's where i get it from so this isn't spoofed i'll go check it out there you can also use a youtube downloader to get the videos yourself if you wanna use the same videos then by all means do it so this is the car image.jpg okay right here and um that's it so the image file we have is just car image.jpg very simple okay and let's just run this this is called unit testing every time you write a new line of code or like a different different group of code i'm a little bit ocd and psychotic and do it every single line i run it to make sure code completed prints because if it doesn't that means the line i just added screwed something up right okay okay called unit testing because you want to test every single unit of change in your code right um even you can be redundant even if it's like as simple as oh i deleted something like you maybe you thought you deleted the d but you actually deleted this that's going to screw you it's going to it's going to break the code true um but yeah pretty selfexplanatory that's the importing the image there second thing is we are going to want some way to be able to detect and track cars okay and pedestrians but let's just start with just cars okay so let's start here so these are um our image we put in some comments because comments are good it's good coding practice and our pretrained car classifier okay so this is a little bit wordy but all it is is like i said when you when you train the algorithm with the hard features and you have a big list of heart features that defines a car when they're all added up like the dark boxes and the light boxes all of those added up define what a car is like it kind of captures the pattern of what a card looks like on in an image or in a frame of a video then you encapsulate all of those numbers and heart features in a file an xml file so um i think yeah so what this looks like i can actually open it right here okay i'll take a look if i just open this up then this is what it looks like so cartesian xml so all this is this is the result of training the algorithm this is what the algorithm at the end spit out after you put in thousands of images oh by the way i totally forgot the car images the data set that that i stole sorry guys we borrowed the hey i got who you bought right now i'm gonna i'm gonna die on the stream you got some water you gotta get it okay what's up get some water you know yeah i got some right here actually so okay i'm gonna drink while i'm talking all right cool cool should be awesome conquering hiccups okay anyways all right so we're not actually going to train the algorithm ourselves on this on this video that takes way too long because like it takes like like a long time for a human to learn and build a habit it takes a long time for a baby to understand what a car and a pedestrian is the same way it takes a long time for a computer to learn what a car is because you have to give it thousands of images and run all the thousands of heart features at every location of every size of every orientation until you eventually decide on the hard features that match nicely for a car and then once you have all those then you're good to go but the end result is pretty much this okay so this is just like some encoding i actually don't know how this works exactly it's just the xml xml encoding is what they use but the idea is you can generate one of these files um and it has all the numbers like these numbers are like different coordinates and different colors and different thresholds of like okay is this a hard feature is this good enough it needs to be above this number below this number and it just goes through the entire list of thousands and thousands and thousands oh yeah guys cause he called me i don't know if you guys can hear one second guys oh we got another donation dope it yeah i'm not in the chat guys i think we've overlooked that but somebody somebody uh donated uh are we still live nos yeah we're live of course all right yeah let's keep going let's keep going there's no no i was just i was just talking with maybe we were like you know yeah yeah yeah all right guys we're back on track somebody else donated i think we missed in the chat because we're focused on the code so we overlooked that but don's keep an eye so whoever that was i don't know their name but appreciate that very appreciate that appreciate the gesture and where was that yeah so the so this is the long list of hard features it's gonna go through all of these and if the image passes all of these you can say okay yeah this is a car awesome or like a little patch of an image if the little patch passes through all these and it's it's a yes all the way through and it it counts as a car if not it's not a car and then that's how we know where they are so you're gonna need to specify this file because this is what's gonna tell us what a car is and what a car isn't and the link to this file is actually in the description so you can just go download this this is just a url just go file save as and you can download this um it's actually just called car.xml but i added a detector for for the video so download that okay that's explanation of that a lot of explanation for one line of code but i don't just want to be like hey just download the work like nah i'm gonna explain i'm gonna explain how it works so they have an overall understanding that's the proper way to do stuff okay we're actually programmers i mean we're lazy half the time but it's fine um all right so moving on um now the next thing we're going to want to do is we're actually going to want to create an image within the opencv format so this here of course this is actually just a string okay car image is just a string in python but we want to give it to opencd remember cv2 and actually read the image so that opencv can actually use it correctly okay so all we're going to do is we're going to call opencv.imageread and pop in the image file the name of the image file which is just car image.jpg again car image.jpg right here so we're reading this in our program and from there we have it in here image so that image is actually now in this variable here in our program okay so why don't we just show uh i believe so the image image image read file imagery file basically like takes in the image and all the and it processes it as like data is that what it does right yep so it just reads it just reads in all the pixel data from that image file and then reads it into some double um multidimensional array so you know like a big array a double array of an array of arrays so that every pixel has its own data and then it's just all encoded into this one variable here image right right right right gotcha gotcha and now what we're gonna do is we're actually just going to this is not a face detector this is a car detector okay we're going to display this image so there is a um we're also going to need this just once so so these two lines of code that we're currently working on we got the image in our program next we're going to need to show the image so opencv has a function or method called image show and the first thing is the name of the window so the name of the window like here is car and pedestrian tracking.pi that's what'll pop up there and then the actual image won't show okay okay that shows up and then in opencv this basically just means display so opencv.wait key you need to you need to run this line of code so that it actually displays otherwise it'll display for a split second basically one frame so like literally a split second then it'll disappear but this says wait until you hit a key before it disappears so it kind of like this displays for a millisecond but this makes it pause and so you need okay okay okay okay it's kind of just like display by the way by the way i just want to say thanks to lars lars donate looks like a euro as well so appreciate that man and we got sony pete guys we got so many people in the comments between abdullah between kristen between tracks between kent usa usma vicky right joshua so many of you guys amazing and so excited in the comments i'm excited that we have such such a great community man literally so yeah i just wanted to mention that because you know so many amazing people that's yeah well let's go ahead and continue on awesome you guys so let's just run this code now all right so again we imported opencv we got the image file we have our car classifier we import the image okay okay um and i just want to show you the image now real quick okay to prove that the image is actually showing up and is within our python program so this will actually pop up a little window with the image and that's it it's not detecting anything yet it's just going to show the actual image so boom right there as you can see it says clever programmer car detector and that's the image right okay okay and remember this this title is from here okay so that's that all right now let's just quit out of this so it's waiting for a key press if i hit space bar or any key it'll just quit out and now we can continue on all right okay so so now we're going to be coding in here because of course at the end we want to make sure we're displaying the image at the end um but now we have our image in our file okay so now that we have the image and we have a classifier how do we actually find where the car is in that image because i mean there's a car here there's a car here there's a car all down here i mean granted these are half cars so it might not detect these i don't think it will but these full cars it definitely will okay well kazi's calling again hey what's up quasi live stream is dead oh stream is dead now uh no you're not mute no it's running is it is the stream up guys in the comments can you guys it's running it should be running guys right it's running you guys hear us it's working yeah it's all good guys always good got it it's all good it's working now all right we don't want another uh dead dead livestream you know you guys it's terrible because it keeps getting cut off but yeah i think we're good right i think we're good yeah we're good we're good we're good we're good we're good we're good anyways so this is the image that's going to be read in and from here we want to be able to classify that this right here is a car so it's like if we pass this little rectangle of the image through that whole xml file and if it gets all the way to the end it's like okay cool this square counts as a car and this square does not count as a car okay okay that's what we're gonna be doing so the next step to do is to actually create our classifier so that's pretty simple that's just this line right here let me show you guys i'll copy and paste this and we want to create our car classifier so all it is is we run this function opencv.cascade classifier because again we're running a har cascade algorithm that's why it's called cascade because there's a cascade a long list a long chain of heart features that we're going to run it through and classifier is just classifying something as a car or classifying it as a pedestrian or classifying it as a face or an apple or whatever but in this case a car and the classifier file is what we just specified the xml file file so we just pop that into here and so opencv we're just going to create a classifier from that file and then we're just going to call it car tracker because once you have a car tracker now we can apply this car tracker to this image and we can actually find where in this image if there is a car or not so here there's a bunch but it might only it might only detect a few but that's the idea okay so in an image we have a car tracker now we just want to apply this car tracker to the image and then spit out the rectangles okay right so let's move on um i mean again this doesn't show anything we just have the car tracker created if i displayed it it's just gonna be the image again so i'm gonna move on like i said in our presentation we do want to convert it to black and white though first so let's just do that next and the reason for this is because it speeds up the algorithm makes it essentially three times as fast because instead of three colors rgb we can just focus on black and white that's it so you're simply converting basically from from color to to to to black and white yep okay question if you guys wanna why why don't why don't you do why don't you do that before you classify is my question like why don't you do that before the classifier i mean you're just creating it yeah we can shuffle this up it doesn't really matter it doesn't matter okay yeah doesn't matter i mean this might make more sense because you have the image then then you change it to black and white and then create the classifier gotcha i mean we could even do this you know we could like keep away or different so like we've got an image here yeah and then we read in the image and then we change it to black and white and then we get a classifier and then we create the classifier and then but the point is what we want is we want to have this uh classifier and this a black and white image ready so once we have both of these we can do this in any order then we can pair these together and actually get the images okay nice so i mean i guess i'm gonna put it back here because i like keeping all of the static stuff together because these can change like you can change the file very easily here or the file very easily here just by changing this and all this code remains unchanged right all right so here we go we got somebody asking how can i how can i donate oh my gosh some of you guys are asking how can i donate dang i really appreciate that guys that is so awesome my paypal is my my venmo my only fans like i got everything just faith all of that you know yeah my snapchat no um i actually don't know how you can do that do you know nas i don't know i think kaz has got it kaiju's got it he's got taken care of all is good yeah cool yeah or we can hook you up with something maybe there's something uh a itch like a fighter course something i don't know yeah it's something up who knows anyways back to the code you guys so once you have the image right in you want to change it to black and white like we said because it speeds up the algorithm and you can still you can still tell what a car is and what a car isn't in black and white images so it's totally fine um you want all the improvements you can have there's always a tradeoff of speed and accuracy pretty much in everything in life um so algorithms are no different so you kind of want to change like again like an apple and a pair if you go black and white it's going to be much harder to distinguish the difference um but a car and a human very easy to distinguish okay right yeah that's true the way we do that is opencv you just there's a function called convert color so all you're gonna do is this allows you to to convert color to black and white it allows you to convert black and white to color and there's all different kind of color encodings i'm not going to get into crazy details but the point is this allows you to convert the color stuff of an image to whatever you want i could even make it all red like have only the red channel it'll look really red and stuff like that all right so i'm not going to demonstrate that here um but well let me see actually now i don't i don't want to go down that rabbit hole um the but yeah the point is you can you can convert any the color of any image so we're going to feed in the regular color image here and then all we're going to do is we're going to say we want to go from color from bgr to gray so bgr is just rgb backwards in openc um rgb rgb is like you know the color of a pixel everybody should know that if you don't well now you do um then they just use it backwards so it's bgr a little bit confusing i don't know why that's so weird that's that's so weird like how about it's like the stan was like but wait if you didn't know if you didn't guys didn't know rgb it's red green and blue those are the three main colors that all the other colors are made up of if you didn't know that so yeah that's that's something interesting for you yeah yeah each pixel has a r uh a red a green and a blue light and then it just like makes the brightness of those three different levels and the combination of those three levels can make any color pretty much if they're all max white if they're all off it's black okay for rgb but for gray it's just one number there's no there's no three channels it's just oh is it zero to like a hundred or something yeah yeah okay from your 100 like what's the brightness that's all it is so we're just converting rgb to gray and once we have that i just call it black and white because why not now we can actually display this black and white image so let's take this and in our image show down here which was showing the color image before let's just change this to the black and white image and of course we need this to display for longer than millisecond and this should actually give us the black and white image okay so let's just run the same thing again again your up arrow key will allow you to go to the last command you ran in your terminal hit enter and voila we have a black ops okay interesting guys give give some give us aaron some round of applause in the comments below i ran six lines of code you know i've been coding for eight years and we converted an image to a black and white image that's what we just did this is all i learned in eight years guys exactly eight years in college eight years in college you know grad school pursuing masters and everything um anyways so that's the black and white image so now that we have the black and white image we can actually apply the card classifier to that image and then we can get the um the the car um in the image out okay yeah so the next thing we're going to want to do is actually detect where the cars are in the image so let's run that next okay okay so i'm going to got it are you trying to figure out what line or line to write this on no no i just kind of want to like submit like these are files shut up it's just like wait don't run down this line or this line guys well guys drop in the comments below what what line should should should aaron write write the piece of code actually cool good question who would win the fight a good question i mean drop that in the comments drop it down in the comment below i'm very i'm very curious we'll see we'll see we'll see one day one day anyways uh yeah so the way you you detect things in opencv is once you have a classifier object okay a car tracker you can apply this to an image so all we're going to do is we're going to say car tracker and we want to detect multiscale so what that means is detect cars of any size of any scale okay so we're going to detect cars it doesn't matter if the car is big or small it's going to detect it matter what or even if it was even bigger it'll detect that too okay got it got it got it got it editor is this guy this is using vs code guys okay visco so like just download this code is the the most the most important one you'll ever use as a developer so yeah it looks like what yep oh by the way um if you guys want to have the the the documentation for opencv um i'll link that link in description too so you can check all these files because there's a lot of cool little things you can tweak i'm not gonna go over all them extensively i'm just getting the app done uh but detect multiscale there's cool things you can add on to the end to kind of like tweak the algorithm to make it perform better or worse yeah that's linked in the description i'll just show it right here though detect multiscale so this is the documentation again link in description just click there it'll zoom in guys yeah cool cool link in bio link in description instagram i'm used to that you know i know i know you dirty millennial okay listen let's just let's just let's focus on the work here okay [Laughter] like i don't like those no boring videos boring live streams anyways so um yeah detect multiscale so of course you take the image in first which is what we were doing here we're just passing in the black and white image but then there's other stuff you can add on there's all this cool stuff reject level scale factor minimum neighbors you can read all the details here if you're interested but you don't need it for the app to work i'm not using it so that's really it so detect multiscale you just plug in the black and white image with the car tracker that we got again from this xml file which was trained with the images and the heart features so that's the whole entire holistic view and once we apply this tracker to this black and white image it'll pick out all the places in that image where there's a square that contains a car and it'll give us the coordinates of all of those cars okay okay so why don't we just print this out and see what the hell is in cars okay okay guys this is this is getting interesting guys this is getting really interesting all right let's see let's see let's run it and boom so again the black and white image is popping up because i still have these two lines of code down here running okay but okay that i printed out cars so all cars is just the numbers yes relative to that really yeah i mean uh i guess it's only taking two cars in this we'll see exactly where they are in a bit um i already know ahead of time because i ran this before but it detects this big car in front and this little car on the right reason being is because these are all half cars so it's not quite smart enough to get the half car well actually actually actually that's a good question guys guys which cars do you think it will actually detect let us know in the comments below like okay man yeah i know you give it away but like this is come on gotta not give it away so easily you know but easy mode i mean like it's impossible to predict bro like not even us you just run the program and see what happens like come on yeah but uh yeah but anyways so yeah it's gonna detect this one and this one okay so there's only two spoilers but these are the two these are the two cars so these are just the coordinates of where the car is it just kind of like defines the square that's all it's doing okay okay so there's two cars one car here one car here if there's ten cars like in the video stream there's going to be like 10 of these in here instead of just two right all right so that's really it let's go back and now all we need to do is once we have these coordinates we just print out we just want to draw a rectangle around that car so we can actually see it because we know where it is we just can't see it because there's no rectangle drawn on the image yet wait so those so those numbers were actually rectangles is what you're saying yeah they kind of define the coordinates oh this is guys yes this one yeah interesting okay okay okay okay okay okay the top left point the top left point of the of the rectangle and this is the width the height see it's the same because it's the square this is the height it's the square yeah yeah that's all interesting okay okay okay gotcha gotcha gotcha gotcha yeah applause for that this is really cool stuff you guys don't hear aaron you don't hear the sound of the chat you know i'm in the chat i'm gonna chat aaron you don't have you you don't have the center fox but we have some amazing sound effects going on in the background just so you know it's amazing sound effects yep yep yep yep you'll you'll see it later don't worry that we'll see you later oh in the stream okay i thought i thought it was like you know it was like dying outside in my background but there's nothing happening bro yeah awesome all right anyway yeah so this is just like because they're squares by default um we're detecting things within a square so this is the width and height of the square because it's the same number within height square and then this is the left the top left point in the image of where it is so from here we can be like okay this is the top left point and i just draw a square of these dimensions at that point going down to the right and that's actually where the um the car is in the image so there's two in this one okay so we have top left point and width and height okay if you guys watched the face detection video a couple weeks ago very similar we're just detecting different things and applying it differently but um same idea okay got it um so guys who's ready who's ready to see some squares and detection squares huh who's ready you guys ready you guys ready drop in the comment below and aaron let's see it let's see it bro got it all right you guys so um okay it's gonna be what's up e uh bgr so this is actually wrong let me okay let me explain this i just copied and pasted um actually let's get rid of this for now i don't want to okay ignore this loop for now actually let me just get it straight up delete it because i want to explain it line by line all right all right all right oops let's go logan hey so here we go here is the um the line to draw a rectangle so opencv allows you to draw a rectangle on any image very straightforward and simple so it's just called dot rectangle so opencv opencd.rectangle and then it's like okay what rectangle of what size what color what thickness and where do you want to draw that rectangle so this is all these specifications here and of course we have that data within cars so if we have the data in there then we can just print it out here okay but where you get the x and the y those are the question where is the x and y coming from uh from here so we're going to get that data out of here so remember okay okay remember we have these here so this is going to be x it's going to be y y it's going to be width and this is going to be height and then from there we can just x y and then x plus width and y plus height and then this is the color this is the color of the rectangle and this is the thickness of the rectangle oh that makes so much sense now guys actually that's not that's not that's not so bad at all guys you get this like drop down below do you get that like it's actually not bad you're simply drawing a rectangle with x y coordinates and you're saying here's the height and here's the width like that is pretty pretty interesting and it's actually not that bad to understand as well you can do it like we can do it you can do it too trust me if they watch their face detection stuff this is very similar they'll probably breathe through this right now just watching us bigger which is awesome exactly that was that was that one was with kazi you know so a little bit hard to make fun of him to make you know yeah he's more of a challenge anyways um so let's just actually prove that this is is working so we're gonna want to unpack um uh this so in cars it was actually an array right so there's an array here and then within the array there's two arrays within the array so let's just grab out these two arrays okay okay so this is going to be array at index zero and this is gonna be arrayed index one okay because there's two elements in this and there's a list of numbers in there okay so all we're gonna do is say um i guess cars at zero so this would be car one okay okay and then why why car zero cars let's just ignore the um let's just ignore the the second car for now okay okay so car one equals cars zero so if we print out if we print out car one car one just like that let's go here run it again as you can see we have just the first car so 375 375 that's what we're looking for and from there we just want to get the um x y within height so what we're going to say is we're going to unpack this i'm going to unpack this this this list here and say this is x this is y this is width and this is height okay okay seems to you guys you're still with us guys guys give us a thumbs up if you're still with us this is kind of like it's all coming together it is honestly not that difficult give us a thumbs up if you're still with us and aaron let's go let's go ahead and start seeing you know the result of all this hell yeah so um all we're doing here is we're unpacking this okay so car one again is this these four numbers and we just want to pack these four numbers into these four variables x y and height okay and then from here now this code should work so x and y is the top left point okay okay we have the we have the image you want to put it on the color image not the black and white image we want to color on the color image um and then put the top left point xy and then the bottom left the bottom right point which is going to be x plus width and y plus height okay that's how the graph works um and then from there this is just going to be uh should be red color so bgr remember instead of rgb so b so blue is zero g green is zero but red is maximum 255 is the highest value you can have so we're creating a rectangle basically that's it yeah a red rectangle of thickness two two pixels thick on this image at this top left point and this bottom right point that's all it is because that's all the rectangle is it's two points thanks and then you just the rectangle between those two points okay so let's run this and see what the heck happens guys ready actually nothing's gonna happen um so we drew it on the color image not on the black and white image but we're still displaying the black and white image so let's just display the color image which has the rectangle drawn on it now okay so now it should work so again let's go i got the perfect gift for it look at that oh look at that oh look at that you don't see it aaron but trust me we see it it's hilarious i'm looking at my code yo but i'm appreciating funny or something i'm making very much fun of aaron guys give aaron a thumbs up in the comments guys this is so epic look at this we already we did we just detected we actually just detected a one car like how crazy is that with how many lines of code directly directly in front of you oh i don't know one two three four five six seven eight nine ten eleven twelve thirteen lines of code fourteen lines of code guys thirteen bro learn to count you count okay you learn how to count okay i'll i can't find it minus one all right guys yeah that's just epic stuff so okay we got one rectangle now my question is how do we get the second rectangle if you guys know how to do that drop down the comments below and a lot of you guys are are a lot of you guys are like whoa let's go we got abdullah in the house we got harsha like yeah we got logan whoa we got oh man you guys are pumped for this look at that you guys are pumped i love it like this when this stream is done definitely go check out the face detection too because it's similar but it's a different application and it's pretty damn cool yeah yeah yeah sweet but this one for car and pedestrians all right so let's see let's see how do we go ahead and actually like get into the second car yeah okay cool well first of all why don't we just change this because this is a very easy change we're currently looking at the first car why don't we just get the second car instead by changing so here instead of grabbing this first car we just grab the second car and let's just draw the rectangle around that we simply do that by just changing this to grab the second car instead of the first car so second car right and let's change this to two just to be clean about and that there should just change all of this to the second car instead and we'll display it to the screen so let's just run it let's see it ready you say bro i'm not kidding abdullah abdullah is like in the comments like damn aaron and nas seem like siblings fighting yeah pretty much i mean like we spend pretty much every day together working on stuff all the time coding like we practically live together it's kind of annoying yeah i know i'm i'm i'm an artist that's it yeah yeah i hate everybody too much too much but anyways let's continue on we're here to learn right let's go yeah yeah yeah um so there that's the second car and like i said in this in this uh image this trained classifier is only good enough to train to like identify fullon cars from the back like this um these half cars you can't actually get them but actually if you trained um something to detect half cars like the right half of a car or the left half of a car you could actually find a way to detect all of these as well but you'd have to train it even further yeah and so on or like the bottom half of a car you know something's being but right now like this pattern is what we're is what we're checking is the the full a full back of the car right okay so now the point is all we want to do is instead of manually going through the array like this we just want to loop through all of them and draw every rectangle on the image for every car that we find okay so that's that's what i had before i'm just gonna have a a loop and this is gonna make it super super simple so let's just start from scratch i'm leaving this here for reference but just ignore just pretend we deleted all this okay so what we're going to want to do is just like in cars so in cars which is an array of an array of arrays we want to or is it an array of arrays we want to iterate through every subarray so we would iterate through this first one and the second one and the third and fourth and fifth if there's any of those so basically we're saying um in cars you wanna take out the xy and the width and the height of every one of every list in there so actually i think if i just if i copy and paste this it'll be a little bit clearer yeah yeah so i think and that's another thing and the thing sorry let's cut you off so really so one important thing guys to mention one one important thing guys to mention is the way that this is works the way the whole y w h right this right here is interpolation like interpolation or there's a special name for it where basically it will take the object that's in cars right it will loop for that and it will basically grab the x y the width and the height out of those numbers right so it will abstract those numbers from those different places and so that is actually in python right i think i'm not sure what it's called interpolation but what it is but you're getting super confusing but no no no but but it's important because they're like okay where's this x y w h coming from right but because here's the thing it's looping through one single object so that maybe i can do like a screen brush on show screen brush if i can do it so yeah right there right so this is the first object right so this first object is going to be on here right in here and it's going to map to the x to here the y to here the w to here and the h to here and you don't see it but i'm drawing basically on your screen so yeah yeah so yeah that's that's the really cool part about python and javascript actually does this too but i just want to explain that and so that you guys know but anyways yeah let's keep going awesome yeah yeah i have the stream up on my phone looks like it's still live yeah we're good we're going we're in the bottom right that's we got 300 people in the house yo wait wait wait 300 which way are you that way can i punch you wait i think i can wait wait wait there we go go there you go hold on hold on hold on hold on ready punch hold on no no no no no no no no beat him up man i wish i wish i wish i wish we could like yeah yeah i wish there's like a real you know maybe you can punch you yeah that'd be good and then you're gonna get in the cage bro let's go i'm ready i'm ready i'm ready man i'm ready have you seen the fight club have you seen warrior with tom hardy steve is like please punch him if he was like please punch him wait punch who punch who's the question each other bro they want to see us in a ring it's like logan paul in the ksi guys who wants to see a live caller who wants to see a live call like that or conor mcgregor in uh mayweather we can do it like that yeah but yeah let's let's keep going we're here we're here let's keep going bro yeah anyways so this is like the longest explanation of a loop ever yeah we're having fun you guys i mean we're having fun um so yeah we're going to loop over all these and then within each of these we're just going to unpack the x y w and h okay so that's all that's happening there and once we have x y w and h we just want to draw all of those rectangles on the screen we can get rid of this hardcoded so we're going to iterate through every um pair of coordinates in that list we're going to get all of them and then it's just the same exact line of code here we're just going to draw every rectangle on the screen but actually what i want to do is um a screw it that's fine what nothing nothing there's a little little flavor styling thing i was going to do but i'll do it later so right here this should work so if we run this this will actually loop through both cars and draw both rectangles both both squares so why don't we just save this and give this a run um so we just give this a run up arrow and hit enter and tada boom oh upper left hand point then we know the width and the height and then we with the width and the height and this point we can calculate this point so it's just boom boom red pixel width boom boom red two pixel width and bam that's it and that's it guys video that's it and then for videos you just want to do this for every single frame of the video over and over guys guys if we just did this for we just did this for a picture guys who's pumped to see this for a video drop that in the comment below aaron are you ready are you ready to show this in the video because i'll be epic oh girl i get up all night coding and i just i'm kind of like bored you know but uh hey let's go stuff is awesome like i'm gonna send this video to eli musk and be like adopt me please you know like uh you know like big bang theory yeah howard howard everyone's yeah yeah that's basically but you know pay me money pay me money i just i just did this for you you're welcome you know you're welcome yeah yeah or maybe he'll hire me who knows i mean maybe one day i'm not sure i'm not sure about it i don't know i don't know why you hired but aaron but anyways yeah i'll be a mma fighter like joe rogan and then i'll have elon musk smoke beat on my podcast oh man abdullah abdullah abdullah was like i put all my bets on nas thank you abdullah oh really all all his it's unknowns i think knowledge would be too scared to hit me i think that's what happened to too scared not sure about that i'm not sure about that whatever whatever okay okay all right let's continue on let's see let's go now that we have it done for one image now it's as simple as getting it into a loop okay all right so um i have that here uh it's pretty simple to add it the only difference is you have to read a video in instead of a um a video in instead of an image so let's go up here and actually change that so instead of image it's going to be a video um video okay so i have a video on my on my desktop called tesla dash cam accident so this is actually real dash cam footage from a real tesla that was running autopilot and avoided an accident okay so let's just um here tesla dash cam accident okay okay okay and this is just this is just a video basically you got from somewhere but like from youtube i think right in the description yeah it's in the description yeah yeah it got you know like selfdriving tesla so as you can see this tesla almost it like auto drove and like got out of the lane and safely did that so we're gonna be detecting all these cars in this video okay it's almost over so that's it that's the car i have i trimmed it to that just that little clip but that's the first clip of the video in the description if you go check it out okay so that's first thing so instead of an image we just wanted a video okay and um from there so all the video is is just a bunch of images so we can just grab out each frame of this video and just apply the same thing as we did to this image to every frame and then display the rectangles on every frame and just loop forever into them okay so let's do that okay so i'm really interested to see how this one this actually works out okay cool cool yeah um i'm gonna hey what's up caesar caesar in the house hey what's up copy paste it you know oh yeah that's the best best way especially the code guys i would just copy and paste don't ever don't ever create your own code i'm kidding by the way i'm kidding so um yeah i'm just taking a peek here so yeah we need a while loop and everything so well i'll type out this one because it's because it's short this is the first line of code i'm actually coding on the stream i copy and pasted everything up to this point okay okay but pretty much what we're going to want to do is we're going to want to have a while loop okay not caps supposed to be and we just want it to run forever okay because the video might be if you're driving a car you don't know how long the video is going to be like a real selfdriving car so you just want it to run forever and then at some point when the car is turned off or like it reaches its destination you could be like okay turn this to false and then it'll stop reading it'll stop reading um stuff from the camera so we're just this is just going to run forever so that's the first step now within here we want to run this same logic on every frame so again we had an image here but instead of an image we want to get a frame from the video so we're actually not going to read an image we're going to be reading a frame from a video and that's what this thing here is so let's just copy and paste this okay okay let's see it's indented properly so the way we do that is okay run forever until car stops or something or crashes okay yeah um yeah there we go i've still until what the car crashes oh i don't get sued by tesla um but yeah so there's in in um an open cv uh once we have the video here okay we have one it's called video capture so see opencv two dot video capture and the name of the the file then you can just uh run this and we can just run read so all this will do is it'll read one frame from the video okay and that's a function part of it's a function part of cv okay interesting okay so once you've got another video capture object here called video then you can call dot read on that video capture object which is just the video so you're just going to read you're going to read a single frame from this video okay and then once it reads a single frame it keeps track of it so when it when you call this the second time it gets the second frame when you call this the third time it gets the third frame again through all the and that's how this is implemented and uh what it returns is it actually returns two values so the first value is if the read was successful or not it might be might be actually keep this in parentheses yeah if the read was successful or not and then the second the second value is if the frame is the actual frame so like this frame is actually the image which is just going to be the same as this so this frame here is actually what we want instead of instead of using image and reading an image in we're reading a frame from this video got it got it got it so we got the frame here and then this here is if the frame was read successfully so we definitely want to have good code and make sure that there wasn't errors before we try to display it yeah okay and the way and the way i see it is like this biscuit this video that read basically returns an array which we simply basically map the first portion so no when you call it a tuple a tuple it's called no it's a tuple right it's a tuple yeah a tuple a tuple returns a tuple until we map the first the first okay fine fine fine fine fine fine because five it's tuple because we map the first part of the tuple to the two here and then the second part of the tuple is going to map to here now we don't actually see this you know but in the background that's actually what happened so i just want to make sure that you guys understand this but yeah anyways let's keep going it's the same thing as here we're unlocking a four pole here i mean it's just a four a four variable two four a fourth ball i can't even say that of course we're unpacking these four variables out of this array same thing we're packing these two values out of this array okay okay okay and this ray is a frame which is itself an array it's an image and then this is a boolean yes or no yo kaz is in the house yo what's up all right keep going what's up quasi all right so next what you want to do is of course i'll just type this one out what you want to do is you only want to handle this frame if it was successful so you want to make sure you're checking so here we'll call this safe coding use protection you guys [Laughter] save coding uh was successful i mean i there's a little optional live stream it's like is this video made for kids i was like uh no i turned that i turned that option on hard so if there's any kids here you're not supposed to be here okay you're supposed to um this guy you can still look at it so you can still learn it's fine but but yeah so here if if read is successful yeah then you want to operate on this frame okay so i'm just going to copy paste the rest because okay so um so if the read was successful okay only then do you want to continue so then at that point we'll get the frame which is here and then we'll convert the grayscale okay because if you um if you if the frame didn't read correctly okay if this returns false because the frame is broken you can't actually call this on this next step is this needs to be a valid frame for it to be converted to grayscale so if this is an invalid frame because the read like screwed up then you just want to skip this and just break out the loop okay all right just when would it ever be a non invalid frame last on when the last frame of a video it'll automatically end video by itself automatically okay okay if you air out or if you manually say hey stop this video yeah but wait guys we're really late guys we're completely kidding about the kids thing if you're a kid it's okay to say a lot of you guys like oh my kid i'm a kid and i'm a kid i'm a kid i'm a kid you know i'm like guys it's okay we're completely joking about this stuff guys i mean it's it's already forgotten at this point yeah yeah yeah welcome kids welcome to woody wonka's chocolate factory oh god all right that's that's let's keep it let's continue um oh man hi mom so where are we at yes it's gonna break out so once we have the grayscale grayscaled frame here the same idea of an image and black and white we can actually change this to black i'll just keep it grayscale that's the proper term instead of black and white then we have a grayscaled frame from here okay okay and why don't we just um display that so okay let's see it actually um let's comment all of this out because it's gonna it's gonna break something okay okay okay and and let's just this is not going to do anything because it's not displaying anything so we do need the display code again okay remember the display code want to display the current frame in this case it'll be scaled frame instead of image okay instead of image it'll be grayscaled frame and it'll only get here if the frame was successful remember that you guys because else we break out of this while loop and then we don't even get to this code so it avoids the errors i'll ask you a question let me ask you a question we have logan actually asked a question would it be better to or to would it be better to only what would it be better to only use every other frame for speed yeah yeah you could do that of course you would have a little bit lowered um quality you could even lower the resolution of each frame to go even faster because just because the resolution of an image is halved like if this was kind of blurry you as a human could still tell this is a car if it was super blurry you could probably still tell it's kind of like a car you could kind of make it out you're like okay this is a highway and a car so there's many things you can do to speed it up you can down scale it um actually i'll touch on quick if you go to detect multiscale that's the scale factor actually be like okay blur this image little bit to make it faster you can like increase factor oh interesting okay that's yeah that was good i think that was a good question yeah like if you have 4k footage it's gonna be kind of like really hard to run all the algorithms but if you scale it down to like scale 4k down to like 360 pixels 360p or 480p it'll be a lot faster and it might still work so you can that's probably and that's probably what tesla does as well right because they probably scale down the image so that they can process it much faster right because you can't pass like 4k yeah yeah there's some tradeoff between having accuracy with high resolution images and also speed because when you're driving a real car you need to have real like realtime feedback so they go as high as as high as the accuracy can be while keeping it real time because speed is speed and accuracy are both important it's like oh this car is going to hit me and then two hours later you don't turn you know you're still getting there yeah yeah you got it like too late yeah just like this playing like this guy crashing before remember like like tesla here it sees this and as soon as he comes over he's instantly it's quick it's quick it's really cool yeah it's like instantaneous so there's a tradeoff of accuracy and speed there yeah yeah okay cool sweet all right moving on so uh from here we're gonna display the gray scaled frame and then of course you need to have um this because this will just display for a split second then disappear so we want it to stay on the frame the current frame and this actually tells us stay on the frame for one second or one millisecond or something like that okay okay and then and then it'll loop up and show the second frame it'll read the frame it will if it's successful it'll turn it gray and then it'll display it the gray the gray skilled frame and then it'll wait a second one millisecond and repeat and it'll do this for every single one so this is basically not you're not creating a video no no i'm creating a video okay you are so this is going to be a black and white version of that same video god okay okay okay okay i get it i get it okay okay okay okay uhhuh is right no i don't know what blue is is it red all i have to right every joke bro like it turns unfunny when you say it anyways hey hey look at that oh this is like it's like sped up why is it so sped up he cut because we changed the gray scale so it can compute it faster oh see okay okay okay okay interesting so it's going faster and this is the whole video the video is going and then when the video ends it automatically closes guys do you understand like in trouble cosplay do you understand how this even like displaying that specific video right because like i mean look like drop in the comments below if you understand like the way this is working right the way i understand it personally the way i understand it personally is literally right if we have the way i see it is like yes we have a video right we have a video right here what we literally do after that point is we literally we unpack the video and we go through frame by frame and then we output that frame again to create yet another basically video it's just at this time we added the video simply because we changed it to grayscale so every single frame as you guys know every video right is created it's created with frames right what we do is literally take that frame we convert it to grayscale and then we show it again and again you went from video to another video except this time it is grayscale so i just thought it was really interesting if you know what i'm talking about like drop in the comments below because that's just that's mindblowing to me you know yeah what he said yeah what i said [Laughter] all right guys so we have the gray skilled images here in a loop and it's properly looping through every frame of the video now all we need to do is run the detection code again and then from there once we have the detection code we can draw the rectangles again on the colored image and then display the colored image the colored frame instead of the grayscale frame and interesting that pretty much does it and then at that point that we also want to introduce pedestrians and use different kinds of videos with both and mix them together but that's the last step so yeah yeah let's go with that next so the next thing is once we have our grayscaled frame we want to run the car classifier on it remember we have our um oh i don't even have it it's uh i deleted it didn't i what cart tracker so let's get this back okay so let's get our car classifier back and paste it up here once we have the classifier file then you want to feed that into cascade classifier and we have a car tracker now so this is the pretrained data that we downloaded from this file okay now with this car tracker we can do the same thing we can just go down here and copy paste the code because laziness and detect cars especially i mean yo copy and paste as much as you can because what's the point of typing it out like you want to show bigger and bigger problems sure at the same time this is literally cutting the stream length in half and we could fill it up with jokes yeah yeah okay okay okay so now we want to detect all the cars in this current frame so again um we have our car tracker up here auto highlights for us and then again we want to detect all of our cars regardless of the scale of the of the um car match and then what we're feeding in is the grayscaled frame okay because this is the current frame in black and white and black and white is much faster okay okay okay and if any and if you just just so you know guys like when we say frame a frame is simply hold on motion a frame is simply just a still image it's just a image from the video right that's why it's able to detect the car so it's not actually moving it's just one image right that's the interesting part about it right we took that image out so yeah let's let's get on and that's how we were able to detect right multiple detect those cars in there hell yeah what he said yeah what i said what he said [Laughter] hey no no no not hitting me let's take it outside okay we'll take it outside next time after this corona things done i'm back in l.a kidding me man man guys man but this can be a live stream okay i'll cough on you bro that's not gonna do anything to me yeah you can cough at your own pace coffee your own plows you know don't don't cough here don't cough in that way this is the stupidest stream ever but whatever um we paid like two dollars right like people have donated to us i know we made two euros we can go get coffee you can get the dollar coffee from mcdonald's hey let's go let's go anyway so yeah we have the cars here and again remember this is an array of a bunch of different coordinates of the cars so why don't we actually print out um print that out so let's print out cars and each time for each frame you're gonna see a bunch of different stuff print out because every frame there's multiple cars so you're gonna see a bunch of stuff printed on the terminal forever because it's a it's a loop so let's actually run this okay and as you can see wow we have a lot of cars detected in each frame we just haven't drawn them on the video yet you can see them all getting spit out here you know top left point bottom right point the width and the height that's insane the width and the height is always the same that's insane by default and then you get and you can see some of them and you can see some of them don't even have a car yeah some of the yeah they don't have cars correctly but there is no car in that frame and it just skips it and then once it gets to the end um this when there's no frames left this actually becomes false because it can't read anymore so this actually does air out so it actually does get to this break statement on the last frame of the video and that's what you're seeing gotcha screen happens okay and then and then it gets to the code completed remember got it that's why it's good to have this because you can see got it there dope so now last step is just drawing the rectangles on the colored image just the same as with the image okay so pretty simple uh we don't need print cards anymore and of course on the copper paste master of course um yeah this one right i think so rectangles there we go so uh pretty much this should work now only only error is that this image is not an image it should be actually uh frame should not be image because we're not doing images anymore we're doing frames so we just pop frame in there so it'll iterate over every single car it finds in each frame and then it'll just draw a rectangle around that car on that current frame again with a red color and a two thickness got it got it so let's just run this and see what happens let's run this baby guys ready are you guys ready for this you guys ready all right let's see what happens actually on okay oh dang uh it is not working and oh no oh man oh no oh no bueno this is not good no good it's not good no good no reason is we are still displaying the grayscale image we actually display the frame because we drew the rectangle on the frame so okay okay little bug there actually did you guys see that did you guys get that did you guys get that i hope you did yeah because it was black and like when i ran it i'll run it again okay it was oh okay so now it's working oh hold on hold on you guys are you guys ready you guys ready you're ready for this you ready for this it's black and white no come on because when i ran it yep still black and white okay because it says grayscaled frame here but if we're explaining the colored frame which has the squares drawn on it then i can save this and display the frame so let's go um back here this is normal frames right now clear again okay now now we're displaying the colored image with the rectangles drawn on each frame over and over and over again okay within the while loop because you want to make sure all right you ready ready hey let's go oh but i mean hey it's not random you can tell that it's more correct than it is incorrect like it's not just random words all over the image it's fairly it's pretty damn accurate like we think about it this is like amazing accuracy that's not nearly good enough for like real world scenarios and cars but you're we're 80 there bro that is insane this is some magic guys seriously like this is some magical stuff like how how pumped are you to see this or to even build something like this especially the fact that we just built this like guys we literally just built this in like what and how many and what i mean an hour an hour and a half and two or maybe holy i mean holy bro chill out guys i only okay i only have i only have one gift to show to show how i think we we feel like right now are you ready ready to see this i'm sorry aaron you don't see this but they will see this so only one only one way only this way oh yeah peace out peace out guys this is how we do it all right let me check this drop in the comments guys for some you'll see it it's there's gonna be a small delay but that's all right who is that there's some random random logan's like this is awesome valley this is epic we got logan wow i mean we haven't even gone to pedestrians yet how do we how do we detect pedestrians and cars in the city oh wait so we haven't got the pedestrians yet no not real we haven't even touched that yet we still got to download that classifier and get that running you have to scan across every frame from both of them so that we can detect pedestrians and cars okay and then you can also you could train them for anything like you could train to detect nas you know um in videos and stuff if you want to that's important detecting who would want to do that everybody okay guys but uh what i'm gonna do is i also want to show you some other videos so i actually have a bunch here okay let's see um i have a couple other videos that i pulled out from youtube this is all from the same video linked in the description there's like okay it's like within the first three or four all three of these clips are in that video i skipped some of them because it was like dark and rainy and it wasn't performing that well but i mean this is pretty good performance for stuff you downloaded off the internet of course if you trained your own hardcast classifier extensively and you let it run for like three weeks and you traded it then that have really really really good results but these are just ones i just downloaded off the internet like like i said like the car data set this was created by people like caltech the california institute of technology um but these cars all look old so this must have been done in the freaking 80s you know so like this is old data um that we're using but they did use this to train their hard cascade but we could go out and take our own thousands of images but i mean i'm not going to do that sorry guys okay yeah yeah that's too much work that's too much work why we define the wheel but it's already defined for you you know yeah yeah and you know it's like use use a library because it exists but hey we got robert robin donated a hundred i don't know what might that i don't know what money that is a hundred you're not euro something i don't know how much money that is it's like robin yeah anyways 100 something thank you robin appreciate it what was his name robin robin yeah appreciate that rob yep appreciate that now um let's continue on so the next step would be um oh yeah i was going to show the other videos so let's just change up this video so this one this one is actually one where um the tesla selfdriving car actually can detected and avoided a tumbleweed so it was a huge thing on the road and it actually avoids it so let's run this footage so this happens here okay it's running in color and then boom tumbleweed where and it just dodged it bro you missed it i missed it oh man oh there it is there it is oh dang so that is insane yeah in an actual video the guy's talking and then somebody behind him actually hits it so i don't know but hopefully they're okay but it's just a tumbleweed it'll damage your car but unless they swerve they might cause an accident but if they just hit it it should be fine i hope and uh yep so that's that's another video from that clip and then here's another one i just pulled this off like randomly off the internet i just did tesla dash cam footage and i just found this video and then here this last one um is some highway footage also from that same clip so feel free to go watch that same clip that's damn guys how cool is that like how cool is that the fact that we just created a system that you know i mean i would say tesla like i mean i would say it's not perfect right but but the gist of it and that now you understand kind of how it works i want to point that out see how this is constantly saying it's a car because think about that there's the dark window the light bumper the dark shadow so it keeps mistaking this for a car because it has that same profile remember the heart feature of light and dark dark and light and then light and dark remember yeah from here so this matches these things this thing kind of looks like this because there's a dark window a light bumper and a dark shadow underneath the car see dark window light bumper and a shadow underneath the car so that's why it is it's miss miss classifying this so false that's why it's not a perfect system right it needs a lot more classification basically for this yeah i mean if you ran it super extensively you could you could detect every single car in the single image perfectly but it would take forever to run it wouldn't be running that fast that makes sense that makes sense uhhuh okay and so that's it so these these clips are in the description um you're gonna have to download the youtube video yourself and then trim it trim out the the clips but you can definitely do that and then just name it whatever you want it's an mp4 file so make sure you download the video got it got it got it that's really it so i had those three um examples okay and one thing i did forget the show is uh nah that's okay it's too late i already showed the image thing yeah uh with the with that video so what should we do now so what what's the next step aaron well why don't we detect this the thing i started off with the demo where there's cars and pedestrians okay both in the same video i don't know if you guys can hear that but okay but yeah this is the the original footage i showed so now we want to actually introduce pedestrians as well all right let's do it bro we got cars next thing is pedestrians then we got cats and dogs no okay we're just going to do pedestrians i think yeah pedestrians so yeah who's probably going to do cats and dogs next time but i mean i think selfdriving cars is cooler yeah yeah maybe next time maybe next time but yeah if you're pumped to see that let's get into it actually drop in the comments below too drop in the comments below yeah so what we're going to want to do is we are going to want to actually download another um classifier okay okay so we have a card classifier and that's what's doing all the work for our car classifier but we're also going to want a classifier for pedestrians and have both of them running okay okay so how we do that is we're just simply going to download another pedestrian classifier so again the link is in the description this one is actually supplied to us from opencv by default there's a hard cascade file xml file again called power cascade full body right here on my desktop open this up so it's the same exact thing again it has the all these crazy numbers and it goes on for thousands and thousands of har features um and it filters through all of it but this series of heart features kind of matches up with what a pedestrian would look like whether they're standing or walking or running or whatever or even like on a scooter they would still they would still be able to detect it yeah yeah so a bunch you can see it goes on forever and it takes forever to train this and actually generate these correct numbers just capturing the relationship in the patterns evil aval aval aval is like wow this is amazing wow oh robin robin just donated another 200 i think it's called v v dollars i don't know what it's called but another 200 dang i don't know what the videls are but it sounds like thank you robin appreciate it oh wait well actually he actually asked a question he asked the question actually his question was and i can't i can't put up on the screen because i don't have a for example for some reason actually show up on ecam but his question was if a different ide is used while speed and accuracy get impacted and output a different ide yeah no no reason being is this ide is just a code editor it just makes the color it makes the colors nice it makes strings orange it makes comments in green it does all that nice stuff but when you're running code from the terminal it's literally just getting this raw text file this raw python file which is just a text file that has python code in it and then it runs that python code so like i could even open up this python code i could open it in text edit okay got it like this is the code for running in vs code so it doesn't matter what you're using to edit it it's just running this raw text code it's just translating this to ones and zeros the computer understands so actually what's running all that stuff is literally just this text file this text file is generating all of this this tracking so it's reading the file name getting all the stuff it's making the classifier i mean you know i can't see but like yeah so to answer so to answer your question quickly no will not biscuit would not matter it will not impact any processing or anything like that at all zero yeah yeah yeah zero sweet and um yeah so let's just move on to pedestrians okay yeah so let's just move on to pedestrians okay so i have a video here a dash cam of dashcam pedestrians which is this video of a lot of pedestrians here there's not so many cars because i want to show this first okay okay okay and what we're gonna have to do is we're gonna have to actually get the um pedestrian classifier as well so actually let's just grab this okay and paste this here okay so classifier file is car detector really this should be called car tracker so actually let's change that so it's only popping up here and here but let's change this to car tracker all right okay okay to car tracker so now it's a little bit clear that this is a car tracker and um well actually what we have two different trackers right one is a car tracker and then wait so yeah yeah i uh screwed it up a little bit so we should actually no no this is car tracker down here so this should be car tracker file oops and this should be car tracker file okay okay so ignore this stuff let me just delete it because it might be confusing so let me ignore that for now so what i did was i changed this name to car tracker file to be a little bit more descriptive with the name and then again we're just popping this car tracker file into here to get the class k classifier which create gives us our car tracker now let's repeat these two lines of code but for pedestrians okay so for us it's going to be pedestrian file tracker no pedestrian tracker file equals this okay so it's the same thing as this line but here for pedestrians okay we have a different xml file for cars a different xml file for for pedestrians and let me just comment this again and actually i think it'll be better to keep these together so our our pretrained cats our pretrained car and pedestrian classifiers with an s okay so we have both of them here and now we can have our pedestrian tracker so this would actually be this is where we actually well actually i don't even have to do it i can just copy and paste this here the cascade classifier okay so pedestrian track is going to be this i'll just type it out this time so cv2 and cascade classifier and it autocompletes for me and then from here then you want to get the pedestrian tracker file and paste that in here so that should make sense we did it once for car car file car tracker now we have pedestrian file and pedestrian tracker all right so we have both now that we have both all we want to do is detect both and every frame and draw rectangles around both in every frame very straightforward so the thing we're going to want to do is um of course for every every frame we want to run the loop we want to read the frame that doesn't change but um and then we create it we change it to grayscale okay that doesn't change either once we have the grayscale image then we want to detect cars and pedestrians okay see that we're only detecting cars right now but we want to detect cars and pedestrians so that would be something like this okay pedestrians equals pedestrian tracker okay pedestrian tracker dot again detect multiscale because you want to detect pedestrians of all scales in all sizes and we're just going to in the grayscale frame so this is just exactly the same code as for cars we're just using a different classifier okay which means it's going to give us different coordinates different squares of different um of different um what you'll for like pedestrians and stuff like that oh yeah i get i get it yeah yeah so this is a bunch a list of cars and this is listed pedestrians that's all it is okay yeah okay um so if you so if you guys if you guys yeah so if you guys don't know it's basically yeah we got pedestrians so we're attacking different pedestrians we're using one classifier for pedestrians right and then we're using another cluster for a classifier for cars right and that's that again is detect that is detected through where through here well i don't think if you can draw but yeah you can see one for car tracker and another one for pedestrian tracker so that is really cool okay all right let's keep going let's keep going yeah and once we have these then we can just repeat the same exact process with the rectangles for drawing the pedestrians that we do for drawing the cars so it's literally the same exact thing i'm just going to draw the pedestrians in yellow instead of red okay and that's really it okay that's it that's it yeah oh man all right so all right okay pasted it the only difference is um for cars you want to iterate through all the cars again for those points then you want to draw on the current frame the current color frame top left point top bottom right of the top left point the bottom right point and make it red with thickness of two now for the pedestrians we want to again we can just reuse the same variables of x y w and h because at this point we're done with them so we can just overwrite them x y w h and pedestrians so again this is a list its own list of pedestrians then we want to draw a rectangle again on the colored frame top left point bottom right point this time we want to do yellow so this is the color for yellow so if um the green and the red are maxed out it becomes yellow i don't know and again guys it's not it's not so much about like you know red green like we simply just picked those colors because you know because why not you just pick the random colors right but you can pick any color you want right that's those zeros yeah this would be completely white so everything you can pretty much you can pretty much change it to anything you want yeah unimportant detail i mean to be honest in on tesla when they're doing selfdriving cars they don't even bother drawing the rectangles around the car because from this point they just know where the car is and the car doesn't need to see it i mean the car already does see the other cars or the pedestrians with this data it doesn't actually need to draw a rectangle no the rectangles are just for humans so yeah on this okay look look look in life logan in the live stream man logan logan appreciate your freaking energy bro logan says like i love this live stream this is so much helpful much nicer way to expose myself to opencv with this then arena communication you know yeah oh yeah yeah apple apple is like aaron you're crushing it buddy keep it up bro you're crushing it bro what watch our video and our jokes yeah let's just let's just read this through the live stream you know that's all we do that's all we do let's read the commentation classifier colon colon detect multiscale detects objects of different sizes of the input image the detected objects are returned as a list of rectangles i mean this is exactly what we're saying right it's just it sounds very nerdy you detect objects in our case cars and pedestrians of different sizes because it's multiscale okay the input images are framed yeah yeah the detected objects are returned as a list of rectangle points and then we just draw them so that's it all right let's do let's see man i'm like so excited let's go guys we're gonna see a bunch of pedestrians because the video we're using okay there's there's a bunch of pedestrians but not very many cars like i think there's like one car here but all these pedestrians will all get um get identified okay so let's just go for it right wait did i delete something ready ready where'd you delete oh i deleted the whole loop oops i was no no i didn't i deleted a bunch of the code i just typed out and then i didn't even run it yet but i caught myself okay okay okay all right let's just do this nastiness all right let's run the python file so car and pedestrian tracking dot pod and boom oh see it's oh deep down taking the pedestrians guys holy moly hey guys this is a wow okay okay holy wait so wait okay this is just pedestrians right now you guys ready check this out how cool is that how cool is that guys drop that in the comment below that is sweet oh man that is amazing all right so wow is that it that is that that's pretty much it what i want to do is i want to add a little bit of flavor to something and then add a couple other um safe keeping things that we're going to go over all right and then add a little bit of style and then and then run it on some new videos and then that'll conclude it pretty much pretty consistent that's that's my face right there guys that that that is that this right here is probably your face right now i'm kidding i'm not kidding like like make that face right now and as you're watching the video make that face right now you know the face i'm talking about oh it's cloudy with a chance of meatballs is that is that okay yeah exactly um bro didn't you grow up when that came out you were like 12 when it came out hey this is still an awesome movie bro yeah who doesn't watch that come on come on man incredibles is better come on man what people are like this is guys what i want to do is um i don't know about you guys but in the thumbnail of this live stream i had like a little quirky styling thing where for the cars it was red and blue and then for pedestrians it was just yellow so i just want to chuck that in so all i did was i'm just drawing two rectangles here instead uh just you know for a little bit of flavor and just pop that in so i actually for each car i actually draw two rectangles one red rectangle and one blue rectangle so this is the reference what's the reason for that i'm just curious just because you want to be fancy yeah i just want to be fancy real quick okay fine i mean so all i did was i just drew a red background here with the red channel max everything else closed and the blue channel here 255 enclosed but i offset it by one and two pixels a little bit so you can see it changing you know this is like this is completely useless code it's just for a little bit of you know frontend development but when you run it you can see i mean there's not that many cars here but you can see whenever a car pops up there's a little bit of blue as well as oh man a little bit of flavor put that image in the center put the video in the center oh never mind just keep going never mind just keep going you're fine you're fine like that guys how cool is that how cool is that to go like okay that that that makes me excited bro honestly all right all right i don't know let's calm down i love this ai stuff i used to i actually guys actually interesting enough i i used to do ai stuff as well for a company but we did we did a yeah so interestingly enough i'll just tell you a really quick story i i did ai for i did ai for um for actually detecting signatures detecting fake signatures so we use the similar we also used alpinstv as well and we detected if signatures were fake or they were real and we had i'm not kidding we had signatures from like thousands and thousands of like images and we will be able to detect like if the images was like real or not by the way i don't really know robin robin seriously holy moly thanks again donated 400 400 v v something v dollars i don't even know i don't know robin you're the best thank you appreciate it what was appreciating donations you know oh man yeah yeah right but anyways fire yeah that was a fight he's like robin's like yo let's go we just hit the goal [Laughter] all right we're almost done you guys just a couple more things and we can run on some extra videos and then we can just let it run and yeah that'll complete the app you guys yeah so uh last things i want to do are actually um when you're running the the video i want to be able to actually quit the the window um with the key so guys there's a robin donated right there i appreciate it bro right there you guys can see it yeah there we go hey all right let's continue on by the way i don't see you do i see you no i don't see you oh there we go there now i see you there you are now there you go am i good no you're good you're good keep going keep going okay got it yeah so here on the code i'm just gonna copy and paste in a little um housekeeping here so if the q key is pressed q for quit then i want to break out of this loop which means it'll abort the video stream like whenever you type that key so the key for a lowercase q and uppercase q are 81 and 113. you can learn look that up online every letter and every keyboard button has its own number and you can just find it with a google search you just be like lowercase q and uppercase q what are the numbers you just put that in and um once you have these numbers then if either of those are pressed if key equals um that or that then it will just break out and we'll just stop okay and the key is automatically whatever you press from wait key because it's waiting for a key you see what i mean and so if it's waiting for a key and you press q automatically it goes to the next one and then key becomes q and it'll it'll match and that's really it cool okay last thing is you want to release the video capture so wait what is the release why release what so um video here our video is the video capture object that we got from our video file all right and it's it's constantly reading a file okay and so video is constantly reading a file so when we're done doing it we just want to release reading of the file so it's just like it's like it's like okay stream of data coming in so it's like you stop basically stop bringing the file you're good that's what it's saying yeah okay it says we're done reading this file just release all resources from trying to read this file so we're done okay that's really it's just a clean up like a memory management thing yeah and that's really it you guys um guys i don't think that's pretty much it i haven't planned that change all right so let's see driving car all right i'm excited to see some videos bro let's do it yeah let's go here and let's run it again oh your name is ready it's not you guys hey guys oh there's an error here it says key is not defined because you guys know what the key is you guys know what the problem is drop in the comment below you guys huh i think i know i know it is do you know aaron yep of course i do not are you sure you do i'm not sure i'm not sure about that so yeah the problem is that this key variable doesn't actually exist and the problem for that the reason for that is we didn't actually set that equal to here so this does wait for a key to be pressed but it never captures that so we gotta capture it in key and now when key is pressed then it should work okay back here let's just clear this out so it's nice and clean run it again and there we go so it's going hey okay if i press the q key it should quit quit sweet okay cool cool cool all right damn guys this is crazy guys this is amazing holy like we just created a system that detects pedestrians and cars within you know an hour two hours with some training data that's it that we didn't create we just bought it we did we you borrowed download all this off the internet like you can download xml files for anything you can probably download xml file for a cat for a dog for a water bottle for a football or anything you can download somebody else probably somewhere on the planet has trained a hard cascade file for you somewhere and uploaded it somewhere you could probably download it and you could probably use it and do a very similar thing depending on how well they trained it and of course you can train your own too if you want to go that route i'm sure it that exists on google how to do that but that's a much longer process you have to find all your own data yeah cool cool your own images wait wait guys so let's let's give you some more videos what has we got yeah so we have a couple more all right um so that was just that was that was like a pedestrian heavy let's run it again this was a very pedestrian heavy video okay lots of pedestrians so what do you guys see what do you guys see you guys see just a lot of pedestrians walking right and it's able to detect those systems and if you think about it right what would a system do you can now since you cannot detect something you basically can now tell a system hey you know if you detected it stop to stop the car or hey you know stop anything you want so that's kind of why this stuff works really well you know what i mean yup so let's just do this okay so another another video file i have is dash cam cars and pedestrians because it has a little bit more mix of both this is actually the video file that i um showed you at the beginning okay so how long is this video all right okay that's a different video it's like four minutes long all right um so let's go and let's just let it run so this is the video i showed you at the beginning oh man that's cool damn guys give us some fire in the comments guys that is cool all right look at this guy's walking what is that you see how it's able to detect that like little pothole at the bottom i thought that was interesting yeah it's not perfect but yeah of course it's better than nothing better than random much better than random and there we go you guys if you can see it looks a little bit slower because it's doing double compute power yeah yeah you see so you can think about it for tesla like a real selfdriving car think about it it has to detect pedestrians it has to detect cars it has to detect signs all different kinds of signs speed limits stop signs has to detect traffic lights have to detect different night time and daytime things have to detect rainy conditions and nonraining conditions it has to actually send those values to the car to break or turn accordingly there's so much going on so this is just scraping the surface this is pretty cool but this is just the very very surface of what actually of what's actually going on i mean in general honestly in general it's like it's it's crazy right because the amount of data that it has to process right in terms of pixels right in terms of in terms of how fast it has to do it as well it's insane but you can see what's real like i think guys what's really interesting and how long i'm actually not let's let's keep watching the video as you guys can see right the really interesting part is like the fact that the relationship part is like all we simply did is if we divide a problem right into different little into certain little parts right into into small little parts right which is how do we divide this up like drop in the comments below how do we divide up this huge problem which is we wanted to detect right we want to detect like um you know pedestrians and cars in the video how do we divide that well first is we found a lot of training data that's part one right two right we basically we first did training we trained uh we first did testing on the pictures individual individual pictures right individual pictures and then what happened is once we got the pictures right we were able to bring in a video we were able to take certain pictures right every single frame from that video and the next thing you know we're able to display it back to the user so but if i'm dividing this up into three or four different parts you're literally just able are able to solve this humongous issue not an issue but this this crazy epic you know thing in an hour or two do you guys see that yeah just drop that in the comment below if you agree with me like seriously because that is to me is insane you know a lot of people think that this is this is crazy stuff but you know honestly you just you know just some work and you're good am i right yeah man look at it go well there i think it's slow motion yeah yeah i mean it's detecting that sign wrong but it's getting the girl is getting some of the cars in the back yeah yeah right there right there screens a little bit yeah yeah and there's ways to optimize this you can be like okay if there's like two if there's two um rectangles in the general same area twice in a row you can kind of be like okay there's a higher chance this actually is a pedestrian it's not just a random thing a random detection so hold on i want to ask you a question so somebody asked a question actually george asked the question how can i get this source code uh if i can take a look at it please so i can take a look at it uh i'll post it in the in the description i'll like upload it to like a riplet or something or i t and then you can download the code if you didn't type it out yourself with us yeah granted it won't work in riplet like you're gonna have to download opencv the opencv package within riplet itself and run it there but you can just i'm just gonna post it there for like code reasons and you can just copy paste it to your own visual studio code yeah wait but can we just put host on github or no we could do that too yeah right that's it yeah either or github's probably the proper way to do it but yeah riplet fanboy so yeah we'll post it to github how is that that's the proper way to do it post the game you can download the code from there exactly exactly exactly so guys how sick was this how sick was that to create such an insane python tutorial such as saying python program aaron i think it's pretty dope i'm just like admiring the the work that other people admire your work okay don't get too cocky bro don't get too cocky on this you know it's just like you know i said i'm admiring the work that other people have done bro that's the option okay okay okay i thought i said admiring my work you know open your ears i mean what i wrote like 20 lines of code it's pretty badass but i mean you know yeah yeah i didn't do all the training the training that's the hardest part yeah yeah but that that to me is insane so yeah but awesome job guys guys give aaron a give aaron a round of applause in the comments right he worked on this all of us give all yourselves you know i was partially involved in the code i was just like you know okay good look at this wow holy crap he's getting these pedestrians super accurately it's like stop stop stop stop you know pedestrians in front yeah yeah yeah and then the bigger the bigger the rectangle the closer it is you know you can do stuff like that like if there's a big rectangle you can tell that the thing is close to you yeah yeah look at that that's insane that's cool that is so cool okay this one's not working at all this one's terrible it's like i think it's just too many people man probably yeah there's too much information confused with crowds and stuff yeah yeah if you had just people walking like on a white sand beach just a single person walking it would track it almost perfectly but just because there's so much noise and stuff it's not quite perfect yeah yeah but dude this this motorcycle driver is like freaking he's trying to run people over you know yeah people are like how are you going his name is royal jordanian so maybe yeah yeah i mean i never i found him this morning because i needed this video but he has like two million subs it's ridiculous oh wow for riding his motorcycle he just rides his motorcycle and he records it is that it i guess so i mean he probably talks about his motorcycle and stuff too i don't i didn't really look at his channel even evil evil is like evil i'm not i don't know how to say that evil was like aaron do a project with me whoa look at this truck i got that truck hard did you hear me did you hear me evan yo it's getting it's getting the the cars in the advertisement it's funny where all the up top yeah are those even cars oh they're not even cars i don't know their cars yeah i mean guys obviously it's not perfect right this is not perfect yeah but still it's insane it's more right than it is wrong yeah yeah yeah that's that's a monumental task yeah hey guys let me ask you a question like what else let me see a question what else would you like us to see like what else would you like us to do in terms of you know ai or face detection anything that you want us to do like let us know in the co drop it in the comments below right because we read your comments right so we have great ideas for you know what to come next before we have great ideas of what you guys want from us right we read those comments i am not kidding so if you got any suggestions right if you got any suggestions on what to do yeah just drop in the comments below we'll take a look at it and then aaron is just going to take a crack at it you know and then create something amazing right there am i amazing bro i mean you know just whip it up yes i'm amazing like onefourth amazing onefourth amazing yep and boom cool projects any cool ideas you guys have for projects going forward related to python and and any kind of artificial intelligence then drop it in the comments too then you can consider it maybe we'll make something maybe we'll use opencv again maybe we'll use something else or else something else something somebody said so we have idol said idol said i don't know ido said to detect numbers okay we could do that actually detecting numbers like you want to yeah you could detect you could yeah you could detect numbers on a page like if you had a piece of paper okay you had opencv you could you could technically um scan that and then find out like all of the places where there's words like that's actually how pdfs are able to like scan the numbers and letters in it and like auto populate all the numbers in the numbers and letters is through scan it doesn't use i don't think it uses hard cascades it uses something different but um yeah same principle you can detect different letters and shapes on a piece of paper same exact principle gotcha gotcha what about somebody said something you said sprush sparsh sparsh asked uh age detection i'm not sure if we can do that that that's a little bit harder yeah i mean in theory it's possible like if you had if you had like facial recognition you know how facebook can can recognize your face and be like oh this is quasi this is nas this is area tag your friend automatically if it can recognize an actual independent face it can easily recognize old versus young um so yeah you could but you would take more training and you would need you would need a lot of picture of old people and a lot of picture uh pictures of a lot of young people and to distinguish between those yeah that's true but i think it's like when you get to like you know when you're 20s or 30s it's really hard to get the exact age like if it can get an exact age it could be like it could be like old middleaged child infant you could just split it into four groups you know infant yeah kid middleaged adult and elder senior citizen you could have like those four that's close that's true so guys if you want us to do like an age detection system that would be actually interesting and then we could age attacked air and they'll probably say like 50 you know or something yeah the thing with that is i don't know if that exists on the internet we have to train our own hard cascades and there's other algorithms hardcast i'm sure there is the algorithm used for this um but maybe we had someone say hold on it's itzhak said face expression detection oh like smile sad like mad you know be like no i'm mad i'm like your smile you know yeah we could do a smile detection a smile that's interesting it's like smiling or not smiling because let's just keep it simple smiling versus not smiling faces it could say like smile on top yeah that's not a bad idea we can look into it some guys anything else would you want us to create a face expression system a smile detector a smile find a small detector system yeah because because that way if you guys don't smile you know we could i don't know we detect some points you know you like points for me i don't know i don't know how but we did we would detect points if you guys smile so yeah sweet i think that's pretty much it bro right we're good yeah that's it so again if you guys are interested in coding more and actually making a living from it if you're not currently doing that if you're uber driver or working at a retail or fast food place or something like that yup um we offer courses here at cleverprogrammer to help you learn how to do that so we teach you a bunch of different projects in python and how to actually monetize those skills so this is a 15week program um hosted by uh qazi and um our other python expert jacob yep and then um also there's a little bit of me in there we're gonna add in um some stuff in there at some point with me and we all teach python and how to actually use python to make a living from it so if you're interested in that then definitely give it a click in the description there's a free threepart master class and also um the actual course is there so you can check out both um if not then yeah just keep watching us on youtube and thanks for watching you guys yeah sweet guys and i just want to say guys is it you just want one one small thing guys if you're interested like i said with the profit with python you get amazing success coaches you get you know you get to learn how to make a live a killing with python right so it's not just about teaching you skills right but it's also teaching you about how to actually make money from that because that's the most important thing that you know you're going to get from a course right we get weekly training calls literally every single week you get a coaching call from a developer who knows his stuff right you have an amazing community who loves each other and you have an amazing facebook community at the same time so yeah if you're interested in you know becoming a python developer or learning python and just making a killing with python where do they go aaron they can go to the link in the description and check it out there profit with python profit guys on course yep and then there's also a free threepart master class it gives you a little bit more information about making money as a python developer you can check that out it's just about like the opportunity there is and stuff and there's some activities in there you can check it out and then you can join the course after if you want or something like that but exactly yep that option is there for those who are interested for those who are not um yeah come back for the small detector next yeah the small detector all right guys awesome guys this was amazing this was so much fun guys oh hold on something evil said my heart my evil says my heart is python my heart is played my heart is python yes what about javascript bro what about javascript that was cool too you guys you guys you guys are not you know not cool anyways but sweet awesome guys in that case i think we're done here hope you guys have a great day if you guys have well i don't know if you hope you guys have a great day and other than that we will see you in the next video right aaron yep next yeah probably probably tomorrow right yeah probably tomorrow schedule for tomorrow yeah i think so awesome guys stay tuned stay tuned and have a great day guys let's go so we are going to be building a realtime ai smile detection app in python i am sunny and today i am here with aaron what's up guys remember me i'm the python guy apparently super pumped guys super super pumped for today aaron what we building today uh all right can they see my screen right now uh coming through now yeah let me pause this like mute this all right guys so this is what we're building i got my little app here and i got a multi detection app let me go ahead and share the screen one sec all right let's go yup they can see you all right here's my face and when i smile it should be able to notify uh detect that i'm smiling and then it displays i mean it's bugging out a little bit right now so go ahead and throw a smile hey look at that there we go guys and what we do how are we getting that to work right now uh this is the code bro that's how stuff works what are we using that's pretty much so that's we're using ai right and we're using what what in particular to get that working uh opencv so we're gonna be using the open computer vision library um as usual if you guys are watching the other couple streams in similar but uh this one has some cool some cool optimizations in uh in the code so it's pretty short so it's pretty powerful library i mean what 50 lines of code with comments and spaces so yeah pretty bitesized but you can do some cool stuff with it awesome dude okay so let's go back to us guys there we go nice so let's go ahead and see where everyone's at nice we've already got 250 people in here that's dope hope you guys okay okay this is the first time guys me and aaron are going live together so this will be exciting yeah first time very first time exactly and also guys i'm not actually a python developer so many of you guys know me for react so this will be cool for me as well so i've never done machine learning with python so i'm excited for today um yeah let's go sonny let's do it so aaron let's go ahead and like let's just jump straight in i think yeah all right yeah let's get straight to the to the project okay so uh here's the stream uh all right got a little presentation here for you guys let's just start off to get a little bit of context um so smile detection with python all right uh first of all you just want to you know pay uh pay respects to the joker himself the the infinite smiler i mean he's always smiling but really not the legend heath ledger residents rest in peace bro but uh yeah guys just make sure you're spying a lot because it's important it's good for your mental health and people will probably like you more or just think you're freaking crazy so how are we gonna do this uh sunny smiles a lot i've noticed so you can be blessed with his super white teeth it's a british thing now you guys just misspelled words that's all it is it's the spilled word all right so how are we gonna do this so you guys guessed it it's all um all things go to machine learning okay all thanks go to machine learning so we're gonna be doing that we're not gonna be training anything but we're gonna be doing some pretty crafty stuff uh in the app with some pretrained models this time it gets a little bit fancy here and there but i'll explain how it's how it's happening so here's a quick code breakdown of our app i just kind of want to give like the overall idea of the code logic just so that people um have some context going before we start coding because i don't like when they just jump in they're like oh what are we doing but this kind of gives you a holistic view so uh so step one the very first thing we gotta do is uh find faces in our photo in our case it's gonna be a frame from the webcam that's what i'm gonna be using an app but here awesome the first thing you want to do is find yeah you want to find faces and that's using the har algorithm what is the heart algorithm yeah so i'm not actually going to be explaining the algorithm in this video but if you want to know how the algorithm actually works in depth you can watch the uh our face detection video for our car and pedestrian tracking video uh from a week or a couple weeks back and in those two videos i explained them in depth uh different explanations in both at the face detection it's at the end um and then the other video it's at the beginning but if you want to actually see how it works you can go watch those videos those are cool but this apps a little bit longer and more complicated so i'm just glossing over it okay awesome also i just want to say so so step one is find the faces so at this point we're literally just finding the face right so we're not actually finding that yeah no smiles yet so so you want to find just the face like that yep step one that step find the face very simple yep and then we also want to crop it out just so we're dealing with this okay okay uh step two we want to find smiles within those faces because i mean it's pretty rare you have a smile outside the face i mean maybe if you had like some dentures lying around or like a weird piece of art on the wall but i mean nine times out of ten a smile is always going to be within a face yeah okay again this is the heart algorithm so again if you want to see how it works it's uh it can it's just generic object detection but we can detect smiles on the faces okay so we just detect the smile there then then step three all we need to do is just put the rest of the image back get rid of that bounding box and give it a nice little label on the bottom because this makes more sense you know i mean you could have a box around the mouth i guess that's kind of cool but this is cooler because then you just kind of want to know if the face is smiling or not it just seems more more human so that was the design choice there for the app nice and that's really it guys so yeah i know it's you basically you found the face first and then what then we found the smile within that box right yep and then why did why do we do that instead of just doing the whole um you'll actually see uh once we get to there okay uh a lot of a lot of yeah a lot of ai stuff you kind of need to get clever with the optimizing and um layering different layers because if we did smile detection just every word the performance is actually really really terrible okay so i'll show you guys that i'll show you guys that uh once we're coding and then you'll see because it's actually pretty accurate like when i'm running the code yeah well here so i actually ran it here on the i mean here it's a little bit bad because it's blurry the lighting's bad but i just wanted to run it on this gif before to show you that it's kind of working like when he's smiling you can kind of see it picking it up a little bit here and there um but on the webcam is pretty accurate so yeah you'll see you'll see how ass though how ass the performance is if you run it on the whole thing but there's there's a little trick to make it like really really accurate so guys let's get to the code yeah so guys for this just all we ask is that before we get started just smash the thumbs up button what we got here what was that yeah i had the i have the other from the car and pedestrian tracking i just forgot to delete it anyways um yeah so let's get to the code okay uh real quick guys before we start though just got a donation dude from tushar near us he says character doing a shadow sign with his hand saying cool oh okay no he actually sent in something uh like we can't actually see it properly on the superchat guys but it's it's some guy waving cool so thank you for that cheers all right uh real quick sonny um you want to show them the stream about the the free training yeah real quick yes let's do it guys so we have a free python master class that i recommend everyone goes ahead and signs up to you uh i haven't actually got the link aaron uh i've got the i've got profit with one second let me go ahead and show this so guys let me go do you mind just slacking me the link for the where's it going yeah or i can do it you just share my screen and then i can go through it let's do it yeah yep there we go there we go can they see my screen i got you yeah what's up guys so uh so if you guys are interested in learning how to actually make a make a living from python then we have a free python training here that teaches you the three secrets of how to become a python freelancer so link is in description you can click down there to check it out or if you just want to jump straight to our python course and we also have a course which teaches you how to do that as well this is a paid course though so if you're interested in that there's also the link in description okay a lot of cool stuff in here free trainings uh private communities weekly live calls um with a couple instructors and yeah feel free to check it out but other than that let's just get to the code okay guys also guys just want to point out one thing with that said the something that i really want to point out that i think is always cool is that we actually offer weekly live training calls in that program so if you do want to go ahead and like and you get a bit bored of the sort of udemy courses that you see online then make sure you go and check it out but before any of that be sure to sign up to that free training guys because it's completely free so you have nothing to lose go ahead and check it out if you enjoy the video awesome all right let's do it dude all right man is the focus back on my screen the focus is back on your screen let's go guys okay so uh let's just jump right in all right so remember we're going to be finding faces first and then from there finding smiles and layering it over so this is the full app again opencv very powerful uh we can do some stuff in a pretty short app um so first thing is you're gonna need to download um a couple files these are in the in the description down below so just go to those web pages and download these two xml files to start out i'll explain this in a second and once you've done that uh you just need to make a python file so start with a small detector.pi yep um and actually i think i'll just i'll just code in here yeah let's do that it's always nice to see a bit of fresh code yeah oh yeah of course but i was gonna make a new file but and i'm not feeling it so we'll just pretend this is a new file okay so just make it make a new file in a new directory um we just got another donation as well we got vishal s dropped a 20 rupee super chat thank you very much dude and i dropped another one thank you guys good show thanks to sure thank you everyone appreciate that much appreciated man yeah all right so let's get started okay so first thing we're gonna need to do is install opencv if you don't already have that so i think that is through the command well let me quit out of this there we are hey get out of that um you're gonna need to install it from pip install open cv dash python okay i'm new to python so what is pip firstly like for for those that don't know uh uh python uh i forget what it stands for but it's it's a package oh package installer python or something okay so it's like it's a bit like npm then right yeah yeah so it just allows you to install um a bunch of libraries that are for python so there's pip there's anaconda um there's homebrew there's a there's a few you can use to download different things but we're just using pip it's the it's the simplest one in my opinion so yep just run pip and then this is a command install and then we're gonna be installing opencv dash python it might be python opencv just try both okay and the one that works works and if you're having issues with that then adding headless at the end um can sometimes fix stuff but yeah just do that or do google search if you really can't figure it out once you have opencv installed then um then we can start coding okay yep so um you can we can just import cb2 so that's the very first step it's just importing um opencvs this two is uh the second version there's the second version of cv2 i actually don't know why it's like that but cv2 is the library for opencv okay and let's just start with uh this just to make sure that our code is running correctly so opencv 2 yeah i mean import cv2 and then it's big enough right yeah yeah very good yeah and that's how we run our python script we write python with the file name dot pi and that's it right yep just make sure you're in the same directory so in my case i'm actually um in a folder but and then make sure you're in a folder here if you guys don't know how to do that then um i mean yeah i don't want to make this too much of a command line thing but cd is change directory yep yeah so actually let me just go back here so see i'm on the desktop here you probably well actually you'll probably be here when you open your terminal it might look different but you'll probably want above the desktop you're going to want to put cd and then just type in desktop to go to your desktop i'm in the desktop and then from there you're going to want a cd to open cv well this is the name of my folder it's opencv default uh smile detection and then from there and now i'm in this folder and then i can run this command okay because the file is located okay yeah i don't know so it's modified dot pi yep and if we run this it should just print what's up because that's all we have in here okay so it's working correctly um that also means this is working correctly it'll pop an error for you if you don't actually have it installed correctly but this one it just doesn't say anything if it says nothing you mean you got it installed correctly if it says something you gotta install it correctly go ahead all right so let's just move on okay let's do it uh let me pull some of these code from down here so first thing i said is we're gonna actually start with just the face section so let me copy the comments as well just so like we have a nice um nice app with comments and everything nice so face class all right so here this is a pretrained model for detecting faces like all the fancy machine learning stuff happens in here it's just a bunch of numbers that the image gets passed through and then it tells you face or not that's all it is you pop in an image to this and then it says yes or no and it gives you an answer again if you want to see how this is actually made the whole algorithm and step by step without everything that's happening inside the computer then you can go watch one of the other face detection or car and pedestrian tracking videos yeah i think it's worth saying well let's just start with just just like uh from my understanding all right like a classifier is something where we have like some kind of input right and then we have this model so in this case we have the har cascade frontal face so some kind of like model is is inside of that classifier and then so let me go ahead and i'm just dropping on the screen so we have some kind of model and then from that so we have some kind of input right then we have a model and then we have a sec and then we have some kind of output and what would that output say whether like a certain value which says if you're smiling or not right yeah literally just a one or a zero yeah okay it'll just say yeah one or yes or no but yeah but well technically it'll give you coordinates on your image of where the box is around the face in practice but i mean basically it just kind of says yes or no okay um kinda i mean it the implementation is different but the idea is it'll just say smile or not smile that's all it'll say right so we have some kind of input a classifier which is what we're using here which is a hard cascade and then some kind of output which is whether it's telling us if it's smiling or not or some kind of coordinate but that's that's how it roughly works guys so as aaron said you pretty much this is the line of code to go ahead and get that working nice yeah carry on yeah actually i guess i can explain a little tiny bit technically if you have a whole entire image or a frame from the video then it will look over every little box inside that and then it'll tell you if each boxes of different sizes if that's a face or not or if that's a smile or not no so that's what it's actually saying if it's a yes it sends you the coordinates within the whole image of the little box and then that's how we draw the little box because we have the coordinate and we can just draw a box at that coordinate so that's actually what's happening so it's the whole image and then you just go over the whole thing and then choose it like no no no no no no oh found a face that's a yes give me the coordinate and then no no no again so if there's multiple faces it'll find multiple faces as well awesome okay so it's not just one phase we can support mobile faces or nice surab yeah we just dropped a 100 rupee donation says thank you so much for sharing awesome thank you dude let's carry on thank you yeah here actually let's uh let's run the code really quick yep um i want to show it with two faces i didn't show with two oh nice yeah i should have shown it with you real quick i can just use my phone there we go well i mean hopefully it works it might bug out because one of them is an image yeah but we'll see oh nice that's dope dude this is smiling yeah and it's real time and it's quite performant like that's that's pretty like fast like it's as you move your phone around if you try and move it around fast yeah look at that that's just smooth nice okay and so there's some kind of loop i'm guessing this running or like some kind of thing that's gonna happen there yeah yeah we're just pulling out the let me clear this we're just pulling out the the webcam footage okay webcam it's the easiest way to get some realtime footage yeah i mean this could be a security camera could be a whatever um but in our case we're just gonna be using the webcam go ahead nice all right so let's do that next let's just pull up the webcam and show you how to get the webcam with opencv if you guys are watching the other streams you guys know how to do this you'd be very comfortable by now the third time we're doing it but let's just do this right there and this is the best way to do it because then there's no typos and i don't embarrass myself right sunny sure that happens a lot yeah but anyways so this is how you want to grab your webcam um we just call it webcam a variable you're gonna need to have a variable for that because this is how we access all the webcam stream footage uh but really it's just video capture so um you just call the opencv library dot video capture and if you put zero this is the webcam but you could actually also put like something like whatever dot mp4 okay you could also get video files and run it on there um like that joker like the joker one that i had yeah over here this is how i did that i just imported this file and then i ran it through and then i recorded it and put it back here but for us zero is webcam nice quick so with popup zero and let's just uh i think you'll see that m show okay no no no not m show uh what is it i always get confused between between uh footage and yeah it is m show okay i always get confused between um images so yeah show the current frame so let's just pop in a quick loop and just show the webcam live to the screen okay so and from here then it should be uh we should clean up i think it's destroy all windows yeah cv2 and and uh oh okay you have to release the webcam as well yes yeah i just clean i mean you technically don't have to but i mean it's just like good practice so this here is what's actually going to show so while true um we're just going to be uh showing the frame oh i forgot another line of code we're actually going to need um one more this is actually a big chunk side let me go line by line let me just get this last one here yep get it here it is read the current frame all right nice let me go line by line because this this kind of was a big chunk so what's happening here is after we get the webcam the webcam variable um uh how we how we get a frame is we actually uh actually let me just show this real quick so let me comment out all this just so that we can go step by step is a better way doing this on the fly guys yeah so here here we go look at this single line here ignore everything after that okay okay um we can okay we'll do this why the way i like to do it code completed so if this prints yeah it means if it prints then there is no errors because it's at the end but so this is how we actually read the webcam so you call dot read on the webcam and what this returns is a tuple so this is actually a two a two tuple so this is the first one first element this is the second element okay and oops what this is this is just the boolean of if it was a successful frame read or not and the second one is uh the actual frame so this is like an image that we can actually um run things on so let's actually just show that okay now i can grab the cv2.image show but right there and this is the name of the window so i just put why so serious but you can put smile detector if you want yeah okay and let's go back to the terminal oops what did i do there we go small detector yep and there's oh i forgot one more so after this you're gonna need to run cb2 dot weight key okay and what does this do okay let's what this does is so what happens is we get the webcam okay and then we call webcam.read which is just reading from the webcam stream and it'll get the first frame the very first frame of the webcam video yeah and then if it succeeded now but ignore this for now it'll get the first frame then from here it'll say cv2 dot image show uh image show means it'll show that image to the screen we're going to show frame what the and then the window name will have small detector like up here at the top of the window will be small detector nice the thing is this shows only for a split second as long as it needs to and then it quits out right what this does is it says let's wait for a key before we continue to the end of the program so it'll stay open till we press a key okay this basically means display right okay so this is so this means that without this line of code it pretty much hides it super quick so now we're saying wait until wait until you press a key on the keyboard to hide it right yeah pretty much and this is here because once we're going frame by frame you don't want to be pressing a key every time the frame changes it's going to automatically change in real time okay so we really only need this for uh this case of doing just the the first frame of the image so let's run this and see what happens there we go so that's the first frame okay so like not it's not an actual video it's just one frame okay um but we're gonna wrap this in a loop and then we'll see it in real time okay oh i see okay so you just got a single frame okay i got you i'm with you yep yep yep because dot read will read a single frame okay and then it keeps track of where it is so every time it calls dot read it'll read the next frame next next frame so we just wrap this in a loop and that's how you can get the realtime webcam footage right so i'm just going to read a single frame right read single frame oops yeah nice okay i'm taking notes for them yeah there we go what's nice bro i'm running out of coffee this is uh this is a disaster so this makes sense yeah we're going to read a single frame and then we're going to wrap it in some kind of loop so we get that realtime functionality exactly which is what we're going to do down here uh so let's get back to here now but i'm just going to plug in things one by one so like i said uh just the webcam and then read a single frame display that frame and then display that frame like wait until a key is pressed before you hide before you hide the frame okay so now all we want to do is just pop this in a loop okay so we got the webcam here now um the loop is going to be here because once we have the webcam we want to keep calling dot read on each frame over and over again yeah okay so we would just want to run this forever and that's why it's a while true loopy it's going to run forever until we're done so let's pop all of this into there and uh from here oh like let me get the cleanup code okay so this here at the end let me let me show you guys this real quick this here is just some cleanup okay so it's not super important it's kind of boring code but i'm just going to say at the end of the whole app you want to make sure you have a webcam dot release it's just letting the operating system know that hey this app is done using the webcam uh free up all resources so that something else can use like zoom or skype can now use the webcam without any uh memory issues go ahead and then and then the last thing is uh cv2 to destroy all windows so this just kind of closes all windows to make sure nothing's still open okay because sometimes that happens yeah this is a cool little thing i forgot about what i found recently so very handy yeah um okay so after this then we get a webcam we have a while loop and same exact thing so this should work the only caveat is uh if this is empty it's gonna keep waiting for a key press so let's let's run this and then i'll show you how that works so here we go it's a frozen frame but as i press a key it keeps going to different iterations of loops so it keeps running it keeps yeah and each time i hit it it gets the current frame because it's calling dot read alright so calls.read on the frame yep dot free and if i spam it and then kind of like real time but that's annoying so what we actually want to do is yeah what we actually want to do is dot weight key actually just waits until the key is pressed uh forever but if we put something in here this is how many milliseconds it'll wait before it automatically goes by right so if we put one it'll automatically spam a key every one millisecond and that's kind of like the behavior if i put like a million then it would just wait a million that'd be too long would be like 10 minutes yeah but if i just put one millisecond now when i run this this should be updating every millisecond by itself and i should be in real time so let's give it a shot nice well let me quit out let me quit out of the old one oh wait i gotta i gotta kill it one second how do you kill it in uh uh it should be as h it should be control c yeah so if you just spam control c sometimes it takes a little bit uh oh it's not working i'll just force quit yeah also guys just want to drop in before wire and sorting now we have one comment over there there's one says bernard you people are really amazing awesome i have no words to express my feelings it's only because of you people today i got a job at google at google he got a job at google did that's insane damn like seeing that holy crap i couldn't even get a job of google what is bro bro get this guy in the stream he should be teaching not me i know yeah not a same we love that guys and we also got another donation from tech programmer thank you very much dude we massively appreciate that and also yeah that's amazing guys drop us questions in the chat and we'll literally we'll be happy to answer it as the stream goes on we really love when you guys engage with us and let us know yeah yeah hey whoever landed the job at google send uh send me and send me a dm on instagram and then uh we want to hear a little about your story that's awesome i don't know that's exciting yeah what was his name sunny what did he say he said yeah let me go ahead and find it again so what is his name it's i don't have it on i don't get removed so i've just popped it open it says ajax got it all right we'll meet yeah we'll be expecting you to dm us okay yeah awesome yeah i'm the google guy yeah i'm the google guy that's insane dude we love that nice kind of jealous actually yeah you soured my mood [Laughter] that's amazing great that's that's exciting we have another awesome comment by she goes you guys are just amazing i've learned a lot from these live stream your work is very inspiring thank you so much that's awesome dude thank you for watching all right let's go all right let's go yeah yeah it did the control c didn't work so i don't know what's happening but i just killed it manually yeah um so where were we before i got distracted oh i was running the frames yeah so when i run this again it should actually refresh every millisecond by itself okay so that's how we we fetch this let's run this and go back here and there we go so i'm feeding the webcam footage i mean opencv is getting the webcam footage the webcam stream and it's just displaying it in this window and then i called it small detector right okay so so that that by putting one inside of the weight key that's pretty much saying every second every second like go to the next frame right yeah like it says only wait for one second it says wait for one second then press it press a key like like a fake key like a pretend key and then it presses a key every one second right okay so this waits one this way it's one millisecond yeah but nothing waits infinitely nice that's the difference awesome or ten we could do ten ten milliseconds is fast so this would still work but it doesn't really matter awesome all right yep nice and okay let's see if it'll kill okay so now control c is working nice i don't know what this red thing is means sunny sunny have you installed this weird shell thing zsh i've only used it like once but i ran away but he says it's colorful yeah usually i think that's when your branch is dirty i think so i mean that's usually i got it something like that yeah yeah yeah i changed the i probably changed the code in here and then it changed but no big deal just ignore this like the color of the arrow but yeah let's just move on okay so i can actually get rid of this stuff because we actually pulled everything out so now we're back to the code ran without errors nice okay uh here let me just pop in some comments we have 350 people watching right now so thank you so much for watching and yeah if you're enjoying what you're what you're seeing right now um with the face detection you think it's pretty cool all we ask is that you just smash the thumbs up button and that will help this video get out to more people nice yeah yeah like smash the track pad like slam your mouse just hit it as hard as you can keep that domestic violence and domestic violence in the software program that's a terrible joke but uh so yeah this is step one all right so we got we got the webcam footage in here all right you guys should be comfortable if you guys done this before pretty straightforward now uh once it one check we want to put in though is actually this so i mean it wasn't it wasn't breaking before but we do want to put in a check here uh right here so after we read the the frame okay the first frame with the dot read method the first variable or i mean the first element is actually a boolean of if the read was successful or not okay so all i want to do is put yeah because sometimes it might bug out um what the webcam is usually fine but for a video file if you're reading an mp4 or something like you put a video file in here like sometimes if one of the frames is corrupted or whatever then it'll not work so you just kind of put a safe check in here so if it wasn't a successful successful frame rate just break out of this while loop and just like abort the program and it'll go down to here and close everything so that it doesn't break it just kind of quits so yep that's that's all that is just a quick quick little aaron somebody asked a decent question they said how can i install the face xml file so the one that we used at the top where did you actually get that from again uh the opencv github document github repo so they they provide all of that the link is in the description so you can just go down and scroll to the bottom and just download this uh the face xml file there's also a smile one but we haven't gotten there yet we're going to be using both we need both to make this work um you'll see you guys will see later why that is yeah but yeah let's let's just continue let's do it uh huh so after we get the frame read and we have this little check here then uh let's actually start detecting faces okay so if you guys watched the face detection video you guys already know how to do this pretty straightforward it's a very similar but there's a little trick here that you guys are probably gonna lower your minds at some point uh hopefully but but maybe not uh okay so after we got the frame to actually run uh face detection on the current frame using this xml we need to use i mean we're using opencv of course it's a very simple code it's just like detects faces pretty much but we do need to yeah we do need to change the frame to black and white though this is just an optimization because in a black and white image you can still you can still tell what a face is you know if a human can can still tell then the computer can still tell and then there's less data to deal with but the actual like you know recognition ability of a face isn't hindered by it being black and white so we just converted to black and white to greatly optimize it it increases it by a lot actually because rgb has three channels black and white only has one channel that's super interesting i had no idea that that would be an optimization so we're making a grayscale so that it actually reduces like the sort of not the amount of processing they have to do on the the video yeah because you're kind of just like jumbling rgmb together into one number you know red green and blue because then you can just kind of be like oh then you can just play with brightness you can be like okay um somebody's eyes look a little bit darker than their right cheeks something like that or somebody's eyebrows are darker than the forehead you can just you just want to see the relationship of brightness between different areas on the thing and those all added together if you do it enough you'll eventually define a face like okay eyebrows darker than forehead eyebrows darker than nose lips a little bit darker than cheeks eyes a little bit darker than cheeks stuff like that like hairline a little bit darker than um if you have dark hair so like it's just those kinds of things over and over um you eventually can can um explain to a computer what a face looks like after thousands of those little relationships or a car or pedestrian or anything or a smile in this case also like teeth you know teeth are whiter than your lips so like it would understand what a smile is nice okay that's that's awesome i would never have thought i would be optimization so that's that's cool also just to jump in chin moy kalia says again because of you i'm able to make my college fees by freelancing just wanted to throw that in i love stuff like that thank you i feel like these people are making making more money than us like i'm kind of kind of upset i know guys that's a guy make money so we can go to school to learn from people that are not us is that is that actually a win for us honey is that actually a win for us let's think about this for a second i think we should cut the stream okay abort yeah nice cut off signals oh got it what i love though anyways is that is this like literally so few lines of code to get this all working yeah that's what i love about it too and then if you if you optimize everything under the hood which is how you should be doing stuff like if you like c or c plus plus under the hood um then it's still pretty fast but you can be very expressive with your stuff i think that's why they choose it for machine learning because there's a lot of weird yeah there's a lot of weird nasty stuff and you actually see the power of python here later on if this was written in javascript it'd probably be like two or three times as long you know like yeah maybe not yeah i could vouch for that yeah of course this is this is this is nice and clean compared to javascript all right let's carry on yeah i don't like javascript yeah yeah i know no javascript is amazing sonny i don't want to hurt your feelings i know it's going to make me hook out guys you just see a video yeah reconnecting it but yeah let's continue on so once it's gray once it's gray okay this is actually requirement like opencv you have to take it um and so oh i should explain all this so what this is is opencv has a function called convert color which allows you to convert the color of an image um to to black and white or back and forth or just the red channel or just a blue channel you can do all different kinds of things but in our case we just want to change something from a color image to um gray okay i mean well this is a bgr which is rgb backwards and then two gray so that's all this means there's like different encodings we can use so we're gonna be using this one to convert this from a color image to gray so let's actually run this now go ahead and actually we need to display the actual black and white frame i feel like i've done this a bajillion times because i actually have it might be boring some people who've seen the other streams but whatever and there we go oh black and white webcam yep so you can still tell that this is the face you can still tell but my mouth is smiling so we don't need color to be already and stuff it actually looks like it's smoother it actually looks a bit smoother when it is yeah because there's there's only a third of the data you know with color you have three channels or four channels actually there's a brightness channel as well yeah um but on this one it's just the brightness channel that's nice that's it so it's actually four times as fast because there's one channel versus four channels awesome and let me just quit out on the terminal control c and let's just clear this up because it's getting messy nice all right so there we go black and white frame now it's literally as simple as popping this grayscale frame into our classifier for faces yeah and it'll spit out the coordinates of where my face is and then we can just draw a rectangle on my face and bada bing bada boom that's a face detector um that's the first and then we gotta do smiles you have to like overlap them in some weird way and there's some cool little there's a little trick i'll show you guys later that is critical for this to work and then some tuning you have to uh tune some variables at the end too which actually make it work properly but i love a simple you make it like yeah you know we just gotta use this machine learning classifier and then you know we're gonna get some coordinates right and then we just gotta draw a box around the face yeah there's no big use you gotta do that infinite loop i mean i'm explaining every line so i feel like people can follow along if they know python if not then uh you know i'll fire myself yeah donald trump nice yeah so let's go down here and actually just detect faces okay let's do that stop here i might go a little bit faster because i'm just kind of this is like repeating the face detection stream yeah we haven't even gotten to the smile stuff yet but here here's the line for detecting the actual faces okay so yep so how this is gonna work is we have our classifier up here okay face detection face detector which we created from this xml file which has like all the data about like what a face actually looks like depending on the brightness relationships like we talked about okay um like and then from there so we have this this phase detector now with this face detector okay with this face detector we can call a function called detect multiscale okay okay and then it just takes in an image and then um so what this will do it will tell us where all the faces are in this image okay it'll say oh there's a face here there's a face here there's a face here and that's what it'll do so is it returning an array yes an array of points okay an array of rectangles so the reason it's called detect multiscale is because you just want to detect uh faces of any scale so if there's a small face you want to detect a small face if there's a big face you want to take the big big face and you want to take multiples of them so you detect all of them that's why it's called detect multiscale uh uh because we can really pop in we can i mean we can use any detector like we have a dog detector or a cat detector we could also detect multiscale of cats or dogs okay so that's why it's called that nice okay so it takes in a frame a black and white frame and then it'll say okay at these at these places there are faces in this image and that's what this is so this is just an array of points yeah uh in my case there's it's gonna be array of length one because there's only one face but when i had the joker on the face um when i had joker on the screen too yeah and let me quick then there would actually be so when there was both of us yeah then there would be these faces would be a length two because there's two faces in the the in the video go ahead it makes sense yep so from there uh let's just print out actually uh faces okay so this is just gonna be a list let's just show this and it's going to spam the terminal here over and over again because we're in an infinite loop remember so as i'm here oh nice you can see the you can see the location of my face is being detected and then it's just being spit out here okay so like x y coordinates you know like blah blah blah yeah and then from this we can just draw a rectangle on the face that's it that's clean man i was expecting like some really intense stuff for that that's super clean how it comes back like yeah that's it so it's it's a it's a list of lists so if there's two faces so actually watch this now there's two faces hey look at that see how there's two faces on the screen yeah and then when i get rid of it we're back to one face the list is linked one not a list of of length two and there's two per them that's nice okay quiet and if there's three then you know three if there's a bajillion yeah or in the matrix you know mr anderson agents going i think it's what i'm saying guys like just from like that classifier you're able to do all of this so this is just the power of machine learning like and like yeah and as i said this is a face detector human face detector but you could easily go and pick up like a dog detector put that here and i guess it would do the same thing right you can detect anything so a hard cascade is a single algorithm that can detect any arbitrary object so basically we're you're like if the computer was a person we're literally downloading this is what a face looks like into its brain that's literally what this is doing you just have to teach this before we give it to it so this was a result of machine learning with a bunch of face images uh that somebody created and it takes probably like a few hours or a few days to create it but then once it's created then anybody can use it so that's kind of the power of it awesome got you yep and of course heart cascade is just one algorithm for for object detection whether whatever object happens to be in our case of face or smile yeah there's many algorithms but this is the simplest and oldest one it's actually based on viola jones um these names probably mean nothing but if you don't look it up look up viola jones algorithm yeah and then um our cascade so these are just names of people who came up with them back in like the 70s or 60s or whatever nice but awesome smart smart people yeah very smart people so okay so that's the face so uh from here we just want to draw those rectangles back on the image here and then when we show it then it'll actually have the rectangles drawn on this as well instead of just showing just the raw frame okay so that's really all we're doing uh then from there then we can get to the smile stuff so at this point we probably should at the beginning oh if you want to get to the smile part just skip ahead but it's too late this is a stream yeah for anybody watching the replay but i mean i guess it is what it is yeah 45 at 0.45 45 minutes or so like that's when we start the smart stuff so yeah we can add that in the comments afterwards uh yeah let's put the timestamps and then you know like the youtube has that nice that thing now or like where the play bar is like segmented that thing might blow exactly yeah that's insane bro you should do that that would be a cool clone to do you should be like youtube you know segmentation clone like you scrape out like the the stuff and you segment the video or something i don't know it would be cool yeah all right stay tuned tomorrow for that because sonny's the beast can code things in five minutes wait guys just as another reminder we actually have quite a few people on this live stream right now tomorrow if you're excited we are building a whatsapp clone so we are building a whatsapp film tomorrow it's going to use firebase it's going to have a realtime chat functionality so if you're excited about that smash the thumbs up and make sure you set a reminder have you coded imessages yet an imessage clone no that's a good idea yeah we'll do that as well yeah you should do that because either facebook messenger but you should do imessage too instead of whatsapp you know what i mean what's that is more internationally yeah yeah forget the android people all right okay so now what we want to do is we just want to run um we just want to draw some rectangles on the frame so i'm going to kind of go over this quickly if you're getting confused then again there the other videos go a little bit uh slower to explain this in detail but i'm just going to go a little bit faster okay because we're going a little longer longer than i thought it's already been an hour bro yeah but uh so are we going to do like i said faces is a list of points so we just want to iterate over all of the points so all of the faces that the the algorithm found let's just kind of list let's just iterate over all of them and pull out those points so like i said there's four points here for each face so um we're just going to iterate over all of them okay go ahead so uh the first point is x the x coordinate the second point is the y coordinate this is the top left point of the face yep and then this is the width and this is the height of how big that uh square a rectangle should be so for a face it's squares by default but for smiles it can be any shaped rectangle so it just gives us like the width and height of the rectangle so we're given a point and a height from that from there that's all we need to actually draw because we can say at this point go this far and then go down and you can just you can you can figure out the rest with math which is what we're going to do here go ahead okay nice so here uh cv2 allows you to draw stuff on frames so like like this we can draw rectangles we can also put text on the screen which is how i put the smiling little thing when it says smiling so you can also put text we'll do that later but for now we're just going to draw a rectangle okay so the way this works is you just give it the image you want to pop it on so in our case we want to we want to draw the rectangle back on the colored frame not the grayscale frame but the colored frame oh okay because we're only doing the calculations on the grayscale on the grayscale frame because the coordinates and everything is exactly the same but once we have the data of where the face is we can just use the color again okay so it's an optimization yep because you're doing the calculations on the black and white image but then we're actually still only seeing the color image which is what you want okay and for rectangle all you need is the top left point and bottom right point of the rectangle for it to draw because those two points it makes it easy to draw the rectangle so the top left point like we mentioned is x y that's what we have here then the bottom right point is just going to be x y but you add the width and the height to the correct coordinate so uh x you want to go an extra width because that's the width of the rectangle just go you just add w to it okay and then why you just want to add the height to it and those two together will be the bottom right point of the rectangle okay if you guys don't know this then just like look at your geometry yeah brush up a little bit x plus the width and then y plus the height and that will give us the square right like the rectangle sorry yep yep go ahead yep square root in our case it'll be a square but uh any rectangle you can draw any rectangle go ahead and what's the numbers on the right so what are these this so this is rgb the color of the rectangle okay um well technically bgr because it's backwards and opencv uh this is just a random color you can put whatever you want you can play these can go from zero to 255. okay uh you can use whatever color you want but i just chose this as a nice green color okay because like it kind of like it matched nicely with the joker the joker screenshot so this is just a random green color you can use use this if you want but you use whatever color you want then this is just the thickness of the rectangle okay nice or four pixels thick that's all so this is just like customization stuff this one line is going to draw the rectangle on that on that frame yep yep i'm just gonna draw on that frame well a single face on that single frame yeah so we're gonna draw all the faces on the frame then we're gonna display that frame nice and then on the second frame it'll detect all the faces in the second frame and then show all the faces in the second frame and then again third frame because we're in remember we're in another loop so this is a nested loop yeah and uh and there's going to be another nested loop within this one which is going to be crazy later on but yeah okay let's go ahead and run this to see if we can actually see the the rectangles that you just you just talked about yeah definitely so um displaying the colored frame here which is what we drew the rectangles on colored frame yeah and let's just run this as you can see here um this is the x point this is the y point yep this is the width and this is the height nice and faces are always squares by default because that's just the parameter they set so you can see the width and height is always the same within height is always the same but different sizes sometimes because detect multiscale it can be smaller or bigger okay awesome let's run this and there we go magic oh snap dude that's insane in javascript that would be like 30 lines of code you know just yeah yeah i know yeah it'd be something you know yeah this is where like i really do come back to python a bit like whoa yeah man you know you can do web development with python too you know you don't actually need javascript you know you just use django i'll fight you and i'll fight you and nas both yeah you might have a green circle around your face but you took it to the hook yeah with no legs right there's an enjoying goat guys i think we should just tell the community like sunny's good is so much stuff so when he joined the team a few months back um i was like one day we're on a team meeting i was like yo sonny you're so good at everything there has to be something effed up about you but he lives in uk we're all in los angeles so kazi was like hmm you know we've never seen sonny's legs and we're like he must be in a wheelchair or something like there's something here everyone thinks i don't have legs so he's always insecure and showing his legs in the in the video chats like yeah but guys at least at least today i i'm not the only one wearing a black shirt so you know is that is that a thing are you always wearing a black shirt that's always a thing dude everyone's always like yes and he's all sunny doesn't have any other shirts besides black tshirt he's like he's like steve jobs wears a whole um you know what's it called um turtleneck right yeah row neck and then they're like sonny wears a black tshirt every single time zuckerberg wears a blue tshirt right yeah like a gray tshirt it saves you time in the morning guys so that's why technically this is dark gray it's not black so you're still by yourself sonny oh but uh anyways let's get back to this so that's the face detection app basically you just repeated the face detection video but whatever so now um that's pretty good so like wouldn't wouldn't a small sector be as simple as just changing this out for a smile and writing the same thing well yeah let's try it i mean you would think so you would think so but you guys about to see some really really weird crap and then really really cool trick to fix that weird crap which is interesting it's a smart thing to do so let's create our smile detector okay let's create our smile detector okay yep so they smoke all correctly yeah there we go smile detect so same exact thing uh we're gonna be using hard cascade and um to detect faces but we can also use use it to detect smiles so in this case there's another file and description it's just called heart cascade dot smile i think let me double check down here yeah our cascade underscores smile yep and we just use this pretrained classifier instead so this took a bunch of images of people smiling with their teeth showing it doesn't it doesn't detect like regular smiles that good it's mostly like teeth smiles um from the training data but you can teach you to do both but in our case you kind of have to show your teeth for it to work like really well uh but that's there so why don't we just use this instead of the face like because it's detecting the face so well right like it was cracking my face perfectly and if there's multiple faces yeah shouldn't be able to detect smiles too supposedly supposedly so let's go down this code and make the changes okay so we have to we we get the webcam uh we want to iterate over every frame we want to read every frame in each iteration and then a little check and then frame grayscale so we get the current frame you change the grayscale now instead of detecting faces let's actually detect oops smiles okay nice okay like smiles and instead of on face detector let's call smile detector and we want to call it on this on the same frame so grayscale frame yeah and then again let's just copy this exact code but instead of and we can use the same variables because this and this loop will never overlap like this loop will completely finish before this loop starts so we can we can use the same variables which is fine okay keep it nice and clean look yep there's no if it was nested we cannot because then they would get um they'd fight over the variables but loop completes before this even starts so it's okay to use the same variables here right um but instead of faces let's draw smiles okay so now this is going to be so this is what it's doing is the same exact thing it's going to find all the smiles in the image and then return a list of points the exact same thing upper left hand point um upper lefthand point here and then the width and height of the smile in this case it's going to be like a horizontal rectangle instead of a square okay so it's returning the same thing right the same coordinates uh the same form yeah it's going to look just like this but instead of giving us the coordinates of faces is going to give us the coordinates of smiles it's like just a different rectangle on the image it's smaller around the mouth and it's like horizontal looking right uh let's change the color though i had a pre uh this color okay that's the color i chose it's like a nice red color yeah and because right now it's the same color as the face but i want to change it to this red color go ahead uh like i said bgr so r is at the end that's why it's so high so it looks more red because the r channel is the highest right okay red so let's run this and let's um let's actually not draw the sm the faces let's just get rid of the faces so i'm not even going to draw the faces okay so we're just going to we should just see yeah so not even faces it should just have things of smiles on my face right okay i mean they just have rectangles around the smile on my face yeah so let's run this and whoa voila as you can see it's working perfectly holy crap okay so this is well this one okay this is what you meant by it's just a lot it doesn't work for yeah yeah it doesn't it does not work but it does uh and i'll explain that in a second and how that actually works but as you can see right now the default it's like this isn't even working properly like what the hell like how like okay is that it's actually getting my smile look at my smile i was actually getting the smile yeah it's actually getting it so it's smart enough to find it but there's a lot of false positives like it's things this stuff over here like this little window sill is there because it probably thinks this white is like teeth and this is my lip or something yeah but i mean there's also getting things here on the freaking freaking curtain which makes no sense you know like like what i mean this may be a little bit too like it looks like the upper teeth and the lower teeth and the little gray line is like maybe the gap between the teeth a little bit we kind of understand maybe we just built a ghost detector or some you know like yeah that's what they said in the face detection video or the pedestrian tracking but yeah point is this is working like ass okay yeah uh so how do we fix this it's like this isn't even working um first let me explain why this is happening so there's a there's probably a couple reasons why i saw what this is happening and i'm gonna explain both okay uh first thing is so let's just quit out of this first so why is this performing so yeah i realize it's wearing screen it's fine it's fine first reason is to be honest uh faces are one of the very first things that people detected from the beginning um that's like the very like that it's like the coolest thing to detect to start with and it has like a very defining feature like detecting squares or detecting a soccer ball is kind of like okay it's kind of cool i guess um i think a face is like pretty cool right so there is a lot more data in this trained algorithm than there is anything else so there was actually just more phase data and this was just trained better than smile was to begin with so that's the first reason why face detection was working so well because it ran out more data for longer yeah while this one probably didn't get much data nice okay just because yeah it's like okay if you want to have like a left finger fingernail detector like there's not going to be as much data as faces just because faces are cooler or like a blade of grass detector like who codes that yeah you don't want to take vigilance and also bleeding guys like if you think about it a face has so many features you have like you have your eyes you have loads of things which which basically are going to tell that model that okay we can be sure that that's the face whereas a smile has a lot less to look for like you just have pretty much like the curvature of your smile that's why you kind of it can easily get confused like the lamp behind aaron has like a little curvature to it so it could get confusing that's a smile whereas a face has several different reference points that it will look for in terms of features so just something to bear in mind as to why you would get that that was the second point i was going to make you stored out of my mouth but that was absolutely correct guys yeah exactly what i was gonna say is yeah there's less features like detecting a tooth is much harder than detecting a face because how do you detect the tooth it's just like a it's just a flat white thing with like a specific shape but it's harder to detect yeah like it might get it might get a tooth and a marshmallow mixed up but it wouldn't get a face in a marshmallow mixed up unless you're the michelin man but uh or the or the or the pillberry tilbury uh guy you know the little little bakery guy but but yeah that's the point that sonny made right that's the second point so first one is face probably just has more data overall just because it's a more defining object and it has more emotional pressure to humans so it's like cool let's detect phases but also it just has more data that i can go by to determine hey is this a face or not versus a smile you're kind of limited nice go ahead so that is absolutely correct so that's why it's performing like ass i mean it could be better it could be better uh if they trained it better with more data yeah um but even then it's still hard harder to detect than a face right so how do we get around this well um first of all there's different parameters we can do so you can actually be like hey if uh something only counts as a smile if there's like two or three things around it that are also a smile because then it kind of thinks okay if this area kind of has like four smiles detected then it's a smile but if it's just one random thing that might kind of be a smile but there's only one instead of like four yeah then um you can go okay that's not small enough so like there's kind of like a redundancy okay code one more time explain that visually right so like here we're just getting a bunch of stuff okay yep um so but you can see like this random one over here just getting they're blipping up every now and then yeah so so are you usually gonna say that can get rid of those right so in a simple sort of like in a one sentence sort of answer like rather than checking the entire sort of webcam view we kind of want to narrow down that that sort of selection down to just your face right um not quite there that's the other optimization i'm gonna show but what i'm saying is um see how there's like random boxes showing up over here yeah like by themselves we can kind of get rid of all the standalone ones that just kind of flash really quick okay but if there's a big group yeah if there's a big group of boxes overlaid on top of each other though we can kind of say the chances of that actually being a smile is a little bit higher like up here we could maybe boil this down to like one smile we'd be like okay there's freaking seven boxes here this is probably a smile there's seven here this is probably a smile there's a bunch here there's probably a smile um but these little ones on the sides that are flashing randomly you can say now we don't want those right and we can actually get rid of that is there some kind of sensitivity or yep that's all it is it's just a sensitivity number and you have to tune it to faces so you find the perfect number which i'll show you guys in a little bit but we can actually do that so let's add that in and you won't see that much of an improvement here on this but i'll show you guys the second optimization which is going to clean everything up and make it go from complete ass to super super accurate which is pretty impressive nice so um detect so this happens in the detect multiscale okay so there's two different things called or two different parameters you can use called min neighbors and scale factor okay okay so let's get these yep here here we go so this let me actually type it out so this is going to be uh scale factor okay i think i might have spelled it and then this is going to be min neighbors okay um it might be the wrong spelling so it might not work but let's just try it so what this is gonna do is it says skill factor this is an optimization to how much you want to blur the image because if you blurred this image you can still kind of tell it's a face if you don't blur it too much okay and then if you blur it that's another optimization on top of the black and white okay you can kind of like generalize and then you can kind of compare the data a little bit more um because there's less data but you can still kind of tell it's a face so you want to kind of optimize this basically this scale factor is blur like how much do you want to blur the image to make it easier to detect faces and kind of like um get the defining features in brightness um or or not so the higher this number then the more it'll get blurred so i found the 1.7 is the best right so just just to be clear there so you're saying essentially to blur the the the sort of the entire frame so that way it will be easier to detect facial features as opposed to like a curtain or like a lampshade yeah because you get a lot of rid of a lot of the details which are unimportant so like if there was like a 4k image and there's a lot of details then it can get very confused with the data but if you blur it enough you can kind of if you blur it like a crap load you can kind of be like okay um there's kind of a blurry face in the middle and then everything else is just like a blurred mess in the background so it actually kind of like contrasts like the objects you can be like okay there's a face and then there's a bunch of blurred background you can't even tell if it's curtain or wall or whatever but you can kind of be like okay there's a face here go ahead okay nice so that's the idea if you can blur it down more you can actually detect faces even better yeah then mid neighbors is what i was just talking about um there has to be 20 neighboring rectangles in total in that little area for it to actually count as a smile okay so if this was one then literally just everything would be passed through but if you make this higher then it's like okay there needs to be a lot of redundant rectangles on this one little area for this to actually be a smile so it's like i found 20 smiles in this little region of the image because they're all overlapping it has 20 neighbors the minimum amount of neighbors of a rectangle needs to be 20 for it to actually be counted as a smile so this will help a little bit yeah let me show you guys and then um well actually not even at all like well actually it helps a lot oh one sec one more than before all right so there we go all right yep right back there you go so as you can see okay it's actually it's actually better a lot better that's what i mean yeah there's still a few things so here yeah i don't know why it's so fixated on this light it's probably thinking that this is teeth it's probably looking for like a yeah a horizontal line of white so it's thinking this is tea okay i mean like you can see why the lamb i mean the top left is a bit of this weird one yeah but i mean you can kind of see like this little white oval and my teeth look similar yeah yeah yeah so it's probably trying to find like teeth and then the curvature of your mouth okay yeah so something like that uh so that works really really well so like a lot of fine tuning needs to be done for things to work properly so just that little change there that worked way better than when i was testing it but uh i mean that's amazing so um tuning tuning different numbers can actually play a big big role in that so like maybe like in a real world application if you're detecting smiles you would want to save these numbers okay and be like okay for smiles always use these parameters this is like additional machine learning on top of all the the crazy numbers machine learning that's in here you have this plus a little bit more so this is kind of like this is kind of like manual machine learning you manually went through and tested a bunch of different sensitivities and you used your eyes to be like okay this is actually machine learning so that you actually taught the computer that these two numbers are closer to a smile than anything else so this is like manual machine learning that that you're doing okay pretty cool yeah nice um okay now going forward uh another optimization that we can do is actually get rid of uh these these errors because like sunny said and what i said in the slides is smiles only show up in faces yeah so why don't we instead of trying to get it across the entire frame just find a face and then only run small detection within that face yeah because we already already did the work of the face detection so why don't we do that that's awesome and that's what we can do next because it makes it faster and more accurate yeah when i first thought about i kind of thought that like oh we're just going to slap a model on the entire webcam and they'll figure it out but guys you have to be prepared like uh take it in mind that you you there's a lot to process it remember in the beginning we said like you pretty much have some kind of input your model and then some kind of output so if you can reduce the amount of input going into the model you can actually speed up the entire thing a lot more like and it's drastically going to be faster and it's also going to be like more reliable in terms of we're only going to select aaron's face and then find the smile inside there so something yeah yeah yeah on the selfdriving car live stream we did the car and pedestrian stream tracking one you can see a really good example of this in real time when we're doing it because there's so many cars on a highway so some highway footage there are so many cars and a lot of pedestrians because because here you're only taking like two or three yeah but in those there's like 10 cars and 20 pedestrians so it was going crazy um when you when you do that one when you um scale it down so if you blur the image more it's faster if you make it black and white it's faster and then some other optimizations you can actually see the footage gets played back really really fast so that's a good visualization if you go check it out go watch that stream too it's nice it's badass as well yeah go check that one out guys i'm going to watch that one as well not watching my content i know i do i do i'm the guy smacking the smashing the dislike i'm joking wow okay so we'll go up this morning he was like aaron i'm really grumpy i don't want to do the stream and i was like bro i need you i don't have my internet stuck i need you man and then uh then he's like now now he's all in a better mood because he's been hanging out with me it's fun we'll definitely do some more streams yeah this will be cool we can even probably do some kind of python react you know like yeah dude let's do that we could like tie it together like do like a cool front end app with uh javascript and we can have some cool like backend python stuff like happening like this you know yeah like a frontend thing where you click like smile detector face detector you know like car pedestrian detector and have like different you pick different files and it feeds it in yeah something some people like that exactly that was awesome uh aaron quick question here from shantao he says is it beginner friendly so just maybe a quick answer to that is this video beginner friendly or is the other ones beginning yeah like just for anyone that's new to the video or who might have joined afterwards is this video beginner friendly like do you need to know python before you do this yes you need to know python but if you know like for loops and all the basic python stuff and how to like call functions then no you know i teach you the rest from there but you do need i don't teach the basics here so you gotta learn the basics then you can come back if you're if you're a complete from zero beginner no if you're just a beginner who knows python but you haven't coded much then yes you can go through this yeah and also just worth mentioning guys i don't code much python but i know javascript so coming to this is actually super super simple in terms of how aaron's broken it down so if you have any coding experience then yeah you can do this so definitely go ahead and do it yeah very straight awesome so i popped back in the faces so let's do this now okay yep let's go back to the terminal and run it again and now we should have uh error oh cause i commented out faces so it's giving me an error because i'm trying to use faces here yeah when i commented it out let's just get rid of that and run it again so there we go so we got the faces here and the smiles nice hey look at that yep awesome but i mean it's still getting this you want to get rid of all these random ones yeah so what we can do like i said is we can actually just run small detection within this window instead of the whole frame which is a smart optimization because i mean in the real world you wouldn't see a smile out in the middle of nowhere unless it was like a piece of art or like dentures or something you know but generally smiles only show up within a face so that's why um we can do this nice okay yep and then i actually show the effect effectiveness of that too i'll get rid of these tuned parameters and actually show you how well that works okay um yeah i mean it kind of works well but those like these scaling factors the sensitivity plus the that little trick together makes it super accurate from what we had before just like freaking right all over the frame just a single smile like like we tuned that down from just two little things so that's it's like really smart clever things to to make your code work using something that doesn't work and making it work yeah with a few numbers awesome yeah so let's continue okay so how do we actually make it so that we only check within a face if there's a smile so how do we actually make it so that we only check within a face if there's a smile okay so like like we said we're in the the global loop here that is looping over the entire frame we read the frame so from here we keep going down blah blah blah and then we get to uh faces okay okay oops run small detection within each of the faces uh run face detection so some of these comments might have not made sense the entire time because they kept popping them so this is what i had before run face detection but now we want to actually do this within each of those faces this is what we're currently going to be installing so how do we do that okay let's look at it just from here so we we we're in the frame and then we find all the faces and we have all the boxes of frames so we have the box of of a face so we have the box of what a face is yeah we draw that box right okay but we have this box so this is actually the box we want to look at this is actually the sub image of the whole image that we want to find smiles we're actually giving it right here but so we can actually just be like okay instead of looking at the whole frame just look at this rectangle for the smiles instead okay and that's what we're gonna do so how do we do that there could be multiple smiles within a face though right if i mean not technically but if there's errors like it might detect like a little just before your mouth so you just want to make sure you find all of them so what we're going to do is we're actually going to have another loop in here is be nested because within a face you have to find all the smiles okay so we're actually going to need to um find the xy um width height of each smile within the face so same thing we're just nesting it okay does that make sense so far yeah quick thing is though because yeah quick right this is a python question so you have uh are your variable names not gonna clash here or is it gonna be in a scope they will okay no they will they will right um i believe i'm 99 sure i didn't even try because i thought they would uh but i'm pretty sure they will so what you can do is you could use like capital letters or something i believe it's case sensitive yeah but you probably don't want to do that what i did is just a little sloppy but i just did this okay just so they don't contend but it keeps it simpler because if you start doing stuff like this the codes start looking really hard on the eyes yeah um because this is so so clean you know x y x w y plus h yeah keep it nice and clear but if we started doing this then it would look like you know over again x smile plus y smart like yeah it starts looking like that yeah so yeah so i just did this just uh it's a little bit messier but it's it's still easy to understand i just added an underscore to the end okay okay so we're going to need to look over uh the face okay okay um i mean i should probably talk about getting the subset first uh let me go over the logic first so what we want to do is you want to find uh in the face okay so you want to find all the smiles in the face okay so uh find all smiles in the face okay so we're gonna do this doesn't exist yet but i'm just using this as a placeholder thing for right now this code will not work because it's currently broken yeah and then just draw um draw all the rectangles around the smile okay or the rectangles just like that oh shut up dude it must be an american thing okay let me yeah let's just do this so it doesn't break uh oh yeah i was making fun of your spelling before right yeah oh god that's hilarious that that backfired didn't it uh anyways so this is the kind of idea we're gonna iterate over um all the faces and then with each of all within each of those faces we're gonna find all the smiles okay and then we just want to draw the rectangle in there so kind of slimmer to what we did here actually okay the only caveat is you have to change the the names here yeah um so why don't we do that actually let me just uh copy this down here so this is the same exact code as we had before we just want to draw a rectangle around the smile okay okay and then instead of x y uh w and h it's just going to be this okay just add the underscores to the end okay it's kind of hard on the eyes but if you space it out like this it's not too bad so so just to bring everyone to speed right now we had an initial loop which was going through all of the faces and then so that was the first one on line 28. so i was going through all the faces and then on line 34 we're going through the individual face that it detects because you might have more than one place and then when you get a rectangle around that individual face right uh no uh within each of those faces you want to find all the smiles and draw a rectangle around all those smiles so what we're going to want to do is um we're going to want to actually not run this here we're going to want to run this oops we're going to want to run this here okay okay yep well i actually not here uh that's incorrect um but i need to explain something else first where do we get actually where do we get the face from is that like placeholder for now or that's um yeah i'm about to explain that this is the tricky part and this is the really cool part so let's just pretend that the face equals this for now okay this code doesn't actually work but this is what it is in flavor okay yeah just pretend this code does not work this code does not work but this is the idea we want the face to be this little mini sub image within the whole image because this is the current face like the little square that surrounds the face so you want this to be like a little image but the thing is um you can't just pass in like these uh detect multiscale and get the get the smiles out of this we have to do some crafty stuff here with the array and and slicing but just this is the idea is that clear sunny yeah yep oh yeah if it makes sense to you then hopefully kind of playing into an object right kind of well what we're going to do is we're just going to slice and tool into the image and get like a sub image in some cool way i'll show in a bit but i just want to show the overall logic first before i do that yeah yep so let's walk through this again so yeah we have all the faces here then we draw the rectangle around the face then we say okay get this little square image instead of the whole frame just get this little square now within this little square use that to detect multiscale so we want instead of looking at frame grayscale we want to actually look at the face okay so let's um uh of course we have to go to grayscale again though for the same reason we have to convert this face because if this was if this was a color image then we would need to change the face to a black and white color image like actually let me show you here this is actually a good uh thing so i said step one okay we want to find faces in our image yep okay then step two get just this so that we don't we don't have to search we don't have to search the whole image instead of searching the whole image we're only going to search within this face so now this is we're doing that because we were getting like random sort of findings outside the face yeah okay yeah we're kind of just eliminating everything outside of the face as automatically no even if it says yes it's going to say no because we know that smiles only show up on faces right okay then step two we find smiles within those faces so we're only going to search within these bounds and then at the end we'll do a nice little labeling that we haven't gotten to yet go ahead but yeah so the idea is the face this is going to be this okay okay so this is so this is frame this is the whole frame this is the face okay okay so we need to get this but it's still color so we need to make this black and white as well just the same as the other image yeah so let's go back and um call or is it let me just copy paste this and change it to face grayscale okay so face gray scale is going to be the face so same idea here we have the face the colored face but now we want to change the black and white so we use the convert color function again okay and we pass in the face the color face we say change it from color to gray okay and save it as face grayscale right okay then now in the small detector now instead of detecting it on the whole grayscale frame let's only run it on the grayscale face go ahead okay yep right there and now now this should be working but the only caveat is this doesn't exist yet properly this doesn't actually work but this is the general idea so once we have um this then we can run the smile detector only on the face there okay and then uh then then we can draw all the rectangles around the smiles within that face after we find the coordinates of smiles so it's actually going to be smiles right i'm with you now they should be a little more clear yeah awesome great so yep find faces draw the rectangles get the little face change the little face to grayscale run smile detector on that little face then draw all the rectangles on that little face go ahead and then and that's how we're gonna get uh this kind of behavior okay awesome so you can see how there's no no red boxes outside of the face it's only within the face yup yup you said yep like a bajillion times on the stream bro i'm kind of confused on so we have the oh okay no i see now because you're doing it on face grayscale and then that's where smiles comes from okay no that makes sense cool got you so you're writing smiles on the face you're not running smiles on the whole frame yeah that's why i was a bit lost yeah so that's there um so this should work in theory right but the thing is uh this doesn't work so how do we do this one little line of code so this is a little tricky i'm gonna have to explain it but it actually is just a one liner can we can actually achieve this but i need to explain how it's done and there's some weird um details that i'm gonna explain um so let's get rid of this okay run smaller sizes with each of those faces because we actually just copied that from over here we just added the underscores at the end so we don't overlap with the variable names uh this remains unchanged you still want to still want to display the current frame and the weight key of one millisecond and then release everything at the end of the auto but how do we do this okay so um we have the frame right we have the overall frame but uh and then we also have the face xywh so how do we get a sub image of um this whole image like if you have a big image like right here you have a big image how do we find this sub image so you can kind of just how do i cut out just that image right yeah cut out that image right um there's there might be like a sub image function opencv but i didn't want to do it that way because i wanted to show you guys this smarter way of doing it or maybe more efficient way it's it's a little bit different so uh do you are you guys familiar with slicing in python i mean if you know the basics of python okay i mean i'm new to python so i even even if you run through that it'd be kind of cool to see you got it yep okay so let's look at this little environment here let me open up a python environment completely separate you start python and this is python2 it's fine though python2 is fine okay um it's the same thing so let's say we have a list okay yep and let's just call it um list let's just call it l okay whatever so we have a list let's call it color of in colors uh i'm trying to think well people yeah yeah yeah yeah colors let's do colors let's just do red blue oh yeah blue green yellow black white that's good okay so we have six six colors here okay this is a good length list okay and let's hit enter uh red oh because it needs to be strings i was just wondering i was like can you do that in python yeah i wanted to see if you could do that yeah nice okay one second yeah little mistake there there we go okay now we have a list of strings colors plural got it yep colors okay there we go so now we have our list okay we have a list called colors and it has all these in here now as you know we can index in two colors with a zero and we would get what sunny you'd get the red absolutely yeah and we can index that one blue get blue and two to get green so on and so forth okay so we can index pretty straightforward in python you can also slice okay so you can get instead of just indexing at the first one or just the second one you can actually get a subset of it you can get like the first three so you could say like from point zero for two points forward from point zero get me like red blue green or something like that exactly we could get like just these two or we could get just these three or we could get just these four um it's called slicing because you can slice up the list into like some some um you can trim it to whatever you want okay so the way you do that is you use a colon okay you put a colon here and then you just put the first and the last so very simple it's so nice and hyphen dude i know man that's why javascript sucks lasting in javascript a little bit more confusing but yeah that makes sense for you yeah that's all it is so what this is saying is for in colors give me the sub list from zero to three so it'll have red which is zero it'll have blue which is one it'll have green which is two and it won't have yellow which is three so it includes the first one but does not include the last one right so it's going to give us element zero element one and element two but not a limit three so zero one and two it should give us this as a list when i hit enter okay red blue green i'm gonna hit it that's exactly what you get okay nice that's how you slice um of course if i what is it so zero one two three four five if i put five it would ignore white so let's try that it would give us everything except for the white but if i put six okay then it would actually which doesn't exist then it should give us all of it or it might break let me see if it breaks no it doesn't so there's a safe check so six goes past here and it'll give you everything up to six because this is five nice um alternatively because this is the maximum list you can just not give it and it'll just say zero to the end of the list oh nice okay and vice versa you could even be like beginning of the list up to four i've seen that in a tutorial somewhere that's nice yeah awesome yep you can just do that so this is like zero this is the same as saying zero to four yeah um it's cool stuff like that uh one more cool thing i want to teach you guys is you can actually be like from zero to six and you can actually add another colon okay and what this is is the stride so if you put two it's going to skip every two so this one this this would actually give us red stride of two instead of if it was straight of one it would give us every one but straight up two will give us red and then skip one then green skip one black so this should give us red green black okay there you go that's insane dude i love that right right that's nice um yeah that's cool so red green black and again if i put a stride of three it would jump in groups of three so it would go red skip skip yellow skip skip nothing it would just be red yellow so let's try this there you go and then again if you did if you did straddle four it would go red skip skip skip black skip and then nothing else so this would just be red black nice boom but guys that's how you do that that's something new even for me like slicing in python so if you guys found that useful what can they do aaron um they can uh send a money request to my uh request to my paypal yeah now you guys can smash the like button uh show us if you guys if your minds are blown just show us um tell us in the comments or if i'm being boring and going over basics um but oh yeah guys i think that's awesome honestly because like i didn't actually know that you could do that in python so awesome to see how you do that nice and we're not even done yet bro we're only halfway there look at this watch this so this is called striding this is called slicing the first colon is slicing the second colon is called striding because you wanted to define your stride okay you can be like if a stride one is the same as not having a stride at all yeah and if you delete it like having like we said it's like having nothing there okay one by default the cool thing is you can also reverse a list by using negative numbers so now instead of going from zero to six you'll go from six to zero and this will actually reverse the whole list no way wait oops um let's try this there we go so now it's reversed what here let me actually explain that so yeah um actually this didn't work i made a mistake there so zero to six yeah um this determines the direction of this of the stride so it's still going to go from index zero which is red to index six or five which is white but it's going in the right direction should you have done you're starting zero zero exactly bro exactly she done six zero because negative means you want to go in the left direction so you want to start from index six um which is really well actually that's incorrect you wanna start from index five because remember the first one is inclusive yeah so you wanna start from index five it'll include it and it'll exclude this last one kodi kodi joshi actually pointed out in the comments nice he goes also that reverses the list nice yeah awesome yep so if you did that then um it'll go through the reason um this isn't going the first one red at the beginning is getting deleted remember blue there's supposed to be a red at the end but it's getting deleted because it doesn't include zero so you could technically put negative one okay and then um okay it doesn't work but i mean i thought it would but if you just like if you just omit it and don't have it there at all then it kind of says like um to go from the beginning all the way to the beginning but don't stop at zero go like one further okay so this is kind of similar to like like when you omit it you just kind of like go to the end when there's not a number there nice so this would be reversing the lip reversing the list i've been talking too much one second that's really powerful that's massively powerful because even in javascript like to reverse a list you can do i mean there are tricks around it but it's it's not as clean as that like that's that's really nice yeah yeah so python makes it nice for like dealing with complex problems which happens a lot in machine learning you want to be able to express these ideas really simply so this looks simple but when you have to do like crazy slicing and like like seven dimensional arrays on like different images of like things things this adds up quickly so it's difficult in python and impossible in javascript so that's why python is the best sunny crossover and if we do a collab with like a reaction that django it's gonna be bickering the whole time this fight like es6 is better than this slicing [Laughter] but yeah so that's that's slicing and striding and using negative strides okay so very very cool there um so we can do that and then of course we can omit uh omit both of them and by default because it's negative it'll just start because it's negative it'll start from the right most spot and go to the left because negative means going to the left so this will also work for reversing a list so this is how you can reverse any list in python with one little line so you have colors yeah and then you have colors at negative one so this and this are reversed got you cool stuff awesome now i'm gonna talk about slicing multidimensional arrays which is what an image is you can actually slice an image by using the same thing and just get a sub multidimensional array from that big array by using the same thing okay so that's why this is relevant so let's say you had um a multimeter right because this this can be kind of hard to explain visually with this example uh okay let's clear let's quit out of this okay clear seller clear and then let's go back into python um let's have a multidimensional array okay yup and let's have one two three four okay yep five six seven eight because this is and one array with three arrays inside of it so far and four okay we've got four right 14 16. so this should be like a um it might be it's going to be kind of hard to do it in here can i could you have like a new line on here i mean if you log in now if you do mra actually let me let me um i kind of want to explain this uh i don't want to i don't want to dirty i don't want to start editing stuff in here because it might get confusing yeah also guys i just wanted to say we just are nearly about to hit 800 likes so massive thank you guys and if you haven't already smash the thumbs up because aaron's about to drop some knowledge on python tricks and tips nice holy crap uh actually let's just try to jump into the code i feel like people probably understand slicing enough at this point to like like translate over the ideas like i don't want to drag on too long because i spent 20 minutes explaining slicing yeah so this is this is the goal we have a frame we have a face in that frame with our coordinates how do we get this as an image of here as a sub image well we can just use slicing with these numbers to slice a portion of this frame which is just a multidimensional array okay and that will actually give us an image instead of just this point because all we have is points and then we're actually drawing a rectangle on it ourself uh up here we're just drawing a rectangle around it but we actually want to get like the full image like all the pixel data of this bounding box okay so the way we do that is instead of doing it this way we actually want to have the face be um a slice so what you want to do is you want to take the frame okay and for a multidimensional array you can actually slice in both dimensions so what we could do is we could be like okay from zero to the end in the x dimension and from zero to the end in the y dimension remember how to slice okay so this will just this will just say get the whole frame this is actually the same thing as representing the whole frame because from zero you're getting every single um you're getting every single uh column and every single row and every single column i'm getting the x and y confused i gotta double check which one is which but we'll try both we'll learn together we're fresh together but uh one is x and one is y and um of course if you had like a 3d threedimensional thing then you could even slice it in three dimensions like if you had a cube and then you want to like find like some subset some cube in there or some rectangle inside there you could also slice that way okay the idea is this zero to the end and zero to the end this will give us the full frame um so you can probably see where i'm going with this uh all we need to do is just utilize these four numbers to actually define the exact frame the exact subframe of the full frame that we want okay yep and so that's really simple i mean all you want to do is just slice so um where do we want to start so from the beginning the top left corner of it is going to be uh x okay and then x plus width okay that's it and then in the y direction we're gonna have y and y plus height that's that's literally it okay so we're going to slice this whole frame and get the sub frame of x x plus w and y y plus h but i'm pretty sure this is backwards i think y needs to come first um i think i just eliminate something so i'm pretty sure y has to come first and then of course if we had a z coordinate as well you would want to do like uh z and then z plus depth or something but we don't have this we're not doing crazy like 3d modeling here we're just doing images but i mean i'm just showing here um that you can do this one thing i do need to point out very very very important is this does actually not work this does not work in vanilla python the reason this does work is because opencv is built on numpy and numpy this works this works in numpy numpy is a library for dealing with numbers and matrices um in python very powerful and it allows you to do cool stuff like this but this is not in vanilla python so that's why in this terminal it wasn't going to work and i didn't want to explain it here because this wouldn't actually work you need to import numpy which is just um numpy like that okay i mean i guess i could have uh defined it here so let me actually show this a little bit uh yeah cause i'm i kinda get it and then there's a little bit of a gap so yeah it'll be handy to go through this yeah yeah um but i think i think it's like a pretty print in in numpy i think it's isn't it oh print f is uh variables uh yeah what is it what is the numpy nice print how to pretty print a numpy array without scientific notation asking if this live will be saved yes this will be available afterwards all of the live streams are available afterwards guys yeah format i mean there might not be a pretty way to print it that's the thing i didn't think there was that's why i can't remember uh yeah i gotta do some some crazy um stuff yeah actually let me just have like is there like a grid of numbers and maybe uh what are we trying to show right now um you wanted to see how how this is getting sliced right yep i think i think maybe we could do it here i think it might be clear on just on the terminal okay the thing is i don't know how to print um okay or let's just try it yeah let's just try it yeah from here so you guys can kind of see like it's not nice and formatted like vertically i was hoping we could like ver because this is a four by four four by four uh um twodimensional matrices yeah because we have a list of length four and each of those there's a list of length fourth in those so it's like a four by four box actually if we layer these on top of each other okay but we can actually slice like i said using the comma and colons somebody said np dot array i'm not sure if np dot array have you heard of that's what it is yeah you just print um np dot l but thank you kodi joshi for that so it says np dot uh array and then open parentheses and then square brackets inside wait what no i know i know i know what he's saying it's coming back to me because i haven't used numpy in a few weeks so i kind of forget it can you type it uh is it in the comments you could do four line in array ah i don't know i don't iterate over it you know yeah i think it's um array.l or something numpy pretty print array i mean we're back here what did he say exactly somebody said import numpy uh or numpy as mp first and then so then you'd end up doing numpy dot array so you could do numpy.org would you numpy the ori oh yeah because yeah you import numpy so numpy or just or just uh no no i think you do numpy dot array and then open parentheses l ah there we go hey thank you guys that's awesome i thought it was pretty print but i mean that's that's the normal yeah all right there we go so this was talking about we have a double double uh twodimensional array here yeah uh four by four so this is easier to visualize what i was trying to do from the beginning yeah oh god guys i think i think he deserves a thumbs up terrible oh we'll hire him have him teach it yeah number three nice um i don't know it wasn't popping up because yeah remember it was something simple with the array but they're like iterating through all the crap i'm like okay i don't want to have to do all that again but anyways uh so here the way we can slice this is you can go by the y dimension then the x dimension so um let's just slice this so let's start with the y dimension let's just get the first two okay okay um so this is the first dimension so what we're doing here is we're getting the first element and the second element so in this over array we're getting the first element which is this list and the second element which is this list okay is that clear yep and now so we we're getting this now what if we wanted to get like this three four and the seven eight as like the the sub sub array of the whole thing then all we want to do is just pop in a um oh i think we are no so the element two oh wait we want to go from element two we're back okay we're back i think i lost you for a second aaron did we we lost the stream for a sec uh i don't know if it was i think it was skype i think it might have just been skype oh it just broke down for a sec yeah all right we're good anyways um so if we have uh the first two elements here um slicing from zero to two one two three four and five six seven eight we're essentially getting these first two the first is like elements because zero up to two but not including two yeah uh now if we want to get this sub array three four seven eight then we're going to need to further uh well actually let's do this subarray two three six seven okay how would we get this out of this whole thing okay well again it's just gonna be a simple slice um but within each of these arrays this is element zero and this is element one so we want to go from element one to element uh two but this isn't included so element three um will give us these two if we say element three right yeah it makes sense sunny yep we're good and this but i think it might be backwards yeah it's backwards so um when you're adding when you're adding uh dimensions to the array you need to actually go in reverse order so it's going to be like this okay so this will give us from these two to these two and then also of these first two rays okay i believe yeah i mean it might might break uh indices do you have questions huh do you have to use the opencv uh opencv is built on nonpartners i mean will they utilize numpy opencv is but you're inside of um you're inside of it yeah that's what screw me up yeah because i need to call the numpy stuff yeah getting turned around over and over still not working um i should have brushed up on my numpy syntax before this i wasn't expecting to show it in here i was just going to show the opencv part uh but all right okay guys let's investigate together so whenever you forget code just you know go to google and and figure it out um how to display numpy uh subreddit i mean it should work i just i don't know why it's not working because it was working in the uh opencv here oh maybe you gotta do uh numpy array well let's let's display the type so this should be a numpy array so let's print the type just make sure that typing is all correct so when we actually somebody said store that in a variable and then use that so i think what we need to do is memory thing yeah how about even you see have it as you had it before it's a number array but i have the square brackets outside the parentheses the score back it's outside the parenthesis uh this is so you know you've got um numpy.al yeah yeah do that and then have the square brackets outside the parentheses outside the parentheses what do you mean the score brackets like did you numpy yeah l and then and then out so outside that bracket so i have l inside the brackets yeah outside the brackets have square brackets so so now on the right so on the right uh put the square brackets and do one three zero two would that work no no so outside the parentheses outside the parentheses yeah oh just index like this directly i think this might actually work no no i was saying so so i have numpy.l yeah and then and then change them print yeah and then get rid of the parentheses just make square brackets oh dang coding in this terminal is terrible yeah no yeah like that maybe that will work yeah hey there we go okay because then you then you're doing it on the object yeah you're getting back yeah but i mean this is also wrong this is uh index you get wrong yeah you get all turned around with these numbers um okay let's let's try the other way around zero and two one and three two three six seven let's see there we go nice all right we finally got it guys so the ordering is um if you wanted to get this sub array then in numpy using raw numpy if you're to do it then you need to use the numpy dot array um get the list so this is um because l is just what is l l l yeah l is just a raw python list okay so we have to convert it to an array here yeah you have to explicitly convert it to an array by using numpy dot array change this and then once it's in numpy form then you can index it like i was saying you can't actually do this on vanilla python yeah so that's where um not enough coffee man i run out of coffee and now and and what we're doing with that indexing is we're saying get the first and second array inside of the the sort uh overall array and then we're saying slice it to get the the the first and second uh first and second in the um y direction so in the y direction you know going top and bottom yeah then we want to get the first and second and then in the x direction you want to go from index one to three so we're getting these two and then from one to three it's going to be these two sunny is also becoming pro in python hey let's go yeah but not not as pro as the guy that was helping me out because i'm just here forgetting about numpy it's been a bit but oh i think we lost aaron again but just treat me he's back this ray i think i lost you for a second aaron we're back we're back oh my god this internet man also just yeah just want to add a comment here so surah rajput says hello there i recently joined pwj community it's awesome and i'm really excited welcome dude i love seeing our own students on the on the streams we can see here so here um this is a casting list this python list okay aaron's internet is being a little janky or is it me i'm not sure if it is connecting uh all right now we have it did it cut the stream no no i don't think it's kind of stream i think it's uh it's okay good yeah so just lagging don't worry let's go let's carry on yeah we'll carry on sunny yep okay okay got it i think it's the shoddy connection yeah i i can't hear you man you can't be there okay cool so like the lag i think there's a huge lag okay oh we've lost we've lost aaron on the stream okay so aaron do you want to share your screen yeah can you hear yeah uh bear with us guys a little bit of an internet moment i'm not sure if y'all or aaron okay i think we're back yeah i've got you now i've got you can you come back sonny yeah all right good good yeah i think there's a internet hiccup there can you hear me oh dude before yeah so can you hear me now yep what was happening what's happening yeah we just got a 50 i think it's mexican dollars super chat from jessica apollina saying i love your streaming i don't have that's a professional experience in python although i'm fond of learning and build my personal projects huge huge thank you jessica that's that's insane we massively appreciate you watching this and yeah like hope keep on enjoying this the content that's that's insane love that especially when we just had some some streaming difficulties but we're we're back we're back nice let's go and coding difficulties yeah like i'm running on three hours of sleep bro this is not yeah why did i do this uh but um what was that saying so yeah here in the numpy i ironed this out so the issue i was making was this is a python list but you got to make sure i'm pilot so you gotta pop into the right function and then from there you can slice in this manner so what i want to make that that parallel here an opencv it's much easier because everything is a numpy array by default like the frame here is this is a numpy array so you can just slice it normally um instead of having to do the whole the whole numpy i don't you don't have to actually make a numpy right yourself okay um but i'll try not to forget that again but yeah so this numpy right and then we slice it like this and again so we're going to do the y direction first and x direction second so this is actually the correct way of doing this back coming back to our application okay so let's delete this out and the sub a frame yeah using uh high uh n dimensional slicing nice okay all right that might be kind of big but there we go yep so opencv built a numpy superpower and uh going forward this should work so let's walk through this again just to touch base again because that was a long ass tangent these streams go on way too long and just want some breakfast don't worry everybody look at all the faces within the frame yeah i can't even see the stream because i'm just in my code but i'm trusting you there's we have like two viewers right two no no no no we're good we got we got about 250 people here dude dope yeah lag is super bad like you reply like six seconds yeah i know but it's okay so just keep going keep going keep going we're good good um all right sonny i don't know if it's a holy crap this internet man really killing uh anyways so let me i'm just going to keep talking and that way it's like so we get the faces we find the the frame we use numpy slicing to get just the face and then we convert just the face to grayscale yep and then once we have just the face of grayscale then we can run the small detector on that little face and then print all the rectangles around those smiles and this out of here god damn it there we go yep we we there yep we're there that's sunny awesome so quit out let's run this one more time and see if it works hey dude there we go got it something something's uh oh yeah yeah i think the x and y is yeah so this is the one last thing i want to say um the area that's happening here is um so we're finding the faces right in front of the faces we're drawing the face uh we're drawing the rectangle around the face okay we're drawing a rectangle around my face that's the first step yep second step is we're getting the face here so we're creating the subarray and then we are searching for the um i mean we're making a great scale and then we're searching for the smiles within that face uh once we get those coordinates those are correct the issue is we're actually drawing the rectangle on the frame instead of on the little face so um the reason reason here is we're getting coordinates so within the face it's a little square right it's a little tiny square yep um when we run smiles on this little tiny square we're getting some coordinates back um in of like from for those smiles does that make sense sunny yep that makes sense so like actually it might be easier to explain here on the uh here so here holy crap here uh we're getting getting the face first and then get the sub image and then and then we want to find the smiles in here so the thing is because this is the sub image the xy point is actually pretty small it's starting from here and we're going to say okay go down this much y and go across this much x this is the top left point and this is the bottom right point and we can draw this the thing the problem is i was actually drawing this rectangle based on these coordinates so this was offset way up here in the left so it was actually taking this um y and this x and drawing it on the big big frame oh actually yeah we actually want to draw it within the little face so how we fix that i mean this actually doesn't matter too much because we're going to get rid of it and show small anyways but it just for additional purposes yeah and so i think it is a game of maya i think it is important some people might want to show that that rectangle you know yeah yeah yeah so we need to do is in smiles when we draw the rectangle instead of drawing it on frame right we actually want to draw it on the face so we take this sub image and we draw it on the face because before here oops when i smile see it's drawing like if you took this if you took this green square and put it in the top left you can kind of see that that's where my face would be my smile go ahead you see yeah yeah so we're just drawing it on the wrong frame right now if we go back here and we quit out uh if we quit out just interrupt that then um we can actually draw it on the face instead so uh this is another thing i want to say so the face is actually just a sub array of frame like i said okay but the thing is when you slice like this i believe you're actually just accessing the actual memory of this full frame so you're not making a copy you're not like saying oh this uh this is a new subarray that's equivalent to like this little range but you're actually saying just get me this portion of memory in this weird slice because you have direct access to the memory like that with numpy okay so if i change this data within here if i change the data of the frame within here then it'll actually change it on the mainframe as well because we're just saying okay this little slice of the whole frame um this editing this in here will also edit this which means editing the face will still edit the frame so we can still we can draw on the face which will work uh if you draw on the face then it'll actually also draw on the on the the master frame okay even though we're not drawing on the frame so that's that's how that works there because when you when opencv draws a rectangle it's actually just going into the the memory and just like changing the memory there there you yep so now let's try one more time and oh hey hello hey with that said guys we just hit over 850 likes just push that to 900 and if you found that cool and aaron and aaron guys aaron just debugged everything in front of you so i think he deserves a smasher thumbs up and just some just some numpy nightmare man yeah syntax numpy nightmare exactly that's the one thing i hate about numpy i wish they had i wish they had some nice like easier syntax to but it's all like function based that's the one downside but i know i mean numpy is awesome yeah and you used a lot you fixed it exactly so that's the main thing thanks thanks uh with help from the community yeah shout out shout out to whoever that was i couldn't find it on google and i was like ah i give up not important but anyways uh from here um now though but i mean this is cool but i mean this is kind of just like the same as face detection or car pedestrian tracking but it's like outlining it but i think it'd be more cool if it like just detected that i was smiling and put the word smiling underneath but i think it'd be more cool if it like just detected that i was smiling and put the word smiling underneath because you're only concerned with smiles if it's like a face you're like oh this face is smiling or this face is not smiling yeah so i think it's cool to um do that instead so let's do that next nice let's quit out of here and the very last thing we're going to do is instead of drawing this okay instead of drawing the rectangles around the smiles at all we're not even going to do that we're just going to completely ignore drawing the rectangles um i mean it was relevant because i wanted to show you the cool little like offset thing how the memory is actually being being saved here when you slice it's the same exact memory so it goes into the same memory and changes it um but i do want to show you how to put some text so i don't i want to avoid another syntax mistake though i'm the master copy paster uh yeah i think it was massively valuable to show them how to draw the actual smile because then it gives them context as to what we're gonna do next yeah yeah so i got rid of drawing the smile because i don't want that there but now i pasted this ugly looking thing here so what this is is now instead of drawing the rectangle around the smile i want to actually draw um the word smile uh i mean write the word smile smiling okay i have it right here smiling underneath the little um portion so like when i go here you can see smiling pops up for a few seconds that's that's what we're going to be doing now instead of having the right i think you're going to have an error because you said if smile length if length of smile so go back to the code is it meant to be plural if length of smiles because you've done smiles array um yeah i think so yeah so length of smiles is greater than zero yeah nice yeah because uh let me just double check yeah because down here i think i used um yeah yeah you smiled singular yeah so yep uh so yep so pretty much all i'm gonna say is if length of smiles is greater than zero because remember smiles is a list of all smiles it found within the face if it's greater than zero which means there's one or more smiles then we're just gonna put some text on the screen so this is very simple this whole thing here is just displaying the word smile at some coordinate so similar to a rectangle it's cv opencv.put text we're going to put text on the frame okay and that's the first thing the image the second argument is going to be the words you actually want to put so i'm going to just going to put smiling yeah or you can put like why so serious or something okay and then next is next is the location the top left point of where you want to display the text so in my case since i want to put the word smiling just outside the the green box of the whole face i'm going to use the green box coordinates okay okay so i want to put it below it so the x coordinate will be the same um but the y coordinate will be y coordinate plus the height right so i'm just going to actually draw this as you do it on the screen yeah because i think it might be handy so carry on talking over and i'll draw like as we do it i have it here if you want to yeah we can explain it here yeah let's do that yeah so um we have the coordinates so we know this this picture is smiling but we also but we want to put the word smiling down here instead of having this we want to have this yep so if we have um we know this is a yes so we know to display smiling then but how do we get the coordinates of this so we have the coordinates of the whole face which is what we want so why don't we just have the use this top left point to figure out how to get down here so we have the top left point which is x so we can just say at x is where you want the top left point of the text to start at x yep but then the y point we don't want it to start here because it would say smiling up here so we add um y this is y yeah plus h plus the height right so y and then we're saying plus the height which is this so like y which is going to be right here yeah and then i added and then i added 40 just to have a little bit so it's not touching the box i just added a little bit and then that's it so this is this point is going to be x and then y plus h plus a little bit more right so you guys that'll put it right here exactly we have x and y in the corner uh just go back to that that side for a second uh so we've got x and y in the corner and then we go we've got we're doing y plus the height and that gets us to the bottom of the box and then you see aaron's got smiling exactly but if he didn't add the 40 it would be sitting on top of the green right now or like oh yeah pretty much on top of it so it would just be touching yeah so we want to add 40 to basically get push it past that little bit extra so yeah awesome nice yup and that's really it guys so as you can see that's gonna be the x is the same and then y plus h plus 40 is right there so that's the top left point where the text is going to start then from there font scale is just the size of the font so size three um and then the font face is just the font you want to use so um opencv has different fonts so that font is called font underscore hershey underscore plane it's the one that looked the nicest you're kind of limited on the fonts but i mean it gets the job done and then last is the color so vgr again but all three are maxed out so this will be white because if all three channels are at maximum brightness 255 then it'll just be white nice so if we run this hopefully with no hiccups no before you run it before you run it we actually just got a superchat from velocity trading he says my girlfriend introduced me to your videos she has a data scientist in nvidia and she loves your content on react yeah shout out to her princy thing that's amazing nice sonny yeah thank you yeah and look at that how crazy is that it's like two worlds came together react yes now we're talking about data scientists where the majority of data scientists code with python so yeah this is this is dope it's awesome yeah you should do a collab with her like a reactive data science project yeah but nice awesome awesome people are showing sonny the love the hulk you get a you should like you should demand people in the comments call you the hulk anybody who wants to cause honey by the hulk pop that in the comments right now going forward we'll legally change his name to the hulk because he can handle anything except standing we have papa react we have was it the react god now we have the hulk the react called god that's just hulk just talk the british proper hulk um but where were we so yeah so we're gonna we're gonna draw smiles underneath the face instead of actually drawing the box well let's put both for now just for demonstration purposes nice let's run this there we go hey nice that's awesome dude yeah it looks a bit like that horror game you know that that slender man that's what the text looks like yeah yeah oh the slenderman text yeah the smiling i mean that's awesome dude and then now if we just get rid of the if we get rid of the um drawing on the rectangles then it should work nice guys if you find that cool because it is it's like look at this look if now we should see no rectangle but we should see the smiling which means that we have that finished sort of hey look at that that's that's that's nice dude that's awesome and even if we have two faces on there because we have that loop it will actually go ahead and do it for a second face as well right i will yeah so let's uh let me just get guys i wish there was a way to get your face on the screen too but the stream tag kind of limits that but yeah let's go ahead and see it wait look at that nice that is awesome guys if you think that's cool smash the thumbs up button that is awesome and if you haven't already and you are following me and aaron on instagram go ahead and shoot us a story right now so this is my tag and this is aaron's tag right over here so my tag is over here aaron you just point somewhere down there you'll see it uh yeah so go ahead and shoot a story and um yeah tag us in there and let us know that you're watching and yeah you guys can we can have a chat with you guys if you found that cool i think that yeah like it's so impressive like how many lines of code was it in total oh even when you zoom in look at that and guys that's a really good example bro because they're showing the actual dynamic width and height changing yeah yeah that's awesome all the wheels man cool 900 likes as well guys that is insane thank you guys but yeah guys that's pretty much the completed app um there's other things you could probably do to clean up the code you could probably pop some of this stuff in a function you know i just kind of blobbed it all in one go um so not very good code design here uh but other than that yeah i mean we went over the using the face detectors and small detectors using xml files which are pretrained if you want to learn how these actually work then you can watch the other streams for the actual algorithm um of how that works uh we captured the the webcam footage we're iterating um forever until we're done with the webcam footage we're reading every frame one by one and then for the current frame we are doing a quick check to make sure the frame is good to go then from the frame we're creating the green the frame grayscale so that we can optimize it and we can um speed up the process and the calculations uh once we have a grayscale frame then we find faces within that frame then from all the faces we want to actually draw the rectangle around each face nice and then from each face you want to create the subarray using the numpy slicing here the the um which is numpy under the hood so we got the little sub right here which is the same um data in memory as the regular frame so when we edit this little subreddit it's still going to edit the mainframe yep the mainframe then then we change the face to grayscale um so we can run small detection on the face and then from there um uh once we have that then we can just label it as hey we found a smile instead of drawing the rectangles right so remember guys what we did that nested approach for when we were drawing uh where did that happen again aaron so where we avoided doing it for everything we did it for just the smiles it was line 38 right yeah yep nice that's so cool and then you put the text there and then um at the end then once we have once we have the once we found the face drew the rectangle found the smiles wrote the word smiling once we've done all that and we've edited the complete frame and all the the correct rectangles and words are on the frame at the right locations at the very end of all that at the end of the end of the detection we uh use cv2.imageshow just to show the frame and then we wait for one millisecond and then we repeat to the second frame so all of that's happening every single frame all of this code dude it's insane like if you actually think about it like let's say we went ahead and got rid of the comments and we got rid of everything that's so little code to get that powerful functionality happening right so let's actually do that yeah so let's make this super optimal nice yeah guys drop in the comments how many lines of code you think this might be if we can if we can do that before aaron gets to the top i'm gonna say maybe like 30 i'd say maybe i think it'll be that around there this is insane though like if you used to do this kind of thing in like javascript you would have to write more and i'm a big fan of javascript but i will say it first time like in python you can get a lot of power out of this uh we're just having small amount of code so that's that's still oh again but okay we're near 30. anybody anybody want to put money down dude 22 bro i mean this doesn't even count this doesn't even count holy crap that's insane and actually this because it's just a break statement you could probably get away with doing this i mean probably not good but i'm cheating because i just fall off that's insane we have machine learning ai everything invoked in there at like 22 21 lines of code so yeah oh my god was close he said that 25 abbas abdelius of 32 young ipsex guys it's less than we all thought like somebody wrote one i don't think we could do one i mean just pop this in a function you know just oh yeah section it's fine that's insane i love that dude that's so so cool man like um yeah that's awesome and guys i think this also goes to show you yeah there you go that's that's the hack to everything guys one line nice i'm doing it bro i'm doing it one second just for that guy because i got nothing better to do with my life i see a lot of people saying like this is like calling uh the ha cascade ai isn't really ai guys anything you have when you have a classification model that is current that comes under ai and trust it take it from a guy who's done a masters in this stuff like it is a like that is that is what we classify yeah if you want to if you want to go see how these are actually generated because we did just download this and just used it but if you want to actually see how you create this like how you can train anything to like like recognize what pepsi cans recognize uh coffee mugs whatever you want then i explained that in the face detection video this is like an extension using smiles but i explained that in face detection and the car and pedestrian tracking of like actually how the algorithm actually how the computer actually learns this like how the hell does the computer take an image and know how does the brain like how does it use its brain to figure out what it is so i i explained that there um but it is ai because this is how computers can learn it's not just random stuff yeah and that's the powerful thing guys like once you have trained models and like a lot of people i think even in firebase there's a bunch of like uh trained models that you just have access to which i'll be dropping some videos on so thumbs up if you if you're excited for that but um yeah like you can pretty much go ahead and use pre guys to train a model from by yourself you need to take a long time yeah you need a massive amount of data that's why things like tesla everything gets better over time because you get more data over time which means the model can get more accurate yes like it's not super feasible for us to train our own um if you understand how the algorithm works and then you utilize it that's really all you need to know to innovate we could technically i could technically go and take fake like get faces from the internet a bunch of different faces a bunch of different smiles and find those pictures and trim them all myself get the data set and then run it through some some training software to do it but then even that that's just an extra step of just taking images plugging into this this thing and then going up if you actually want to code up this algorithm that gets pretty deep and nasty i did it i did that at my schooling at georgia tech um it's interesting and fascinating but it's a big headache so like why reinvent the wheel so we're doing that here but if you want to get down in the nittygritty then uh by all means go through it there's a there's a free computer vision course from georgia tech on udacity you can look it up it's called computer vision they talk about all this stuff in complete detail they talk about other object tracking like common filters and uh cnns which are convolutional neural networks which is another way to do like tracking and object detection um but har cascade is just the simplest way that i'm showing you because you just download this one file and then you pop it into opencv and it's all nice and free and easy to use but yeah if you do want to get deep in you don't do like legit ai this is just this is like baby stuff compared to real stuff like even me i haven't done too much i haven't worked at tesla on selfdriving cars unfortunately i wish i have but um you can get some you can get go pretty deep so if you want to check that out then by all means go check out opencv the opencv course and uh feel free to just go ham yeah for those of you who are javascript developers you can use something like tensorflow tensorflow is pretty much a very similar thing to what we use here but it's not cv2 it'll be tensorflow and then you can actually go ahead and get models just like the hard cascade um and you pretty much plug them into your tensorflow and do the same thing as what we did today so what i challenge everyone on this stream right now to go and do is actually go ahead and like follow along this tutorial build your get it working on yourself but go ahead and swap the um the hard cascade one that you're using and try and detect like an eye or something like that that'd be kind of cool yeah try and detect like an eye or something like that that'd be kind of cool yeah yeah yeah there's there's literally an i one like if you just the google it the opencv documentation or the github github repo there's the i1 where you can detect eyes as well um we could even do it really quickly why don't we just do it on the fly really quick as a bonus i'm supposed to be done here but let's uh let's do it because i actually have because i have it downloaded already the eye because i was going to do that but i was like it's not important for small detection but let's do it really quick okay what time is it it's 41 okay i'm gonna how fast can we do this let's do it all right boom i dot xml uh in the comments right now let him let's get let's get him let's get him in that flow state uh eye detector so we're gonna want to get is okay so the face we have the face face grayscale smiles smile detector eyes is going to be um eyes will be eye detector dot detect multi scale face gray scale and uh skill factor i don't i didn't tune the eyes so like it might not work but um yeah we'll just we'll see how it goes so eyes equals that yep then we're going to want to draw the smiles and then also we're going to want to draw the eyes and eyes yeah why don't we just go double this is very sloppy but i mean i just well actually i can just use this because the for loops aren't overlapping so let's just leave it like this yeah and then um the i okay and let's just change this to 255 25 and 255 in eyes grayscale so this should work nice i mean it should let's see if it works guys if it works destroy that thumbs up button because aaron just done that on the fly like oh the eye is not defined i have a typo somewhere oh i was going to say that yeah because you have the eye but we need to splice it or slice it sorry right oh oh um nope i mean the face okay that's what it takes oh snap dude mouths and eyes look kind of similar sometimes you know you can kind of see yeah let's try to tune it we gotta tune it a little bit let's tune the variables a little bit and see if we can get it working better so that's what that's where these two things come in handy scale factor in mid neighbors so i'm there's probably some ideal number let's just try like i don't know 1.3 and 10 and see what happens okay like some iron man video okay okay not quite not quite let's try 1.1 and 10. oh again that dude so what what what was the phone oh i just need to i just because i'm asian but if i open my eyes big it works it's not creepy as hell but like big eyes big smile then it can get it it can get it nicely that is awesome the greatest ever let's get this to 1k likes everyone i think we do yeah this this kind of stuff this kind of stuff is what snapchat instagram use on their filters you know like when you like vomit the rainbow and stuff they're like ah and then when they see it they can locate it and have it like drip down stuff like that so this is actually what's going on behind the scenes when using a snapchat filter like the selfie camera and you know you have like the crazy filters over your face this is what it's doing behind the scenes it might be using convolutional neural networks instead of hard cascades but this is similar principles yeah they would have a model that's already sitting there that's already ready and it's just the input would be the camera that you're saying output being that little tongue emoji or like the dog thing whatever you're using yeah nice yep that's it and about what that took four minutes to get the eye up and running so it's the power of python and having pretrained of course if you train yourself it's gonna take hours or days or weeks if you have to get your own data it depends where you did it if you're taking your own photos with your own phone you gotta it's gonna take forever or you can just what people have done you got some you got some good comments coming in and says aaron you are awesome aaron apparently not at numpy whoever in the comments i don't know who you were but thanks man you saved you saved my ass man or man or woman whoever that was much appreciated i could stop embarrassing myself the greatest ever says that's amazing information i'm going to squeeze that in when i'm being interviewed that's that's awesome dude that would impress them yeah i will impress this is the real smile look look at that it's so funny that was nice we could we could even be like we could even like have a diamond changing like smiling and wideeyed like or unasianified or something you know you could be like smiling and have like another piece of text like unasianified underneath let's do that dude you know what you could do i reckon there's probably some kind of model there which tells you the ethnicity of someone and then you have the sensitivities based on ethnicity oh that'll be it'll be hilarious but let's just here let's just look at this code if length of eyes i mean is that racial profiling is that like racist no i mean i mean we've got one we've got one asian we've got one brown asian fried let's just do so literally the greatest ever just said unasianified there we go here let's try this right aaron you're a good teacher i like it nice oh wait uh i think we need to tune this a little bit better to eyes needs to be maybe 20. let's try this and this is way too much let's try 90 and quit this out here [Laughter] i love that that's i think we gotta tune a little bit more let's try uh let's try 30. bro i'm still there i'm supposed to go work out my friend but that's what was probably 20 minutes ago but this the numpy thing you know i really put a cog but whatever oh man oh wow tyler shaw says that's the most amazing live video of programming ever we love that dude that's insane that's furious with my eyes bro and look at the light on my face better so funny i'm having so much fun with this man i wish i could uh send it to you but yeah i do gotta get going no dude you've crushed that and you we didn't even plan on getting the eyes done so we got the eyes in there i mean yeah that's the power of pretrained models they also have like dog and cat let me just pull up the open cv real quick where did my chrome go oh it's in full screen so if you just go to opencv um har github then you go here hard cascades they have all these pretrained opencv is like open source so it's free and low weight uh the algorithms and stuff they use at facebook and snapchat like in instagram for real they're trained even better than these are that's why they're so much more accurate these are just kind of like halfway there but they're also like pretty old but here here's the eye um i tree eyeglasses i don't even know what this is uh this is the frontal face default we're using for frontal face there's other frontal faces see how much is frontal cat face uh full body this is what used for the pedestrian tracking um for cars i had to download a heart xml file from somebody else it wasn't provided by opencv but you can go you can find other trained models too like is once an xml file is created from any object section then you can just download and use it for yourself so like here uh like this is literally what i typed in there har car has hard cascade xml file i went here i clicked on it and then i um i literally just downloaded the xml file uh from some it's somewhere linked in here but you can find the xml file once you find it so like literally it could be anything it could be like like what else what else besides car is cool to identify um um our cascade file uh i mean that one might not exist but i mean here soccer ball cascade so use yeah there soccer ball cascade.xml and then so this could probably detect soccer balls in a video without a video or something like that so like it's generic object detection you can you can detect any object um any arbitrary pattern yeah you know in a in a frame so that's the power of that using using my aaron just showed you that you can easily detect like some balls you know like are your your balls round like a soccer ball or are they are they excited like a rugby or football yeah but here there's hard cascades there's also some here there's hog cascades so hog stands for hog is like another way to do it it's like optimization for horror or some something i forget what it stands for but it's another objection algorithm thing that you can use um but here we have all these and then there's cats and uh or if you go into hog what is in here pedestrians okay but yeah guys that's that's it smile detection and asian detection asian asian person detection in um in python awesome guys if you guys enjoyed that let's give aaron a massive thank you because i think he crushed it today with that and even i learned so much with this uh tutorial today so like i thought it was cool thank you aaron that was amazing dude welcome sonny thanks for streaming for me because my computer's a computer is a rock sorob singh says aaron and sunny looking for some more in the future cheers yeah we would definitely be doing more that was fun definitely yeah i am planning on doing some tensorflow because i've kind of exhausted this open cv stuff we got three streams on it but i do want to get into tensorflow and maybe even pi torch yeah um like something mentioned so maybe in the next few weeks stay tuned for that i might have like a tensorflow like crash course stream or something like that yeah they will actually train a model ourself with uh with somebody else's picture data i'm not gonna do it myself yeah but i'll find some online data set of a bunch of images and we can maybe train something and you can watch the neural net get created and then we could do something like this again that would be dope dude that'd be awesome yeah i think um also worth mentioning guys for anyone who joined and maybe missed this in the beginning what's lingering in the description right now yeah so yeah yeah if you guys like coding in python if you enjoyed this and want to do this for a living then that's what we do a clever programmer so we teach people how to take their coding skills and make money from it as uh web developers with javascript as python developers python freelancers whatever it is you want like automating stuff with python or whatever then go check the link in the description there's a free training that teaches you how to do that uh and then there's also a fullblown course that you can join if you want to invest some money into that in time and actually uh pursue becoming a python developer as your career choice if not then feel free to enjoy your free content that's what this is here for and you know make asian stupid stupidass apps like this [Laughter] my mom would smack me yo respect your culture okay i love you mom you eating the [Laughter] then ah yeah that's the truth isn't it yeah we're all dropouts here aren't we that's awesome dude i think if there's aaron got any last few things you want to add oh we also got a donation thank you saurabh singh just dropped a nice little donation there appreciate that dude and lots of wicked comments coming in yeah nice i think the last thing with hilarious would be uh actually get rid of the boxes what was that and then um it would be hilarious get rid of the boxes you just have like the full clean app let's do this last demo because i'm i'm all hyped what's that hey let me go ahead and try it on that there we go i think i think it's okay when you when you're you're the same race it's all good half audition if i uh anyways okay i'm gonna stop goofing around because now we're just wasting time all right yeah so if you guys wanna check out the the free training or the course then it's in the description um if not then keep watching our daily streams i think we've been going for what like four weeks now straight i think it's longer dude i think we've gone over a month and a half now yeah how have we not run out of like project ideas dude we have so many project ideas now still to come like tomorrow's a big build another massive build coming up so we'll be amazing what's that yeah yeah we have what's up tomorrow stay tuned guys go ahead and literally set a reminder on your phone right now for that and we're doing that was it in i think it's 9 15 est and 6 15 bst that's my time yeah uh yeah so awesome guys hope you guys enjoyed that and with that said uh make sure if you're not following us already go ahead and check us out we always posting some content so you've got me and aaron over there and we'd love to have a chat with you guys but yeah i think i think aaron needs to go and hit uh hit a workout yeah eat some food more coffee totally sleep deprived but yeah guys thanks for joining me in sunny and coating this up there's a lot of fun and uh we'll do it again featuring some time right hulk that's it dude we'll do it again samurai yeah yeah yeah what time all right guys peace out peace out guys thank you so today we're going to be coding up a image classifier app in tensorflow and we're going to be extending a little bit from last week and uh we're going to be building a slightly more advanced uh a slightly more complicated neural network here and we're actually going to be using tensorflow to be able to classify different images so i'm i have this data set here uh that has a bunch of different images of different kind of clothing pieces so shoes and shirts and bags and stuff i'll show you guys a little bit more in a bit but the idea is that we just want to train our neural net on a bunch of these little pixelated images of different clothing types and then eventually be able to recognize these images and classify them correctly uh going forward on on new unseen data so that's kind of what we're good what we're going to be doing today okay let me see if i can find some other other data in here too let me close this i want to show you guys a couple of the pictures i think there is a there was a link i found but i i lost it that had like a better okay here we go so this worked fine so this is another uh image that we're gonna be using so this one kind of looks like a shirt as you guys can probably see and um this data set is actually really big it's actually built into tensorflow because it's kind of like the introductory data set that people can use for image classification so let me look at a couple more and see if um there's a few that we can look at together okay so this one kind of looks like address i guess and let me just keep going through the data a couple more yeah another address here and i think you guys are getting the idea so this basically there's just a bunch of images there's like 70 000 images of different um clothing pieces and what we're going to be doing is we're actually going to be training our null net on about 60 000 of 60 000 of those images and uh properly classifying and training the neural net and then on the remaining 10 000 images we're going to want to actually use that as our test data to see how accurate our our neural net is all right awesome so let's uh get back to the code so yeah i showed you guys a bunch of those images so the idea um is we're going to code up a neural network and um i'm going to kind of like go step by step of how we would solve this problem so the the thing we're trying to achieve is we have 70 000 images of different clothing pieces like we have and there's actually ten different types if i go back to the documentation here um there's ten different types of clothing here and they're just labeled zero zero through nine just for simplicity so as you can see like the first one was an ankle boot like let me go back uh to this and let's just show the first one again and print this out as you can see here this kind looks like an ankle boot or a shoe but i guess they call it ankle boot and uh the label is nine so actually let me show you the the label too just so you guys can get a little bit familiar with the data uh there we go so labels add zero so yeah so um i pulled this data or let me actually show you guys um i should show you guys this in a second let me just show you the label so here i'm actually printing out the label for the for the first image here which is a zero and then this is the shoe like i i just showed you guys but when i print it out it'll actually give us the label as well so i'm going to be quit out of this and run this and as you can see so this is a shoe and it actually print out the label of nine and if we go back to the data here you can see that nine uh corresponds to ankle boots so pretty simple there's 70 000 of these images of different things and then each of them has a label attached to it so we'll be using this data to train our neural network and then uh we'll be using another subset of this data to actually test our network to see how accurate it is and uh it's uh pretty good yeah as you can see here so the fashion this is called the fashion mnist data set um mnist is this thing i actually don't know what it stands for but i mean there's a lot of like pretrained and prelabeled data sets that mnist uh provides for us there's like uh there's like handwriting ones and and other stuff so um this one just happens to be like a bunch of fashion stuff uh and yeah as we said here i just mentioned this we're going to be using 60 000 um images grayscale images of different different clothing pieces and then we'll use the remaining 10 000 for for testing so uh now let's just jump into the code and let me start explaining these uh each line one by one so you guys can can follow along and everything will make sense any questions up to this point or is everybody uh following the law following along perfect what is this uh thing i have heard a lot about it like what this is karis is like uh okay let me just spend a quick second on this it's basically like a or let's just go to the actual documentation so it's just like a library that allows you to like build neural nets so um tensorflow itself like is like a wrapper or it utilizes keras because kerose allows you to like make like um graphs in different structures like graph structures so it's perfect for neural nets and you can look into it if you want the idea is though that just tensorflow is just built on top of keras like it utilizes terrace uh keras to build the neural nets and all the other graphs so and like you can also think of it like a neural network you know the basis neural networks and on top of that machine learning spirit right so machine learning is actually like so in neural network a part of machine learning and karaoke allows us to do that yeah that's a good way to explain it yeah so keras is good for creating neural networks but then tensorflow is actually good for pumping data through that to actually achieve machine learning and like solve machine learning problems but keras is just for building the structure like the data structure and defining that and then tensorflow on top of that allows you to like oh train and import data and pump the data through and do all the number crunching does that make sense from zero yeah i think that i think so this is basically that guys yeah all right so let's just start going through all the code here so that you guys can follow along and then i'll answer any questions as we go but this one's going to be a little more interesting than last week so uh let's just start one by one so this stuff up here you guys can actually pretty much ignore this i was running into some downloading errors when i was trying to download the data i just had to do some permission stuff so just completely ignore this um the proper way to do it is to actually uh install a different package on your computer but i just pop this this hacky thing in the code so just ignore it i'm just gonna not even show it um so let's start here we just go one by one and uh of course we want to import tensorflow uh that's the first thing we're going to want to do and then also import keras because we're going to need both and also done pi because numpy is how we are going to be dealing with all of our data so actually uh like this here this is actually just a numpy array so this image is um a 28 by 28 grid of grayscale images and um it's actually stored as a numpy array so we need numpy to uh to hold this data and then we're just going to be pumping it into our donet so that's what we need numpy here and then also we need uh matplop just uh uh map flop is just to display the images so that's why i'm displaying it here um so you guys can kind of just ignore that it's just for for visualization purposes so this is where the code actually starts um so the first thing we're going to do for any kind of machine learning thing is we're going to need a bunch of data so unfortunately for us they have this all of this labeled data like with the shirts and shoes and stuff already preinstalled in tensorflow for us so it's as simple as just downloading it here and just accessing the builtin data set which is nice um in the real world if you're trying to collect your own data which sometimes happens sometimes like if you're working on a team like i did this um at my i had a machine learning artificial intelligence paid internship thing where they actually went and would uh like capture their own data and you'd have to like label it yourself and it was kind of annoying um so i mean i guess you do have to do it in the field if you are if you are going to be doing that in the future but ideally you just have the data already labeled and somebody already did it for you um so that's what we have here a bunch of the data here so i'm just gonna get handle here to that data set and um you just do that by calling cara so within keras we have the the fashion mnist which is what i was just looking at in the documentation here um wherever it went i don't know where it went uh keras fashion feminist there we go so like i said keras has like these data sets built in so i just basically call this code so fashion.mnis.loaddata is what i called here um or actually i call it down here but this is uh this this is just like saving um the the handle to the data but down here uh you can just call fashionmnis.loaddata just like it says in the documentation here and we get the data in so this might differ if you're using a different dataset but for this dataset this is how we're getting it and the way this is returned is by default it returns um 60 000 of the images here for training and then the remaining 10 000 of the images here for testing so now we have these these four variables here that we can use for uh training and data so these are just simply just lists of a bunch of different images and whatnot this is actually how i was displaying all of the images so right here i'm displaying uh the first element of the training images which is actually this boot image that we see so uh very straightforward so if i index train images at zero then it just spits out this numpy array and then i just use uh matplotlib to display it so you can see that and then i showed you guys the dresses and stuff i like the first index and second index and it goes all the way up to 60 000. so uh that's how the data is structured so all you guys gotta remember really is just that these four these four variables here is how we're going to access our data so and then these are just lists of numpy arrays or images and and that's that's all it is this here is just for printing so we don't have to worry about this too much this is just using some matplotlib i'll actually show you guys this this is kind of interesting because you can even see the actual data in the terminal if i quit out of here oops there we go so what i'm doing here is i i get the data like i said i have the 60 000 uh images and labels here and then the 10 000 images and labels here and all i'm doing is i'm printing out the label and then the actual image in the terminal so if you look in the terminal you can actually see like the the the data here so this is the actual image that we're seeing of the shoe but i mean of course it doesn't look like a shoe in here because it's just a bunch of numbers but um it's just a black and white image so on the range from 0 to 255 is the uh range of numbers um that they can be it's just kind of like the brightness of each pixel but then that's reflected here so i'm just using matplotlib to show that and that's through the image shown in the show here so uh any questions up to this point is that is that pretty clear cut for everybody or does anybody have any questions is that just for one image yes yeah just for one image so we can actually get rid of this because i don't want to print it in the terminal and like clutter it but all that's happening here is i'm using uh matplotlib i just renamed it to plot for simplicity and then you call image show and then you just pop in whatever numpy array you want um and then this is just for uh making sure that it's it's a gray scale so you just kind of say like yeah it's the color map is gray scale and then min and max values is that um you have to specify those and then you just show it and then that's how the uh this image shows was that you tom was that it sounded like tom yeah it was yeah so i'm not well sweet i'm staying on mute oh goodness hold up make sure you drink some water and get some food in your something it's not the corona is it or that no no i had to get my kid tested it came back negative but it's just fluid yeah we all got tested here too at uh all the guys here clever programmer because we all kind of live together or work together on a daily basis and then we're all negative so that's positive sign because i know los angeles is kind of kind of iffy what is your is that the 28 by 28 that's the matrix matrices uh matrix that the 70 000 of 28 by 28 yeah so uh if i go back to this data set then uh this predefined data set in keras is yeah a bunch of 28 by 28 grayscale images of different fashion categories so like shoes or dresses and stuff that i showed you guys before so uh we keep it small just because there's so many and um if it's recognizable by a human by the eye then it's prob then it's are arguably recognizable to uh to a computer like if you if it's like if it was like two by two then yeah then you can't you wouldn't go to recognize it but 20 by 28 is like as small as they could get uh reasonably by still being recognizable as these different things what you printed out was because it didn't have 28 columns so what was the mapping of what you printed out again um you mean this or the actual the image when i produce that whatever that's showing yeah that 28 by 28 is that what that's representing well yeah this should be i mean it should be is it not 28 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 3 45 seconds yeah 20 so it is 28 so this is 28 long this is the first row and then this is the second row and then it just now it's just the formatting is kind of crappy that's why because i was dealing with it from the top only i didn't i didn't follow the uh ending yeah so this is just a twodimensional numpy array so this is the outer wrapper and then each of these are the rows right and then yeah as you can see so like this is all zeros so like there's nothing on the top and then when we actually run it then you can see yeah that the whole top row is completely black which is what zero stands for because those pixels are off so the first row is all black the first row is all black there awesome so that's the data we're going to be dealing with and now we can actually jump into creating a neural net for it so let me just go line by line there we go so like last week uh we're going to be creating a very similar the the code is going to be very similar but the neural nets is actually going to be uh a lot more complicated but that's what's nice about tensorflow because it you're able to create really really complex neural nets and the code is is pretty concise and straightforward like it never gets too advanced and that's that's a really good thing so uh let me do a little recap too just so for anybody who doesn't remember let me annotate uh i think red is good okay can you guys see you guys can see me i'm annotating right yes all right cool so let's just have like a a sample neural net here so anybody who doesn't know what a neurologist it's just like a a bunch of different layers of nodes and they call them like neurons and then um they're all they're all connected so let me just draw this out really quick and there we go so um oh it's kind of covering the code here let me put out can you guys see down here this code down here so line 28 it says model um so the first thing we want to do when we're we have a machine learning problem or something like in tensorflow is you want to design our model in a way that will be compatible with our input data and also our output data so in this case for anybody who doesn't know a model is just a a neural net so this here is the example of a neural net that has three uh three layers so one input layer here with three three nodes um and then one hidden layer with four nodes and then one output layer with two nodes uh so this is kind of like a model that that um i just dropped here r is gonna look a little bit different but i just want to visually represent it here so um in keras like we we established earlier keras allows us to um define different uh graph structures so it's really good for for this purpose and um so that's we're utilizing keras here so keras uh there's a thing called sequential we were this last week and this just means that there's a sequence of horizon a vertical vertical columns like this of different layers and then they go in a row so um this this column of nodes can only connect to the next one and so forth you can't like skip and hop over so this is like the most um basic type so sequential is the first one we want to do and um we're gonna make this a sequential neural net so from there all we need to do is just within this list is just define all of the different layers that we have so let me get rid of this drawing real quick clear all drawings okay so um the sequential so for the first thing we want to do when we're dealing with a uh machine learning problem or or for for an old nets is we want to make sure that the input and the output is correct so for the first one remember let me just show you guys the first one the first layer um so the first the first layer that we're going to want to have in our neural net is going to be the input layer and as we know the data that we're dealing with is going to be a 28 by 28 um image and those are the the the data we're going to be pumping in so the way i shouldn't deleted that neural net you see i'll just make a little bit simpler so i'm not going to draw the lines just because it's it's kind of long but something like that so um the idea is uh for our input we want to have a 28 by 20 input for um our input here a 28 by 28 matrix and uh what we want to do is we actually want to flatten that out into one long layer so the input layer actually each node is going to have one pixel um so that of of each of those images so that we can um pump in the the full data all the way across and then from there the data will filter through and eventually at the end will spit out be like okay is this a is this a boot is this a dress is this a shirt um and that's that's the overarching idea so um the first the the first thing we're going to want to do is yeah just make sure the first layer is compatible with our input so again we just we just call this here so it takes in a 28 by 28 image um and we actually want to flatten this so uh like i said each layer of the neural net is just one long vertical column of our our data and um so we want to make sure that we flatten this 28 by 28 thing into one flat one flat layer and then i think it comes out to 784 28 times 28 yeah 784 so let me actually just copy this code out or the comments um yeah i wrote here so the flatten the flatten here just flattens this 28 by 20 matrix into one um flat 784 by one input layer so actually this uh neuron that we that we started building up to this point so this only has one single layer will actually look like this annotate so uh it's sequential of course but right now we only have one layer and what this is gonna be is this is actually gonna have um a bunch of input layers here and this is actually gonna be 784 uh long so this this whole input layer is gonna be 784 um neurons long so this is the first layer okay and then we're gonna have a hidden layer and then we're gonna have an output layer uh but does does that make sense so far so that we have one little node for each pixel of each of these images is there a reason why you need to flatten it um it's to simplify it's to simplify the the structure of the neural net um it's because each each layer of the neural net is just a singular column so instead of treating it as a multidimensional array then we just kind of want to flatten it because at the end of the day like each pixel is just a piece of data it doesn't really matter where it is we can just kind of treat like okay the top left pixel is the top left pixel and as long as that's consistent across all the images when we're training and testing then it should be okay so it's just a way to simplify the data into one one long layer to make sure that every pixel is represented in a clean way is it more efficient more efficient it actually doesn't really matter like the implementation under the hood everything is just it's boiled down to optimize matrix multiplications at a at the lowest level like tensorflow abstracts all that away uh this here is just kind of to like make it more um understandable for like a human when you're thinking about a neural net like okay we have this long this whole input layer is just one long column and every single pixel has its own little node and then each of those pixels has its numbers so like if this was black then this would be like zero if it was white it would be 255 um in this node and then it's just every pixel is represented then we can kind of be like okay this set of numbers this long 784 list of numbers represents this first image like if i if i run this yeah so um this first input layer will just take like all of these this um all these pixels so the first row will just be like up here second then the second row would just be right after the third row will be right after that just going all the way down until the very last row and these last two pixels down here in the bottom right are these two little nodes here just so that every pixel is represented then from there we've fully um gotten all the data of this image and then from there we can kind of like tweak the the different parts of the neural net and eventually we will be able to like filter um this image through and then by the end of it it'll it'll spit out like okay this is an ankle uh ankle boot and not a shirt or something like that actually i've just thought of a question um why why is the um grayscale numbering from zero to two five five ah so um it's just a uh the way the computer hardware has been implemented uh like as computers evolve from like the 1940s till now uh 250 0255 actually just means there's 256 numbers because 0 is the first one so 256 is just the power of 2 so it's just a way to stand to encode the data so i think this is what 2 to the not two to the eighth yeah so two to the eighth which just means that there's eight it's just eight bit so this is an eight bit image of black and white that's all that means so we can be on a scale from yeah so this is that's the range of all the different steps there's 255 steps of colors from zero from black to white and then there's 255 colors of gray between that that you can um specify and that's all it is um okay let's go so if you didn't it would still it would still come out and your output would still be the same or um i actually don't know i mean i just always use flattened just because it's easier to understand i mean we can try because i mean remember last week we used dents and we're going to be using dents going forward um but this kind of just like just uh um defines it so it kind of what this does i i think is it has kind of like this 28 by 28 thing and then um but it says hey just flatten that so there's actually a layer there's actually a matrices over here over here of 25 28 and then it just kind of like magically turns it into one layer and then we kind of just treat it as our first layer but it kind of like maps the matrices 28 by 28 to this one single input layer which is simpler for our neural net design because ideally down the road we're going to i mean not ideally but we actually are going to be doing is creating like a another layer of stuff here and then at the end we'll have like um a bunch of different notes here that's just like okay what's the probability that this is a shoe versus uh you know probably versus a shirt it's really hard to write with this but and then so on and so forth and there's going to be 10 different ones as we saw here there's there's about um tshirts trousers pull over's dress coat sandal sure all these so there'll be one of so yeah actually uh let's talk about that a little bit so what this our neural eventually going to look like is we're going to have this input layer which is just the image then we're going to have one hidden layer that's going to kind of try to capture the patterns of what actually a shoe is what a shirt is what a dress is stuff like that um and then from there we're going to have an output layer that's going to have 0 to 9 so it's going to have 10 nodes in the output layer and each of these nodes is going to tell you the probability of um how much the neuron that believes that it's going to be a shirt or a shoe or something else so there's only six here but you can just imagine that there's gonna be there's gonna be ten um like it's going that be 10 10 notes there and um then so the idea is if we put in an image um like the like the first shoe image would be pass it in and say okay this shoe should be uh really close to one it might be like 0.9 or something because this is a probability um then we want this to be really high and everything else would be low and then from there we can kind of uh train it eventually to the point where when when we pass in a new image the new image will pass through here every single pixel it'll filter through all of the hidden layers that we're about to create and then at the end it should say like okay uh the second image might be a shirt so this should be really close to one and everything else should be like lower closer to zero is uh is that yeah and your hidden layers represent the model is that what the model is the um the whole neural net itself is a model so uh like i like we went over last time um this annotates a little bit i gotta find a better tool for drawing i think oh but it'll it'll be okay that's everything yeah so the model is the model is inclusive the entire neural net is the the model and we're going to be designing it so right now we we only built the 28 by 20 matrice and we flattened it into the 784 input layer and you can kind of ignore the 28 by 28 now because it's just a simplification to make the neural net look nicer because if you have this weird matrices that pumps into this column layer and everything is just kind of like a weird thing we just want it to be a sequential uh series of columns of nodes and eventually you you pass in an image it goes through all this magic and figure out all the patterns and then spits out the probabilities here at the end and it's like okay shoes max is the biggest one so we can probably say that this image with all these pixels filtered through this known that is issue we can confidently say with the 90 accuracy that it's issue but this entire thing is going to be um the the model so again these are going to be connected i just didn't draw these and then there's a bunch of lines everywhere connect like every node is connected to every other node uh the way it can and and then these are just going to be numbers multiplied um together like going through the neural net so um uh let's let's go back to the code a little bit i want to explain the input and output a little bit to you guys and then i'll explain a little bit more about how the neural that is actually going to do the work let's go back to the code and let's actually just delete all this because it's getting too messy there we go so this is the first layer is going to be a flattened layer okay and um like i said before uh that's the input and then the output is going to be um uh a series of numbers from from zero to nine and those are the probabilities that it's going to be each of those so the output layer is actually going to need ten nodes okay it's gonna need ten nodes from zero to nine and um from there then then um then we can create the hidden layers after that so the first thing we want to do is uh let's grab the output layer so the you always want to go like input layer and output layer first and then you can kind of um experiment with the hidden layers to see what you get you get like the most the biggest bang for your buck because uh there's always that tradeoff of accuracy and speed so and this one we're only going to have one hidden layer and it it works pretty well uh but let's just start with this so input layer is again the 28 by 28 image and then we flatten that so this is just the input layer of 784 and now the output layer is just going to be um 10 10 nodes going up and down um and each of those going to correspond to one of these numbers is that clear so far or is anybody did anybody get lost awesome awesome and so so that's the uh first things we want to do is the input and the output and again we're using dents here dense just means that every node in each column is connected to every other node in each column so there's a bunch of like crossing over lines uh between each neural net let me just find an image actually densely connected neural network like i showed some of these last week but here this one works nice ah it's not working here we go so this here um is uh like this one has a bunch of inputs so for us we're gonna have the image and all the pixels in here and then we're gonna have the the ten different um numbers here uh corresponding to each each of the the clothing types uh ignore this for now this this thing here um i'll explain this in a little bit but just remember that the i'm i think i did this last time to make it a little bit clearer so units will actually define how many nodes are in this column so the type of column is going to be dense this layer the the layer or column i'm kind of using those terms interchangeably but they're the same thing so that layer is going to have 10 units out of the coming out of the back this only has 4 but just pretend there's 10 and then the input has 784 again so once we have those specified then usually you can just start off by just testing it with one hidden layer and then kind of see how well your neural net performs testing it with one hidden layer and then kind of see how well your neural net performs because simpler is better and then um and in our case it'll work pretty well only one one hidden layer and we're about to build that uh but sometimes you need really really deep layers to actually create robust systems so for us like we're simply classifying like like 10 different types of clothing which is pretty pretty simple um but sometimes you want to have like a really really deep neural network and that's actually where deep learning comes in is this is where like there could be like a lot of hidden layers like tens hundreds of hidden layers and that's why it's called deep learning just because the neural outlook is really really deep but those can get really powerful like if they opt people have like learned how to optimize it enough to not take like years and years to train um but then it's able to like be really really powerful for like recognizing like a large large array of different uh things like it can tell what a cat is what a coffee mug is um what an airplane is like who obama is and stuff like that um uh all in one neural net but you need a lot of hidden layers but for ours it's pretty simple so we only need one one hidden layer and we'll just start with one and we'll see that it actually works pretty well so let me go pull that out next uh we're currently designing our our neural network structure using keras so um so this here is actually the final neural network that we're going to be building so we have the entire thing specified here um the the the hidden layer we're going to be using is another dense layer so again it's going to be fully connected like this as in every layer column layer here is fully connected densely to the to the next one um so it's this is what it's going to look like but we're only going to have one hidden layer so you can ignore two and three you can pretend those aren't there and um and then we're gonna have 128 again let me type in units to be a little bit clearer uh we're going to have 128 nodes in that one okay so there's actually going to be 128 tall so the first the first one is going to be 778 tall second one is going to be 128 tall so smaller and the last one is going to be 10 tall so you can kind of see like we're filtering from a big image and then we're going to we're pulling it down to like a little bit a few patterns and eventually we're going to um um we're going to boil it down to 10 probabilities of of these different clothing types uh so that's kind of the structure of our uh neural net um you can kind of just you kind of just want to like guess for this one uh you can just kind of like like last week we started with a very very simple one um but for images you usually want to try like some some decent numbers so you might want to start you could even start with like 60 64 or something and then you can just jump up to 128 but 128 is like a good medium ground like it's not too big of a number for a computer to do with uh but it it captures a good amount of relationships you kind of just have to like play with it and stuff for for prebuilt projects usually people figure out these finetuned numbers for you but for us you can just kind of like just pick a number and see what happens you kind of have to play with it and see how the computer learns like how accurate it learns okay so is everybody following up to this point we um this is just all kind of like preliminary code stuff of like importing the data and everything but here designing our neural net we have a sequential neural net with uh input of an image um one hidden layer of 128 nodes and a output layer of 10 nodes is that clear to everybody is it a good i don't know common practice to make the hidden layer some um factor of two or power two um not really uh it can be anything i don't know why they actually choose 128 um because i i found this project online and um it's like neural nets can you can use any number of nodes it's just uh arbitrary um number of nodes and then you can capture relationships so i actually don't think it needs to be uh like some special number actually i mean we could probably even choose a different number but um did they just i guess people just like like powers of two because it kind of goes nicely with like how computers work internally so maybe maybe it's good practice maybe not but i mean in theory you don't need to have it be a power of two but maybe in implementation yeah i didn't know those conventions or something yeah um i i guess i mean yeah a lot of stuff in code in general is like based on powers of two so maybe it's a it's a it doesn't hurt to just start there if you're choosing a random number then that you just choose a power of two because it might might simplify things but it should it shouldn't doesn't matter like on a theoretical level so uh from here we have our entire neural net created in design so let me actually just draw this out visually once so that anybody watching the recording can see exactly what it looks like so we have our entire neural net created in design so um let me actually just draw this out visually once so that anybody watching the recording can see exactly what it looks like so first layer is going to be 784 layers of like that it's going to be 7 84 flattened and then this one is going to be 128. oh hello i think my i think my connection cut out for a second you guys there yes all right perfect then this is going to be um 128 and then the last one is going to be 10 10 here is going to be 10. and then of course these are all connected there's all those crazy lines between each of these just like we have um here okay so you can kind of just assume that this is the neural net but then just pretend the lines are all there so this is the what our doorknob actually looks like that we just built um again it's just as simple as uh just calling uh terrace and the type of neural net and then just listing the layers in this list one by one so layer layer layer input hidden and output okay i think i explained that adequately enough let me get rid of these drawings so we can continue on oops um aaron i have a i had a question actually yeah what's up hi uh so uh when these uh when we add a hidden layers okay so does that uh number have to be um consistent for example we have a 128 nodes in the first hidden layer so for example if we are creating uh further hidden layers so for example we are creating five hidden layers so it has to be 128 128 and 128 for all five layers or it can increase and decrease based on it can increase and decrease based on anything um this is where the neural net design gets kind of like uh up in the air um for this one this is a pretty simple problem like relatively because we're dealing with small black and white images we're not dealing with like 4k big images or anything uh so but yeah it can be anything usually what you want to do is the neural net usually starts big and then eventually gets smaller and smaller into something small um because you want to take like a big thing of data and then like all the pixel data and then just say shoot or a bunch of pixel data and say okay okay this is um like martin luther king jr or something if it's his face like you just want to like have like simple labels at the end so usually the neural network starts big and eventually filters down smaller and smaller into some some set of outputs in our case it's going to be a list of 10 numbers which again correspond to the probabilities listed here for each of these okay so the number of nodes in the hidden layer has to be less than the input layer or it can no it can be it can be anything it can increase as well um because you could theoretically capture more um patterns the the thing is the data uh that's there is um 784 tall right the input layer we have all that um so you can kind of if if the input layer is also the same size then you're kind of like not boiling it down to like smaller patterns you can because there's like weird like uh how to explain this um there's there's patterns you could pick up on if it's bigger you kind of like find like weird like underlying patterns in the data that you can't really like visualize like like a human wouldn't really understand it but like you can kind of uh pick up these patterns in numbers if you get more complex but then also at the same time as you create more hidden layers it takes longer to train so as a general rule of thumb it's usually better to just get smaller and smaller and smaller or stay the same size you could go like big and then have like two layers of 16 or three layers of 16 and then like go down to like a layer of output of two if like if it was like you're trying to be like oh is this a cat or a dog or something like that it could be like image then 16 16 16 then two for for that neural net for like if you're trying to do like a dog okay so what would be an efficient approach uh to have us like for the example uh 128 is two power six i guess or eight or something yeah yeah some power of two yeah uh okay so two power of seven so what if uh i wanna split it uh maybe uh 128 into like uh seven right so it will be uh uh two part three and two power four i wanna have two hidden layers so is that will that be a more uh efficient approach or having it both in a single hidden layer will be um more similar actually less layers is better uh if you can get it to the the least amount of layers possible that's usually better because it keeps the neural net simpler and they're not as deep um but as you go deeper you can actually yeah you can like pick up on different patterns so like um for us it might be like okay for a shirt like i might pick up like long like or actually let me just print let me give an example so when you say uh going deep into the neural network so does that mean uh going into more into hidden layer number one hidden layer number two or increasing the length of the hidden layer oh you mean like like you mean making uh a hidden layer versus having two hidden layers exactly so what if i want to have that hidden layer just uh beneath the hidden layer one i want to append the hidden layer to under hidden layer one maybe yeah well again there's like there's a fine tuning thing of like the complexity of the neural net versus how much you have so like uh the more the more nodes you have in a layer in principle the more patterns you'll be able to pick up um but then also it'll take longer to train so yeah you could just have like um you could you could like like you could have are you asking like one like one 128 layer versus two 64 layers or something like that yeah usually you'd want to pile it into just one 128 layer which is what we're doing now because it gets the job done with one layer because each layer you add kind of adds a level of like exponent it gets exponentially more complicated uh faster than than um okay so keeping it to us in into a single layer makes it like keeps it simple yeah for now um okay there are yeah there's there's a lot of different tradeoffs but i mean just as a general rule of thumb just try to keep the layers as low as possible because it uh keeps its and also i mean like if 64. like this is 128 but like if 64 gets us decent results that's a better uh choice to go with 128 seems to be the sweet spot that will be that would be the number of units would be the minimum number which would get us a result of a decent accuracy yeah something like that yeah so you just kind of want to optimize this neural net for this task and that's kind of like the name of the game is like figuring out the neural net design the numbers and the training set to get it working pretty good for whatever problem you're facing for us we're just trying to classify clothing types versus so our aim would be to keep minimum number of nodes and minimum number of hidden layers to get the maximum accuracy yeah yeah like that you just find that find that balance point for whatever you're trying to solve like if you need like a realtime solution you'd probably sacrifice some accuracy to be like instant instantaneous classification like for like for tesla's selfdriving cars it's like okay that's a person walking that's a telephone pole it needs to be real time so um they'll probably rather have it be real time and be a little bit less accurate and then just kind of like be extra careful uh with their things it's like okay i'm not sure if that's a human i'm just gonna say it's a human so i don't hit it you know like just kind of like sacrifice accuracy but make sure it's fast so you just gotta depending on the problem you're trying to solve you have to kind of like balance that out okay okay yeah thank you thanks aaron yeah i was going to ask something similar um um is it almost the same thing or equivalent of the the increase as you increase your hidden layers that increases the time complexity meaning it's like almost like exponential so if you added a second one it's you know i forgot to go through here this is sequential wait say that again yeah so is it is it more like you know it adds a number of permutations or combinations because the node has to touch yeah because it increases the increase yeah yeah it's going to be i think i might have gotten backwards i know like putting if you just want to like trim it down as much as you can but yeah as you increase the nodes and stuff then because every node and every connection or they're called neurons or synapse like neurons and synapses like to reflect the human brain but it's just nodes and connections between those nodes like here so like these these are nodes these are the connections or synapses or these are neurons in these synapses whatever you want to call it each of these lines has a weight so like you would have the pixel and then you would have the weight of each of these lines then you just multiply that pixel value by that weight and you get a different a different number here um and then from there you do it again and again and again and then eventually all these little numbers together kind of like represent a function that captures the patterns and eventually spit out um the correct numbers so since every single line and every single node has its own number um and then there's a bunch of like crazy uh multiplications going on they're at the at the bottom level they're just matrix multiplications which has been highly optimized with numpy so it's as fast as it can get pretty much um and once those are all like multiplied together then then that's how this this is all computed and it goes through but yeah as you as you add more layers you can see that each um each extra layer and each extra node adds like an exponential kind of um thing to it so the computation goes up and then i guess also that the time the space comes the space complexity too okay and so there may be times where you may have a higher number of nodes in your hidden layer if like your input layer i guess you don't have that many nodes to increase your uh uh pattern you know increase the number of patterns that you might be able to yeah because yeah because sometimes there can be like weird nuanced patterns in the data that aren't really clear uh so like yeah like if your input was like really small um like what's a good example like yeah like maybe you maybe you had some training data of like maybe you had some stats like you're trying to do some stocks and you're like okay these are the prices of the stocks over here and you only have like a small little thing like the input layers maybe like only 64 long but you kind of want to like capture some weird like numerical patterns between everything you could have like your hidden layers be much bigger to try to capture some some patterns that the human couldn't pick up on right okay some something like that yeah i'm just trying to understand the strategy of how you design your uh layers and then the length of them yeah uh the the best the simplest way like like i'm explaining here is you just want to start with your input um and then your output first always start with that and then the hidden layer just start with one and see what happens you know and play with the number and then maybe it's like okay this is doing crap um i can then you can play with the activation functions too i'll touch on these in a second because this is another kind of uh number crunching thing that happens and then there's different things you can pick like these two are different like they're both activation functions but these two do do different things um and so it's kind of just like you play with it and you play with all the different numbers and different types and hopefully get some um some useful uh use out of out of your neural net uh but yeah just just start with one and then you can always expand out from there uh okay let's continue on unless there's any any more like burning questions from people about about this uh all right i'll take that as a note that is that is good okay so we designed our neural net here uh now let's continue on there's actually not too much left because tensorflow makes everything nice and concise so we only have a few more lines of code here uh let's just go one by one so let's grab this paste it in so anybody who remembers from last uh from last week then after you create your model we have to compile it uh which basically just means take all the stuff that kara's built because we just specified the nodes and the numbers and the types and all that like you know densely connected make this flattened make it this big make this hidden layer 128 tall make sure sequential all the stuff that kara's put together now we want to actually compile it so it's ready to be trained which um just means kind of like i actually don't know exactly what's happening under the hood when keras but it just kind of says like okay take all this put it into a form where it's ready to do to do stuff and then we also have to specify an optimizer function and a loss function so let me just touch on this again really quickly one more time for anybody who forgot or is new so um just remember remember there's a lost thing and an optimizer thing so let me go to this uh neural net here and kind of explain visually what's happening so what happens is when you put in an image in input layer you would put one through and um you would want to pick random numbers for all these lines and for all these lines and just filter it through so once you have an image come in you'd multiply it by all these random numbers and then you'd get another set of numbers here you take those and multiply by all these random numbers on all these lines and then you get it all um all here and then again and again to get to the very end and you'll get some output um so again you're going to get we're going to get 10 outputs in hours that correspond to the probabilities of it being these 10 things and uh basically whichever one is the highest we can kind of say that neural net believes that the image we passed in is that thing and then we can compare that um that answer that the neuron that gave us to the actual label of what the data set gave us because the the training data actually tells us what it is what it's supposed to be like like a human went in there and actually labeled it for us um and so uh what we want to do is the loss function here will tell us how correct or how incorrect we are and basically it'll say like okay the neural net said it was uh like maybe move the neural that said it was a tshirt but it was actually a boot for like this first one um for the for the for the boot image that i showed earlier then we know that that it's very wrong and we can kind of see the loss function is like okay you're this much wrong but how do we get better uh so it tells if we're super wrong then we want to get closer to being right and that's where the optimizer comes in uh which just kind of tells us like okay make these changes to all these these weights here to be a little bit more correct because um we can just like we can alter these by saying okay if we if we um if we know it's an ankle boot but it thought it was a tshirt all we need to do is just kind of like adjust all the weights that connect to the tshirt node at the end and be like okay lower all those weights because that was way wrong um but we know it is a boot so it's like okay well we know it's a boot so let's increase all of the the numbers that were connected to the boot because this should be higher and the tshirt should be lower and then that's how that changes all these weights here and then we repeat the same process here and then here and then here again and then that's one that's kind of that's what one epoch is with one image and then we um for anybody from last week remember the whole epoch conversation we had uh and then then we can repeat that again with um another image so uh to cover that again so the loss function we we pass in some data it goes through all these random numbers and then we get something out then the loss function will tell us how wrong we are so we're just you can this fancy name is just like a name of a function that we can use to tell us how wrong we are and then the optimizer is a way to alter these weights in a way um to make this normal a little bit more accurate in being able to classify different images as these these data types i mean as these uh clothing types does uh does that kind of make sense it's kind of a complicated thing to explain i think there's probably people on the internet who've explained it better but i i hope i didn't lose you guys again hello hello is anybody anybody there no it's good yeah it's clear okay awesome awesome awesome okay so yep loss tells us how long we are optimizer tweaks all the numbers in the neural net um and actually yeah did somebody say something um i'm just i'm trying to remember it from last week was that the is that a different optimizer and loss functions that we used in the last weeks yes so the thing about loss functions and optimizer functions is and even knowledge too like there's different neural nets and different optimizers and different loss functions that are useful for different types so for images these are actually pretty good for image data like last time we were working with just like straight numbers a very very simple onetoone number relationship but now we're trying to map a 28 by 28 image to like a series of ten numbers which is the probability of okay maybe this is a shirt maybe it's a shoe um so these are different uh but basically there's just a bunch you can use and you can go and test all of them but um and then all the math behind this uh is there i don't actually understand i don't remember i don't remember what atom is or sparse categorical crossing should be whatever this is but um they're just things you can specify you can just like choose whichever one works so these are are i'm pretty sure are good for for images so i'm guessing i'm guessing like tensorflow or keras whatever whatever it's coming from it's got um like predefined libraries of all these functions and and somewhere on on the internet somewhere there'll be a i'll list them with like an explanation of what they're good for yeah probably like that i mean we can maybe look a little bit like what is this sparse i'm curious because i actually didn't learn the specific there's just so many sparse i mean the documentation is a good place to go so like if you look here so tensorflow.keras.losses so this is lost function so that's why it's losses and this is called sparse categorical cross entropy so i mean just from the name i mean it sounds scary i mean the first thing that comes to mind is um it's probably trying to pick up on like different splotches of like brightness and darkness in each image and then it's trying to like find like the amount of chaos and randomness inside of those um images and then like i don't know what categorical means but it's probably doing something like that and trying to like translate that to like how right or wrong you are um i mean i kind of just pulled out my my ass but that's what it sounds like it says computes the sparse i mean okay what's just explaining itself here that's not very helpful um yeah i don't i don't know the math behind this one but uh the idea is it just tells you how right or how wrong you are you just get a number from zero to one at the end of it or something like that uh for this for this specific one but someone documented it like a dummy's guide yeah hopefully there's some crazy math behind it and and stuff yeah i mean it's it's a whole it's a whole like um field of thought right you know machine learning and all these different there's always like new papers and research coming out about like all these different things like this actually is uh something fairly fairly new uh really i'll touch on this in a second um relu is something that they they started doing more recently there used to be a different one but this is like a huge optimization thing that makes throw that's like 10 times faster but still get pretty good accuracy they started using this instead of something else and now it's kind of like a like accepted standard to use this relu thing um i forget what it stands for but oh yeah i wrote right here relu so um okay let me let me explain this a little bit i forgot to touch on the activation functions actually okay let me let me explain this a little bit i forgot to touch on the activation functions actually um so how the neural net works is again we have all the pixel numbers here from 0 to 255 on each of these nodes then we have a bunch of weights here that could be any any numbers at all it could be 0.1 could be 4.6 could be anything could be negative numbers too and you just multiply it and then you get like hidden layer stuff then from here when you get numbers you want to you want to pass this into another function um called the activation function like once we get the pixel data we multiply it by all these crazy numbers and we get like a new column of data here of new numbers these we also want to do an extra step that's hidden within these nodes that's called the activation function which kind of um treats it as it's like an another layer of filtering it kind of like specifies the threshold of like okay this is good enough or not good enough like um like for like like one good example is in the output layer we can say okay if the output is above 0.9 aka above 90 we can confidently say that this is a shoe but maybe it's a sandal you know like maybe shoe and sandal are both above 9.9 and that can we can specify that threshold of 0.9 um but then just the highest one will be the actual the actual answer like maybe it's like 0.95 and then 0.99 so the 0.99 would win but we can kind of like specify some threshold of what gets passed on and stuff so you can kind of filter that stuff there you can be like okay anything above 0.9 let it keep going anything below 0.9 completely turn off because we're we're sure it's not a shirt we're sure it's not a bag and stuff like that so the activation function just acts as like a filtering mechanism within each layer um that can further filter out our data um does that make sense with that whole like 0.9 example of like in the last layer yup it didn't make sense okay okay good uh so that's what that does and basically so what what we're doing here is um before they they had some crazy function called the sigmoid function uh it's not important it just it's this thing that kind of like uh it's a perfect continuous it's a nice pretty curve function that kind of like okay if we're above this little threshold then let it buy um but it's really computationally intense when you get really big neural nets so basically what they did is this relu thing they said okay literally if anything is zero like below zero just return zero this passes zero through um but if it's above zero just pass the actual number it is so basically it's just like chopping off all negative it's just getting rid of number negative numbers that's all it's doing and it sounds really simplistic but it seems to work in in practice so uh totf is tensorflow and and i believe this neural network um then uh relu is uh it just gets rid of negative numbers so basically like i said these weights can have negative numbers but once it gets here if it's a negative number it automatically just gets turned to a zero and then any positive numbers just stay what they are and it kind of um simplifies like the pattern stuff i don't i don't remember the the exact theory behind it but it does that and it actually improves the the um performance of the neural net and it does that for for um for each layer that has really specified so bradley is like really a really popular one um uh this one down here is so the activation function here so uh this one is softmax and all softmax does is it just picks the greatest number out of everything so in our point um because i said that the the last layer is going to be ten layers here from zero to nine and it's gonna have the probability of each one it being one of these um then it'll just pick the one that has the highest the highest probability and spit that out so for our case if i go back to this quit out of this and run the code again so this is our first data um data image then we know this is a shoe um so uh this probability would probably be the highest like the this bottom node might be like 0.99 or something or 0.97 and all these might be like zero point one zero point four zero point three like it's not it it's pretty sure it's not all of these and since this is the highest it'll just give us nine it'll just give us nine and then we know nine is is uh mapped to ankle boot but it'll just pump out the number nine so um soft max basically just gets the the maximum um number within that layer and that's all that activation function does very simple because that's all we need to do in this last layer is just kind of like which one is the highest like that's the final filtering mathematical thing we want to do in this last layer um to to finish off the neural net is just find that find the greatest one in in actual practice what it does is i believe it does this like it might be like 0.1 you know 0.3 0.4 0.2 blah blah blah blah and then all the way to 0.99 for the last one um all it really does is it just does this so it just it just makes all these zero oh wait i screwed it up it just makes all these zero and then makes the greatest one one it would be like that so that's really what it's doing that's what soft max is actually doing just kind of like boiling this down to this and then from there we can like okay so the ninth one is the one that's on okay this is a shoe and that that's kind of what's happening uh within the neural net is that clear so far yeah it's kind of clear but i have a doubt and that so basically what's happening is the hidden layer is filtering out all the negative values and it's just keeping the positive values and the outer layer what it's doing it's it's just picking up selecting the max value and setting it to one or like it's telling us oh yeah it's it's gonna it's the max value zero point nine and so it's gonna be a shoe yeah so uh like why are we introducing uh the hidden layer if can we do uh this uh operation using a function maybe like a simple function or like why are we why is the need to introduce the hidden layer can we uh do it without the hidden layer is it possible or like is it computationally tough or like it's not possible or like what is what could be the solution so um the point of the hidden layer is to actually well i mean you need the hidden layer for it to be like a knurled in the first place like if we just went from um what happens if if we eliminate the middle layer what happens then everything wouldn't it wouldn't work that well at all because the here let me draw it out let me annotate a little bit so you would have the you know the 784 here the 784 input layers here which is just the pixel data and then you would simply have the 10 the 10 output layers here right which is what you're asking yeah so we'll just let me just draw this out so you have the 10 here and you have the 784 here like that and then um we want this to be like densely connected so um this you would get i mean i didn't haven't actually tried it you would get like decent results maybe but the idea is you have all the pixel data then you want to multiply all the pixels by certain numbers and get an output uh the problem with this is there's no this actually really isn't a neural net because there is no hidden layer the idea of the hidden layer is to capture some kind of pattern and kind of generalize like some visual patterns or any any in this case visual because it's image stuff but any pattern in any data and i'll capture those patterns and then eventually filter through enough time to get some kind of results so i mean this does qualify as a neural net but if you delete if you get rid of the hidden layer um the idea of the hidden layers is the more hidden layers you have when the bigger the hidden layers are then the more patterns you can pick up on and the more accurate you can get so this kind of completely eliminates like all that pattern seeking stuff because you only have like uh one layer of of numbers to tweak so it probably wouldn't work that well uh but one single hidden layer does work pretty well um comments nigel says the hidden layer and its connection is the function so pretty much yeah it kind of like it's yeah it is i mean it's a function in the sense that you have input and then it does a bunch of computations and then you have some output um so the whole neural net itself is a function but also each layer is like a mini function within that so um yeah but then i mean the function we're trying to do here is input image output label of what the heck it is so that's the the high level function but then the inner function would be like okay um maybe for for this it's like okay does it have a curve like is there like a weird looking curve thing here because that it might pick up this curve and be like okay this might be a shoot because most uh shoes have a little curve you know like where your toe goes up to your ankle there's there's a curve in um and shoes a lot and does it does this look like an l you know something like that like a zork out of here are we gonna dive into the computations and how these neural networks work are we gonna dive into that or it's just the basic um outlay off a little bit i i want to touch on a touchdown a little bit but not too much because i mean yeah you can go you can go down the whole math rabbit hole if you want um but then it doesn't get too applicable i've touched on a little bit before but i don't want to go too deep into it so is it a good practice to dive into what like what this neural networks do or it's just like oh yeah this functions uh does this thing so i need not worry about what's going on within the hidden layer and it's just like one of those things it depends what you want to do or if you're trying to become a professor or become like an academic or research kind of person then yeah you should understand the math but if you're just trying to create apps and you want to find a way to apply this and make money from it like as a freelancer then you probably can you don't need to worry about the math so it really depends what your personal goals are um i'm trying to find like a good middle ground between both just to kind of give like a general understanding of okay the underlying math so somebody could like converse about it in a more intelligent way but then also have some kind of tangible result at the end without getting lost in the calculus because it gets really messy and i don't remember half of it i'd have to review all the the dirty math actually i'm uh pursuing my master's degree in data science okay a little bit uh curious i'm just starting off so this was a little bit curious about what's really going on within the hidden layers so as of now let's keep it simple maybe i'll go through your previous videos it's my first like uh coaching call with you i think oh welcome welcome so i'll definitely go through those uh your previous videos as well and grab uh most of the information from there and maybe i will get back to you later yeah awesome yeah i can pass you a couple resources too like if you're actually studying it there i know a couple other guys are doing similar stuff they're getting their masters um i was i i dropped out a few months ago but i was i was also pursuing my master's in machine learning but then i stopped to work here fulltime so uh yeah i'll pass you a couple what is your or just message me on slack and then i'll pass you a couple of resources you can check out that you might find interesting yeah definitely yeah for that for the math stuff yeah of course yeah thanks aaron yeah um what was i saying oh yeah so the hidden layers are definitely needed because that's kind of like where the power the the work gets done it's like like that's the function the function like the main part of the function like this is just an input function this is just an output function but then you need like the pattern recognition like okay what is happening function which is the hidden layers okay uh let's continue on so okay uh let's continue on so um i'll leave that there because it might be useful later okie doke i was talking about the activation functions and then okay loss functions again loss functions tells us how wrong the neural net is and then optimizer tells us how to tweak all the numbers um and that's what we need for compiling just because we need to specify like how to do the correct calculations like once we pass data into the neural net we need to know what function to use once it's gone all the way through to measure our incorrectness and then also what function we need to use to opt to change all the numbers and uh repeat that with every image over and over and over again so that's what compiled us we're just getting our model our neural net model ready for uh training now we're just specifying all these things so next step from here is just to probably just pass in the data and get it going so let's do that next how many people are still on here you see one two four fifteen people or so hey aaron hey joe what is up i'm trying to make sense of what the hell is going on here ah did you come in were you here from the beginning or did you just jump no this is my first coaching call i mean i i was on a first first call but this is the first call with tensorflow is this is this the first call where you're starting tensorflow you did one before last week we did one yeah i missed that then okay yeah but the recording's in the course you can go watch it that one yeah it's about two hours it's a little bit messy yeah so if you if you can give me like a quick twominute pitch of what what's the final goal here are we trying to achieve and yeah sure yeah i'll do that again because doing doing that over and over again is not a bad idea either just because it helps kind of solidify the ideas so again yeah tensorflow we're using this to design neural networks and um solve problems so we're creating a neural network like this within tensorflow the idea is we want to pass in um a bunch of images here uh within here each one of these correlates to a pixel brightness and then from there it'll filter through um the neural net all that all that means is each of these numbers has each of these lines has a number and you multiply that number by all the pixel values and over time you can pick up weird patterns and at the very end we can be like okay um this might be a shoe or this might be a shirt because the data we're looking at is actually um some oops was it supposed to do that well what happened one second one second there we go this one there we go uh did you see the the data that we were um looking at were you here from the beginning of the call joe no i just joined like maybe five oh okay got it yeah so we have a bunch of images like this is a shoe and then um let me just show you one more so this one is a um oops ah yeah it's running all this stuff because we have all the the code in there just ignore that for now so we had a shoe before and then we also have a shirt here okay so what we do is we have a bunch of images of different types and it's just like 20 by 28 images like this for shirts and basically they're of these 10 different types so boots bags shirts tshirt top trousers address all this stuff and the idea is we want to train our neural net on a bunch of these images that are labeled like this is a shirt the one before it was a shoe and we want to go through our neural net here and uh train this neural net so that going forward we can put in new images that look like this and then properly identify what they are gotcha so that's the so that is the practical example of it basically you're training you're training the network to recognize certain images associated it's like how your brain functions when you see something then next time when you see kind of associated with that correct yep that's it so that's what we're doing so what we did is we designed the whole model we designed the whole neural net um we have the whole input layer correspond to the whole image so 28 by 28 we we flatten this out into a 784 by one column which is here so every pixel is represented then we filter it through all these crazy numbers so each of these lines has a number you multiply the number by the pixel value and you get a new set of numbers and then you do some other stuff and then you keep doing it over and over and at the end we're gonna have 10 different nodes and then each of those is going to have a probability of how much it believes it's one of those things so in this case this is probably going to be probably shirt probably spit out a 6. and then the one before is was an ankle boot um and so so that's what that's what we're currently doing okay yep and let me just quit out if it will my computer is kind of screaming right now there we go oh no i think i broke it um dang it okay i'm gonna need a new all right cd desktop tensorflow app and uh source v and uh bin activate i think does anybody remember what the command for let me just find it why is even opening there we go bin yeah bin activate that's correct so this should work okay and then python 3 image classifier that pi and okay there we go add though okay yeah this is the annoying thing because it's training the model every single time over five epochs just wait wait a second guys okay let's get rid of this one because this one is broken and there we go okay back to where we were so welcome joe so that's what we're doing uh now let me continue on in the code so each of these just uh just to interject so each of these lines uh when you say model uh so if you no scroll not not here go back to your code up scroll up for a second so model are you assigning this like a is that a library keras not sequential yeah okay so really really quick um you can watch the recording later to get the full explanation but really quick uh keras is a library that tensorflow uses to create graphs which is what matches it for the things and then tensorflow allows us to do the actual computations all this means sequential just means that there's a sequential thing of columns one by one one at a time there's no jumping between there's no jumping that's each is in sequence so that's the overall neural net then we specify three layers so the first layer for us is a layer of 128 and then i mean of 28 by 28 which comes out to 784 and then we have one hidden layer of 128 and then ignore these two pretend these two layers aren't here and then there's an output layer of 10 um which is going to correspond to these 10 which is going to have the probability that each of these what how much it believes it's the image is one of these 10 things all right so that's how we create the model then from there then we created uh we have to compile it we have to specify a loss function and optimizer function so this just tells us how wrong the neural net is and this tells us how to up to change the neural net to make it a little bit more correct uh we just specify those two there uh you can choose a bunch like these names aren't important it's just there's a bunch you can choose from then from there then we can just start training so once we have the model built and we tell it which functions to use then we can uh start training the model here so this is how we do it so all you do is you call model.fit and fit just means we're going to fit our current model that we just created to the data set that we have uh given to it so in our case we have a bunch of these images like the the the clothing images there's 60 thousand so the 60 000 images in the training and each of those is also labeled 60 000 somebody some crazy person went through all 60 000 and manually label all of them um which is something i would not want to do and then we also want to specify how many times you want to go through this whole thing so an epoch is just one um one pass of this so you would put pass through all of the the images all 60 000 images see how wrong all of them were and optimize all them 60 000 times for all 60 000 images because there's 60 000 in here and then you would you would change everything in the neural net one time so what we're doing is we're actually adjusting all the weights in the neural net five times and that's what it does is we pass all the images and see how wrong they all are take the average of all how wrong it is overall and then optimize it overall and then we do that five times and that's actually what you're seeing here you can see that it runs five epochs here you pop one of five two five blah blah blah from this this was covered last week too if you wanna watch the recording um so that's what this does we're just taking our model and we want to fit it to our training images and labels so you just pass it in in this way images first then labels and then you specify them on an epochs and five seems to actually be pretty good because the images are pretty small only 20 by 28 we're not they're not even like they're they're really really tiny um so eat five epochs is sufficient here um cool yup uh last thing is now that we've that we trained our model now we just want to actually uh test it so all you do is you call the evaluate function instead so because after we run fit it's trained our model is now trained uh across five epochs that's why it was taking a while you saw that let me just run it again so when we run this you can see that the image is going to pop up um just ignore that so um here so you can see the epoch is running so it's actually running all 60 000 images and then it's it's seeing how wrong it is and then optimizing then how wrong it is and optimizing how wrong it is optimizing across all 60 000 images and it does that five times and then then it stops so that's that was the training and then at this and then you can actually see the loss so it's telling you how wrong it was after the first epoch and then you can see the loss is actually getting smaller and smaller and smaller and then i believe this is the uh average or something i think this is like some overall arcing uh loss or something like some global loss the whole neural net overall um and then from there so that's what's happening here now we can actually is it is it is it just learning one image or is it learning all the ten images across when you feed it in um so it's actually taking all of the 60 000 uh images and it's it's training it on all 60 000. oh okay and that error is and that error is across all those images right averages of all the images yeah how wrong they all work because we know the correct answer and then we know the answer the neural net thought it was and then we can kind of like measure how wrong it was and then from there which is what this does and then the optimizer will tell us how to optimize the weights a little bit better cool and if quick question then if you're only running five epochs on that and it's still down to what was it like 0.5 something for an error if presumably if you ran that like 10 epochs could you get that you would get that down even closer i mean i guess let's try it i don't actually know um i just know that the the numbers within this app were actually pretty finely tuned to be like decent performance so let's run this for 10 and see what happens so first loss was three and then it got down pretty small i mean it's a pretty big jump and then the jumps get kind of smaller so i think there's yeah there's like a point of diminishing returns it doesn't look like it's getting too much smaller you can see it's kind of leveling out there yeah there's probably the data set isn't good enough and the image would be just too small so at a certain point it's just proportionally steeped in levels out right yeah so i mean that's also kind of like you need to like just use some human brain power there and just kind of be like okay well this seems kind of useless for the amount of time it took like this got eighty percent of the results so maybe we can just keep it the five um so we'll just put it back to five but okay i need a faster computer so if you increase the number of epochs this image won't get any clearer right now it's blurry no so what's happening is um there's a bunch of different images uh so like i just show you the first and second image the shoe and the shirt there's actually 60 000 in here so i i could even go like you know 50 000 if i wanted i could show you this image um why don't i do that just out of demonstration purposes but the idea is you're just passing in all these different images and then you want to um train across all those images but the image will always be 28 by 28 so this is just another issue so the 50 50 000 image in this data set is another issue but a little slightly different shoe okay oh my goodness i gotta i gotta stop doing that because it's gonna it keeps retraining the whole neural net over and over again every time okay so you're only focusing on a shoe you're focusing on even the shirt and the other 10 10 all together images combined oh we are so i mean if i chose like 40 000 hopefully this is not a shoe but there's ten different types of clothing types and it's just shuffle it's just randomized data label all right so here's another shoe okay i keep getting shoes for some reason but well and then again with the the one and ten chance yeah i mean how many times am i gonna get a shoe versus like dresses or bags or something by the time yeah i mean i wish they had images in here they don't have you know they don't like show you like the images like they'll be nice to actually have some sample but you have to go into the data set yourself so it is what it is but i can use you can just kind of take it with a grain of salt that this is what the data is it's just like randomized images that look like these things um so let's see what we have here so uh yeah so we trained our model across five epochs and we saw kind of like the diminishing returns there so epochs 5 seems to be like a nice finely tuned number there for this uh this specific training data um and then the next thing we want to do is want to test our model the next thing we want to do is we want to test our model so we do that from using model.evaluate and very similar similarly to here instead of training it or fitting it on the training data we just want to test it on the test data so like i said at the beginning there's actually seventy thousand images uh within this data set we use sixty thousand for training and the remaining ten thousand for test so we we um put the sixty thousand in here and we're going to use remaining ten thousand images to see how accurate our neural net actually uh performed and and the thing is going to return is just um test uh the loss the overall loss which is it's actually just going to spit out this number this last one i think this is like some kind of loss average or something like that um but it's not super important i just kind of put there to save it i mean there is an accuracy number we can get i think uh there's like measure accuracy or something we can actually add that in a second but let me just finish off that first and then we can add it at the end um so when i do that then we kind of have to do all this code together because it nothing's gonna show but what happens here is it's basically evaluating and tells us how wrong it is but then we can also um make predictions so um let's do that next uh so yeah this will get us accuracy i'll do that in a second after afterwards but the predictions here so what we can do is we can actually take the test images that we have the remaining 10 000 and we can use our model to predict um each of these images and then we can actually compare that to the actual data the actual labels we have because we have the correct labels here the test labels but we don't want to give it the labels you just want to give it just the image and see how well it performs so this is going to give us predictions and um what predictions is is it's actually just going to give us the 10 probabilities of each of these last 10 things so let's start with that and let me just actually show you predictions at zero and predictions at i mean uh well actually let's let's do this so i'm going to get rid of this stuff and go down here so what we're going to do is on instead of train images we're going to go on test images so let's go to the first test image here i want to show you guys the first test image uh and then show that and let's actually just comment all this out first so we can go step by step together so we have the whole model trained and built and all that stuff now i just want to show the first test image and then let's just see what it is together because i actually don't know what it's going to be aaron i have a question instead of uh running the whole program again and again like it will again train the data in this thing we can use jupyter notebooks for just running the cell right yeah we could use jupyter notebooks yeah there's like a thing that has tensorflow built in um and it's called the google collaboratory but i i just prefer running it locally but i guess i guess we could i still haven't looked into that uh tori collaboratory google collab tensorflow i think i mentioned this last week oh yeah or we could just use regular jupiter notebook if we wanted to but i'm i came from c so i'm a big fan of just writing it in the local machine yeah because even for testing a single data we need to train the entire model that's yeah over and over yeah it doesn't keep the state i mean there's probably some way to keep the state um there between between runs in some way like actually you can probably save the neural net um in its current state and they just keep keep running it but yeah i haven't looked into the jupiter notebooks i haven't used juvenile books that much actually at all uh in my in my time programming but i'll try to look into it if it streams like streamlines the process for for next week yeah thank you thank you for the suggestion but uh okay so this is the first test data so again another shoe so apparently this data set is very shoe heavy and um let's actually also print out the uh label so let's go down here and print out the label of this first one so this should be test labels at zero uh yeah so we're just gonna have to wait for the it's train each time for now all right cool so it's a shoe here and then when i put out of this it should say nine which is uh ankle boot so nine is ankle boot so that's the correct label um so that's what we want to see we want to see the correct label here so we're just focusing on this chunk of code here the first test image is issue and the label is nine so now we want to use our trained model to actually predict um what is going to predict what it's going to be so if we print predictions at zero so this is the first image of a shoe in the label then we call model.predict and we pass in all the test images and it's going to give us all the predictions so and then all we need to do is this this is just a list of a bunch of outputs from the neural net so if we go at predictions at zero what we're going to get is we're actually going to get the the list of 10 probabilities for the first image and then if we this if this was predictions at one we would get the list of 10 probabilities for the second image so on and so forth but let's just focus on one at a time so let's um go back to here and run it again yeah i'll look into jupiter notebooks because this is going to get tedious at least it doesn't take it just takes like seven eight seconds not so bad all right and there we go so you see this here this is actually the the list of probabilities that our trained neural net popped out for that test image of that shoe that we just saw pop up so it needs to be nine so um ideally this is going to be the biggest number and it looks like it is like this is all scientific notation so um as this gets bigger that means it's a smaller number so 19 13 38 15 38 3 18 3 12 yeah one so this is actually the biggest number which is the ninth place because this is the probability of it being uh the first thing second thing and last one is ankle boot so this is the biggest number um and uh we can see it's actually performing correctly there but this is really messy and ugly so what i did is i put in a little hack to make it nicer to look at so let's do that together now and that's actually these two lines and all this is doing here is instead of printing out that nasty list of all these probabilities here for each of the 10 different things in the neural net um all i do is i find i use the max function so the max function here so look at this highlighted portion of code here this max function finds the the max number within this list for us which is going to be this last one it'll find this and then i just call index on it so uh so that i can find the the um the index of the the max number in that list so all this is doing here this is kind of messy is it's just getting the index of the biggest number in this list in this case it's going to be 9. so this will just return us the index of the biggest number and that's what i'm printing here instead so let's print that out and see what happens predictions and labels at zero oh again it's got a train okay one last time for this demonstration purpose and then i'll do one more image too because i think it it gets these correct there we go so here's the shoe of the first test image and it's labeled the label is supposed to be nine which pops up and then as you can see here's the 10 probabilities again the probabilities are a little bit different this time because it i guess it trains it in different it trains the neural net in random orders of the images or something like that so it's not always exactly the same but as you can see the it says that this number is the highest because it's the last one so uh it actually predicted this image correctly um i don't know if i printed out twice i think i'm printing it oh because i i print out this again now i don't need this actually let's get rid of that one so as you can see it's well actually put that back let me get rid of this last one um so as you can see it actually predicted it correctly so it's supposed to be 9 and then the neural net predicted it to be 9 as well and if we go to the second image which hopefully is an issue this is bad coding design just popping in the one there like that but just to show you guys so let's see what this is uh hopefully it's a shirt or something okay ah nice a shirt okay or some some type i don't actually don't know what it is it might be it might be pull over or probably probably going to be pull over because it's long sleeve it looks like it's a sweater or something so this is the image the second test image and we see that it's a two labeled as two so yeah it is a pullover too and then this is the probabilities of everything and it seems like a pretty predicted it to be correct so it it accurately predicted predicted it to be a pullover and if we look at this 0 one two yeah it looks like this index is the biggest number because this is only negative one compared to everything else is a little bit bigger don't know what this is it's a little funky um i'm not sure why these are zeroed out but uh yeah it looks like um it's it's predicting it pretty pretty accurately so uh that there is actually it for the for the app let me see if i can get that accuracy thing because this will actually uh test the accuracy of the thing overall i think it was measure accuracy matrix equals accuracy class there you go maybe this yeah so when you're compiling the model you can actually also specify uh different metrics for it to spit out um so if you go back up to compile and i add it here i think it's metrics equals see i think um and then let's just try that and see if it breaks it might break um actually i think it worked well i think it's gonna give an error right now because i didn't specify the oh okay i didn't complain um i think i think they changed some stuff in the new version tensorflow um matrix accuracy maybe this one let's try this since that's what they're telling me to use no actually the accuracy is written there uh below under each epoch open the terminal maybe i noticed did you see something yeah yeah right 81.97 accuracy oh nice i didn't even see that because it was okay pocket shows that finally i didn't see that at all good eye good eye thank you oh nice yeah i only i'll usually only look at lost because you because uh all of all of the machine learning is when the neural net is you're just trying to minimize the loss like at the end of the day you want to get this as close to zero as possible and then this has like an inverse portion to the accuracy so cool so we didn't even have to worry about it um wait was this actually running oh no when i did pop in accuracy it added it on nice so like when i added on this this metrics accuracy so this actually is correct what it is does is i guess it it um added on the the the accuracy metric here so we have the loss um and then i guess uh not sure what this is probably just the timing but yeah the accuracy is is here which is good so we don't have to that's it so that actually that was correct i just didn't i didn't notice it thanks for noticing that um was that you ruben yep is it you thank you ruben no problem so yeah the accuracy there so we can actually say that uh across everything it has a 0.81 accuracy uh for all of the test data so when it's running those 10 000 test images then the accuracy is about about that much oh pretty cool i mean if we run 10 epochs i wonder how much that will actually improve the accuracy of the neural net and i think this can be the last thing we do to wrap it up seven okay yeah it looks like it's increasing slowly nice and then there's the second test image of the shirt but yeah it looks like it's going up slowly i mean it's probably going to level out at some point um because of the structure of the of the neural net like if you have a deeper neural net we might be able to get this up into the 90s or something the accuracy but i mean this is this is pretty good i mean if it's if it's right 83 at the time i feel like that's a pretty decent neural net for the time it took to train it it only took like what 20 seconds 30 seconds so um that that kind of completes it guys for the uh like computer vision example of using tensorflow so a lot more interesting than last week i know last week we kind of just did this this uh this cute little number mapping thing wasn't that interesting and it wasn't that that uh it was just kind of numbers and stuff but this one i think it it kind of shows the power of tensorflow a little bit better because it's so easy to define your models and then flatten it you can tweak all the numbers and all the different functions already implemented for you all different types like dense and flat and it's all there for you which is which is amazing um so i mean that really concludes it for the for this image classification of course we can get a lot more complex and a lot deeper than this but this kind of gives a a good uh introductory example to um computer vision and image classification with tensorflow so uh does anybody have any any questions about anything at all um regarding regarding this just a quick one um if you go up to the where you've got your hidden layer again is it as simple if you were if you wanted to create a network with more than one hidden layer is it just duplicating that piece of code there and having it yep just like that so why don't we try to see what happens um hopefully it doesn't break anything i mean sometimes like i don't know like this might be some memory issues or because you know it exponentially changes stuff or let's let's just make this 64. and see what the heck happens um because yeah the input and the output is still consistent with our data um that we're dealing with the hidden layers can be abstracted to anything we want so uh yeah let's see actually let's run it for that's fine i can just cut it if it breaks all right nice all right there we go so it ran and um it seems like the first loss is a little bit lower than general it doesn't look like it really improved the effectiveness that much i mean also the time didn't go up too much either so it kind of really didn't do anything um yeah i didn't really do much with this data set in this this problem but i mean i mean why don't we try to add oh it's i mean if adding a second one didn't do anything adding a third one is not going to do anything either that's usually how it goes uh well let's try to go to up to 128 and see if that changes anything just see what the heck happens i mean it still predicted it correctly because we added we added more accuracy to it so it makes sense that it's still correct when it when it predicts and the actors actually was a little bit higher right i think it was a little bit higher by like two percent but it's kind of um okay well it seems like this one got worse even though i increased the the length of the hidden layer so yeah i guess this is where the fine tuning comes in and then like there's also like you might over fit to like your training data sometimes like sometimes if you train it too much then it gets so so familiar with the training data that it actually has a reverse effect on um new data like it gets so so well trained to the training data and like that data exactly that it gets stupider the more you train it so there's like a weird tradeoff there too you kind of want to don't train it too much because then you can kind of preserve the generic patterns that are existing in the training set without over fitting it the term is overfitting so when you fit it to this training thing that you kind of want to like not do it too much it's this is balance act this balancing act all right um what would be a practical example of this uh you know in the real life kind of is it like a facial recognition that does the c you know the fbi and they they run is that something similar yeah so i mean tensorflow like there's a lot of applications for machine learning in general uh one that i like to use that just kind of like uh let me just pop up the tensorflow the docket classifier the cat classifier yeah yeah i mean from a standpoint of like okay where is this useful it's just like you could use it for anything like one of the classes i mean i didn't take it but i did a little bit in my time it georgia tech was using machine learning for trading so it's like doing um stocks and understanding trends and stuff in the economy um for day trading and stuff like that but yeah so like uh you can you can use it for applications like that joe to um maybe like find patterns and like stock prices and you're like okay you can kind of use machine learning to figure out like okay tesla stock is going to keep rising because historically it has you can like pick up patterns that humans really can't pick up that that well um so there's stuff like that there but little projects like this are just kind of to just kind of showcase your ability to use tensorflow and stuff like that um but you do need to understand you need to understand like the general machine learning concepts you need to understand how to actually code tensorflow itself and all the little different nuances and the syntax stuff there but then also how you can apply this to like the real world if you actually want to use machine learning uh to your advantage to make it like you know a monetizable skill for yourself uh as a freelancer or as a fulltime developer or something so if if you take your uh stock trade an analogy how would that uh transpose uh when you're talking images versus uh numeric data right at the end of the day the images are just a two by two matrix of numbers which is the pixel brightness so it's just picking up arbitrary patterns in a two by two matrices of numbers so you can actually even pick up similar data within like stock prices and historical data or something like that pick up patterns there be like okay this is a good trend this is a bad trend of a stock price this is a good stock this is a bad stock stuff like that and then you can kind of like label it as this trend is good this trend is bad train it train and train it pop in new trends and then it can kind of tell you if it's good or bad stuff like that's the kind of have you have you thought about doing a class project to do the lot of numbers oh lotto numbers um that would be kind of interesting training to pick a lot of numbers for you well a lot of numbers are kind of com aren't they completely randomized so i mean i don't know if machine learning i mean maybe no but you you get the data on on the uh if you go to the lottery website they give you the past 10 years of data and based on based on historical you know that there are very good chance that they repeat the numbers on that day for that day like they run if you do the what is that it's not truly randomized wait the lotto isn't truly randomized no i'm not this is a friend of mine i think he figured out a way so you know how you play in the one one is at the two o'clock and there's another uh at ten o'clock at night yeah i've never actually done it but i'm so if you if you so this guy he he would download five years of history from the lotto website and then he he had a excel macro created that would color chart basically and then he would just play the numbers that get that the macro would spit out and he was making 42 grand a year oh wow really yeah i mean this is no joke this is the guy i work with and yeah i mean machine learning yeah it's it's powerful yeah because like a lot of stuff i know guys in poker who use it you know they like use it to like play poker and maximize stuff using machine learning by like doing that you can apply it to anything it's just like at the end of the day yeah it's just picking up patterns and data and i guess yeah if the lottery isn't 100 randomized like truly randomized then yeah you can pick up patterns over time and kind of like bend it to your um gambling benefits but uh i've never personally done that i mean it sounds like a cool project though i mean i touched on a good amount of tensorflow so far because it doesn't get too much from here like it doesn't get too much in depth like i've kind of covered like half or sixty percent of like the basic like skills you need to like kind of get started then of course there's all these different functions and then you have to kind of figure out like okay like which optimizer is good for this thing and the different data types and making sure everything is like lined up correctly um maybe i've only done like five or six projects with it like in depth um but uh from there then i mean yeah we could probably it might be interesting to do something like that like i'll like just kind of build a lotto lotto thing together just to see you you you train the model and then you pick a ticket it's a buck and see you know you close like actually you want to like actually get a real a real live number i mean it's not like a dollar or something right yeah maybe and they and then they have the uh they draw a drawing at two o'clock in the afternoon and then they draw it 10 o'clock at night i don't know in connecticut at least they do it i don't know how they do it up in la uh might be different yeah i've never even looked into it i try to stay away from that because i feel like it's just it's like i'd rather just go to vegas you know like at least have some fun with it instead of oh they picked my number no they didn't like vegas you know there's there's people and there's yeah more fun than lotto but um yeah i mean that that's a cool idea i did want to ask though because i have been doing tensorflow stuff and i mean it's been kind of like a twomonth process of like teaching you guys like the algorithms insertion sword and going through numpy and pandas and everything slowly up to this point um but i was talking to kazi the other day too and then he was like yeah like i mean the idea clever programmer is to get you guys the results like maximize results like maximize value for you guys so this stuff i mean it interests me and i'm teaching you guys and i feel i finally got into this point of teaching you guys um a good chunk of tensorflow you guys kind of get your feet wet in it um if you're if you're not pursuing your master's in data science like some some people are in the course which is great but uh i want to ask you guys what would be most of value to you like would it be more of value to you to like go back to web development and like the freelancing stuff because i can kind of brush up on that because i know nasir was talking about he would learn some django rest api stuff so i'm pretty rusty on that but i could i could try to brush up for uh the following weeks and then i know i know your ecommerce website tom i i see you posting about that periodically um stuff like that so i just want you guys input if you guys like doing this this tensorflow stuff or if you guys would prefer to like go back to web development um and we're still in the process process of looking for a really good python developer we're trying to find a guy that can um who has more experience than me to really help you guys scale up you know you are doing good aaron i really like the content of the it was today today was my first class after the first coaching call actually with you and i pretty much pretty much learned a lot of things out of it so i think like you had a machine learning uh career in the past and you are teaching machine learning related stuff so you i think you should pretty much um focus on this maybe like maybe for a bit of change or something you can uh skip on to web development just for the taste of it but maybe you should keep your uh like the path clear in like in which you are comfortable with which is which suits more for you most yeah i mean i could the only thing is that like there are a lot of beginners so that's the problem you run into when you have group like group calls and group sessions is everybody's kind of at a different spot so it's kind of hard to figure out something that's good for everybody without being too beginner or too advanced um machine learning i mean there's probably only like a few edge cases where you'd actually need it like for people if they're advanced and they could probably like land clients or it'd be applicable to some project they're working on but usually they're more advanced usually like whipping up like you know like the amazon club or something or something front end might be a little bit better like the way um like they are within the javascript course or something but about combining say you have create a web interface with maybe a rest interface and you run this algorithm or another algorithm algorithm on the back end and then you output it to the browser or something that'll be cool yeah like tying it together um i mean it'd be cool to like like just take this this project we just did and then like kind of wrap it in like a frontend thing and like maybe save something maybe save the state of the neural net in like some django database so that we have to keep like training it like we did and then maybe we could do something big or something like that could be cool uh okay uh anybody else have have anything they want to say about that though like would they feel like web development might have a little bit more um value for them when it comes to like actually yeah i mean if you look at any anything that's on upwork or any others you know that's more i don't see any tensorflow tensorflow stuff that's i mean unless you unless you have that skill and niche and it's very hard to find that kind of projects but you would find a lot of web development projects there yeah yeah i think like more than 60 percent of the web development i mean whereas we've suggested a kind of a blend of both where you know leverage and you get machine learning learning um output yeah definitely i mean it would be cool and fun to blend it um it would be a fun a fun thing to do but these are all recorded which is why i kind of touch on it because anybody wants to learn all this thing there's like a series of like six videos recorded sessions that they can go through and kind of get started with it which is the great thing with these live calls because they're kind of like they stay there forever um but going forward um i just don't know if that would be more useful for you guys like yeah looking here i've been i haven't been on i've been through that in a long time but tensorflow machine learning data i need to look under jobs not people in my opinion um javascript has a more solid grip in web development and python is more oriented towards machine learning data science it has more to do with the data than the side effect yeah aaron have you what the content you produced on youtube why don't you go over some of that image recognition or car face detection i mean why don't you go over that i could yeah um open cv heavy so i was i didn't really use tensorflow too much for that stuff and then actually we implement i mean because i was it i was at georgia tech so they're very much about like academic research and everything like that that kind of school they're very much about like you know cutting edge research blah blah blah so like we actually had to code like stuff up from scratch like why didn't we use opencv but we would code things like not even using tensorflow um at the beginning yeah i mean yeah i didn't mean it to be specific to uh tensorflow but you know just as the projects oh like opencv um i'm trying to think of what i did yeah there is some word the issue with that is some of the stuff i learned is is like it's fascinating to me because like we get into the dirty math but at the same time i don't it's kind of hard to explain these really complicated concepts too because like it requires like understanding of a lot of calculus and weird things so it's sometimes it's hard to like regurgitate what i learned to you guys so i the stuff on youtube was great though because i kind of boil it down to like the general principles of you know like selfdriving cars and car and pedestrian tracking and everything uh face detection small detection all that stuff was cool but um just it's more tangible you can't relate you can show and demonstrate and then people can understand is that yeah i just try to like trying to find like the the good middle ground of um just like interesting content but useful i mean i could go into opencv a little bit more maybe i could find some cool projects there instead of tensorflow or even tie it together both but um um just on that last topic i was just thinking like where would ai be used in commerce like on a commerce site or something where people are like um matching up buying and selling or search algorithms or yeah so i mean i guess like you know like recommend you know amazon like you know amazon has like that'll be actually pretty cool because i know sunny and then they did the amazon clone and stuff it'd be cool if we implemented like uh you know like a recommended item yeah that's exactly yeah recommended systems are huge in ai or machine learning yeah definitely like that or like or like netflix clone you could have like recommended shows or or spotify clone you got recommended songs um you know how is it trends in people's behavior in netflix it's a if you look if you watch a certain genre movie it recommends hey since you watched this maybe you would interested in and the others like words recommended so yeah right here inspired by your purchases so apparently i was uh why is it recommending this stuff i don't know what this is i reckon it's a regular menu this is why i should get a topic because amazon does this to me all the time i think an insight into your life here flour water salt yeast so apparently i want to learn how to cook bread at some point you bought something today i searched for pizza and i got results for bikinis again this could be someone tagged you on facebook that they they do a lot of cross they do a lot of cross uh hashing too meaning you know yeah one of your friends who tagged you and either the algorithm is weak or the user or the buyers are stupid it could yeah i mean if i had to give any feedback on it this stuff's really interesting i've never never heard of tensorflow before the last week of the week before um i mean so i would probably just echo what the other guys were saying you know just just kind of played your strengths if this is the stuff that you know um yeah and stick with it i think the only thing i would say being new to this is it's all really um it's very abstract um yeah so behind it yeah but i mean the whole concept of what it's doing it's it's kind of you know it's really abstract and um i think if you can find something like what you're just looking here you know the recommended things and how how it could be applied in real world situations um yeah if you can come up if you can come up with something like just a really obvious one like like you said amazon recommended or whatever um this is how you can leverage what you know sort of stuff whether it's tensorflow specifically or this you know the same similar sort of theory just you know different platform whatever they're using um would tensorflow be used in like speech recognition and we have like you have 1000 different languages across the world right yeah absolutely yeah you can use it for voice recognition too because voice recognition at that it's a little different because the files the data is like a little bit different um i mean like once it's once it's within the correct form then it's fine but like voice data is like a continuous stream rather than like you know an image but i mean with like so when i buy the alexa right it's it's that is this thing is this thing built into alexa or or when you speak when you talk to alexites it's communicating with another server that has the machine level being constantly updated it's constantly learning and oh um i actually don't know how it works probably something yeah i think you need to be connected because every time i get disconnected from my my uh echo or whatever devices it doesn't respond mostly the second case joe actually i read about it somewhere that it actually the server trains your data are received by this echo dot it's like it continuously trains your data so so there is dropping on me or they can see they have yep they have all your data actually yeah and it's always it's always learning because i've looked at my election and it's got comes up with like a yellow flashing band on it and it's just you say what are you doing and it says i'm listening to you like it's listening it's listening yeah it says i'm listening to your speech and things going on in the background to like to learn as long as it's powered if you if you don't want it to listen if i take out the power it it won't right no there supposed to be options to disable it i mean this was a huge issue years ago that people it was very big issue a couple years ago yeah the privacy and everything consent and all that right yeah i know mark zuckerberg got busted right for like a similar thing right like yeah because of the data analytica the they did the whole rig the whole election thing well they took the data and they did and they used it for for you know whatever the ads without um yeah but this is interesting it's it's washed um like whoever's doing the machine data science for them you know they have this like you know as a part of the curriculum then it's awesome but for us we'll get into like you know trying to get a project make money make money off of it having but the blended would make more sense in this way at least you can put it in a portfolio that you did this and i'll look it up no worries thank you guys appreciate it yeah absolutely all right i think we've been going on for like almost two and a half hours now um any less questions or um is it time to go get some lunch you guys are on the east coast or something it's 3 30 am over here all right you guys well thanks for sticking to the end um all right guys talk to you guys next week yeah guys and that's really it so i handpicked these four projects for you because i feel like they're just really like a good bitesized project for beginner to go from complete beginner to maybe like beginner intermediate um in ai and really get you started okay other than that you guys i hope you enjoyed the video but if you're interested in actually um excelling your skills on python and actually making a real income from it a real living then um please click on the link below to check out our course profit with python which does just that it pretty much assumes you're a beginner and takes you through the complete roadmap from beginner to actually making an income from beginning to end using python and to actually become a fullfledged python developer all right you guys i know we've been sleeping on python for a long time we've been doing all the javascript stuff you know this might have been plugged in by the way but we've we've been doing uh javascript react stack all that stuff but don't sleep on python because python is huge okay on the back end pretty much everything uses python python's everywhere so you really need to know python as well make sure you know your python you