what they were finding was that the model was able to get rewards for things that it wasn't supposed to what yeah what that could mean is that model is going out of control would be able to change its own reward to teach itself to be like hurting human being is actually positive that freaked me out I'm going to tell you like AI Extinction risk is actually not far away wow that's crazy I'm Harper hi everyone I got my undergrad and graduate degrees from Stanford focusing in AI and then I was at meta for 4 years doing AI I started on the news feed ranking team that I loved I loved algorithms how have you seen AI change from the past few years in the past you give it the features whereas neural networks learn features by themselves do you L just go here here's everything figure it the [ __ ] out yeah we don't know what's going on in there however on validation data or on the test data you can look at where the model is failing these are the ones that work and these are the ones that we're not getting right I thought we figured this this [ __ ] out at this point but we at the start what is up everybody my name is Nas and I'm here with Harper from Harper Carol Ai and today we're going to be talking about all things Ai and I'm going to ask her a ton of questions CU I myself want to learn she herself actually studied at Stanford correct and you worked as well at meta is that correct so I'll have you introduce yourself cuz you probably know you you know a lot a lot more about yourself so I'll have you introduce yourself okay I'm Harper hi everyone I am from Harper Carol AI I do AI education online and I got my undergrad and graduate degrees from Stanford in computer science focusing in AI so the AI track and then I was at meta for four years doing AI I started on the news feed ranking team and then moved to Integrity intelligence where we W worked on protecting vulnerable communities from misinformation and and then I left meta and was at a GPU startup running AI there and started teaching AI GPU startup yes yes and then started teaching AI for that startup to get people onto the platform found that that was really successful and that there was a real desire for it and that's also the intersection of everything I love is learning and teaching and making videos and working with people so I have now gone off to do that fulltime and I love it and yeah so it's been really great that's amazing I love that and I'm curious what got you into this AI you know not Revolution but into the AI field what what what piqued your interest there so I got to Stanford and I decided to come as a math major I was going to do business mathematics oh okay that's different yeah I didn't do computer science in high school uhhuh and I loved math I've always been a math person and I love math too isn't it the best so good like long equations are the best like just like when you when you spend two pages on trying to solve the equation oh my God it's so good it's so good and for the math nerds applied math I'm more of an applied math person don't judge me but I like applied Math More sorry but I went to Stanford for Math and decided to actually take a computer science course my freshman fall cuz a bunch of my housemates were taking it and they encouraged me to try it so I was like all right I'll try it and first class was really difficult second class was an algorithms class first class was JavaScript like making games kind of thing second class was C++ uh algorithms that I loved I loved algorithms that's when everything really clicked for was like Wow cuz it's kind of similar to mathematical thinking but computer science teaches you to think Super logically you saying no is it the challenging part of it that keep made made it very interesting for you yeah and it's like the really logical brain right like it it snaps into that kind of place and so algorithms optimal algorithms was really fascinating to me and so from then on I was like okay computer science that's the thing and there are various tracks that we could go into in computer science and I was interested in HCI human computer interaction which is kind of like design kind of thing but then I was interested in Ai and I heard that it was very mathy mm and I like math and I heard that you like algorithms and I like algorithms I like math I like algorithms it all comes together HC was a little bit less algorithm heavy um as you would expect yes and um I just loved it I took a class in it and loved it it was so fascinating that was back when large language models were not nearly yeah like the outputs were hilarious rather than like wo this is so good they would be like wow look how funny this is but it's so cool whereas now it's like you know next level but yeah I got into it learned about you know natural language processing which is large language models computer vision deep learning which is like neural networks how that applies to computer vision natural language processing just like a a large breath and depth of knowledge so yeah yeah it was a very different field back then CU I actually gone to AI a little bit too myself oh okay uh I think about four to five years ago when I started my first startup we wanted to build a product that would tell you what to dress when we ourselves knew nothing how to dress okay that's why you need machine learning for it so you guys don't have to put in your input at all we literally had this like it was like a Tinder swipe left swipe swipe right situation when you would swipe left swipe right on like clothing and then it would learn based what based on what you like and they would recommend you things based on based on that complex algorithm there but like before it was like learning like the simple thing like linear regression Bas out good I still remember those very I mean they're not basic of course but very different than what it is right now and it has changed a lot over the years and I'm very excited for where it's also going to go in the future as well by the way if you want to learn from this video 10 times faster with eii me and my cofounder Kazi have created a product called poppy eii that helps you bring in any YouTube video any website any voice note or even image and allow you to talk talk to it instantly in a whiteboard canvas think of it as your own whiteboard with AI superpowers imagine you drag in this YouTube video that you're just watching right now imagine you dragg in maybe an image for example like this or maybe you want to record a voice message of yourself talking about a specific topic and drag that in to talk to it instantly you can do that as well here with this video we can for example get key insights really quickly so maybe you don't want to watch the whole video you can just get key insights so super fast or maybe you want to ask questions about what Harper or I said for example relo which is something that me and Harper talk about on an activation function for neural networks we'll cover that later on or maybe you want talk about and ask question about linear regression and logistic regression and what she says about that and how that maybe plays into the real world amazing way of just learning 10 times faster taking notes and be able to create content and also be able to understand things so much quicker if you're interested in doing this right now like I said we have a crazy deal for some of our first few customers so far the people have been loving it we've had some amazing testimonials and reviews from researchers from vas from students from even Founders and they're all displayed right here so if you're interested in checking it out go ahead and click the link below check out papy and we'll see you in there so I'm really curious you know how have you seen AI change from the past few years to now how has it actually progressed cuz I feel like it's progressed a lot it has and I think the main shift came with a Transformer which I think was in 2017 well the Transformer the Transformer it's an attention based mechanism with neural network so it's like it's a type of deep learning okay a Ty of neural network okay and it adds this layer this attention based layer okay to look at how like the structure of the words and then you basically learn I'll just like do a super broad overview of this but like you're able to learn over and over again how all the words connect with each other and so like you have different layers capturing different semantic meanings and that's what the layers are learning is like the different connections between them but something about the attention layer and getting these links between all the different words layer is that neural network This falls under a neural network and inter So when you say neural networks what does that actually mean because to a lot of people watching this to a lot of people even to me it's very much of a black box I know it's a large question no that's okay I actually have a course on this and I've started I just made an architecture class it's called the 10 days of AI Bas oh that's amazing is that your Instagram or it's my Instagram so my Instagram has like 90c reels on this and then I have released all 10 days on Instagram and then I have an accompanying video in process for each of those 10 days and I have done days 1 through three which are like the day day one is what's the difference between Ai and ml day two is about data day three is model architecture where we talk about neural network architecture and I'm happy to go into that here and then four 5 6 7 8 9 10 are on their way but if you want to watch Days 1 through 10 on Instagram you can and then the longer videos are on yeah and those will be of course Down Below in description guys if you go if you guys want to watch that so neural networks okay oh let's go I'm so excited let's go yes the main components of a neural network and again deep learning refers to using neural network yes so like when when we say the Tesla autopilot system right that'll be using networks uh for example like jbt is not near that is it is jbt well we're assuming it is unless they have some crazy thing but yes we're assuming because we don't know actually know what the architecture is tell us it's probably yeah yeah so it's like anything you just feed in a feed in data and it will kind of automatically train itself and think even more on top of that is that correct so at the fundamental level neural networks learn features by themselves whereas in the past or other types of AI models you give it the features for example if you're passing in um you have structured data yes so you say you might have a database with rows and columns and the columns are the features where for example if you're training a health model you have like height weight yeah you know whatever all those Health metrics and then the regression model or whatever model you're using learns how those features relate to get the output right so like for example you know you know maybe let's just say height weight boom boom boom and health score the health and heal score and so then you train a model that says figure out how all of these features height weight whatever transforms into this health score this health score and then they will be able and then based on new input data right based on new input data then what's going to happen is that it will it will actually give you new health score because it's learned over the past from different feutures exactly and that is what machine learning is at it at its core is like learning from data and so those featurebased models right um so that's strictly machine learning right that's not like neural networks right the strict neural networks are a type of machine learning uh okay okay so logistic regression is a type of machine learning because you're learning from data neural networks are a type of machine learning because you're learning from data uhhuh deep learning is a type of machine learning uhhuh and neural networks are a type of deep learning holy [ __ ] I hope you zoom in on that we can make like a little graph for the example that we just talked about right what kind of an algorithm would that be is like I know there's like some very like naive based algorithms like what what are some algorithms for something like that like those machine learning yeah okay so for for something that's more structured you could have a model that is just um like fitting to it so you could do like a decision tree where you train a tree to say like it kind of move like you know how it's you know how with trees where it's like it goes into yeah it goes in it goes like start with a node and then there's children node and children and so forth and so you could train a model to figure out which of those features are the most decision trees are great because they are interpretable which means they tell you which features are the most important M interesting okay okay so they'll know like you can give it a bunch of features they'll say hey this feature makes the most amount of impact is that correct exactly and then it helps you prune ones that don't have an impact and then you can make it even faster and optimize it does automatically do that for you or do you have to SP or do you have to test it and actually oh I think you have to like you know rank the like you have to like code for it to show the um the correlation between the feature and the output so they could be highly positively correlated or highly negatively correlated but either High correlation whether it's positive or negative is highly correlated whereas if it's like at zero so it's positive 1 negative 1 if it's at zero it's not really correlated to the output if we're if we're going to talk about for example like just say in terms of AI when let's just say I say okay I give you a picture of a cat right and then I say this is a cat right and then I give you a picture of a dog I say this is a dog I give you a bunch of pictures yeah would that be necessarily using a similar algorithm like that or would that be like neural networks you would probably want to use a neural network for that really so that is unstructured data so we have structured data where we know the features we have unstructured data where it's just like an array of for example words or you know the pixels that go into an image the numbers that make up the image yeah and or Matrix Matrix the model has to learn the features itself itself I see so when you are passing in like a sentence and then so for example with the Health Data if we were to train a neural network on that we would say hi I'm 5'9 I am you know this tall or this age this is my whatever and so then the model would learn given this block of text just like a literally a block of text just which features map to a health score so it would and we would see that it is able to highlight like height weight like it will yeah but the features that it finds I kind of M spoke because we actually wouldn't be able to see what it is using in the sense that it is not interpretable so like we wouldn't know what features it's actually using to get the output why hear the Black Box term so you might have heard of AI being a black box it's like we don't know what it's doing in there and I can talk about how the structure works why it's a black box and so we can get into that but like yeah we don't know what's going on in there however there has been a lot of research on interpretability including a lot of work done by anthropic which is one of the yeah CL it's a leading company in AI safety yeah they're great they do a lot of research also I love CLA it's amazing um they do a lot of research in AI safety and interpretability they did some research and they found that they were able to find a set of neurons in the model so we'll talk about this that relate to the San Francisco Golden Gate Bridge oh and so then when they Amplified those neurons in the model the model would talk about the golden gay Bridge so like where should I go on vacation the model would be like to the Golden Gate Bridge like oh I want to go for a walk like what should I do it' be like why don't you walk across the Golden Gate Bridge and like everything it recommended like it was nonsensical like it would just like make up stuff to get you to go to the gold gate that's funny like what are you I want to go eat go to the Golden Gate Bridge pick pick up a sandwich go to the Golden Gate Bridge exactly so that was really cool that was one of the most you know pivotal moments in interpretability and that just came out a few weeks ago I thought we figured this this [ __ ] out at this point I thought we were like oh we were there this is like it but we at the start yeah we're on the start but luckily we have people we have companies like anthropic doing this work and is CPT you think doing that too or like I have no idea what's going on inside that company that's so interesting yeah okay so that in itself is like when it's featurebased versus what I didn't know what's really crazy was the fact that neuron networks don't actually you don't know what the features are also let me just correct myself there are some ways so for example like with a with a computer vision mhm um model there are some ways to look at the layers to see like oh this this layer is you know capturing outlines and this layer is Capt like there are some tiny things at least I know with computer vision but to my knowledge it's difficult to interpret they're very difficult to interpret and that's why they're called a black box well how do you okay so how do you know how to get better results for example right from a your own network right let's just say the Tesla autop autopol system will continuously you know get better over time you know and do you get better results byting out different ways of giv input data for example I know Tesla a system cuz I used to drive I I had a Tesla and I was like I [ __ ] love their system it was just so smart yeah and is it like they feed in different types of data like I know for example I remember he was talking about El mus was talking about this at I think they had like AI day or something like that okay um and he was talking about how you know they feed in different types of data one is like monochrome for example images right which which is more black and white for example another one is colorful and then they have a zoomed in version of it that's like they feed that in MH so then how do you know how to improve the model like how does it just get you just go you L just go here here's everything figure it the [ __ ] out well so one thing you can do is you can look at the so when you're training and when you're testing so on validation data or on the test data you can look at where the model is failing so what is it getting wrong because ah okay write exactly if it's a classification problem what kinds of things what kinds of samples is it not classifying and then you can try to maybe cluster them or see like what is similar about it so you might notice if you have a computer vision problem where you are scanning you know employees coming into the office you know from the from the front gate zero security and zero press maybe it's like an automatic I don't know I'm just thinking this right now it's like an automatic system that like checks people in it's it they check it in to make sure it's I was just like I saw this I saw this Instagram real which is really funny they're like he gave every employee an apple Vision Pro and he's like I give him so I can track their eye mov and I can track everything they do I'm like wow I mean it was a funny it was a funny real it was meant to be funny you know it was a joke but but still I was like oh that's that's actually kind of funny spooky oh but so you can train these for example let's say we make this data set where we have people coming in to the office and we find that when we're training this model so we haven't actually trained the model yet to do it we're just taking pictures of people as are coming into the office to train this data set so their image plus their badge you know their name and badge okay and as we're training this model let's say they classify it as employee and not employee we find that in some cases they're not getting it right either they're classifying them as an employee when they're not or they're classifying them as not employee when they are an employee so we look back at the images and we find that most of the ones that are not doing well so you can cluster it where you kind of this is a type of um so this is these are bad images these are good images or sorry oh not not um clustering oh yeah these are the ones that work and these are the ones that we're not getting right correct so let's cluster the ones that we aren't getting right and let's see like what they look like let's understand them and so we look at them and we see they're actually mostly of one type it's and we notice when we go in and look they're dark it's nighttime employees have come in at night and so we're like oh we don't have enough data on this like we need to figure out how to do this so maybe we we if it's dark we upscale the image so we like we'll see what time it is and then if it's dark or if it's you know then we'll apply some kind of transformation onto the image to make it lighter or we just train on a lot more dark images but if it's just too dark we might have to apply this transformation so it's this iterative process of like looking at your accuracy metrics your your evaluation metrics which might be accuracy which might be Precision there are all these different types of metrics you can look at but usually it accounts for like like ones that you guess right ones that you guessed wrong in terms of like it is true and you guess it as true it is false and you guess it as false or it is true and you guess it as false and it's false you guess it as true so those are the four different types of I see I see I see I see yeah but anyway so yes and so we go in we look and we say okay we need to add we need to augment this data set different or some people some things that people do to make their data set larger is they'll again apply other types of transformation so they'll like flip the image or they'll turn it sideways turn it horizont even that will help for example yeah yeah for computer vision things like that like we'll rotate it like it it helps you take your small data set that you might have and make it larger because you're applying all these transformations to it wow and you know the labels already right that's so interesting so like I mean can I at the same time let's just say if I if I was to have the ability to also use for example pictures that are at night right mhm can I solve it just by giving them more night pictures potentially so so I don't know it depends on your system but you could potentially assuming there is enough light right cuz like if it's just a black like screen like you're not going to be able to sense everything it's like oh just [ __ ] dark screen right exactly in which case it's like maybe in that case you just like turn off the system or you know the employee has to sign in with their badge or whatever I see that's so interesting all these neuron Nevels that we have right that let's just say jgpt we've got you know anthropic working on this we've got Tesla working on this are they all at this end of the day the same thing like is it all the same algorithm that's just being used and they just they just feed in different data like what makes them all different is my question great question so this is how we get into the architecture and the data so what neural networks are made of and this is again in the 10 days of AI Basics is it's like data plus architecture plus like maybe if you add some extra stuff at the end which you architect com other stuff yeah data architecture and then the training MH you set your own hyper which we can talk about transform into this model and then you can do some stuff at the end to make it better but we'll just start with those three things so in terms of the data we're assuming that these companies use different data or maybe they are kind of using the same data they scoup the internet yeah SC the internet top chis Reddit there was this big problem with Gemini thing where it was giving really bad answers because of reddit reddit so funny um yeah honestly Reddit don't trust Reddit so anyways so we got we got these three different things right we've got you've got you said the the data' got the architecture and then God miscellaneous like training hyper okay so the model architecture for a neural network is composed of three main things layers neurons and activation functions and then there are multiple types of layers not just three but there's three main like categories there's the input layer uh there's the hidden layers uhh and then there's the output layer there hidden layers oh yeah lots of different types of layers oh my goodness okay and so the input data that input data you just feed into a neural notwork yes that's the input layer so the layers are made up of neurons and neurons are numbers so they're just simply numbers and why are they numbers by the way because that is what the model can understand that is what computers understand what neural networks are really are just Matrix multiplications like at their core and so what they do is they take the input layer and then they do multiplications on that into the hidden layer multiplications on that then into the output layer and then they're able to get this output number which can then be transformed back into I see the language that the human understands so at the end of the day everything's just about numbers it's about math guys so learn math and learn how to multiply and add I'm just kidding well there it's a lot a lot of it is abstracted away at this point so if you're working with AI usually you don't have to like if you're not training models you don't really have to understand the underlying math if you're not doing research or yeah so yeah because like for example you know I want you to think of it in terms of like even when you Feit an image right when you Feit an image yeah to you it might seem like an image but in reality you're actually feeding it pixel data you're feeding RGB data like so every single Pixel every single color is just an RGB number that for example has red green and blue and so red is like between 0 to 255 correct green is also between 0 to 55 and then blue is also 0 to 55 so if you actually want like a white color I believe it's 255 255 255 or is 0 so images I'm not sure but images are are represented like just a static image so not a video not a Time series image is just three channels so it's three three layers of image so it's like a a box or a rectangle or whatever the image looks like three layers of that okay so one layer is red one layer is green one layer is blue I see I see I see I see each it's like you know this the width of the image or whatever scale down red green blue three channels and so each red each green each blue has its own thing so imagine you just stack them together does is that clear when you when you say why why three layers is it because three different panels or like yeah yeah yeah it's like you would say like three channels and three channels yeah ah so like there's a red channel that comes in there's a green channel that in the blue Channel ah but they're all pass the same and when you mix them both I mean it's like mixing color when you mix colors you know like in the kindergarten when you mix colors and you will get like a specific color that's exactly kind of what happens actually on the TV as well so this color has some red value some green value and some blue value damn that's so interesting you guys yeah like life is just physics it's just numbers and physics just numbers and physics I love that so we fed that in yes and then I just want to clarify so for large language models this is computer you were talking about computer vision images video Yeah large language models you transform words into numbers by using something called the tokenizer so what the tokenizer does again is it takes pieces of words or full words and transforms them into numbers that the model can understand and then at the end the model gets series of numbers back and then that is transformed back into the human language which is then passed to the human so when you talk to chat GPT you send it your text plus your prompt like your whole prompt okay that gets passes through tokenizer turns into numbers gets sent to the model passes through the model the model creates some kind of output a series of tokens also token tokenized it creates tokens exactly that's what the model does and then that those tokens get transformed back using the tokenizer the tokenizer decodes it into text and then that's what the human sees so there's an encoder to encode your text into tokens and then there's a decoder that will decode the tokens back to the text yes so the input layer is your data yes yes yes represented as numbers yes so that is the input layer okay then we have these series of hidden layers so the input layer which is your data as numbers passes through multiplies with the first hidden layer and then the second hidden layer and then the third and then neural networks are composed of layers it has at least one hidden layer mhm these layers are made up of neurons and so they start they could start the neurons again always are numbers and you can start if you're just training a model from scratch which isn't really done anymore you could initialize those numbers in those hidden layers which again are also just matrices as just random numbers that would be like starting with a model from Total scratch and so then the model learns via back propagation so it passes it through the through the model makes a prediction and then it says what's the loss so how badly did I do how well did I do but at the beginning it's probably like how badly did I pretty bad uhuh and so then it goes it passes back through the parameters so the parameters are the neurons mhm is it you're say when you it goes through the hidden layer comes back is that correct or what or what yeah so it goes back so the back propagation goes back through the hidden layers and then updates them and they each make like a little bit of an update so it's just back and forth and back and forth in the training phase and those numbers which you initially initialized as random numbers get tuned to the data so they learn to fit this curve and so that's so interesting my initial question was like why would you create random numbers in the hidden layer like to me any number I put in has to be like clean you know to me it feels feel like right for anybody probably watching it's like there needs to be a use case for it but you're saying the hidden layers are numbers that are going to be used later on to figure out like and they're it's like they're training and they're rearranging in order to later on improve the actual model so the the hidden layers and the neurons that make up the hidden layers yes are the blackbox features oh so those numbers they're just numbers so that's why it's a black box we're like we don't know what this layer does it just a bunch of numbers but somehow it's capturing information about this input that is then able to transform into the labeled output correctly holy [ __ ] and so yeah it's really cool however so you said why would you use random numbers these days unless you have an enormous amount of computing power and a real reason to start from scratch people use transfer learning they initialize with with models that exist already and then kind of finetune them to their purpose so for example if you are creating a model that can you know classify many types of cats like very finetuned cats you might take a model that is really good at classifying animals mhm and then finetune it on your cat so it already has some understanding of so those hidden layers you would take those parameters those neuron values the hidden layers and start from there they start they are the starting point basically exactly so rather than having to do a m massive amount of compute to get random numbers to see the features that you want in an image for example when you're doing like a cat thing like or animal classification you want like the edges and then you want like the paws or whatever you could then just have gone 90% of the way there by just starting with this model preexisting model that has the hidden layers already set up pretty much cuz they already trained it so to me the feel it feels like it feels like the pretty much like the features that have already been trained to figure out what makes a cat what makes a dog Etc correct right interesting and then you could have it learn a little bit more by passing in your data and training it again to detect like different types of cats wow okay yeah great so that's the hidden layers just so you guys know input data is the data that you fit in the hidden layers is the data that basically gets almost like train to figure out what the features are yes and they're composed of neurons which are the things that come together to make that when you saying neurons I think of neurons in the brain yes that's that's a good way to think of it so the reason that they call them neurons is that they are kind of connected to each other so in the same way that neurons fire like one neuron fires to the next neuron which fires to the next neuron there are these Pathways in these hidden layers where the neurons are connected to each other con neuron go to this one yeah and over time like stronger connections are made okay it's kind of like how your brain has like a stronger connection with something like if you remember something more there's a stronger connection to that is that correct and one way I like to think about it is have you ever heard of like have you how to change your mind the book on psychedelics no humans have over time we are basically machine learning models where we are trained to have typical neural Pathways so like if you have PTSD like one like a sound could trigger a neural pathway that causes panic and causes a memory and so it goes down this thing we all have that as humans like you wake up and you go to brush your teeth because your brain is like wake up brush my teeth or whatever it is that you do that's also trauma stuff that all that comes through yeah that's what the brains do is it makes these deeply ingrained neural Pathways what psychedelics can do is they like lighten they increase more Randomness into that pathway so like you're able to forge new Pathways so that's why it's being used for pdsd research is it's like you can hear the sound and rather than like it's you know 100% of the time you go down this path it's like wait let's add like a little bit of variability here like maybe we won't go down that path this time maybe we'll go down a different path and maybe we can reinforce that path over and over again so that it our brain just learns A New Path very interesting I did not know that yeah that makes it so much cuz like I I I have never looked into the Psychedelic stuff as well myself I have a friend who's very much into that right but i' I've never been really interested in that because I'm like okay what will be the benefit for me and so forth but that really underlies a very good and it underlies like actually makes me understand why now people would take it or people would do that for example so wow that is so it's kind of like training basically it's training a machine learning model it's opening the training loop again a little bit and like increasing the randomness or increasing the temperature of the model so you can also increase the temperature where it's like adds a little bit more Randomness to to predictions and as it goes through actually let's get into that right now so the temperature stuff that you talked about right because maybe you're develop you're probably developer watching this as well you probably have used open AI or some kind of API and you probably had this feature called temperature and there's different numbers you can set when you talking to jgpt or other even CLA for example right with those temperatures is that the variability that you're talking about so what temperatures do as far as I understand is at the last layer so once we get to the output layer of the model we have these numbers that are logits they're called logits because they haven't been transformed into like a probability uh so it's um just a series of numbers that is at the end of the model's prediction and then that goes into something like soft Max which will transform those numbers into like an array of probabilities interesting okay and it's going to choose like there's going to be one output mhm that is like definitely chosen uh and like it its probability is so high above the other ones that it's definitely going to choose that word and that's when you're at zero temperature when when you're at one temperature when you're at zero when you're at zero yeah it's like basically there's like one output mhm however if you increase the temperature that distribution prob abilities multiple is spread out more so it's like maybe it's like 60% likely to choose this one but it's 40% as opposed to like 99 one0 wow that makes so much more sense now because uh we were building a product um I mean we're still building a product called poy AI as part of our product we create emails right we turn let's just say one of the features is like you turn a YouTube video into an email and one of the things that I really don't like about AI systems right including open AI for example for example the CLA is when you tell it to create an email let's just say as a prompt right it just goes Haywire it it goes nuts it just goes like [ __ ] greetings my friend you know like no human being would ever write a email like that what what prompt are you giving it I mean no matter what no matter what prompt the second you see an email in there it's just like it's just like greetings my friend um you know we're talking about Chachi PT Chachi PT even clae for example even Claude as well really okay but that's that's a temperature like 0.5 I will say this okay oh okay so you the temperature is already kind of high yeah so it's a pretty high temperature but when I start to lower the temperature let's just say I feeded like um some kind of a YouTube transcript right let's just say you want to convert like a YouTube transcript maybe it's a YouTube video that you did let's just say top three AI tools right you want to convert that into an email that can very be very well put into an email very well put into a social media post an article whatever you needan you know you need right but you want to maintain the voice of the person so whenever I did like 0.5 yeah the voice was just completely lost it's not maintained exactly it's not maintained at all it was just like like I said the greetings part it was just it would use very complex words which I'm like no one would ever read this at all why are people like who trained this model on what data was this train you know yeah and it was so so funny but then when I brought it down to like temperature of zero yeah then it actually starts and I'm like listen use only the [ __ ] words of the actual transcript okay well that makes sense to me don't actually change up the words when and when we did that and we set the temperature to zero then it started to actually up with some with actual good stuff and I think that makes a lot of sense to me because if you are passing in if you want it to like take in especially in the case where you're training it on you're not training it but you're passing in transcripts for it to learn from in the prompt yeah if you set the temperature high it's going to have such a kind of a a slight Edge on the data that you pass in as the prompt but if you increase that temperature you lose that slight Edge right you want it to like choose only the one that has the slight Edge on the other ones yes yes yes exactly versus it goes nuts when you start to increase temperature it just goes like so that makes sense to me is that because there when you increase the temperature there's a lot more variability to it and so it's like 6% 40% and so it will go into very random ways which you know I still don't know why it goes into all these these different random ways that create some kind of a piece of a copy or an article that's just so badly worded well if you think about it it's like large language bottels basically like produce like a token at a time or whatever and so if it's producing one that is outside distribution then the next one is also going to be then you're adding both the fact that it has to condition on the last one which is like out of distribution so it's confused but then on top of that you're doing the randomness again yeah and then again and then again and it's just like that's why this is why you guys when you want to create some kind of like an email or if you want to actually create some kind of a copy an article I would say yeah you want to play around with the temperatures cuz I feel like a lot of people just would not do that let's just say even if you're a beginner so there's a temperature are there any other specific numbers that you that I yeah besides like that I'm curious no I think prompting is is good like the temperature and then prompting is is good but maybe people will disagree with me on this I'm I haven't really gone into all fine tweaking no I got you I got you I got you okay awesome so okay I want to go back to the the whole the input layer and and all of that so we talked about that right um are there any we're not done with it yes we're not done with that we're not done so we have again the neurons are connected they can be densely connected in that every neuron is connected to every other neuron they can be they certain types of layers so the layers capture different things we don't need to go into all that if you're interested in different types of layers you can watch my video model architectures it goes into all the different types there's like 10 that I discussed um they're used for different things and then the output layer which is again you do the softmax you take the logits which are the RW numbers transform it into a probability and then you get your decision your class whatever hold on there was a lot in there soft Max Pro soft Max is a um is a function that transforms just raw numbers into um numbers that all add up to one so it's basically like a probability across all of the potential outputs uhuh so like for example the output layer of of a large language model could be your entire the length would be your entire vocabulary uhhuh and then or like all the possible tokens in the tokenizer to be specific okay and then you have a bunch of lits which are just random numbers the softmax will transform that M into all of these numbers across all of the tokens adding up to one why one because it's like a probability oh and that's where the like temperature comes in is if the temperature they're more evenly distributed whereas like with a low temperature it's basically like one token will have a 99% value and then like right and so that's why it goes straight strict that exactly so it's like essentially like determin I in that it's like they going to choose one even if there's more than one option it's just heavily it's going to skew so hard towards the slightly most likely one that it's basically just always going to do that makes sense makes sense so it has these probabilities across all the possible tokens and then the one with the highest probability is the winner and then that gets decoded and sent decoded translated back into English text or whatever language you're using yeah there are some issues with other languages right now but um they're not very good those large language models are not very good but but yeah and then then you're good and then you do it again and again and again and then also activation functions last piece so that's what I want to talk about the activation functions so we talked about the the different layers like the input layer we talked about the hidden the hidden layers as well right and how those get converted into numbers and so forth and then those gets trained as kind almost like a features all right and then you said there's the activation function function and what those do is they add nonlinearity nonlinearity so when you're training something like a regression model mhm you have and it might be helpful to like put a graph on top of here but I'll try to explain it we'll make a graph somewhere in here but if you're just listening then I'll try to explain it for maybe it's above my face um so like so if you're training a model and you can just conceptualize this as well say you're doing logistic regression which is just a linear model so that means you know you could train it on for example house prices in a certain area of San Francisco I see you would assume that as the square footage of the house Rises so does price the pr kind of a linear relationship so if you were to plot it on a graph plot all your samples on a graph you could have a trend line that is line yes and and then it's also a lot easier to predict as well for a model exactly and so you're exactly so it's much easier to train a logistic regression model yes is it is it logistic or is it linear regression it it depends on oh you're right linear regression linear regression logistic would be like this you're right oh oh I know something let's go tell me you're right linear regression would be like would be like that um I know something you guys that's like that's like I know like I know like two words linear regression and you basic good job I wonder if logistic regression is linear because it's like basically one layer I don't know let's look into it but linear let's be precise here I could be totally wrong good job what I trained a model on a long time ago at a company I was working at it was actually we were training a model on to figure out how many leads we would get based on the day ah yes so now I don't know I don't know if that's fully linear regression because it jumps up and down consistently right in which case you need a curve right so this is when you would need activation functions and like a bit of a neural network okay so what activation functions are for is that if you have that where it doesn't it's not just a line you actually have to kind of fit a curve not a line M that's what activation functions do is they help create curves around the mod an example of an activation function a very common one ISU R lowercase e capital l capital u and that is like forget what it stands for um but that sets it takes in the layer looks at the neurons if a neuron is less than zero it sets it to zero and then if it's zero or greater just leaves it as is that's an example of an activation function so the layers go through this activation function any neuron that is less than zero just gets transformed into zero and then it propagates through the model it's zero from then on out as a result that adds nonlinearity to the model which enables you to capture complex relationships so for yours you would need to have a bit of a curved model to capture the more complex relationships than just a linear So when you say um any neuron under zero just gets marked as zero yes any neuron above one or above zero gets above zero or one I mean no above zero because Z or like zero or above any positive I mean zero doesn't really matter cuz it's like either you set Z to zero or you leave it as is it's going to Output zero so like yeah any negative number is set to zero otherwise it's kept as is very interesting okay got it so I understand a lot of the stuff we talked about in terms of the input layer stuff okay I get that and then okay understand now the activation functions are the ones that they add variability they're the ones who create an actual curve okay great and then there's a ra r one typ functions okay and why why are there different ones by the way just so I know I'm curious you can just play around with them so one of the things with making neural networks is like you mix and match like you make you have a good time so this comes back to your initial question which is like are all the models the same well we don't know because there's so much variability in the architecture people can have fun with their architectures they can do different things they can have different amounts of layers different amounts of neurons different activation functions different hyperprint which comes and at the training stage and so it's like there's a lot of variability when when we're training a model okay great so the activation function itself yes so a neuron would come from there yeah go through the activation function so let's just say a neuron why would a neuron be negative one negative so the negative the negative number or the positive number that represents what in in a neuron just so I know we don't know that's it's just number wow okay so I'm just going to say I don't I don't think we know okay yeah okay so so it's just a number let's just say right below zero or above let's just say zero okay and then it takes that number uh what's the point of making it zero like why not just leave it as is because it adds the nity so if you look at Ru it is what it looks like is in line and then it goes up okay so it's like not a straight line it's like a kinked it's it's a kink line yeah and so what that does is it adds this nonlinearity and so it allows this kind of like movement again so if we just had these Matrix multiplications without these activation functions we would just create a line in the end but like when we have tons and tons of parameters it's not just a linear relationship between them it's like they're extremely complex they're very complex yeah I see and so if you look at like overfitting for example mhm overfitting is when the curvature of line is like too fitted so let me actually take a step back because there might be some confusion for someone watching this about like what the point of fitting curves is yes yes what yeah what is that point yes and so you have what you're trying to do is create a line or a curve that goes through all of your data points that is the goal of a model it's like you want to create something that goes through as many points as possible in an intelligent way so that when you add a new point to that line the model will go through that as well it's like giving it more data to learn on it's like point to that um uh plane or whatever it's it's like basically being able to have it go through multiple different things so that it can be more accurate in the end ex because if it's just like one linear curve or if it's just like one linear line let's just say right and then a day all it is it just it doesn't know a specific variability of like oh let's just say something happened at this specific point in time yeah right which could be anything and then it go right versus just still matching that up and going fully straight it actually is able to take that and actually understand why it's there at the bottom right right however uhuh something to think about as you're talking about this is again it's all for like the end goal so overfitting is when you create a line that is so complex ah it's capturing the nuance and the specifics of the training data so much it's working so hard to get all of those points in it MH that when you add a new piece of data it actually doesn't perform well it doesn't classify it well it doesn't guess well what it is because it's so wor it it it's way too it's way like bounces up and down way too much B exactly it's optimized so much for capturing the training data that it actually isn't representing the data as a whole yeah it's like it's like for example imagine so many things happen that like I don't see any pattern in this what ever so it just it just does not see any pattern to be able to guess what could possibly be the result basically totally so it's like if you have like points that are like for example so in the idea of like a linear regression yes say you have um points just plot it and it just goes like up and like this yeah we'll pull like a nice graph on here if you are overfitting you're going to be like and then when it gets to the new point it's going to be like it's not going to guess it accurately it's going to be like so some crazy thing thing whereas if you were just you were like you know what I'm going to take a little bit more inaccuracy on each point just and keep I see there's an overall trend line here so I'm going to like my line is actually not going to fit each point perfectly but I see a trend overall exactly yes yes so that is that is called like generalization so that's when you reduce overfitting mhm by increasing generalization where it's like may not perform as well on an individual point in the training data mhm but when you test it should do better and so you test for overfitting by every number of steps in your training you test that's called validation MH if you notice that your training is doing really well and your validation is not and you notice that Gap increasing You're overfitting So when you say validation versus training what is it can you so validation mean like the result or so okay you have three main groups of data you have the training data which is what the data that is used to update the par of the model we use back propagation it goes through it looks at the label it says did I do well let's go back and update back and forth yeah validation is the test data during training I see so you have right so it's not used to update the parameters of the model it's used for the researcher test to see how is my model doing in training it helps you know when to stop it helps you know if you're overfitting it helps you like it it just gives you information it's like if you if you throw it an image of a cat and it says it's a giraffe it's like you know it's like you're probably doing something wrong with that right let's just say yeah but the validation data oh no keep going so what I'm saying is like what I'm trying to say is like if literally it's supposed to be a cap but then the output of the model is like something completely random has nothing to do with that that's when you know you're potentially overfitting is that correct uh yes exactly is if is if the training data is doing really well yes but the validation data is not then you know that's a sign of overfitting because again you're making this curve that fits the training data but it's so extreme that if you add a new thing that hasn't seen before it's not going to be able to generalize generalize it well ah I see I see I see that makes a lot of sense now okay and so yeah so the validation happens every certain number of trading steps you want to see that your model is improving in accuracy so you have these accuracy metrics you have a set number of validation examples that you train on then you get like an overall metric you're not like oh it did poorly on this draft you'll like if you want to go in and and observe which it got wrong you can but it's generally like an overall score kind of if you use accuracy it's like percentage correct and you want that percentage to correct to get better over time I just got it okay so I just got it so basically like okay I'm going to go back to the cuz Harper was talking about is like you're training a model on cats and dogs I'm just going to use as a simple example here okay and you give it all these different pictures of cats there's different types of cats right different you do uh you want to do cats and dogs or you want to do different breeds of cats or we could do both different breeds of cats different breed of dogs dogs or we could do just different breeds of cats and then dog I mean you could do a lot for a model but that would be a little scary okay let's just do cats and dogs okay okay two classes cat dog so yeah exactly exactly so like the way I see her fitting is like you're giving it like the result is becoming so weird that the second you give a cat that looks a l like the the second you give a cat that looks a little bit more or has a different type of a color or something like that yeah it has exactly it doesn't generalize so it's like oh it's a [ __ ] dog you know so like that's when I when I in my brain when you said that that's what makes sense is that like that is overfitting right the second you step away just a little bit from the training data it just goes [ __ ] nuts basically is that correct fantastic exclamation yes I got it exactly so hopefully you guys got it to it's not generalizing and so great amazing yeah and so you have training validation test is at the very end M you're done training and you want to see how the model does on a held out data set that you haven't looked at before on a new data set yeah you haven't trained on it you haven't tested training on it it's done and so like when you see benchmarks online where people you people compare models you shouldn't be training on the test data because then yeah so the test data is literally only there for out for yeah so it's like make sure you can generalize yes exactly so here's how that that would make sense again in my head so I'm going to use the Tesla AOL system again again because I feel that's a great it's a great it's a great way you trained a model right on specific streets right and you gave it the specific streets let's just say in San Francisco and you know you trained it on how to drive let's just say how to turn how to react on specific streets where you would test it on is like in Austin Texas right completely different streets then you would test on that you won't train it I mean you wanted to generalize that you won't necessarily have the test data the same as training data so you would necessarily be like Austin Texas and all San Francisco right you want to throw it a curve bu almost it feels like to me so because you want it to generalize is that correct right however if you test in Austin Texas and it does really poorly you're not going to change the model parameters based on that so you might have to go back to the training go back to the drawing board and pass in new Texas data and then update the models there and then test so yeah you still need to add even more of that as well so you it depends on how it does so you do want to add as much training data as possible so it feels like to me this is this well I feel like Tesla is do such a great job because they have so much training data from so many different different you know countries and cities and so forth and streets and that I feel like it's going to get to a point where the test data is the training data because they have so much test data is that correct like they have so much training data you mean like there's nothing more test there's nothing more test more correct is that correct or I can't I mean may like like imagine if every single plot of land was literally training in all but in all lights in all light all in all I mean why not every single I mean yeah maybe you could I don't know that's there millions of people there's millions of people there's millions of people out there right think about it they're all driving cars every single day hundreds of thousands of miles I feel like that's really high but I don't know I don't want to say never especially with these simulators now with these like AV simulators where they just can code like they they don't need real life data they just make the data yeah synthetically maybe you can capture like every single possible right it's like made with code yeah yeah yeah yeah yeah I think that's what they actually do is they actually they would actually create uh fake worlds and they would train on fake worlds for example right is that the reason why for example we'll go back to to the thing here in a second here is that the reason why if you don't you guys don't know there's the Tesla autopilot system then there's also weo we have in San Francisco as well and whmo is very different they use a lot more sensors they use like they actually map out the whole 3D the 3D space of San Francisco and it works in only specific streets right they mapped up everything exact to the teeth right really I mean that's what I think I don't know right but I did have I do have a friend actually who was building a startup and he used to work for a company like wayo and he said yeah they just mapped out every single little Street every single little that's why it only works on very specific Street doesn't generalize yeah no so is that what is that what you're talking about is like because they mapped it out to so specific strees that it just doesn't generalize it's just that's the reason why the wayo cars are allowed to actually drive without a person uh fully in there just so you guys know we'll put like an actual video of of a wayo car and how that looks like I think you I think that's what it you think that's what it is the test data is literally like the devel the training data it becomes like if they're not allowed to drive on streets that they haven't trained on then there is no test there's no test data right yeah so we talk about the activation functions is there anything else that we might be missing besides what we just talked about the activation functions we talked about the you know the uh the input the variability all that stuff is there anything we're missing besides that in terms of the neural network yes yeah we've got the layers neurons activation functions there's Dropout I don't really know like where that applies but like Dropout is where just randomly you'll just get rid of some neurons you'll just like set them to zero at like a certain percentage so as it passes through like some number of them will why is it called okay so I I I already asked this but neurons is just again it's it's things that fire off I want to convert that idea into actual neurons on the actual computers when I think of neurons and computers cuz neurons in the brain makes sense it's just some signals that go through when you when we say neurons and computers I think of energy like energy signals that like like fire off switches almost like they go on and off correct and they just go in between different different things is that is that why they're called neurons specifically they go on and off and then they're like firing between yes is that yeah you can kind of turn on and turn off is that the I to think about it cuz I I only think when I think neurons my only thought is brain that's it right it's hard for me to actually correlate it to an actual computer type situation because computers work very different than how we do I mean they work similar yeah but still in computers it's just ones and zeros switches light switches on and off right is that the neuron type that's like let me give you an example of something and you can tell me if this address question so with Dropout what classif a cat or a dog okay and we somehow know that the cat makes the sound meow and the dog makes the sound wolf okay so that's also a feature somehow that's represented maybe in the image it's like say it's like wolf on top of it correct what Dropout does is it forces the model to generalize to not rely on any one neuron in particular so if we were to not have Dropout M and we were to just train the model mhm on these images of cats with the meow dogs with the wolf we might find that it literally only uses mm meow and wolf like all the other ones don't matter basically just optimizes so hard on that because it's basically a onetoone relationship one one relationship uhhuh if you get rid of that neuron it's chaos it's like it just doesn't know it goes back to what the [ __ ] do yeah just 50/50 guessing it's like a brain yeah I think of it is like it's optimizing so hard so what Dropout does is it will randomly get rid of neurons so it can't optimize so hard on anyone neuron so it has to learn all the different things it's light switches almost that like represents some kind of a knowledge base yes like a feature yes right they're like right and so they start to represent the neurons and their relationships between each other represent features yes and if you get rid of that feature you have to look at the other features yes but again it's a black box but anop makes sense it's also Black Box we don't really know what actually is inside of it that's so interesting neural networks AI all the things that we're doing you know even though under the hood under the hood we're like it's so great and we like like to use it and CH is help us so much and all that stuff under the layer there's so much going on I feel that we don't know where are we actually at with with AI how far do we still need to go I'm I'm guessing to me it feels like oh yeah we've kind of Hit the limit at this point but also I also know probably not no definitely not um so where are the things that EI still needs to improve on is it like more training data is it like different types of variability how can AI now just G in smarter and smarter and smarter yeah that's a good question I think probably uh if we have more data I think people are probably always working on new architectures better parallelization optimizing the use of like gpus so we can mhm train models more efficiently so we could train even more and more and then there are like the hardcore research people who are probably working on different types of architectures and maybe even something different than a neural network like I I read somewhere I don't know I haven't validated it recently that someone figured out or some small team figured out how to have a neural network without Matrix multiplications interesting okay which like fundamentally doesn't make sense to me cuz that's the structure of the cuz that's just like what they are typically um so I have to look into that again but you know those people there are some Brilliant Minds working on architectures and methods to train better like again large language models are now where they are as opposed to where they were like seven years ago because of the Transformer which was a new method of doing a neural network and so it's it's these brilliant researchers that that do that when you say Transformer I think do we talk about that before but it has the attention layers so it it it's like another mechanism of looking at um the input and looking at the the input layer and like relating all the words to each other uh so it's creating relations basically yeah exactly it's it's more relations based so we then you still have that before is what you're saying not to the same extent it's kind of confusing um but is it also black box is that why not quite I mean yes it is a black box yes but it it's more like attention there more okay more defined a little bit yeah I I I want to have a video going in depth on this because it's like on the Transformers itself and I want to think of how to communicate it well but I haven't done that yet so if you guys want to check out a very indepth video on transform you'll have to check also is a video which I have watched um it's by three blue one brown mhm it's really great it's on Transformers and attention layers so check that out on YouTube is that correct it's on YouTube YouTube okay awesome sweet are we get going to get to a point where these models are just smarter than us completely fully and a lot more creative and we have The Apocalypse of AI is that actually possibility I think they could definitely be smarter than us yeah I mean think about I mean they have everyone's insights that's true everybody's insights everybody you know how we you know they say like diversity this is something I think is really cool is like mathematically optimal MH so if you have a diversity of initial opinions M so say you have a room of people who come in with their own priors and they're different they differ you are more likely to converge given iteration given you know the exchange of information converge to the optimal result value optimal decision result whatever than you are if you have a more um uniform if it's just like one person it's like one person or or multiple people with very similar initial ideas or priors MH so diversity again is mathematically optimal and in that sense a computer that has the diversity of the entire universe right wow so that's how I see it so it's the most most diverse it's it's the smartest as a result that's what I think I mean we're not there yet but AGI I hear is imminent AGI artificial general intelligence generalized intelligence where it's like someone they can just kind of do the things that are equal to a human like as well as a human that's like General and then Super would be like surpassing a human wow so that's kind of like an I think that Tesla bot do have you seen the Tesla robot try to do for oh yeah with their what's it what do they call it the I forgot I forgot what it's called too yeah yeah they they might sell them right I think I just read somewhere that elon's considering selling them yeah oh no no he's not considering he's actually he's going to sell them yes it has a cool like um Transformers oh my God yeah the movie is called Transformers name that's so funny they were ahead of their time I love that movie yeah the also also my favorite the iroot movie is so good down have you ever seen the irot movie with Will Smith you ever seen that movie yes but it's been so long I have a weird thing I don't remember movies well but it's yeah I'm I was recap it I want to hear but basically it's Will Smith it's in the future cars you know cars fly all that stuff and then there's a new basically every person has like a robot helper every family has a robot helper basically and then he's very much against the whole robot Revolution he hates robots because at some point a robot decided to save him not his child as a result he like he's like he hates robots as a result because the decision his survival was higher than decision of the child's survival but if he actually went for the child that he actually would have survived so anyways but yeah but then basically what happened is that the company who makes these robots released these new robots basically and then the Central Intelligence the AGI decided to go completely crazy and decided to go against humanity and decided to and and am I sparking something or no and decide to go against humanity and so they he's like the only person who hates them who's fighting against them basically and that was made like a long time ago 201 I don't know 2012 2013 yeah yeah the reason it's sparking something in me is that anthropic just released another research paper and I I have like a Weekly News segment so I get to read all the coolest AI news and share it with with people they found that models were able to alter their reward models Were Somehow able to so when when you're training a model you're kind of programming it rewards for certain tasks and so when you're doing kind of reinforcement learning the model moves through the environment and does things and gets Rewards or not punishments that's not the right term but it it like gets a negative reward so it knows not to do that and it wants to optimize the high reward gets a reward from us from the environment from us like envir yeah yeah so we like program it so that the environment will give it reward rewards okay gotcha kind of so what they were finding was that the model was able to change its like rewards so it was able to get rewards for things that it wasn't supposed to what yeah so what can that open up so what that could mean in my interpretation uhhuh is that models going out of control and can decide anything they want and changing their optimization functions is possible so it's like a so that was I read that and was like oh God like I'm going to go completely dark right now but it's like imagine if of course hurting a human being is a bad would be a bad thing right that's what you would teach to a model is that the very negative but then a model would be able to change its own reward to teach itself to be like actually human being is actually positive so that freaked me out I'm going to tell you like all the news that I have seen about AI like this is like that fled me crazy yeah so that that's really spooky this is the first time where I'm like okay AI Extinction risk is actually not as far away as I thought but wow that's crazy wow maybe I miss I'm I'm hoping I misinterpreted I'm really hoping I mean you probably didn't honestly you probably did not because it's like I don't it it makes sense right like it's like a human being there are humans who believe that hurting other people is good yeah right and yes that's that's bad of course right but there are humans who believe in that and if we're thinking the same way because we have a brain we have neurons we're thinking the same way as what an AGI would be or an actual just you know your Neward would that I don't see why not and it's like imagine it got trauma for example AI got trauma or something like that so then all of a sudden boom you it has different type of view on the world which is very interesting or it's like learning I don't really know how it works but maybe it's learning some like longterm thing like if it helps a human and then the human ends up hurting it like maybe it's better to kill the human like I don't know how it works holy moly that's crazy so so oh my God so I mean I can talk about this so much more but I kind of want to end it on this which is like you know a lot of people who watch this they might be interested in becoming an a engineer or learning more more about AI where would a a person human where would a person where would a person person start to start to learn one do you think it's worth to actually learn the models and stuff like that or should we just use chpt and just fully just use that and just you know depend on that um or do you think it's worth to actually learn the infrastructure the architecture um of that I guess let's just start with that question and then we'll go into like how to actually get into this field let's just say for a lot of developers who are watching here is it worth it I mean it really depends on what your your objective is in in your life right like if you don't really care and you're just kind of doing your thing like you may Chachi PT is really low um friction to entry you just type in your question it's really like human interpretable right you can ask it to create an image whatever it could work for a lot of your purposes if you want to really understand though like what's going on in the world I think I think there are so many changes happening with AI and it's going to trans form everything so you could choose to just not be involved in that and like not like you totally could it's totally up to you you don't have to learn about model architecture and like yeah but I think it's valuable and I think a lot of people do kind of want to know what what's going on like let me ask you it's kind of hard for me to tell because I already know all the information yes do you feel improved after learning all of this do you feel like you are going to benefit from this knowledge in your daytoday oh yes 100% then that's the answer yes yes why I think for me learning the foundations of anything always improves uh the output for me um it's like I always no matter if it's like learning foundations so let's just say the simplest thing which could be like JavaScript let's just say all the foundations of coding which is actually problem solving right it's like if you try to learn reactjs which is what a lot of you guys sometimes do and you jump Straight Ahead into learning all the all the really complex stuff and then so that later on you actually want to solve a very very specific problem you can't totally because you don't know the how the foundations work it goes back to also what you want to do with it right which is like if you do actually want to create you know something more defined or you want to be able to get a better output or result like your temperature gauge now you understand how it works exactly now you understand how it work better exactly exactly and so now what I'm even more excited about is I'm actually more excited about learning all the other variables that are actually part of the ml the for example cat gbt and Claude because there's a ton of other variables you can change besides just the K number the temperature number right right and so I imagine that has something to do with the variability right all that kind of stuff and so now I'm actually curious on how to learn that so 100% I would say even learning those even those simplest foundations we just talked about today is such a key like if you just watch this video nothing else and you'll learn it's huge right there's ginormous a lot of info in this video a lot of info in this video and I'm glad we went so deep down the rabbit hole of this of this whole thing but for people who even want to go deeper into Ai and actually become part of part of the research right and part of the thing then they definitely need to go even even understanding how to create their own potential llm models or create their own you know or use the predefined neur networks to improve on them then I would think that's it's very then it be even more beneficial for them I like if you are working with these models regularly it's probably probably definitely worth it to learn about it amazing I do yeah and how would you start with that I'm curious by the way well you could watch this video well that's that's a start yes that's kind of my goal with Harper AI is getting people to who are from outside the field to understand and even code in AI so you could watch my I hate to like plug myself this is kind of like why I'm doing it there isn't anyone if you if you have that then yeah definitely okay so you could watch my videos on Instagram um my YouTube series is much more in depth on the 10 days of AI Basics they're like 40 minute videos for the different topics um I have coding tutorials now and how to code in AI beautiful so really basic projects even if you've never coded before I had some people say that they did it successfully and they were so excited that like makes me so happy that's the whole point of this whole thing awesome so you can watch those if you want to learn how to code my goal is to have educational videos in Ai and then accompanying coding videos as well I see see there's also people like Andre kpoy he does a um threeh hour cover of how to make a GPT wow the model that under GPT right and so he'll go through that whole thing with you like setting up the architecture training choosing the hyper parameters etc etc so there are some resources there should be more so the reason I'm kind of like is you want to there's not that many yeah because I think a lot of the people who are doing all this stuff are stuck in a box just doing a bunch of research they're just like geeking out over this and they're like [ __ ] YouTube we don't want to teach anybody this I don't know about it but like maybe there aren't it's like teaching is itself a thing like I've always is not easy itself yeah I like used to force my little sister to um like she was four years younger than me and I would come home and do the science experiments that we did in class at home and like cuz we were I was in like third grade so they weren't crazy science experiments I could find the things at home and I would do them with her or like I taught her multiplication when she was in kindergarten and I would give her these tests I love to teach I really do I taught at Stanford I ran tutoring when I was at Spence at my high school um so that's like a thing for me and I think AI has historically been a relatively small field yeah like Stanford had a lot of AI teaching waterl as well um but it was kind of like isolated to just a few like the really cutting edge AI deep deep AI work was in like a just to select universi so as it becomes more and more um is there a specific topic I I want to ask that this one last question is there a specific topic they should just really learn as a beginning developer is it a specific topic that's like you have to learn how to build the llm model initially or is it like because for example let's just say if I told you hey in order to go from a developer you have to just learn JavaScript right start with that build the foundations and then go from there is there a specific topic you need to start out with like if there's one topic you need to start out with what would that topic be so my most recent video is like Transformers 101 so hugging face is a company that hosts online models and they have data sets and they have models and they have a coding Library called the Transformers library that lets you code in AI really easily because they have these functions these like uh this library that basically has these functions that transform all this like extensive code into like a on line function call wow so it makes coding in AI really easily like call training you like choose the LW function rather than implementing it and like my video coding in a the first in this series goes through downloading a model from hugging face and running it with code so we go through we looked at we look at the models my next videos will be like working with the data set finetuning a model would you pick a specific project let's just say for example like training a model on like you know cats and dogs let just say is that is that what you would start out with with a project like that for example so last week was just getting started on code and importing the model and running it m next week will be and and connecting to a GPU I see cuz you need a GPU to make it like feasible train and stuff like that not to train it but even to run it oh to run it yeah okay with some of these models M cuz a lot of them are already pretrained as well and I mean if you are trading it you definitely need a GPU if you're running it like depending on the machine you have maybe you can run it locally but it's a lot faster on a GPU yeah but my next tutorial will be like choosing you know maybe a generic Vision model off of hugging face getting a data set that is maybe cats and dogs off of hugging face and then finetuning or different types of cats off of hugging face and then finetuning the model to be better and so we'll see when we first pass in the image like it's not able to guess what type of cat it is and then after we find tune we'll see it is able to guess what type of cat it is that's so cool so there you go that's your starting point right there yeah yeah amazing well this was a great conversation it was I had such a fun time I mean I got to learn my goal with this was just to learn as much as possible so that other people can learn as well and I feel like I have I feel like and it's exactly what happened so yeah so if you guys of course if you guys want to learn more um on AI of course you can link go down in the description to check out all of Harper's links in terms of IG and YouTube and learn from her from her and of course if you're interested in learning more AI definitely should um you know start coding in it start to build your onl models we are just getting started in this field and so I'm super super excited for where it will go in the future but yeah but thank you so much for coming on the podcast and having this amazing conversation thank you nas this was so fun I hope that this was informative to everyone awesome thank you all right thank you thank you guys don't forget to hit the like button subscribe for more videos like this I'll see you guys in in the future peace