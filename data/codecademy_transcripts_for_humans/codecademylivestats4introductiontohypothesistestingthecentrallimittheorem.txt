With timestamps:

00:00 - if not already
00:06 - possibly now
00:16 - all right i think we're live something
00:20 - happened
00:20 - on my screen welcome everyone
00:24 - uh we're just gonna wait uh a minute or
00:27 - two
00:27 - to make sure that we are fully live
00:31 - um jamie and i are going to be talking
00:34 - about the central limit theorem today
00:36 - and i'm very very excited uh thank you
00:39 - for letting us know in the chat that you
00:40 - can see us
00:41 - um so i am very excited for this
00:46 - uh anyway we are i think
00:49 - as usual streaming on a couple of
00:50 - different services but just as a
00:52 - reminder
00:53 - um we're gonna be keeping an eye on the
00:55 - chat in
00:56 - uh youtube so if you are on facebook or
01:00 - twitch
01:00 - or one of the other platforms that we
01:02 - are streaming on if you would like to
01:05 - code along with us and ask us questions
01:07 - or say hello
01:08 - um you can go to the youtube uh
01:12 - streaming and let us know that you are
01:16 - here by saying hello in the chat
01:18 - um cool
01:22 - uh so i guess we can get
01:26 - started today so i will share my screen
01:30 - today's lesson is gonna be
01:34 - heavy on the theory uh and
01:38 - there's we're definitely going to be
01:39 - doing some coding like we need some
01:41 - coding to get
01:42 - a sense of the theory but
01:45 - the focus is going to be on
01:47 - understanding
01:48 - some pretty deep theoretical concepts
01:52 - which i find super fun
01:55 - um but i think it can also be a little
01:57 - bit intimidating sometimes
01:59 - so um i really want to encourage
02:03 - everyone to ask questions if anything
02:07 - comes up that you are confused about
02:11 - um i really really welcome questions
02:15 - because
02:16 - it will help me keep track of
02:20 - what is making sense to people and
02:22 - what's not and we can
02:23 - slow down at any point and kind of recap
02:26 - things
02:26 - if um if anything is is confusing
02:30 - so uh again as per usual
02:34 - we're using some code that's available
02:36 - on
02:37 - our github for this streaming series if
02:40 - you want to
02:41 - download that code ahead of time you're
02:43 - welcome to
02:44 - there's also like a little simulated
02:46 - data set in here
02:48 - for this week's um this week's materials
02:50 - so
02:51 - you can find that if if you go to
02:55 - the github page and hopefully that is
02:57 - linked in
02:58 - youtube and other streaming services
03:01 - um cool i'm to open up starting cook
03:07 - okay so to get started
03:10 - um the first thing i want to prepare
03:13 - everyone for
03:14 - is i'm going to ask us to take on a
03:17 - couple of different
03:18 - personas during this lesson so we're
03:20 - gonna switch back and forth
03:22 - from the researcher perspective so
03:26 - that's somebody who is trying to conduct
03:30 - some research trying to analyze
03:32 - some data we're going to switch between
03:34 - that and
03:35 - the all-powerful perspective so
03:38 - we get in this lesson to be
03:42 - like gods or goddesses whatever you want
03:46 - to call it
03:47 - if you're if uh or all powerful in some
03:50 - way we get to like
03:51 - see things that the researcher would not
03:54 - get to see
03:55 - um and kind of imagine imagine both
03:58 - perspectives if we had all the knowledge
04:00 - that we could possibly have and if we
04:02 - only had the knowledge that a researcher
04:04 - had
04:05 - um the other thing i want to kind of set
04:08 - up here
04:09 - is up to this point we have been
04:12 - talking through uh summary statistics
04:16 - just basic descriptive statistics we
04:19 - looked at some data visualizations as
04:21 - well
04:22 - and um a lot of so
04:25 - that content is really useful for
04:28 - a lot of different types of research
04:30 - that you might want to do but
04:32 - i want to kind of separate what we're
04:34 - doing today
04:35 - uh from that a little bit and say so
04:39 - you could kind of imagine two different
04:42 - types of
04:42 - questions that you want to answer um
04:46 - on the one side you could imagine that
04:48 - let's say
04:49 - you work at a company like codecademy
04:51 - there's
04:52 - i think like 150 employees at this point
04:56 - and let's say you um you want to
04:58 - understand something about
05:00 - salary and demographic characteristics
05:03 - among employees and you have the data
05:05 - for every single person
05:07 - that works at the company that you're
05:09 - that you care about then
05:10 - you can just use descriptive statistics
05:12 - because the thing that you care about
05:14 - you have all of the data for but there
05:17 - are a lot of situations
05:19 - where you cannot for some reason
05:22 - collect all of the data that you need to
05:24 - answer the question that you want
05:25 - to answer and that could be for a
05:28 - variety of reasons it could be just
05:30 - because
05:31 - the population that you care about is
05:33 - really large
05:34 - like you want to understand trends
05:37 - between
05:38 - salary and demographics for all u.s
05:41 - adults and you can't you just cannot get
05:44 - that information for all u.s adults
05:46 - um that could be one situation another
05:49 - situation
05:49 - a lot of times in like marketing is that
05:52 - you can imagine
05:53 - you have a new feature for your product
05:56 - and you want to test it out and see if
05:58 - or let's say like it's a different color
06:00 - subscribe button and you want to see if
06:02 - more people press the green subscribe
06:05 - button
06:06 - compared to the red subscribe button
06:09 - and uh you want to know
06:13 - whether more people like all the future
06:15 - visitors to your website you want to
06:17 - know what
06:18 - all those people would do but
06:21 - you can't see all the future people that
06:24 - will ever access your website and in
06:26 - fact
06:27 - even among the people that you do sample
06:29 - you can't
06:30 - ever see what somebody would have done
06:33 - in another situation so if you show
06:35 - someone a green button
06:36 - you can't see what they would have done
06:38 - if they saw a red button
06:39 - so that's another form of missing data
06:42 - you just can't see
06:43 - you know ideally you'd like to show
06:45 - every person that could possibly visit
06:47 - your website the red button
06:49 - erase their memory and then do the same
06:51 - thing with the green button
06:52 - and like see all of those things and
06:54 - then look at the data but you can't
06:56 - always do that so in that case you need
06:59 - some
06:59 - other tools in order to understand
07:03 - something about a population about all
07:05 - the people that might visit the website
07:06 - or feel confident about it
07:08 - having only collected a smaller amount
07:09 - of data okay
07:11 - i've now i always do this i ramble a
07:14 - little too much at the beginning of
07:15 - these i hope i didn't lose too many
07:16 - people yet but hopefully that sets up
07:18 - kind of the motivation for what we're
07:20 - doing
07:22 - so um what i have here
07:25 - is a um a jupiter notebook i'm just
07:29 - gonna load a bunch of packages
07:31 - i i just copy this over every time i
07:34 - start a new project because
07:36 - i may not use all the packages but at
07:39 - least i have all of them
07:40 - imported um and i can import more if i
07:43 - need
07:44 - this uh hourly pay text file
07:47 - is um it's just essentially an array of
07:52 - numbers
07:53 - uh and this was simulated but what it's
07:56 - meant to represent is
07:59 - salaries in u.s dollars for
08:03 - theoretically all adult
08:06 - americans um
08:10 - it's like it's it's fake data but it's
08:13 - based off of census data so it's
08:14 - somewhat
08:16 - similar to what this would look like in
08:18 - real life um
08:19 - so i'm gonna go ahead and really quickly
08:23 - plot a histogram of this so we can take
08:25 - a look at it
08:27 - uh let's do like
08:31 - 100 bins and
08:38 - yes maybe 100 was too many let's do 50.
08:43 - um okay so it looks something like this
08:47 - uh which we probably expect you know
08:50 - there's this
08:51 - there's a spike at kind of a low salary
08:54 - seems like most people are kind of oh
08:57 - and this is an
08:58 - hourly pay or hourly salary um
09:01 - so looks like most people are kind of
09:04 - under 20
09:05 - an hour there are some people between 20
09:08 - and 40
09:09 - and then it kind of drops off from there
09:12 - there's some from 40 to 60 and then like
09:14 - very few but still some people all the
09:16 - way up to
09:17 - 140 an hour in this chart
09:21 - and you can see over here this is like a
09:24 - a pretty big scale
09:25 - each of these bars um
09:29 - this axis represents frequencies so we
09:32 - have like frequencies
09:33 - and some for some of these bars of over
09:35 - three hundred thousand
09:37 - um cool so
09:41 - this gives us a little bit of a sense
09:43 - right now we're in
09:45 - all powerful modes so we're gonna
09:48 - pretend
09:49 - um in this in today's lesson we're gonna
09:52 - pretend
09:53 - that we're a researcher that's
09:55 - interested in
09:56 - figuring out what the average salary for
09:59 - all us adults is
10:00 - and then as the all-powerful being
10:04 - we can see data for
10:07 - salary information for all u.s adults so
10:10 - those are the two
10:11 - uh the two perspectives will shift
10:15 - between
10:16 - so right now we're all powerful we can
10:17 - see this histogram
10:19 - um and we can actually calculate the
10:21 - mean uh salary so i'll do that
10:24 - so if i do i mean
10:27 - hourly pay uh
10:32 - and actually i'll save this as mean
10:35 - salary and
10:38 - print it
10:42 - is this also big enough for everyone i
10:45 - realize
10:47 - click zoom in and i can print the mean
10:50 - salary
10:54 - okay so it's about 18
10:57 - and 84 cents cool
11:02 - okay so we've taken a minute
11:05 - we're all powerful we know the answer to
11:08 - the question
11:09 - that our researcher is going to try to
11:11 - answer we know that
11:13 - the average salary for all american
11:16 - adults
11:17 - based off of this i don't know if this
11:18 - is exactly what it is um i think this
11:20 - data
11:21 - that i based this off of was from like
11:23 - 2013 or something so
11:24 - it might be outdated but it's
11:26 - approximately eighteen dollars and
11:27 - eighty-four cents
11:28 - we're going to pretend that that's the
11:30 - truth that our researcher can't
11:32 - know now we're gonna for a minute
11:36 - imagine that we are a researcher
11:39 - so um as this researcher
11:44 - we are going to try to answer our
11:46 - question what's the mean salary of u.s
11:48 - adults and we're going to
11:49 - do that by finding a sample of of u.s
11:53 - adults
11:53 - and calculating their mean salary
11:56 - because that's all we can do right we
11:57 - can
11:58 - find and by sample i mean like some
12:01 - subset
12:02 - of this original um
12:05 - of this original set of numbers right
12:07 - some subset of all the people that we
12:09 - actually
12:10 - care about cool
12:13 - so um i'm gonna actually
12:16 - hold on i'm gonna open up the final code
12:18 - and pull this over
12:20 - so that i can also see it uh because
12:24 - i just want to make sure okay
12:28 - cool um there's a few different ways to
12:30 - do this a few different
12:31 - functions that you can use for random
12:33 - sampling i guess
12:35 - for this at least in the final code i
12:37 - gave you guys i used random so i'll use
12:39 - that here
12:40 - um so i'm just gonna demo really fast
12:43 - what this random sample function does
12:45 - uh before we do any examples here so
12:49 - if i just had an array i'm going to call
12:51 - it
12:52 - arr um
12:56 - of a bunch of numbers like 1 1
12:59 - 2 2 3 4 5 6 6
13:02 - 7 8. okay i've got a bunch of numbers in
13:06 - this array
13:08 - if i say um
13:11 - if i say give me a random
13:14 - sample of array and i say give me a
13:18 - random sample of
13:20 - five numbers let's say
13:26 - oh i guess actually it requires a list
13:33 - it gives me a sampling of the numbers in
13:36 - this array
13:37 - uh so this first time i got 6 6 5 1
13:41 - 8. um one of the questions you might be
13:44 - interested in and actually i'll do this
13:46 - again so here's five different numbers
13:49 - interesting that i got the two sixes
13:50 - again oops
13:52 - let's try it again two sixes again wow
13:57 - okay that time i only got one so it will
14:00 - it will run this randomly every single
14:02 - time
14:03 - and we'll get different results every
14:04 - single time one thing you might be
14:06 - interested in is whether there's
14:08 - replacement here so by replacement i
14:11 - mean after it picks a number
14:13 - can that number be picked again by
14:15 - default
14:16 - this function does not use replacement
14:18 - but if you
14:21 - wanted to you could always do a quick
14:23 - google search to try to figure that out
14:26 - so
14:26 - i'm just going to demonstrate because
14:29 - this is also
14:30 - a coding uh
14:34 - demo so
14:37 - actually now the
14:41 - function documentation
14:48 - um all right let's try this again this
14:50 - was a bad demo
14:53 - uh sample python
14:58 - and we'll go back to all
15:04 - okay it's weird that
15:08 - the function documentation doesn't come
15:11 - up
15:12 - right away but here
15:15 - i guess is the whole random package so
15:17 - it'll be in here
15:18 - somewhere
15:24 - yeah there it is um and you can look
15:27 - through
15:28 - and see what what all of the parameters
15:31 - are
15:32 - it should say somewhere whether
15:35 - it is replaceable
15:39 - oh yeah sampling without replacement so
15:41 - it's not going to put anything back
15:44 - okay so we have this this sample
15:48 - from our array and we can see that we
15:50 - can do this in
15:51 - python so now i'm going to demo this
15:54 - using our full population so
15:58 - i'm imagining i'm the researcher and i'm
16:00 - going to go in
16:01 - and as the researcher i'm going to find
16:04 - a sample
16:05 - or a subset of people in this population
16:08 - and i'm going to collect their
16:12 - salaries so let's uh let's do it this
16:15 - way
16:17 - i'm going to call this samp1
16:23 - and i'm gonna pass in what did we call
16:26 - it
16:27 - hourly pay uh actually
16:30 - okay just to make everything super super
16:34 - clear
16:36 - i'm going to say i'm going to re-save
16:38 - this as something called population
16:41 - i'm going to save it as a list
16:45 - but i'm just saving the exact same
16:47 - numbers again so that we're really clear
16:49 - that this is the
16:50 - the full population and then this is
16:52 - going to be our sample
16:54 - so we'll sample from that population
16:57 - and i don't know jamie pick a pick a
17:00 - number
17:01 - how many do we want to sample from it uh
17:05 - 20. okay let's sample 20 people to start
17:11 - and then let's print out the mean
17:15 - of our sample
17:18 - and it was 17.24 interesting
17:22 - okay we could do this as many times as
17:25 - we wanted so
17:26 - if we do this again because this is
17:28 - random sampling we're going to get
17:30 - different samples every single time
17:32 - so i'll do it again we got something
17:35 - different
17:36 - i also think so i'll show you really
17:38 - quickly
17:40 - pissed stamp one
17:44 - um
17:55 - okay let's pick uh let's pick a slightly
17:58 - larger sample size let's do like 150 so
18:01 - we can really see it
18:04 - if we look at this histogram right of a
18:07 - sample of 150 people from our population
18:11 - you'll notice that it looks pretty
18:14 - similar to our original histogram that
18:18 - we made right like so our original one
18:20 - looked like this there was a spike
18:22 - around zero
18:24 - um then there was this long tail most of
18:26 - the
18:27 - the density of this thing was between 0
18:29 - and 20
18:30 - then 20 to 40. and if we look back at
18:33 - this we see kind of a similar shape
18:35 - right we've still got this
18:36 - low spike we've got some den some high
18:40 - density between 0 to 20 some
18:42 - like medium density from 20 to 40 and
18:44 - we've got this kind of
18:46 - long tail obviously it's a little bit
18:48 - sparser
18:49 - um but we still we see a similar shape
18:52 - and we see that
18:54 - this mean for our sample 18.65
18:58 - is kind of pretty similar to the mean
19:01 - for the overall population and
19:05 - no matter how many times we do this
19:06 - taking different samples of 150 people
19:10 - from our population which let's see how
19:13 - big is the population
19:16 - can i do one on this
19:20 - actually don't know yeah
19:25 - uh okay
19:29 - that's three minutes well i guess this
19:30 - is not the whole population
19:32 - because it's not as long as it would
19:36 - need to be
19:36 - but you'll have to suspend disbelief so
19:38 - we've got like three million in here
19:41 - um we can imagine that the population is
19:45 - something else i don't know
19:48 - okay so but we we do see right that
19:52 - no matter how many times we do this
19:55 - we're going to get a sample that's
19:57 - somewhat similar to the population it's
19:58 - not going to be exactly the same
20:00 - it's going to be slightly different
20:01 - every time there might be different
20:03 - outliers that show up like this one
20:05 - randomly has
20:07 - two people i think out in this uh
20:10 - like over a hundred per hour category
20:12 - which
20:13 - is kind of surprising given how rare
20:16 - that is
20:17 - in the full population but sometimes
20:19 - just by random chance we'll get
20:20 - those people so
20:24 - okay and the framework that we're now
20:28 - going to take so do this one more time
20:30 - because it's kind of fun
20:34 - we're going to think about what happens
20:36 - if we do this a lot of times so
20:39 - now that we have pretended to be the
20:42 - researcher
20:43 - we've taken a sample from our population
20:46 - we have taken a look at it and seen that
20:49 - it's similar to the population but
20:51 - there's some variation in there
20:52 - sometimes we get
20:53 - a high mean sometimes we get a low mean
20:56 - compared to the population mean
20:58 - now we're going to go back to uh
21:01 - now we're gonna go back to all powerful
21:02 - mode okay
21:05 - so in our all-powerful mode
21:08 - what we're gonna do is we're gonna
21:11 - repeat this process
21:13 - a whole bunch of times so
21:18 - jamie what kind of
21:21 - uh coding technique do you think
21:24 - i should use to repeat this a bunch of
21:28 - times
21:28 - or what do you have any ideas how to how
21:30 - i could kind of
21:32 - go about that yeah so i guess if we want
21:34 - to basically repeat the same pos
21:37 - repeat the same process a lot of times
21:39 - we might maybe want to use some type of
21:40 - loop
21:41 - like have it automatically do it yeah
21:44 - yeah so instead of just pressing this
21:46 - run button a bunch of times
21:48 - and seeing what the output is i'm gonna
21:49 - use a for loop
21:52 - um and i could use a different kind of
21:55 - loop actually
21:56 - uh there's nothing i could use like a
21:59 - while loop
22:00 - as well um but i'm just gonna use a for
22:04 - loop because it's easy
22:06 - um and what i'm gonna do is i'm gonna
22:08 - say for
22:09 - i and range
22:12 - i don't know like 10 000. what this is
22:15 - gonna do
22:16 - is it's gonna repeat the process
22:19 - that i tell my that i tell python to
22:23 - repeat it's gonna repeat it
22:25 - 10 000 times um
22:28 - it see might seem a little bit silly
22:30 - that i have this like i
22:31 - here where i say for i and range
22:35 - 10 000 um i'm not going to
22:38 - use it for the purposes of what we're
22:40 - doing here
22:41 - i'm really just setting this up because
22:46 - i want i just want something to
22:49 - [Music]
22:50 - to happen ten thousand times i want to
22:53 - kind of like
22:54 - essentially if i was coding something
22:57 - else
22:57 - right every time this whatever code i
23:01 - put down here
23:02 - under the for loop would happen every
23:04 - time that would happen
23:05 - i would increase by one and it would or
23:08 - it would start at zero so go
23:09 - zero one two three four um
23:13 - right so like if i print four i in range
23:16 - ten print i and i
23:20 - uh and i run this i'm just going to get
23:21 - the numbers 0 through 9
23:23 - because i is going to be 0 the first
23:26 - time
23:27 - then it's going to be 1 then it's going
23:29 - to be 2 and it's going to happen
23:30 - 10 times in total and it's going to
23:33 - print out the value of i
23:34 - each time but i'm just not going to use
23:37 - i because i don't need it
23:38 - i just need something to happen 10 000
23:41 - times or a large number of times
23:44 - okay actually good coding practice
23:48 - is to never start a loop by repeating
23:50 - something 10
23:51 - 000 times because if you screw up the
23:53 - code uh
23:55 - then it can get stuck and like quit out
23:58 - on you so i like to start with like
24:00 - 10 and then we'll we'll iterate on this
24:04 - so i'm going to kind of grab my code
24:07 - from up here
24:11 - i've got population has already been
24:14 - saved
24:15 - and every time in this loop
24:19 - what i'm going to do is take a sample
24:23 - call it sample of some number of
24:26 - observations
24:28 - and then i'm going to calculate the mean
24:31 - of the sample
24:37 - actually i'm going to call this samp
24:40 - because another good coding
24:43 - practice is to not name variables the
24:46 - same thing
24:47 - as functions um because that can
24:50 - sometimes get a little bit mixed
24:52 - up great okay so
24:55 - i'm going to calculate the mean of
24:57 - sample but i don't want to just
24:58 - calculate the mean and just
25:01 - let it go i want to save it somewhere so
25:04 - uh jamie do you have any ideas for how i
25:07 - could
25:07 - save it yeah so we're probably going to
25:11 - want to save more than
25:12 - one of these because you're going to be
25:13 - iterating a lot so
25:15 - we could save it inside of a list cool
25:18 - so maybe
25:19 - we can make like a list outside of the
25:21 - for loop
25:22 - that is empty that we can just add stuff
25:25 - to it
25:26 - yeah so i'm going to create an empty
25:28 - list called samp means
25:30 - perfect and then i'm going to say
25:35 - samp means dot append
25:39 - which means append that value onto the
25:43 - list
25:44 - um and i'm going to append the mean of
25:47 - that particular sample
25:50 - so uh okay
25:54 - and now i'm just going to print out what
25:56 - this looks like after 10 iterations
26:00 - and we'll take a look at it
26:04 - cool so all of all of what we've done
26:07 - here is we've taken
26:09 - 10 sam 10 different samples of 150
26:13 - each for each sample we calculated the
26:16 - mean
26:16 - and we saved that in our list so the
26:18 - first sample mean was
26:20 - 20.68 this next one was 19.35
26:24 - then 18.66 and so on and so forth
26:28 - uh i see that i saw that there was a
26:30 - question
26:31 - about um memorize
26:35 - memorizing and knowing how the number
26:37 - goes so yes
26:38 - uh i think jamie responded but if you
26:41 - could clarify that question i would be
26:43 - happy
26:44 - happy to answer it um
26:47 - okay so
26:50 - all right so we've done this we've
26:52 - confirmed that we can do it 10 times and
26:54 - we can
26:55 - collect 10 sample means and now i'm
26:58 - gonna do it
26:59 - a whole bunch more times i'm going to do
27:03 - 10 000. i'm gonna run it
27:07 - i'm not gonna print it anymore because
27:09 - that's gonna be 10 000 numbers
27:11 - but what i will do is i
27:19 - i'll make an will of it
27:32 - this will take a second to run
27:37 - cool cool
27:40 - interesting okay so
27:44 - let's break down what this picture is
27:46 - telling us
27:48 - so remember that what we did as all
27:50 - powerful beings
27:51 - is that we collected 10
27:54 - 000 different samples each sample had
27:58 - 150 people in it
28:00 - for each sample we calculated the mean
28:04 - and then we plotted a histogram of them
28:07 - um when we plotted this histogram we saw
28:11 - that
28:12 - it looks kind of symmetrical part of the
28:15 - reason why i chose this data is because
28:17 - i think
28:17 - this is really a stark contrast
28:20 - to the population distribution
28:25 - which i think is interesting so like
28:27 - this population distribution
28:29 - i would describe as very right skewed
28:31 - right there's this
28:32 - very very long right-handed tail
28:36 - and most of the data is on the low end
28:39 - of the distribution
28:41 - but here and that's true right for all
28:43 - of the individual samples that we took
28:46 - all those individual samples are also
28:49 - right skewed
28:51 - but suddenly when we calculate sample
28:54 - means
28:55 - and we plot a histogram of all of the
28:58 - sample means
28:59 - we get this really nice symmetrical
29:01 - distribution
29:02 - and if we calculate the mean
29:06 - of all of the sample means
29:11 - it's going to be so it's like 18.82
29:15 - about which is almost exactly
29:19 - the same as the the true population mean
29:24 - and maybe that feels i don't know to me
29:27 - that feels like it makes sense
29:29 - that the mean of the means like the
29:31 - middle of the means of all these samples
29:34 - is going to be equal to
29:36 - the population mean but it's actually
29:39 - like
29:41 - a super super powerful statistical
29:44 - theorem
29:45 - that is not i mean we take it for
29:47 - granted like
29:49 - uh what this what this means
29:52 - in like and i don't mean to use
29:56 - mathy terms but there's uh this is
29:59 - called
30:00 - a unbiased estimator so the mean is
30:04 - is called an unbiased estimator of the
30:06 - population mean
30:08 - which means that if you take a bunch of
30:11 - samples from a population and you
30:13 - calculate the mean for each one
30:16 - on average those sample means
30:19 - will be the same as the population mean
30:21 - but that's not necessarily true for
30:24 - for example if you calculate
30:27 - standard deviation or variance of a
30:31 - population
30:32 - it's almost an unbiased estimator
30:35 - but that's why there's a difference i
30:36 - don't know some of you may have seen
30:38 - this so there's a difference between
30:39 - calculating population standard
30:41 - deviation and sample standard deviation
30:44 - you divide by n in one case and you
30:46 - divide by n
30:47 - minus one in the other case and the
30:49 - reason for that
30:50 - is that if you divide by n it becomes a
30:53 - ever so slightly
30:54 - biased estimator um of
30:57 - the population standard deviation and if
31:00 - you think of something like
31:02 - the maximum of a data set which is
31:05 - another
31:06 - statistic that we might use so like we
31:08 - might calculate
31:09 - the maximum uh salary in each sample
31:12 - like that might be something that we're
31:14 - interested in
31:15 - if we count if we take the maximum of
31:18 - all of these population or all these
31:21 - samples
31:22 - and plot a histogram of the maximums
31:26 - it's not going to be centered at the
31:27 - population maximum
31:30 - so it's it's not true for all statistics
31:33 - that this lines up but for the sample
31:35 - mean it does
31:37 - and it's really really nice that it does
31:39 - okay
31:40 - so i guess the first question is why is
31:43 - this so valuable
31:45 - and the reason it's so valuable is that
31:48 - it allows us to understand uncertainty
31:52 - and uncertainty is really the key to
31:56 - statistics and inferential statistics
31:59 - specifically
32:00 - because again put yourself in in the
32:04 - feet of or in the shoes of a researcher
32:08 - um again i like that marketing example
32:12 - if you're like you're trying to figure
32:14 - out what proportion of visitors to a
32:16 - website
32:17 - will press my green subscribe button and
32:21 - you can only sample
32:25 - a thousand people you can only show the
32:26 - button to a thousand people and observe
32:28 - what they do
32:30 - you need to know how cert let's say you
32:32 - find that
32:35 - ten percent more people push the button
32:38 - if it's green than in the old version
32:41 - you need to be
32:42 - know how certain you can be that it's
32:44 - really ten percent
32:45 - and not negative one percent
32:49 - right like maybe in the population
32:53 - it's negative one percent but you just
32:55 - found in your random sample
32:56 - 10 more press that button
32:59 - and in this case right like if
33:03 - if you find as the researcher that the
33:06 - average salary
33:07 - is 16 an hour
33:10 - you want to know how certain you can be
33:13 - that that lines up with the population
33:15 - average salary if that's what you're
33:17 - trying to estimate you want to know how
33:19 - far off you could be
33:22 - and that's what this tells you tells you
33:24 - how far off you could possibly be
33:26 - because it gives you a sense of how
33:29 - spread out
33:31 - these numbers and how spread out the
33:33 - sample means
33:35 - are if you were all powerful and you
33:37 - could take a bunch of sample means of
33:39 - that size
33:40 - you this tells you how spread out they
33:43 - could possibly be
33:44 - um so i guess one of the things that
33:47 - i'll point out here
33:49 - um and maybe we intuit it but i think
33:52 - it's
33:53 - like a powerful thing to show
33:56 - is uh what happens when
34:00 - we change the sample size so what i'm
34:03 - going to do is i'm actually going to
34:06 - i'm going to uh
34:10 - make sure that we plot this on the same
34:13 - axis every time i'm gonna set
34:17 - plt dot x slim
34:21 - of 0 to 40.
34:24 - uh and i'll plot this again
34:31 - yeah okay so i'm just plotting this from
34:33 - 0 to 40 so we can see the full
34:36 - whole thing if i do
34:40 - if i do this again
34:43 - with let's say a sample size of
34:47 - a hundred instead
34:53 - it's going to be a little bit wider
34:55 - let's pick something lower
34:56 - really show it i'm gonna
35:02 - sample size of 50. okay so now we can
35:05 - see right this distribution when we took
35:07 - samples of size 50
35:09 - it's going from the sample means are
35:11 - going from 10
35:12 - all the way up to 30. here they're going
35:16 - between
35:17 - like 15 and 25 which makes some sense
35:21 - right because if you think about it
35:24 - if you take a bigger sample it's more
35:27 - likely to be representative of the
35:29 - population
35:30 - then if you take a small sample then you
35:32 - could have outliers that
35:34 - throw everything off the other thing
35:37 - that i won't demo here but that
35:39 - the other thing that can influence this
35:41 - the width of this thing
35:43 - is the amount of variation
35:46 - in the population so if the population
35:50 - has a lot of variation
35:52 - the width of this thing will be bigger
35:55 - and if the population has very little
35:56 - variation like let's say
35:58 - everybody's salary was around 20
36:01 - instead of that spread out distribution
36:03 - that we saw before
36:04 - going all the way up to 140 then there's
36:07 - just going to be
36:08 - less variation in sample means by
36:10 - default right like if everybody was
36:12 - making 20 in the most extreme case then
36:15 - all of the sample means would be exactly
36:16 - 20.
36:17 - so however however much variation there
36:20 - is in the population will also influence
36:22 - this
36:23 - [Music]
36:24 - so what i'll show i think
36:27 - like a cool thing to see just to kind of
36:31 - verify it
36:32 - even is that
36:37 - and this is the the official central
36:39 - limit theorem that we're getting to
36:41 - now is that um we can
36:45 - basically describe exactly what
36:49 - this shape is going to look like
36:51 - mathematically
36:52 - without having done what we did here
36:55 - which is take all of these sample means
36:58 - i'm gonna plot this again but this time
37:02 - i'm going to i'm gonna grab some kind of
37:05 - this is again like a little bit i don't
37:08 - mean to
37:09 - just like pull fancy code and make
37:11 - everybody
37:15 - accept it um
37:18 - but i'll talk through what this is doing
37:22 - so on top of this histogram what i'm
37:24 - gonna do
37:26 - and i'm gonna normalize the histogram
37:28 - which means
37:29 - or actually i'm gonna switch to
37:32 - a disc plot
37:36 - um what i'm doing here is i'm i'm
37:38 - normalizing the histogram so
37:40 - here the histogram is going from
37:43 - 0 to 600 on the y-axis these are
37:46 - frequencies
37:48 - and if i were to say density
37:52 - equals true here or if i use disk plot
37:54 - and i'll demo that in a second
37:57 - all that does is it changes this y-axis
38:00 - so that
38:00 - the scale of this is such that the total
38:04 - area of this thing adds up to one um
38:07 - this is so that it mimics what's called
38:10 - a probability distribution function
38:12 - which you don't really need to know too
38:14 - much about right now
38:16 - but that allows us to compare this to
38:18 - kind of mathematical
38:20 - functions um and if we do dist plot here
38:25 - it does the exact same thing it also um
38:29 - puts what's called a oops
38:32 - oh yeah it doesn't take bins
38:36 - and also um
38:42 - oh it's sms
38:46 - bad it also gives you this
38:49 - kernel density estimation again
38:52 - not super important all you need to know
38:54 - is it's kind of like
38:55 - a smoothed version of this histogram
38:58 - so it's trying to like smooth out this
39:02 - uh this shape so
39:05 - if we do this um okay what i've done
39:09 - i'm gonna walk through what this code is
39:10 - doing or maybe jamie do you wanna walk
39:12 - through
39:12 - try to walk through what this code is
39:14 - doing i'm putting you on the spot a
39:15 - little bit
39:16 - yeah sure um let me just
39:19 - change some things okay
39:23 - okay so the where should i start from
39:26 - should i start from you
39:27 - and sigma or so i guess
39:31 - mu is just the population mean um i'll
39:34 - come back to this
39:36 - in a second so maybe start with this
39:38 - what is this lin space things so
39:42 - linspace mu minus three times sigma
39:44 - oh so i think linspace you're
39:48 - basically setting up like an interval
39:49 - range using mu
39:51 - and sigma um which i think sophie said
39:54 - she'll
39:54 - come back and explain what sigma is but
39:56 - basically it's going to set a range of
39:58 - values
40:00 - in a variable called x and then you're
40:02 - going to plot
40:03 - that range of values um
40:06 - [Music]
40:08 - and then what is stats.norm.p i think
40:10 - that's just like
40:12 - to like give a normal distribution
40:16 - with the given x and yeah
40:19 - give with the given range of values mu
40:21 - and sigma
40:22 - so i'll demo this part really fast
40:25 - actually i should have done just like 10
40:26 - numbers
40:27 - um all that linspace does
40:30 - is it says okay start at 0 end at 1 and
40:34 - give me
40:35 - 10 numbers that are equally spaced so
40:37 - this just gives me
40:38 - 10 numbers between 0 and 1 that are
40:41 - equally spaced apart
40:43 - and all i'm doing here is i'm saying
40:46 - basically this is something that is not
40:49 - super important but
40:50 - this gives me a sense of how
40:53 - wide the x-axis of my distribution is
40:57 - going to be
40:58 - um basically i'm just saying like what's
41:01 - the lowest number i need to plot here
41:02 - what's the highest number i need to plot
41:04 - here in order to fit this
41:06 - on my graph and i'm getting a hundred
41:08 - numbers
41:09 - and then i'm going to get essentially
41:13 - the normal distribution version of this
41:17 - a normal distribution again is a
41:19 - probability distribution
41:20 - and all you need to know for right now
41:22 - is that
41:23 - it describes a particular shape of this
41:27 - distribution
41:28 - mathematically and so
41:31 - i'm plugging in all of those values that
41:33 - i just got between
41:36 - the two ends of that distribution
41:38 - calculating how high that line needs to
41:40 - be and i'm just using them to
41:42 - draw that line on top of my graph
41:45 - and when i do that
41:49 - oh it's because i did this again
41:58 - uh did i not save this
42:07 - sorry guys
42:10 - oh
42:13 - um sci pi import
42:16 - stats okay gonna run
42:20 - okay there we go so what you see here is
42:23 - i've
42:24 - drawn in black what's called the normal
42:27 - distribution
42:28 - on top of the distribution that we got
42:32 - just by taking samples of size 50 and
42:35 - plotting
42:36 - the um and collecting the means for each
42:39 - sample
42:40 - and what you see here is that it's
42:42 - basically the same thing
42:43 - so i've used like a mathematical formula
42:46 - to say what the shape
42:48 - can look should look like and then we've
42:50 - kind of proven
42:51 - what that shape actually looks like by
42:53 - taking the samples
42:55 - and what i've done here is
42:58 - i've drawn a normal distribution that
43:00 - has a mean
43:01 - that's equal to the population mean and
43:04 - a standard deviation
43:05 - that's equal to the population standard
43:08 - deviation
43:09 - divided by the
43:12 - square root of the sample size that's
43:15 - what this
43:16 - um double times sign means
43:19 - to 0.5 so taking something to the 0.5
43:22 - power is the same as taking the square
43:24 - root of it
43:25 - so 50 times times 0.5 is the square root
43:29 - of 50
43:30 - and then so this whole thing
43:34 - is standard deviation of the population
43:37 - divided by the square root
43:38 - of the sample size and we see it that if
43:40 - we take a normal distribution with those
43:43 - parameters
43:45 - again mathematical description of a
43:47 - curve
43:48 - it really perfectly matches up with what
43:51 - this
43:51 - this shape looks like and this piece
43:56 - the standard deviation of the population
43:58 - divided by the square root
43:59 - of the sample size this is what's called
44:02 - the
44:03 - standard error of
44:06 - the mean
44:09 - so um sophie uh you have a question from
44:12 - the chat which is asking
44:13 - which part of the like code you made was
44:17 - like the actual normal distribution
44:19 - was the actual normal distribution
44:20 - perfect i should have commented this out
44:23 - so this part
44:26 - here i'm just plotting
44:29 - the sample means
44:32 - this part here is where
44:37 - i'm plotting
44:42 - the normal distribution on top of it
44:47 - great awesome so
44:51 - yeah i think this i mean we're gonna run
44:54 - out of time for all the things i want to
44:56 - cover today but i do think like
44:58 - just taking a second to stop and look at
45:00 - this picture
45:01 - makes me just really happy it's really
45:03 - really beautiful
45:04 - because we've statisticians have like
45:09 - it seems like almost magically figured
45:11 - out these crazy formulas
45:13 - to describe things that seem
45:17 - i don't know hard to describe and
45:20 - um and it's really cool that that we can
45:24 - that we can quantify our uncertainty in
45:27 - this
45:27 - way okay so
45:31 - again coming back to the standard error
45:33 - piece so the standard error
45:35 - again is the standard deviation
45:39 - of this sampling distribution
45:42 - it's basically a measure of how wide is
45:46 - the sampling distribution
45:47 - and the sampling distribution again
45:51 - because i i feel like no matter how many
45:53 - times i
45:54 - i heard this when i was first learning
45:56 - it it like took maybe a hundred times of
45:58 - hearing this before
46:00 - it clicked in my brain um
46:04 - the sampling distribution we got from
46:05 - taking samples of
46:07 - the same size calculating the mean for
46:10 - each one
46:10 - and then plotting the distribution of
46:12 - the means
46:14 - the standard error is how is a
46:17 - description of how wide that
46:19 - distribution is
46:22 - okay all right so we've we've made it
46:26 - pretty far we've gotten some interesting
46:27 - things
46:28 - already out on the table now
46:32 - so we were in all powerful mode we made
46:34 - this distribution
46:36 - we saw what it looked like we proved to
46:38 - ourselves that
46:39 - the central limit theorem works um i
46:42 - don't even think i said what the central
46:43 - limit theorem
46:44 - is but we just proved it basically um
46:47 - without even using any math which is
46:49 - super cool
46:50 - the central limit theorem just says that
46:52 - this distribution is normal
46:54 - and that the mean normally distributed
46:56 - so it follows the shape
46:57 - the mean is the same as the population
47:00 - mean and the standard deviation
47:02 - is equal to the population standard
47:05 - deviation
47:06 - divided by the square root of the sample
47:08 - size that's the whole central limit
47:10 - theorem
47:11 - um you could do it with math or you
47:14 - could do it by actually taking all those
47:15 - samples and calculating the mean of each
47:17 - one
47:19 - okay so now let's go back for a moment
47:22 - to the perspective of the researcher so
47:25 - like
47:26 - all right back in researcher mode
47:31 - i should have put these in the final
47:34 - code
47:35 - would have been helpful uh okay so we're
47:37 - back in researcher mode and now
47:39 - we're not all powerful anymore we can't
47:41 - actually see what this distribution
47:44 - or we can't actually see the whole
47:45 - population so we can't take
47:47 - samples from the whole population and
47:49 - see what the distribution looks like
47:52 - but now that we have the central limit
47:54 - theorem
47:55 - we actually kind of can see what it
47:57 - looks like
47:58 - or we can approximate what it looks like
48:01 - so remember the things that we needed to
48:04 - plot that black line
48:07 - so to plot the blue histogram we needed
48:10 - to take samples from the full population
48:12 - but to get the black line all we needed
48:15 - to know
48:16 - was the mean of the population and
48:20 - the standard deviation of the population
48:22 - and the sample size
48:25 - other than that we didn't need any more
48:27 - information
48:29 - so we can approximate this
48:33 - if we have an estimate of the population
48:36 - mean
48:37 - and of the standard deviation of the
48:40 - population
48:42 - and we're going to get those things from
48:44 - our sample
48:45 - they're not going to be perfect we don't
48:48 - right we don't know what the population
48:50 - mean
48:50 - is anyway we're trying to estimate it um
48:54 - the sample standard deviation like i
48:56 - said it's going to be an
48:57 - unbiased estimator of the population
48:59 - mean
49:00 - if we calculate it with that n minus 1
49:02 - on the denominator which we will
49:05 - but it's not going to be perfect we can
49:07 - still do it though
49:08 - so let's go back uh i'm
49:11 - again going to print
49:15 - the mean for
49:18 - our sample i think we still have a
49:20 - sample sample one
49:22 - somewhere in our or what did i call it
49:30 - let's see yeah we called it stamp one we
49:33 - still have a sample in here somewhere
49:35 - let's actually let's like
49:39 - calculate a new one oh that was a good
49:42 - one
49:43 - it was low okay
49:46 - okay so we have a sample let's calculate
49:49 - also
49:49 - the standard deviation of that sample
49:54 - and i'm going to save those things
49:56 - sample mean
49:58 - equals and populate or sorry
50:02 - sample standard deviation
50:06 - and we'll print them
50:17 - and we see okay so the the sample mean
50:21 - is equal to 16.33
50:26 - the population or sorry the sample
50:29 - standard deviation was 13.21
50:32 - um okay all powerful mode for a second
50:35 - let's remind ourselves of what these
50:37 - values
50:39 - r for the population so um
50:42 - print see v dot
50:45 - mean of population
50:47 - [Music]
50:48 - and also for standard deviation
50:55 - okay so what we notice here is that
51:00 - our sample that we took had less
51:03 - uh less variation than the population
51:06 - so the sample standard deviation was
51:09 - 13.2
51:10 - the population standard deviation was
51:12 - 18.1
51:14 - um so we're gonna under
51:17 - estimate the amount of variation in the
51:20 - sample
51:21 - the larger the sample we take the better
51:24 - of an approximation we're going to get
51:25 - here
51:27 - but we're going to work with it because
51:29 - it gives us at least some sense
51:32 - back to researcher mode
51:35 - so as the researcher we're now going to
51:39 - estimate what
51:42 - this distribution looks like
51:45 - so i'm actually going to grab
51:48 - this exact same code
51:52 - but now we're going to do this with
51:56 - the um
51:59 - we're going to do this with the sam
52:03 - just the information from the sample so
52:05 - we have our sample mean we have our
52:06 - sample standard deviation
52:08 - we're going to use a mu which is really
52:11 - just the mean of this normal
52:13 - distribution
52:14 - of the sample mean
52:18 - and we're going to use the
52:23 - sample standard deviation here
52:26 - and i believe that that sample had a
52:30 - was a size 150 but we'll just do one
52:35 - sample one that will tell us how many
52:37 - values are in there
52:39 - um or even i think
52:42 - even clearer is to say sample size
52:45 - equals
52:46 - that so we're really clear and then
52:49 - we'll put sample size in this equation
52:53 - and if we plot this we get this
52:56 - this curve um it's going gonna be i
52:59 - should
53:00 - maybe plot it on top of this so it's
53:02 - gonna be more s
53:04 - um or actually maybe
53:07 - less spread out than
53:12 - this
53:18 - it's going to be a little bit off from
53:22 - what it should be uh
53:27 - that's more off than i thought it would
53:29 - be
53:31 - or it's smaller oh oh oh it's because
53:34 - this was a sample size of 50.
53:37 - sorry ignore that uh
53:40 - let's redo this i guess with a sample
53:42 - size of
53:43 - 150.
53:52 - i know we're gonna run out of time but
53:56 - now this will right so this
54:00 - is our estimation of
54:03 - this is a little bit off pretty much
54:06 - because this this estimate was so off
54:10 - but what we can do is now use this
54:13 - distribution
54:14 - to try to estimate the plausible range
54:19 - of what values we might get
54:22 - if we could observe the entire
54:24 - population
54:25 - and take samples from it so
54:29 - the the reason why these two
54:31 - distributions are offset from each other
54:33 - is because this one we centered at the
54:35 - popul
54:36 - or the sample standard deviation this
54:38 - one we sent centered at the population
54:40 - standard
54:41 - sorry at the sample mean for this one at
54:44 - the population
54:45 - mean for this one so they they're off
54:48 - from that
54:48 - but the width of it is the part that we
54:51 - really care about
54:52 - and even though we were pretty far off
54:54 - on our sample standard deviation
54:56 - compared to the population
54:57 - standard deviation this
55:01 - the width of this distribution is pretty
55:04 - close to the width
55:05 - of what we would find if we were
55:09 - able to like be all powerful and see
55:12 - and take samples from everybody and so
55:16 - what we end up doing is we end up using
55:18 - this
55:19 - this distribution here to figure out or
55:23 - a plausible range that the population
55:25 - mean might be in
55:27 - and so we end up saying that the
55:29 - population mean is somewhere between
55:31 - like we think
55:34 - 12 and 20 or
55:37 - whatever like these points are and we
55:40 - can
55:41 - we can choose percentile so we could do
55:43 - like the
55:45 - second percentile and the 98th
55:46 - percentile to cut off
55:48 - kind of the tails of this but that's
55:50 - really all that a 95
55:52 - confidence interval is and i can demo
55:55 - that super fast i know we're running out
55:57 - of time
55:58 - um but i also know
56:02 - that this is a super complicated uh
56:06 - a super super complicated process
56:09 - and like exp mind experiment
56:13 - so i think it's nice if we kind of stop
56:15 - here and
56:17 - get like three more minutes to talk
56:20 - about it a little bit
56:22 - so here we go all i'm doing here
56:25 - is i'm taking i'm trying to find like
56:27 - the 2.5th
56:28 - percentile and the 97.5th percentile of
56:32 - this black
56:33 - line um
56:39 - oops let's put stamp one here
56:45 - and i save this as standard error
56:51 - i saved it as sigma
57:01 - so this goes from roughly 14.22
57:06 - to 18.45 and so if we were the
57:10 - researcher
57:11 - we would say our sample mean
57:14 - was 16.33 but we are
57:18 - 95 confident that
57:21 - the true population mean is somewhere
57:23 - between
57:24 - 14.2 and 18.45
57:28 - which is accurate although it is really
57:31 - close to
57:32 - that upper bound which was you know
57:35 - a random fluke and that happens but this
57:37 - is the way that statisticians and data
57:40 - scientists
57:42 - use the central limit theorem to try to
57:45 - quantify their uncertainty
57:46 - about a sample mean without having
57:50 - been able to see the entire population
57:53 - cool
57:55 - so i'm gonna stop there we've got two
57:57 - minutes to spare
57:58 - jamie what do you think would be a good
58:01 - use of this time do you think
58:03 - there's anything that's worth like
58:05 - talking about i hadn't
58:08 - had a a good eye on the stream or on the
58:11 - chat were there any questions that came
58:13 - up i think we
58:14 - covered all the questions wait one thing
58:16 - i'm curious about what was the actual
58:18 - population mean because i'm wondering if
58:20 - it was actually within the 95
58:22 - the population mean was 18.84
58:26 - about 839. okay and so it was like
58:30 - just just barely yeah but it wasn't
58:33 - in that range we could kind of do this
58:36 - with
58:37 - another sample like if we
58:41 - i wish i organized my code better
58:45 - but uh it's
58:48 - organized better in the final version
58:50 - that
58:51 - is available on github but if i take
58:53 - another sample
58:55 - here let's find one that seems like
58:58 - similar to the population
59:00 - yeah that seems more similar to the
59:01 - population
59:03 - if we use a different sample
59:07 - where these things yeah so here this one
59:11 - we got a little bit closer in terms of
59:14 - standard error
59:15 - and pop and mean like our sample was
59:19 - more similar to the population
59:21 - and then that will give us
59:25 - a
59:29 - slightly
59:32 - yeah uh a confidence interval
59:36 - that makes that more comfortably
59:40 - includes the population mean um
59:43 - so again like the i think the
59:46 - thing that i had trouble conceptualizing
59:50 - for a really long time is that the
59:53 - central limit theorem tells us something
59:55 - about
59:56 - the shape of this black line but it
59:59 - can't really
60:00 - tell us we still have to make
60:03 - a leap there because we still don't know
60:05 - what the population standard deviation
60:07 - is
60:08 - we still have to estimate the population
60:09 - standard deviation
60:11 - using our sample and so it's not
60:14 - like totally magic that we can just
60:16 - recreate
60:17 - exactly this but we can get a pretty
60:21 - good read on at least how
60:23 - how much variation we can expect and i
60:26 - think
60:26 - that's that is the the true power um
60:29 - and i i encourage so there's um on
60:32 - codecademy
60:33 - there is a article on the central limit
60:35 - theorem that kind of walks through this
60:37 - again
60:37 - and so if you watch this series and
60:41 - you still feel a little confused or you
60:43 - still want to like
60:45 - go back and confirm your understanding i
60:48 - highly recommend that you read that
60:49 - article or
60:50 - look up on the internet central limit
60:52 - theorem and and read about it because i
60:54 - think
60:54 - this is one of those things it's like
60:56 - it's deceptively simple and also really
60:59 - deep
61:00 - and uh and
61:03 - i think even for me i learned it about
61:05 - like i said like a hundred times before
61:07 - i actually learned it so
61:10 - all right next week we're going to jump
61:13 - into
61:13 - actually using this central limit
61:15 - theorem to run
61:16 - some hypothesis tests and we're going to
61:19 - learn even more about how hypothesis
61:22 - tests work
61:23 - so i'm really excited for that um but
61:26 - otherwise
61:27 - uh thank you kevin for for that question
61:31 - kevin says i have a question why are
61:33 - there only so few people watching this
61:35 - is pure quality
61:37 - thank you i agree i well i don't know
61:40 - about quality but
61:42 - i'm having a lot of fun doing these and
61:44 - hopefully more people will find them
61:45 - after the fact
61:47 - but for those that are here you get the
61:49 - extra benefit of being able to
61:52 - ask questions and really speak with us
61:55 - personally so please take advantage
61:58 - all right with that i think we'll sign
62:01 - off
62:01 - everyone have a great rest of your
62:03 - tuesday and
62:05 - we hope that these are helpful
62:09 - goodbye

Cleaned transcript:

if not already possibly now all right i think we're live something happened on my screen welcome everyone uh we're just gonna wait uh a minute or two to make sure that we are fully live um jamie and i are going to be talking about the central limit theorem today and i'm very very excited uh thank you for letting us know in the chat that you can see us um so i am very excited for this uh anyway we are i think as usual streaming on a couple of different services but just as a reminder um we're gonna be keeping an eye on the chat in uh youtube so if you are on facebook or twitch or one of the other platforms that we are streaming on if you would like to code along with us and ask us questions or say hello um you can go to the youtube uh streaming and let us know that you are here by saying hello in the chat um cool uh so i guess we can get started today so i will share my screen today's lesson is gonna be heavy on the theory uh and there's we're definitely going to be doing some coding like we need some coding to get a sense of the theory but the focus is going to be on understanding some pretty deep theoretical concepts which i find super fun um but i think it can also be a little bit intimidating sometimes so um i really want to encourage everyone to ask questions if anything comes up that you are confused about um i really really welcome questions because it will help me keep track of what is making sense to people and what's not and we can slow down at any point and kind of recap things if um if anything is is confusing so uh again as per usual we're using some code that's available on our github for this streaming series if you want to download that code ahead of time you're welcome to there's also like a little simulated data set in here for this week's um this week's materials so you can find that if if you go to the github page and hopefully that is linked in youtube and other streaming services um cool i'm to open up starting cook okay so to get started um the first thing i want to prepare everyone for is i'm going to ask us to take on a couple of different personas during this lesson so we're gonna switch back and forth from the researcher perspective so that's somebody who is trying to conduct some research trying to analyze some data we're going to switch between that and the allpowerful perspective so we get in this lesson to be like gods or goddesses whatever you want to call it if you're if uh or all powerful in some way we get to like see things that the researcher would not get to see um and kind of imagine imagine both perspectives if we had all the knowledge that we could possibly have and if we only had the knowledge that a researcher had um the other thing i want to kind of set up here is up to this point we have been talking through uh summary statistics just basic descriptive statistics we looked at some data visualizations as well and um a lot of so that content is really useful for a lot of different types of research that you might want to do but i want to kind of separate what we're doing today uh from that a little bit and say so you could kind of imagine two different types of questions that you want to answer um on the one side you could imagine that let's say you work at a company like codecademy there's i think like 150 employees at this point and let's say you um you want to understand something about salary and demographic characteristics among employees and you have the data for every single person that works at the company that you're that you care about then you can just use descriptive statistics because the thing that you care about you have all of the data for but there are a lot of situations where you cannot for some reason collect all of the data that you need to answer the question that you want to answer and that could be for a variety of reasons it could be just because the population that you care about is really large like you want to understand trends between salary and demographics for all u.s adults and you can't you just cannot get that information for all u.s adults um that could be one situation another situation a lot of times in like marketing is that you can imagine you have a new feature for your product and you want to test it out and see if or let's say like it's a different color subscribe button and you want to see if more people press the green subscribe button compared to the red subscribe button and uh you want to know whether more people like all the future visitors to your website you want to know what all those people would do but you can't see all the future people that will ever access your website and in fact even among the people that you do sample you can't ever see what somebody would have done in another situation so if you show someone a green button you can't see what they would have done if they saw a red button so that's another form of missing data you just can't see you know ideally you'd like to show every person that could possibly visit your website the red button erase their memory and then do the same thing with the green button and like see all of those things and then look at the data but you can't always do that so in that case you need some other tools in order to understand something about a population about all the people that might visit the website or feel confident about it having only collected a smaller amount of data okay i've now i always do this i ramble a little too much at the beginning of these i hope i didn't lose too many people yet but hopefully that sets up kind of the motivation for what we're doing so um what i have here is a um a jupiter notebook i'm just gonna load a bunch of packages i i just copy this over every time i start a new project because i may not use all the packages but at least i have all of them imported um and i can import more if i need this uh hourly pay text file is um it's just essentially an array of numbers uh and this was simulated but what it's meant to represent is salaries in u.s dollars for theoretically all adult americans um it's like it's it's fake data but it's based off of census data so it's somewhat similar to what this would look like in real life um so i'm gonna go ahead and really quickly plot a histogram of this so we can take a look at it uh let's do like 100 bins and yes maybe 100 was too many let's do 50. um okay so it looks something like this uh which we probably expect you know there's this there's a spike at kind of a low salary seems like most people are kind of oh and this is an hourly pay or hourly salary um so looks like most people are kind of under 20 an hour there are some people between 20 and 40 and then it kind of drops off from there there's some from 40 to 60 and then like very few but still some people all the way up to 140 an hour in this chart and you can see over here this is like a a pretty big scale each of these bars um this axis represents frequencies so we have like frequencies and some for some of these bars of over three hundred thousand um cool so this gives us a little bit of a sense right now we're in all powerful modes so we're gonna pretend um in this in today's lesson we're gonna pretend that we're a researcher that's interested in figuring out what the average salary for all us adults is and then as the allpowerful being we can see data for salary information for all u.s adults so those are the two uh the two perspectives will shift between so right now we're all powerful we can see this histogram um and we can actually calculate the mean uh salary so i'll do that so if i do i mean hourly pay uh and actually i'll save this as mean salary and print it is this also big enough for everyone i realize click zoom in and i can print the mean salary okay so it's about 18 and 84 cents cool okay so we've taken a minute we're all powerful we know the answer to the question that our researcher is going to try to answer we know that the average salary for all american adults based off of this i don't know if this is exactly what it is um i think this data that i based this off of was from like 2013 or something so it might be outdated but it's approximately eighteen dollars and eightyfour cents we're going to pretend that that's the truth that our researcher can't know now we're gonna for a minute imagine that we are a researcher so um as this researcher we are going to try to answer our question what's the mean salary of u.s adults and we're going to do that by finding a sample of of u.s adults and calculating their mean salary because that's all we can do right we can find and by sample i mean like some subset of this original um of this original set of numbers right some subset of all the people that we actually care about cool so um i'm gonna actually hold on i'm gonna open up the final code and pull this over so that i can also see it uh because i just want to make sure okay cool um there's a few different ways to do this a few different functions that you can use for random sampling i guess for this at least in the final code i gave you guys i used random so i'll use that here um so i'm just gonna demo really fast what this random sample function does uh before we do any examples here so if i just had an array i'm going to call it arr um of a bunch of numbers like 1 1 2 2 3 4 5 6 6 7 8. okay i've got a bunch of numbers in this array if i say um if i say give me a random sample of array and i say give me a random sample of five numbers let's say oh i guess actually it requires a list it gives me a sampling of the numbers in this array uh so this first time i got 6 6 5 1 8. um one of the questions you might be interested in and actually i'll do this again so here's five different numbers interesting that i got the two sixes again oops let's try it again two sixes again wow okay that time i only got one so it will it will run this randomly every single time and we'll get different results every single time one thing you might be interested in is whether there's replacement here so by replacement i mean after it picks a number can that number be picked again by default this function does not use replacement but if you wanted to you could always do a quick google search to try to figure that out so i'm just going to demonstrate because this is also a coding uh demo so actually now the function documentation um all right let's try this again this was a bad demo uh sample python and we'll go back to all okay it's weird that the function documentation doesn't come up right away but here i guess is the whole random package so it'll be in here somewhere yeah there it is um and you can look through and see what what all of the parameters are it should say somewhere whether it is replaceable oh yeah sampling without replacement so it's not going to put anything back okay so we have this this sample from our array and we can see that we can do this in python so now i'm going to demo this using our full population so i'm imagining i'm the researcher and i'm going to go in and as the researcher i'm going to find a sample or a subset of people in this population and i'm going to collect their salaries so let's uh let's do it this way i'm going to call this samp1 and i'm gonna pass in what did we call it hourly pay uh actually okay just to make everything super super clear i'm going to say i'm going to resave this as something called population i'm going to save it as a list but i'm just saving the exact same numbers again so that we're really clear that this is the the full population and then this is going to be our sample so we'll sample from that population and i don't know jamie pick a pick a number how many do we want to sample from it uh 20. okay let's sample 20 people to start and then let's print out the mean of our sample and it was 17.24 interesting okay we could do this as many times as we wanted so if we do this again because this is random sampling we're going to get different samples every single time so i'll do it again we got something different i also think so i'll show you really quickly pissed stamp one um okay let's pick uh let's pick a slightly larger sample size let's do like 150 so we can really see it if we look at this histogram right of a sample of 150 people from our population you'll notice that it looks pretty similar to our original histogram that we made right like so our original one looked like this there was a spike around zero um then there was this long tail most of the the density of this thing was between 0 and 20 then 20 to 40. and if we look back at this we see kind of a similar shape right we've still got this low spike we've got some den some high density between 0 to 20 some like medium density from 20 to 40 and we've got this kind of long tail obviously it's a little bit sparser um but we still we see a similar shape and we see that this mean for our sample 18.65 is kind of pretty similar to the mean for the overall population and no matter how many times we do this taking different samples of 150 people from our population which let's see how big is the population can i do one on this actually don't know yeah uh okay that's three minutes well i guess this is not the whole population because it's not as long as it would need to be but you'll have to suspend disbelief so we've got like three million in here um we can imagine that the population is something else i don't know okay so but we we do see right that no matter how many times we do this we're going to get a sample that's somewhat similar to the population it's not going to be exactly the same it's going to be slightly different every time there might be different outliers that show up like this one randomly has two people i think out in this uh like over a hundred per hour category which is kind of surprising given how rare that is in the full population but sometimes just by random chance we'll get those people so okay and the framework that we're now going to take so do this one more time because it's kind of fun we're going to think about what happens if we do this a lot of times so now that we have pretended to be the researcher we've taken a sample from our population we have taken a look at it and seen that it's similar to the population but there's some variation in there sometimes we get a high mean sometimes we get a low mean compared to the population mean now we're going to go back to uh now we're gonna go back to all powerful mode okay so in our allpowerful mode what we're gonna do is we're gonna repeat this process a whole bunch of times so jamie what kind of uh coding technique do you think i should use to repeat this a bunch of times or what do you have any ideas how to how i could kind of go about that yeah so i guess if we want to basically repeat the same pos repeat the same process a lot of times we might maybe want to use some type of loop like have it automatically do it yeah yeah so instead of just pressing this run button a bunch of times and seeing what the output is i'm gonna use a for loop um and i could use a different kind of loop actually uh there's nothing i could use like a while loop as well um but i'm just gonna use a for loop because it's easy um and what i'm gonna do is i'm gonna say for i and range i don't know like 10 000. what this is gonna do is it's gonna repeat the process that i tell my that i tell python to repeat it's gonna repeat it 10 000 times um it see might seem a little bit silly that i have this like i here where i say for i and range 10 000 um i'm not going to use it for the purposes of what we're doing here i'm really just setting this up because i want i just want something to to happen ten thousand times i want to kind of like essentially if i was coding something else right every time this whatever code i put down here under the for loop would happen every time that would happen i would increase by one and it would or it would start at zero so go zero one two three four um right so like if i print four i in range ten print i and i uh and i run this i'm just going to get the numbers 0 through 9 because i is going to be 0 the first time then it's going to be 1 then it's going to be 2 and it's going to happen 10 times in total and it's going to print out the value of i each time but i'm just not going to use i because i don't need it i just need something to happen 10 000 times or a large number of times okay actually good coding practice is to never start a loop by repeating something 10 000 times because if you screw up the code uh then it can get stuck and like quit out on you so i like to start with like 10 and then we'll we'll iterate on this so i'm going to kind of grab my code from up here i've got population has already been saved and every time in this loop what i'm going to do is take a sample call it sample of some number of observations and then i'm going to calculate the mean of the sample actually i'm going to call this samp because another good coding practice is to not name variables the same thing as functions um because that can sometimes get a little bit mixed up great okay so i'm going to calculate the mean of sample but i don't want to just calculate the mean and just let it go i want to save it somewhere so uh jamie do you have any ideas for how i could save it yeah so we're probably going to want to save more than one of these because you're going to be iterating a lot so we could save it inside of a list cool so maybe we can make like a list outside of the for loop that is empty that we can just add stuff to it yeah so i'm going to create an empty list called samp means perfect and then i'm going to say samp means dot append which means append that value onto the list um and i'm going to append the mean of that particular sample so uh okay and now i'm just going to print out what this looks like after 10 iterations and we'll take a look at it cool so all of all of what we've done here is we've taken 10 sam 10 different samples of 150 each for each sample we calculated the mean and we saved that in our list so the first sample mean was 20.68 this next one was 19.35 then 18.66 and so on and so forth uh i see that i saw that there was a question about um memorize memorizing and knowing how the number goes so yes uh i think jamie responded but if you could clarify that question i would be happy happy to answer it um okay so all right so we've done this we've confirmed that we can do it 10 times and we can collect 10 sample means and now i'm gonna do it a whole bunch more times i'm going to do 10 000. i'm gonna run it i'm not gonna print it anymore because that's gonna be 10 000 numbers but what i will do is i i'll make an will of it this will take a second to run cool cool interesting okay so let's break down what this picture is telling us so remember that what we did as all powerful beings is that we collected 10 000 different samples each sample had 150 people in it for each sample we calculated the mean and then we plotted a histogram of them um when we plotted this histogram we saw that it looks kind of symmetrical part of the reason why i chose this data is because i think this is really a stark contrast to the population distribution which i think is interesting so like this population distribution i would describe as very right skewed right there's this very very long righthanded tail and most of the data is on the low end of the distribution but here and that's true right for all of the individual samples that we took all those individual samples are also right skewed but suddenly when we calculate sample means and we plot a histogram of all of the sample means we get this really nice symmetrical distribution and if we calculate the mean of all of the sample means it's going to be so it's like 18.82 about which is almost exactly the same as the the true population mean and maybe that feels i don't know to me that feels like it makes sense that the mean of the means like the middle of the means of all these samples is going to be equal to the population mean but it's actually like a super super powerful statistical theorem that is not i mean we take it for granted like uh what this what this means in like and i don't mean to use mathy terms but there's uh this is called a unbiased estimator so the mean is is called an unbiased estimator of the population mean which means that if you take a bunch of samples from a population and you calculate the mean for each one on average those sample means will be the same as the population mean but that's not necessarily true for for example if you calculate standard deviation or variance of a population it's almost an unbiased estimator but that's why there's a difference i don't know some of you may have seen this so there's a difference between calculating population standard deviation and sample standard deviation you divide by n in one case and you divide by n minus one in the other case and the reason for that is that if you divide by n it becomes a ever so slightly biased estimator um of the population standard deviation and if you think of something like the maximum of a data set which is another statistic that we might use so like we might calculate the maximum uh salary in each sample like that might be something that we're interested in if we count if we take the maximum of all of these population or all these samples and plot a histogram of the maximums it's not going to be centered at the population maximum so it's it's not true for all statistics that this lines up but for the sample mean it does and it's really really nice that it does okay so i guess the first question is why is this so valuable and the reason it's so valuable is that it allows us to understand uncertainty and uncertainty is really the key to statistics and inferential statistics specifically because again put yourself in in the feet of or in the shoes of a researcher um again i like that marketing example if you're like you're trying to figure out what proportion of visitors to a website will press my green subscribe button and you can only sample a thousand people you can only show the button to a thousand people and observe what they do you need to know how cert let's say you find that ten percent more people push the button if it's green than in the old version you need to be know how certain you can be that it's really ten percent and not negative one percent right like maybe in the population it's negative one percent but you just found in your random sample 10 more press that button and in this case right like if if you find as the researcher that the average salary is 16 an hour you want to know how certain you can be that that lines up with the population average salary if that's what you're trying to estimate you want to know how far off you could be and that's what this tells you tells you how far off you could possibly be because it gives you a sense of how spread out these numbers and how spread out the sample means are if you were all powerful and you could take a bunch of sample means of that size you this tells you how spread out they could possibly be um so i guess one of the things that i'll point out here um and maybe we intuit it but i think it's like a powerful thing to show is uh what happens when we change the sample size so what i'm going to do is i'm actually going to i'm going to uh make sure that we plot this on the same axis every time i'm gonna set plt dot x slim of 0 to 40. uh and i'll plot this again yeah okay so i'm just plotting this from 0 to 40 so we can see the full whole thing if i do if i do this again with let's say a sample size of a hundred instead it's going to be a little bit wider let's pick something lower really show it i'm gonna sample size of 50. okay so now we can see right this distribution when we took samples of size 50 it's going from the sample means are going from 10 all the way up to 30. here they're going between like 15 and 25 which makes some sense right because if you think about it if you take a bigger sample it's more likely to be representative of the population then if you take a small sample then you could have outliers that throw everything off the other thing that i won't demo here but that the other thing that can influence this the width of this thing is the amount of variation in the population so if the population has a lot of variation the width of this thing will be bigger and if the population has very little variation like let's say everybody's salary was around 20 instead of that spread out distribution that we saw before going all the way up to 140 then there's just going to be less variation in sample means by default right like if everybody was making 20 in the most extreme case then all of the sample means would be exactly 20. so however however much variation there is in the population will also influence this so what i'll show i think like a cool thing to see just to kind of verify it even is that and this is the the official central limit theorem that we're getting to now is that um we can basically describe exactly what this shape is going to look like mathematically without having done what we did here which is take all of these sample means i'm gonna plot this again but this time i'm going to i'm gonna grab some kind of this is again like a little bit i don't mean to just like pull fancy code and make everybody accept it um but i'll talk through what this is doing so on top of this histogram what i'm gonna do and i'm gonna normalize the histogram which means or actually i'm gonna switch to a disc plot um what i'm doing here is i'm i'm normalizing the histogram so here the histogram is going from 0 to 600 on the yaxis these are frequencies and if i were to say density equals true here or if i use disk plot and i'll demo that in a second all that does is it changes this yaxis so that the scale of this is such that the total area of this thing adds up to one um this is so that it mimics what's called a probability distribution function which you don't really need to know too much about right now but that allows us to compare this to kind of mathematical functions um and if we do dist plot here it does the exact same thing it also um puts what's called a oops oh yeah it doesn't take bins and also um oh it's sms bad it also gives you this kernel density estimation again not super important all you need to know is it's kind of like a smoothed version of this histogram so it's trying to like smooth out this uh this shape so if we do this um okay what i've done i'm gonna walk through what this code is doing or maybe jamie do you wanna walk through try to walk through what this code is doing i'm putting you on the spot a little bit yeah sure um let me just change some things okay okay so the where should i start from should i start from you and sigma or so i guess mu is just the population mean um i'll come back to this in a second so maybe start with this what is this lin space things so linspace mu minus three times sigma oh so i think linspace you're basically setting up like an interval range using mu and sigma um which i think sophie said she'll come back and explain what sigma is but basically it's going to set a range of values in a variable called x and then you're going to plot that range of values um and then what is stats.norm.p i think that's just like to like give a normal distribution with the given x and yeah give with the given range of values mu and sigma so i'll demo this part really fast actually i should have done just like 10 numbers um all that linspace does is it says okay start at 0 end at 1 and give me 10 numbers that are equally spaced so this just gives me 10 numbers between 0 and 1 that are equally spaced apart and all i'm doing here is i'm saying basically this is something that is not super important but this gives me a sense of how wide the xaxis of my distribution is going to be um basically i'm just saying like what's the lowest number i need to plot here what's the highest number i need to plot here in order to fit this on my graph and i'm getting a hundred numbers and then i'm going to get essentially the normal distribution version of this a normal distribution again is a probability distribution and all you need to know for right now is that it describes a particular shape of this distribution mathematically and so i'm plugging in all of those values that i just got between the two ends of that distribution calculating how high that line needs to be and i'm just using them to draw that line on top of my graph and when i do that oh it's because i did this again uh did i not save this sorry guys oh um sci pi import stats okay gonna run okay there we go so what you see here is i've drawn in black what's called the normal distribution on top of the distribution that we got just by taking samples of size 50 and plotting the um and collecting the means for each sample and what you see here is that it's basically the same thing so i've used like a mathematical formula to say what the shape can look should look like and then we've kind of proven what that shape actually looks like by taking the samples and what i've done here is i've drawn a normal distribution that has a mean that's equal to the population mean and a standard deviation that's equal to the population standard deviation divided by the square root of the sample size that's what this um double times sign means to 0.5 so taking something to the 0.5 power is the same as taking the square root of it so 50 times times 0.5 is the square root of 50 and then so this whole thing is standard deviation of the population divided by the square root of the sample size and we see it that if we take a normal distribution with those parameters again mathematical description of a curve it really perfectly matches up with what this this shape looks like and this piece the standard deviation of the population divided by the square root of the sample size this is what's called the standard error of the mean so um sophie uh you have a question from the chat which is asking which part of the like code you made was like the actual normal distribution was the actual normal distribution perfect i should have commented this out so this part here i'm just plotting the sample means this part here is where i'm plotting the normal distribution on top of it great awesome so yeah i think this i mean we're gonna run out of time for all the things i want to cover today but i do think like just taking a second to stop and look at this picture makes me just really happy it's really really beautiful because we've statisticians have like it seems like almost magically figured out these crazy formulas to describe things that seem i don't know hard to describe and um and it's really cool that that we can that we can quantify our uncertainty in this way okay so again coming back to the standard error piece so the standard error again is the standard deviation of this sampling distribution it's basically a measure of how wide is the sampling distribution and the sampling distribution again because i i feel like no matter how many times i i heard this when i was first learning it it like took maybe a hundred times of hearing this before it clicked in my brain um the sampling distribution we got from taking samples of the same size calculating the mean for each one and then plotting the distribution of the means the standard error is how is a description of how wide that distribution is okay all right so we've we've made it pretty far we've gotten some interesting things already out on the table now so we were in all powerful mode we made this distribution we saw what it looked like we proved to ourselves that the central limit theorem works um i don't even think i said what the central limit theorem is but we just proved it basically um without even using any math which is super cool the central limit theorem just says that this distribution is normal and that the mean normally distributed so it follows the shape the mean is the same as the population mean and the standard deviation is equal to the population standard deviation divided by the square root of the sample size that's the whole central limit theorem um you could do it with math or you could do it by actually taking all those samples and calculating the mean of each one okay so now let's go back for a moment to the perspective of the researcher so like all right back in researcher mode i should have put these in the final code would have been helpful uh okay so we're back in researcher mode and now we're not all powerful anymore we can't actually see what this distribution or we can't actually see the whole population so we can't take samples from the whole population and see what the distribution looks like but now that we have the central limit theorem we actually kind of can see what it looks like or we can approximate what it looks like so remember the things that we needed to plot that black line so to plot the blue histogram we needed to take samples from the full population but to get the black line all we needed to know was the mean of the population and the standard deviation of the population and the sample size other than that we didn't need any more information so we can approximate this if we have an estimate of the population mean and of the standard deviation of the population and we're going to get those things from our sample they're not going to be perfect we don't right we don't know what the population mean is anyway we're trying to estimate it um the sample standard deviation like i said it's going to be an unbiased estimator of the population mean if we calculate it with that n minus 1 on the denominator which we will but it's not going to be perfect we can still do it though so let's go back uh i'm again going to print the mean for our sample i think we still have a sample sample one somewhere in our or what did i call it let's see yeah we called it stamp one we still have a sample in here somewhere let's actually let's like calculate a new one oh that was a good one it was low okay okay so we have a sample let's calculate also the standard deviation of that sample and i'm going to save those things sample mean equals and populate or sorry sample standard deviation and we'll print them and we see okay so the the sample mean is equal to 16.33 the population or sorry the sample standard deviation was 13.21 um okay all powerful mode for a second let's remind ourselves of what these values r for the population so um print see v dot mean of population and also for standard deviation okay so what we notice here is that our sample that we took had less uh less variation than the population so the sample standard deviation was 13.2 the population standard deviation was 18.1 um so we're gonna under estimate the amount of variation in the sample the larger the sample we take the better of an approximation we're going to get here but we're going to work with it because it gives us at least some sense back to researcher mode so as the researcher we're now going to estimate what this distribution looks like so i'm actually going to grab this exact same code but now we're going to do this with the um we're going to do this with the sam just the information from the sample so we have our sample mean we have our sample standard deviation we're going to use a mu which is really just the mean of this normal distribution of the sample mean and we're going to use the sample standard deviation here and i believe that that sample had a was a size 150 but we'll just do one sample one that will tell us how many values are in there um or even i think even clearer is to say sample size equals that so we're really clear and then we'll put sample size in this equation and if we plot this we get this this curve um it's going gonna be i should maybe plot it on top of this so it's gonna be more s um or actually maybe less spread out than this it's going to be a little bit off from what it should be uh that's more off than i thought it would be or it's smaller oh oh oh it's because this was a sample size of 50. sorry ignore that uh let's redo this i guess with a sample size of 150. i know we're gonna run out of time but now this will right so this is our estimation of this is a little bit off pretty much because this this estimate was so off but what we can do is now use this distribution to try to estimate the plausible range of what values we might get if we could observe the entire population and take samples from it so the the reason why these two distributions are offset from each other is because this one we centered at the popul or the sample standard deviation this one we sent centered at the population standard sorry at the sample mean for this one at the population mean for this one so they they're off from that but the width of it is the part that we really care about and even though we were pretty far off on our sample standard deviation compared to the population standard deviation this the width of this distribution is pretty close to the width of what we would find if we were able to like be all powerful and see and take samples from everybody and so what we end up doing is we end up using this this distribution here to figure out or a plausible range that the population mean might be in and so we end up saying that the population mean is somewhere between like we think 12 and 20 or whatever like these points are and we can we can choose percentile so we could do like the second percentile and the 98th percentile to cut off kind of the tails of this but that's really all that a 95 confidence interval is and i can demo that super fast i know we're running out of time um but i also know that this is a super complicated uh a super super complicated process and like exp mind experiment so i think it's nice if we kind of stop here and get like three more minutes to talk about it a little bit so here we go all i'm doing here is i'm taking i'm trying to find like the 2.5th percentile and the 97.5th percentile of this black line um oops let's put stamp one here and i save this as standard error i saved it as sigma so this goes from roughly 14.22 to 18.45 and so if we were the researcher we would say our sample mean was 16.33 but we are 95 confident that the true population mean is somewhere between 14.2 and 18.45 which is accurate although it is really close to that upper bound which was you know a random fluke and that happens but this is the way that statisticians and data scientists use the central limit theorem to try to quantify their uncertainty about a sample mean without having been able to see the entire population cool so i'm gonna stop there we've got two minutes to spare jamie what do you think would be a good use of this time do you think there's anything that's worth like talking about i hadn't had a a good eye on the stream or on the chat were there any questions that came up i think we covered all the questions wait one thing i'm curious about what was the actual population mean because i'm wondering if it was actually within the 95 the population mean was 18.84 about 839. okay and so it was like just just barely yeah but it wasn't in that range we could kind of do this with another sample like if we i wish i organized my code better but uh it's organized better in the final version that is available on github but if i take another sample here let's find one that seems like similar to the population yeah that seems more similar to the population if we use a different sample where these things yeah so here this one we got a little bit closer in terms of standard error and pop and mean like our sample was more similar to the population and then that will give us a slightly yeah uh a confidence interval that makes that more comfortably includes the population mean um so again like the i think the thing that i had trouble conceptualizing for a really long time is that the central limit theorem tells us something about the shape of this black line but it can't really tell us we still have to make a leap there because we still don't know what the population standard deviation is we still have to estimate the population standard deviation using our sample and so it's not like totally magic that we can just recreate exactly this but we can get a pretty good read on at least how how much variation we can expect and i think that's that is the the true power um and i i encourage so there's um on codecademy there is a article on the central limit theorem that kind of walks through this again and so if you watch this series and you still feel a little confused or you still want to like go back and confirm your understanding i highly recommend that you read that article or look up on the internet central limit theorem and and read about it because i think this is one of those things it's like it's deceptively simple and also really deep and uh and i think even for me i learned it about like i said like a hundred times before i actually learned it so all right next week we're going to jump into actually using this central limit theorem to run some hypothesis tests and we're going to learn even more about how hypothesis tests work so i'm really excited for that um but otherwise uh thank you kevin for for that question kevin says i have a question why are there only so few people watching this is pure quality thank you i agree i well i don't know about quality but i'm having a lot of fun doing these and hopefully more people will find them after the fact but for those that are here you get the extra benefit of being able to ask questions and really speak with us personally so please take advantage all right with that i think we'll sign off everyone have a great rest of your tuesday and we hope that these are helpful goodbye
