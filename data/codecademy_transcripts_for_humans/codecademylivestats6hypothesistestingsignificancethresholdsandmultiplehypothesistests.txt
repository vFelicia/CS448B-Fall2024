With timestamps:

00:01 - i know it says we're live but
00:03 - i don't believe it i don't believe it
00:06 - until i see it
00:11 - okay we're good to go
00:14 - all right hi everyone uh
00:17 - i hope that everyone is having a good
00:20 - tuesday
00:21 - and i'm excited to get into uh
00:24 - our week six topics um
00:28 - i think we had a little snafu with the
00:30 - timing on the youtube page so
00:32 - it's possible uh that people will be
00:34 - filtering in
00:35 - slowly uh today but if you're here and
00:38 - you're live
00:40 - ask us any questions you have on the
00:42 - youtube chat and we will
00:44 - make sure to address them uh
00:47 - cool so i think we can get started
00:50 - pretty quickly this
00:51 - this time around um i have something
00:53 - that i want to address
00:55 - from last week uh a small correction so
00:59 - i'm gonna start with that and then we're
01:00 - gonna get into the material for this
01:02 - week
01:03 - so with that i will share my screen
01:06 - yeah i saw you posted a comment on the
01:08 - last video so this is also in the last
01:09 - video but
01:10 - uh something that we were going over
01:13 - that
01:13 - um uh i was either said incorrectly or
01:17 - you just want to go
01:19 - oops sorry i shared the wrong screen
01:23 - yes exactly
01:27 - all right sure
01:30 - all right um yeah so this was a really
01:32 - quick
01:33 - edit from last week and this was related
01:36 - to a
01:36 - really good question that alex asked so
01:40 - um it comes back to our discussion of
01:43 - how the binomial distribution
01:44 - is pretty similar to the normal
01:47 - distribution
01:48 - except for um except that it's discrete
01:52 - uh which means that like you can only
01:55 - have
01:57 - the numbers one two you can only have
02:00 - integer values
02:01 - um along your x-axis and i kind of walk
02:04 - through the
02:04 - exam or i talk through how the
02:08 - central limit theorem sort of applies
02:10 - and um at one point alex asked if we
02:12 - could
02:13 - see how the the width of the
02:15 - distribution changes for different
02:16 - sample sizes
02:18 - and we didn't get to it but uh off
02:21 - as i was thinking about it later i
02:23 - realized that actually
02:25 - what we were looking at last time and i
02:27 - think we still have it
02:28 - was we were looking at a histogram of um
02:32 - in this case the number a number of
02:34 - purchases or earlier we were looking at
02:36 - a histogram
02:38 - of coin flip results where each number
02:41 - on the x-axis represented
02:42 - a number of coin flips that resulted in
02:44 - heads um
02:46 - but this example
02:50 - of a normal or this example of a
02:51 - binomial distribution if you think about
02:54 - whether you flip
02:55 - 500 coins versus 10 coins um
02:58 - the 10.1 is going to be less
03:02 - the distribution for 10 coin flips
03:05 - the distribution of the number of heads
03:06 - for 10 coin flips is going to be
03:09 - um thinner than this distribution just
03:12 - because the number
03:13 - there are less numbers between 0 and 10
03:16 - than there are between
03:17 - 0 and 100 so what i
03:20 - everything i was saying only applies if
03:22 - you
03:23 - divide each of these numbers by the
03:25 - sample size
03:26 - so just demoing it down here and the
03:29 - intuition
03:30 - like makes a lot of sense and i feel
03:32 - like people probably intuited this at
03:34 - the time
03:34 - but if you flip 10 coins and you record
03:38 - the proportion of heads
03:39 - instead of the number of heads and plot
03:42 - that distribution
03:44 - you could get anywhere from zero to a
03:46 - hundred percent heads
03:49 - in infinitely many coin flips
03:52 - whereas if you put if you flip a hundred
03:55 - coins
03:55 - um you're more likely or 500 coins i
03:59 - think in this example
04:00 - you're more likely to get closer to 50
04:04 - heads you could still potentially get
04:06 - zero percent heads but it's a lot like
04:08 - it's like
04:09 - so much more minuscule it's not even
04:11 - gonna happen in our
04:12 - in this simulation um and so
04:16 - so so this example the blue histogram is
04:19 - uh 10 um what's the terminology 10
04:23 - attempt 10 coin flips
04:24 - 10 like attempts or something like that
04:27 - yeah so
04:28 - this is we repeated this process a bunch
04:30 - of times
04:31 - each time we flipped 10 coins and we
04:34 - recorded the proportion of heads in each
04:35 - of those
04:36 - 10 flips and we did that and then the
04:40 - orange is 100
04:41 - 500 or something like that i think the
04:42 - orange i i made it 500 but yeah you can
04:44 - see
04:45 - and the histograms look a little funny
04:47 - because of how the x-axis
04:49 - shows up but um but you get the idea
04:51 - that it's basically
04:52 - you can be more confident about the
04:56 - proportion
04:56 - of heads that will come up the more
04:59 - times you flip the coin
05:01 - okay cool and yeah and and again the the
05:04 - correction from last week is we weren't
05:05 - talking last week we didn't specify
05:07 - that's the proportion
05:08 - if you scroll back up to that other
05:09 - graph we were talking about like the
05:10 - overall number
05:12 - and so of course when you're flipping
05:15 - a hundred coins the number of heads can
05:17 - range from zero to a hundred
05:18 - versus ten coins it can only be zero to
05:20 - ten so like by definition
05:22 - that range is going to be smaller but
05:23 - you know that's not what we're actually
05:24 - interested we're interested in the
05:26 - percentage or proportion exactly cool
05:29 - makes sense
05:29 - so with that um i'm going to move to
05:33 - today's topic which i think is a really
05:35 - fun one
05:36 - and we're going gonna use the same data
05:38 - in the same framework as we did last
05:40 - time just to keep things simple
05:42 - um but we're going to talk
05:45 - about the issue of multiple hypothesis
05:49 - tests and we're going to talk a little
05:50 - bit more so
05:52 - last week we we introduced the idea of a
05:54 - p-value
05:56 - as being like an outcome of a hypothesis
05:58 - test
05:59 - um and we'll we'll review a little bit
06:02 - what that
06:02 - definition of a p-value was but then
06:05 - there's another question about
06:07 - what to do with that p-value value
06:10 - and in order to answer that question
06:13 - we're going to need to
06:15 - think a little bit more deeply about
06:19 - about what it means to make a decision
06:22 - based off of a probability
06:24 - so that's the that's the topic for today
06:28 - and this is really important because you
06:30 - may have heard
06:31 - of the reproducibility crisis
06:35 - in statistics um which is the idea that
06:38 - a lot of published research can't be
06:40 - reproduced like people aren't getting
06:43 - the same findings when they try to
06:45 - do the same study over again um
06:48 - and that issue is related to
06:52 - what a lot of people call p hacking um
06:56 - which is going to be a topic of today
07:01 - so with that uh let's jump
07:04 - in so a quick reminder from last week
07:08 - i'll actually
07:09 - pull up um pull up our code from
07:13 - last week and so as a quick recap
07:16 - we were looking at this situation where
07:18 - we had
07:19 - some data about uh people making
07:22 - purchases
07:23 - on a website and we had a sample of 500
07:26 - people
07:27 - and we expected the purchase rate to be
07:30 - 10
07:31 - and we wanted to know if the purchase
07:34 - rate was
07:35 - significantly less than that because we
07:37 - thought there was some sort of bug or
07:39 - we had changed something where we
07:41 - thought the purchase rate
07:43 - might go down we want to check that
07:45 - assumption so we ran this test
07:47 - where we collected our sample we have
07:49 - 500 visitors to a web
07:51 - website who saw this thing and we saw
07:55 - that
07:55 - i think it was like uh like
07:59 - eight percent made a purchase i forget
08:01 - like 41 out of 500 whatever that was
08:03 - yeah so 41 out of 500 so less than our
08:06 - expectation made a purchase
08:08 - um right if it was 10 it would be 50 and
08:11 - we saw only 41
08:12 - made a purchase and then we talked about
08:14 - how
08:15 - um the outcome of this hypothesis test
08:18 - is
08:18 - we could kind of say well if the
08:20 - purchase rate was what we expected
08:22 - then we would expect 50 purchases but if
08:25 - we repeat this process
08:26 - randomly a bunch of times and give
08:29 - everyone a 10
08:31 - chance of making a purchase we still see
08:33 - a range in the number of purchases
08:36 - that happen among 500 people in
08:38 - simulated samples
08:40 - and so based off of that we estimated
08:42 - this p value which was
08:44 - the probability that
08:47 - a randomly sampled group of people a
08:50 - group of 500 people
08:52 - made 41 or fewer purchases given that
08:55 - the true
08:56 - probability of a purchase was 10
09:00 - um and that was that's our
09:04 - p value it came out i think to like 0.1
09:06 - um
09:07 - we did it using simulation we also did
09:09 - it with a built-in function and
09:11 - both times it came out to around 0.1 and
09:13 - so that's
09:14 - that's a probability um and it can be
09:16 - interpreted right if we
09:19 - if we got a really low probability so
09:21 - like let's say
09:22 - we observed only 30 purchases in our
09:26 - sample
09:27 - then the probability would just be like
09:30 - the area of this tiny little block to
09:32 - the left of 30
09:34 - divided by the total area of the whole
09:36 - thing so it'd be a really small number
09:39 - and right and intuitively right if we
09:42 - say the probability of making
09:44 - 30 or fewer purchases given that the
09:47 - true probability of a purchase is 10
09:51 - if that probability is really small then
09:53 - it's unlikely
09:54 - that um it's unlikely that the purchase
09:58 - rate really was
09:59 - 10 in that case so we're making some
10:02 - estimate of
10:03 - how likely is it that the null
10:05 - hypothesis
10:06 - is true given what we observed
10:10 - right and i think uh you might go into
10:12 - this in this lesson sophie but i think
10:14 - a lot of times or the thing that i know
10:16 - about p-value is that like
10:18 - 0.05 p-o value 0.1 p-value right like
10:23 - we're saying that okay at this level we
10:25 - can reject the null hypothesis
10:27 - because um you know the probability of
10:30 - purchase is
10:31 - ten percent or you know in the other
10:33 - case it'll be like two percent if we saw
10:35 - um if we saw 30 purchases instead of
10:39 - um instead of 41. so why
10:42 - why those values why 0.5 and
10:45 - 0.1 as like the values where you say
10:48 - like this is
10:48 - when we can reject the null hypothesis
10:50 - yeah so we're actually gonna just
10:52 - jump right into that right now so um
10:55 - so what alex is alluding to is that
10:58 - um i think we all if we're all okay
11:02 - with the idea of a probability or
11:05 - hopefully we feel comfortable with the
11:06 - idea of the probability
11:08 - but sometimes you need to use that
11:09 - probability to actually make a decision
11:12 - so
11:13 - in this case it's maybe maybe the
11:15 - example that i came up with
11:17 - isn't super conducive to this but let's
11:19 - say that
11:20 - um let's say that what we were doing was
11:23 - we tried out some new version of our
11:26 - website that's
11:27 - cheaper for us to build and um
11:31 - and so we expected the purchase rate
11:33 - might go down
11:34 - we wanted to know if it really did go
11:36 - down or not
11:38 - and if the purchase rate didn't go down
11:41 - significantly with our new
11:44 - cheaper version of the website then
11:47 - we're going to
11:48 - implement the cheaper version of the
11:49 - website because it will save us money
11:51 - but if the purchase rate went down
11:53 - significantly then
11:54 - we don't want to implement it and so we
11:56 - have to make that decision
11:58 - implement don't implement based off of
12:01 - this number and
12:04 - if we're going to do that we don't
12:06 - really want to like
12:08 - i think in general we often want to
12:12 - have some cut off for ourselves like
12:15 - this is a probabilistic
12:18 - number the p-value is a probability um
12:22 - but we're not necessarily comfortable
12:25 - with the idea that like
12:26 - there's just a 10 chance that
12:30 - the purchase rate really did drop at a
12:32 - 90
12:33 - chance that it didn't or whatever we
12:35 - want to
12:36 - um or whatever we want to
12:39 - ascribe to this we want to actually use
12:42 - that probability to decide like is it
12:44 - worth making this decision or not
12:46 - and so a way that people do that
12:49 - is they choose a threshold and they say
12:53 - okay any p-values below
12:56 - this threshold i'm gonna deem them
12:59 - significant what that means it or
13:03 - i'm gonna decide to reject the null
13:06 - hypothesis which is the
13:07 - um the wording that alex used and the
13:10 - idea here is that
13:12 - the null hypothesis in our example was
13:15 - that the probability of a purchase is 10
13:18 - if we get data
13:21 - that challenges that null hypothesis
13:24 - that makes it
13:25 - unlikely that that null hypothesis is
13:27 - true then we're gonna reject it
13:30 - and say okay it's unlikely that the null
13:33 - hypothesis
13:34 - is true therefore i'm gonna say that
13:36 - it's more likely or therefore i'm gonna
13:39 - accept
13:40 - or i don't know people use different
13:42 - language
13:43 - uh usually we don't say like accept the
13:47 - alternative but you say i reject the
13:49 - null hypothesis in favor of the
13:51 - alternative which is to say that we
13:53 - haven't proved
13:54 - that we haven't calculated a probability
13:57 - of the alternative hypothesis we've only
13:59 - calculated a probability of the null
14:01 - hypothesis
14:02 - and then said that it's unlikely um and
14:05 - so
14:05 - a common choice for that threshold at
14:08 - which we say
14:09 - will reject the null hypothesis is .05
14:14 - um but lots of people use .01
14:17 - or um or a different threshold or 0.1
14:21 - um so there's some choice in that and we
14:25 - need to decide it ahead of time
14:27 - um in this case yep i hear i see someone
14:30 - wrote fail to reject so
14:32 - in this case if we got a p-value of
14:34 - about 0.1
14:35 - and if we set a significance threshold
14:38 - of 0.05
14:39 - we would fail to reject the null
14:41 - hypothesis because
14:42 - 0.1 is not smaller than .05
14:46 - um and so the probability that the null
14:49 - hypothesis is
14:51 - untrue given our data data is not
14:54 - small enough for us to reject the null
14:58 - and so uh interesting thing with the
15:00 - language here is that yes is that
15:02 - then saying that we think that the
15:05 - probability of purchase is indeed 10
15:07 - or that we just don't think that it's
15:10 - less than 10 percent
15:13 - um no it's saying that we so if we
15:17 - oh you mean if we don't if we fail to
15:19 - reject the null if we if we fail to
15:21 - reject the null is that us saying that
15:23 - we think that it is
15:24 - that it remains uh 10 probability of
15:27 - purchase
15:28 - um no i mean
15:33 - depending on if you want to be technical
15:36 - about how you should interpret it
15:37 - but if you fail to reject the null
15:39 - you're basically just saying that
15:41 - there is not enough evidence
15:44 - that the purchase rate is not 10
15:48 - so um you can't say
15:51 - basically you can't say whether the null
15:54 - hypothesis
15:54 - is true or not right just that you can't
15:57 - that you can't accept this alternative
15:59 - hypothesis
16:00 - or you just say you can't reject the
16:02 - null
16:04 - i know it's like it goes in circles
16:06 - because
16:07 - uh and the language is complicated and i
16:10 - feel like it's been ingrained in me to
16:12 - be really
16:13 - careful about what language i use really
16:15 - precise
16:16 - um but yeah the whole framework of a
16:19 - hypothesis test is really about
16:22 - setting up the null hypothesis testing
16:24 - the null hypothesis
16:26 - and then saying whether you have enough
16:28 - evidence to reject the null hypothesis
16:30 - or not reject and
16:33 - that's like that's as far as you can go
16:36 - if you reject you're saying
16:38 - it's unlikely that the null hypothesis
16:40 - is true
16:41 - if you fail to reject then you're saying
16:43 - there's not enough evidence
16:45 - for me to say the null hypothesis is not
16:48 - true
16:49 - okay and that's a lot of words that i
16:51 - just said um
16:53 - and i know it's confusing so uh bear
16:55 - with me
16:56 - i think as you're learning this stuff
16:58 - you have to like
17:00 - do it a bunch of times try practice
17:02 - problems
17:03 - decide reject or fail to reject
17:06 - interpret
17:07 - and practice interpreting so that you
17:09 - feel comfortable with that idea
17:11 - yeah lots of double negatives like fail
17:13 - to reject is like
17:14 - a double negative of like oh we're
17:16 - failing to turn this thing down right
17:17 - it's uh i can see how it gets uh it gets
17:19 - confusing
17:20 - yeah okay so with that i'm gonna jump
17:24 - right in
17:25 - so um
17:29 - first thing i wanna do is
17:32 - i want to think through um
17:35 - in the same way that when we talked
17:37 - about the central limit theorem we kind
17:39 - of
17:40 - had this like all-powerful mode
17:43 - and in that all-powerful mode we got to
17:46 - know what the truth was
17:48 - and then um and then we kind of went
17:50 - into researcher mode where we didn't
17:51 - know where the what the truth was and we
17:53 - were trying to
17:54 - analyze something as a researcher we're
17:56 - gonna do the same thing
17:57 - for right now so remember that
18:00 - um that last time we looked at this data
18:04 - this was like a simulated data set
18:06 - 500 visitors to a website um and
18:09 - basically the important thing here is
18:11 - whether or not the
18:12 - each visitor made a purchase and
18:16 - in this data set we have um
18:20 - 41 purchases but we can recalculate that
18:23 - so
18:24 - i think we discuss such disrespect the
18:27 - importance of our
18:28 - uh items that we came up with uh i mean
18:31 - no disrespect at all i love this date i
18:34 - love this data set so much
18:36 - i just watch it here even though it's
18:38 - totally fake
18:39 - i watched love actually for the first
18:40 - time over the weekend so now i could uh
18:42 - be this purchaser of the cue card i wish
18:44 - i had watched it this weekend i totally
18:47 - forgot about that
18:49 - um did you enjoy it it was great
18:52 - very pleasant yeah
18:56 - it was just nice yeah it is nice
19:00 - okay so we'll just confirm there's 40
19:02 - oops
19:04 - i didn't
19:08 - yeah okay so confirming that there's 41
19:11 - purchases
19:12 - but now we're let's go back to what we
19:15 - were doing
19:16 - in the previous week so
19:19 - remember that last week we started doing
19:22 - this
19:24 - these kind of simulations where we said
19:26 - okay but what if
19:28 - the true probability of a purchase was
19:30 - 0.1
19:32 - i'm going to copy over this code so we
19:34 - don't have to rewrite it
19:37 - but for those that haven't seen that
19:41 - if you're just visiting for the first
19:44 - time
19:44 - um what we're doing here right is we're
19:46 - saying okay but what if
19:48 - in this data set we saw 41 purchases but
19:51 - what if the truth
19:52 - is that the probability of a purchase is
19:57 - 0.1
19:58 - and we simulate 500 new visitors so this
20:02 - data set has 500 visitors what if we
20:04 - simulate 500 new visitors and see how
20:06 - many purchases we get
20:08 - and remember that we expect 0.1 times
20:11 - 500 or 50 purchases but we're going to
20:14 - get
20:15 - some variation around 50 so this time we
20:17 - got 55
20:19 - um and every time we run this we're
20:21 - going to get a different number and it's
20:23 - going to be totally random
20:26 - okay so next thing i want to do is
20:30 - think about what would happen if we
20:33 - repeated
20:34 - this a bunch of times and instead of
20:37 - every time collecting the number of
20:39 - purchases what if
20:40 - every time we run this we
20:43 - run a binomial test and calculate
20:47 - a p p value
20:50 - okay so um
20:53 - let's let's try writing this out
20:56 - here i'll make a new
21:00 - so alex do you want to like walk me
21:02 - through
21:03 - yeah say that sentence again i think i i
21:05 - think i got lost so
21:07 - every time we run one of these um tests
21:10 - or run one of these simulations we're
21:12 - going to run a
21:14 - um p-test on it or we're gonna get a
21:16 - p-value for it
21:18 - yeah so we're gonna run a binomial test
21:22 - okay yeah so
21:25 - [Music]
21:28 - right
21:31 - this is this is gonna get like a little
21:33 - bit meta so
21:34 - um if if anyone is confused in the chat
21:38 - um please please please let me know
21:41 - um okay so each time i run
21:46 - this loop i'm going to simulate
21:50 - 500 visitors each with a 0.1 probability
21:54 - or 10
21:54 - probability of making a purchase
21:58 - i'm going to calculate the number of
21:59 - purchases
22:01 - but then what i'm going to do is i'm
22:03 - going to grab this code
22:04 - and i'm actually going to just grab the
22:08 - the binom test code so
22:12 - right because because last week what we
22:14 - did is we ran that a thousand times
22:16 - um and then made a distribution of like
22:18 - oh this time we saw 50 purchases this
22:20 - time we saw 45 and we made that
22:22 - distribution
22:23 - um now we're not making that
22:25 - distribution anymore we're just
22:27 - running the uh binomial test on it
22:30 - yeah actually you know what i feel like
22:32 - i skipped a step
22:33 - let me let me go back before we do this
22:36 - for loop
22:37 - let me quickly just demonstrate what i'm
22:39 - going to do
22:40 - inside the for loop but demonstrate it
22:43 - outside the for loop
22:44 - so right we have this process where
22:48 - here every time we're calculating the
22:51 - number of purchases
22:52 - in our simulated sample but what if
22:54 - instead of
22:56 - that we import this binome test function
23:00 - and then we run the binomial test
23:05 - the exact same test that we simulated
23:07 - last week
23:14 - and we'll do with alternative
23:18 - is less and instead of putting 41
23:22 - in here let's put in the number of
23:24 - purchases
23:25 - in our simulated test
23:29 - our simulated data set so the originally
23:31 - the 41 came from our real data of 41
23:33 - people
23:34 - um bought the item but let's see what
23:37 - happens if we do it
23:38 - with a random a random number
23:41 - yeah and actually each time i'm going to
23:44 - print the number of purchases
23:45 - and then i'm going to print the p value
23:47 - so you can see both of them
23:49 - so here we go
23:54 - all right this time we got 55 purchases
23:57 - and we got a p-value
23:59 - of 0.795 alex do you want to
24:02 - talk through like how would you
24:05 - conceptualize this
24:07 - p-value or how would you explain that
24:10 - p-value
24:11 - right so i'm visualizing the
24:14 - um the distribution right and so
24:18 - um we expect the um
24:22 - number of purchases to be 50. we saw 55
24:25 - and so we're saying if um
24:29 - if the actual number of
24:32 - or if the actual rate of purchase was 10
24:34 - which would give us our 50
24:35 - and we saw 55 percent there's a and we
24:38 - saw 55 purchases rather than 50.
24:40 - there's a uh 79.5
24:44 - chance that um
24:48 - that the uh the the true value is
24:52 - uh ten percent right
24:55 - or not sort of so we again it's like the
24:58 - double negative of like we can't rej
25:00 - it's not that it's 10 it's that it's um
25:03 - like can you write out the um null
25:05 - hypothesis for me
25:07 - yeah so the null hypothesis here i'll do
25:10 - it and mark down
25:11 - so the null hypothesis
25:15 - is that the purchase rate is 10
25:19 - and then the alternative hypothesis
25:24 - is that because we did alternative
25:26 - equals less the alternative
25:28 - hypothesis is that the purchase rate
25:31 - is less than 10
25:35 - right and so um
25:40 - like what i want to say is there's a
25:41 - 79.5 chance that the null hypothesis is
25:44 - true but it's not exactly that right
25:46 - so i would say there's a 79.5
25:50 - chance that um
25:53 - or sorry let me back up
25:57 - there's a 79.5 chance of observing
26:00 - 55 or fewer purchases
26:03 - given that the purchase rate is 10
26:07 - so because we had alternative equals
26:10 - less
26:10 - this is going to be it's going to be a
26:12 - probability of observing 55 or fewer
26:15 - purchases
26:16 - if the true purchase rate were 10
26:22 - um so let's do another one let's run it
26:24 - let's see if we can get something that's
26:26 - like
26:26 - less than 50. okay so here's 39.
26:30 - actually this
26:31 - this p value is pretty close to 0.0.05
26:35 - this is pretty close to our threshold
26:37 - even though
26:38 - right in our simulation the probability
26:40 - of a purchase was
26:42 - 0.1 no it was yeah 0.1 but we got a
26:45 - randomly really small number
26:47 - so this is saying that there's a 5.5
26:50 - chance of seeing 39 purchases
26:52 - given that the true purchase rate is 10
26:55 - yeah 39 or fewer purchases because yeah
26:59 - because the alternative was less than
27:01 - yeah right
27:02 - yeah something that's interesting so we
27:04 - uh in the last one that you ran
27:06 - i think the value the total number was
27:08 - like 62
27:09 - and so the p value was like 0.98 um
27:13 - which means that there's like a 98
27:17 - chance of seeing 63 or fewer
27:20 - purchases given that the total purchase
27:22 - rate is 10 which is like it's a little
27:24 - bit confusing because normally
27:26 - you know you're used to seeing like very
27:28 - small p values
27:30 - so i always come back to it has to do
27:33 - with the fact that we have
27:34 - that alternative equals less
27:37 - um contingency if we had um
27:41 - if we had changed the alternative or to
27:44 - uh both i think is how it's coded here
27:48 - or
27:48 - i think it's also the default then you
27:50 - get the um double-sided p-value it would
27:52 - have been really small
27:54 - for that value but um i think the i like
27:56 - to conceptualize it
27:58 - and i think i have some pictures
28:00 - somewhere i can
28:01 - like pull them up but i like to
28:03 - conceptualize it with this
28:04 - this image it this image so i think
28:07 - about
28:08 - that p-value as a proportion of the area
28:11 - of this blue
28:13 - histogram and so for when we had
28:16 - 41 the p-value was the proportion of the
28:20 - histogram that was
28:21 - left of 41. so that was about 0.1
28:25 - when we got 69 it was all the way over
28:28 - here
28:29 - and it was the proportion of the
28:31 - histogram that's less than
28:33 - 69 and so we got 0.98
28:37 - and could we could we see can we go back
28:40 - to our code and hard code in that
28:41 - 69 and see that it's 98 percent
28:45 - rather than purchases and then maybe
28:47 - flip from
28:49 - let's first see what it looks like with
28:50 - alternative equals less and then
28:53 - um here
28:56 - uh actually
28:59 - let me just create a new yeah
29:04 - right i'm sorry if this is a tangent no
29:06 - no no this is great
29:08 - this is a really helpful discussion
29:09 - because you feel like this is the kind
29:11 - of thing that helps
29:13 - um conceptualize the next steps i'm glad
29:15 - we're taking the time to do it
29:19 - okay so 99
29:23 - chance of seeing 69 or fewer purchases
29:26 - given a 10
29:27 - purchase rate which again if you're
29:28 - picturing that histogram that's like
29:30 - basically all of the area under the
29:31 - histogram but now if we switch to not
29:33 - less but the default which is like
29:36 - two-sided right
29:40 - so this is now saying there's a point
29:42 - seven percent that we're
29:44 - either above 69 purchases
29:47 - or below some very small value
29:50 - right yeah so i'm gonna just actually
29:54 - we're going to go to codecademy.com
29:57 - outlooker and
30:01 - let's pull up
30:06 - there's
30:14 - um thanks for hanging with me guys
30:18 - um i think it's in this lesson
30:29 - oh yeah right
30:33 - so i find this picture kind of helpful
30:36 - so um right
30:40 - the two-sided p-value which is the um
30:42 - which is the default
30:44 - is looking just at the probability of
30:47 - observing
30:48 - something as extreme or more extreme
30:51 - than
30:52 - um than what was observed in the data so
30:55 - in the case where we had a value of
31:01 - 69 we're like drawing we're drawing a
31:04 - line at 69
31:06 - shading everything to the right of 69
31:09 - red and then we're drawing we're saying
31:10 - okay 50
31:12 - 69 minus 50 is 19 so 69 is
31:16 - 19 units away from 50. so let's go 19
31:20 - units away from 50 in the other
31:22 - direction
31:23 - to 31 and let's also add in
31:26 - everything to the left of 31 right
31:31 - so um right so it's like distance away
31:34 - from the expected
31:35 - mean right versus what we did
31:39 - what we're doing before is we're just
31:40 - coloring everything with the alternative
31:43 - being less we're coloring everything to
31:45 - the left
31:46 - and then um if we get a high number
31:50 - then you're going to get a really large
31:51 - p value yeah and so going back to our
31:54 - code now if we
31:54 - i assume we can put in a parameter for
31:56 - the third value where we've done less
31:58 - and then
31:59 - two-sided can we put in greater than and
32:01 - see
32:02 - they'll like point the like one percent
32:05 - of
32:05 - uh seeing something greater than 69 um
32:08 - given the 10
32:10 - yeah so it's going to be even it's gonna
32:11 - be half as big as this
32:13 - right so if we do alternative
32:17 - i think it's just greater let's try it
32:21 - yeah yeah right and so again that's
32:24 - picturing that histogram
32:26 - finding uh your value and saying okay
32:28 - what's the area greater than that
32:30 - that area and it's um you know 0.5 of
32:32 - the total histogram
32:34 - yeah exactly cool
32:38 - um all right i'm glad we went on that
32:40 - tangent i feel like hopefully that
32:42 - clarified some things for people um
32:46 - and now we'll go and try to do this a
32:48 - bunch of times so
32:51 - in this case right if we and
32:54 - let's just like take it back to the um
32:58 - to the original goal of this
33:01 - right in this case if we had observed 69
33:05 - purchases and let's say we used our
33:08 - alternative
33:09 - hypothesis was that the purchase rate
33:12 - was greater than 10
33:14 - and then we observed 69 purchases we'd
33:17 - be
33:18 - pretty certain or we could be pretty
33:21 - certain that
33:22 - the null hypothesis is not true
33:26 - or in other words i should say we could
33:29 - be
33:30 - there's a very low probability that the
33:32 - null hypothesis is true
33:33 - in that case because 69 is so much
33:35 - different from our expectation
33:39 - and so if we were using a
33:44 - threshold of 0.05 to decide whether
33:46 - something
33:47 - whether we should reject the null
33:49 - hypothesis then in this case we would
33:52 - and the key that we're going to talk
33:55 - about now is that
33:56 - sometimes when we reject the null
33:59 - hypothesis
34:00 - we're going to be wrong right like we
34:03 - randomly simulated
34:05 - 69 visitors we did that earlier right
34:08 - completely randomly where the true
34:10 - purchase rate was 0.1
34:12 - um and so sometimes by random chance
34:14 - extreme things happen right like
34:16 - sometimes by random chance you um flip
34:20 - 100 coins and 80 of them come up heads
34:23 - or whatever it is so sometimes we'll
34:26 - reject the null and we shouldn't have
34:28 - rejected the null so that's where we're
34:29 - going
34:30 - but let's let's go through this so um
34:33 - here we've got
34:34 - all of this now i'm putting it inside a
34:36 - for loop so i'm just saying i want to
34:38 - repeat this a bunch of times
34:39 - each time i'm going to simulate my
34:41 - visitors with a
34:43 - 10 probability of a purchase
34:46 - then i'm going to calculate the number
34:48 - of purchases and then i'm going to put
34:51 - that into my
34:54 - um binomial test and i'm going to get
34:56 - rid of this alternative equals less
34:58 - but for some reason
35:02 - my computer doesn't like to
35:06 - i think it has something to do with zoom
35:09 - um okay
35:11 - and then what i want to do actually
35:12 - before this is i want to collect those p
35:15 - values from for further inspection
35:19 - so i'm going to say
35:22 - p vowels equals
35:26 - empty list and then each time i'm going
35:28 - to say p
35:29 - vowels call this a thing
35:34 - simpler like p val u
35:38 - and then we'll say p vowels equals p val
35:41 - stop append um p
35:44 - value thank you
35:49 - do you do the overwrite or can you just
35:51 - do p values dot append
35:53 - um what do you mean do you need to set p
35:56 - values equal to the new thing or can you
35:58 - just do
35:58 - p files oh right you're right yes
36:02 - okay so um so we've appended the new p
36:05 - value
36:06 - onto our list so that we're saving them
36:08 - every time
36:09 - um so i'm gonna run this and then
36:13 - what i'm gonna do is um
36:16 - i'm gonna plot a histogram of the p
36:19 - values
36:20 - so here's where i feel like
36:24 - when i first saw this like i had a
36:26 - professor once that did this in
36:28 - class and before before plotting this
36:31 - they asked the whole class what they
36:32 - thought this histogram would look like
36:34 - and like the one person that had seen it
36:37 - before
36:38 - got it right and all of the rest of us
36:41 - voted
36:41 - for something that was wrong so um so
36:44 - now i'm going to pose this question to
36:46 - you alex
36:48 - that's a hard question the people in the
36:50 - chat also answered this question
36:51 - oh yeah people in the chat also please
36:53 - try to answer this question so
36:55 - i'm going to repeat as i'm going to give
36:57 - you a minute to think and while you're
36:59 - thinking i'm going to repeat what we're
37:00 - doing
37:01 - so basically we've repeated this a
37:04 - thousand times
37:05 - each time we're going to simulate 500
37:07 - visitors
37:09 - where each visitor has a 10 chance of
37:11 - making a purchase
37:12 - we've set the purchase rate to 10 but by
37:14 - random chance there's going to be
37:15 - different numbers each time
37:17 - for each simulated sample of 500 we're
37:20 - going to calculate the number of
37:21 - purchases
37:23 - then we're going to run a binomial test
37:26 - to see whether
37:28 - the number of purchases is significantly
37:30 - different from
37:32 - 50 which is our expectation if the
37:34 - purchase rate is 10
37:36 - and so and given also a sample size of
37:40 - 500
37:41 - right and this is our null hypothesis
37:43 - and then we're going to collect the p
37:44 - values from we're going to collect the p
37:48 - values in a list and then we're going to
37:49 - plot a histogram of them
37:51 - we want to know like so remember when we
37:53 - were doing this example before
37:55 - we were printing out the p values each
37:56 - time and we said like
37:58 - you know when it's 39 we're gonna get a
38:02 - p-value of 0.05
38:04 - um or whatever
38:07 - so each time we're just collecting the
38:09 - p-values
38:11 - um yeah dr monkey uk says no pressure
38:15 - alex nobody else
38:16 - nobody else has been brave enough to
38:18 - venture a guest so
38:19 - the bad thing is that i like reviewed
38:21 - your content uh and so i've
38:23 - i've already oh this is i actually i
38:26 - don't think i put this in the content
38:27 - because
38:28 - i feel like i
38:31 - don't remember i didn't want to this is
38:34 - a bonus
38:35 - by watching this okay so i think the
38:39 - so i i don't think this is the actual
38:42 - answer because you've like prefaced this
38:43 - with so much like anticipation and
38:45 - uh trickery maybe you're just smarter
38:48 - than
38:48 - my entire class i mean so i would just
38:50 - guess that it looks like
38:52 - you know the normal curve where it's um
38:55 - we see a lot of
38:58 - so we're not going to see a lot of
39:02 - um things that are
39:06 - um oh god i don't even know now sorry
39:09 - i'm trying to think through it because
39:10 - we ran this a couple of times and we saw
39:11 - like
39:12 - we occasionally saw things that are tiny
39:14 - like this like .004
39:17 - um and i guess we would also
39:20 - occasionally see something that's huge
39:22 - like 0.99 but more often than not we're
39:25 - gonna see something that's like
39:26 - right in the middle so i would guess
39:29 - that it's like the normal curve
39:30 - with the center going from zero to one
39:33 - with the center at
39:34 - 0.5 okay and i see some message and
39:38 - messages in the chat um kristin in the
39:41 - croissants at
39:42 - croissant says total shot in the dark a
39:44 - normal distribution shape so
39:46 - agrees with you um dr monkey uk says i
39:49 - thought that too
39:50 - you guys are all following the same trap
39:52 - that i fall
39:53 - i fell into so that makes me feel better
39:56 - about myself
39:57 - um i'm gonna plot it now the way it is
40:00 - over
40:03 - i don't know if you want to drumroll
40:04 - this now i actually need sound
40:06 - i need sound effects on this thing i
40:09 - know
40:11 - whoa what is it it's basically
40:15 - what we call a uniform distribution
40:20 - which is to say that in fact
40:23 - if the null hypothesis is true
40:26 - you're equally likely to get any p-value
40:29 - between zero and one
40:32 - nice kristen and the croissant actually
40:34 - got it there right before we yeah
40:37 - just we we know that there's a delay on
40:40 - chat so
40:40 - we got it before i showed the picture
40:44 - yeah exactly um yeah
40:47 - so actually your intuition when you were
40:49 - first talking it through alex
40:50 - was right right on right like we saw
40:53 - some
40:54 - we saw just as many large and small
40:57 - numbers
40:58 - as we did in the middle so um
41:01 - so basically this is this is a super
41:04 - important
41:04 - like thing to understand for the context
41:08 - of um when you
41:11 - when you make mistakes in hypothesis
41:14 - testing
41:15 - which is that so again i'm just
41:18 - repeating what we did
41:19 - but um with like a new lens so
41:22 - we simulated a sample where the true
41:26 - probability of a purchase was 0.1
41:29 - then we ran a binomial test where the
41:31 - null hypothesis was that the purchase
41:33 - rate was 0.1
41:35 - so we when we ran this
41:38 - this hypothesis test in this line
41:42 - every single time we ran this hypothesis
41:44 - test
41:45 - then the null hypothesis was actually
41:48 - true
41:49 - because we simulated the sample like the
41:52 - way that we got this number
41:54 - was that we simulated a sample where the
41:57 - null hypothesis was true where the where
41:59 - the purchase rate really was 0.1 so
42:02 - because
42:02 - we simulated our sample knowing
42:06 - like saying the purchase rate is 0.1
42:10 - then when we run this test with the null
42:11 - hypothesis that the purchase rate is 0.1
42:15 - we're running this test where
42:18 - the null hypothesis is true
42:21 - does that that makes sense but why does
42:24 - that
42:24 - why does that make this uh you know
42:28 - essentially a straight line across so
42:30 - okay
42:31 - so let's let's again
42:34 - now like think through some potential
42:36 - errors that we can make so
42:38 - um so if the null hypothesis is true
42:42 - then um there's there's two things that
42:45 - could happen
42:46 - so if the null hypothesis is true then
42:50 - we don't want the p-value to be
42:52 - significant right we
42:54 - if the null hypothesis is true we should
42:57 - not reject
42:58 - the null um and maybe instead of not
43:01 - significant
43:02 - p-value above
43:06 - threshold right and then p-value
43:11 - below threshold
43:14 - um
43:20 - make this a little bit easier right so
43:23 - if the null hypothesis is true we want
43:26 - our p-value to be above
43:27 - the threshold that if the p-value is
43:30 - above the threshold then we are correct
43:32 - um if the p-value is below the threshold
43:35 - like if we simulate
43:37 - a sample where the null hypothesis is
43:38 - true we run our binomial test and we get
43:41 - a p-value less than 0.05
43:43 - then we've made what's called a type 1
43:45 - error
43:46 - which means that we rejected the null
43:49 - hypothesis
43:50 - even though it's true and
43:54 - it it turns out right when we said so
43:57 - think back to
43:58 - our um our picture
44:01 - and our interpretation of that p-value
44:04 - remember that
44:06 - in this example right the interpretation
44:08 - of the p-value
44:10 - was the probability of observing 41
44:13 - or fewer purchases given that the null
44:16 - hypothesis is true
44:17 - which is to say that our p-value is
44:19 - exactly
44:20 - the probability of observing one of
44:23 - these values by random chance
44:25 - even when the null hypothesis is true
44:28 - so right like
44:31 - if we um right
44:34 - we got a couple of those examples of
44:36 - like when we when we randomly
44:38 - got 30 true and the p-value
44:41 - was like 0.02 or something like that
44:44 - um then that was just
44:48 - that was a time when we would have
44:50 - rejected the null hypothesis even though
44:52 - we know that we were randomly picked
44:54 - those values with a 10
44:55 - purchase rate yeah exactly
44:59 - and whoop right the p
45:02 - values that we collected here are just
45:05 - the probability
45:06 - of observing something more extreme
45:10 - than this given that the null hypothesis
45:13 - is true
45:15 - there is a it's a probabilistic process
45:19 - so every time we run this
45:22 - right every time we we simulate a new
45:26 - set of visitors we're simulating it
45:30 - so that we there is a
45:33 - a probability of getting something that
45:36 - is extreme that we don't
45:38 - expect and then every time we're just
45:42 - looking at the probability of observing
45:44 - something
45:45 - that extreme
45:48 - or more extreme wouldn't we more often
45:51 - get things that aren't as extreme right
45:53 - aren't we going to more often get
45:56 - exactly
45:56 - 50 people purchasing because the true
45:59 - probability is 10
46:01 - so more often than not we're going to
46:02 - get 50 people purchasing less we're less
46:04 - often going to see 10 people purchasing
46:06 - um and so wouldn't that make it because
46:09 - we more often see
46:10 - 50 people purchasing wouldn't we more
46:12 - often um
46:15 - like see a different value here like
46:18 - what what's the so if we go back up to
46:20 - the the code um
46:21 - and we enter in let's the not in the
46:24 - loop let's just do one example
46:27 - uh if you scroll back and scroll up like
46:30 - if we hard code in rather than 69 there
46:31 - if we hard code in 50
46:33 - right right what's the
46:36 - what's the um upsides 40
46:39 - not not 50. oops sorry what's the
46:42 - p-value going to be alex
46:44 - right so i think this is going to be
46:45 - like 0.5 or wait it's one
46:47 - oh because it's uh because it's
46:49 - two-sided in this case
46:51 - um gotcha okay
46:56 - so wouldn't we see a lot more ones
46:59 - because we're
47:00 - most often going to get 50 there as that
47:03 - number
47:05 - that is a really well phrased question
47:08 - and
47:09 - i'm gonna be honest that my brain is
47:11 - like i
47:12 - when i really like putting you on the
47:14 - spot no no i this is really good and i
47:17 - feel like
47:18 - um i i this is one of those things where
47:21 - i go in and out of
47:23 - being able to explain it clearly and
47:24 - sometimes i
47:26 - have it in my head and sometimes my
47:28 - brain is tired and i'm like
47:30 - that's a good point alex uh let me see
47:33 - if i can explain that to you
47:34 - um let me let me like talk it through
47:38 - and maybe we can figure it out together
47:40 - and then if not i want to
47:41 - leave a little time to do one other
47:43 - thing totally um
47:44 - also in the chat if you have like a good
47:46 - way of conceptualizing this
47:48 - definitely share it with us
47:52 - and i guess one thing that we could do
47:53 - is can we run the the
47:55 - loop of a thousand over again and see
47:58 - another example of this graph because
47:59 - i'm curious
48:00 - because right now we do see one more
48:02 - often than not one right the the highest
48:04 - bar in the histogram is one
48:06 - um and i don't know if that's a
48:07 - coincidence or not no it's just a
48:08 - coincidence
48:09 - actually what i'd like to do to help
48:11 - answer our question
48:13 - is just i mean we know what this is
48:15 - going to look like but
48:19 - the so the part if we were to collect
48:21 - the purchases when we do this
48:24 - right if we like purchase
48:29 - [Laughter]
48:32 - and we do
48:45 - this and then
48:48 - below this we'll also
48:51 - do pld.hist
48:55 - um yeah purchase files here
49:02 - this should be a i guess a binomial
49:04 - distribution right
49:06 - right let's read
49:10 - it's funny that you're right it does
49:11 - like
49:13 - look like that every time but i
49:16 - promise you and if we crank it up to
49:18 - like 10 000 which might take
49:20 - more time to run i'm curious what
49:21 - happens right
49:24 - so okay so more frequently we're getting
49:27 - around 50 purchases
49:30 - um and now
49:34 - yeah let's see 10 000.
49:44 - it's running you can see a little good
49:46 - jupiter notebook trick is that you can
49:47 - see the
49:48 - okay there we go interesting
49:51 - why is this i'm actually confused why it
49:55 - looks like this
49:56 - every time
49:59 - like it it keeps seeming to like have
50:02 - the shape where it goes like
50:04 - up to two percent like point two and
50:07 - then
50:08 - up to point to one point oh so i hope
50:10 - i'm not like misleading you guys
50:12 - again like i did last time
50:16 - at the start of the next session though
50:18 - no no no but
50:19 - it should be that i i know this is like
50:22 - making me sad that my brain is
50:26 - not upset well it is confusing
50:29 - um um but basically
50:32 - this time it looks a little different
50:34 - but it still has that same shape i'm
50:35 - like
50:36 - i'm not sure about that but yeah we are
50:39 - getting
50:40 - this distribution which we expect um
50:48 - let's uh let's get to the the rest of
50:52 - the
50:52 - exercise and next week we can come back
50:54 - with further thoughts about this because
50:56 - i'm also curious about
50:57 - what's happening here okay yeah i have
51:00 - i definitely um i definitely
51:04 - can't explain this well when uh when
51:06 - i've like
51:09 - go through yeah sorry um
51:12 - no no it's i'm so glad that you do um
51:15 - okay so
51:16 - the last thing i wanted to kind of
51:18 - demonstrate is that
51:20 - um so remember
51:23 - so we went over these different kinds of
51:25 - errors
51:27 - where if the probability if the p-value
51:29 - is below
51:31 - our threshold when the null hypothesis
51:33 - is true
51:35 - then we've made a type 1 error and
51:40 - so the question is like if the null
51:42 - hypothesis
51:43 - is true how often are we going to make
51:46 - a type 1 error and so let's pick a
51:50 - threshold let's pick
51:52 - 0.05 i guess okay
51:55 - and let's let's run this with a
51:58 - threshold of 0.05
52:00 - um so i'm gonna
52:03 - copy and paste this below so that we can
52:07 - make a couple of edits to it
52:09 - and this time i'm gonna start a counter
52:14 - um and i'm gonna i'm gonna count the
52:16 - number
52:17 - of times that we make an error so i'm
52:19 - going to count
52:21 - the type 1 errors
52:26 - so i'm going to start my counter at zero
52:29 - and every single time
52:31 - i run this
52:34 - i'm going to um
52:38 - i'm going to say if
52:42 - actually we don't need to keep the
52:45 - p-values this time
52:49 - so now i'm going to say if
52:52 - the p-value
52:56 - is less than our threshold so less than
52:58 - 0.05
53:01 - arbitrarily chosen threshold then i'm
53:04 - going to say
53:06 - add 1 to type 1 error so i'm going to
53:09 - say
53:09 - type 1 errors plus equals 1. which just
53:12 - means
53:13 - so and so this is a case where it's like
53:15 - we from our
53:17 - randomized sample we got a really let's
53:19 - say tiny value this time
53:20 - like 30 purchases when
53:24 - uh when we know that the the actual
53:27 - purchase rate is 10
53:28 - and that's going to happen a certain
53:29 - number of times where we get this like
53:30 - really tiny value
53:32 - randomly yeah or i guess really large
53:34 - value randomly too since this is
53:36 - two-sided right
53:37 - yeah so i'm going to do print type 1
53:40 - errors
53:40 - over i'm going to do the this is going
53:43 - to be the type 1 error rate so we
53:45 - we ran this experiment 10 000 times
53:49 - and then i'm going to print how many of
53:51 - those 10
53:52 - 000 times resulted in a type 1 error
53:58 - okay let's try that
54:02 - it's gonna run it's a little slow
54:06 - quick question from chat briefly uh
54:08 - there's no uh
54:09 - you haven't seated the random numbers
54:11 - have you
54:12 - no i haven't seeded them um
54:15 - one thing that gets a little bit funky
54:18 - with um with the binomial distribution
54:23 - is also if our probability is too
54:26 - close to zero we start getting like
54:29 - um like some weird skew
54:33 - so we can try again but basically
54:37 - the point that i was trying to make and
54:39 - now i'm going to like go back and
54:40 - try to talk through your um your
54:43 - confusion alex
54:45 - but as you'll see here this number
54:48 - is pretty close to 0.05 right and
54:52 - because this should be
54:55 - uniformly distributed um
54:58 - basically exactly five percent
55:02 - of the time if you use a
55:06 - a threshold of 0.05 then exactly
55:09 - 5 of the time you're going to get
55:12 - a p-value that is less than 0.05
55:17 - because right like any p-value between 0
55:21 - 1 and 1 is equally likely and so
55:24 - if we say what's the
55:28 - what's the probability of getting a
55:29 - p-value less than 0.05 it's really just
55:33 - like that proportion of this area
55:36 - right and if that was a perfect
55:37 - rectangle then that would be five
55:39 - percent of the rectangle
55:40 - right um which is to say that
55:44 - basically whatever significance
55:46 - threshold you set
55:48 - becomes the type 1 error rate
55:51 - for your test and so um so if you say
55:54 - i'm going to set
55:55 - a significance threshold of 0.05 i'm
55:57 - going to reject the null hypothesis
55:59 - when um a p-value
56:02 - is less than .05 then
56:06 - you're saying that i'm okay with the
56:07 - idea that five percent of the time
56:10 - the null hypothesis is going to be true
56:12 - and
56:13 - i'll still reject the null
56:16 - and so putting that in context of like
56:18 - back to the very start of like we've
56:19 - made this change to the website we want
56:21 - to see if
56:22 - purchases have uh decreased because of
56:25 - this change
56:26 - um or i guess are different because of
56:29 - this change because it's two-sided
56:30 - right right then
56:34 - then this is saying like what it what is
56:36 - this
56:38 - can you put it in terms of like the
56:39 - actual experiment
56:41 - so right so and i think actually this
56:44 - like
56:45 - somehow helps with the confusion from
56:47 - before so
56:48 - remember that our experiment was
56:51 - essentially
56:52 - we're gonna look at a sample of 500
56:56 - visitors
56:56 - and see whether the purchase rate in
56:59 - those visitors
57:00 - was less than
57:03 - our expectation so our expectation was
57:06 - that it would be 10
57:08 - and we're gonna see if
57:12 - it's less than that or we're going to
57:13 - test this hypothesis that it's
57:15 - equal to 10 or less than that is our
57:18 - alternative
57:19 - and so now we're coming at it from
57:22 - another
57:22 - perspective we're saying let's say like
57:24 - the true purchase rate like if we could
57:26 - show
57:27 - this website to this version of the
57:30 - website to
57:31 - every visitor who could ever visit our
57:33 - website
57:34 - if we could show it to all of those
57:36 - people
57:38 - the true purchase rate the two
57:40 - probability of a purchase for each
57:41 - visitor would be 10
57:44 - let's say let's suppose that that's true
57:46 - but we by random chance like
57:48 - we got 500 we got a sample of
57:51 - 500 uh visitors where
57:54 - among those 500 visitors the purchase
57:58 - rate just happened to be low by random
58:00 - chance
58:01 - we're saying this like
58:05 - five we're we're okay with the idea that
58:09 - five percent of the time if the true
58:12 - purchase rate was
58:15 - ten percent we're good five percent of
58:17 - the time
58:18 - we're still going to get a p value less
58:20 - than .05
58:22 - right so if we did that this experiment
58:24 - of getting 500 different people
58:25 - 10 000 times like we're doing here then
58:27 - five percent of those times
58:29 - we're going to reject the null
58:31 - hypothesis even though it was true
58:34 - okay yes um okay
58:38 - one thing i want to see with respect to
58:42 - this picture is really quickly is if we
58:45 - change this
58:46 - to like 0.5 and 0.5
58:52 - and 0.5 whether
58:56 - this shape is still persisting
59:05 - so now it looks more like i would expect
59:10 - um although it's still really jagged
59:12 - right i
59:14 - guess that's that jagged with 10 000 uh
59:19 - uh runs yeah i don't know
59:22 - this honestly might be yeah i'm
59:24 - surprised
59:25 - about it too i feel like there's
59:27 - something going on with
59:29 - how random seeds are being interesting
59:32 - or like how the random function is
59:35 - is working yeah um that's interesting
59:38 - but yeah that is really interesting it
59:40 - should be if the null hypothesis
59:42 - is true then this should be a a uniform
59:45 - distribution
59:46 - i'm going to um after this because we're
59:49 - running out of time
59:51 - but once i'm not on the spot i'm going
59:53 - to write out
59:54 - a clear explanation of this and why this
59:57 - is the case
59:57 - and then i will add it to the video
60:00 - but um but i want to leave
60:04 - you with kind of like the the main
60:07 - takeaway from all of this
60:09 - which is that when we run
60:13 - an experiment and we use a significance
60:16 - threshold so we say
60:17 - we're going to reject the null
60:18 - hypothesis if the p-value is below some
60:20 - threshold
60:22 - the p-value is is probabilistic
60:25 - remember that p-value is the probability
60:28 - of observing something
60:29 - or more extreme given that the null
60:32 - hypothesis is true
60:33 - but that doesn't
60:36 - even if you get a p-value of 0.001
60:42 - that doesn't mean that what you observed
60:46 - is not possible it just means that it's
60:49 - unlikely but you can still observe that
60:53 - and so you have
60:54 - even if the null hypothesis is true so
60:56 - you have to have some threshold for
61:00 - error and what this means is
61:03 - because many people are using 0.05 as a
61:06 - significance threshold
61:08 - it means that five percent
61:11 - of all the tests that have been run with
61:15 - a significance threshold of 0.05
61:19 - are wrong um if we're using that
61:22 - threshold
61:23 - right and so what ends up happening and
61:25 - we didn't get into this as much as i
61:27 - hoped but like
61:28 - if you let's say you run
61:32 - a hundred experiments at your company
61:35 - so i know my boyfriend for example
61:38 - his company is caught constantly running
61:41 - experiments
61:42 - let's say you run and they're probably
61:44 - running like thousands
61:46 - a day i would wouldn't be surprised
61:49 - so let's say but let's say you ran a
61:51 - hundred different tests
61:53 - what that means is that even if the null
61:55 - hypothesis was true for
61:57 - all of those 100 tests five of them
62:00 - would result in a significant p-value at
62:03 - a 0.05 significance level
62:05 - and if all you do is report and act upon
62:08 - the ones that are significant
62:10 - then you're acting upon being a mistake
62:15 - and then that
62:19 - experiment might not be reproducible it
62:21 - was a fluke that you got
62:23 - something that your sample was so
62:25 - different from expectation
62:27 - but and how do you how do you counteract
62:29 - that though because you're no matter
62:30 - what you're always going to have
62:31 - whether it's five percent or one percent
62:32 - or point five percent
62:34 - right there's always going to be uh it's
62:37 - always probabilistic so
62:39 - like what's the what's the upshot of
62:41 - that how do you protect it yeah there's
62:43 - lots of different ways that people
62:45 - do this um sometimes people just use a
62:48 - smaller
62:49 - threshold so 0.01 instead so
62:52 - you have a lower chance of making a
62:55 - mistake
62:56 - um there's also like ways that you can
62:59 - basically uh what's the word
63:03 - um like adjust all of your p-values
63:06 - based on the number of
63:09 - uh based on the number of tests that
63:11 - you've run so like a bonferroni
63:14 - adjustment is like one that's common um
63:18 - so there's different there are different
63:21 - uh
63:21 - approaches but the truth of the matter
63:24 - is you never are gonna fully
63:26 - you're never gonna fully escape the
63:29 - probability
63:30 - of some probability of making a mistake
63:33 - and the only antidote to that is being
63:37 - is one setting all of this like setting
63:41 - your threshold and setting
63:43 - and figuring out how you're going to
63:44 - adjust p values or what p what threshold
63:47 - you're going to use ahead of time
63:48 - figuring out how many tests you're going
63:50 - to run ahead of time and then if you're
63:52 - publishing a paper
63:53 - and you ran or your pub you're making a
63:56 - decision based on some results and
63:57 - you're like presenting it to your
63:58 - company
63:59 - you should show data for every single
64:02 - test that you run
64:03 - you ran not just the ones where you got
64:06 - a significant result
64:08 - right um so yeah
64:11 - the the antidote is clear communication
64:15 - of what you did and how you decided to
64:18 - do it
64:18 - um cool yeah
64:22 - cool all right um good work sophie
64:26 - uh sorry for putting on the spot i feel
64:28 - bad oh no no
64:29 - don't feel bad this is like what that's
64:31 - what this is all about
64:32 - i feel bad i feel like we've been doing
64:35 - these streams on tuesdays
64:36 - aft after the work day and so sometimes
64:39 - i
64:40 - you know i come in a little bit frazzled
64:43 - but i want to make sure that everybody's
64:45 - getting as much as possible out of these
64:47 - and i hope that they're super helpful
64:48 - and i will be sure and we're kind of
64:51 - pretending that this is like a
64:53 - this is a real class and so in a real
64:56 - class
64:56 - it's like we would come back next week
64:58 - and talk about this which is
65:00 - why we talked about last week this week
65:01 - so um so yeah i will i will make sure to
65:04 - post
65:05 - a more full explanation um
65:08 - so that everybody can benefit from that
65:11 - cool
65:12 - all right well thank you everyone we
65:13 - will uh yeah see you next week
65:16 - all right good one

Cleaned transcript:

i know it says we're live but i don't believe it i don't believe it until i see it okay we're good to go all right hi everyone uh i hope that everyone is having a good tuesday and i'm excited to get into uh our week six topics um i think we had a little snafu with the timing on the youtube page so it's possible uh that people will be filtering in slowly uh today but if you're here and you're live ask us any questions you have on the youtube chat and we will make sure to address them uh cool so i think we can get started pretty quickly this this time around um i have something that i want to address from last week uh a small correction so i'm gonna start with that and then we're gonna get into the material for this week so with that i will share my screen yeah i saw you posted a comment on the last video so this is also in the last video but uh something that we were going over that um uh i was either said incorrectly or you just want to go oops sorry i shared the wrong screen yes exactly all right sure all right um yeah so this was a really quick edit from last week and this was related to a really good question that alex asked so um it comes back to our discussion of how the binomial distribution is pretty similar to the normal distribution except for um except that it's discrete uh which means that like you can only have the numbers one two you can only have integer values um along your xaxis and i kind of walk through the exam or i talk through how the central limit theorem sort of applies and um at one point alex asked if we could see how the the width of the distribution changes for different sample sizes and we didn't get to it but uh off as i was thinking about it later i realized that actually what we were looking at last time and i think we still have it was we were looking at a histogram of um in this case the number a number of purchases or earlier we were looking at a histogram of coin flip results where each number on the xaxis represented a number of coin flips that resulted in heads um but this example of a normal or this example of a binomial distribution if you think about whether you flip 500 coins versus 10 coins um the 10.1 is going to be less the distribution for 10 coin flips the distribution of the number of heads for 10 coin flips is going to be um thinner than this distribution just because the number there are less numbers between 0 and 10 than there are between 0 and 100 so what i everything i was saying only applies if you divide each of these numbers by the sample size so just demoing it down here and the intuition like makes a lot of sense and i feel like people probably intuited this at the time but if you flip 10 coins and you record the proportion of heads instead of the number of heads and plot that distribution you could get anywhere from zero to a hundred percent heads in infinitely many coin flips whereas if you put if you flip a hundred coins um you're more likely or 500 coins i think in this example you're more likely to get closer to 50 heads you could still potentially get zero percent heads but it's a lot like it's like so much more minuscule it's not even gonna happen in our in this simulation um and so so so this example the blue histogram is uh 10 um what's the terminology 10 attempt 10 coin flips 10 like attempts or something like that yeah so this is we repeated this process a bunch of times each time we flipped 10 coins and we recorded the proportion of heads in each of those 10 flips and we did that and then the orange is 100 500 or something like that i think the orange i i made it 500 but yeah you can see and the histograms look a little funny because of how the xaxis shows up but um but you get the idea that it's basically you can be more confident about the proportion of heads that will come up the more times you flip the coin okay cool and yeah and and again the the correction from last week is we weren't talking last week we didn't specify that's the proportion if you scroll back up to that other graph we were talking about like the overall number and so of course when you're flipping a hundred coins the number of heads can range from zero to a hundred versus ten coins it can only be zero to ten so like by definition that range is going to be smaller but you know that's not what we're actually interested we're interested in the percentage or proportion exactly cool makes sense so with that um i'm going to move to today's topic which i think is a really fun one and we're going gonna use the same data in the same framework as we did last time just to keep things simple um but we're going to talk about the issue of multiple hypothesis tests and we're going to talk a little bit more so last week we we introduced the idea of a pvalue as being like an outcome of a hypothesis test um and we'll we'll review a little bit what that definition of a pvalue was but then there's another question about what to do with that pvalue value and in order to answer that question we're going to need to think a little bit more deeply about about what it means to make a decision based off of a probability so that's the that's the topic for today and this is really important because you may have heard of the reproducibility crisis in statistics um which is the idea that a lot of published research can't be reproduced like people aren't getting the same findings when they try to do the same study over again um and that issue is related to what a lot of people call p hacking um which is going to be a topic of today so with that uh let's jump in so a quick reminder from last week i'll actually pull up um pull up our code from last week and so as a quick recap we were looking at this situation where we had some data about uh people making purchases on a website and we had a sample of 500 people and we expected the purchase rate to be 10 and we wanted to know if the purchase rate was significantly less than that because we thought there was some sort of bug or we had changed something where we thought the purchase rate might go down we want to check that assumption so we ran this test where we collected our sample we have 500 visitors to a web website who saw this thing and we saw that i think it was like uh like eight percent made a purchase i forget like 41 out of 500 whatever that was yeah so 41 out of 500 so less than our expectation made a purchase um right if it was 10 it would be 50 and we saw only 41 made a purchase and then we talked about how um the outcome of this hypothesis test is we could kind of say well if the purchase rate was what we expected then we would expect 50 purchases but if we repeat this process randomly a bunch of times and give everyone a 10 chance of making a purchase we still see a range in the number of purchases that happen among 500 people in simulated samples and so based off of that we estimated this p value which was the probability that a randomly sampled group of people a group of 500 people made 41 or fewer purchases given that the true probability of a purchase was 10 um and that was that's our p value it came out i think to like 0.1 um we did it using simulation we also did it with a builtin function and both times it came out to around 0.1 and so that's that's a probability um and it can be interpreted right if we if we got a really low probability so like let's say we observed only 30 purchases in our sample then the probability would just be like the area of this tiny little block to the left of 30 divided by the total area of the whole thing so it'd be a really small number and right and intuitively right if we say the probability of making 30 or fewer purchases given that the true probability of a purchase is 10 if that probability is really small then it's unlikely that um it's unlikely that the purchase rate really was 10 in that case so we're making some estimate of how likely is it that the null hypothesis is true given what we observed right and i think uh you might go into this in this lesson sophie but i think a lot of times or the thing that i know about pvalue is that like 0.05 po value 0.1 pvalue right like we're saying that okay at this level we can reject the null hypothesis because um you know the probability of purchase is ten percent or you know in the other case it'll be like two percent if we saw um if we saw 30 purchases instead of um instead of 41. so why why those values why 0.5 and 0.1 as like the values where you say like this is when we can reject the null hypothesis yeah so we're actually gonna just jump right into that right now so um so what alex is alluding to is that um i think we all if we're all okay with the idea of a probability or hopefully we feel comfortable with the idea of the probability but sometimes you need to use that probability to actually make a decision so in this case it's maybe maybe the example that i came up with isn't super conducive to this but let's say that um let's say that what we were doing was we tried out some new version of our website that's cheaper for us to build and um and so we expected the purchase rate might go down we wanted to know if it really did go down or not and if the purchase rate didn't go down significantly with our new cheaper version of the website then we're going to implement the cheaper version of the website because it will save us money but if the purchase rate went down significantly then we don't want to implement it and so we have to make that decision implement don't implement based off of this number and if we're going to do that we don't really want to like i think in general we often want to have some cut off for ourselves like this is a probabilistic number the pvalue is a probability um but we're not necessarily comfortable with the idea that like there's just a 10 chance that the purchase rate really did drop at a 90 chance that it didn't or whatever we want to um or whatever we want to ascribe to this we want to actually use that probability to decide like is it worth making this decision or not and so a way that people do that is they choose a threshold and they say okay any pvalues below this threshold i'm gonna deem them significant what that means it or i'm gonna decide to reject the null hypothesis which is the um the wording that alex used and the idea here is that the null hypothesis in our example was that the probability of a purchase is 10 if we get data that challenges that null hypothesis that makes it unlikely that that null hypothesis is true then we're gonna reject it and say okay it's unlikely that the null hypothesis is true therefore i'm gonna say that it's more likely or therefore i'm gonna accept or i don't know people use different language uh usually we don't say like accept the alternative but you say i reject the null hypothesis in favor of the alternative which is to say that we haven't proved that we haven't calculated a probability of the alternative hypothesis we've only calculated a probability of the null hypothesis and then said that it's unlikely um and so a common choice for that threshold at which we say will reject the null hypothesis is .05 um but lots of people use .01 or um or a different threshold or 0.1 um so there's some choice in that and we need to decide it ahead of time um in this case yep i hear i see someone wrote fail to reject so in this case if we got a pvalue of about 0.1 and if we set a significance threshold of 0.05 we would fail to reject the null hypothesis because 0.1 is not smaller than .05 um and so the probability that the null hypothesis is untrue given our data data is not small enough for us to reject the null and so uh interesting thing with the language here is that yes is that then saying that we think that the probability of purchase is indeed 10 or that we just don't think that it's less than 10 percent um no it's saying that we so if we oh you mean if we don't if we fail to reject the null if we if we fail to reject the null is that us saying that we think that it is that it remains uh 10 probability of purchase um no i mean depending on if you want to be technical about how you should interpret it but if you fail to reject the null you're basically just saying that there is not enough evidence that the purchase rate is not 10 so um you can't say basically you can't say whether the null hypothesis is true or not right just that you can't that you can't accept this alternative hypothesis or you just say you can't reject the null i know it's like it goes in circles because uh and the language is complicated and i feel like it's been ingrained in me to be really careful about what language i use really precise um but yeah the whole framework of a hypothesis test is really about setting up the null hypothesis testing the null hypothesis and then saying whether you have enough evidence to reject the null hypothesis or not reject and that's like that's as far as you can go if you reject you're saying it's unlikely that the null hypothesis is true if you fail to reject then you're saying there's not enough evidence for me to say the null hypothesis is not true okay and that's a lot of words that i just said um and i know it's confusing so uh bear with me i think as you're learning this stuff you have to like do it a bunch of times try practice problems decide reject or fail to reject interpret and practice interpreting so that you feel comfortable with that idea yeah lots of double negatives like fail to reject is like a double negative of like oh we're failing to turn this thing down right it's uh i can see how it gets uh it gets confusing yeah okay so with that i'm gonna jump right in so um first thing i wanna do is i want to think through um in the same way that when we talked about the central limit theorem we kind of had this like allpowerful mode and in that allpowerful mode we got to know what the truth was and then um and then we kind of went into researcher mode where we didn't know where the what the truth was and we were trying to analyze something as a researcher we're gonna do the same thing for right now so remember that um that last time we looked at this data this was like a simulated data set 500 visitors to a website um and basically the important thing here is whether or not the each visitor made a purchase and in this data set we have um 41 purchases but we can recalculate that so i think we discuss such disrespect the importance of our uh items that we came up with uh i mean no disrespect at all i love this date i love this data set so much i just watch it here even though it's totally fake i watched love actually for the first time over the weekend so now i could uh be this purchaser of the cue card i wish i had watched it this weekend i totally forgot about that um did you enjoy it it was great very pleasant yeah it was just nice yeah it is nice okay so we'll just confirm there's 40 oops i didn't yeah okay so confirming that there's 41 purchases but now we're let's go back to what we were doing in the previous week so remember that last week we started doing this these kind of simulations where we said okay but what if the true probability of a purchase was 0.1 i'm going to copy over this code so we don't have to rewrite it but for those that haven't seen that if you're just visiting for the first time um what we're doing here right is we're saying okay but what if in this data set we saw 41 purchases but what if the truth is that the probability of a purchase is 0.1 and we simulate 500 new visitors so this data set has 500 visitors what if we simulate 500 new visitors and see how many purchases we get and remember that we expect 0.1 times 500 or 50 purchases but we're going to get some variation around 50 so this time we got 55 um and every time we run this we're going to get a different number and it's going to be totally random okay so next thing i want to do is think about what would happen if we repeated this a bunch of times and instead of every time collecting the number of purchases what if every time we run this we run a binomial test and calculate a p p value okay so um let's let's try writing this out here i'll make a new so alex do you want to like walk me through yeah say that sentence again i think i i think i got lost so every time we run one of these um tests or run one of these simulations we're going to run a um ptest on it or we're gonna get a pvalue for it yeah so we're gonna run a binomial test okay yeah so right this is this is gonna get like a little bit meta so um if if anyone is confused in the chat um please please please let me know um okay so each time i run this loop i'm going to simulate 500 visitors each with a 0.1 probability or 10 probability of making a purchase i'm going to calculate the number of purchases but then what i'm going to do is i'm going to grab this code and i'm actually going to just grab the the binom test code so right because because last week what we did is we ran that a thousand times um and then made a distribution of like oh this time we saw 50 purchases this time we saw 45 and we made that distribution um now we're not making that distribution anymore we're just running the uh binomial test on it yeah actually you know what i feel like i skipped a step let me let me go back before we do this for loop let me quickly just demonstrate what i'm going to do inside the for loop but demonstrate it outside the for loop so right we have this process where here every time we're calculating the number of purchases in our simulated sample but what if instead of that we import this binome test function and then we run the binomial test the exact same test that we simulated last week and we'll do with alternative is less and instead of putting 41 in here let's put in the number of purchases in our simulated test our simulated data set so the originally the 41 came from our real data of 41 people um bought the item but let's see what happens if we do it with a random a random number yeah and actually each time i'm going to print the number of purchases and then i'm going to print the p value so you can see both of them so here we go all right this time we got 55 purchases and we got a pvalue of 0.795 alex do you want to talk through like how would you conceptualize this pvalue or how would you explain that pvalue right so i'm visualizing the um the distribution right and so um we expect the um number of purchases to be 50. we saw 55 and so we're saying if um if the actual number of or if the actual rate of purchase was 10 which would give us our 50 and we saw 55 percent there's a and we saw 55 purchases rather than 50. there's a uh 79.5 chance that um that the uh the the true value is uh ten percent right or not sort of so we again it's like the double negative of like we can't rej it's not that it's 10 it's that it's um like can you write out the um null hypothesis for me yeah so the null hypothesis here i'll do it and mark down so the null hypothesis is that the purchase rate is 10 and then the alternative hypothesis is that because we did alternative equals less the alternative hypothesis is that the purchase rate is less than 10 right and so um like what i want to say is there's a 79.5 chance that the null hypothesis is true but it's not exactly that right so i would say there's a 79.5 chance that um or sorry let me back up there's a 79.5 chance of observing 55 or fewer purchases given that the purchase rate is 10 so because we had alternative equals less this is going to be it's going to be a probability of observing 55 or fewer purchases if the true purchase rate were 10 um so let's do another one let's run it let's see if we can get something that's like less than 50. okay so here's 39. actually this this p value is pretty close to 0.0.05 this is pretty close to our threshold even though right in our simulation the probability of a purchase was 0.1 no it was yeah 0.1 but we got a randomly really small number so this is saying that there's a 5.5 chance of seeing 39 purchases given that the true purchase rate is 10 yeah 39 or fewer purchases because yeah because the alternative was less than yeah right yeah something that's interesting so we uh in the last one that you ran i think the value the total number was like 62 and so the p value was like 0.98 um which means that there's like a 98 chance of seeing 63 or fewer purchases given that the total purchase rate is 10 which is like it's a little bit confusing because normally you know you're used to seeing like very small p values so i always come back to it has to do with the fact that we have that alternative equals less um contingency if we had um if we had changed the alternative or to uh both i think is how it's coded here or i think it's also the default then you get the um doublesided pvalue it would have been really small for that value but um i think the i like to conceptualize it and i think i have some pictures somewhere i can like pull them up but i like to conceptualize it with this this image it this image so i think about that pvalue as a proportion of the area of this blue histogram and so for when we had 41 the pvalue was the proportion of the histogram that was left of 41. so that was about 0.1 when we got 69 it was all the way over here and it was the proportion of the histogram that's less than 69 and so we got 0.98 and could we could we see can we go back to our code and hard code in that 69 and see that it's 98 percent rather than purchases and then maybe flip from let's first see what it looks like with alternative equals less and then um here uh actually let me just create a new yeah right i'm sorry if this is a tangent no no no this is great this is a really helpful discussion because you feel like this is the kind of thing that helps um conceptualize the next steps i'm glad we're taking the time to do it okay so 99 chance of seeing 69 or fewer purchases given a 10 purchase rate which again if you're picturing that histogram that's like basically all of the area under the histogram but now if we switch to not less but the default which is like twosided right so this is now saying there's a point seven percent that we're either above 69 purchases or below some very small value right yeah so i'm gonna just actually we're going to go to codecademy.com outlooker and let's pull up there's um thanks for hanging with me guys um i think it's in this lesson oh yeah right so i find this picture kind of helpful so um right the twosided pvalue which is the um which is the default is looking just at the probability of observing something as extreme or more extreme than um than what was observed in the data so in the case where we had a value of 69 we're like drawing we're drawing a line at 69 shading everything to the right of 69 red and then we're drawing we're saying okay 50 69 minus 50 is 19 so 69 is 19 units away from 50. so let's go 19 units away from 50 in the other direction to 31 and let's also add in everything to the left of 31 right so um right so it's like distance away from the expected mean right versus what we did what we're doing before is we're just coloring everything with the alternative being less we're coloring everything to the left and then um if we get a high number then you're going to get a really large p value yeah and so going back to our code now if we i assume we can put in a parameter for the third value where we've done less and then twosided can we put in greater than and see they'll like point the like one percent of uh seeing something greater than 69 um given the 10 yeah so it's going to be even it's gonna be half as big as this right so if we do alternative i think it's just greater let's try it yeah yeah right and so again that's picturing that histogram finding uh your value and saying okay what's the area greater than that that area and it's um you know 0.5 of the total histogram yeah exactly cool um all right i'm glad we went on that tangent i feel like hopefully that clarified some things for people um and now we'll go and try to do this a bunch of times so in this case right if we and let's just like take it back to the um to the original goal of this right in this case if we had observed 69 purchases and let's say we used our alternative hypothesis was that the purchase rate was greater than 10 and then we observed 69 purchases we'd be pretty certain or we could be pretty certain that the null hypothesis is not true or in other words i should say we could be there's a very low probability that the null hypothesis is true in that case because 69 is so much different from our expectation and so if we were using a threshold of 0.05 to decide whether something whether we should reject the null hypothesis then in this case we would and the key that we're going to talk about now is that sometimes when we reject the null hypothesis we're going to be wrong right like we randomly simulated 69 visitors we did that earlier right completely randomly where the true purchase rate was 0.1 um and so sometimes by random chance extreme things happen right like sometimes by random chance you um flip 100 coins and 80 of them come up heads or whatever it is so sometimes we'll reject the null and we shouldn't have rejected the null so that's where we're going but let's let's go through this so um here we've got all of this now i'm putting it inside a for loop so i'm just saying i want to repeat this a bunch of times each time i'm going to simulate my visitors with a 10 probability of a purchase then i'm going to calculate the number of purchases and then i'm going to put that into my um binomial test and i'm going to get rid of this alternative equals less but for some reason my computer doesn't like to i think it has something to do with zoom um okay and then what i want to do actually before this is i want to collect those p values from for further inspection so i'm going to say p vowels equals empty list and then each time i'm going to say p vowels call this a thing simpler like p val u and then we'll say p vowels equals p val stop append um p value thank you do you do the overwrite or can you just do p values dot append um what do you mean do you need to set p values equal to the new thing or can you just do p files oh right you're right yes okay so um so we've appended the new p value onto our list so that we're saving them every time um so i'm gonna run this and then what i'm gonna do is um i'm gonna plot a histogram of the p values so here's where i feel like when i first saw this like i had a professor once that did this in class and before before plotting this they asked the whole class what they thought this histogram would look like and like the one person that had seen it before got it right and all of the rest of us voted for something that was wrong so um so now i'm going to pose this question to you alex that's a hard question the people in the chat also answered this question oh yeah people in the chat also please try to answer this question so i'm going to repeat as i'm going to give you a minute to think and while you're thinking i'm going to repeat what we're doing so basically we've repeated this a thousand times each time we're going to simulate 500 visitors where each visitor has a 10 chance of making a purchase we've set the purchase rate to 10 but by random chance there's going to be different numbers each time for each simulated sample of 500 we're going to calculate the number of purchases then we're going to run a binomial test to see whether the number of purchases is significantly different from 50 which is our expectation if the purchase rate is 10 and so and given also a sample size of 500 right and this is our null hypothesis and then we're going to collect the p values from we're going to collect the p values in a list and then we're going to plot a histogram of them we want to know like so remember when we were doing this example before we were printing out the p values each time and we said like you know when it's 39 we're gonna get a pvalue of 0.05 um or whatever so each time we're just collecting the pvalues um yeah dr monkey uk says no pressure alex nobody else nobody else has been brave enough to venture a guest so the bad thing is that i like reviewed your content uh and so i've i've already oh this is i actually i don't think i put this in the content because i feel like i don't remember i didn't want to this is a bonus by watching this okay so i think the so i i don't think this is the actual answer because you've like prefaced this with so much like anticipation and uh trickery maybe you're just smarter than my entire class i mean so i would just guess that it looks like you know the normal curve where it's um we see a lot of so we're not going to see a lot of um things that are um oh god i don't even know now sorry i'm trying to think through it because we ran this a couple of times and we saw like we occasionally saw things that are tiny like this like .004 um and i guess we would also occasionally see something that's huge like 0.99 but more often than not we're gonna see something that's like right in the middle so i would guess that it's like the normal curve with the center going from zero to one with the center at 0.5 okay and i see some message and messages in the chat um kristin in the croissants at croissant says total shot in the dark a normal distribution shape so agrees with you um dr monkey uk says i thought that too you guys are all following the same trap that i fall i fell into so that makes me feel better about myself um i'm gonna plot it now the way it is over i don't know if you want to drumroll this now i actually need sound i need sound effects on this thing i know whoa what is it it's basically what we call a uniform distribution which is to say that in fact if the null hypothesis is true you're equally likely to get any pvalue between zero and one nice kristen and the croissant actually got it there right before we yeah just we we know that there's a delay on chat so we got it before i showed the picture yeah exactly um yeah so actually your intuition when you were first talking it through alex was right right on right like we saw some we saw just as many large and small numbers as we did in the middle so um so basically this is this is a super important like thing to understand for the context of um when you when you make mistakes in hypothesis testing which is that so again i'm just repeating what we did but um with like a new lens so we simulated a sample where the true probability of a purchase was 0.1 then we ran a binomial test where the null hypothesis was that the purchase rate was 0.1 so we when we ran this this hypothesis test in this line every single time we ran this hypothesis test then the null hypothesis was actually true because we simulated the sample like the way that we got this number was that we simulated a sample where the null hypothesis was true where the where the purchase rate really was 0.1 so because we simulated our sample knowing like saying the purchase rate is 0.1 then when we run this test with the null hypothesis that the purchase rate is 0.1 we're running this test where the null hypothesis is true does that that makes sense but why does that why does that make this uh you know essentially a straight line across so okay so let's let's again now like think through some potential errors that we can make so um so if the null hypothesis is true then um there's there's two things that could happen so if the null hypothesis is true then we don't want the pvalue to be significant right we if the null hypothesis is true we should not reject the null um and maybe instead of not significant pvalue above threshold right and then pvalue below threshold um make this a little bit easier right so if the null hypothesis is true we want our pvalue to be above the threshold that if the pvalue is above the threshold then we are correct um if the pvalue is below the threshold like if we simulate a sample where the null hypothesis is true we run our binomial test and we get a pvalue less than 0.05 then we've made what's called a type 1 error which means that we rejected the null hypothesis even though it's true and it it turns out right when we said so think back to our um our picture and our interpretation of that pvalue remember that in this example right the interpretation of the pvalue was the probability of observing 41 or fewer purchases given that the null hypothesis is true which is to say that our pvalue is exactly the probability of observing one of these values by random chance even when the null hypothesis is true so right like if we um right we got a couple of those examples of like when we when we randomly got 30 true and the pvalue was like 0.02 or something like that um then that was just that was a time when we would have rejected the null hypothesis even though we know that we were randomly picked those values with a 10 purchase rate yeah exactly and whoop right the p values that we collected here are just the probability of observing something more extreme than this given that the null hypothesis is true there is a it's a probabilistic process so every time we run this right every time we we simulate a new set of visitors we're simulating it so that we there is a a probability of getting something that is extreme that we don't expect and then every time we're just looking at the probability of observing something that extreme or more extreme wouldn't we more often get things that aren't as extreme right aren't we going to more often get exactly 50 people purchasing because the true probability is 10 so more often than not we're going to get 50 people purchasing less we're less often going to see 10 people purchasing um and so wouldn't that make it because we more often see 50 people purchasing wouldn't we more often um like see a different value here like what what's the so if we go back up to the the code um and we enter in let's the not in the loop let's just do one example uh if you scroll back and scroll up like if we hard code in rather than 69 there if we hard code in 50 right right what's the what's the um upsides 40 not not 50. oops sorry what's the pvalue going to be alex right so i think this is going to be like 0.5 or wait it's one oh because it's uh because it's twosided in this case um gotcha okay so wouldn't we see a lot more ones because we're most often going to get 50 there as that number that is a really well phrased question and i'm gonna be honest that my brain is like i when i really like putting you on the spot no no i this is really good and i feel like um i i this is one of those things where i go in and out of being able to explain it clearly and sometimes i have it in my head and sometimes my brain is tired and i'm like that's a good point alex uh let me see if i can explain that to you um let me let me like talk it through and maybe we can figure it out together and then if not i want to leave a little time to do one other thing totally um also in the chat if you have like a good way of conceptualizing this definitely share it with us and i guess one thing that we could do is can we run the the loop of a thousand over again and see another example of this graph because i'm curious because right now we do see one more often than not one right the the highest bar in the histogram is one um and i don't know if that's a coincidence or not no it's just a coincidence actually what i'd like to do to help answer our question is just i mean we know what this is going to look like but the so the part if we were to collect the purchases when we do this right if we like purchase [Laughter] and we do this and then below this we'll also do pld.hist um yeah purchase files here this should be a i guess a binomial distribution right right let's read it's funny that you're right it does like look like that every time but i promise you and if we crank it up to like 10 000 which might take more time to run i'm curious what happens right so okay so more frequently we're getting around 50 purchases um and now yeah let's see 10 000. it's running you can see a little good jupiter notebook trick is that you can see the okay there we go interesting why is this i'm actually confused why it looks like this every time like it it keeps seeming to like have the shape where it goes like up to two percent like point two and then up to point to one point oh so i hope i'm not like misleading you guys again like i did last time at the start of the next session though no no no but it should be that i i know this is like making me sad that my brain is not upset well it is confusing um um but basically this time it looks a little different but it still has that same shape i'm like i'm not sure about that but yeah we are getting this distribution which we expect um let's uh let's get to the the rest of the exercise and next week we can come back with further thoughts about this because i'm also curious about what's happening here okay yeah i have i definitely um i definitely can't explain this well when uh when i've like go through yeah sorry um no no it's i'm so glad that you do um okay so the last thing i wanted to kind of demonstrate is that um so remember so we went over these different kinds of errors where if the probability if the pvalue is below our threshold when the null hypothesis is true then we've made a type 1 error and so the question is like if the null hypothesis is true how often are we going to make a type 1 error and so let's pick a threshold let's pick 0.05 i guess okay and let's let's run this with a threshold of 0.05 um so i'm gonna copy and paste this below so that we can make a couple of edits to it and this time i'm gonna start a counter um and i'm gonna i'm gonna count the number of times that we make an error so i'm going to count the type 1 errors so i'm going to start my counter at zero and every single time i run this i'm going to um i'm going to say if actually we don't need to keep the pvalues this time so now i'm going to say if the pvalue is less than our threshold so less than 0.05 arbitrarily chosen threshold then i'm going to say add 1 to type 1 error so i'm going to say type 1 errors plus equals 1. which just means so and so this is a case where it's like we from our randomized sample we got a really let's say tiny value this time like 30 purchases when uh when we know that the the actual purchase rate is 10 and that's going to happen a certain number of times where we get this like really tiny value randomly yeah or i guess really large value randomly too since this is twosided right yeah so i'm going to do print type 1 errors over i'm going to do the this is going to be the type 1 error rate so we we ran this experiment 10 000 times and then i'm going to print how many of those 10 000 times resulted in a type 1 error okay let's try that it's gonna run it's a little slow quick question from chat briefly uh there's no uh you haven't seated the random numbers have you no i haven't seeded them um one thing that gets a little bit funky with um with the binomial distribution is also if our probability is too close to zero we start getting like um like some weird skew so we can try again but basically the point that i was trying to make and now i'm going to like go back and try to talk through your um your confusion alex but as you'll see here this number is pretty close to 0.05 right and because this should be uniformly distributed um basically exactly five percent of the time if you use a a threshold of 0.05 then exactly 5 of the time you're going to get a pvalue that is less than 0.05 because right like any pvalue between 0 1 and 1 is equally likely and so if we say what's the what's the probability of getting a pvalue less than 0.05 it's really just like that proportion of this area right and if that was a perfect rectangle then that would be five percent of the rectangle right um which is to say that basically whatever significance threshold you set becomes the type 1 error rate for your test and so um so if you say i'm going to set a significance threshold of 0.05 i'm going to reject the null hypothesis when um a pvalue is less than .05 then you're saying that i'm okay with the idea that five percent of the time the null hypothesis is going to be true and i'll still reject the null and so putting that in context of like back to the very start of like we've made this change to the website we want to see if purchases have uh decreased because of this change um or i guess are different because of this change because it's twosided right right then then this is saying like what it what is this can you put it in terms of like the actual experiment so right so and i think actually this like somehow helps with the confusion from before so remember that our experiment was essentially we're gonna look at a sample of 500 visitors and see whether the purchase rate in those visitors was less than our expectation so our expectation was that it would be 10 and we're gonna see if it's less than that or we're going to test this hypothesis that it's equal to 10 or less than that is our alternative and so now we're coming at it from another perspective we're saying let's say like the true purchase rate like if we could show this website to this version of the website to every visitor who could ever visit our website if we could show it to all of those people the true purchase rate the two probability of a purchase for each visitor would be 10 let's say let's suppose that that's true but we by random chance like we got 500 we got a sample of 500 uh visitors where among those 500 visitors the purchase rate just happened to be low by random chance we're saying this like five we're we're okay with the idea that five percent of the time if the true purchase rate was ten percent we're good five percent of the time we're still going to get a p value less than .05 right so if we did that this experiment of getting 500 different people 10 000 times like we're doing here then five percent of those times we're going to reject the null hypothesis even though it was true okay yes um okay one thing i want to see with respect to this picture is really quickly is if we change this to like 0.5 and 0.5 and 0.5 whether this shape is still persisting so now it looks more like i would expect um although it's still really jagged right i guess that's that jagged with 10 000 uh uh runs yeah i don't know this honestly might be yeah i'm surprised about it too i feel like there's something going on with how random seeds are being interesting or like how the random function is is working yeah um that's interesting but yeah that is really interesting it should be if the null hypothesis is true then this should be a a uniform distribution i'm going to um after this because we're running out of time but once i'm not on the spot i'm going to write out a clear explanation of this and why this is the case and then i will add it to the video but um but i want to leave you with kind of like the the main takeaway from all of this which is that when we run an experiment and we use a significance threshold so we say we're going to reject the null hypothesis if the pvalue is below some threshold the pvalue is is probabilistic remember that pvalue is the probability of observing something or more extreme given that the null hypothesis is true but that doesn't even if you get a pvalue of 0.001 that doesn't mean that what you observed is not possible it just means that it's unlikely but you can still observe that and so you have even if the null hypothesis is true so you have to have some threshold for error and what this means is because many people are using 0.05 as a significance threshold it means that five percent of all the tests that have been run with a significance threshold of 0.05 are wrong um if we're using that threshold right and so what ends up happening and we didn't get into this as much as i hoped but like if you let's say you run a hundred experiments at your company so i know my boyfriend for example his company is caught constantly running experiments let's say you run and they're probably running like thousands a day i would wouldn't be surprised so let's say but let's say you ran a hundred different tests what that means is that even if the null hypothesis was true for all of those 100 tests five of them would result in a significant pvalue at a 0.05 significance level and if all you do is report and act upon the ones that are significant then you're acting upon being a mistake and then that experiment might not be reproducible it was a fluke that you got something that your sample was so different from expectation but and how do you how do you counteract that though because you're no matter what you're always going to have whether it's five percent or one percent or point five percent right there's always going to be uh it's always probabilistic so like what's the what's the upshot of that how do you protect it yeah there's lots of different ways that people do this um sometimes people just use a smaller threshold so 0.01 instead so you have a lower chance of making a mistake um there's also like ways that you can basically uh what's the word um like adjust all of your pvalues based on the number of uh based on the number of tests that you've run so like a bonferroni adjustment is like one that's common um so there's different there are different uh approaches but the truth of the matter is you never are gonna fully you're never gonna fully escape the probability of some probability of making a mistake and the only antidote to that is being is one setting all of this like setting your threshold and setting and figuring out how you're going to adjust p values or what p what threshold you're going to use ahead of time figuring out how many tests you're going to run ahead of time and then if you're publishing a paper and you ran or your pub you're making a decision based on some results and you're like presenting it to your company you should show data for every single test that you run you ran not just the ones where you got a significant result right um so yeah the the antidote is clear communication of what you did and how you decided to do it um cool yeah cool all right um good work sophie uh sorry for putting on the spot i feel bad oh no no don't feel bad this is like what that's what this is all about i feel bad i feel like we've been doing these streams on tuesdays aft after the work day and so sometimes i you know i come in a little bit frazzled but i want to make sure that everybody's getting as much as possible out of these and i hope that they're super helpful and i will be sure and we're kind of pretending that this is like a this is a real class and so in a real class it's like we would come back next week and talk about this which is why we talked about last week this week so um so yeah i will i will make sure to post a more full explanation um so that everybody can benefit from that cool all right well thank you everyone we will uh yeah see you next week all right good one
