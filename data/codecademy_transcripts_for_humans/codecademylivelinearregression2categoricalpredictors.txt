With timestamps:

00:00 - the chat um we're gonna get started in
00:03 - just a minute
00:04 - um once we once we know we're fully live
00:08 - um but happy tuesday
00:13 - yeah i guess i'll use this time really
00:16 - quickly to
00:17 - plug uh our thursday
00:21 - office half hour um
00:24 - so just a reminder that on thursdays at
00:27 - the same time
00:28 - we are running a little office half hour
00:31 - where you can come and ask any questions
00:34 - that you might have
00:35 - uh we had one person last time so we
00:38 - really got to chat
00:39 - uh you know they got some personal
00:44 - two-hour or personal half hour to just
00:46 - like ask us whatever
00:47 - questions they had about uh about the
00:51 - data science path and data science
00:52 - curriculum on codecademy so
00:54 - if you have questions even if they're
00:55 - unrelated to this live stream
00:58 - you should definitely pop on and we'll
01:00 - be happy to answer them especially if
01:01 - it's a small
01:02 - group so cool yeah we're also looking
01:05 - into the
01:05 - codecademy as a pretty active discord
01:08 - and so uh we're looking into
01:10 - making a channel there talking with
01:11 - people over there um
01:13 - so if you are on the codecademy discord
01:16 - um yeah we we might be over there we'll
01:19 - prob
01:19 - probably we're gonna do a couple more of
01:21 - these um office hours on zoom
01:24 - and then uh in a few weeks probably try
01:26 - the the discord
01:27 - it'll be fun yeah i'm learning learning
01:29 - about discord now so this is good
01:32 - um all right i think we can
01:36 - get started um i see some people saying
01:38 - hello in the chat
01:40 - always always fun to know where you guys
01:42 - are signing in from so
01:43 - let us know say hello if you haven't
01:45 - already and
01:46 - we'll get started cool
01:50 - well let's see
01:56 - sophie has a uh has a new tool that
01:58 - we'll be using today too which is which
02:00 - is fun we um
02:01 - we have an ipad that we can do some
02:03 - drawings on
02:04 - yes um all right i'm gonna
02:08 - actually delete all this because i was
02:11 - playing around with this this morning
02:13 - but we'll come back to this in a second
02:15 - so um as a quick recap what we did last
02:18 - week
02:19 - was we took a look at a linear a simple
02:22 - linear regression model
02:24 - where we had um an outcome variable and
02:27 - then we had a predictor and that
02:29 - predictor was quantitative
02:31 - um i can actually even pull up exactly
02:34 - what that looked like
02:36 - um right so we had height and weight
02:40 - as this kind of dummy example we were
02:42 - trying to predict weight
02:43 - based off of height as our predictor and
02:46 - so we
02:47 - fit this line we talked about what are
02:50 - the components that we need to calculate
02:52 - in order to define what this line looks
02:55 - like
02:56 - um and then we looked a little bit at
02:58 - the assumptions of linear regression
03:00 - and that was as far as we got in week
03:02 - one
03:03 - so in week two we're now going to
03:07 - kind of transition to thinking about how
03:10 - we could build more
03:11 - complex models than just this simple
03:14 - line but in order to get there we need
03:17 - to talk about
03:18 - how to handle categorical predictors so
03:21 - you notice right now
03:22 - right we can think of the idea of
03:24 - drawing a line
03:25 - makes a lot of sense when our predictor
03:29 - is height
03:30 - our outcome variable is weight they're
03:32 - both quantitative and so we have
03:35 - points that are kind of along
03:38 - along an axis and then we can draw a
03:41 - line through them
03:42 - but what do we do if the predictor
03:44 - variable so imagine like the variable
03:46 - down here
03:47 - is not a number it's something like
03:50 - um something
03:54 - a binary thing binary or something that
03:56 - even is not binary that has multiple
03:58 - categories
03:59 - um trying to think like if you know
04:02 - we're actually trying to predict the
04:04 - weight
04:04 - of um of dogs and we have different
04:08 - breeds of dogs and we've got some
04:09 - poodles and we've got some
04:11 - uh some pugs
04:15 - chihuahuas and so we want to include
04:19 - something about the breed of dog um
04:22 - in our in our model but that's not a
04:25 - quantitative predictor
04:27 - so we can't really like organize those
04:29 - categories in any particular order along
04:31 - this axis
04:32 - it doesn't really make sense necessarily
04:35 - to think of it as a line
04:37 - event yeah well and interesting because
04:40 - we talked about this in our last uh
04:42 - stats series where there's almost like
04:44 - two scenarios here right where
04:45 - one is unordered where it's chihuahua
04:48 - and poodle and your other dog breed
04:49 - there's no order associated with those
04:51 - but then you can also have categorical
04:52 - variables where it is ordered where
04:55 - i know i know we said last time like um
04:57 - you know a rating of one to ten
04:59 - isn't necessarily the best thing to use
05:02 - but there's
05:03 - right is that true that there's kind of
05:05 - like two different ways of thinking
05:06 - about this where ordered versus
05:07 - unordered
05:08 - really makes a difference yeah so if you
05:11 - have an
05:11 - ordered categorical variable and you
05:13 - think that the order
05:15 - matters for predicting your outcome then
05:19 - yeah it actually people do it all the
05:22 - time where we
05:23 - they use a an ordered categorical
05:26 - variable
05:26 - as a numerical variable as a numerical
05:29 - predictor
05:30 - um so just like if you have a rating on
05:32 - a scale from
05:33 - one to ten you can put that into
05:36 - your model right you can just have the
05:38 - numbers one through ten and treat it
05:40 - like a regular number
05:41 - um and people do that all the time if
05:43 - it's your
05:44 - outcome variable you need some different
05:47 - methods but
05:48 - depending on the circumstance but um but
05:52 - yeah
05:52 - for a for a predictor variable you can
05:56 - definitely just put that in
05:58 - normally like you would height um but if
06:02 - it's a fine line right so it's like
06:05 - what about uh like
06:08 - seasons of the year like that's kind of
06:10 - order
06:11 - but there's not really a smallest and
06:14 - the largest
06:15 - do you think that you know starting from
06:19 - if you're looking at the character right
06:21 - that it just goes
06:22 - up with the seasons numerically like no
06:25 - you think it's probably
06:27 - i don't know so depending on how you
06:30 - what you count as number one and what
06:32 - you count as number four
06:34 - uh yeah that also loops where like four
06:36 - should also be close to one
06:38 - uh yeah so it's it's kind of it's a
06:41 - fine line and you have to definitely
06:43 - think about how you're gonna code
06:45 - categorical variables
06:47 - um cool i see lots of people joining
06:50 - sao paulo new york city nice
06:54 - london columbia super awesome
06:58 - it's always fun to see people from all
06:59 - over the world here
07:01 - um cool so i'm gonna jump in
07:05 - so for today we're gonna be using this
07:07 - kind of made-up data set
07:09 - um we'll start with a made-up data set
07:12 - then we'll use
07:13 - a non-native data set um but so
07:17 - this is something that i simulated we're
07:19 - imagining that we work for
07:21 - a company and we're trying to understand
07:23 - we want to
07:24 - model the time that people spend
07:28 - on the websites we want to kind of
07:29 - predict how long is somebody going to
07:31 - spend on our website
07:33 - and so we collect some data about how
07:35 - many seconds people are sending on the
07:37 - website
07:38 - we also collect some data about their
07:39 - age and what
07:41 - browser they were using and in this case
07:43 - we're going to just stick
07:45 - pretend like only people with safari or
07:48 - chrome
07:49 - are visiting our website so that's
07:51 - that's
07:53 - a caveat here okay
07:56 - so eventually what we're going to build
07:59 - up to
08:00 - is a model where we could include both
08:03 - age and browser as predictors
08:07 - but for right now in order to understand
08:09 - what's going on in that model
08:11 - we're going to first think about the
08:13 - model where we
08:14 - just include browser
08:17 - so what i'm going to do is i'm just
08:19 - going to go ahead
08:20 - and demonstrate that i can fit this
08:23 - model
08:25 - and then we're gonna go back and we're
08:26 - gonna talk about what's going on
08:29 - so um let's see
08:33 - we've got statsmodels.api
08:36 - um
08:39 - as sm so to fit this model we've got
08:43 - sm dot i think
08:46 - hold on actually i need to pull the
08:50 - code ols formula
08:55 - spray cap um
08:58 - well us from formula and then this time
09:01 - our formula is just going to be
09:03 - time in seconds predicted by browser
09:09 - and our data is called
09:16 - yeah and again just stressing that we're
09:19 - using some of these
09:21 - built-in packages which it takes a
09:22 - little bit of like
09:24 - looking at the documentation like sophie
09:26 - i imagine you didn't
09:27 - have you know you didn't know this from
09:29 - formula
09:30 - um function uh memorized or anything
09:34 - and so again kind of just stressing that
09:37 - the exact code to make this happen isn't
09:39 - uh really the highlight here yes
09:43 - um
09:46 - exactly and i saw you answered this
09:50 - question
09:51 - quickly but yes i was talking about dogs
09:53 - as an example of a categorical variable
09:57 - um that you could use to predict weight
09:59 - in this
10:00 - example we're going to use a different
10:02 - categorical brow a different categorical
10:05 - variable specifically browser to predict
10:08 - time in seconds but just in general
10:10 - today we're talking about the idea of
10:12 - categorical predictors in a linear
10:14 - regression model
10:17 - okay so i ran this
10:21 - linear regression press run again so
10:23 - this goes away
10:25 - and you'll notice that i get some output
10:28 - so it was able to run
10:32 - um so we we can do this but now we see
10:35 - that
10:36 - instead of getting an intercept and a
10:39 - slope on browser we're getting
10:41 - the slope on browser
10:45 - t dot safari and so what
10:48 - what's going on there why are we getting
10:50 - this new variable
10:52 - here that's what we're going to try to
10:53 - figure out
10:55 - so to start i'm going to also
10:58 - demonstrate
10:59 - if i just plot
11:03 - this and i plot
11:06 - website dot browser
11:10 - against website time
11:15 - seconds
11:20 - actually
11:25 - i actually get a plot as well and the
11:28 - plot looks like this
11:29 - it has um safari on one side
11:33 - with a bunch of dots and chrome on the
11:35 - other side with a bunch of dots
11:38 - and what i see here right so
11:42 - i should have put um i should have
11:45 - i think if i do sns.scatter
11:48 - plot then it automatically puts the axes
11:52 - yeah
11:52 - so this axis is time in seconds
11:57 - and then this access is our browser so
12:00 - we've got safari and chrome
12:01 - even though this isn't a number it's
12:03 - still putting safari over here in chrome
12:05 - over here
12:06 - for some reason and then i can see that
12:09 - these dots
12:11 - are each uh so like all the dots in this
12:14 - line are people who were accessing the
12:17 - website using safari
12:19 - and this is the and each dot represents
12:21 - the amount of time and seconds that they
12:23 - spend on the website so like
12:25 - this dot is someone who came on the
12:27 - website using safari and
12:29 - spent about 580 seconds on the website
12:33 - and this dot is someone who spent over
12:35 - 700 seconds on the website
12:37 - and accessed it using chrome
12:40 - cool so
12:44 - looking at this do you think there's a
12:45 - relationship alex between
12:47 - what browser someone is using and how
12:49 - long they're spending
12:50 - on the website i mean it certainly
12:53 - doesn't seem as strong as our last one
12:55 - right
12:55 - comparing it to what we did in the last
12:57 - session where we um
12:59 - had you know points that looked like
13:01 - they could kind of fall along a line
13:03 - but obviously not perfect um
13:07 - you know that looked like a pretty
13:08 - strong relationship here i can kind of
13:10 - imagine drawing a line that maybe is
13:12 - sloping upward a little bit
13:14 - um but you know the the
13:17 - uh the points are gonna be pretty far
13:19 - off of that line
13:22 - yeah so well in this case right we don't
13:25 - really have
13:26 - first of all these aren't numbers but
13:28 - second of all right we don't have
13:30 - any points in here so there's gonna be
13:34 - lots of and then there's a lot of
13:36 - variation
13:37 - even among these these points so by just
13:40 - drawing a line it's
13:41 - not like we're explaining that much of
13:44 - this variation
13:45 - um but i would say looking at this right
13:48 - these dots tend to be higher than these
13:52 - dots like if you had to pick the middle
13:53 - of the safari dots
13:55 - it might be somewhere around 400 and
13:58 - then if you had to find the middle of
14:00 - the chrome dots
14:01 - it might be somewhere around 500 and
14:04 - maybe a little bit easier to see
14:06 - in a side-by-side box plot
14:10 - but here we've got safari the median is
14:13 - a little before
14:14 - below 400. the median for chrome is a
14:17 - little
14:17 - below 500 and so the middle of these two
14:21 - distributions is
14:22 - is kind of different like there is some
14:25 - relationship between
14:27 - which browser someone is using and how
14:29 - long they're spending on the website
14:30 - even though
14:31 - it's not prescriptive you know if you
14:33 - are accessing from chrome
14:35 - you might spend as few as 250 seconds
14:38 - and as many as over 700
14:40 - if you're accessing from safari you
14:42 - might be sending
14:44 - anywhere in this range as well but
14:46 - overall these numbers are smaller than
14:48 - these numbers
14:50 - yeah cool so
14:54 - this is kind of modeling some of that
14:58 - so let's look at those or are you are we
15:01 - about to talk about those two numbers in
15:03 - in particular well we will talk about
15:06 - those numbers in just a second
15:08 - yeah cool i think one thing that's
15:10 - helpful to know
15:12 - and this is this is something that i
15:14 - think will help you if you're thinking
15:15 - about trying to learn
15:17 - other packages as well is
15:21 - what's happening under the hood when you
15:24 - when we ran this code um
15:27 - a bunch of things right like our
15:30 - computer is doing some calculations and
15:32 - there are some steps
15:33 - that happen in the midst of those
15:36 - calculations that we're not seeing
15:39 - so one thing that's a little bit helpful
15:41 - is to actually
15:42 - break that down a little bit and see one
15:45 - of the
15:46 - the middle steps so i'm gonna do that
15:49 - by using this um this package called
15:52 - patsy
15:53 - so actually patsy is a
15:57 - is a dependency of stats models and it
15:59 - uses
16:01 - this package in order to fit this model
16:04 - and so i'm going to just use patsy
16:06 - directly to show you what
16:08 - that middle step looks like so using
16:12 - patsy.d matrices
16:15 - i'm going to actually grab this exact
16:18 - same
16:21 - code that i used with stats models
16:26 - um and i'm going to do return type
16:29 - equals data frame so that we can see
16:31 - this
16:35 - and actually here let me run this to see
16:37 - what the output is so
16:38 - there's actually two different pieces of
16:41 - output
16:42 - there's a y vector and an x vector
16:46 - um don't worry too much about that right
16:48 - now but i'm just going to save them as
16:50 - y and x and then i'm just going to print
16:53 - out
16:53 - x so that we can take a look at it
16:57 - okay so this is what x looks like
17:00 - um in two weeks from now we're going to
17:03 - talk about
17:04 - this column of ones um and why that's
17:07 - there
17:08 - that has to do with some of the matrix
17:10 - algebra that we're using
17:11 - to calculate the ordinary least squares
17:15 - solution to this regression problem
17:18 - but i want to point out that we get this
17:21 - same variable that we saw
17:23 - before and you'll see that it's
17:27 - a bunch of ones and zeros and
17:30 - the first five rows are one zero one
17:32 - zero one
17:33 - if we look back at our original
17:37 - data we've got safari chrome safari
17:40 - chrome safari
17:42 - what's happening here is we're taking
17:45 - this data
17:47 - and we're re-coding it as ones and zeros
17:51 - because it's just a binary variable
17:54 - there are two
17:54 - possible outcomes and so we're just
17:57 - replacing one of them with a one
17:58 - and one of them with a zero and
18:00 - specifically
18:02 - we're replacing safari with a one and
18:05 - chrome with a zero
18:07 - and if we had if we weren't binary if we
18:08 - had multiple variables would we get one
18:10 - zero one two so
18:14 - um no
18:17 - we won't we're gonna do that in a second
18:20 - but
18:21 - actually no we won't because once
18:23 - remember once we
18:24 - have um once we have
18:28 - more numbers like zero one two then
18:31 - we're
18:31 - really assuming that there's an order
18:33 - that zero comes before one comes before
18:35 - two and we don't want that
18:39 - so um in this case safari was coded as
18:43 - a1 and um and chrome was coded as a zero
18:48 - and that's what this this means here so
18:51 - when it says browser t.safari
18:54 - it's saying that t
18:57 - means it stands for true so it's saying
19:02 - true that is equal to safari
19:06 - and it's a one if that's true and it's a
19:10 - zero otherwise if you've programmed in
19:14 - other languages you might know that
19:16 - usually true
19:18 - is coerced to a one and then
19:22 - false a zero so
19:26 - this kind of makes sense with this
19:29 - like true false construct um
19:34 - cool so i don't see any questions so
19:39 - i'm gonna jump over to this picture
19:43 - so coming back to this picture
19:46 - i'm realizing now that it's a it's a
19:49 - little bit misleading because in this
19:50 - picture
19:51 - safari is is overall
19:55 - on the right so in reality these would
19:57 - these are
19:58 - switched uh when we're thinking about
20:01 - this
20:01 - um i see where that negative might be
20:05 - coming from now because
20:06 - i was saying oh this is probably if i
20:09 - were to draw a line
20:10 - in this picture it would probably be
20:11 - going up right it would have a positive
20:13 - slope
20:14 - but if chrome is actually on the left
20:16 - and safari is on the right then i would
20:17 - say oh that has a negative slope and so
20:19 - i'm guessing that's why
20:20 - this negative number is showing up yeah
20:23 - i think that this is so here's what i'm
20:26 - going to do to make this
20:28 - a little bit nicer i wish i had done
20:30 - this
20:31 - ahead of time but let's see if i can do
20:34 - it
20:34 - quickly here so if i do
20:38 - website dot browser
20:41 - dot replace
20:44 - and then i'm gonna replace safari
20:47 - [Music]
21:00 - with
21:02 - um one dash
21:07 - safari and i'm gonna replace
21:14 - chrome with
21:19 - zero dash chrome
21:23 - and i'll do in place equals true so that
21:27 - i
21:28 - i make this replacement in the actual
21:35 - data let's see if this works cool
21:39 - and then i bet you ah
21:44 - still where you think it's like
21:46 - alphabetical
21:48 - i was assuming yeah yeah
21:51 - what if i do
21:56 - um
21:59 - like a crow
22:03 - i want you want chrome on the left
22:14 - so a chrome and b safari
22:20 - we'll try one more time it doesn't work
22:23 - it doesn't work
22:25 - yeah why is that
22:28 - oh well um maybe it's just whichever is
22:32 - first in the list is on the right
22:36 - um i mean there's obviously ways that we
22:40 - could dig into the scatter plot function
22:41 - to like force the axis to be
22:43 - in a a certain order yeah i wonder if we
22:47 - can just like
22:48 - well okay i'm gonna let it go um okay
22:52 - so instead i guess maybe i'll draw a
22:56 - picture
22:57 - this will be fun okay
23:00 - so i'm gonna stop share for a second
23:04 - and let me this is my new
23:08 - technology of the day
23:11 - okay um
23:16 - we're gonna get an iphone ipad via cable
23:21 - share
23:24 - and now can you guys see that
23:27 - yes that looks good yeah some someone in
23:29 - chat is saying that probably because
23:31 - safari is coming first it plots at first
23:33 - so the yeah the the order of that data
23:36 - was probably determining it not the name
23:38 - i i agree with that okay
23:41 - i have to redraw this picture now
23:44 - because i was
23:45 - drawing this before as uh
24:01 - but we've got this sort of picture
24:05 - where we've got
24:10 - um we got some points for safari
24:14 - right and then we've got some points for
24:17 - chrome
24:22 - i'm not going to do a good job right
24:25 - and what's happening is we're getting
24:28 - we're calculating a regression line
24:30 - just as we did before
24:33 - but that regression line is just
24:36 - connecting
24:37 - the middle of these two points so
24:40 - if we have a point here
24:44 - and we have a point here
24:48 - sorry the middle of these two sets of
24:50 - points
24:51 - our regression line
24:56 - is connecting them like this
25:00 - now okay we had
25:03 - i wish i could give you guys the side by
25:06 - side of the numbers
25:07 - but i'll write them i guess i'll write
25:09 - them over here so
25:12 - in our model we had
25:16 - that the intercept
25:21 - let's think uh
25:24 - we had that the intercept was equal to
25:29 - uh like 490
25:34 - and then we had that the
25:40 - that like browser browser
25:43 - t dot uh what was it safari or chrome i
25:46 - forget which one was one which one was
25:48 - zero
25:49 - t dot safari
25:54 - equals negative 99 about
26:01 - let's like think about what this
26:03 - corresponds to
26:05 - on our graph so when it says
26:08 - intercept equals 490 that means that
26:12 - the intercept the y-intercept is 490.
26:16 - and remember that the y-intercept is
26:19 - just the same as
26:21 - the the point at which our line crosses
26:24 - the y-axis in this case the y-axis
26:28 - right is the same
26:32 - as where all these points are
26:36 - um because i don't understand the joke
26:43 - just some anime uh
26:46 - um so here right remember
26:50 - this zero was corresponding to chrome
26:55 - so the y-intercept is this red point
26:58 - here
26:59 - and that's our 490
27:02 - right that's
27:06 - hitting the y-axis at 490.
27:10 - so that's where well so is that the
27:15 - that's the point on
27:18 - uh on chrome which is zero that is 490
27:22 - or is it like if i extended the
27:24 - so that's different than what i expected
27:26 - what i expected was oh let me extend
27:28 - this line
27:29 - um so you know so the line hits the um
27:34 - the y-axis and then that's my intercept
27:37 - but i guess that doesn't really make
27:38 - sense because it's already
27:39 - zero right yeah so it's all like kind of
27:42 - semantics of how i plot this
27:44 - so i'm plotting it with space between
27:47 - this
27:48 - axis and this this spot
27:51 - right but remember the y-intercept is
27:53 - where
27:54 - the line crosses the y-axis and the
27:57 - y-axis
27:58 - is where the x-variable is equal to zero
28:02 - so the y-axis is actually this dotted
28:05 - line
28:07 - right so really it's all on top of each
28:09 - other but just for ease of drawing this
28:11 - so we can see the blue dots and stuff
28:13 - you've shifted it over a little bit yeah
28:15 - so
28:16 - if i want to make this like a little bit
28:18 - nicer so that we can all
28:20 - see it um we could
28:32 - i've erased this and we could think of
28:35 - this as our y-axis
28:39 - and our points are just kind of along it
28:41 - right
28:42 - like these these points that we drew
28:48 - for chrome are all along what's
28:51 - technically
28:53 - our y-axis because chrome
28:56 - we're we're making chrome equal to zero
28:59 - and our y-axis is where well
29:04 - that should be a straight line but
29:08 - you know right yeah and so that makes
29:09 - sense for our intercept there where it's
29:11 - um
29:12 - yeah 490 the line doesn't really
29:14 - continue to extend i guess it does
29:15 - extend in
29:16 - to the left but uh it's hitting the axis
29:19 - right where
29:20 - since chrome is encoded as zero right
29:22 - okay
29:24 - so our line our line technically
29:28 - continues on in both directions
29:31 - but the thing that we care about is that
29:34 - the y-intercept is actually the middle
29:37 - of these blue look
29:39 - these blue points that correspond to
29:42 - chrome
29:44 - and then we've also got some points over
29:46 - here
29:47 - that correspond to safari
29:51 - right so these are our safari points
29:57 - and we we need to understand what this
29:59 - number is coming from
30:00 - or the where this number comes into play
30:03 - and remember
30:04 - that a line has to have a y-intercept
30:09 - and it has to have a slope
30:12 - and so the slope remember is
30:15 - rise over run so the slope of a line
30:23 - over run in this case
30:26 - this line has a positive run
30:29 - so the run to get from one point to the
30:32 - next
30:34 - we move over
30:37 - one unit that's
30:40 - a run of one unit
30:44 - and then we have to go down to get to
30:47 - the next point
30:50 - by some distance this is our rise
30:55 - and it turns out we know that's like
30:56 - three so i bet if we looked in our data
30:58 - and found the middle of
31:00 - the safari data it would be what 391
31:06 - right yeah so we'll do that in just
31:10 - one second but i'm gonna just write
31:13 - in here right so the rise
31:17 - is equal in this case
31:23 - equal to negative 99
31:30 - and so our slope is rise over run
31:34 - it's negative 99 over 1 or
31:37 - negative 99.
31:42 - we have a really good question from
31:43 - harsh deep of
31:45 - last time we had weight and height and
31:47 - so it was a little bit
31:48 - like more intuitive to understand what
31:52 - uh what these um coefficients are
31:54 - meaning so
31:56 - uh his question is what does this
31:58 - represent in terms of the data what
32:00 - is 490 with respect to time and browser
32:04 - yeah so that's that's a really great
32:06 - question
32:07 - um so in this picture and we'll show it
32:09 - in the data in just a second
32:11 - you'll notice that the 490
32:15 - right is the middle of all of these
32:19 - blue points and the blue points are
32:22 - amount of time
32:24 - spent by chrome users on the website
32:28 - so the middle is going to end up being
32:31 - the mean
32:33 - time spent on the website by
32:36 - chrome users and as we see right
32:39 - we can think of this as this negative 99
32:42 - as a slope
32:43 - but because the run between these two
32:46 - points is one
32:47 - right like the difference between zero
32:49 - and one is just one
32:50 - then it's really just the rise
32:55 - or the difference in the vertical
32:59 - uh height of these two red dots
33:03 - and this red dot represents the mean
33:07 - time spent on the website by safari
33:09 - users
33:10 - so in other words this
33:13 - minus 99 represents the fact
33:17 - that on average safari users are
33:20 - spending about 99 seconds less
33:23 - on the website compared to chrome users
33:28 - y-axis is seconds yes
33:35 - good um good call
33:38 - so the y-axis of the seconds the x-axis
33:42 - is browser and we've got
33:46 - our y-intercept which is mean
33:50 - time for chrome users of 490
33:54 - and then we've got our slope rise over
33:56 - run
33:57 - run is one so our slope is the rise
34:01 - and that is this distance and this is
34:04 - the
34:04 - vertical distance between this point and
34:08 - this point
34:09 - these two points each represent the
34:11 - middle of their respective sets of
34:13 - points
34:15 - the middle being the mean time spent
34:18 - on the website
34:24 - we got another good question from the
34:26 - chat of like why is the rise negative
34:29 - oh that's a great a great question so
34:32 - this comes back to um a little bit of
34:36 - like graphing algebra right so
34:39 - um rise so coming back to just like
34:42 - equation of a line and slope
34:44 - slope is rise over run and when we when
34:47 - we think about slope
34:49 - um we think about to get from one point
34:52 - on a line to the next point on the line
34:55 - how far over do we have to go and how
34:57 - far
34:58 - vertically do we have to go when we talk
35:01 - about
35:02 - over when we talk about horizontal and
35:04 - vertical distance
35:05 - we always think of going to the right as
35:08 - positive
35:09 - and going to the left as negative and we
35:11 - think of going
35:12 - up as positive and down as negative so
35:16 - this is a positive sloping line this top
35:19 - one
35:20 - for this positive sloping line to get
35:22 - from one point to another point
35:24 - we go our rise
35:27 - is up and our run is over
35:31 - so our rise is positive and our run is
35:33 - positive
35:34 - so a positive over a positive is a
35:37 - positive
35:38 - for this one to get from one point to
35:40 - the next
35:43 - our rise is down
35:47 - right and then our run is positive or we
35:50 - could also think
35:52 - of it as like run is positive
35:56 - or sorry rise is positive run is
35:58 - negative in either case
36:00 - we've got either a negative over a
36:03 - positive or a positive over negative
36:06 - a negative over a positive or a positive
36:09 - over a negative is negative
36:11 - so the slope is negative because we have
36:14 - to go
36:14 - right this point when we go over
36:18 - one unit positive one unit
36:21 - we have to go down to get to
36:24 - the average safari time and so the rise
36:29 - is negative 99 which really just tells
36:31 - us that
36:32 - the average for safari is less than the
36:36 - average
36:36 - for from
36:40 - cool okay
36:45 - exactly
36:49 - yes um okay now this is
36:52 - nice and pretty i'm going to stop this
36:54 - share and i'm going to go
36:56 - back to back to my code
37:06 - okay so now let's go ahead
37:12 - and i'm going to copy this over so you
37:15 - can print it out down here
37:18 - run and then i'm going to also do
37:23 - website dot group by
37:26 - [Applause]
37:27 - browser dot mean
37:30 - [Music]
37:34 - i think and then we really just want
37:39 - ten seconds so this gives us
37:43 - the mean time in seconds that
37:47 - people spent on each um
37:52 - on each browser go back to
37:55 - our regular
38:00 - okay um so we've got
38:04 - 489.7 seconds on chrome and
38:09 - 390.65 seconds
38:11 - about on safari on average
38:14 - and you'll see right that this number
38:17 - matches up with our intercept so that's
38:19 - what we were talking about before
38:20 - the intercept gives us the average time
38:23 - spent
38:24 - on chrome and then
38:27 - this number we said gives us the
38:29 - difference in
38:30 - mean time spent on chrome versus safari
38:34 - and it tells us that people are spending
38:36 - less time on safari
38:38 - so if we take this number
38:42 - and we subtract this number
38:45 - basically add these two together
38:50 - we get 390.64
38:54 - this 64717
38:58 - which is exactly the same as we
39:01 - calculated
39:02 - them as the mean time spent
39:05 - on safari i guess so my question after
39:09 - seeing all this is
39:10 - like all of this follows together we dr
39:12 - we have those two like yellow points
39:14 - uh so that corresponds to the intercept
39:16 - and then we can find the slope between
39:18 - those two points
39:19 - um but i i guess my question that kind
39:22 - of like relates back to the very
39:23 - beginning is like why do we choose the
39:24 - mean right we have these
39:26 - um we have these two columns of points
39:28 - and we could choose the median
39:30 - or we could choose you know some other
39:32 - metric to find the middle
39:34 - um all of this is coming from we chose
39:37 - the mean of these two points so why
39:39 - why the mean and not something else it's
39:41 - a great question
39:42 - so it it turns out and you can prove
39:45 - this to yourself mathematically
39:47 - remember that when we fit this model
39:50 - we're using the ordinary least squares
39:52 - method
39:54 - which is to say that we're trying to
39:56 - minimize
39:58 - the distance between each point
40:01 - and the line um
40:05 - and so if we draw this line on top we
40:08 - can
40:10 - think
40:13 - if i remember properly
40:16 - yeah you can here i'm gonna just grab
40:19 - this but
40:20 - uh i can explain what i'm doing so
40:24 - [Music]
40:29 - if i re-plot this and then
40:32 - on top of it i just plot the points
40:35 - 0 comma 390 and 1 comma
40:40 - 489 it'll plot this line
40:43 - it's kind of backwards for this example
40:47 - but we'll just run with it right if this
40:50 - is our line we're fitting this line to
40:53 - minimize
40:54 - the squared distance between all of the
40:56 - points in the line so
40:58 - to minimize the square distance between
41:00 - each point
41:01 - and this middle and it turns out that
41:05 - mathematically
41:06 - the point that minimize the the point
41:09 - that minimizes the distance between
41:11 - all of these points and this middle is
41:13 - the same as the mean
41:16 - mean people yeah and and then again uh
41:20 - this line looks different this is a
41:21 - positive slope and again that's because
41:23 - we're actually chrome is our
41:26 - is zero safari is one and so if we could
41:29 - flip those two if we could put
41:31 - chrome on the left and safari on the
41:32 - right um
41:34 - but still connect the two means then it
41:35 - would look identical into that graph we
41:37 - were just drawing before
41:39 - exactly um okay
41:42 - in the interest of time i'm going to
41:44 - switch over to another example where we
41:46 - use
41:47 - a categorical variable with some more
41:50 - categories
41:51 - so i'm going to grab this data set from
41:58 - here this is back to our rentals data
42:01 - set if you've
42:02 - uh if you've come to any of these live
42:05 - streams before
42:07 - or done any of the uh regression
42:10 - or other machine learning stuff on our
42:13 - website you may have seen this data set
42:15 - before
42:16 - we're just going to look at a subset of
42:18 - it where
42:19 - we have some information about rental
42:22 - prices in manhattan and we have some
42:25 - information about what burrow
42:27 - each of those apartments was in um in
42:30 - manhattan
42:32 - and you'll notice that burrow has
42:36 - in this case there's more than three
42:38 - burgers but
42:39 - uh in this in this data set we have
42:42 - a column burrow that has three possible
42:45 - values
42:46 - brooklyn manhattan and queens and so now
42:48 - we've got
42:50 - one more uh category
42:53 - and so all of a sudden this initial
42:57 - setup no longer works
43:02 - okay uh so
43:06 - i see there's a question so this mean
43:09 - time
43:09 - the mean time people spend on the
43:10 - website or the meantime
43:12 - the web browser loads the website in um
43:15 - for this example
43:16 - i was using the like
43:19 - it's it's not real data but i was just
43:21 - making up that it was the amount of time
43:23 - people were spending on the website
43:25 - um but it could be either but it could
43:27 - be either you know you could have a
43:29 - different
43:30 - a different data set um
43:33 - [Music]
43:35 - yes and yes i see someone commented
43:39 - formula for mean is the same as for
43:40 - average
43:41 - um it's just the same thing
43:44 - yeah use different names for different
43:47 - things sometimes
43:48 - um okay
43:52 - so similar problem
43:55 - but now we've got three categories
43:57 - instead of two
43:58 - how are we gonna handle this number of
44:01 - categories
44:02 - is the question so i'm gonna actually do
44:06 - the same thing that i did before with
44:09 - patsy.d matrices i'm going to print out
44:12 - the
44:13 - the x matrix for this problem
44:17 - um where we're we're predicting rent
44:20 - based off of borough
44:24 - and this time the data is rentals
44:28 - and if you like the web browser example
44:33 - again
44:33 - this could this would be the exact same
44:34 - thing if we added a third browser if
44:36 - you know yeah we could do predicting
44:38 - time based on chrome safari or firefox
44:40 - or whatever you want
44:42 - exactly
44:45 - um i probably should have done that but
44:48 - just
44:48 - make a new data set um okay so you'll
44:51 - notice that now we actually get
44:54 - multiple columns that didn't exist
44:57 - before now we get
44:59 - two columns of the format borrow t
45:02 - something but now we've got furo t
45:05 - manhattan and burrow t queens
45:10 - and then we don't have boro t brooklyn
45:12 - even though we know that that's
45:13 - represented in the data set
45:15 - so let's look through this we've got our
45:18 - first five rows remember are brooklyn
45:20 - manhattan manhattan
45:21 - queens queens so for the t manhattan
45:24 - column we've got zero one one zero
45:28 - zero and we see that that matches up
45:31 - with
45:32 - the two rows where the apartment was in
45:35 - manhattan
45:36 - so this column is going to be zero
45:40 - everywhere that the apartment was
45:43 - not in manhattan and it's going to be
45:45 - one
45:46 - when the apartment is in manhattan um
45:51 - it doesn't matter if it's not in
45:53 - manhattan and in brooklyn or not in
45:54 - manhattan and in
45:55 - queens either way it's going to be a
45:58 - zero if it's
46:00 - not manhattan and a one if it is
46:02 - manhattan
46:03 - we call this like a dummy variable for
46:07 - manhattan and then
46:10 - for this column we have the same thing
46:13 - but for queens
46:14 - so it's a one if the apartment is in
46:18 - queens that's why we have two ones here
46:20 - and it's a zero everywhere else so
46:23 - brooklyn or manhattan is not queens
46:25 - so we're gonna get zeros everywhere else
46:28 - um
46:28 - alex do you have an idea why we don't
46:31 - need to have
46:33 - brooklyn here yeah i guess we can figure
46:36 - that out from kind of process of
46:38 - elimination
46:38 - of if we know there's only three
46:40 - categories and
46:42 - i guess taking that row zero for example
46:45 - it's not manhattan
46:46 - it's not queens and because we know we
46:48 - only have one more category
46:50 - we can kind of um deduce
46:53 - the brooklyn column based on um based on
46:56 - these other two columns
46:57 - exactly so having a separate burrow
47:02 - t brooklyn column
47:05 - doesn't give us any more information
47:08 - when we get into multiple linear
47:10 - regressions so we have multiple
47:11 - predictors
47:12 - we'll talk about this issue of
47:14 - co-linearity which means
47:16 - if you have an extra column of your data
47:19 - that provides
47:19 - no new information compared to the other
47:23 - columns that you have
47:24 - then that actually causes issues with
47:26 - fitting the model
47:28 - um so we've got
47:31 - just the two dummy variable columns that
47:34 - we would need in order to
47:36 - fully recreate this borough column but
47:39 - we have the minimum amount
47:40 - of extra information
47:44 - okay so now let's go ahead
47:47 - and actually run the regression um
47:54 - and we'll see what this looks like
47:57 - so we've got model equals
48:02 - and this time we're doing
48:06 - rent predicted by burrow
48:09 - we're printing the model parameters
48:12 - and we'll see that
48:16 - we get an intercept again and then as
48:20 - expected based on this output we get a
48:23 - slope
48:24 - for t manhattan and we get a slope
48:28 - for t queens
48:31 - two different slopes what do we do with
48:35 - that
48:36 - so i i have no clue how to how to
48:38 - interpret the two different slopes but
48:40 - if i were to do it
48:41 - independently of each other so the
48:43 - intercept is where it's hit
48:45 - is going to be the mean of the
48:49 - um whatever is is category categorized
48:52 - as
48:52 - a zero which i guess in this case is
48:55 - uh well i guess it's it could be either
48:59 - of them right
49:00 - like it's not the same thing where we
49:01 - have like it's not zero one two
49:04 - um so i don't i actually don't know i
49:06 - was i was gonna say i was gonna guess
49:08 - that that
49:09 - uh 3000 was the mean of brooklyn
49:12 - um i don't know if that's the case or
49:14 - not so
49:16 - let's actually
49:19 - let's draw it out um i'll switch to
49:23 - this is so fun um
49:27 - i'll switch to my drawing board again
49:38 - okay um
49:42 - see that and um
49:48 - i'm gonna just write out these numbers
49:51 - again
49:52 - um so we've got intercept
50:01 - our intercept was equal to
50:06 - three three two
50:09 - seven our borough
50:16 - t manhattan
50:21 - was equal to one one
50:24 - eight one roughly and then our
50:28 - burrow
50:32 - t queens
50:37 - was equal to negative
50:40 - eight one one
50:43 - it turns out we have
50:47 - two lines that we've now
50:51 - determined based off of this
50:56 - this regression output so
50:59 - this time in our first graph
51:03 - we've got a comparison between
51:06 - brooklyn and manhattan so
51:10 - in our brooklyn versus manhattan graph
51:13 - we've got some points for the rental
51:16 - price
51:17 - in brooklyn and then we've got some
51:19 - points for
51:20 - the rental price in manhattan
51:27 - again this is
51:32 - this y-axis rental price
51:38 - and then the middle
51:44 - of those points is going to be
51:51 - that's our mean rental price in
51:56 - brooklyn here i'll label these axes so
51:59 - this axis here is brooklyn
52:04 - and then this axis here is
52:07 - manhattan
52:12 - workout we're treating brooklyn as zero
52:15 - we're treating manhattan as
52:17 - one and then
52:20 - we've got the mean here
52:25 - the mean in brooklyn is equal to the
52:28 - intercept
52:30 - so the mean in brooklyn
52:39 - mean in brooklyn is 3327
52:45 - and then this is our line
52:50 - our regression line
52:54 - and remember again since manhattan is
52:56 - one brooklyn is zero
52:58 - our run is one so
53:01 - the slope is really just the rise
53:04 - so the slope is the vertical distance
53:07 - between
53:08 - these two
53:14 - that's our slope
53:18 - and that's equal to this value
53:26 - so alex what is
53:31 - the slope for
53:34 - t manhattan what does that represent
53:40 - um so that represents
53:44 - yeah the uh so i mean i can figure out
53:47 - the
53:48 - at the mean of manhattan based on based
53:51 - on that where it's
53:52 - we're gonna be going over one unit um
53:55 - and then
53:56 - up uh 1100 units and so i can say okay
53:59 - the average of
54:01 - the manhattan data set is 4
54:04 - 400 4 500 something um so let me write
54:10 - that in
54:11 - so the right the vertical distance
54:15 - between these two points
54:17 - is equal to 1 1
54:20 - 8 1 and so
54:24 - if the average price
54:27 - in brooklyn is three three two seven and
54:29 - the difference between brooklyn and
54:31 - manhattan is one one eight one
54:33 - then this point is equal to or this
54:36 - height
54:37 - is equal to 3 3 2 7
54:41 - plus 1 1 8 1 whatever that is equal to
54:46 - we'll calculate that in a second
54:49 - then we also have this second line
54:53 - that's determined by
54:57 - that's determined by this slope
55:00 - and i'll draw that on a separate axis so
55:03 - we still have
55:04 - all these points
55:09 - for brooklyn
55:16 - and the mean of those points
55:20 - is still three three two seven
55:27 - so the mean is still three three two
55:28 - seven for brooklyn
55:31 - right this is still zero and it's still
55:34 - brooklyn
55:34 - is zero but now we've got
55:40 - one over here
55:43 - which corresponds to queens
55:49 - sorry i'm still learning how to use this
55:51 - ipad um
55:54 - right our one corresponds to queens and
55:56 - then
55:57 - it looks like the slope is negative
56:00 - so i'm going to draw these points so
56:03 - that we can visualize it
56:05 - a little bit lower
56:11 - and then the average
56:15 - is about 8 11
56:18 - units lower than this average so our
56:21 - regression line
56:23 - is like this
56:27 - and the vertical distance between the
56:29 - points
56:32 - is minus 8 11
56:35 - which means to get to this average the
56:38 - average in queens
56:42 - average rent
56:46 - in queens
56:49 - we've got to take the intercept which is
56:51 - the average rent in brooklyn
56:53 - or 3327 and we need to subtract
56:58 - 8 11.
57:01 - so basically all we've done
57:04 - and i'll go back now to our
57:12 - do our code basically all we've done
57:15 - here
57:16 - is we've recovered the average prices
57:20 - in each of the boroughs so what i'll do
57:24 - is i'll now do rentals
57:28 - dot um
57:31 - group by burrow
57:35 - and then calculate mean rent
57:39 - sophie we can't see you typing that for
57:41 - some reason
57:43 - oh what am i sharing
57:47 - um or at least i can't see it
57:51 - let me try yeah great question in the
57:53 - chat which uh we should definitely get
57:54 - to of um
57:56 - why did we not get between manhattan and
57:58 - queens why was base
57:59 - everything based on brooklyn but um okay
58:00 - cool we can see that now
58:02 - yeah that is a great question so
58:06 - if we print this out we see that the
58:09 - average
58:10 - rental price in brooklyn is 3327.4
58:15 - so that's this number then we see that
58:17 - the average rental price
58:19 - in manhattan was 5138
58:22 - and if we take this if we take
58:29 - this number and we add
58:33 - this number we should get that number
58:37 - nice and then if we take
58:41 - this number
58:46 - and we add this number
58:50 - so by adding a negative number we're
58:52 - just subtracting
58:54 - but plus sign in there
58:57 - we get the average rental price
59:00 - in queens so by giving us
59:04 - the intercept and the two slopes
59:07 - we can recover the rental price in every
59:09 - borough because
59:10 - this is the average in brooklyn and then
59:13 - this
59:14 - is the difference in brooklyn and
59:16 - manhattan
59:17 - so by adding these two numbers we get
59:19 - rental prices in manhattan
59:21 - and then this is between the difference
59:23 - between brooklyn and queens
59:24 - so by adding the intercept and this
59:26 - slope we get
59:28 - the rental price average rental price
59:30 - includes
59:32 - okay um so if we wanted to
59:36 - make a different comparison so remember
59:38 - when we
59:40 - printed this out brooklyn was the
59:43 - missing
59:43 - column right we had manhattan and we had
59:47 - queens
59:48 - um we call in this case and
59:51 - this is just by default brooklyn is the
59:55 - uh is the reference variable
59:58 - for this regression that we're doing and
60:01 - anytime we have a categorical variable
60:03 - with more
60:04 - than two categories we need to choose a
60:07 - reference variable
60:09 - that's going to be omitted from the
60:11 - regression
60:12 - or omitted as from
60:15 - sorry omitted from um
60:19 - this like design matrix and then
60:22 - in every case then the intercept is
60:25 - going to give us
60:26 - the at least for simple regression the
60:29 - intercept will give us the average
60:31 - for that group and then all of the
60:34 - slopes will be in reference to that
60:36 - group so that's why we call it the
60:38 - reference variable
60:39 - um if we want to change the reference
60:42 - variable
60:42 - then we can use some other notation so
60:46 - i'm going to just quickly show because i
60:48 - already have this written out
60:49 - and here i think um
60:52 - so this code um
60:56 - this like notation tells us tells
61:00 - uh this function that i want manhattan
61:03 - to be the reference variable
61:05 - instead of brooklyn if i want manhattan
61:08 - to be the reference or if i say
61:09 - manhattan is the reference variable
61:11 - then the intercept now represents the
61:14 - average in manhattan
61:16 - and then all of these are in reference
61:18 - to that so now this is
61:19 - brooklyn compared to manhattan and this
61:21 - is queens compared to manhattan
61:23 - and i could choose any reference
61:25 - variable i wanted
61:27 - um if you're using um
61:31 - if you're using sklearn which i know
61:33 - many people do
61:34 - you have to do this manually so you can
61:37 - do
61:38 - pd.getdummies and then
61:41 - if you don't do drop first so if you
61:44 - like
61:47 - here i can
61:51 - report this over so if i do
61:56 - if i use this get dummies function it
61:59 - gives me all three dummy variables
62:01 - and then in sklearn i can actually
62:09 - just choose which ones i want so if i
62:12 - want
62:12 - um queens the
62:16 - reference variable i can put in brooklyn
62:18 - and manhattan
62:20 - to this model and then print out the
62:22 - coefficients
62:23 - and it'll give me everything in
62:25 - reference to queens
62:27 - this is the way that this prints out
62:29 - this is the intercept and these are the
62:31 - two slopes
62:32 - the this learn output is a little bit
62:34 - harder to read
62:36 - yeah sophia i know that we're like
62:38 - basically out of time but i
62:39 - uh my question is like how does this all
62:42 - come together right where we
62:43 - like we now have these two graphs we
62:45 - have these two lines
62:47 - um but i like i don't even know how to
62:49 - visualize
62:50 - plotting these the three
62:53 - columns of lines of brooklyn manhattan
62:55 - queens like i don't i don't know how to
62:56 - get all of this onto one
62:58 - uh one graph now yeah so
63:02 - it's pretty it would be pretty hard to
63:04 - graph it
63:05 - in one graph and that's going to be
63:09 - part of the difficulty as we move
63:11 - towards more complicated models with
63:13 - more predictors
63:14 - because basically what this is is we we
63:17 - basically started
63:18 - talking about multiple linear regression
63:21 - without
63:22 - realizing it because when we fit this
63:24 - model
63:25 - we actually fit a model with multiple
63:28 - predictors
63:30 - it kind of happened on unintentionally
63:33 - because we had one
63:34 - column in our original data set but in
63:36 - order to fit the model
63:38 - we actually had to create two an extra
63:41 - variable
63:42 - in order to model this using linear
63:45 - regression and
63:46 - actually the same thing is true for most
63:48 - machine learning models that you might
63:50 - use you're going to have to dummy code
63:52 - um categorical variables because most
63:55 - models
63:56 - use like numerical distance metrics and
63:59 - if you don't have things written as
64:01 - numbers
64:02 - then you can't fit the model um
64:05 - so as we move into more complicated
64:09 - models where we want to have let's say
64:10 - we want to
64:11 - predict rental prices but based on
64:14 - burrow
64:15 - number of floors area number of
64:18 - bathrooms number of bedrooms like we
64:20 - want
64:21 - a lot of things we're going to end up
64:23 - with this really complex model that we
64:25 - can't really
64:26 - visualize anymore um
64:29 - if we have multiple uh quantitative
64:33 - predictors like if we have two
64:34 - quantitative predictors
64:35 - we end up fitting like a plane so we can
64:38 - kind of visualize it in 3d space
64:41 - um but then once we get past 3d like two
64:44 - predictors
64:45 - we're we're stuck we can't visualize
64:47 - things anymore
64:49 - so at this point
64:52 - we're trying to still visualize by
64:53 - drawing two different graphs
64:55 - and then in the coming weeks we're gonna
64:57 - kind of get out of
65:00 - out of the realm where we can visualize
65:02 - everything at once we can only visualize
65:06 - maybe a piece of it at once got it so
65:10 - multiple linear regression would
65:11 - normally be like hey i want to predict
65:13 - my
65:14 - dog's weight based on its height and
65:16 - it's
65:17 - um you know some other variable about
65:20 - the dog
65:20 - and yeah yeah breed is like a
65:22 - categorical thing so i want to say
65:24 - that but like i mean um no but you can
65:26 - have categorical variables in there
65:28 - yeah and so in this case even though we
65:31 - still
65:31 - only have two variables of cost and
65:34 - burrow
65:34 - we've now split that into we've built
65:37 - this model based on cost
65:39 - and uh i guess in the example that we're
65:42 - looking at that's
65:43 - brooklyn compared to manhattan and
65:46 - brooklyn compared to queens so we've
65:47 - like split this one variable out into
65:49 - two different
65:50 - variables and now we're doing like a a
65:52 - multiple linear
65:53 - regression thing um just like we would
65:55 - do again if we were trying to do like
65:57 - dog's weight based on height and breed
66:00 - yeah
66:00 - this time our predictors are is it in
66:03 - manhattan
66:04 - yes or no and is it in queens yes or no
66:07 - those are our two predictors for this
66:09 - model
66:11 - cool cool
66:14 - all right we ran a little late i always
66:17 - think like am i gonna have enough to get
66:18 - through an hour and then
66:20 - um i get we get good questions so that's
66:24 - awesome
66:25 - um so we will be available on thursday
66:27 - if you have any
66:28 - questions that you want to ask also
66:31 - there's a really great
66:32 - article and lesson has a lesson on this
66:36 - in the linear regression course so
66:39 - you can check those out on codecademy
66:43 - and feel free to also post
66:46 - any questions as comments in the youtube
66:49 - um video anything i'm missing
66:54 - no that sounds good uh yeah and then
66:55 - we'll be back next week for uh
66:57 - for another live stream yeah all right

Cleaned transcript:

the chat um we're gonna get started in just a minute um once we once we know we're fully live um but happy tuesday yeah i guess i'll use this time really quickly to plug uh our thursday office half hour um so just a reminder that on thursdays at the same time we are running a little office half hour where you can come and ask any questions that you might have uh we had one person last time so we really got to chat uh you know they got some personal twohour or personal half hour to just like ask us whatever questions they had about uh about the data science path and data science curriculum on codecademy so if you have questions even if they're unrelated to this live stream you should definitely pop on and we'll be happy to answer them especially if it's a small group so cool yeah we're also looking into the codecademy as a pretty active discord and so uh we're looking into making a channel there talking with people over there um so if you are on the codecademy discord um yeah we we might be over there we'll prob probably we're gonna do a couple more of these um office hours on zoom and then uh in a few weeks probably try the the discord it'll be fun yeah i'm learning learning about discord now so this is good um all right i think we can get started um i see some people saying hello in the chat always always fun to know where you guys are signing in from so let us know say hello if you haven't already and we'll get started cool well let's see sophie has a uh has a new tool that we'll be using today too which is which is fun we um we have an ipad that we can do some drawings on yes um all right i'm gonna actually delete all this because i was playing around with this this morning but we'll come back to this in a second so um as a quick recap what we did last week was we took a look at a linear a simple linear regression model where we had um an outcome variable and then we had a predictor and that predictor was quantitative um i can actually even pull up exactly what that looked like um right so we had height and weight as this kind of dummy example we were trying to predict weight based off of height as our predictor and so we fit this line we talked about what are the components that we need to calculate in order to define what this line looks like um and then we looked a little bit at the assumptions of linear regression and that was as far as we got in week one so in week two we're now going to kind of transition to thinking about how we could build more complex models than just this simple line but in order to get there we need to talk about how to handle categorical predictors so you notice right now right we can think of the idea of drawing a line makes a lot of sense when our predictor is height our outcome variable is weight they're both quantitative and so we have points that are kind of along along an axis and then we can draw a line through them but what do we do if the predictor variable so imagine like the variable down here is not a number it's something like um something a binary thing binary or something that even is not binary that has multiple categories um trying to think like if you know we're actually trying to predict the weight of um of dogs and we have different breeds of dogs and we've got some poodles and we've got some uh some pugs chihuahuas and so we want to include something about the breed of dog um in our in our model but that's not a quantitative predictor so we can't really like organize those categories in any particular order along this axis it doesn't really make sense necessarily to think of it as a line event yeah well and interesting because we talked about this in our last uh stats series where there's almost like two scenarios here right where one is unordered where it's chihuahua and poodle and your other dog breed there's no order associated with those but then you can also have categorical variables where it is ordered where i know i know we said last time like um you know a rating of one to ten isn't necessarily the best thing to use but there's right is that true that there's kind of like two different ways of thinking about this where ordered versus unordered really makes a difference yeah so if you have an ordered categorical variable and you think that the order matters for predicting your outcome then yeah it actually people do it all the time where we they use a an ordered categorical variable as a numerical variable as a numerical predictor um so just like if you have a rating on a scale from one to ten you can put that into your model right you can just have the numbers one through ten and treat it like a regular number um and people do that all the time if it's your outcome variable you need some different methods but depending on the circumstance but um but yeah for a for a predictor variable you can definitely just put that in normally like you would height um but if it's a fine line right so it's like what about uh like seasons of the year like that's kind of order but there's not really a smallest and the largest do you think that you know starting from if you're looking at the character right that it just goes up with the seasons numerically like no you think it's probably i don't know so depending on how you what you count as number one and what you count as number four uh yeah that also loops where like four should also be close to one uh yeah so it's it's kind of it's a fine line and you have to definitely think about how you're gonna code categorical variables um cool i see lots of people joining sao paulo new york city nice london columbia super awesome it's always fun to see people from all over the world here um cool so i'm gonna jump in so for today we're gonna be using this kind of madeup data set um we'll start with a madeup data set then we'll use a nonnative data set um but so this is something that i simulated we're imagining that we work for a company and we're trying to understand we want to model the time that people spend on the websites we want to kind of predict how long is somebody going to spend on our website and so we collect some data about how many seconds people are sending on the website we also collect some data about their age and what browser they were using and in this case we're going to just stick pretend like only people with safari or chrome are visiting our website so that's that's a caveat here okay so eventually what we're going to build up to is a model where we could include both age and browser as predictors but for right now in order to understand what's going on in that model we're going to first think about the model where we just include browser so what i'm going to do is i'm just going to go ahead and demonstrate that i can fit this model and then we're gonna go back and we're gonna talk about what's going on so um let's see we've got statsmodels.api um as sm so to fit this model we've got sm dot i think hold on actually i need to pull the code ols formula spray cap um well us from formula and then this time our formula is just going to be time in seconds predicted by browser and our data is called yeah and again just stressing that we're using some of these builtin packages which it takes a little bit of like looking at the documentation like sophie i imagine you didn't have you know you didn't know this from formula um function uh memorized or anything and so again kind of just stressing that the exact code to make this happen isn't uh really the highlight here yes um exactly and i saw you answered this question quickly but yes i was talking about dogs as an example of a categorical variable um that you could use to predict weight in this example we're going to use a different categorical brow a different categorical variable specifically browser to predict time in seconds but just in general today we're talking about the idea of categorical predictors in a linear regression model okay so i ran this linear regression press run again so this goes away and you'll notice that i get some output so it was able to run um so we we can do this but now we see that instead of getting an intercept and a slope on browser we're getting the slope on browser t dot safari and so what what's going on there why are we getting this new variable here that's what we're going to try to figure out so to start i'm going to also demonstrate if i just plot this and i plot website dot browser against website time seconds actually i actually get a plot as well and the plot looks like this it has um safari on one side with a bunch of dots and chrome on the other side with a bunch of dots and what i see here right so i should have put um i should have i think if i do sns.scatter plot then it automatically puts the axes yeah so this axis is time in seconds and then this access is our browser so we've got safari and chrome even though this isn't a number it's still putting safari over here in chrome over here for some reason and then i can see that these dots are each uh so like all the dots in this line are people who were accessing the website using safari and this is the and each dot represents the amount of time and seconds that they spend on the website so like this dot is someone who came on the website using safari and spent about 580 seconds on the website and this dot is someone who spent over 700 seconds on the website and accessed it using chrome cool so looking at this do you think there's a relationship alex between what browser someone is using and how long they're spending on the website i mean it certainly doesn't seem as strong as our last one right comparing it to what we did in the last session where we um had you know points that looked like they could kind of fall along a line but obviously not perfect um you know that looked like a pretty strong relationship here i can kind of imagine drawing a line that maybe is sloping upward a little bit um but you know the the uh the points are gonna be pretty far off of that line yeah so well in this case right we don't really have first of all these aren't numbers but second of all right we don't have any points in here so there's gonna be lots of and then there's a lot of variation even among these these points so by just drawing a line it's not like we're explaining that much of this variation um but i would say looking at this right these dots tend to be higher than these dots like if you had to pick the middle of the safari dots it might be somewhere around 400 and then if you had to find the middle of the chrome dots it might be somewhere around 500 and maybe a little bit easier to see in a sidebyside box plot but here we've got safari the median is a little before below 400. the median for chrome is a little below 500 and so the middle of these two distributions is is kind of different like there is some relationship between which browser someone is using and how long they're spending on the website even though it's not prescriptive you know if you are accessing from chrome you might spend as few as 250 seconds and as many as over 700 if you're accessing from safari you might be sending anywhere in this range as well but overall these numbers are smaller than these numbers yeah cool so this is kind of modeling some of that so let's look at those or are you are we about to talk about those two numbers in in particular well we will talk about those numbers in just a second yeah cool i think one thing that's helpful to know and this is this is something that i think will help you if you're thinking about trying to learn other packages as well is what's happening under the hood when you when we ran this code um a bunch of things right like our computer is doing some calculations and there are some steps that happen in the midst of those calculations that we're not seeing so one thing that's a little bit helpful is to actually break that down a little bit and see one of the the middle steps so i'm gonna do that by using this um this package called patsy so actually patsy is a is a dependency of stats models and it uses this package in order to fit this model and so i'm going to just use patsy directly to show you what that middle step looks like so using patsy.d matrices i'm going to actually grab this exact same code that i used with stats models um and i'm going to do return type equals data frame so that we can see this and actually here let me run this to see what the output is so there's actually two different pieces of output there's a y vector and an x vector um don't worry too much about that right now but i'm just going to save them as y and x and then i'm just going to print out x so that we can take a look at it okay so this is what x looks like um in two weeks from now we're going to talk about this column of ones um and why that's there that has to do with some of the matrix algebra that we're using to calculate the ordinary least squares solution to this regression problem but i want to point out that we get this same variable that we saw before and you'll see that it's a bunch of ones and zeros and the first five rows are one zero one zero one if we look back at our original data we've got safari chrome safari chrome safari what's happening here is we're taking this data and we're recoding it as ones and zeros because it's just a binary variable there are two possible outcomes and so we're just replacing one of them with a one and one of them with a zero and specifically we're replacing safari with a one and chrome with a zero and if we had if we weren't binary if we had multiple variables would we get one zero one two so um no we won't we're gonna do that in a second but actually no we won't because once remember once we have um once we have more numbers like zero one two then we're really assuming that there's an order that zero comes before one comes before two and we don't want that so um in this case safari was coded as a1 and um and chrome was coded as a zero and that's what this this means here so when it says browser t.safari it's saying that t means it stands for true so it's saying true that is equal to safari and it's a one if that's true and it's a zero otherwise if you've programmed in other languages you might know that usually true is coerced to a one and then false a zero so this kind of makes sense with this like true false construct um cool so i don't see any questions so i'm gonna jump over to this picture so coming back to this picture i'm realizing now that it's a it's a little bit misleading because in this picture safari is is overall on the right so in reality these would these are switched uh when we're thinking about this um i see where that negative might be coming from now because i was saying oh this is probably if i were to draw a line in this picture it would probably be going up right it would have a positive slope but if chrome is actually on the left and safari is on the right then i would say oh that has a negative slope and so i'm guessing that's why this negative number is showing up yeah i think that this is so here's what i'm going to do to make this a little bit nicer i wish i had done this ahead of time but let's see if i can do it quickly here so if i do website dot browser dot replace and then i'm gonna replace safari with um one dash safari and i'm gonna replace chrome with zero dash chrome and i'll do in place equals true so that i i make this replacement in the actual data let's see if this works cool and then i bet you ah still where you think it's like alphabetical i was assuming yeah yeah what if i do um like a crow i want you want chrome on the left so a chrome and b safari we'll try one more time it doesn't work it doesn't work yeah why is that oh well um maybe it's just whichever is first in the list is on the right um i mean there's obviously ways that we could dig into the scatter plot function to like force the axis to be in a a certain order yeah i wonder if we can just like well okay i'm gonna let it go um okay so instead i guess maybe i'll draw a picture this will be fun okay so i'm gonna stop share for a second and let me this is my new technology of the day okay um we're gonna get an iphone ipad via cable share and now can you guys see that yes that looks good yeah some someone in chat is saying that probably because safari is coming first it plots at first so the yeah the the order of that data was probably determining it not the name i i agree with that okay i have to redraw this picture now because i was drawing this before as uh but we've got this sort of picture where we've got um we got some points for safari right and then we've got some points for chrome i'm not going to do a good job right and what's happening is we're getting we're calculating a regression line just as we did before but that regression line is just connecting the middle of these two points so if we have a point here and we have a point here sorry the middle of these two sets of points our regression line is connecting them like this now okay we had i wish i could give you guys the side by side of the numbers but i'll write them i guess i'll write them over here so in our model we had that the intercept let's think uh we had that the intercept was equal to uh like 490 and then we had that the that like browser browser t dot uh what was it safari or chrome i forget which one was one which one was zero t dot safari equals negative 99 about let's like think about what this corresponds to on our graph so when it says intercept equals 490 that means that the intercept the yintercept is 490. and remember that the yintercept is just the same as the the point at which our line crosses the yaxis in this case the yaxis right is the same as where all these points are um because i don't understand the joke just some anime uh um so here right remember this zero was corresponding to chrome so the yintercept is this red point here and that's our 490 right that's hitting the yaxis at 490. so that's where well so is that the that's the point on uh on chrome which is zero that is 490 or is it like if i extended the so that's different than what i expected what i expected was oh let me extend this line um so you know so the line hits the um the yaxis and then that's my intercept but i guess that doesn't really make sense because it's already zero right yeah so it's all like kind of semantics of how i plot this so i'm plotting it with space between this axis and this this spot right but remember the yintercept is where the line crosses the yaxis and the yaxis is where the xvariable is equal to zero so the yaxis is actually this dotted line right so really it's all on top of each other but just for ease of drawing this so we can see the blue dots and stuff you've shifted it over a little bit yeah so if i want to make this like a little bit nicer so that we can all see it um we could i've erased this and we could think of this as our yaxis and our points are just kind of along it right like these these points that we drew for chrome are all along what's technically our yaxis because chrome we're we're making chrome equal to zero and our yaxis is where well that should be a straight line but you know right yeah and so that makes sense for our intercept there where it's um yeah 490 the line doesn't really continue to extend i guess it does extend in to the left but uh it's hitting the axis right where since chrome is encoded as zero right okay so our line our line technically continues on in both directions but the thing that we care about is that the yintercept is actually the middle of these blue look these blue points that correspond to chrome and then we've also got some points over here that correspond to safari right so these are our safari points and we we need to understand what this number is coming from or the where this number comes into play and remember that a line has to have a yintercept and it has to have a slope and so the slope remember is rise over run so the slope of a line over run in this case this line has a positive run so the run to get from one point to the next we move over one unit that's a run of one unit and then we have to go down to get to the next point by some distance this is our rise and it turns out we know that's like three so i bet if we looked in our data and found the middle of the safari data it would be what 391 right yeah so we'll do that in just one second but i'm gonna just write in here right so the rise is equal in this case equal to negative 99 and so our slope is rise over run it's negative 99 over 1 or negative 99. we have a really good question from harsh deep of last time we had weight and height and so it was a little bit like more intuitive to understand what uh what these um coefficients are meaning so uh his question is what does this represent in terms of the data what is 490 with respect to time and browser yeah so that's that's a really great question um so in this picture and we'll show it in the data in just a second you'll notice that the 490 right is the middle of all of these blue points and the blue points are amount of time spent by chrome users on the website so the middle is going to end up being the mean time spent on the website by chrome users and as we see right we can think of this as this negative 99 as a slope but because the run between these two points is one right like the difference between zero and one is just one then it's really just the rise or the difference in the vertical uh height of these two red dots and this red dot represents the mean time spent on the website by safari users so in other words this minus 99 represents the fact that on average safari users are spending about 99 seconds less on the website compared to chrome users yaxis is seconds yes good um good call so the yaxis of the seconds the xaxis is browser and we've got our yintercept which is mean time for chrome users of 490 and then we've got our slope rise over run run is one so our slope is the rise and that is this distance and this is the vertical distance between this point and this point these two points each represent the middle of their respective sets of points the middle being the mean time spent on the website we got another good question from the chat of like why is the rise negative oh that's a great a great question so this comes back to um a little bit of like graphing algebra right so um rise so coming back to just like equation of a line and slope slope is rise over run and when we when we think about slope um we think about to get from one point on a line to the next point on the line how far over do we have to go and how far vertically do we have to go when we talk about over when we talk about horizontal and vertical distance we always think of going to the right as positive and going to the left as negative and we think of going up as positive and down as negative so this is a positive sloping line this top one for this positive sloping line to get from one point to another point we go our rise is up and our run is over so our rise is positive and our run is positive so a positive over a positive is a positive for this one to get from one point to the next our rise is down right and then our run is positive or we could also think of it as like run is positive or sorry rise is positive run is negative in either case we've got either a negative over a positive or a positive over negative a negative over a positive or a positive over a negative is negative so the slope is negative because we have to go right this point when we go over one unit positive one unit we have to go down to get to the average safari time and so the rise is negative 99 which really just tells us that the average for safari is less than the average for from cool okay exactly yes um okay now this is nice and pretty i'm going to stop this share and i'm going to go back to back to my code okay so now let's go ahead and i'm going to copy this over so you can print it out down here run and then i'm going to also do website dot group by browser dot mean i think and then we really just want ten seconds so this gives us the mean time in seconds that people spent on each um on each browser go back to our regular okay um so we've got 489.7 seconds on chrome and 390.65 seconds about on safari on average and you'll see right that this number matches up with our intercept so that's what we were talking about before the intercept gives us the average time spent on chrome and then this number we said gives us the difference in mean time spent on chrome versus safari and it tells us that people are spending less time on safari so if we take this number and we subtract this number basically add these two together we get 390.64 this 64717 which is exactly the same as we calculated them as the mean time spent on safari i guess so my question after seeing all this is like all of this follows together we dr we have those two like yellow points uh so that corresponds to the intercept and then we can find the slope between those two points um but i i guess my question that kind of like relates back to the very beginning is like why do we choose the mean right we have these um we have these two columns of points and we could choose the median or we could choose you know some other metric to find the middle um all of this is coming from we chose the mean of these two points so why why the mean and not something else it's a great question so it it turns out and you can prove this to yourself mathematically remember that when we fit this model we're using the ordinary least squares method which is to say that we're trying to minimize the distance between each point and the line um and so if we draw this line on top we can think if i remember properly yeah you can here i'm gonna just grab this but uh i can explain what i'm doing so if i replot this and then on top of it i just plot the points 0 comma 390 and 1 comma 489 it'll plot this line it's kind of backwards for this example but we'll just run with it right if this is our line we're fitting this line to minimize the squared distance between all of the points in the line so to minimize the square distance between each point and this middle and it turns out that mathematically the point that minimize the the point that minimizes the distance between all of these points and this middle is the same as the mean mean people yeah and and then again uh this line looks different this is a positive slope and again that's because we're actually chrome is our is zero safari is one and so if we could flip those two if we could put chrome on the left and safari on the right um but still connect the two means then it would look identical into that graph we were just drawing before exactly um okay in the interest of time i'm going to switch over to another example where we use a categorical variable with some more categories so i'm going to grab this data set from here this is back to our rentals data set if you've uh if you've come to any of these live streams before or done any of the uh regression or other machine learning stuff on our website you may have seen this data set before we're just going to look at a subset of it where we have some information about rental prices in manhattan and we have some information about what burrow each of those apartments was in um in manhattan and you'll notice that burrow has in this case there's more than three burgers but uh in this in this data set we have a column burrow that has three possible values brooklyn manhattan and queens and so now we've got one more uh category and so all of a sudden this initial setup no longer works okay uh so i see there's a question so this mean time the mean time people spend on the website or the meantime the web browser loads the website in um for this example i was using the like it's it's not real data but i was just making up that it was the amount of time people were spending on the website um but it could be either but it could be either you know you could have a different a different data set um yes and yes i see someone commented formula for mean is the same as for average um it's just the same thing yeah use different names for different things sometimes um okay so similar problem but now we've got three categories instead of two how are we gonna handle this number of categories is the question so i'm gonna actually do the same thing that i did before with patsy.d matrices i'm going to print out the the x matrix for this problem um where we're we're predicting rent based off of borough and this time the data is rentals and if you like the web browser example again this could this would be the exact same thing if we added a third browser if you know yeah we could do predicting time based on chrome safari or firefox or whatever you want exactly um i probably should have done that but just make a new data set um okay so you'll notice that now we actually get multiple columns that didn't exist before now we get two columns of the format borrow t something but now we've got furo t manhattan and burrow t queens and then we don't have boro t brooklyn even though we know that that's represented in the data set so let's look through this we've got our first five rows remember are brooklyn manhattan manhattan queens queens so for the t manhattan column we've got zero one one zero zero and we see that that matches up with the two rows where the apartment was in manhattan so this column is going to be zero everywhere that the apartment was not in manhattan and it's going to be one when the apartment is in manhattan um it doesn't matter if it's not in manhattan and in brooklyn or not in manhattan and in queens either way it's going to be a zero if it's not manhattan and a one if it is manhattan we call this like a dummy variable for manhattan and then for this column we have the same thing but for queens so it's a one if the apartment is in queens that's why we have two ones here and it's a zero everywhere else so brooklyn or manhattan is not queens so we're gonna get zeros everywhere else um alex do you have an idea why we don't need to have brooklyn here yeah i guess we can figure that out from kind of process of elimination of if we know there's only three categories and i guess taking that row zero for example it's not manhattan it's not queens and because we know we only have one more category we can kind of um deduce the brooklyn column based on um based on these other two columns exactly so having a separate burrow t brooklyn column doesn't give us any more information when we get into multiple linear regressions so we have multiple predictors we'll talk about this issue of colinearity which means if you have an extra column of your data that provides no new information compared to the other columns that you have then that actually causes issues with fitting the model um so we've got just the two dummy variable columns that we would need in order to fully recreate this borough column but we have the minimum amount of extra information okay so now let's go ahead and actually run the regression um and we'll see what this looks like so we've got model equals and this time we're doing rent predicted by burrow we're printing the model parameters and we'll see that we get an intercept again and then as expected based on this output we get a slope for t manhattan and we get a slope for t queens two different slopes what do we do with that so i i have no clue how to how to interpret the two different slopes but if i were to do it independently of each other so the intercept is where it's hit is going to be the mean of the um whatever is is category categorized as a zero which i guess in this case is uh well i guess it's it could be either of them right like it's not the same thing where we have like it's not zero one two um so i don't i actually don't know i was i was gonna say i was gonna guess that that uh 3000 was the mean of brooklyn um i don't know if that's the case or not so let's actually let's draw it out um i'll switch to this is so fun um i'll switch to my drawing board again okay um see that and um i'm gonna just write out these numbers again um so we've got intercept our intercept was equal to three three two seven our borough t manhattan was equal to one one eight one roughly and then our burrow t queens was equal to negative eight one one it turns out we have two lines that we've now determined based off of this this regression output so this time in our first graph we've got a comparison between brooklyn and manhattan so in our brooklyn versus manhattan graph we've got some points for the rental price in brooklyn and then we've got some points for the rental price in manhattan again this is this yaxis rental price and then the middle of those points is going to be that's our mean rental price in brooklyn here i'll label these axes so this axis here is brooklyn and then this axis here is manhattan workout we're treating brooklyn as zero we're treating manhattan as one and then we've got the mean here the mean in brooklyn is equal to the intercept so the mean in brooklyn mean in brooklyn is 3327 and then this is our line our regression line and remember again since manhattan is one brooklyn is zero our run is one so the slope is really just the rise so the slope is the vertical distance between these two that's our slope and that's equal to this value so alex what is the slope for t manhattan what does that represent um so that represents yeah the uh so i mean i can figure out the at the mean of manhattan based on based on that where it's we're gonna be going over one unit um and then up uh 1100 units and so i can say okay the average of the manhattan data set is 4 400 4 500 something um so let me write that in so the right the vertical distance between these two points is equal to 1 1 8 1 and so if the average price in brooklyn is three three two seven and the difference between brooklyn and manhattan is one one eight one then this point is equal to or this height is equal to 3 3 2 7 plus 1 1 8 1 whatever that is equal to we'll calculate that in a second then we also have this second line that's determined by that's determined by this slope and i'll draw that on a separate axis so we still have all these points for brooklyn and the mean of those points is still three three two seven so the mean is still three three two seven for brooklyn right this is still zero and it's still brooklyn is zero but now we've got one over here which corresponds to queens sorry i'm still learning how to use this ipad um right our one corresponds to queens and then it looks like the slope is negative so i'm going to draw these points so that we can visualize it a little bit lower and then the average is about 8 11 units lower than this average so our regression line is like this and the vertical distance between the points is minus 8 11 which means to get to this average the average in queens average rent in queens we've got to take the intercept which is the average rent in brooklyn or 3327 and we need to subtract 8 11. so basically all we've done and i'll go back now to our do our code basically all we've done here is we've recovered the average prices in each of the boroughs so what i'll do is i'll now do rentals dot um group by burrow and then calculate mean rent sophie we can't see you typing that for some reason oh what am i sharing um or at least i can't see it let me try yeah great question in the chat which uh we should definitely get to of um why did we not get between manhattan and queens why was base everything based on brooklyn but um okay cool we can see that now yeah that is a great question so if we print this out we see that the average rental price in brooklyn is 3327.4 so that's this number then we see that the average rental price in manhattan was 5138 and if we take this if we take this number and we add this number we should get that number nice and then if we take this number and we add this number so by adding a negative number we're just subtracting but plus sign in there we get the average rental price in queens so by giving us the intercept and the two slopes we can recover the rental price in every borough because this is the average in brooklyn and then this is the difference in brooklyn and manhattan so by adding these two numbers we get rental prices in manhattan and then this is between the difference between brooklyn and queens so by adding the intercept and this slope we get the rental price average rental price includes okay um so if we wanted to make a different comparison so remember when we printed this out brooklyn was the missing column right we had manhattan and we had queens um we call in this case and this is just by default brooklyn is the uh is the reference variable for this regression that we're doing and anytime we have a categorical variable with more than two categories we need to choose a reference variable that's going to be omitted from the regression or omitted as from sorry omitted from um this like design matrix and then in every case then the intercept is going to give us the at least for simple regression the intercept will give us the average for that group and then all of the slopes will be in reference to that group so that's why we call it the reference variable um if we want to change the reference variable then we can use some other notation so i'm going to just quickly show because i already have this written out and here i think um so this code um this like notation tells us tells uh this function that i want manhattan to be the reference variable instead of brooklyn if i want manhattan to be the reference or if i say manhattan is the reference variable then the intercept now represents the average in manhattan and then all of these are in reference to that so now this is brooklyn compared to manhattan and this is queens compared to manhattan and i could choose any reference variable i wanted um if you're using um if you're using sklearn which i know many people do you have to do this manually so you can do pd.getdummies and then if you don't do drop first so if you like here i can report this over so if i do if i use this get dummies function it gives me all three dummy variables and then in sklearn i can actually just choose which ones i want so if i want um queens the reference variable i can put in brooklyn and manhattan to this model and then print out the coefficients and it'll give me everything in reference to queens this is the way that this prints out this is the intercept and these are the two slopes the this learn output is a little bit harder to read yeah sophia i know that we're like basically out of time but i uh my question is like how does this all come together right where we like we now have these two graphs we have these two lines um but i like i don't even know how to visualize plotting these the three columns of lines of brooklyn manhattan queens like i don't i don't know how to get all of this onto one uh one graph now yeah so it's pretty it would be pretty hard to graph it in one graph and that's going to be part of the difficulty as we move towards more complicated models with more predictors because basically what this is is we we basically started talking about multiple linear regression without realizing it because when we fit this model we actually fit a model with multiple predictors it kind of happened on unintentionally because we had one column in our original data set but in order to fit the model we actually had to create two an extra variable in order to model this using linear regression and actually the same thing is true for most machine learning models that you might use you're going to have to dummy code um categorical variables because most models use like numerical distance metrics and if you don't have things written as numbers then you can't fit the model um so as we move into more complicated models where we want to have let's say we want to predict rental prices but based on burrow number of floors area number of bathrooms number of bedrooms like we want a lot of things we're going to end up with this really complex model that we can't really visualize anymore um if we have multiple uh quantitative predictors like if we have two quantitative predictors we end up fitting like a plane so we can kind of visualize it in 3d space um but then once we get past 3d like two predictors we're we're stuck we can't visualize things anymore so at this point we're trying to still visualize by drawing two different graphs and then in the coming weeks we're gonna kind of get out of out of the realm where we can visualize everything at once we can only visualize maybe a piece of it at once got it so multiple linear regression would normally be like hey i want to predict my dog's weight based on its height and it's um you know some other variable about the dog and yeah yeah breed is like a categorical thing so i want to say that but like i mean um no but you can have categorical variables in there yeah and so in this case even though we still only have two variables of cost and burrow we've now split that into we've built this model based on cost and uh i guess in the example that we're looking at that's brooklyn compared to manhattan and brooklyn compared to queens so we've like split this one variable out into two different variables and now we're doing like a a multiple linear regression thing um just like we would do again if we were trying to do like dog's weight based on height and breed yeah this time our predictors are is it in manhattan yes or no and is it in queens yes or no those are our two predictors for this model cool cool all right we ran a little late i always think like am i gonna have enough to get through an hour and then um i get we get good questions so that's awesome um so we will be available on thursday if you have any questions that you want to ask also there's a really great article and lesson has a lesson on this in the linear regression course so you can check those out on codecademy and feel free to also post any questions as comments in the youtube um video anything i'm missing no that sounds good uh yeah and then we'll be back next week for uh for another live stream yeah all right
