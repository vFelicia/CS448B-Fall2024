With timestamps:

00:05 - We will now take a closer look at the concepts of supervised and
00:08 - unsupervised learning.
00:09 - And also understand exactly what the differences are between
00:13 - these two techniques.
00:14 - So to begin, let us take a look at an example which we have studied so far.
00:18 - Where we have a linear regression line,
00:21 - which plots the relationship between a particular cause, x, and an effect, y.
00:26 - So the point of linear regression is to find a best fit
00:29 - straight line which models such a relationship.
00:32 - And this is expressed by the equation, Y = Wx + b.
00:37 - In a linear regression, the aim is to find those values of W and
00:41 - b, which best represent your data.
00:44 - This is where the learning part of machine learning comes into the picture.
00:48 - So whether your model is one which performs the regression or
00:50 - classification, you will first feed it a corpus of data.
00:54 - This represents your training data, and your model will go through
00:57 - each of the data points within it, and then make a prediction.
01:01 - Following that, a loss will be computed.
01:04 - This is a measure of how far away your predicted value is from
01:07 - the actual one.
01:08 - And the aim of any training, is to minimize this loss value.
01:12 - At the end of this training phase, you'll end up with your trained model.
01:16 - Which in the case of a linear regression,
01:18 - could be a straight line or a plane.
01:20 - And in the case of a classification model,
01:23 - which uses support vector machines, this will be a hyperplane.
01:27 - In either of these cases though,
01:28 - a loss is computed by comparing the predicted value with the actual y value.
01:34 - Now, what if you actually do not have any y values to work with?
01:38 - For instance, consider that you have a corpus of data which includes
01:42 - millions of emails, but
01:43 - there is no categorization available, whether those emails are spam or ham.
01:48 - So the machine learning techniques which we have studied so
01:50 - far in this learning part.
01:52 - Which has included classification and regressions,
01:54 - are examples of supervised learning.
01:58 - This is where our data set includes not only the input features x, but
02:02 - also labels y which correspond to those input features.
02:06 - A machine learning algorithm will go through all of the input data points and
02:10 - then plot a relationship y = f(x).
02:14 - This is in fact similar to performing some form of reverse engineering
02:18 - in order to learn of the relationship between the input x and the output y.
02:23 - It is the input training dataset or the corpus which will be iterated over,
02:27 - often multiple times, in order to learn of the weights and
02:30 - biases which will represent this relationship.
02:33 - In the case of a linear regression,
02:35 - the goal of the training phase is to find the relationship, Y = Wx + b.
02:41 - Where W represents the weight, and b is the bias.
02:45 - So in short, supervised learning is where you have a set of input features
02:49 - and a collection of correctly labeled outputs corresponding to them.
02:52 - And this data will be used in the training phase in order to
02:55 - learn a relationship.
02:57 - Which is represented by Y = f(x).
03:00 - This particular relationship can then be used in order to make
03:03 - predictions on real data later on.
03:05 - And both regression as well as classification
03:08 - are examples of supervised learning.
03:11 - So given that, we now move along to the concept of unsupervised learning.
03:15 - Where we have a collection of data, however, we need to examine that data and
03:20 - then generate an output without having any correct labels or
03:24 - identifiers to work with.
03:27 - So to summarize, unsupervised learning is where your model has to
03:31 - learn of patterns by merely looking at the data.
03:34 - Once those patterns have been identified,
03:36 - you can then decide what course of action to take based on those results.
03:41 - So just to contrast supervised and unsupervised learning.
03:44 - In the case of supervised learning such as regression and
03:47 - classification, you will have training data to work with.
03:51 - This will include not only the features x, but
03:53 - also a corresponding label for each of the features y.
03:57 - And it is the job of the supervised learning algorithm
03:59 - to learn of this relationship between x and y.
04:03 - It will do this by constantly adjusting the model parameters in the training
04:06 - phase until its loss is minimized.
04:09 - And now moving along to unsupervised learning,
04:12 - this is a situation where you do not have any training labels to work with.
04:16 - The task of the unsupervised learning algorithm is to structure the model
04:20 - in such a way so that some patterns can be gleaned from the underlying data.
04:25 - Once such patterns have been obtained,
04:26 - it is up to the user to decide how exactly to act upon them.
04:30 - For example, if you have information about a lot of users on social media,
04:35 - and you apply some unsupervised learning algorithm on them,
04:38 - they may break up all of the users into groups.
04:40 - Where some groups represent music lovers and
04:43 - other groups represent sports lovers.
04:45 - An advertiser may wish to target the music lovers with music-themed
04:49 - advertisements and sports-themed advertisements for the sports fans.
04:54 - So let us now summarize some of the characteristics of unsupervised learning.
04:58 - This is where you'll often end up with a large unlabeled dataset.
05:02 - That is, there are no y values to speak of.
05:05 - The job of the unsupervised learning algorithm is to structure a model in
05:09 - such a way that patterns can be gathered from the underlying data.
05:13 - And an important point to keep in mind is that these patterns
05:16 - are self-discovered by the model.
05:19 - There are no specific patterns which are being searched for.
05:21 - And there are no correct or incorrect patterns which can be gleaned.
05:26 - So an example of a supervised learning model is a classifier.
05:29 - Which can label an email which enters your inbox as spam or ham,
05:33 - and then take an action accordingly.
05:35 - If the email is marked as spam, it will be sent to your trash folder.
05:39 - And if not, it will appear in your inbox.
05:42 - In the case of an unsupervised learning algorithm however,
05:45 - the input data is not labeled in any way.
05:48 - The output of unsupervised learning are a collection of self-discovered
05:52 - patterns within the data.
05:54 - There are no correct or
05:55 - incorrect answers which are produced by an unsupervised learning algorithm.
05:58 - Just a collection of patterns which the user
06:01 - can use in order to make a further decision.
06:04 - So given that there are no correct or
06:06 - incorrect answers when it comes to applying unsupervised learning.
06:10 - How exactly can this help?
06:12 - Well, as we have already touched upon, unsupervised learning algorithms can
06:16 - help you find logical groupings in your data.
06:19 - For example, with social media users, there may be groups of music lovers and
06:23 - sports lovers.
06:24 - And this information can help you direct some customized
06:27 - advertising campaigns towards each of these groups.
06:31 - In addition, unsupervised learning can also help you extract
06:34 - the significant factors in your data.
06:36 - We will cover an example of that in just a little bit.
06:40 - So moving along to the use cases for unsupervised learning.
06:44 - We already saw that logical groups within the data
06:47 - can help you identify users who are music lovers or sports lovers.
06:51 - And you're likely to find patterns which you never even imagined in
06:54 - the first place.
06:55 - For example, you may find a group of teenagers
06:58 - who happen to be very interested in music from the 1950s.
07:01 - Another common application of unsupervised learning
07:04 - is in the field of latent factor analysis.
07:07 - This will help you extract the significant factors in your underlying data.
07:11 - For example, if your dataset includes a number of different products and
07:15 - their sales quantities and a number of different factors which affect them.
07:19 - Then you may be able to gather all of the common factors
07:22 - which seem to affect the sales of a number of products.
07:25 - Another common application of unsupervised learning
07:28 - is to categorize data which is unlabeled.
07:31 - So for example, if you happen to have pictures from a number of vacations of
07:35 - yours, an unsupervised learning algorithm may be able to identify
07:38 - the same flower from different photos across your vacations.
07:42 - You could then question whether there is some kind of subconscious
07:45 - force which is drawing you towards those flowers.
07:48 - One more area where unsupervised learning finds significant use
07:51 - is in the field of fraud detection.
07:54 - So given a number of different transactions,
07:56 - often numbering in the millions, an unsupervised learning algorithm
08:00 - may be able to cast all of the unusual transactions into a single group.
08:05 - So while these transactions will not be labeled as fraudulent, you may decide
08:09 - that these transactions are in fact worthy of further investigation.
08:13 - An unsupervised learning can in fact be a precursor to
08:16 - applying supervised learning techniques.
08:19 - For that, consider that you have some unlabeled data and
08:22 - you find some logical groups within them.
08:24 - You could then apply labels explicitly to each of these logical groups and
08:28 - then train a classification model.
08:31 - And then later use it to categorize data into these groups.
08:35 - Some of the commonly used unsupervised learning techniques include
08:39 - clustering, where data is split into a number of clusters, and
08:42 - the data in each cluster has a number of common attributes.
08:46 - You can also use this for dimensionality reduction
08:49 - in order to trim the number of dimensions in your data.
08:52 - And we have already discussed the concept of latent factor analysis.

Cleaned transcript:

We will now take a closer look at the concepts of supervised and unsupervised learning. And also understand exactly what the differences are between these two techniques. So to begin, let us take a look at an example which we have studied so far. Where we have a linear regression line, which plots the relationship between a particular cause, x, and an effect, y. So the point of linear regression is to find a best fit straight line which models such a relationship. And this is expressed by the equation, Y = Wx + b. In a linear regression, the aim is to find those values of W and b, which best represent your data. This is where the learning part of machine learning comes into the picture. So whether your model is one which performs the regression or classification, you will first feed it a corpus of data. This represents your training data, and your model will go through each of the data points within it, and then make a prediction. Following that, a loss will be computed. This is a measure of how far away your predicted value is from the actual one. And the aim of any training, is to minimize this loss value. At the end of this training phase, you'll end up with your trained model. Which in the case of a linear regression, could be a straight line or a plane. And in the case of a classification model, which uses support vector machines, this will be a hyperplane. In either of these cases though, a loss is computed by comparing the predicted value with the actual y value. Now, what if you actually do not have any y values to work with? For instance, consider that you have a corpus of data which includes millions of emails, but there is no categorization available, whether those emails are spam or ham. So the machine learning techniques which we have studied so far in this learning part. Which has included classification and regressions, are examples of supervised learning. This is where our data set includes not only the input features x, but also labels y which correspond to those input features. A machine learning algorithm will go through all of the input data points and then plot a relationship y = f(x). This is in fact similar to performing some form of reverse engineering in order to learn of the relationship between the input x and the output y. It is the input training dataset or the corpus which will be iterated over, often multiple times, in order to learn of the weights and biases which will represent this relationship. In the case of a linear regression, the goal of the training phase is to find the relationship, Y = Wx + b. Where W represents the weight, and b is the bias. So in short, supervised learning is where you have a set of input features and a collection of correctly labeled outputs corresponding to them. And this data will be used in the training phase in order to learn a relationship. Which is represented by Y = f(x). This particular relationship can then be used in order to make predictions on real data later on. And both regression as well as classification are examples of supervised learning. So given that, we now move along to the concept of unsupervised learning. Where we have a collection of data, however, we need to examine that data and then generate an output without having any correct labels or identifiers to work with. So to summarize, unsupervised learning is where your model has to learn of patterns by merely looking at the data. Once those patterns have been identified, you can then decide what course of action to take based on those results. So just to contrast supervised and unsupervised learning. In the case of supervised learning such as regression and classification, you will have training data to work with. This will include not only the features x, but also a corresponding label for each of the features y. And it is the job of the supervised learning algorithm to learn of this relationship between x and y. It will do this by constantly adjusting the model parameters in the training phase until its loss is minimized. And now moving along to unsupervised learning, this is a situation where you do not have any training labels to work with. The task of the unsupervised learning algorithm is to structure the model in such a way so that some patterns can be gleaned from the underlying data. Once such patterns have been obtained, it is up to the user to decide how exactly to act upon them. For example, if you have information about a lot of users on social media, and you apply some unsupervised learning algorithm on them, they may break up all of the users into groups. Where some groups represent music lovers and other groups represent sports lovers. An advertiser may wish to target the music lovers with musicthemed advertisements and sportsthemed advertisements for the sports fans. So let us now summarize some of the characteristics of unsupervised learning. This is where you'll often end up with a large unlabeled dataset. That is, there are no y values to speak of. The job of the unsupervised learning algorithm is to structure a model in such a way that patterns can be gathered from the underlying data. And an important point to keep in mind is that these patterns are selfdiscovered by the model. There are no specific patterns which are being searched for. And there are no correct or incorrect patterns which can be gleaned. So an example of a supervised learning model is a classifier. Which can label an email which enters your inbox as spam or ham, and then take an action accordingly. If the email is marked as spam, it will be sent to your trash folder. And if not, it will appear in your inbox. In the case of an unsupervised learning algorithm however, the input data is not labeled in any way. The output of unsupervised learning are a collection of selfdiscovered patterns within the data. There are no correct or incorrect answers which are produced by an unsupervised learning algorithm. Just a collection of patterns which the user can use in order to make a further decision. So given that there are no correct or incorrect answers when it comes to applying unsupervised learning. How exactly can this help? Well, as we have already touched upon, unsupervised learning algorithms can help you find logical groupings in your data. For example, with social media users, there may be groups of music lovers and sports lovers. And this information can help you direct some customized advertising campaigns towards each of these groups. In addition, unsupervised learning can also help you extract the significant factors in your data. We will cover an example of that in just a little bit. So moving along to the use cases for unsupervised learning. We already saw that logical groups within the data can help you identify users who are music lovers or sports lovers. And you're likely to find patterns which you never even imagined in the first place. For example, you may find a group of teenagers who happen to be very interested in music from the 1950s. Another common application of unsupervised learning is in the field of latent factor analysis. This will help you extract the significant factors in your underlying data. For example, if your dataset includes a number of different products and their sales quantities and a number of different factors which affect them. Then you may be able to gather all of the common factors which seem to affect the sales of a number of products. Another common application of unsupervised learning is to categorize data which is unlabeled. So for example, if you happen to have pictures from a number of vacations of yours, an unsupervised learning algorithm may be able to identify the same flower from different photos across your vacations. You could then question whether there is some kind of subconscious force which is drawing you towards those flowers. One more area where unsupervised learning finds significant use is in the field of fraud detection. So given a number of different transactions, often numbering in the millions, an unsupervised learning algorithm may be able to cast all of the unusual transactions into a single group. So while these transactions will not be labeled as fraudulent, you may decide that these transactions are in fact worthy of further investigation. An unsupervised learning can in fact be a precursor to applying supervised learning techniques. For that, consider that you have some unlabeled data and you find some logical groups within them. You could then apply labels explicitly to each of these logical groups and then train a classification model. And then later use it to categorize data into these groups. Some of the commonly used unsupervised learning techniques include clustering, where data is split into a number of clusters, and the data in each cluster has a number of common attributes. You can also use this for dimensionality reduction in order to trim the number of dimensions in your data. And we have already discussed the concept of latent factor analysis.
