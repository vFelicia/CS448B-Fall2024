00:00 - okay hey everyone welcome to forecasting
00:11 - Google Trends data with our welcome
00:15 - join our is an awesome language
00:17 - hopefully everyone will soon get really
00:20 - excited about and everyone as you join
00:26 - feel free to start writing in where
00:30 - you're joining us from we want to know
00:33 - who are who are audiences
00:38 - hi Melissa hey Kenneth from Michigan Oh
00:44 - Diana Oh
00:47 - Montreal French Jane Chu Lebanon
01:03 - Argentina all across the speeds good
01:11 - afternoon or early evening to you
01:17 - Vietnam so good okay yeah nice morning
01:26 - how is everyone doing today are it guys
01:29 - excited going data science we're
01:33 - definitely excited over here and we are
01:35 - coming to you live from New York
01:41 - normally we are at the code Academy Soho
01:44 - Office but today we are both coming
01:47 - straight from our homes as I'm sure you
01:51 - are as well well we are going to make
01:55 - the best out of this situation and one
01:57 - thing that you can do from home is learn
02:00 - and programs and code and Kaila we will
02:05 - be learning our and not only will we be
02:07 - learning our we're going to be doing
02:09 - some time series analysis
02:11 - and some really cool forecasting really
02:14 - the bread and butter of a lot of our
02:16 - predictive analytics so I think it's I'm
02:21 - very excited it's gonna be a great time
02:23 - and have you been joining us all day
02:26 - logging some of our other sessions where
02:28 - we've been talking about a little bit of
02:30 - web development or learning other
02:33 - languages this sessions gonna be a
02:34 - little bit different we're gonna go in
02:37 - the direction of the data which is
02:38 - something that camellia and I both
02:40 - really love and we'll be showing you
02:42 - some really cool things that you can do
02:44 - with data science and we'll start off
02:46 - with a little bit on platform and the
02:49 - Codecademy environment which you might
02:50 - be familiar with but will also be
02:52 - venturing off platform to see what it's
02:54 - like coding on your computer hello
03:06 - everyone we'll wait another maybe 30
03:11 - seconds or a minute or so to let
03:14 - everyone come in so we have a question
03:17 - from Maria do I need to download our so
03:21 - for this session today I would recommend
03:24 - that you go ahead and just follow along
03:27 - with us to see what we're able to do
03:29 - with our we'll spend some time on code
03:32 - Academy where we welcome you to follow
03:34 - along with us if you'd like but when we
03:38 - go off platform into our own environment
03:40 - I will be showing you some cool things
03:42 - that you can do and we recommend just
03:44 - watching along asking questions as they
03:47 - arise I'm asking why we're doing certain
03:49 - things or what else we can do with
03:52 - coding and data science and then you'll
03:54 - have the opportunity afterwards to go
03:57 - off platform download our yourself and
04:00 - try and explore it and have to do with
04:04 - some where analysis - what we do here
04:05 - today and I think the biggest thing for
04:07 - me just because I have you know been a
04:09 - data science for some years now is I
04:11 - wish I had the opportunity to have
04:13 - someone like Ian who's gonna be able to
04:15 - walk us through the code and you're just
04:17 - gonna get you super familiar with are
04:18 - super excited about a lot of the
04:20 - statistical methodologies that we're
04:21 - gonna go in together and then I think
04:23 - the biggest thing is just
04:25 - be scared go into Codecademy play around
04:28 - with a learning environment get familiar
04:30 - with all the functions like our might
04:32 - become your best friend you you may not
04:34 - know it yet and we have another great
04:38 - question from a bot cell what is our
04:40 - great question so our is magnificent and
04:44 - amazing and fun and it is a programming
04:47 - language and the cool thing about R is
04:50 - it is a statistical programming language
04:52 - so it's designed to work well with doing
04:55 - statistical analyses or doing data
04:57 - analysis so it's great for taking in all
05:00 - that data that is being collected all
05:02 - over the world about every single topic
05:05 - and letting you find interesting
05:06 - insights or maybe creating
05:08 - visualizations and ultimately trying to
05:11 - find answers that can help us make
05:15 - decisions about the world who I am
05:17 - loving these are verses Python questions
05:19 - and R versus JavaScript questions and I
05:22 - just really want to answer it because I
05:24 - think as a data scientist it's really
05:26 - these very diverging philosophies right
05:28 - like do I go for our joy go for Python I
05:30 - would hardly say that any data scientist
05:34 - is trying to get their hands dirty with
05:35 - Java or JavaScript but that's mostly
05:37 - just because it's way more complicated
05:39 - it's actually an object-oriented
05:40 - language however what I will say is that
05:44 - art is super easy to use it was actually
05:47 - built by statisticians for statisticians
05:50 - and that means that people like analysts
05:52 - data scientists sociologists economists
05:55 - whatever don't necessarily need to have
05:57 - the most you know I would say strongest
06:01 - foundations in computer science you can
06:03 - just go ahead and learn our and within a
06:05 - few like few lines of code be able to
06:08 - develop an analysis even then you know
06:11 - develop a machine learning model um so
06:13 - that's why I highly like especially if
06:14 - it's your first programming language
06:16 - definitely go for are like the learning
06:18 - curve is just so much easier and similar
06:25 - to that we're seeing some questions
06:26 - about what exactly is is data science
06:30 - and do I need to have any prerequisite
06:32 - knowledge going into this today should I
06:34 - know math for
06:37 - we want to just spend some time showing
06:39 - you what are the possibilities with data
06:41 - science and data science is essentially
06:43 - just taking some data and doing
06:45 - something with it organizing it in a
06:48 - different way formatting in a different
06:49 - way so that we can find out some new
06:51 - information or recognize some patterns
06:53 - and so you don't need to have any
06:55 - background and no programming or math
06:59 - will explain things along the way and we
07:02 - just want you to be thinking about kind
07:04 - of what is the bigger picture what are
07:06 - we finding out from our analysis and
07:09 - what does it mean for for like our lives
07:13 - or for our interest or for the world or
07:15 - even for you personally so you know no
07:18 - need to fret if you don't have that
07:19 - background well be taking you hand in
07:22 - hand today well that being said Ian
07:24 - should we start since I think people are
07:27 - almost done coming in we can start with
07:29 - some intros if you want to kick it off
07:30 - yes let's do it
07:32 - so hi everyone welcome to our session
07:35 - today on analyzing Google Trends data
07:38 - with our my name is Ian freed and I am a
07:41 - senior Human Development and so what I
07:45 - do in my job is spend a lot of time
07:48 - working on designing the courses that go
07:51 - on the Codecademy website specifically
07:54 - related to data analytics and data
07:57 - science so in the past I've done some
08:00 - courses on machine learning which maybe
08:01 - you've heard about or natural language
08:03 - processing which is where we're looking
08:06 - at text data and trying to get some
08:08 - insight into that kind of data I've also
08:11 - worked on creating our learn our course
08:13 - which I will recommend as a great entry
08:17 - point to programming as well as to data
08:20 - science so after the session feel free
08:23 - to check that out and give it a go
08:24 - yourself and really excited to be here
08:29 - with you all today to learn a little bit
08:34 - about our checkout code kata me and then
08:36 - do some data science um so hi guys my
08:42 - name is camellia Hassan I am a data
08:44 - scientist at code Academy and I've been
08:48 - identified is for quite some time now I
08:50 - just moved to
08:51 - working before this I was a data
08:53 - scientist at uber we're very similar to
08:56 - what I'm doing at code Academy now um I
08:58 - was building out experiments designing
09:01 - some causal inference frameworks
09:04 - rebuilding machine learning models which
09:07 - is always fun in the space of risk and
09:10 - safety so I'm very very passionate about
09:12 - data science I think like a lot of you
09:14 - I'm a total math physics statistics nerd
09:18 - and I think for people who have these
09:20 - types of affinities this is a really
09:22 - amazing field to be in just because once
09:25 - you have basic understanding about a lot
09:27 - of these you know core methodologies you
09:30 - can go ahead and apply it to any type of
09:32 - industries may it be operations
09:35 - ride-sharing logistics healthcare
09:39 - finance I mean you name it
09:41 - the world will always always need data
09:44 - scientists so that being said we have a
09:47 - really incredible agenda today so I know
09:49 - the title of the course is forecasting
09:51 - using Google Trends with our but Before
09:54 - we jump into that we're actually as Ian
09:57 - mentioned we're gonna go into the
09:58 - learning environment and we're just
09:59 - gonna go and do some really basic
10:03 - foundations of exploratory analysis you
10:07 - know try to figure out how to manipulate
10:08 - data frames and I think once we are able
10:11 - to do this we can actually get our hands
10:13 - really dirty and get into the code so
10:17 - once again it's very interactive if you
10:19 - have any questions while we are in the
10:22 - learning environment or at any point
10:23 - just chat us I'll be monitoring um and
10:27 - then yeah I mean overall ours just once
10:28 - again I couldn't say like ah such a
10:31 - great and easy and fun language it was
10:33 - built by statisticians for statisticians
10:36 - really with a main purpose of data
10:39 - analysis and of course you can do data
10:40 - analysis in Java and in Python but um
10:44 - are just so easy and for me like
10:46 - examples of work that I do using are is
10:48 - just any type of exploratory analysis
10:52 - where I'm looking you know am I looking
10:54 - at a normal or at a personal
10:55 - distribution am i when I'm doing
10:57 - hypothesis testing if I want to compute
10:59 - a power R has some packages within one
11:02 - line I can look at the sample size
11:03 - estimates
11:04 - um so I just I couldn't recommend it
11:07 - enough from like today really we're
11:09 - gonna be doing it some time series
11:12 - analysis so we would love to know time
11:13 - series analysis have you done it
11:15 - that being said um Ian let's let's go
11:19 - into the Le let's have some fun
11:21 - definitely and um you should see also in
11:26 - the zoom there is a poll going right now
11:28 - where you're able to answer some
11:31 - questions about your familiarity with
11:34 - our with time series analysis so make
11:36 - sure you're going ahead and answering
11:38 - that poll question it seems like we have
11:39 - a lot of people who are new to our
11:42 - haven't worked with time series analysis
11:43 - before which is super exciting we're
11:45 - gonna take you on a great journey today
11:48 - so I'm gonna go ahead and start sharing
11:51 - my screen so we can go jump into the
11:53 - learning environment and take a look at
11:57 - some are together and now as I jump into
12:01 - this let me say before coming to our I
12:03 - know a lot of you are asking these
12:04 - Python bizarre questions I I was a
12:08 - Python person that's what I started out
12:10 - learning when I got into data analytics
12:11 - data science and it was what you know
12:15 - was first introduced to me and I grew to
12:17 - love it but then about a year ago I
12:20 - started working with our for Coke atom
12:22 - II and it's been a really great journey
12:25 - as well I now I'm a huge fan of our in
12:29 - addition to Python so it's what I want
12:32 - to let you guys know is that it's not
12:34 - about one language or the other it's
12:36 - about which tool is gonna help you
12:38 - accomplish your task and when it comes
12:40 - to data analysis and data science Python
12:42 - and are both really steal the show can't
12:45 - go wrong with I just want to give one
12:48 - example because I know everyone's
12:49 - freaking out this are versus Python
12:51 - which is always super exciting but I can
12:53 - give you a really quick example of in
12:55 - one case where you would use Python
12:57 - versus R I think really once you become
13:00 - like a full stack data scientist which
13:02 - means that you're building machine
13:03 - learning models and you need like real
13:05 - time pipelines so you're basically
13:07 - needing pipelines to predict things
13:09 - every second every minute and there is
13:11 - like operational needs then yes I think
13:13 - Python is definitely more powerful than
13:16 - R however we
13:18 - will not be doing that today and to be
13:20 - honest like that just takes a lot of
13:22 - time a lot of effort and you can still
13:24 - do so money so much cool work with like
13:27 - what we're going to be showing you right
13:29 - now definitely great point camellia and
13:33 - on the other end of things there are
13:35 - some things that are can excel ads and
13:37 - some people's opinions one of which is
13:39 - often data visualization and we'll be
13:41 - doing a little bit of that today so you
13:43 - all get to see some of that advantage
13:45 - that we can get from so in order for us
13:49 - to get to that now let's dive into the
13:51 - learning environment we're here on our
13:53 - introduction to data frames and our
13:56 - lesson and in this lesson which we
14:00 - really recommend that you take some time
14:02 - to go through after the session over the
14:04 - weekend and any of the free time you
14:06 - have the next coming weeks and learn
14:09 - about how we work with data in data
14:13 - science and we often boat our data into
14:17 - something called a data frame and a data
14:19 - frame is essentially like a table that
14:22 - you might see if you're working and
14:24 - Google sheets or if you're working in
14:26 - Excel where we have rows and columns and
14:29 - from this table like format we're able
14:31 - to go ahead and do a lot of interesting
14:34 - analysis so it's a good foundation for
14:36 - us to work off of and so in this lesson
14:39 - you learn all about data frames and I
14:41 - just want to spend a little bit of time
14:42 - going through what this lesson looks
14:44 - like if you're coming to it for the
14:46 - first time and how we can take advantage
14:47 - of the power of our so in this lesson we
14:52 - have our code at the right you never
14:55 - work with code Kadim e we often have
14:57 - some content on the left side of the
14:58 - screen we have a code editor in the
15:01 - middle and then on the right hand side
15:02 - we have our browser component so this is
15:06 - where we're gonna see the output of our
15:07 - code in this case since we're working
15:08 - with an our notebook which is a really
15:10 - useful kind of file where we're able to
15:14 - write some code and then have it display
15:16 - and a rendered HTML page so we really
15:19 - add some dynamic ability to your code
15:22 - and so we can see right now when I try
15:25 - and run this file nothing is happening
15:28 - we're getting some errors
15:31 - and our code isn't working as we'd
15:32 - expect and the reason for this is we are
15:35 - using some are packages which are really
15:38 - useful collections of code that other
15:40 - people have written that accomplish
15:42 - tasks for us and that's one of the great
15:45 - parts of our is that there are all these
15:46 - packages out there of people who have
15:48 - spent time and research figuring out how
15:51 - to accomplish different data sets on ISS
15:53 - and they've gone ahead and put all that
15:55 - together for you so you need to write
15:56 - all that code my hand you can just use
15:58 - these packages well we're not loading
16:00 - that package into our code file right
16:03 - here so what I'm going to do is I'm
16:05 - going to load two really helpful
16:08 - packages I'm right here into this code
16:12 - block and so we can see a little code
16:14 - block is defined by a few backtick so
16:18 - three on the top three on the bottom and
16:19 - in here I can write our code so what I'm
16:22 - gonna do in here
16:22 - here's write library and I'm going to
16:25 - put the our packages I would like to
16:27 - load one is called the reader package
16:29 - and one is called supplier and these
16:34 - packages are part of a greater
16:36 - collection of packages in our that we
16:37 - call the tidy verse which is a
16:39 - collection of packages that are super
16:41 - helpful super useful and enable us to do
16:43 - a lot of these tasks and we want to go
16:45 - ahead and do so now that I've written in
16:48 - here to go ahead and load those packages
16:51 - I'm gonna click the Run button so we can
16:53 - run our code and voila amazingly now our
16:58 - code that we had written here is
17:00 - displaying all this information on the
17:03 - right hand side and so let's go ahead
17:05 - line by line and see what is going on
17:07 - here so we can go through together so
17:11 - after I load these packages on lines 8 &
17:14 - 9 we load our data into a data frame and
17:18 - so what is this data that we're actually
17:20 - working with we can see that there is
17:22 - this file artist CSV which is a CSV file
17:26 - which we can open up right over here and
17:30 - you might have seen CSV files at work or
17:32 - at school they essentially contain that
17:34 - same kind of data that you might have in
17:36 - a Google sheet or an Excel spreadsheet
17:40 - and in this format it's a little bit
17:43 - hard for us to read
17:45 - this data I can look at it and I can see
17:47 - some band names from around the world
17:49 - I'm a huge music fan a huge music lover
17:53 - so I love working with music data and
17:55 - that's I also think one of the cool
17:57 - things with data science is you can find
17:58 - data about any sort of topic that really
18:01 - interests you so I went ahead and show
18:03 - some music data for this lesson and
18:06 - we're going to take that CSV data and
18:08 - use a function from one of our packages
18:11 - called read CSV to load it into a data
18:14 - frame that we're naming artists and in
18:18 - this next code block we're using a few
18:20 - different functions to go and look at
18:22 - that data into data frame so right here
18:26 - on the right hand side we can see our
18:27 - artists data frame has a few different
18:29 - columns one is group which looks like to
18:32 - be showing a group name we have a
18:34 - country representing the country that
18:36 - nut band is from as well as the genre
18:38 - and if we click over we have a few
18:41 - columns representing streaming numbers
18:43 - so we have Spotify monthly listeners
18:46 - YouTube subscribers year founded and the
18:49 - number of albums that that band has
18:51 - created so we have a few different
18:52 - columns here of data some of these
18:55 - columns contain what we call encoding a
18:58 - string which is text data so for the
19:01 - band name and for the country those are
19:03 - strings
19:03 - other columns represent some numeric
19:06 - data that we have so like those
19:08 - listeners or the year founded and so we
19:14 - can use a few different helpful our
19:15 - functions to inspect or analyze this
19:19 - data frame one of which is the head
19:21 - function so that goes ahead and just
19:23 - just grab just the first five rows from
19:25 - that data frame that we have and then or
19:30 - four six excuse me and then we also have
19:33 - our summary function so the summary
19:36 - function which is on line 21 is able to
19:40 - give us some information and statistics
19:43 - about are the columns of our data frame
19:47 - so we can see here we have the min value
19:51 - the median value the mean and so it's
19:55 - writing us some quick insights about
19:58 - our different columns that we have one
20:04 - less code block that we have here in
20:06 - this notebook file we're doing a lot of
20:12 - stuff here so I want to break it down
20:13 - with you line by line and if anyone has
20:17 - any questions feel free to put them into
20:19 - the chat about what's going on and we'll
20:21 - make sure that we can jump into them so
20:25 - we're taking our artists data frame that
20:28 - we have right so that's that same
20:30 - collection that we had right up here and
20:33 - we're going to use some functions from D
20:35 - plier to filter and breakdown and see
20:40 - what's going on inside of our data frame
20:42 - so first we are going to use a function
20:46 - called select and what the Select
20:48 - function does is it says let's only look
20:51 - at certain columns of our data frame so
20:52 - some of them are important to us other
20:55 - ones aren't so in this case I'm telling
20:58 - on line 27 that we do not want to see
21:01 - that country column the year founded
21:03 - column or the albums column those aren't
21:06 - important to me we're gonna take them
21:07 - out and remove them and really quick
21:10 - click now because I see a lot of people
21:12 - were also asking about how are relates
21:14 - to sequel and for those sequel lovers
21:16 - you'll see that their functions select
21:18 - is very similar so you can really just
21:20 - think of that block of code from line 26
21:23 - to 30 as a really long select from where
21:26 - function condensed in our syntax so
21:29 - there's definitely a bunch of similarity
21:31 - than actually for those who like started
21:33 - learning sequel and then are moving to
21:35 - our it's a really easy way to put things
21:37 - into perspective definitely before I
21:41 - ever knew R or Python even I had that
21:45 - background with sequel and so I had
21:47 - learned those select from you know
21:52 - ordering by and a lot of those same
21:54 - concepts filter on right over to R so
22:01 - now lets you talk about another function
22:04 - that we can do in R that is similar to a
22:08 - sequel statement actually so
22:11 - it's equal if you work with that we can
22:14 - use a where clause where we say we are
22:17 - looking for rows that have a certain
22:19 - value in a column well in our we can use
22:22 - our filter function so in line 28 we are
22:26 - using a filter function and we're saying
22:29 - let's only take the rows of this data
22:32 - frame where thus modified monthly
22:34 - listeners is greater than this number
22:36 - which is I'm checking right now
22:39 - 20 million so if we have any rows where
22:43 - the number of Spotify monthly listeners
22:45 - is greater than 20 20 million we want
22:47 - those rows and we're also going to pass
22:50 - another condition that we only want
22:52 - groups that are not in the genre of
22:54 - hip-hop and so in this case I could have
22:58 - said I only want groups to have a genre
23:00 - of rock or a genre of electronic but
23:03 - here we're specifically saying we just
23:04 - want any group that has the Spotify
23:08 - multi listener is greater than 20
23:09 - million but a genre that is not hip-hop
23:11 - and then on our last line also going
23:15 - back to sequel if you're familiar about
23:16 - that order by Clause here we're using
23:18 - the arrange function and this says let's
23:21 - order or arrange the rows of this data
23:23 - frame by certain columns so in this case
23:28 - we want to order our data frame by the
23:30 - number of YouTube subscribers but we
23:33 - want to do it in descending order so
23:34 - that means going from the greatest value
23:37 - to the lowest value so if we take a look
23:40 - at what that code looks like when we've
23:41 - run it we can see that we now only have
23:44 - three rows three groups ruin five
23:47 - imagine dragons and Coldplay so if we
23:50 - have any fans of these groups in the
23:53 - chat feel free to shout it out we can
23:57 - see that these are all rock bands rock
23:59 - is you know pretty Universal popular
24:02 - genre all across the world
24:05 - and we can see they all have spawned
24:07 - five monthly listeners that are over
24:10 - that twenty million number so we can see
24:15 - here since we're or arranging by number
24:17 - of YouTube subscribers that the band has
24:19 - the highest number of YouTube
24:21 - subscribers which is 240 million seven
24:24 - hundred eleven
24:25 - and 114 is maroon 5 so it seems like
24:28 - they are our big big popular band so I
24:31 - see L pretty happy about that I'm glad
24:34 - that you're a band that you love is
24:36 - being represented hold plays number
24:38 - three coral call play number three and I
24:44 - see a great question in the chat from
24:46 - Alina um what exactly does the pipe
24:49 - operator do and so the pipe operator is
24:52 - this funky-looking symbol right here
24:55 - with a % carry and % and this is
24:59 - something that I think is pretty unique
25:02 - to our and specifically to the tidy
25:04 - verse which is this collection of
25:06 - packages that we're working with here
25:08 - and if you're familiar with programming
25:12 - at all or have any background or
25:14 - experience typically when you're using a
25:17 - function you'll pass in a variety of
25:19 - arguments so for example with this
25:22 - select line or select function we're
25:25 - saying we don't want the country we
25:27 - don't want your founded and we don't
25:28 - want the album's on line 27 and
25:32 - typically we would also as a first
25:36 - argument directly pass in our artists
25:39 - data frame right here so if we wanted to
25:42 - just do this in one line like this we
25:44 - would write something like that with
25:45 - artists as a first argument but the pipe
25:48 - symbol enables us to write code in a way
25:53 - that I think makes a lot of sense and is
25:57 - helpful when you want to do multiple or
26:00 - use multiple functions in a row so in
26:03 - this case I want to take that artists
26:05 - data frame and I want to select certain
26:08 - columns from it on line 27 then I want
26:10 - to filter on line 28 and then I want to
26:13 - arrange or order them on line 29 and so
26:16 - this pipe operator is allowing us to
26:18 - basically say let's do that selection on
26:22 - line 27 and then take that selection and
26:25 - now use the pipe to send it to our
26:28 - filter function and once I do that
26:30 - filtering on line 28 let's use the pipe
26:32 - again to pipe that filtered data frame
26:38 - into our arranged function so lets us
26:40 - write our code in a sequential order
26:43 - that you traditionally wouldn't be able
26:45 - to do so a great question of a liter
26:50 - awesome so this was a nice little quick
26:52 - jump into the learning environment into
26:55 - our but there's so much more that we
26:57 - have in store for you all today and it's
27:00 - going to take us venturing off platform
27:02 - venturing to other parts of the web so
27:05 - if you want to circle back to our learn
27:07 - our course we highly recommend that you
27:09 - do that in your free time after the
27:13 - session later today or over the weekend
27:14 - and check it out for yourself it's a
27:16 - really easy start to your programming
27:20 - journey and I think you had a lot of fun
27:23 - cool so um yeah just another this was we
27:27 - did everything and like one lesson but
27:30 - if you actually take the time to do the
27:32 - lesson you'll see that it'll be breaking
27:33 - broken down so you know a lot of people
27:36 - are like what's a pipe you know operator
27:37 - there will be you know like one lesson
27:39 - specifically on that and then another
27:40 - one on like select and you know
27:42 - understanding tidy verse so I think like
27:44 - if you take your time you'll be able to
27:46 - just break it down more and have a
27:47 - deeper understanding of what's really
27:49 - happening in terms of the language but
27:52 - now it is time to get into some
27:55 - forecasting using Google Trends um so I
27:58 - think Before we jump into the code I
28:00 - want to talk about Google Trends um so
28:03 - little trends is going to be the data
28:05 - source that we will be using today I'm
28:07 - gonna have a quick voice over but you'll
28:09 - see Ian on the Google Trends website and
28:11 - for those all of you online feel free to
28:14 - kind of get on that website and play
28:16 - around it is an amazing publicly
28:20 - available data set and really for those
28:22 - who are unfamiliar with it all of it met
28:25 - measures is relevant hits and kind of of
28:29 - all of your search queries and it's not
28:31 - just with me or review but all over the
28:33 - world I think what's really great about
28:35 - Google Trends is that you're able to
28:37 - look at it from like as a total time
28:40 - series so let's say if I were to search
28:41 - sushi I would be able to set see how the
28:44 - hits of sushi because I'm getting hungry
28:47 - has changed over time and then another
28:51 - cool thing is that
28:52 - and actually even compare things so
28:54 - especially these days you're feeling a
28:55 - little bit bored you can compare well
28:57 - how is sushi and pizza doing across the
29:00 - way in the last five years and so really
29:03 - what it's going to do it's going to take
29:05 - all of those queries that all of us in
29:07 - the world have queried for and then just
29:09 - be able to compare the interest over
29:11 - time now Google Trends can compare only
29:15 - five things at a time so we'll have to
29:17 - we'll have to raise ourselves and then
29:20 - you cannot also look at it not only from
29:22 - a time series perspective but you can
29:24 - look at it geographically by category
29:27 - interest by region interest by City um
29:30 - so super super interesting data sets and
29:34 - one of the reasons actually that there's
29:35 - been a lot of papers published using
29:39 - this data sets is that there is a
29:41 - hypothesis that there's a very strong
29:43 - correlation with the actual level of
29:46 - activity or you know kind of interest in
29:50 - that actual matter so you know if
29:52 - depending on whatever like application
29:56 - you're looking into it so in this case
29:58 - today we're going to be using Google
29:59 - Trends and what you'll see is that
30:01 - there's a fantastic our package and arm
30:04 - function that just takes that data and
30:06 - will be used for our case today to
30:10 - analyze now forecasting forecasting is
30:16 - one of my favorite topics in data
30:19 - science and I think it's somebody it's
30:21 - something it's not a person thing that
30:24 - all of you have had exposure in one you
30:28 - know you've probably learned about it in
30:29 - your statistics class you've heard about
30:31 - it in terms whether folk at forecasts
30:34 - electricity demand sales customer
30:38 - supports tickets I'm you don't all
30:40 - things that you can forecast and that's
30:43 - what we're going to be doing using the
30:44 - Google Trends data set now how are we
30:47 - gonna forecast I wouldn't I wouldn't be
30:50 - freaking out right now if none of you
30:51 - have you know haven't even taken a intro
30:53 - to statistics course that is okay
30:55 - because the really cool thing about
30:57 - forecasting is that there are so many
30:59 - methodologies out there there are some
31:00 - really naive ways to do sis to do
31:02 - forecasting sometimes you can just
31:04 - really
31:04 - take the mean of your historical time
31:06 - series and use that as your proxy for a
31:09 - forecast or sometimes you can literally
31:11 - take your last observation and whatever
31:13 - you see in your data set that would be
31:15 - your proxy for your forecast as well
31:17 - today we're actually going to be doing
31:18 - something more complex but actually be
31:20 - able to deliver it in such a simple way
31:22 - using the profit package I know I have a
31:27 - very glamorous look names so for those
31:29 - of you who haven't heard about profit
31:30 - profit is a library to the package that
31:34 - is created by Facebook now what does
31:37 - profit do profit is essentially a
31:40 - forecasting it is a forecasting package
31:43 - that any one of us have access to that
31:46 - we're going to teach you how to install
31:47 - and that you can apply to your data set
31:50 - another really cool thing about profit
31:52 - is that you don't necessarily need to
31:54 - have like some really deep understanding
31:57 - on regression models or like complex
32:00 - statistical methodologies all you need
32:03 - to do is really understand what is it
32:05 - trying to extract yep I'm slowing down
32:08 - guys sorry this is me getting so
32:09 - motivated so it's something that you
32:14 - just need to understand what is the
32:16 - seasonality what is the trend and then
32:20 - you apply profit to your data set and it
32:22 - will apply the forecast so I understand
32:26 - I spoke very very quickly and do not
32:29 - worry we are gonna go through this with
32:31 - the code and I think I will be able to
32:34 - reiterate it once you guys see it in
32:36 - real life so that is all from me you
32:40 - take it away
32:41 - hold on one moment before I don't know
32:46 - if we want to while transitioning or
32:49 - before transitioning take a moment to
32:51 - get to some of these great questions
32:53 - that we have open yeah great great
32:58 - mention ELISA and so I'm looking through
33:00 - some of these right now so Jeff is
33:01 - asking when working in data science what
33:04 - percentage of time is spent scrubbing
33:06 - data versus analyzing data so you can
33:09 - ask this question to a lot of data
33:10 - scientists or data analysts and you get
33:13 - a variety of answers but there is a lot
33:15 - of truth to this idea that so much time
33:18 - for an analyst might be spent on
33:21 - cleaning or organizing data and getting
33:24 - it ready for that analysis phase this
33:27 - can depend on the environment that
33:28 - you're working in so there are some
33:30 - organizations or companies where there's
33:33 - good data infrastructure and you know
33:35 - these data cleaning tasks maybe aren't
33:38 - as time-consuming but I would say from
33:42 - from you know what I know what I hear
33:44 - there's can often be a lot of time doing
33:46 - that cleaning an organization which in
33:48 - my opinion can be a ton of fun I really
33:50 - enjoy it it's a cool part of doing data
33:54 - analysis but you do also get to spend a
33:56 - lot of time doing that you know actual
33:59 - analyzing or building models or
34:01 - interpreting your data too so I would
34:03 - say that most most jobs have exposure to
34:06 - both sides of Camellia would would you
34:09 - agree with that yes I would and
34:11 - unfortunately it's one of the it's one
34:14 - of the activities of a data scientist
34:16 - that we enjoy the least it's really
34:18 - cleaning the data and there's always a
34:21 - basic kind of I want to say 6040 rule
34:24 - where you have to spend 60% actually
34:26 - getting the data tailoring it trying to
34:29 - make sure that it's reliable doing a
34:30 - bunch of QA and then getting it to a
34:33 - format or you can then actually do the
34:36 - really cool analysis and modeling yes
34:39 - Joe I hate cleaning data it's really not
34:42 - my specialty but we're all you know
34:45 - we're all we all have to do it
34:46 - unfortunately part of the job so some
34:53 - other questions we see here this is a
34:57 - good one
34:58 - that maybe Camellia you can chat a
35:00 - little bit about we have a question from
35:01 - Steve and asking is a forecast and I
35:03 - have a hypothesis the same thing that is
35:07 - a very very good question so actually
35:09 - this is what your question is actually
35:12 - very smart in the sense that you need to
35:15 - have four you need to have hypotheses
35:17 - first of all as a data scientist as an
35:19 - analyst all we come prepared with a
35:21 - hypothesis you need to have an intuition
35:23 - of what's happening and what's driving
35:25 - the data right once you have an
35:27 - understanding of what's actually
35:28 - happening and what is your data
35:30 - like then you're going to have to have a
35:32 - bunch of assumptions that you're gonna
35:34 - have to give and that's what makes
35:36 - really the job of a data scientist
35:38 - irreplaceable is the assumptions that
35:40 - you're putting and you are applying to
35:42 - your data set and so that's going to be
35:44 - able to really kind of configure the
35:47 - forecasts that you use and so right now
35:49 - I will definitely dive into this when we
35:51 - look at our when we look at our
35:53 - application we're gonna have to apply a
35:56 - bunch of assumptions to our forecast but
35:58 - thankfully profit is already going to
36:00 - apply but you will be able depending on
36:04 - the data set that you use in future use
36:05 - and depending of course on the
36:07 - hypothesis you'll have to configure as
36:09 - as as you see fit
36:15 - great question and then we also have
36:18 - another question about what is the
36:21 - difference between forecasting and
36:22 - predicting and can these terms be used
36:25 - interchangeably so I would say that a
36:29 - forecast is a type of prediction we hear
36:30 - this word prediction a lot in data
36:32 - analysis data science and a prediction
36:35 - can be one of a variety of things maybe
36:37 - we are predicting the type of user if
36:42 - we're looking at a bunch of user data so
36:43 - what is maybe like the characteristics
36:45 - of this user or maybe we are predicting
36:47 - a house price based on a variety of
36:51 - factors such as number of bedrooms or
36:53 - the bathrooms but a forecast in itself
36:56 - is a prediction of a future value of
36:58 - something that we are analyzing so that
37:02 - was a great question and so basically
37:03 - forecasting can be aporia's prediction a
37:06 - prediction can mean a lot of different
37:08 - things and the thing is is that as Ian
37:11 - said forecasting and predicting uses
37:14 - basically the same I mean you they are
37:17 - essentially
37:17 - tied together the methodologies that you
37:19 - use for forecasting such as regressions
37:22 - those are the same methods that you're
37:24 - going to be using in any type of you
37:27 - know machine learning and doing a
37:29 - logistic regression and doing a linear
37:30 - regression um so definitely I mean
37:33 - forecasting is part of the modeling and
37:36 - predictive analytics world cool so we
37:44 - have a few more questions I'm I'm seeing
37:47 - a few about the tidy verse and as we
37:49 - jump into our code in our studio I'm
37:53 - will chat a little bit more about that
37:55 - there and so I think we'll move forward
37:58 - into this next step so we can get our
38:00 - hands dirty on a little more code and
38:03 - we'll circle back in to answer some more
38:05 - questions in a bit I will be monitoring
38:09 - the chat and a QA apologies if I don't
38:12 - get to everyone but I will focus on you
38:14 - I promise
38:15 - yeah we love all your questions thank
38:17 - you so much for you know be inquisitive
38:20 - that is one of the I think really
38:23 - defining characteristics of a data
38:25 - analyst or data scientist is asking
38:27 - questions I'm asking questions about the
38:29 - data where the data is coming from if
38:32 - you have someone who's telling you to
38:34 - look at the data and do some insights
38:35 - you should be asking that person
38:36 - questions why why are you interested in
38:39 - this metric what assumptions are you
38:42 - making about the data why why are you
38:44 - interested in it asking questions is
38:46 - really one of the greatest tools that
38:49 - you have out there so keep it up
38:51 - everyone and as Ian logs in and starts
38:55 - working in our I'll give you guys a fun
38:56 - fact I remember when I was a kid
38:58 - everyone was always telling me Camellia
39:00 - you're so curious you don't need to know
39:01 - that stop asking questions and well
39:04 - jokes on them
39:05 - I guess now this intrinsic curiosity is
39:08 - really helping me in my day to day
39:11 - definitely definitely cool so I switched
39:15 - over to our studio which is a
39:18 - interactive development environment for
39:21 - our and when you're going and getting
39:23 - started with our use code Academy check
39:25 - out our lessons it's a great playground
39:28 - for exploring but there comes a time
39:30 - with most programmers when they want to
39:33 - go and start coding on their computer
39:36 - itself and our studio is the best way on
39:40 - your local computer for you to go ahead
39:41 - and do that and so throughout this
39:43 - session we'll do some exploration of our
39:45 - studio I'll show you how to run code in
39:48 - here utilize some of the features and
39:50 - functionality and you'll see that it's a
39:52 - really great tool for writing code in
39:55 - our and on code Academy we have access
40:00 - to a video that we'll go ahead and also
40:03 - show you how to work with our studio
40:05 - that you will have access to temporarily
40:09 - as the part of this whole session so
40:10 - feel free to check that out awesome so
40:16 - let's go ahead and get started with
40:19 - doing some analysis on some Google
40:21 - Trends data so people were asking about
40:23 - how do we work at the tiny purse when in
40:26 - the example we were only going ahead and
40:29 - loading in deep liar and reader so
40:33 - reader and deep liar are part of the
40:34 - tiny birds so we can use our library
40:36 - function to load that package explicitly
40:39 - by just saying library
40:40 - with GPIO reader as a argument or we can
40:45 - just use tiny bursts overall and this
40:48 - tool automatically load for us all the
40:51 - packages in the tidy verse so there are
40:52 - a lot of them out there does it be a
40:54 - simpler thing to do when you're working
40:55 - locally um and we'll do not here in
40:59 - addition there are few other packages
41:00 - that we're gonna use here today that I'm
41:01 - going to load right here and a start for
41:03 - us when it's called lewberty this
41:05 - package is really useful for working
41:07 - with date data so it's a kind of a play
41:10 - on the word lubricate because it makes
41:12 - working with dates easy I like that one
41:15 - there's lots of punny names with our and
41:19 - our universe so I always enjoy that
41:21 - another package we're going to be using
41:23 - as G trends are this package enables us
41:26 - to go and search Google Trends for the
41:28 - specific search terms that we want and
41:31 - get that trend data additionally we're
41:35 - going to use the profit package as
41:37 - Camellia was mentioning created by
41:39 - basically sorry Ian Cara is definitely
41:42 - right did you misspelt ID verse hi Dean
41:46 - thank you so I do this all the time I
41:50 - misspell things when I'm coding and then
41:53 - I go ahead and run my code which I'm
41:55 - gonna try and do right now and we're
41:57 - gonna see I got this error so thank you
41:59 - so much for calling that out I'm gonna
42:02 - go ahead and update this to tidy burst
42:05 - and now when I go ahead and run the code
42:06 - in just a second we should see no issues
42:09 - don't worry about you know sometimes
42:11 - spelling things wrong it happens when
42:13 - you're coding happens to me all the time
42:15 - thankfully we have errors which help us
42:17 - got us in the right direction so great
42:20 - call out and then one less package we're
42:22 - going to use is the maps package and
42:25 - this package will enable us to do some
42:27 - visualizations with maps which are I
42:30 - think really fun really useful we're
42:32 - seeing a lot of these visualizations
42:34 - today with the ongoing kovat 19
42:38 - situation for visualizing you know cases
42:41 - and things like that so we'll do a
42:42 - little example here today and so in art
42:46 - studio i'm able to run a code block
42:48 - using some keyboard shortcuts so for
42:51 - anyone out there who does work in our
42:53 - studio
42:53 - or it's gonna get started with it that's
42:55 - command shift enter and I'm able to run
42:56 - that code and get those packages going
42:59 - um sorry one more comment I think
43:01 - there's some confusion how do we follow
43:03 - along on this so I think this is a
43:06 - little bit different from what we did
43:07 - previously in the le where you guys um
43:10 - had access to the learning environment
43:12 - and could run it on your own we're
43:14 - really this is what we're gonna be doing
43:16 - right now is just showing you how to use
43:18 - this code and so just really all you
43:20 - need to do to be honest is just listen
43:22 - and look and then we'll be providing the
43:24 - code so after you can go ahead and play
43:26 - around with it and run on your own so
43:28 - really all you need to do is just listen
43:30 - and learn yeah and at the end we will
43:35 - share this file with you so you're able
43:37 - to go ahead download our studio yourself
43:40 - and then play around with the code or
43:42 - run it in your own environment um but
43:44 - like Amelia said just sit listen and
43:47 - feel free to ask questions along the way
43:49 - and we'll be asking you some questions
43:50 - too to get some so let's go ahead and
43:56 - get that Google Trends data so we're
43:58 - able to do this using that G trench
44:00 - package I'm gonna use a function called
44:02 - G Trends and this function if we want to
44:06 - get an idea of how it works or what we
44:08 - need for it we're able to go ahead and
44:10 - use a helpful feature of our studio
44:12 - which is this help feature so if I just
44:15 - put a question mark in front of a
44:16 - function I can go ahead and do on a Mac
44:21 - command enter and you'll see in this
44:22 - bottom right hand corner it brings up
44:24 - the documentation for dysfunction and
44:27 - documentation as I'm sure you may have
44:30 - heard from people is a really important
44:33 - part of the coding process documentation
44:35 - is essentially instructions that were
44:37 - written by the creators of packages that
44:40 - explain to you how to use the different
44:43 - functions that they're using they tell
44:45 - you what kind of data you need to put
44:46 - into it what you get out of these
44:47 - functions and overall it's really
44:49 - helpful when you're trying to go and
44:51 - write some code so we can see here that
44:54 - this G Tron's function as arguments
44:57 - takes a few things that we're going to
44:58 - use today and we're going to use the
45:00 - keyword argument the geo argument and
45:02 - the time argument so the keyword
45:05 - argument represents
45:07 - the search terms that we want to use so
45:09 - before we search for sushi and pizza but
45:12 - this time we are going to search for a
45:15 - few different programming languages and
45:18 - so today we're gonna focus on two that
45:21 - you might have heard I heard of Python
45:24 - and Java so in addition to providing two
45:29 - G trends which terms we want you to take
45:31 - a look at we're also going to provide
45:33 - another argument of Geo and the geo
45:35 - argument represents which geographic
45:37 - region we want to focus on so in this
45:41 - case we for today just to make our
45:43 - analysis a little bit easier we're gonna
45:45 - focus on the US so be looking at
45:47 - different interests in the search terms
45:51 - Python and Java
45:52 - I'm throughout the u.s. lastly we're
45:55 - gonna use this time argument in order to
45:59 - limit our search to a specific time
46:02 - period and so we want to look back from
46:06 - today so this current date and then go
46:10 - five years into the past
46:12 - so this plus five is saying let's go
46:15 - back five and then the Y saying five
46:18 - years if I was only interested in going
46:21 - back five months I could change this Y
46:22 - to an M I want to go back five days I
46:25 - can D but we want to go back all the way
46:28 - to 2015 and use Y and I want to save the
46:34 - output of the search to a variable that
46:39 - I'm gonna call mine we'll go and run
46:42 - this code blue on says I'm getting an
46:45 - error and what is my error here so um
46:53 - let's see if I take out this keywords I
46:56 - think it might be true to do keyword
47:01 - we'll give this a shot there we go
47:04 - so misspelling my argument came there
47:07 - but we have to give this a little bit of
47:09 - time to load because what the G times R
47:12 - package is doing is it's going to Google
47:15 - Trends
47:15 - searching these terms for us going back
47:17 - five years and storing it
47:19 - our land area bowl um so let's go ahead
47:22 - and take a look at this variable and by
47:24 - the way guys when you do have access to
47:26 - this code and start playing around with
47:28 - it on your own have fun with it change
47:30 - the parameters like if you're from Kenya
47:32 - look at like the different trends on
47:34 - different top searches if you're from
47:35 - Brazil
47:36 - like look at what's been happening in
47:38 - like forests versus you know anything
47:41 - else
47:42 - be creative these are the things we're
47:43 - really you'll just become a total expert
47:46 - and whatever data said that you're
47:48 - looking at and that's a great point
47:51 - camellia another thing of data science
47:53 - that I was touching on a little bit
47:55 - before is kind of the topic or the
47:57 - domain of interest and so we're talking
48:00 - about programming programming languages
48:02 - here since we love programming we work
48:05 - at an educational technology company and
48:07 - something that we're passionate about
48:08 - but let's say you're a sports fan um you
48:12 - can feel free to update those keywords
48:13 - to different sports or if you love food
48:16 - different food options or video games
48:19 - you can put it in popular video games
48:21 - here whatever your interest is feel free
48:24 - to go find data related to that I think
48:26 - it's one of the really interesting about
48:28 - data science is being able to dive into
48:29 - whatever it is that excites you one of
48:31 - the fun things that you guys can
48:32 - actually do because I'm sure that all of
48:34 - you will want to go on vacation after
48:36 - this you know this era you can go ahead
48:41 - and be able to use this code to like
48:43 - look at different top holiday
48:45 - destinations and then like predict how
48:48 - popular this holiday holiday
48:50 - destinations are gonna be so you can
48:52 - figure out you can do some price
48:53 - wrangling and figure out what will be
48:55 - maybe the cheapest ones those are just
48:57 - some ideas I mean there's you can
48:58 - literally spend hours on this once again
49:00 - total dirt totally so many options so
49:03 - many ways you can go so when we're
49:06 - looking at this Lang variable we can see
49:09 - it's spitting out all this data and so
49:11 - this data looks like those data frames
49:13 - that we were looking at before and that
49:15 - would be a good guess because they are
49:17 - data frames when we're getting multiple
49:19 - data frames here so we have a lot of
49:22 - different data and so we're able to go
49:25 - and get an idea of how is this data
49:27 - organized by quickly looking at the the
49:31 - names of the different
49:33 - data frames that we have stored in here
49:34 - so I'm gonna pass our Lang variable into
49:37 - this names function and it's showing us
49:39 - that we have all these different data
49:40 - frames one is interest over time and
49:43 - this is what we'll be using for that
49:44 - time series analysis we can also look at
49:47 - interest by country or interest by
49:49 - region
49:50 - and if we actually looked at interest by
49:51 - country here we would find this data
49:53 - frame empty because we are only
49:54 - searching on us but if we did a global
49:57 - search we'd have all these different
49:59 - countries here and can do a cool
50:00 - analysis but for today we're gonna just
50:04 - go and quickly look at interest by
50:08 - region as a quick starch so if we do
50:16 - lying interest by region and when I
50:19 - start typing in a name of one of these
50:23 - data frames we can see it pops up
50:24 - automatically as a different option so I
50:27 - can click interest by region and the way
50:29 - that we access that's a big data frame
50:31 - within lying is we use this dollar sign
50:32 - operator
50:33 - so we're saying within the Lang variable
50:36 - let's go grab that interest by region
50:39 - and now I'm gonna use our pipe operator
50:42 - and let's try and take a look at the
50:48 - regions that are most interested in
50:51 - Python let's think that's something that
50:52 - we once you get out of this data um and
50:57 - actually before I do this it'll probably
50:58 - be helpful for us to take a look at this
50:59 - data really quickly so I'm going to show
51:01 - that right here so let's look at this
51:07 - data what do we have here right it's
51:09 - easier for us to decide what and I'll so
51:10 - you want to do once we see what we have
51:11 - we have a column location that
51:13 - represents different states we have our
51:16 - hits column which is representing that
51:18 - Google trend popularity so that's what
51:21 - is that interest in this topic so 100
51:26 - being high is eroding the lowest then we
51:28 - have the keyword so that's the actual
51:30 - search term of interest and then we also
51:32 - have a few other columns so we have the
51:34 - geography US but we're not gonna worry
51:36 - about those right now let's just think
51:38 - about that hits and the keyword and
51:41 - location so if I wanted to see which
51:44 - states are most interested in Python
51:47 - what I can do is use that pipe operator
51:49 - and say let's filter this to only show
51:53 - the rows where the keyword is and I
51:59 - could choose here either Python or Java
52:00 - so let's say I want to look at Java I
52:03 - will then use our pipe operator and then
52:06 - say let's arrange these rows by keyword
52:13 - in per sorry by hits in descending order
52:16 - this is saying in descending order write
52:21 - the rows that are I have the highest
52:25 - value for hits with the keyword Python
52:27 - and I only want to see the top 10 rows
52:30 - so I'll use this head function that we
52:32 - were mentioned earlier which just grabs
52:35 - the first number of rows in the data
52:37 - frame that you ask it to so if I pass in
52:39 - 10 here and I'll grab us just the first
52:41 - 10 rows and if we go ahead and run this
52:45 - we can now see the states that have the
52:48 - greatest interest in Java so at the top
52:52 - we have Washington and Virginia I'm so
52:55 - we have one West Coast state one East
52:57 - Coast State and then we also have
53:00 - Massachusetts California Maryland
53:01 - rapping out that top five and really
53:06 - easily if I wanted to go ahead and just
53:07 - see what is the most popular States for
53:11 - a Python I can just go ahead and change
53:13 - that keyword to Python on my code and
53:17 - now we have the states where python is
53:20 - most popular Massachusetts California
53:23 - Washington so it seems like
53:24 - Massachusetts or Washington big coding
53:27 - places and this is one of those things
53:29 - that I think is really fun is to think
53:31 - about why like why is may or may be
53:34 - people looking up coding in these places
53:38 - and a way that we can dig into this a
53:41 - little bit further is let's go ahead and
53:43 - change the data frame really quickly
53:44 - instead of looking at our data frame
53:46 - interest by region
53:47 - let's change us to interest by city so
53:50 - it's gonna be a very similar analysis
53:52 - but instead of the location being a
53:53 - state we're gonna see it by city I'm
53:55 - gonna run this we get some interesting
54:00 - so the most popular place for City for
54:04 - Python is mountain view
54:06 - I don't anyone out there knows if there
54:09 - are certain companies that are based in
54:10 - Mountain View
54:11 - maybe that has to do with it maybe there
54:14 - are some Googlers that are out there
54:16 - searching for Python but that is a
54:20 - possibility so these are the kind of
54:23 - insights that can be fun to search into
54:25 - when you're kind of looking through a
54:26 - data frame to see what you can find and
54:28 - so going back to that question about you
54:30 - know hypothesis testing I think this is
54:33 - like really the power of exploratory
54:35 - analysis right once you start looking at
54:37 - these different types of distributions
54:40 - by city by country by region then in
54:43 - whatever you know in whatever industry
54:44 - or framework you're in that's when you
54:46 - can start building out these these types
54:48 - of hypotheses of like oh well um is
54:51 - there you know are people who are
54:53 - interested in Python or overall in
54:54 - programming and in Mountain View than in
54:57 - anywhere else in the world well what are
54:59 - the things that we can do to test us out
55:01 - and how is that going to affect our
55:02 - forecast so really that's the point of
55:04 - these types of exploratory analysis
55:07 - great great point Camellia and we have a
55:11 - good question from Rachel are the list
55:13 - of hits normalized to 100 and so this
55:17 - hits column is representing relative
55:21 - interests so basically what it's saying
55:25 - is yes we're kind of normalizing from
55:27 - zero to 100 so it's looking like over in
55:32 - a relative manner
55:33 - right like where is this language like
55:36 - most popular or at least popular so yes
55:39 - it isn't that kind of fixed range 0 to
55:41 - 100 it is not exactly a hundred hits
55:44 - there are I'm sure or more than 100
55:47 - searches for the word Python from a view
55:50 - great question though and that's
55:52 - something that you'll see in data a lot
55:55 - maybe were normalizing variables which
55:58 - might mean we're changing the range that
56:00 - they go over in order to aid in our
56:03 - analysis
56:11 - cool so now that we've done this a
56:17 - little bit of exploratory analysis on
56:19 - our data frame it can sometimes be
56:23 - helpful to make a visualization to
56:28 - showcase what we're talking about so
56:31 - it's one thing to look at a list of
56:32 - places where something is popular but if
56:34 - we have that visual with it can be a
56:39 - little more intriguing or interesting um
56:40 - so let's quickly go ahead and make a
56:43 - visualization that will showcase um
56:47 - where certain languages are popular by
56:51 - state so we're gonna go ahead and I'm
56:54 - gonna write some code quickly to do this
56:56 - for us and essentially we're gonna map
57:01 - this data to an actual map of the United
57:04 - States so I'm gonna say I'm gonna use
57:07 - this map data function from the maps
57:10 - package and I'm going to pass in state
57:14 - here and what this is doing is it's
57:16 - grabbing the actual latitude and
57:18 - longitudes of all the US states and
57:23 - grabbing them in this data frame which
57:24 - we're gonna use to do some plotting
57:26 - really quickly and for the sake of time
57:31 - I'm going to copy in some code that I
57:34 - have pre-written
57:35 - I'm so we're able to see this
57:37 - visualization and make sure that we get
57:38 - to the forecasting that we have since I
57:41 - want you all to be able to see this cool
57:43 - visualization
57:43 - but make sure that we get to talk about
57:45 - that forecasting as well I'm gonna do
57:49 - this only for Python or Java so if you
57:51 - can do a quick shout out in the chat if
57:53 - you want to see this this map for a Java
57:55 - or for Python
57:56 - let me know and we'll do the one that
57:58 - we're seeing we're getting more
57:59 - responses from we got a lot of Python
58:02 - here a lot of Python okay so let's do
58:05 - this for scientists I can tell Python
58:08 - lovers so what I'm doing here this is
58:15 - some code that is taking this interest
58:17 - by region data frame that we had
58:19 - up here this is interest by city knob or
58:21 - take that interest by region data frame
58:23 - I'm gonna do a few things to it quickly
58:24 - we're going to create a new column based
58:28 - on the location where we're just lower
58:30 - casing all those values in that column
58:33 - and this enables us to use this data in
58:38 - coordination with the state data that
58:41 - we've looked downloaded from the maps
58:42 - package so we can see this region column
58:44 - is all lowercase but before our
58:48 - locations were had a capital letter so
58:50 - now we're just removing those capitals
58:51 - so we're working in the same format and
58:54 - then we're gonna filter our data frame
58:57 - to only have rows where our region or
59:00 - state in this case is one of the states
59:05 - that we have in this state table and
59:08 - then we're gonna select just two columns
59:10 - to look at the region or the state and
59:13 - the popularity which is the hits we're
59:15 - gonna order it in descending order by
59:17 - fits so now we see for python these are
59:22 - those most popular states and now let's
59:26 - go ahead and create that visualization
59:28 - with ggplot so ggplot is a package that
59:32 - is really amazing for doing
59:34 - visualizations in our and it's I would
59:40 - say a really user friendly plotting
59:43 - package I've worked with madpal live and
59:47 - Python if any of you are familiar with
59:48 - that which is also a really great and
59:50 - useful tool but there is a little bit of
59:53 - a learning curve that comes with using
59:55 - MATLAB and our ggplot is a little bit
59:59 - easier to get up to speed with and don't
60:03 - worry if you don't recognize or
60:05 - understand this code a bunch of payson
60:06 - right now if you start going through our
60:09 - learn our course you can learn more
60:11 - about ggplot and some of those functions
60:12 - and we'll briefly chat about it and take
60:14 - a look at what's going on here briefly
60:18 - but what we are doing is we are using
60:23 - ggplot to add a few maps so we see this
60:28 - geo map here on line 46 to 49
60:31 - and 52:53 and essentially what's
60:35 - happening here as we are creating maps
60:37 - with different data the first map we're
60:39 - creating is the actual state map where
60:42 - we're using that longitude and latitude
60:44 - data to plot out the actual states so we
60:48 - can see the shapes of them and visualize
60:51 - that the next step is going at an adding
60:55 - Ana this popularity data that we have
61:00 - right here so now we're saying on top of
61:02 - that blank map that we created let's go
61:05 - ahead and fill in that information about
61:09 - which states really enjoy Python and
61:13 - we've added in a few more things here
61:15 - that kind of changed the axis so we can
61:18 - see the data more clearly and I just
61:22 - change some of our labels were able to
61:23 - see them more easily we go ahead and run
61:25 - this data we're now able to get this
61:28 - awesome map which I want to expand for
61:31 - us all right here expanding the wrong
61:34 - way this is actually a really and this
61:41 - is I know some people were like ggplot
61:42 - or matplotlib
61:43 - and so this is actually a really easy
61:45 - way to be you know to actually visualize
61:47 - the results in a map versus in a bar
61:51 - chart or in a time series and so here
61:54 - you clearly see that the top hits are in
61:57 - California in Massachusetts and
61:59 - unfortunately in this in more states in
62:02 - the south or now Midwest are there it is
62:05 - less relevant let's say um so I highly
62:08 - recommend to like when you are doing a
62:10 - lot of these types of data analysis to
62:11 - think of a lot of the creative ways that
62:13 - you can actually visualize it especially
62:15 - when you're you know presenting to
62:17 - stakeholders or to leadership it just
62:20 - summarizes so much in one easy in one
62:24 - easy picture
62:30 - great so I'm just looking in the chat to
62:34 - see we have any questions here anyone
62:40 - what's happening right now
62:43 - I think it looks like people are being
62:45 - pretty like thinking really critically
62:47 - about the data it's coming up I really
62:51 - appreciate the like we're trying to
62:54 - understand why California being such a
62:56 - huge state like I do not appreciate
62:57 - what's happening and yet these are the
63:00 - kinds of questions that are great to ask
63:02 - the the data helps us see what is
63:05 - happening but then there's the question
63:06 - of why sometimes and that's where it
63:09 - helps to kind of have some knowledge
63:11 - about the data that you're working with
63:12 - or to have that background because once
63:15 - you're able to see what is going on you
63:17 - can use that knowledge to explain the
63:20 - changes that we're seeing and provide
63:22 - that insight so great questions everyone
63:26 - so I'm just I just have to our our data
63:32 - manager our data team manager is hanging
63:35 - out in the chat and being funny I wonder
63:39 - if you can spot her yeah total credits
63:42 - to her she was giving me tips IRL
63:45 - hey cat awesome so now that we've gone
63:56 - ahead and done some of this exploratory
63:58 - analysis seen our data visualized in
64:03 - different ways let's focus in on the
64:05 - test that we have which is that
64:09 - forecasting and looking at our data over
64:11 - time so to do this let's look at our
64:14 - data frame of the interest over time let
64:21 - me take a look at it here
64:22 - really quickly we have a few different
64:23 - columns we have the date we have the
64:25 - hits which is that popularity we have
64:28 - the keyword those are the columns that
64:30 - we're gonna be focusing on for this
64:33 - analysis and so in order for us to go
64:37 - ahead and get this data ready for our
64:47 - time series there's a few things we can
64:49 - do so let's go ahead and do a little bit
64:57 - of data cleaning on this data so let's
65:03 - take this laying interest over time and
65:06 - we are going to do some manipulation so
65:13 - first I'm going to pass this into a
65:16 - function called a Sybil and don't have
65:20 - to worry about this function too much
65:21 - this is essentially just converting this
65:23 - data frame into a type of data room that
65:26 - works better in the tiny purse so don't
65:29 - able us to do some manipulation more
65:31 - easily and handle this data a bit better
65:35 - and then we're going to do a little more
65:38 - data cleaning where we're going to
65:41 - update our date column to a different
65:45 - date format which will help us or more
65:47 - easily plot and work with this data and
65:49 - then in addition we are also going to do
65:55 - a filter to only look at data that is
65:57 - occurring
65:59 - from at least a week ago and back so we
66:02 - don't wanna look at data from the last
66:03 - week there could be some noise in that
66:05 - data I mean you just want to focus on
66:07 - data from before that time so to do that
66:10 - I'm gonna say I want the date to be less
66:12 - than and I can use this date which will
66:16 - hold the current date and we want to say
66:19 - that we want this date to be at least
66:21 - seven days before this current date and
66:24 - I'm going to save this to a variable
66:26 - Lang time series cool and we have that
66:36 - and I can also just showcase this you
66:37 - quickly and then we're gonna do a really
66:39 - quick visualization on this data before
66:41 - we go ahead into our modeling and we're
66:45 - seeing the requests to slow down a
66:48 - little I think that Ian and camellia are
66:51 - trying to make this a very action-packed
66:54 - 90 minutes yeah succeeding at making
66:58 - this an action-packed 90 minutes for you
67:01 - this will be available as a recorded
67:05 - version on YouTube and fingers crossed
67:09 - that this ends up in your email inbox
67:11 - too since you registered so you will
67:14 - find this again and be able to slow it
67:17 - down okay I'll stop and the only reason
67:20 - I think we might be going a little
67:22 - quicker than we would want to is we're
67:23 - just so excited to get to the forecast
67:26 - in the time series part so bear with us
67:29 - we we will get there yeah and you know
67:33 - it can definitely seem like a lot and it
67:35 - is a lot if you're coming to this never
67:38 - having worked with our before so don't
67:41 - feel bad if you're not understanding
67:43 - every line of code or what's happening
67:45 - this will be like we said available to
67:47 - you to take a look at later on and you
67:50 - can dive into it and you know look back
67:54 - and see again what was happening so and
67:59 - thank you for whoever and the chat was
68:01 - posting that more information with the
68:02 - Google Trends data I think that's really
68:05 - helpful for getting an understanding of
68:07 - what is happening with that hits or a
68:10 - relative interest column
68:14 - but essentially what I just did here was
68:16 - change the format of our date so it's
68:18 - easier for us to work with and we're
68:19 - just looking at dates from a week ago
68:21 - back to 2015 so I don't want to look at
68:24 - this past week a week ago to 2015 and
68:28 - let's do a really quick visualization on
68:32 - this data so I'm gonna take our Wang
68:36 - time series and I'm going to pipe it
68:41 - into ggplot and with ggplot there is
68:44 - this weird kind of little different
68:47 - thing where we use this plus sign sort
68:49 - of the pipe symbol when we're piping our
68:52 - information into a different or the next
68:55 - function in this case instead of making
68:59 - a map like we were last time we're going
69:01 - to make a line graph so we can look at
69:05 - this plot over time and what we are
69:10 - going to be plotting over time is our
69:12 - date on the x-axis and then we want on
69:16 - our y-axis to be that popularity or the
69:20 - hits in addition we're looking at both
69:24 - Python and Java here so we're gonna add
69:27 - one more parameter here which is
69:32 - assigning the color to be recognized as
69:35 - our keyword so we could choose to just
69:37 - plot the Python interest over time and
69:41 - we wouldn't need to add in this color
69:43 - keyword if we maybe go and filter our
69:45 - data to just be Python but because we
69:47 - have both Python and Java we're gonna
69:50 - edit this additional keyword so it'll
69:51 - put them both in their own color and
69:55 - lastly I'm going to add one more
69:58 - parameter here of size equal to one
70:00 - which says how big do we want to draw
70:02 - this plot so I'm going to go ahead and
70:04 - run this code and we can get a really
70:07 - quick visualization of what this data or
70:10 - this time series data looks like over
70:12 - time you can see we start and maybe
70:15 - camellia if you want to jump into
70:17 - analyzing this for us I mean yeah I mean
70:20 - this is I think where the core of the
70:22 - time series analysis actually begin so
70:24 - what
70:25 - CEA's x-axis the date which we've been
70:27 - pulling from Google Trends and our
70:29 - y-axis is the hits and so I think one
70:32 - thing that you would never have been
70:34 - able to visualize if you just looked at
70:35 - this in tabular format is that overall
70:38 - the trend which once again is a very key
70:40 - term in time series analysis the trend
70:43 - for Java is decreasing whereas the trend
70:46 - in Python is increasing and you see that
70:49 - really starting around 2016 you're
70:51 - starting seen this kind of shift where
70:54 - the hits kind of like a bifurcated and
70:56 - so that's when you can start developing
70:58 - a lot of these hypotheses
71:00 - however Travis I think has just
71:03 - mentioned it which is no one is
71:05 - searching code on new years as you guys
71:08 - see these are cyclical trends and every
71:10 - single year starting you know December
71:12 - December 20th or so there's just this
71:15 - huge dip where people are just like done
71:18 - I'm not interested in programming I just
71:21 - want to spend time with my family for
71:23 - holidays and so this is something that
71:24 - definitely we'll be able to replicate in
71:27 - the in in the in the forecast because
71:29 - this is a really core element of our
71:32 - time series and then in terms of
71:34 - hypothesis really one of the reasons
71:37 - that you could potentially think about
71:38 - why the interest in Java is decreasing
71:41 - versus Python is increasing is that for
71:44 - example in data science you start seeing
71:46 - that Python is a language that can
71:47 - definitely easily be used for so many
71:50 - applications and then there's a lot of
71:52 - the core functionalities of Java that
71:55 - make it a little bit more of a tougher
71:56 - language to learn can be used with
71:58 - similar applications in Python one
72:01 - hypothesis but there's so many things
72:02 - that you can derive from this plot great
72:10 - thanks for that analysis camellia and
72:13 - one of the things that I just want to go
72:16 - back to what Gigi plot is in three lines
72:19 - of code we were able to go ahead and
72:22 - create this plot which i think is really
72:24 - awesome really user friendly and even if
72:28 - you don't you know know the ggplot
72:32 - syntax at this time that's totally okay
72:34 - you can check out our course on GG plot
72:37 - which will go ahead and
72:39 - all the code that's here and if you get
72:42 - to that lesson you'll be able to create
72:44 - a chart just like this
72:50 - so now that we have this time series
72:52 - data we can move on to that really
72:56 - exciting part of modeling and so a lot
72:59 - of people keep asking questions the chat
73:01 - about you know what does that split
73:04 - between cleaning and getting data ready
73:08 - and the modeling and so we're finally
73:10 - getting to that point now where we can
73:12 - do that model make those predictions and
73:16 - so we're going to do this using the
73:18 - profit package so I'm going to create a
73:23 - new variable that will store our model
73:26 - I'm gonna call it Python M to represent
73:29 - the model and I'm now going to use the
73:32 - profit function from the profit package
73:35 - and I'm going to pass into it our time
73:40 - series data I know there's actually one
73:42 - thing that I'm forgetting to do before
73:44 - this and we just want to focus on the
73:47 - Python data at this time and not worry
73:49 - about our Java data so I'm gonna do a
73:55 - really quick sub setting of our data and
73:58 - cleaning it so it is ready for modeling
74:01 - so I take it back it's a little more
74:03 - cleaning that we need to do in order for
74:05 - us to go ahead and make that model so
74:08 - I'm going to take our lang time series
74:14 - and I'm going to filter it for a keyword
74:20 - equal to Python so I only want the rows
74:23 - of our data frame where the keyword is
74:24 - Python and then I only want two columns
74:29 - from the state of frame
74:30 - I want that date column and I want the
74:34 - hits column so we're only interested
74:36 - right now and like the date of interest
74:40 - and the level of interest on that date
74:43 - and there's one more thing we need to do
74:45 - to work specifically with the profit
74:47 - package is we need to rename these
74:49 - columns for data frame since when we
74:50 - pass this data over to profit and once
74:53 - that data in a particular format profit
74:55 - is picky we have to appease it so in
74:59 - order to go ahead and do that we're
75:01 - going
75:01 - to rename our date column TS which i can
75:04 - do using this rename function and I say
75:07 - I want the new name to be equal to this
75:10 - ole name and then we want to rename our
75:13 - hits column with bi and lastly we want
75:18 - to go ahead and arrange this and order
75:21 - update just so we have it in that nice
75:23 - border of starting out with our oldest
75:26 - data moving forward to our newest data
75:27 - and we can go ahead and look at this
75:30 - variable as well
75:31 - and we can now or this data frame we can
75:34 - now see we have this DES column starting
75:36 - from April 12 2015
75:38 - and the interest in Python was 43 and if
75:42 - I go all the way to the end if I click
75:43 - this 26 here we can see that the most
75:45 - recent data is that week ago or about a
75:47 - week ago March 29 interest of 75 so we
75:51 - see that general increase from 43 to 75
75:54 - over the last five years I'm now gonna
75:58 - go and take that time Python time series
76:01 - data that we have pass it in to our
76:04 - profit function and when I run this this
76:09 - is gonna actually go ahead and create
76:11 - this model for us if you're doing this
76:14 - on your local computer the first time
76:16 - you do this it might take a little bit
76:17 - of time to actually go and run that
76:19 - model I'm the profit package is doing a
76:22 - lot of stuff on the back end doing some
76:25 - math some calculations building that
76:28 - model for you and finding out I'm kind
76:32 - of all that information that's hidden in
76:34 - that data so it's recognizing are we
76:37 - seeing a general increase potentially in
76:40 - our data or is there that seasonality
76:44 - right now new years
76:45 - you know dip that we were seeing things
76:47 - like that I didn't remember that
76:49 - essentially what profit does is curve
76:52 - fitting and so as Ian mentioned it has
76:54 - to be able to capture all of these
76:55 - patterns and understand what are the
76:57 - underlying what are those parameters in
77:00 - order to create the most robust forecast
77:03 - so that's why you just have to be
77:04 - patient with it when it runs and yeah
77:10 - great point patients once again a virtue
77:13 - of a JSON
77:14 - as well so the next step for us is to go
77:19 - ahead and think about how far in the
77:21 - future do we want to make predictions
77:23 - and this is a good thing that you should
77:28 - discuss or think about and plan before
77:31 - you go ahead and start making
77:32 - predictions for ten years into the
77:35 - future you know I was thinking once when
77:38 - I was learning data science learning
77:40 - that I could forecast things I was like
77:42 - okay let me go grab some stock market
77:44 - data and let me go predict what's gonna
77:46 - happen over the next few years so I know
77:48 - exactly where to put my stocks and I'll
77:51 - make all this money why is that maybe
77:54 - not a good idea correct me on this sorry
77:58 - I was answering some chats can your
78:00 - people no worries I'm just saying how
78:04 - when I was first thinking about
78:05 - forecasting and learned that I could go
78:08 - predict out or forecast things maybe a
78:10 - few years into the future I was thinking
78:13 - about putting all my money into these
78:15 - stocks based on my forecast over the
78:17 - next five years or ten years why is that
78:19 - maybe not a great idea yeah I mean
78:22 - markets are very volatile and you
78:24 - definitely want to just have a forecast
78:26 - as close to the present as possible
78:29 - because as you keep extending to two
78:31 - years three years five years you have
78:34 - less of an understanding of what
78:35 - happened in the kind of near in a not
78:39 - only in the in the history in the last
78:40 - year but you're just gonna have like way
78:42 - more error and your residuals will keep
78:44 - growing so definitely keep it in a very
78:47 - non volatile market such so I highly do
78:51 - not recommend to try do not try
78:53 - forecasting come out of the indices or
78:55 - anything relating to finance and just
78:57 - 365 days anything past that it's it's
79:00 - really just gonna be a directional
79:03 - approximation at best and ask or oil so
79:09 - we can make some predictions but we want
79:11 - to keep them in that smaller range Thank
79:14 - You camellia so to go ahead and make a
79:18 - decision on how far we want to go and
79:20 - make these predictions we use this make
79:22 - future data frame function from profit
79:24 - and what this will do is it will create
79:27 - a data frame of
79:28 - it's for us that will include the dates
79:31 - of our actual data that we have so that
79:33 - passed five years from 2015 up through
79:36 - last week and we're gonna go ahead and
79:39 - then look at another 365 days into the
79:42 - future so we use this period equals 365
79:46 - keyword right I'm with that value of 365
79:49 - to say let's look 365 days in advance
79:52 - so I passed that with our model that we
79:55 - created into this make feature data
79:56 - frame function and let's take a look at
79:59 - what we get out of this really quickly
80:01 - we see it just gives us this data frame
80:03 - that starts once again in 2015 of April
80:07 - so like we saw that original five years
80:09 - ago but now if we go to the end it's
80:12 - taking us all the way through 2021 March
80:15 - 29th so instead of being up to a week
80:17 - ago we now have dates all the way to a
80:20 - year from now now we get to go ahead and
80:26 - actually use our model to make those
80:28 - predictions and so to do that we use a
80:32 - handy function that is built into our
80:36 - called predict and the predicts function
80:38 - takes any model that you built and it
80:41 - applies that model to a set of data that
80:44 - you feed to it so we're gonna pass them
80:46 - to predict our profit model as one
80:49 - argument and then as a second argument
80:51 - we are going to pass in our dates so the
80:55 - Python present huge future and I'm going
80:57 - to save this into a variable I'm gonna
81:00 - name Python future and let's go ahead
81:09 - and take a look at this as well and now
81:13 - one more thing I'm gonna do actually
81:15 - before I take a look at this data frame
81:17 - is I'm going to once again use that as
81:19 - table function in order to make this
81:22 - data frame easier for us to work with
81:27 - and now let's take a look at this Python
81:30 - future data that we have
81:33 - there's a lot of great stuff in this
81:36 - data frame that we are going to use so I
81:39 - think it helps to take a second to dive
81:42 - into it and talk a little bit about
81:44 - those columns yeah briefly since I know
81:46 - we are getting short on time community
81:51 - one take a look at discuss one of the
81:54 - best things that we can do is why don't
81:56 - we plot this as a time series so then we
81:59 - can actually go through these sorry that
82:01 - was a lot of noise but we can go through
82:02 - the lock lower and upper bounds and then
82:04 - um I can explain to you what the trend
82:07 - and the additive terms are I think
82:08 - that'll be way helpful than just looking
82:10 - at the data frame awesome great point
82:13 - visualizations are always better than
82:16 - looking at tables and so in order for us
82:20 - to do this for the sake of time there's
82:22 - a little bit of code that I'm just going
82:23 - to paste in here that allows us to do
82:25 - some data cleaning on this data frame so
82:28 - what we're doing here is we're taking
82:30 - this data frame with predictions or
82:33 - forecasts that we made and we are
82:35 - essentially saying let's segment this
82:38 - data into what we actually already had
82:42 - the real data from the past five years
82:44 - and then data from the forecasts so that
82:51 - next year out that were predicting and
82:53 - we just want to make that distinction
82:54 - there so we're able to plot those
82:57 - separately and so I'm sorry that we're
83:00 - not going to dive into this code here
83:01 - there's a lot of fun stuff that we could
83:02 - discuss but I want to make sure that we
83:04 - get to that visualization and now with
83:11 - this data frame we can go ahead and plot
83:15 - this data so what I'm going to do is I'm
83:21 - going to take that Python forecast that
83:23 - we just created and I'm gonna pipe it
83:27 - into ggplot and I'm going to add a few
83:35 - different genomes here to represent
83:37 - different things so first we're gonna do
83:39 - a line graph of our actual data
83:52 - so I want to plot the date versus um
83:59 - inside our date here is D s so the date
84:02 - versus the number of hits which is our Y
84:04 - here and then we're going to and this
84:10 - will plot that actual data that we saw
84:13 - before in our visualization so over the
84:15 - last five years what is going on there
84:16 - and if I plot that quickly we can see
84:19 - that right this is the same data that we
84:21 - have from before just for our Python now
84:25 - let's go ahead and we will add in some
84:29 - code that showcases the forecast that we
84:35 - had and also since we have eight minutes
84:38 - I am going to just paste this in
84:40 - normally I'd walk through it but I want
84:42 - to make sure that we have time to
84:43 - discuss the visualization which is
84:45 - ultimately what we are all here to see -
84:48 - - - and I'm just gonna make sure this is
84:51 - all good all right so let's take a look
84:57 - at this because this is the big the big
84:59 - interesting results this isn't really
85:01 - the final product right this is your
85:03 - forecast essentially and so you'll see
85:04 - that the red part is specifically the
85:08 - part that you predicted based on those
85:10 - five years of data you'll see that the
85:13 - shade
85:13 - those are your predator essentially your
85:15 - prediction intervals so when you saw in
85:17 - that previous data frame upper and lower
85:20 - that's exactly what it was predicting
85:22 - and that's just giving you a cushion of
85:23 - based on the forecast what you can
85:26 - expect that it won't go over and under
85:28 - and yes somebody Travis it predicted new
85:31 - years and why is that because it's an it
85:34 - is an additive regression model it will
85:36 - predict your seasonality and it will
85:39 - protect your trend and so your trend was
85:42 - that since 2015 it was increasing and
85:45 - that is exactly what we are seeing
85:46 - starting 2020 Anna you know at a
85:50 - different slope but it's still
85:51 - increasing now what you're seeing then
85:54 - it also predicts is exactly that
85:56 - seasonality is that every single year
85:59 - December you know the usage or the
86:01 - relevance of that programming languages
86:03 - dips and that's exactly what it's doing
86:05 - um so really this was just a really
86:07 - great example to show you how first of
86:10 - all robust of a prophet is it's a really
86:13 - excellent forecasting package but it
86:15 - also really analyzes the data in order
86:18 - to come up with the most accurate and
86:20 - robust prediction
86:29 - great Thank You camellia for that
86:31 - explanation and what we're even able to
86:35 - do with the profit package is dig a
86:37 - little bit further into what is going on
86:41 - in terms of that seasonality that we
86:43 - were discussing and that trend we're
86:45 - able to do that using this function
86:47 - profit clock components and if we pass
86:52 - into this function our model and our
87:02 - forecast data this is what I love the
87:09 - most because you know it was one thing
87:12 - for me to just do that voice over on
87:14 - like how I would interpret that
87:16 - prediction but profit once again here
87:19 - extracts the seasonality and the trend
87:22 - component of that data set of that time
87:26 - series and tells you exactly what I was
87:28 - just saying how starting 2015 that trend
87:31 - was an increasing trend but at a I don't
87:35 - let so it was increasing more slowly
87:38 - starting 2019 right that's something
87:41 - that we were also seen in the prediction
87:42 - and then can you scroll down a little
87:44 - bit Ian for the early for the
87:47 - seasonality yeah so that's exactly what
87:50 - you see starting man even before no vet
87:53 - yeah I think that's about Thanksgiving
87:55 - actually starting Thanksgiving you start
87:58 - seeing that the hits of Python just
88:02 - decreases dramatically and now this is
88:05 - all cool and I love I mean you know once
88:07 - again if you're interested in this type
88:09 - of stuff if you want to understand how
88:10 - our model works these are some really
88:12 - cool trends to be able to understand but
88:14 - why is this even more relevant in let's
88:17 - say in an operation or in logistics or
88:20 - in supply chain because when you're
88:22 - actually trying to say okay like I need
88:24 - this number of supply for the month of
88:27 - November well you're gonna use your
88:29 - historical time series to be able to say
88:31 - well you know between September and
88:34 - November my supply is always between X
88:37 - you know X amount and Z amount which
88:40 - this is where the confidence intervals
88:42 - come in and you're really able to have a
88:44 - stronger more solid understanding of
88:46 - your business if you're able to
88:47 - understand me seasonality and trends
89:02 - call you in awesome thank you for that
89:06 - explanation camellia and now what we can
89:08 - do quickly with our few remaining
89:11 - minutes is take a look at our Java data
89:16 - and I'm just gonna go and paste in a
89:18 - bunch of code here that's essentially
89:20 - replicating what we were doing earlier
89:23 - I'm but it's not able to go and look at
89:26 - both our Java and Python together so I'm
89:31 - just gonna grab this and let's run some
89:45 - of this code so what's happening here is
89:48 - we're creating that time series for just
89:49 - Java like we did with Python and we're
89:53 - gonna go and build our model for Java
89:57 - make those pick shion's on or this
90:00 - forecast for the next year and we're
90:04 - gonna do a little bit of data cleaning
90:07 - segmenting our data into the data that
90:09 - we already have versus what our forecast
90:12 - is and now we're gonna go and combine
90:15 - that forecast data for both Python and
90:19 - Java into one data frame and then we can
90:22 - go ahead and plot it all together so now
90:29 - we can see what those google trends look
90:32 - like over time for the past and for our
90:35 - forecast for both Java and Python here
90:37 - so what's the what's the outlook for
90:40 - Java Camellia are we are we gonna see a
90:43 - Java resurgence I don't know I don't
90:45 - know it's just this graph does not give
90:47 - me much confidence I will definitely say
90:49 - that it's at best staying at the level
90:53 - that it was in 2020 with similar
90:56 - seasonality for Christmas 2021 um and
91:02 - Python is gonna keep increasing which
91:04 - I'm very excited to see yes yes seems
91:09 - like Python is having having a good
91:11 - moment I'm interested to run this
91:13 - analysis on R and see how R is doing my
91:19 - gut says that our would also be seeing a
91:21 - similar increase with with Python with
91:24 - data science becoming we're talked about
91:26 - more popular these days but we'll have
91:29 - to do some coding and find out and guys
91:32 - I know we went we covered a lot a lot a
91:35 - lot of material but definitely try you
91:38 - know try to rerun parts of this code
91:40 - play around with different keywords play
91:43 - around with different regions um do the
91:46 - question mark profit question mark
91:48 - ggplot2 question mark whatever and
91:51 - really learn about your packages learn
91:53 - about your tools and learn about your
91:54 - methodologies because as a data
91:56 - scientist you're really only as good as
91:57 - your toolkit um so really could not and
92:00 - don't be afraid that's really my biggest
92:02 - recommendation yeah go out explore find
92:06 - anything interest you and if you're not
92:09 - sure where to get started on this whole
92:11 - journey to learn our course that we have
92:13 - on Koch Adam II is a great starting
92:15 - place
92:15 - we highly recommend it and you know it's
92:19 - a great place to get your feet wet so
92:21 - don't be scared keep asking all those
92:23 - questions and you'll have a great time
92:26 - and really the last thing that I will
92:28 - say because I know in every intro to
92:29 - programming courses you know your
92:31 - professor or your teacher will always be
92:32 - like you can't break it you're not gonna
92:34 - break your computer and that couldn't
92:36 - even be more true for AR you will never
92:38 - break anything so just go ahead be crazy
92:41 - be ruthless and just practice makes
92:43 - perfect right
92:46 - yep give it a shot give it a go nothing
92:49 - you can do will be wrong it's all
92:51 - learning journey so I hope everyone had
92:54 - a great time today I posted a link in
92:57 - the chat to download the code we will
92:59 - also place it on the site for you so you
93:05 - can be on the lookout for it there but
93:07 - once again I'm going to paste that link
93:08 - one more time you want to go ahead and
93:10 - download that code so feel free to just
93:13 - go and download it right there thank you
93:17 - all so much we had a wrap-up session
93:20 - that you can move on over to to hear
93:24 - some closing remarks from our day of
93:26 - code and I'll hang out around here for a
93:30 - little bit and try and answer some more
93:31 - questions I'm just in the chat but thank
93:35 - you all so much fun today thank you bye
93:39 - bye everyone
93:52 - and everyone who's still here I'm
93:56 - looking for the lang to send you all
93:58 - over to our closing remarks
94:15 - okay everyone I'm about to post in the
94:18 - chat the link to the closing remarks
94:21 - feel free to check it out
94:24 - thank you all um awesome Thank You Renee
94:30 - mazwell for posting them there you all
94:34 - take care have a great day and yeah I
94:37 - feel free to reach out to us on you know
94:39 - can the internet LinkedIn things like
94:43 - that I'm happy to chat more take care