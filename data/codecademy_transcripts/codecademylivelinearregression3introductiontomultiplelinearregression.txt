00:00 - think we should be
00:03 - live in just about a second
00:10 - i am going to
00:14 - oh i see someone in the chat
00:17 - let us know in the chat on youtube if
00:20 - you can see us
00:21 - um for anyone who's following along we
00:24 - are going to be streaming on a few
00:27 - different services but we'll be keeping
00:28 - an
00:29 - eye on the youtube chat so if you'd like
00:31 - to
00:32 - chat with us you can find us there um
00:35 - hopefully we are all set
00:39 - but cool okay i see looking good
00:43 - thank you um we're so jamie and i are
00:46 - flying
00:47 - without alex today and he's the uh the
00:50 - resident
00:51 - expert in live stream so we're just
00:53 - making sure we know what we're doing
00:55 - but i think we got it so um
00:59 - cool so today we're going to be talking
01:01 - about
01:02 - multiple linear regression and we're
01:05 - going to
01:06 - um we're going to use some kind of small
01:08 - examples to get ourselves
01:10 - started but it's going to be a pretty
01:12 - packed day
01:13 - so i'm going to go ahead and get started
01:17 - right away
01:18 - um actually really quickly as i'm
01:20 - sharing my screen do you want to
01:21 - introduce yourself jamie
01:23 - for those who met you hi everyone i'm
01:26 - jamie
01:27 - um i'm just tagging along and helping
01:29 - out sophie with this live stream
01:31 - i'll also be helping to answer any
01:33 - questions in the chat and be monitoring
01:35 - it
01:35 - so if you have any questions
01:38 - or talking about multiple linear
01:40 - regression um please serve in the chat
01:42 - yeah awesome yeah so um jamie can also
01:47 - stop me at any time uh since he could
01:50 - like get my attention more easily so
01:52 - i will keep an eye on the chat but if i
01:54 - miss something
01:55 - um or you need me to go over something
01:58 - again just
01:58 - let let us all know um
02:02 - in the chat awesome so
02:05 - we'll jump right in um today we're going
02:08 - to be using another
02:10 - dummy data set to start and then we'll
02:12 - use um
02:14 - we'll also use a real data set for the
02:17 - second example
02:18 - um so this is actually part
02:22 - of a project on codecademy so if you're
02:24 - following along
02:26 - in the um the linear regression
02:29 - with python course on codecademy this is
02:33 - the
02:33 - linear regression at codecademy um
02:37 - project and this is a made-up data set
02:40 - but
02:40 - it's actually something that we could do
02:43 - at codecademy that we thought about
02:45 - um and so i'm gonna like paint the
02:48 - picture for everyone
02:50 - so the idea is that we're imagining
02:53 - we're some curriculum developers we're
02:55 - trying to develop
02:56 - a new lesson and we we actually have two
03:00 - versions of a lesson teaching the same
03:02 - thing
03:02 - this is actually true of our linear
03:04 - regression uh courses
03:06 - we have an old lesson that um i think
03:08 - alex or maybe sunny wrote
03:10 - and then we have uh this newer lesson
03:13 - that i wrote
03:14 - um so you could imagine right that we've
03:17 - got two different lessons
03:18 - but teach the same topic but we have one
03:20 - quiz at the end
03:21 - and we're trying to see uh whether
03:24 - one lesson is better than the other
03:26 - lesson in terms of
03:28 - teaching students that topic but we also
03:32 - have some other information about each
03:34 - student
03:35 - and that is the number of other content
03:37 - items they have completed
03:39 - on our website and so you'll see in this
03:42 - data set that i've printed out
03:44 - for everyone for each student they're
03:47 - going to get a score
03:49 - on the on the final quiz
03:53 - and then they're going to get a number
03:55 - here in this completed column that tells
03:57 - us how many other content items they've
04:00 - completed
04:01 - and then here we've got an indicator
04:04 - that tells us which lesson they took on
04:07 - codecademy's website
04:10 - and we want to use all this information
04:13 - to
04:13 - predict score and in the process we want
04:16 - to understand
04:17 - what's the relationship between all
04:19 - three of these things at once like
04:21 - what's the relationship between how many
04:23 - um
04:25 - how many content items someone completed
04:27 - on their score
04:28 - and what's the relationship between
04:30 - which lesson they took and their score
04:33 - and we're going to build a model to do
04:34 - that so
04:36 - up to this point we've only
04:40 - done simple linear regression which is
04:42 - to say that we've only used
04:44 - one predictor in our linear regression
04:46 - models
04:47 - so we have the skills so far
04:51 - to create a model where we predict score
04:54 - using the completed variable so i'm just
04:57 - going to demonstrate i'll
04:59 - quickly plot these things so that you
05:01 - can all see
05:03 - so we do a scatter plot
05:08 - of um completed
05:13 - against
05:16 - score
05:20 - show that
05:23 - right we get this relationship between
05:25 - these points
05:26 - and we can see that it looks like people
05:29 - who have just completed
05:31 - more content items regardless of what
05:33 - those patent items are
05:35 - people that have completed more content
05:36 - items are doing better on the quiz
05:39 - right people who are who have done less
05:41 - content items are doing the first on the
05:43 - quiz
05:45 - we can also make a box plot right we can
05:47 - do this
05:51 - um of
05:54 - the same thing
05:57 - uh but now looking at
06:00 - the lesson variable
06:05 - and we see it looks like on average
06:08 - people are doing a little bit better if
06:11 - they took lesson a
06:13 - compared to if they took less than b
06:18 - so we've now looked at two bivariate
06:20 - relationships we looked at the
06:21 - relationship between these two variables
06:24 - and these two variables but we haven't
06:26 - looked at all three together
06:28 - and remember before when we were when we
06:31 - used simple linear regression
06:33 - when we fit a linear model here we're
06:35 - trying to find the line that minimize
06:37 - the the vertical distance between the
06:39 - line and all these points
06:41 - when we did a linear regression
06:44 - with these two variables we were doing
06:46 - the exact same thing
06:48 - it's just that we were
06:52 - here
06:55 - it's just that our points
06:58 - [Music]
07:00 - were
07:13 - sorry sometimes coding and talking is
07:16 - tough
07:18 - right but we did we had something like
07:21 - this right where
07:22 - we have a set of points here a set of
07:24 - points here we basically are finding the
07:26 - mean of each
07:27 - set of points and drawing the line that
07:29 - goes through those two points
07:33 - now we're going to try to fit a model
07:36 - that predicts
07:37 - score using
07:40 - both completed and lessen
07:44 - as predictors
07:47 - so in order to do that i think actually
07:49 - the first thing i'm going to do
07:51 - is i'm just going to fit the model and
07:54 - then we're going to go back we're
07:55 - going to try to understand what the
07:57 - output looks like
07:58 - [Music]
08:00 - so um
08:01 - [Music]
08:03 - let us go ahead and i'm going to grab
08:07 - this from my final code
08:12 - to be honest i don't see any question
08:14 - about
08:15 - a candle bar in in trading stocks
08:19 - crafts um i don't know what a candle bar
08:22 - plot
08:23 - is to be honest but
08:26 - a box plot really quickly is just so
08:29 - this just shows this line in the middle
08:31 - shows the median and then these are the
08:34 - 25th and 75th percentiles and these i
08:38 - believe are like the 90
08:40 - 50 or 97.5 percentile and 2.5 percentile
08:45 - so like 95 of the data is in between
08:48 - these two lines and then these are
08:50 - outliers so it just gives you a sense of
08:53 - where this data lies um
08:57 - similar to this picture i will look up
09:00 - what a candle bar graph looks like
09:03 - um okay so here's our model
09:08 - we're again gonna use oh i gotta
09:10 - probably grab
09:12 - oh no sorry guys
09:19 - so here's our model um
09:22 - we're using this ols from formula
09:25 - function again
09:26 - we've been using up to this point we're
09:29 - fitting this model where we say
09:31 - let's predict score using
09:34 - lesson and completed as predictors
09:38 - and we're going to use the codecademy
09:41 - data so that's this
09:42 - data set that i printed up here
09:47 - and then we're going to fit the model
09:50 - and then we're going to print out the
09:52 - parameters of the model
09:53 - so here i'll do this so everyone can see
09:55 - all of my code in one place
10:00 - so i run this
10:04 - i get an intercept a
10:08 - slope on lesson t dot
10:11 - lesson b which looks a lot like what we
10:14 - saw last week when we talked about
10:16 - categorical predictors already
10:18 - and then i also am getting a
10:21 - slope on completed
10:24 - so we're going to try to understand what
10:27 - these
10:28 - three pieces of information give us
10:32 - the other thing i want to do before we
10:33 - jump into this a little further
10:36 - is i'm going to just add a little bit to
10:39 - this graph right here
10:41 - so in this graph remember we're just
10:43 - looking at
10:44 - the relationship between completed and
10:47 - score
10:48 - so just two of our variables in this
10:50 - equation
10:52 - down here but
10:55 - i can visualize the third variable which
10:57 - was less than
10:58 - by using a little bit of color
11:04 - um i also think actually a nicer way to
11:06 - write this
11:08 - is you can do
11:11 - this and then tell
11:15 - python where the data is coming from so
11:18 - now
11:18 - python knows all of this is coming from
11:21 - this codecademy data set and so i don't
11:23 - have to
11:23 - append the name of the data set on each
11:25 - of these things um
11:28 - and when i do that
11:36 - oh is it i think i have to put it and um
11:45 - okay so now we can visualize
11:49 - these three variables at once and we see
11:52 - right that we can still see that
11:54 - relation that positive relationship
11:56 - between
11:57 - completed and score and then we can also
12:00 - see that the blue points for lesson
12:02 - a are a little bit higher than the
12:04 - orange points for lesson b
12:06 - so we can also we can see now those two
12:09 - relationships
12:11 - that we graphed separately here
12:15 - and here or here these two are telling
12:18 - us the same thing
12:21 - cool okay
12:24 - now that we have these two pieces of
12:27 - information
12:28 - i'm gonna switch things up
12:31 - and we're gonna grab the ipad which is
12:35 - very exciting
12:36 - and we're going to kind of walk through
12:38 - some of the math
12:40 - behind this
12:43 - and if anybody has questions please ask
12:46 - them
12:47 - because i know i'm moving a little bit
12:50 - quick
12:52 - so i don't want to miss anyone
12:55 - in the process sorry a little bit
12:58 - off-center
13:01 - okay so i've now
13:05 - written everything out here that we just
13:08 - looked at
13:08 - we've got this graph right that shows
13:11 - lesson a
13:11 - and lesson b color and then we've seen
13:15 - we see score
13:16 - against completed right
13:20 - and then we've also got a
13:23 - we've got our output from that model
13:26 - and we've got the model written out here
13:28 - so remember we did score
13:30 - as a function of lesson and completed
13:34 - so let's write out now what these two
13:38 - things
13:38 - tell us about our model so
13:42 - when we fit this score as a function of
13:45 - lesson and completed model what we're
13:48 - actually saying is
13:49 - we want to fit
13:53 - the following equation so
13:56 - we are saying we want score
14:01 - to be equal to some number i'm going to
14:05 - call it
14:06 - b0 this is a notation thing
14:09 - so before we were using mx
14:12 - plus y equals mx plus b is our equation
14:15 - for a line
14:16 - we're going to write that equation
14:18 - slightly differently now
14:19 - and we'll talk about why we can do that
14:23 - so we're going to write our equation as
14:26 - b 0
14:28 - plus b1
14:32 - times less than
14:37 - plus b2
14:41 - times completed
14:47 - okay now let's take a step back for a
14:51 - second
14:52 - and think through why this is the same
14:56 - as our original equation of a line y
14:59 - equals mx plus b
15:02 - so remember right we started with this
15:05 - equation
15:07 - y equals mx plus b
15:11 - where y was the outcome variable so
15:15 - that's something like
15:16 - score right this is our outcome variable
15:20 - x is our predictor
15:23 - so that's something like completed or a
15:26 - lesson
15:29 - and then this b was our y-intercept
15:36 - and this m was our slope right
15:39 - and these were just numbers
15:42 - so we notationally chose
15:46 - to put the mx term first and the b
15:49 - second but you can add numbers in
15:52 - any order so right like 2 plus 5 is the
15:55 - same as 5
15:56 - plus 2. so we could really rewrite this
15:58 - equation
16:00 - as y equals b
16:03 - plus mx
16:08 - and then we've just chosen to use the
16:11 - letters b
16:12 - and m but we could replace those with
16:16 - anything else
16:17 - so in our new equations we're replacing
16:20 - them
16:20 - with b0 and b1
16:24 - so y equals b zero plus b
16:28 - oops
16:31 - plus b one x is really the same
16:35 - equation as the one above we've just
16:38 - decided to call the slope and the
16:39 - intercept
16:40 - slightly different things
16:44 - so the reason why we use this
16:48 - equation the b0 and the b1
16:51 - is that as we add more predictors like
16:54 - in this case we have less than
16:56 - and completed as predictors
17:00 - we want to be able to expand our
17:02 - equation and
17:04 - use more letters and so if we just use b
17:07 - and m
17:07 - like what's the next letter we're going
17:09 - to use we don't know instead
17:11 - it's a little easier to just say like
17:13 - i'm going to call
17:14 - all of these things b0 b1 b2 b3 and then
17:17 - i can add as many of them as i want
17:20 - so that's why we're using the slightly
17:23 - different equation
17:24 - but the key thing to know is that
17:28 - it's really no different from the y
17:31 - equals
17:32 - mx plus the equation that we started
17:34 - with
17:37 - okay so here's our equation
17:41 - and here is our
17:46 - output right so now let's plug in
17:49 - this output into the equation so we
17:52 - actually have
17:53 - everything written now so really this
17:57 - equation is
17:58 - score equals
18:02 - b zero is our intercept
18:05 - right still the y-intercept is the one
18:08 - that's not multiplying any of the
18:10 - predictors
18:11 - so b zero is 18.3
18:15 - about
18:21 - b1 is our
18:26 - coefficient or slope
18:29 - on lesson now you'll notice that
18:33 - in the output sorry there's some sirens
18:36 - in the background here
18:38 - um you'll notice that in the output
18:41 - lesson got printed out as lesson t dot
18:44 - lesson b
18:46 - what that means is this is actually a
18:50 - indicator for when the lesson is equal
18:54 - to lesson b
18:56 - so remember from last time in order to
18:59 - fit the
19:00 - model with a categorical predictor we
19:02 - have to code the categorical variable
19:04 - as zeros and ones in this case we're
19:07 - saying
19:08 - one for the purpose of this equation
19:12 - 1 is equal to less than b and 0
19:15 - is equal to less than a so i'm going to
19:18 - go ahead and just write this
19:19 - out exactly like it is in the output and
19:21 - then we'll talk about it after
19:23 - so um plus but then it's
19:27 - a negative 13.2 about so
19:30 - plus a negative is really just a
19:32 - negative but we'll write it all out for
19:33 - now
19:34 - so we've got plus minus 13 13.2
19:40 - times and then i'm going to write this
19:44 - whole thing out
19:45 - lesson t dot um so if you have a
19:48 - question in the chat
19:49 - um yeah so uh
19:53 - someone's saying i'm new to python would
19:55 - linear aggression be used for a ride
19:57 - share price predictor
19:59 - it certainly could yes
20:03 - um yeah i'm super excited that people
20:06 - are using this
20:07 - as a way to get more familiar with
20:08 - python they do think
20:10 - it's a lot easier to do to work on a
20:13 - project if you have
20:15 - a specific goal and so these types of
20:18 - these types of problems are super
20:19 - interesting
20:21 - um and it's i think a good way to get
20:22 - started with programming
20:24 - um okay so and then we've got
20:28 - another slope b1 or sorry b2
20:33 - on completed and that's equal to 1.35
20:37 - i'm going to round to 1.4 but
20:41 - 1.4 times
20:46 - completed
20:50 - so here's our equation score equals 18.3
20:55 - plus minus remember plus minus just
20:57 - means
20:58 - minus so i'm actually gonna
21:02 - erase this for a second and just replace
21:05 - it with a minus sign
21:07 - adding a negative is the same as
21:08 - subtracting
21:10 - score equals 18.3 minus 3.2
21:14 - times lesson this
21:17 - whole thing here this lesson t lesson b
21:20 - is just an indicator it's equal to
21:24 - equals one if less than b
21:29 - equals zero if less than a
21:35 - and then plus 1.4 times completed
21:38 - where completed is the number of
21:41 - prior exercises completed
21:45 - so now what i'm going to do is i'm going
21:47 - to break this up
21:49 - into two equations so we're going to get
21:51 - an equation for lesson
21:53 - a and we're going to get an equation for
21:55 - lesson b
21:58 - let's start with lesson a
22:06 - so if a person took lesson a
22:10 - jamie what would the value of this
22:12 - lesson t dot lesson
22:14 - b variable v i think um so
22:17 - since lesson uh t s and v is an
22:20 - indicator variable
22:21 - um and we're looking for the equation
22:22 - with less than a we want to plug in
22:25 - zero for that indicator variable um
22:29 - so then we just get the value um
22:32 - zero for that exactly
22:36 - so if someone took lesson a then the
22:38 - value of this
22:40 - lesson t lesson b thing is zero
22:44 - in that case when we write out this
22:46 - equation we've got score
22:49 - equals 18.3
22:54 - plus 13.2 times 0
23:00 - plus 1.4
23:03 - times completed
23:08 - right and like jamie said
23:12 - anything times zero is zero so
23:15 - 13.2 times zero is just zero
23:18 - so if we simplify this we get score
23:21 - equals 18.3
23:25 - plus zero plus
23:28 - 1.4 times completed
23:31 - and we don't even have to write out plus
23:33 - zero it doesn't mean anything
23:35 - so we get score equals 18.3
23:41 - plus 1.4 times completion
23:46 - now this looks a lot more like our y
23:48 - equals mx plus b
23:50 - equation
23:54 - that we have before we have another uh
23:56 - question in chats
23:57 - someone's asking what if there's an
23:59 - intrinsic correlation
24:01 - between lesson and completion um that's
24:04 - would that have any effect on the uh
24:07 - um aggression so okay so
24:11 - that is a complicated question
24:15 - it seems simple but it's a complicated
24:17 - question um
24:19 - so we have to think about how we
24:21 - designed this experiment
24:23 - so if we if we just randomly assigned
24:26 - people to lesson a or lesson b then we
24:29 - won't be worried about that right we
24:31 - won't
24:31 - we won't worry about the relationship
24:34 - between
24:35 - lesson and completion because
24:39 - lesson was randomly assigned
24:42 - but if not if that's not how we went
24:46 - about this
24:47 - if there's some relationship between
24:51 - lesson and completion then we're gonna
24:54 - need to
24:57 - take it into account somehow um
25:05 - we're gonna come back to that
25:08 - in a couple weeks
25:11 - um so that's like the topic of a future
25:15 - a future discussion um
25:19 - but yeah it's a tough
25:22 - it's a tough question it also it also
25:25 - depends on what your goal
25:26 - of this analysis is like if your goal is
25:29 - to
25:30 - determine whether the lesson that
25:32 - someone took
25:33 - caused them to do better on the
25:37 - on the quiz so you're trying to
25:39 - determine a causal relationship because
25:41 - you want to say like
25:43 - in the future if we show more people
25:44 - lesson
25:46 - uh was it lesson a yeah lesson a where
25:48 - they did better
25:49 - show more people less than a will they
25:50 - continue to do better on this quiz
25:54 - because this is causing them to do
25:56 - better it's a better lesson or something
26:00 - if that's your goal then
26:03 - you then you're gonna need some other
26:06 - strategies
26:07 - to figure out how to and you can't do
26:11 - like a randomized trials you can't
26:12 - randomize people
26:14 - then you're gonna need what's like this
26:16 - field called causal inference
26:18 - to try to balance the groups as best as
26:21 - possible
26:22 - um but yeah there's
26:26 - there is a lot to be said about that but
26:29 - with this method we can't
26:32 - take it into account
26:38 - um okay so this is
26:41 - lesson a our equation for lesson a and
26:44 - now we also are going to have an
26:46 - equation for lesson b
26:47 - let's see where can i do this
26:50 - oops
26:54 - sorry guys i thought i would be able to
26:57 - move this thing
26:59 - okay maybe not
27:06 - all right we'll try to fit this bottom
27:10 - um so for lesson b
27:27 - so for lesson b
27:30 - the value of this lesson t lesson b is
27:34 - equal to one
27:36 - so now when we plug in we're going to
27:37 - plug in a one for that
27:39 - variable so we've got
27:43 - score here
27:46 - four equals starts out the same 18.3
27:51 - then we've got 13.2
27:54 - so minus oops i also realized i just
27:58 - messed this up
28:08 - right so that's a minus
28:16 - we got 18.3 minus
28:19 - then we've got 13.2
28:23 - sorry again times 1
28:27 - because now this whole thing is equal to
28:30 - one
28:30 - if it's less than b and then we've got
28:34 - plus
28:35 - 1.4 times completed
28:44 - okay now anything times one
28:47 - is equal to itself so we can say
28:53 - four equals eighteen point three
28:58 - minus 13.2 because 13.2 times
29:02 - 1 is just 13.2
29:05 - and then we've got plus 1.4
29:08 - times completed
29:12 - and then finally we can simplify this a
29:14 - little bit so we've got 18.3
29:16 - minus 13.2 that's equal to
29:20 - 5.1
29:25 - so we've got score equals 5.1
29:31 - plus 1.4
29:38 - times
29:41 - and that's our equation
29:44 - for a lesson um
29:47 - okay i see a question
29:51 - oh yeah we might need to calculate
29:53 - variance inflation factor
29:55 - prior to doing the regression
29:58 - um
30:01 - yes i i am a little bit
30:05 - rusty on um
30:09 - on this to be honest but you there's
30:12 - definitely ways that you can
30:13 - weight the regression um
30:17 - based off of the like differences
30:20 - between
30:21 - the groups for lesson a and less than b
30:24 - um
30:25 - but yeah again like if if your goal is
30:28 - to prove that
30:29 - lesson a causes an improved score
30:32 - then you're gonna need causal inference
30:35 - methods
30:36 - um yeah
30:39 - okay uh so we've got
30:43 - our two equations for lesson a and
30:45 - lesson b
30:47 - let's try to draw them on this picture
30:53 - so for lesson a our
30:56 - equation was score equals 18.3
30:59 - plus 1.4 times completed
31:03 - so that means that the y-intercept is
31:06 - 18.3
31:08 - and then the slope is 1.4
31:13 - so i'm gonna like imagine right the
31:15 - intercept is back here somewhere
31:18 - in this picture
31:21 - or the y-axis is back here somewhere
31:24 - because this is 10 so back here is zero
31:30 - if we were to extend this out a little
31:32 - bit
31:34 - so if we're crossing 18 at the y-axis
31:38 - it's gonna start that line is going to
31:40 - start around here
31:44 - and we've got a slope of 1.4
31:48 - it's gonna look it's going to be like
31:50 - over 1.4
31:52 - or sorry over 1 up 1.4 over 1 up 1.4 i'm
31:55 - not going to
31:56 - really try to grab try to graph this but
31:59 - we've got some sort of line like this
32:04 - for the other group the slope
32:07 - is exactly the same
32:11 - right the slope is 1.4
32:15 - because the number multiplying completed
32:18 - in both of these equations is 1.4 so
32:21 - it's going to be exactly the same
32:23 - steepness
32:25 - but now the intercept instead of being
32:28 - 18.3
32:29 - it's 5.1 it's exactly
32:32 - 13.2 units below
32:37 - this intercept so for
32:40 - this line the y-intercept is going to
32:43 - start
32:43 - a bit lower but then it's going to oop
32:47 - it's going to have the same slope we're
32:49 - going to try to draw that
32:50 - so same steepness but
32:53 - start slower and that kind of looks like
32:56 - it fits
32:57 - what these points are looking like
33:01 - cool okay are there any questions about
33:05 - this
33:06 - i know we just went over quite a lot um
33:08 - so
33:09 - i actually have a question so will this
33:11 - kind of be like the
33:13 - so for like any kind of multiple linear
33:16 - regression
33:16 - model that's like similar to this where
33:18 - there's an indicator variable
33:19 - and then a like quantitative variable
33:22 - will always be the case that
33:24 - they like basically have like the two
33:26 - different lines
33:28 - um for the indicator variable will have
33:30 - the same slope but different
33:31 - intercept or they ever have the case
33:33 - where they like might intersect
33:35 - um that's a really good question also
33:39 - something that we're going to cover in a
33:40 - future session um but yes there's a way
33:43 - that you can
33:44 - create a set of models where
33:48 - the you're not constrained that the two
33:50 - groups have the same intercept and
33:52 - the same oh sorry have the same slope
33:54 - but have different intercepts you can
33:56 - allow the intercepts and the slopes to
33:58 - vary for the two lines
34:00 - um but the way that you do that is
34:02 - actually by adding
34:03 - another predictor to the model um
34:07 - and so you you end up adding what's
34:09 - called an interaction term
34:11 - um between the two variables so in this
34:14 - case between
34:15 - completed and lesson
34:18 - and we'll we'll talk about that in the
34:20 - future in a future lesson but
34:23 - if as long as you don't have that extra
34:25 - term you don't have an interaction term
34:26 - you just have
34:27 - a binary variable or any categorical
34:30 - variable really and
34:31 - a quantitative variable and you're just
34:33 - adding them as predictors
34:34 - you're always going to end up with a
34:40 - like a set of lines where the slope is
34:42 - the same
34:44 - because all you're ever doing is for
34:46 - different values
34:47 - of your categorical variable
34:50 - or even if this was a quantitative
34:52 - variable and that's what we'll go over
34:53 - in a second
34:54 - but for any values of this variable
34:58 - you're really just multiplying by some
35:00 - number and then that gets
35:02 - added into the intercept and you can
35:05 - never
35:06 - by changing the value of
35:09 - or like by changing the value of this
35:13 - you can never change this 1.4 right like
35:16 - this 1.4
35:17 - is multiplying completed and that's the
35:21 - slope
35:21 - on completed which is what we're looking
35:23 - at in this graph
35:26 - and this piece of the equation
35:29 - can never change that 1.4
35:34 - and uh i guess my other curiosity is um
35:37 - [Music]
35:38 - so our what is the slope um for
35:41 - completed
35:42 - like the multiple linear regression
35:44 - model here versus um what you calculated
35:46 - in the last live stream where you're
35:47 - just like looking at completed
35:50 - as its own like as the one predictor
35:52 - term and then
35:54 - um as like the different lessons as the
35:56 - one particular term
35:58 - that's a really good question so the
36:00 - slope is not necessarily the same
36:02 - as what you would fit so i think what
36:04 - you're asking you can tell me
36:06 - i'm wrong but i think what you're asking
36:08 - is if i
36:10 - fit the original model where i just
36:12 - didn't i didn't color these points
36:14 - off at all i just drew the regression
36:16 - line for
36:17 - this entire set of points so i fit like
36:20 - score
36:21 - as a function of completed
36:27 - and then i just fit that line
36:32 - that slope is not necessarily the same
36:35 - is not necessarily going to be the same
36:36 - as the slope
36:38 - for these two ones
36:41 - yeah that's exactly what i was asking um
36:44 - and then we have a another question in
36:46 - the chat um
36:49 - are the coefficients based on
36:50 - correlation value of less than and
36:52 - complete
36:53 - uh with score yeah so
36:56 - actually um from the regression
37:00 - you can basically recover
37:04 - the correlation between um
37:09 - between like any set of two variables so
37:11 - if we just looked at this
37:13 - score as a function of completed
37:16 - like if we just looked at that model we
37:19 - could
37:20 - recover the correlation between score
37:22 - and completed
37:23 - from the model output
37:27 - um the higher the correlation like the
37:30 - better the
37:31 - the model will appear to be and we'll
37:33 - talk about that
37:34 - in the last session or second to last
37:36 - session a little bit more
37:38 - um so yes it's essentially we're
37:41 - essentially calculating
37:45 - we're not calculating the correlation
37:47 - directly but we're saying
37:48 - the model is going to be a better fit to
37:51 - the data
37:52 - if these things are highly correlated
37:54 - with each other
37:55 - so if score and completed are highly
37:57 - correlated and
37:58 - score and lesson are highly correlated
38:01 - then
38:02 - we can fit a better model that explains
38:06 - more of the variation and the data that
38:08 - we have
38:11 - good questions cool
38:15 - so i'm gonna stop this share now
38:18 - and reshare my notebook
38:25 - cool so i'm just gonna demonstrate
38:29 - really fast how we can
38:31 - um we can add this to add those lines to
38:35 - our graph
38:37 - so remember i i wrote this down
38:40 - um but already down here for everyone
38:44 - so for lesson a we calculated that the
38:47 - equation is
38:48 - or we wrote out the equation as score
38:51 - equals
38:52 - then we said 18.3
38:57 - plus 1.4
39:00 - times theta
39:04 - and that was our equation for a lesson
39:11 - so let's add that to the model or let's
39:13 - let's add
39:14 - that to our picture first so here
39:18 - we're going to do i'm going to add
39:20 - klt.plot
39:23 - i'm going to go from
39:29 - let's see actually what i'm what i'm
39:31 - going to do is
39:32 - i'm going to re-plot codecademy
39:38 - i'll write these out sorry
39:43 - write it out down here so
39:47 - i'm going to write out some x values so
39:50 - my x values are going to be
39:54 - completed so this is the original data
39:59 - academy.completed i can print it right
40:02 - out so that everyone can see actually
40:04 - right these are just
40:05 - my original completed values and then
40:08 - what i'm going to do is i'm going to
40:10 - apply this formula
40:14 - i'll call it completed actually
40:18 - right so i'll apply this formula so then
40:20 - my predicted based on this model my
40:23 - predicted
40:24 - scores based on these values
40:29 - are going to be 18.3 or i'll actually
40:33 - grab this whole thing so it's 18.3
40:41 - plus
40:44 - this number 1.35 whatever
40:48 - times these completed values
40:52 - and then i'll print those out predicted
40:56 - of course great
41:00 - so to get this number 65.75
41:05 - what i did was i took 18.34
41:08 - plus 1.35 times 35
41:13 - and that gave me my predicted score for
41:16 - someone who oops
41:20 - actually yeah so that gave me my
41:22 - predicted score for someone who
41:23 - completed
41:25 - lesson a so i should say
41:29 - predicted scores a
41:32 - yeah okay
41:35 - so let's add that line to our graph
41:40 - now so we can add plt.plot
41:45 - we're going to plot completed versus
41:49 - predicted scores
41:53 - okay
41:56 - and and there's our line
42:01 - for the blue points now to jamie's point
42:04 - if i was just if i was like isolating
42:07 - the blue points
42:08 - and just trying to draw a line through
42:10 - those blue points
42:12 - i probably would draw a slightly steeper
42:14 - line
42:16 - but we're restricted that the
42:19 - the lines have to have the same slope so
42:25 - it's not it's not the perfect line that
42:27 - we would draw through those blue points
42:30 - but it does reflect that the blue points
42:34 - are a little bit higher
42:37 - now let's do the same thing for
42:41 - lesson b
42:44 - so for lesson b my equation was
42:48 - score equals
42:52 - five point one
42:55 - plus one 1.4
42:59 - times completed
43:02 - remember
43:05 - that that 5.1 is really coming from
43:10 - 18.34 whatever
43:13 - minus 13.816 so i'm actually gonna
43:18 - write that all out here
43:24 - and then
43:27 - this is yeah so there's my equation for
43:30 - predicted scores b and now i'm gonna add
43:34 - this to my model
43:39 - all right this is my plot so you can all
43:43 - see it
43:45 - and now we've got right the blue line
43:48 - is the predicted or the line for lesson
43:51 - a
43:52 - the orange line is the point is
43:55 - the line for lesson b and like we said
43:57 - before
43:58 - they have the same slope they're exactly
44:00 - parallel they will never intersect
44:02 - but they do represent two relationships
44:06 - they represent
44:07 - the relationship between score and
44:09 - completed but also
44:11 - the relationship between score and which
44:14 - lesson someone took
44:17 - really quickly because i know we're
44:19 - going to run short on time
44:21 - and i want to get to the next example
44:24 - the other thing to notice about this is
44:27 - that
44:28 - so as we're interpreting this if we just
44:32 - interpreted
44:34 - within lesson a so like let's forget
44:36 - about lesson b for a second
44:38 - this is our our line for lesson a
44:42 - the way we would interpret the slope and
44:44 - the intercept
44:45 - and this kind of comes back i think we
44:48 - skipped over it a little bit in the
44:49 - first week and i
44:50 - kind of regret that because i wish we'd
44:53 - spent more time on it but if you've
44:54 - taken the
44:55 - the lesson onto academy thought about it
44:58 - a little bit maybe you
44:59 - got there yourself right the
45:01 - interpretation of the intercept
45:03 - for this line is it's the expected
45:07 - score on the quiz for someone who
45:10 - completed
45:11 - zero assignments right because the
45:13 - intercept
45:14 - is where this line intersects the y
45:18 - axis and the y-axis happens when
45:21 - completed
45:21 - equals zero so when we have this
45:24 - this y-intercept of 18.3
45:28 - that means that for someone who took
45:30 - lesson a were
45:31 - expecting them to score an 18.3 on the
45:35 - quiz
45:35 - if they completed zero prior assignments
45:38 - based on this model and the slope
45:42 - is the expected difference in score
45:46 - for a one unit increase in completed
45:50 - so right because remember the slope is
45:53 - rise over run
45:55 - so it's the expected vertical increase
45:58 - here which is this difference in score
46:00 - because that's on the y-axis
46:02 - for a one unit run a one unit
46:06 - increase and completed so
46:09 - for groups of people for a student who
46:12 - who completed one more assignment than
46:15 - someone else
46:16 - we expect their score based on this
46:18 - model to be
46:19 - 1.4 points higher on the quiz
46:21 - [Music]
46:23 - and what we're saying here is
46:27 - if this is our model we're not expecting
46:31 - someone's like
46:34 - the potential impact and that word kind
46:38 - of
46:39 - is not the right word um because we're
46:41 - not saying
46:42 - we're not proving any causal inference
46:44 - here but
46:45 - it's the we're not saying that there's
46:47 - any difference in the relationship
46:49 - between completed
46:50 - and score for these two lessons
46:53 - but we are saying that someone is
46:56 - expected to score higher
46:59 - if they took lesson a than lesson b
47:03 - if they completed zero
47:08 - uh lessons prior but also if they
47:10 - completed
47:11 - any number of lessons right because we
47:13 - because the distance between these two
47:15 - lines
47:15 - is stays the same the whole time and
47:18 - it's always going to be
47:20 - whatever this number was like the
47:22 - distance between those two lines is
47:24 - 13.18 points
47:26 - and so the way we would interpret this
47:28 - is we would say
47:29 - controlling for how many
47:33 - lessons someone completed so if we if we
47:36 - freeze this at
47:38 - one particular number of lessons say 30
47:41 - so controlling for how many lessons
47:42 - someone completed we expect
47:44 - the score to be 13.2 points higher
47:51 - among lesson people who completed lesson
47:53 - a
47:54 - compared to people who completed lesson
47:56 - b
48:00 - um i saw a question is there any
48:03 - difference between
48:04 - features and parameters um
48:08 - i think so i would say
48:12 - this is all like semantics of
48:16 - what you refer to things as and
48:19 - people refer to different things
48:23 - with the same thing with different words
48:26 - and different things with the same word
48:27 - sometimes so it's like
48:30 - these the word feature and the word
48:32 - parameter
48:33 - while they have definitions they often
48:36 - get used in different contexts
48:40 - and so i think so
48:43 - i should probably be caught referring to
48:46 - these predictors
48:49 - or these like columns of my data set as
48:52 - features
48:53 - um or predictors if they are predictors
48:56 - on a target variable or outcome variable
48:58 - if they're the outcome variable
49:00 - um but you might see people referring
49:02 - them to
49:03 - referring to them as parameters um
49:07 - okay let me
49:12 - i'm gonna grab the like solution code
49:14 - for the next 10 minutes so that we can
49:16 - get through a little bit more
49:20 - so for the last 10 minutes i'm going to
49:23 - talk about a slightly different example
49:26 - and this example is actually it's from a
49:29 - data
49:30 - set that i grabbed from the uci machine
49:32 - learning repository
49:35 - you can see the citation at the bottom
49:37 - um
49:38 - so this is a study of a group of
49:41 - students
49:42 - so similar topic um and
49:45 - we're just going to focus on some score
49:48 - some test scores for those students
49:50 - so the scores are for a math test
49:54 - and then a portuguese test and
49:58 - there are numbers after them so there's
50:00 - a math one math two math three
50:02 - port one port two part three in this
50:04 - data set and these are like
50:06 - semesters of the school year i think so
50:08 - it's like
50:10 - their math ones their math one value
50:13 - is their score on the math test after
50:15 - their first semester
50:17 - then sec after their second semester and
50:19 - then this is like at the end of the year
50:23 - i believe so
50:28 - we've got this picture here and i'm
50:30 - actually gonna switch
50:34 - switch back to
50:41 - my picture for
50:45 - a second my ipad
50:50 - one second um but what i what we're
50:53 - looking at here
50:54 - is we're saying okay what if we try to
50:56 - predict
50:58 - someone's final portuguese score
51:01 - based off of their initial math score
51:05 - and we see there's a relationship like
51:07 - maybe this is just
51:09 - students who are better at studying they
51:11 - can do better on both
51:12 - math and portuguese and so um
51:15 - it looks like people who have higher
51:17 - math scores are
51:18 - tending to do better on their portuguese
51:20 - tests and people with lower mass scores
51:22 - are tending to a little worse on the
51:23 - portuguese test
51:24 - there does appear to be some
51:26 - relationship here um and then we're
51:28 - coloring
51:29 - this by portuguese score in the first
51:32 - semester
51:33 - so that's this port one right and so we
51:36 - see
51:36 - darker colors are higher portuguese
51:40 - scores in the first semester
51:41 - and lighter colors are lower portuguese
51:43 - scores in the first semester
51:46 - and this is almost the same thing as
51:48 - what we were looking
51:49 - at before but now this portuguese
51:54 - or this port one score is no longer a
51:58 - categorical variable it's a continuous
52:01 - or in
52:02 - this case it's like a um
52:05 - discrete quantitative variable but we
52:08 - can think of it as a continuous variable
52:10 - um but basically it's a number
52:14 - it's not a category so we can do the
52:18 - exact same thing
52:19 - but it's gonna look a little bit
52:21 - different so i'm gonna show you guys
52:24 - um i'm gonna show you guys on my ipod
52:27 - again
52:28 - what that looks like
52:32 - okay
52:38 - okay can everyone see this
52:42 - yes hopefully okay um okay so here
52:46 - is another model where we have port
52:49 - three as a function of predictors math1
52:53 - and port one
53:00 - right and then we can fit a model
53:04 - just as we did before with two
53:07 - predictors
53:08 - by putting this model formula into our
53:12 - sm sm.ols
53:14 - dot from formula function i'll demo that
53:16 - in a second when we come back
53:18 - and in this but in this picture right
53:21 - we've got
53:22 - two quantitative variables instead of
53:24 - having like
53:26 - just ones and zeros for math one
53:29 - we can have any number of values and
53:32 - same thing for port one
53:35 - so i'm gonna do is i'm gonna write this
53:36 - out the same way we did before
53:39 - using my output i'm gonna write the
53:41 - equation
53:42 - of the line so the equation is
53:46 - port 3
53:49 - equals the intercept which is
53:54 - 0.44
53:56 - plus the slope on math 1 is about 0.11
54:01 - so we've got 0.11
54:03 - times math1
54:08 - and then we've got the slope on port one
54:11 - is point eight six
54:13 - we've got point eight six times
54:18 - port one
54:24 - okay now we can think about this
54:28 - for a few different values of port one
54:31 - let's write out what the equation would
54:32 - look like
54:34 - so to start let's try
54:38 - when port one equals zero
54:42 - so when four one equals zero we've got
54:46 - port three
54:49 - equals point four four
54:52 - plus 0.11 times math 1
54:58 - plus 0.86 times 0.
55:02 - and anything times 0 is 0. so this is
55:05 - really just
55:06 - port three
55:09 - port three equals point four four
55:13 - plus point one one times
55:16 - math one
55:21 - when port one equals one
55:25 - we can do something similar but now
55:27 - we've got port three
55:29 - equals point four four plus point one
55:32 - one times math one
55:37 - plus one times point eight side
55:41 - plus point eight six times
55:45 - one and
55:49 - algebraically right
55:53 - it doesn't matter what order we add
55:55 - things in so we've got
55:57 - a point eight six times one
56:00 - and then we've got this 0.44 we can add
56:04 - those together
56:06 - and so we end up with
56:12 - port 3 equals 0.44
56:17 - plus 0.86
56:20 - this whole thing is now our intercept
56:24 - plus 0.11 times math one
56:29 - and you can kind of see how this would
56:31 - continue for port
56:33 - one equals two
56:39 - we have the same thing but now this is
56:42 - going to be a 2
56:44 - this nut 1 here is going to become a 2
56:47 - and so we'll be adding
56:48 - 0.86 times 2 to the intercept so we'll
56:51 - end up with something like
56:52 - port 3 equals 0.44
56:57 - plus point eight six times two
57:02 - that's now the intercept plus
57:05 - point one one times math one um
57:09 - when you're saying like port one equals
57:10 - one and port
57:12 - one equals two like what is the scale
57:14 - for like what two
57:15 - corresponds to like for like the first
57:19 - exam so
57:22 - [Music]
57:24 - port one equals one just means that they
57:28 - scored a one
57:29 - on their first portuguese okay
57:32 - those would go all the way up to like a
57:34 - hundred um i think actually
57:36 - they're like goes up to zero
57:41 - just based off of the graph it looks
57:43 - like the scores are roughly between 0
57:45 - and 10.
57:46 - um but yeah so it's whatever
57:50 - whatever the um
57:54 - the scale is in the original data
57:57 - and what's happening here is the
58:00 - intercept
58:01 - is just increasing every time
58:05 - so as port 1 increases we get a higher
58:08 - intercept
58:09 - and what that means for our picture is
58:16 - as port 1 increases we would draw
58:20 - a slightly higher line and there's
58:23 - infinitely many lines that could be in
58:26 - here because port one
58:27 - could be infinitely many values i mean
58:30 - in reality it's really probably just
58:33 - 0.51 1.5 to
58:36 - 2.5 etc but like theoretically with
58:39 - another quantitative predictor it could
58:41 - be any value
58:43 - right and it makes sense right we see
58:46 - that like
58:46 - these darker points are higher up so
58:49 - like
58:50 - at the top where port 1 equals 12 we've
58:53 - got like these
58:54 - darker blue points and so we would draw
58:57 - the line up here and for the lighter
58:59 - points we would draw a line down here
59:01 - they should all have the same slope but
59:03 - we're just thinking like
59:05 - as port one increases the intercept of
59:08 - our line
59:09 - is going to increase the line is going
59:10 - to move up um
59:12 - but the slope will stay the same
59:15 - okay we are just about at time
59:20 - so i'm gonna stop it there um
59:23 - but i hope that today's lesson was
59:26 - helpful in terms of getting a first look
59:27 - at what we're
59:29 - what we're thinking about when we run a
59:31 - regression with multiple predictors
59:33 - um and if you want to learn more and
59:35 - think a little bit more deeply about
59:36 - this
59:37 - i highly recommend that you take the
59:39 - linear regression
59:41 - uh in python course on codecademy we've
59:44 - linked out to it
59:45 - in a bunch of places on youtube and on
59:47 - the event pages
59:48 - um and on github i believe as well
59:52 - and there is a whole lesson on multiple
59:55 - linear regression
59:56 - and you can learn even more about it and
59:58 - how to interpret all the coefficients
60:01 - um so that if you're if you're
60:04 - interested in learning more that's a
60:05 - good place
60:07 - and then next week we're going to come
60:09 - back and we're going to
60:10 - investigate some of the math behind how
60:13 - these models are actually
60:15 - fit and it's a little bit it's a little
60:17 - bit technical but it's really important
60:20 - for being able to
60:22 - debug a model in python
60:25 - or even just figure out how to fit the
60:28 - model
60:28 - using some new software or a different
60:31 - package in python
60:33 - understanding a little bit of that
60:34 - matrix math is super super
60:37 - helpful um so
60:40 - hopefully everyone can join us for that
60:43 - uh thank you for all of the questions in
60:46 - the chat today
60:47 - i would love to see even more questions
60:49 - in future sessions the questions are
60:50 - really helpful for helping
60:52 - me figure out like what i need to go
60:54 - over to clarify things
60:57 - but it's awesome to see more people back
61:00 - every week
61:01 - and yeah i really appreciate
61:04 - everyone stopping by i just want a
61:06 - second also to take sophie's
61:09 - like linear regression lessons they're
61:11 - very awesome
61:12 - um and they're like very helpful if you
61:14 - want to learn more about this stuff
61:16 - um so yes definitely like look at those
61:19 - um and thanks for joining us today and
61:21 - thanks for letting me join you today
61:24 - sorry office hours on thursday at the
61:27 - same time
61:27 - 11 a.m eastern time um in the us
61:31 - and we will also uh
61:36 - after this week because not too many
61:37 - people have been showing up so
61:39 - please show up if you'd like to there's
61:41 - if you go to
61:42 - academy.com events you can check out or
61:45 - you can get the link to that
61:47 - um but after this week we'll be on we
61:50 - will be trying out office hours on get
61:53 - on sorry
61:54 - on discord um so if you're interested
61:58 - that could be really cool um there's
62:01 - i've just joined our discord
62:02 - and have discovered there's lots of
62:04 - really good conversation
62:06 - going on on discord so if you'd like to
62:09 - join
62:10 - for that highly recommend okay
62:13 - all right have a good rest