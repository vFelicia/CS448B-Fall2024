00:00 - okay we will be
00:03 - on in just a second cool yeah i think
00:06 - we're good to go
00:08 - yeah yeah let's do it
00:11 - all right well welcome everyone um this
00:14 - is the seventh live stream uh
00:17 - event in our series and we're going to
00:20 - take a break
00:21 - um after this week and then we'll be
00:24 - back in two weeks to kind of walk
00:26 - through a whole
00:27 - almost like a summary of everything
00:29 - we've done so far
00:32 - but for today we are going to talk about
00:35 - comparing linear models so up to this
00:38 - point we've talked about a few different
00:39 - methods for
00:42 - creating a linear model for fitting
00:44 - different kinds of models like
00:46 - a more flexible model by adding a
00:48 - polynomial term or an interaction term
00:51 - um but we haven't really talked yet
00:53 - about how we evaluate whether doing
00:55 - those things
00:57 - actually has like a positive
01:00 - impact on your model enables you to like
01:03 - model the data better make better
01:04 - predictions um any of those things so
01:07 - that's what we're
01:08 - uh going to cover today cool cool
01:11 - um all right so i'm just gonna jump
01:14 - right in
01:16 - uh we've got this um
01:20 - this code was uploaded to our github
01:22 - repository this morning
01:24 - um so if uh
01:28 - if you want to go ahead and run it
01:29 - yourself you can um also yeah i see
01:32 - a couple people saying hello on the chat
01:34 - um we are back with the green screen
01:37 - um but make sure to say hello if you
01:39 - have any questions
01:41 - um ask them in the chat and alex will
01:43 - keep an eye i'll also try to keep an eye
01:45 - so um we can we can make sure that we
01:47 - cover any of your questions as well yeah
01:49 - and i see a lot of people watching on
01:51 - twitter right now and so
01:53 - um we are mostly interacting with the
01:55 - the youtube chat uh so if you're over on
01:56 - twitter
01:57 - and are just kind of like randomly
01:59 - seeing this we have a lot of these
02:00 - sessions
02:01 - on um on youtube and so if you go and
02:03 - find codecadmin on youtube you'll be
02:05 - able to find
02:05 - all these sessions and really kind of be
02:07 - able to watch live and
02:09 - talk with us there exactly cool awesome
02:13 - um cool so we'll jump right in uh
02:16 - this week we're going to be working with
02:18 - this bike's data set
02:20 - i actually i got this from the uci
02:22 - machine learning repository
02:24 - this is a um a resource that we've used
02:26 - for a lot of
02:27 - codecademy projects and lessons um and
02:31 - also just
02:31 - for anyone i say just for anyone who's
02:34 - looking for good data sets to practice
02:36 - with
02:37 - this is a really great place to take a
02:39 - look because
02:40 - they've got a good mix of different
02:43 - types of things
02:45 - and different levels of cleaning so you
02:48 - can start
02:49 - anywhere and and get a good data set to
02:53 - kind of practice your skills um
02:56 - so this one it's a a data set about bike
02:59 - share
03:00 - a bike share um and i don't know we can
03:03 - read through
03:04 - a little bit but basically um
03:07 - there's some information about um
03:11 - the the date the season the year
03:14 - whether or not it's a holiday what day
03:16 - of the week it is what the weather
03:18 - looked like the temperature humidity
03:20 - wind speed
03:22 - um and then kind of the thing that
03:23 - you're trying to predict
03:25 - is this count bear variable which is the
03:27 - number of total rental bikes that
03:29 - were um that were rented
03:33 - and so you could imagine like this is
03:34 - the kind of thing that if you worked for
03:36 - this bike share company
03:37 - you might want to be able to predict
03:39 - like how many bikes are going to be
03:40 - rented on a particular day given all
03:42 - this information
03:43 - and so um one knowing how each of these
03:47 - predictors are related
03:49 - to the number of bikes that are rented
03:52 - is useful and then also being able to
03:54 - get accurate predictions
03:55 - is useful so that you know how many
03:56 - bikes to have at each of the stations
04:00 - so yeah so that's what we're gonna kind
04:02 - of work with
04:04 - and i think i'm gonna load this
04:07 - up run run
04:12 - okay so um
04:16 - we're gonna start with a couple of
04:19 - different models
04:20 - actually i'll delete this um and i
04:23 - actually saw
04:24 - a question on one of our earlier live
04:27 - streams this
04:28 - past week about r squared and so i think
04:31 - a good place to start
04:33 - for in terms of evaluating a model is r
04:37 - squared it's
04:38 - probably the most typical thing that you
04:40 - learn first when you take
04:42 - a a course in linear regression and
04:45 - i have this written now but i'm gonna
04:48 - just
04:48 - delete this for a minute um
04:51 - and i'm gonna fit two models here we've
04:55 - got
04:55 - model one which predicts the count
04:58 - variable based on
04:59 - temperature wind speed and holiday
05:03 - whether or not it's a holiday and then
05:04 - i've got another model that
05:06 - predicts based off of humidity the
05:09 - season
05:10 - and the day of the week i was using a
05:13 - bike chair yesterday and it was very
05:15 - humid and
05:16 - boy is that a predictor oh my god i yeah
05:20 - i i walked to work this morning and it
05:22 - was not fun
05:25 - i will tell you that much um and then
05:27 - let's say
05:28 - just to start i want to print out i'm
05:31 - just going to print the whole model one
05:34 - summary we'll print just model one
05:37 - summary to start and then we'll take a
05:38 - look at the other one
05:39 - um well it says some of these so i've
05:42 - been here for some of these sessions and
05:43 - not here for some of these sessions and
05:44 - so
05:45 - this one where you where we have a mix
05:47 - of
05:48 - categorical uh is weekday a categorical
05:51 - variable or is that a binary
05:52 - i actually think weekday is a um
05:56 - is not we can check yeah so if you look
05:58 - at the output you can usually
06:00 - tell um actually let's look at model 2
06:03 - summary
06:04 - but um it looks like
06:08 - season is categorical right because
06:10 - we're getting this like um
06:12 - true spring true summer true winter and
06:15 - then
06:16 - um fall must be the reference category
06:19 - for this
06:20 - right um but then it looks like humidity
06:22 - on weekday we just have one
06:24 - um one slope
06:27 - i'm pretty sure weekday actually we can
06:29 - print out
06:30 - the initial you can just like print out
06:33 - the
06:36 - like stop head just take a look yeah
06:40 - that's cool seeing that uh that season
06:42 - because that was something that we did
06:43 - in an earlier session of um
06:46 - kind of figuring out what the reference
06:47 - variable is um learning how to use these
06:49 - categorical categorical variables what
06:50 - was that that was like week
06:52 - four or five or something yeah it was a
06:53 - couple weeks ago
06:55 - um yeah exactly so it it all comes back
06:58 - to
06:59 - the same same topic that we've been
07:01 - talking about this whole time
07:02 - but um but yeah so we can see actually
07:05 - weekday
07:06 - it looks like is a number from zero to
07:10 - six
07:11 - is is my guess because i see at least
07:12 - one instance of zero and one instance of
07:14 - six
07:15 - and i assume we're talking about a seven
07:17 - day week cool
07:18 - um yes so so we've got
07:21 - one um and we've got one
07:24 - slope um okay
07:28 - so i see a question in the chat about
07:31 - comparing models using information
07:32 - criteria like bic and aic
07:34 - we're going to get to that as well but i
07:37 - just think it's useful
07:38 - for this first pass
07:42 - to see that you can get this
07:45 - model summary which gives you a whole
07:47 - bunch of information
07:48 - and actually it gives you a lot of the
07:51 - things we're going to discuss
07:52 - today it gives you an r squared value
07:56 - it gives you an adjusted r squared we'll
07:58 - talk about that in a minute
08:00 - um it also gives you this f statistic
08:04 - and um prob f statistic which is
08:07 - this is a p value um and i'll i'll talk
08:10 - a little bit about what this means in
08:12 - a minute but basically this is comparing
08:17 - um this is i believe a comparison to a
08:20 - model
08:20 - where you have no predictors so you're
08:23 - just taking like
08:24 - you're basically making your prediction
08:26 - based on the average
08:27 - um count of bikes that are
08:30 - rented um in a given day and you're
08:34 - saying
08:34 - is this model better than just taking
08:37 - the average
08:38 - and because this p value is very small
08:41 - this like e to the minus 75 means
08:43 - point like set point zero zero zero zero
08:46 - like 75 zeros and then five two so we're
08:49 - like very very
08:50 - much below any threshold you might set
08:52 - for a p-value
08:54 - so this is like saying that this model
08:56 - is statistically significantly better
08:58 - than just taking the average count which
09:00 - we probably
09:01 - expect um and then we've got log
09:04 - likelihood we'll talk about that today
09:06 - we've got aic and bic which we will also
09:08 - talk about today
09:10 - and so yeah if you use stats models one
09:13 - of the nice things is you get
09:15 - all this information right off the bat
09:18 - for your model
09:19 - that gives you some diagnostics then
09:21 - think about like
09:22 - um how well your model is fitting your
09:25 - data
09:25 - cool um so the r squared
09:29 - um r squared is generally interpreted
09:32 - as the proportion of variance in the
09:36 - outcome
09:37 - variable that is described by
09:40 - this model um so
09:43 - i think actually i should pull up the
09:46 - like
09:47 - we can pull up the r squared
09:50 - formula um
09:53 - right so r squared is one minus
09:57 - the residual sum of squares over the
10:00 - total sum of squares
10:02 - um and i can show really quickly
10:04 - residual sum of squares
10:06 - versus total sum of squares so total sum
10:09 - of squares i believe
10:10 - is just like the total sum difference if
10:13 - you just drew a line
10:15 - at if you drew that regression line
10:17 - where it's just a straight line across
10:19 - at the average
10:21 - um total sum of squares is how far
10:24 - off all the points are um and then
10:28 - well basically a measure of how far off
10:30 - the points are
10:31 - and then residual sum of squares is
10:35 - the sum of the squared residuals um
10:39 - and residuals being how far each point
10:41 - is from the prediction
10:43 - okay so basically we want that number to
10:45 - be so we want r squared
10:47 - to be big right so we want this
10:50 - residuals over total to be a small
10:52 - number
10:52 - and that will be a small number if uh
10:56 - the residuals number is small or if the
10:59 - total sum squared
11:00 - is super big and residuals at least
11:03 - do okay right okay yeah
11:06 - so so r squared basically
11:10 - a measure of the proportion of variation
11:12 - in the data that is
11:13 - explained by the model and if you
11:16 - can explain more variation in the
11:18 - outcome variable
11:20 - then you're doing a better job with your
11:21 - model so
11:23 - um so now let's go back
11:26 - we can print just the r
11:30 - squared for each of these models and
11:32 - compare them
11:34 - and so we see um and i'm just pulling
11:36 - out the r
11:37 - squared by doing like model dot r
11:40 - squared
11:41 - um and we see that the first model with
11:44 - temperature wind speed on holiday
11:47 - is doing a little better we're getting
11:49 - like about 41
11:51 - 42 of the variation in the outcome
11:54 - variable which is count
11:56 - um or cnt of bikes that are rented
12:00 - is slightly higher it's about 42 percent
12:02 - of that variation
12:03 - here and then in our second model
12:06 - we're only explaining about 39 of the
12:09 - variation
12:10 - which i mean i guess makes sense like
12:13 - you we kind of think
12:14 - probably the temperature the wind speed
12:17 - and whether or not it's a holiday
12:19 - i would imagine is better than is our
12:22 - better predictors as a group
12:24 - than humidity season and weekday
12:27 - probably humidity and season are pretty
12:29 - correlated
12:31 - um and then i don't know
12:34 - weekday i imagine that the biggest
12:37 - difference in terms of weekday is just
12:39 - um time like well i was i would say like
12:43 - friday saturday sunday versus the rest
12:45 - right
12:46 - so do you think when you say humidity
12:48 - and season are highly correlated
12:50 - um that makes sense oh in the summer
12:51 - it's going to be more humid than in the
12:53 - winter probably
12:54 - so is your kind of intuition there like
12:57 - oh we don't really need
12:58 - both of them or like we could just use
13:00 - one of them would that be something that
13:01 - you would
13:02 - do is there a downside for using both
13:05 - well let's
13:05 - let's take a look so with both of them
13:08 - in the model
13:09 - um our r squared is about
13:13 - .388 what if we take
13:17 - season out of this model um
13:24 - so actually the r squared dropped by a
13:29 - lot that was actually
13:30 - way more than i was expecting yeah
13:33 - wow and what if we reverse it so if we
13:35 - maybe humidity is contributing like
13:37 - nothing
13:40 - wow apparently humidity is not
13:45 - super useful so this is obviously
13:48 - something you can do
13:50 - you can test different you can have test
13:53 - different predictors
13:54 - you could put all the predictors
13:56 - together so let's say
13:58 - you know we could test all of these in
14:02 - one model
14:03 - and then we could say okay what about
14:06 - all of these in a model
14:08 - and then let's also add
14:14 - humidity
14:16 - interesting so this is also this is one
14:20 - of those things where
14:22 - it the um the relationships between all
14:27 - of these predictors matter
14:29 - so maybe if you know the temperature
14:32 - then humidity is important
14:34 - but if you don't know the temperature
14:35 - then humidity is not important
14:37 - got it i don't know maybe maybe we
14:40 - really want
14:41 - a interaction between temperature and
14:44 - humidity
14:45 - i'm just guessing um
14:48 - does that improve it didn't go up very
14:51 - much
14:51 - about the same um so you get the sense
14:54 - right that you can
14:55 - continue to you can
14:59 - can continue to add more and more to
15:01 - this model
15:02 - and see whether it improves the r
15:04 - squared significantly
15:06 - um and you know you can make decisions
15:09 - about how much addition to the r squared
15:11 - is really meaningful
15:13 - um and then maybe you think if it just
15:16 - goes up by .001
15:18 - maybe you don't care um
15:21 - okay guys don't make fun of my voice
15:24 - this is kind of rude in the chat right
15:26 - here
15:27 - you know we all we all have uh
15:31 - days when our voice sounds better than
15:33 - others
15:34 - um okay i'll i'll do my best not to
15:37 - get into the croaking
15:45 - all right it's fine um
15:48 - okay so let's um
15:52 - let's see let's like take an example and
15:54 - see
15:55 - how much we can how much complexity we
15:57 - can add
15:58 - to a model before
16:01 - things start to break down because one
16:04 - of the issues that happens
16:05 - is if if you're fitting uh
16:08 - if you're fitting a model and you add
16:10 - more complexity
16:11 - for each additional term that you add
16:15 - you are going to explain
16:18 - your data the variance in your data a
16:21 - little bit
16:22 - better um so actually what happens and
16:25 - i i think maybe if i go back to this and
16:28 - i just
16:29 - take this model exact same model but
16:33 - without the interaction term
16:36 - right and i just compare these two
16:38 - models they're exactly the same
16:40 - except the first one doesn't have an
16:42 - interaction term between temperature and
16:44 - humidity and the second one does
16:46 - and i run them we see okay
16:49 - so my r squared was like 0.54098
16:56 - and then it went up to 0.54100
17:00 - okay so this interaction term
17:04 - increase the r squared very slightly
17:07 - but does that really warrant having a
17:10 - more complicated model
17:12 - um not necessarily and one of the things
17:16 - you're gonna find
17:17 - is that actually it's impossible for the
17:20 - r-squared to go down
17:21 - if you add more complexity to the model
17:25 - these are what are called
17:28 - nested models which means that this
17:32 - this model is nested inside this one
17:36 - right like this bigger model contains
17:38 - all of the same
17:39 - predictors as the smaller one plus
17:42 - one additional and it would still be
17:44 - nested if i added even more like
17:46 - i could add numpy that power
17:49 - like i could add a polynomial term for
17:52 - temperature right
17:56 - and i could run it again oop that
17:57 - actually improved the model
17:59 - a bit more but these are still
18:02 - considered nested models because the
18:04 - smaller one contains all the same
18:05 - predictors
18:06 - and it turns out that the larger of two
18:10 - nested models will
18:11 - always have a higher r squared because
18:13 - you're always going to be explaining
18:14 - at least a little bit more variation in
18:17 - the outcome variable
18:19 - but now we're going to talk about why
18:20 - that's not always useful
18:23 - um okay so
18:26 - i'm just checking the chat for questions
18:30 - um would the type of encoding of the
18:33 - categorical variables affect the
18:35 - accuracy
18:36 - for example one hot encoding versus
18:38 - integer encoding
18:40 - that is a great question um i think
18:43 - that is a question that i would turn to
18:46 - um i would turn to some
18:50 - like exploratory data analysis to try to
18:53 - answer
18:54 - so for example we can just do this
18:56 - really quickly
18:58 - um i think if i can remember
19:01 - sns box plot if i do
19:04 - like um the
19:11 - weekday
19:15 - and y is count
19:18 - and um the data is spikes
19:23 - i think you want cnt not count oh right
19:25 - yeah
19:26 - i like said it out loud and then typed
19:28 - exactly okay
19:30 - so um so this is one where
19:33 - i would probably just look at this
19:36 - picture
19:37 - first of all i don't know what weekday
19:39 - equals zero means
19:41 - like i don't know which day of the week
19:42 - is zero probably it could be sunday
19:44 - could be monday
19:45 - um but i would look and i would
19:49 - take a look at something like this and i
19:50 - would say okay
19:53 - is there some sort of linear
19:55 - relationship like is it
19:56 - is it just going up throughout the
19:58 - weekday sorry
20:00 - um you could also look at a scatter plot
20:03 - it might be less useful because it's
20:06 - just going to be
20:07 - well anyway we we would
20:10 - take a look at this and see okay like is
20:12 - this something that we
20:14 - think we want to represent with a line
20:16 - based on looking at this it looks like
20:18 - the
20:18 - median number of bikes that are rented
20:23 - is roughly the same every day of the
20:25 - week
20:26 - maybe it goes up and then goes down a
20:29 - little bit
20:30 - so in this case i think it doesn't look
20:34 - like weekday is honestly the best
20:36 - predictor to put in this model but what
20:39 - i was hoping i could show you is
20:40 - something where like
20:42 - let's say you saw that for saturday and
20:44 - sunday it was
20:46 - a lot higher like the rental there were
20:48 - way more rentals on saturday and sunday
20:50 - than they were on other days of the week
20:52 - then maybe you would want to one hot in
20:55 - code and just say like
20:57 - just have weekend and weekday versus
21:00 - weekday
21:01 - um and if you saw that like there was
21:04 - some order of these where it
21:05 - looks like it's you could fit a line to
21:07 - it like it looks like it's just steadily
21:09 - increasing throughout the week
21:11 - then maybe it makes sense to leave it as
21:13 - zero one two three four five six um
21:16 - if it's not a good predictor at all then
21:19 - um
21:20 - then it's not a good predictor
21:23 - um cool
21:27 - all right hopefully that helps answer
21:28 - the question yes this is a
21:31 - jupiter notebook okay
21:34 - so this is actually a kind of a common
21:39 - demo that people
21:42 - use to demonstrate overfitting so and
21:46 - the reason it's
21:46 - it's kind of nice is because you can
21:48 - visualize the overfitting happening in a
21:51 - single plot
21:52 - so now what we're gonna do is we're
21:54 - gonna we're gonna take a bunch
21:56 - of models and the mod the only thing
21:58 - that we're going to change about the
21:59 - models is we're going to add more
22:00 - polynomial terms to higher powers
22:03 - and we're going to see and try to
22:04 - visualize what happens to the model
22:06 - right and the thinking here is kind of
22:08 - doing what we just did of like oh look
22:09 - the more of this that we add the
22:11 - higher that number goes which is which
22:13 - is better and so we're going to see that
22:15 - this is not necessarily the case if we
22:16 - just keep
22:17 - adding more and more and more um
22:18 - polynomial terms exactly
22:22 - okay so here is a scatter plot
22:25 - of
22:28 - of temperature on the x-axis
22:32 - and count of rentals
22:35 - on the y-axis and actually we see this
22:38 - relationship
22:39 - i'm i guess yeah sometimes it can be
22:42 - negative temperature i guess
22:43 - um so we do see this positive
22:46 - relationship but actually
22:47 - if i were to draw a line through this i
22:50 - would say it probably increases
22:52 - and then it starts decreasing which
22:55 - maybe makes sense right because as the
22:57 - weather gets nicer
22:58 - people are more likely to rent bikes and
23:00 - then
23:01 - it gets really hot and then you're like
23:04 - if it's over
23:05 - 90 degrees out which i don't know what
23:07 - that equates to
23:08 - in centigrade which is bad um but
23:11 - basically
23:11 - you know at a certain point it gets too
23:14 - hot and all of a sudden
23:15 - fewer people are going to rent bikes
23:17 - because they just don't want to be
23:18 - outside anymore
23:20 - um so okay maybe a
23:23 - just a line is not going to be the best
23:26 - here
23:26 - but let's let's fit a line and at least
23:28 - see what it looks like
23:30 - so here is
23:34 - my plot where
23:37 - i fit a line to this this model
23:41 - um and so right my
23:44 - model formula is just
23:47 - count um predicted by temperature
23:50 - so i have one predictor temperature to
23:53 - predict
23:54 - the number of bikes um and then this is
23:57 - just some code
23:59 - to create that line
24:02 - i'm just creating a list of numbers
24:04 - between the minimum
24:06 - temperature and the maximum temperature
24:08 - that number list of numbers
24:10 - contains 100 values and then i'm getting
24:13 - the predicted
24:14 - number of bike rentals based on this
24:16 - model for all of those values
24:18 - and then just plotting them down here um
24:21 - you guys have seen this
24:22 - a few times if you have tuned in to some
24:25 - of the other
24:26 - um the other sessions and so when we
24:30 - plot all of this
24:31 - we end up with this regression line
24:33 - which
24:34 - is what we expected right if we just fit
24:36 - a line we can't model that curve
24:40 - okay so let's say that we did a little
24:43 - bit of research
24:44 - beforehand um thank you
24:47 - um we did a little bit of research
24:49 - beforehand a little bit of exploratory
24:51 - analysis we saw
24:52 - that this relationship look this
24:55 - relationship looks kind of curved
24:57 - and so we think okay like we'll add a
25:00 - polynomial term
25:01 - to this model that might do a better job
25:03 - of fitting the data
25:06 - okay so here we are here's the model
25:09 - where we fit a polynomial term
25:14 - a squared polynomial term so we're
25:15 - taking
25:17 - count as a function of temperature and
25:20 - temperature squared
25:21 - in our model okay
25:24 - so r squared uh this is not
25:28 - uh what was the first one was just it
25:30 - was just count and temperature
25:32 - so this is so that was a subset of this
25:34 - one so this r squared value
25:36 - is guaranteed to be higher than the
25:37 - first one right it is and after we look
25:39 - at all these pictures we'll print out
25:41 - all the
25:41 - r squareds of all of the models so we
25:43 - can see what's happening
25:44 - okay cool okay so we add
25:47 - this square term
25:49 - [Music]
25:51 - make the same plot and now we see we're
25:53 - able to model
25:54 - this curve a little bit it goes up
25:57 - and then it kind of levels off maybe
26:00 - goes down a little bit
26:01 - at the very end okay
26:05 - that maybe is a little bit better i
26:07 - would expect that that would
26:08 - improve the r squared somewhat
26:12 - meaningfully we saw it actually before
26:13 - when we
26:14 - added that squared term the the um r
26:17 - squared even in the bigger model that r
26:19 - squared went up a bit
26:20 - so we know that that that probably helps
26:24 - okay now let's add
26:27 - temperature cubed to our model
26:32 - and run it and now we've got
26:37 - a little bit more um
26:40 - a little bit more curve to this like it
26:42 - looks like it it starts out a little bit
26:44 - flatter
26:45 - gets steeper and then um
26:49 - and then at a certain point it curves
26:50 - down even more than it did in the first
26:53 - example so i'll just i'll go back really
26:56 - fast
26:57 - so we've got that versus this
27:02 - i mean maybe better not necessarily
27:08 - terrible yeah that drop off at the end
27:10 - maybe looks a little bit better
27:11 - if it drops off quicker yeah not
27:14 - not too bad okay
27:18 - we're gonna continue here i'm gonna add
27:20 - two at a time we're gonna like pick this
27:22 - up a little bit
27:23 - let's add all the way up to five
27:26 - um a power of five so now we've got
27:30 - squared temperature plus temperature
27:32 - squared plus temperature
27:33 - cubed plus 10 plus temperature to the
27:35 - fourth plus temperature to the fifth
27:39 - all in our model let's run it
27:43 - okay
27:47 - oh i didn't get to that one yet i
27:49 - spoiled it i
27:50 - almost spoiled it okay this one doesn't
27:53 - really look any different
27:54 - from the one above it right like
27:58 - sorry i would guess that the r squared
27:59 - is like almost identical into the one
28:02 - above it yeah so model four
28:06 - compared to model three
28:09 - doesn't look that different maybe it's
28:10 - like a little bit more we've got like
28:13 - even more of a flattening here like it
28:16 - looks like this is more
28:19 - oh you can't see my um you can't see my
28:22 - cursor but basically
28:24 - maybe on the left side of this plot it
28:26 - looks a little bit
28:28 - more curved for the five
28:31 - um fifth power one but it's not super
28:33 - different
28:35 - and then i spoiled it but jumping ahead
28:39 - to this one i think has ten
28:42 - in here so we go all the way up to a
28:44 - power of 10
28:46 - in this model now we get
28:50 - this and this is kind of the
28:53 - epitome of over overfitting
28:58 - um so what's happening here is that
29:02 - we're allowing as much cur we're
29:04 - basically allowing as much curve in this
29:06 - line as we want we're allowing the
29:08 - the line to go up and down like five
29:11 - times
29:12 - and so we see those bumps right like we
29:14 - see
29:15 - i wish you could see my cursor but you
29:17 - see the the first bump on the left
29:19 - another bump another bump
29:21 - another bump and another one um and
29:24 - and each of those little bumps in the
29:27 - line
29:28 - are really responding to very localized
29:32 - um anomalies so it might be just a
29:34 - couple of points that are
29:36 - that are causing that line to go up a
29:39 - little bit um because
29:40 - we're we're just allowing so much
29:44 - flexibility
29:45 - to fit this exact data that we're not
29:48 - really
29:49 - like thinking about well what is what is
29:51 - the actual relationship between this
29:53 - like what
29:54 - what proportion of these data points
29:56 - represent like some sort of random
29:58 - chance that
29:59 - we we see a relationship but like
30:02 - something could be a little higher a
30:04 - little bit lower by random chance on a
30:06 - particular day
30:07 - and we don't necessarily want to fit
30:09 - like exactly to
30:10 - all of those little anomalies
30:14 - right so like maybe that this uh and
30:16 - again we can't see the pointer but that
30:18 - third dot on the left the one that's a
30:19 - little bit higher
30:21 - at you know like 20 200 and negative
30:24 - two um so that's kind of a random single
30:28 - day it's an outlier but that single
30:29 - point is probably doing
30:31 - is what's causing that point to or the
30:33 - line to be
30:34 - kind of pulled up and then back down and
30:36 - so the idea is that
30:38 - that's great for this data set this this
30:40 - line is better for this data set where
30:42 - this line describes that
30:43 - data better but now if we start to think
30:45 - about okay
30:46 - i just have a new day it's a new random
30:49 - day do we really want that single data
30:51 - point from that one day
30:52 - really kind of shaping what this line is
30:55 - and future predictions
30:56 - yeah exactly and i think the answer
30:59 - is probably no if we're trying to build
31:01 - a predictive model
31:03 - and we're trying to make predictions for
31:05 - the future
31:06 - we don't want like one or two random
31:09 - fluke
31:10 - days where it happened to be a really
31:12 - high
31:14 - high rental day or low rental day just
31:16 - by random chance or whatever there was
31:18 - an event that day
31:19 - we don't want to take that into an
31:21 - account in our model
31:22 - when really we're just trying to model
31:24 - though
31:26 - we're trying to make predictions based
31:27 - on like the overall trend
31:30 - i mean
31:37 - i'll drink some water too um
31:41 - okay so here we go
31:44 - we've got this we've seen that there's
31:46 - this overfitting problem
31:48 - and now let's take a look at the
31:50 - r-squared values and see if they match
31:52 - up to
31:53 - our expectation based off of what we saw
31:56 - in the picture
31:57 - so remember that i named these kind of
32:01 - stupidly but
32:02 - remember that model 5 has all 10
32:05 - powers in it um from no from just like
32:08 - temperature
32:09 - all the way up to temperature to the
32:10 - 10th power and then
32:13 - model four was the one that just has up
32:16 - to five powers
32:18 - and then three has up to the third power
32:21 - two
32:21 - has up to the second power and one
32:23 - doesn't have is just straight linear
32:25 - um and so down here let's print out
32:29 - i think i've already run this but we'll
32:31 - print out the
32:32 - um the r squareds for all of these
32:34 - models
32:35 - and we can see okay so the first one we
32:38 - had about .39
32:40 - then by adding the square term we go up
32:42 - to 0.45
32:44 - so it's up like six we're explaining six
32:46 - percent more of the variation
32:48 - in the outcome variable that's pretty
32:50 - good
32:51 - um we add a cubed term and it maybe
32:54 - helps a little bit we're up from like
32:56 - it increases this by 0.01
33:00 - um so about one percent more variation
33:04 - then we go up from like from
33:07 - having just the cube term to having the
33:10 - turn the temperature to the fourth and
33:12 - temperature to the fifth so we added two
33:14 - more terms
33:15 - this is just going up to 0.4628
33:18 - instead of 0.4626 so it's going up by
33:22 - point .0002
33:25 - um and remember those were the two
33:27 - pictures where we said they looked
33:29 - basically the same it was this one
33:31 - and this one and so visually we're
33:34 - seeing right it's not
33:36 - it's not getting that much better um
33:39 - and then numerically we're seeing we're
33:40 - not doing that much better of a job of
33:43 - fitting the data
33:46 - now i think probably like and you might
33:48 - you might be about to get to this but i
33:49 - think a common question is like how do i
33:51 - know when to stop them like we can look
33:53 - at the pictures and and see that oh yeah
33:55 - this
33:55 - this fifth one certainly looks very bad
33:58 - but if i'm
33:59 - plotting something more complicated if
34:00 - there are more variables and i can't
34:02 - plot it in two dimensions like how do i
34:03 - know
34:04 - when you know adding that second term
34:07 - sure seems like a good idea but uh like
34:10 - was the third term a bad idea because it
34:12 - didn't do that much or was it not like
34:14 - how do you decide
34:15 - um yeah enough is enough that is a great
34:18 - question um
34:20 - so there are a few things
34:23 - first of all um there are a bunch of
34:26 - methods which we're going to talk about
34:27 - in a minute
34:28 - that introduce some sort of penalty for
34:31 - increased complexity so every time you
34:34 - add another term to
34:36 - your model you're adding more complexity
34:38 - to the model
34:39 - and so you can just like basically take
34:43 - r squared and then subtract
34:46 - some number times the number of
34:48 - predictors and say like
34:49 - for every additional predictor i want to
34:52 - i want to
34:53 - penalize this number so that
34:56 - got it we can so that there's some sort
34:59 - of
35:00 - pull and push here like it if we don't
35:04 - do that
35:05 - then we're always going to see these
35:06 - numbers increasing by adding more
35:08 - complexity
35:09 - so let's like add something else that
35:10 - says like
35:12 - wait actually if you add complexity then
35:15 - like
35:16 - if it only goes up 0.1 for that
35:19 - complexity but we
35:20 - subtract out point two for each added
35:24 - term
35:24 - then um then it'll actually go down
35:28 - um so we can see that that's basically
35:31 - what
35:31 - adjusted r squared is it just adds a
35:34 - penalty for each additional predictor
35:36 - which means that if something increases
35:40 - if this r squared is only a little bit
35:43 - better but we
35:44 - had to add a lot more terms to get there
35:46 - then
35:47 - um the adjusted r squared will go down
35:50 - um and so we can print out the adjusted
35:52 - r squared
35:54 - this way um just r squared underscore
35:57 - adj
35:58 - for justin and actually you will see
36:02 - something interesting here so
36:04 - um remember in this
36:07 - first example the r squared went up um
36:11 - for the first three models and then it
36:12 - went up just a little bit
36:14 - and then it went up another percentage
36:16 - point or so
36:18 - here it's going up up up
36:22 - then it goes down so
36:25 - when we add the term to the fourth and
36:28 - the term to the fifth
36:30 - the r squared actually goes down um it
36:33 - only goes down by
36:34 - a little bit so we're not adding a huge
36:36 - penalty here
36:38 - for those two extra terms but at least
36:40 - it goes down
36:42 - um but actually it does go back up
36:45 - um when we add to its highest value
36:49 - when we add all of those terms so
36:54 - you know this is one of those things
36:56 - where you might have to
36:59 - you might have to decide what you're
37:00 - comfortable with yourself like
37:03 - if that term that model with the squared
37:06 - term gets you to .45 and by adding
37:10 - eight other eight other terms you are
37:13 - only getting up to 0.46 maybe you just
37:17 - decide
37:18 - i'm not comfortable with that that seems
37:20 - like too much complexity it's also
37:22 - it also makes the model a lot harder to
37:24 - explain to somebody else
37:26 - obviously when we're just using
37:27 - temperature um
37:29 - it's a little bit easier to explain but
37:31 - you could imagine instead of adding
37:33 - squared terms and cubed terms in
37:35 - terms of the fourth etc you could be
37:37 - adding different predictors into your
37:39 - model
37:39 - and once you have 100 predictors in your
37:42 - model
37:42 - if you have a really big data set and
37:45 - then somebody has to app
37:46 - and then let's say like you're
37:48 - presenting this to your boss and you're
37:49 - saying like okay i have this model to
37:51 - predict
37:52 - how many people are gonna rent bikes on
37:54 - this day
37:55 - um and you're and your boss says
37:59 - like oh like how does the how is the
38:01 - model working
38:02 - like what what are the predictors that
38:04 - are most
38:05 - um that are most predictive of this
38:08 - outcome because like maybe some of those
38:10 - things we can control and so
38:12 - we want to know like if um if we only
38:14 - put out the blue bikes instead of the
38:16 - red bikes like just that
38:18 - um does that change the the number of
38:21 - p or that does that change our
38:23 - prediction like we want to understand it
38:25 - or also even from a perspective of like
38:28 - bias
38:28 - a lot of um for example i've seen this
38:31 - in
38:33 - um papers i've read about like you know
38:35 - like
38:36 - models that they're using in police
38:38 - departments or um jails to predict like
38:40 - recidivism
38:41 - in order which basically means like how
38:43 - likely somebody is
38:45 - to commit a crime again and so
38:48 - they are using these like black box
38:50 - models and just throwing all the data
38:52 - they have into the model
38:53 - they don't really know how the model is
38:55 - making a prediction
38:57 - and so if your data is biased in some
39:00 - way
39:00 - that can creep into the predict the
39:03 - method
39:04 - that the model is using to make that
39:05 - prediction even if
39:08 - you know that's not if the data wasn't
39:12 - biased in the first place
39:13 - this is not the best predictive model
39:15 - and so
39:17 - you won't necessarily if you if you use
39:19 - a black box model or you just create a
39:21 - super complicated model and you just
39:22 - dump all your data
39:24 - in um you might get into a situation
39:26 - where
39:29 - your computer is biased and you don't
39:30 - know and that's
39:32 - that creates an issue of fairness in
39:36 - in many different fields many different
39:38 - industries
39:41 - so i this is why this is part of why i
39:44 - like
39:44 - linear regression i know linear
39:46 - regression gets a bad rap
39:48 - um but actually you know like i've
39:51 - i've done a number of projects where
39:52 - i've compared like a random forest model
39:54 - to a
39:55 - logistic regression which is a basically
39:57 - another
39:58 - a slight modification of linear
40:01 - regression
40:02 - um and uh you know svm and like
40:06 - a bunch and a naive bayes like fit all
40:08 - the different models and compare
40:10 - them in terms of accuracy and the
40:12 - logistic regression like nine times out
40:13 - of ten
40:15 - does almost as well logistic rate that
40:18 - linear regression
40:19 - well in in that case if you're
40:22 - i mean if you're comparing logistic
40:24 - regression to most other most
40:26 - i feel like most machine learning
40:29 - algorithms are not
40:30 - predicting quantitative outcomes they're
40:32 - predicting like
40:34 - whether somebody will click on a link or
40:42 - it's a basically a linear regression
40:44 - with a transformation
40:46 - applied to it but it's basically the
40:48 - same um and
40:49 - mathematically like we're still making
40:51 - the same assumptions
40:53 - and yeah like it
40:57 - i don't know i like that in linear
40:59 - regression you can print out all the
41:01 - you can print out all the um the
41:03 - coefficients and
41:06 - i don't know i also like tree based
41:08 - models because tree based models you can
41:10 - like
41:10 - you can do a similar thing and they're
41:12 - pretty simple it's like
41:14 - tree logic like if this then go down
41:16 - this branch if this then go down this
41:17 - other branch and
41:19 - that's also easy to explain once you get
41:21 - into neural networks
41:22 - you might like have a really successful
41:25 - model but like
41:27 - explaining how the model works to
41:29 - somebody who doesn't have
41:31 - a lot of background in machine learning
41:34 - is going to be super complicated um
41:38 - okay cool so
41:41 - um anyway we see that adjusted r squared
41:44 - does a little bit better than r squared
41:47 - we still have to make some judgments
41:48 - about what we're comfortable with
41:50 - um and then i'm just going to
41:54 - show this really quickly this is another
41:56 - way of basically doing the same thing
41:59 - you can run an anova um
42:02 - comparing all of these models and
42:05 - basically
42:06 - get like a p value that compares
42:09 - each nested model to the one to the
42:12 - one smaller nested model and so
42:16 - here i i threw all of the models in and
42:19 - we see that like
42:20 - this these are the p values so this is
42:22 - the p-value comparing model
42:24 - 2 to mod like the model with the squared
42:27 - term to the
42:28 - um first model and saying like
42:32 - do at least one of the additional
42:34 - predictors
42:35 - in this model like significantly better
42:39 - describe this data and we have
42:42 - basically a p-value of zero for the
42:45 - first two
42:46 - it's significantly better and then
42:49 - then we get to a p-value 0.62 comparing
42:53 - the one with the cube term and the one
42:56 - with the
42:57 - fourth and fifth power ones which was
43:00 - the same here right like we had the
43:02 - adjusted r squared
43:04 - actually went down between those two
43:06 - models so we expect like it's not
43:07 - significantly better
43:09 - um but then comparing that model to the
43:11 - model with all the terms
43:13 - we do have a pretty small p-value if it
43:16 - would depend on what threshold we were
43:17 - using for this
43:18 - this is like a mole this is a bunch of
43:20 - comparisons at once so we would probably
43:23 - want to use a smaller significance
43:25 - threshold so maybe if we're using 0.01
43:27 - instead of 0.05
43:28 - this wouldn't be a statistically
43:30 - significant well and
43:32 - and so that p-value is comparing the
43:36 - fifth model to the
43:37 - fourth model yeah which um again if we
43:40 - look at those numbers that was like the
43:42 - 0.459 uh
43:45 - r squared or adjusted r squared compared
43:47 - to the 0.464
43:49 - and so that seems like that's a
43:52 - significant difference but
43:54 - would it be fair to say because model
43:57 - four
43:57 - is not significant compared to model
43:59 - three that even though five isn't gonna
44:00 - compare to four that we just like cut it
44:02 - off at uh
44:04 - yeah i i i surely would
44:07 - um i mean yeah if we see if we compare
44:10 - model
44:11 - 3 to model 5 it's not significantly
44:15 - different
44:15 - because remember like it went this
44:18 - adjusted r
44:19 - squared went down and then back up
44:22 - um so yeah yeah so if you cut out that
44:26 - that step of uh model four really
44:30 - didn't do anything and then model model
44:32 - five improved on model four
44:34 - um you'll see if we just cut out that
44:36 - middle that middle one of
44:37 - uh model four three to five it's okay
44:41 - it's closely significant right it's 0.07
44:43 - and our significant threshold is 0.05 um
44:47 - yeah but i would think in this well
44:49 - first of all there's no such thing as
44:50 - like the enclosure
44:52 - things are either significantly like
44:55 - significant or not but um but yeah like
44:59 - i would say i don't know
45:02 - because we're doing multiple comparisons
45:04 - like having a significance threshold of
45:06 - 0.05
45:07 - for all of those comparisons also would
45:11 - mean that your false positive rate is
45:13 - higher than 5
45:14 - so most people would apply like some
45:17 - sort of
45:18 - either like i don't know some
45:21 - sort of multiple comparisons uh
45:25 - like i'm blanking on the word
45:28 - basically you probably would use a
45:30 - smaller threshold or apply
45:32 - some sort of transformation to those um
45:34 - i
45:35 - can you move your wall water glass and i
45:37 - just want to see
45:38 - um okay have you ever compared a linear
45:41 - regression model
45:42 - with an artificial neural network
45:46 - regressor model um
45:50 - i have i have compared a logistic
45:53 - regression
45:55 - to like a simple neural network
45:58 - and in the one this was like a project
46:01 - they did a while ago but in that project
46:03 - i think they performed equally
46:05 - equally well um but yeah i think it's
46:08 - like it's definitely
46:10 - worthwhile to fit if you
46:13 - have the ability the computing power and
46:16 - like the right amount of data
46:17 - and you can fit a bunch of different
46:19 - models like
46:20 - why not fit a bunch of different models
46:23 - and see which one
46:24 - is the best this is actually related to
46:26 - a question i i tried to answer on
46:28 - discord
46:29 - um last week and i'm still interested if
46:32 - other people have thoughts on it
46:34 - but it's like i don't think there's any
46:36 - i don't think there's anything wrong
46:38 - with fitting a bunch of models and
46:39 - seeing which one
46:41 - is has the best accuracy or has the
46:44 - um the best predictive power and like we
46:46 - can we'll discuss in a second
46:48 - some other ways of of evaluating that
46:50 - for a model
46:52 - um but if you
46:55 - if you do find that a neural network or
46:58 - some other type of model improves the
47:01 - accuracy
47:02 - a lot over your logistic regression or
47:06 - whatever else you're trying to fit
47:08 - if you've if you find that then it's
47:10 - actually like an
47:11 - interesting thing to dig in further
47:13 - because
47:14 - it's picking up on something in the data
47:18 - that you're not able to model with your
47:20 - with your simpler
47:22 - regression model um and maybe you can
47:24 - figure out what that is like maybe
47:26 - there's just some sort of relationship
47:28 - that you're not taking into account
47:30 - um but yeah i'm sure there are
47:33 - situations where
47:34 - where a neural network will do better i
47:37 - mean
47:38 - they're definitely situations um
47:42 - but it comes with comes with some
47:43 - downsides just as adding
47:45 - more complexity to a linear model maybe
47:48 - improves it but comes with downsides
47:51 - and i think one of the things i know i'm
47:53 - going on a tangent here but i think one
47:54 - of the things that is
47:56 - really difficult about data science and
47:59 - that a lot of data scientists disagree
48:01 - about
48:01 - also i don't know what all of these
48:03 - errors are i haven't figured this out
48:05 - um but i think a lot of one something
48:07 - that a lot of people disagree about is
48:09 - like
48:09 - what is the best way to draw lines in
48:12 - the sand
48:13 - and what is what is the best way to
48:17 - accomplish the same goal so like
48:20 - do you where do you sacrifice
48:24 - interpretability for accuracy and where
48:27 - don't you
48:27 - and there's not it's a field where i
48:30 - think there's
48:31 - a lack of there's a lack of
48:36 - agreement among people about like what
48:38 - the right
48:39 - what the right threshold is for
48:42 - for questions like this um
48:46 - yeah exactly it's like harder to
48:48 - interpret
48:49 - and if if you're trying like if your
48:52 - goal is
48:53 - you have to present this at a meeting
48:54 - and be like okay
48:56 - like i made this i built this model um
48:59 - this is
48:59 - the data we have this is how the model
49:01 - works and you want to be able to
49:04 - and you want to be able to look for like
49:06 - understand
49:08 - what the model is doing and understand
49:09 - how bias might be creeping in like
49:13 - a more interpretable model is going to
49:15 - be better
49:16 - has real value and also
49:19 - like if you want to be able to take
49:21 - action based off of the model like
49:23 - we're thinking about the bike share data
49:25 - set like
49:27 - maybe you just want to predict how many
49:29 - bikes
49:30 - are going to be rented um on a
49:33 - particular day and that's your only goal
49:35 - but like
49:35 - that actually seems unlikely like you
49:38 - probably want to be able to make that
49:39 - prediction
49:40 - but you also probably want to be able to
49:42 - understand like what are the factors
49:44 - that predict
49:45 - it because like yeah is it really only
49:47 - the weather that we can't control or is
49:49 - it you know the location of our
49:50 - right yeah you know stations or whatever
49:53 - it is
49:54 - um yeah exactly
49:57 - should we uh so we had the earlier
50:00 - question about
50:00 - um bic and aic i don't know if uh
50:04 - yeah so we'll jump into those right now
50:07 - um so that we don't run out of time so
50:11 - log likelihood um there are a bunch of
50:14 - methods that are
50:15 - likelihood based methods um and
50:18 - the log likelihood function
50:22 - is and i always get this mixed up so
50:24 - maybe i should pull up the
50:26 - uh i should pull up this on codecademy
50:28 - let's just see if i can do that really
50:30 - fast
50:31 - um because i always get it mixed up
50:33 - whether it's like the probability of
50:36 - the data given the model i think that's
50:38 - right
50:40 - um but
50:45 - just so that i don't tell you all the
50:47 - wrong thing
50:48 - um also i this maybe helps because i can
50:50 - show you where this is
50:52 - it's in the choosing a linear regression
50:55 - model
50:56 - um module and then in this lesson
51:00 - you can you can play with this data set
51:03 - yourself
51:04 - um but
51:09 - go to this log likelihood um yeah so
51:12 - it essentially measures the probability
51:14 - of observing our data
51:16 - given a particular model so this is like
51:18 - a probability based
51:20 - um function rather than
51:24 - like a proportion of variance explained
51:27 - um and i'm not going to go into the math
51:31 - of
51:31 - like what that probability looks like
51:34 - but you can kind of imagine
51:36 - um when we think about a model we think
51:39 - about like a data generation process
51:41 - and so like this model let's like think
51:44 - about for
51:45 - a a second the super simple model we had
51:48 - at the beginning
51:49 - where we did just like count as a
51:50 - function of temperature
51:52 - right really what this model is saying
51:54 - is that
51:55 - we believe that the this data is
51:58 - generated
51:59 - based on like around this line where all
52:02 - these points are just
52:03 - randomly like this is our prediction
52:06 - and then there's some random error on
52:09 - any given day
52:10 - and so like we think there's a higher
52:13 - probability that it'll be close this
52:15 - line
52:15 - and a lower probability that a
52:17 - particular data point will be far away
52:19 - from this line
52:20 - in this model like same thing and so for
52:22 - each model we have some probability for
52:25 - each of these data points that like
52:27 - you know uh um one of these points
52:30 - that's really far away from the line
52:32 - is less probable than a point that's
52:34 - close to the line
52:36 - and so you can imagine calculating for
52:39 - all of the data points what's the
52:40 - probability of observing all those data
52:42 - points
52:44 - given the model that we've created
52:47 - and then you want to maximize that
52:48 - probability instead of
52:50 - maximizing the um the variance explained
52:55 - it's just a different method
52:56 - and so but then we use this like we use
53:00 - log um so we take that probability and
53:03 - then we take
53:04 - the log of it um so that we can
53:09 - it basically just makes it easier to
53:11 - search that
53:13 - that space for the um
53:17 - for the like optimal value um
53:20 - and so and that's like a
53:24 - a whole separate thing but basically so
53:26 - log likelihood
53:28 - we want um we want log likelihood to be
53:31 - as
53:34 - as large as possible
53:38 - um but large means
53:42 - usually log likelihood will be negative
53:45 - so a larger log likelihood is actually
53:49 - like
53:49 - it'll be a smaller negative number in
53:52 - most cases
53:53 - it is closer to zero if it's if it's
53:55 - negative yeah
53:56 - it is possible to get positive log
53:58 - likelihood but
53:59 - i i've actually seen it in one instance
54:02 - when i was trying to make this lesson
54:03 - the first data set that i grabbed had
54:06 - like
54:07 - r squared values i couldn't get it over
54:08 - like point one
54:10 - basically and then the um the log like
54:14 - lee hoods were positive um but so we see
54:16 - again here
54:18 - it's um increasing
54:22 - right becoming less negative less
54:24 - negative
54:25 - less negative it just like
54:28 - um regular r squared log likelihood will
54:31 - always increase with more
54:33 - complexity um but
54:38 - we have aic and bic which function
54:42 - much in the same way if a ic and bic
54:45 - are to log likelihood what adjusted r
54:49 - squared is to r squared which is to say
54:52 - that
54:53 - aic and bic are just log likelihood
54:57 - actually they are negative log
54:59 - likelihood so they
55:01 - turn it into a positive number and then
55:04 - minus some number times
55:08 - the number of predictors basically so
55:10 - it's a
55:11 - penalty term for adding more predictors
55:14 - and bic
55:15 - gives you a bigger penalty for each
55:18 - predictor um so
55:21 - we'll see aic is going to
55:24 - decrease decrease then increase
55:27 - and because we so because of the
55:30 - negative
55:30 - it's now negative now a smaller number
55:33 - is better in this case
55:34 - so smaller is better so now we've got
55:38 - it's getting so sorry was i saying
55:41 - decrease or increase no i don't know but
55:43 - basically right okay good
55:45 - um so basically the mod we're saying the
55:46 - model gets better and better and better
55:48 - then it gets worse then it gets better
55:50 - again so the aic is basically giving us
55:53 - the same relationship that we got
55:55 - for adjusted r squared um and then
55:58 - you'll see
55:59 - bic because we have a um
56:04 - a bigger uh penalty for each additional
56:07 - predictor
56:08 - bic goes down for the first
56:13 - one and then it just goes up after that
56:15 - so
56:16 - after just adding the square term bic
56:19 - would have you choose bic would say like
56:21 - every all of these additional
56:23 - terms are worse so bic would have you
56:26 - choose
56:26 - the um just the squared term and i think
56:30 - for that reason a lot of people do
56:31 - prefer bic because it like it helps you
56:33 - find more
56:34 - simple models and it just it gives you a
56:37 - bigger penalty for each
56:40 - piece of added complexity um
56:44 - okay i know i'm like i always do this
56:46 - i'm running out of time
56:47 - but i just want to talk about one other
56:49 - way
56:50 - really quickly and then you can read
56:52 - more about this and
56:54 - learn more on the actual course um
56:57 - but one other way that people assess
57:00 - um model accuracy is they split the data
57:04 - up
57:05 - into a training set and a test set
57:08 - um i think actually alex did was it you
57:10 - that wrote an article
57:12 - about this somewhere and yeah somewhere
57:16 - for the original set of machine learning
57:17 - things we can probably find it
57:20 - yeah because i think there was a nice
57:22 - picture
57:23 - in that and we can do the picture
57:25 - instead of
57:27 - the uh
57:32 - look at the picture instead of the code
57:36 - i think it's somewhere in
57:47 - there we go training set versus
57:48 - validation set versus
57:54 - um okay
57:58 - oh i guess you only have the one for
58:00 - tenfold cross validation
58:02 - but basically the idea is you
58:06 - split the data in some way so let's say
58:10 - just looking at this first ex this first
58:12 - picture under fold one
58:14 - the yellow bar represents some subset of
58:16 - the data
58:18 - right and then the blue bars represent
58:21 - the rest of the data
58:22 - and essentially what you do right is you
58:25 - fit if
58:26 - you fit the data on your training set
58:29 - which is maybe 90 of the data or it
58:31 - could be
58:32 - 80 or 70 whatever you want and then you
58:35 - fit
58:36 - and then you test the model out on the
58:38 - rest of the data to see how well it
58:40 - predicts your outcome
58:42 - and the reason why we might do this is
58:44 - because we know
58:45 - the true outcome value for the
58:49 - test set so like if we split the um
58:53 - the bike's data into into pieces
58:56 - then even for the test set we have the
59:00 - true
59:00 - value of count and so we can use our
59:03 - training set
59:04 - to predict count to create the model
59:07 - then
59:07 - predict that outcome variable for our
59:11 - test data set that we did not use to fit
59:13 - the model
59:14 - and we can see how well it performs
59:16 - maybe we just take like
59:18 - um the different you know the sum of
59:20 - squared differences or the sum of
59:22 - differences between
59:23 - the predictions and the the real values
59:28 - and that is kind of becomes kind of like
59:30 - our measure of accuracy
59:32 - that we can use to evaluate the model
59:35 - and what happens is
59:37 - in a situation like this
59:41 - your model is going to be better at
59:44 - making predictions
59:45 - for your um
59:50 - sorry your bottle is gonna be better at
59:52 - making predictions for your training set
59:54 - but it's gonna be probably worse at
59:57 - making predictions for your test set
59:59 - because this model was so um
60:03 - sensitive to specific data points
60:06 - that that could have messed with it
60:09 - um cool uh yeah i see a note in the chat
60:13 - on facebook um come chat with us in the
60:16 - youtube
60:17 - stream yeah we we can really only have
60:20 - one chat
60:21 - open at a time so we'll probably figure
60:23 - out ways to get facebook as
60:25 - well but uh we're just getting set up in
60:27 - the uh back in the office here so
60:29 - um i'm glad that you at least made it to
60:31 - the youtube chat if you saw that on
60:33 - on facebook yeah we're sorry
60:37 - um but yeah hopefully hopefully everyone
60:39 - was able to um get their questions
60:41 - answered um like i said
60:43 - we i highly recommend that you take a
60:44 - look at the course um itself because it
60:47 - has a lot more information here
60:48 - kind of rush through in an hour um so
60:51 - we'll be back in two weeks to kind of
60:53 - do like a a wrap up and um
60:56 - and apply everything that we saw so far
60:59 - in all of these streams
61:00 - we'll like pick a data set and kind of
61:02 - play with it and make it it'll be a
61:04 - little bit more open-ended and fun
61:06 - so you can you know give us insights or
61:09 - give us suggestions for what you think
61:11 - we should add to the model or take out
61:13 - and we can
61:13 - kind of do some model building in real
61:15 - time together um
61:17 - and then um
61:20 - on thursday we will have office hours
61:24 - um on discord again um but
61:28 - we recommend like if you have questions
61:30 - um ask them in discord we'll keep an eye
61:32 - on it so that we can make sure that we
61:34 - answer some of those questions give the
61:35 - next two weeks um
61:38 - so yeah ask us questions and we'll we'll
61:40 - make sure we check them before the final
61:42 - live stream so that we can
61:43 - we can answer some of those questions
61:45 - live if you don't have the ability to
61:46 - come
61:47 - to the office hours yeah then uh
61:50 - so in two weeks that's our eighth and
61:52 - final stream
61:53 - for this linear regression series if you
61:55 - have other things that uh
61:57 - you're interested in uh in us doing a
62:00 - live stream on
62:00 - uh let us know and maybe we can make it
62:02 - happen right now we have no plans for
62:04 - a next series but um yeah we would
62:07 - uh i at least would be excited to do
62:10 - another one of these so
62:11 - um yeah if you have ideas on other live
62:14 - streams that you'd like to see
62:15 - uh let us know you can comment on this
62:18 - youtube video if you're if you're
62:19 - watching it
62:20 - uh sometime in the future totally
62:23 - cool all right