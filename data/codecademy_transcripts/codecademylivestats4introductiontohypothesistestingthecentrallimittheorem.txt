00:00 - if not already
00:06 - possibly now
00:16 - all right i think we're live something
00:20 - happened
00:20 - on my screen welcome everyone
00:24 - uh we're just gonna wait uh a minute or
00:27 - two
00:27 - to make sure that we are fully live
00:31 - um jamie and i are going to be talking
00:34 - about the central limit theorem today
00:36 - and i'm very very excited uh thank you
00:39 - for letting us know in the chat that you
00:40 - can see us
00:41 - um so i am very excited for this
00:46 - uh anyway we are i think
00:49 - as usual streaming on a couple of
00:50 - different services but just as a
00:52 - reminder
00:53 - um we're gonna be keeping an eye on the
00:55 - chat in
00:56 - uh youtube so if you are on facebook or
01:00 - twitch
01:00 - or one of the other platforms that we
01:02 - are streaming on if you would like to
01:05 - code along with us and ask us questions
01:07 - or say hello
01:08 - um you can go to the youtube uh
01:12 - streaming and let us know that you are
01:16 - here by saying hello in the chat
01:18 - um cool
01:22 - uh so i guess we can get
01:26 - started today so i will share my screen
01:30 - today's lesson is gonna be
01:34 - heavy on the theory uh and
01:38 - there's we're definitely going to be
01:39 - doing some coding like we need some
01:41 - coding to get
01:42 - a sense of the theory but
01:45 - the focus is going to be on
01:47 - understanding
01:48 - some pretty deep theoretical concepts
01:52 - which i find super fun
01:55 - um but i think it can also be a little
01:57 - bit intimidating sometimes
01:59 - so um i really want to encourage
02:03 - everyone to ask questions if anything
02:07 - comes up that you are confused about
02:11 - um i really really welcome questions
02:15 - because
02:16 - it will help me keep track of
02:20 - what is making sense to people and
02:22 - what's not and we can
02:23 - slow down at any point and kind of recap
02:26 - things
02:26 - if um if anything is is confusing
02:30 - so uh again as per usual
02:34 - we're using some code that's available
02:36 - on
02:37 - our github for this streaming series if
02:40 - you want to
02:41 - download that code ahead of time you're
02:43 - welcome to
02:44 - there's also like a little simulated
02:46 - data set in here
02:48 - for this week's um this week's materials
02:50 - so
02:51 - you can find that if if you go to
02:55 - the github page and hopefully that is
02:57 - linked in
02:58 - youtube and other streaming services
03:01 - um cool i'm to open up starting cook
03:07 - okay so to get started
03:10 - um the first thing i want to prepare
03:13 - everyone for
03:14 - is i'm going to ask us to take on a
03:17 - couple of different
03:18 - personas during this lesson so we're
03:20 - gonna switch back and forth
03:22 - from the researcher perspective so
03:26 - that's somebody who is trying to conduct
03:30 - some research trying to analyze
03:32 - some data we're going to switch between
03:34 - that and
03:35 - the all-powerful perspective so
03:38 - we get in this lesson to be
03:42 - like gods or goddesses whatever you want
03:46 - to call it
03:47 - if you're if uh or all powerful in some
03:50 - way we get to like
03:51 - see things that the researcher would not
03:54 - get to see
03:55 - um and kind of imagine imagine both
03:58 - perspectives if we had all the knowledge
04:00 - that we could possibly have and if we
04:02 - only had the knowledge that a researcher
04:04 - had
04:05 - um the other thing i want to kind of set
04:08 - up here
04:09 - is up to this point we have been
04:12 - talking through uh summary statistics
04:16 - just basic descriptive statistics we
04:19 - looked at some data visualizations as
04:21 - well
04:22 - and um a lot of so
04:25 - that content is really useful for
04:28 - a lot of different types of research
04:30 - that you might want to do but
04:32 - i want to kind of separate what we're
04:34 - doing today
04:35 - uh from that a little bit and say so
04:39 - you could kind of imagine two different
04:42 - types of
04:42 - questions that you want to answer um
04:46 - on the one side you could imagine that
04:48 - let's say
04:49 - you work at a company like codecademy
04:51 - there's
04:52 - i think like 150 employees at this point
04:56 - and let's say you um you want to
04:58 - understand something about
05:00 - salary and demographic characteristics
05:03 - among employees and you have the data
05:05 - for every single person
05:07 - that works at the company that you're
05:09 - that you care about then
05:10 - you can just use descriptive statistics
05:12 - because the thing that you care about
05:14 - you have all of the data for but there
05:17 - are a lot of situations
05:19 - where you cannot for some reason
05:22 - collect all of the data that you need to
05:24 - answer the question that you want
05:25 - to answer and that could be for a
05:28 - variety of reasons it could be just
05:30 - because
05:31 - the population that you care about is
05:33 - really large
05:34 - like you want to understand trends
05:37 - between
05:38 - salary and demographics for all u.s
05:41 - adults and you can't you just cannot get
05:44 - that information for all u.s adults
05:46 - um that could be one situation another
05:49 - situation
05:49 - a lot of times in like marketing is that
05:52 - you can imagine
05:53 - you have a new feature for your product
05:56 - and you want to test it out and see if
05:58 - or let's say like it's a different color
06:00 - subscribe button and you want to see if
06:02 - more people press the green subscribe
06:05 - button
06:06 - compared to the red subscribe button
06:09 - and uh you want to know
06:13 - whether more people like all the future
06:15 - visitors to your website you want to
06:17 - know what
06:18 - all those people would do but
06:21 - you can't see all the future people that
06:24 - will ever access your website and in
06:26 - fact
06:27 - even among the people that you do sample
06:29 - you can't
06:30 - ever see what somebody would have done
06:33 - in another situation so if you show
06:35 - someone a green button
06:36 - you can't see what they would have done
06:38 - if they saw a red button
06:39 - so that's another form of missing data
06:42 - you just can't see
06:43 - you know ideally you'd like to show
06:45 - every person that could possibly visit
06:47 - your website the red button
06:49 - erase their memory and then do the same
06:51 - thing with the green button
06:52 - and like see all of those things and
06:54 - then look at the data but you can't
06:56 - always do that so in that case you need
06:59 - some
06:59 - other tools in order to understand
07:03 - something about a population about all
07:05 - the people that might visit the website
07:06 - or feel confident about it
07:08 - having only collected a smaller amount
07:09 - of data okay
07:11 - i've now i always do this i ramble a
07:14 - little too much at the beginning of
07:15 - these i hope i didn't lose too many
07:16 - people yet but hopefully that sets up
07:18 - kind of the motivation for what we're
07:20 - doing
07:22 - so um what i have here
07:25 - is a um a jupiter notebook i'm just
07:29 - gonna load a bunch of packages
07:31 - i i just copy this over every time i
07:34 - start a new project because
07:36 - i may not use all the packages but at
07:39 - least i have all of them
07:40 - imported um and i can import more if i
07:43 - need
07:44 - this uh hourly pay text file
07:47 - is um it's just essentially an array of
07:52 - numbers
07:53 - uh and this was simulated but what it's
07:56 - meant to represent is
07:59 - salaries in u.s dollars for
08:03 - theoretically all adult
08:06 - americans um
08:10 - it's like it's it's fake data but it's
08:13 - based off of census data so it's
08:14 - somewhat
08:16 - similar to what this would look like in
08:18 - real life um
08:19 - so i'm gonna go ahead and really quickly
08:23 - plot a histogram of this so we can take
08:25 - a look at it
08:27 - uh let's do like
08:31 - 100 bins and
08:38 - yes maybe 100 was too many let's do 50.
08:43 - um okay so it looks something like this
08:47 - uh which we probably expect you know
08:50 - there's this
08:51 - there's a spike at kind of a low salary
08:54 - seems like most people are kind of oh
08:57 - and this is an
08:58 - hourly pay or hourly salary um
09:01 - so looks like most people are kind of
09:04 - under 20
09:05 - an hour there are some people between 20
09:08 - and 40
09:09 - and then it kind of drops off from there
09:12 - there's some from 40 to 60 and then like
09:14 - very few but still some people all the
09:16 - way up to
09:17 - 140 an hour in this chart
09:21 - and you can see over here this is like a
09:24 - a pretty big scale
09:25 - each of these bars um
09:29 - this axis represents frequencies so we
09:32 - have like frequencies
09:33 - and some for some of these bars of over
09:35 - three hundred thousand
09:37 - um cool so
09:41 - this gives us a little bit of a sense
09:43 - right now we're in
09:45 - all powerful modes so we're gonna
09:48 - pretend
09:49 - um in this in today's lesson we're gonna
09:52 - pretend
09:53 - that we're a researcher that's
09:55 - interested in
09:56 - figuring out what the average salary for
09:59 - all us adults is
10:00 - and then as the all-powerful being
10:04 - we can see data for
10:07 - salary information for all u.s adults so
10:10 - those are the two
10:11 - uh the two perspectives will shift
10:15 - between
10:16 - so right now we're all powerful we can
10:17 - see this histogram
10:19 - um and we can actually calculate the
10:21 - mean uh salary so i'll do that
10:24 - so if i do i mean
10:27 - hourly pay uh
10:32 - and actually i'll save this as mean
10:35 - salary and
10:38 - print it
10:42 - is this also big enough for everyone i
10:45 - realize
10:47 - click zoom in and i can print the mean
10:50 - salary
10:54 - okay so it's about 18
10:57 - and 84 cents cool
11:02 - okay so we've taken a minute
11:05 - we're all powerful we know the answer to
11:08 - the question
11:09 - that our researcher is going to try to
11:11 - answer we know that
11:13 - the average salary for all american
11:16 - adults
11:17 - based off of this i don't know if this
11:18 - is exactly what it is um i think this
11:20 - data
11:21 - that i based this off of was from like
11:23 - 2013 or something so
11:24 - it might be outdated but it's
11:26 - approximately eighteen dollars and
11:27 - eighty-four cents
11:28 - we're going to pretend that that's the
11:30 - truth that our researcher can't
11:32 - know now we're gonna for a minute
11:36 - imagine that we are a researcher
11:39 - so um as this researcher
11:44 - we are going to try to answer our
11:46 - question what's the mean salary of u.s
11:48 - adults and we're going to
11:49 - do that by finding a sample of of u.s
11:53 - adults
11:53 - and calculating their mean salary
11:56 - because that's all we can do right we
11:57 - can
11:58 - find and by sample i mean like some
12:01 - subset
12:02 - of this original um
12:05 - of this original set of numbers right
12:07 - some subset of all the people that we
12:09 - actually
12:10 - care about cool
12:13 - so um i'm gonna actually
12:16 - hold on i'm gonna open up the final code
12:18 - and pull this over
12:20 - so that i can also see it uh because
12:24 - i just want to make sure okay
12:28 - cool um there's a few different ways to
12:30 - do this a few different
12:31 - functions that you can use for random
12:33 - sampling i guess
12:35 - for this at least in the final code i
12:37 - gave you guys i used random so i'll use
12:39 - that here
12:40 - um so i'm just gonna demo really fast
12:43 - what this random sample function does
12:45 - uh before we do any examples here so
12:49 - if i just had an array i'm going to call
12:51 - it
12:52 - arr um
12:56 - of a bunch of numbers like 1 1
12:59 - 2 2 3 4 5 6 6
13:02 - 7 8. okay i've got a bunch of numbers in
13:06 - this array
13:08 - if i say um
13:11 - if i say give me a random
13:14 - sample of array and i say give me a
13:18 - random sample of
13:20 - five numbers let's say
13:26 - oh i guess actually it requires a list
13:33 - it gives me a sampling of the numbers in
13:36 - this array
13:37 - uh so this first time i got 6 6 5 1
13:41 - 8. um one of the questions you might be
13:44 - interested in and actually i'll do this
13:46 - again so here's five different numbers
13:49 - interesting that i got the two sixes
13:50 - again oops
13:52 - let's try it again two sixes again wow
13:57 - okay that time i only got one so it will
14:00 - it will run this randomly every single
14:02 - time
14:03 - and we'll get different results every
14:04 - single time one thing you might be
14:06 - interested in is whether there's
14:08 - replacement here so by replacement i
14:11 - mean after it picks a number
14:13 - can that number be picked again by
14:15 - default
14:16 - this function does not use replacement
14:18 - but if you
14:21 - wanted to you could always do a quick
14:23 - google search to try to figure that out
14:26 - so
14:26 - i'm just going to demonstrate because
14:29 - this is also
14:30 - a coding uh
14:34 - demo so
14:37 - actually now the
14:41 - function documentation
14:48 - um all right let's try this again this
14:50 - was a bad demo
14:53 - uh sample python
14:58 - and we'll go back to all
15:04 - okay it's weird that
15:08 - the function documentation doesn't come
15:11 - up
15:12 - right away but here
15:15 - i guess is the whole random package so
15:17 - it'll be in here
15:18 - somewhere
15:24 - yeah there it is um and you can look
15:27 - through
15:28 - and see what what all of the parameters
15:31 - are
15:32 - it should say somewhere whether
15:35 - it is replaceable
15:39 - oh yeah sampling without replacement so
15:41 - it's not going to put anything back
15:44 - okay so we have this this sample
15:48 - from our array and we can see that we
15:50 - can do this in
15:51 - python so now i'm going to demo this
15:54 - using our full population so
15:58 - i'm imagining i'm the researcher and i'm
16:00 - going to go in
16:01 - and as the researcher i'm going to find
16:04 - a sample
16:05 - or a subset of people in this population
16:08 - and i'm going to collect their
16:12 - salaries so let's uh let's do it this
16:15 - way
16:17 - i'm going to call this samp1
16:23 - and i'm gonna pass in what did we call
16:26 - it
16:27 - hourly pay uh actually
16:30 - okay just to make everything super super
16:34 - clear
16:36 - i'm going to say i'm going to re-save
16:38 - this as something called population
16:41 - i'm going to save it as a list
16:45 - but i'm just saving the exact same
16:47 - numbers again so that we're really clear
16:49 - that this is the
16:50 - the full population and then this is
16:52 - going to be our sample
16:54 - so we'll sample from that population
16:57 - and i don't know jamie pick a pick a
17:00 - number
17:01 - how many do we want to sample from it uh
17:05 - 20. okay let's sample 20 people to start
17:11 - and then let's print out the mean
17:15 - of our sample
17:18 - and it was 17.24 interesting
17:22 - okay we could do this as many times as
17:25 - we wanted so
17:26 - if we do this again because this is
17:28 - random sampling we're going to get
17:30 - different samples every single time
17:32 - so i'll do it again we got something
17:35 - different
17:36 - i also think so i'll show you really
17:38 - quickly
17:40 - pissed stamp one
17:44 - um
17:55 - okay let's pick uh let's pick a slightly
17:58 - larger sample size let's do like 150 so
18:01 - we can really see it
18:04 - if we look at this histogram right of a
18:07 - sample of 150 people from our population
18:11 - you'll notice that it looks pretty
18:14 - similar to our original histogram that
18:18 - we made right like so our original one
18:20 - looked like this there was a spike
18:22 - around zero
18:24 - um then there was this long tail most of
18:26 - the
18:27 - the density of this thing was between 0
18:29 - and 20
18:30 - then 20 to 40. and if we look back at
18:33 - this we see kind of a similar shape
18:35 - right we've still got this
18:36 - low spike we've got some den some high
18:40 - density between 0 to 20 some
18:42 - like medium density from 20 to 40 and
18:44 - we've got this kind of
18:46 - long tail obviously it's a little bit
18:48 - sparser
18:49 - um but we still we see a similar shape
18:52 - and we see that
18:54 - this mean for our sample 18.65
18:58 - is kind of pretty similar to the mean
19:01 - for the overall population and
19:05 - no matter how many times we do this
19:06 - taking different samples of 150 people
19:10 - from our population which let's see how
19:13 - big is the population
19:16 - can i do one on this
19:20 - actually don't know yeah
19:25 - uh okay
19:29 - that's three minutes well i guess this
19:30 - is not the whole population
19:32 - because it's not as long as it would
19:36 - need to be
19:36 - but you'll have to suspend disbelief so
19:38 - we've got like three million in here
19:41 - um we can imagine that the population is
19:45 - something else i don't know
19:48 - okay so but we we do see right that
19:52 - no matter how many times we do this
19:55 - we're going to get a sample that's
19:57 - somewhat similar to the population it's
19:58 - not going to be exactly the same
20:00 - it's going to be slightly different
20:01 - every time there might be different
20:03 - outliers that show up like this one
20:05 - randomly has
20:07 - two people i think out in this uh
20:10 - like over a hundred per hour category
20:12 - which
20:13 - is kind of surprising given how rare
20:16 - that is
20:17 - in the full population but sometimes
20:19 - just by random chance we'll get
20:20 - those people so
20:24 - okay and the framework that we're now
20:28 - going to take so do this one more time
20:30 - because it's kind of fun
20:34 - we're going to think about what happens
20:36 - if we do this a lot of times so
20:39 - now that we have pretended to be the
20:42 - researcher
20:43 - we've taken a sample from our population
20:46 - we have taken a look at it and seen that
20:49 - it's similar to the population but
20:51 - there's some variation in there
20:52 - sometimes we get
20:53 - a high mean sometimes we get a low mean
20:56 - compared to the population mean
20:58 - now we're going to go back to uh
21:01 - now we're gonna go back to all powerful
21:02 - mode okay
21:05 - so in our all-powerful mode
21:08 - what we're gonna do is we're gonna
21:11 - repeat this process
21:13 - a whole bunch of times so
21:18 - jamie what kind of
21:21 - uh coding technique do you think
21:24 - i should use to repeat this a bunch of
21:28 - times
21:28 - or what do you have any ideas how to how
21:30 - i could kind of
21:32 - go about that yeah so i guess if we want
21:34 - to basically repeat the same pos
21:37 - repeat the same process a lot of times
21:39 - we might maybe want to use some type of
21:40 - loop
21:41 - like have it automatically do it yeah
21:44 - yeah so instead of just pressing this
21:46 - run button a bunch of times
21:48 - and seeing what the output is i'm gonna
21:49 - use a for loop
21:52 - um and i could use a different kind of
21:55 - loop actually
21:56 - uh there's nothing i could use like a
21:59 - while loop
22:00 - as well um but i'm just gonna use a for
22:04 - loop because it's easy
22:06 - um and what i'm gonna do is i'm gonna
22:08 - say for
22:09 - i and range
22:12 - i don't know like 10 000. what this is
22:15 - gonna do
22:16 - is it's gonna repeat the process
22:19 - that i tell my that i tell python to
22:23 - repeat it's gonna repeat it
22:25 - 10 000 times um
22:28 - it see might seem a little bit silly
22:30 - that i have this like i
22:31 - here where i say for i and range
22:35 - 10 000 um i'm not going to
22:38 - use it for the purposes of what we're
22:40 - doing here
22:41 - i'm really just setting this up because
22:46 - i want i just want something to
22:49 - [Music]
22:50 - to happen ten thousand times i want to
22:53 - kind of like
22:54 - essentially if i was coding something
22:57 - else
22:57 - right every time this whatever code i
23:01 - put down here
23:02 - under the for loop would happen every
23:04 - time that would happen
23:05 - i would increase by one and it would or
23:08 - it would start at zero so go
23:09 - zero one two three four um
23:13 - right so like if i print four i in range
23:16 - ten print i and i
23:20 - uh and i run this i'm just going to get
23:21 - the numbers 0 through 9
23:23 - because i is going to be 0 the first
23:26 - time
23:27 - then it's going to be 1 then it's going
23:29 - to be 2 and it's going to happen
23:30 - 10 times in total and it's going to
23:33 - print out the value of i
23:34 - each time but i'm just not going to use
23:37 - i because i don't need it
23:38 - i just need something to happen 10 000
23:41 - times or a large number of times
23:44 - okay actually good coding practice
23:48 - is to never start a loop by repeating
23:50 - something 10
23:51 - 000 times because if you screw up the
23:53 - code uh
23:55 - then it can get stuck and like quit out
23:58 - on you so i like to start with like
24:00 - 10 and then we'll we'll iterate on this
24:04 - so i'm going to kind of grab my code
24:07 - from up here
24:11 - i've got population has already been
24:14 - saved
24:15 - and every time in this loop
24:19 - what i'm going to do is take a sample
24:23 - call it sample of some number of
24:26 - observations
24:28 - and then i'm going to calculate the mean
24:31 - of the sample
24:37 - actually i'm going to call this samp
24:40 - because another good coding
24:43 - practice is to not name variables the
24:46 - same thing
24:47 - as functions um because that can
24:50 - sometimes get a little bit mixed
24:52 - up great okay so
24:55 - i'm going to calculate the mean of
24:57 - sample but i don't want to just
24:58 - calculate the mean and just
25:01 - let it go i want to save it somewhere so
25:04 - uh jamie do you have any ideas for how i
25:07 - could
25:07 - save it yeah so we're probably going to
25:11 - want to save more than
25:12 - one of these because you're going to be
25:13 - iterating a lot so
25:15 - we could save it inside of a list cool
25:18 - so maybe
25:19 - we can make like a list outside of the
25:21 - for loop
25:22 - that is empty that we can just add stuff
25:25 - to it
25:26 - yeah so i'm going to create an empty
25:28 - list called samp means
25:30 - perfect and then i'm going to say
25:35 - samp means dot append
25:39 - which means append that value onto the
25:43 - list
25:44 - um and i'm going to append the mean of
25:47 - that particular sample
25:50 - so uh okay
25:54 - and now i'm just going to print out what
25:56 - this looks like after 10 iterations
26:00 - and we'll take a look at it
26:04 - cool so all of all of what we've done
26:07 - here is we've taken
26:09 - 10 sam 10 different samples of 150
26:13 - each for each sample we calculated the
26:16 - mean
26:16 - and we saved that in our list so the
26:18 - first sample mean was
26:20 - 20.68 this next one was 19.35
26:24 - then 18.66 and so on and so forth
26:28 - uh i see that i saw that there was a
26:30 - question
26:31 - about um memorize
26:35 - memorizing and knowing how the number
26:37 - goes so yes
26:38 - uh i think jamie responded but if you
26:41 - could clarify that question i would be
26:43 - happy
26:44 - happy to answer it um
26:47 - okay so
26:50 - all right so we've done this we've
26:52 - confirmed that we can do it 10 times and
26:54 - we can
26:55 - collect 10 sample means and now i'm
26:58 - gonna do it
26:59 - a whole bunch more times i'm going to do
27:03 - 10 000. i'm gonna run it
27:07 - i'm not gonna print it anymore because
27:09 - that's gonna be 10 000 numbers
27:11 - but what i will do is i
27:19 - i'll make an will of it
27:32 - this will take a second to run
27:37 - cool cool
27:40 - interesting okay so
27:44 - let's break down what this picture is
27:46 - telling us
27:48 - so remember that what we did as all
27:50 - powerful beings
27:51 - is that we collected 10
27:54 - 000 different samples each sample had
27:58 - 150 people in it
28:00 - for each sample we calculated the mean
28:04 - and then we plotted a histogram of them
28:07 - um when we plotted this histogram we saw
28:11 - that
28:12 - it looks kind of symmetrical part of the
28:15 - reason why i chose this data is because
28:17 - i think
28:17 - this is really a stark contrast
28:20 - to the population distribution
28:25 - which i think is interesting so like
28:27 - this population distribution
28:29 - i would describe as very right skewed
28:31 - right there's this
28:32 - very very long right-handed tail
28:36 - and most of the data is on the low end
28:39 - of the distribution
28:41 - but here and that's true right for all
28:43 - of the individual samples that we took
28:46 - all those individual samples are also
28:49 - right skewed
28:51 - but suddenly when we calculate sample
28:54 - means
28:55 - and we plot a histogram of all of the
28:58 - sample means
28:59 - we get this really nice symmetrical
29:01 - distribution
29:02 - and if we calculate the mean
29:06 - of all of the sample means
29:11 - it's going to be so it's like 18.82
29:15 - about which is almost exactly
29:19 - the same as the the true population mean
29:24 - and maybe that feels i don't know to me
29:27 - that feels like it makes sense
29:29 - that the mean of the means like the
29:31 - middle of the means of all these samples
29:34 - is going to be equal to
29:36 - the population mean but it's actually
29:39 - like
29:41 - a super super powerful statistical
29:44 - theorem
29:45 - that is not i mean we take it for
29:47 - granted like
29:49 - uh what this what this means
29:52 - in like and i don't mean to use
29:56 - mathy terms but there's uh this is
29:59 - called
30:00 - a unbiased estimator so the mean is
30:04 - is called an unbiased estimator of the
30:06 - population mean
30:08 - which means that if you take a bunch of
30:11 - samples from a population and you
30:13 - calculate the mean for each one
30:16 - on average those sample means
30:19 - will be the same as the population mean
30:21 - but that's not necessarily true for
30:24 - for example if you calculate
30:27 - standard deviation or variance of a
30:31 - population
30:32 - it's almost an unbiased estimator
30:35 - but that's why there's a difference i
30:36 - don't know some of you may have seen
30:38 - this so there's a difference between
30:39 - calculating population standard
30:41 - deviation and sample standard deviation
30:44 - you divide by n in one case and you
30:46 - divide by n
30:47 - minus one in the other case and the
30:49 - reason for that
30:50 - is that if you divide by n it becomes a
30:53 - ever so slightly
30:54 - biased estimator um of
30:57 - the population standard deviation and if
31:00 - you think of something like
31:02 - the maximum of a data set which is
31:05 - another
31:06 - statistic that we might use so like we
31:08 - might calculate
31:09 - the maximum uh salary in each sample
31:12 - like that might be something that we're
31:14 - interested in
31:15 - if we count if we take the maximum of
31:18 - all of these population or all these
31:21 - samples
31:22 - and plot a histogram of the maximums
31:26 - it's not going to be centered at the
31:27 - population maximum
31:30 - so it's it's not true for all statistics
31:33 - that this lines up but for the sample
31:35 - mean it does
31:37 - and it's really really nice that it does
31:39 - okay
31:40 - so i guess the first question is why is
31:43 - this so valuable
31:45 - and the reason it's so valuable is that
31:48 - it allows us to understand uncertainty
31:52 - and uncertainty is really the key to
31:56 - statistics and inferential statistics
31:59 - specifically
32:00 - because again put yourself in in the
32:04 - feet of or in the shoes of a researcher
32:08 - um again i like that marketing example
32:12 - if you're like you're trying to figure
32:14 - out what proportion of visitors to a
32:16 - website
32:17 - will press my green subscribe button and
32:21 - you can only sample
32:25 - a thousand people you can only show the
32:26 - button to a thousand people and observe
32:28 - what they do
32:30 - you need to know how cert let's say you
32:32 - find that
32:35 - ten percent more people push the button
32:38 - if it's green than in the old version
32:41 - you need to be
32:42 - know how certain you can be that it's
32:44 - really ten percent
32:45 - and not negative one percent
32:49 - right like maybe in the population
32:53 - it's negative one percent but you just
32:55 - found in your random sample
32:56 - 10 more press that button
32:59 - and in this case right like if
33:03 - if you find as the researcher that the
33:06 - average salary
33:07 - is 16 an hour
33:10 - you want to know how certain you can be
33:13 - that that lines up with the population
33:15 - average salary if that's what you're
33:17 - trying to estimate you want to know how
33:19 - far off you could be
33:22 - and that's what this tells you tells you
33:24 - how far off you could possibly be
33:26 - because it gives you a sense of how
33:29 - spread out
33:31 - these numbers and how spread out the
33:33 - sample means
33:35 - are if you were all powerful and you
33:37 - could take a bunch of sample means of
33:39 - that size
33:40 - you this tells you how spread out they
33:43 - could possibly be
33:44 - um so i guess one of the things that
33:47 - i'll point out here
33:49 - um and maybe we intuit it but i think
33:52 - it's
33:53 - like a powerful thing to show
33:56 - is uh what happens when
34:00 - we change the sample size so what i'm
34:03 - going to do is i'm actually going to
34:06 - i'm going to uh
34:10 - make sure that we plot this on the same
34:13 - axis every time i'm gonna set
34:17 - plt dot x slim
34:21 - of 0 to 40.
34:24 - uh and i'll plot this again
34:31 - yeah okay so i'm just plotting this from
34:33 - 0 to 40 so we can see the full
34:36 - whole thing if i do
34:40 - if i do this again
34:43 - with let's say a sample size of
34:47 - a hundred instead
34:53 - it's going to be a little bit wider
34:55 - let's pick something lower
34:56 - really show it i'm gonna
35:02 - sample size of 50. okay so now we can
35:05 - see right this distribution when we took
35:07 - samples of size 50
35:09 - it's going from the sample means are
35:11 - going from 10
35:12 - all the way up to 30. here they're going
35:16 - between
35:17 - like 15 and 25 which makes some sense
35:21 - right because if you think about it
35:24 - if you take a bigger sample it's more
35:27 - likely to be representative of the
35:29 - population
35:30 - then if you take a small sample then you
35:32 - could have outliers that
35:34 - throw everything off the other thing
35:37 - that i won't demo here but that
35:39 - the other thing that can influence this
35:41 - the width of this thing
35:43 - is the amount of variation
35:46 - in the population so if the population
35:50 - has a lot of variation
35:52 - the width of this thing will be bigger
35:55 - and if the population has very little
35:56 - variation like let's say
35:58 - everybody's salary was around 20
36:01 - instead of that spread out distribution
36:03 - that we saw before
36:04 - going all the way up to 140 then there's
36:07 - just going to be
36:08 - less variation in sample means by
36:10 - default right like if everybody was
36:12 - making 20 in the most extreme case then
36:15 - all of the sample means would be exactly
36:16 - 20.
36:17 - so however however much variation there
36:20 - is in the population will also influence
36:22 - this
36:23 - [Music]
36:24 - so what i'll show i think
36:27 - like a cool thing to see just to kind of
36:31 - verify it
36:32 - even is that
36:37 - and this is the the official central
36:39 - limit theorem that we're getting to
36:41 - now is that um we can
36:45 - basically describe exactly what
36:49 - this shape is going to look like
36:51 - mathematically
36:52 - without having done what we did here
36:55 - which is take all of these sample means
36:58 - i'm gonna plot this again but this time
37:02 - i'm going to i'm gonna grab some kind of
37:05 - this is again like a little bit i don't
37:08 - mean to
37:09 - just like pull fancy code and make
37:11 - everybody
37:15 - accept it um
37:18 - but i'll talk through what this is doing
37:22 - so on top of this histogram what i'm
37:24 - gonna do
37:26 - and i'm gonna normalize the histogram
37:28 - which means
37:29 - or actually i'm gonna switch to
37:32 - a disc plot
37:36 - um what i'm doing here is i'm i'm
37:38 - normalizing the histogram so
37:40 - here the histogram is going from
37:43 - 0 to 600 on the y-axis these are
37:46 - frequencies
37:48 - and if i were to say density
37:52 - equals true here or if i use disk plot
37:54 - and i'll demo that in a second
37:57 - all that does is it changes this y-axis
38:00 - so that
38:00 - the scale of this is such that the total
38:04 - area of this thing adds up to one um
38:07 - this is so that it mimics what's called
38:10 - a probability distribution function
38:12 - which you don't really need to know too
38:14 - much about right now
38:16 - but that allows us to compare this to
38:18 - kind of mathematical
38:20 - functions um and if we do dist plot here
38:25 - it does the exact same thing it also um
38:29 - puts what's called a oops
38:32 - oh yeah it doesn't take bins
38:36 - and also um
38:42 - oh it's sms
38:46 - bad it also gives you this
38:49 - kernel density estimation again
38:52 - not super important all you need to know
38:54 - is it's kind of like
38:55 - a smoothed version of this histogram
38:58 - so it's trying to like smooth out this
39:02 - uh this shape so
39:05 - if we do this um okay what i've done
39:09 - i'm gonna walk through what this code is
39:10 - doing or maybe jamie do you wanna walk
39:12 - through
39:12 - try to walk through what this code is
39:14 - doing i'm putting you on the spot a
39:15 - little bit
39:16 - yeah sure um let me just
39:19 - change some things okay
39:23 - okay so the where should i start from
39:26 - should i start from you
39:27 - and sigma or so i guess
39:31 - mu is just the population mean um i'll
39:34 - come back to this
39:36 - in a second so maybe start with this
39:38 - what is this lin space things so
39:42 - linspace mu minus three times sigma
39:44 - oh so i think linspace you're
39:48 - basically setting up like an interval
39:49 - range using mu
39:51 - and sigma um which i think sophie said
39:54 - she'll
39:54 - come back and explain what sigma is but
39:56 - basically it's going to set a range of
39:58 - values
40:00 - in a variable called x and then you're
40:02 - going to plot
40:03 - that range of values um
40:06 - [Music]
40:08 - and then what is stats.norm.p i think
40:10 - that's just like
40:12 - to like give a normal distribution
40:16 - with the given x and yeah
40:19 - give with the given range of values mu
40:21 - and sigma
40:22 - so i'll demo this part really fast
40:25 - actually i should have done just like 10
40:26 - numbers
40:27 - um all that linspace does
40:30 - is it says okay start at 0 end at 1 and
40:34 - give me
40:35 - 10 numbers that are equally spaced so
40:37 - this just gives me
40:38 - 10 numbers between 0 and 1 that are
40:41 - equally spaced apart
40:43 - and all i'm doing here is i'm saying
40:46 - basically this is something that is not
40:49 - super important but
40:50 - this gives me a sense of how
40:53 - wide the x-axis of my distribution is
40:57 - going to be
40:58 - um basically i'm just saying like what's
41:01 - the lowest number i need to plot here
41:02 - what's the highest number i need to plot
41:04 - here in order to fit this
41:06 - on my graph and i'm getting a hundred
41:08 - numbers
41:09 - and then i'm going to get essentially
41:13 - the normal distribution version of this
41:17 - a normal distribution again is a
41:19 - probability distribution
41:20 - and all you need to know for right now
41:22 - is that
41:23 - it describes a particular shape of this
41:27 - distribution
41:28 - mathematically and so
41:31 - i'm plugging in all of those values that
41:33 - i just got between
41:36 - the two ends of that distribution
41:38 - calculating how high that line needs to
41:40 - be and i'm just using them to
41:42 - draw that line on top of my graph
41:45 - and when i do that
41:49 - oh it's because i did this again
41:58 - uh did i not save this
42:07 - sorry guys
42:10 - oh
42:13 - um sci pi import
42:16 - stats okay gonna run
42:20 - okay there we go so what you see here is
42:23 - i've
42:24 - drawn in black what's called the normal
42:27 - distribution
42:28 - on top of the distribution that we got
42:32 - just by taking samples of size 50 and
42:35 - plotting
42:36 - the um and collecting the means for each
42:39 - sample
42:40 - and what you see here is that it's
42:42 - basically the same thing
42:43 - so i've used like a mathematical formula
42:46 - to say what the shape
42:48 - can look should look like and then we've
42:50 - kind of proven
42:51 - what that shape actually looks like by
42:53 - taking the samples
42:55 - and what i've done here is
42:58 - i've drawn a normal distribution that
43:00 - has a mean
43:01 - that's equal to the population mean and
43:04 - a standard deviation
43:05 - that's equal to the population standard
43:08 - deviation
43:09 - divided by the
43:12 - square root of the sample size that's
43:15 - what this
43:16 - um double times sign means
43:19 - to 0.5 so taking something to the 0.5
43:22 - power is the same as taking the square
43:24 - root of it
43:25 - so 50 times times 0.5 is the square root
43:29 - of 50
43:30 - and then so this whole thing
43:34 - is standard deviation of the population
43:37 - divided by the square root
43:38 - of the sample size and we see it that if
43:40 - we take a normal distribution with those
43:43 - parameters
43:45 - again mathematical description of a
43:47 - curve
43:48 - it really perfectly matches up with what
43:51 - this
43:51 - this shape looks like and this piece
43:56 - the standard deviation of the population
43:58 - divided by the square root
43:59 - of the sample size this is what's called
44:02 - the
44:03 - standard error of
44:06 - the mean
44:09 - so um sophie uh you have a question from
44:12 - the chat which is asking
44:13 - which part of the like code you made was
44:17 - like the actual normal distribution
44:19 - was the actual normal distribution
44:20 - perfect i should have commented this out
44:23 - so this part
44:26 - here i'm just plotting
44:29 - the sample means
44:32 - this part here is where
44:37 - i'm plotting
44:42 - the normal distribution on top of it
44:47 - great awesome so
44:51 - yeah i think this i mean we're gonna run
44:54 - out of time for all the things i want to
44:56 - cover today but i do think like
44:58 - just taking a second to stop and look at
45:00 - this picture
45:01 - makes me just really happy it's really
45:03 - really beautiful
45:04 - because we've statisticians have like
45:09 - it seems like almost magically figured
45:11 - out these crazy formulas
45:13 - to describe things that seem
45:17 - i don't know hard to describe and
45:20 - um and it's really cool that that we can
45:24 - that we can quantify our uncertainty in
45:27 - this
45:27 - way okay so
45:31 - again coming back to the standard error
45:33 - piece so the standard error
45:35 - again is the standard deviation
45:39 - of this sampling distribution
45:42 - it's basically a measure of how wide is
45:46 - the sampling distribution
45:47 - and the sampling distribution again
45:51 - because i i feel like no matter how many
45:53 - times i
45:54 - i heard this when i was first learning
45:56 - it it like took maybe a hundred times of
45:58 - hearing this before
46:00 - it clicked in my brain um
46:04 - the sampling distribution we got from
46:05 - taking samples of
46:07 - the same size calculating the mean for
46:10 - each one
46:10 - and then plotting the distribution of
46:12 - the means
46:14 - the standard error is how is a
46:17 - description of how wide that
46:19 - distribution is
46:22 - okay all right so we've we've made it
46:26 - pretty far we've gotten some interesting
46:27 - things
46:28 - already out on the table now
46:32 - so we were in all powerful mode we made
46:34 - this distribution
46:36 - we saw what it looked like we proved to
46:38 - ourselves that
46:39 - the central limit theorem works um i
46:42 - don't even think i said what the central
46:43 - limit theorem
46:44 - is but we just proved it basically um
46:47 - without even using any math which is
46:49 - super cool
46:50 - the central limit theorem just says that
46:52 - this distribution is normal
46:54 - and that the mean normally distributed
46:56 - so it follows the shape
46:57 - the mean is the same as the population
47:00 - mean and the standard deviation
47:02 - is equal to the population standard
47:05 - deviation
47:06 - divided by the square root of the sample
47:08 - size that's the whole central limit
47:10 - theorem
47:11 - um you could do it with math or you
47:14 - could do it by actually taking all those
47:15 - samples and calculating the mean of each
47:17 - one
47:19 - okay so now let's go back for a moment
47:22 - to the perspective of the researcher so
47:25 - like
47:26 - all right back in researcher mode
47:31 - i should have put these in the final
47:34 - code
47:35 - would have been helpful uh okay so we're
47:37 - back in researcher mode and now
47:39 - we're not all powerful anymore we can't
47:41 - actually see what this distribution
47:44 - or we can't actually see the whole
47:45 - population so we can't take
47:47 - samples from the whole population and
47:49 - see what the distribution looks like
47:52 - but now that we have the central limit
47:54 - theorem
47:55 - we actually kind of can see what it
47:57 - looks like
47:58 - or we can approximate what it looks like
48:01 - so remember the things that we needed to
48:04 - plot that black line
48:07 - so to plot the blue histogram we needed
48:10 - to take samples from the full population
48:12 - but to get the black line all we needed
48:15 - to know
48:16 - was the mean of the population and
48:20 - the standard deviation of the population
48:22 - and the sample size
48:25 - other than that we didn't need any more
48:27 - information
48:29 - so we can approximate this
48:33 - if we have an estimate of the population
48:36 - mean
48:37 - and of the standard deviation of the
48:40 - population
48:42 - and we're going to get those things from
48:44 - our sample
48:45 - they're not going to be perfect we don't
48:48 - right we don't know what the population
48:50 - mean
48:50 - is anyway we're trying to estimate it um
48:54 - the sample standard deviation like i
48:56 - said it's going to be an
48:57 - unbiased estimator of the population
48:59 - mean
49:00 - if we calculate it with that n minus 1
49:02 - on the denominator which we will
49:05 - but it's not going to be perfect we can
49:07 - still do it though
49:08 - so let's go back uh i'm
49:11 - again going to print
49:15 - the mean for
49:18 - our sample i think we still have a
49:20 - sample sample one
49:22 - somewhere in our or what did i call it
49:30 - let's see yeah we called it stamp one we
49:33 - still have a sample in here somewhere
49:35 - let's actually let's like
49:39 - calculate a new one oh that was a good
49:42 - one
49:43 - it was low okay
49:46 - okay so we have a sample let's calculate
49:49 - also
49:49 - the standard deviation of that sample
49:54 - and i'm going to save those things
49:56 - sample mean
49:58 - equals and populate or sorry
50:02 - sample standard deviation
50:06 - and we'll print them
50:17 - and we see okay so the the sample mean
50:21 - is equal to 16.33
50:26 - the population or sorry the sample
50:29 - standard deviation was 13.21
50:32 - um okay all powerful mode for a second
50:35 - let's remind ourselves of what these
50:37 - values
50:39 - r for the population so um
50:42 - print see v dot
50:45 - mean of population
50:47 - [Music]
50:48 - and also for standard deviation
50:55 - okay so what we notice here is that
51:00 - our sample that we took had less
51:03 - uh less variation than the population
51:06 - so the sample standard deviation was
51:09 - 13.2
51:10 - the population standard deviation was
51:12 - 18.1
51:14 - um so we're gonna under
51:17 - estimate the amount of variation in the
51:20 - sample
51:21 - the larger the sample we take the better
51:24 - of an approximation we're going to get
51:25 - here
51:27 - but we're going to work with it because
51:29 - it gives us at least some sense
51:32 - back to researcher mode
51:35 - so as the researcher we're now going to
51:39 - estimate what
51:42 - this distribution looks like
51:45 - so i'm actually going to grab
51:48 - this exact same code
51:52 - but now we're going to do this with
51:56 - the um
51:59 - we're going to do this with the sam
52:03 - just the information from the sample so
52:05 - we have our sample mean we have our
52:06 - sample standard deviation
52:08 - we're going to use a mu which is really
52:11 - just the mean of this normal
52:13 - distribution
52:14 - of the sample mean
52:18 - and we're going to use the
52:23 - sample standard deviation here
52:26 - and i believe that that sample had a
52:30 - was a size 150 but we'll just do one
52:35 - sample one that will tell us how many
52:37 - values are in there
52:39 - um or even i think
52:42 - even clearer is to say sample size
52:45 - equals
52:46 - that so we're really clear and then
52:49 - we'll put sample size in this equation
52:53 - and if we plot this we get this
52:56 - this curve um it's going gonna be i
52:59 - should
53:00 - maybe plot it on top of this so it's
53:02 - gonna be more s
53:04 - um or actually maybe
53:07 - less spread out than
53:12 - this
53:18 - it's going to be a little bit off from
53:22 - what it should be uh
53:27 - that's more off than i thought it would
53:29 - be
53:31 - or it's smaller oh oh oh it's because
53:34 - this was a sample size of 50.
53:37 - sorry ignore that uh
53:40 - let's redo this i guess with a sample
53:42 - size of
53:43 - 150.
53:52 - i know we're gonna run out of time but
53:56 - now this will right so this
54:00 - is our estimation of
54:03 - this is a little bit off pretty much
54:06 - because this this estimate was so off
54:10 - but what we can do is now use this
54:13 - distribution
54:14 - to try to estimate the plausible range
54:19 - of what values we might get
54:22 - if we could observe the entire
54:24 - population
54:25 - and take samples from it so
54:29 - the the reason why these two
54:31 - distributions are offset from each other
54:33 - is because this one we centered at the
54:35 - popul
54:36 - or the sample standard deviation this
54:38 - one we sent centered at the population
54:40 - standard
54:41 - sorry at the sample mean for this one at
54:44 - the population
54:45 - mean for this one so they they're off
54:48 - from that
54:48 - but the width of it is the part that we
54:51 - really care about
54:52 - and even though we were pretty far off
54:54 - on our sample standard deviation
54:56 - compared to the population
54:57 - standard deviation this
55:01 - the width of this distribution is pretty
55:04 - close to the width
55:05 - of what we would find if we were
55:09 - able to like be all powerful and see
55:12 - and take samples from everybody and so
55:16 - what we end up doing is we end up using
55:18 - this
55:19 - this distribution here to figure out or
55:23 - a plausible range that the population
55:25 - mean might be in
55:27 - and so we end up saying that the
55:29 - population mean is somewhere between
55:31 - like we think
55:34 - 12 and 20 or
55:37 - whatever like these points are and we
55:40 - can
55:41 - we can choose percentile so we could do
55:43 - like the
55:45 - second percentile and the 98th
55:46 - percentile to cut off
55:48 - kind of the tails of this but that's
55:50 - really all that a 95
55:52 - confidence interval is and i can demo
55:55 - that super fast i know we're running out
55:57 - of time
55:58 - um but i also know
56:02 - that this is a super complicated uh
56:06 - a super super complicated process
56:09 - and like exp mind experiment
56:13 - so i think it's nice if we kind of stop
56:15 - here and
56:17 - get like three more minutes to talk
56:20 - about it a little bit
56:22 - so here we go all i'm doing here
56:25 - is i'm taking i'm trying to find like
56:27 - the 2.5th
56:28 - percentile and the 97.5th percentile of
56:32 - this black
56:33 - line um
56:39 - oops let's put stamp one here
56:45 - and i save this as standard error
56:51 - i saved it as sigma
57:01 - so this goes from roughly 14.22
57:06 - to 18.45 and so if we were the
57:10 - researcher
57:11 - we would say our sample mean
57:14 - was 16.33 but we are
57:18 - 95 confident that
57:21 - the true population mean is somewhere
57:23 - between
57:24 - 14.2 and 18.45
57:28 - which is accurate although it is really
57:31 - close to
57:32 - that upper bound which was you know
57:35 - a random fluke and that happens but this
57:37 - is the way that statisticians and data
57:40 - scientists
57:42 - use the central limit theorem to try to
57:45 - quantify their uncertainty
57:46 - about a sample mean without having
57:50 - been able to see the entire population
57:53 - cool
57:55 - so i'm gonna stop there we've got two
57:57 - minutes to spare
57:58 - jamie what do you think would be a good
58:01 - use of this time do you think
58:03 - there's anything that's worth like
58:05 - talking about i hadn't
58:08 - had a a good eye on the stream or on the
58:11 - chat were there any questions that came
58:13 - up i think we
58:14 - covered all the questions wait one thing
58:16 - i'm curious about what was the actual
58:18 - population mean because i'm wondering if
58:20 - it was actually within the 95
58:22 - the population mean was 18.84
58:26 - about 839. okay and so it was like
58:30 - just just barely yeah but it wasn't
58:33 - in that range we could kind of do this
58:36 - with
58:37 - another sample like if we
58:41 - i wish i organized my code better
58:45 - but uh it's
58:48 - organized better in the final version
58:50 - that
58:51 - is available on github but if i take
58:53 - another sample
58:55 - here let's find one that seems like
58:58 - similar to the population
59:00 - yeah that seems more similar to the
59:01 - population
59:03 - if we use a different sample
59:07 - where these things yeah so here this one
59:11 - we got a little bit closer in terms of
59:14 - standard error
59:15 - and pop and mean like our sample was
59:19 - more similar to the population
59:21 - and then that will give us
59:25 - a
59:29 - slightly
59:32 - yeah uh a confidence interval
59:36 - that makes that more comfortably
59:40 - includes the population mean um
59:43 - so again like the i think the
59:46 - thing that i had trouble conceptualizing
59:50 - for a really long time is that the
59:53 - central limit theorem tells us something
59:55 - about
59:56 - the shape of this black line but it
59:59 - can't really
60:00 - tell us we still have to make
60:03 - a leap there because we still don't know
60:05 - what the population standard deviation
60:07 - is
60:08 - we still have to estimate the population
60:09 - standard deviation
60:11 - using our sample and so it's not
60:14 - like totally magic that we can just
60:16 - recreate
60:17 - exactly this but we can get a pretty
60:21 - good read on at least how
60:23 - how much variation we can expect and i
60:26 - think
60:26 - that's that is the the true power um
60:29 - and i i encourage so there's um on
60:32 - codecademy
60:33 - there is a article on the central limit
60:35 - theorem that kind of walks through this
60:37 - again
60:37 - and so if you watch this series and
60:41 - you still feel a little confused or you
60:43 - still want to like
60:45 - go back and confirm your understanding i
60:48 - highly recommend that you read that
60:49 - article or
60:50 - look up on the internet central limit
60:52 - theorem and and read about it because i
60:54 - think
60:54 - this is one of those things it's like
60:56 - it's deceptively simple and also really
60:59 - deep
61:00 - and uh and
61:03 - i think even for me i learned it about
61:05 - like i said like a hundred times before
61:07 - i actually learned it so
61:10 - all right next week we're going to jump
61:13 - into
61:13 - actually using this central limit
61:15 - theorem to run
61:16 - some hypothesis tests and we're going to
61:19 - learn even more about how hypothesis
61:22 - tests work
61:23 - so i'm really excited for that um but
61:26 - otherwise
61:27 - uh thank you kevin for for that question
61:31 - kevin says i have a question why are
61:33 - there only so few people watching this
61:35 - is pure quality
61:37 - thank you i agree i well i don't know
61:40 - about quality but
61:42 - i'm having a lot of fun doing these and
61:44 - hopefully more people will find them
61:45 - after the fact
61:47 - but for those that are here you get the
61:49 - extra benefit of being able to
61:52 - ask questions and really speak with us
61:55 - personally so please take advantage
61:58 - all right with that i think we'll sign
62:01 - off
62:01 - everyone have a great rest of your
62:03 - tuesday and
62:05 - we hope that these are helpful
62:09 - goodbye