00:01 - hi there my name is Michelle McSweeney
00:03 - and I am the domain manager for the data
00:05 - science domain here at code academy
00:07 - today in celebration of national coding
00:10 - week I'm going to take you through a
00:12 - project that you could put into a data
00:15 - science portfolio so if you are
00:17 - following along with us for the other
00:19 - two live streams this week
00:21 - um you saw benstone go through how to
00:24 - make a portfolio using HTML CSS and
00:27 - JavaScript that's fantastic but now you
00:30 - might be wondering what do I put in that
00:32 - portfolio you might already know that a
00:35 - portfolio is Far and Away the most
00:38 - important way that you can show
00:41 - employers what skills you actually have
00:45 - um so we're going to walk through some
00:47 - types of things and an example of
00:49 - something that you could put into a
00:50 - portfolio ideally
00:53 - um you would want to be thinking about
00:55 - your portfolio keeping in mind what
00:58 - types of roles you want to fill so let's
01:03 - say you are someone who's really
01:05 - interested in answering answering and
01:07 - asking and answering questions with data
01:10 - right if you're like I just want to know
01:12 - what's there I want to get to the root
01:14 - of it I want to be able to tell people
01:15 - what is going on and what they should
01:18 - use in order to make data-driven
01:19 - decisions then your portfolio should
01:21 - file should focus on answering analytics
01:24 - questions if however you're like I
01:27 - really want to do Predictive Analytics
01:28 - I'm super excited about machine learning
01:30 - and using data to help guide
01:33 - companies and organizations around what
01:35 - they should do based on what happened
01:37 - before you sh your portfolio should be
01:40 - focused on machine learning right if
01:43 - however you're really curious about
01:45 - testing hypotheses and like figuring out
01:47 - why things happened then your portfolio
01:49 - should focus on a b testing and causal
01:52 - inference right so thinking about that
01:55 - one thing that across the board everyone
01:59 - who wants to work with data should have
02:01 - in their portfolio is data cleaning and
02:03 - exploratory data analysis everyone needs
02:06 - to be able to do that it should always
02:08 - be there and having that'll naturally be
02:11 - baked into bigger projects that you do
02:13 - but having a standalone project that
02:16 - shows that you can explore a data set
02:18 - and figure out which variables you
02:19 - should focus on to begin with that is
02:22 - going to set you up for Success so
02:24 - that's the kind of project that we're
02:25 - going to work on today we're going to do
02:27 - an exploratory data analysis of NBA
02:30 - Trends right so NBA the National
02:32 - Basketball Association is an American
02:34 - organization focused on basketball
02:37 - obviously
02:39 - um and we're going to look at how a
02:41 - couple of teams have performed
02:44 - what their outcomes are in relationship
02:47 - to whether they're playing at home or
02:49 - whether they're playing away and finally
02:52 - we're going to look at um how we can
02:56 - compare variables and if we should look
02:58 - deeper at a couple of different
02:59 - variables all right so without further
03:01 - Ado let's dive in and look at this
03:04 - project all right so I'm going to share
03:07 - my screen this is a project that's in
03:10 - our exploratory data analysis course
03:13 - it's in our data scientist from data
03:16 - science fundamentals skill path it's in
03:18 - a lot of
03:20 - um really key like foundational concepts
03:22 - for data science
03:24 - um so so this data was originally
03:27 - sourced from 538's analysis of the
03:30 - complete history of the NBA 538 is a
03:33 - statistics journalism
03:35 - organization that does a lot of work on
03:38 - specifically Sports and politics they
03:41 - cover Science and Arts and a lot of
03:42 - other topics but they focus mostly on
03:44 - Sports and politics that's where both
03:47 - hypothesis testing and Predictive
03:49 - Analytics come in handy no matter what
03:51 - they have to figure out what variables
03:53 - they want to work with so without so
03:55 - we're going to dive in and see how they
03:57 - might do something like that okay so we
04:01 - are going to work with their data set
04:02 - you can learn a lot more about the data
04:04 - set here in this data set that they've
04:07 - created they've put in a forecast
04:09 - prediction so they've already created
04:11 - their own proprietary internal algorithm
04:14 - to figure out who who might win a match
04:18 - right so this is their work we're going
04:21 - to test whether their work uh
04:25 - um pans out or not okay
04:27 - so first thing that we're going to do
04:29 - whenever we're working with data is
04:31 - we're going to import numpy and pandas
04:33 - you might see as NP and as PD these are
04:36 - what we call aliases
04:38 - oh no I lost my connection anyhow an
04:41 - alias is because programmers are lazy I
04:44 - don't want to type out the entire word
04:46 - pandas I want to type out just PD
04:49 - um so every time I'm calling something
04:50 - I'm just going to write PD rather than
04:51 - the whole word
04:52 - so that's what these these aliases do
04:55 - for us anytime you're working with data
04:57 - you're going to want to have numpy and
04:59 - you're going to want to have pandas
05:00 - because there's incredibly powerful
05:04 - um tools within both of them to work
05:07 - with what we call a data frame
05:09 - so as you are diving into your first
05:13 - data science projects you're going to
05:14 - see data frames come up a lot it's
05:17 - really a special way to organize a data
05:21 - set um and it's a special way that
05:22 - pandas stores a data set it looks a lot
05:25 - like a table it's actually what you're
05:27 - seeing right here
05:28 - um so I have some specific features that
05:30 - we're not going to dive in too much here
05:32 - but I do encourage you to take our
05:34 - pandas course if you want to learn a lot
05:35 - more about those features anyhow okay so
05:39 - we are also going to import the Pearsons
05:41 - R which we're going to use to test the
05:43 - association and a chai square
05:45 - contingency oftentimes you wouldn't
05:48 - import these until much later in your
05:50 - code because you wouldn't necessarily
05:51 - know that that's what you're going to
05:53 - want to use but we know it early on so
05:55 - we're importing it right up at the top
05:57 - the other thing we're going to work with
05:58 - is Matt plotlin because we want to make
06:00 - some plots and Seabourn because we want
06:03 - to make some nicer plots
06:05 - finally we have this import code academy
06:07 - lib3 you don't have to worry about that
06:09 - if you're doing this project off
06:10 - platform because that is a package that
06:14 - just helps translate when we're within
06:16 - the code code academy environment
06:19 - um finally I've set these print options
06:21 - that just tells
06:23 - um
06:24 - how that just tells my code how I want
06:27 - to see these things output
06:29 - um
06:30 - okay so we have here in our files this
06:35 - NBA games CS feed we have actually
06:39 - shortened that file so that everything
06:41 - runs a little bit faster and we've only
06:43 - included five teams um there's only a
06:46 - few years worth of data in it okay
06:49 - so we've loaded this in for you
06:53 - um set this we've loaded in this CSV as
06:58 - a data frame and we've called that data
07:00 - frame NBA
07:02 - so the first thing that we're going to
07:04 - do is we're going to separate out just
07:06 - 2010 and just 2014. we're looking at
07:09 - these two years strategically to be
07:12 - completely transparent
07:13 - um because they illustrate some things
07:15 - that we really want to be able to talk
07:16 - about within this project okay so the
07:19 - way that I am subsetting for 2010 is I'm
07:22 - making a brand new data frame I'm
07:25 - calling that new data frame NBA 2010 and
07:28 - that's just for me so I know that it's
07:29 - the 2010 data and I'm saying take this
07:33 - entire data frame and find only where
07:36 - the year of the data frame is equal to
07:39 - 2010 okay so it says take this column
07:43 - year ID
07:44 - and find only 2010.
07:46 - right but give me back all of The
07:49 - Columns of the data frame
07:51 - just filter for these rows
07:54 - I did the same thing here for 2014. I
07:57 - said give me the whole data frame but
07:59 - only the rows where the year is equal to
08:02 - 2014. okay and then I'm going to look at
08:05 - the head of both of these I save that
08:08 - and what I see here is our data frame
08:12 - now let's take a quick look and see how
08:14 - this data is organized just to give us a
08:16 - mental model to go forward okay so we
08:18 - have an ID a unique identifier we have a
08:21 - unique identifier for the game
08:24 - um this looks like it's probably a
08:26 - concatenation of a lot of different
08:28 - things but this is probably unique and
08:31 - it's going to tell me
08:33 - um exactly what game that is
08:35 - I have the gear we already use that to
08:38 - filter for only 2010.
08:40 - I have franchise ID so this looks to me
08:44 - like the name of the team
08:47 - and interestingly we have opponent
08:50 - franchise so that is who they were
08:52 - playing
08:53 - this tells me that everything is going
08:56 - to be in relationship to this franchise
08:59 - ID
09:00 - it doesn't necessarily mean that that
09:02 - was the home team or the away team just
09:05 - that
09:06 - this is who everything else is in
09:09 - relationship to okay so we have the
09:11 - franchise ID here is Celtics and they
09:14 - were playing the Cavaliers and it was a
09:16 - way so it was a way for the Celtics we
09:20 - can assume usually that that means it
09:23 - was home for Cavaliers but not always
09:25 - right so it doesn't necessarily mean
09:28 - that the Cavaliers were playing in their
09:30 - home stadium
09:32 - um it just means that it was downloaded
09:34 - away for the Celtics is it a playoffs
09:37 - game no
09:38 - the Celtics scored 95 the opponent
09:43 - scored 89. so here we're like okay we
09:47 - actually are centering this around the
09:49 - Celtics the Cavaliers are secondary the
09:52 - Cavaliers are just the opponents and
09:54 - they scored 89 points it was a win for
09:57 - the Celtics
09:58 - um 538 had forecasted as about 28 chance
10:03 - of winning and it looks like there was a
10:05 - six point difference okay so it looks
10:08 - like both of our data frames are
10:11 - organized the same way as they should be
10:13 - since they're coming from the same
10:14 - original data frame
10:16 - so that's just a good mental model for
10:18 - us to have all right so now suppose that
10:22 - we want to compare the Knicks to the
10:24 - Nets we're in New York we're like okay I
10:26 - want to know about the Knicks and the
10:27 - Nets everybody who's local
10:29 - um with respect to points earned per
10:31 - game so we're going to use the points
10:34 - column from our 2010 data frame to
10:38 - create NYX points 2010
10:41 - and Nets points 2010. okay so I am going
10:46 - to
10:48 - actually
10:51 - I pre-wrote the code
10:53 - um an important thing to do whenever
10:55 - you're teaching something live pre-write
10:56 - your code you don't want to see me make
10:58 - typos it's not fun okay so we have NYX
11:01 - points 10 we have our NBA 2010 data
11:04 - frame that's the one we made up here
11:06 - that's filtered just for 2010
11:09 - and I have only where the Knicks
11:13 - are the franchise and I only want the
11:16 - points column
11:18 - so I did the same thing I did up there
11:20 - but I'm saying only the points column
11:23 - and I'm going to do the same thing for
11:25 - the Nets right so I say
11:29 - NBA 2010
11:32 - only where the franchise ID is equal to
11:34 - the Nets so I want only those rows where
11:37 - the franchise is the Nets I want the
11:39 - whole data frame but now I say at the
11:42 - end to give me only the points column
11:43 - right so if we work this from the inside
11:45 - out we say only those rows and then on
11:48 - the outside we say give me everything oh
11:51 - I changed my mind just give me the
11:52 - points right
11:54 - I'm going to back up just a little bit
11:56 - and point out something that is really
11:58 - common that I forgot to go over before
11:59 - okay
12:00 - so here I've written this code about the
12:04 - 2010
12:05 - um filtering for 2010 and 2014 two
12:08 - different ways so I could show you the
12:10 - two ways to filter your columns
12:13 - so very commonly you'll see us use dot
12:17 - um
12:18 - notation this means that I take the data
12:21 - frame and I put a dot here and then I
12:23 - specify which column
12:25 - there's a second way that you're gonna
12:27 - see and it's super common and it took me
12:28 - a really long time to figure out why
12:30 - things were written two ways the reason
12:33 - why there's two options is that this is
12:36 - short and I am lazy
12:38 - this if rather than having year
12:41 - underscore ID we had your space ID we
12:44 - wouldn't be able to use dot notation
12:46 - because there'd be a space here so that
12:47 - would create a mess right
12:50 - if there was a space here I could still
12:52 - use what's called bracket notation
12:55 - because I put the I put the name of the
12:58 - column in quotes
12:59 - and then I put a bracket to say give me
13:02 - this column from this data pane
13:05 - so what that means is that
13:09 - this
13:11 - is exactly the same as this
13:15 - the reason there's two is to account for
13:18 - when you might have a space in your
13:20 - column name okay cool all right so we've
13:23 - done that here and we've gotten our next
13:24 - points and our Nets points I'm going to
13:26 - save it
13:28 - and I'm going to check off that task and
13:30 - say I'm done okay
13:32 - so now I might want to know what the
13:34 - difference is between the mean points of
13:38 - the mix and the mean points of the Nets
13:40 - in 2010 right on average what's the
13:44 - difference right so I have the mean of
13:49 - this NYX points 10
13:52 - which is this series that we created a
13:55 - series is just a one column data frame
13:57 - or one column of a data frame
14:00 - and then I have
14:02 - and then I'm saying give me the mean
14:04 - calculate what the average is
14:07 - same thing with the next points I have
14:09 - the series I want to calculate the mean
14:11 - and then I want to take subtract them
14:13 - and find the difference
14:15 - I'm going to print that and it looks
14:18 - like I have 9.73
14:21 - based on this do you think that the
14:25 - franchise
14:27 - and the number of points are associated
14:32 - maybe there might be something to that
14:34 - okay
14:36 - um but maybe not I actually don't have
14:39 - enough information to figure that out so
14:41 - I'm going to move on to the next okay
14:44 - rather than comparing means it can be
14:47 - very useful to look at the full
14:49 - distribution
14:50 - um to understand whether a difference in
14:52 - means is Meaningful
14:55 - like
14:57 - whatever that wasn't is the difference
15:00 - in means meaningful
15:02 - um so we're going to create a set of
15:03 - overlapping histograms that can be used
15:06 - to compare the points scored
15:08 - for the Knicks to the points scored for
15:10 - the Nets okay so we're going to use the
15:13 - series that we already created so this
15:15 - NYX points 10 series that's that one
15:18 - column data frame the Nets points 10
15:20 - series one column and we're going to
15:24 - plot them against each other
15:26 - so
15:28 - let's go through here and talk about
15:31 - this code
15:33 - so I'm going to use matte platlin and
15:35 - I'm going to call the histogram function
15:36 - so it's going to give me a histogram I'm
15:38 - going to say take the Nyx from 2010
15:41 - that's going to be the data that I want
15:43 - you to plot use on the y-axis
15:46 - the alpha is going to be 0.8 that just
15:49 - means how see-through it's going to be
15:50 - so I want it to be a little bit
15:51 - see-through so I can compare them
15:54 - normed is true so we're going to assume
15:56 - this
15:58 - um
16:00 - on a normal distribution
16:02 - and then call give it a label of the
16:05 - next
16:06 - I'm going to do the exact same thing for
16:08 - the Nets but give it the label of the
16:09 - Nets I'm going to tell it to give me a
16:11 - legend give me a title of 2010 and then
16:14 - show yourself
16:16 - so I'm going to plot that and then take
16:19 - a look over here and see what we got all
16:22 - right so
16:24 - I'm seeing that the Knicks and the Nets
16:27 - have a lot of not overlapping space the
16:31 - not overlapping space is clustered at
16:34 - two different ends so I'm going to
16:37 - assume that their points are not
16:41 - associated and that the Knicks the fact
16:44 - that they are different teams that is
16:46 - what has the association that there's a
16:48 - relationship there okay so
16:52 - I've I'm gonna check that one off now we
16:56 - want to compare the 2010 games to 2014.
16:58 - Okay so we've done enough in comparing
17:00 - the Knicks and the Nets now we're going
17:01 - to compare 2010 to 2014.
17:04 - okay
17:06 - so
17:07 - I'm gonna say I'm gonna do all
17:10 - everything that I just did but I'm gonna
17:12 - do it for the 2014. so I have here my
17:15 - 2014 season
17:16 - I'm going to call just the Nyx and just
17:21 - the points column
17:22 - 2014 season just the Nets just the
17:25 - points column I'm going to compare their
17:27 - means
17:30 - and then I'm going to plot it
17:35 - one thing I'm going to back up really
17:37 - quick I'm going to add this
17:40 - plt.clf this clears the space so if your
17:44 - plots are ever appearing on top of each
17:46 - other you probably just need to call PLT
17:47 - clf and
17:50 - um make a new canvas okay so go ahead
17:53 - and plot that and we see very different
17:56 - distributions between 2010 and 2014
17:59 - right
18:00 - so in 2010 there is
18:04 - clearly not an association between these
18:07 - two teams in 2014 it's clear that
18:10 - they're a lot closer they're performing
18:12 - a lot more similarly to each other
18:15 - okay
18:16 - so
18:19 - for the remainder of the project we are
18:21 - just going to focus on 2010 right so
18:24 - we're like okay what is going on in 2010
18:26 - the Knicks and the Nets are you know
18:28 - they're both New York teams but they're
18:30 - performing super super differently
18:32 - um so we want to understand that a
18:33 - little bit better okay so for 2010 we're
18:38 - going to generate side-by-side box plots
18:41 - for all five of our teams to understand
18:44 - if there's a relationship between them
18:47 - okay so I'm going to clear my field
18:48 - I'm going to use the Seaborn Library I'm
18:51 - going to call it box plot
18:53 - and I'm going to say just give me all of
18:55 - the 2010 data that entire NBA 2010 data
18:59 - frame
19:00 - on the x-axis put the franchise ID so
19:04 - along the bottom the franchise ID on the
19:07 - y-axis put how many points and then show
19:10 - yourself
19:12 - so I'll go ahead and save that
19:15 - and
19:17 - wow the Nets are really doing poorly
19:20 - compared to everyone else
19:22 - um so what we're looking at here is a
19:24 - box plot and what you see in the middle
19:26 - is the mean you see one quartile another
19:29 - quartile
19:30 - uh the lowest quartile the uppermost
19:33 - quartile and the outliers box plots are
19:36 - really great for showing the
19:37 - distribution especially when you care
19:39 - about outliers
19:41 - um so
19:42 - when there's a lot of overlap between
19:44 - different categories that means that
19:47 - there's likely an association when
19:49 - there's a something that isn't does not
19:52 - have a lot of overlap there is not
19:53 - likely an association so the Nets are
19:56 - performing way worse than everyone else
20:00 - so we're going to look at the
20:02 - relationship between these category
20:03 - variable categorical variables okay so
20:07 - we are we say okay maybe there's
20:10 - something to like wins and losses
20:12 - compared to home in a way
20:14 - right so maybe when teams are home they
20:18 - might win more games there's like a
20:20 - cheering effect you know like maybe that
20:23 - could help them out so let's
20:26 - go ahead and look at uh look at across
20:30 - tab
20:32 - so we want to understand if there are
20:37 - if there's a relationship between the
20:39 - game result and the game location is
20:42 - there an association between whether
20:44 - they win and lose and if it was home and
20:46 - away okay
20:48 - so let's go ahead and calculate that and
20:50 - a cross tab is a box
20:52 - of
20:54 - away and home losses and wins right so
20:58 - this is just number of times that they
20:59 - lost when they were away number of times
21:02 - they lost when they were home number of
21:03 - times they won when they were away and
21:06 - one when they were at home wow so it
21:09 - looks like they did actually win more
21:12 - times when they were at home
21:14 - it's not sure that there's a strong
21:16 - Association there but there is something
21:19 - that might be worth looking into okay
21:21 - but I'm looking at this and I'm like ah
21:24 - I don't really understand like the
21:27 - percentages right like I know that
21:29 - there's more losses when they're away
21:31 - then there are winds when they're away
21:33 - but like it's really hard for me to do
21:36 - that Mental Math I'd rather look at a
21:38 - table of proportions
21:39 - okay so I'm going to check this one off
21:42 - and I'm going to go next to make it a
21:44 - table of proportions
21:46 - and what is
21:48 - what I'm going to do here is actually
21:49 - quite clever
21:51 - so I'm going to take this table of
21:53 - results right and this was just the raw
21:55 - counts and I'm going to divide it by the
21:57 - entire length of the table
22:00 - right I'm going to divide it by the
22:01 - entire length of the data frame
22:03 - because what I'm saying is each one of
22:06 - these so to get a proportion
22:09 - sorry
22:11 - um I can take 133 and divide it by the
22:15 - sum of all of these the easiest way to
22:17 - get the sum of all these is actually
22:19 - just to take the length of the entire
22:21 - data frame so that's what we're doing
22:23 - right here
22:25 - okay
22:26 - so I'm going to run that
22:28 - and I get proportions now I can see that
22:32 - it's when teams are away they lose
22:36 - almost 30 percent of the time they only
22:39 - win a little over 20 percent of the time
22:42 - when they're home they win almost 27 of
22:46 - the time and lose about 23 of the time
22:49 - still it's really hard for me to eyeball
22:51 - that I'm not totally sure if there's an
22:53 - association yet I'm gonna mark this one
22:55 - complete and go to the next okay so this
22:58 - is where she uh chi-squared contingency
23:00 - test comes in chi-squared is a
23:04 - statistical test to determine if there's
23:06 - an association between categorical
23:07 - variables right what we're looking at
23:10 - are categorical variables away in home
23:12 - win and loss those are categories right
23:15 - unlike numeric variables or quantitative
23:18 - variables categorical variables are kind
23:21 - of like bins I put it into the away bin
23:24 - or the home bin the win bin or the lose
23:27 - bin
23:28 - usually these are described by words
23:30 - sometimes we even use numbers to
23:32 - describe categorical variables so for
23:35 - example
23:36 - let's say that you are talking about
23:38 - medals at the Olympics right and Simone
23:41 - biles to one of gold and a bronze you
23:44 - cannot average those and make a silver
23:47 - that's because metals or places in a
23:50 - race is a categorical variable even
23:52 - though it's represented by numbers right
23:55 - so
23:56 - if you're looking at places in a race or
23:58 - Olympic medals you would put it again
24:02 - um into a chi-square contingency
24:05 - um test okay so we are going to
24:11 - just use the chai square contingency
24:14 - test that we got out of the package
24:16 - above
24:17 - here it's going to tell us the
24:20 - chi-square value
24:21 - which is the strength of the association
24:24 - the p-value so the point out or the
24:27 - degree to which is statistically
24:28 - significant
24:30 - the degrees of freedom and what we would
24:32 - have expected if there was nothing
24:35 - um nothing out of the ordinary if our
24:37 - null hypothesis was true right okay so
24:40 - I'm going to call it on the frequency
24:43 - table not the proportions table why well
24:47 - the chi squares chi-square contingency
24:51 - test is expecting raw numbers it is
24:55 - going to do the proportions behind the
24:57 - scenes unlike me as a human this test is
25:01 - not trying to do any Mental Math right
25:04 - so it is expecting you to give it the
25:06 - raw numbers not the proportions that
25:08 - might seem a little bit
25:09 - counter-intuitive but here we go all
25:11 - right so I'm going to go ahead and run
25:12 - that
25:15 - and what do I get all right I get my
25:19 - output down here
25:21 - it looks like my expected values would
25:24 - have been 119 119 so here losses would
25:27 - have been 119 119 and 106 106. that's
25:31 - not what we get at all
25:32 - the value of the Chi Squared is 6.5
25:38 - okay on its own that means basically
25:41 - nothing
25:42 - if you were going to use this test on
25:44 - your own you would look up what is
25:48 - um indicative of an association and you
25:51 - would find that it's around four so for
25:55 - a two by two Matrix about four is
25:57 - indicative of an association we're at
25:59 - 6.5 that is much larger awesome we
26:03 - probably have an association so what
26:06 - this tells us is that there's probably
26:08 - some relationship between winning and
26:10 - losing and being home or away
26:13 - that's interesting that tells us not
26:16 - necessarily that we should write a paper
26:18 - like you know tell every team to play
26:21 - their games at home but rather it tells
26:24 - us hey there's something here look a
26:26 - little bit more deeply right we haven't
26:28 - necessarily set this up as a hypothesis
26:31 - test but this is telling us hey explore
26:34 - the relationship between those variables
26:36 - because there might be something there
26:39 - okay so I'm going to mark that one off
26:41 - and go to the next one
26:43 - all right so
26:45 - cool we've looked at categorical
26:47 - variables now let's look at quantitative
26:49 - variables what new quantitative
26:51 - variables in this data set are
26:54 - interesting to us okay so I'm curious
26:57 - about this like forecasting that
27:01 - um 538 did and if there's some
27:03 - relationship between the number of
27:05 - points and the strength of that forecast
27:07 - right so if that forecast was like 0.68
27:10 - that's pretty close to 50 50. but if
27:13 - that forecast was like 0.9 that's way
27:17 - way more in favor or way more likely
27:19 - that the other team will win I'm curious
27:22 - if the strength of that forecast
27:25 - is then borne out by the number of
27:29 - points different that the teams were
27:31 - okay so that means that we're going to
27:33 - test the association between two new
27:37 - quantitative variables and use a
27:39 - different test this is why we imported
27:40 - Pearson's R we may have already already
27:42 - realized that okay so here I'm going to
27:47 - use
27:48 - um
27:49 - I'm going to use the forecast and the
27:52 - points different
27:54 - um
27:55 - columns and I'm going to look at the
27:57 - covariance which means literally do they
28:00 - vary together do they covariate covary
28:05 - um and we're going to call this our
28:07 - Point difference covariance so I'm going
28:09 - to use the numpy
28:11 - um
28:13 - function COV which stands for covariance
28:16 - and I'm going to look at the point
28:18 - difference column and I'm going to use
28:20 - the forecast column both from the MBA
28:22 - 2010 data set so all five teams NBA 2010
28:26 - looking at the covariance here and I'm
28:28 - going to print that out
28:31 - okay so if I'm looking at this Matrix
28:37 - um
28:38 - which is the margin of Victory and
28:40 - defeat
28:42 - do we think that there's going to be a
28:43 - covariance between these two variables
28:45 - well I do initially
28:50 - um
28:50 - because I'm seeing them
28:55 - um
28:56 - how do we say
28:57 - basically because this number is much
28:59 - much larger than all of the others okay
29:01 - now I'm going to actually I'm going to
29:03 - mark that one off and I'm going to test
29:05 - this statistic because it's one thing
29:07 - for me to eyeball it and it's another
29:09 - for me to use an actual
29:12 - um statistical test on it okay so here
29:15 - I'm going to calculate the Pearson's R
29:18 - um which is a way to test the
29:20 - association between two quantitative
29:22 - variables okay and the variables and we
29:25 - look at are the forecast and the point
29:27 - difference
29:28 - I'm going to run that
29:31 - and here I have it that
29:35 - the forecast is 0.44
29:40 - and
29:41 - the degree to which it is statistically
29:45 - significant is 9.4 to the negative 23rd
29:49 - this means to me that they definitely
29:51 - are
29:53 - um Associated that there's a very strong
29:56 - Association and it is slightly positive
29:59 - so zero would mean no association
30:04 - um and one would be a very strong
30:07 - positive Association so it looks like
30:10 - there is an association here
30:12 - um and the degree to which we are
30:14 - confident in that is very very high
30:17 - so
30:19 - um
30:19 - I'm going to mark that off but again
30:21 - it's still really hard for me to think
30:23 - through that or to visualize it so I'm
30:25 - going to generate a scatter plot
30:28 - um
30:28 - and that should give me a little bit
30:31 - more of a visual in the relationship
30:32 - between whether a team is home or away
30:34 - and whether they win or lose
30:39 - so we'll go ahead and plot that here
30:41 - we're using the matplotlib scatter plot
30:45 - on the x-axis we're putting the point
30:48 - difference on the y-axis we're putting
30:50 - the forecast and the data that we're
30:52 - using is the NBA 2010 data set
30:56 - um we'll label our x-axis forecast wind
30:59 - probability wait a minute
31:04 - this is these are flipped so sorry about
31:07 - that
31:09 - um
31:12 - so I'm going to move this one up here
31:14 - and move that down there
31:18 - I'm going to save it and
31:22 - oh I probably you see how I have these
31:25 - dots right here you know what that means
31:27 - it means that I did not clear my field
31:31 - up here so now I'll save it again
31:36 - and our box plot looks good again and
31:39 - our scatter plot looks good again okay
31:42 - so the forecasted wind probability
31:45 - um we have a couple of outliers here you
31:47 - know this one was highly forecasted to
31:50 - win and there was a huge Point
31:52 - differential
31:54 - um this one was you know kind of a mid
31:56 - but the point differential was really
31:59 - extreme to the um
32:01 - that the
32:03 - reference team lost
32:05 - um so there's some interesting features
32:08 - going on here it's not an obvious like
32:10 - straight line like we might have
32:11 - expected but this is what about a 0.5
32:17 - um correlation looks like it looks like
32:18 - there's a little bit of an association
32:20 - but it's not super super
32:22 - um strong it's not like they're all very
32:24 - close to this regression line
32:27 - okay so if you were to do a project like
32:30 - this you would then write up a summary
32:33 - um and publish it on something like your
32:35 - personal website or GitHub or something
32:38 - along those lines saying that yes we
32:41 - should look more deeply at the
32:42 - relationship between game result and
32:44 - game location and yes we should look
32:46 - more deeply about
32:48 - um home or away and wins and losses all
32:51 - right thank you so much for joining us
32:54 - on this journey and looking at this
32:56 - project with us
32:57 - um let us know down in the comments if
32:59 - you have any questions and we look
33:01 - forward to seeing you at our next live
33:03 - stream all right take care bye-bye
33:07 - foreign