00:01 - foreign
00:08 - hello hey everyone welcome back to this
00:12 - final live stream in our three-part
00:14 - journey through code Academy's Evolution
00:17 - today we're looking at one of our brand
00:19 - new courses intro to generative AI I'm
00:23 - Corey c code Academy's content marketing
00:25 - manager and I'm joined by Betty Garcia
00:27 - Lorca our community manager who you
00:30 - probably recognize from these live
00:31 - streams and forums and Discord as well
00:34 - as Adam Herman curriculum manager at
00:37 - code academy who will be walking us
00:39 - through this lesson and then over in the
00:41 - chat we have Alicia grama a senior
00:43 - curriculum developer who is on hand to
00:45 - answer all of your questions live
00:48 - so in case you haven't heard it's code
00:50 - Academy's birthday tomorrow we're
00:52 - turning 12 almost a teenager
00:56 - um the tech world has has changed a lot
00:58 - since we started out in 2011 and one of
01:02 - the biggest Transformations happened
01:03 - just last year when the research company
01:06 - opened AI launched the generative AI
01:08 - chatbot chat GPT and I'm curious how
01:11 - many of you here use Chachi BT to code
01:14 - or for work or just for fun let us know
01:17 - in the chat
01:18 - we recently launched a bunch of brand
01:21 - new AI courses and case studies that'll
01:24 - teach you how to use and build AI
01:26 - systems like these in a thoughtful
01:29 - responsible and inventive way uh but
01:33 - today Adam's going to show us how to
01:35 - make an original children's book with
01:38 - generative AI using our free beginner
01:41 - friendly course intro to generative AI
01:43 - as a guide this is a fun use for AI but
01:46 - it's also a very practical one if you
01:48 - say need some more bedtime stories in
01:51 - your rotation or you're a teacher of
01:53 - young children or you just need a clever
01:55 - gift idea for a kid in your life but
01:59 - keep in mind that you can go and take
02:01 - this course whenever you want on your
02:02 - own time and it's linked in the
02:03 - description below
02:05 - before we get into it let me tell you a
02:07 - little bit about Adam he started as a
02:10 - classroom teacher before moving in to
02:12 - Tech and now he's the curriculum manager
02:14 - at codecademy where he does strategy
02:16 - work for articles and code academy docs
02:19 - and has recently been working on
02:21 - producing new generative AI content for
02:24 - us hi Adam
02:26 - hey Corey hey
02:28 - I wanted to ask you a question before
02:30 - you jump into it
02:32 - um do you use generative AI Tools in
02:36 - your daily life and if so how
02:39 - that is a great question Corey so
02:42 - I think what's so interesting in general
02:44 - about like this moment with chair and of
02:46 - AI is that we are
02:48 - in kind of like a state of play with it
02:51 - of this is such a different cool
02:55 - interesting technology and we are still
02:59 - constantly finding new ways of
03:02 - integrating it both into our work lives
03:05 - and into our personal lives and
03:07 - something that was uh really drove this
03:10 - home for me was
03:12 - um like a month or two months ago I
03:16 - I am a fairly mediocre Chef
03:19 - um but I I try and I wanted to make a
03:24 - meat sauce and I was very intimidated so
03:28 - I went to Chachi BT and I said you know
03:31 - I'm a beginner level Chef I want to make
03:33 - a meat sauce I want to be this many
03:35 - servings what do I do and it spit out a
03:39 - whole recipe for me
03:41 - and the part where it got really really
03:44 - cool was I can then ask okay well how do
03:48 - I get oil out then or how do I chop the
03:51 - garlic pasta properly so you could keep
03:54 - digging in in a way that you don't get
03:57 - with things like a Search tool or other
03:59 - research tools
04:01 - and it is okay that's what I'm wanting
04:05 - to know surprisingly yes
04:07 - um there is a screenshot that thank you
04:10 - for asking um there's a screenshot of
04:11 - the recipe on my phone I'm very proud of
04:14 - it
04:15 - um so yes the the robot had good taste
04:19 - in food somehow
04:21 - love it thank you and that's the kind of
04:25 - thinking
04:27 - I think we're all working on and
04:28 - something I hope to encourage in all of
04:31 - you from today is not just what can
04:33 - these Technologies do it's how can they
04:35 - interact with each other how can they
04:37 - interact with our lives to change how we
04:40 - work and interact
04:43 - so go I'm going to share my screen with
04:45 - all of you
04:51 - and let's get into this course we'll be
04:54 - going through
04:59 - so the course is intro to generated Ai
05:02 - and
05:04 - as the name implies this is a
05:07 - introductory course going through
05:09 - different
05:11 - types of generative AI tooling and how
05:14 - people are using it we'll also be going
05:17 - into as Corey implied earlier
05:20 - how to use this technology responsibly
05:23 - and some of the interesting ethical
05:26 - conversations happening in this space
05:28 - right now
05:30 - I am not going to go too much into how
05:33 - to program with serendive AI we do have
05:35 - a lot of really great content around
05:37 - that that this is more for people
05:39 - looking to see what this technology is
05:43 - and how people are using it
05:50 - so why are we going to cover
05:52 - we're going to be doing an intro to the
05:55 - course and what it is
05:58 - I'll be going into this generative AI
06:02 - content workflow so I'll be showing you
06:04 - as I create this children's story how
06:07 - these different Technologies can be used
06:09 - together and what responsibilities we
06:12 - have as human users to make sure that
06:14 - the content is accurate and safe
06:18 - and as well as going into those ethical
06:21 - considerations I talked about before and
06:23 - then finally we're going to do a wrap up
06:25 - with some q a between myself and FedEx
06:31 - so over this you should be learning what
06:34 - generative AI is the different types of
06:37 - generative AI in their use cases and as
06:39 - I said before those ethical concerns and
06:42 - considerations
06:43 - so let's hop into the course so the
06:47 - course as I said is intro to generative
06:51 - AI
06:52 - and the author of this course Alicia
06:56 - grama is actually in the chat uh here
07:00 - today so she's here to answer any
07:03 - specific questions you may have about
07:06 - the course content
07:08 - so before anything else just what is
07:11 - generative AI
07:14 - um generative AI is
07:16 - a very Advanced learning uh model that
07:22 - uses that is trained on millions of
07:26 - different texts images uh code samples
07:30 - and what is more than anything is a
07:33 - synthesizer so it can take all of that
07:35 - information look for certain patterns
07:38 - and create an output
07:40 - system
07:42 - so to address the first thing is is it
07:45 - intelligent depends how you define
07:47 - intelligence uh a generative AI could
07:50 - not create something wholly new per se
07:54 - what it does is create
07:57 - an amalgamation
07:59 - of other things that have been input
08:01 - into it
08:02 - if you want to get philosophical about
08:04 - it that's everything that anyone makes
08:07 - is that but obviously it doesn't make it
08:10 - in a self-conscious way which is
08:12 - arguably where that
08:15 - intelligence happens but
08:19 - um whether or not it's AI it is really
08:21 - cool and very inventive and efficient in
08:25 - what it can do
08:27 - and what we're trying to figure out is
08:30 - at what point does the work that the AI
08:33 - can do end and human work begins and how
08:37 - I typically have learned to divide it
08:39 - there's a uh great book called range uh
08:44 - by an author named David Epstein and he
08:48 - talks about the difference between kind
08:51 - systems and wicked systems a kind system
08:54 - is something like uh chess it's
08:58 - something like uh maybe
09:01 - um
09:02 - certain types of legal work where
09:05 - it's happening within a very set system
09:08 - in which there are defined rules uh AI
09:12 - do very very well in kind system problem
09:16 - solving it's why AI
09:18 - um initially when I came onto the scene
09:20 - one of the most high profile things it
09:21 - could do was play chess
09:24 - uh humans are very good at Wicked
09:27 - problems they are good at high level
09:30 - strategy taking disparate pieces
09:32 - information and creating
09:35 - something cohesive out of it
09:37 - so throughout this I'll be showing you
09:39 - how to use AI to get to a point that you
09:43 - can begin as a human iterating on what
09:46 - you're using and making it something
09:47 - wholly better in original and suited to
09:50 - your purposes
09:52 - foreign
09:58 - so the first thing uh we'll be talking
10:00 - about is text-based generative AI this
10:03 - is probably the most famous or
10:06 - splashiest of the technologies that
10:09 - we've seen
10:10 - uh most famously chat gbt but there are
10:12 - also resources like bards that you can
10:15 - use I'll point out that within this
10:18 - course we have a fake GPT that uh we
10:21 - have a really brilliant interactive
10:24 - developer named Wesley on the team who
10:27 - made this for us and it simulates chat
10:29 - TBT right in our learning environment so
10:32 - I can click that and click play and it
10:35 - will generate an answer similar to in
10:38 - the chat TPT experience
10:41 - is right now the most famous but you
10:44 - also have other resources like bards
10:46 - produced by Google that are very popular
10:49 - I would say like anything else different
10:51 - tooling has different strengths and
10:53 - weaknesses uh chat gbt in my experience
10:57 - is a little bit more um quote unquote
10:59 - creative in one can come up with whereas
11:02 - Bard I think is stronger as a research
11:06 - tool in that it has built-in citations
11:08 - so it's August if you're in the southern
11:12 - state you've already started school if
11:15 - you're uh in New York where I live
11:18 - Schools starting up in a couple of weeks
11:20 - and then you're an educator may be
11:23 - thinking about how to use these
11:24 - Technologies in the classroom
11:27 - um that's a situation where I may
11:28 - recommend something like Bard and it's
11:30 - better citation unless you're doing
11:31 - something like a creative writing
11:33 - exercise which is what we'll be doing
11:36 - now actually
11:39 - so I'm going to take chat gbt and share
11:44 - that here and I want to create this
11:50 - children's story now
11:52 - on a personal note I am a uh proud Uncle
11:56 - of two uh five-year-old nephews they are
12:01 - entering first grades this year and
12:06 - like many five-year-old boys they love
12:09 - dinosaurs and they love jeeps and I I
12:12 - want to as a start of the school year
12:14 - gift make them a story
12:17 - so
12:19 - something I think is really cool about
12:21 - Chachi BT is if you're not sure where to
12:25 - get started with your prompts
12:27 - you can just ask it ask for a prompt so
12:31 - I'm going to open this up and I'm going
12:34 - to ask it for five prompts for a
12:36 - children's story about twin brothers who
12:39 - go on an adventure on the Dinosaur
12:40 - Island to be clear in terms of Dinosaur
12:43 - Island I'm thinking more
12:45 - um Savage lands from X-Men versus
12:49 - um you know the island in Jurassic Park
12:51 - I would not send a child to the island
12:52 - in Jurassic Park that would just be
12:54 - irresponsible but
12:56 - of those five prompts I asked for I
12:59 - asked for two prompts that would be
13:00 - funny
13:01 - two that would be scary and one that
13:05 - would be random this is a way of me
13:08 - engineering my prompt to see different
13:10 - options this is me leveraging what this
13:14 - generative AI can do versus me acting as
13:17 - myself in a brainstorming capacity
13:21 - so ask that to run and we can see some
13:25 - of these options come up
13:31 - and we have a dino race day Dino picnic
13:35 - party lost in a dark Roar of Doom love
13:38 - upon fantastic
13:40 - and Dino Dance Fusion uh We've also
13:44 - named the twins Max and Leo
13:49 - that's fun
13:51 - and
13:54 - I'm looking through and I think the
13:57 - picnic party
13:58 - sounds good so I'm going to start I'm
14:03 - going to copy this
14:05 - and paste it and we're going to continue
14:06 - but I'm also going to refine refine this
14:11 - prompt a little bit more
14:12 - so I'm going to type
14:15 - create a 1000 to 1500 word story
14:21 - about
14:24 - off of the following prompt
14:29 - and I'll click play
14:32 - Emma watched that story show up now
14:37 - this is where this um human AI
14:40 - relationship comes in I am not going to
14:43 - take this story and immediately read it
14:45 - to my nephews there may be things that
14:49 - are not age-appropriate there may be
14:51 - things that are nonsensical there may be
14:53 - things just that I know within my own
14:55 - personal taste I wouldn't want in the
14:58 - story so that's where I am going to go
15:00 - in and refine that process
15:05 - but
15:07 - just in the length of me giving that
15:08 - explanation this entire story was
15:12 - generated
15:14 - and I can copy it to this clipboard and
15:16 - paste it separately where I can continue
15:18 - to work on it
15:21 - so going back to the course
15:26 - we're going to talk a bit more now about
15:28 - image based generative AI so what I just
15:32 - showed you was chat and some of those
15:34 - different techniques for the prompting
15:37 - process within chat
15:39 - and
15:42 - now we're going to do image image very
15:43 - similar of whereas instead of being
15:46 - trained on text these sharing of AIS
15:49 - have been trained on images so different
15:52 - art styles schools
15:56 - um
15:57 - kind of considerations like that
16:00 - that allows to make some really cool
16:01 - stuff and it is technically text to
16:04 - image we are including text and getting
16:06 - an image back so generate a futuristic
16:09 - version of the Mona Lisa
16:11 - and we might get something like this
16:15 - now for the purposes of this live stream
16:17 - I'm going to be using uh Dolly too
16:21 - but I encourage you to look into other
16:24 - resources like mid-journey stable
16:26 - diffusion like I said with Google bard
16:29 - and chat gbt different tools have
16:33 - different strengths and weaknesses and I
16:35 - encourage you to explore that there are
16:37 - also more professional resources that
16:40 - you can pay for to use because this is
16:44 - based off of a free course I'll just be
16:46 - going through free or fairly inexpensive
16:50 - Resources with you today
16:53 - so I have uh Dolly up here and
17:00 - I'm uh as Corey mentioned at the
17:02 - beginning of the
17:04 - presentation of the live stream my
17:07 - background is as a history teacher and I
17:10 - am a dork for a good map love a map and
17:14 - I think that's something that would
17:16 - really enhance this story
17:18 - so I'm going to ask uh create a another
17:22 - create a map of a Dinosaur Island
17:28 - in the style of a 1600s
17:33 - nautical
17:35 - map
17:37 - when I say A nautical map I'm thinking
17:39 - of those
17:40 - you know kind of old school Maps where
17:43 - you have the dragon in the corner and
17:44 - you know there's sea monsters all over
17:48 - the place
17:49 - um and this is what we've gone in here
17:52 - are a few of these different options
17:55 - that we can click
17:58 - and go through
18:01 - and I have to say I kind of love this
18:04 - one I love the abstract shapes I like
18:07 - how there's this idea of signage but I'm
18:11 - also curious if we can drill down on
18:13 - just this format a little bit more
18:16 - so I'm going to click on variations
18:19 - and this is a way of continuing to
18:23 - prompt and guide this machine to give us
18:26 - an output that we want
18:29 - um
18:29 - ultimately generative AI is still a
18:32 - computer and computers want nothing more
18:36 - than to make us happy but we need to ask
18:39 - them for what we want correctly and this
18:42 - is an example of that the more specific
18:44 - and targeted are prompts the better the
18:47 - output is going to get
18:50 - and we have some more of these Maps more
18:54 - of this weathered style I actually like
18:56 - this one I like that there's kind of
18:59 - this foggy area around that that makes
19:01 - it feel much more serious
19:05 - and you'll notice here that I have the
19:07 - option to save this share it download it
19:11 - and it's from here I may move it into
19:15 - something like a Photoshop where I can
19:18 - continue to edit it and work on it and I
19:20 - think this will be a great cover or
19:23 - companion piece to our story
19:27 - so before I go to the next one I'm
19:30 - curious uh Fede or Corey are there any
19:33 - questions in the chat
19:40 - I'm taking a look uh seems like we are
19:43 - answering them as they come so we're
19:46 - good
19:47 - all right fantastic I'll just keep keep
19:50 - on keeping on them
19:55 - all right
19:58 - all right this is actually a really good
19:59 - thing to know so you'll notice that this
20:02 - hasn't loaded for me yet I can just go
20:05 - over here and say restore default
20:08 - workspace and that will allow me to see
20:11 - this applet again
20:13 - so the next thing we're going to be
20:14 - talking about is audio based generative
20:17 - AI this is something I think
20:20 - is both really cool and probably one of
20:23 - the most
20:24 - interestingly challenging gerund of AIT
20:28 - utilize compared to image and text
20:32 - so this is something that can be used in
20:34 - things like Music Creation audio
20:36 - creation
20:38 - um
20:39 - while we're getting into
20:41 - some of those ethical considerations
20:44 - think about how different artists have
20:47 - very distinct musical styles so if
20:50 - you're creating generative music are you
20:52 - allowed to say
20:54 - I want this to sound like a Bob Dylan
20:57 - song where that's an artist who has a
21:00 - very specific sound and feel to his
21:04 - music there was a really interesting
21:07 - case uh fairly recently of someone
21:09 - posting a song on Spotify that sounded
21:13 - like a Drake and the weekend song and it
21:16 - was entirely made through generative
21:17 - music
21:19 - where
21:20 - it's less ethically messy is if you're
21:25 - um a video editor if you are trying to
21:29 - maybe get started with mixing music and
21:31 - playing around with that yourself it's a
21:33 - great way of quickly creating a
21:37 - background track to take and then use as
21:39 - a base to work on
21:42 - so similar as this create a calming song
21:45 - and we have this recording here
21:48 - I was fortunate enough to
21:52 - get a
21:54 - um trial into music LM
21:58 - which is Google's
22:00 - attempt at getting started with gerund
22:04 - of music it's free and it's very fun to
22:07 - play around with so
22:11 - the reason why I said this was
22:13 - interestingly challenging is
22:15 - you know our our eyes are our primary
22:18 - sets right so we're very good at
22:21 - describing things we see and we're very
22:23 - good at communicating so for asking for
22:27 - a text or asking for an image we
22:29 - intuitively know how to be very exact in
22:32 - what we ask for
22:34 - I do not have a particularly strong
22:36 - background in music theory so I can't
22:40 - ask this program to be specific you know
22:43 - to ask for it to be in a certain chord
22:46 - or something like that
22:47 - I don't know how to do that but what I
22:50 - find really cool about this tool is that
22:51 - it can
22:53 - work within a certain mood so
22:56 - I had that up there before but I'm going
22:58 - to say a happy song
23:01 - um
23:02 - with an adventurous
23:06 - tune
23:07 - good for exploring a jungle
23:15 - and I'm going to see how it does with
23:18 - that
23:28 - it's going to give it a moment of
23:29 - looking
23:31 - [Music]
23:34 - and I actually like this quite a bit
23:38 - um
23:38 - I apologize I'm not sure if you're
23:42 - able to hear the audio on your end but
23:46 - it came in a really interesting way what
23:49 - I do find with the music LM is
23:51 - it can sound a little tinny which is
23:54 - really interesting to me I'm not sure
23:56 - why that is but again this is where you
23:59 - can take this download this track and go
24:02 - forward I'll also add that there's a
24:04 - really cool
24:05 - um rating system that they have this is
24:07 - how they're training their AI so for
24:10 - every prompt you actually get two song
24:13 - objects
24:14 - and I actually like this one more so I'm
24:17 - going to give it a trophy got a little
24:20 - confetti
24:21 - oh all right um I'm glad to hear that
24:24 - you were able to hear it and from here
24:27 - you can click it and download it or send
24:30 - feedback and continue to work on it
24:37 - all right so let's go back over to the
24:41 - course
24:43 - oh
24:44 - so right now
24:46 - um I now have
24:48 - my text I have my cover and I have
24:52 - background music to play now there's
24:55 - other things I could do I could get a
24:58 - voice to text to read it out although
25:02 - most voice text tools are not guarant of
25:04 - AI they may use AI button
25:07 - um sharing of AI is a fairly specific
25:10 - thing
25:11 - and
25:14 - I may want to create a video which would
25:16 - be the next slide now I am not
25:19 - um going to take you through that
25:21 - process
25:22 - just because
25:25 - video editing is obviously a more
25:28 - extensive process we would be here for
25:31 - the next hour as I click through and
25:34 - check audio levels that's not going to
25:36 - be fun for anyone
25:38 - but I will talk a little bit Ah I think
25:42 - it's having a little trouble because I'm
25:43 - zoomed in that's okay
25:46 - so this is really interesting though and
25:49 - there's been a lot of
25:52 - very interesting controversy around uh
25:55 - the applications of AI and video
25:59 - you know there was
26:01 - um Prince's likeness being used during
26:04 - the Super Bowl in Minnesota a couple of
26:05 - years ago a lot of this
26:09 - um current strike in Hollywood is around
26:13 - actors being paid a lump sum to have
26:16 - their AI likeness used in perpetuity by
26:19 - Studios and what does that mean and
26:22 - that's
26:24 - a really interesting place of what we're
26:27 - talking about in a bit which is this
26:29 - intersection of new technology and
26:32 - ethics of what does a technology
26:36 - like this represent for people's labor
26:38 - for their
26:41 - control over their likeness
26:44 - um these are things that will have to
26:47 - consider over the coming years and we'll
26:50 - have to figure out a lot very quickly
26:53 - on the plus side
26:55 - generative AI videos boost productivity
26:58 - it allows you to create things faster
27:01 - and will likely lead to
27:05 - furthering this you know really
27:07 - incredible artistic explosion we've seen
27:09 - since YouTube was invented of
27:12 - this democratization of Art and in
27:16 - overall increase in quality so I'm I'm
27:18 - really excited to see what generated
27:21 - video can do as long as we're using it
27:23 - in a way that isn't
27:25 - uh alienated for people
27:28 - and that is something if you're someone
27:30 - who is considering using generative
27:33 - video themselves
27:35 - um to consider
27:37 - all right
27:41 - risks and limitations of Darren of AI I
27:43 - really like this
27:45 - and this is something I'll say is really
27:48 - important to us at code academy is
27:52 - as I've said a couple times this
27:54 - technology is really exciting and
27:57 - there's so much
27:59 - it can do in so much it will do uh
28:03 - as a transformative thing
28:05 - but we need to also understand it for
28:09 - what it is so that we don't overly rely
28:11 - on it or use it irresponsibly
28:15 - so the first thing I'll say is at least
28:18 - for now these AIS
28:22 - view any information that's input into
28:25 - them equally so it won't necessarily
28:27 - know what information is private versus
28:31 - what information is public that you
28:33 - would put in
28:34 - so you'll know this when I was creating
28:37 - this story
28:38 - I didn't add the names of my nephews I
28:41 - also didn't add a picture of them when I
28:44 - was playing around with an Island map
28:46 - for Dolly that's because there's a
28:49 - chance that once I click in that
28:50 - information that now lives within the
28:54 - generative Ai and may be used in future
28:56 - models there's a lot of controversy
28:59 - right now
29:00 - um I was reading even this morning that
29:02 - the New York Times may be suing open AI
29:05 - because of how much chat CBT was trained
29:09 - on the New York Times articles I've also
29:12 - seen comic artists who have very
29:15 - specific Styles or viewpoints have their
29:19 - work used through generative AI by
29:23 - different groups maybe groups who don't
29:25 - represent their political Outlook or
29:28 - social Outlook but it still looks like
29:30 - their work
29:32 - so there's a lot of interesting
29:34 - conversations right now going on of
29:38 - again like how do we use this correctly
29:40 - and responsibly I'll also add this in
29:43 - terms of data so
29:47 - tactivities are really a good tool for
29:50 - coding we actually have a case study up
29:53 - right now on how to debug your code
29:56 - using chat gbt or how to simulate paired
30:00 - programming with chat gbt that's
30:02 - something we'll be having out on the
30:04 - website within the next couple of weeks
30:06 - but keep in mind any codes you put on to
30:10 - chat TPT now lives there and is now
30:13 - within that system so if there is code
30:17 - that is unique to yourself or unique to
30:20 - the organization that you work for you
30:23 - really should not be testing it within
30:25 - uh chat gbt
30:32 - another limitation to talk about is
30:35 - hallucination
30:37 - so
30:39 - Hallucination is something really
30:41 - interesting to me because it's something
30:43 - that
30:45 - feels very alien but is actually
30:46 - something humans do as well in that what
30:51 - this machine does what DDT does and
30:54 - other alternative AI is that it looks
30:55 - for patterns and then takes those
30:57 - patterns and says okay based off these
30:59 - patterns I am going to come to these
31:01 - conclusions and it doesn't know if it's
31:04 - true or false it just knows that within
31:07 - the pattern it would make sense for that
31:09 - to be true so it's the same way of
31:12 - you know maybe looking at
31:16 - something and saying okay
31:19 - um
31:20 - so I Ferris wheels
31:24 - um thinking okay that is was probably
31:28 - invented by a guy named Ferris which by
31:30 - the way it was but if it wasn't that
31:33 - would be a hallucination of because it's
31:36 - a word and then a thing after it I am
31:39 - going to assume okay actually the better
31:42 - example uh if I'm using duct tape there
31:45 - is no uh Mr or miss duck in the world
31:48 - it's just called duct tape
31:51 - so that would be a human hallucination a
31:56 - pattern misunderstanding and
31:58 - the problem with cat gbt is that it will
32:01 - deliver this information factually
32:04 - so this is why while something like this
32:07 - is a very useful research tool in a
32:10 - limited capacity
32:13 - um you shouldn't use it to make more
32:16 - complex decisions so to give an example
32:20 - I recently wanted to take my wife out
32:24 - for a date in Queens where I live so I
32:27 - asked for 10 data ideas in Queens for
32:31 - under thirty dollars
32:33 - and
32:34 - I promise I'm generally not cheap I was
32:36 - just curious to see what would come from
32:39 - it
32:40 - and what came out was a lot of different
32:43 - answers but not everything was in Queens
32:45 - some was in Brooklyn someone was in
32:47 - Manhattan because what it probably did
32:49 - was look at hundreds if not thousands of
32:53 - websites that have
32:55 - fun date idea or fun cheap date idea
32:58 - lists in New York City
33:00 - and didn't narrow it down correctly
33:04 - so the process of verification is very
33:08 - important when using generative AI for
33:10 - doing any kind of research if you're
33:12 - doing something like what I just did
33:14 - which is a more creative exercise that's
33:17 - fine don't have to worry about that as
33:18 - much
33:20 - um but definitely if you're doing
33:21 - something for work
33:28 - all right
33:29 - and last is these ethical questions
33:33 - which I've been talking about throughout
33:36 - so things like
33:38 - where does work begin and end and how
33:41 - this credit for that work
33:42 - work
33:44 - we are actually talking about this a lot
33:46 - internally at codecademy so at
33:49 - I help manage something called
33:51 - codecademy docs which is an open
33:53 - contribution tool and we've had
33:56 - discussions internally of
33:58 - if someone submits something that was
34:01 - created by a generated AI did they write
34:04 - it
34:05 - and
34:06 - we've had conversations and we still are
34:10 - not 100
34:11 - happy with the answer that we have which
34:14 - is if someone used generative AI as a
34:17 - base and then augmented it and made it
34:20 - their own to a point that it's their own
34:22 - work that's fine but that
34:26 - vagueness of at what point does it go
34:29 - from being more artificially
34:31 - intelligently created versus human
34:33 - created
34:34 - is a very interesting
34:37 - and sticky question that will probably
34:41 - be working through for a while again
34:43 - going back to the writer strike just
34:45 - because that's such a big thing in our
34:47 - cultural conversation right now
34:49 - if someone gets an idea for a TV episode
34:52 - from gerund of AI and then writes it do
34:55 - they get credit for that idea
34:58 - um think about highly serialized shows
35:00 - like a law and order or Chicago Fire or
35:04 - an
35:05 - um Gray's Anatomy
35:07 - generative AI could probably write at
35:09 - least the beginning of a script for
35:10 - those shows because they've been going
35:12 - for so long there's a certain flow and
35:15 - feel to those scripts so what does it
35:18 - mean for things like that in the future
35:20 - there's also issues of
35:24 - data and how it's interpreted
35:27 - so chat TBT again doesn't make
35:30 - assumptions it merely takes things in
35:33 - and outputs what it sees in terms of the
35:37 - patterns so if it's looking at things
35:41 - like government data things like that
35:43 - and ask for reports it will not be able
35:44 - to look at it through a human lens only
35:48 - um through exactly what it seats so
35:50 - there's
35:51 - a lot of stuff where we don't
35:55 - again go through the trouble of
35:57 - verifying checking coming to our own
35:59 - conclusions it can lead to
36:02 - um
36:04 - incomplete views of the world
36:09 - thank you for someone who said duct that
36:11 - was I I actually uh questioned myself
36:15 - and I was like is it duck or ducked it
36:18 - is ducked but again there's no Mr dot as
36:21 - far as I'm aware or misstocked
36:24 - all right so that is the overview of the
36:28 - course but again we have a lot of other
36:30 - really great AI content both for
36:33 - introductory levels like our case
36:35 - studies our um docs entries we have
36:38 - tutorial articles we have our intro to
36:41 - chat TPT course we have a lot of great
36:43 - content we also have more advanced AI
36:47 - content
36:49 - um that you can check out on our site we
36:51 - have an AI Hub it's awesome I would
36:54 - highly encourage you to check it out
36:58 - so that's everything for
37:02 - my presentation so if um
37:05 - buddy if you want to do any questions we
37:08 - can use that time for you know next 10
37:09 - minutes
37:14 - absolutely thank you so much for the
37:16 - presentation that was awesome very
37:18 - instructive I think everybody enjoyed it
37:21 - in the chat
37:22 - uh yeah so I'm going to just ask the
37:25 - chat to collect their thoughts and think
37:28 - about questions that they want to ask
37:29 - you I'll be reading them through as they
37:33 - come in and then Adam you can give us
37:35 - your thoughts and your takes on the
37:37 - questions from the audience so please do
37:40 - share them in the chat I will ask you a
37:42 - question of my own while we wait for
37:44 - people to submit their own questions and
37:46 - I was wondering
37:48 - looking at generative Ai and how the
37:52 - term AI in general is thrown around uh
37:56 - you touched on this during the
37:57 - representation that generative AI is
38:00 - different it's very specific type of AI
38:02 - so
38:04 - do you see that uh misconceptions of
38:08 - what AI does between the different types
38:11 - or like different flavors of AI is that
38:13 - something that you see people confusing
38:15 - and maybe leading up to uh maybe using
38:18 - AI wrong like it's an amazing tool but
38:20 - you still need to know what is it that
38:22 - is going to give you what to expect
38:26 - that's a really interesting question
38:28 - father
38:29 - um
38:31 - I would say it's
38:33 - there's two aspects to it right which is
38:36 - people are using
38:39 - generative AI
38:41 - machine learning in AI interchangeably a
38:45 - lot of the time and they're not
38:48 - interchangeable so we had AI in our
38:52 - lives for a really long time
38:55 - um maybe just not in ways we see or ways
38:58 - we think about so for example on a lot
39:00 - of our smartphones we have
39:03 - a Siri or you know a Google Assistant
39:07 - Siri actually just turned on for me so
39:09 - that that's on me
39:12 - um helping out and it will creep me out
39:15 - when my phone will say
39:17 - hey it's
39:19 - um 6 a.m like you usually take you know
39:23 - you eat at this time so like do you want
39:24 - to eat breakfast and that's so creepy
39:28 - but it's just pattern recognition and
39:30 - that's the kind of thing that AI is good
39:32 - for is that I'll put them into my
39:33 - calendar a lot like eat breakfast or
39:36 - I'll
39:37 - you know
39:38 - um a better example would be on
39:41 - Thursdays at six o'clock I call my
39:43 - parents and I might get a reminder for
39:45 - my phone to call my parents that's AI or
39:48 - the ranking we see on social media of
39:51 - knowing how to kind of curate our feed a
39:53 - certain way is an AI being used that's
39:56 - not a generative AI it's not as smart as
39:59 - what we see but it is an implementation
40:01 - of that
40:04 - um
40:05 - machine learning I don't have the
40:07 - strongest background in admittedly
40:11 - um but I'll say again it's a use of
40:14 - large
40:16 - uh amounts of data to come to different
40:18 - conclusions it's not necessarily
40:20 - generative there's perhaps more of a
40:22 - human component in there
40:24 - in terms of how people think about it
40:29 - we're already
40:32 - seeing companies
40:34 - um lay off certain employees because
40:35 - they think they'll be able to replace
40:36 - some with gerund of AI I think they're
40:39 - going to be
40:42 - sorely surprised
40:44 - um how much they miss people because I
40:48 - think it this will not
40:53 - destroy jobs so much as displaced them
40:56 - so it's not that a job will
40:58 - fundamentally disappear it's that
41:01 - perhaps a starting job as a copywriter
41:04 - you'll be doing a lot more copy editing
41:06 - of content that I generated AI created
41:09 - which is ultimately in my opinion
41:11 - probably a little bit more interesting
41:12 - work you're thinking a little bit more
41:13 - strategically about content
41:16 - um
41:17 - but I think people are in a little bit
41:19 - of a rush to say this is going to like
41:22 - utterly change the world I I don't think
41:25 - we're there quite yet
41:27 - okay fair enough thank you for your
41:29 - answer I see a question in the chat from
41:32 - Matthew uh has someone who is learning
41:34 - to program at the present moment
41:36 - would you recommend using the AI to
41:38 - assist with code now on an early stage
41:41 - of learning or learn to write code
41:43 - without a without Ai and use it later
41:48 - that's such an interesting question
41:51 - um I've wondered about this a lot myself
41:53 - of everyone remembers being in math
41:57 - class and being told hey well everyone
42:00 - over 25 26 remembers being in math class
42:03 - and being told you're not going to have
42:05 - a calculator everywhere you go so you
42:08 - need to learn how to do math this way
42:09 - and surprise we have calculators on us
42:14 - everywhere we go
42:15 - and
42:17 - I do wonder is that going to be the case
42:20 - with coding of
42:23 - there's so much that's going to be
42:25 - taking care of you through the
42:26 - generative AI that
42:29 - um the amount you'll have to learn or
42:30 - how you'll learn will be different
42:33 - well I will say though if we stay within
42:35 - this math example is even if you are
42:39 - using a calculator you still need number
42:41 - sense you still need to know the rules
42:43 - of math and how different equations
42:46 - relate to each other for how to
42:48 - implement them so I would say if you are
42:52 - just getting started out learning to
42:54 - code it's still important to learn how
42:56 - that code Works what's unique about that
42:59 - language what it does
43:02 - um and the Mechanics for it before going
43:04 - to generative AI because if you go to
43:07 - Giant of AI immediately you'll be more
43:11 - using something without fully
43:13 - understanding it and especially if you
43:16 - plan to work as a programmer that puts
43:18 - you in a very vulnerable position
43:20 - it sounds to me a little bit like the
43:23 - analogy of the bicycle and walking where
43:26 - the bicycle will make you move faster
43:28 - but you still need to know where you're
43:30 - going
43:32 - I love that
43:34 - um I was also thinking
43:36 - it's like the difference between knowing
43:38 - how to drive from a car and being a
43:41 - mechanic uh
43:45 - um
43:47 - I know it has four wheels but I couldn't
43:50 - I think it's very self-explanatory for
43:53 - anyone that thinks that AI can do it all
43:55 - if you just don't have like you said any
43:57 - knowledge any sense of the code I
43:59 - becomes very obvious very quickly that
44:01 - you you're not going to get very far
44:04 - tools uh let's see looking at the chat
44:10 - somebody said generative AI doesn't
44:12 - always give facts but rather recognizes
44:15 - patterns this can become very convincing
44:18 - how can we ensure that we don't fully
44:21 - believe it I guess the question is about
44:24 - how to vet the answers you're getting
44:26 - from AI how do you know
44:28 - because it can be very convincing
44:30 - sometimes it's just you know the AI
44:31 - sounds like it knows what it's talking
44:33 - about
44:34 - yeah um
44:36 - this may come as a surprise to people
44:39 - but sometimes there's misinformation on
44:42 - the internet just in general
44:45 - um
44:46 - and again this is the
44:49 - former history teacher in me of it's
44:52 - always good to verify information
44:55 - and we know there are certain sources
44:59 - that are more trustworthy there are the
45:02 - Wikipedia is actually shockingly
45:04 - trustworthy in a lot of ways
45:06 - um
45:07 - respected news organizations
45:10 - uh scientific journals that we can check
45:12 - in on information
45:15 - I would say again it depends
45:18 - what kind of information you're looking
45:20 - for if you're a look if you are planning
45:24 - um a vacation and you're just looking at
45:25 - things to do in Dallas
45:27 - that's probably fine you don't have to
45:30 - worry about it too much maybe if you
45:31 - plan to book something you'll end up
45:34 - verifying it that way
45:35 - however if you are
45:38 - looking up something
45:41 - um
45:42 - more scientific then yes you shouldn't
45:46 - or certain treatments for something
45:48 - first of all call a doctor don't use
45:50 - generative AI to treat a cult
45:54 - um
45:55 - but also make sure to verify I'll also
45:58 - say I feel like some people are worried
46:01 - about that when they talk about Job
46:02 - displacement what if there is a cheaper
46:04 - medical tier which is AI enabled and for
46:07 - and to talk to a real human you have to
46:09 - get through an AI first right
46:12 - so
46:14 - that that is really interesting
46:17 - um
46:17 - give me a moment
46:21 - so
46:25 - a uh
46:26 - podcast I listen to It's called
46:28 - philosophize this did
46:31 - a um the host is a man named Stephen
46:34 - West he did a whole episode on gerund of
46:37 - AI and its meaning and he actually
46:38 - talked about medicine specifically and
46:42 - how there could be really exciting
46:44 - applications in that
46:46 - there are just so many doctors in the
46:49 - world
46:51 - and
46:53 - you do see kind of a natural
46:58 - um choke point in that you have a lot of
47:00 - people that need care and only a certain
47:02 - amount of doctors who can provide that
47:04 - care and
47:06 - we don't have it now but maybe in five
47:09 - years ten years there will be a
47:11 - generative AI that is sufficiently
47:12 - trained to accurately provide
47:17 - um medical advice to people at least for
47:19 - low-level things so that doctors can
47:22 - focus on bigger concerns I'm thinking
47:25 - specifically of
47:27 - um
47:28 - a family member who recently had a child
47:31 - and has been calling my poor cousin
47:36 - who's a pediatrician every two days
47:38 - saying is this normal is this normal is
47:40 - this normal
47:41 - having a generative AI tool that's
47:44 - trained to reliably help provide medical
47:47 - information would
47:49 - really be a game changer for situations
47:52 - like that but again we are not there yet
47:56 - another jail right I think we are
48:00 - this might be related to what we're just
48:02 - talking about a little bit uh there was
48:03 - a user in the chat asking about the
48:05 - degradation of AI by saying if AI
48:09 - generated content enters the data sets
48:12 - the future AIS will be trained on do you
48:15 - have some sort of vicious spiral where
48:17 - the data just keeps getting worse and
48:19 - worse because it's you know it's sort of
48:22 - feeding itself have you have you read
48:23 - into this do you do you think that this
48:26 - could become a problem
48:28 - no but that's scary
48:30 - um
48:32 - again it's one of those things of we
48:35 - just need to be mindful of the pitfalls
48:39 - with any new technology and build robust
48:42 - systems to incorporate it and use it
48:46 - responsibly like maybe this means
48:49 - um and I've had conversations with
48:50 - people on our data science team
48:53 - um about this that we need to be really
48:55 - disciplined about having clean clear
48:58 - data before inputting anything into a
49:00 - generative AI which is again something
49:03 - we should be doing anyway and is a big
49:06 - problem in the field of data is bad data
49:09 - so we're kind of there already
49:12 - so it's it's more of a matter of again
49:15 - like making sure
49:17 - we adapt in a responsible way and I
49:20 - think in terms of it being a spiral I
49:23 - don't know about that I could definitely
49:25 - see it getting worse before it gets
49:27 - better
49:28 - because humans are reactive we like to
49:30 - create a problem for ourselves before we
49:32 - solve it
49:33 - but I don't think it will cause you know
49:35 - some kind of data apocalypse
49:39 - uh going on about the pattern
49:43 - recognition that you talked to during
49:44 - the presentation someone is asking in
49:46 - the chat
49:47 - if generative AI could be used to
49:51 - leverage business Analytics
49:53 - so I guess the field of statistics and
49:55 - math is something that ji jnai can work
49:58 - on
50:00 - um yeah so this is where I was talking
50:02 - about different types of tooling so chat
50:06 - EBT can do very basic things so in my
50:10 - own work I think a lot about search
50:12 - engine optimization so how well things
50:15 - rank on Google
50:16 - and you can go on chat gbt and say what
50:20 - are best practices for SEO and it will
50:24 - give you something pretty good I can't
50:26 - go into chat TBT and say give me a full
50:28 - SEO strategy based off like these
50:31 - metrics in the company because one I'd
50:34 - be giving chat to BT a lot of
50:36 - information about code academy that I
50:38 - shouldn't be and to
50:41 - it doesn't know enough about the
50:43 - specifics of our context to give
50:46 - good information
50:48 - in terms of business analytics that's a
50:50 - long way of me saying yes I imagine
50:52 - there is Jared toong that could do that
50:54 - very well it would likely be a paid tool
50:57 - and
51:00 - we're in a bit of a wild west era where
51:02 - maybe in a year or two years there will
51:04 - be a tool with that sophisticated
51:08 - um to be able to do that if there is I
51:10 - don't know of it yet
51:12 - nice I think it reminds me do you feel
51:15 - like this is a bit like the revolution
51:17 - with computers back in the 80s or the
51:20 - 90s where computers were getting fast
51:21 - enough that they they were actually
51:23 - useful to solve scientific questions and
51:25 - problems and simulations and at the time
51:29 - uh there was this problem where you not
51:32 - you didn't always know why the computer
51:34 - was giving you the answer it was so it
51:37 - became very important for scientists at
51:39 - the time to know how to how to ask the
51:42 - right question so you would know that is
51:44 - answering your question and it's not
51:46 - just spitting out numbers that you're
51:47 - not really sure what you know if they're
51:49 - actually about what you asked the
51:50 - computer so do you see some similarities
51:53 - with that nowadays with AI where the
51:55 - ability to craft a good prompt and to
51:58 - know the limits of AI and how far that
52:01 - prompt is gonna go how it's going to be
52:03 - interpreted uh it's almost as important
52:06 - as knowing how to use the tool itself uh
52:08 - like your example with uh looking for
52:10 - restaurants in Brooklyn
52:13 - but I can only say yes that was a great
52:16 - I agree
52:18 - yeah um I think that makes complete
52:20 - sense and it's also that these
52:22 - Technologies happen in stages
52:24 - um where they typically start off
52:28 - invented existing being used in very
52:31 - specific Circles of specialists and then
52:36 - you get to where we are where certain
52:39 - applications are found potential is
52:42 - understood
52:43 - and the next phase is
52:46 - building out that infrastructure and
52:49 - systems of use that will allow it to
52:52 - fully be employed in the general
52:54 - population and be as transformative as
52:57 - it has the potential to be
52:58 - so to go way back
53:01 - you know people knew the steam engine
53:03 - was a big deal when it was invented
53:05 - there was another 50 years before we had
53:06 - railroads
53:08 - so we are in the steam engine moment
53:12 - um I'm very interested to see what the
53:14 - railroads will look like
53:15 - fair enough someone was asking about
53:18 - completing code academy courses and then
53:20 - what
53:21 - so
53:24 - um thinking about the AI content that
53:27 - we've released recently we have several
53:29 - courses on it uh how do you see somebody
53:33 - is this sort of do you see these AI
53:36 - courses uh something that goes alongside
53:38 - of machine learning and data science
53:40 - courses do you think that is something
53:42 - complementary or something that should
53:43 - come before or after how do you see the
53:46 - the catalog for somebody that is data
53:48 - curious I guess
53:50 - I think that's a that's really
53:52 - interesting I I would say it depends
53:55 - what you want your outcome to be
53:57 - so if you are just
54:00 - looking to understand what generative AI
54:04 - is
54:06 - um I full you can take these courses do
54:08 - these case studies to see how you might
54:10 - implement it in your work and in your
54:12 - life and that may be enough
54:15 - um how we're thinking of it and how we
54:17 - hope to evolve our curriculum over the
54:20 - rest of the year is to really find a way
54:23 - to work it into your workflows and
54:25 - practices be it as a programmer or a
54:28 - data scientist or a cyber security
54:30 - specialist
54:32 - so we'll
54:34 - um we just put out a new data science
54:36 - course Alicia if you could actually put
54:38 - that in um the chat that covers aspects
54:42 - of data science and AI
54:45 - um I'd also say things like machine
54:48 - learning would be a direction to go in
54:50 - if you're interested in the nitty-gritty
54:51 - of how it works
54:53 - I would say
54:55 - regardless and you know if you're not
54:57 - doing this already I would encourage you
54:59 - to do so in the chat think about
55:02 - those moments at work and recognizing
55:05 - them as
55:06 - okay this is a place where I could use
55:09 - gerund of AI to make my life a little
55:11 - bit easier and then you can start
55:13 - working to establish yourself on your
55:15 - team in your company as a leader who
55:18 - understands how to use this and put
55:20 - yourself in a real position to be
55:21 - successful in that way
55:24 - okay well I think that I was very solid
55:27 - advice for anyone trying to get into the
55:28 - data field so we have run out of time
55:32 - for Q a and I want to thank everybody
55:34 - for attending today's live stream if
55:36 - you've attended or part one or part two
55:38 - of our series thank you again for coming
55:39 - back for part three if you haven't
55:42 - please check out our YouTube channel
55:43 - where you can find the other two parts
55:45 - of our three-part series on the
55:47 - evolution of code academy we are
55:49 - celebrating our 12 years in online so
55:52 - thank you everybody for for joining us
55:54 - in this journey I hope that it was a fun
55:56 - experience I hope that everybody took
55:58 - something home with them today from Adam
56:00 - I think it was very very good the
56:02 - explanations I learned a lot today and I
56:05 - really hope that if you enjoy this
56:07 - content and you want to see more of
56:08 - these content you consider con creating
56:11 - an account with code academy or at least
56:13 - signing up for for free one
56:16 - don't forget to subscribe to our socials
56:18 - Twitter uh LinkedIn Facebook that sort
56:21 - of thing Instagram so you can stay up to
56:23 - date with all the events that we're
56:24 - having and the ones that we'll have in
56:25 - the future
56:26 - and thank you again Adam for being with
56:29 - us today
56:31 - have a good weekend everybody all right
56:33 - thanks everyone have a good day
56:38 - all right