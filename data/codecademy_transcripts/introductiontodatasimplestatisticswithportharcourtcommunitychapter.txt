00:01 - okay uh let me click the button
00:04 - go live
00:06 - okay great so now we are live on youtube
00:08 - and everything you say now is gonna be
00:11 - recorded forever on the youtube archives
00:14 - so welcome to this event
00:16 - uh i'm here with samuel and augustine
00:19 - and they're going to be conducting an
00:21 - event for us today
00:22 - um i'll hand over the mic to you samuel
00:25 - and you can just explain the event and
00:27 - get on with
00:28 - it yeah thank you very much fed
00:31 - um hello everyone welcome to this
00:33 - wonderful event
00:35 - hosted and organized by codecademy
00:38 - community sport hackers in collaboration
00:40 - with co-classic hq fed thank you for
00:43 - making this work and thanks to everyone
00:45 - that could help me hq for pulling this
00:48 - out um with me is uh amazing
00:52 - guests and speaker really talented and
00:55 - educated
00:59 - is a
01:01 - great educator with um four years of
01:03 - experience
01:05 - um specialized in arrow
01:07 - molecular studies biochemistry
01:11 - you know the funny and the good thing
01:13 - the crazy thing about data is how
01:16 - wide it can be applied to various
01:19 - various fields you know everything we do
01:22 - is data
01:24 - i'm gonna let i guess you know ex talk
01:26 - more about that
01:28 - we hope that by the end of this event
01:31 - that
01:32 - you if you if you ever had that
01:35 - uh you know thinking
01:37 - how you want to begin your career in
01:39 - data science
01:40 - or you know just
01:42 - made up your mind we hope by the end of
01:44 - this event you will have enough
01:46 - information and you will you'll be you
01:49 - know have morale and support of course
01:52 - everyone supports you to
01:55 - start learning data we have a lot of
01:58 - courses we have path where you can you
02:00 - can begin your career in data science
02:03 - i'm going to introduce and let's our
02:05 - guest first number introduce himself and
02:09 - then moving forward we can go on thank
02:12 - you
02:13 - because then
02:15 - right thank you so much for having me
02:17 - thank you so much thank you fred it's an
02:20 - amazing opportunity
02:22 - to be with you guys today
02:24 - to talk a little bit about data and
02:27 - statistics some of my favorite teams
02:30 - so
02:31 - myself i am augustine at mccree i have
02:34 - my bachelor's in microbiology from the
02:36 - federal university of technology in
02:39 - overa nigeria
02:41 - then i am also an advocate of
02:43 - personalized medicine so i was motivated
02:46 - to
02:47 - apply to the university of liverpool
02:50 - for
02:52 - a master's program in advanced
02:53 - biological sciences the pathway is
02:56 - bioinformatics
02:57 - there in liverpool i
03:00 - i worked on a number of
03:02 - important human diseases especially
03:04 - those involving
03:06 - cardiovascular diseases i worked on
03:08 - proteins
03:10 - first i used a compositional knowledge
03:12 - to predict the structure of proteins
03:14 - that are involved in human diseases
03:17 - and in recognition of my contribution i
03:20 - was awarded a scholarship a studentship
03:23 - particularly
03:24 - to continue my education up to the
03:26 - doctoral level which i have just
03:28 - completed in
03:30 - bioinformatics
03:32 - so
03:33 - for the last
03:35 - six years of my life i have
03:38 - slept i'm woken up with data
03:40 - so it's actually
03:42 - you know
03:43 - i
03:45 - yeah i i feel honored to share some of
03:47 - these insights with you guys today and
03:50 - at the end of this section
03:52 - i hope that i would have motivated all
03:55 - of us
03:56 - to start considering
03:58 - i've to have a fundamental knowledge
04:00 - about what data is
04:02 - what kind of data we give out
04:05 - and then
04:06 - what are the simple statistics that we
04:08 - perform every day and we're not even
04:10 - aware of
04:11 - so the aim is to draw our attention to
04:14 - our environments particularly
04:17 - and
04:18 - like someone mentioned if we have any
04:21 - challenges
04:23 - in terms of
04:24 - beginning a career in data science or in
04:27 - any data related field
04:29 - i hope that at the end of this
04:31 - [Music]
04:34 - presentation
04:35 - will be convinced
04:37 - if we have questions we'll answer that
04:39 - if we have concerns we crash it out
04:42 - and then chat a new course for
04:44 - our careers
04:46 - so without wasting time i would start
04:49 - sharing my screen and then we'll go
04:51 - straight into the business of the day
04:56 - okay somebody just raise the hand
04:59 - i don't know let's go
05:02 - yeah so while um augustine is finished
05:06 - um
05:07 - again um yeah data is a beautiful career
05:11 - myself i'm tearing off as a data
05:13 - scientist and i must say even though i
05:16 - have you know delved
05:17 - a little bit out of data but um to apply
05:21 - that so yeah i'm augustine i think your
05:24 - assets over to you
05:27 - right thank you so much so today we'll
05:29 - be introducing data and a simple
05:32 - statistics
05:34 - so during the course of this
05:35 - presentation
05:37 - uh we're going to go over a few things
05:40 - so this this presentation is divided
05:42 - into two sections the first section
05:44 - would
05:45 - would deal with data
05:48 - and then the second session
05:50 - so during the first session we're going
05:51 - to cover different types of data
05:54 - sources of data
05:56 - laws governing the collection
06:00 - the use and sharing of data
06:04 - different data formats
06:06 - and ways that we can present these data
06:09 - that we've talked about
06:11 - to our audience and to make
06:14 - meaningful
06:15 - interpretations of the data
06:19 - so the second part of this section will
06:21 - talk about statistics so we're going to
06:23 - introduce ourselves to the basic
06:25 - concepts in statistics
06:28 - we're going to
06:30 - draw more on descriptive statistics
06:33 - and then
06:34 - finish up on impression statistics
06:37 - basically t-tests
06:39 - and then we'll summarize what we plan so
06:41 - far
06:43 - and
06:44 - again we'll be open to answering all the
06:46 - questions that we may have
06:51 - so the big question is
06:54 - what is data
06:56 - every one of us
06:58 - must have come across this word data
07:00 - but what is actually data
07:04 - let's take a moment to look around us
07:07 - there are so many things out there
07:09 - there's so many things before us
07:11 - that we actually neglect
07:14 - but they contain very important
07:16 - information that can
07:18 - influence our decisions
07:20 - so simply put
07:22 - data
07:24 - effects statistics
07:27 - details
07:28 - features or item of information
07:31 - collected together
07:33 - as reference or for reference or
07:35 - analysis
07:37 - so this definition covers a lot of
07:39 - things
07:40 - facts
07:42 - statistics
07:43 - figures
07:45 - we come across these
07:48 - each and every day
07:50 - of our life
07:52 - another important thing that this
07:54 - definition covers is item of information
07:58 - that means it encompasses the
08:01 - information
08:02 - that we receive and we share
08:07 - so data can be
08:08 - quantitative
08:11 - when we talk about numbers
08:13 - or qualitative when we talk about
08:15 - interviews
08:18 - so we'll dwell a little bit more about
08:20 - the types of
08:21 - data
08:22 - in the latter slides
08:28 - so another important question is this
08:32 - why what about data why is it so
08:34 - important why is everybody talking about
08:36 - it
08:39 - so there are so many reasons why
08:42 - everybody is keen
08:44 - or people like him researchers are keen
08:46 - scientists are kid you know people in
08:48 - the financial sector everybody is keen
08:52 - to understand data
08:56 - one of them
08:58 - is to provide solid backing for your
09:00 - arguments
09:02 - let's take for example
09:04 - we want to say
09:06 - within this within participants of this
09:09 - event today
09:10 - that those located in africa
09:13 - for example
09:15 - are taller
09:17 - than those
09:18 - located in the rest of the world
09:22 - it would just be a statement
09:24 - if
09:25 - we do not substantiate this with data
09:30 - let's
09:31 - take another example so let's say we
09:34 - measure the height of every participant
09:36 - here
09:39 - and we decide to cl
09:41 - cluster these participants into two
09:43 - groups
09:44 - like again those in africa
09:47 - and those in the rest of the world
09:50 - if we collect this data
09:53 - this data i'm talking about now i'm
09:54 - referring to heights
09:57 - and we calculate it
09:58 - and we compute
10:00 - say
10:01 - a simple
10:02 - frequency to say oh
10:04 - the height of these people in
10:07 - africa is actually more
10:09 - than the height of those in the rest of
10:11 - the world we have been able to
10:12 - substantiate that statement with facts
10:19 - another thing is that we want to make
10:21 - informed decisions
10:24 - many of us do a lot of online shopping
10:28 - like me i know many of us will struggle
10:31 - with choosing between products to buy
10:35 - how do we make the decision
10:37 - we rely on data
10:40 - let's take for example you want to order
10:42 - a pair of sneakers from amazon
10:45 - or any other online vendor
10:48 - but you're not sure
10:50 - between two brands so let's say brand a
10:52 - and run b
10:54 - you're not sure which one you want to
10:55 - take
10:58 - but then your friend has mentioned to
11:00 - you that brand a is better
11:02 - and then you've opened the webpage and
11:04 - looking at the two brands
11:06 - the first thing that you want to look at
11:08 - is the reviews
11:10 - what are the people saying in the
11:12 - comment section understand
11:15 - the shoes or the pair or the brand
11:17 - you're looking at is nice or not
11:21 - after looking at the reviews they're
11:22 - going to look at the rating
11:24 - is it five star over five
11:27 - is it's 1 star over 5.
11:30 - obviously
11:31 - let's say brand a has 20 people
11:34 - giving it a 5 star
11:37 - unless the brand b has 10 000 people
11:39 - giving it a 4.5 star
11:42 - the decision becomes easier to make
11:44 - because if
11:46 - 20 000 people or 10 000 people have
11:49 - rated a particular product with a 4.5
11:52 - star
11:53 - if you wait it's better than 20 people
11:56 - writing a product five star
11:58 - so you've made that informed decision
12:01 - based on the data
12:03 - available to you on that web page
12:06 - unlike so many other decisions that we
12:08 - make in our everyday life
12:12 - so it's also another importance of data
12:18 - we need data to improve our lives
12:21 - what will wonder
12:22 - why
12:24 - but the reality is this
12:29 - if you want to
12:31 - make
12:32 - decisions that affect the lives of
12:34 - people you want to substantiate that
12:37 - with data
12:38 - how do i mean
12:40 - let's talk about
12:42 - census for example
12:45 - why do why does the government conduct
12:46 - census
12:50 - because the government wants to
12:51 - understand
12:52 - the number of persons that have either
12:55 - migrated
12:57 - or located within a geographical
12:59 - location
13:01 - why
13:03 - to
13:04 - better
13:05 - allocate resources
13:07 - so let's give this example let's say
13:10 - within the last five years
13:12 - there is roots b
13:16 - within that would be the services a
13:18 - particular community there are 10 people
13:21 - and there are four buses that you know
13:23 - service these communities
13:25 - but then within the last one year
13:28 - an extra 50 000 people have migrated to
13:30 - the community
13:32 - the question is
13:34 - will those four buses be sufficient to
13:36 - service this number of persons
13:40 - obviously no
13:42 - how will the government know
13:44 - the government will collect statistics
13:46 - of the number of people or influx of
13:49 - people within that community
13:52 - and then
13:53 - make that decision to say oh no these
13:56 - people are going to struggle with four
13:57 - bosses so we're going to include the
13:58 - verses to 20
14:00 - because of the number of people
14:03 - the same thing goes for other social
14:04 - amenities such as
14:06 - electricity
14:08 - water supply waste
14:12 - waste management
14:13 - the frequency which the waste collectors
14:16 - come around to call it the waste
14:18 - will increase with population
14:21 - but if that number if that data is not
14:24 - available then that decision will not be
14:26 - made
14:27 - and these people will struggle
14:33 - another
14:34 - importance of data is to provide
14:37 - solutions i have touched on this in the
14:39 - course of discussing improving lives
14:42 - but again
14:44 - we can look at this in a different
14:46 - context
14:48 - let's say we have a car manufacturer
14:51 - who supplies a particular brand of car
14:55 - or cars
14:56 - action and then the feedback from the
15:00 - customers is that the car is not energy
15:02 - efficient
15:04 - by the time the the
15:07 - manufacturer collects this information
15:10 - and puts them through the production
15:12 - line
15:14 - the manufacturer will be able to provide
15:16 - cars
15:17 - that will
15:19 - be more energy efficient
15:21 - let's take for example the climate
15:23 - crisis that we're experiencing
15:26 - because we have information
15:29 - that the climate or the climatic
15:31 - conditions have changed over the years
15:34 - now you see that we have more electric
15:37 - and hybrid vehicles being manufactured
15:40 - compared to
15:41 - when we had diesel and
15:44 - gasoline powered cars
15:47 - so that way we're trying to provide a
15:49 - solution
15:51 - or the manufacturers are trying to
15:53 - provide a solution to the climate crisis
15:57 - so we can begin to think about some of
15:59 - that you know importance of data in our
16:01 - everyday life
16:04 - how about planning and strategy
16:07 - why do you need data to plan
16:10 - so let's say for for example
16:14 - many of us are high school
16:16 - students
16:17 - and those early in their career
16:21 - let's say you want to advance in your
16:23 - career but you want to know
16:28 - the
16:28 - requirements for this particular type of
16:31 - job that you want to
16:32 - you know attain or you want to secure
16:36 - let's say you want to be a data
16:37 - scientist for example
16:42 - now you need information about okay how
16:45 - many job opportunities are available to
16:47 - data scientists
16:50 - you also need information about what are
16:52 - the skills that are required for me to
16:55 - acquire
16:56 - to secure that job
16:59 - now the data that you've collected about
17:02 - the job statistics we help you in
17:04 - planning which location do i have to
17:06 - apply to which location has more job
17:08 - opportunities
17:10 - the strategy comes in right now that i
17:12 - know that there are more jobs in sales
17:14 - location b
17:18 - how do i make myself marketable
17:21 - what are the skills required of me
17:24 - do i need to learn programming do i need
17:25 - to learn statistics what do i need to
17:28 - learn
17:30 - let's take it into a business context
17:33 - let's say you want to open a startup
17:39 - one of the things that you want to do is
17:40 - to collect information about one how
17:43 - many startups are within that location
17:45 - within the country
17:47 - how many startups are
17:48 - [Music]
17:50 - doing the same thing that i'm proposing
17:52 - to do
17:54 - what are their success stories
17:57 - what is their failure rates
18:01 - now you put this together in your
18:03 - drawing board and you say okay
18:06 - this is what they have done in the past
18:08 - that didn't work
18:10 - now i'm going to use a different
18:12 - strategy to present the same products to
18:15 - the markets
18:17 - data
18:20 - i also mentioned in the preview when i
18:23 - was discussing improving lines i
18:25 - mentioned something about allocating
18:27 - resources
18:29 - but i'm going to give
18:31 - this example in the context of
18:33 - the industry
18:36 - as
18:37 - the head of an organization you want to
18:40 - know where to channel your resources to
18:42 - maximize production
18:45 - this may include demand and supply
18:48 - but you need the information
18:50 - to make that decision
18:53 - you need to know which departments
18:56 - in your organization is the most
18:58 - productive
19:00 - and which department is less productive
19:03 - which department needs more manpower
19:06 - which department needs less manpower and
19:08 - that way you are you you are able to
19:11 - efficiently
19:12 - allocate your resources to maximize
19:15 - not just the success rates the
19:17 - production
19:18 - and outputs
19:25 - so
19:26 - what are the types of data
19:34 - when we described
19:35 - data we did mention that data can be
19:38 - quantitative or qualitative
19:44 - now
19:45 - what is quantitative data basically
19:48 - quantitative data includes numbers
19:52 - values
19:55 - so it can be discrete
19:57 - which means you're looking at the counts
20:02 - or continuous when you're looking at the
20:04 - measure
20:06 - i know that's
20:08 - during my undergraduate days i struggled
20:10 - with understanding the difference
20:11 - between discrete and continuous values
20:15 - for me i always think they're all
20:17 - quantitative values so why classify them
20:19 - again but i've come to understand that
20:22 - interpreting them statistically is
20:25 - different slightly different
20:28 - so
20:30 - for discrete values or looking at
20:31 - frequencies
20:32 - while for continuous values you're
20:34 - looking at intervals and ratios
20:37 - during the um
20:38 - statistics section we'll dive a bit more
20:41 - into what these values mean
20:44 - but i'm going to give an example of
20:46 - discrete values
20:50 - so let's assume that you own
20:53 - a shop
20:56 - and you want to generate data and you
20:57 - want to generate discrete data what kind
20:59 - of data you're looking at so you're
21:01 - looking at
21:02 - the number of customers who bought a
21:04 - particular or different items from you
21:11 - again
21:13 - let's say you want to generate
21:14 - continuous values so you want to measure
21:16 - the height of everybody that has come
21:18 - into your shop
21:21 - so
21:22 - in
21:22 - in measuring you're looking at
21:26 - a range of numbers
21:29 - they would definitely contain some will
21:31 - contain fractions however in discrete
21:34 - that just counts and integers
21:38 - how about qualitative data
21:42 - so qualitative data can be
21:45 - arduino
21:48 - so odd now data may include it's a type
21:51 - of categorical value so another name for
21:55 - qualitative is
21:56 - categorical so it's a type of
21:58 - categorical value
22:00 - that contains information that can be
22:02 - ranked
22:03 - for example let's look at socio-economic
22:06 - status of an individual so we have those
22:09 - that around as low income
22:12 - we have those that are run as
22:14 - middle income
22:16 - and we have those ranked as high income
22:19 - so this is an example of an ordinal data
22:23 - how about a nominal data
22:26 - can we think of anything
22:31 - so in nominal data you cannot rank it
22:34 - or you cannot order it
22:36 - so whichever order it appears is fine
22:39 - for example i want to ask let's look at
22:42 - sex for example we have let's say male
22:45 - and female
22:47 - can you rank male before female
22:49 - or can you rank the other before the
22:51 - other can you run female before male
22:56 - let's say we're looking at race
23:00 - are you going to say
23:02 - black race comes first white race comes
23:04 - second
23:05 - and the rest
23:07 - no
23:08 - if black fps fest is fast if black
23:11 - appears last with last there is no order
23:13 - to which you can write it
23:20 - so what are the data forms
23:22 - and this is the very interesting parts
23:26 - we find that
23:27 - almost everything around us contains
23:29 - data
23:31 - our name
23:34 - our telephone number
23:37 - date of bets
23:40 - postal codes
23:44 - where we've been to
23:46 - the news articles we read the news media
23:49 - will listen to
23:50 - and what have you
23:52 - contains importance
23:55 - data that we can harness
23:58 - you know
23:59 - and maximize it
24:00 - to
24:01 - [Music]
24:02 - actually
24:04 - make better decisions as we have
24:06 - discussed in the importance of data
24:10 - so
24:10 - these are the different forms of data
24:13 - and you'll be amazed at how much data
24:16 - that we give out without even knowing
24:20 - like for example we can look at our
24:21 - phone
24:22 - look at your your map your gps
24:26 - it has track of all the places that you
24:28 - have been to
24:30 - data
24:32 - sometimes we have this medical unhealth
24:35 - data that keeps track of our
24:37 - you know how many steps we've completed
24:39 - in a day
24:41 - how many calories with bonds
24:44 - and things like that sometimes even
24:46 - our posts
24:48 - our heart rates
24:51 - how about online consumption i've
24:53 - mentioned amazon before
24:55 - take a look at your shopping history
24:59 - your online consumption contains
25:01 - information about the brands that you
25:03 - patronize
25:04 - the type of products the designs the
25:06 - styles
25:08 - it also contains information about your
25:10 - shopping preferences which stores you
25:12 - prefer to shop from
25:15 - and
25:17 - your delivery address
25:19 - where do you how do you prefer to
25:20 - receive your products
25:25 - and let's talk about government data
25:31 - what kind of data does the government
25:32 - have about us
25:34 - so in the west here i know
25:37 - once
25:38 - a baby is delivered or born
25:41 - the government issues
25:42 - a best certificate that contains
25:44 - information about when the baby was born
25:47 - the name the name of the parents the
25:49 - time the weights and some things like
25:52 - that
25:53 - let's talk about the biometrics
25:55 - that we freely give out it contains
25:58 - information about us
26:01 - so these are the various ways of various
26:03 - forms of
26:06 - data
26:10 - now
26:11 - how do we source for these data
26:17 - so there
26:18 - are two main ways we can source for data
26:21 - so the first one is the primary
26:25 - so basically what primary data sourcing
26:27 - means is that you have to perform the
26:30 - experiments you have to perform the
26:32 - analysis you have to interview people
26:35 - you have to generate the data yourself
26:38 - and you can simply do that by looking
26:40 - around you count the number of pain you
26:42 - have in front of you
26:44 - if you work in a department how many
26:45 - computers does the department have
26:49 - we can even do a head count here we can
26:52 - see
26:53 - how many male are on this call
26:55 - how many female are on this call these
26:58 - are primary data because we are actually
27:00 - performing this interrogation or this
27:03 - you know this kind of analysis
27:06 - how about when we don't perform this but
27:08 - we still want the data
27:10 - yes we can source data that we do not
27:13 - generate
27:14 - and that brings us to
27:17 - secondary
27:18 - data sourcing
27:21 - so secondary data sourcing
27:24 - can be
27:25 - internal
27:27 - so if you work in an organization has
27:29 - collected data
27:30 - you can access that data
27:34 - external
27:35 - you can look outside your organization
27:39 - for data
27:40 - and
27:42 - there is no there is no limit to where
27:45 - you can source for data
27:48 - so i'm going to explain a bit more about
27:50 - these two types of data sourcing
27:57 - so for primary data
28:00 - we're looking at observation you
28:02 - recording what you observe
28:05 - you're looking at conducting survey
28:08 - you're looking at conducting interviews
28:11 - and recording them
28:13 - you're looking at performing experiments
28:17 - and recording your observations you're
28:19 - looking at conducting pools
28:23 - and also focus groups
28:27 - so the unique characteristics of primary
28:29 - data is that you are performing you are
28:32 - performing something
28:35 - how about secondary data
28:38 - so you can walk up to government
28:40 - agencies to request for information
28:43 - let's say for example you want to know
28:46 - the number of uh new buildings that are
28:48 - being erected in your location
28:51 - you can go to your regional and urban
28:53 - planning and ask for this information
28:56 - and they will provide you with it you
28:58 - didn't generate this information
29:00 - they did and they've offered you the
29:02 - information
29:04 - you can even make inquiries about
29:07 - you know working in to your health
29:08 - department to ask about
29:11 - important health issues and they'll
29:13 - provide you with their data
29:17 - another favorite for me the favorite
29:20 - place for me to source my data is
29:21 - through published materials so you can
29:23 - look at published sales for a company
29:26 - and extract information in one day i
29:28 - study data from that
29:30 - you can look at information published in
29:32 - the newspapers in research articles
29:35 - company brochures and orders
29:40 - again you can look at sales data from
29:43 - financial institutions from commercial
29:44 - institutions
29:48 - or you can look at databases
29:51 - now some databases are public some are
29:54 - private
29:56 - so for the public databases we refer to
29:58 - them as public repositories
30:02 - people generate this data and store them
30:05 - there for easy dissemination of
30:07 - information
30:10 - but
30:11 - just look at the tone of places where we
30:13 - can generate data from
30:15 - for me in the last six years i have not
30:18 - done any primary data collection
30:20 - i just wait for them to do it and i
30:22 - extract it and i use it to
30:25 - you know
30:26 - develop patterns and provide actionable
30:29 - insights into
30:31 - anything i'm looking at
30:36 - so what the laws governing data sharing
30:40 - now because i have explained to us
30:44 - how much data we generate and freely
30:46 - give out
30:48 - now people are becoming more sensitive
30:51 - and more concerned about what type of
30:53 - data
30:54 - companies institutions have about them
30:57 - so governments across the globe have
31:00 - enacted laws governing how to collect
31:03 - information
31:06 - how to use the information collected
31:09 - and how to share this information
31:12 - so be sure to you know look up
31:16 - laws and regulations in your location
31:18 - covering the collection
31:20 - use and um
31:22 - dissemination of data
31:25 - so to give an example
31:27 - in the u in the u.s for example there is
31:29 - this uh gram
31:31 - leaders act
31:33 - that governs personal information
31:36 - collected by banks and financial
31:38 - institutions
31:40 - so there was they will the law will set
31:44 - the criteria for the institutions to
31:46 - collect information
31:49 - the direction they can hold that
31:51 - information and what they can use that
31:53 - information for
31:56 - look at the general data protection
31:58 - regulation in the eu
32:01 - that governs the collection and use of
32:03 - interview of data by individuals and
32:06 - organizations i know that this is
32:08 - not exhaustive of the laws governing
32:11 - data sharing
32:12 - so before you begin to collect data for
32:15 - any particular purpose
32:17 - take some time to understand the rules
32:20 - and regulations
32:21 - the laws governing how you collect that
32:24 - data
32:25 - how long you collect that data what you
32:27 - use the data for
32:29 - how you use it
32:31 - and how you share this data and it's
32:34 - even is very important if you have
32:36 - collaborators that are not located
32:38 - within the same geographical location
32:44 - so so far we've learned a lot about data
32:47 - we've talked about data types so what
32:49 - about data formats
32:54 - this place i know a lot of people do
32:57 - why do we have data formats
33:00 - so there are so many reasons why we have
33:02 - classified different data into different
33:04 - formats
33:06 - and i hope that at the end of this
33:08 - presentation will understand that
33:12 - so here we have three classes we have
33:15 - the structured
33:17 - we have the semi-structured
33:19 - and we have the
33:22 - um have the unstructured
33:27 - if we look at the structured data it
33:29 - looks organized
33:31 - we can actually look at the squares and
33:34 - say oh the uniform
33:37 - however if you look at the
33:38 - semi-structured
33:40 - we can see some of them are uniform
33:42 - others are not
33:45 - but in the unstructured
33:47 - nothing is uniform it doesn't appear to
33:51 - mean a lot
33:54 - for the purpose of this presentation i'm
33:56 - going to show us
33:58 - an example of a structured data
34:01 - so look at this excel containing student
34:03 - information
34:05 - and their grade point aggregates
34:08 - by just looking at this
34:10 - i could tell that mary has the highest
34:14 - gpa
34:17 - how about if i present it in a
34:20 - semi-structured way
34:23 - will i easily decode that from this
34:26 - especially when i have let's say 100
34:28 - students
34:29 - obviously not
34:32 - it contains the same information as a
34:33 - table
34:35 - however
34:36 - in a different format
34:39 - now how about if i present this same
34:41 - information as unstructured data
34:45 - i'm writing to mary to say hey i just
34:48 - saw the results i i just saw the results
34:50 - a 4.0
34:52 - gpa
34:55 - yeah
34:56 - imagine if i had to contact
34:58 - 10 100 students that means i have to
35:01 - write hundred emails
35:02 - individually
35:04 - to each of these students
35:06 - to say hey i just saw your gpa hey i
35:08 - just saw your gpa when i can easily
35:10 - present it as a table or even as a
35:12 - figure
35:18 - so
35:21 - i've already mentioned that there are
35:23 - different ways that we can present data
35:26 - i just mentioned table
35:28 - but i'm going to show us different ways
35:31 - of presenting data
35:34 - so let's say we conduct a pool right now
35:37 - and we ask everybody on this call to
35:39 - select their favorite colors
35:43 - let's say we have a thousand people on
35:45 - this call
35:46 - how do we know
35:48 - the color that is chosen the most
35:52 - well i say hi john you chose red mark
35:55 - you choose blue
35:57 - no
35:58 - how many times i have to say that
36:00 - for me to cover everybody when i could
36:03 - present that results
36:04 - and everybody will see it at the same
36:06 - time
36:08 - so how about i ask everybody in the pool
36:11 - to see select your vex color
36:13 - and then i compute the frequency of the
36:16 - colors
36:17 - and generates about a bar plots to
36:20 - present the results
36:22 - clay
36:25 - without wasting much time we could see
36:27 - that a particular color will win
36:30 - so this pool was conducted for children
36:33 - and they were asked to choose
36:36 - their favorite colors
36:39 - and then the frequency was computed
36:43 - from this
36:44 - bar plot i'm showing here
36:46 - we can see that
36:47 - most of the children choose yellow as
36:49 - their favorite color
36:53 - i don't need to know
36:54 - the names of the children that chose
36:57 - which color
36:58 - however i need to know that the children
37:01 - that were sampled chose yellow
37:05 - how about
37:06 - if i want to present more information on
37:08 - about plots
37:10 - let's say for example i want to look at
37:13 - the financial data of different councils
37:17 - let's say i have three councils in the
37:18 - uk but i want to look at their
37:21 - financial
37:23 - information in the first second and
37:24 - third quarter of the year
37:27 - how can i present this to an audience
37:29 - that they will understand immediately
37:32 - so that is what we call the group bar
37:34 - charts which i'm going to bring up here
37:37 - so here you see that the bar chart is
37:40 - color coded
37:41 - in such a way that a color is
37:44 - informative
37:46 - even though i'm looking at
37:48 - data from 2020 different quarters
37:51 - i could tell which council
37:54 - has
37:55 - or generated more revenue
37:57 - than the order
38:00 - so for example in the first quarter
38:02 - lincoln generated more revenue than the
38:04 - rest
38:05 - however in the second third and fourth
38:08 - quarter
38:09 - kent generated more revenue than the
38:12 - rest
38:15 - easy
38:16 - without having to read all the documents
38:19 - to picture this out i have presented
38:22 - this information
38:24 - to an audience that will understand with
38:26 - minimum
38:30 - efforts now this is the interesting part
38:34 - so let's say this many of us are
38:37 - students
38:38 - so let's say we want to
38:40 - make an argument or we want to make a
38:42 - case where our pocket money has to be
38:44 - increased
38:46 - so we're looking at
38:48 - data so let's assume that our monthly
38:51 - allocation or allowance from our parents
38:54 - or guidance
38:55 - is 200
38:58 - and we want to increase this um amounts
39:01 - to maybe 400.
39:03 - remember
39:04 - for you to make a generic case you want
39:06 - to arm yourself with data
39:08 - so let's see how do you present this
39:10 - information to your parents or your
39:12 - guiding
39:13 - or guidance
39:14 - so you can generate
39:16 - a pie chart
39:18 - of expenses
39:21 - and that pie chart will contain the
39:23 - percentage of your money that goes into
39:27 - academics traveling housing so when you
39:30 - call your your parents or your guide and
39:32 - say hey i need an increase look i have
39:34 - this information here
39:36 - it's showing that i spend a lot of money
39:38 - on transports which means i don't have
39:40 - enough
39:41 - for my test books
39:43 - and this is the information this is the
39:44 - data i have collected over a three
39:46 - months period
39:48 - they'll be like oh okay you deserve it
39:52 - so let's say you want to know how much
39:54 - money you spend also in constructing
39:57 - your home
39:59 - let's say you have a million dollars
40:01 - to build the home
40:04 - and you want to know
40:05 - what proportion of this money is spent
40:08 - on actually building the house
40:11 - so you can see that you spend almost 25
40:13 - percent paying people to do some work
40:15 - for you
40:18 - and you spent the least
40:20 - on buying timber
40:24 - how about
40:25 - we do another pool here
40:28 - and we sample people and ask them to
40:30 - choose the best fruits
40:33 - and then we want to present this
40:34 - information instead of a bar chart now
40:37 - we want to present it as a pie chart
40:42 - so you see it's possible for us to
40:44 - present the same information
40:47 - using different ways
40:51 - okay
40:52 - how about if we want to understand
40:54 - relationships between
40:57 - events for example
41:02 - how about if we choose
41:04 - to look at incidents of measles in the
41:07 - u.s
41:08 - over time so we're looking at from 1930
41:11 - up to
41:13 - 2000
41:16 - you can see that
41:17 - across the 50 states of of the us
41:20 - you can track
41:22 - the incidence of measles
41:25 - there is a there is a color legend that
41:27 - tells you the number of incidents per
41:29 - 1000 or 100 000 actually
41:33 - and you can use information like this to
41:35 - say oh no i'm not going to a particular
41:36 - state because there is higher incidence
41:39 - of measles in that state
41:40 - compared to the other states
41:44 - and again if you're presenting this to
41:46 - me
41:48 - as
41:49 - reasons why you you're making that
41:51 - decision
41:53 - it's easy for me to follow to say oh
41:55 - okay
41:56 - i understand now
41:58 - so you don't have to move
42:02 - so
42:03 - the task i'm going to give to all of us
42:05 - now is for us to take a moment
42:08 - and think about other ways if possible
42:10 - put it in the chats
42:13 - other ways of presenting
42:15 - data to an audience
42:17 - i'm gonna give us about
42:19 - one minute to do that
42:21 - then we can proceed
42:40 - okay
42:42 - so
42:55 - okay so just to recap
43:00 - so we've described
43:02 - the importance of data
43:04 - we've discussed the types of data
43:06 - quantitative and qualitative we also
43:09 - mentioned the
43:10 - forms of available data and data sources
43:15 - we've also discussed the laws governing
43:17 - the collection of data
43:20 - and sharing of information
43:22 - we mentioned the different data formats
43:25 - and how to present our data
43:29 - so i'm just going to give us a quick
43:31 - break one second
43:33 - so that we can all relax and then we can
43:36 - move on
43:44 - so introducing the next section so
43:47 - i've introduced us to basic concepts in
43:49 - statistics
43:51 - and why it's kind of important for us to
43:53 - understand these concepts before we i
43:56 - mean as data scientists as scientists as
43:58 - anybody we find out that we perform
44:00 - statistics in our everyday life
44:04 - how
44:05 - we count the balance when we go to the
44:07 - store we count
44:09 - how much balance we received if that's
44:12 - the correct balance we're expecting
44:16 - your accounts money to give to somebody
44:20 - they might not seem like a lot but
44:23 - what we're actually doing is that we're
44:25 - performing some statistics
44:29 - right so what is statistics to start
44:31 - with
44:39 - so statistics is concerned with
44:41 - developing
44:46 - is concerned with developing
44:48 - and studying methods for collecting
44:51 - analyzing
44:53 - interpreting and presenting data
44:57 - so
44:59 - let's take a moment and reflect the last
45:01 - time we performed any statistics
45:04 - you might be surprised that it might be
45:05 - as recent as just some minutes ago
45:14 - so
45:16 - what are the types of statistics or
45:18 - statistical analysis
45:21 - there are a number of them but for the
45:22 - purpose of this presentation i'm going
45:24 - to stick to just two
45:28 - so the first one
45:30 - is descriptive statistics
45:34 - so descriptive statistics
45:35 - tries to answer the characteristics of
45:38 - the respondents
45:41 - so when i give you a data set and i ask
45:44 - you to perform the descriptive
45:45 - statistics i'm trying to
45:47 - what i'm asking you to do is
45:50 - describe the characteristics of the data
45:52 - i've given to you
45:54 - you can start by checking
45:57 - the number of rows the number of columns
46:00 - and tell me oh the data contains 10 rows
46:03 - and 20 columns
46:06 - it could be inferential which is
46:09 - what are the characteristics of the
46:10 - population
46:12 - that you're looking at
46:17 - it could be just the differences what is
46:19 - the difference between
46:20 - a and b
46:22 - i know we do that a lot
46:27 - it could be associative
46:29 - so
46:30 - what you're asking here is
46:34 - is a related to be
46:36 - or not
46:40 - or
46:41 - it could predict it could be predictive
46:43 - so you're trying to predict an unknown
46:45 - value because you know one or two more
46:47 - values
46:49 - so for the purpose of this presentation
46:52 - i'm going to stick to descriptive and
46:54 - inferential
46:56 - statistics
47:00 - so before we continue
47:02 - i just want to
47:04 - clarify here that there are so many ways
47:07 - of performing statistical analysis
47:10 - and there are so many packages
47:13 - that you can use packages i mean
47:15 - software applications
47:18 - so for those of them for those of us
47:20 - that are really really into quantitative
47:22 - and qualitative studies so there is this
47:24 - tool called mask
47:26 - max qda
47:28 - is a very useful tool for
47:31 - quantitative and qualitative analysis
47:37 - i'm sure many of us are familiar with
47:38 - python
47:40 - this is the language of data scientists
47:45 - r as well
47:48 - most people prefer r for data
47:49 - visualization
47:51 - i'm going to stick to r for the purpose
47:53 - of this presentation
47:56 - excel 2 is a very powerful tool
48:00 - for
48:00 - performing statistical analysis
48:03 - i'm sure many of us have used excel at
48:05 - one point or the other
48:08 - there is spss
48:11 - there is sql
48:13 - for those that query databases to
48:15 - generate information
48:18 - that is for those that also perform
48:21 - qualitative analysis
48:24 - and recently um power bi and tableau has
48:28 - emerged as important visualization tools
48:31 - for
48:33 - organizations
48:34 - so that's why i brought in tableau here
48:38 - so
48:40 - let us do some coding in our and see how
48:43 - easy it is to actually perform some of
48:44 - these statistics
48:49 - so i'm sure many of us can see my
48:52 - scripts
48:54 - so the purpose of this
48:56 - brief our tutorial is to show us some of
48:59 - the things that we can do with r
49:01 - in terms of computing the descriptive
49:03 - and influential statistics
49:06 - i'm not going to go into the principle
49:08 - behind each of these statistics
49:10 - it's beyond the scope of this particular
49:12 - presentation but i am happy to answer
49:14 - specific questions that we may have
49:18 - so i'm going to use this data iris
49:21 - iris is an imbued data with our package
49:23 - anybody can access it if you have any
49:26 - other programming language
49:28 - so i'm just going to import it into this
49:30 - work environment
49:34 - and
49:41 - yep sorry guys
49:44 - [Music]
49:47 - yes
49:49 - and we can look at the data it contains
49:51 - information about fishes so there are
49:54 - different species of fish here
49:56 - and then it's measuring the lengths the
49:58 - widths
50:00 - this
50:02 - spiral length
50:04 - and petal lengths spar whips and spout
50:08 - and petal weights
50:10 - across different species
50:13 - we can see there are about three of them
50:17 - now this is one of my favorite data
50:21 - so in descriptive statistics
50:23 - there are two types i did mention to us
50:27 - so the first one measures central
50:29 - tendencies
50:30 - so by central tendencies we mean
50:33 - the mean the median and the mode
50:36 - so let's look at this data for example
50:40 - and let us
50:42 - look at the lens
50:43 - this power length
50:45 - so we want to understand what is the
50:47 - mean
50:49 - of this power line across these three
50:51 - species
50:53 - it's very easy for us to compute that
50:56 - we can easily just ask
50:58 - the mean function to help us
51:01 - if we run this function here
51:05 - we know that the mean is about five
51:07 - point eight three
51:10 - threes and it wants to round this number
51:12 - up we can round it up so five points
51:16 - it's four
51:18 - for this particular length that we're
51:20 - showing here so for the length here
51:23 - the mean
51:24 - of this length is about 5.8
51:27 - how about the median
51:30 - so
51:32 - the median is
51:34 - the center or the middle number
51:36 - basically
51:38 - we can also generate that results
51:41 - and we see that 5.8 is not just the mean
51:44 - but also the median
51:48 - now
51:49 - as they take home i would want us on our
51:51 - own to try and compute
51:53 - the mean
51:55 - the max
51:56 - the variance the standard deviation and
51:59 - the range
52:00 - of this particular data of this
52:02 - particular column
52:05 - sparling
52:10 - okay
52:11 - there are also other ways of generating
52:14 - these descriptive statistics without
52:15 - having to compute them
52:17 - individually
52:19 - let's say for example i just want to
52:21 - look at
52:22 - that column and then generate most of
52:24 - this information
52:26 - i can use the summary function in r
52:30 - and
52:31 - i will know that the mean is 4.30
52:34 - and the max is 7.90
52:37 - i could tell that the mean is
52:39 - 5.843
52:43 - and the median is 5.80
52:46 - so with just one function i'm able to
52:48 - generate
52:49 - most of the descriptive statistics that
52:51 - i have mentioned
52:53 - there is still also a different package
52:57 - or a different library in r
52:59 - that i can use
53:01 - and generate the same information
53:05 - but here i generated the information
53:08 - across the entire data
53:10 - so i had four columns
53:13 - contains quantitative values
53:15 - and here you can see
53:17 - i know what the standard deviation for
53:19 - each of these columns are
53:21 - i know what they mean is
53:23 - i know the median i know the sum i know
53:26 - the range
53:28 - so
53:29 - why is this important why are we talking
53:31 - about this
53:33 - sometimes like i did explain once you
53:36 - have data before you
53:38 - you want to look at your data you want
53:40 - to make sense out of your data you want
53:42 - to understand whether the data is well
53:45 - formatted
53:47 - or not
53:48 - and
53:50 - the best way to do that is to generate
53:52 - summary statistics for that data
53:55 - so let's assume that i have some missing
53:57 - values it will occur here
54:01 - but because i didn't have any missing
54:02 - values it's showing as zero
54:06 - so that way i know that if i perform any
54:08 - statistical analysis on any of the
54:10 - columns here a war on because there are
54:12 - no missing values
54:16 - now how about if we want to visualize
54:18 - this
54:19 - let's say for that for example we still
54:21 - go back to this at the spiral lens
54:30 - and then we want to generate a histogram
54:32 - to show
54:34 - the range
54:37 - of information contained within this
54:39 - column
54:40 - we can simply do that and
54:43 - you can see
54:44 - that we know from here we know what the
54:46 - frequency of each of the values are
54:50 - we know that
54:51 - the highest frequency occurred between
54:55 - 6.0 and 6.5
55:00 - okay
55:01 - and we can begin to
55:02 - present data
55:04 - in a more concise
55:07 - and interactive way
55:09 - we can begin to look at this data and
55:10 - begin to make sense oh okay so more
55:12 - people chose this more people didn't
55:14 - choose this we can begin to see patterns
55:17 - immediately
55:18 - how about if i want to present the
55:20 - central tendencies using the box plots
55:24 - again
55:25 - remember that we talked about the mean
55:26 - and median being at 5.8 look at this
55:30 - here
55:31 - look
55:32 - we know where the range is we know that
55:34 - this is the maximum value
55:36 - and this is the minimum value it still
55:38 - corresponds to the information that we
55:40 - have presented here
55:45 - but here
55:46 - and here
55:49 - next
55:51 - we want to look at
55:53 - we want to look at another way of
55:54 - presenting this across the different
55:56 - species this time around we want to look
55:58 - at the relationship
56:00 - between this uh lens across the
56:04 - different species in our data
56:08 - [Music]
56:10 - so here
56:11 - i can tell you categorically that data
56:14 - contained in
56:16 - virginica
56:19 - has
56:20 - a well i say
56:22 - it's more actually compared to data
56:24 - collected for
56:26 - the other species
56:28 - you can also see that the mean
56:30 - and the median is even higher it's about
56:33 - 6.5 compared to
56:35 - this with 5.0 and 6.0
56:38 - so we can begin to see the patterns by
56:40 - just looking at the central tendencies
56:42 - alone we're having to do any much
56:45 - statistics
56:47 - and this is some of i mean when we look
56:49 - at
56:50 - obligations these are some of the
56:52 - results that presents to us
56:54 - you know to support their findings
56:58 - how about if we want to look at
56:59 - relationships
57:03 - obviously i have generated a box plot
57:07 - sorry scatter plots
57:09 - but what does this tell us not much
57:12 - but this plot can be enhanced
57:15 - to show us the relationship
57:18 - you know between the
57:20 - petal lens and the super
57:22 - lens
57:24 - in this data or across the different
57:26 - species
57:27 - so let's say i want to color coded and i
57:30 - want each species to have a different
57:32 - color and i want to visualize these
57:34 - results
57:44 - i believe that this is more visually
57:46 - appealing
57:47 - to us
57:48 - we can begin to see relationships again
57:52 - so we know that this group
57:56 - doesn't really
57:57 - associate well with this group
57:59 - and we can begin to see this pattern and
58:01 - again
58:02 - look at this
58:05 - notice that i have presented the same
58:07 - information
58:08 - using different means
58:11 - okay
58:14 - and
58:15 - we can do a lot more
58:18 - visualizing data using different
58:21 - different patterns different techniques
58:23 - but the end goal is to communicate the
58:26 - idea to an audience
58:28 - and to make the information clear enough
58:33 - so i'm going to pause for a minute so
58:35 - that we can assimilate what we've had so
58:37 - far
58:39 - and then we'll move forward
58:45 - [Music]
58:48 - okay
58:50 - so when we talked about different types
58:52 - of statistical analysis we mentioned
58:55 - inferential analysis as looking at the
58:57 - characteristics of a population
59:01 - so we're going to use the same data to
59:04 - do that
59:05 - now
59:07 - there are different ways of performing
59:09 - inferential statistical analysis
59:12 - the most common
59:13 - are the t tests
59:15 - and the anova
59:19 - the t-test basically tests
59:22 - between
59:23 - two groups so you're looking at
59:25 - information shared between two groups
59:29 - and anything more than two groups the
59:31 - t-test is no longer valid
59:34 - you're looking at anova
59:36 - so when you have two groups and you want
59:37 - to compare the mean of the two groups
59:41 - you're looking at eighty tests
59:43 - so let's say for example we want to we
59:45 - want to compare the mean heights
59:47 - of participants
59:49 - in africa compared to the rest of the
59:51 - world
59:53 - we have two groups so we're looking at
59:55 - t-tests
59:56 - however let's say we want to compare
59:59 - the mean heights
60:01 - for participants in three different
60:03 - continents so we're looking at africa
60:04 - we're looking at america and we're
60:06 - looking at europe
60:07 - we can no longer use the t-tests to
60:10 - perform this type of analysis
60:14 - so the t-test
60:17 - tests or compares the mean within two
60:19 - groups
60:21 - or two samples okay
60:23 - and there are different types of t-tests
60:25 - so you have the one sample t test so one
60:28 - sample t test is when you're comparing
60:31 - just the mean
60:32 - of the population to a standard
60:36 - or you have two sampled t-tests
60:43 - and then you have the paired t-tests
60:48 - so we'll talk a little bit more about
60:50 - them in a minute
60:59 - so but before then before we perform a
61:01 - t-test
61:03 - there is there are some assumptions
61:06 - about the t-test
61:08 - that has to be met before we select what
61:11 - type of t test we have to perform
61:14 - so one of these assumptions is that
61:17 - i've already mentioned it has to be
61:19 - two treatments
61:21 - another important thing is that it has
61:24 - to be normally distributed
61:28 - that means you're going to go for a
61:30 - parametric t tests so when the data is
61:32 - normally distributed
61:34 - you go for a parametric t test when the
61:36 - data is not normally distributed there
61:39 - are a few things that you can do which
61:42 - is actually beyond the scope of this
61:43 - workshop but i'll just mention it
61:46 - so one of them is to transform the data
61:50 - by transforming it could be log 10 or
61:52 - not 2 transformation
61:54 - and then check again to see if the data
61:56 - is not normally distributed
61:58 - and if it is not then you have to
62:00 - perform a non-parametric t-test
62:02 - for the purpose of this particular
62:04 - workshop i'm going to stick to the
62:06 - parametric t-tests
62:08 - so the first thing i'm going to do is to
62:10 - check for
62:12 - normality just to check if the data is
62:15 - normally distributed
62:16 - and again i'm going to use just a column
62:19 - of the data that we've read into r
62:23 - and i'm going to use two methods to
62:25 - check for normality so the first one
62:28 - is the shapiro tests which is an arrow
62:30 - function that calculates and tells you
62:33 - a p-value
62:35 - to make that decision whether your data
62:36 - is normally distributed or not
62:39 - so
62:41 - and i'll explain the results in a minute
62:43 - and then the second one is a histogram
62:45 - where you visually look at your data and
62:48 - decide if it is normally distributed
62:50 - so i'm going to go ahead and show that
62:52 - now
62:54 - right
62:55 - so the first test is the shapiro test
62:59 - now
63:00 - for you to make a decision that
63:04 - your values or your data is normally
63:06 - distributed then the team the p-value
63:10 - has to be greater than uh
63:13 - it has to be greater than 0.05
63:17 - in our case here
63:20 - by looking at this
63:22 - we can estimate that this data is
63:24 - normally distributed it's not perfect
63:27 - but we can't because i already know this
63:29 - data so i can estimate that this data is
63:32 - normally distributed and i'm happy to
63:34 - proceed with um
63:37 - et tests
63:38 - but let's assume that
63:40 - there is no data here
63:43 - and this data is located here which
63:46 - means that even if i transform it i do
63:48 - not get a dumbbell shape or i cannot put
63:51 - a dumbbell curve across these points
63:56 - then i will begin to think about
63:58 - using a different type of t-test which
64:01 - is the non-parametric test which i won't
64:02 - be covering here
64:05 - now
64:06 - let's be practical here
64:08 - so let's say
64:10 - we want to know i did mention we want to
64:13 - know the mean heights
64:15 - of individuals on this call
64:17 - and we know that the standard or the
64:20 - assumed standard
64:21 - of heights should be let's say
64:24 - seven feet
64:27 - so when we
64:28 - when we measure everybody's height in on
64:30 - this call
64:31 - we want to make sure that the mean
64:34 - is equal to
64:36 - seven
64:39 - so our high our null hypothesis would be
64:42 - that there is no difference
64:45 - while our alternate hypothesis will be
64:47 - that there is a difference
64:50 - there are two ways we can do that
64:56 - so we can either perform a one-sided
64:58 - test just check basically if
65:00 - the heist that we've measured
65:02 - is greater or lower than the standard
65:04 - which i have discussed
65:08 - or we can do the two-sided to see if
65:11 - there is any difference whatever the
65:13 - difference is whether higher or lower
65:16 - so i'm going to show us the result of
65:18 - these two analysis
65:23 - so in the first case
65:30 - in the first case
65:32 - we have
65:33 - [Music]
65:34 - um we have the results of the one-sided
65:37 - t-tests
65:41 - and it's telling us
65:42 - what happened
65:44 - okay so it's telling us
65:46 - that
65:47 - the difference the p-value is about 2 to
65:50 - the power -16
65:52 - that means
65:53 - the true mean is not equal to 27.
65:58 - so what about if we change this true
66:00 - mean to say
66:02 - 5
66:03 - for example
66:10 - so let's just say we change this mean to
66:12 - just five
66:14 - and we perform this analysis again
66:18 - it's going to tell us
66:21 - that the alternate hypothesis is true
66:23 - because the true mean is greater than 5
66:26 - it's 5.8
66:28 - so if we make the true mean exactly this
66:30 - number here
66:32 - then it's going to tell us that there is
66:34 - no difference
66:36 - so let's just do this so that we can see
66:38 - that as well
66:40 - [Music]
66:43 - so it's telling us the alternate
66:44 - hypothesis is not true the true mean is
66:46 - not equal to this and
66:50 - it's computing the test statistics for
66:52 - us
66:53 - so this way we can compare
66:56 - the mean
66:57 - of our heights to the standards that we
67:00 - know
67:01 - and this can be applicable to so much as
67:04 - to so many types of data and scenarios
67:08 - so if you was let's say for example you
67:11 - you actually collected some financial
67:14 - information
67:15 - and you want to see that the stock the
67:17 - mean stock over this week is equal to
67:20 - a particular standard that you have set
67:22 - say hundred
67:24 - and then
67:25 - you computed the information and then
67:27 - you check the mean
67:29 - to your standard and compare it it will
67:32 - tell you if there is any difference or
67:34 - not
67:36 - so how about
67:38 - if we want to look at
67:42 - more than just one um category so we're
67:45 - trying to look at this
67:49 - the lens but this time around we're
67:51 - looking at it across the different
67:53 - species
67:54 - so we're going to look at um
67:56 - the two sample t tests
67:58 - so here we have
68:01 - the assumption is that it has to be two
68:03 - samples remember
68:05 - but in the data that i presented we have
68:08 - three species which means it's more than
68:10 - two already that means
68:12 - t-test will not work
68:14 - however
68:16 - because i want to show us how to perform
68:18 - this type of t-test i did subset the
68:22 - data so that i can only extract only
68:26 - two categories or two species
68:29 - you can choose any species you want
68:32 - and then
68:34 - i'm going to show that and then i'm
68:35 - going to show the t tests
68:39 - so first of all i'm showing here that
68:41 - i've only gotten data from two species
68:44 - so i have omitted the data from the
68:46 - third specie
68:48 - secondly i've been able to compute the
68:50 - same information the same
68:53 - test statistics as i did here but this
68:55 - time around
68:56 - without any specif without specifically
68:59 - telling it's the standard
69:01 - so i am comparing the mean
69:04 - across these two species
69:07 - to see if there is a difference between
69:09 - the heights or the lens sorry
69:11 - across these two species
69:14 - we can do that again
69:17 - we can look at individuals on this core
69:19 - and we can say the mean heights so we
69:21 - cut we're comparing the mean heights of
69:23 - male versus female
69:26 - participants in this call
69:29 - note that i did not tell it's what the
69:31 - standard should be it's just looking at
69:33 - the two means
69:35 - and then it will tell us
69:36 - if the male
69:38 - or the female participants are taller or
69:40 - their mean height
69:42 - is greater or less than
69:43 - the other
69:46 - how about when we have
69:49 - all three all three uh species and want
69:51 - to compare across all three of them
69:55 - it's still possible to do that
69:57 - but note that it is not going to be the
70:00 - t-test it has to be an anova
70:04 - similar to the t-test
70:07 - the anova has its own assumptions which
70:09 - i won't be covering in this workshop
70:12 - but again
70:13 - one of the criteria is that you have to
70:14 - check for normality
70:17 - is the data normally distributed
70:20 - or not
70:22 - note that there are two ways you can do
70:24 - that you can use the sh
70:26 - the function call or you can use the
70:27 - histogram
70:30 - some researchers and some data
70:31 - scientists have encountered prefer to
70:33 - use the shapiro tests
70:36 - because sometimes they don't want to
70:38 - output anything they just want to know
70:39 - that it's there it's working
70:41 - they embed it in their function call
70:44 - however
70:46 - you can always do that
70:47 - because it's always good to be conscious
70:49 - so that you don't make
70:51 - um statistical predictions that are not
70:54 - true
70:55 - because you've omitted a particular step
70:58 - now for the anova
71:00 - it has to be more than two um treatments
71:04 - that you're comparing
71:07 - so
71:08 - in the case of anova we're going to look
71:10 - at the three species simultaneously and
71:13 - we're going to look at
71:14 - the lengths across these three species
71:19 - another thing is this
71:21 - anova works especially in air
71:24 - by developing
71:26 - a linear model
71:28 - what does that linear model mean is
71:29 - trying to establish a linear
71:31 - relationship
71:32 - between the lines
71:34 - in the different species
71:37 - so the first thing i would do if i'm to
71:39 - generate an anova statistics is to
71:42 - generate a model
71:44 - okay
71:45 - and then i can output the anova model so
71:48 - that we can see
71:50 - and then call the anova function on the
71:52 - module
71:54 - so
71:55 - basically what i have access
71:57 - is is there any difference in the length
71:59 - similar to what i would have asked the t
72:01 - tests
72:02 - and it's telling me that there is a
72:04 - difference
72:05 - the p value here
72:07 - is
72:08 - 1.6 to the power minus 31 which means
72:12 - that there is a very significant
72:13 - difference
72:14 - between
72:16 - the length across these species
72:19 - if there was no difference with top-up
72:21 - dance
72:23 - however as data scientists you don't
72:25 - just tell people
72:27 - oh there is a difference
72:30 - the question is where is the difference
72:33 - how do i identify the difference
72:37 - so
72:37 - there is what we call the post talk
72:39 - tests for anova
72:42 - you do you perform the post hoc test to
72:44 - identify
72:46 - exactly where the difference is
72:49 - some other people prefer to use a box
72:51 - plot
72:52 - sometimes it's not always obvious in the
72:54 - box plots so i'm going to show us that
72:56 - method
72:58 - i'm going to show us that we can present
73:00 - the same information as a post talk and
73:02 - as a box plots
73:05 - [Music]
73:06 - so first of all
73:08 - we have to perform a tricky
73:11 - hsd test
73:13 - and here we can look at from here you
73:15 - can see that there is a difference here
73:20 - so there's difference between this group
73:23 - and the difference is greater compared
73:25 - to the rest of the group
73:28 - now
73:28 - we can represent the same information in
73:31 - the box plots
73:34 - look at it
73:36 - we can tell that there is difference
73:37 - between these two
73:39 - and the difference between this
73:42 - virginica
73:44 - and basic color is not as much as the
73:47 - difference between virginica and
73:49 - septusa
73:51 - and
73:52 - again
73:53 - we could represent this information
73:56 - in our post-hoc tests
73:59 - and in our
74:01 - box plots
74:03 - there are also other
74:05 - types of um
74:07 - statistical analysis that we can perform
74:10 - inferential analysis
74:12 - some of them may include things like
74:14 - linear regression
74:17 - linear regression is not far from what
74:19 - we've done here
74:21 - by generating scatter plots
74:23 - the only difference is that we needed to
74:26 - put a line of best fits
74:29 - and generate the
74:30 - the linear
74:32 - equation
74:35 - so it is very similar so the beauty of
74:38 - it is this
74:40 - take home message from me
74:42 - there are a thousand and one ways
74:44 - that
74:46 - you can present information
74:48 - the same information
74:51 - once you know the audience that you want
74:53 - to capture
74:55 - that you can tell on your presentation
74:57 - to them
74:59 - for example
75:00 - if you're dealing with people in the
75:02 - industry
75:04 - they want a pictorial representation of
75:06 - anything that you're telling them
75:08 - not tables not chats they want to see
75:11 - the patterns
75:13 - they want to see how you arrived at your
75:15 - conclusions
75:17 - at the glance they don't want you to
75:19 - know the computational aspect
75:23 - number two
75:24 - statistics is very simple and
75:26 - straightforward
75:27 - once you understand the basic principles
75:29 - and concepts
75:31 - you will find out that they will become
75:33 - very handy
75:34 - as you advance
75:36 - and
75:38 - for a biologist like myself
75:41 - diving a lot into statistics it tells a
75:43 - lot
75:45 - half of all the experiments even though
75:48 - we perform them in the wet lab we try to
75:50 - substantiate or
75:53 - draw inferences based on statistical
75:56 - values not just necessarily what we
75:58 - obtained in the lab
76:02 - the same for every sector of
76:05 - you know of the economy and our lives
76:09 - when people
76:11 - conduct interviews and compile them
76:15 - they also find a way to present them in
76:17 - form of
76:18 - numbers frequencies and patterns
76:22 - so
76:23 - no matter how far or how wide we go
76:26 - statistics is a part is an integral part
76:29 - of the society
76:32 - and the earlier we embrace it
76:34 - the better for us
76:36 - so just to recap and then i would take
76:38 - the questions
76:42 - so
76:45 - so we've introduced the different types
76:46 - of statistical analysis
76:48 - we've mentioned different applications
76:50 - that facilitate
76:52 - statistical analysis
76:54 - and we've presented some examples of
76:56 - descriptive and inferential statistics
76:59 - so
77:00 - i am happy to answer any questions that
77:02 - we may have
77:06 - all right
77:08 - thank you austin
77:09 - thank you uh
77:11 - let me
77:12 - i know that we had a few from uh about
77:14 - like an hour ago but hopefully the
77:16 - person's still around iveta i think
77:18 - uh the name is ivetta um compromising
77:21 - wrong really sorry
77:23 - uh her the question was
77:26 - i'm about to start my master's degree in
77:28 - data science and analytics analytics in
77:30 - the uk i'm worried about not being able
77:33 - to find good data for my final final
77:35 - dissertation project any tips
77:40 - yeah so that's a very good question
77:44 - now
77:45 - the the tip i'm gonna ask is first of
77:47 - all define the scope of what analysis
77:49 - you want to
77:50 - perform
77:52 - so the scope will guide you in your
77:54 - search for data
77:56 - there is something out there
77:58 - it might not be perfect
78:00 - but when you have a clearly defined
78:02 - scope
78:03 - then you don't have to look everywhere
78:04 - you know where to look
78:08 - okay so i guess the advice is make sure
78:10 - that your scope is defined properly and
78:14 - that will help you make sure that the
78:15 - data you're collecting or the data
78:17 - you're using is
78:18 - the the right kind i guess
78:20 - since the person is worried about
78:22 - quality of the data i guess i'm finding
78:24 - good data for the dissertation
78:26 - um
78:27 - okay uh send it
78:30 - had a question
78:32 - is
78:32 - i started studying software engineering
78:34 - this year
78:35 - uh will this lecture be helpful i asked
78:38 - the user they were going to use data and
78:40 - they said
78:41 - i'm in my third year i will have to
78:43 - choose oh in my third year in software
78:46 - engineering i'll have to choose a
78:47 - specialization which could be data
78:49 - science so i guess what they're asking
78:51 - more is um i guess that the question in
78:54 - general is should they go focus in data
78:56 - science if they are studying software
78:57 - engineering and they have to uh
78:59 - focus in one particular area i guess
79:01 - you're biased because you do data so of
79:02 - course you're gonna say yes but uh maybe
79:04 - you can explain a little bit of the
79:06 - different fields
79:08 - actually
79:09 - so software engineering is broad no
79:12 - doubts
79:14 - there are so many
79:16 - aspects to it
79:17 - but again
79:18 - one thing that they need to understand
79:20 - is that
79:21 - no matter what software you write
79:24 - your results
79:26 - your conclusions are still going to be
79:28 - based on data
79:30 - and statistics
79:33 - somebody needs to put in some numbers
79:34 - into your software and get results that
79:37 - will be convincing
79:39 - so data science is an integral aspect of
79:42 - software engineering no matter how
79:45 - little you want to dive into it
79:48 - for someone
79:50 - for me i like numbers
79:53 - so for someone like me i would want to
79:55 - specialize in
79:58 - numbers
79:59 - more
80:03 - i would like to specialize in numbers
80:04 - more
80:05 - because that way i can i can actually
80:08 - derive a lot more information
80:12 - so i will encourage her to go and there
80:14 - are lots of job opportunities as well in
80:16 - data science
80:18 - i think that uh uh i've heard other data
80:21 - scientists explain that a main focus of
80:24 - data even if you don't work with it
80:25 - every day is that you need to show your
80:27 - work
80:28 - and a lot of times when you're talking
80:30 - to your manager or your boss and you're
80:32 - trying to maybe get a new project off
80:33 - the ground or get resources for a new
80:35 - idea they will often ask why and how are
80:39 - you showcasing that this is important
80:41 - and if you're able to collect the right
80:43 - data and present it in a way that is
80:45 - compelling and that is useful
80:47 - uh it facilitates that sort of
80:49 - conversation where you say well here's
80:50 - the data and here is
80:52 - what we see that's why i think we should
80:54 - invest more in this or that's why i
80:55 - think we should put more effort into
80:57 - that area or this area so i know that
81:00 - that's a big argument for everyone to
81:02 - learn sql for example or to learn uh the
81:05 - basics of data visualization
81:08 - yep john you're actually correct i mean
81:11 - if you
81:12 - remember during the course of my
81:13 - presentation when i talked about
81:15 - ways of presenting data
81:17 - i made a case for somebody going to
81:20 - their parents or guardian to ask for
81:21 - more money
81:23 - it's similar to this case so if you want
81:25 - to if you want to
81:27 - ask for a new project or change the
81:29 - direction of your project based on
81:32 - information you have you need to you
81:34 - need to have something warm substantive
81:37 - so you need to have something that they
81:39 - can visualize and identify without you
81:42 - having to explain anything and that's
81:44 - the power of
81:45 - data visualization
81:48 - so
81:49 - if you are yourself with the right
81:52 - figures
81:54 - from the right information you can get
81:57 - any projects you know started
82:00 - so yes it's really important i know i
82:03 - had a math professor in high school that
82:05 - said statistics was really hard because
82:07 - you can always make the data say
82:09 - whatever you wanted to say uh if you
82:11 - start
82:13 - changing the data or only looking at
82:14 - certain data visualizations but in a
82:16 - particular way he said you know if if
82:20 - the if a study came out that said that
82:21 - the last car in a train is the most
82:24 - dangerous then someone would say well we
82:26 - just have to remove the last car but
82:28 - there's always going to be a last car so
82:30 - it's kind of it's a simple example of
82:32 - like how sometimes you will come up with
82:34 - conclusions and you have to make sure
82:36 - that you know
82:37 - data will always tell your story it's
82:39 - just making sure that you're asking the
82:40 - right questions and that you know what
82:42 - you're answering
82:44 - exactly
82:45 - so
82:47 - yeah that's that brings you back to
82:48 - statistics
82:50 - like you said you can beat the data
82:53 - and the more you beat it the more
82:54 - information you get out but what is the
82:57 - quality of that information is the right
82:58 - kind of information you're getting out
83:00 - or the wrong kind of information
83:02 - i'll give an example
83:04 - so let's say for let's say for example
83:07 - we want to
83:08 - track the devastation
83:11 - um devastation pattern in a particular
83:14 - country
83:16 - now we've collected data
83:18 - across the country and then you analyze
83:21 - a portion
83:22 - where there is less fascination and then
83:24 - you make a conclusion that oh the
83:26 - vaccination rate in this country is low
83:30 - it's the same data but you've only
83:32 - analyzed a portion of the data and
83:33 - you've made a generalistic conclusion
83:35 - which is biased
83:38 - now i know that that happens a lot with
83:40 - uh political intention right like
83:41 - sometimes they would say
83:43 - um
83:44 - sometimes there might there might be
83:45 - some statistics in the news that say the
83:47 - the intention to vote is 60 40 this way
83:50 - or that way and then you look at the
83:53 - fine print and you'll realize that they
83:55 - are extrapolating out of maybe
83:57 - 3 000
83:58 - questions that they had in a souvenir in
84:00 - a survey or something like 3 000 people
84:02 - are deciding
84:03 - uh how the intention of vote is for an
84:05 - entire country like i know that that it
84:07 - can be difficult sometimes to understand
84:09 - how small amounts of data can uh project
84:12 - so much
84:13 - well that brings us to the other type of
84:16 - data that i didn't cover in this context
84:18 - so i did mention something about
84:20 - predictive data analysis
84:24 - so
84:25 - let's talk about that a bit more let's
84:27 - say we have information about a certain
84:29 - group of let's say we have a certain
84:32 - information about a certain geographical
84:34 - location their voters
84:36 - and we've sampled
84:39 - say
84:39 - 3000 like you said
84:42 - but we know that within this demography
84:45 - this 3000 replace represents
84:49 - you know
84:49 - independence groups within that
84:53 - by independent group i mean independent
84:55 - clusters so let's say for example you
84:57 - have the location and then you have the
84:58 - blacks the hispanic and
85:00 - whatever ethnic group and then you
85:01 - sample each one of them so it's the full
85:03 - representation of the population because
85:06 - you have samples from each one of them
85:08 - and then they all say something so let's
85:10 - say 60 percent says they're getting
85:12 - false
85:13 - so you're going to make that assumption
85:14 - because you have a representation of the
85:17 - demographic
85:18 - but it's not always correct
85:20 - so that brings sometimes people you know
85:23 - double it between population and sample
85:26 - studies
85:28 - but
85:29 - how do you get everybody to say
85:31 - something very difficult not possible
85:34 - so we what if the data is tainted right
85:36 - what if you were paying them a hundred
85:37 - dollars for replying to your survey like
85:39 - then you have other biases right you
85:41 - know if you coerced an answer
85:43 - [Laughter]
85:46 - in the survey
85:47 - i
85:48 - i think that there usually is some some
85:50 - followed way to top
85:52 - these
85:56 - yes so but then
86:00 - there is always going to be the tendency
86:02 - for bias
86:03 - however you do what you can to minimize
86:06 - it and you minimize it by asking the
86:08 - right type of questions
86:10 - and collecting the right type of data
86:15 - i don't know if that makes sense to you
86:17 - so let's go back to the voting
86:19 - population if you go to
86:22 - yeah sorry uh sorry for interrupting i
86:24 - was just looking at the chat and uh
86:26 - yvette actually had another question
86:27 - that uh
86:28 - that might be related to this where we
86:30 - were talking about the types of data and
86:32 - how to collect it and the question was
86:34 - if you have any advice for applying for
86:36 - jobs as a data scientist and i guess
86:37 - this kind of like wraps into the idea of
86:39 - what data you want to work with what
86:41 - you're interested in i would imagine
86:43 - that you can be a data scientist in the
86:45 - weather forecast right looking at the
86:46 - predictive models of storms you can be a
86:48 - data scientist in medicine
86:50 - or environment in biomedical like you
86:52 - are um
86:53 - do you uh do you have any thoughts on
86:55 - like how someone with a background in
86:58 - data science
86:59 - focus finds the right data to work with
87:01 - or explores different fields
87:05 - as a professional
87:07 - yeah actually i do so the first thing i
87:10 - would suggest is
87:12 - to ask the person
87:14 - what he or she likes
87:17 - because you start from your likes
87:20 - for me
87:21 - i love biology
87:23 - so even though i work in data science i
87:26 - always tell my finest was biology
87:30 - but again i do some teaching and some of
87:33 - my students actually
87:35 - are finance students so when i teach
87:37 - them i have to tell it to finance
87:40 - so
87:42 - for them
87:43 - they're coming to data science but their
87:45 - intention is to make financial
87:47 - predictions
87:49 - now once you answer that question what
87:52 - do you love
87:53 - what motivates you that the next
87:55 - question you're going to answer is what
87:58 - are the skills i need to achieve it
88:01 - because data science is very broad
88:06 - some people will tell you python is the
88:07 - way forward
88:09 - and some people will tell you oh no hold
88:11 - on ah
88:12 - even people that do advanced exam will
88:14 - tell you is the way to go
88:17 - so
88:18 - when you identify what you like
88:21 - and identify what you need to do
88:24 - or what skills you need to gain
88:26 - to act to accomplish that
88:29 - then you're good
88:31 - did uh did you mention excel people use
88:34 - excel for advanced uh what's in uh
88:36 - what's in the the uk last year when they
88:38 - had a crash in their systems because
88:40 - they were tracking vaccinations through
88:42 - an excel sheet and it maxed out on the
88:44 - number of rows they could echo track
88:46 - yeah so that happened last year
88:50 - it was kind of embarrassing and
88:52 - fascinating at the same time
88:53 - because some people's databases are
88:56 - actually a collection of excel files
89:00 - i don't know okay
89:01 - this is usually wrong it's not it's not
89:02 - a problem with excel it's a problem with
89:04 - the implementation
89:06 - exactly
89:07 - so
89:08 - they can tell you oh
89:15 - sam what did he say
89:17 - no i was i was confirming like go on i
89:20 - was confident oh okay
89:22 - so yes some it's kind of weird what
89:25 - people call databases this
89:28 - you can actually have um
89:29 - [Music]
89:30 - an office document that contains you
89:33 - know lines of information and then you
89:34 - say this is my database and nobody's to
89:37 - query you but yes
89:40 - okay
89:42 - uh sam do you have any other questions
89:44 - for the guests today
89:46 - um well
89:48 - um augustine you you really were like
89:51 - this is really detailed
89:53 - um
89:54 - if i hadn't made it switch to software i
89:58 - would
89:59 - i would just say no data science all the
90:01 - way because you you were really specific
90:04 - and you spoke broadly about on the topic
90:08 - of data and why data is important and
90:11 - how it costs across every field i did
90:14 - have a question about how to handle bias
90:16 - but during the course of our
90:18 - conversation you kind of like you know
90:21 - talked spoke about that i i don't see
90:24 - any more questions on
90:26 - youtube
90:27 - so um
90:29 - i would love to thank everyone who
90:32 - found time to be here again i'd love to
90:35 - thank
90:36 - um the code academy hq
90:39 - team love to thank fed love to thank you
90:42 - our honored um guest we are we're so
90:46 - grateful on behalf of from code academy
90:48 - hacker chapter thank you for finding the
90:50 - time um it is we started very early your
90:53 - time which is around pm not everyone
90:56 - would
90:57 - want to do that um you have indeed shown
91:00 - that you are truly altruistic as regards
91:04 - education and
91:05 - talking about data i believe i mean
91:08 - in the long run moving forward that
91:11 - legacy will live on
91:12 - your love for data and your love for
91:15 - talking about
91:16 - data and educating people so just want
91:19 - to say thank you on behalf of cool
91:21 - academy for hackers yeah thank you no
91:24 - problem we love it uh you know any
91:26 - information that we can gather i mean
91:28 - augustine knows his stuff and i'm sure
91:30 - there's a lot of people that are gonna
91:31 - watch this other live today or in the
91:33 - future they're gonna come to your
91:34 - channel and they're gonna
91:35 - they're gonna have a lot of questions
91:36 - that i'm sure that augustine is
91:38 - answering already before they even ask
91:39 - the questions so that's great we're pre
91:42 - preemptively answering questions on data
91:44 - science uh i think before we leave uh
91:46 - augustine i don't know someone was
91:48 - wondering if the jupyter notebook that
91:50 - you were using has an example that's
91:52 - available publicly
91:53 - or maybe there's some way that they can
91:55 - reach to you or contact you so they can
91:56 - get some of those examples
91:59 - uh if they reach through some
92:01 - i will be able to get it to some my
92:03 - problem okay
92:05 - perfect so if you want to get access to
92:08 - ice yeah
92:09 - i saw that
92:16 - and i was
92:17 - thinking that
92:19 - um
92:21 - yeah i was thinking that augustine could
92:22 - send it to me
92:24 - and i see you fed which um you can
92:27 - include in the description in the
92:29 - youtube description um like
92:34 - okay yeah we can uh we can definitely
92:36 - include uh a link to the pork court
92:40 - chapter and then if anyone wants to
92:41 - reach out to you they can just use the
92:43 - chapters page
92:44 - to send you an email or contact you
92:47 - great well i guess that wraps it up for
92:49 - today thank you everybody for stopping
92:50 - by
92:52 - and
92:53 - we'll see you in the next live stream
92:55 - right
93:00 - okay
93:01 - bye everybody
93:02 - [Music]
93:04 - like