00:02 - should
00:03 - be working
00:10 - think that we are live um but as per
00:13 - usual we will just give it
00:15 - a minute to get things set up
00:18 - um let us know in the chat
00:22 - if you are there uh we're we're keeping
00:25 - an eye on the youtube chat
00:27 - so if you're watching from a different
00:30 - streaming service
00:32 - we might not see your messages so come
00:35 - on over to
00:36 - youtube if you'd like to talk to us
00:39 - throughout the stream
00:41 - for those that haven't watched before
00:44 - i'm sophie
00:45 - and this is jamie who's going to be
00:47 - joining me today
00:48 - walking through some hypothesis testing
00:51 - for associations
00:53 - we're really excited to get started
00:56 - i think ooh select star from awesomeness
01:00 - i like it
01:01 - yeah that's what we're going for
01:05 - uh on this kind of where i am it's a
01:08 - little bit cloudy
01:09 - and i don't know i'm ready for some some
01:12 - fun coding
01:13 - together cool
01:16 - so it seems like people can see us and
01:20 - we might as well get started because
01:22 - we've got a lot of material to get
01:24 - through today i don't know how much of
01:25 - it we will actually get through
01:28 - um so with that i will share my screen
01:32 - so if you do have one question from the
01:35 - chat did she break alex after last week
01:41 - no i i don't think i broke alex alex
01:44 - could live stream all day long if if
01:47 - somebody would
01:48 - allow him um but
01:52 - we wanted oops that is not what i meant
01:55 - to share
01:55 - um we wanted to uh
01:59 - mix it up a little bit jamie also very
02:02 - much
02:02 - enjoys live streaming so um
02:05 - and he is also helping me with some of
02:07 - the master statistics
02:09 - uh phase two work right now
02:12 - so um so yeah we're
02:16 - we're all uh kind of running this live
02:19 - stream series together me alex
02:21 - and jamie and we're excited to have
02:24 - jamie today
02:26 - i'm excited to be here yeah
02:30 - and alex is in the chat confirming that
02:32 - i didn't break him
02:35 - so all right let's get started um so
02:38 - this week we're actually going to be
02:40 - returning to a data set that we used
02:42 - earlier in this series
02:46 - so this is i think it's the first data
02:48 - set we actually use
02:51 - it's the heart disease data set so as a
02:53 - quick reminder
02:55 - this is a set of data for a sample of
02:57 - patients
02:58 - who were screened for heart disease and
03:02 - some information about those patients
03:04 - was collected
03:05 - um and
03:09 - we're gonna focus in on a smaller subset
03:12 - of that
03:13 - larger data set that we looked at in the
03:15 - first week
03:16 - and so for this week we're just going to
03:18 - look at a few
03:19 - of the variables um and we're going to
03:23 - see if we can try to understand the
03:25 - relationship between each of those
03:27 - variables
03:28 - and this heart disease variable which
03:30 - indicates whether or not a patient was
03:32 - ultimately diagnosed with heart disease
03:36 - um i see yeah i see some people from
03:40 - various places in the chat and i see a
03:42 - question what do you do when you don't
03:43 - work on data
03:45 - um i i mean
03:49 - i don't know i feel like there maybe
03:51 - there's two ways to interpret that
03:52 - question but i feel like we're all just
03:54 - working on data all the time
03:56 - data is everywhere um
04:00 - anyway so basically
04:04 - similar questions to what we were
04:05 - looking at the last time jamie was on
04:07 - um so i think the last time jane jamie
04:10 - was on we were talking
04:12 - or actually maybe two times ago we were
04:14 - talking about
04:15 - uh relationships between variables and
04:18 - we looked at
04:19 - some plots and we looked at some summary
04:21 - statistics like correlation
04:24 - or um a difference in means
04:27 - and in that case we were looking at
04:31 - a data set and calculating summary
04:33 - statistics for that exact data set
04:35 - but in this lesson we're going to start
04:38 - talking about
04:39 - hypothesis testing for an association
04:42 - and the reason why this is a little bit
04:44 - different
04:44 - is that in this example we have this
04:47 - sample
04:48 - um here i'll actually run some of this
04:52 - code so that you can see
04:54 - uh we can take a look at the info
04:57 - actually see how many rows there are
05:02 - um right so there's 303
05:06 - uh patients in this data set
05:09 - so we could calc or we could look at
05:12 - this data set and understand the
05:13 - relationships between different
05:15 - variables
05:16 - so we could understand like are there
05:18 - more males or females who are diagnosed
05:20 - with heart disease or
05:22 - do people who are diagnosed with heart
05:23 - disease in this data set tend to have
05:25 - higher cholesterol or something like
05:27 - that um
05:29 - for today though we're not interested in
05:33 - just this data set
05:34 - we're actually gonna be trying to think
05:37 - about how this data set can tell us
05:39 - something about heart disease more
05:41 - generally
05:42 - so we're going to kind of open things up
05:45 - and say like
05:46 - based off of this data we're going to
05:49 - imagine that this data is
05:50 - randomly sampled so these people were
05:52 - randomly sampled from the general
05:54 - population
05:55 - we're going to say based on this data
05:56 - can we understand what predictors
05:59 - are or what variables what things about
06:01 - a person
06:02 - are most predictive of whether or not
06:04 - they're diagnosed with heart disease
06:06 - out in the world not just in this data
06:08 - set
06:10 - cool um great so
06:14 - i see there's a question about what kind
06:16 - of data is this
06:18 - um this is well
06:21 - i'm going to answer that two ways so
06:23 - this is a tabular data set
06:25 - um in its format so jamie do you want to
06:28 - discuss really quickly what
06:29 - tabular data is um so yeah tabular data
06:32 - is basically just data
06:34 - that is in table form as we see here so
06:36 - each
06:37 - column represents a variable in the data
06:40 - set so we have
06:41 - age sex trust bps
06:45 - called you know just like a bunch of
06:46 - different columns and then the values
06:49 - within the columns like
06:50 - are part of like each of these variables
06:52 - so some of the variables in this data
06:54 - set
06:55 - are categorical and some of them are
06:57 - quantitative
06:58 - um so for example um i think like one of
07:01 - the
07:02 - columns that we're going to look at here
07:03 - is going to be that
07:05 - i might pronounce this wrong style yeah
07:08 - memes are really bad so i think this is
07:11 - uh foul so sal
07:15 - refers to the heart and then this is
07:17 - short for
07:18 - achieved um because it's related to like
07:21 - the heart rate that you achieve during
07:24 - an exercise test
07:25 - um yeah we'll go over the exact meaning
07:30 - but exactly so the the tabular tabular
07:33 - data is just data that's arranged in
07:34 - rows and columns
07:37 - and then kind of the next level down
07:40 - in terms of what kind of data this is is
07:43 - it's being stored as a csv file
07:46 - um which is just a common format
07:49 - for storing tabular data but there's
07:51 - lots of other ones that we could read in
07:54 - cool so i think let's get started um
07:58 - i'm gonna kind of walk through
08:02 - some examples of tests and then even
08:04 - though this is not
08:05 - in the stats path i think we're gonna do
08:08 - some simulations of tests too because i
08:10 - think
08:10 - i think it's fun and it helps us
08:12 - understand
08:14 - so um the first thing i want to do is
08:17 - let's let's take a look at some of the
08:21 - quantitative variables so things like
08:24 - we'll go through what they all are so
08:25 - we've got age
08:26 - which is just the age of the person in
08:28 - years
08:30 - t-rest bps is um
08:34 - i believe a blood pressure reading
08:37 - at rest so bps is blood pressure and t
08:40 - rest is yeah um i think
08:44 - blood pressure at rest uh
08:47 - call is cholesterol levels we're gonna
08:50 - ignore these two i think if you joined
08:53 - in the first
08:54 - serie or first session you'll see these
08:56 - are actually
08:59 - categorical variables and then
09:03 - we'll focus on val achieved or
09:07 - heart rate that's achieved during in
09:09 - exercise
09:10 - tests yeah okay we have a
09:14 - um another question that i think will be
09:16 - of interest to you in the chat
09:17 - so someone asked when inspecting
09:19 - associations at this level can we talk
09:21 - about predicting
09:22 - as in flagging which variable is
09:23 - predicting watch
09:25 - yeah so i think it's really i'm not sure
09:29 - if i fully understand the question so if
09:31 - i don't ask
09:32 - or if i don't answer it to uh
09:35 - to the degree that you're hoping then
09:37 - definitely let me know and i can try
09:39 - again
09:40 - um but i think it's interesting to
09:41 - actually think about the difference
09:43 - between
09:44 - looking at an association and
09:48 - figuring out whether you can use that
09:50 - association to make a prediction
09:53 - um and so
09:56 - if you see an association in the data um
10:00 - it doesn't necessarily mean that one
10:02 - thing
10:03 - causes another and it doesn't tell you
10:05 - about
10:06 - why it doesn't tell you anything about
10:08 - the why um
10:11 - for that association so one piece of
10:14 - the complicate or one piece of
10:15 - complication is that if you really
10:18 - want to make any sort of inference about
10:21 - causality like if you lower your
10:23 - cholesterol
10:24 - you'll be less likely to get
10:28 - be diagnosed with heart disease or
10:29 - something that kind of
10:32 - that kind of research requires a diff
10:34 - requires
10:37 - focus on the the design of the
10:39 - experiment
10:41 - not the actual analysis so much
10:45 - i mean the analysis piece too but
10:48 - you can't really answer those causal
10:50 - questions
10:51 - with simple methods unless you
10:54 - have set up the experiment to do so um
10:57 - but then there's
10:58 - the next piece which is that it's a
11:00 - different problem to try to like set up
11:03 - a predictive um model for example of
11:07 - who's gonna be
11:08 - diagnosed with heart disease based off
11:10 - these factors
11:11 - than it is to look at each individual
11:15 - variable separately um we we definitely
11:18 - have some upcoming
11:20 - new content on predictive models
11:24 - which i think will be hopefully useful
11:26 - to people
11:28 - um but yeah we can definitely
11:31 - look at flagging like
11:34 - thinking about which of these variables
11:36 - for example is most predictive of heart
11:38 - disease
11:39 - um so i'm gonna do
11:42 - what the way i'm gonna do this to start
11:45 - is i'm gonna
11:46 - use that same like group by function
11:48 - that we used earlier
11:49 - earlier on when we were talking about
11:51 - summary statistics
11:52 - so what i'm gonna do is i'm going to
11:56 - group my data set by um
12:00 - heart disease so whether or not someone
12:02 - has heart disease
12:04 - and then i'm just going to calculate the
12:06 - mean
12:08 - of those like by those groups for each
12:11 - of the quantitative variables
12:14 - cool so um looking at this
12:18 - i don't know jamie do you wanna
12:21 - uh talk about any of this like what do
12:24 - you see here
12:25 - we can kind of ignore these two
12:28 - um and focus on the other four so i
12:31 - guess i
12:32 - just like looked for like mean
12:33 - differences across each of the columns
12:36 - so i think the one that sticks out to me
12:38 - the most
12:39 - is uh i still don't remember how
12:42 - the the thalak
12:45 - i'll call it that um the one column on
12:47 - the far right
12:48 - so there seems to be a pretty big mean
12:50 - difference um
12:52 - when heart disease is absent versus
12:54 - present
12:55 - so that might be like one i want to that
12:57 - i would want to analyze
12:59 - and then also the cholesterol level
13:03 - column also seems to be a pretty big
13:05 - mean difference um like
13:06 - when heart disease is present present
13:08 - there seems to be
13:10 - uh there are like when heart disease is
13:13 - present like there's
13:14 - seems to be a higher average level of
13:16 - cholesterol
13:17 - um and then age and the i think the
13:21 - resting blood pressure column
13:22 - like there's also like a somewhat
13:25 - noticeable mean difference so like
13:27 - those are all columns that we might want
13:28 - to analyze to see if there actually is
13:30 - truly
13:30 - a mean difference across these variables
13:34 - for sure yeah so it looks like there's
13:37 - differences across the board
13:39 - but as jamie pointed out some of them
13:41 - are definitely bigger than
13:42 - others so we see like the biggest
13:43 - difference here um and we can also do
13:46 - this for median
13:47 - if we wanted here i'll actually just
13:49 - grab this
13:51 - it might look a little different i'm not
13:53 - sure
13:56 - i think honestly so
13:59 - interesting so for median it's the same
14:02 - median
14:03 - resting blood pressure for the two
14:04 - groups
14:06 - even though it's slightly different here
14:08 - so that's interesting
14:10 - and the median age difference is
14:12 - actually even larger than
14:15 - yeah and that's interesting
14:18 - cool um i think beyond just looking at
14:21 - these
14:23 - pictures it's useful to actually
14:26 - or these tables it's actually useful to
14:28 - look at a picture
14:30 - so um there's a few different options
14:32 - for pictures that we could look at but i
14:34 - find
14:35 - that a box plot is really useful so
14:37 - let's do that let's do it for
14:40 - i think what did i do in the final i did
14:44 - val achieved or that lock i
14:47 - of course she chose the most complicated
14:50 - sounding one
14:51 - um so let's do that so we're gonna do
14:54 - um x equals
14:58 - heart dot um val
15:01 - oh no heart disease
15:06 - and y equals
15:21 - right so we see that differential even
15:23 - more clearly we see that
15:26 - val achieved is is higher for
15:29 - people who have no heart disease or who
15:33 - are not diagnosed with heart disease so
15:35 - basically people taking this exercise
15:38 - test they can get a higher heart
15:40 - their heart rate up higher if they don't
15:42 - have heart disease if they do have heart
15:44 - disease it seems like
15:45 - there's some sort of limit um or a lower
15:48 - limit to how high they can get their
15:50 - heart rate
15:50 - during this test so that's interesting
15:54 - so like i said before i think
15:58 - the next question and actually i think
16:00 - let's pick one
16:01 - that is closer which one was close
16:05 - t-rest bps maybe yeah it's pretty close
16:08 - it had the same medium so
16:10 - right so let's see
16:14 - t rest bps
16:20 - so here's one right where when we looked
16:23 - at the means
16:25 - so let's scroll up for a second looked
16:27 - at the means
16:30 - it seems like blood pressure resting
16:32 - blood pressure was slightly higher
16:35 - for people who had who were diagnosed
16:37 - with heart disease
16:39 - like very very slightly higher mean not
16:42 - even a slightly higher median
16:44 - and when we look at this box plot we
16:46 - kind of see what that looks like it
16:47 - seems like there's a larger range maybe
16:49 - for
16:50 - um resting blood pressure among people
16:53 - with heart disease
16:55 - but for the most part right like these
16:58 - these boxes look pretty close together
17:01 - and the question is is this result like
17:05 - if we found a hundred thousand more
17:08 - people
17:09 - and we collected their resting blood
17:12 - pressure and then we've
17:13 - recorded whether or not they were
17:14 - diagnosed with heart disease down the
17:16 - line
17:17 - if we did this for a hundred thousand
17:19 - more people or a million more people
17:21 - would this picture still look like this
17:23 - would there still be a difference in the
17:25 - means
17:26 - uh what they're not is this just a
17:28 - result of random chance
17:30 - in the same way that we talked about the
17:31 - binomial test and same thing here right
17:34 - like
17:34 - it's possible that
17:38 - there's just a difference between these
17:40 - two groups
17:41 - because of the random sample that we
17:44 - chose
17:45 - i don't know what do you think jamie do
17:47 - you think that this big of a difference
17:49 - could be due to randomness um
17:52 - i think less likely for like the these
17:56 - two box blocks i also think it depends
17:57 - on like the size of the sample so
18:00 - like depending on like 303
18:04 - yeah with like 303 different data points
18:07 - i think that there clearly is like and
18:10 - this like
18:11 - it seems like there definitely is an
18:12 - association for the thalak
18:15 - group um but for like the resting bps i
18:19 - feel like this one is like
18:21 - requires like more analysis to see like
18:23 - is there actually
18:24 - you know like is there actually like
18:25 - some sort of something going on here
18:28 - between the resting
18:29 - blood pressure and like whether or not
18:31 - heart disease is present
18:33 - yeah totally i i tend to agree with you
18:38 - um so i think with that let's let's jump
18:41 - into try to trying to simulate how we
18:43 - would do it how we would run a
18:44 - hypothesis test here because
18:46 - i actually think you know i think two
18:50 - sample t-tests
18:51 - are probably the most commonly used
18:54 - hypothesis test
18:56 - and a lot of people
18:59 - don't know how it works underneath the
19:01 - hood so
19:02 - i think you you all will be really
19:04 - benefited by
19:06 - hopefully seeing this at least once so
19:10 - let's let's give it a try
19:13 - first thing i want to think about is if
19:16 - we're running a hypothesis test
19:19 - we have to start with a null and
19:21 - alternative hypothesis
19:23 - so i'm going to switch to markdown we're
19:25 - going to write out our null and
19:26 - alternative hypotheses really quickly
19:30 - so start with the null
19:35 - jamie what do you think the null
19:37 - hypothesis test is going to be so
19:40 - again what we're trying to understand is
19:42 - is whether
19:43 - um this difference or
19:46 - this difference in group means is going
19:49 - to
19:50 - be true of the whole population so like
19:53 - if we're trying to come up with
19:54 - standards in the
19:55 - in the usa or maybe global standards for
19:59 - um what predicts heart disease or what
20:03 - is associated with heart disease
20:05 - um we want to know if this kind of a
20:07 - mean difference
20:08 - that we're seeing here is going to
20:09 - persist for that larger group
20:12 - so null hypothesis
20:16 - so i would say the null would be that
20:19 - there is no
20:20 - that like there is um no difference
20:23 - um so basically that
20:27 - the like there would be no
20:31 - um mean difference in are we doing uh
20:36 - here uh there's no difference should we
20:38 - choose one that's a little bit easier
20:41 - let's choose let's actually look at
20:44 - what did i do earlier today because i
20:47 - thought that was a good example
20:49 - let's do t-rest bps let's do the resting
20:53 - blood pressure one
20:54 - yeah so for doing uh resting blood
20:56 - pressure it would be that there's no
20:58 - difference
20:58 - in resting blood pressure between
21:01 - patients who
21:02 - have heart disease and who don't have
21:05 - heart disease
21:13 - great okay
21:16 - so and i'm gonna add just one word you
21:18 - might have said this and i just didn't
21:20 - catch it
21:21 - but for the two sample t tests we
21:23 - specifically
21:24 - compare sample means instead of medians
21:27 - um
21:28 - but you could do you could run a test to
21:31 - compare sample medians if you wanted to
21:34 - so here that sounds good to me there's
21:36 - no difference in mean resting blood
21:38 - pressure among patients who do and do
21:39 - not have heart disease
21:41 - well what would be the test you'd run
21:42 - for uh median differences
21:44 - would it be like a similar t-test type
21:46 - thing or is it like called so
21:49 - to be honest you'd probably have uh
21:52 - there's there might be a test but you
21:54 - would probably
21:55 - the only way i can think of to do it is
21:57 - by running this kind of simulation that
21:59 - we're about like building out yourself
22:01 - um because i don't know what the null
22:03 - distribution would be
22:05 - off the top of my head probably look it
22:07 - up um
22:08 - yeah that's a great question i actually
22:10 - don't know that the
22:12 - answer if you if you know the answer to
22:14 - that in the chat
22:15 - then definitely let us know um okay and
22:19 - then the alternative could be one of
22:21 - ver various two different things or
22:24 - various things
22:25 - three different things i guess um let's
22:27 - actually look at
22:29 - the one we haven't looked at a box plot
22:31 - for
22:32 - resting blood pressure let's do that
22:37 - oh no we did we did oh it's here
22:43 - sorry um okay so we we have this here
22:47 - we've seen that um in our
22:51 - in our mean differences that people who
22:54 - had heart disease had slightly higher
22:57 - uh resting blood pressure but the
22:59 - medians were the same and the
23:01 - there's a fair amount of overlap here
23:04 - so let's say our alternative hypothesis
23:08 - is that
23:12 - there is a difference
23:16 - in me and resting blood pressure
23:19 - among patients who do and don't have
23:23 - heart disease cool um
23:26 - okay so with that lined up
23:30 - let's run this um
23:33 - so remember that the thing that we need
23:35 - in order to run a hypothesis test
23:38 - is we need to use the null hypothesis to
23:41 - generate what's called
23:42 - a null distribution so another way of
23:45 - writing this null hypothesis
23:47 - is saying that and i'll actually
23:50 - write it down another way of saying this
23:57 - is that the true
24:00 - mean resting
24:04 - blood pressure of people
24:07 - with heart disease
24:10 - minus the true
24:13 - mean resting blood pressure of
24:16 - people without heart disease equals zero
24:20 - so basically the difference in the mean
24:23 - blood pressures for people with and
24:24 - without heart disease
24:26 - is zero is basically what this null
24:28 - hypothesis is saying
24:30 - i remember writing that a lot um when i
24:33 - took ap
24:34 - statistics yeah it was like for sure
24:37 - classic way to start
24:38 - like the classic yeah usually with like
24:40 - the the greek mew
24:42 - which is i i always loved writing out
24:44 - that greek you because i like
24:45 - it was like the first time i like was
24:47 - using those fancy symbols
24:49 - so fancy um yeah
24:52 - so okay so keeping this in mind right
24:56 - basically what we're going to want to do
24:58 - in order to run a hypothesis test to
25:00 - test this
25:01 - is we're going to want to say okay let's
25:03 - imagine that the true mean
25:05 - between these two things is zero let's
25:08 - generate let's imagine that we took
25:11 - random samples
25:13 - with that with the true mean being zero
25:17 - the true mean difference being zero
25:19 - calculate the mean difference for each
25:21 - of those samples
25:22 - and look at what that distribution looks
25:24 - like that's our null distribution
25:27 - and then we're going to look at the
25:29 - observed mean difference that we got
25:31 - and see where it falls in that
25:32 - distribution so
25:35 - let's like let's actually think this
25:36 - through because i think there's
25:38 - different ways to simulate
25:39 - all these different hypothesis tests and
25:41 - i feel like this one is really fun
25:43 - so jamie do you have any ideas
25:47 - and this is this is a tricky question
25:50 - and i also will
25:51 - ask it of everyone in the chat if you
25:53 - are
25:54 - if you're coding along with us or
25:56 - watching along with us
25:58 - feel free to answer this as well so
26:01 - we have this data set right with um
26:05 - with information for each person i'll
26:07 - reprint it
26:08 - um about whether or not they have heart
26:12 - disease
26:13 - and what their resting blood pressure
26:16 - was
26:18 - do you have any ideas jamie or audience
26:21 - how we could simulate a situation
26:25 - where there's really no difference
26:27 - between
26:28 - the resting blood pressure of
26:31 - people with and without heart disease
26:34 - using this data
26:39 - kind of a hard question i'm gonna just
26:43 - like
26:48 - um so if you want to take like i'm
26:51 - guessing you want to take like random
26:53 - samples like from the data set
26:56 - but you want to make sure like those
26:58 - random samples
26:59 - like don't have a mean difference
27:03 - um yeah really
27:07 - like it's actually like a really fun
27:11 - a fun trick um
27:15 - i'll give you a hint and no
27:18 - nobody from the chat has yet been brave
27:20 - enough so we'll keep
27:21 - we'll keep going with the suspense for a
27:23 - second
27:24 - um it has to do with
27:27 - this heart disease column we're going to
27:29 - do something to this heart disease
27:32 - column
27:37 - oh are you just gonna like randomly
27:38 - assign
27:40 - each like could you basically just like
27:42 - randomly assign
27:43 - things absent and present so basically
27:46 - instead of like
27:48 - actually being associated correctly it's
27:49 - just like random
27:51 - yeah so the mean difference will go to
27:53 - zero
27:55 - exactly so part of the assumption if
27:57 - there's
27:58 - an association here is that
28:02 - whether or not someone has heart disease
28:04 - is gonna
28:05 - somehow impact what their resting blood
28:09 - pressure is so
28:10 - each like row kind of goes together
28:13 - right and the way that we're gonna
28:15 - simulate the null hypothesis
28:17 - is we're gonna break that we're gonna
28:20 - say
28:20 - okay each row doesn't go together
28:22 - anymore this is just a list of
28:25 - resting blood pressures and this this
28:28 - column just tells us
28:29 - how many people have blood pressure and
28:31 - how many people don't
28:34 - but we're gonna kind of i mean we could
28:37 - do this without permuting this without
28:40 - missing this
28:41 - mixing this around by using um like
28:45 - a probability like a sampled probability
28:48 - and use like the
28:49 - probability that you do or don't have
28:51 - heart disease to resample this for
28:52 - everyone but it's easier to just do it
28:54 - by
28:55 - basically taking this column sorry just
28:58 - the heart disease column
29:00 - mixing it around randomly and then
29:04 - recalculating the difference in means
29:08 - for that simulated simulated data set
29:12 - where the simulated data set is our
29:14 - original data set where we just
29:16 - broke the any possible
29:19 - association between these two things
29:23 - that's really cool yeah so let's
29:26 - let's walk through how to do that kind
29:28 - of piece by piece
29:30 - so um first let's just walk through how
29:33 - we would
29:34 - move this um how we would permute this
29:37 - heart disease column
29:39 - so i'm going to just like write this out
29:41 - so i'm going to call this
29:42 - scrambled and we're going to take
29:47 - basically before i call it anything
29:49 - we'll just do this out
29:51 - so i like this numpy.random.sam
29:54 - function and it takes a couple of
29:57 - different parameters
29:58 - the first one is just the thing that we
30:00 - want to sample from
30:02 - so we're going to sample from heart dot
30:05 - heart
30:06 - disease
30:09 - now how many values jamie do you think
30:13 - are we going to sample um the same
30:16 - like number of data points are in the
30:18 - data set
30:19 - yeah exactly so we're going to sample
30:22 - everything
30:23 - in this in this column
30:26 - um so i'm just going to do like blend
30:28 - heart
30:30 - which is going to be 303 and then
30:34 - we want replace equal to
30:38 - what jamie uh so we probably don't
30:42 - want to put like when we take when we
30:44 - sample a data point we probably don't
30:46 - want to return it
30:47 - yeah i mean no you definitely could
30:50 - do sampling with replacement i believe
30:53 - that's called
30:54 - like a bootstrap don't quote me on that
30:57 - because
30:57 - i think that's right um like a
30:59 - bootstrapped sample
31:01 - pretty sure that's right um
31:04 - so you definitely could do that but in
31:06 - this case if we really just want to take
31:08 - all these
31:09 - take this whole com column and randomly
31:12 - rearrange it
31:13 - we'll do replace equals false so
31:15 - basically we're just like
31:16 - we're putting all of these absences and
31:18 - presences
31:19 - in a bucket and we're randomly choosing
31:21 - one at a time
31:23 - and then the first one we choose will be
31:25 - first the second one we choose will be
31:26 - second
31:27 - and so on and we're going to choose all
31:29 - of them
31:31 - again but we're just randomly when we
31:33 - are randomly choosing them we're
31:35 - randomly choosing the order
31:36 - that they're gonna be in whoop and
31:40 - clearly i did something wrong is this
31:44 - no let's see what i did in my
31:48 - example code you might need to
31:52 - specify or replace if it's not
31:53 - necessarily oh you already did specify
31:55 - replacements
31:59 - oh i think it's dot choice not dots
32:01 - [Music]
32:03 - yes all right guys
32:07 - okay so there we go we see now this has
32:11 - been
32:11 - reordered um so before the first ones
32:15 - were absence presence presence
32:17 - absence absence now we've got absence
32:20 - presence absence absence
32:21 - absence so a little bit of a reordering
32:25 - and the entire this entire column has
32:27 - basically been reordered
32:30 - so i'm going to do is i'm going to save
32:31 - that as scramble
32:34 - so that's my scrambled heart disease
32:37 - um output whoops some
32:42 - for some reason this jupiter notebook
32:45 - when i zoom in
32:47 - i like can't put my cursor at the end
32:50 - um okay so the next thing we're gonna do
32:55 - is we're going to use that scramble
32:57 - version
32:58 - to recalculate a difference in means
33:01 - so we're going to say okay now we're
33:04 - going to make our
33:05 - simulated t-rest
33:09 - bps for people with heart disease
33:12 - we're going to set that equal to
33:17 - heart.t rest bps
33:21 - but we're going to take just the resting
33:23 - blood pressures
33:24 - where scram the scrambled heart diseases
33:29 - are equal to presence
33:33 - so i think you have a tiny typo on the
33:36 - secondly i think it's i think it's bps
33:38 - not bsp
33:41 - good catch um
33:45 - okay and then i'll copy that
33:49 - and we're gonna do for no heart disease
33:54 - it's where our scrambled is equal to
33:57 - absence
33:59 - and then sim
34:03 - mean diff is going to be the difference
34:06 - in means between those two so it's going
34:08 - to be
34:09 - mean of this
34:13 - minus mean of this
34:21 - um so i see as we're doing this i see a
34:24 - question
34:25 - asking is this a statistical class or
34:27 - python
34:28 - um it's actually kind of both
34:32 - it's really a stats class um but we're
34:35 - using python so if you want to
34:37 - also get comfortable with python i think
34:40 - this is a great way to do it especially
34:42 - if what you're interested in
34:43 - is stats or data analysis or data
34:46 - science
34:50 - this is a great way to also learn python
34:54 - and then um
34:58 - and then i also see a question about
34:59 - using jupyter notebook versus another
35:02 - ide
35:03 - definitely you can use any ide that you
35:05 - would like
35:06 - uh we've been using jupyter notebook
35:08 - just because it
35:09 - is a really nice way to save your code
35:11 - and output
35:12 - in one go but
35:19 - oops i'm not paying attention
35:22 - but you can definitely copy this code
35:25 - over
35:26 - to any ide that you're comfortable with
35:28 - and then
35:29 - run it also if you have a codecademy
35:32 - subscription
35:33 - then you can for sure um
35:37 - do do this in our learning environment
35:40 - this
35:40 - is actually based on a project that we
35:42 - currently have and
35:44 - you think upcoming hopefully soon is a
35:46 - sandbox learning environment that you
35:48 - can use so
35:50 - i'll actually send that project to the
35:51 - chat so people can see it
35:54 - nice okay so in this example
35:58 - um just to recap what we did we
36:01 - scrambled
36:02 - absence and presence and then
36:05 - given those new scrambled absences and
36:08 - presences
36:09 - we recalculated a mean difference and in
36:12 - this case
36:12 - that mean difference for people with
36:15 - simulated
36:16 - or scrambled absence of heart disease
36:19 - versus presence of heart disease that
36:22 - mean difference was negative 3.5
36:25 - in this simulated sample and if we do it
36:28 - again
36:29 - we'll get a different number now it's
36:30 - closer to zero
36:33 - right now it's positive so we'll get
36:35 - slightly different numbers each time
36:38 - and what we can do is we can actually
36:41 - put this
36:42 - inside of a for loop so that we repeat
36:44 - it
36:45 - and grab these numbers each time
36:48 - so i'm gonna just create a
36:51 - null mean diff uh
36:55 - empty list and then
37:01 - repeat this a thousand times
37:03 - unfortunately
37:07 - tab everything and then what i'm going
37:09 - to do is in this last line instead of
37:11 - printing it
37:12 - i'm going to take null mean diff
37:17 - and append that simulated mean def
37:20 - onto the end
37:24 - and then so that we can take a look at
37:27 - it
37:28 - i'm gonna plot this
37:35 - well i see a
37:38 - question about or someone said i'm
37:40 - learning r now
37:41 - i love r if you are learning r
37:45 - that makes me happy because it's just
37:48 - great
37:50 - i've gotten so used to python now at
37:51 - this point that's also
37:53 - exciting for me but yeah r was
37:56 - technically the first language i learned
37:59 - because i used it like a tiny bit in
38:01 - high school once but then i like
38:04 - went to learn python in college because
38:06 - that's what all my classes used so now
38:08 - yeah it's all if i know that much are
38:10 - left what your class is or what your
38:12 - um or what your work
38:15 - uses in the end um
38:18 - okay so jamie do you want to kind of
38:20 - walk through this picture
38:22 - like what do you notice about this
38:23 - picture and is it what you expected it
38:25 - to be
38:26 - so it's centered around zero and it's
38:30 - like
38:30 - pretty much an approximately a normal
38:33 - distribution
38:34 - um and we should we should expect to see
38:37 - it centered around zero because
38:38 - of what we did in the beginning where we
38:40 - tried to basically make it so that
38:43 - when we took like when we took samples
38:45 - from
38:46 - the like our data set we you know like
38:50 - scrambled the absence and presence
38:54 - values to make it so that you know it
38:56 - would come out as a mean difference of
38:57 - zero
38:58 - um and basically what we see right now
39:01 - is like
39:02 - just a thousand samples of that i think
39:04 - it was a thousand right
39:05 - and just like plotted so yeah and i
39:08 - think
39:09 - because of what we did the way we played
39:11 - with the data we
39:12 - this is what we should see yep
39:15 - exactly so right so
39:18 - it's centered at zero exactly like jamie
39:21 - said because
39:22 - we simulated our data set so that
39:25 - the mean difference would be zero by
39:28 - essentially breaking the association
39:31 - between those two columns um
39:35 - cool uh i see a quick question how long
39:38 - does it take for a beginner to learn
39:40 - python or any other language
39:42 - i think it's a slow process i'm still
39:44 - learning
39:45 - for sure and as you learn more languages
39:48 - you get faster at learning new ones
39:51 - but for a beginner you know you can
39:54 - definitely get off the ground pretty
39:55 - quickly
39:56 - and then it's just a continual uh
39:59 - learning experience to be honest for
40:01 - years and years
40:02 - especially because they change
40:03 - everything so quickly
40:06 - so okay so this is our null distribution
40:09 - and now let's actually plot our observed
40:12 - uh mean difference onto this
40:14 - distribution so remember
40:17 - let's actually calculate that uh we'll
40:20 - calculate
40:20 - it down here down here so our true
40:23 - observed
40:24 - mean difference was mp.mean
40:28 - of heart dot
40:32 - uh t rest bps
40:36 - among heart
40:39 - dot heart disease
40:43 - equal equal uh presence
40:47 - actually i should break this out so that
40:49 - we can all see it
40:51 - so basically what i'm doing here is i'm
40:53 - saying in the actual data
40:57 - what's the observed mean difference so
41:00 - this
41:00 - is the t rest
41:04 - bps for
41:07 - people who have heart disease
41:12 - and then we can pull out
41:16 - the true blood pressure
41:20 - of people who don't have heart disease
41:27 - and then gosh i can't spell today
41:30 - and then we can take the mean difference
41:33 - between
41:34 - them
41:38 - right and
41:42 - and then i didn't print it so
41:47 - this we could have gotten from the table
41:49 - up above
41:50 - but our true mean difference between
41:52 - these two was 5.32
41:55 - so in reality there's about a 5.32
41:58 - point difference in mean blood
42:01 - progressing blood pressure for people
42:03 - with and without heart disease
42:05 - so let's plot that as a vertical line
42:08 - on this graph
42:14 - so it's going to be um plt.ax
42:19 - line x equals
42:24 - this and color
42:27 - we'll make it uh
42:34 - and we see that this is pretty far out
42:37 - to the right we could have seen that
42:38 - before drawing the line too
42:40 - we see that if there's really no
42:42 - association um
42:44 - that big of a mean difference is pretty
42:47 - unlikely
42:48 - it's definitely not unheard of but it's
42:50 - actually pretty unlikely
42:52 - which is a little bit surprising like
42:55 - given how close those two boxes were but
42:57 - i guess the sample size is pretty big
43:00 - and then if we want to actually
43:02 - calculate how many
43:04 - are outside of this what we can do is we
43:07 - can
43:08 - use our same trip trick from before we
43:11 - can take
43:12 - the sum of all of these
43:16 - values in the null distribution and we
43:18 - have to turn them into a numpy array
43:20 - first
43:21 - so our remember all the values in this
43:24 - null distribution are called
43:26 - null mean diff so we're going to say how
43:29 - many of these values
43:32 - are greater than the
43:35 - observed mean difference
43:38 - um
43:42 - in our sample and that comes out to
43:46 - there are three and then the p-value
43:49 - remember is the proportion
43:51 - so we did this a thousand times i guess
43:55 - instead of hard coding this i can say
43:57 - len
43:58 - of this
44:02 - so that's about .003
44:06 - and remember that this is a one-sided
44:08 - p-value
44:09 - the two-sided p-value we draw a line
44:12 - that's equally distant on the other side
44:14 - and also include the area to the left of
44:16 - that which
44:18 - theoretically this thing should be
44:21 - symmetrical so it should be roughly
44:23 - equal
44:24 - so the two-sided p-value would be
44:26 - roughly two times that
44:28 - that would be roughly this times two
44:35 - and now we can actually compare this so
44:37 - there's a built-in function
44:39 - for running a um or there's a
44:42 - there are a lot of functions that you
44:44 - could use for running a two-sample
44:46 - t-test
44:47 - i'm gonna grab one um that i've used
44:51 - before from sci-pi
44:54 - uh
44:57 - sorry i see this is an example of always
45:00 - learning right
45:01 - i don't have this memorized of
45:04 - um like which is
45:07 - the best function to use i gotta
45:12 - find it
45:16 - okay well there we go
45:23 - so we can also run this
45:27 - um but instead of sal achieved we want
45:31 - the um we want t
45:34 - rest bps
45:38 - for people with heart disease and then
45:42 - t rest pps for no heart disease
45:46 - let's see
45:49 - print p val
45:53 - and it's about .08 so our simulation
45:56 - slightly underestimated this
45:58 - but if we run it again we might get
46:02 - closer or if we run it
46:03 - more times let's try that one
46:10 - yeah so that time we got .008 so almost
46:13 - the same as
46:14 - what we got for the t-test that's
46:18 - housed within sci-pi um i'm just taking
46:22 - a look at the
46:23 - chat really quickly um
46:28 - are there any other questions i see
46:30 - there's someone who said they didn't get
46:31 - a reply
46:32 - was that was there a question in here or
46:34 - was that one an earlier
46:36 - or was that a different comment
46:39 - um i think i'm answering uh
46:42 - his question right now because it's the
46:44 - most recent one someone also asked um a
46:46 - question about r
46:48 - and i sent them something but i'm not
46:50 - sure if you have a quick answer yeah
46:51 - someone asked about the pipe uh
46:54 - at some point hopefully i would love to
46:57 - do a live stream on r
46:58 - and the pipe uh function because it's
47:01 - great um i see a question two sample
47:05 - t-test does this refer to the two
47:07 - subsets of binary categories grouped
47:09 - within the data set
47:10 - absolutely yeah so two a two sample
47:13 - t-test is really
47:15 - we're kind of treating these two things
47:16 - those are two samples
47:18 - um and they're we're thinking of them as
47:21 - independent samples so
47:23 - there's a group of people that have
47:25 - heart disease and that's one of the
47:26 - samples and then a group of people that
47:28 - don't have heart disease that's our
47:29 - other sample and we're comparing our
47:31 - sample means
47:32 - um it's called a t-test because
47:36 - this distribution is theoretically a
47:39 - student t
47:40 - distribution it's actually theoretically
47:42 - a normal distribution
47:44 - but the student t distribution is really
47:46 - similar to the normal distribution
47:48 - and we use it a lot of times because um
47:51 - it's almost like a slightly slightly
47:53 - squished
47:53 - normal distribution it has thicker tails
47:56 - and so it
47:57 - overestimates the um
48:00 - it overestimates the p-values like
48:02 - slightly
48:03 - which helps protect against errors so
48:06 - last week we were talking about
48:08 - hypothesis testing
48:09 - and errors and so that's why people use
48:12 - a t
48:12 - distribution student t distribution over
48:15 - a normal distribution
48:16 - for hypothesis testing but yeah we
48:19 - should get
48:20 - the same numbers cool
48:25 - um yeah so i see can we test for
48:28 - normality with the t-test
48:30 - um so if you're gonna if you want to
48:34 - test whether your data is
48:35 - normally distributed using a hypothesis
48:38 - test you would need a different
48:39 - hypothesis test
48:41 - but if you are asking whether
48:44 - um we could test
48:47 - against a normal distribution instead of
48:49 - a student t distribution
48:51 - the answer is yes so you could use like
48:54 - a
48:55 - two sample z test um you could basically
48:58 - use a z
48:59 - test for this as well and you would get
49:02 - the same answer basically
49:06 - um i hope yeah i hope that the screen
49:09 - isn't too blurry i'll try not to
49:11 - um scroll too fast so i wonder if that
49:14 - also causes it
49:16 - okay i also have another random question
49:19 - because yeah so this was the
49:22 - um this was like the variable where the
49:24 - mean difference was pretty small and the
49:25 - median difference was zero right
49:28 - does that mean if we did a median like
49:31 - if because like the sample median
49:34 - difference was zero would that mean if
49:35 - we like did
49:36 - a similar t-test style thing but with
49:38 - medians like we were describing earlier
49:40 - would we get a much different result
49:43 - from it
49:44 - probably yeah do you want to try it so
49:48 - let's let's just say we wanted to
49:51 - get a um a null distribution for the
49:54 - medians
49:55 - i'm just going to copy this down so
49:59 - we're gonna do exactly the same thing
50:01 - except we're just gonna calculate
50:03 - the median difference here instead of
50:06 - the mean
50:08 - and then append that
50:12 - and then we'll
50:17 - just a lot of histogram of this
50:21 - and show it really fast
50:26 - and we'll see
50:30 - yeah so basically it looks like
50:34 - this distribution we get is really we
50:37 - can add some more
50:38 - here i'm gonna reprint this
50:42 - with is it bins
50:47 - 50 oh wow
50:51 - wow yeah so basically what's happening
50:54 - is that
50:55 - the median and the simulated null
50:57 - distribution is almost always zero
51:00 - it's very rarely these other numbers so
51:02 - it's i guess
51:04 - hard to calculate a p-value here based
51:07 - off of this simulation i don't know
51:09 - actually
51:11 - what this distribution should look like
51:15 - super interesting it's probably
51:19 - it's just a very condensed distribution
51:22 - like zero is by far the most common
51:25 - um yeah that's interesting
51:30 - so yeah so the p value i mean are
51:33 - observed
51:34 - mean median difference was zero so the p
51:37 - value
51:38 - would be like a hundred percent yeah
51:42 - the the p-value would never be
51:46 - that small yeah yeah huh
51:49 - it's like so weird that the mean median
51:51 - would have like such a different
51:53 - like evaluation of the test
51:56 - yeah for sure and like
52:00 - i think the reason why people use the
52:02 - mean generally is that
52:04 - the central limit theorem applies which
52:06 - is to say that
52:08 - because we have we have the central
52:09 - limit theorem and
52:11 - this is getting into the weeds of things
52:13 - but
52:14 - right the expectation of a
52:18 - of a difference or of two random
52:21 - variables
52:22 - added together is just the the sum of
52:24 - the expectations so basically like
52:27 - the distribution i guess it doesn't
52:30 - matter so much expectation but basically
52:32 - if you have two normal distributions
52:34 - their sum is also normal
52:36 - so or their difference so basically like
52:39 - this is this is normally distributed
52:42 - and we know that it's normally
52:44 - distributed or student t distributed
52:46 - if we want to be conservative so it's
52:48 - it's very easy to run this test
52:52 - cool so we are also running pretty low
52:55 - on time
52:56 - um but i think it's worthwhile to just
52:59 - show
52:59 - since we spent most of the time on um
53:03 - on the t-test anyway
53:07 - let's see can i
53:14 - pull this over um
53:17 - if you look in the final code for this
53:20 - week
53:20 - you'll see that we did this for um
53:24 - for a few other variables
53:28 - and you'll see for example that um
53:31 - the p-value for resting blood pressure
53:34 - was .008
53:36 - for cholesterol i think it was even
53:39 - higher
53:40 - 0.139 um
53:43 - and if you look at i think i did the
53:46 - simulations out for a couple of them
53:49 - so this was the simulation that we just
53:52 - did
53:52 - this was a different simulation of the
53:55 - basically the same thing
53:56 - um i again got i think .008
54:01 - um but
54:04 - if you sorry if you were to simulate out
54:08 - um with something where there's a more
54:12 - clear association
54:14 - so i think i did with an example with
54:16 - the chi-square test
54:18 - out here which is like this is my null
54:20 - distribution and this was my observed
54:22 - value
54:23 - then this is where you get like those
54:25 - super small
54:26 - p values like 0.00017 or something was
54:31 - one of them
54:34 - cool all right what do you think jamie i
54:36 - think we're gonna kind of run out of
54:38 - time
54:39 - so i'm just gonna run through really
54:41 - quickly some of the other
54:44 - tests that you can run and things that
54:46 - people might
54:47 - want to look into if they're interested
54:49 - in learning more about this
54:51 - so if you take this course on codecademy
54:55 - you're going to see
54:56 - a few other different types of
54:57 - hypothesis tests so you'll see something
55:00 - about the anova hypothesis test
55:04 - and tukey's range test which are useful
55:08 - when in our example before right we had
55:10 - a binary
55:12 - variable so again back to the two sample
55:14 - t test right we have
55:16 - we have either heart disease or no heart
55:20 - disease
55:21 - but what if we are instead interested in
55:23 - how
55:24 - that fall achieved or whatever the heart
55:27 - rate that you achieve
55:28 - is related to what kind of chest pain
55:30 - you have and there are actually four
55:32 - different kinds of chest pain
55:34 - not just two categories um so if you
55:37 - want a hypothesis test to
55:38 - understand whether there are differences
55:41 - between any
55:42 - of the pairs of these two categories
55:45 - right so there's
55:45 - a bunch of different pairings that you
55:47 - could make then you can run
55:49 - an anova test and you can then follow it
55:52 - up with tupi's range test
55:54 - which will tell you where those
55:56 - differences lie
55:57 - so in this example here's an example of
56:00 - a tukey's range test looking at the
56:01 - association between
56:03 - um type of chest pain and
56:07 - uh and val achieved
56:11 - and when we look at this output we see
56:15 - that there are significant differences
56:17 - between the asymptomatic group
56:19 - and every other group with respect to
56:22 - chest pain
56:23 - but there's no significant differences
56:25 - between the other groups
56:27 - so the true right means that the p-value
56:30 - was small enough at a level of 0.05 to
56:33 - reject the null hypothesis and say that
56:35 - those two groups are
56:36 - statistically significantly different um
56:40 - and then we can see that in this picture
56:42 - right where the asymptomatic group
56:44 - has a lower vowel achieved than all of
56:47 - the other
56:48 - groups but the other groups seem pretty
56:50 - similar
56:53 - and then the other hypothesis test
56:55 - that's included in here
56:57 - is the chi-square test which is
57:00 - used for looking at an association
57:02 - between two categorical variables so in
57:05 - this case
57:05 - for example people who
57:09 - have and don't have heart disease
57:12 - and different types of chest pain
57:15 - so is there an association between
57:18 - whether someone has heart disease and
57:19 - what kind of chest pain they have
57:22 - and we can run that hypothesis test
57:24 - using a chi-square
57:26 - test and if you are interested i have
57:29 - included some
57:30 - questions or some examples at the end
57:33 - in the final code um that's available on
57:36 - github
57:37 - where i simulate a chi-square test so if
57:40 - you're interested in learning how to
57:41 - simulate a chi-square test
57:44 - you can look there essentially all it
57:46 - all it is
57:47 - is you say okay what proportion of
57:51 - people have heart disease
57:52 - i'm going to randomly assign whether or
57:54 - not someone has heart disease based on
57:55 - that proportion
57:57 - and then i'm going to randomly assign
57:59 - whether or not someone or what kind of
58:01 - chest pain
58:02 - someone has i'm going to randomly assign
58:05 - them separately
58:06 - we can even do exactly what we did
58:07 - before which is like randomly permute
58:10 - this row
58:10 - or this column of the data set and
58:12 - randomly permute this column of the data
58:14 - set
58:15 - recalculate the chi-square statistic
58:17 - every single time and look at that null
58:19 - distribution
58:20 - so um with that i think we have one
58:24 - minute left i'm looking at the chat to
58:26 - see if there's anything
58:27 - else i can adjust or
58:30 - address sorry sophie i did
58:34 - mention uh because someone's asking
58:36 - questions about like r and statistics
58:38 - based questions
58:39 - yeah item i did direct them to like the
58:41 - forums and mention that
58:42 - you like answering our questions about r
58:44 - and statistics
58:46 - yes definitely if you post in the forums
58:49 - you can definitely
58:50 - tag me i also um keep an eye on the
58:53 - forum questions
58:54 - but i think my tag is so summer three
58:58 - um i will i'll double check that
59:03 - uh but yeah definitely post in the
59:05 - forums i i check them and i love
59:07 - talking about stuff um
59:12 - i don't know off the top of my head what
59:14 - the shapiro test is i'm seeing this
59:16 - question about
59:17 - t-tess versus shapiro
59:20 - let's look it up really fast
59:25 - oh foreign normality
59:29 - so oh shapiro wilkes test
59:33 - right so shapiro wilkes s is for
59:37 - testing whether a distribution
59:40 - is statistically significantly different
59:42 - from normal
59:43 - um so it's actually like
59:47 - i i've seen this used now that i'm
59:49 - seeing this i've seen this used to
59:51 - check assumptions for a model so for
59:53 - example
59:54 - if you are going to write up or try to
59:58 - design a predictive
59:59 - model in order to predict
60:02 - resting blood pressure based off of
60:04 - other characteristics
60:06 - um one of the assumptions is that
60:08 - resting blood pressure has to be
60:10 - normally distributed
60:12 - and so if we look at it
60:16 - best bps um
60:23 - it may or may not look normally
60:25 - distributed this doesn't really look
60:27 - normally distributed
60:28 - it looks kind of skewed and so then if
60:31 - you wanted to test
60:32 - is this is this significantly different
60:34 - from
60:35 - what a normal distribution would look
60:37 - like you could use the shapiro
60:39 - wilkes test the t-test is specifically
60:41 - testing for
60:42 - different mean differences between two
60:45 - groups
60:46 - so looking at an association between a
60:49 - quantitative outcome var or a
60:51 - quantitative variable and a
60:52 - binary categorical variable
60:56 - um okay well
60:59 - uh ed you can go back and uh
61:02 - hear my answer to your question
61:05 - hopefully
61:06 - cool so hopefully we got through all
61:10 - those questions if you have more i love
61:12 - hearing from you
61:13 - post on the videos in youtube post in
61:16 - the forums on codecademy
61:18 - talk to me tell me that you like these
61:21 - tell me that you hate them
61:22 - tell me what we can do better um these
61:25 - are really
61:26 - we hope that learners are getting
61:27 - something out of this and that we can
61:29 - have this kind of
61:30 - little community um i know both jamie
61:33 - and i and i know the same is true for
61:34 - alex we all
61:36 - love kind of having connections to
61:38 - everybody that
61:40 - is learning on our platform and we also
61:42 - are constantly learning ourselves so
61:44 - this is
61:45 - really fun for us to get to even though
61:48 - we're all kind of locked away in our
61:49 - houses
61:50 - um get to interact with you all and
61:52 - hopefully
61:53 - um learn from each other so
61:57 - cool well with that i hope everyone has
62:00 - a great rest of their tuesday
62:03 - thank you for letting me join thank you
62:06 - for joining thank you so much al
62:07 - alright thank you so much jamie