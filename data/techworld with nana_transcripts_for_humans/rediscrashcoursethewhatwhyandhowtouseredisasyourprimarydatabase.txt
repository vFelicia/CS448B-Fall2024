With timestamps:

00:00 - in this video we're going to talk about
00:02 - redis and how redis can be used as a
00:04 - primary database for complex
00:06 - applications that need to store data in
00:09 - multiple formats first we will see what
00:12 - redis is and its usages as well as
00:15 - why it is suitable for modern complex
00:18 - microservice applications we will talk
00:20 - about how redi supports storing multiple
00:23 - data formats for different purposes
00:26 - through its modules next we will see how
00:29 - redis as an in-memory database can
00:31 - persist data and recover from data loss
00:34 - we'll also talk about how redis
00:36 - optimizes memory storage cost using
00:40 - redis on flash
00:42 - then we will see very interesting use
00:43 - cases of scaling readies and replicating
00:46 - it across multiple geographic regions
00:50 - and finally since one of the most
00:52 - popular platforms for running
00:54 - microservices is kubernetes and since
00:57 - running stateful applications in
00:59 - kubernetes is a bit challenging we will
01:02 - see how you can easily run redis on
01:04 - kubernetes i'm proud to say that i have
01:07 - partnered up with redis to make this
01:09 - video so big thanks to redis for
01:11 - sponsoring and making this video
01:13 - possible
01:15 - now first of all redis which actually
01:17 - stands for remote dictionary server is
01:21 - an in-memory database
01:24 - so many people have used it as a cache
01:26 - on top of other databases to improve the
01:29 - application performance however what
01:31 - many people don't know is that redis is
01:34 - a fully fledged primary database that
01:36 - can be used to store and persist
01:39 - multiple data formats for complex
01:41 - applications let's see the use cases and
01:44 - examples for that let's look at a common
01:46 - setup for a microservices application
01:49 - let's say we have a complex social media
01:52 - application with millions of users and
01:55 - let's say our microservices application
01:58 - uses a relational database like mysql to
02:01 - store the data
02:02 - in addition because we are collecting
02:05 - tons of data daily we have an
02:07 - elasticsearch database for fast
02:10 - filtering and searching the data
02:12 - now the users are all connected to each
02:15 - other so we need a graph database to
02:17 - represent these connections
02:19 - plus our application has a lot of media
02:21 - content that users share with each other
02:24 - daily
02:25 - and for that we have a document database
02:28 - and finally for a better performance for
02:30 - the application we have a cache service
02:33 - that caches the data from other
02:35 - databases and makes it accessible faster
02:39 - now it's obvious that this is a pretty
02:42 - complex setup but let's see what are the
02:44 - challenges of this setup
02:47 - first of all all these data services
02:49 - need to be deployed run and maintained
02:52 - right this means your team needs to have
02:54 - some kind of knowledge on how to
02:57 - operate all these data services
02:59 - plus of course for high availability and
03:02 - better performance you would want to
03:04 - scale your services and each of these
03:06 - data services scales differently has
03:09 - different infrastructure requirements
03:11 - and that could be an additional
03:13 - challenge so overall using multiple data
03:15 - services for your application increases
03:19 - the effort of maintaining your whole
03:21 - application setup of course as an easier
03:24 - alternative to running and managing the
03:26 - services yourself you can use the
03:28 - managed data services from cloud
03:31 - providers but this could be very
03:33 - expensive because on cloud platforms you
03:36 - pay for each managed data service
03:38 - separately
03:40 - now on the development side your
03:41 - application code also gets pretty
03:44 - complex because you need to talk to
03:46 - multiple data services and for each
03:49 - service you would need a separate
03:51 - connector and separate logic and this of
03:54 - course makes testing your applications
03:57 - also quite challenging
03:59 - and finally the more number of services
04:01 - that talk to each other the higher the
04:03 - latency because even though each service
04:06 - may be fast on its own
04:09 - each connection step between the
04:11 - services or each network hub will add
04:14 - some latency to your application
04:16 - in comparison with a multi-modal
04:19 - database like redis you resolve most of
04:22 - these challenges first of all you run
04:24 - and maintain just one data service so
04:27 - your application also needs to talk to a
04:29 - single data store and that requires only
04:31 - one programmatic interface for that data
04:34 - service and latency will be reduced by
04:37 - going to a single data endpoint and
04:39 - eliminating
04:40 - several internal network hubs so having
04:44 - one database like redis that allows you
04:47 - to store different types of data or
04:49 - basically allows you to have multiple
04:52 - types of databases in one as well as act
04:55 - as a cache solves such challenges
04:58 - so let's see how redis actually works
05:01 - first of all how does ready support
05:04 - multiple data formats in a single
05:06 - database
05:07 - the way it works is that you have ready
05:09 - score which is a key value store that
05:12 - already supports storing multiple types
05:14 - of data and then you can extend that
05:16 - core with what's called modules for
05:19 - different data types which your
05:21 - application needs for different purposes
05:23 - so for example ready search for search
05:26 - functionality like elasticsearch or
05:29 - redis graph for graph data storage and
05:31 - so on and a great thing about this is
05:34 - that it's modular so these different
05:36 - types of database functionalities are
05:39 - not tightly integrated into one database
05:42 - as in many other multi-modal databases
05:45 - but rather you can pick and choose
05:47 - exactly which data service functionality
05:50 - you need for your application
05:52 - and then basically add that module and
05:54 - of course when using redis as a primary
05:56 - database you don't need an additional
05:58 - cache because you have that
06:00 - automatically out of the box with redis
06:02 - that means again less complexity in your
06:05 - application
06:06 - because you don't need to implement
06:09 - the logic for managing populating and
06:12 - invalidating cache and finally as an
06:14 - in-memory database redis is of course
06:17 - super fast and performant which of
06:19 - course makes the application itself
06:21 - faster but in addition it also makes
06:25 - running the application tests way faster
06:28 - as well because radius doesn't need a
06:30 - schema like other databases so it
06:32 - doesn't need time to initialize the
06:34 - database and build the schema and so on
06:37 - before running the tests so you can
06:40 - start with an empty redis database every
06:42 - time and generate data for tests as you
06:45 - need and fast tests can really increase
06:47 - your development productivity
06:52 - okay great so we understood how redis
06:54 - works and all its benefits but at this
06:57 - point you may be wondering how can an
07:00 - in-memory database persist data because
07:03 - if the redis process or the server on
07:05 - which redis is running fails all the
07:08 - data in memory is gone right and if i
07:10 - lose the data how can i recover it so
07:13 - basically how can i be confident that my
07:15 - data is safe well the simplest way to
07:18 - have data backups is by replicating
07:21 - redis so if the redis master instance
07:24 - goes down the replicas will still be
07:26 - running and have all the data so if you
07:28 - have a replicated redis the replicas
07:30 - will have the data but of course if all
07:33 - the radius instances go down you will
07:35 - lose the data because there will be no
07:38 - replica remaining so we need real
07:40 - persistence
07:42 - well redis has multiple mechanisms for
07:44 - persisting the data and keeping the data
07:46 - safe first one the snapshots which you
07:50 - can configure based on time number of
07:52 - requests etc so snapshots of your data
07:55 - will be stored on a disk which you can
07:58 - use to recover your data if the whole
08:01 - radius database is gone but note that
08:03 - you will lose the last minutes of data
08:05 - because you usually do snapshotting
08:07 - every five minutes or an hour depending
08:10 - on your needs so as an alternative redis
08:13 - uses something called aof which stands
08:16 - for append only file in this case every
08:20 - change is saved to the disk for
08:22 - persistence continuously and when
08:24 - restarting redis or after an outage
08:27 - redis will replay the append only file
08:30 - locks to rebuild the state so aof is
08:34 - more durable but can be slower than
08:36 - snapshotting
08:38 - and of course you can also use a
08:40 - combination of both aof and snapshots
08:43 - where the append only file is persisting
08:45 - data from memory to disk continuously
08:48 - plus you have regular snapshots in
08:50 - between to save the data state in case
08:52 - you need to recover it this means that
08:54 - even if the redis database itself
08:57 - or the servers the underlying
08:59 - infrastructure where redis is running
09:02 - all fail you still have all your data
09:04 - safe and you can easily recreate and
09:07 - restart a new redis database with all
09:10 - the data
09:11 - now a very interesting question is
09:14 - where is that persistent storage so
09:16 - where is that disk which holds your
09:19 - snapshots and the append only file locks
09:22 - located are they on the same servers
09:24 - where redis is running well this
09:27 - question actually leads us to the trend
09:29 - or a best practice of data persistence
09:31 - in cloud environments which is that it's
09:34 - always better to separate the servers
09:36 - that run your application and data
09:39 - services
09:40 - from the persistent storage that stores
09:43 - your data so with a specific example if
09:46 - your applications and services run in
09:49 - the cloud on let's say aws ec2 instance
09:53 - you should use ebs or elastic block
09:57 - storage to persist your data instead of
09:59 - storing them on the ec2 instances hard
10:02 - drive for example because if that ec2
10:05 - instance died you won't have access to
10:07 - any of its storage whether it's ram or
10:10 - disk storage or whatever so if you want
10:13 - persistence and durability for your data
10:16 - you must put your data outside the
10:18 - instances on an external network storage
10:21 - as a result by separating these two if
10:25 - the server instance fails or if all the
10:27 - instances fail you still have the disk
10:30 - and all the data on it unaffected you
10:32 - just spin up other instances and take
10:34 - the data from the ebs and that's it and
10:37 - this makes your infrastructure way
10:39 - easier to manage because each server is
10:42 - equal you don't have any special servers
10:44 - with any special data or files on it so
10:47 - you don't care if you lose your whole
10:49 - infrastructure because you can just
10:51 - recreate a new one and pull the data
10:53 - from a separate storage and you're good
10:55 - to go again
10:56 - so going back to redis example
10:59 - ready service will be running on the
11:01 - servers and using server ram to store
11:04 - the data
11:05 - while the append only file logs and
11:08 - snapshots will be persisted on a disk
11:11 - outside those servers making your data
11:13 - more durable
11:17 - great now we know you can persist data
11:20 - with redis for durability and recovery
11:24 - while using ram or memory storage for
11:27 - great performance and speed
11:29 - so the question you may have here is
11:32 - isn't storing data in memory expensive
11:35 - so you would need more servers compared
11:37 - to a database that stores data on disk
11:40 - simply because memory is limited in size
11:43 - so there's a trade-off between the cost
11:45 - and performance well redis actually has
11:48 - a way to optimize this using a service
11:51 - called redis on flash which is part of
11:55 - redis enterprise so how does this work
11:58 - it's a pretty simple concept actually
12:00 - redison flash extends the rem to the
12:03 - flash drive or ssd where frequently used
12:06 - values are stored in rem and the
12:09 - infrequently used ones are stored on ssd
12:12 - so for redis it's just more ram on the
12:15 - server and this means
12:17 - that redis can use more of the
12:19 - underlying infrastructure or the
12:21 - underlying server resources by using
12:23 - both ram and ssd drive to store the data
12:27 - increasing the storage capacity on each
12:29 - server and this way saving you
12:32 - infrastructure costs
12:37 - all right so we've talked about data
12:39 - storage for redis database and how it
12:41 - all works including the best practices
12:44 - now another very interesting topic is
12:47 - how do we scale a redis database
12:50 - let's say my one oneredice instance runs
12:52 - out of memory so data becomes too large
12:55 - to hold in memory or radius becomes a
12:58 - bottleneck and can't handle any more
13:00 - requests in such case how do i increase
13:03 - the capacity
13:05 - and memory size for my redis database
13:09 - we have several options for that first
13:11 - of all ready supports clustering which
13:14 - means you can have a primary or master
13:17 - redis instance
13:18 - which can be used to read and write data
13:22 - and you can have multiple replicas of
13:25 - that primary instance for reading the
13:27 - data this way you can scale red is to
13:30 - handle more requests and in addition
13:32 - increase the high availability of your
13:35 - database because if master fails one of
13:38 - the replicas can take over and your
13:41 - radius database basically can continue
13:44 - functioning without any issues
13:46 - now these replicas will all hold copies
13:50 - of the data of the primary instance so
13:52 - the more replicas you have the more
13:55 - memory space you need and one server may
13:58 - not have sufficient memory for all your
14:01 - replicas plus if you have all the
14:03 - replicas on one server and that server
14:06 - fails
14:07 - your whole radius database is gone and
14:09 - you will have a downtime instead you
14:11 - want to distribute these replicas among
14:13 - multiple nodes or servers so for example
14:17 - your master instance will be on one node
14:19 - and two replicas on other two nodes
14:23 - well that seems good enough
14:25 - but what if your data set grows too
14:27 - large to fit in a memory on a single
14:30 - server plus we have scaled the reads in
14:34 - the database so all the requests that
14:36 - basically just query the data but our
14:39 - master instance is still alone and still
14:42 - has to handle all the rights so what is
14:45 - the solution here for that we use the
14:48 - concept of sharding which is a general
14:50 - concept in databases and which redis
14:54 - also supports
14:55 - so sharding basically means that you
14:58 - take your complete data set and divide
15:01 - it into smaller chunks or subsets of
15:04 - data where each shard is responsible for
15:07 - its own subset of data
15:09 - so that means instead of having one
15:11 - master instance that handles all the
15:14 - writes to the complete data set
15:16 - you can split it into let's say four
15:18 - shards
15:19 - each of them responsible for reads and
15:22 - writes to a subset of the data and each
15:26 - shard also needs less memory capacity
15:29 - because they just have a fourth of the
15:31 - data
15:32 - this means you can distribute and run
15:34 - charts on smaller nodes and basically
15:37 - scale your cluster horizontally and of
15:39 - course as your data set grows and as you
15:43 - need even more resources you can reshart
15:46 - your radius database which basically
15:48 - means you just
15:49 - split your data in even smaller chunks
15:52 - and create more shards
15:54 - so having multiple nodes which run
15:57 - multiple replicas of redis which are all
16:00 - sharded gives you a very performant
16:02 - highly available redis database that can
16:05 - handle much more requests without
16:07 - creating any bottlenecks now i have to
16:10 - note here that this setup is great but
16:12 - of course you would need to manage it
16:15 - yourself do the scaling add notes do the
16:18 - sharding and then resharting etc so for
16:20 - some teams that are more focused on the
16:23 - application development and more
16:25 - business logic rather than running and
16:27 - maintaining data services this could be
16:30 - a lot of unwanted effort so as an easier
16:33 - alternative in redis enterprise you get
16:35 - this kind of setup automatically because
16:38 - the scaling sharding and so on is all
16:40 - managed for you
16:42 - now let's consider another interesting
16:44 - scenario for applications that need even
16:47 - higher availability and performance
16:50 - across multiple geographic locations so
16:53 - let's say we have this replicated
16:55 - sharded redis database cluster in one
16:58 - region in the data center of london
17:01 - europe but we have the two following use
17:04 - cases
17:05 - first our users are geographically
17:08 - distributed so they are accessing the
17:11 - application from all over the world so
17:13 - we want to distribute our application
17:15 - and data services globally
17:18 - close to the users to give our users
17:21 - better performance and second if the
17:24 - complete data center in london europe
17:27 - for example
17:28 - goes down we want an immediate switch
17:31 - over to another data center so that the
17:34 - ready service stays available in other
17:37 - words we want replicas of the whole
17:39 - redis cluster in data centers in
17:42 - multiple geographic locations or regions
17:46 - this means a single data should be
17:48 - replicated to many clusters spread
17:51 - across multiple regions
17:53 - with each cluster being fully able to
17:56 - accept reads and writes
17:58 - so in that case you would have multiple
18:01 - redis clusters
18:02 - that will act as local redis instances
18:06 - in each region and the data will be
18:09 - synced across these geographically
18:11 - distributed clusters
18:13 - this is a feature available in redis
18:15 - enterprise and is called active active
18:18 - deployment because you have multiple
18:20 - active databases in different locations
18:22 - so with this setup we'll have lower
18:25 - latency for the users
18:27 - and even if the redis database in one
18:30 - region completely goes down the other
18:32 - regions will be unaffected and if the
18:35 - connection or syncing between the
18:37 - regions breaks for a short time because
18:40 - of some network problem for example
18:42 - the reddish clusters in these regions
18:45 - can update the data independently and
18:48 - once connection is re-established they
18:50 - can sync up those changes again now of
18:53 - course when you hear that the first
18:55 - question that may pop up in your mind is
18:58 - how does redis resolve the changes in
19:01 - multiple regions to the same data set so
19:04 - if the same data changed in multiple
19:06 - regions how does radies make sure that
19:08 - data changes of any region isn't lost
19:12 - and data is correctly synced and how
19:14 - does it ensure data consistency
19:16 - specifically for that redis enterprise
19:19 - uses a concept called crdts which stands
19:23 - for
19:24 - conflict-free
19:26 - replicated data types and this concept
19:28 - is used to resolve any conflicts
19:31 - automatically at the database level and
19:34 - without any data loss so basically redis
19:37 - itself has a mechanism for merging the
19:40 - changes which were made to the same data
19:42 - set from multiple sources in a way that
19:46 - none of the data changes are lost and
19:48 - any conflicts are properly resolved and
19:52 - since as you learned ready supports
19:54 - multiple data types for each data type
19:57 - they use its own data conflict
19:59 - resolution rules which are the most
20:01 - optimal for that specific data type
20:04 - so simply put instead of just overriding
20:06 - the changes of one source
20:09 - and just discarding all the others all
20:12 - the parallel changes are kept and
20:14 - intelligently resolved
20:17 - and again this is automatically done for
20:19 - you with this active active
20:21 - geo-replication feature so you don't
20:23 - need to worry about that and the last
20:25 - topic i want to address with redis is
20:28 - running redis in kubernetes as i said
20:31 - redis is a great fit for complex
20:33 - microservices that need to support
20:36 - multiple data types and that need an
20:39 - easy scaling of a database without
20:41 - worrying about data consistency
20:44 - and we also know that the new standard
20:46 - for running microservices is the
20:48 - kubernetes platform so running redis in
20:51 - kubernetes is a very interesting and
20:53 - common use case so how does that work
20:56 - with open source redis you can deploy
20:58 - replicated redis as a help chart or
21:01 - kubernetes manifest files and basically
21:03 - using the replication and scaling rules
21:06 - that we already talked about
21:08 - set up and run a highly available redis
21:11 - database
21:12 - the only difference would be that the
21:14 - hosts where redis will run will be
21:17 - kubernetes pods instead of for example
21:19 - ec2 instances or any other
21:22 - physical or virtual servers but the same
21:25 - sharding replicating and scaling
21:28 - concepts apply here as well when you
21:30 - want to run redis cluster in kubernetes
21:33 - and you would basically have to manage
21:35 - that setup yourself
21:37 - however as i mentioned many teams don't
21:40 - want to have the effort of maintaining
21:43 - these third-party services because they
21:45 - rather invest their time and resources
21:48 - in application development or other
21:50 - tasks so having an easier alternative is
21:53 - important here as well so redis
21:56 - enterprise has a managed redis cluster
21:59 - which you can deploy as a kubernetes
22:00 - operator if you don't know operators
22:03 - operator in kubernetes is basically a
22:05 - concept where you can bundle all the
22:08 - resources
22:10 - needed to operate a certain application
22:12 - or service so that you don't have to
22:15 - manage it yourself or you don't have to
22:17 - operate it yourself
22:19 - so instead of a human operating a
22:21 - database you basically have all this
22:23 - logic in an automated form to operate a
22:26 - database for you and many databases have
22:29 - operators for kubernetes and each such
22:32 - operator has of course its own logic
22:34 - based on who wrote them and how they
22:37 - wrote them
22:38 - the redis enterprise on kubernetes
22:40 - operator specifically
22:42 - automates deployment and configuration
22:45 - of the whole radius database in your
22:47 - kubernetes cluster it also takes care of
22:50 - scaling doing the backups and recovering
22:52 - the redis cluster if needed etc so it
22:55 - takes over the complete operation of
22:58 - radius cluster inside the kubernetes
23:00 - cluster well i hope you learned a lot in
23:02 - this video and that i was able to answer
23:05 - many of your questions if you want to
23:07 - try redis enterprise cloud be sure to
23:10 - check out my special link in the video
23:12 - description for a 200 credit and if you
23:15 - want to learn more similar technologies
23:17 - and concepts then make sure to subscribe
23:19 - to my channel because i make videos
23:22 - regularly about different devops and
23:24 - cloud technologies also comment below if
23:27 - you have any questions regarding reddis
23:30 - or any new topic suggestions and with
23:32 - that thank you for watching and see you
23:35 - in the next video

Cleaned transcript:

in this video we're going to talk about redis and how redis can be used as a primary database for complex applications that need to store data in multiple formats first we will see what redis is and its usages as well as why it is suitable for modern complex microservice applications we will talk about how redi supports storing multiple data formats for different purposes through its modules next we will see how redis as an inmemory database can persist data and recover from data loss we'll also talk about how redis optimizes memory storage cost using redis on flash then we will see very interesting use cases of scaling readies and replicating it across multiple geographic regions and finally since one of the most popular platforms for running microservices is kubernetes and since running stateful applications in kubernetes is a bit challenging we will see how you can easily run redis on kubernetes i'm proud to say that i have partnered up with redis to make this video so big thanks to redis for sponsoring and making this video possible now first of all redis which actually stands for remote dictionary server is an inmemory database so many people have used it as a cache on top of other databases to improve the application performance however what many people don't know is that redis is a fully fledged primary database that can be used to store and persist multiple data formats for complex applications let's see the use cases and examples for that let's look at a common setup for a microservices application let's say we have a complex social media application with millions of users and let's say our microservices application uses a relational database like mysql to store the data in addition because we are collecting tons of data daily we have an elasticsearch database for fast filtering and searching the data now the users are all connected to each other so we need a graph database to represent these connections plus our application has a lot of media content that users share with each other daily and for that we have a document database and finally for a better performance for the application we have a cache service that caches the data from other databases and makes it accessible faster now it's obvious that this is a pretty complex setup but let's see what are the challenges of this setup first of all all these data services need to be deployed run and maintained right this means your team needs to have some kind of knowledge on how to operate all these data services plus of course for high availability and better performance you would want to scale your services and each of these data services scales differently has different infrastructure requirements and that could be an additional challenge so overall using multiple data services for your application increases the effort of maintaining your whole application setup of course as an easier alternative to running and managing the services yourself you can use the managed data services from cloud providers but this could be very expensive because on cloud platforms you pay for each managed data service separately now on the development side your application code also gets pretty complex because you need to talk to multiple data services and for each service you would need a separate connector and separate logic and this of course makes testing your applications also quite challenging and finally the more number of services that talk to each other the higher the latency because even though each service may be fast on its own each connection step between the services or each network hub will add some latency to your application in comparison with a multimodal database like redis you resolve most of these challenges first of all you run and maintain just one data service so your application also needs to talk to a single data store and that requires only one programmatic interface for that data service and latency will be reduced by going to a single data endpoint and eliminating several internal network hubs so having one database like redis that allows you to store different types of data or basically allows you to have multiple types of databases in one as well as act as a cache solves such challenges so let's see how redis actually works first of all how does ready support multiple data formats in a single database the way it works is that you have ready score which is a key value store that already supports storing multiple types of data and then you can extend that core with what's called modules for different data types which your application needs for different purposes so for example ready search for search functionality like elasticsearch or redis graph for graph data storage and so on and a great thing about this is that it's modular so these different types of database functionalities are not tightly integrated into one database as in many other multimodal databases but rather you can pick and choose exactly which data service functionality you need for your application and then basically add that module and of course when using redis as a primary database you don't need an additional cache because you have that automatically out of the box with redis that means again less complexity in your application because you don't need to implement the logic for managing populating and invalidating cache and finally as an inmemory database redis is of course super fast and performant which of course makes the application itself faster but in addition it also makes running the application tests way faster as well because radius doesn't need a schema like other databases so it doesn't need time to initialize the database and build the schema and so on before running the tests so you can start with an empty redis database every time and generate data for tests as you need and fast tests can really increase your development productivity okay great so we understood how redis works and all its benefits but at this point you may be wondering how can an inmemory database persist data because if the redis process or the server on which redis is running fails all the data in memory is gone right and if i lose the data how can i recover it so basically how can i be confident that my data is safe well the simplest way to have data backups is by replicating redis so if the redis master instance goes down the replicas will still be running and have all the data so if you have a replicated redis the replicas will have the data but of course if all the radius instances go down you will lose the data because there will be no replica remaining so we need real persistence well redis has multiple mechanisms for persisting the data and keeping the data safe first one the snapshots which you can configure based on time number of requests etc so snapshots of your data will be stored on a disk which you can use to recover your data if the whole radius database is gone but note that you will lose the last minutes of data because you usually do snapshotting every five minutes or an hour depending on your needs so as an alternative redis uses something called aof which stands for append only file in this case every change is saved to the disk for persistence continuously and when restarting redis or after an outage redis will replay the append only file locks to rebuild the state so aof is more durable but can be slower than snapshotting and of course you can also use a combination of both aof and snapshots where the append only file is persisting data from memory to disk continuously plus you have regular snapshots in between to save the data state in case you need to recover it this means that even if the redis database itself or the servers the underlying infrastructure where redis is running all fail you still have all your data safe and you can easily recreate and restart a new redis database with all the data now a very interesting question is where is that persistent storage so where is that disk which holds your snapshots and the append only file locks located are they on the same servers where redis is running well this question actually leads us to the trend or a best practice of data persistence in cloud environments which is that it's always better to separate the servers that run your application and data services from the persistent storage that stores your data so with a specific example if your applications and services run in the cloud on let's say aws ec2 instance you should use ebs or elastic block storage to persist your data instead of storing them on the ec2 instances hard drive for example because if that ec2 instance died you won't have access to any of its storage whether it's ram or disk storage or whatever so if you want persistence and durability for your data you must put your data outside the instances on an external network storage as a result by separating these two if the server instance fails or if all the instances fail you still have the disk and all the data on it unaffected you just spin up other instances and take the data from the ebs and that's it and this makes your infrastructure way easier to manage because each server is equal you don't have any special servers with any special data or files on it so you don't care if you lose your whole infrastructure because you can just recreate a new one and pull the data from a separate storage and you're good to go again so going back to redis example ready service will be running on the servers and using server ram to store the data while the append only file logs and snapshots will be persisted on a disk outside those servers making your data more durable great now we know you can persist data with redis for durability and recovery while using ram or memory storage for great performance and speed so the question you may have here is isn't storing data in memory expensive so you would need more servers compared to a database that stores data on disk simply because memory is limited in size so there's a tradeoff between the cost and performance well redis actually has a way to optimize this using a service called redis on flash which is part of redis enterprise so how does this work it's a pretty simple concept actually redison flash extends the rem to the flash drive or ssd where frequently used values are stored in rem and the infrequently used ones are stored on ssd so for redis it's just more ram on the server and this means that redis can use more of the underlying infrastructure or the underlying server resources by using both ram and ssd drive to store the data increasing the storage capacity on each server and this way saving you infrastructure costs all right so we've talked about data storage for redis database and how it all works including the best practices now another very interesting topic is how do we scale a redis database let's say my one oneredice instance runs out of memory so data becomes too large to hold in memory or radius becomes a bottleneck and can't handle any more requests in such case how do i increase the capacity and memory size for my redis database we have several options for that first of all ready supports clustering which means you can have a primary or master redis instance which can be used to read and write data and you can have multiple replicas of that primary instance for reading the data this way you can scale red is to handle more requests and in addition increase the high availability of your database because if master fails one of the replicas can take over and your radius database basically can continue functioning without any issues now these replicas will all hold copies of the data of the primary instance so the more replicas you have the more memory space you need and one server may not have sufficient memory for all your replicas plus if you have all the replicas on one server and that server fails your whole radius database is gone and you will have a downtime instead you want to distribute these replicas among multiple nodes or servers so for example your master instance will be on one node and two replicas on other two nodes well that seems good enough but what if your data set grows too large to fit in a memory on a single server plus we have scaled the reads in the database so all the requests that basically just query the data but our master instance is still alone and still has to handle all the rights so what is the solution here for that we use the concept of sharding which is a general concept in databases and which redis also supports so sharding basically means that you take your complete data set and divide it into smaller chunks or subsets of data where each shard is responsible for its own subset of data so that means instead of having one master instance that handles all the writes to the complete data set you can split it into let's say four shards each of them responsible for reads and writes to a subset of the data and each shard also needs less memory capacity because they just have a fourth of the data this means you can distribute and run charts on smaller nodes and basically scale your cluster horizontally and of course as your data set grows and as you need even more resources you can reshart your radius database which basically means you just split your data in even smaller chunks and create more shards so having multiple nodes which run multiple replicas of redis which are all sharded gives you a very performant highly available redis database that can handle much more requests without creating any bottlenecks now i have to note here that this setup is great but of course you would need to manage it yourself do the scaling add notes do the sharding and then resharting etc so for some teams that are more focused on the application development and more business logic rather than running and maintaining data services this could be a lot of unwanted effort so as an easier alternative in redis enterprise you get this kind of setup automatically because the scaling sharding and so on is all managed for you now let's consider another interesting scenario for applications that need even higher availability and performance across multiple geographic locations so let's say we have this replicated sharded redis database cluster in one region in the data center of london europe but we have the two following use cases first our users are geographically distributed so they are accessing the application from all over the world so we want to distribute our application and data services globally close to the users to give our users better performance and second if the complete data center in london europe for example goes down we want an immediate switch over to another data center so that the ready service stays available in other words we want replicas of the whole redis cluster in data centers in multiple geographic locations or regions this means a single data should be replicated to many clusters spread across multiple regions with each cluster being fully able to accept reads and writes so in that case you would have multiple redis clusters that will act as local redis instances in each region and the data will be synced across these geographically distributed clusters this is a feature available in redis enterprise and is called active active deployment because you have multiple active databases in different locations so with this setup we'll have lower latency for the users and even if the redis database in one region completely goes down the other regions will be unaffected and if the connection or syncing between the regions breaks for a short time because of some network problem for example the reddish clusters in these regions can update the data independently and once connection is reestablished they can sync up those changes again now of course when you hear that the first question that may pop up in your mind is how does redis resolve the changes in multiple regions to the same data set so if the same data changed in multiple regions how does radies make sure that data changes of any region isn't lost and data is correctly synced and how does it ensure data consistency specifically for that redis enterprise uses a concept called crdts which stands for conflictfree replicated data types and this concept is used to resolve any conflicts automatically at the database level and without any data loss so basically redis itself has a mechanism for merging the changes which were made to the same data set from multiple sources in a way that none of the data changes are lost and any conflicts are properly resolved and since as you learned ready supports multiple data types for each data type they use its own data conflict resolution rules which are the most optimal for that specific data type so simply put instead of just overriding the changes of one source and just discarding all the others all the parallel changes are kept and intelligently resolved and again this is automatically done for you with this active active georeplication feature so you don't need to worry about that and the last topic i want to address with redis is running redis in kubernetes as i said redis is a great fit for complex microservices that need to support multiple data types and that need an easy scaling of a database without worrying about data consistency and we also know that the new standard for running microservices is the kubernetes platform so running redis in kubernetes is a very interesting and common use case so how does that work with open source redis you can deploy replicated redis as a help chart or kubernetes manifest files and basically using the replication and scaling rules that we already talked about set up and run a highly available redis database the only difference would be that the hosts where redis will run will be kubernetes pods instead of for example ec2 instances or any other physical or virtual servers but the same sharding replicating and scaling concepts apply here as well when you want to run redis cluster in kubernetes and you would basically have to manage that setup yourself however as i mentioned many teams don't want to have the effort of maintaining these thirdparty services because they rather invest their time and resources in application development or other tasks so having an easier alternative is important here as well so redis enterprise has a managed redis cluster which you can deploy as a kubernetes operator if you don't know operators operator in kubernetes is basically a concept where you can bundle all the resources needed to operate a certain application or service so that you don't have to manage it yourself or you don't have to operate it yourself so instead of a human operating a database you basically have all this logic in an automated form to operate a database for you and many databases have operators for kubernetes and each such operator has of course its own logic based on who wrote them and how they wrote them the redis enterprise on kubernetes operator specifically automates deployment and configuration of the whole radius database in your kubernetes cluster it also takes care of scaling doing the backups and recovering the redis cluster if needed etc so it takes over the complete operation of radius cluster inside the kubernetes cluster well i hope you learned a lot in this video and that i was able to answer many of your questions if you want to try redis enterprise cloud be sure to check out my special link in the video description for a 200 credit and if you want to learn more similar technologies and concepts then make sure to subscribe to my channel because i make videos regularly about different devops and cloud technologies also comment below if you have any questions regarding reddis or any new topic suggestions and with that thank you for watching and see you in the next video
