With timestamps:

00:00 - in this video we will go through a
00:02 - practical use case
00:04 - of deploying a managed kubernetes
00:05 - cluster on lynode
00:07 - we will deploy a replicated database and
00:10 - configure
00:10 - its persistence and make it accessible
00:13 - through a ui client
00:14 - from browser using ingress and we will
00:18 - use
00:18 - helm to make this process more efficient
00:21 - so you will see helm in practice and
00:23 - some of its advantages
00:25 - to give you a more detailed overview
00:27 - first we will deploy
00:28 - mongodb in lynode cluster using helm
00:32 - we will create replicated mongodb using
00:35 - statefulset
00:36 - and we will also configure data
00:38 - persistence
00:39 - for mongodb database using lynode's
00:42 - cloud storage we will then deploy a ui
00:45 - client
00:46 -  express for a mongodb database in
00:49 - order to access it from the browser
00:52 - and for this client we will configure
00:55 - nginx ingress
00:56 - so we will deploy ingress controller in
00:58 - the cluster and configure
01:00 - ingress rule in order to demonstrate
01:03 - handling browser request
01:05 - in the cluster and almost hundred
01:08 - percent of this whole setup is what you
01:10 - probably will always need to do when you
01:12 - set up your kubernetes cluster
01:14 - no matter which database or cloud
01:17 - platform you use
01:18 - so you can use the concepts you learn
01:20 - here for many other use cases as well
01:24 - so the first thing we'll do is create
01:26 - kubernetes cluster
01:27 - on lean node kubernetes engine
01:31 - so i have clean state i don't have any
01:32 - nodes yet i don't have any volumes
01:35 - it's all clean so here from create tab
01:38 - i can choose kubernetes and this is a ui
01:42 - where
01:43 - basically you can give all the
01:44 - information for your kubernetes cluster
01:46 - let's call it test
01:48 - i'm going to choose a region which is
01:50 - closest to me
01:53 - this version i'll choose the latest from
01:56 - the list
01:57 - and this is a place where you can choose
01:59 - your
02:00 - notes so as i explained to you in the
02:02 - theoretic part of the video
02:04 - manage kubernetes service basically
02:07 - manages the
02:08 - masternodes for you so you don't have to
02:10 - create or end masternodes
02:12 - they're hidden away from you you don't
02:13 - have access to them and they're managed
02:16 - including their security and backups etc
02:19 - you only need to care about the worker
02:21 - nodes and this is a
02:23 - place where you choose your worker nodes
02:26 - these are the capacities of different
02:28 - ones
02:29 - so i'm going to choose the second one
02:30 - actually the 4gb
02:32 - and i'm going to choose number or how
02:35 - many
02:35 - of those worker nodes i want i'm going
02:37 - to choose 2
02:39 - and i'm going to add that to my cluster
02:41 - and
02:42 - here i see the capacity again and i also
02:45 - see the
02:46 - monthly cost of that cluster
02:49 - and create cluster so basically this is
02:52 - all you need to do in order to create a
02:55 - cluster this is all the information you
02:56 - need
02:57 - everything else will be done in the
02:58 - backend for you and then you see this
03:01 - dashboard with all the information and
03:03 - you see the progress basically of your
03:05 - worker notes provisioning or being
03:08 - created
03:08 - so we're gonna wait until that creates
03:11 - it takes actually
03:12 - just a couple of minutes to create the
03:14 - cluster and here in the notifications
03:16 - you actually see what's happening
03:18 - in the background so you see for example
03:20 - your worker nodes
03:21 - got created some configuration has been
03:24 - added etc
03:26 - so you see the nodes are running they're
03:27 - ready so now we have
03:29 - a kubernetes cluster on leanode platform
03:32 - and obviously we want to access it from
03:34 - our local machine from a laptop
03:36 - so that i can execute cubectl commands
03:39 - and deploy stuff on that
03:40 - in order to do that i need access file
03:43 - or access credentials and this is all
03:46 - stored right here so you can download it
03:50 - and this is what i have right here so
03:53 - this file basically if you open it you
03:54 - can see
03:55 - there are credentials for the cluster
03:58 - and also the certificate so this will
03:59 - make it possible for you to
04:01 - connect to the remote kubernetes cluster
04:06 - so the first thing you want to do when
04:07 - you download this file
04:10 - is i'm going to go to the folder where i
04:13 - downloaded it
04:14 - so this is the cubeconfig file and you
04:17 - have to set it as an environmental
04:18 - variable
04:19 - so i'm going to do export cube config
04:25 - and set the value to this file
04:30 - and now if i do cube ctl get node
04:34 - i see my two linode worker nodes so i'm
04:38 - connected to this remote
04:39 - cluster and i can now deploy stuff
04:43 - in there using cube ctl command and all
04:46 - you need to do that for that
04:48 - is set this variable and you see the
04:51 - status of nodes
04:52 - is also ready so we've created
04:55 - kubernetes cluster
04:56 - and we are now connected to it now the
04:59 - second step that we're gonna
05:00 - do is deploy mongodb stateful set
05:04 - in the cluster so there are two ways to
05:06 - do that the first one
05:08 - is we can create all the files or the
05:11 - config files necessary to deploy
05:13 - or mongodb stateful set this will be the
05:16 - stateful set config file itself this
05:18 - will be the two services that we need
05:20 - and maybe some configuration as well and
05:23 - in order to do that
05:24 - we need to find the image the version
05:27 - for the stateful set or maybe google and
05:30 - find
05:30 - correct configuration for mongodb like a
05:33 - script
05:34 - that synchronizes the parts
05:37 - of the stateful set and so on
05:40 - or the second option the easier one is
05:43 - we find a bundle of those configuration
05:47 - files
05:48 - that somebody already created tested
05:51 - and is managing or maintaining and
05:54 - use that file so that we don't have to
05:56 - figure out all the details
05:58 - and that bundle could be a helm chart so
06:01 - whenever you have this situation where
06:03 - you need to deploy a stateful set for
06:05 - example
06:06 - which has a lot of configuration details
06:09 - the first thing you can do
06:10 - is search if there's a helm chart for it
06:13 - so i'm gonna look for mongodb helm chart
06:17 - and currently the maintained mongodb
06:20 - chart
06:20 - helm chart is uh managed by bitnami
06:23 - by the way if you don't know exactly
06:25 - what helm is and helm charts are
06:28 - i have a separate video about that where
06:29 - you can learn exactly what helm is what
06:31 - are the
06:32 - advantages of it and then you can come
06:34 - back to the video and see
06:35 - how to actually use it in practice okay
06:39 - so the first thing i need to do is add
06:42 - the repository
06:43 - that contains my helm chart so i'm gonna
06:47 - go back and i'm gonna execute this helm
06:49 - command here
06:51 - you have to install helm if you don't
06:52 - have it yet and
06:54 - one thing to note here as well when i
06:56 - execute helm command
06:58 - it is gonna execute it against the
07:01 - cluster that i'm connected to right
07:04 - so we connect it to the cluster so now
07:06 - we can execute cubectl and also
07:09 - help comments against that cluster so
07:12 - helm will use
07:13 - cubectl in the background so i'm going
07:15 - to add
07:16 - bit number repository it has been added
07:20 - and what i can do now is i can do helm
07:23 - search repo bitnami
07:30 - and i can see all the charts that this
07:32 - repository contains
07:34 - and let's actually search for mongodb
07:39 - and these are the two so i have mongodb
07:42 - chart
07:42 - right here i see the version of the
07:45 - chart
07:46 - and the version as well so this is our
07:48 - chart this is what we're gonna
07:50 - install in our cluster now when you're
07:52 - installing a chart there might be some
07:54 - values that you want to override so
07:56 - chart provides you some default values
07:58 - and you want to see or you want to check
08:00 - what parameters or what values you can
08:02 - override
08:03 - so let's go back to the browser and
08:07 - let's see what parameters we have
08:09 - available so
08:10 - let's check mongodb and this is all the
08:13 - description
08:14 - for the chart and here are the
08:16 - parameters
08:17 - so the first thing that we are going to
08:19 - do is we're going to define
08:20 - that we want to run a stateful set right
08:24 - so because we want to replicate our
08:26 - mongodb database we want to
08:28 - we don't want just one pod we want
08:30 - multiple
08:31 - replica parts so we're going to set this
08:33 - to replica set
08:34 - another thing that we're going to do is
08:37 - pass root password or
08:39 - set the root password ourselves if not
08:41 - it will just
08:42 - create a random one which we can also
08:44 - access later
08:45 - so that's our choice and another thing
08:48 - that we want to override here
08:49 - is the volume configuration so we want
08:53 - the chart to use the storage
08:56 - class of leanode cloud storage
09:00 - because we want it to connect to linode
09:02 - and create
09:03 - volumes or physical storage on lynode
09:06 - and attach it to our pods this may sound
09:08 - a little bit complicated
09:09 - as a concept but you as a user you don't
09:12 - have to do much for it it's just one
09:14 - line
09:15 - and everything else is done in the
09:16 - background now if you want to learn
09:18 - more about stateful sets or what
09:21 - persistent volumes or storage classes
09:23 - are
09:24 - i have separate videos on all of those
09:25 - topics so you can check them out
09:27 - right so how do we actually pass those
09:31 - parameters to a chart so how can we
09:33 - override some values that are defined in
09:35 - the chart already
09:36 - and we do that in helm using a values
09:39 - file
09:40 - so i'm going to go back and create a
09:43 - file
09:43 - that will overwrite some of these
09:46 - parameters
09:49 - so i have the file created already this
09:50 - is a yaml file and these are the
09:52 - parameters
09:54 - so this is just the yaml file with key
09:57 - value pairs defined
09:58 - to override those parameters so i have
10:00 - architecture which is replica set
10:02 - replica count is going to be three so
10:05 - when you
10:06 - set it to replicate then you can use all
10:09 - these
10:09 - parameters for stateful set so i set
10:13 - replica count
10:16 - to three and in persistence i use
10:19 - storage class linode block storage
10:23 - right so let's go back and see
10:25 - persistence
10:28 - persistence parameters so persistence
10:32 - dot storage class and this is how i
10:35 - define it here
10:37 - and the value of it is linode block
10:40 - storage
10:41 - so this is everything you need to do in
10:43 - order to configure persistent
10:45 - volume for your mongodb this is
10:48 - easy as that so what this will do is in
10:51 - the background
10:52 - it will connect to lenode and it will
10:54 - create physical storages
10:56 - using linux cloud storage and attach it
10:58 - to your pots
11:00 - again if you don't understand this
11:02 - concept you can watch
11:04 - my video about storage and you will have
11:07 - a better understanding there
11:08 - and we also overriding the root password
11:11 - so we have everything ready we have the
11:12 - chart
11:13 - and we have the values that we use to
11:16 - override some of the parameters of the
11:18 - chart so now all we need to do is
11:20 - execute the command
11:22 - in order to install the chart using
11:24 - those override values
11:26 - and that command is helm install and
11:28 - then
11:29 - i define an arbitrary name that i want
11:32 - to give
11:32 - mongodb in my cluster so let's call it
11:35 - mongodb
11:36 - and this is where we pass this
11:39 - parameters file that we created
11:42 - so this is going to be values
11:47 - flag and i have that file
11:50 - in downloads folder so let's see
11:53 - let's test
11:57 - mongodb that's the file and finally
12:01 - we are going to provide the name of the
12:04 - chart
12:04 - so this is the name repository slash
12:08 - chart name and this is the complete
12:10 - command so
12:12 - install this is the name that we give
12:15 - our mongodb stateful set the values file
12:19 - as a parameter and the chart name so
12:21 - when i execute this
12:23 - it will install that mongodb chart
12:26 - in my cluster and you see i get some
12:29 - additional output
12:30 - of the status so it basically started to
12:34 - deploy them
12:35 - i have three replicas as i provided
12:38 - here and each one of them gets
12:42 - their own service so now let's actually
12:46 - check what is happening in our cluster
12:48 - and you see
12:49 - that our pod replicas are being created
12:52 - so this can take a little bit of time
12:55 - so we clear this up okay so
12:58 - it must be started already and as you
13:00 - see i have
13:01 - three parts of mongodb running plus
13:04 - there is another part that manages
13:06 - um the replication uh between those but
13:09 - again you don't have to worry about the
13:10 - details you don't
13:11 - have to know how the whole thing is done
13:14 - because this
13:15 - gets updated as well all the time that's
13:17 - why it's much more practical to use the
13:19 - charts instead of trying to patch
13:21 - together your own configuration files
13:24 - okay let's also see what other things
13:26 - got created
13:28 - so i'm just gonna print out everything
13:31 - in the
13:31 - default namespace um so in addition to
13:34 - our pods
13:35 - you see the services we have three
13:38 - mongodb services
13:39 - that have been created and one of them
13:41 - is mongodb
13:42 - headless service again i'm not going to
13:45 - go into much detail to how
13:46 - stateful set and services work because i
13:49 - made a
13:50 - separate video on them so go check that
13:52 - out if you haven't seen that already
13:54 - and the stage will set of course and
13:56 - this is the name that we gave when
13:58 - installing the helm chart it's called
14:00 - mongodb and
14:02 - what we also have is a secret
14:05 - of mongodb that actually contains
14:09 - the the root password that we provided
14:11 - here so
14:12 - now what about the persistent storage
14:14 - let's actually head back
14:16 - to leenote ui and let's go
14:19 - to first of all in lean nodes you have
14:21 - those two worker nodes and their status
14:25 - if you click in one of them you can see
14:27 - all the configuration there
14:28 - like ip addresses etc and in volumes
14:32 - you see it was empty when we set up the
14:35 - cluster and now we have three persistent
14:39 - volume
14:39 - components that were dynamically
14:42 - provisioned or created
14:44 - so basically this configuration right
14:46 - here the node block storage
14:48 - defined as storage class what happened
14:50 - is that
14:51 - when the stateful set was created
14:54 - for each pod one a physical storage
14:58 - was created for each of the three parts
15:01 - so this is the physical storage
15:03 - somewhere on the node servers
15:04 - and for each physical storage a
15:07 - persistent volume was created and that
15:09 - is now attached
15:10 - to the node where the pod is running
15:14 - we have only two nodes so these two are
15:16 - the same
15:17 - and this is the second node so again we
15:20 - didn't have to do much here
15:21 - everything is configured pretty easily
15:24 - and now we have
15:25 - a replicated mongodb with its persistent
15:28 - volume configured
15:30 - in the cluster now the next thing we're
15:33 - going to do
15:34 - is deploy express which is going
15:36 - to be the ui
15:38 - for mongodb now since express is
15:42 - actually
15:42 - just gonna be one part um so we don't
15:45 - have to replicate it and it's gonna have
15:47 - one service it's pretty straightforward
15:49 - i actually went ahead and created own
15:52 - configuration file
15:53 - i don't need to search for a chart or
15:55 - anything there
15:56 - because it doesn't have so many parts um
15:59 - so this is the file
16:00 - and by the way all these files that you
16:02 - see here i'm going to put them in a git
16:04 - repository and link them
16:05 - in the description so you can use them
16:07 - as well if you want to practice along
16:09 - with this video
16:10 - so this is very simple straightforward
16:12 - deployment configuration we have
16:14 - express
16:15 - name everywhere and this is our
16:17 - container so we take the latest
16:20 - express
16:20 - image is going to run on port 8081
16:25 - and this is the configuration for
16:27 - connecting
16:28 - to mongodb and these are the
16:30 - environmental variables
16:31 - configured so that express can
16:34 - connect
16:35 - to mongodb database and if you're asking
16:38 - where i got these
16:39 - environmental variables from or how do i
16:41 - know what they're called
16:42 - you can check out the express
16:45 - docker file
16:47 - it comes with the documentation of how
16:49 - it works
16:50 - and here are all those environmental
16:52 - variables so it's pretty easy to find
16:54 - that out
16:56 - and also if you want to fixate the
16:57 - version you can
16:59 - choose one of the texts i'm just using
17:01 - the latest
17:02 - okay so we have configured username
17:06 - the admin username which is root by
17:08 - default and we have
17:10 - admin user password this is what we
17:13 - configured here
17:14 - and because those yaml files are usually
17:17 - checked into the repository
17:19 - it's not a good practice to write
17:21 - passwords directly
17:22 - so we are getting it from the secret
17:25 - right and this is a syntax for it again
17:27 - i have a separate video about that if
17:29 - you want to check that out so i'm not
17:30 - gonna go into syntax details
17:32 - but just very quickly i'm taking that
17:35 - root password
17:36 - value from the secret this is secret
17:39 - that we saw before
17:40 - so this secret actually contains we can
17:42 - check that
17:49 - like this you can check the values
17:52 - inside
17:53 - so we have two key pair values we have
17:56 - the replica set key we don't need that
17:57 - and this
17:58 - is the root password key so i'm going to
18:01 - be root password
18:02 - that's how i'm accessing it and the
18:04 - third one this is also important one
18:06 - is the value of mongodb server
18:10 - so this is the end point where
18:12 - express will
18:13 - connect to mongodb pod and this is the
18:17 - pod endpoint
18:18 - this is the pod name and this is the
18:20 - headless service name so this is how
18:23 - the endpoint looks like this this
18:26 - concept is also covered in a stateful
18:27 - set video
18:28 - so you can learn it there so i have the
18:31 - endpoint
18:32 - user and password in order to connect to
18:35 - mongodb
18:36 - let's look at the service also very
18:38 - straightforward it's an internal service
18:40 - so it's not accessible through browser
18:43 - it's only accessible within the cluster
18:45 - it listens on port 8081
18:48 - and sends the request
18:51 - to the pod on port 8081
18:55 - so this is the target port right here so
18:58 - this is all we need
18:59 - to configure express and i'm gonna
19:03 - create that in the cluster so let's
19:05 - clear that actually
19:08 - keep ctl apply
19:15 - like this so now we have the
19:18 - express
19:19 - running as well and container will
19:21 - create
19:23 - so when it successfully connects to
19:25 - mongodb
19:26 - it will have a running state so let's
19:28 - check again
19:32 - and as you see it's running we can also
19:34 - check the logs to be sure
19:36 - logs
19:41 - admin database connected cool so we have
19:45 - mongodb running in the cluster the data
19:48 - is being persisted
19:49 - and we have express so we can
19:51 - access the mongodb ui
19:53 - however as you saw the express is
19:56 - internal service so we have to open it
19:58 - to the browser for external requests
20:02 - and we're going to do that using ingress
20:05 - so the next step
20:06 - will be to install ingress controller
20:09 - in our lee notes kubernetes cluster and
20:12 - let's see how that works
20:14 - so now we're going to deploy ingress
20:16 - controller in our cluster
20:17 - uh english control also has some
20:19 - different components so instead of
20:21 - creating the configuration file
20:22 - ourselves for it we're gonna use helm
20:25 - chart
20:26 - for ingress controller as well and i
20:28 - believe there are a couple of different
20:30 - helm charts for ingress controller
20:32 - we're gonna deploy the kubernetes
20:34 - managed
20:35 - nginx ingress controller and i already
20:37 - found a helm chart for it
20:39 - so i'm gonna add the repository first
20:42 - of that helm chart it's been edit and
20:44 - now i'm gonna execute
20:47 - the installing of the helm chart so
20:49 - again the name that i
20:51 - giving to this component this is the
20:54 - chart name
20:55 - from the repository so it's stable nginx
20:58 - ingress
20:58 - and i'm passing in some attribute or
21:01 - some parameter
21:03 - and here again we see the output this is
21:06 - a
21:06 - example ingress rule file and we can now
21:10 - check that the ingress controller was
21:12 - deployed we see two nginx ingress pods
21:16 - are running here the one is just a
21:18 - default backend if no rule is configured
21:21 - and the controller itself so this means
21:24 - that now we can actually create
21:25 - ingress rules in our cluster so now we
21:28 - can define
21:29 - a domain name or host name that will
21:31 - then route to
21:32 - some kubernetes service now as i also
21:34 - explained in the theoretical part of
21:36 - this video
21:37 - series ingress controller uses
21:40 - some cloud native load balancer in the
21:43 - background
21:44 - so if i go back to lee notes ui and if i
21:47 - go to node balancers
21:48 - this is leenode's own node balancer or
21:52 - worker node balancer
21:53 - that was dynamically created and
21:56 - provisioned
21:57 - as we created the ingress controller
22:00 - and as i explained this node balancer
22:03 - becomes the entry point into our cluster
22:06 - so this node balancer basically gives us
22:09 - the external ip address
22:10 - this is the one accessible from browser
22:12 - we have the ports open on it
22:14 - the 80 and so http and https ports
22:18 - and the node balancer will then forward
22:21 - the request
22:22 - coming into into the cluster then to
22:25 - the ingress controller and to our
22:28 - internal services based on the ingress
22:31 - roles that we create
22:32 - so let's go ahead and create the ingress
22:34 - role for our express
22:36 - service so that we can access it from
22:38 - the browser we can also see that
22:41 - nginx ingress service was created
22:44 - so let's see service
22:48 - and here we have the enginex ingress
22:50 - controller service
22:52 - and as you see the type is load balancer
22:55 - this basically means that this service
22:57 - is accessible externally
22:59 - and the cluster ip services are internal
23:02 - services
23:02 - so they're not accessible from outside
23:05 - the cluster
23:06 - and the external services also have
23:10 - external ip address in addition to the
23:12 - internal cluster ip address
23:14 - and this ip address is actually the same
23:18 - as the ip address of the node balancer
23:23 - so as you see here here we have the ip
23:25 - address
23:26 - of the node balancer and this is the
23:28 - same one
23:29 - as this here so as i said this will act
23:32 - as an entry point into our cluster
23:34 - and will forward the requests based on
23:37 - the nginx
23:38 - rule that we create to respective
23:41 - service
23:42 - so now we're going to go create ingress
23:44 - rule for
23:45 -  express service so that we can
23:48 - access it from the browser
23:49 - so this is the ingress rule that we're
23:51 - going to create we're going to call it
23:53 -  express
23:54 - and the first thing we need to configure
23:56 - is the host so
23:58 - host has to be a valid domain address it
24:01 - cannot be an ip address
24:03 - so this is the first value that we're
24:04 - going to get so the host is basically a
24:07 - domain address
24:08 - that is connected to your cluster so i'm
24:11 - going to go back to linux
24:12 - and load balancer i have the hostname
24:15 - of the load balancer as well so i'm
24:17 - going to use that one
24:19 - but in production for example in normal
24:21 - case you would have your
24:22 - application domain so myapp.com or
24:25 - whatever it is
24:26 - so basically you have to configure the
24:28 - domain
24:29 - wherever it's hosted to point to the ip
24:32 - address of the note balancer
24:34 - so that whenever someone types the
24:35 - domain address in the browser
24:37 - the domain name server will resolve that
24:40 - domain name
24:41 - to the ip address of your cluster
24:44 - entry point server right so i'm just
24:47 - gonna go with the host name that i have
24:49 - for the node balancer because it's
24:51 - already pointing to the ip address
24:53 - and i'm gonna go back and paste that in
24:57 - so i have my host and here we basically
25:00 - define
25:01 - a http forwarding of request that's
25:05 - coming from this domain to our internal
25:08 - service so request came into the cluster
25:11 - from this domain
25:12 - on that path on the root path basically
25:15 - and we are forwarding it to
25:17 - service name called express
25:19 - service this is the service name which
25:21 - we created here
25:22 - the internal service on the service port
25:25 - 8081.
25:26 - this is where the service express
25:28 - is listening to
25:30 - and this will be it for the ingress file
25:32 - so let's actually apply that in the
25:34 - cluster
25:35 - let's clear that
25:39 - cube ctrl
25:43 - [Music]
25:45 - and our ingress is created as well let's
25:48 - actually check that
25:51 - that's our ingress roll so now if i copy
25:55 - that
25:55 - this is the domain that we defined in
25:57 - our ingress rule
25:59 - so when i access this domain i get
26:03 -  express ui so
26:06 - now again for clarification i
26:10 - typed in the host name that i configured
26:13 - in my
26:14 - ingress rules in the browser this host
26:17 - name was resolved to the ip address of
26:20 - node balancer which is the external ip
26:23 - address
26:24 - of my cluster or entry point of my
26:26 - cluster so now the ingress controller
26:28 - looked at the request and looked at the
26:30 - ingress rules that it has
26:32 - inside the cluster and actually resolved
26:35 - that request must be forwarded to our
26:37 - internal service called
26:39 -  express service at the port 8081
26:42 - and that's how the whole request flow
26:44 - happened in the cluster and that's why
26:46 - we see
26:46 -  express ui under that host name
26:50 - so now i can create a new database
26:53 - you can see it here and update some
26:56 - stuff as well
27:00 - so everything works i have my database
27:02 - here and this
27:03 - changes will also be persisted because
27:06 - we have
27:06 - data persistence configured as well
27:09 - using the volumes
27:11 - so this means that if i now delete the
27:14 - pods
27:15 - and restart them the data will still be
27:17 - there so
27:19 - let's actually do that now
27:22 - i'm going to scale down the stateful set
27:28 - called mongodb to zero replicas
27:34 - let's check that
27:37 - pod it's terminating so all the parts
27:41 - are gone so now i'm gonna scale it back
27:44 - to three
27:45 - [Music]
27:46 - so this means the containers um inside
27:50 - so the pods and the containers inside
27:52 - will be created
27:53 - again so if i go back to lean node you
27:56 - see that
27:57 - the volumes were unattached and now as
27:59 - the pods are creating a gain
28:02 - they're reattaching the volumes that
28:04 - belong to them
28:05 - which is a good thing because on the new
28:08 - start on the restart
28:10 - they basically get the same data that
28:13 - they had before they were stopped or
28:15 - they were removed
28:16 - so all the data is reattached to those
28:19 - pods
28:20 - and now if i'm done with the chart for
28:22 - example
28:23 - or for example if i want to reinstall my
28:26 - charts
28:27 - or update or whatever i can also
28:30 - uninstall it pretty easily using helm
28:33 - so with helm ls i see all my charts here
28:36 - i have mongodb
28:37 - and nginx ingress so i can do
28:40 - helm uninstall
28:44 - mongodb
28:45 - [Music]
28:47 - and the great thing about it is that if
28:49 - you manually created all those
28:52 - components like secret services
28:56 - pods stateful set etc you would have to
29:00 - go and clean up all those stuff manually
29:02 - or you would have to know what was
29:04 - created
29:05 - and remember so that you can remove them
29:07 - as well
29:08 - with helm basically uninstalled as the
29:11 - revert of install
29:12 - so this is another advantage of using
29:14 - helm charts actually
29:15 - so now after uninstall you see all the
29:18 - volumes got
29:19 - unattached again so i don't have mongodb
29:22 - stateful set running at all in my
29:25 - cluster
29:26 - all the components were deleted but i
29:28 - still have
29:29 - the volumes or i still have the data in
29:32 - case i
29:32 - re-start them or re-install that
29:36 - stateful set and this is a security
29:37 - feature because you may not want to lose
29:39 - the data when you delete the application
29:42 - and if you don't need those you can
29:45 - actually just go and
29:46 - delete them and also if you're done with
29:49 - cluster
29:50 - you don't have to go and delete all
29:51 - those components like volumes and
29:53 - workers
29:54 - etc you go to your kubernetes delete the
29:57 - whole cluster
29:58 - pretty easily or maybe if you've
30:01 - corrupted cluster i don't know you
30:03 - tested around
30:04 - some stuff and kind of got messed up you
30:07 - can basically delete it
30:08 - and start from scratch so
30:11 - that's it for the demo i hope you also
30:14 - practiced along and you were able to
30:17 - create the same setup if you got stuck
30:19 - somewhere or if you have any questions
30:21 - please write them in the comment section
30:23 - below and i will try to
30:25 - answer as many questions as i can thank
30:28 - you for watching this video
30:29 - and see you in the next one

Cleaned transcript:

in this video we will go through a practical use case of deploying a managed kubernetes cluster on lynode we will deploy a replicated database and configure its persistence and make it accessible through a ui client from browser using ingress and we will use helm to make this process more efficient so you will see helm in practice and some of its advantages to give you a more detailed overview first we will deploy mongodb in lynode cluster using helm we will create replicated mongodb using statefulset and we will also configure data persistence for mongodb database using lynode's cloud storage we will then deploy a ui client express for a mongodb database in order to access it from the browser and for this client we will configure nginx ingress so we will deploy ingress controller in the cluster and configure ingress rule in order to demonstrate handling browser request in the cluster and almost hundred percent of this whole setup is what you probably will always need to do when you set up your kubernetes cluster no matter which database or cloud platform you use so you can use the concepts you learn here for many other use cases as well so the first thing we'll do is create kubernetes cluster on lean node kubernetes engine so i have clean state i don't have any nodes yet i don't have any volumes it's all clean so here from create tab i can choose kubernetes and this is a ui where basically you can give all the information for your kubernetes cluster let's call it test i'm going to choose a region which is closest to me this version i'll choose the latest from the list and this is a place where you can choose your notes so as i explained to you in the theoretic part of the video manage kubernetes service basically manages the masternodes for you so you don't have to create or end masternodes they're hidden away from you you don't have access to them and they're managed including their security and backups etc you only need to care about the worker nodes and this is a place where you choose your worker nodes these are the capacities of different ones so i'm going to choose the second one actually the 4gb and i'm going to choose number or how many of those worker nodes i want i'm going to choose 2 and i'm going to add that to my cluster and here i see the capacity again and i also see the monthly cost of that cluster and create cluster so basically this is all you need to do in order to create a cluster this is all the information you need everything else will be done in the backend for you and then you see this dashboard with all the information and you see the progress basically of your worker notes provisioning or being created so we're gonna wait until that creates it takes actually just a couple of minutes to create the cluster and here in the notifications you actually see what's happening in the background so you see for example your worker nodes got created some configuration has been added etc so you see the nodes are running they're ready so now we have a kubernetes cluster on leanode platform and obviously we want to access it from our local machine from a laptop so that i can execute cubectl commands and deploy stuff on that in order to do that i need access file or access credentials and this is all stored right here so you can download it and this is what i have right here so this file basically if you open it you can see there are credentials for the cluster and also the certificate so this will make it possible for you to connect to the remote kubernetes cluster so the first thing you want to do when you download this file is i'm going to go to the folder where i downloaded it so this is the cubeconfig file and you have to set it as an environmental variable so i'm going to do export cube config and set the value to this file and now if i do cube ctl get node i see my two linode worker nodes so i'm connected to this remote cluster and i can now deploy stuff in there using cube ctl command and all you need to do that for that is set this variable and you see the status of nodes is also ready so we've created kubernetes cluster and we are now connected to it now the second step that we're gonna do is deploy mongodb stateful set in the cluster so there are two ways to do that the first one is we can create all the files or the config files necessary to deploy or mongodb stateful set this will be the stateful set config file itself this will be the two services that we need and maybe some configuration as well and in order to do that we need to find the image the version for the stateful set or maybe google and find correct configuration for mongodb like a script that synchronizes the parts of the stateful set and so on or the second option the easier one is we find a bundle of those configuration files that somebody already created tested and is managing or maintaining and use that file so that we don't have to figure out all the details and that bundle could be a helm chart so whenever you have this situation where you need to deploy a stateful set for example which has a lot of configuration details the first thing you can do is search if there's a helm chart for it so i'm gonna look for mongodb helm chart and currently the maintained mongodb chart helm chart is uh managed by bitnami by the way if you don't know exactly what helm is and helm charts are i have a separate video about that where you can learn exactly what helm is what are the advantages of it and then you can come back to the video and see how to actually use it in practice okay so the first thing i need to do is add the repository that contains my helm chart so i'm gonna go back and i'm gonna execute this helm command here you have to install helm if you don't have it yet and one thing to note here as well when i execute helm command it is gonna execute it against the cluster that i'm connected to right so we connect it to the cluster so now we can execute cubectl and also help comments against that cluster so helm will use cubectl in the background so i'm going to add bit number repository it has been added and what i can do now is i can do helm search repo bitnami and i can see all the charts that this repository contains and let's actually search for mongodb and these are the two so i have mongodb chart right here i see the version of the chart and the version as well so this is our chart this is what we're gonna install in our cluster now when you're installing a chart there might be some values that you want to override so chart provides you some default values and you want to see or you want to check what parameters or what values you can override so let's go back to the browser and let's see what parameters we have available so let's check mongodb and this is all the description for the chart and here are the parameters so the first thing that we are going to do is we're going to define that we want to run a stateful set right so because we want to replicate our mongodb database we want to we don't want just one pod we want multiple replica parts so we're going to set this to replica set another thing that we're going to do is pass root password or set the root password ourselves if not it will just create a random one which we can also access later so that's our choice and another thing that we want to override here is the volume configuration so we want the chart to use the storage class of leanode cloud storage because we want it to connect to linode and create volumes or physical storage on lynode and attach it to our pods this may sound a little bit complicated as a concept but you as a user you don't have to do much for it it's just one line and everything else is done in the background now if you want to learn more about stateful sets or what persistent volumes or storage classes are i have separate videos on all of those topics so you can check them out right so how do we actually pass those parameters to a chart so how can we override some values that are defined in the chart already and we do that in helm using a values file so i'm going to go back and create a file that will overwrite some of these parameters so i have the file created already this is a yaml file and these are the parameters so this is just the yaml file with key value pairs defined to override those parameters so i have architecture which is replica set replica count is going to be three so when you set it to replicate then you can use all these parameters for stateful set so i set replica count to three and in persistence i use storage class linode block storage right so let's go back and see persistence persistence parameters so persistence dot storage class and this is how i define it here and the value of it is linode block storage so this is everything you need to do in order to configure persistent volume for your mongodb this is easy as that so what this will do is in the background it will connect to lenode and it will create physical storages using linux cloud storage and attach it to your pots again if you don't understand this concept you can watch my video about storage and you will have a better understanding there and we also overriding the root password so we have everything ready we have the chart and we have the values that we use to override some of the parameters of the chart so now all we need to do is execute the command in order to install the chart using those override values and that command is helm install and then i define an arbitrary name that i want to give mongodb in my cluster so let's call it mongodb and this is where we pass this parameters file that we created so this is going to be values flag and i have that file in downloads folder so let's see let's test mongodb that's the file and finally we are going to provide the name of the chart so this is the name repository slash chart name and this is the complete command so install this is the name that we give our mongodb stateful set the values file as a parameter and the chart name so when i execute this it will install that mongodb chart in my cluster and you see i get some additional output of the status so it basically started to deploy them i have three replicas as i provided here and each one of them gets their own service so now let's actually check what is happening in our cluster and you see that our pod replicas are being created so this can take a little bit of time so we clear this up okay so it must be started already and as you see i have three parts of mongodb running plus there is another part that manages um the replication uh between those but again you don't have to worry about the details you don't have to know how the whole thing is done because this gets updated as well all the time that's why it's much more practical to use the charts instead of trying to patch together your own configuration files okay let's also see what other things got created so i'm just gonna print out everything in the default namespace um so in addition to our pods you see the services we have three mongodb services that have been created and one of them is mongodb headless service again i'm not going to go into much detail to how stateful set and services work because i made a separate video on them so go check that out if you haven't seen that already and the stage will set of course and this is the name that we gave when installing the helm chart it's called mongodb and what we also have is a secret of mongodb that actually contains the the root password that we provided here so now what about the persistent storage let's actually head back to leenote ui and let's go to first of all in lean nodes you have those two worker nodes and their status if you click in one of them you can see all the configuration there like ip addresses etc and in volumes you see it was empty when we set up the cluster and now we have three persistent volume components that were dynamically provisioned or created so basically this configuration right here the node block storage defined as storage class what happened is that when the stateful set was created for each pod one a physical storage was created for each of the three parts so this is the physical storage somewhere on the node servers and for each physical storage a persistent volume was created and that is now attached to the node where the pod is running we have only two nodes so these two are the same and this is the second node so again we didn't have to do much here everything is configured pretty easily and now we have a replicated mongodb with its persistent volume configured in the cluster now the next thing we're going to do is deploy express which is going to be the ui for mongodb now since express is actually just gonna be one part um so we don't have to replicate it and it's gonna have one service it's pretty straightforward i actually went ahead and created own configuration file i don't need to search for a chart or anything there because it doesn't have so many parts um so this is the file and by the way all these files that you see here i'm going to put them in a git repository and link them in the description so you can use them as well if you want to practice along with this video so this is very simple straightforward deployment configuration we have express name everywhere and this is our container so we take the latest express image is going to run on port 8081 and this is the configuration for connecting to mongodb and these are the environmental variables configured so that express can connect to mongodb database and if you're asking where i got these environmental variables from or how do i know what they're called you can check out the express docker file it comes with the documentation of how it works and here are all those environmental variables so it's pretty easy to find that out and also if you want to fixate the version you can choose one of the texts i'm just using the latest okay so we have configured username the admin username which is root by default and we have admin user password this is what we configured here and because those yaml files are usually checked into the repository it's not a good practice to write passwords directly so we are getting it from the secret right and this is a syntax for it again i have a separate video about that if you want to check that out so i'm not gonna go into syntax details but just very quickly i'm taking that root password value from the secret this is secret that we saw before so this secret actually contains we can check that like this you can check the values inside so we have two key pair values we have the replica set key we don't need that and this is the root password key so i'm going to be root password that's how i'm accessing it and the third one this is also important one is the value of mongodb server so this is the end point where express will connect to mongodb pod and this is the pod endpoint this is the pod name and this is the headless service name so this is how the endpoint looks like this this concept is also covered in a stateful set video so you can learn it there so i have the endpoint user and password in order to connect to mongodb let's look at the service also very straightforward it's an internal service so it's not accessible through browser it's only accessible within the cluster it listens on port 8081 and sends the request to the pod on port 8081 so this is the target port right here so this is all we need to configure express and i'm gonna create that in the cluster so let's clear that actually keep ctl apply like this so now we have the express running as well and container will create so when it successfully connects to mongodb it will have a running state so let's check again and as you see it's running we can also check the logs to be sure logs admin database connected cool so we have mongodb running in the cluster the data is being persisted and we have express so we can access the mongodb ui however as you saw the express is internal service so we have to open it to the browser for external requests and we're going to do that using ingress so the next step will be to install ingress controller in our lee notes kubernetes cluster and let's see how that works so now we're going to deploy ingress controller in our cluster uh english control also has some different components so instead of creating the configuration file ourselves for it we're gonna use helm chart for ingress controller as well and i believe there are a couple of different helm charts for ingress controller we're gonna deploy the kubernetes managed nginx ingress controller and i already found a helm chart for it so i'm gonna add the repository first of that helm chart it's been edit and now i'm gonna execute the installing of the helm chart so again the name that i giving to this component this is the chart name from the repository so it's stable nginx ingress and i'm passing in some attribute or some parameter and here again we see the output this is a example ingress rule file and we can now check that the ingress controller was deployed we see two nginx ingress pods are running here the one is just a default backend if no rule is configured and the controller itself so this means that now we can actually create ingress rules in our cluster so now we can define a domain name or host name that will then route to some kubernetes service now as i also explained in the theoretical part of this video series ingress controller uses some cloud native load balancer in the background so if i go back to lee notes ui and if i go to node balancers this is leenode's own node balancer or worker node balancer that was dynamically created and provisioned as we created the ingress controller and as i explained this node balancer becomes the entry point into our cluster so this node balancer basically gives us the external ip address this is the one accessible from browser we have the ports open on it the 80 and so http and https ports and the node balancer will then forward the request coming into into the cluster then to the ingress controller and to our internal services based on the ingress roles that we create so let's go ahead and create the ingress role for our express service so that we can access it from the browser we can also see that nginx ingress service was created so let's see service and here we have the enginex ingress controller service and as you see the type is load balancer this basically means that this service is accessible externally and the cluster ip services are internal services so they're not accessible from outside the cluster and the external services also have external ip address in addition to the internal cluster ip address and this ip address is actually the same as the ip address of the node balancer so as you see here here we have the ip address of the node balancer and this is the same one as this here so as i said this will act as an entry point into our cluster and will forward the requests based on the nginx rule that we create to respective service so now we're going to go create ingress rule for express service so that we can access it from the browser so this is the ingress rule that we're going to create we're going to call it express and the first thing we need to configure is the host so host has to be a valid domain address it cannot be an ip address so this is the first value that we're going to get so the host is basically a domain address that is connected to your cluster so i'm going to go back to linux and load balancer i have the hostname of the load balancer as well so i'm going to use that one but in production for example in normal case you would have your application domain so myapp.com or whatever it is so basically you have to configure the domain wherever it's hosted to point to the ip address of the note balancer so that whenever someone types the domain address in the browser the domain name server will resolve that domain name to the ip address of your cluster entry point server right so i'm just gonna go with the host name that i have for the node balancer because it's already pointing to the ip address and i'm gonna go back and paste that in so i have my host and here we basically define a http forwarding of request that's coming from this domain to our internal service so request came into the cluster from this domain on that path on the root path basically and we are forwarding it to service name called express service this is the service name which we created here the internal service on the service port 8081. this is where the service express is listening to and this will be it for the ingress file so let's actually apply that in the cluster let's clear that cube ctrl and our ingress is created as well let's actually check that that's our ingress roll so now if i copy that this is the domain that we defined in our ingress rule so when i access this domain i get express ui so now again for clarification i typed in the host name that i configured in my ingress rules in the browser this host name was resolved to the ip address of node balancer which is the external ip address of my cluster or entry point of my cluster so now the ingress controller looked at the request and looked at the ingress rules that it has inside the cluster and actually resolved that request must be forwarded to our internal service called express service at the port 8081 and that's how the whole request flow happened in the cluster and that's why we see express ui under that host name so now i can create a new database you can see it here and update some stuff as well so everything works i have my database here and this changes will also be persisted because we have data persistence configured as well using the volumes so this means that if i now delete the pods and restart them the data will still be there so let's actually do that now i'm going to scale down the stateful set called mongodb to zero replicas let's check that pod it's terminating so all the parts are gone so now i'm gonna scale it back to three so this means the containers um inside so the pods and the containers inside will be created again so if i go back to lean node you see that the volumes were unattached and now as the pods are creating a gain they're reattaching the volumes that belong to them which is a good thing because on the new start on the restart they basically get the same data that they had before they were stopped or they were removed so all the data is reattached to those pods and now if i'm done with the chart for example or for example if i want to reinstall my charts or update or whatever i can also uninstall it pretty easily using helm so with helm ls i see all my charts here i have mongodb and nginx ingress so i can do helm uninstall mongodb and the great thing about it is that if you manually created all those components like secret services pods stateful set etc you would have to go and clean up all those stuff manually or you would have to know what was created and remember so that you can remove them as well with helm basically uninstalled as the revert of install so this is another advantage of using helm charts actually so now after uninstall you see all the volumes got unattached again so i don't have mongodb stateful set running at all in my cluster all the components were deleted but i still have the volumes or i still have the data in case i restart them or reinstall that stateful set and this is a security feature because you may not want to lose the data when you delete the application and if you don't need those you can actually just go and delete them and also if you're done with cluster you don't have to go and delete all those components like volumes and workers etc you go to your kubernetes delete the whole cluster pretty easily or maybe if you've corrupted cluster i don't know you tested around some stuff and kind of got messed up you can basically delete it and start from scratch so that's it for the demo i hope you also practiced along and you were able to create the same setup if you got stuck somewhere or if you have any questions please write them in the comment section below and i will try to answer as many questions as i can thank you for watching this video and see you in the next one
