in this course you will learn machine Learning Without libraries coding without libraries is the best way to learn the inner workings of a machine learning system and it will help you greatly improve your software development skills Dr redu teaches this course we already released his no black box phase one course this is phase two but you can still follow along even if you didn't see phase one in this course you will learn how to implement classification methods such as neural networks to recognize drawings you'll also learn about data cleaning confusion matrices geometry and the difference between vector and raster data if you want to learn how common machine learning algorithms work under the hood this is the course for you hi and welcome to phase two of the null Black Box machine learning course in JavaScript the goal here is to take the drawing recognizer we built in Phase One and improve its accuracy by implementing more advanced methods now if you didn't complete Phase 1 you may be okay starting directly with this especially if you already know some basic machine learning Concepts I will explain our code base briefly in the beginning so try to understand ask questions below or on Discord and if all else fails then go to phase one this time we'll learn about data cleaning it's a tedious process but I'll teach you how to build a tool to make the job easier then we'll learn to visualize a confusion Matrix a special kind of table that helps us understand our model even better than the chart we built last time it will be especially helpful when working with more than two dimensions speaking of which so far we've only been using two features but the K nearest neighbor algorithm is not limited to that all it needs is the way to calculate the distance between data points and I'll teach you how to do that in 3D 4D 5D any D really I'll show you an intuitive way to think about multidimensional spaces and distances and we'll use up to 400 dimensions in this course we also study another classifier the neural network we'll use the same code from my selfdriving car course because I want you to understand that machine learning methods are General techniques and algorithms we just apply to solve different kinds of problems now this is more complex than that selfdriving scenario and our optimization strategy there wasn't really good so I should teach you something better like back propagation but I don't know how I tried to come up with a lesson I just can't seem to add anything to those out there so I'll teach you how to train the network in Python and then take the resulting model and just use it in JavaScript so python will do the heavy lifting and our Javascript app just benefits from it am I cheating maybe a bit but I think that learning this is possible is a really important lesson here you'll see finally I'll demonstrate deep neural networks as well so I don't get many comments about it now I need to stress this course is supposed to be a learning experience I want you to understand how machine learning works and why we do the things we do we use the data you helped me collect so we have a real challenge not some textbook data set and we use JavaScript because it's a high level language where we don't need to worry about the small things and because we can use it to build nice user interfaces that we can share without the need to download install and so on I really hope you learned to build real things not just something that reads from files and writes into the console another reason I use JavaScript it's because it's not well known for machine learning but many people do know JavaScript and want to learn machine learning so if this is you you found the perfect course and if you don't like JavaScript take it as a challenge and implement the same things in something you like we don't use libraries so it's really doable I think sound good Okay then if you plan to follow along take the starting code from GitHub it's similar to the last one from phase one but a little bit different I've added your homework submissions and made few other optimizations as well also remember to get the data from this link place it next to the code like this and you're ready to start the first thing we'll check out is the drawing app we use to create new data here inside the web folder and create our HTML if you open this in the web browser you'll see it looks quite different from before but the functionality is still the same it's going to ask you to enter a name here and then to draw several things but the style is different because ninja coder did homework too and I adopted his style you can see these changes here in style CSS and everything I've marked as new style starting from beginning are things that he has added and I commented out previous Styles I've used in case you're curious how to do different styling I kept both here for reference now you'll also notice this compatibility section here at the top and that's because in homework 1 I asked you to test the app and let me know how it went there were some problems on iPhones making the screen scroll when you want to draw I got a suggestion from meso to set touch action To None Aaron commented that these should be set to none as well for it to work really not sure if these are enough because I don't have an iPhone to test but I also got feedback from mjake and Rick and they said that I should go here in the sketchpad component and add prevent default to the pointer events which by the way Kelvin said I use instead of the mouse events and touch events separately I really don't know if these comments help because when I test on mobile it works just fine but please let me know if it works for you I've added these changes on the version of the app on my website that I still use to collect data if you want to submit and also in the recognizer that will build by the end of this course now after you're done with the drawing and press next you're gonna get the option to save this and it's going to create this file that contains all the information about the drawings you just made it's a Json file that if I'm going to format like so contains the information about the student some unique identifier and then the different drawings the eight different drawings Each of which are made of a collection of paths containing points so this is the x y coordinate of the points and this here is One path that is used to draw the car and this is another path of the car and another path of the car so the car I drew had three different paths and then the face and so on a quick note here about downloading this Json file Marcus suggested I set here application Json otherwise there could be some problems and Godlike Mouse pointed out that I don't need to add this anchor here in the body and it still worked just fine now all the data I collected from you has the same structure as this one right here but it's inside of this data folder and there are a bunch of them 716 of you made drawings so that's a total of 5728 drawings and we can visualize these drawings using this other app that we built but if we open this viewer HTML in a browser we see that nothing is there and if we open the console there are some errors and that's because we need to run some scripts to get things started these are here inside of the node folder we open a terminal I took Diego's advice to use the terminal from here instead of command prompt change the directory to be inside of this note folder and let's make sure that we have node installed and we do if not you're gonna have to install it and then you can run npm install inside of this folder and it's going to automatically run all the scripts that we need it now generates a data set by running this script and what that means is that here inside of the data we don't have just that raw folder anymore it created a couple of new ones the data set folder contains two subfolders the Json folder contains one file per sample so now these paths here are for one drawing the same drawing that you can actually see here in the image folder if you open one.png there is a car here but because it's black and with the transparent background doesn't look very nice but it's okay because all our scripts have finished now so we can investigate this data in the viewer HTML after we refresh it you can see how ninja coder's style looks here as well I like this dark mode I think it's better on the eyes now what we see here on the left are many many people the 716 who have made drawings the drawings are here in one row and if you click on one you can see its features on the right highlighted on the chart now these features the width and the height that we extract are the features of the bounding box if I drag this item up here like so to see it better this is what the width means and this is what the height needs so this car has a much larger width than the height seems to be about double now if we scroll down here about halfway we're going to see a new section starting called testing and here the labels that you see written are what our machine learning system thinks that they are the blue highlights are the correct ones but the others are wrong and here if we are going to click on something for example this pencil we will see a different kind of highlight here on the chart let me zoom in a little bit and just to make things clear I'm going to click on this pencil few more times and notice that it's not originally there it's a new point that we've added now and it's categorized as a pencil because its nearest neighbors the majority of them are pencils here we use 50 nearest neighbors and I'm drawing a connection to all of them so based on the majority our machine Learning System the K nearest neighbor classifier categorizes this as a pencil but sometimes like this guitar for example seems to be a house let's figure out why it's quite hard to count but you can probably see quite many houses here in this area so it is a house our accuracy is not that good at the moment but I'm gonna teach you how to double it by the end of this course there's also this button here for opening the sketch pad and here you can draw something live and in real time you're going to get the classification if you zoom out you're gonna see this drawing that we made here and all of its nearest neighbors and in this case the majority are pencils but maybe if we're gonna turn this into a tree now this has changed and the new majority seem to be trees we've built some really nice tools didn't we one more thing I should remind you of is that we also have this decision boundary plot is colored background right here we can use this decision boundary plot more effectively if we go inside of the viewer here and pass the testing samples instead of the training samples to the Chart so now when we refresh well okay things look quite different the decision boundary is only on this side but that's because we have this one sample here from armenio which I suspect actually has a really really long width and it was some glitch in the drawing so for that reason it has about two width instead of a maximum of one these are normalized anyway now when we look at these testing samples here if they lie on the same color as the decision boundary plot indicates they are correctly classified but if they don't like this one right here then it means that it's a wrong classification so anything that looks colorful on a different background it's a bad classification like this is apparently a guitar let's review a bit how these scripts work in the node folder the data set generator is creating necessary directories if they don't exist yet and then it's generating this new form of the data set it's going through each of the samples one by one and it's writing them in a new file and also generating an image for each one this is the function from down here now feature extractor is going through the samples one by one and extracting features as specified by this feature functions in use you can find these feature functions in the common folder at the top right here and there are several functions defined here but in use we just have the width and the height functions that I mentioned previously these two are not used at the moment they could replace the width and the height here but these are just much better so we keep them for now now back to our feature extractor.js after we get these functions we call them here on the paths of every sample one by one and extract the data point we then split in training and testing half and half and normalize the data to be between 0 and 1. and then we just write the output files in training and testing respectively and there are three formats here training training JavaScript and training CSV and same for testing you can find these in the data data set and they are right here the Json files are here and the CSV files are here and the JavaScript files are up here in JS objects testing and training JS they are the same information written in a bit different way because I want these to be accessed by our scripts here but also by our web page and also by the Python scripts that we have here that's what the CSV is for and yeah I know python can read Json too but I've seen so many people use csvs in Python and I think it's a common practice and you should know about it too so if I'm going to open here testing Json and I'm going to format it here you will see first the feature names the width and the height and then all the samples here Car Fish House tree bicycle guitar pencil Rock and then another car Fish House tree and so on all of the 2864 samples are listed here and this long array and the point is just the width and the height values for each of these samples you're gonna find the same information here in testing CSV but here it's a different form but width and the height and then the label here it's something you could easily paste in Excel as well and the Javascript file here at the top is the same as testing Json but with this in front of it it's creating essentially a global variable called testing with this content here and I'm not particularly happy about this code structure it would have been much better to use modules here and make them read Json actually rumax suggested I do that and I recommend you try what he says there the problem for me is that if I use the live server extension for some reason everything starts lagging on my computer I'm not sure if it's just me or for some reason the code we're writing doesn't work in general with the live server extension but if you do try it out let me know how it went now going back to these node scripts the last one is run evaluation and it's going to use the k n classifier here built using the training samples and it's going to classify the testing data and compute an accuracy it also generates this decision boundary plot and stores it here in data models this is where that image comes from now this image is a low resolution here because when running this script this part is quite slow it's going to generate that color for each individual pixel and the size of this image is 100 by 100 pixels but that means 10 000 different pixels there to calculate and for each pixel you need to calculate the distances to all of the nearest neighbors and that's a really intensive process so if you want to set here a bigger value like 5000 this decision boundary plot it's going to look much nicer but you're going to have to wait a few hours but you're in luck because if you want to see how such a decision boundary plot looks like you can open up this resources folder and it's this one right here kmn 50. you can replace the one from here if you want to see it in action on the web page and refresh and now it's much sharper and you can also zoom in to see how the edges look like now before we get into implementing new things I have to mention this chart right here I've implemented a more optimized version of it if we close these things and open the chart from the web folder the optimization I've done is that from the chart homework nobody did it and I can understand why it's kind of challenging but I did point out what I did here and there and you can compare with the previous code if you're curious basically if doing something like maybe updating now this Point here the one that we are drawing I'm not redrawing everything all the time it just Updates this one drawing on an overlay canvas on top of the previous one I did get one optimization for the scaling which I've added here this was suggested by better and I also want to point out improvements I got to my prerequisite videos about 2D vectors and trigonometry from Christian and Georgia Christian rewrote the code in an objectoriented way and used bootstrap and Georgia tells us how to make it work if you scroll with the magic mouse on Apple devices also one funny thing that happened is that these emojis now are different than before because I got Windows 11 on my operating system and they changed a bit I recorded them a little bit differently here with the filters but they would have been just fine otherwise as well quick mention to this python folder here so if I'm going to start the terminal now and go to python folder and type python k n we're going to get the accuracy here as well but the code there is really small like this is it because we use the scikitlearn library and we import the K nearest neighbor classifier from there read the data from our CSV files directly and this is actually done here with a read feature file function from the functions py and the python is not really adding anything into this project it's just showing you another way of doing things with libraries which is common I think now let's begin to implement a way to do data cleaning and speaking of cleaning I reformatted all the code to use spaces now and we are going to be testing on the different window like this I got a lot of bad comments saying I should use spaces and now with this larger window here I have room for that now data cleaning means that we are going to throw out some samples which make our model bad for some reason for example here this is a drawing of a guitar but it looks like some kind of mistake and same for this pencil here we can also see maybe here this one this is not the drawing of the car it's a drawing of a of a bird I think so small things like that that are probably ruining the model in some way I'm going to want to throw away it's very tedious to start writing down which samples need to be removed so I'm going to build a tool that allows me to click on the samples here and remove them you'll see but now the clicking is implemented already here in display.js right here where we click on the sample container and we should inspect the event we get when clicking here to see if we can figure out how to maybe control click on the item and do something else instead of this handle click function so I'm going to type here EVT for event and now I'm going to open here a curly brace and close it like this because we're going to write more things let's begin with the log in the console logging this event saving the file and now refreshing the page and I'm going to open the console and click on something here and you can see now the event is printed here if we look at the properties we will find this control key that is set to false and if I hold now control when I click on something and scroll down here we will get another print of the event but this one has Ctrl key set to true so that's how we're gonna distinguish between the two let's remove this line and check if the control key is on we are going to toggle the flagged sample because I want to flag something when I click on it like that but I also want to unflag something in case I did a mistake I don't want to refresh the whole page if that happens so otherwise here we are going to set else and put this handle click in that case now this functionality for toggle flagged sample will be implemented in a new file I'm going to call this data cleaner so let's open our viewer here and import this new file data leaner and created here inside of this JavaScript folder data winner dot JS here our flagged samples are going to go inside the list which is empty for now and our function for toggle flag simple given a sample is going to do the following it's going to check if the flag samples includes the ID of the sample and if so we will remove it I first get the index of this sample that we clicked on and then I'm going to remove it by using the splice at the given index removing one item now if we clicked on something that isn't yet in the flagged samples we just add it there using the push method like so and now we want to visually emphasize which items are flagged and which not we're going to make a flagged class that is going to be added to all the flagged samples and every time we click on something we remove the class from everything and then add the class to those flagged samples kind of like a refresh mechanism so let's first remove this flagged class from all items that are flagged like this using a for each Loop so that each items lagged class gets removed and then readded like so we are going to Loop through the flagged samples get the element using get element by ID the sample with that ID and add this to the class list like so so this should work only thing we need is a new class called flagged and we're going to be adding that in styles.css and I'm going to be doing it here at the bottom of the file it's just going to be marking everything with a red color and I'm using here important because I want it to be on top of the previous style let's save this and now refresh and clicking things normally works as before but control clicking gives us this flagged View and if I click again on the item is going to go away so let's start flagging here the things I pointed out previously and I'm now going to go through all the things and mark down anything I see suspicious and I'm done it took much longer than I thought it will but it's over and um I basically marked down things that are incorrect or don't look at all like what they should be this should be a bicycle but somebody drew a house here so sometimes these things happen and Pi just drew mixing things up I think they wanted to see how the system handles those cases but most of the data is quite good and in total I think there is probably about maybe 200 or so flagged samples this is a funny one this is supposed to be a house but many people drew a horse there instead like gin and I think this has to do with psychology um basically house and horse are very close when you look at the letters and I asked you to draw a house after a fish so it's after another animal and without the context just being told to draw this then you might read Horse by mistake and Jin is not the only one there are actually quite many horses here in the database and that's funny because it reminded me of this uh Mandela effect if you don't know what it is I'm gonna link it in the description but basically there are things that people remember differently than what they happened and there are things that large groups of people remember something differently than what what actually happened and this could be one example of that like if we're gonna group together everybody who has drawn horses here and we asked them what were they supposed to draw they will definitely remember the horse being asked but I never asked anybody to to draw a horse I asked for a house anyway let's have a look at our flagged samples so I'm going to type this in the console here and there are oh actually close to 300 of them so 300 flagged samples that means we have 5445 to work with and one thing I really need to mention here is that I actually flagged samples also in the testing set and normally you don't do that because testing should be as natural as possible and we only want to do the flagging in the training data which we use to create our models but I did it because I don't think it's going to impact on the accuracy that much and I think that the people who have made those drawings that are messed up on purpose will not expect the system to mess up as well so normally that's not needed but also because I don't want to do this again anytime soon and if more data comes then a lot of them are going to be flagged already so yeah just keep in mind that normally you don't touch the testing samples now this array here is quite long and I would like to copy it somehow I'm just going to write here Json stringify the flagged samples and this is going to display all of it here as a string like so I'm going to copy it and go into common and utils and under the flagged users which are people that have drawn some bad stuff I'm going to add here flag samples and I'm going to paste here what we got and remove the string syntax from there and now we're going to use these flagged samples when creating the data set to Omit them from the raw data we'll still keep them in the Raw data for a reference but we won't be using them in any of our tasks so let's go here inside of our node folder and data set generator and right here a line in this for Loop that is going through all of the samples like so if the sample is not flagged so if the flagged samples doesn't include this ID that we are generating here then we do everything for it write it in the new file and generate the image for it here like so and now we can run this data set generator using node so I'm going to start the terminal go to the node directory and type here node data set generator you can put JS if you want but it will work like this as well and now those samples that are problematic should be omitted from our processing now after the script is done we also have to run feature extractor and this run evaluation if we want to use the viewer app because it's based on the features and the decision boundary plot is calculated using that so node feature extractor and node run evaluation we are done and you can see the accuracy is actually a little bit different 42.36 compared to what we had previously so now when we refresh this page we will see these changing maybe here also some of these will look different I don't know and of course some of these samples will not appear here let's see refresh so a different result here as expected and now the decision boundary plot is again pixelated if you want to have a better one then you have to wait and put there something like 5000 or use the one that I provide for you in the resources here there are two of them one that you used previously is this KNN 50 and the other one is kmn 50 after filtering and they look a little bit different but not by much so let's take this one and in the data models I'm going to paste it here and delete the small resolution one we just created and rename this one so that I remove everything except for decision boundary and refreshing now the page is going to show the other one that I gave you it's much sharper now now if we scroll down we see that some of these samples are missing sometimes entire users might be missing if I flagged all the samples and I actually flagged all the samples of the flagged users so those won't appear here anymore and everything looks fine but out of proportion I would like to keep everything the same size here so I'm going to fix that by going to Styles CSS at our sample container and I'm going to add here a Max width of eight percent I notice that this does the trick so let's refresh and now the things look better aligned one more thing is that when we go here at our halfway point where the testing starts you will notice profit here has his data split into some of it will be the training data and some of that is used for testing that's just fine it's where the midpoint happened to be now one more thing I want to do is say somehow that we have this new flagging functionality so I'm going to add the title here an info button and when we hover it it's going to say some instructions how to use that we do that in this viewer HTML file and here in the H1 tag let me just open it like this and type here span with the class called info button let's close this pan and I'm going to add here this info button symbol and then inside here I will have a tool tip inside this I will just write now let's save this and go inside our styles at the bottom one for the info button let's make it red and have the cursor be a pointer because we can click on it or hover it and then when hovering it's going to make the tooltip text visible so one more style now for this tool tip text and I'm gonna have this one have white text on a red background I think the combination goes well and let's position it so absolute positioning hidden by default and a small font size and let's have it around a bit and give it also padding and remove the bold of the font because that's how they are by default inside of this H1 tag so refreshing here's now our button here and when we hover it we get the instructions so far we've measured the goodness of our system using one number but if we want to improve our recognizer we need to understand what it does good and what not like can it recognize pencils better than houses for example a good tool for understanding this is the confusion Matrix a table that says how many items are misclassified as something else like here out of 343 trees 211 are correctly recognized but three are classified as cars one is a fish 45 is a house and so on now let's learn how to code this new visualizer and don't worry you won't be confused for long we will draw the confusion Matrix on top of this chart somehow and there will be a button here to toggle it on or off so we can still see the chart sometimes let's go to viewer HTML where we have our chart container and I'm going to open it up like this and add the container for the confusion Matrix here so this will be a simple div just like this one but it will be called confusion container let's give this a style and I will go in style CSS let's look for our chart container and put this one underneath because they're related and type confusion container the position will be absolute and I want it to be far right as possible so right 0 and let's give this a white background color and I want the Z index of one the chart has now there are some additional items and I want it to be on top of those let's save this and go back to viewer HTML and add a button to toggle this output as well so this we will refer to as the output what is on the right and now the toggle input function is in JS display JS at the very bottom here I'm going to copy it and make a similar one for toggle output and this one is going to use the confusion container instead of this input container so Fusion container here and we don't need anything else than doing this styling right here let's refresh and here's the button and when we press it nothing really happens but if we open the console here and inspects this element we can see that this confusion container is actually there it's just empty so it has 0 0 width and height if we would force it to have here maybe a width of 500 pixels and the height of 500 pixels then it's now going to cover the charts perfectly and toggling it seems to work let's implement this component next we will make this component very similar to the Chart component here it's just going to work something like confusion is a new confusion and here we pass the container the same way that we passed the container for the chart and then we also need to pass here the testing samples and we will also need as all the classes here so in order they are Car Fish House three bicycle guitar pencil look and I just realized that we don't have these defined anywhere really so let's cut this from here and add these to utils so utils classes and now here in common utils at the top we have these styles that contain them somehow but it's convenient to have them listed as well so utils classes is equal to what I just copied from there and back to viewer HTML I will also pass these options to the confusion Matrix component as well okay now we Define this confusion in another file so let's go up here next to the other chart elements I will also put it inside of the chart folder so let's put here confusion Js inside of the chart here I will create a new file confusion Js and here we begin to type this new class so class confusion and in the Constructor the first thing is the container followed by the samples we will be passing the testing samples here and the classes list and then these options let's store these as attributes so first samples then passes and I'm gonna take out the size and the style from the options that's really what we need here now the Matrix inside there will be an 8 x 8 Matrix but I will actually make it 9 times 9 because I wanted to include the header section on the top and another kind of header section on the left those would have cumulative values on the columns and rows respectively so a size for this Matrix let's say n is going to be equal to the length of the class is how many classes there are plus one and now imagine the space here divided as a grid of 10 by 10 cells we'll use the left Mouse and the topmost for the labels and then the Matrix will go in the remaining space so the cell size that we are looking for can be calculated here like so we need to add another more 1 to that n for it to be proper we'll display this confusion Matrix as a table so let's create a table element using the create element the passing table here and now I'm going to pass here a style we will collapse the borders borders make things very confusing to me at least and we just don't need them it's going to be quite nice looking without you'll see and everything will be also aligned to Center all the text elements and because I want to keep space for those labels on the left and on the top I'm going to also add here a margin left of the cell size like so and the same goes for margin top now we also need to append this table to the container and now this table is going to be the holder of the Matrix we need to prepare the Matrix and fill the table so these are going to be two private methods let's get the Matrix ready from the samples and then fill the table like so the Matrix will be an attribute here so we'll have access to it this free per Matrix function is going to start off with an empty Matrix so let's define it as an empty list like this but we will have to generate its rows as well and different rows each of them is going to be an empty list and each row will be filled with n zeros for now so I'm going to generate this Matrix filled with zeros like so and now we can start putting here the values coming from the samples so let's look through the samples I'm going to name each sample s because it's shorter and the next line is going to be quite long so the Matrix of and now I want to get the index of the true value of that sample so the index relative to this classes up here I'm going to type Oasis index of the true value of the sample because those are going to be vertically and because the leftmost column will do something special and have some cumulative values I want to go past that so I add here one and the second index is going to be the same but with s dot label which is the label we predicted using our machine Learning System and also the top header means shifting here by one as well we take that value of the Matrix at these indices and we increase it and that's it now we just have to return here this Matrix like so and it will be passed to this attribute now the fill table method here is going to add the rows and cells into that table so let's define it like so and because I don't want to type this all the time I'm going to use this destructuring assignment here and I will take out some of the attributes from this and now I can just use them by typing them as such we will look from 0 to n like this and generate a new row in The Matrix this role we generate with the create element and we use the TR element for table row and let's append this to the table and now we can loop again so now we are going to go through each individual cells and create those these cells are going to be create elements a TD element is for creating the cells and let's style this cell so that it has cell size pixels in width and I'm going to copy this or the height as well and let's remove the padding also and now I'm going to add the text of this cell to be the value of the Matrix at inj simple as that we just have to add the cell to the row now and we can save refresh and this looks as expected these zero values will have to take care of but I also want to take care of this top text here and the left text here let's begin with that so at the top after we create this table I'm going to add to the container two more things so let's generate a div for this top text like so and this is going to be saying predicted class and we'll style it to have an absolute positioning and give it a really large font extra large and let's set the Top Value to 0 pixels and I'm going to position it 50 from the left but that's going to position its top left corner 50 from the left so I'm also going to transform translated by minus 50 horizontally and let's append this to the container now if I'm going to refresh it's almost good I would like it to be lower like this if possible so I'm gonna give this a height equal to the cell size and then I'm gonna use flex positioning here to align the center so let's go here and give the height of cell size in pixels and set the display to flex and the Align items Center okay much better but um I would like this to be in the middle of this right here so this should be the middle point and that means I need to add the margin of half the cell size to the left so let's go here and say so that great now we need to do the same for the left text so let me just copy everything here and I'm gonna rename this left text and the differences are this is going to be the label for True class and I want this text to be rotated by minus 90 degrees and here left and top should be switched so let's move this stop here and this left value here now we refresh looks good let's calculate these cumulative values here by adding everything in this way and everything in that way I'm going to go after we prepared The Matrix here at the end of this prepare Matrix and now we have those values the ones that we see here in this bottom right corner and I'm going to use them to add to the zero values on the left here and at the top so we do that with a for Loop so going through all the elements but skipping the zeroth row and another for Loop going through all the elements of each row but skipping the First Column so starting at one instead of 0. and here we set the Matrix 0 and J to be increased by matrix of I and J and the same for the First Column also let's refresh and these seem to be just right this looks like a very small value here and these all here seem to be small values none of them is over 100 so I think this calculation is correct now these numbers here is what I would expect to get these values should match these values here if we would do a perfect prediction and if a value is bigger like for example this 466 here is much bigger than this 343 or five three seven here it's much bigger than three three nine then we are generating too many of these items if it's too small then we are generating too few of these items so I would actually like to see these at the top as a kind of a relative difference to this let's do that also with the for Loop going through all of the items at the top I'm going to modify them now that they exist by subtracting the value at I and zero basically the value on the left there refresh and now you read these as here we have too many there is an excess and here we have too few there should be more of this item I think that I would like to see a plus sign there for those particular cases and um and also this is zero here is useless and should be removed so let's do that I'm going to set here Matrix 0 0 to nothing and here if the value is greater than zero add the Plus in front of it I'm styling these just the way I like if you want to do it differently then feel free but I'm quite happy with what the end result is going to be you'll see okay good but we don't really know what these objects are supposed to be we can probably remember the Car Fish House tree bicycle guitar pencil clock but better if we show their the icons and they are part of the styles so I'm going to go here and style these cells even more but only if it's the top row and skipping the first item there in that corner so if I is 0 and J is greater than 0 Let's give this cell a background image and I will set this to a URL coming from this place so the styles are going to contain for each class the image and I will take the source of that image and pass it to this URL now here we need to do a j minus 1 because our JS increase by one because of that First Column header and let's close this here like so now I'm going to save this file refresh and we should see on the top row I'll add the items are but these background images repeat now unnecessarily so let's go here and say background repeats set it to no repeat and now let's align these the center and I also want to give them a little bit spacing from the top there so let's type here background position 50 from the left and let's say 20 from it okay and let's move now the text lower so I'm gonna align it vertically to bottom and let's make it bold as well to be emphasized as a header okay good and I want to apply the same style also here on this side so let's just copy this below and replace here I with J and J with I and here J with I as well now this is good but these values here the plus and minus I would like to emphasize them using colors as well it's hard when looking at so many numbers otherwise so let's have these positive values red and the negative values blue kind of like uh temperature scale I'm going to go up here the color intensity is really going to depend on those values from the left so we could take out this as a proportion Matrix of i j divided by matrix of JY like so and let's set the value for red if B is greater than 0 then I'm just going to take e and multiply it by 255 that's the maximum of the red that you can get and here zero red otherwise and blue is going to be the same but looking in the negative and I can't give it a blue intensity that is a negative I have to put here minus B times 255 or 0. and with these I'm going to set the style color of the cell using this RGB a like so actually I don't think we need this a at the end so just RGB I was thinking to use the alpha as well but I think that this is going to look just fine let's a refresh and you can see some kind of color here but to get here maximum red or here my maximum blue these differences would need to be really really big um they are not like this should be double 339 so 600 something and even at our current situation with this low accuracy it doesn't appear so strong so I'm going to go here and multiply this P value by two and that's going to make it more striking when there is a considerable high value here and this looks good I think now the next step is going to be to give these cells in the middle a background color also depending on their value and I'm going to use linear interpolation here and give them some values in between the minimum value that we see here and the maximum value that we see here you can also use 0 and the maximum value it it's up to you really but let's first take out all of these values from our Matrix and find out those extremes I'm going to go here at the top of fill table and write the values that we are interested in we take them from the Matrix I'm going to slice The Matrix from one so that we skip the first row entirely and then we are going to take just the items inside by slicing from one so that we skip also the first element on the left and I'm going to flatten these so that all of the values are in one long array and from these I can easily calculate now the minimum using the math minimum function I just have to spread this values array like so and let's do the same here for Max using the max function so now we know the range where we want to do this polar scale in between and we can calculate the value in between this range using the inverse lerp function the inverse linear interpolation function that we defined some time ago I do have a video on that interpolation concept if you want to learn more but basically here if we are inside of the Matrix so that we are not in header section so if these are positive I'm going to get this pvalue using this inverse slurp between minimum and maximum from The Matrix of I and J value that we are currently displaying and I'm going to set the background of the cell here using rgba so 255 for red and let's put 0 and 0 4 green and blue and the alpha is going to be this pvalue which is going to be between 0 and 1 depending on how far it is from mean between Min and Max so this inverse slurp function is a really simple function here given an interval A and B and the value inside the interval it first subtracts from the value a and then divides by this difference so you get a result between 0 and 1 depending on this difference back here let's save the file and refresh the page and this is how it looks like it's really easy to tell what we are seeing here like many houses are classified as as clocks which is a bad thing but um here many trees are classified as trees this is a good thing so one thing that I would still like to emphasize is that anything on this diagonal is a good thing because it means that the item is classified as itself and let's change the color for that as the final update here so well let's say if I is equal to J so if we are under diagonal I'm going to have this let's copy it and here let's close this curly brace else I paste this again inside close the curly brace and for the diagonal let's replace here this red green blue with 255 and set this one to zero so this is going to be blue and again the transparency is controlled by the same thing let's save this and refresh and we're done with the confusion Matrix and some things here are kind of obvious like um the house could be classified as a clock I can accept that because we are now just looking at this bounding box there and the aspect ratio so it doesn't really matter what's inside but some things here are really strange like why so many pencils are classified as clocks this makes no sense I mean pencils and clocks look nothing similar even if you look at the bounding box let's close this output and try to figure out what happens here and if we go here this is really a mess I don't see anything useful here with so many things displayed there what we can do is tell the charts to display fewer items maybe just the pencils that are labeled as clocks so these are very easy things to do we just go to the viewer here where we have our testing samples that we pass to the chart and we can filter them so let's filter these testing samples so that each sample has is going to be kept if it is a pencil but it's labeled as a clock now I'm teaching you this not just for the demonstration now but also that you can inspect your data like this quite efficiently and if I refresh here and close this output all we see now is the pencils and these are pencils that are within this gray region in our decision boundary plot so they are labeled as clocks but now we can click on them ah okay they are probably all drawn at an angle like this so that means that the aspect ratio is pretty much it's comparable to a clock most likely all of these pencils here are drawn at this kind of 45 degree angle I actually thought that pencils are very easy to classify because they were so clearly visible inside of this magenta region let's actually see here like if I remove here this filter and refresh toggle this output it's like nothing else is there blocking them but what I understand now because of this confusion Matrix is that there are actually a lot of pencils there in the middle we just don't see them because this visualization is so crowded we could see them if I add my filter back here and remove this part It's Gonna Keep just those things that should be pencils and let's see where they appear now pretty much everywhere and since we are not drawing everything including herminia's house which is somewhere there it means that our decision boundary plot is scaled in a nicer way these pencils here seem to have a square aspect ratio inside of this feature space so far we've only been using two features the width and height of the bounding boxes but we saw that they're not good enough a pencil like this can be confused with the clock for example today we'll introduce a new feature which will measure how elongated the shape is this will help to separate pencils from other items in a third dimension now Elia solved this problem on Discord it was part of homework assignments 3 and 4. so we're going to use his code and let me briefly explain how it works he first computes something called the convex Hall the smallest convex polygon that encloses the drawing he did it using the gram scan algorithm it's not the only algorithm that can calculated but Ilya used it and I think it's a good choice it goes like this first it only considers the points not the paths it finds the lowest point and from there it calculates the angles to all other points and sorts them then in order new points are added to the stack again and again but if the points are found to be in a clockwise order the middle one is removed from the stack repeating this until the end gives us the convex Hall now Elia used the edges of the convex hole one by one to construct oriented bounding boxes around the shape and chooses the one with the minimum area that's how he solved the problem scared don't be Elia did the hard part and we're just going to use the end result I also think that if you study his code it won't take long before you understand it we're gonna implement the new feature using ilia's help who solved homework assignments 3 and 4 pretty much I'm gonna give you this link in the description let's copy this code and I'm also gonna write it in a file called geometry.js let's go and put it inside of common here create a new file geometry Js and I'm going to paste his code here format it slightly and at the top let's write where this code belongs to originally and I'm gonna paste this link right here as well and here we find all the functions needed by the algorithm this Returns the lowest point and it keeps in mind that the yaxis goes downward then here the points are sorted relative to their angle and here is the actual implementation of the Graham scan algorithm the points are added to this stack right here and then the stack is returned there's also this helper function here that calculates the width and height of a box aligned to the hole in some way these are all Vector operations and they should be clear if you've watched my prerequisite video but basically it finds out what is the left top right and bottom and then calculates the width and height using that Elia also returns these vertices here which were returned back in the original space they're not really needed I think but it helps debugging and you'll see will make use of them now this one is basically going to iterate through all the possible orientations and find the box that has the minimum area and then everything is returned here like so two other helper functions here one for getting the angle and one for calculating the distance the squared distance actually because Ilia only needs here the relative distances and there's no point in taking the square root anymore it's a kind of an optimization now that's the code pretty much and it looks good but how can we be sure it's good the only way really is to test it we could write unit tests for it but I prefer to debug visually so let's go to our data set generator file here and now where we generate the image file here I'm going to run elia's code take out the vertices from the minimum pounding box and here we need to pass an object containing points so I'm going to flatten the paths and just take the points from there and make sure that you pass here this it's required and then with these vertices I'm going to draw them with the red color on the canvas now let's save this and open a terminal go to the node directory and here let's run the data set generator like so and while it's doing it we can check the progress here and we can see now this rotated pounding box but it's missing one of the lines there let me just stop this and fix it by passing the first vertex one more time at the end so what I will do is I will create here a new array containing all the elements of vertices and then one more time vertices of zero the first vertex vertex is just a funny word for a point now if we run this again and check what happens in the images it's closed as we expect but I would like to see also the whole and just to make sure that whatever happens here is correct so let me close this one more time and in the geometry I'm going to go here where the hole is also calculated and I'm going to add it here let's save this file and back in data set generator I'm going to also destructure here the wall that we are passing now and I'm going to copy this one more time with hole here and maybe let's put this color to Blue let's try one more time now we can really debug what happens here and make sure that the bounding boxes and the convex holes are what we expect really while this is processing let's go and Implement our new feature using Elias code so in feature functions I'm going to import here at the top geometry if it's undefined I'm doing this check because we're going to need to also use this file on the web and geometry might be there already and now the feature name is going to be elongation and what we do to calculate this elongation is take out the points by flattening the paths and then we just get the width and height from Helios function here as before and we return here the maximum between the width and height divided by the minimum of the width and height and now in practice it could be possible that the width or height is zero from the drawings like if somebody draws a perfectly horizontal line then the vertical coordinate is the same for all the points and then height is going to be zero and then this is going to be zero so typically what you can do in this case is wrap these like so and add the plus one to each of them because it kind of makes sense if you think about pixels that it does have some kind of height even if it's zero from this Vector point of view and it's just one way that we avoid this problem I'm not really sure if it happens here but I was thinking about this division by zero so anyway this new function now we can add right here elongation and get the elongation and for it to work we need to adapt our distance function in utils right here to use the third dimension as well so we could do that for example like this by just including here the difference on this third dimension denoted by this 2 here so 0 1 2 means one two three but it's nicer to write this in a more General way so we don't have to do this again and again every time we add a new dimension so let's remove this and initialize the variable called squared distance with zero and loop through all of the dimensions of the first point one by one and add to this squared distance the difference on that Dimension squared and here we just return the square root of that squared distance and now we don't have to bother with this function anymore so let's try to extract these new features now I'm going to go here and type node feature extractor Js and now let's run our evaluation and look at that we went above the 50 mark quite a significant Improvement here let's see the results on the web as well so I'm going to go here and make a few changes in viewer HTML we need to import also geometry now and I'm going to do it here under utils I think it's a good place and let's save the file and refresh the page and something is not right because this input shouldn't be there and if I open the cons so I see there are some errors in Geometry there and I'm quite sure they are because this input is empty and it's giving a list of zero points basically and let's have a quick look here insides of geometry.js there are sometimes used points from the first index second third index at least so we would need to have at least three points for this code to work properly and we can do that in multiple ways maybe we could go here and viewer HTML at the bottom and only update what's on the sketch pad only process that for example his there are paths and if they have more than three points so here I'm writing the opposite and I'm saying return if it's not like that so this would work here there's no more error but the problem is if we do draw something here and then maybe revert everything it doesn't process anymore this empty page so I would actually like to return 0 with and zero height if not enough points so I don't keep this update here instead I cut it and I go in Geometry Js in the function that calculates here the minimum bounding box and I say paste but only focusing on the points and if they are too few I will return now a width of zero height of zero and let's return the vertices on the whole and I'm just going to return all the points so points points like so now this should work again without an error here right and if I draw something on the input and I undo it also changes so nothing is a car in this model's mind now this is much better accuracy and also if we look at the column here and the row here the pencils are doing really really good now so we got what we wanted and let's toggle this output to see the chart as well and this is quite confusing now because we are having three dimensions so we should plot that elongation also on the third dimension but it's Overkill I think and soon we're gonna have even more Dimensions than that and what do we do then also this decision boundary plot it's not proper at the moment uh it should be a decision boundary Cube not a rectangle like this one but we could start slicing this Cube somehow if we really want let me first actually remove these samples from here because they are confusing for what I want to show you next and I do that here in the chart options by typing hide samples set to true and then for that decision boundary plot in run evaluation here I'm going to go at the bottom and here it's doing the prediction with just two Dimensions so we basically get the same as only with the width and height here because the distance function is implemented based on how many dimensions this point has so to have a threedimensional plot we need to add another value here and it would actually require another for Loop and passing here another dimension but this will just be a set of images on top of each other so we have to slice this Cube somehow and now I'm slicing it at the minimum elongation and I could slice it in other parts as well if I want but let's just see what we get here and I'm going to run this evaluation again and refresh toggle the output and you can see the pencils are actually gone but that can't be true because pencils are being classified correctly and they are even classified the best according to our confusion Matrix here what happens is that the slice that we are doing in this cube with the minimum elongation doesn't contain them we would have to slice further away maybe with the maximum elongation since they are the most elongated shapes there so let's try that put here one instead regenerate the decision boundary plot refresh the page toggle the output and everything seems to be pencils so if it's the maximum elongation our model thinks that everything should be a pencil here but there must be a place where it kind of contains pencils and something else so let's try cutting this Cube maybe in the middle regenerate the decision boundary plot refresh the page toggle the output and seems like even here everything is a pencil okay let's go even smaller maybe 0.2 refresh the page toggle the output and now we see something like that basically the pencils are creeping out somehow and being replaced with something else as we Traverse this this cube in the zaxis but let's inspect the samples a bit too I'm going to go to viewer HTML and remove this height samples let's comment it for now and here let's still focus on the pencils but only those pencils that are incorrectly predicted let's refresh toggle the output and here are the incorrectly predicted pencils but this decision boundary plot now is kind of useless because we don't really understand it anymore with the third dimension there like these are all wrongly classified pencils but some of them appear to be over this magenta patch here because they might be in somewhere close to low elongation so if I would click something here you can see this pencil is very fat so to speak so it's in that Zone where there was no magenta at all maybe and that's why it's categorized as a house and not a pencil this seems to be a guitar it's also a little bit thicker and all of these bounding boxes and convex Halls look great I think really good job Ilia what happens here this looks interesting this looks like a problem but what I think is here is that there is actually a small point there that somebody drew and in our system if somebody makes a point it's not going to be drawn because there is no thickness basically but it might be there let's inspect a little bit so it's this five zero seven eight image I'm going to go in our data data set Json this time and five zero seven eight is here let me format this and I actually see here the first path even it's exactly the same point repeated twice so I guess this can happen too basically there's one path there that is small and it's not rendered by our software but the calculations pick it up so it's not really a problem with ilia's implementation maybe it's a problem with mine with my visualization but I don't want to bother with with things like this so let's forget it's an issue let's focus on clocks next most clocks are round so the next feature we'll Implement is a kind of roundness measurement I've already done something like this in my AR portal drawing game tutorial here on YouTube so you may know it already but this time we combine it with the convex hole from before to measure the roundness we first calculate the length and the area of this shape and compare it to the area of a circle with the same length if you want to learn why the circle has the largest area I have a video on that it's quite intuitive though so I don't think you really have to watch it now get ready for another round to calculate the roundness I'm going to add some functions here inside of the geometry file let's begin with the function called length of a given polygon now this polygon is just going to be our paths but I write it here as such because I think it gives the idea that the function will consider the first point also at the end to Loop and let's implement it unlike so initialize the length with zero and then Loop through the points like so and get a value for the next index so next index is going to be I plus 1 but when we are going to have I is equal to polygon length minus 1 at the end adding 1 to that will give us an index that is not good and we should Loop that around to be zero again so I'm going to use the module operator like this and add to the length the distance between the polygon of I and the polygon of next I like so let's return now this length and because we're using utils here I need to add it here at the top to include it if it's not existing and then include it like that and we are adapting now this file from Ilia here so let me just write a quick comment here adapt it from the original author now the next thing we'll need here is to calculate the area of a polygon and we'll do that by breaking it into triangles according to some fixed point and calculating the area of each triangle and adding them together so let's say our fixed point is going to be a and that will be polygon of zero and now we Lu from I is equal to 1 and less than polygon length minus 1 this time because we're also going to use this next index here but we don't want to Loop anymore and here let's define B as the polygon of I and C as the polygon of I Plus 1. so a is going to be fixed but b c is going to change from those next to I and then B is going to be the previous C and we get the new C and so on until we add up all the triangle areas and for the triangle area I'm going to write the separate function here called triangle area between these three points and let's return the area here to get the area of a triangle we're going to first calculate its side length and then use Heron's formula it's one of my favorite formulas I learned in school now I won't prove it here but you can take it as a homework and prove it yourself maybe using the Pythagorean theorem anyway this way of measuring the area of a polygon is not the only way in fact in the portal drawing game I mentioned earlier I use the shoelace formula and that one works with concave polygons as well check it out if interested so the formula works by calculating the lengths of the triangles so typically we refer to as the side length of a of B and C and we do the same thing here for B and that will be A and C and we get here C and that will be A and B so these are the side lengths that we just calculate as the distance between those and then we Define p as the semi parameter or half parameter the half length of the triangle so this is going to be a plus b plus C divided by two and this is Heron's formula so the area will be the square root of the half parameter times P minus a times P minus B times P minus C we just need to return it here and now we can use these two functions the area of the polygon and the length of the polygon to implement our roundness function the roundness function is going to take the polygon as a parameter and first thing we do is get its length hand area using the but functions we built previously and now let's calculate the radius of the maximum Circle that could be built using this length so that would be the length divided by 2 pi like this and the area of such a circle would be pi times the radius squared so the roundness is going to be the area divided by this circle area and here we could return the roundness but in case this circle area ends up being 0 then this roundness is going to be not a number so to be safe we are going to check here if it's not a number let's just return 0 in that case otherwise we return this roundness value and that's it now let's debug if what we implemented works and I'm going to go here in data set generator where we were previously drawing these vertices and the whole to debug Elias code and let's include now our roundness calculation here so we can do that like this roundness is equal to calling geometry dot roundness on the whole this time because that's what we want to measure the roundness of and now I won't need these vertices anymore I will just focus on the hole here but I will give it a different color the color will range between blue and red if it's blue it means a low roughness and if it's red it means a high roundness so let me go here and say R for red is going to be the floor of this roundness multiplied by 255 because that's the range of the colors then green is going to be zero we won't care about that and for blue I'm just going to copy this and invert it here so 1 minus this roundness multiplied by that and this is B here with this we create a new color and I'm using here these template literals and replacing the color here when drawing the hole now let's save this and open the terminal in the regenerate the data and let's check it out as it's doing it here in the data data sets image this looks reddish okay okay much red here in this house pencil is quite blue here and the clock is red as expected let's go here and make this line thicker I'm going to add here 10 pixels in width and I will modify this draw path function from here to accept also the width let's set it by default to three and replace the three that was hard coded here previously and let's write the function for extracting this roundness feature as well I'm going to go in feature functions and type it here it will be get aroundness of the paths and let me copy here this code from the elongation because we're going to call ilia's minimum bounding box function and instead of width and height we are going to extract the whole now and then return here the roundness of that hole like so let's add this also to our feature list here and roundness get around this and regenerate the data extract the features and run our evaluation and look at that we're getting above 60 now but this decision boundary won't be proper there because it's not yet slicing the hyper Cube fourdimensional Cube now just yet we'll get to that but first let's just refresh the page and our colors here are not proper because they are inverted by Ninja coders new style here let me just go back here in data set generator and invert these as well so 255 minus that 255 minus that 255. minus that and rerun everything and the features and run the evaluation forgot that hypercube again but we'll get to that Okay so refresh and now it's how I want it red for these and you can see a lot of clocks are red but there is a lot of red everywhere because things tend to have a high roundness value if you look at the convex hole here in general if you would like to differentiate better between really round things like these circles here that are making the clocks you could use a nonlinear function here for the roundness like maybe Square this value or even a higher power will make the difference even more significant maybe like fifth power here you'll notice that generating these decision boundary plots is becoming slower and slower because the classification is becoming slower and slower because we're adding more and more Dimensions so that distance function has to do more work for all of the neighbors repeated many many times let's refresh and now these differences are more striking the circles here do appear more reddish than anything else but our decision boundary plot still looks the same as before here and that's because in our run evaluation here we are still sending three dimensions to it when we now have four and we could in principle add one more Point here but to make this function General enough so that we don't have to do this every time we can just remove this and use a while loop until the length of this point is going to be the number of Dimensions let's just add the value here so maybe point push and I'm just going to slice at the lowest value in the elongation and roundness dimensions and get something but this is not really going to be something useful when we have so many dimensions so this decision boundary plot is only useful for two Dimensions really let's see what we get we just have to run the evaluation now so that we get a different decision boundary plot and refresh the page toggle the outputs and that's how it looks like apparently not interesting really let's go back to the confusion Matrix here and notice how white this section is becoming here and how good our system became at recognizing pencils and clocks which is what we were trying to do looking at elongated shapes and looking at Round shapes started working now what doesn't work is the car being confused with Fish And The Fish being confused with the car we have this small square here and actually cars are also confused with bicycles and fish the same because these tend to have the same aspect ratio and their convex holes tend to look similar as well the guitar as well actually gets confused with the car and the fish for similar reasons I think we just didn't try to extract features that would help distinguish these and we could like cars are much more blocky I think and fish are much more organic in shape maybe looking at this kind of a curviness how curvy the lines are it may help to recognize the fish and distinguish them from Cars also from bicycles the bicycles well they do have circles here so maybe using the roundness measure in some other way could help to recognize those maybe looking for corners when I look at houses they typically have some triangles there Corners many corners there is a problem when considering triangles and let me show you let's close this and start our input here if I'm going to draw a house I could draw it for example like this and now start making a rectangle here and a triangle here like so and these could be recognized relatively easy if you look at the data that we collected because there are three independent shapes so you could maybe recognize that one is a triangle one is a rectangle and there is a flat line here but what if you draw the house like this now the second shape will be just this kind of upside down U shape and then the roof I'm not going to draw a full triangle I'm just going to draw this upside down V shape to me both of them look pretty much the same but the data that we store is significantly different this has just two sides this has three this has three sides this has four and you can draw these in different ways but the problem is if we would like to extract things like triangles or rectangles or these kind of shapes looking at the vector data is not as easy as looking at the pixel date so we're gonna study how to access pixels next so far we've been working with the data in raw Vector form the coordinates of the points and the paths they create but that's not what we humans see when we look at the drawings we see the pixels and some features can be calculated more meaningful if using those like these drawings look the same but their Vector representation is very different and it would be quite strange if they would not be classified as the same thing wouldn't it if you've never worked with images you can watch this video where green Rado explains how to make an image recognizer that works with the camera I think it's a good watch especially now that you have a good understanding of machine learning already now I won't teach you any sophisticated image processing techniques but I want to set you up just in case you want to experiment more there are a bunch of things that can be tried out with this new approach selfstudy them ask me questions in the comments or on Discord and we'll try to figure things out let me show you how we can access the pixels from the canvas I'm going to do this in the console here and type sketchpad CTX getting the context of this sketch pad that we're drawing on and get image data from 0 0 which is the top left corner using the sketchpad canvas width and the sketch pad canvas height so I want to get all of this information and we press enter we get this which is containing some information about color space the width and height 400 by 400 and this really really long data array here now this data array is going to be filled with the zeros pretty much because that's what is drawn on the canvas now everything is actually transparent black this stands for red green blue Alpha of the first pixel in the top left corner on the canvas and this is the pixel on the right of that so red green blue Alpha red green blue Alpha and so on if I'm gonna draw a line here on the canvas and run the same code here again you can see zeros here but at some point we start getting some values and these are the values from this line that I drew here and they only appear as Alpha values because the lines are black actually they are here inverted because of the styling but basically anything with an alpha is a pixel that is lighting up so that's what we want to extract from here really we don't care about colors we just want to know which pixels are visible and which not so if I'm gonna bring this code back here again we can filter this to take just the fourth item in the array every fourth item in the array using filter on the data and taking the value and the index so here we're gonna filter using this index if modulo 4 is equal to 3. and this gives us that just the alpha values and they are 160 000 so this is 400 times 400 a matrix written in linear form pretty much so let me close this console and write the code to extract these pixels in our feature functions I'm going to go in common feature functions and here below the roundness feature I'm going to implement a function to get these pixels it won't be a single number as an output it will be all the pixels it's not a feature yet but eventually we'll use it as a feature as well you'll see and I'm gonna write it here in the feature functions for now so let's right here get pixels and given the paths Now by default we used this 400 by 400 pixel canvas all the time I'm gonna set the size here equal to 400 but we can set the parameter here to get the pixels from a smaller canvas if necessary let's first Define our canvas and I'm using let here and setting it to null because now I'm going to do a trick I'm going to try to initialize the canvas for the web by asking the document to create the canvas element like this and then setting its width the size and its height to the size like so but if this fails it probably means that we are doing this in a node and I'm going to catch an error I'm not going to worry too much about what the error is because in our environment this can only be the reason why it doesn't work that we're trying it on node so this code here is for node and here we have to require the create canvas function from node node modules canvas where the canvas was installed and then our canvas can be initialized with create canvas size and size like this now the code should work both on web and inside of node and we can now get a reference to the canvas context like so and draw these given paths here on this new canvas we then get the image data from the whole canvas and take out just the alpha values that we're interested in so I'm just going to return directly image data dot data dot filter value index and then index module for when it's equal to three so every fourth element will be returned now we're drawing here and we haven't included that file here yet so I'm just going to do that real quick troll draw like so and now let's test our code in the data set generator again I'm going to go here in node data set generator and we need to include the feature functions here so feature functions and feature functions and let's go down where we are generating the image and we don't need this fancy stuff anymore because this new visualization will be just me writing some text on the images how many pixels are visible so let's first access these pixels using our newly created function and let's store the number of pixels in a variable which we're gonna call complexity because I'm eventually going to make a feature from this and complexity just means the more pixels the more complex it is so let's say complexity is and we count now how many values are nonzero these are just the alpha values remember that so if they are visible they will be counted and then let's just draw some text this complexity value and let's use blue color now this draw text doesn't exist so let's save this file and go here to draw JS we can draw paths but we can't draw text just yet so we need to implement a function for this given the context and the text and the color we set it to Blue but let's give this one a default color as well and now the location by default will be 0 0 where we want the text to be in the top left corner and let's set a relatively large size because we are just printing there those small thumbnails in the viewer the text should be quite big now this function is going to first set the font and I want it bold let's concatenate here the size and I will use Courier font because I want the text to be in the screen I want the bass line to be on the top because if zero zero chord then it is used otherwise the text would just be over that then we wouldn't see it and I'm gonna put here text Baseline stop and let's set the fill style to the color and fill the text at this location I'm just spreading the array into the two X and Y components and that's it let's save this and open the terminal make sure we are in the node folder and let's generate our data set once again and while it's doing that we can quickly check what happens here in data data set image and this is a number that probably works meaning it's the number of visible pixels here maybe it's okay we'll see later when we can visualize them in the app but while it's doing this I'm actually going to implement the complexity function that I mentioned so let's go to our feature functions here below the new function we just created and the complexity function is going to be just get complexity from the paths and it's going to return this one number so first thing that happens is we extract these pixels and now we're going to count how many of them are visible like so and we can add this new feature here and get complexity like so now we're dealing with this five dimensional feature vector and I don't really know how good this feature is going to be I don't really have High Hopes I just want to teach you how to work with pixels and then it's up to you you can look online find some help how to do image processing if you're curious but I won't get into that now this is done let's also extract the features and this is probably going to take some time now because doing this pixel manipulation is time consuming each image is 400 times 400 so a lot of calculations let's add here also this kind of progress indicator so I'm going to go to feature extractor and this for Loop here where we are looping through the samples let's rewrite it using a classical for Loop looping through all the samples like that and let's here initialize the sample list samples of I and at the bottom here let's print the progress using our utility function high and samples length minus one for a hundred percent now next time we run this code we will know how long it takes at the moment I have no idea so I just have to be patient band it's done let's now run the evaluation there is some improvement it jumped to 66.13 here and now this decision boundary plot is going to use all of the features because we implemented in a general way last time but I don't really care about this decision boundary plot anymore it's not very usable as it is when more than two dimensions so we're done let's refresh the page and this is what we get we see now the numbers here and I think they're proper this is a very small value here 1000 something when most of them of several thousand and you can see just a few pixels showing up for this small pencil I think that this is correct but thinking about it it's kind of unfair to say that this is less complex than this because they kinda look the same if we talk about the feature meaning complexity maybe we should scale these items so they fill the whole canvas and then count how many pixels are lighting up let's try to do that I'm gonna teach you a little bit of image processing anyway so let's just scale these and stretch them to fill the whole canvas and see if this feature improves or not but I won't insist more than that in feature functions where we extract our pixels here I'm going to pass another parameter to the function saying if we want to expand or not so that the drawn image fills the entire canvas and if it's set to True which will be the case by default then we go here before drawing the paths and rescale these paths somehow we check if we need to expand and if we do I'm going to take the bounds first the minimum maximum on the X and Y so let's take out the points by flattening the paths and these bounds will be an object with left equal to the minimum points only looking at this x chord and it's the first chord in it here so I'm going to copy this like so for the right with the maximum here and let's copy both of these for the top and the Bottom now these will be one here because we're using the second dimension we are now going to remap these points and generate some new paths with remapped points so let's write here New Paths and this is going to be an empty array and we're going to Loop through the paths pass by path and now we're gonna generate new points from the path's current points so these will be in this variable and we'll use the map function where we remap each point p to be a new twodimensional array the first will be remapping using inverse slurp between left and right using p of 0 and this is going to give us a value between 0 and 1 depending how far from left to right we are so we have to scale this also by the size of our canvas now I'm going to copy this again here and this will be between top and bottom using the First Dimension here now we need to push these new points into our new paths every time we create them and finally we can draw here the New Paths on the canvas so New Paths like so and this will go in the else Clause so here we have else we do that because in this case we don't want to expand anything now if we open our terminal and regenerate our data if we look here we will start to see that the values are different than before but I would also like to visualize what we did exactly so while it's running I'm going to redo the visualization part in this data set generator here and I'm going to show the new image that we get after expanding them so here after we have our pixels I'm going to figure out the size they are going to be a square canvas always so I just take the square root of these pixels length and then let's get the image data that we have on the canvas at the moment I just need the data structure essentially and I'm going to Loop through these pixels one by one and I'm going to write on top of this image data the values that we currently have so to do that I'm going to consider just this Alpha value others will be 0 for red green and blue so starting at the I times for index because they come in group of four I'm going to set the image data data at the start index to zero so this is for red now and this has to be copied three more times here and now we're going to set the green and the blue and the alpha component this is not zero this will be the alpha that we calculated previously and now we put this new image data on the context so put image data image data 0 0. and I don't think I need this complexity value appearing anywhere here when debugging I know the number of pixels is calculated correctly already let's regenerate the data okay this is done and now let's extract the features we can see how this progress indicator works now much slower when we're dealing with these pixel values okay and now let's run the evaluation and done a little bit improvement from previously but not much and this is what we get the images are now stretching all over the canvas there and I kind of like this view because now we can see the drawings much better even for those who made small images they are stretched here like that but remember that all we do with these stretched images here are counting the pixels as a kind of complexity measure all the other calculations still happen the same on the raw Point data one thing I am really curious to see is arminio's house aha it was like that for some reason the app registered some point very very far away and that's why its width is so huge now let's try drawing here and I do sense a little bit slower reaction time here because every time we make a new update to the drawing it's going to take the features including this pixel feature which is slower to calculate and um basically it takes a little bit longer time here I would say it's still real time we move on to neural networks next and I don't have the patience to teach you what they are but don't worry I know just a person to do it take it away red Rado neural networks are Computing systems inspired by the biological neural networks in our brain these are some neurons these branchlike structures receive the signals when stimulated enough a neuron will fire a signal through its Axon so a single neuron does something really simple and intelligence only comes when they work as a team you see your brain has 86 billion neurons you also have quite many of them in your spinal cord and sensory organs like in your eyes and ears these sensors send signal to some neurons that pass it to the brain there the processing happens like a chain reaction where some neurons fire some don't eventually signals arriving to motor neurons that pass them through your spinal cord and make some muscles contract in very specific ways hey A lot happened in just a split second let me try to slow this down and explain it to you pay attention sensors inside the ear pick up compression waves from the air and send signals to the brain which figures out the direction based on different intensities signals then travel to neck muscles tell them to contract and turn the head in that direction the eye catches a glimpse of what's happening and new signals travel to the brain peripheral vision is blurry but good enough information exists to detect some kind of object approaching and new signals travel to facial muscles to contract and protect the eyes from getting hurt eyes are really important at the same time the brain begins a kind of Defense protocol by sending signals throughout the body time passes and the image becomes more clear the brain does pattern matching and recognizes the object as a ball contextual and historical information will play an important role in what happens next let's stick to the first one the brain concludes there is no threat and uses knowledge about physics it learned during its lifetime to predict where the object is headed it then sends new signals to the muscles to contract in slightly different ways to catch the object instead of blocking it and the rest is history one history where the brain did the good thing and not much happens afterwards but sometimes this happens and the Brain learns it did something wrong and configures itself so the same thing doesn't happen again hopefully anyway I'm feeling really good about myself now that I know my brain can do something like that in an instant hope you do too our cars in your own network will do something like that neurons on the first layer will be connected to the sensors they will send signals forward a few times and the last layer will be connected to the car controls to make it actually do something spoiler alert will be working with relatively small networks here but that's okay because we actually don't need very large networks to solve this problem now that you have a basic idea take the code from the link in the description you'll need it to follow along but beware I will just briefly go through it and if you really want to understand it go watch these two videos first of course watching the whole selfpriving car series is even better there is one thing about what redrado said in the beginning that bugs me so a single neuron does something really simple I got this comment from Mikhail and I should point out that biology is really not that simple we don't fully understand how brains work to this day but a simple model like that is all we need to build an artificial neural network I definitely don't want you to draw the wrong conclusion and that comment made me think twice about my wording I've added the two files here in common we have Network JS now and in web JS we also have viewer JS here viewer.js is pretty much the same as in that tutorial except that I made these output labels be images now there I used emojis but here I wanted to use the colored emojis we generated earlier and there are a few other small tweaks here and there but pretty much the same code as you've seen there and network JS here is the same code from the tutorial with this small difference here instead of how it was originally written because in the selfdriving car case the car could press two keys at the same time like maybe accelerate and go to the left but here we need to decide which is going to be the winning class so we are leaving these outputs as the raw value there and we will select the class to be the maximum value that we get I've also added here this export so that it fits with our current structure but other than that it's exactly the same we have here the neural network made out of different levels the level having inputs outputs biases and the weights we have methods for randomizing these weights and biases because that's how we knew to optimize in that other course we just tried randomly different networks and hoped for the best we kept the best one all the time then the feed forward algorithm just implements that summation and outputs all the outputs to feed forward for the whole network just feed forwards each individual level like that and the only difference is really this line of code here but if you've watched that tutorial you know what it means now to use this new code we will build a new classifier next to our KNM classifier that we had here already and I'm going to copy this one for reference let's copy and paste it here with a new name I will rename this file mlp.js MLP stands for multilayer perceptron and I think it's a good name here because neural network is kind of like an N from here so I want to keep this different and it will also match with what we do in Python later on now we will modify this code inside of mlp.js so here we have MLP now and let's export here also MLP like so and I'm going to empty here the Constructor we won't save the samples here this model doesn't store the samples it's what makes it much more efficient than this K nearest neighbor let's remove them from here as well and I'm going to empty also this predict method but I will keep the return so that we know what structure we need to return things in now the Constructor is going to take as parameters the neuron counts we need to know how many neurons we should use and also the classes the model needs to know what are the options let's save these here as attributes of this MLP so the classes and now let's initialize a neural network with the code from the file we just added and pass here the neuron counts so this we need to include here same as we include utils but here we include the neural network like so from the network JS file and the prediction here is what changes we just get the output from the neural networks feed forward algorithm when we pass this point the parameter from here and this network that is stored as the attribute of the class right here from these outputs we calculate the maximum so let me use math Max and spread here this output array and let's get the index of the element with the maximum like so and the label of that is going to be taken from classes at that index simple as that now for consistency with the KNN I will keep here an object with the attribute label but we don't have any nearest samples here it's gonna be null let's save this file and to evaluate this MLP model I'm going to copy here in node the Run evaluation so let's copy this paste it here and we will have two run evaluations one will be with knnn and the other one will be with MLP like so so let's modify this run evaluation MLP and the first thing we do here at the top is rename our classifier to MLP like that and then reading it here from MLP JS and here where we initialize our model we don't have K and N instead we have MLP and this MLP is going to take the two parameters first the neuron counts and we have five features at the moment so the first neuron count is going to be five and the second one is going to be let's just say directly the outputs and we have eight different outputs Car Fish House tree bicycle guitar pencil clock and the second parameter we pass are the classes which are here and these hardcoded values we don't have to keep them hard coded we can just replace here five with taking the training samples first item there the point and the length of that point and here is just the length of these classes so now we don't have to change these anymore they will work as expected so this is a neural network without a hidden layer it just connects the inputs to the outputs directly and we will experiment with hidden layers later here you could pass a hidden layer with maybe 10 neurons and another one with 10 neurons and one with five and so on but at the moment we don't we just have this simple connection now let's copy this and replace every time we want to do a prediction n with MLP and here also that's it now let's run this new evaluation I'm going to start the terminal make sure we're in the node directory and node run evaluation MLP this time and it's really fast I didn't speed up the video this time it's also not very good this accuracy here is random chance if you've done homework 7 then you know this is random chance and Leo Caesar 3D mentioned this in a comment now because this is based on Randomness when we add the weights and biases every time we run this evaluation we will get a different value here sometimes we're more lucky than others because the networks that we are getting just happen by chance to be a good or a bad configuration in the selfdriving car course we experimented with many different networks and choosing the best so let's try to do that here as well we will try to fit the network to the training data so let's open our MLP file here and Implement a new method here called fit the samples now we pass the samples to this because it's going to need them but it's not going to store them it's just going to update the weights and biases according to these samples somehow you'll see and we'll use the same strategy of Randomness and trial and error we will try for example one thousand times and keep the best network that came so let's consider the best network being the one in the class attributes and the best accuracy let's evaluate that Network on the samples now we are evaluating on the training data we are not yet seeing testing data but we are trying to improve the model this is okay I'm going to now Loop through this number of tries and let's try to generate a new network after we do that we evaluate its accuracy on the training samples and if it's better than the best accuracy we keep it and we also keep the network like so now here at the end we just set this network to the best one that we found and we still need to implement this evaluate method here it's not complicated all we have to do is implement the method like that and count how many of them are correctly predicted when we Loop through all of the samples take out the label and remember here to destructure because that's what MLP predict will return on the sample point now the true value for this is what is stored in the sample label we know the true labels for our samples but if this predicted label here matches the truth then we increase the correct count so correct count increases if truth is equal to label one otherwise it doesn't increase and here we just calculate the accuracy by dividing correct count by samples length and let's return this accuracy let's save this file and in run the evaluation MLP after we initialize the MLP classifier here we fit it to the training date so MLP set training samples and let's try this again I'm going to open now the terminal and rerun the evaluation MLP now we get 26.8 which is much better than the random chance things we were getting previously so it is working we are searching through 1000 networks and if we're going to increase here maybe by I don't know 5000 then this accuracy should be even better because now it's trying even harder it's going through even more it's an expectation but of course you can be really unlucky with those 5000 randomly generated networks and then it's not gonna look sick and it doesn't really make sense once we have found the good one like this to go back down to a crappier one so what we could do is save this model every time we find it and then load it when we do this optimization so we can continue a previously made optimization with the saved Network as a basis let's save this model so I'm going to type here write file sync and we will need the constant for where the model should go and then I'm just going to stringify the whole MLP object and that's it now I want this model to be accessed also by the web page so that we can try the neural network there as well and I'm going to use the same structure here putting model and JS also as a constant and here initializing a variable called model and then putting this stringified Json inside of it and now let's close this template literal like so now these constants need to be added I'm going to go here in constants.js and let's copy this one for the decision boundary this is going to be model now and it's going to be in this models directory let's call it model dot Json and the JS object let's just copy this min max here and this is going to be model Js and model Js now when we are going to run this evaluation this model with 31.96 percent accuracy is going to be saved in data models model here next to the decision boundary and if I'm gonna format it you will see it has the neuron counts information the classes information and the network with all the levels which is just one level for this one and we have the inputs the five different features the outputs the result of the feed forward algorithm and here the biases and the weights through from all the inputs to all the outputs now the inputs here and the outputs here are just the last values that have been used in the training process they are meaningless every time you do a classification these will become overwritten with whatever the features are and these here are going to become generated from the feedforward algorithm they're now just placeholders here and that's okay now if we want not to lose this model and get at least 31.96 accuracy in the next model we have to load this one so in run evaluation MLP after we do this initialization let's load it from that file before we do the fitting so let's say here if that file exists the one that contains the model I'm going to mlp.load and parse it after we read it like so now this load is a really simple method that we still need to implement here inside of mlpjs I'm going to do it just below the Constructor here and load given an MLP model I'm just going to update this model's neuron count to that ones and the same thing for the classes and the same thing for this network it's basically a copy Constructor now let's save this and rerun the evaluation and the same accuracy as before we didn't get lucky with the 5000 tries here but if we try again still no luck if we try again still nothing still nothing but now it worked so we could optimize like this would take quite a long time to reach the same level accuracies that we are getting with our knnn there are better optimizers than this trial and error out there and we'll try those later but now let's get this to work on the web page as well let me close some of these things and here in viewer HTML we are gonna have to import many JavaScript files so here we need the new MLP classifier similar to the kmn classifier then we also need that model the one that we calculated on the back end so this is here in JS objects the JavaScript variant then we need the neural network code and the visualizer let me add this network JS here underneath utils and the visualizer here from this JS folder now we'll visualize this on another canvas and I'm going to Define it here inside of the chart container underneath the confusion container so this is going to be Network canvas and it's going to be what we draw the canvas on let's give this a style similar to the confusion container inside of styles CSS the confusion container is here I'm just going to copy it below rename this to network canvas and give it a black background let's save this and close this file and let's begin to work with the MLP classifier we won't use KNM anymore in this course I'm going to keep it here for reference but I'm going to start using the MLP classifier so MLP and I will initialize it with uh empty and empty ear for the neuron counts and for the classes because they will be loaded from the model that we have calculated with the scripts now every time we see KNN here I'm going to comment out the line and write MLP variant below so this happens here when we are calculating the accuracy of the testing samples but also below for the real time processing here so let's copy this comment it out and replace KNN with MLP so it's the same thing but now with the different classifier this should work already but we are not visualizing it yet so let me go here at the top and also do the visualization I'm going to set the width of the network canvas 500 and same for the height and let's get a reference to the network context from this network canvas like so now we also need the output labels to look nice and we can get those here after the graphics generate images but let me just put this maybe here above the sketch pad and below the confusion because now we have these related somehow so we generate these output labels from the styles by looking at the values of the Styles and then remapping them so we only take out the image of that style we don't care about the color or the text just the image component and then we use our visualizer to draw the network on this network canvas the network stored in our MLP classifier and using these output labels that we just defined we also want to update the visualization here after we do a realtime prediction like so and now let's save the file and we should be able to test the refresh the page and something looks horribly wrong I noticed that this width and height features that we calculate for this empty canvas are minus infinity and minus infinity and this is causing some problems now for this neural network it was working okay for the KNN because it was just some coordinate but now it's sent to some calculations there and it's causing some not a number to happen and problems so let's fix those functions real quick I knew they will become an issue at some point so inside of this feature functions at the top our width here if the points are empty if there is nothing there I'm just going to return 0 for the width and same thing will happen for the height as well now let's refresh this page and close this console toggle the input and now the network does something here it's saying that this is a car because this car note here output value is the highest and you can see that there's a yellow color coding here blue means negative values and the least visible they are closer towards zero so this is very visible bright yellow here it means it's a high value and um it's not fantastic 33.28 we had much better results but that is what we can do now with this random optimization strategy and this here at the bottom are the features so when we look at this we can see a relatively high value for the width because it's a wide image and this is the height here which is smaller then this is going to be the elongation apparently quite the small value but if we draw something like this really elongated shape it's going to be bright and then these final ones are the round Miss value and this is not round at all but if we do make it round it's going to be bright and the last one is the number of pixels basically so if we would fill this space with a lot of pixels then that one starts to light up as well and apparently it is able to pick up that this is a clock one thing that I still want to do is toggle the output and this doesn't work anymore we need to rewrite it so that we consider this one as well not just the confusion Matrix and the chart so let me go to display JS and quickly rewrite this from scratch and I will just say that if the network canvas is visible then let's make this one invisible and let's make the confusion container visible otherwise if the confusion container is visible we will make it invisible otherwise we will make both of them visible again so now we are going to toggle between the three items there let's save this refresh and this seems to work interestingly we get a lot of zeros here so it looks like the network that we have is really good at recognizing cars and pencils and clocks but nothing else so now we can see that this accuracy really doesn't tell a good story but this confusion Matrix really tells us what is really going on the model forgot about these other things pretty much and let's see now in this decision boundary plot we can't really see much because it's still this High dimensional Cube but we could revert to the simple features I like doing that let's go back to width and height two features and see how this decision boundary plot looks like now when using a neural network so in feature functions I'm just going to comment out here everything except for these width and height and let's open the terminal and let's rerun the feature extraction so node feature extractor.js and now it's fast because it's not doing the pixels thing and now we have to optimize again our neural network model but the model that we created previously here inside of the data models is pretty good and it's using the five different features so it's incompatible with the two feature models that we try to create now and we'll need to delete this for the code to work so right click delete the model and now run evaluation MLP should work we got a new model with 26.38 accuracy now if I run this again it's going to try 5000 more times and maybe get the better version or not let's try one more time see if we're lucky and we are we got 29 accuracy with this one and you'll notice that this decision boundary plot is generated really quickly now because doing the feed forward algorithm is much faster than doing the nearest neighbor search so we could go in node here in the Run evaluation MLP and set a higher value for this image size to get a better quality image there maybe 1000 is enough now let's rerun this took a bit longer but it's done and accuracy didn't change so let's try to refresh and we see now this network with just two nodes here the width and the height just two features and the input layer and the output it looks different but it seems again the same kind of scenario with just three things considered the car the tree and the bike now let's toggle again and this is now the Precision boundary plot and it looks interesting it has here at the top the tree section and then the bicycle section and then the car section this is confusing me with the pencils so let's go back to viewer HTML and put all the testing samples now I'm going to comment out this filtering from here a refresh and now we can see this decision boundary plot and every one of these trees here in the green region is classified correctly every one of these bikes here is classified correctly and every one of these cars here is classified correctly but a lot of misclassifications happen there is a pencil region here and this car is in the pencil region so why didn't it show up in our confusion Matrix oh it did it has a one here I didn't notice it and the tree should be there as well apparently and there it is hermino's house is also there classified as a car nice now let's try one more thing and see if we can add the hidden layer here and if we get any difference in our run evaluation MLP at the top let's say we are going to add 10 nodes on a hidden layer and see what happens because we redo this evaluation and the network that we have at the moment doesn't have those I'm gonna have to delete again this model here and rerun the evaluation a bit worse accuracy let's try to improve it give it five thousand more tries doesn't seem to work one more try maybe we're lucky and we are not let's just keep it like this and see what we have on the page so this is how the neural neural networks looks like and if we toggle the inputs and we draw something really wide you can see now this lighting up let's make it also tall so this will light up and a lot of things are lighting up here in the middle in interesting ways when these properties change so it's a more complex model but not a very good one it also seems to now prioritize two things here let's see the decision boundary plot let's close this input and I don't really see it so well let's keep just the decision boundary plot now here and I'm going to add again this filter because it keeps that plot in a kind of squarish aspect ratio because that's where the pencils are there's no arminius house to stretch things so let's hide the samples and refresh toggle the output that's how it looks like let's readd all the features one last time now with this hidden layer there so in feature functions I will remove this comment from here and here we go down and feature extractor it's done and now let's run evaluation MLP oh I forgot to remove that model that we had last time delete and now run evaluation MLP refresh and now the input layer is more complex again still this kind of bad looking confusion Matrix and this one is unreliable now because we just showed the first two Dimensions there now optimizing this with the current strategy is not going to work well you could wait for it to randomly try a bunch of different values and you could leave it overnight or something you will get better values but next time I'm going to teach you how to use Python to get the values with more complex optimization algorithms the neural network is now there but it needs to be optimized better and the typical way of doing this is with the back propagation algorithm I don't have a good way to teach it and the best video I know on the topic is from three blue one brown so go watch it what we'll do is use back propagation in Python there are some JavaScript implementations as well but I wanted to see that you can combine programming languages like that and use their strengths when needed python has many machine learning libraries we'll continue to use scikitlearn because we use it in phase one but others are more popular nowadays I think it doesn't really matter all we need is something that gives us good weights and biases and paste them into our model now get ready to blur the lines between programming languages make sure you have python installed for this next part last time we used python we were in this python folder and we had this KNM py and some functions for reading the CSV features we're going to make a new file similar to this KNN but we'll call it MLP so copy and paste it here rename MLP and it's the same thing as k n for now but we will include from this scikitlearn Library not from Neighbors this time but from neural network and we import the MLP classifier it has an implementation of it already then here we write MLP MLP MLP everything looks the same but here we are going to have this MLP classifier and these parameters don't fit anymore instead we should pass the number of hidden layers and actually how many neurons should be on each hidden layer so we have to use a tuple for that and at the moment I just have here 10 because I want it to be the same kind of structure as we used last time in JavaScript so let's pass here this hidden and now we can test so let's open the terminal we normally worked inside of this node directory so if you're still there make sure that you're gonna run this python code by first going outside so bison to running command and then going outside of the node folder and then python mlp.py this is what we'll run this code and looks like we're getting something really good 61 percent and an error here saying something about the optimization not being finished yet and that's because there is a parameter that we can set to this classifier that it can iterate longer so I'm going to pass this set here Max either to ten thousand and let's save this and run this again now we get 66 percent almost 67 percent which is really good now if you're gonna run this code again it's possible that you're gonna get another accuracy here like now it changed slightly and that's because it also uses randomness of some kind but if you want to have predictable results here you can pass another parameter and fix the random State it's still going to use Randomness but now the randomness is predetermined if that makes sense so saving this and running this gives us some value now maybe 61 percent I guess we weren't as lucky as we were before but it's consistent and if you change this value to something else you will get some other accuracies there some of them will be more lucky some of them not depending on your luck I guess but I'm just gonna fix one here I don't really care about the accuracy that much sixty percent is definitely very good compared to what we were getting with random chance but okay this is just one of these printing in the console things it's not so great how to get it to work inside of our web application and see it in practice well we have to first debug what this MLP object contains and I'm going to start to print some of its properties like the intercepts so let's run this again and you can see here two values pretty much the first value here are 10 numbers and these are the biases for the neurons on the hidden layer the 10 neurons on the hidden layer and these ones here are the eight biases for the output neurons the eight different classes we can also print here the socalled coefficients run this again and now we're getting something much bigger here these are the weights so the weights are much longer than the biases so these intercepts and coefficients need to go over our model here if I'm going to format this we also have to specify in your own counts and the classes here and then the network we have the different levels for each of them we have inputs outputs and then the biases and the weights so the intercepts and the coefficients are going to be the biases and the weights we need to fill those in here for all of the levels but the inputs and outputs we don't need to worry about that because these are going to come in as a given the inputs and the outputs are going to be calculated by the network so really we only need to pass here the weights and the biases and also these things that the model requires so let me show you how to do that let's remove here this and I'm going to need to know what these classes are let's define them in a list Car Fish House tree bicycle guitar pencil clock and now let's start forming our object it's going to be this adjacent object and the neuron counts now the values from this are going to be the length of X of 0 where we have the number of features basically for the input layer and then the hidden which is defined up here followed by the length of the classes which we just defined here then the classes I'm just going to pass this object directly and then the network this is going to be a dictionary here with levels which is going to be an empty list and now these Network levels is what we have to fill in from the intercepts and the coefficients so I'm going to Loop through all of the coefficients like this and let's define the level with the weights and I'm going to convert these coefficients into a list and I'm going to do the same thing with the intercepts like so and inputs is going to be just zeros I'm just going to multiply them by how many coefficients there are and outputs I'm going to multiply them by how many intercepts there so these are just zeros and then we need to append this level to our Json object Network levels so this is a dictionary so we refer to the Keys like that and append the level now python does have a Json module and we can import it here and use it to define a Json objects with an indent so we can read it more nicely and now what we have to do is write this Json object into our file here that we will use in our viewer both the one year and the models and the one in JS objects here I will modify both of them in Python so we don't have to worry about it let's open the one in data models model.json for writing and right the Json object now I'm going to copy this also for the JS object the JavaScript object and this is going to be in common JS objects and model JS like that and when we write it here we also need to concatenate that string to assign it to an object so const model is equal to endless concatenate with this and then here at the end concatenate to it a semicolon and now when we run this python code again here in the terminal let me first clear it up a bit so if I'm going to run it again it lists here the accuracy but our models the model JS file here and also the model Json file here should have updated with the new values so now the weights are going to be calculated from Python and the biases come from Python and the inputs outputs are turned into zeros if we did everything correctly then now we can run this run evaluation MLP and it's actually now trying to improve that model if it can but most likely it cannot and it's done let's see it now in practice I'm gonna refresh the page and there you have it a neural network that now has 61.79 accuracy and if we toggle this we can see this confusion Matrix looks much nicer quite similar what we got with the k n actually and the decision boundary not going to help us much in these high dimensional spaces but we now have a neural network here that actually is able to recognize things quite nicely quite well with 61.79 accuracy nice okay it's quite good actually now I didn't plan to teach too many things about neural networks here I plan to do that in phase three of my selfdriving car course after Phase 2 is done but let's try to investigate a bit using just two features again so we can see also this decision boundary plot coming from a good neural network I'm going to go here inside of common feature functions and let's keep just the width and the height again and now let's do feature extraction with these two features only and now let's do the training with python so we got a 42.3 percent accuracy with just two features which is comparable to the k n we got previously with just two features now let's run the evaluation so it generates also the decision boundary plot and something looks off this 31.7 percent accuracy what what happened it was supposed to be 42 percent why did it drop so much Well turns out the reason is the activation function that this MLP classifier uses by default is the rectified linear unit and we will need to implement this rectified linear unit into our JavaScript code for it to be fully compatible let's do this I'm gonna open here the network Js and here where we're Computing the outputs we need to apply this value activation function here goes done it's just a maximum between zero and that other value it doesn't like to have negative values here so let's save this and now run this evaluation again I should really turn off this trying to optimize here let me go to run evaluation MLP and here where we're doing the fitting I'm just going to decrease this value by a lot let's say I will remove it so it defaults back to 1000. it's gonna be almost instantaneous okay and now you actually see here the accuracy being 42 .4 percent so the same as we got in Python and now let's test on the web page there's the network and if we toggle the output it looks okay for just two features the width and the height and the decision boundary plot looks like this it's much more simple than the complex one we got previously from KNN but otherwise it's comparable in many ways like a section here for the pencils and one for the fish and this one for the clocks I can obviously tell that they are there now these activation functions they are several of them and you can check the documentation and the scikitlearn library web page for example if we go back in Python we can actually pass them here we could say activation set to hyperbolic tangent for example and this is going to be again one of those really difficult ones to implement but let's see first if it works so let's try the hyperbolic tangent now in Python here it's not a big difference but I want to show you just how the decision boundary looks different now let's implement this hyperbolic tangent in JavaScript and the good news is it's already there the math library has an implementation of it so we can just call it directly here and remove that zero that we used for the max previously now let's run also the evaluation here so that we get a new decision boundary plot and if we refresh toggle the output and again you'll see that it looks more curved because of what we just did I think this way of learning is really nice and if you're gonna go deeper and study the mathematics behind the things you're going to have an intuition of what to expect but yeah let's add all the features again and see what effect this hyperbolic tangent has on all of them wow we got the 68 percent now to see this on the web page we don't really have to run the evaluation anymore because the model is already there and with so many features the decision boundary plots are useless pretty much so when we want to optimize we can just run this python code and open the viewer unless we change the features as well then we have to do the feature extraction again if we refresh the viewer this is what we get we have now this neural network here and it starts to have kind of a structure it's not anymore completely random if you look at the links The Matrix here looks better and better all the time almost 70 percent accuracy so that's quite good and this I won't bother with it anymore we can check also down here in the testing section to see that a lot of blue started appearing recently and in many situations all the drawings from one person are recognized starts to feel like this is actually doing something good I decided to include this section on deep neural networks so you don't ask something like when are you going to teach us something cool like deep neural networks well you already know how to use them it's just a neural network that has many connections many hidden layers and so on I'm also going to teach you a way to go from the five features we've been using to 400 features but as you can see from how long this video is it won't be rocket science we'll just use the pixels themselves as features so it won't really be a deep dive this time we'll only go Skin Deep inside of feature functions I'm going to comment out everything here really and we will implement a different kind of code structure here it will break what we have previously so keep a backup of that if you want to compare but we won't do many changes today so you can also revert if you pay attention now what we do here is we open up an object with the name pixel array so this will have all the features coming from one function call and the function is going to be called on paths but then it's going to return all the pixels from our get pixels function which we call on the paths but I'm also going to specify a size because I don't want to have 400 times 400 pixels that's going to be a lot of pixels and they are not necessary we can figure out what the drawing is even from a small drawing and it's going to be more efficient so in my case here I'm going to use a small 20 by 20 canvas now let's close these and this is going to be a feature Vector with 400 dimensions now we need to change some things in the code to work with this new structure and we're going to go to node feature extractor.js and comment out this line here and instead write this new one that only takes out the values of calling the first and only function that we get from the feature functions in use so we call this one here directly on the paths and get the values assigned them to the point now this feature names at the moment would just say pixel array here and that's not good they need to be many of them 400 of them so what we do here is comment out this line and I'm gonna write this new one where we create an array the same size as the first samples Point length and we fill it with zeros or anything you want really we can fill it with an empty string like this it just needs to have 400 items for the code to work now for the web to work we also have to do this for the real time calculation of the features there instead of this mapping here and here we can just take the first function and call it underpaths like so now this should work if we open now the terminal we can extract these new features let's go to the node folder and then extract these new features and let's have a quick look what they are inside data data set and now let's for example open these csvs they are easier to read you can see at the top the feature names they are those empty strings separated by commas and there are many of them 400 of them and last thing is still the label and then here there are pixel values visible pixels here and some pixels may not be fully visible because of this antialiasing but some pixels are completely invisible and this is the whole very long feature Vector for each individual sample so can this work well if I'm going to optimize now with python it seems it does and we're now at 70 almost 75 percent wow let's take a look in the web page and we now have this Beast here with all these connections here from each individual pixel all 400 pixels of the small 20 by 20 size image and this is the new accuracy this is the new Matrix here and it looks really really good doesn't it this we already said we don't look at anymore with these high number of Dimensions there and if we try to make a new input here it seems to work and I made these nodes here very very small in the visualizer if they exceed a certain value now if you want to get an even nicer visualizer here that somehow modifies also the weights based on the activation of these bottom neurons here then you could go in the visualizer and go to draw level and here we're drawing these weights between the inputs and the outputs so they are the lines and we set here the value the rgba of the weight value but we can multiply this by the inputs of I and this is going to make that connection disappear if that pixel is off or be there present if the pixel is on because of that antialias saying it could be also some transparent value so let's save this refresh and now everything is off here but if we start drawing something we start to see there those connections appearing and I think it's interesting it makes this a much more dynamic system this is not a pencil oh come on maybe if we give it some more detail like okay now it's a fish great but um this is not yet a deep neural network because it just has this one hidden layer let's go deeper we're going to go to our python script let's put 100 nodes on this one hidden layer for now and then we try more later so let's optimize again 82 percent accuracy we broke another barrier there at 80 percent let's see how this one looks like and this is it wow look at that now this system starts to become slow because of this visualization here but also because the model becomes more complex and there are more calculations I think we can try with two hidden layers so that we do get some deep Network even though deep means a lot of them but you get the idea let's add 100 more 83 percent not a very very big Improvement but it's still an improvement now let's see how it looks like so now we have this and if we draw something a lot of crazy stuff happening there and it is a house it seems to be quite reliable like after it's a house it's it's a house here let's see our confusion Matrix one more time and yeah this looks really good and let's have a look also at the classifications very few of them are not blue right now now people have different views here some like the small models with relatively few features and consider big models like what we just built as a waste of resources but others think they're worth it because you can teach them pretty much anything without the pain of tailoring features one by one the problem is it's really hard to explain why the system works a certain way if the model is so big hope you liked the course let me know if you want to see more like I didn't teach you anything about clustering yet and it's an important part of machine learning or we could try to identify the person who is doing the drawing instead of what is being drawn maybe we can make a really sophisticated authentication system like that what do you think go in the poll in the description and vote your favorite see you guys