all right and with that i'd like to welcome everyone to our little debate panel or discussion panel where hopefully we will have a friendly conversation with one another and i noticed some some people have joined me up on the stage here but who are these people i have no idea can you maybe quickly introduce yourself sure my name is brian tarlston i work at microsoft on uh the language side of the chakra core engine and also on typescript um i also go to the tc39 meetings and do that standards work as well i think it's a little bit of an understatement to say you do a little bit of standards work you're the editor of the ecmascript spec true i mean gonna get an applause for that yeah okay and who are you yeah my name is benedict i already spoke earlier yesterday you might have seen my talk i work on the v8 engine which is the engine in chrome and yeah i do a bit of performance work sometimes another understatement i guess uh wait that's that's an interesting coincidence you both work on a javascript engine wow oh surprise maybe we should talk about that yeah it's okay but you mentioned that you work on typescript that's one of the things you do um and we see a lot of developers using things like typescript and flow and other developer tools in their in their workflows and you also work on standards do you think types is something that should somehow be added to ecmascript as a language itself or should it remain at a build level um my personal opinion i think is that in um as far as types being in the in the engine and understood by the engine and used to produce um optimal machine code in sort of the same way that a c compiler might i'm not convinced that that is really possible javascript seems sort of fundamentally opposed to that kind of work i think probably benedict can share some actual data on that based on um strong mode investigations but i think there is some a space for types in in the tooling space um a sort of erasable type layer like like typescript has where um there can be uh you can you know maybe even see them in the dev tools and get feedback in your dev tools in the browser about uh what what's happening with types uh and you know get errors at run time for for type mismatches and that kind of stuff i think that's an interesting avenue to pursue but it is also very difficult to do because we have a lot of type systems now we have typescript we have flow there's also closure compiler and these are all kind of occupying the same space and they all have different ways of doing things so i think we'll see over the next few years whether there's coal there's a kind of coalescing of these ideas and sort of rallying around one sort of system to to rule them all or if uh as i actually suspect uh there's actually value in having type systems that make different tradeoffs um uh so i think that might be actually an interesting place we might end up yeah i agree with many things you said so i don't really see types as a way to speed up javascript performance because you cannot really rely on them and the types don't operate on the level that the engine needs to operate on what i see though is the value for developers and i think the missing link that we have so far is that the browser doesn't give you or the engine doesn't give you feedback on whether you actually it doesn't validate the types really so you validate ahead of time but then at runtime anything can happen anyways you can pass objects that don't have that type because those are just living outside of the typescript world and we recently launched a new system that we call type profiling which you already might have seen already actually apple has this for some time in the web inspector and one use case that we could imagine is we collect the types at runtime so we know precisely what kind of object we have seen and we could use this information and combine it with the static information that you have in typescript or in flow and signal errors if you see a type an object of at runtime that doesn't match the type of the typescript declaration for example and doing this i think you can produce pretty good code because the engine you keep your code monomorphic just because you use the types to restrict it you can get if you subset javascript like if you get rid of eval and you get rid of the function constructor and a few other things um you end up with the sort of javascript subset that could be strongly typed um but that doesn't i don't know that many people are interested in using something that's not really javascript and you can't like use javascript libraries right you briefly touched on strong mode before is that something you have some more background on i don't have a lot of background on stronghold except that this experiment was discontinued because we found that so the idea is that we um we have a subset of sort of subset of the of javascript running in a dedicated mode similar to a strict mode that would be used strong and it would be restricted so that many of the things that make your program slow or behave in the wrong way no longer happen but i think that goes against what the standards committee is currently interested in and having this 1.js approach we also had an experiment on chakra core we had an awesome intern who um wanted to investigate uh how good how what what kind of performance gains we could get if we built in types into javascript and these types weren't typescript types these types were actual native types you know so he was annotating variables as this is an in 32 and this is you know an n16 and that kind of stuff and we found that as long as you just blindly trust the types which is not something that you can actually get away with in in practice but if you blindly trust the types you can get some pretty nice speedups across the board on the order of like 10 to 15 um but the real trouble is we we have this awesome ecosystem with so much stuff in it and we just can't we can't break that we need to find a way to evolve from where we are and it's not entirely clear what that looks like yet and speaking of standardization at dc39 there is a stage process for new features to be added to the language would you say there is a similar process that happens once a feature starts getting implemented in the engine itself a similar process like what kind of stages does a feature go through once it starts to get implemented on the browser side so outside of the dc39 process um yeah i mean at least on our team we usually start with some kind of prototype or a spike so we'll start doing this work um you know around stage three in the in the standards process that's that's a stage when the committee says we're pretty much done making changes to this and we really want implementer feedback um and then it's just a matter of uh getting all the test 262 tests passing after that no small feat and then after that it's a an iterative uh cycle of you know shipping these features to developers and developers tell us hey this is great but you know xyz we go fix that ship it again and this whole cycle just kind of uh continue so those wouldn't be bug fixes anymore because you already passed the test suite would there be more like performance optimizations for common yeah yeah it's usually performance optimizations um it's really hard to anticipate in advance what patterns you guys are going to be using like um it's it's it's uh it's a hard game to play and if we try to guess what you might use we might get it wrong we might spend a lot of time optimizing something that just isn't important so this feedback cycle is really important to us that we can you know hear from developers how they're using a feature so that we can optimize it and improve ergonomics and other things like tooling and that kind of stuff what are your thoughts on that benedict it's actually very similar so we also start looking two new features once once they reach end of stage two early stage three uh we usually try nowadays we try to work together with babel for example to also make sure that things are aligned because it would be really bad if you use the feature at stage one already and then you rely on babel semantics and then the browser gives you completely different semantics once it hits the engine on the performance side we we we have to wait until some use appears so even before it hits the browser we can often see it um when we just look at the actual code that people write and then transpire babel but it's hard to estimate what is important so for example we just now start optimizing proxies just um this year we started looking into proxy performance and proxies have been there in year 6 since uh two years already so this is roughly the timeline when we noticed that okay maybe it's time to look into how people use it and then optimize the relevant cases so it sounds like engines optimized for a real world code which means that there's a bit of a chicken egg problem where if there's a new language feature that lands in browsers a lot of developers maybe they think oh it's not going to be fast yet in engine x or y so i'm going to not use it for now and maybe still transpile my code and avoid using this feature directly but that means that also it won't get optimized so how what is the best way to break this pattern and break this cycle so in my experience since we have evergreen browsers nowadays you should go for it as early as possible maybe just ship it to a subset of the users and see can you do this is this viable is this a logo and specifically on the node side you completely control the version of node and you completely know exactly which version of chakra core or which version of v8 is inside so it would be nice if you tried earlier and provide feedback and then we can look into this yeah i definitely agree with that um and also i find that um a lot of times you can get away with using these new features and areas of your application that aren't performance critical um so that's that's sort of my my approach to this problem is to um uh because like i can't wait to use these features after they get implemented but uh you know i'm not going to be using four of in a in a hot pass because it's um well now it's pretty fast but it wasn't as of six months ago um uh so yeah i think um there is a little bit of a chicken and an egg problem but yeah just you know really rely on feedback and you really can't get out of uh out of that out of that problem benchmarks are interesting um especially when they go out of their way to try and emulate real world code as much as possible but benchmarks just aren't um aren't enough like we really need to hear from developers and on top of that i see a danger one pattern that i see in the wild is when people use babel and try to optimize the transformation so that it produces the ideal whatever transpiled code and i think there's some danger in doing that because long term you don't want to transpire this code anymore or ideally you shouldn't transplant it anymore so i see the value in that but there's also a lot of danger because then once you stop transpiling you'll be set and then you go back to transpiling and you don't make progress right so the set of features to be transpiled should be a moving window and i think an easy way for developers to make that happen is to use bubble preset amp which basically it's like auto prefixer for bauble so you tell it the browsers that you explicitly support and it won't transpile anything that it doesn't need to transpile and that kind of solves the chicken egg problem as well to some extent right to some extent um you know like it's the the performance of the transpiled code um isn't particularly relevant to the the performance of the feature that you're trying to use um but you know if you're using something like preset m it does mean that um you know once browsers catch up you're gonna sort of immediately be um opted into this new feature which is certainly helpful yeah and on top of that there are many options um to even ship modern code already to modern browsers so one option that we have been discussing a lot in the past you can just ship modules to the browser nowadays and there's a fallback you can just provide the full transpired bundle to browsers who don't support modules but all the browsers that support modules support es6 so that is a good way to upgrade without breaking uh old browsers so we should be transpiring to two sets of two bundles basically essentially it produces two bundles so there's a webpack sample configuration for this or that probably also rollup configurations to do that and i think this is a pretty safe way to move forward and it buys you a lot because the untranspired code is usually it's up to orders of magnitude smaller than the transpiled code okay so that's something that we all can do to make i mean to give better feedback and more data to browser developers so that they can make all these new features as fast as possible that'd be great cool and we have i want to stress this again we have evergreen browsers report a bug we can look into it if we don't know that there's a problem then we can never fix it unless we stumble over it by accident and then six weeks later up to 12 weeks later you have the new version and the feature is optimized ideally that sounds pretty cool i'm sold now we're here at a conference with lots of javascript developers and we've talked about standardization a little bit earlier how can the javascript community directly contribute to the whole standardization process um there's a number of ways in fact i'm giving a talk um at uh i believe 4 30 today um on that topic essentially but the spoiler alert yeah spoiler alert uh you should still attend my talk even after i say some things um so the the the best way is of course to to just try these features as they come out and get this feedback but even earlier in the process um tc39 is now entirely on github all of the standards work that we do plays out on github very little of it happens behind on closed doors it's usually just like administrivia and um you know ip related discussions and stuff like that uh so github.com tc39 has i think there's like 100 repos now um like every proposal has its own github repo that you can follow so if you're really interested in a particular proposal like pipeline or the bind operator or whatever you can go to github and find that repo and you can watch it and the issues are used to discuss um you know issues and pull requests you can send actually pull requests and that's fine we can take those um so that might update the you can spend your own make your own spec updates uh that's a really great way um also like we're all on twitter you can talk to us on twitter uh we have an irc channel on free node i know irc is not the easiest uh technology to use um but uh we do have that as well so that uh that's another way i remember times when things were different when the ecmascript spec was published as like a word document it was literally maintained as a word document with annotations for the divs so for each new release you would have to download it with annotations enabled go through the annotations figure out what changed and then even for small typos people would have to report a bug and create a tracking issue and then the core editor would have to go and fix it in the word doc and upload it to somewhere and now uh most of my job is just accepting pull requests from various people so it's pretty nice that sounds pretty good i remember at the time people actually ended up writing a script to turn the word document or even the pdf version generated from the word document into an html version so that it could be posted online and linked to yeah that actually turned out to be uh transformational work because it was that work that enabled us to actually move the spec onto github because we're not just dumping the word doc in a github repo right we have a whole new uh html spec format and the whole tool chain built on node to make it like really easy for web developers especially to write spec text and read spec text and contribute right what other challenges would you say there are when it comes to measuring the real world performance because we mentioned before that there's a lot of micro benchmarks out there synthetic benchmarks and they're useful certainly but what we really want to optimize for is the real world performance of the code that people end up riding right yeah this is a very complicated topic so for for one thing there's the web we can just browse around and check web pages and we do this we actually take web page replay to make it reproducible and we look into web pages what they do like top thousand web pages but we have a lot of trouble on the note side because we don't have access to your applications and you should rather not give everyone access to it so getting useful workloads there is very hard plus the workloads on the web are just one aspect of the problem it's not it if you load a web page on your mobile phone then the engine does something completely different than you than if you i don't know use google maps or use google earth on your desktop and the same for a node and there's also the developer tooling site so we last week or the week before we launched the new benchmark suite that is the web tooling benchmark and we really literally just dropped the code that is shipped on npm into the benchmark and run exactly the code that runs on your machine too so that we make sure we don't just have a proxy for the application but we measure the application itself so the goal is to make the build times of developers tools faster like when you run npm run builds you're speeding that up yes so much tools like webpack or parts of webpack are included babel is in typescript is in ugly files and all of the things that take up all the time on your machine and when you deploy it to somewhere on the continuation continuous integration service for example benchmarks like these can be used by all browser and engine developers right it's not just specific to one engine yep yep we've been looking at the web tooling benchmark as well i certainly appreciate that benchmark since npm build is or npm run build is um well that's my get coffee time i guess does anyone have a question from the audience please raise your hand ask us a question come on asking us a question would be less awkward than not asking a question at this point so we're gonna we're just gonna be quiet up here and stare out web assembly never heard of it have you guys uh i what is this technology i don't know [Laughter] i love webassembly um so like i work on javascript the the language side and i'm kind of a language geek i guess um so like while i appreciate a bunch of the interesting things with webassembly you know regarding um you know compiling native applications to run on the web and and um you know getting really close to native performance and all of that really i'm just excited about the prospect of uh other languages becoming firstclass citizens on the web i think that's going to open up a huge window for innovation from um all of you in the audience and i'm really excited to see what that technology enables yeah i i agree i personally i would love to see like next year or 2019 having one big game publisher published on the web like next version of assassin's creed runs on the web only that would be awesome wow yeah how many megabytes would it take though yeah that's an unsolved problem plus all the drm issues that they have right but yeah so there are some technical details but otherwise it would just be awesome on the other hand for a game it's different than for downloading a website where you want to view some content right so you might be willing to to pay a little bit more and get all those megabytes in so i would be fine if i wouldn't run on my phone right so that would be okay the use case is completely different from desktop i think there's also a lot of room for um like you know these 3d engines have these massive asset pipelines and um i think there's it's we're in the very early days i think we're going to see tooling that's going to enable sort of streaming of game content and and that kind of stuff too to help um help address this problem of like hey if you want to play a game you probably don't want to download you know all of those assets again like even just checking if it's fresh could be could be expensive right that makes sense there was a question oh yeah sure okay so the question is about the binary ast proposal just so everyone hears okay so what is the status of the binary est proposal at dc39 and what is your stance on it for both of you so i don't know you can probably talk to the state but my personal opinion on it i think it would solve some really hard problems that we currently face in the javascript land but um for every new thing that we add it also adds a lot of new problems that we then have to solve as well so while i i'm generally in favor of it um i'm not the expert there so i i leave it to the expert to decide and maybe brian has a better opinion i'm also not an expert on on this um so the the basic idea of this proposal is um what if we instead of shipping javascript source code to browsers what if we shipped some packaged binary that includes that source text but also additional information that is sort of shoved up front so that engines don't need to scan over all of your code and collect all this information about like what variables have you captured and you know are using eval in this scope and all of this uh sort of information that our runtimes need to produce optimal code it's a great idea like there are i i definitely agree that this is an actual problem like this addresses like the goal of this proposal is to address that parttime bottleneck that many of you with massive code bases are feeling you know it can take seconds to parse javascript on mobile devices on some big properties so like that is not a good situation but in terms of difficulties what i what i'm really interested to see is how this proposal will handle um all of the different kinds of information that engines need to collect because we all actually collect slightly different information because we just have different implementations and different tradeoffs so i think this proposal will only work if it is a sort of superset of all of the information that all of the implementations need to collect in order to produce optimal code i'm not super convinced that that's possible but i i think mozilla is going to work on a prototype and once that prototype comes out i think we'll know a lot more about how feasible this idea is and what's the current status of the proposal is it at stage zero or one um it's probably stage one i don't i don't remember off hand it's really easy to get to stage one stage one is yeah we agree there's some problem here and there's definitely some problem there so let me let me say one thing there will be a session in the deep track by my colleague maya on the browser so that would be an ideal question for that session oh yes okay and with that i'd like to thank you for your cooperation during this debate oh such a debate such a debate yeah it sounds like you agree about a lot of things you