hey this is Andrew Brown over here on free cocam bringing you another free Cloud certification and this time it's the hashicorp terraform associate version three and the way we're going to achieve certification is through lecture content HandsOn labs and as always I provide you a free practice exam and so at the end of the day you're going to get that certification and you could put it on your resume on your LinkedIn to demonstrate that devops skills and try to go get that cloud or devops role you've been looking for or trying to upgrade to so if you like the materials here a great way to support more content like this is to look at the paid additional materials it will also help you increase the odds on your exam and it also really does help out and support the production of more of this kind of content and if you are not familiar with me I produce a lot of different kinds of cloud certification courses like AWS Azure kubernetes you name it I've taught it and so you're in really good hands and we'll see you in class soon ciao foreign everybody it's Andrew Brown and welcome to the start of our journey and we're asking the most important question first which is what is terraform and I just want to tell you that I'm on screen now but I'm going to vanish here shortly and stay out of the way so that you can see the full content but I just wanted to know you to know that I'm here with you the entire way okay so the terraform associate certification is a specialty certification in terraform terraform is a technology produced by hashicorp and it's specifically for infrastructures of code and it's a declarative infrastructure as a code and it's a cloud agnostic infrastructure as a code we will dive into all of this in great detail in the introduction section and just notice that I put an asterisk there on declarative because there is something special about terraform that we will discover if you are considering the terraform associate then you most likely are looking for a devops role you want to automate infrastructure or writing scripts you want to work with multiple Cloud providers or you know you enjoy designing iterating on endtoend infrastructure life cycle so if this sounds like anything that you are interested in then you would probably want to take this certification I want to tell you that terraform is one of the most indemand skills for devops rules today and it's becoming quickly the industry standard just because it is so flexible and works with all providers and goes beyond a lot of these other tools and the terraform associate exam itself isn't that difficult uh but I would say that the concept of learning terraform is a bit tricky because uh you know it's not something that you can just go do the lecture content uh and and do the lab content I had to do a mix of it uh so in this course you'll see me do lecture lab lecture lab because I'm trying to solidify the knowledge as soon as we do that this is not the format that I use for my other courses it's just because with terraform it requires patience it is a silical learning process to understand so just uh stick with it and by the end of it you will be really good with terraform uh you know and so that's that there so let's talk about our multicloud roadmap I'm going to get out of the way so we have a little bit more room um and so you know what I would recommend uh is that you start with an Associate certification so just getting my pen tool out here uh if I can get it here here we have the Google's Ace um the cloud engineer or maybe some level of AWS uh associate certification I personally think the sysops is the best pairing for terraform or the Azure administrator if you're going for Azure and quite possibly learning more than two would be very beneficial but of course whatever your primary provider you're using is where you're going to benefit with uh terraform and you really should learn this stuff before you do terraform it is super hard to learn both cloud and terraform at the same time you should have that Foundation before you tackle onto terraform and so there's a lot of different paths for multicloud and just to kind of give you an idea of all the different ways you can go you know you can go from associate to either Vault and to the Vault professional if you're looking at a security background but it's very common for people to get the terraform and then go for uh Vault afterwards but you know it's up to you to which path you want to take how long do you have to study to pass this exam well uh it's a spectrum based on where your background is so let's take a look at beginners first so a beginner to me would be someone that's never written IC uh they have not previously focused on automating infrastructure they might may not hold an associate level certification so you're adding those additional hours or trying to make up the difference you could be looking at 30 hours or more if you're already experienced with writing IAC but maybe just not terraform maybe you know Azure bicep or cloud formation you already work in devops you're already comfortable writing scripts and you hold associate level certification knowledge of you know a major cloud provider then you're looking at something like 12 hours but you know if you're looking for a general study guide somewhere in between I would recommend between one to two hours a day for 14 days and you'll be in a really good place by then you know what does it take to pass this exam well there is a lecture content and I have a lot of it um you know the thing is that the exam itself is very practical it's not like AWS aws's exams where it's very um uh Theory based at a conceptual level this one is very much how do we use this technology and so the lecture content is there to really support the lab content and you really really need to do the lab content uh because that's the nature of this exam um and to make this a lot easier I do recommend taking some practice exams we have a free practice exam and we also have uh many more practice exams if you take all these Pax exams and you've done the labs prior to that you're going to be in really good shape to pass in terms of the content outline um I can't remember how many domains we'll see how many there are but we have one so understand infrastructure as code so I see Concepts understand the purpose of terraform understand terraform Basics the use of terraform outside core workflows interact with terraform modules use the core terraform workflow Implement and maintain State regenerate and modify configuration and understand terraform Cloud capabilities so yeah nine domains uh something that's different about uh the hashicorp certifications is they do not provide distribution of domains what do I mean by that well they're not weighted right so it's not like uh we know that uh like eight is I'm going to have a particular weighting that's higher but we can look at the exam guide outline to see generally how many questions we probably would so we could kind of infer our own waiting but they do not provide it so I would just say it's not known but we'll take our best guess when we look at the full exam guide outline where do you take this exam well you can take it in an inperson test center or online from the convenience of your own home I do believe that the test center that hashicorp is using is PSI or PSI online and understand that this is a proctored exam so someone is supervising you watching you monitoring you as you take the exam so that you uh that there's no funny business happening there's no cheating and to ensure that uh you know that you gain gain that knowledge in a reputable way so just understand that in terms of the grading you need to get about 70 percent to pass or round that it uses scaled scoring uh is it possible for you to fail if you've got exactly 70 percent it might be so always aim to get higher than 70 percent um and so I always say aim for a target of you know 10 to 15 above what the score is if you're getting that on your prax exams then you're going to be in good shape in terms of the response types they don't tell you exactly how many questions there are but I've always observed there's 57 questions and so you know based on that calculation I feel that you have 70 17 questions you can get wrong there are no penalties for wrong questions so always answer your questions do not leave any blank the format of the questions is multiple choice and multiple answer and then sometimes you get a fill in the blank so type a one word answer most likely it's going to be a command right so or a flag for a command so you definitely have to know the technical components of terraform okay the duration of the exam is one hour so that means you get about a minute to answer per questions the questions are very short format so it's not like you have to read a ton of text to figure out what's going on the exam time is 60 Minutes the seat time is actually 90 minutes so when we say C time referring to the amount of time you should allocate for the exam so that means that would include things like time to review the instructions show uh show the online proctored your workspace to make sure there's nothing going funny on with your environment read and accept the NDA complete the exam provide feedback at the end and I'm going to tell you you really do want to get for your exam much sooner than you think because it is a very stressful process and things tend to always go wrong when when you uh when you don't show up early enough okay so just make sure you do that if you do pass this exam it's going to be valid for 24 months so that's two years before recertification and the last thing I just want to talk about is um well maybe not the last thing I got two more slides here for you but this course is going to be designed around the 1.1.6.0 specification of terraform and even when I'm making this course as of today 1.60 is an alpha this will be in the future so 1.60 will be out but I like to try to give you more knowledge in the future even if it's not an exam just so that you are prepared and this course does not go stale sooner terraform is always incrementing inversion so you know when you study you always want to go back three minor versions since I'm showing 1.60 it doesn't make a whole lot of sense but if you're let's say you're on 1.54 you'd want to do one you want to make sure you know terraform for a range of versions going a few versions back and so so you know I will be showing you things that may be deprecated but are still uh but might still be in use based on the version that people are using so just understand that um and again you know these these certifications are or the terraform certification is heavily dependent on your practical knowledge so if you are taking the time to apply the knowledge uh this version difference differencing is not going to make a big difference okay um so just make sure you know you put the time in with the labs um now this is the third version of the certification and so I just kind of want to tell you that not a whole lot has changed between version zero zero two and zero zero three uh the one of the big differences is they change the badge design why I don't know uh is it better who cares um but uh it is a different looking badge um one thing is that there were superficial name changes to the outlines of the domain so basically all the domains are the same they just kind of did some tweaks there they did kind of cut some content out in the uh the like first uh first first two domains because those ones were just more General concept of knowledge and so they slim those down I'm leaving that content in this course because I think it's very valuable to know more rounded knowledge there so you're going to be over prepared for those first two domains there used to be this thing called provisioners it's still in terraform but the thing is that it's just no longer needed to know in the exam so this is about doing remote execution annoying all the provisioners and so I mean local execute and remote execute are things you need to learn and definitely something that you will use on the job but knowing how to provision and use a lot of Provisions is no longer a focus there there's this thing called null resource that we learn about and now they have a new thing called terraform data so that is a evolution of terraform data so we'll still learn about null resource but we'll also learn terraform data where it makes more sense to use uh you know terraform Tate had taint has been replaced with uh just a flag uh called hyphen hyphen uh uh replace uh on the terraform plan and we have a few more others like that so refresh has a flag um and uh the thing was is that when I made this exam the first time they were already talking about doing this so This exam is already um my previous one is up to date with the current version of zero zero three if that if that's surprising here uh terraform workspace is no longer part of the exam um I would still cover terraform workspace uh you know if we come across it because I still think again it's practical knowledge that you should know um connecting to terraform Cloud now uses its own cloud block instead of remote block um I believe that we can still use remote block here and I will definitely test that in the in the um in the uh the labs in this course so you know it's good to know both of them but the focus will be using uh Cloud block um we have the lock file so the lock.hcl files are new um I mean they weren't new when I made the previous exam so they were already in there so again I already had this content here um but I'm just pointing out that that's something that they're focusing on uh within the certification here um you need to know how to Mark data as being sensitive again that's something I had in the older exam but one major thing is terraform cloud has a new UI and it looks like there's a lot more functionality so in terms of the old exam or a course that I produce and this one I'm definitely going to have to reshoot all of terraform cloud and go deeper into it there's obviously a few different functionalities that have been added like the terraform Cloud block the terraform data block um but you know for the most part there's not a whole lot that has changed so the majority of this will be very similar to the last one but I'm just touching up and improving lab content where we can and hopefully adding a lot more additional content to expand the terraform knowledge that I wasn't able to do the first time around so hopefully that gives you a good idea of what you're getting yourself into uh but yeah we will proceed forward to looking at the exam guide foreign Brown and welcome back as we are taking a look at the exam guide uh for the hashicorp terraform associate certification I want to tell you uh throughout this course I'm going to show you where I get things so I will be going to Google I will be typing in where things are it's not because I don't know where things are I'm doing that for your benefits so that you build up the skill to know how to find things just the way that I would go find things and I'll be very transparent about that so for this one all I did was go into Google and type in terraform exam guide and so I found it here this is also the place where you can register for the exam so if you click this it should load up certain metrics I'll make a popup you have to authenticate it I'm not showing that here right now but when you are ready to register for the exam you can go ahead and do that you'll notice they also have this button here called prepare for the exam they have their own study guide here it's very text based heavy I do believe that somewhere in here there is a way to launch tutorials and this will launch sandbox environments I think through instruct at least the last time I checked those are great if you don't have an environment set up what I want to do with you is I want I want you to set everything up in your own environment because I want you to have those Real World skills so you can use this stuff adjacent to this course I've gone through all this material here I'm trying to cover things that aren't in here and try to make sure that we are doing things without guard rails without the bowling bumpers because I want you get that Real World Experience okay but I do want to point out that this is here and you can use it um and it's okay so let's scroll down and take a look at our exam guide here and so here they say we have some prerequisites so they say basic terminal skills that makes sense we're going to be doing a lot of stuff uh in terminal basic understanding of onpremise and Cloud architecture uh I think what they really mean is do you know how to use AWS you know how to use Azure gcp what is your major uh cloud provider or or stuff like that um now I keep talking or focusing on AWS Azure gcp but understand that terraform can be used for anything as long as there is a provider for it it can provision on almost anything okay and that's why they're being very generic in their description this says the product version tested is terraform 1.00 and higher so it shows you that this is still even though it's the zero zero three it's still really the zero zero two exam with some minor tweaks but just understand in this course we're going to go well beyond this because I'm just future proofing you and making sure you have Real World skills let's scroll on down here and let's just it's about renewing your certification so if you hold an unexpired terraform associate 002 certification uh you can take the new one starting 18 months after your previous exam if you hold an unexpired one you can take the new exam starting 18 months after your previous exam uh if you hold an expired one you're eligible to recertify at any time I really like this because what happens for me with certifications not a problem for you but problem for me is that I will sit a certification and then nine months later the new one comes out and I can't sit the new one and tell you about it so it looks like we've gotten a bit of flexibility there and again I'm on video here I will get out of the way um it's just that we're in the uh these earlier videos and I want to just hang out here with you okay going down below we can confirm it's the one hour duration this is seventy dollars it might vary based on your location and other stuff you I just don't want to tell you that 70 I want you to go through the process and find out yourself but that's probably what it's going to cost you um there is no free retake included um some certifications like CompTIA you are basically or uh the kubernetes ones from looks Foundation you basically get a retake so you're basically paying a love for two and they call it a free retake which it really isn't free but uh I think this is okay um I think it's fine there's no retake it's in English expires in two years we covered that before let's take a look at the exam objectives so the first one is understand infrastructure as a code and Concepts they used to have a bunch of junk in here um and honestly I didn't even know what they were talking about when they said that I remember I had to comb through uh the study guide and try to watch uh articles and stuff like that but I think they realized that it was junk uh that they were trying to uh impart too much conceptual stuff and they cut back this one here same thing with two it doesn't show us the comparison of the old one at some point on this website they showed the comparative between zero zero two and zero zero three but all I'm saying is that they cut back here I have a bit more content on this in the course it's not going to hurt you to watch it it's just going to help you understand it but you're not going to be tested 100 on this stuff the other thing I want to note is that for each point that is here each subdomain or or Point whatever you want to call it they're going to ask you a question on this is very different uh way of Designing uh an exam uh other exams like AWS they will they will list a bunch of stuff but they say it might not be on the exam or it might have stuff that are that's outside of it so you just have to broadly study and uh you'll over over study for the content because you just don't know what you're going to get uh get on the exam for hashicorp exams they're very fair if you know each of these points you can expect to see them generally on the exam and that's how you're going to know that you are ready if you if you know all these things in this course we're going to go beyond that because again I want you to have those Real World skills but just feel confidence in knowing every single point Point here going down here understand terraform Basics install and version terraform providers so that is what we will be doing a lot of in this because we're going to at least touch more than one provider in this course I'm not going to go in great detail on uh the cloud infrastructure part of it because you're already supposed to know it um and I'm going to leave that for other things doing future projects for specific uh for for specific Cloud providers we're focused here on terraform in this course not the underlying providers but we do use multiple ones here describe plugin based architecture write terraform configuration using multiple providers describe how terraform finds and fetches providers so you can see there is a a lot of stuff about providers not to be confused with provisioners I said earlier that provisioners is no longer covered in this certification course but again the materials here so you can learn it for real world practice use terraform outside of core of core workflows I think this used to be like you use terraform CLI outside of core workflows so they made a small tweak there so it says destroy describe when to use terraform import to import existing infrastructure into your terraform State terraform import is super super powerful going over to other providers uh you know for a long time AWS did not have an import option and so the idea is that by having this import we can bring an infrastructure that was not necessarily there before we have terraform state to view our terraform State something that you're going to find unique to terraform is State Management it's something that's super important and it's probably the hardest Concept in terraform because when you use something like cloud formation or Azure bicep the state is managed by services on those providers there isn't a managed service managed service on those providers and so you have to decide where you want to put your State uh and one example would be terraform cloud and that's one that we do use in this in this course here describe one to enable verbose logging and what the outcome is so you have to know how to debug things here which is great interact with terraform module so contrast and use different module Source options including public terraform module registry interact with modules inputs and outputs describe variable scope and module child modules set module versions modules is a way of creating reusable code uh we are going to use uh public libraries as well as uh make our own modules making modules is not as hard as you would imagine but they can get very complex uh so you know we're not going to go super Advanced into modules but we are going to make sure we can write our own and and use public ones use the terraform uh use the terraform workflow so this is something we're going to have to know a lot about which is just the general life cycle workflow of working with infrastructure as code so we have a knit validate plan apply destroy format plan it apply are the ones we're going to be using a lot of there is a lot of trickery with the init so that's something else that we'll do there as well Implement and maintain state so maintaining State working with State super super important so we'll look at how it works with local state state locking handling backend Cloud Integrations authentication methods uh you know they're talking about managed providers like terraform Cloud the different between remote State backend options manage resource drift and terraform State terraform is super good at drift and fixing drift it's so good at remediation compared to other IEC tools and that's why it is such a popular tool to use describe backend block and Cloud integration configuration understand secret management and state files then we have regenerate modify configuration so demonstrate the use of variable variables and outputs describe secure secret injection best practices understand the use of collection and structural types create and differentiate resource and data configuration use resource addressing and resource parameters to connect resources together use HCL and terraform functions to write configuration describe builtin dependency management and the last one here is understand terraform Cloud capabilities so explain how terraform clouds helps to manage infrastructure describe how terraform Cloud enables collaboration government governance I'm going to tell you right now we're going to probably do more terraform Cloud than we we need to it's just because when I made this course the first time I I just lightly did terraform Cloud just enough to pass the exam I have the time to do a little bit more there I would like to do that for your own benefit and so we will expand on that a bit more but you can see this is mostly about terraform the technology not necessarily terraform Cloud the uh the service if you're confused about terraform and terraform Cloud uh again we'll explain that in this course and make sure it's very clear what the difference is one other thing I wanted to notice that you do have some sample questions here so you can go through here and you can just see that the questions are very straightforward and they're just like this they're very simple uh but you know you do have to know you do have to know what you're looking at and see like here they're showing code so you can see you have to choose code and you might get a code block so it is very focused on the Practical component of it it's less about the conceptual okay but yeah hopefully that gives you an idea of what we're getting into and we'll see in the next one okay ciao foreign hey this is Andrew Brown from exam Pro and what I want to do is walk you through a few of our practices and questions just to give you an idea of what it will be like on the real exam and where we might have had to make some adjustments to help your study so what you'd have to do to access this prax exam is you'd have to be signed up and logged in to the exam Pro platform make a way over to the hashicorp terraform course except the free tier or pay for full access but once you go there you'll scroll all the way down to the bottom and you should see three or four products exams at the time of writing this we're still writing the questions so that's why they're not shown in the video here but what I want you to do is to go to the first practice exam and notice that there are 57 questions you get an hour on on the exam here and we have a breakdown based on domain now the percentage is not something that uh terraform or hashicorp provides so we just had to break it down based on the coverage of questions that we saw in the exam guide outline and so that should be accurate enough and that's kind of what it felt like on the exam so I don't think that's going to be a problem if we click into here we're just going to look at some of the questions I'll talk around them so the first one here is we have how do you create a workspace and it's showing us a bunch of CLI commands and so on the exam you do need to know um uh you know CLI commands and the difference of them and the questions can be as simple as this where you're just choosing the option and some are obvious distractors like there isn't there is no one called terraform workspace Branch okay so just understand that you not just need to know the conceptual ideas behind terraform but also it in practice okay another one here would be the terraform registry can search based on the following Search terms we have an option to choose multiple questions and so this is something that you will see on the exam where you're choosing multiples of something I didn't get a lot on my exam but I cannot say for certain like how many questions would show up like this um but you know they're not really that hard to figure out okay and this question is about um a tool or sorry uh the public terraform registry website and that is just a uh a publicfacing website if we go to registry.terraform.io here it's this website here so it's not just the tooling of terraform itself but it's the ecosystem around it so terraform Cloud the terraform registry things like that another type of question you will see and I think it's over here is what they will do is they'll ask you to fill in the blank now we don't have that support in our platform just as of yet but the idea is they'll say like okay uh we'll ask you a question or we'll even give you um maybe they'll have like underscores they'll say fill in this thing and you'll literally have to type type the answer in but the answer is going to be like a one word answer so on the exam I literally had a question which was like where is the API stored and it was actually terraformed at TF state but I did not know I could not recall the name of it which is kind of embarrassing but uh you know that is the level of fillins that you'll have to do and you're very likely to see some code on the on the exam two so if I just click through here really quickly you may see a code block okay and you might have to decipher it so that's the difficulty exam I would not say this is a heart exam but you just have to understand the scope of those kind of questions and make sure that you have wellrounded study in both practical and conceptual concepts of terraform so hopefully that helps you out okay everybody there it's Andrew Brown and I just wanted to tell you about the content that you're going through because honestly between the zero zero two and zero zero three there was not much to update um and so you know the key differences is the versions of terraform and the versions of the providers that you are using um and for the most part everything worked out perfectly fine I thought that I'd have to reshoot all of the lab content but it turns out nope barely nothing has changed what has changed and I want to point this out early on is that when you are specifying a version for the provider just go use at least version five zero you can use an older version if you want to follow along but uh you know I think it's better to be more um up to date if you can the version that we were using prior in the follow alongs was version three again there are no major changes that will break anything um so at least there shouldn't be but I ran through these Labs my cloud support engineer ran through these Labs so we're pretty confident you're going to be in good shape otherwise if they weren't I would go rerecord them but I just wanted to point out those two things uh there so hopefully you know that makes sense and you're going to be in good shape okay now I did say that we're scoping things around terraform 1.6.0 and again there's not much to call out for that the biggest thing that I think that 1.6.0 might bring would be testing and even if I looked into it and it just wasn't where I thought it was going to be so I did not include it at least at this time in uh this uh this this course and again this is me going uh above and beyond because I'm trying to just future proof the contents of this course and future proof uh stuff that I believe that is coming to terraform form but yeah you should be in good shape and you know if there are any changes on exam Pro we're very proactive of having those differences there so if you do run into anything that's giving you any kind of issue they're going to be on the the main learning platform there okay if if for whatever reason there's minor updates or things that are found out but yeah you'll be in good shape and have fun on your journey learning terraform ciao hey this is Andrew Brown from exam Pro and we are looking at what is infrastructure as code and before we talk about that we need to talk about the problem with manual configuration so manually configuring your Cloud infrastructure allows you to easily start using new cloud service offerings to quickly prototype architectures however it comes with a few downsides so it's easy to misconfigure a service through human error it's hard to manage the expected state of the configuration for compliance it's hard to transfer configuration knowledge to other team members and so this is why infrastructure code is going to really help us out so infrastructure is code commonly abbreviated to IAC and you'll see that a lot in this course allows you to write a configuration script to automate creating updating or destroying Cloud infrastructure notice I gave great emphasis on automate or automation because that is really key to infrastructure as code IEC could also be thought of as a blueprint of your infrastructure IEC allows you to easily share version or inventory your Cloud infrastructure and just to kind of get your visualization imagine you write a script and that's going to provision and launch a bunch of cloud services that are all interconnected okay all right so we're taking a look at popular IAC tools and so of course this course is about terraform but by understanding um all the options out there if you understand why we're using terraform uh and one thing that is very important to understand is the difference between declarative and imperative IAC tools those are the broad categories that we see for IAC so let's start with declarative so the idea here is what you see is what you get everything's explicit it's more verbose but there's zero chance of misconfiguration and this all relies on the fact that they use a scripting language such as Json yaml XML in the case of terraform they have their own language called HCL but the way these languages are structured is that they're very verbose and there's not a lot of programming logic involved so for Azure we have arm templates and Azure blueprints for AWS we have cloud formation for Google we have Cloud deployment manager and there there is of course terraform which has many cloud service providers such as AWS Azure gcp kubernetes and a lot more but these are all in the declarative category on the right hand side we have imperative so you say what you want and the rest is filled in everything here is implicit it's less verbose but you could end up with misconfiguration and when I say that it's that like if you were to find um let's say a virtual machine you might not have to provide every single uh option that you would normally do and it would fill in the rest but if you weren't aware of what it was doing that's where you could end up with misconfiguration uh though I would say that imperative tools generally try to always uh have their defaults as best practices so you're not usually in a bad position uh but you know you might end up with something you don't expect imperative can do more than declarative so there's just some very hard limitations with declarative languages so there's just cases where you want to do imperative and the idea here is imperative languages use programming language you know like python Ruby JavaScript golang you know whatever it is uh there's likely an SDK for it and so it's just a lot more programmer friendly a lot of developers like imperative tools so AWS has their own called Cloud development kit cdk and it technically only supports AWS I say technically because hashicorp has a very cool library that allows you to generate out terraform HCL files which allows you to work with anything but when we're just talking about cdk on its own it's just for AWS then you have plumy it supports AWS Azure gcp and kubernetes so it can do a lot so why would you choose with your team to use declarative over imperative well it just really depends on your your team right so like if they're all used to if they're all administrators and they're used to using Json yaml and they're not good with programming languages that is one reason why you might want to use declarative over imperative the other thing is just you know you prefer to know exactly every single thing that was defined right you don't want anything left up to a chance and so that is another reason why you might want to use declarative but both are great options it's just really depends depends on your team's knowledge and what your goals are okay so we just looked at imperative and declarative but I just want to clarify that terraform even though it's a declarative language it has imperativelike features so I've coined the phrase declarative plus and so terraform kind of gives you the best of both worlds so you have declarative and imperative and then the three types so our yaml Json XML we have terraform language which actually utilizes HCL underneath and then you have programming languages on the right hand side like Ruby python JavaScript what it have you right so when we're looking at yaml or Json these are very limited languages or scripting languages where uh you know you don't really have any kind of complex data types you probably don't have a whole lot of robust functions but in some cases you can extend That Base Behavior so in the case of cloud formation which uses yaml or Json files they have a concept called macros so you can extend it a bit but again it's very inflexible and so a lot of people are led to go and use cdk so terraform is great because it kind of has a lot of stuff you'd see in programming languages like for Loops Dynamic blocks locals it also has complex data structures and a lot of functions around using those data structures and so it allows you to stay in that declarative world but having the stuff that you generally need when you're in the parative world when you're in the imperative side the idea is that the language is what you're utilizing so you can do anything that the program language allows you to do but I just wanted to kind of show you that terraform sits in the middle okay hey it's Andrew Brown from exam Pro and we are looking at infrastructure life cycle so what is infrastructure lifecycle it's the idea of having clearly defined and distinct work phases which are used by devops Engineers to plan design build test deliver maintain and retire Cloud infrastructure where we're talking about like sdlc so software development life cycle there's usually a really great visual that I can show for you but for infrastructure lifecycle especially Cloud infrastructure lifecycle there isn't something that is well defined which is weird by the definition but I think that there's just nobody's agreed up on one yet or nobody's made the graphic yet so I just don't have anything to show you for that but I just want you to get familiar with the term infrastructure life cycle because you're likely to hear it again but one particular infrastructure life cycle that is pretty common is ones that talk about day zero day one and day two so the idea here is this is a simplified way to describe phases of infrastructure life cycle so when we say we are on day Zero we are planning and designing our infrastructure on day one we are developing and iterating it so we might be uh you know deploying or provisioning it and actually testing it uh in the cloud and then day two is actually when we go live with real production users and maintain it and the idea of mentioning day zero one and two is to say Well when does IAC start and the idea is it starts on Day Zero okay the days do not literally mean a 24 hour day it's just a broad way of defining where in the infrastructure project we would be okay so after defining what infrastructure life cycle is what advantage or what an advancement are we going to have when we add IAC to our infrastructure lifecycle well the first thing we're going to get is reliability so IC makes changes impotent consistent repeatable and predictable I'm going to give extra attention here to impotent because it is a very strange English word but no matter how many times you run your IC you will always end up with the same state that is expected that is a very important concept of IEC whereas if you use configuration management there's no guarantee of that that's why you use terraform over something like ansible okay you have manageability so enable mutation via code revise with minimal changes and then you have sensibility so avoid financial and reputational losses to even loss of life when considering government and Military dependencies on infrastructure so there you go okay so it impotent is a very important concept to infrastructure as code and so we're going to give it a little bit more attention I wouldn't stress out about the pronunciation uh there's more than one way to pronounce it in English and I've probably even said it wrong uh in the previous slide so uh just be uh forgiving on that part okay but the idea is that let's stage a scenario between a nonitipotent example and an independent example so when I deploy my IAC config file it will provision and launch two virtual machines that is what I'm expecting okay and that is what I get but what happens when I go and I update this infrastructure code file saying maybe I want to increase the size of the VMS or some of the configuration I deploy that again when it's nonedepotent what will end up happening is I will end up with two additional virtual machines with the new configuration and the old ones will be there and so this is something you might not want because you just want to have a file that says exactly the state that you expect okay so when we have something that is Idi potent the idea is we will go and we will Define our two virtual machines and we will get our two virtual machines but we go and we update that file and we deploy again and what happens this time is it just ends up modifying the original virtual machines or if it really can't and it has to it might delete them and recreate them but the idea is that we end up in a state of exactly what we want so in the first case we expect it to but we ended up with four but with the independent uh case we expected to and we always end up with two so hopefully that makes that very clear okay hey this is Andrew Brown from exam Pro and what I want to do here is concretely Define the difference between provisioning deployment and orchestration now in practice sometimes these have overlapping responsibility so you might say provisioning when you really mean deployment or vice versa it's not a big deal uh we all get kind of mixed up about it but I did want to just take the time to make sure that we understand what these things are supposed to mean okay so the First on our list here is provisioning so to prepare a server with systems data and software and then make it ready for Network operation if you're using a configuration management tool you are most likely provisioning because that's what these tools do so puppet ansible Chef bash scripts Powershell or cloudnit so you can provision a server when you launch a cloud service and configure it you are provisioning it okay then you have deployments the deployment is the act of delivering a version of your application to run a provision server deployment could be performed via AWS code pipeline harness which is a thirdparty deployment tool Jenkins GitHub action Circle CI there's a lot more other providers out there then you have orchestration so orchestration is the active coordinating multiple systems or Services orchestration is a common term when working with microservices containers and kubernetes so orchestration could be done with kubernetes salt or fabric so if you're working with containers generally like you use the word orchestration especially with kubernetes because you're working with thousands of microservices okay so you know hopefully that helps you know the difference between the three again it's not a big deal if you don't perfectly know them but there you go hey this is Andrew Brown from exam Pro and we are taking a look at configuration drift so this is when provision infrastructure has an unexpected configuration change due to team members manually adjusting configuration options malicious actors so maybe they're trying to cause downtime or breach data or side effects from apis sdks or CLI so you've written some code that uses a CLI and a bash script and it does something you did not expect to happen so here an example could be imagine you have a server like a database and a junior developer turns off delete on termination for your production database this could be a problem where let's say there's an accidental deletion of the database this feature would protect the database from deletion but if it's turned off you don't have that right so configuration drift going unnoticed could be a loss or breach of cloud services and residing data will result in Interruption of services or unexpected downtime so there's a lot of downsides to to neglecting or not noticing configuration drift so what can we do about this so how to detect so there's three things detect um we can fix it and then prevent it okay so to detect configuration drift if you have a compliance Tool uh it can detect misconfiguration so it was config can do that as your policies can do that gcp security health analytics can do that some of these are constrained to security things not just configuration in general but there are tools there for all the cloud service providers there is builtin support for drift detection for it was cloud formation it's called cloud formation drift detection other providers don't necessarily have that if you're using terraform which is this which is all this course is about you have the terraform State files which says what the state of things should be so that's how you could detect configuration drift how to correct configuration drift well compliance tools can remediate so again it is config you can create a custom Lambda to say hey when this happens then do this so set the configuration back into place with terraform you can use the refresh and plan command which we'll look at in detail in this course or you can manually correct it so if the option was changed you could do that not recommended to do that another thing would be tearing down and setting up the infrastructure again because that would bring it back into its original state that could be a risky thing to do depending on how you have things set up or could be it could be fine right then there's prevention so um this is a the important thing and kind of why we're talking about configuration drift which is all about immutable infrastructure so always create and just destroy never reuse so that might be blue green deployment strategies servers are never modified they are all they're just always deployed with a new version the way you would do that would be baking Ami images or containers via AWS image Builder or hashicor Packer or a build server like gcp Cloud run or code build like AWS but the idea is that you're not modifying after they're deployed you'd have that image already ready to go another thing you could use is git Ops so you would Version Control your IAC like within GitHub or something like that and you would peer review every single uh change the a pull request to the infrastructure so hopefully that gives you an idea of things we can do to tackle configuration drift okay we were just talking about immutable infrastructure but I just want to give it a bit more attention here so the idea is um we are going to first develop our infrastructure as a code file terraform cloudformation what have you and then we're going to go ahead and deploy that so we'll end up with our own virtual machine and that virtual machine needs to be configured so you need to install packages and things like that that's where Cloud init would come into play ansible puppet Chef salt whatever configuration management tool you want to use the problem here is that there's no guarantee that that configuration is going to stay in place so that's where immutable infrastructure comes into play so we develop our infrastructure as a code file terraform cloud formation and then we're going to go ahead and do our configuration by building a virtual machine or building a container so we can use something like Packer and then the idea is once we are happy with our configuration what we're going to do is bake that image and put it in an image repository and then that image is going to be referenced when we do our deploy and so that's going to make sure that our infrastructure is always immutable okay hey this is Andrew Brown from exam Pro and we are taking a look at the concept or methodology of git Ops so this is when you take infrastructure as code and you use a git repository to introduce a formal process to review and accept changes to infrastructure code and once that code is accepted it automatically triggers a deploy and changes that infrastructure so here's my illustration through it so the idea is you would have a terraform file and you would place that in something like GitHub you would apply your commits and when you're ready you'd make a pull request you would merge that pull request into the main branch or whichever branch is set up for production and that could trigger something like GitHub actions and GitHub actions would then trigger a terraform plan and and accept it or maybe you have to manually intervene to say Okay I accept these changes but then it would roll out those changes now terraform does have their own and it's pretty darn similar but I thought mine was a bit easier to read but the idea is you have your git repository you have your pull request this is pulling from terraform Cloud because you can have files and state managed there so that is another means to do it but that's generally how it works okay foreign so we were just looking at immutable infrastructure but what I want to do is just kind of cement in your head things that you should be asking yourself as a devops engineer so that you kind of lean towards that immutable uh kind of way of thinking and so this is mostly going to be applicable for virtual machines but let's just ask some questions of things we should be thinking about so what's going to happen if we deploy our virtual machine and there is a physical failure of the hardware by the provider so this can sometimes happen on AWS where they have two status checks that have to complete before a virtual machine is ready sometimes they fail and so you know your infrastructure is not ready to graded or damaged right then you have application failure so you have this post installation script maybe to install your application and there's either a bug so introduced by developer or maybe there's just a dependency and it's changed and so it's breaking your app what happens when you need to deploy in a hurry what have happens in worst case scenarios where you have accidental deletion compromised by malicious actor need to change regions maybe there's a region outage and so the thing is is that when you look at these things what happens when multiples of these happen at the same time because that's the problem where you know it's like okay I have something wrong with my application code but I also have uh you know now we also have a region down and so you don't want to be dealing with more than one problem at the same time and so that's we're going to have an issue of agility in terms of deployment another thing that is overlooked is there's no guarantee of one to one if you are configuring your code after deployment because if you were to deploy a virtual machine and installed all the dependencies and then you to were to deploy a virtual machine literally a minute later one of those dependencies could have a minor revision and so that would be deployed with that one minor revision so they would look very similar but they aren't one to one so by introducing golden images which is an immutable infrastructure idea you get a guarantee of one one to one with your Fleet you have increased Assurance of consistency security you have you can speed up your deployments the reason why you have an improvement of security is because at that stage you could um you could perform kind of Security checks and things like that there on that image before you roll it out so I don't know um I would just say that I would recommend that you go with the immutable infrastructure or baking your images when you can if you're using VMS okay hey this is Andrew Brown from exam Pro and we're going to take a look here at what is hashicorp so hashicorp is who creates terraform and they are a company specializing in managed open source tools used to support the deployment and development of largescale service oriented software installations and they have their own cloud platform called the hashicorp cloud platform hcp and it's a unified platform to access hashicorp various products so uh the main thing is that it's Cloud agnostic so hashicorp makes it really easy to build across cloud and they have support for all the three main providers so AWS gcp Azure I'm sure they have more support like kubernetes and things like that they're highly suited for multicloud workloads or crosscloud workloads and they have a lot of products that will help you out there so let's go through them quickly so first we have boundary this is secure remote access to systems based on trusted identity this is console this is a full featured service mesh for secure service segmentation across any cloud or runtime environment you have Nomad this is scheduling and deployment of tasks across worker nodes in a cluster you have Packer which is a tool for building virtual machine images that will be later deployed or they will place them in a image repository then you have terraform which is infrastructure as code software which enables provisioning and adapting virtual infrastructure across all major providers then you have terraform cloud and this is just a place to store and manage your IAC State files and things like that with a team or just in the cloud by yourself we have vagrant so building and building and maintenance of reproducible software development environments via virtualization technology we have Vault so secret management identity based access encrypting application data auditing of Secrets for application systems and users and lastly we have Waypoint a modern workflow to build deploy and release across multiple platforms so there you go hey this is Andrew Brown from exam Pro and we are looking at what is terraform so terraform is an open source and Cloud agnostic infrastructure as a code tool and terraform uses declarative configuration files and the configuration files are written in the hashicorp configuration language HCL and so that's what you can see on the right hand side we'll generally call it the terraform language which we'll talk about later but notable features of terraform are installable modules plan and predict changes dependency graphing State Management and provisioning infrastructure in familiar languages that's something you could do via AWS cdk so I wouldn't say it's core to terraform but that's what they listed on their websites that's why I put in there and terraform registry which has over 1 000 plus providers okay so there we go so we were just looking at terraform but what is terraform Cloud well it's a software as a service offering for remote State Storage Version Control Integrations flexible workflows and allows you to collaborate on infrastructure changes within a single unified web portal and this is all accessible via terraform.io and the first thing you'll have to do is create yourself an account on terraform i o but it's free to start with and they actually have a very generous free tier that allows for team collaboration for the first five users of your organization that's not part of the team's plan that's part of the free plan and in the majority of cases you really should be using terraform Cloud as your remote backend even if you are an individual just because you know it makes experience so much better the only case that you might not want to use terraform cloud is if you have a very large company that's trying to meet particular regulatory requirements and it's not that terraform Cloud does not meet them but sometimes there's just a long procurement process so in the meantime you would have to use something like standard remote back end or Atlantis or maybe you need to investigate terraform Enterprise I do want to note that terraform cloud and terraform Enterprise is the underlying software known as terraform platform it's not something you're going to ever have direct access to but just to clarify that terminology okay so what I want to do is just set you up with understanding the terraform life cycle this is not necessarily uh described in the documentation anywhere but it's something that is inherently known when you're working with terraform uh and it's definitely not uh inclusive with every single command that can be ran but the ones that you're going to counter most often so at the start you're going to be writing or updating your terraform configuration file okay and from there the first thing you'll want to do is initialize your projects and or if you need to pull the latest providers and modules you're going to use terraform indit to do that as well from there you're going to use plan so plan allows you to speculate what will change or generate a saved execution plan that you could use later on when you run plan validate happens automatically but you could also run this separately and ensures types and values are valid ensures the required attributes are present within your configuration file from there if everything is good you're going to execute your execution plan by running terraform apply you can also from this point use terraform apply to destroy infrastructure so if you have things set up there's actually a flag for it or you can use the Alias the terraform destroy command and then you know as you work you're just going to keep updating your code and that is the terraform life cycle so you know hopefully this gives you kind of a a snapshot of what the workflow will be and I mean we'll be covering it tons and tons of times over in this course okay foreign hey this is Andrew Brown from exam Pro and we are taking a look at change automation but to understand that we need to first talk about change management so this is a standard approach to apply change and resolving conflicts brought about by change in the context of IAC change management is the procedure that will be followed when resources are modified and applied via configuration scripts so what is change automation then it is a way of automatically creating a consistent systematic and predictable way of managing change requests via control and policies notice and I should have probably emphasized this is change requests saying I'm going to change these resources terraform uses change Automation in the form of execution plans and resource graphs which will look at detail those two things in upcoming slides and apply review complex change sets so a change set is a collection of commits that represents changes made to a versioning repository and for IEC uses change sets so you can see what has changed by who over time so when I say versioning repository that doesn't necessarily mean get and if you're using get Ops I suppose you could consider your chain sets being committed to that but something like cloud formation when you apply a change you actually have to accept a change Set uh and so the version repository is part of AWS and so um it will terraform you just kind of accept it in place it's not necessarily on your local machine but I guess reflecting your state file okay so change automation allows you to know exactly what terraform will change and in what order avoiding many possible human errors a change automation is essential to any IAC tool they all have it okay so there we go this is Andrew Brown from exam Pro and we are taking a look at execution plans so this is a manual review of what will add change or destroy before you apply changes and so let's say you type in terraform apply it's not just going to go ahead and do that it's going to have you uh type in yes or accept the value but what you can do is see the resources or configuration settings that will be added changed or destroyed and it will summarize them at the bottom and then you'll have to type something like yes in order to accept the changes okay something else I want to show you is that you can actually visualize your execution Plans by using the terraform graph command and terraform will output a graph of his file you'll have to have graph Vis installed but Graphics is an open source tool for drawing graphs specified in the dot language scripts having the file name extension of GV so I believe this is crossplatform it's open source but once it's installed in your machine you can run terraform graph and here this is Linux so we're using a pipe to say okay pass it over to graphis which is Dot and that is going to then create an SVG file you can just open that in your browser and the idea is you're going to get this graph which kind of shows you the relationship of the resources here but we'll talk about the these relationships in the next slide here which is a resource graph okay let's take a look here at the resource graph so terraform builds a dependency graph from the terraform configurations and walks this graph to generate plans refresh rate and more when you use terraform graph this is a visual representation or presentation of the dependency graph if you're wondering what a dependency graph is in mathematics it's a directed graph representing dependencies of several objects towards each other so it's pretty much like nodes with relationships between other nodes so that is one that I generate out from terraform and so there's a few different types here we have a resource node that represents a single resource a resource meta node represents a group of resources but does not represent any action on its own and provider configuration nodes that represents the time to fully configure a provider will you need to know this for the exam probably not do you need to know this in great detail probably not because there's a lot to the resource graph but the idea here is just kind of like terraform saying just so you know we're using a graph database and graph databases are very well suited for this kind of stuff and that's why terraform is very good at figuring out conflicts and things like that okay foreign from exam Pro and we are taking a look at terraform use cases and the idea here is not necessarily because it's going to show up in the exam but the idea is to give you a business use case or to highlight the features as to why you'd want to be using terraform and the first one here is that it has exotic providers so terraform supports a variety of providers outside of gcp AWS and Azure and sometimes is the only provider terraform is open source and extendable so any API could be used to create IC tooling of any kind of cloud platform or technology so you can make your own provider there's some interesting ones that they have like Heroku or even Spotify playlists I have my own platform called teacher seat and I want to have IAC for my platform and so this is what I'm going to be using terraform for for multitier applications terraform by default makes it easy to divide large and complex applications into isolate configuration script modules you'll notice in this course that when you have a bunch of terraform files they're all treated as one so that makes it really easy to split up your uh your projects or your your infrastructure so so it has a complexity advantage over Cloud native IC tools for its flexibility while retaining Simplicity over imperative tools then we have disposable environments this is not unique to terraform it's any kind of ISE tool but easily stand up an environment for a software demo or a temporary developer environment resource schedulers so terraform is not just defined to infrastructure of cloud resources but can be used to set Dynamic schedules for Docker containers Hadoop spark and other software tools you can provision your own scheduling grid and the last one here is multicloud deployment terraform is cloud agnostic and allows a single configuration to be used to manage multiple writers and to even handle crosscloud dependencies and that is a big deal and is a very unique offering to terraform okay let's take a look here at terraform core and terraform plugins so terraform is logically split into two main parts terraform core which uses remote procedure calls RPC to communicate with terraform plugins and terraform plugins so expose an implementation for a specific service or provisioner something that's interesting to know is just terraform core is written in go um you know you probably will never encounter it but it's just a fact okay and so here's the graphic that terraform uses to kind of like explain terraform core versus terraform plugins and how they all relate so here's the terraform core and here are the plugins notice we have providers here which will cover provisioners uh and there's just this is the group for plugins overall um but yeah that's about it we'll show up an exam probably not but it's good to understand from a top level view the split between these two things okay if you are new to terraform I just wanted you to be aware of an additional resource that you can use Beyond this course which is called terraform up and running so it's a a book and it has a deep dive into the internal workings of terraform and this is really great if you want to go beyond this course Beyond certification beyond the basics because what it will do is teach you about testing with terraform Cloud zero downtime deployment common terraform gotchas and compositions of production grade terraform code there's a lot more to it and this book in particular is written by Jim who's the cofounder of grunt work and we do have a whole section just on grunt work and the thing is I just want you to know about this resource you definitely don't need it to pass a certification or to have a good understanding or working of terraform but you know at some point you if you want more I just want to point you to that resource okay there's one other resource I want you to check out for terraform and this one is free and just online and it's the terraform best practices so it's an open book it's a get book so it's essentially a Wiki and it basically covers the best practices that are being used in the industry and so this is stuff that is separate from the terraform documentation it's just good practices you know if you're going to be using terraform professionally within the industry so I just wanted to make you aware of this resource and to go check it out okay foreign foreign hey this is Andrew Brown from exam Pro and we are taking a look at terraform provisioners so provisioners install software edit files and provision machines created with terraform and terraform allows you to work with two different provisioners we have Cloud net and Packer so Cloud init is an industry standard for crossplatform cloud instance initialization when you launch a VM on a cloud service provider you'll provide either a yaml or Bass script and so for the case of AWS what you'll have is this box called user data and so you can either put your yaml or Bass script in there it's the same if you're using Google or Azure they both have this box it might just not be called user data but that is using Cloud init underneath then you have Packer this is an automated image Builder service you provide a configuration file to create and provision the machine image and the image is then delivered to repository for use if you've ever heard of ec2 image Builder it's a very similar service except that one's just for AWS I suppose for Google you can use Google Cloud run and even on AWS you could use um code build but uh Packer is great because it's Cloud agnostic so you're going to just build the image and then you can deliver it to any provider provisioners should be used as a last resort for the for more common situations there are better Alternatives this is a warning that hashnode puts out in their terraform provisioner section and so I wasn't really sure why they were saying this so I reached out to Anton and Anton uh if you don't know him he's an as Community hero just like myself and so he specializes in terraform like he wrote so many modules for the terraform AWS so he knows it pretty well and he says here the main reason is that provisioners will do something that won't be reflected in the terraform State and the better alternative for that one is to use cloud provider features like Cloud init scripts I think this comes back to immutability when we're looking at the fact that we want to lean towards doing an approach with Packer right we want to um uh bake our Baker machines or virtual machines and then deploy because that's going to be probably the better alternative so if we wanted to use cloud init the idea is we'd have to provide a cloudinet yaml file which is a a very particular format you can find them on the cloudinet website and the idea here is we have these run commands so this just like bash commands here to start and stop Apache we can install our packages here do an update do an upgrade we'll have to pass along our SSH key here that's a very important component to that once we have that file configured we can reference it as a template file over here call it user data and then we're going to pass it on to this section here for user data so that when we launch up this VM and this one in particular is for AWS that's going to pass it to that user data okay now you might be asking well where's all these other provisioners because there's a lot of other tools out there so terraform used to directly support thirdparty provisioning tools in the terraform language but they were deprecated because it was considered to be poor practice suggesting better Alternatives as we were just talking about so you might be asking where is Chef where is puppet where is salt and the thing is is that you can technically still use chef and puppet through Cloud init because cloudinit actually supports some dsls in there I've never used this before myself but it doesn't look too complicated but the idea is that there's just not direct support so you're not going to use it directly in the language you can use it through cloud in it if you really need it one thing I didn't see mentioned anywhere was ansible and this one's a little bit confusing because there's a lot a lot of videos online about terraform and ansible working very well together and they're complementary Technologies so ansible is a little bit different than these other ones because it does more than just configuration management so maybe that's the reason there um but anyway the point is is that there's no direct support for these anymore you got to use cloud in it and generally if you can use Packer instead when you're working with virtual machines okay hey this is Andrew Brown from exam Pro and we are taking a look at local exec which allows you to execute local commands after a resource is provisioned so the machine that is executing terraform so what's doing the terraform apply is where the command will execute and a local environment could be your local machine so your laptop or workstation a build server like gcp Cloud build a business code Builder Jenkins or terraform Cloud run environment so that is a single use Linux virtual machine so just an example and there's a lot of cases where you might want to automate but the idea here is after your provision a VM you need to supply the public IP to a thirdparty security service to add the VM IP address and you can accomplish this by using locally installed thirdparty cli's on your build server and so there is a bit of an overlapping responsibility between terraform outputs versus local exec because the idea is that by getting by getting data out after something is provisioned or something like that you can do something pragmatic but the idea here is terraform outputs allow you to Output results after running terraform apply local exec allows you to run any arbitrary commands on your local machine commonly used to trigger configuration management like ansible Chef or puppet okay let's take a look at some example code for a local exec so here we have a bunch of examples on the right hand side and so I just kind of want to walk through some of the commands that we can use but before we do that just let's take a quicker look here at the code so notice we have a resource like Ava's instance in web and then we are specifying a provisioner being a local exec and then we have a command that is being executed under there okay so hopefully that makes it pretty clear but let's just kind of work through the options we have available to us so the first is we have a command and this is required and this is the command you want to execute so notice that we are doing an echo there so it's whatever is possible uh there and I think by default it's using bash okay so if you're using Linux that's what it would be using we could also set a working directory we don't see an example there on the right hand side but if you wanted to say where the command will be executed that's something you could do so maybe you want it over here another thing is The Interpreter so this is the entry point for the command I think by default again it would probably use bash if you're on Linux machine but you could say use bash Ruby it was CLI Powershell whatever you want okay if you needed to pass environment variables in maybe you need a key and secret so the example here is you know we are printing out those keys and then putting them into a credentials XML file so that could be an example there okay hey this is Andrew Brown from exam Pro and we're taking a look at remote exec so this allows you to execute commands on a Target resource after a resources provision so the idea is you have a local machine executing terraform and so the idea is that when remote exact happens it has a script and it's sending that off to the Target so this case it could be a provision virtual machine and this is where the command is going to run so a remote execute is useful for provisioning a virtual machine with a simple set of commands for more complex tasks it's recommended to use cloud init and strongly recommended in all cases to bake golden images via Packer or uc2 image Builder if you want to use something more complex like ansible or something let's take a look at an example of a remote exec script so here we have a couple and just to quickly go through it the idea is you define your resource so here it's just a virtual machine on AWS and we are provisioning our provisioner is going to be remote exact and so we're able to put these inline commands and say okay let's run puppet apply and then we'll use console join which is the CLI for hashicorp console so there are three different modes for a remote exec the first is inline list of command strings which is what we are seeing over here and then the other option is we can provide a script or scripts so the idea is that you would um well you just specify those locations and it would run it what's interesting here is that it doesn't say um like because we saw with local exec that we could use an interpreter and so it's my assumption that it's just going to use bash or it's going to use a script that is executable right where you have a shebang in the top there and so that's something you know I might test out it's not something that's going to be on the exam but maybe we'll just test out that theory because it's not in the documentation as of the time I'm recording this let's take a look at the file provisioner and this is used to copy files or directories from our local machine to the newly created resource so here we have some on the right as an example so again we have a virtual machine that we're deploying to AWS we've set the provisioner as file and we are specifying a source file and a destination so source is going to be the file that's on your local machine or whoever is the considered the local you might also want to provide content directly so in this example here you see that we're literally just giving it a string and then there's the destination where you want that file to be I don't have it shown in the code example here but there's a high chance that you would have to provide a connection block so that you could say okay I need to use SSH or winrm to gain access to that machine okay so we just mentioned that there's a connection block so it tells the provisioner or resource how to establish a connection so here is a big example on the right hand side so this is using the example for a provisioner file and here we are specifying our connection block and this one in particular is for SSH as you can see and there's a bunch of different parameters like the user the password the host you could also use a Bastion host I don't I'm not showing it here but if you're using SSH you could specify a bunch of keys in order to do that because maybe you need to go through a Bastion first for Windows Remote Management you also have that option down below okay hey this is Andrew Brown from exam Pro and we are taking a look at null resources so this is a placeholder for resources that have no specific Association to a provider it's a bit confusing but it makes sense once you run into some use cases for it so here is a big example where we have an AWS instance and we're defining a cluster and so we need a null resource here because we want to run this trigger and that's generally why you're going to be using null resources is to trigger a resource so triggers is a map of values which should cause this set of Provisions to rerun so values are meant to be interpolated references to variables or attributes of other resources and triggers are interesting because I think we also see them in terraform Cloud I'm not sure if this is the same kind of functionality but yeah that's in all resources okay all right let's take a look at terraform data so this is very very similar to null resource but the key difference here is that it does not require or the configuration of Provider because when you install null resource it actually installs a provider called null and so now it's just with this dare terraform data you can do something very similar like this with null resource and literally replace it with terraform data and for more or less it will do the same thing now it's not one to one because uh some of those parameters are a little bit different so instead of triggers we have triggers replace but more or less you know you can almost replace it and get the exact same result and you know I would recommend it over using null I was trying to figure out if there was a case where you'd want to use an all resource but I really could not determine that it did not seem like there was anything additional so yeah there you go it's as simple as that foreign hey this is Andrew Brown from exam Pro and we are taking a look at terraform providers so providers are terraform plugins that allow you to interact with cloud service providers like AWS Azure gcp software as a service provider so GitHub and Golia stripe or other apis such as kubernetes or postgres servers there's a lot there there's like over a thousand providers so providers are required for your terraform configuration file to work so you have to have at least one provider and providers can come in three different tiers we have the official one so published by the company that owns the provider technology or service verified so actively maintained up to date and compatible with both terraform provider communities so published by Community member but no guarantee of Maintenance up to date or compatibility providers are distributed separately from terraform and the plugin must be downloaded before use so if we do terraforming knit this will download the necessary plugin provided plugins listed in the terraform configuration file so there you go hey this is Andrew Brown from exam Pro and we are taking a look at the terraform registry so this is a website portal to browse download or publish available providers and modules and just remember providers and modules are plugins within terraform both of them okay so to get to this website we go to registry.terraform.io and everything published to the terraform registry is public facing so let's just distinguish between providers and modules and I feel that I should have given providers a little bit more attention in the uh in its own slide but I'll give it a clear distinction between providers and modules here so a provider is a plugin that is a mapping to a cloud service provider's API so if you wanted to call individual API actions that is what the provider is providing to you when we're talking about modules a module actually relies on a provider plugin but a module is a group of configuration files that provide common configuration functionality this is going to help you enforce best practices reduce amount of code code reduced time to develop scripts so the way to think about it is imagine that you have to do something in your CSP like AWS and there's just common things that would go along with it so let's say you're launching a load bouncer Auto scaling group with ec2 instances that's a bunch of services that you are just very common you'd have to configure it together so there could be a module that allows you to do all that with writing very little amount of code it will choose best practices when doing that okay let's take a look here at providers and modules within terraform registry really quickly so um here is the AWS one here and so I just want to point out that this official one is by hashicorp it's not by AWS but it does mean that it has uh proper support so you know it's going to have pretty much onetoone mapping to the AWS API um and so it has really really good documentation now I complain about terraform not having great documentation for learning like their language but for the actual documentation of doing things practically they're really really good and here's just an example where we see app mesh and they just give you full examples for basically everything it's really great and if you need a code sample to get going like to actually install it within your configuration file it's right there over here so you can just go ahead and grab that for terraform modules it looks pretty similar so the idea is you get your module code on the right hand side here you want to check out the examples it's going to be dependent on who is developing these modules this one is made by Anton so he has lots and lots of really great examples and then you can see a list of dependent modules here under sub modules so it's not too complicated so there you go so we're taking a look at terraform registry which is a public registry but let's talk about private registry how would we do that well that's where we use terraform Cloud it allows you to publish private modules for your organization within the terraform Cloud private registry when creating a module you need to connect to a Version Control System of VCS and choose a repository so here you can see we can be using something like GitHub gitlab betbucket or azure devops and of course we're going to cover terraform Cloud a lot more further on in the course and it does definitely does more than just act as a private registry but I figured this is the best place to put it against the terraform registry okay let's take a look at how we would get a list of the current providers you are using so all you'd have to do is type in terraform providers and you'd get a full list this command is useful if you have a very complex architecture where you're using a lot of files and modules within terraform I wanted to just show this command just because I saw it on the exam and so it's just an easy point if you happen to get that question okay so we know we can set multiple providers of in our terraform configuration file but there are some variations here that you should know so one thing is is that if you need to have an alternate provider you can use this thing called Alias so if you just notice here there's the Alias this is useful if let's say you want to have resources within different regions of AWS is a very common use case when you want to reference uh what resource should use with provider you're going to have that little provider attribute and then you're just going to do what the name is of the provider followed by the Alias you can also set an alias provider for a parent module so notice here in the required providers we have this attribute here and we're using this configuration Alias and then if you need to set an alias provider for a child module but more or less you just need to remember these two up here okay for setting an alias hey this is Andrew Brown from exam Pro and we're giving closer attention to modules so a terraform module is a group of configuration files that provide common configuration functionality to enforce best practices reduce the amount of code and reduce the time to develop scripts I definitely had a lot of confusion understanding the difference between a provider and a module initially but the clear thing is that a provider is just an API mappings to the service okay so on the example here on the left we have AWS as a provider and the example is to show you if you had to create a VPC you'd have to specify many networking resources and just notice that I have the three ellipses there to suggest there is a lot more that you'd have to configure but by using a module and there's one called the AWS VPC module it basically has this short domain specific language that allows you to quickly provision a VPC so the easy way to remember modules is Imagine clicking a wizard that creates many Cloud resources like it able to have the VPC wizard that's basically the idea behind modules just to kind of give a better contrast to the value that modules have we'll look at the Azure provider so imagine you had to provision an Azure virtual machine this is how much code you'd have to write so it's going to vary based on providers so AWS does not require this much work it's very short gcp requires a little bit more work and for some reason Azure requires a lot so this is a case where you'd want to use a module so there's a module called compute and network module and it reduces the code to amount of this still a bit long but that's just what it is okay thank you all right let's talk about the fine line and this is understanding the gray areas of responsibility between terraform infrastructure as code and thirdparty configuration management tools like ansible so there are cases where when you get outside of AWS as your gcp you might see providers like for postgres database and you might say okay well what part of terraform should be automating it and so that's a little bit more complicated question because terraform does more than one thing so terraform has providers modules and provisioners and then on outside of that if we're not even using terraform we have thirdparty configuration management tools that we can use like ansible and the thing is is that you could have ansible do everything but that does not mean that you should have it do everything and with terraform at more or less most of these levels you can have them do everything but that doesn't mean that they should right so the idea is to try to figure out what should be where and how to define that so let's talk about creating a database so if we created a database that is like setting up a new service so that is going to be under the providers and so you'd use the postgres terraform provider to set up a database now you have users and so users are an entity they're not just like loose data so there's something that you can add remove add permissions to and we would treat them as entities and so it wouldn't necessarily be under the providers but that's a great place to put it under modules okay then you have your data so where would the data go well data is not necessarily an entity it's just a bunch of data so I would say that that is for provisioners that can run random scripts and then when we want to do things like backup tables to data warehouses or truncate data daily tables things that are repetitive tasks that is what we're going to use ansible for or a thirdparty configuration management tool outside of terraform you wouldn't have terraform to that stuff at all so when you have a task done one time to set up the database like seating data it's going to go to provisioners what you have repeatable tasks for ongoing maintenance it's going to be out as a third party provider and if you have something that is like identified as an identity like as a resource that you want to manage like Asset Management which are these things these are going to be over here in providers and modules I do want to point out that a provisioner can be using ansible but we would still want to use ansible or thirdparty configuration management tool isolate or separate to do these kind of things you do not want terraform running these okay foreign hey this is Andrew Brown from exam Pro and we are looking at Hashi Corp configuration files also known as terraform files that which contain the configuration information about providers and resources this is basically core to terraform and that's what we're doing so terraform files and in the extension of dot TF or TF Json and we'll talk about the Json case a little bit later but terraform files are written in the terraform language and so here is kind of an abstract way of looking at the language I know it's confusing here but don't worry we're going to reiterate on it to make more sense but terraform language consists of only a few basic elements you have blocks and so these are containers for other content and they represent an object so I'll have a block type which can have zero or more labels and a body you have a block label it's a name of a block you have arguments which is which is what you assign a value to a name so notice like we have assignments so we have identifier to an expression okay they will appear within block so here it is within a block as you can see um Expressions represent a value either literally or by referencing and combining other values they appear as values for arguments or within other Expressions you might come across hashicorp configuration language so HCL and this is the low level language for both the terraform language and alternative Json syntax I don't know if we'll be getting into it in this course um or if there's even an easy way to distinguish it because it's basically terraform language but just if you see HCL just think terraform language it's the easiest way to think about it okay let's take a look here at the alternate Json syntax so terraform supports alternate syntax that is Json compatible terraform expects Json syntax files to be named dot tf.json so we mentioned that earlier and so this is generally what it would look like okay the syntax is useful when generating portions of a configuration pragmatically since existing Json libraries can be used to prepare the generate configuration files and that's pretty much it would you want to work on this it's up to you um but uh yeah so that's the reason for this alternate syntax all right let's take a look at terraform settings so the terraform configuration block type terraform curly braces you'll see this within your configuration file is used to configure some behaviors of terraform itself so here is what it looks like and what's very common is you're going to see those required providers so there are different things that we can put in here so we can put the required version so this expects us to match to a particular version of terraform required providers this is the providers that will be pulled during the terraform init we can also do experiments here so these are experimental language features that the community can try and provide feedback on and then we have provider metadata so this is module specific information for providers okay hey this is Andrew Brown from exam Pro and we are taking a look at the hashicorp configuration language also known as HCL I'm going to tell you I was really confused at the start working with terraform because sometimes they mention things like hashicorp configuration files hashicorp configuration language terraform language and I could not discern you know what the difference was but so this is the idea here is to give you that Clarity okay so HCL is an open source toolkit for creating structured configuration languages that are both human and machine friendly for use of command line tools and it's an open source project so you can find it at github.com HCL so the idea is that they have this Baseline language that you can extend for your own use case so uh terraform is using it and so it uses a good like it uses the language itself but then it goes ahead and extends it by adding additional functionality for its specific use case and this HCL based language is not just for terraform it's used for hacker templates Vault policies boundary controllers and workers console configuration Waypoint application configuration Nomad job specification and this one isn't a hash Accord product but this is an open source project called Shipyard and you can use it for Shipyard blueprints surprisingly Sentinel which is a Hachi Corp policy as code server service does not use HCL but it has its own HC ACL custom language but the idea is that you know we're looking at mostly the use case is for hashicorp services but if you wanted to extend this language for your own use case you totally could and so I think that's really cool but hopefully that kind of distinguishes between HCL and terraform language okay hey this is Andrew Brown from exam Pro and we are taking a look at input variables so also known as terraform variables or just variables are parameters for terraform modules that is the way we get data in to our configuration scripts is via input variables so you can declare variables in either the root module or child modules and the way you define them is via this variables block there at the top and just to kind of go over the possible fields for that block we have the default option so the default option which is here is going to be the default variable if you do not set it for type this is an argument that specifies the value types that are accepted for the variable so this case up here we can see string and this one is a list for description this specifies the input variables documentation we don't see an example there I believe that is optional but it's always great to put a description in when you can there is a validation block so a block to Define validation rules usually in addition addition to type constraints so we don't see that here on the right hand side but the idea is that you know let's just make sure that there's less of a human error entering the wrong information you can also have sensitive this limits terraform UI output when the variable is used in the configuration and we will cover sensitive a lot more in this course outside of just this one slide okay let's take a look here at variable definition files and these allow you to set the values for multiple variables at once so variable definition files are named with the dot TF vars extension or if you want to use the alternative syntax it's the tfbars.json file by default if you have a file called terraform.tfrs within your project directory this will be automatically loaded so it's pretty common to make that file to create a definition file it just uses the terraform language so you would just assign values here you wouldn't make variable blocks but you just Define these um identifiers and give them values okay another way of loading input variables is via environment variables and this is very common uh way of loading them if you have your own CI CD process for terraform so if you're using terraform cloud or you're using some kind of build server that's going to be the primary way you're going to get variables into those build servers probably won't be doing this much locally but the way it works is that terraform will watch for any environment variable starting with TF underscore VAR underscore followed by the name this is very important to remember because it definitely will show up on the exam so let's say we want to do set a variable for an image ID so we do TF underscore VAR and then image ID probably most cases when you follow the name it's going to be a lowercase underscore I don't think you'd probably want to uppercase that stuff and you just set the value okay so there's a lot of ways for us to load input variables we just saw two so we saw terraform tfrs and environment variables but there's a lot more caveats to this so let's just run through them so we already covered uh terraform.tfrs the idea here is that if you create this file and it's in your project it will automatically be loaded when running terraform apply you can name other TFR files uh so I just called them use additional TFR files but they won't be loaded by default you'll have to use a command line to load them this is useful if you have like a Dev and prod environment and you want to swap those out now if you want to have files that auto load then you can just put the dot Auto here and give it any name you want this would be useful if let's say you had a very large terraform tfrs file and you wanted to break it up to make it more human readable you could do that then you have the hyphen VAR file flag when you're doing terraform apply or or plan and this is actually how you load up these additional variable files if you need to override a single value you you can use hyphen VAR so here I'm overriding the ec2 type to be T2 medium and then lastly here we have environment variables we covered this this is where it starts with TF underscore VAR underscore followed by the name and this is going to be very common when you are using Code build servers or runtimes to run this in a CI CD automated way now there's a precedence to which these get loaded meaning that that certain configurations of or input of variables will override other ones so as we go down this list these ones will override the previous one so at the top you have environment variables if you have a terraform tfrs file that will override the environment variables if you have the Json one that will override that one if you have auto files that will override the default tfrs file and then on the last list you have hyphen VAR and hyphen VAR file will override the rest so there you go in terms of the exam they're not going to ask you the president's here but you're going to need to know what VAR VAR file are environment variables are in this default line okay thank you foreign let's take a look here at output values which are computed values after a terraform apply is performed output values allow you to obtain information after resource provisioning such as a public IP address I'll put a file of values for chromatic integration crossreference Stacks via outputs in a state file via terraform remote State and so here's an example of an outputs block so notice that there's a block and you specify some stuff there you can optionally provide a description it's not necessary but generally with outputs I would recommend putting that in there you can also Mark it as sensitive so it does not show in your terminal this is important if you're doing like logging stuff you don't want to compromise those values there but understand that output values even though they might not be outputted to your terminal or SD out they will be visible within the state file so if somebody opens up the state file they're going to be plainly visible there so just understand that sensitive does not protect the values there okay now in terms of how we would use the CLI with the output values if we type terraform output it's just going to print out all the values that are within the state file I don't show this in the example here but if you wanted to use a um a like bash command to parse Json you could extract them out and see they're just plainly in the Json okay if you need to get exactly a particular field you type in terraform output and Then followed by the name if you wanted an adjacent format all the output then you could give that flag I don't know if it would work with this one I actually didn't test I just thought about that here for this one here if you want the raw output of it meaning like if you output a string and you want it to be escaped or what have you then you could use it pragmatically by passing it to something like curl to do something but the idea with all these output values is that it's one way of inspecting but you could also use this in a configuration script or or something to do kind of like an after action okay all right so we're taking a look at local values also known as locals that assigns a name to an expression so you can use it multiple times within a module without repeating it so here what we're going to do is Define our local block up here and then the idea is that we're assigning these names or IDs expressions or values so that we can reuse them throughout our code notice that we can Define multiple local blocks in the same file and I just say this because like when you use required providers you're only allowed to have a single block but this case like with variables or locals you can have many and you could even Nest them within each other so notice down here we're referencing local within a local so that's totally possible and I imagine it's in the order to which it is specified we can do static values or computed values so we can actually here's a function write an expression and then it will output a value once a local value is declared you can reference it via the dot as local dot the name so here notice within our it was resource we have local and common tags I have to point this out but when you're referencing you use the singular local because you might get an exam question which shows you local dot or locals Dot and the trick here is you got to remember which one it is locals help can help dry up your code it is best practice to use local sparingly since it's uh in terraform it's intended to be declarative and overuse of locals can make it difficult to determine what the code is doing this call comes back to describing terraform as declarative plus where they give you functionality that's imperative like but the idea is that you know if you overuse these you can run into trouble okay hey it's Andrew Brown from exam Pro and we are taking a look at data sources for terraform so the idea here is you want information to find outside of terraform and it's defined by another separator from configuration or Modified by functions so the idea here is we are going to Define ourselves a data block and we have an external resource we're looking for so we're saying hey I want to see if I have an AWS Ami we're going to use these filters as a way of of kind of selecting it within our AWS account so we'd have a provider set up and so it'd be looking within that account to find it and it's even saying look for the most recent Ami okay and once we have found that data source we can just reference it so notice we're using data to reference it there so data AWS ami.web ID so there you go we're taking a look here at name values and these are builtin Expressions that reference uh various values you'll find your configuration scripts we do cover these in their respected sections but I wanted to consolidate them here in one place just so that you get a second chance to reinforce this information because Crux of questions of the exam could be based on knowing how the name values work so let's go through them the first is resources I'm going to get up my pen tool here and so the way resources work is that you start with the resource type so AWS instance and then you're going to do the name of it so there's nothing that uh starts before the left hand side of it so just remember it just starts with that resource type then you have input variables and that starts with VAR period so that's the singular VAR then we have local values and again that's singular so local period for child modules it starts with module period again singular for data sources it's going to be data singular just remember singular because they can have a matchup on the on the exam questions whether it'll be like data or datas for file system and workspace info we have path.module this is the path of module where the expression is placed we have path.root this is the path of the root module of the configuration we have path CWD this is the path of the current working directory and in practice the default CWD is the same as the roots so those would be technically the same we have terraform.workspace this is the name of the currently selected workspace then we have block local values these are things that appear within a body of a blocks so this could be within a resource provisioners things like that so we have if we're using the count meta argument we're going to get count and with that we'll have count dot index so we can say okay this is the fourth iteration of you know uh this this account Loop then we have for each and this allows us to have the key and the value so we can access that during our iterations we have self uh so selfless uh references information within provisioners or connections so it's just like a selfreferencing thing name values resemble the attribute notation of map or object values but are not objects and do not act as objects you cannot use square brackets to access attributes of name values like an object so there you go foreign hey this is Andrew Brown from exam Pro and we are taking a look at resource meta arguments so the terraform language defines several metaarguments which can be used with any resource type to change the behavior of resources and so we'll quickly go through the list here and then we will Deep dive on each so the first is depends on so this is for specifying explicit dependencies we have count which is for creating multiple resource instances according to account we have four each which is used to create multiple instances according to a map or set of strings provider so this is for selecting a nondefault provider configuration life cycle this is for life cycle customizations provisioner this is and also for connections for taking extra actions after resource creation so there's the Quick List now let's jump into them all right the First Resource meta argument we want to look at here is called depends on and this is the order of which resources are provisioned and is important when resources depend on others before they are provisioned terraform implicitly can determine the order of provision of resources but there may be some cases where it cannot be determined or like the correct order so this is where you can be a bit more explicit so here we have some terraform configuration where we have an AWS instance and it relies on a policy and so what we're doing is we're setting an explicit depends on here so that it knows that it requires that now in a normal use case you would not have to do this but it's hard to find use cases where this happens but when it does become a problem you'll know because your resources will not provision correctly you'll get an error so there you go let's take a look here at the count resource meta argument and this is when you're managing a pool of objects so an example here would be a fleet of virtual machines where you want to use count so here on the right hand side we have an example of us using that in terraform so we can specify the amount of instances we want so here it is four and then we'll have access to this name value called count dot index so the tags will start at zero so it'll be server zero one two and three then just down below here I just want to show you that with count you can accept a numeric expression so you know if you had a variable that you had set as the subnet IDs or even just an arbitrary number like you want to have X amount of servers this would allow you to do that okay but just so you know those numbers must be whole and a number must be known before the configuration which you'd put in your input variables okay all right so let's take a look here at four each which is for iterating over resource meta arguments but it's slightly different because it allows you to map over Dynamic values giving you a little bit more flexibility so here's an example of us defining A4 each and notice that we have defined a map sometimes I call it an object because they're so similar but this is a map and the idea is that once you have your map defined with your 4H you will now have access to these name values so you can do each dot key or each dot value to extract that out you can also just use it like with an array so here we have an array and then we use two set to turn it into a set which it will accept as well and then we can just pull out the key because there will be no value so just an example of with a map and then with something that looks like an array okay to understand the resource meta argument life cycle we need to understand how resource Behavior works and so when you execute your execution order via terraform apply it will perform one of the following to a resource so the most common one you'll see is a create so these are resources that exist in the configuration but are not associated with a real infrastructure object in the state the way you can tell it's creating it will have this nice little green plus sign the next one is destroy so resources that exist in the state but no longer exist in the configuration and so that's going to tear down your resources out of your Cloud providers this is represented by a minus symbol then you have update in place so the resources who arguments have changed so the idea here is that if you have a virtual machine and let's say you change the size of it it's not going to destroy it it's just going to modify its settings this is represented with a tilde and the last one here is destroy and recreate so resources who arguments have change but which cannot be updated in place due to remote API limitations so there are just some Cloud resources that always require destroy and recreate and this is something very easy to trigger if you are using the replace command or the older terraform tank command in order to replace a degraded or damaged instance so let's talk about life cycle so lifecycle blocks allow you to change what happens to resources on the create update and Destroy lifecycle blocks are nested within resources so here is a resource which is just an Azure Resource Group and within it we have a life cycle block and we're setting our first option here that's possible called the create before destroy so this is a Boolean and when replacing a resource first create the new resource before deleting it so the default is destroyed old first so this is more about just the order of How It's destroyed prevent destroy so ensures a resource is not destroyed then we have ignore changes and this is based off a list of attributes that you feed to it so don't change the resource on create update to store right if a change occurs for the listed attributes so maybe um maybe you uh you're just changing a tag and you say don't don't change uh like don't tear down create or do anything strange if we change a tag okay so there you go that's uh life cycles so we're looking at our last meta argument here which are resource providers and this goes along with the idea of an alias so here we are defining ourselves a provider in Google Cloud but there's a case where we might need to override the provider uh at a at a per resource level and the way we do that is by creating an additional provider and setting an alias and then here we could change something like the region and then once we have that set we can then reference our provider explicitly under a resource and so that's all there is to it definitely on your exam you will see a question about Alias or you'll see that example so definitely want to know how to do that okay thank you all right so we're starting our introduction here into terraform Expressions because there's a lot we can talk about here so expressions are used to refer to or Com or compute values within a configuration so terraform Expressions is a large topic and we'll be covering types and values strings and templates reference to values operators function calls conditional Expressions four Expressions Splat Dynamic blocks type constraints actually I don't think we covered type constraints just because there's nothing really to say about it but we definitely cover version constraints so yeah let's start off the section and go to it so we're taking a look here at types and values for expressions and so the result of an expression is a value and all values have types and so we have primitive types no type and complex structural collection types that last one is a bit more complicated than what we are presenting here we're going to simplify it and then cover it later okay so for primitive types we have strings so you have your double quotations which represent your string then you have numbers so it's going to be integers or floats then you have booleans so this is either true or false for no types we have null and so null is different in all different types of languages so it's very important to understand how it works and so null represents absence or Omission when you want to use the underlying default of a provider's resource configuration option so when you're saying null doesn't mean it's nothing it's going to be whatever the default is and the default also could be nothing it's just depending on what that is on the provider so for collection or for a collection types complex structural types we have list or Tuple and this generally looks like an array the then you have map and object and this looks like basically like a Json object or a ruby hash or I think they call it in Python a dictionary so that gives you an idea of the basic types but for this last one here because this I found really confusing list tuples map object we definitely explain this more in the course okay okay so we're giving a little bit more attention to the string type because there's a little bit more going on here so when quoting strings you got to use double quotes uh at one point terraform I believe supported single quotes I think it only Sports double quotes now and honestly you generally want to just use double quotes because double quotes always support Escape sequences this is pretty much standard across all programming languages but the idea here is you can do things like new line carriage return tab literal quotes literal backslashes Unicode characters both basic multilingual plane and supplementary planes there are some special Escape sequences this makes sense when we look at the next slide for string templates but there's these things where you can do interpolation and so you might not want to actually do them you might want to do it without and so if you just use double of the symbol that will allow you to do it then there is also the ability to have multiline strings and we use hear DOC for that and so here Doc is a little bit different in all languages but here we're using Unix style so that means that we're going to start with these two two angled brackets to the left our opening angle brackets followed by some word that is all in uppercase it doesn't have to be eot it could be whatever you want I always like to type here Doc and then it has to end at the same indentation level with the same word all uppercase and then everything in between will be treated as um as multiline the nice thing about this is that when you have this you can actually just use double quotes wherever you want because you don't have to escape them okay let's take a look at string templates because this is the real power of strings so the first is string interpolation and this allows you to evaluate an expression between the markers so the idea is instead of having to do double quotations and do plus signs to stitch together uh strings what you do is just do a dollar sign uh curly braces and then put the the expression or variable that you want uh to be converted okay then you have string directives and these are slightly different this allows you to evaluate an expression for a conditional logic between the markers so let's say we want to have an if else statement so if the name is blank then use VAR name or sorry if it's not blank then use the name provided otherwise put it as unnamed okay you can also use interpolation directives with hear docs so you know just to show that you can do it and then the last one thing here is you can strip out white space that would normally be left by directors blocks by providing a trailing tilde so just notice this little tilde here on the end because these do take up space so if you were to view it there'd just be an empty space there if you want that space to vanish then you just put that tilde on the end so there you go foreign let's take a look here at the possible operators that we can use within terraform expressions and so just a refresher operators are mathematical operations you can perform two numbers within Expressions I'm not going to show full examples here and the outputs of them because this is pretty common for programming or scripting languages and also the exam is not really going to focus on the use cases for these so it's just more so to tell you what is available too so you know what you can use the first is multiplication so you take two numbers and times them to get a larger number division so it uses a forward slash modulus and if you've never used modulus I really like this it allows you to see if something is divisible by a certain amount and then you get the remainder you have addition subtraction if you need to flip to a negative number you can just put a minus sign in front of it if you need to do equals its doubles if you want to do does not equal its exclamation equals then we have a less than so that's a open angled bracket less than or equal so that will be followed by an equal sign greater than is a closing angle bracket and Then followed by an equal sign for greater than or equal you have or which uses the double pipes you have n which uses the double ampersands if you need to flip a Boolean you can just put an exclamation in front of it so if it was true now it is false if it was false now is true I'm not sure what it would do for an all I would think that it would turn it to true but uh yeah so there you go foreign we're taking a look here at conditional expressions and this is pretty much the only way that you can do ifel statements within terraform but it works out fine and so it's actually using the ternary style of ill if else so what that looks like it's a single line so the it starts with a question mark so that's the if and then it's the True Value and then the colon represents the else and then you have your false value it's ternary because there's three things one two and three okay so that's the way I remember this thing it's not a a preferred way of doing Ethel statements in other languages because it is a little bit condensed but it makes sense when you're using scripting language and you're really restricted on per line actions so this is what it would look like in action so we'd have a variable that is a if a does not equal a blank then use the variable or set it to default a as a string so that's kind of an example there I'll just wipe that away there the return type of it of of the if and else must be the same type so if you have a number okay and the one if statement and then you have a string they have to be the same so uh obviously we want a string to be returned in both cases so what we'll do is use this builtin function to string to turn this into a string so that we're not going to run into any problems so there you go all right we're taking a look here at four expressions and so these allow you to iterate over a complex type and apply Transformations a four expression can accept as input list set Tuple map or an object I want to distinguish this between four each which is a resource meta argument which allows you to iterate over a a resource or a collection of resources that are similar but four expressions are for these primitive types or not these primitive types but these collection structural types that we talked about in types and values okay so here's an example of something we might want to do imagine we have a list of names and we want to iterate through our list and make them all uppercase so we could do that with this four so we have the four with the n and then we're providing the value of each item in our list it's easy to think of list or Tuple as an array so I'll just call it an array okay then you have a map and so this is where it has a key and value this is going to be for maps or objects and the idea is that we can then go apply Transformations and notice that we are returning only a single string so we're actually going to get back something like a tuple and so how does it decide whether it returns a um a array or something that looks like an object we'll explain that here in a moment the last one here is we have a list with an index so it's very similar to the first one but in this case we want to know the index here so imagine this says zero is Andrew one is Cindy two is Peter and it would come back as an array or list so let's talk about the return types the return types are defined by the um uh the braces or brackets that are around the actual expression so if you have square braces we're going to go back to Tuple so it's just think that array so for in this case where we had our list it was returning back a tuple okay if we have curly braces it's going to return an object so here we have a list so it's like an array that's coming in here and then we were specifying as the return uh this kind of object structure and so that's how we're going to get that so that's that there's one other thing we want to mention which has to do with um reducing or ordering so an if statement can be used to reduce the amount of elements returned so in this case what we're doing is we're using an if statement and so we're saying unless this is true so if this is true then return if it's not then return less of what is there so if there's any blank names that are in our list they just won't show up it'll just only show names that are actually there um then we have implicit element ordering so since terraform can convert an unordered type so map objects and sets to an order type list or tuples it will need to choose an implied ordering so for maps and objects they're stored by key A to Z set of strings stored by a strings A to Z everything else is going to be arbitrary ordering so there you go all right we're taking a look here at spy expressions and these provide a shorter expression for the four expression which we just looked at so what is the Splat operator a Splat operator is represented by an asterisk it originates from the Ruby language and Splats in terraform are used to roll up or soak up a bunch of iterations in a for expression so here is an example where it's for list sets or tuples so here we have a list and the idea is that we're iterating over this ID or in this game we're iterating over um its objects or sorry a array and then that array is containing a bunch of objects and so we're accessing the name within it and so instead of writing it like that we don't even have to use it for at all what we can do is put this asterisk here and this is going to equate to the same thing so here this is going to return all the IDS and in this case it's going to return a all the lists and allow us to access the interfaces along to the name okay so let's take a look at spy Expressions uh when we're applying them to lists so if the value is anything other than a null value then the Splat expression will transform it into a single element list if the value is null then the expression uh the then the Splat expression will return an empty Tuple and so this behavior is useful for modules that accept optional input variables whose default value is null to represent the absence of any value to adapt the variable value to work with other terraform language features that are designed to work with collections so I know that's a big mouthful it's just kind of like an edge case to these Spa Expressions this is not going to show up in the exam but I just wanted to show it to you in case you're interested here and just notice the spots being used over here okay foreign so we're taking a look here at Dynamic blocks and this allows you to dynamically construct repeatable nested blocks so I want to emphasize that this is a very powerful feature that can lead to abuse where your code becomes uh difficult to read but it's also very flexible it will absolutely show up in the exam so pay close attention on how this works so let's say you needed to create a bunch of Ingress rules for your ec2 security group and so this would lead to a lot of repeatable elements for rules within your resource and so what you can do with Dynamic blocks is you can Define objects locally so here I have my Ingress rules as an object so here's one and here is two and then using Dynamic block what I can do is use a 4H to reference those Ingress rules and within this Dynamic Ingress block we'll have our content and this will specify the things that we're swapping out so the idea is that it will iterate over this and apply all those values there so it's something you can't do with a 4H or account this is basically the the most advanced iteration but just understand if you remember this use case and it's very easy to understand or remember how to use it when you're doing an exam okay we're looking at version constraints so terraform utilizes semantic version for specifying terraform providers and module versions so semantic versioning is an open standard on how to define versioning for software management so you have your major minor and your patch and so here are examples or variants on this here so we have um you know where you see major minor then you can have this RC this rc1 or you could not have it or you can have beta and this can all be read about on the samver.org but just to quickly go through it major version is when you want to make incompatible API changes minor is when you add functionality that is backwards compatible in matter patch is when you make backwards compatible bug fixes there are additional labels for prerelease build metadata that are available as extensions so that's where we see those little additions there at the top a version straight is a string containing one or more conditions separated by commas so you have your equals or no operators or sorry your equals or no operators so match exact version of the number so it's either with the equals or not with the operator at all okay that's what I'm trying to write there excludes an exact number uh version so if we just said does not or will not be uh 1.0.0 then you have a comparative ones so they have the version has to be greater or equal to 1.0.0 um and then we have one with the tilde so allows only the rightmost version of the last number to increment so what this means is that the the last number here is only allowed to increment okay so let's talk about Progressive versioning because this kind of ties into semantic uh versioning but Progressive version is the practice of using the latest version to keep a proactive stance of security modernity and development agility and we like to describe this as practicing good hygiene when we're uh working with our code okay so by being up to date you're always pushing left on things that need to stay fixed or compatible you'll have to deal with smaller problems instead of dealing with a big problem later on run nightly builds is a good example where you might have golden images and the idea is to provide a warning signal just to kind of elaborate on that a nightly build is an automated workflow that occurs at night when developers are asleep so if the build breaks because A change is required for the code the developers will see this upon arrival in the morning and be able to budget accordingly so what I'm trying to get at is that when you are like putting in your providers especially if you copy from the terraform um the terraform website to get the providers and modules what they'll do is they'll actually have it set as the I'm just going to roll back here for a second but they'll actually have it set as the equals what I'm saying to you is you want to use something like a tilde or a greater than or equal sign so that you are staying Progressive okay so that's just one thing I want you to watch out for and we will talk about that when we go through the follow alongs okay hey it's Andrew Brown from exam Pro and we are moving on to our expression section starting with string templates let's learn all about that and we are going to have to CD into a new folder here so I have one called expressions and we will make ourselves a new file called main.tf we'll Define a local back end and I'm going to just Define a new variable I'm going to call this variable hello and I'm going to give it a type of string okay and that's all I'm going to do there and then what we're going to do is create ourselves a TF VAR file so we'll say terraform Dot tfvars and in there we'll just set hello to world and so what I want to do is enter terraform console okay this is going to allow us to just run arbitrary Expressions I want to show you how you quit it you just type exit and so we'll do is make a string so we'll just first do a Hello World I want to show you that you can put a uh a new line there and we'll get back a multiline document this is a um this console doesn't allow for multiple lines so we can't write our own here doc but I can show you what it looks like and then we can interpolate a uh a variable there so we'll just say hello and notice we get hello world so that's how interpolation works it's not super complicated directives is a little bit different where we have string right so we can do instead this but the control word is a bit different because you're using the uh this um percentage sign the directives when you're doing something like an if else statement so what we could do is say something like um barsoon here okay and what I'm going to do is just exit out here clear because I don't know if it um it reloads the uh the variables there if you just change them on the Fly but what we'll do is we'll just say hello and we will write ourselves an if statement so we're going to say if VAR dot hello equals bar soon what it's going to do is then print out um it's going to instead print out Mars okay otherwise what we're going to get is um world okay you know what's really interesting is we're using the if and else here but I I could have swore that the only thing you had was ternary operators so like if you look at the conditional expressions notice here that it's doing this and it's not showing the documentation the FL so you know maybe maybe that's just for a oneliner and if else does exist for expressions and I might have missed that in the course but you cannot blame me if the documentation shows it like that okay so what I'm going to do here is just go ahead and hit enter and here we get hello Mars so that pretty much uh shows you how string interpolation works for both interpolation and directives we'll just type in exit and so that's all we want to do there okay all right so let's learn about four Expressions so four Expressions allow us to kind of iterate over something and do something fun with it and so what we're going to do is create ourselves some more complex types here so how about instead of like this was just hello a second ago but we'll change this over to Worlds and what I'm going to do is just list out a bunch of Worlds here from the uh the book uh John Carter books so we have bar soon we have jasum we have things like sesum okay and then we have whoops so assume and then we have something like cosume okay and so the idea here is now that we've defined that there we've got to go back to our main TF I'm just going to update this to the worlds this will just be a list all right and so what we'll do is make our way over to terraform cloud or sorry terraform console and we will try to do a four Loop here so I'm going to do Square braces four and we'll just say w in VAR dot worlds and then what we can do here is make a colon whoops okay and then type upper W and so that returns them all in uppercase there and if we were to use the Splat operator and technically this is something we want to move on to the next part but um yeah we'll leave it for the next video I'll just keep that separate so that is for just if we had a list imagine if we had this as the as an index here um or we'll say map because what we can do is actually map these two names so bring this down here and this would be Earth now you can use the colon or the equals it's just whatever you want to use here they're both supported actually this is an Earth this is Mars and then this one here is Earth and this one here would be Jupiter and then this one here would be Venus okay um and so I think we still need to Define it over here so I'm just going to say world's map and then what we can do here instead of having list we can say map and we'll try to iterate over this so it's going to be very similar except the difference is now we have a key and we have a value and so if we just want to return the names in capital we can just do K here oh that's the index uh what if we do oh you know why it's because um we have to do Worlds Map okay so reference to Undeclared variable map so we do have to exit and restart and oh sorry the input was complaining there so I'll just copy the one up here so I have to type it again nope it did not work as we thought okay so I do have to type it by hand kind of a pain but I guess that's just how it works so we'll say 4K V invar Dot worlds map and then we say upper B here okay or we could just say take the K here and get the other values now I didn't show you this a moment ago but if we do worlds here we can specify an index and an index would come first so it would be the value like the world the second and the index is first so notice that I is all a number the index of it and then the that is the value there um we could probably also return this as a map so notice that square braces are going to give you a list or and then curlers are going to give you map which kind of correspond to their actual data structure so if we wanted to turn this into the opposite here what we could do is just say uh we probably do string interpolation like this here and do I and then do equals or even maybe a colon here and then do the world like that and it didn't like the way I specified it so I'll try it like this instead extra characters after the line four so I don't see that wrong there just give me a moment I think um oh you know what it's we need to use in this case I think we have to do it this way okay so we use use the hash rocket so in that particular case you have to use the hash rocket that's what that symbol is called the equal zero um and so that's how we can get that value there so that pretty much outlines how to use um the for loops and next we're going to go probably look at the Splats okay so I'll see you back here in a moment I'm just going to exit this actually before we move on to Splats I just want to add one more thing to four Expressions which is filtering so we'll just go back here and get back into our terraform console here and what I'm going to do is just write another four and it probably would make sense to use the uh the the world's list we just did there so I'm going to do KV type in VAR world's map and so the idea here is that I only want the let's say we'll say the upper I only want the key value here but I would just say at the end here I can say if the V the value equals I can't remember what we set these as so this is key in value so if it is Mars I think it's double equals so if it is Mars then only return it that way or we could say the opposite say give me everything but Mars okay so I just wanted to show you you could use that if to do that filtering so I'm going to exit there and we'll move on to spots okay all right so we're moving on to Splats and what we'll have to do is create ourselves a new variable here I'm going to call this one world's Splat and this one is going to be a list and so if we go back up here to tfvars we'll make ourselves a new variable down here and we'll just call this one splat and it's going to be a list but it's going to contain inside of it a bunch of maps okay so we'll do pretty much this up here okay but what's going to happen here it's going to be slightly different where we are going to set what is the name so we'll just say like um Earth name that's actually Mars name so it's a Mars name here for all these and then over here these are going to be the Earth name so I think that is valid and what we're going to do here is just type in terraform console and if we wrote that correctly oh no we got an error so it says expected an equal sign to Mark the beginning of a new attribute value so I mean this should be okay uh oh you know what I think this Colon's just missing here put it up again there we go we're fine so if we just want to look at that variable I think we just type it in here and it might print it out if we're lucky yes so there it is um so what we're going to do here is use a Splat to get maybe the Mars name or something so if we used a for Loop what we'd have to probably write we could try this but we'd have to do four and then it would be for the actual map so say m for map in world's splat and then we would have to do m Dot Mars name and so a reference to the attribute by one axis treatment specifying the resource name so I mean that looks oh you know it's because we didn't write VAR okay I say we but it was really me so you know that's that but we could write this in a more concise way okay and so we use a splat Mars name okay so you know that's a lot more convenient if we're just trying to access variables like that um I think that if you're trying to do things like if you want to do upper here I think you still have to use A4 expression okay I don't think you can do this we can try it but I really don't think that will work no and if we look at the documentation they don't show an example like that so you know it's not that bad but you can see that it's for a particular use case you can't use that for uh Maps or whatever the equivalent the other map is object but it's useful for this one particular use case okay hey it's Andrew Brown from exam Pro and we are on to the dynamic blocks follow along so this one should be uh pretty fun because it's uh quite a powerful feature so what I've done is I've created a new folder here called Dynamic blocks I'm going to make a new file here as always it's going to be main.tf and a really good example for this would probably be a database Security Group just because there's all those Ingress and out outgress or egress rules so what we're going to do is just Define our terraform settings block and I'm just going to pull up over here and make our way over to the registry for terraform and what we're going to do is go over to the AWS provider and go to the documentation and actually I first want to grab the provider itself because that is something very easy that we can do here we'll just move that on over so we can see what we're doing and paste that on in and we're going to have to Define our provider of course so we'll name that as AWS the profile is going to be defaults and our region will be us East one okay and so now what we need is to cocreate ourselves a security group so we have of course done that previously here but let's pull up the uh documentation here I believe it was actually under VPC so let's just go down to VPC here and we will expand that and then underneath here there should be a AWS Security Group uh there it is and if we scroll on down there's the thing okay so what I'm going to do is copy uh this code here and go over and we'll just paste that on in and there is our security group so I remember that we had to have the description if you remember it complained about that so outgoing for everyone and we need to also have a few additional things we will just scroll on down here because it wanted the prefix list IDs okay remember we needed that I think there was like self false and there was like security groups I think it was actually AWS security groups in particular let's just double check to make sure that is the case it is called uh oh it's just security groups okay so we'll say self equals false we do not need cider block four here or six um we do not need this one here and it doesn't really matter what we set this to so it could be set to the main side or block that's totally fine but we are going to need to add a data source just like last time for the VPC so we'll say VPC we'll call that Main and I think it just needed the VPC ID it was as simple as that and so we will go over to AWS over to VPC and from there we are going to go to rvbcs and I will go grab that VPC ID Okay so we've grabbed our VPC ID and then we just need to name this as data and then we're going to name this as data we don't really care what the cider block is it's just again for um this demo purposes we don't need tags we'll take those out and um yeah everything else is fine okay so this now comes to the fact that we want to use Dynamic blocks before we do that let's just well I think I didn't leave the console there last but what we'll do here is just to our terraform inits and as that is pulling that stuff we're going to look up Dynamic blocks uh terraform so we'll go here and so Dynamic blocks is like way more powerful than um the four each where what we can do I'm just trying to find that example there but we have uh we have to set the dynamic part the 4H you know what I'm pretty sure I have these in my slides so let's just use my slides as the reference here dynamic ah here it is okay so the idea is that we'll just set up a locals with all of our information here and then we will create this Dynamic block and then provide the content okay so I'm just going to move that off screen so I can see what I am doing here as we type it in and we'll see if we run into any problems um failed to query the available product for packages could not retrieve the list of the available versions for the provider uh not have a provider registry terraform name all models should specify the required providers so I'm not sure why it's complaining here but we'll scroll all the way to the top and the required providers is correctly set here so it shouldn't be a problem not sure what it doesn't like um so let's just type in terraform providers here the VPC um is VPC a module you know what it's probably because I didn't do AWS VPC that's probably my problem here terraforming net and as that's thinking there we'll just pull this on down and we'll start to make our locals block okay so we can go here make some locals and we'll do our Ingress and we'll just go like that and the idea is we can say Port whoops we can set the port like that 443 we have to always have a description so we'll just set that as well so port 443 we can set as much as we want here so I'll just go ahead enter okay and I think that looks right yeah so we have one Ingress here and then we'll just copy this and make a comma vs code is not really formatting the way I wanted to and so we'll do port 80. and then down below we will need to specify hour um for each okay so that's going to be within our Dynamic block so what we're going to do is tab in here I'm going to say dynamic and we'll type it Ingress because that's a match for what we're doing um and then from there we can do our four each equals local Ingress and then we need to specify our content I don't really understand why it's called content and things like that but I just know that that's what we have to do and it's not really that big of a deal so we'll go here and paste that in we can take out our Ingress block there we know we're going to need self these all here but what's going to change are these ports so we will go here it will say Ingress Value Port and this will also be Ingress Value Port and then this will be Ingress value description if we really wanted to we could also set the protocol protocol Pro Tove call and this could be then TCP and so we would just say Ingress value protocol so it just saves us from repeating these over and over again if they're all the same there's a lot you can do with Dynamic blocks but honestly you shouldn't do anything too crazy we'll do our terraform plan and see if this works whoops bring that up there um an argument VPC ID as not expected here okay so that was me just guessing from memory and I guess I guessed wrong uh so what we'll do is we'll just look that up AWS VPC data source terraform oh it's just ID okay so what we'll do is just set ID here and then we'll just hit plan again and that should resolve our issue there uh inappropriate value for a tribute egress security groups is required okay that's fine well this one says doesn't say uh Syria groups and this one doesn't say Security Group so that's probably our problem here so we'll just hit terraform plan again and here it says this VPC ID does not exist probably what happened is they might be in the wrong region it's very common problem on AWS just because of the way their UI works if I can get this window over here and so this is because we're in USC's we're supposed to be in U.S east one here and I'm going to go up to here we'll save that let me hit terraform plan and we could probably like use the filter and also just say choose the default but it's just so easy to put that in like that so doesn't seem like we have any problems here so let's go ahead and execute let's just double check to make sure these values are correct so for the Ingress um Port 443 Port 443 it's probably just because I didn't update the description probably because of a copy paste job yep okay and let's just make sure this works so we'll say terraform apply Auto approve and we'll give it a moment and it's already created so it's that fast we can go here and take a look at it if we like it's not that big of a deal um so we should see it in here I just have so many uh junk security groups here this is a bit hard to find oh allow TLS is what we called it so here it is go to our inbound rules 80443 and that's pretty much it so terraform apply destroy Auto approve okay there we go all right so I want to talk about versioning very quickly here and so I have a new folder called versions I'm going to just make a new file called main.tf and we're going to create a terraform block but what we're also going to do is set required uh providers or sorry required uh we're not providers required version and so what this is going to do is say explicitly what version of terraform we want to use and I'm sending it this as 1.0.0 and I'm using this tilde Arrow if you're wondering you know what is the logic behind all those things I think it's all explained in the semantic or semver.org so if you want to learn more I strongly recommend you read through this to understand all the stuff inside and out highly applicable across the devosphere not just to terraform um but you know if we go over to terraform GitHub repository and we drop down the branches and go to tags here we can see all the versioning we are using version 1.0.0 and it all goes up to 1.1.0 Alpha which is not out yet and if you wanted to really know what's going on here you go to releases and you can read what they have done so here 1.0.7 remove check for computer attribute prevent object types with optional attributes for ETC empty containers so when you're looking at the patch the patch which is the third number the the rightmost number that's going to keep you up to date in terms of security for the the major minor version that you have for the 1.0 and you absolutely always want to be using the latest and so that's what this tilde does it says take the far Road uh the the farthest number to the right and make sure that it's the latest version that has been published um and you know this comes back to my Progressive versioning slide which is if you want to have really good hygiene in terms of your devops we should be doing is at least setting the tilde for sure like this the tilde Arrow or I would even go as far as saying equals arrow and if you're really concerned about um you know not using the next major version you could say you will less than you know like less than um less than you know one point 2.0 even if it's not out that's a good indicator to say okay well I don't want to go too far ahead of time but if you want to have Progressive versioning you should really be setting it like this okay and this is going to be applicable for your image providers anything else so you know if we go over to if we go over to the registry and we choose whoops AWS and we drop this down here we have that required version as well so as you copy it in you're going to notice that it's actually hard coded but I would strongly recommend again if we go here and take this and at least at least do this and if you're really really being clever you could do that okay and these are also all in GitHub repositories as that's how everything works so you can go here and click and you can go over to the tags and see the versioning and you can go over to the releases and it's the same thing you can read about all the things that have changed okay and that's something that you should uh you know consider doing all right so that's all there really is to this I might want to show you one more thing and this one is with terraform Cloud so I'm going to go to terraform IO and we're going to open up our terraform cloud and I'm going to sign in I probably haven't signed in a while so probably ask oh nope no username password that's great what we can do is in a workspace we go to settings and is it Version Control no it is general and under here we can actually set the terraform version so if you happen to be working with a particular version you can go and say okay only use this version for terraform cloud and that will um that will not upgrade it'll just keep you there if you need for legacy reasons but again you know what you really should be doing is using that Progressive versioning doing nightly builds and discovering overnight that things are breaking so you can go fix those in the morning okay and that's it hey this is Andrew Brown from exam Pro and we are taking a look at terraform state so what is State well it's a particular condition of cloud resources at a specific time so give an example imagine we expect to have a virtual machine running Centos on AWS with a compute type of T2 micro that would be the state that we are expecting okay so how does terraform preserve State well when you provision infrastructure via terraform it will create a state file named terraform TF State it's very important to remember that name because it literally is an exam question the exact naming of that okay this state file is a Json data structure with a onetoone mapping from resource instances to resource or to remote objects and if you're wondering what is a remote object versus a resource instance I cannot tell you I would imagine one is the representation of things that are deployed in the cloud and the other one are objects or or things represented in the state file but they don't clarify it so I just have to take a guess so this is kind of what the Json structure looks like like you can see you see resources this is describing like a type of instance and stuff like that there's not really any case for you to ever go through the terraform State file and look at it but we might take a peek just so that we get familiar as to what it is doing so just to kind of give it a diagram to help you visualize this imagine you have your configuration file so you have your main TF maybe a variables TF a TF bars to load in your variables and then you run a terraform apply command what it's doing is using the terraform API and it's going to create what we'll say these we'll call these remote objects but maybe these are resource instances um but it will go ahead and create those things and then those will get represented within a state file so the idea is that whatever is in the cloud is going to match what's in that file okay now there is a CLI commands for terraform State and it's good just to quickly go through them so we have terraform State list this will list resources in the state terraform State move this will move an item in the state terraform State pull pull current remote State and outputs to St out terraform State push so update remote States from a local state terraform State replace provider so replace a provider in the state terraform State removed so remove instances from the state terraform State shows so show a resource in the state some of these are a little bit interesting so we'll definitely look in Greater detail to move and some of these people just explore through our follow alongs okay foreign special attention to terraform State move because it's definitely on the exam uh and it is a little bit interesting to what it can do so terraform State moves allow you to rename existing resources move a resource into a module move a module into a module so if you were just to rename a resource or move it to another module and run terraform apply terraform will destroy and create that resource but State move allows you to just change the reference so you can avoid a create and Destroy action so an example for renaming a resource we would have terraform State move and then we would have the we would identify the old one so here we have packet device dot worker and we are renaming it to helper so it's we that's just how we're doing it okay if we wanted to move a resource into a module what we do is say something like packet device dot worker and then do module.worker.packetdevice.worker okay so the idea here is that we're moving it into this module here uh and I think we could probably even rename it at the same time but uh we're not doing that okay so move module into a module so here we have module app and then we're moving it into the parent one so we go module.parent module.app okay so what's important to remember for the exam is that terraform State move is when you want to rename existing resources they're not going to get into these more complicated use cases but that's how you rename a a resource okay okay let's talk about how we back up our state file so all terraform state subcommands that modify state will write a backup file so readonly commands will not modify it so imagine listen show will not cause a backup file to be created terraform will take the current state and store it in a file called terraform.tsstate.backup so this is what it would look like backups cannot be disabled this is by Design to enforce best practices for Recovery to get rid of the backup file you would need to manually delete the files so there you go foreign from exam Pro and we are taking a look at terraforming knit so it initializes your terraform project by downloading plugin dependencies so providers and modules creating a DOT terraform directory so that's a hidden directory and creating a dependency lock file to enforce the expected versions for plugins in terraform itself so on the right hand side here we can see we have that hidden directory but also notice here that we have a DOT terraform lock.hcl that is our dependency lock file and so our dependencies are all going to end up within this sewers as providers that's the provider version there okay so terraform in it is generally the First Command you will run for a new terraform project if you modify or change dependencies run terraform in it again to have it apply the changes you need to know that for the exam because they will absolutely ask you that the First Command here is and these are ones with flags so you can just do terraform in it but we have some extra options so terraforming it hyphen upgrade upgrade all plugins to the latest version that complies with the configuration version constraint terraforma knit hyphen get plugins and I think it's supposed to be equals false there but skip plugin installation terraform init plugin hyphen dir equals pass so Force plugin installation to read plugins from only target directory and then we have terraform init hyphen lock file so you can change the lock file mode it actually doesn't say what the modes are so I don't even know what you'd do in that case and I could not find any examples but it is an option I just want to make it very clear that there is a dependency lock file but there's also a state lock file and the way you know that they're different is that one has Dot Lock in it and the other one has dot TF State this one up here is for dependencies this one of course is for State a terraform and it does not create a state lock file that is going to happen when you do a terraform apply okay let's take a look at terraform get so terraform get command is used to download and update modules in the root module so when you're a developer you own terraform modules and you may need to frequently pull updated modules but you do not want to initialize your state or pull new provider binaries and so the idea here is terraform get is a lightweight way it's because it's only updating the modules it's not pulling providers in most cases you want to use terraform init with the exception of local module development this will not show up on the exam but I saw terraform getting I was just so confused about it so I just wanted to make sure I included it here okay okay so we're going to be looking at three CLI commands that are used to improve debugging configuration scripts the first is going to be terraform format this rewrites terraform configuration files to a standard format and style terraform validate this validates the syntax and arguments of terraform configuration files in a directory and then you have terraform console an interactive shell for evaluating terraform expressions and so let's go jump into these three okay all right let's take a look at terraform format so this command applies a subset of terraform language style conventions along with other minor adjustments for readability so terraform format will be by default look in the current directory and apply formatting to all your dot TF files so let's look at some examples of what it would format so the first is adjusting spacing two spaces indent so here we have something and it's over indented and so by running terraform format it fixes the indentation we can also get syntax errors so notice here that we have a problem and so what it's saying is is that this bracket okay is supposed to be up here okay but it's all it's down here uh and the last one here is we can do terraform format hyphen hyphen diff that's going to show what it would change okay so there you go let's take a look at terraform validate so this runs checks that verify whether configuration is syntactically valid and internally consistent regardless of the provided variables in existing state validate is useful for General verification of reusable modules including correctness of attribute names and value types so here's an example where I just had some code and there was a problem it's just saying you're missing your argument because for an AWS instance you always have to specify an instance type so when you run terraform plan or terraform ply validate will automatically be performed one thing I need to mention about terraform validate is that it does not go to external resources to check things are valid so if you have a a value and it's expecting a string that's all it's going to check for it's not going to check that the string is actually a proper uh like type of size so if it's supposed to be like a t2.micro and you write you know gobblegoop in there it's not going to know that that's not a valid type so but we do cover that in the follow along so I think we have like some practice exam questions that cover that use case okay we're taking a look here at terraform console and this is an interactive shell where you can evaluate expressions so the idea is you type in terraform console and what I can do is I can you know use like builtin functions and expressions so there I'm using Min and I've actually entered it in incorrectly so there it's throwing an error and here I'm using the correct way of using it so I get the output so this is a great way just to kind of test very simple things you can't do things like Define variables or or resources or Define providers but you if you need to figure out how the Expressions work before you apply them in your code this is a great place to do that okay all right let's talk about terraform plans so this command creates an execution plan also known as a terraform plan and it consists of reading the current state of an already existing remote object to make sure that the terraform state is up to date comparing the current configuration to the prior State and noting any differences proposing a set of change actions that should if applied make the remote objects match the configuration and so this is an example of one that's generated you're going to see it uh throughout this course multiple times so it's not going to be unique that's why I don't have to make that too big for you there terraform plan does not carry out the proposed changes that's going to be the responsibility of terraform apply and a terraform plan file if you happen to generate one out is a binary file so if you open it up it's just machine code you cannot make sense of it okay so when you run terraform apply you have speculative plans and save plans and so speculative plan plans is what's going to happen when you run terraform apply so the tear so terraform will output the description of the effect of the plan but without any intent to actually apply it when you have a save plan you're going to have this hyphen out flag to save it and you can name that file whatever you like and it will generate out that save plan file and again that's a binary file so you're not going to be able to see what it does and what you can do is then pass it along to terraform apply so you do terraform apply whatever the file name is and when you are using terraform apply what you have to understand is that it will not allow it will not ask to manually approve it as you normally would it would just be Auto approved so that's one thing you have to watch out when using those safe plans but you know I just wanted to make it concretely understood that terraform plan can generate at a file uh and it's not actually the one that's doing the apply okay I don't have it written in here but when you do terraform apply it also is running terraform validate as well okay thank you let's talk about terraform apply here so terraform apply command executes the actions proposed in an execution plan and it has two modes the automatic plan mode and the saved plan mode so for automatic plan mode that's just when you run terraform apply what it's going to do is execute the plan validate and then the apply uh you can or you have to manually approve the plan by writing yes but if you want to skip that process you can use the hyphen Auto approve flag to automatically approve the plan we just saw save plan mode like how it worked in the previous slide but let's cover it again so when you provide a file name to terraform to the save plan file it's going to be terraform apply file and it's going to perform exactly the steps specified by that plan file it does not prompt for approval so if you want to inspect a plan file before applying it you can use terraform show okay all right let's talk about managing resource drift so drift or configuration or infrastructure drift is when you're expected uh resources are in different state than your expected State and the way we can resolve drift are in three different ways in terraform we can replace resources so when a resource has become damaged or degraded that cannot be detected by terraform we can use the hyphen replace flag we can import resources so when an approved manual edition of a resource needs to be added to our state file so we use the import command and refresh state so when an approved manual configuration of a resource has been changed or removed we're going to use the refresh only flag to reflect the changes in our state file it's very important to know these three different ways they will all show up an exam and in practice you're going to need to know them okay foreign let's first here take a look at replacing resources so we can use the terraform tank command it is used to Mark a resource for replacement the next time you run apply and why would you want to Mark a resource for replacement well the idea is that um you know and here's the command here but a cloud resource becomes damaged or degraded and you just want to return the expected resource to a healthy state so that's the idea behind it and the unfortunate thing is that terraform taint was deprecated in version 0.152 however there is a better way of doing it now and so it is recommended to use the hyphen replace flag and providing it a resource address when you're doing a terraform apply so it's basically the exact same thing the reason why they made this change was so that um you actually have an opportunity to confirm your change beforehand because terraform tank would just run and this one down below will actually prompt you to say are you sure you want to do this okay but it's not complicated you just do a hyphen replace and then you use the resource address of the thing that you want to use that for and this can be used for both plan and apply the replace flag appears to only work for a single resource so you can't use multiple resources it's just one at a time and that's something that you should remember okay so we just saw a resource address and resource addressing is very important to know for the upcoming commands let's just give it a bit more attention here so resource address is a string that identifies zero or more resource instances in your configuration an address is composed of two parts so the module path and the resource path and just expand out that module path it would be module.module name module index and then on the resource spec this is resource type.resource name and then if there's multiple instances you give it an index so module path addresses a module within a tree of modules a resource spec address is a specific resource instance in the selected module so a module is the namespace of the module module name is user defined name of the module module index when the multiple so when there's multiple specifying index on the other side that's your resource type your resource name an instance ID most of the times you're going to be just working with resources but once you start getting to modules it becomes pretty simple it's always going to be module period because that's just I think that's the name of the name value so it's always going to be module Dot and then the module name but here we have a very simple example just for resource type so here if we had a resource called Abus instance and it was web and there was four of them and we wanted to select the third one we do AWS instance dot web Square braces three and that would get us the third virtual machine so there you go foreign terraform import and this is a command that is used to import existing resources into terraform so this is how you define it so you'd say what resource you want and you can just leave it blank so do you define a placeholder for your imported resource and configuration file and you can leave the body blank and fill it in after importing but it will not be autofilled so you do have to specify all the values okay so the idea here is you're going to do terraform import AWS instance dot example and then the name of the ID so that Maps over to the resource address and the ID okay the command can only import one resource at a time this sounds very similar to that other command we saw for replace not all resources are importable you need to check the bottom of the resource documentation for support okay okay so we're going to look at refreshing and so we're going to break this between the old command refresh and the new command refresh only across two slides so terraform refresh command reads the current settings from all managed remote objects and updates the terraform state to match so here we have the terraform refresh and I just want to point out that the terraform refresh is basically the Alias for terraform apply hyphen refresh only hyphen Auto auto approved so you technically have this functionality in the latest version it's just that you can't use the old Alias terraform refresh terraform refresh will not modify your real remote objects but will modify the terraform state so terraform refresh has been deprecated and the refresh only uh and with the refresh only flag like it's been replaced with it because it's not safe since it did not give you the opportunity to review proposed changes before updating the state file so that's why the reason they got rid of it let's take a look here at the refresh only mode so hyphen refresh only flag for terraform planner apply allows you to refresh and update your state file without making changes to your remote infrastructure just to really make this clear I want to give you a scenario and I want you to pay close attention here to understand the difference because this is so important on the exam and also extremely useful for your daytoday operations so here's a scenario imagine you create a terraform script that deploys a virtual machine to AWS you ask an engineer to terminate the server and instead of updating the terraform script they mistakenly terminate the server via the AWS console because they don't know any better so what happens if you were to run a terraform apply versus with a refresh only flag so that's what we'll do with and without the flag so without the flag first terraform will notice that the VM is missing terraform will propose to create a new VM so the state file is going to be what's considered as correct and the changes and so changes to the infrastructure will be made to match the state file okay if we use terraform apply hyphen refresh only terraform will notice that the vmu provision is missing but with the refresh only flag it's going to know that the that the VM is missing it's an intentional okay so I have a couple spelling mistakes there but the idea is that it knows that the VM is supposed to not be there so terraform will propose to delete the VM from the state file so just the Json code from the state file so the state file is considered wrong and changes to the state file will be made to match the infrastructure so hopefully that makes it clear okay foreign how we would actually go about troubleshooting terraform so there are four types of Errors you can encounter with terraform uh the first is language error so terraform encounters a syntax error in your configuration for the terraform or HCL language you have state error so your resources States has changed from the expected state in your configuration file core errors so a bug that has occurred with the chord Library provider errors so the provider's API has changed or does not work as expected due to emerging edge cases and when we talk about what's easy for us to solve and what's hard well the first two are very easy and the other two are harder to solve so for language errors we can use format validate or version to resolve our language errors version would just be say hey what version are we using maybe we need to update it right validate with detect if something's wrong with um the uh the the syntax and format would fix formatting syntax but you know that probably wouldn't fix that much there for State errors the idea here is we might want to use refresh apply replace everything that we saw in the drift section for core errors we might want to go check out the log so TF underscore log is basically just the way of saying like hey these are where the log files are or is logs turned on we have a whole slide on that but really like all you're going to do is use the logs to find information and then report a GitHub issue since all terraform is on GitHub you just go there and then somebody would try to resolve it and the same thing with providers providers are all hosted on GitHub and so you would just use TF logs to try to find some information there but we'll take a look a greater look at TF log and how to you know get that information for the harder to solve cases okay okay so let's talk about how we would go about debugging terraform via the log file so terraform has detailed logs which can be enabled by setting the TF underscore log followed by the type environment you want to run so the variables that we have or the environments we can specify is Trace debug info warn error or Json Json will output logs at the trace level or higher and use parsable Json encoding as the formatting okay so logging can be enabled separately so you can do this via TF log core or you can get it at the TF log provider so if you just want core stuff or if you just want provider stuff you just set those environment variables and as we saw in the previous thing that there you know there was core errors and provider variables so that could be a good way to do that and so TF uh TF core TF log core and TF log provider take the same environment variables we see on the right hand side there Trace debug info Etc okay if you want to choose where you want to log things you just can set the TF log path I don't think I actually say where the default path is I think it's actually in the the project directory but if you want to override that you can I imagine it either takes an absolute path or a relative path and here's an example of a terraform log so this is for everything and so there you can see information I'm going to get my pen tool out here for a moment but you can see we have information about the provider this is using um there then there's some backend local stuff so you know there's some information you're not expected to understand this information generally but you could go bring it to the provider but you could probably solve something you know if you were to read the core code or the provider is okay okay so we looked at TF log which is the terraform log but there's also a crash log and so if terraform ever crashes and basically this means it goes into panic because it uses the go runtime it saves a log file with the debug logs from the session as well as the Panic message and back Trace to the crash.log and so I imagine this is golang information so I don't use golang that often but you can see we have dot gopanic.go so I think that there's not much you can do with it so this is where you would just create a GitHub issue and pass it along to the terraform team because they're going to be able to make sense of it okay foreign so we're on to our module section uh so let's first talk about how we would go find a module I know we already saw this earlier when we were looking at the terraform registry but let's just cover it again and talk about some of the uh uh details of search okay so terraform modules can be publicly found in the terraform registry and so on the left hand side when you're under the modules within terraform registry you can filter your providers okay but another thing you can do is you can type in Search terms and you can do partial Search terms like Azure compute but what I really want you to know is that only verified modules will be displayed in Search terms and so I assume that means verified and also official ones and the reason I'm giving this extra emphasis is because it was an exam question so I just want you to know that only verified and official ones are going to show up when you search okay foreign let's talk about using modules and there's our public modules and private modules so public modules are going to be on the terraform registry and private modules are going to be in terraform cloud or I suppose terraform Enterprise so terraform registry is integrated directly into terraform so it makes it really easy to start using them so all you're going to do is use the module block so I'm just going to highlight that there then we have the name of our module we're providing the source of our module and then there's the version of our module terraform init command will download and cache any module referenced by a configuration now looking at private modules it looks very similar um it's just that the name is different so we're specifying the host name in front here and a namespace as well so to configure private module axis you need to authenticate against terraform Cloud via terraform login so that's something there we definitely cover that a lot in the Brax exam so just in case you know you know all the education is there alternate alternatively you can create a user API token and manually configure credentials into CLI to configure the file so there you go foreign let's talk about how we would go about publishing modules and this in particular is for the terraform registry so these are public modules so if we want to publish modules it supports versioning automatically generating documentation allowing uh users to browse the version histories showing examples and read Maze and all of these modules are actually going to be hosted on GitHub so the idea is you're going to put your module there first and once a module is registered to push updates you simply push new versions to properly form get tags you have to name the your your modules in a very particular way on GitHub so the thing is it has to start with terraform hyphen then the provider so AWS and then the name so hyphen VPC and the way you publish it on terraform registry is you have to connect and publish via your GitHub account so you just hit sign in with GitHub and it's just going to give you a drop down and you're just going to choose the repo and that's as simple as it is okay foreign all right let's talk about verified modules so these are reviewed by hashicorp and actively maintained by official contributors to stay up to date and compatible with both terraform and their respective providers so here's an example of a module from our friend Anton down below and as you can see it has a little badge that's how you know that it's verified so verified modules are expected to be actively maintained by hashicorp Partners verified badges aren't an indication of the flexibility or feature support but just to kind of go through some things here very simple modules can be verified just because they're great examples of modules unverified modules could be extremely high quality and actively maintained unverified modules shouldn't be assumed to be poor quality unverified means it hasn't been created by a hashicorp partner so you know that again it's not indicative of quality but it just means that it's gone through a bit of vetting okay all right let's take a look here at the standard module structure and this is a file and directory recommended for module development and this is the idea if you were to go and publish your own module this is what people would expect to see so if you had root modules that's what it'd be and you have nested module I want to point out that when you are running terraform you technically are creating modules even if you aren't intending them to publish them into the terraform registry but you know when you make a main.tf you've basically made your own root module okay so the primary entry point is the root module and these are required files in the root directory so your main.tf is the entry point file for your module variables TF is the variables that can be passed in outputs.tf are outputted values readme describes how the modules work license the license under which the module is available for NASA modules which are optional but must be contained in the modules directory a sub module that contains a readme is considered usable by external users a sub module that does not contain a readme is considered inter for only internal use and the idea is to avoid using relative paths when sourcing module blocks so hopefully that gives you an idea okay foreign let's talk about core terraform workflows and these have three steps write plan and apply so write plan and apply we saw this kind of in the terraform life cycle and the idea here is that you know it's just to try to describe what it's going to be for your team and requirements as you grow and you're utilizing this workflow so if you're talking about individual practitioners so a single person a team using OSS so they're not using they're using open source software using terraform but they're not using the terraform Cloud platform and then what it would be like if they're using the terraform Cloud platform in terms of this right plan apply you're going to see these examples don't perfectly fit here I am just presenting a summarized versions of the documentation and the reason why is because on the exam this is one of the sub domains that you need to know so I'm not saying that I think these are perfectly presented but I think that I have to cover them because they are in the exam and I you do learn something here so we will go through them okay so let's take a look at a terraform or team workflow for a single person an individual practitioner looking at the right step first so you're going to be writing your terraform configuration in your editor of choice on your computer um but the thing is you'll be storing your terraform code in something like GitHub even if you are an individual user you're going to be putting in git or GitHub or some kind of Version Control System you're going to be repeatedly running terraform plan or even possibly terraform validate to find syntax errors and the great thing about this is that you get this tight feedback loop between editing the code and running your test commands because it's all on your local machine we're not sending things off to build servers or other services so it's very fast and easy talking about the plan stage so when the developer is confident with their workflow in the right step that commits their code to their local repository this is the stage where it's a local limit it's not a remote commit they may be only using a single Branch so just probably working in Maine or if you're still using the old syntax Master Branch once their commit is written they'll proceed to apply that'll bring us to the apply stage so they will run terraform apply this is on your local machine it's not part of any other process you're just running terraform apply and it'll be prompted to review their plan after the review the final review they will approve the changes and await provisioning after a successful provision they will push their local commits to their remote repository so this is where you will then finally commit your code so there you go so we looked at what it would be like if we had a single person working with terraform let's talk about if it's a team and they're not using terraform Cloud they're just doing it uh the oldfashioned way okay so each team member writes code locally on their machine in their editor of choice as per usual a team member will store their code in a branch in their code repository whether it's a uh per feature per user per whatever is up to you branches help avoid conflicts while a member is working on their code but branches will allow an opportunity to resolve conflicts during a merge into main it's no different than working with you know code because that's what it is terraform plan can be used as a quick feedback loop for small teams so we still have that option but as your team grows larger a concerned over sensitive credentials becomes a concern and so this is where you may need to introduce a CI CD process so that it's it's going to be in control of the credential so the idea is that you don't run plan you just push to your branch and it can run it or it only happens on pull requests that's up to you know your team and how they decide to set it up when a branch is ready to be incorporated on pull requests an execution plan can be generated I guess when we say execution plan this could be a speculative plan okay so it's not something we're going to run it's just something we're going to review and displayed within the pull requests for review to apply the changes the merges need to be approved and merged which will kick off a code build server that will run terraform apply that's the apply stage there so this is all good but what we need to kind of highlight is all the work and labor that goes into setting up your own team if you're going to do it all from scratch without terraform Cloud so the devops team has to set up and maintain their own CI CD pipeline they have to figure out how to store the state files whether they're going to be in a standard back in a remote state or they're going to encrypt it and put them into the code repository which is not recommended they are limited in their access controls so they can't do granular actions to say okay I only want to allow this person to destroy and this person to apply it's not like that with get repos they have to figure out a way to safely store and inject secrets into their build server's runtime and that's not argue argue it's not very hard depending on the solution that you choose but it is a thing that they have to figure out they might need to manage multiple environments and this can create additional overhead because for each environment you'll have to create another ciccd pipeline okay so hopefully that gives you the idea of the effort here and this is going to set us up to say what terraform cloud is going to solve okay let's take a look at what our team workflow or our terraform workflow will be if we were using terraform clouds so 18 we'll use terraform Cloud as a remote backend of course they were using uh their favorite editor as per usual working on their local machines to write that code the input variables will be stored on terraform Cloud instead of their local machine terraform cloud integrates with your version control system such as git to quickly set up a cicd pipeline a team member writes code to a branch it commits per usual so that doesn't change a pull request is created by a team member in terraform Cloud will generate the speculative or execution plan however you want to call it for review in your version control system the member can also review and comment on the plan in terraform Cloud after the pull request is merged terraform cloud in the terraform Cloud runtime sorry the terraform Cloud runtime will perform a terraform apply and a team member can confirm and apply the changes within the terraform Cloud UI okay so terraform Cloud streamlines a lot of the CI CD efforts storing it storing and securing sensitive credentials and makes it easier to go back and audit the history of multiple runs so in terms of the exam if and I didn't see any questions on this but I know they exist they're just going to be asking you you know which like they might describe something and say which kind of workflow does this fit and so if you generally know the difference between terraform Cloud working with the team open source software without terraform cloud and individual workflow it's not too hard you'll be okay all right foreign we're taking a look here at back ends and each terraform configuration can specify a back end which defines where and how operations are performed and where State snapshots are stored so terraform divides their backends into two types we have standard and enhanced first looking at standard this is where you can only store the state and it does not perform terraform operations such as terraform apply so to perform operations you have to use a CLI on your local machine and the reason why is that standard back ends are basically thirdparty backends so a standard back end could be AWS S3 and so you know this is a storage service it doesn't have the capabilities of pragmatically triggering things okay uh when we have when we're talking about enhanced back ends we can store both the state and perform terraform operations so enhanced backends are subdivided further so we have local so files and data are stored in a local machine executing terraform commands and remote so files and data are stored in the cloud so terraform Cloud the reason why they can perform terraform operations and when you look at local and remote local is your machine so of course it can execute terraform and then remote is terraform Cloud which has its own runtime environment it's basically a build server so it of course can do both those operations and that's how you're going to remember the difference between those two okay all right so we were just talking about standard and enhanced back ends and I was saying that standard back ends are basically thirdparty providers that is something other than terraform Cloud so let's take a look at what options we have available to us starting with the major cloud service providers so AWS has simple storage S3 Azure has block storage account notice it says Azure RM because that's just the name of what they call it I don't know what the RM stands for resource manager I imagine Google Cloud Storage is an option then we have Alibaba we have openstack we have 10 cent and then we have Manta which is part of joynet's cloud storage so I don't think a lot of people are going to remember joinet joynet was very popular provider like post or pre2010 so I remember them 10 cent is a Asia provider I think they were a texting service they're very popular but they're not the largest provider over in Asia Alibaba is and of course we have the the three major ones here and then openstack is for uh private Cloud okay then on the other side of it when we're looking at more exotic or things that aren't Cloud server providers we have um artifactory we have hashicorp console etcd postgres database kubernetes secrets and you can also use the ACP protocol now notice I have these little locks here that's indicating which have state locking which do not if you don't know what state locking is don't worry we'll talk about it here in a moment um would there be a question on the exam saying oh which service you know doesn't have state locking and the answer is no they would never ask that it's too minute but just notice that the only thing that doesn't have state locking is uh artifactory which I'm kind of surprised because it's a universal repository manager and there's the one case like with HP protocol where it's optional so it's not that you can't have it it's just that it's not it doesn't necessarily have to be there and in particular some the the state is or the Locking State locking is buy another service so for AWS it's dynamodb that is doing the state locking and then with Alibaba uh alibaba's cloud storage it's table store okay so uh you know there's not much to know here but uh you know it's just kind of interesting if you want to have a different kind of backend maybe you want to use postgres because you're really familiar with it you can actually store it there okay so let's take a look at what it would look like if we were to use a standard back end so here's an example for AWS since I think S3 is very popular so if you were to set up your back end so here I have a bucket here and I've have to name the state file so I call it State file and then I give it the region and there it is so the backup of a state file will reside on your local machine so the backup's not going to be an S3 configuring a standard back end does not require terraform cloud account or workspace because you know it's it's totally separate from it so that's something I wasn't sure when I was first using it was okay can I use a standard back end but I still have to have a terraform account or workspace and the answer is no all right all right so we're taking a look at enhanced back end so we're going to start with local and then move on to remote so for the local back end we store the state on the local file system and it locks the state using the systems API it also performs operations locally and when we say local we just mean a local machine we don't necessarily mean it has to be our workstation a code build server could also be considered a local machine okay it just means anything but terraform Cloud that is running the terraform code so by default you are using the backend State when you have not specified any kind of back end so normally you'd see a background defined in here we don't so it's going to just default to the local you can specify the back end with an argument local most people don't you just leave it blank and you can change the path to the local file a working directory so I think that if you were to specify you'd want to put the path in but generally again we keep that blank you can set a back end to reference another state files so you can read it outputted values this is a way of crossreferencing stacks so just notice that we have this thing that says terraform remote State we're going to repeat this later on in the course because this is a very important concept and I feel that it gets overlooked in the documentation but it has to do with local backends so the idea is that you could say hey I have this other file that has a back end and I'm just going to use data sources specify its backend and then point to its actual terraform State file okay foreign we're taking a look here at remote back ends for the enhanced backend type and a remote back end uses the terraform platform which is either terraform cloud or terraform Enterprise by default I usually just say terraform Cloud when I'm referring to the terraform platform but just to understand there is a distinction between terraform cloud and terraform enterprise Enterprise being the onpremise offering okay so with a remote back end when terraform apply is performed via the CLI the terraform Cloud run environment is responsible for executing the operation so that's what you get when you get terraform cloud is you get this run environment so it's basically just a builtin code build server to run terraform commands for you one thing I really want you to know about remote backends because this really tripped me up uh when I was actually trying to make the follow along which is the fact that because the terraform Cloud run environment is the one exiting the command your provider credentials need to be configured in the environment variables in terraform Cloud so you know if you had a project and you configured it with um TF bars locally and then you were to swap out your remote backend it's not going to work the way you expect it to because um again the terraform Cloud run environment is not going to take your credentials and then move them to the cloud okay you have to do that yourself when using a remote backing you need to set a terraform Cloud workspace so you would go ahead and go to terraform cloud and just go create one you create one or multiple ones for a single project if you use a single workspace for a project you're just going to use the workspaces uh name and if you set multiple workspaces via prefet you can use a prefix okay and the way this prefix works is that you're going to say like my app or something and when you go to run terraform apply what it's going to do is prompt you to say which environment do you want to use so and this is what you've created in your terraform Cloud workspace you've created one called Dev you've created one called Product saying which workspace do you want to deploy to I want to know that you can only set either name or prefix you can't set both okay so just understand that all right so we're taking a look at the cloud backend um uh code block here and so this is very similar to terraform backend remote if we're specifying terraform as our back end but now instead of having to do backend remote we can just give it a cloud block and the reason for this is well I don't know you can still foreign all right let's take a look at the cloud backend block so when using terraform Cloud as a remote backend State you should instead use the cloud block to configure its usage so uh previously in previous uh terraform versions it would look like this so you'd have terraform back and remote and the way you know it'd be using terraform cloud is that the hostname would be set as app.t terraform.io and so this has been changed so now that all you have to do is use this Cloud block and so you just don't specify that hostname and for the most part um uh you know the configurations between them are very similar so the only thing that we're seeing different is this prefix maybe that prefix is still there we'd have to double check the documentation on that but what's important to understand is that there's this Cloud block and it is the record amended way to do it now I do want to point out that I tested both and the remote the remote version still works so you can still do it this way if you're doing it the old school way and this is just an alternate way uh would they ever make it so you could not use the remote state in the future for uh terraform Cloud you have to use the block I don't know but I can tell you right now that they do have that cloud block so both are valid options and the latter of course being the recommended uh use one so yeah there you go thank you so since we're talking about back ends let's talk about backend initialization in particular the back end hyphen config flag this is more of an exotic option but I figured we should go over it because it could appear on your exam so the flag for the back end config flag for terraform init can be used for partial backend configuration so in situations where the backend settings are dynamic or sensitive so they cannot be statically specified in your configuration file this is what you would do so here would be your main.tf and notice it says back in remote and it has no details in it so then what you do is you create a separate file called backend.hcl and now you're specifying the workspace the host name the organization and then uh with terraform and net you're going to then say Okay use this file as the backend information that we're going to inject into our backend remote so there you go okay we're taking a look here at terraform remote State and I give this a lot more attention in the course because I feel that it gets overlooked within the terraform documentation it's such a powerful feature and something that I'm used to having in cloudformation which is crossreferencing Stacks so I want to make sure that you know it too so terraform remote State data source retrieves the root module output values from another terraform configuration file using the latest State Snapshot from the remote back end so the idea is that you can reference a state file from somewhere else you can do it uh via a remote backend and a local backend so just take a look here we see data and the data sources terraform remote State and we're setting the back end as a remote on the right hand side here it is local and if it's a local back end we give the path to the TF State file if it's remote that means it's another workspace and terraform Cloud so we set the workspace that we want to access and then when we want to access those resources we're using data sources so we do data Dot and it's terraform remote State and then we specify it knows that it's no difference whether it's remote or local but you're going to be getting datas from outputs okay so only the root level output values from the remote State snapshots are exposed resource data and output values from nested modules are not accessible to make module outputs values accessible as a root module output values you must explicitly configure a passthrough in the root module so here's an example of us doing a passthrough so we have a module called app and it has a source and then we're just setting an output notice that we are just grabbing the value and passing it along I want to tell you about the alternative to terraform remote State because if you can you should use these as opposed to using terraform Road States so terraform remote state only exposes output values its users must have access to the entire State snapshot which often includes some sensitive information it's recommended explicitly uh it it's recommended to explicitly publishing data for external consumption to a separate location instead of accessing it via a remote state so what would be Alternatives well you've seen this because when we looked at data sources we were technically we're using Alternatives but the idea is that you are going to say AWS S3 bucket AWS rep 53 zones and these are kind of already set up to work with AWS or whichever provider okay so that's that there but uh yeah hopefully that's pretty clear so the idea is that when you can use these data sources because you know they're actually working off of live data right like it's hitting a resource it's not just looking at a state file that contains data okay so we had mentioned State locking just briefly when we were looking at standard back ends but let's go take a look in detail what these are because they're very important for your workflows so terraform will lock your state for all operations that could write State this prevents others from acquiring the lock and potentially corrupting your state so State locking happens automatically on all operations that could write State you won't see any message that it's happening if the state locking fails all right so terraform does not output when a lock is complete however if acquiring the lock is taking longer than expected terraform will output a status message so neither on failure and neither when it is complete just if it takes too long so there's a transient issue something with like a networking issue you can disable lock so what you do is use the hyphen lock flag but it's generally not recommended you can force and unlock there's cases where uh you know just does not unlock or add so what you'll have to do is use the force unlock camera and if you unlock the state when someone else is holding the lock it could cause multiple writers Force unlock should only be used to unlock your own lock in the situation where automatic unlocked failed to protect you the force unlock command requires a unique lock ID so terraform will output this lock ID if unlocking fails so this is what it would look like so we have terraform Force unlock and then whatever the ID is hyphen Force so yeah there's a lot going on here but yeah that's what it is all right so let's talk about protecting sensitive data so terraform State file can contain sensitive data so longlived database credentials and is possible attack Vector for malicious actors and so when you're dealing with the local state when you're using local backend the state is stored in plain text Json files you need to be careful you do not share the state file with anyone you need to be careful you do not commit this file to your git repository when you're using a remote state with terraform Cloud the idea here is the save file is held in memory and is not persisted to disk the state file is encrypted at rest the state file is encrypted in transit with terraform Enterprise you have detailed audit logging for tampering evidence to take it one step further so you can just see that there's a lot of work that has to be done when you are using it locally but with terraform Cloud this is kind of the cell for terraform cloud is that it's just going to do everything possible to make that secure would it be secure to use a remote say with a thirdparty storage let's talk about that so you can store state with a various thirdparty backends but you need to be careful to review your backend's capabilities determine if you meet your security and compliance requirements some backends are not by default as secure as they could be so for example AWS S3 you could have you have to ensure encryption and versioning is turned on and you need to create a custom Trail for data events so you can get tamper evidence logging if you turn on data events for custom cloud trail events but one thing that if it's important to you is that you know if you use S3 it's not held in memory you know that'd be using a cloud HSM or KMS so you know you have to understand there are some tradeoffs okay let's take a quick look here at terraform ignore files and if you know what git ignore files it's pretty much the same thing so when executing a remote plan or apply in a CLI driven run an archive of your configuration directory is uploaded to terraform cloud and so you could Define paths to ignore from upload via the dot terraform ignore file at the root of your configuration directory if this file is not present the archive will exclude the following by default so dot get dot terraform and Dot terraforming Nora works just like a DOT get ignore with the only difference is that you cannot have multiple dot terraform ignore files in subdirectories only the file in the root directory will be read so there you go and yes I know there's a double the okay so don't worry about that foreign foreign let's talk about resources so resources in configuration files represent infrastructure objects such as virtual machines databases virtual Network components and storage and so it pretty much looks like this a resource type is determines the kind of infrastructure object it is so here it says AWS instance and this would represent an AC AWS ec2 instance this is all defined within the providers documentation so you have to kind of look at what name they use to figure out what it is and even though you don't see provider explicitly set here a resource does belong to a provider and you can explicitly set it and you would do this when you'd want to set a resource outside the default provider that you have in your configuration file and so one little thing that I hadn't mentioned anywhere else and that's why I made this slide was to mention about special timeout nested blocks within resources so some resource types provide a special time on asset block argument that allows you to customize how long certain operations are allowed to take before being considered to have failed okay so there you go foreign let's talk about complex types so a complex type is a type that groups multiple values into a single value and complex types are represented by type Constructors but several of them are have shorthand keyword versions okay so there are two categories of complex types we have collection types for grouping similar values so list map set and structural types for grouping potentially to similar values so Tuple an object and it's now that we have an overview let's go jump into collection types and structural types a collection type allows multiple values of one other type to be grouped together as a single value and the type of value within a collection is called its element type the three kinds of collection types are list map and set and so looking at our first one here what we're doing is we are setting ourselves something that looks kind of like an array and it's these list type here and what we can do is use our index so the indices 0 to reference the first element which is Mars so that's going to make our username Mars for a map it's very similar to a ruby hash or singleness to Json object and the idea here is that it's very similar to the first except now we're doing a key and value and then we access it by based on the key name so plan B is going to return 50 USD okay we have set it is similar to a list but has no secondary index or preserved ordering all values must be of the same type and will be cast to match the first element okay so it's a great way to kind of have um well I guess no secondary index but yeah so you do two set and then it would turn into this okay all right let's take a look here at structural type so a structural type allows multiple values of several distinct types to be grouped together with a single value structural types require a schema as an argument to specify which types are allowed for which elements so this is what they're talking about when they say this schema so when you actually Define the variable notice where it says object and you are actually setting a is going to be a string and B is going to be a string there's this optional option which I think is right now in beta but hopefully by the time this course is out or it's the future you have that option there but just assume that they're all required so that's what they're talking about is that you are specifying exactly what you expect the schema to be okay so there are two kinds of structural types we have objects and tuples and they're going to look very familiar to maps and lists because they're pretty much the same but with explicit typing so object is a map with more explicit keying so this example we'd have name for string age for number and so that's what it would expect the data structure to be for Tuple multiple return types with a parameter so we can have string number or Boolean so so this is where we'd have a as a string 15 or true as a Boolean so you know there you go hey this is Andrew Brown from exam Pro and we're going to look at the collection and structural type so I have a new folder down below just in case we need to Define some things so I'm going to go here and just call this main.tf and we are just going to configure this for a local terraforms we'll just give the brackets there and so the idea is that we might have different kinds of variables and we had done this previously where we created a list and a map but we can do that again so we'll have like planet right so that's list and then we just default that to a value Mars Earth Moon and then we could also have you know plans here and that would be our map type okay and so here we'll just set it the curlies plan A Plan B plan C um so we'll do terraform console and so that should load these variables for us to use and so if I do var.plans I get that and if I do VAR dot planets uh didn't like what I did there input variable has not been declared I suppose just plan it there so I should have named that planets up here and so what we're going to do here is just go ahead and exit type clear I'm just going to expand this a bit bigger so we're taking over more of the screen and let's take a look at structural types so these require you to actually Define um parameters so what I'm going to do is go down below and we're going to do the object and object is very similar to the map so let's go down here plans object and so here what we do is we'd say type object and we would just have to Define some settings here um so we could say a is a string all right we'll see if that works the default value is now compatible with the variable type constraint attribute a is required so that's fine what we could do is just Define this as like plan A Plan B plan C and now if we just do VAR plans object when you are using this you know you might want to specify some different kinds here so you could just say like you say like plan here as soon as they plan name plan amount maybe it's like number and so then we'd say plan name plan amount basic maybe this will be 10. okay and we'll just uh type exit here and go back into terraform Cloud hopefully we don't get an error here so the plan amount is required so you know we can't have a spelling mistake here just do VAR plan here um well we named it correctly there and when we went up here and specified it I think we got it right plan object so tripler doesn't like here oh you know what we're not in terraform Cloud okay that's fair and we're still spelling this wrong oops okay so there we go we get our basic plan um and then we could do a tuple here so I don't know if I've ever defined a tuple before so let's just try it here and so we'll just say uh groceries or value or random type equals Tuple I'm just looking up if there's any kind of definition I can find here I'm not really finding anything but I'm just going to go Define this here because I thought maybe it needed like a schema or something but maybe it doesn't so we'll just say hello 22 false okay terraform console dribble Constructor requires one argument specifying the element types as a list okay so if that's the case then what we could do is say string number Boolean the type Constructor requires one argument specifying the number of elements so clearly I'm doing this wrong so just give me a second I'll be back in a moment okay all right so I think the problem here was just that I need to make brackets here like this we'll give that a go boolean's not a valid option what if we try Bool okay we say VAR dot random good and so I'll just go ahead and exit that out I'm just going to see what happens if I change the order here so let's say I do instead of 22 here we go here okay so notice that you know we can have all sorts of Kinds but they have to match exactly the order that is there so yeah that's pretty much it so there you go the terraform language includes a number of builtin functions that you can call from within Expressions to transform your combined values so we have numeric string collection encoding file system date and time hash encrypto ipnetwork type conversions so we are going to go through all of these we might not go through every single function but we'll go through every single major category in terms of the exam the only thing that's going to show up might be string functions why they do this I don't know it's not a very good exam question but those might appear but I think that this is one of the strongest features of terraform over something like cloud formation and I really want to just show you the Gambit of them okay foreign let's take a look here at numeric functions starting with absolute so Returns the absolute value of the given number so 23 is 23 0 is 0 and if you get a negative number it's going to flip to the positive for 4. what it does is it rounds down to the nearest whole number so see where it says 4.9 becomes a 4. you have logs so it Returns the logarithmetic I can't say that word logarithm logarithm of a given number in a given base so log 50 comma 10 is going to give you that 16 comma 2 is going to give you 4 okay seal it it's where it will always round up so see where it says 5.1 and it goes all the way to 6. we have Min so take one or more numbers and return the smallest number from the set and Max take one or more numbers and return the greatest number of the set I don't have examples because that's pretty straightforward you know if there's a two and a four it's going to return the two in Min if it's a two and a four it's going to return the four for Max we have parse n so parse is the given string as a representation of an integer in the specified base and Returns the resulting number so if we have a hundred here in strings it's going to and we say comma 10 we're going to get 100 because that's the base system it's base system 10 base system 16 we can see letters in there right so it's able to translate that this is two so that's basically binary so zeros and ones so you get the idea there uh pow so calculates an exponent by raising its first argument to the power of the second argument so that's just the way of doing powers and then we have Signum so determine the sign of a number returning a number between negative one and one to represent the sign so there you go all right let's take a look here at string functions the first being chop so removes new line characters at the end of a string so you know if there's a hyphen n or sorry backslash n you don't want to see that there that's the way you get rid of it then you have formats it produces a string by formatting a number of other values according to the specification so here there are percentage Delights so this is representing a a digit so it's taking that number this says it's going to be formatted as a string okay format list so produce a list of strings by formatting a number of other values according to a specification string so here we have an array and then we have our specification so you can see it's substituting the name there um we'll look at indents so adds a given number of spaces to the beginnings of all but the first line in a given multistring so here we have a string and what it's going to do is see where we have the interpolation here and then we have indent I know the the highlighting is not great because it's a single string but we have interpolation we have parentheses two so give it a a layer of two indentation and then it's going to break that up and give it indentation so we have join so produce a string by concatenating together all elements of a given list of strings with a given deliminator so use delimiters is double click or sorry it's a comma and so it's going to glue that together to make this okay if there's only a single one there just won't be any comma in there we can lower all the text it's pretty straightforward we have regular Expressions so that is an extremely powerful feature so here we have the regex I don't know what the regex format is uh maybe it's Pearl I'm not sure there's like a bunch of different types of regex Standards so you know do you have to figure that out so you know how to use it and then there's a regex all so applies to a regular expression to a string and returns a list of notches where this just is returning uh one okay We have replaced so search is a given string for another given substring and replaces each occurrence within a given replacement string this is just like the JavaScript replace we have split this is the opposite of join so if we want to split on the comma we specify comma here we have Str rev so string reverse so reverse is a string so hello becomes Ole we have sub ol sure I don't know um so substring so extracts a substring from a given string by offset and and length so we have a substring and we're saying we want one to four so we only want one two three four here okay because it starts at zero we have title so make a title okay so capitalize the H and the w we have trim removes the specified character from the start and end of the string so we don't want these and we tell it to remove those there's a lot of string functions uh so we have trim prefix so it removes the specified prefix from the start of the given string if the string does not start with the prefix the string is is returned and unchanged so here we say we want to get rid of hello in the front so we do that suffix is the opposite so we want to get a rid of world out of the suffix so we do that we have trim space so removes all types of white space from both the start and end of the line so it gets rid of the new lines and the spaces upper is going to put everything to Upper and there you go on the exam they probably will ask you uh like what string function does or which one does not do something so this is the only part of the builtin functions you have to know for the exam I don't think it's a very good exam question but it does appear there so you need to know it okay foreign functions and these are the most powerful builtin functions and there's a lot of them and I made sure to give you an example for each one because I really do want you to know these because this is the power of terraform the First on our list here is altru's returns true if all elements in a given collection are true are true or it also returns true if the collection is empty so it's either true true right or we have true false so because there's a false it's not going to be true so any true is very similar but there only has to be one that is true so if this is true and there's a false that's going to be true if it's blank it's going to be false okay we have chunkless splits a string list into fixed size chunks returning a list of lists so here we're telling it to chunk it every two so grab every two and make them into their own little array or list I suppose we have coalesce takes any number of arguments Returns the first one that isn't null or empty string if you're used to postgres you use this all the time but the idea is it's going to grab the a in this case it'll grab the B because that's blank in this case we'll grab the one because that's the first value we have coalesce list takes any number of list arguments and Returns the first one that isn't empty so very similar it's just using lists or if we want to call them array so the first one is available so it takes that one we have compact so it takes a list of strings and returns a a new list with an empty string elements removed so it's just going to get rid of that space there and we'll get ABC we have concat so it takes two or more lists and combines them into a single list so that's very convenient we have contain so determines whether a given list or set contains a given single value as one of its elements so does it have an A yes it does does it have a d no it does not we have distinct so takes a list and returns a new list with any duplicate elements removed so we just want to make sure we only have one of each so do we have any duplicates here we have two a's and two B's so we're going to end up with just a single list so only exactly one of each letter we have elements retrieves a single element from a list so get me the element at uh at three here so um wait retrieves a single element from a list okay well that's what it does you give it a three and it gives you an a I don't know why it's not clicking for me but I I'm not following through here index finds the element index for a given value in a list so we say where is B and the index of B is is one because it'd be zero and this would be one still really confused about this one flatten takes a list and replaces any elements that are are lists with a flattened sequence of list content so basically it says give me a bunch of eraser let's turn into one flat list uh Keys take a map and return a list containing the keys from the map so we just want the keys a c and d we want length this is pretty straightforward so what's the length of this zero this is two this is one because it's a one uh mapper one thing key value in there and if it's a string it's going to count the characters so there's five characters we have lookup so retrieves the value of a single element from a map given its key if the given key does not exist the given default value is returned instead so we say look up a and what we get is a y right look up C and it could not find C so by default give us what instead key a match Keys construct a new list by taking a subset of elements from one list whose indexes match the corresponding indexes of values in another list that sounds complicated let's read that one more time so constructs a new list by taking a subset of elements from one list who indexes match the corresponding index of values in another list that is confusing so we have one less than another one so we have this one here and we have us West Us East USD so we say okay we have uses so the elements here is two and three so give us two and three so that's what it does that was a that was a tricky I can't think of what you use that for but that's a interesting function merge takes an arbitrary number of maps or objects and returns a single map or object that contains a merged set of elements from all arguments so it just merges them together so it's just like concat or I suppose like flatten uh one takes a list set or Tuple values from with either zero or one element if the collection is empty one returns null otherwise one Returns the first element if there are two or more elements then one will uh one will return an error so it returns null on an empty List It Returns the first one and then here it says invalid function so it's just saying is there one right is it one or zero ranges generates a list of numbers using a start value a limit value and a step value so we say three and we get 0 1 and 2. during its a list of numbers using a start value limit value and a step value okay uh reverse so takes a sequence and produces res oh not reverse Reserve sorry Reserve takes a sequence and produces a number induced sequence of the same length with all the same elements as the given sequence but in reverse order oh it is reverse r e reverse I guess I spelled it wrong here sorry reverse one two three three two one just notice this is a spelling mistake okay uh set intersection so function takes multiple sets and produces a single set containing only the elements that all of the given sets have in common in other words it computes the intersection of the sets well it's tiring so from what I can tell it's like they all have B so give us B right set product functions find all the possible combinations of elements from all of the given sets by Computing the cardistarian product we're really getting into math here so we got app one and app2 and so we got uh development develop okay so this continues on so it's going to say give me app one with development give me uh app two with development then Apple Mustang and then app2 with staging and etc etc because that's why I put the three dots there set subtract function returns a new set containing the elements from the a from the first set that are not present in the second set in other words it computes the relative complement of the first set in the second set uh it lost me there but it says set subtract so here I see a B and C A and C minus it you get B okay set Union function takes multiple sets and produces a single set containing the elements from all the given sets in other words it computes the union of the sets so it says set Union so we have a b b c and d and in the results we get d b c a so I guess um single set containing the elements from all the given so yeah yeah I guess it's just we get unique ones across the sets uh we have slice and notice like we're going through all these things it's like you probably won't use these more exotic ones so it's not a big deal if we don't nail them here but it's important that we go through these so that you know you just know all the options are here so slice extract some constructive consecutive elements from within a list so here we are saying one and three so we have B and C that's where they start index one um and then extract some consecutive elements from within a list one comma three okay sort takes a list of strings and returns a new list with those strings sorted lexicographically so we have e d a and x and so now they're alphabetical so a d e and X well I think this is the last one uh some takes a list of set numbers and Returns the sum of those values that's pretty straightforward add them all up transpose take a map of list of strings and swap the key and values to produce a new map a list of strings so kind of like inverts it values takes a map and returns a list containing the values of the map so we saw this earlier we got the keys this is where we just want to get the values zip map so construct a map from a list of keys and a corresponding list of values so we have a b one two and this turns it into a equal one b equals two I think I saw this on the exam so that one you might want to remember but yeah that's collection functions as you can imagine they're extremely powerful but they can also be really confusing so maybe just use them a little bit when you need to okay we're taking a look here at encoding and decoding functions so functions that will encode and decode for various formats so imagine we need to encode into base64 so we do hello world or imagine we give that encoded string and we want to decode it back to hello world that's what we can do so there's a lot of different encoding decoding functions most of them are the same they're just kind of variants so we're not going to go through every single one but I'll list them out so you know what they are so we have base64 encode Json encode text and code base64 yaml encode base64 gzip URL encode base64 decode CSV decode Json decode text decode base64 yaml decode and just notice that you know these aren't one to one so there is one for this we have one for here uh we have one for yaml uh this is unique this is unique this is unique okay just so you can tell for your own code I think this one's a very common one that you'll use but the idea is that let's say you have hello world you want to replace that string with a uh whatever friendly for a URL right so it just encodes it okay it's very useful when you're making URL links so there you go we're taking a look here at file system functions so this has everything to do with the file system so the first is absolute path so the idea is you give it something that's relative and it's going to give you something absolute directory name so this is a string containing a file system path and removes the last portion from it so we don't need the file name so we just remove that off of there we have path expand so takes a fossils and path that might begin with a tilde and expands it into its absolute path so this would be like for home okay um base name so it takes a string containing a file system path and it's basically the opposite of directory name we just want the file here okay onto the next page here this file will read the contents of the file pretty straightforward we can check if a file exists so we just do file exists here we have file set so it enumerates a set of regular file names given a path and pattern file base64 so it reads the contents of a file at a given path and Returns the basics before encoding that might be good for images template file so reads the file at a given path and returns its content as a template using a supplied set of template variables so that's really useful if you want to do some kind of templating uh and just notice it's a twostep process so this is the template file the actual file itself and then we load it here it's called a DOT TPL so there you go we're taking a look at date and time functions the first is format date so the idea is that we provide a format that we want and then we give it a timestamp that is in the RFC 3339 format and we get a variety of different um formats out there we can add time so again it's going to be that RFC 3339 format and we say add 10 minutes add one hour then we have timestamp so you it returns a UTC timestamp string in the RFC 3239 format so you just say timestamp it's I guess it would get right now and then you get it in that format okay let's take a look at hash and crypto functions so generates hashes and cryptographic strings so the most popular one out there would probably be B so here we just say hello world and we're going to get this thing here understand that a hash cannot be reversed so once it is turned uh into uh you know this format the only way you're going to be able to confirm the contents of it is to Hash something that is similar and then compare it against it okay so we have base64 Shaw 256 we have 512 we got B Crypt we have file Bay 64 Shaw 256 file based 64 Shaw 512 file md5 file Shaha one file Shaw 56 file Shaw 512 md5 RSA decrypt sha1 Shaw to V6 Shaw 512 uuid uid V5 so I only showed the one because you know it gets kind of boring to go through all these and really it's just going to be based on your use case what you're going to be using on a daytoday basis is probably bcrypt md5 and you uids so there you go let's take a look at IP network functions these are the coolest functions I think that are built into terraform so we have cider host so what we can do is give ourselves a a address and then we can give it a subnet Mass size and we'll get back an IP address and so you can see we have this both in the ipv4 and the IPv6 we have cider net mask so here we are doing cidernet math so we just say forward slash 12 and it's going to translate it into the full ipv4 then we have cider subnet so this is just where we say Okay I want a subnet of a particular size so we say 172 1600 comma 4 2 and look it's going to give us 18 0 back doesn't make sense that's okay I mean networking is really hard but I just want you to know that these functions are here for you okay cider subnet calculates a sequence of consecutive IP addresses within a particular cider prefix so 4484 and then you get those sizes there okay all right we're on to type conversion function so the first we're looking at is can so can evaluates the given expression and returns a billion value indicating whether the expression produced a result without any error so can we use this right so we say local.food.bar and so you know if if this Foo wasn't defined then it would say false but apparently we've made it all the way to borrow okay we have defaults a specialized function intended for use with input variables whose type constraints are object types or collection of object types that include optional attributes and I don't show that one here because it's not that exciting but nonsensitive takes a sensitive value and returns a copy of that value with the sensitive markings removed therefore exposing the sensitive values so if we have an output here and we want to make it nonsensitive that's what we could do then sensitive as you imagine is just the opposite okay we have two Bool so converts its arguments to a Boolean value so if we have a string that's true we can turn it into a real Boolean value we have to map converts an argument to a map value to set converts it to a set to list converts it to a list to number converts it to a number string to string and then we last we have is try so evaluates all of its arguments expressions in turn and Returns the result of the first one that does not produce any errors the thing that's the hardest to figure out is set I cannot find really good examples or documentation on the use case of set there are some cases where you need to use sets which is an actual type but even talking to DA's and technical writers they weren't even sure themselves so this is not something you're going to come across very often but there's like one case where I saw it so I'll probably point that out when we do hit it okay hey this is Andrew Brown from exam Pro and we are going to go take a look at um builtin functions as soon as my terminal decides to be responsive I don't know why as soon as I start recording it decides to lock up so we'll just give it a moment there there we go and so I have a new folder there I figured we could just find some variables so that we don't have to uh you know constantly write stuff in so we'll just say main.tf we're going to go terraform here and so might be fun to you know kind of some kind of variable here and so I have off screen here all the functions so we're just going to kind of pick some at random here to play around with so we get some experience okay so just going through strings I think what we can do is Define like our strings so we just say Str here and we'll just say type equals string and we'll just say default here able to say hello world forward slash n something like that okay and then we'll do terraform console here I gotta remember to do it this way so we do var.str okay and so that accesses our string there maybe we might want to take out the new line for now so I'm just going to kind of pull this up over here look at some kind of things we can do okay maybe collapse that get that out of the way all right so there's a lot of string functions and on the exam they might actually ask you some which is in my opinion I don't I don't really like that but that's what they do and so you know we might want to look at something like split or something so here we could do hello world okay start that up again so we'll do split comma VAR Str okay and that would split that into a list we might want to do something like upper so I think we did that earlier where we did upper okay you might want to do trim remove specify characters from the start and end of the string so maybe we have this here and so we'll say trim VAR Str and whoops it's not what I wanted to do trim far Str UCT like that okay and there's again there's not a lot that's exciting here maybe we'll try a replace so we can do replace and we'll we want to replace we won't provide our string and then the substring that we're looking for so world replace that with bar soon which is Mars there we go so nothing super exciting over there what's more interesting are some things like these hash encryptos so something we might want to generate out is a uuid I think that we might be able to do this here so let's just see what happens if we try to call it like that clear to our form cloud oops terraform console that's what I meant to type and so functions can't be called in here which is totally fine so go back and just set that like that I just wanted to show you that so if we did uuid we would get that if we used bcrypt so I might say bcrypt hello world okay might be something interesting the IP network here so we might want to generate out a cider subnet right the typing conversions is something that you might come across a bit so we already saw that when we converted a set to a list and things like that so maybe we might want to convert something to a Boolean so we might say two Bool true okay these are pretty complicated the collections but we might have something that we want to do here so coalesce might be something that's interesting where we have an array so or a list I suppose so we might say like items and make that a list null null empty last okay bar items so we might say coal Plus okay and that didn't look like it pulled anything out of there to reform coalesce operation with this list of strings use this symbol so we could use that um to do that so that just kind of expands the arguments and so that what happened here is null didn't exist Alden exists this didn't exists so it pulled out last okay maybe we might want to just use keys maybe we might just want to use Keys here okay so it might sound like hello world goodbye Moon and remember we can do uh hash Rocket Arrow equals or colon it's just up to your preference I just wrote that in for whatever reason I'm used to using Ruby and that's what we use as hash Rockets that's the name of the symbol the equals Arrow um okay it didn't like that so I guess we do have to do it this way that's totally fine I'm not upset by that I thought it supported all three maybe it's like minus equals or something I don't know but what we'll do say is save our stuff and then what we can do here is do keys okay and it didn't look like it grabbed oh yeah I grabbed the keys that's fine okay and then we might say values all right um you know maybe we might want to try reverse that one's pretty clear one two three okay so nothing super complicated I wonder if absolute would work in here like the file system so we have absolute path I don't know if I don't know if this would produce anything here oh it does okay so we could ABS path say path dot root there you go okay so that pretty much gives you a general idea of builtin functions so there you go all right let's take a look here at terraform Cloud again but in Greater detail so terraform cloud is an application that helps teams use terraform together and so there is the UI there and terraform cloud is available as a hosted service on terraform terraform.io it's actually at the app.t terraform.io once you're logged in and it has a lot of different features so it can manage State files uh have a history of your previous runs a history of your previous States easy and secure variable injection tagging run trigger so chaining workspaces together specify any version terraform per workspace Global State sharing commenting on runs notifications via webhooks email and slack organization and workspace level permissions policy is code via Sentinel policy sets MFA single signon cost estimation Integrations with service now Splunk kubernetes and custom run tasks and that is not the limit to what it does but this is what I could fit on the slide okay let's take a quick look here at the terminology or anatomy of terraform clouds so we have an organization and with an organization we have our workspaces and a workspace represents a unique environment or stack then you have your teams these are composed of multiple members and a team can be assigned to multiple workspaces then you have runs a run represents a single run of the terraformrun environment that is operating on an execution plan runs can be triggered by like you your the UI itself or maybe like a git repo it could be API driven or CLI driven so there you go foreign so there are three types of cloud run workflows so when you create a workspace you have to choose a workflow and you have either Version Control workflow we have CLI driven workflow or API driven workflow okay so just going over them in Greater detail for the first one which is that version controlled workflow terraform cloud is integrated with a specific branch in your VCS so githubs via web hooks whenever pull requests are submitted for branch speculative plans are generated whatever a merge occurs to that Branch then a run is triggered on terraform Cloud then you have API driven so workspaces are not directly associated with the Version Control System repository and runs are not driven by web hooks on your VCS provider a thirdparty tool or system will trigger runs via uploading a configuration file via the terraform Cloud API so this configuration file is a bash script that is packaged in an archive and you're pushing it as a configuration version so you're basically creating configuration versions every time you do that then there's CLI driven and this is the way we're going to be using mostly in the course so runs are triggered by the user running terraform CLI commands so you'll run terraform apply and or plan locally on your machine it's going to just work as per usual okay let's take a look at organization level permissions which manage certain resources or settings across an organization so the first things that you can set would be something like manage policy so create edit delete the organization Central policies manage policy override so override soft mandatory policy checks manage workspaces so create administer all workspaces within an organization manage VCS settings so set of VCS providers and SSH Keys available within the organization and for an organization we have this concept of organization owners so every organization has at least one organization owner and you can have multiple this is a special role that has every available permission and some actions only available to owners so this could be publishing private modules invite users to organizations manage team memberships view all secret teams manage organization permissions manage all organization settings manage organization Billings delete organizations and manage agents so just understand that there are these special ones just for this organizational owner and then these are these other ones here that you can set for other types of organizational level permissions okay let's take a look here at workspace level permissions that allows you to manage resources and settings for a specific resource and we have granular ones and then we have premade permissions so let's go through the granular permissions first so these granular permissions you can apply to a user via a custom workspace permissions and so we have read runs queue plans apply runs lock and unlock workspaces download signal locks read variables read and write read State outputs read State versions read and write State versions and so the idea is that what you can do is just go and cherry pick out what you want to assemble your permissions for your user now if you want something a little bit easier to do you can use fixed permission sets and these are premade permissions for quick assignment and they're based on the read plan and write so we have read runs read variables read State versions for plans we have q plans read variables read State versions We have write so apply runs lock and unlock workspaces download setting unlocks read write variable read write State versions and then there are workspace admins and this is kind of like the organizational owner so a workspace admin is a special role that grants all level of permissions in some workspace admin only permissions those admin only permissions would be read and write workspace settings set or remove workspace permissions of any team and delete workspaces so there you go let's take a look here at API tokens so terraform Cloud supports three types of API tokens users teams and organization tokens so for organization API tokens they have permissions across the entire organization each organization can have one ballot API token at a time only organization owners can generate or revoke an organization token organization API tokens are designed for creating and configuring workspaces and teams they're not recommended as allpurpose interfaces to terraform Cloud so basically you just use them when you are setting up your organization for the first time and you want to do it pragmatically okay then you have Team API tokens so this allows access to workspaces that the team has access to without being tied to any specific user each team can have one valid API token at a time any member of a team could generate or revoke that team's token when a token is regenerated the previous token is immediately becomes invalid designed for performing API operations on the workspaces same access level to the workspace the team has to access to I would imagine this is when you're sending out your own custom CI CD pipelines or something like that I'm not really sure exactly the use case for team API tokens we have user API tokens the most flexible token type because they inherit permissions from the user they are associate could be for a real user or a machine user when you do terraform login this is what you're getting a a um a user API token okay foreign so I just wanted to quickly show you this axis levels chart that helps you understand uh what kind of permissions you were giving at the access level and notice there's implicit and then required or explicit permissions I'm assuming that this means that you need to assign those permissions to the user first before they'd have it so just because you have a user token doesn't mean you get all of these orange diamonds it's just the ones that you've assigned to that user or team where I believe that the organization you're going to run into a chance where you're going to have all these permissions by default whether you want them or not so just understand uh that you have to double check this before you use your tokens and that this chart exists okay all right so we covered private registry earlier in the course when we were looking at the terraform registry the public one but let's cover it again with a little bit different information so terraform Cloud allows you to publish private modules for your organization within terraform Cloud private registry and tour from Cloud's private module registry helps you share terraform modules across your organization include support for module versioning a searchable filterable list of available modules a configuration designer which I didn't find this thing but it sounds really cool all users in your organization can view your private module registry authentic for authentication you can either use a user token or a team token so I guess this would be the case where you might want to use a team token for authentication but the type of token you choose May Grant different permissions as we saw with the access levels just the slide prior using terraform login will obtain a user token just a reminder and to use a team token you'll need to manually set it in your terraform configuration CLI file okay so there's a feature within terraform Cloud that can do cost estimation and it is a feature that will give you a monthly cost of resources displayed alongside your runs this feature is only available starting at the teams and governance plan and above but the idea is that it will tell you for specific resources and give you a summary so notice here that we have some pricing I'm going to get my pen tool out but we have the overall cost and then it's broken down per resource and so you can see we have an hourly monthly and monthly Delta I don't know what the monthly Delta is but um you know it gives you kind of idea of cost you can use sentinel policies to assert the expectation that the resources are under a particular cost so that's just kind of a bonus there where you're like okay I want to assure my spend is this the only downside at least at the time right now for cost estimation is the amount of support it has so we have AWS Azure and gcp so these are the resources that it will support and so you have to look through here and say okay you know is there any resources I'm using outside of this that I really care about um and that so I think that if you're using like core services so like ec2 instances load balancers things like that that should help you out so like we see AWS instance the load balancer the volume some cloudwatch logs ALB for Google it's just disk instance and database so yeah it's just really dependent on you know what's here so you know it may meet your needs or you might say okay this is not enough okay here's just a few options that I think are worth noting within the terraform Cloud workflows we have a whole section of workflows but I decided to put it over here just because let's talk about it one thing you can do within terraform cloud is set whatever version you want so you can go as far back as you want uh and this is great if you need to mix and match different workspaces because you have different stacks and they were built on different terraform versions and you're just not ready to upgrade them yet you can choose to share State globally across your organization for a particular workspace this could be really useful if you need to reference things wherever you can choose to Auto approve run so if you don't want to always do that manual approve you can do that this is great if you are looking for that kind of agile kind of workflow where if something is merged then it should be rolled out okay please let's talk about if we had to migrate our local state and we're using just the default one two terraform Cloud how would we do it so to migrate terraform projects it only uses the default workspace here from cloud it's pretty easy you're going to create a workspace and terraform Cloud you're going to replace your terraform configuration with the remote backend so if you have nothing it's using local and you just put in your remote State and then once you have that in there you do a terraform and knit and it's going to say hey do you want to copy the existing state you're going to type yes and once you've done that I believe you have to delete your old State file if you are migrating multiple um multiple environments or you're moving from a standard remote back end it's a little bit more complicated they definitely have guides in the docs but this is the pretty much standard one that you're going to come across when you're working very early and we'll definitely see this as we are using terraform in our follow alongs okay foreign I want to talk about what kind of Integrations we have for terraform for Version Control Systems so we have GitHub GitHub auth GitHub Enterprise get lab gitlab EEG and CE I assume that's Enterprise Edition and Community Edition bucket Cloud bitbucket Server and data center Azure devops service Azure devops server so it's very simple you're just going to choose from the one of the four right and then you're gonna just drop down and choose what variant it is there and connect your repo every single provider has different configuration settings so you might have to meet those depending on what they are you can get from private repos you might have to add your SSH key or something like that okay let's talk about terraform Cloud run environment so when terraform Cloud executes your terraform plan it runs them in its own run environment so what is a run environment a run environment is a virtual machine or container intended for the execution of code for a specific runtime environment a run environment is essentially a code build server so the terraform Cloud run environment is a singleuse Linux machine running on the x86 or x64 architecture and the details of its internal simple petition is not known it is possible to install software on it but the only issue is that we don't know what it is is a Debian is it Ubuntu you just can't tell terraform Cloud will inject the following environment variables automatically on each runtime so we have TFC run ID this is a unique identifier for the current run the workspace name the workspace slug so this is the organization followed by the workspace just going to get my pen tool to just kind of point out over here on the right hand side we have the configuration version and git Branch so you know if it is going to be on Main it's going to tell us that if it's going to be a particular version we'll know that as well we can get the shaw of the current commit there's that version and if you want to access these variables you just Define variable and the name and then you can access it throughout the code okay let's take a look here at terraform Cloud agents this is a paid feature of the business plan to allow terraform Cloud to communicate with isolated private or onpremise infrastructure it's kind of like an inbetween uh between a terraform cloud and terraform Enterprise where you want to use terraform Cloud but you have uh onpremise infrastructure but you're not ready to move to terraform Enterprise so this is useful for onpremise infrastructure types such as vsphere nutanix and openstack the agent architecture is pole based so there are no inbound connectivities required any agent you provision will pull terraform Cloud for work and Carry Out execution of that work locally agents currently only support the x86 architecture or the x64bit Linux operating system okay so you can also run the agent within Docker using the official terraform agent Docker container if you just prefer that over a VM agent supports terraform version 0.12 and above the system requires request the system requires I'm going to change that in the slide later on but the system requires at least four gigabytes of free to space for temporary temporary local copies and two gigabytes of memory needs access to make outbound requests so you need to have open port 443 for app terraform i o registry terraform i o releases hashicorp.com and um archivist.terra for my IO so there you go this is Andrew Brown from exam Pro and we are on to our terraform Cloud uh follow alongs now we already did terraform Cloud uh Version Control System earlier than I thought we were going to do so I'm going to remove from the list and what we'll do is focus on permissions and maybe the API tokens and things like that so what I want you to do and I've got some old tabs open here but I'm going to make my way over to uh terraform.io and I'm going to go log into terraform Cloud here and I don't think I've ever done this but I can upgrade to the trial count because the thing is is that when we are in our account here and we're trying to look at permissions and we're not using Force unlocking anymore I might just keep that around for a little bit but if we were to go to our user settings here we go to organizations um that might not be a very good example like I said I wanted like the organization settings here which would be maybe here yep up here and so you know when we go to our teams and our users our users everyone's being added as an owner we don't have like granular permissions and that's because we'd have to upgrade and so I figured this would be a good opportunity for me to just kind of upgrade to show you those uh more detailed uh rolebased Access Control permissions just so you know where they are so I'm gonna go the upgrade now and notice that we're on the free plan and also take note because later on the course I talk about pricing or we've already already acrossed it but notice that we have a team plan and a team and governance plan this one's at twenty dollars and this one's at seventy dollars so you know this is not something that's reflected at least not right now on the terraform website and so it just looks like there's a team in governance plans for twenty dollars in this middle one's missing the key difference here is this one has Sentinel policies code but you can see on the free plan we are able to do teambased stuff let's go switch over to the trial plan I'm going to see if I can do this without entering a credit card in so here it says you're currently on trial planned I didn't have to enter anything in that's really great and so that means now I have all these Team Management options so if I go over to team management I can actually go ahead and create some teams uh so I'll just say like Developers okay and so now I have all these options so we can say this person if someone's in this team they're allowed to manage policies they're able to do that a visible team can be seen by every member or you can keep them secret we can generate team API tokens which I guess we could just like cover this as we do it but notice we can go here and that generates out that token that we can use I'm going to go ahead and delete that token um so nothing super exciting there you know it's not like that complicated if we want to set things on the workplace now if we go back to workplace or workspaces here and now we have Team access and notice I can go to add team uh permissions here and we can say select this team for their permissions and so these are these uh prebuilt ones in um so we have read plan rights so these are those three predefined ones that we talked about previously and then we have down here like assign permissions for the admin of a workspace we are able to set customized permissions so if we toggle this um we should be able to do it I mean this looks like it's the same thing no I guess it's more granular so here I guess we have our granular permissions that we can set so for runs we can do read plan or reply Locker unlock a workspace send a locks things like that it's not super complicated if we want drain out API tokens for uh well there's the organizational one there's the teams one and then there's the user one so if we go to the organization we can see that we can generate out one here so I can say create an API token so there it is let's go ahead and delete that and if we go back to our teams we did this earlier but we can generate one here and then if you want to generate one for your users probably under user settings yeah so we generate tokens there as well okay so I mean again there's not a lot to talk about here but um yeah so I guess that really covers permissions and API tokens okay okay so that finished deploying there and so we can see our resources have been created but one thing that we didn't set was the prefix I'm actually interested to see that that worked properly but what I could do is say prefix and then do an underscore here and I don't know how that would affect it and this actually happened over in this repository here I'm actually using a hyphen so I'm going to just change that to that might have to do a terraform edit there migrate the state so that was a complete mistake on my part but I guess my thought was that I thought I had to have um this is still on Main and I guess we'd never really set up a production Branch but yeah so now when we have the prefix in it's actually going to prompt us for the other one so the currently selected workspaces are default does not exist and so Dev is showing up and notice that we can't deploy to main so I think the thing is is that if we wanted a production one we would just create that workspace and then it would reflect here so the way you make uh multiple workspaces here would actually have to make them all so we'd have to make a VCS terraform prod and I'm very certain that it would just show up here and then you would select the number that you'd want though what's interesting is the fact that we are in the dev branch and we have to say oh I want to deploy the dev one so that's kind of a little bit of a caveat there but I guess there's not really any way around it but I mean this pretty much you know explores what we need for multiple workspaces with terraform cloud and we did the remote ones and we're all good so there we go I guess the last thing here we should probably do is just clean up so if we go to terraform Dev here we're going to go down to destruction and we'll run a destroy plan here okay and once this is all done you know you can go ahead and just delete these repositories and notice this one is it has a private lock on it so oh because it's actually running right now so it's being locked so yep there we go so that's it all right now let's take a look at the terraform registry the private registry so just go over here and click on registry at the top and we can bring in public um public things here so I can just go here and type this in and we can hit add and so now um we just hit add to terraform cloud add to my organization and that's public facing but we could also add private facing modules so if we go back to our registry here just going to go ahead and uh down to publish here and we go to GitHub and I guess custom and so then I suppose we just have to enter all the stuff in here so as an optional display name for your V Version Control provider client IDs client secrets so it seems like there's a lot of work to do we'd have to set up the SSH key pair but I mean that's generally the details that you need to know for that okay just seems like a lot of work for us to set that up you know and the course is going to be like hey can you add a private module and be like yes okay so we'll go ahead and just remove this so you can add both public and private modules um you know so there you go I have mentioned terraform Enterprise so many times in this course but we've never really talked about in detail and now is our opportunity to do so so terraform Enterprise is the selfhosted distribution of terraform platform and I just want to point out sometimes I call the terraform platform terraform Cloud just because that's the more prominent uh version of it but terraform cloud is a separate product from terraform Enterprise it's just one is uh assassin the other one is selfhosted so terraform Enterprise offers a private instance of the terraform platform application with the benefits such as no resource limits with additional enterprisegrade architectural features such as audit logging so you do you'd have tamper evidence saml single signon and I'm sure there's a lot more other options there so let's just kind of look at the architecture really quickly on how this works so the first thing is you have the terraform platform which is going to be installed on a machine and in particular this is installed on Linux and it's specifically installed on Debian okay so I believe that is the Debian logo as far as as I remember if it's not we'll find it on the next slide if I'm wrong okay you're going to have to have some kind of storage and there's a few different options probably the most common is going to be on something like S3 but you can store it on the storage or on the disk itself you have to have a postgres database so that's part of the infrastructure because that is what the platform uses and you'll also have to have your own TLS certificate to access the machine but there are also cases where you know these are going through air gapped environments but the idea is that you have SSL or TLS it's like endtoend encryption it goes all the way to the machine that's where it terminates okay you'll also need your terraform license so you'll have to plug that in once you start up the terraform platform say hey tell us the code so you can unlock this um this software for you to use on this dedicated machine okay foreign so the requirements for terraform Enterprises is going to highly vary based on your operational mode that you choose to run it in and that is really dependent on how data should be stored and when we're looking at the uh the architectural diagram that was uh the operational mode of external Services there's three types of operational nodes the first being external Services that's when you use postgres and then use cloud storage so in that example we're using S3 but you can use gcp Azure blob storage or Mino object storage but the idea is that postgres and the cloud storage are external they're not part of that Linux server okay then you have a mounted disk so this would just be having a a persisted disk attached to the VM so you know in the best case it's called EBS so this stores data in a separate directory on the host intended for external disk so that would be both the postgres database and the storage volume itself you know postgres is still a requirement and no matter what mode you use then you have demo so stores all data on the instance data can be backed up with snapshots not recommended for production use so this is where you have ethereal data so you know the data you know can vanish if you restart the machine unless you make physical snapshots another component is credentials ensure you have credentials to use Enterprise and have a secure connection so the first is we need the terraform Enterprise license so you obtain that from hashicorp and the other part is having a TLS certificate and private key so you need to prove uh you're the uh you own uh your own TLS certificate okay then we have the Linux instance so terraform Enterprises designed to run on Linux and it supports more than one version so you know I said it was only Debian but I guess there's a bunch I just forgot so we have Debian Ubuntu Red Hat Centos Amazon Linux there's a variety for those Oracle Linux so yeah I guess I just a big fan of Debian so that's I guess that was my my thinking there for Hardware requirements we have at least 10 gigabytes of disk space on the root volume at least 40 gigabytes of disk space for the docker data directory so that would be the VAR lib Docker at least eight gigabytes of the system memory and at least four CPU cores so there you go foreign let's talk about error gapped environments so what is an air gap an air gap or disconnected network is a network security measure employed on one or more computers to ensure that a secure computer network is physically isolated from unsecure networks so the public internet so it's no internet no outside connectivity Industries in the public sector so government military or large Enterprises finance and energy often employ air gap networks and so I want you to know that hashicorp terraform Enterprise supports an installation type of air gap environments okay so to install or update terraform Enterprise you will supply an air gap bundle which is an archive of a terraform Enterprise release version so that's how you would um you know provided okay so let's take a look at terraform Cloud features and pricing so I just want to quickly go through it here so we have three models we have the open source software so OSS we have the cloud offerings and the selfhosted offerings I know these tiers we have free teams and governance technically it's teams and then teams and governance so they're two separate plans but this is the way they display it in their marketing content but it really is a separate two separate tiers in there you have business and then Enterprise which is considered selfhosted so in terms of feature set across the board you have IAC workspaces variables runs resource graphs providers modules the public module registry which is terraform registry workspace is a bit odd because there are terraform Cloud workspaces right and then you have local workspaces so technically those should be broken up into two separate things or named differently but that's just how it is with terraform so you know just asterisk on that workspaces there for the free tier you get remote state or sorry for everything outside of the open source you get remote State vs VSC connection so that's Version Control State connection so connecting to GitHub or or git lab or whatever workspace management secure variable storage remote runs private module registry once we get into Cloud we get Team Management Sentinel policy as code management cost estimation the reason why I have that in Red is because on the exam it could ask you when is Sentinel policy available is it available at what level and the thing is it goes from teams and governments all the way to the Enterprise level now technically there is again one called teams and there's teams and governance so it's part of teams and governance not part of teams okay uh once we get into business this is where we start to get single signon and audit logging so you know if you need it in the cloud or if you need it selfhosted both options are available in the business we have the you can have the selfhosted agents for configuration designer servicenow integration you have it for those uh as well in terms of how many runs you can have this is very important because this is how many this is going to put a bottleneck in terms of your infrastructure rights on the free Terry you can have one current run of a workspace and teams you could have two and then at the business level and Beyond its unlimited current runs for uh how you would actually interact with um terraform you know this is going to be through the local CLI for the open source software for these it's Cloud meaning that um it's Cloud that is triggering the execution commands and then selfhosted it's not in the cloud it's on that private machine okay uh then we have support So for support it's all community so that's just going reaching out to DA's maybe there's a slack Channel I believe that they have a form so they have like a form where you can ask questions and then they have these layers like bronze silver and gold I could not determine what these are like what is offered in them and the odd thing is is that you know there's a silver and gold but it's offered both at business and Enterprise so I don't know if like you can upgrade to from silver to gold so it's optional or you always get silver and gold could not get clarification I tried asking the sales team no one would tell me so I think you have to really be deep in that sales funnel to find out in terms of pricing it's zero to up to five users so the thing is and this is really confusing about terraform cloud and they really shouldn't have called it teams up here but you can start using terraform Cloud for free up to five users as a team okay so just negate the fact that it's not called teams what they're saying is that teams is really about getting a base workspace Remote Manager which is actually our RBA like our ABC controls uh rolebased access controls so that's the whole point of using teams so if you need that and that's when you're at five that's going to use it but you can use it in the free tier as a team and you it absolutely should once you get to the teams plan it's going to be twenty dollars a month and then if you need teams and governance it's actually like seven dollars a month so again it's kind of like a bit misleading how they've labeled this out but if you go and open up teams Cloud you can see what the actual packages are for uh business that selfhosted your contact and sales so I have no idea what the cost is there so there you go all right we're taking a look here at workspaces so workspaces allow you to manage multiple environments or alternate State files such as development reproduction and there are two variants of the workspace we have CLI workspaces a way of managing alternate State files locally or via remote backends and then we have terraform Cloud workspaces that act like completely separate working directories I'm going to tell you these two are confusing because they don't exactly work the same way but they have the same name and originally workspaces were called environments and so you know when you're using terraform Cloud it makes a lot of sense to call them environments and the CLI workspace it's just a little bit different so you know I'm not sure if I'm going to do a great job explaining the difference of these things you really have to go through the motion of it to really get the hang of it but I'll do the best I can here okay so think of workspaces as being similar to having different branches in a git repo workspaces are technically the equivalent to renaming your state file okay so in terraform 0.9 they used to be workspaces used to be called environments but people got confused which I have no video why but you know that's what it is now so by default you already have a single workspace in your local backend called default and the default workspace can never be deleted so even if you don't think you're using workspaces you absolutely are even the first time you use terraform at least in the CLI workspace okay let's get a little bit into the internals this isn't really that much detail but depending if you are on a local or remote back end changes how the state file is stored so if you're on a local state or a remote State it's going to be different so uh terraform stores the the workspace States in a folder called terraform.tfstate.d on the road State the workspace file are stored directly in the configured backend in practice individuals or very small teams will have been have known to commit these files to the repos but using a remote backend instead is recommended when there are multiple collaborators so I guess there's not really much to say here but just understand that when you have a local state file it's going to be in that terraform TF State D and then when it's remote State you don't have to worry about it okay let's talk about interpolation with current workspaces so you can reference the current workspace name via the terraform.workspace named value so we saw that in the lineup way earlier in the course so the idea here is that if you wanted to um see if the default like let's say you want to say am I in the default workspace then return five as opposed to one because maybe you're very comfortable spinning up more in the default than whether it was something else and just another example maybe you want to use it to apply the name of the workspace as a tag so here that would actually give this virtual machine in AWS the name web hyphen whatever it is production or development so there you go foreign let's talk about multiple workspaces so a terraform configuration has a back end that defines how operations are executed and where persistent data is stored so like the terraform state so multiple workspaces are currently supported by the following backends Azure RM console cos GCS so that's Google Cloud Storage kubernetes local Manta postgres remote S3 they're not going to ask you this on the exam which ones are supported but you know for your own purposes if you want to use multiple workspaces with a a standard back end you probably want to know which ones certain back ends support multiple name workspaces allowing multiple states to be associated with a single configuration that the configuration still has only one back end but multiple distinct instances of the configuration to be deployed without configuring a new back end or changing authentication credentials why would you want to use multiple workspaces for something like a standard um a standard back end well the idea here is that you know if let's say you're using terraform cloud and you've reached your limit of five users and it just gets too expensive to go to the sex user where you have to pay for all of them uh you know then the thing is is that you know this is an option for you it's just kind of like another option out there until you are ready to pay for terraform Cloud at the next tier up so that's the reason why I'm mentioning it here for you okay all right let's quickly walk through the terraform Cloud workspace and the easiest ways to just show you a screenshots so you create a workspace on terraform Cloud so first you'll create an organization mine's called exam Pro and within that you'll create multiple workspaces from there you'll click into your workspace and you'll see uh like previous run States variable settings we'll click into runs from runs what we'll get is a list of what happened previously we can click into one of those and we can see our plan and our apply we can leave a comment on each run that has happened if we if we just want to expand the plan and apply here for plan we will see all the details of what it would change and then apply is it actually setting up that infrastructure and whether it was successful or not notice you can also download Sentinel unlock files we'll come and talk about that later when we get to our Central section we can also see a history of previously held States so these are snapshots of that infrastructure and so you can click into there and exactly see what it looks like this is useful if you want to go and download it if you were to need it so here's a diff of what changed since the last state okay and of course you can download that stuff so you know hopefully that gives you an idea of what you can do with terraform cloud workspaces foreign let's talk about terraform Cloud run triggers so terraform Cloud provides a way to connect your workspaces to one or more workspaces via run triggers within your organization known as source workspaces so run triggers allows runs to queue automatically in your workspace on successful apply of runs in any of your source workspaces and you can connect each workspace to up to 20 source workspaces so run triggers are designed for workspaces that rely on information or infrastructure produced by other workspaces if a terraform configuration uses data sources to read values that might be changed by another workspace run triggers lets you explicitly specify the external dependencies so the idea is just allow you to say okay I have one workspace I I've triggered that I wanted now to do that so this is really great if you have a bunch of uh of environments or or Stacks that are reliant on each other and you want it to kind of have a chain reaction the reason I'm mentioning run triggers is a I think it's a cool feature and B Because triggers is something that is also uh something else when we're looking at provisioners and I just wanted to just clarify that there's run triggers from terraform cloud and then there's triggers that are for um well I said provisioners I really mean null resources they have triggers in that okay so it's not going to show up an example it's just a good to know feature I just want to make sure there's no confusion with the other triggers let's take a look at some of the terraform workspace CLI commands that we have available to us the first starting with terraform workspace list so list all the existing workspaces and the current workspace is indicated by an asterisk so that is our current workspace there terraform workspace show show the current workspace so right now we're working in development terraform workspace select switch to a Target workspace so here we could say select default and now we're in the default terraform workspace new so create and switch to a new workspace and then we have terraform workspace delete so delete a Target workspace now understand that this is affecting your local ones for the CLI commands Okay but um yeah so this would actually show up in the exam they might ask you like you know which is Select and what does list do and things like that so make sure you know these commands Okay all right so I just wanted to contrast against the local or CLI driven workflows via the terraform Cloud workflows because there's this great uh table chart that's from the documentation that I want to show you so to our firm cloud workspaces and local working directories serve the same purposes but they store their data differently so just looking here we'll go down to components here so for terraform configuration it's going to be on disk for local for terraform cloud in linked Version Control repositories or periodically uploaded via the API or CLI we have variable values so this is where we use tfrs and when we're in terraform Cloud it's in the actual workspace the terraform Cloud workspace and so that means that we are setting environment variables to propagate that into our code or inject those variables into our code on execution for State it's on disk or in a remote back end and in the workspace for terraform Cloud it's actually in the workspace credentials and secrets are in Shell environments or our internet prompts and workspace they're stored ascent the variables these are environment variables again so there you go hey this is Andrew Brown from exam Pro and we are on to our terraform Cloud uh follow alongs now we already did terraform Cloud uh Version Control System earlier than I thought we were going to do so I'm going to remove from the list and what we'll do is focus on permissions and maybe the API tokens and things like that so what I want you to do and I've got some old tabs open here I'm going to make my way over to uh terraform.io and I'm going to go log into terraform Cloud here and I don't think I've ever done this but I can upgrade to the trial account because the thing is is that when we are in our account here and we're trying to look at permissions and we're not using Force unlocking anymore I might just keep that around for a little bit but if we were to go to our user settings here we go to organizations um that might not be a very good example I guess I wanted like the organization settings here which would be maybe here yep up here and so you know when we go to our teams and our users our users everyone's being added as an owner we don't have like granular permissions and that's because we'd have to upgrade and so I figured this would be a good opportunity for me to just kind of upgrade to show you those uh more detailed uh rolebased Access Control permissions just so you know where they are so I'm gonna go the upgrade now and notice that we're on the free plan and also take note because later on the course I talk about pricing or we've already already acrossed it but notice that we have a team plan and a team and governance plan this one's at 20 and this one's at seventy dollars so you know this is not something that's reflected at least not right now on the terraform website and so it just looks like there's a team in governance plans for twenty dollars in this middle one's missing the key difference here is this one has Sentinel policies code but you can see on the free plan we are able to do teambased stuff let's go switch over to the trial plan I'm going to see if I can do this without entering a credit card in so here it says you're currently on trial planned I didn't have to enter anything in that's really great and so that means now I have all these Team Management options so if I go over to team management um I can actually go ahead and create some teams uh so I'll just say like Developers okay and so now I have all these options so we can say this person if someone's in this team they're allowed to manage policies they're able to do that a visible team can be seen by every member or you can keep them secret we can generate team API tokens which I guess we could just like cover this as we do it but notice we can go here and that generates out that token that we can use I'm going to go ahead and delete that token um so nothing super exciting there you know it's not like that complicated if we want to set things on the workplace now if we go back to workplace or workspaces here and now we have Team access and notice I can go to add team permissions here and we can say select this team for their permissions and so these are these uh prebuilt ones in um so we have read plan rights so these are those three predefined ones that we talked about previously and then we have down here like assign permissions for the admin of a workspace we are able to set customized permissions so if we toggle this um we should be able to do it I mean this looks like it's the same thing no I guess it's more granular so here I guess we have our granular permissions that we can set so for runs we can do read plan or reply Locker unlock a workspace send a locks things like that it's not super complicated if you want to drain out API tokens for uh well there's the organizational one there's the teams one and then there's the user one so if we go to the organization we can see that we can generate out one here so I can say create an API token so there it is just go ahead and delete that and if we go back to our teams we did this earlier but we can generate one here and then if you want to generate one for your user it's probably under user settings yeah so we generate tokens there as well okay so I mean again there's not a lot to talk about here but um yeah so I guess that really covers permissions and API tokens okay okay so that finished deploying there and so we can see our resources have been created but one thing that we didn't set was the prefix I'm actually interested to see that that worked properly but what I could do is say prefix and then do an underscore here and I don't know how that would affect it and this actually happened over in this repository here I'm actually using a hyphen so I'm going to just change that to that might have to do a terraform edit there migrate the state so that was a complete mistake on my part but I guess my thought was that I thought I had to have um this is still on Main and I guess we'd never really set up a production Branch but yeah so now when we have the prefix in it's actually going to prompt us for the other one so the currently selected workspaces are default does not exist and so Dev is showing up and notice that we can't deploy to main so I think the thing is is that if we wanted a production one we would just create that workspace and then it would reflect here so the way you make uh multiple workspaces here would actually have to make them all so we'd have to make a VCS terraform prod and I'm very certain that it would just show up here and then you would select the number that you'd want though what's interesting is the fact that we are in the dev branch and we have to say oh I want to deploy the dev one so that's kind of a little bit of a caveat there but I guess there's not really any way around it but I mean that's pretty much you know explores what we need for multiple workspaces with terraform cloud and we did the remote ones and we're all good so there we go I guess the last thing here we should probably do is just clean up so if we go to terraform Dev here uh we're going to go down to destruction and we'll run a destroy plan here okay and once this is all done you know you can go ahead and just delete these repositories and notice this one is it has a private lock on it so oh because it's actually running right now so it's being locked so yep there we go so that's it hey this is Andrew Brown from exam Pro and we are taking a look at Sentinel which is an embedded policies code framework integrated within the terraform platform so what is policies code when you write code to automate regulatory or governance policies and features of Sentinels include uh it that it's embedded so enable policy enforcement in the data path to actively reject violating Behavior instead of passively detecting so it's very active or proactive finegrained condition based policies so make policy decisions based on the condition of other values multiple enforcement levels so advisory soft and hard mandatory levels allow policy writers to warn on or inject reject Behavior we have external information so Source external information to make holistic policy decisions we have multicloud compatible compatible so ensure infrastructure changes are within business and Regulatory policy across multiple providers and Sentinel is a paid service part of the team and governance upgrade package so Syrian team in governance it's available for that business and Enterprise okay let us expand a bit on the concept of policies code and relating to Sentinel so Sentinel is built around the idea and provides all the benefits of policy of code let's talk about the benefits we get with this so sandboxing the ability to create guardrails to avoid dangerous actions or remove the need of manual verification codification the policies are well documented exactly represent what is enforced Version Control easy to modify or iterate on policies with a chain of history of changes over time testing so syntax and behavior can easily be validated with Sentinel ensuring policies are configured as expected automation so policies existing as code allows you to allows you to direct integrate policies in various systems to Auto remediate and notify we're talking about senatal and policies code we have language so all Sentinel policies are written using the sender language this is designed to be nonprogrammer and programmer friendly and embeddable and safe for development Central provides a CLI for development and testing and for testing Central provides a test framework designed specifically for for automation so hopefully that gives you an idea of the benefits of policy code and in particular with Sentinel all right let's take a look at the Sentinel language and also just a broad uh range of of use cases that we could use these for so you can start thinking about how to start applying Sentinel the great thing is that there are a bunch of example policies provided by hashicorp so you can easily um you know start using them right away but let's go through the big list to kind of give you an idea where you would use policies code so for AWS maybe you'd want to restrict the owners of the AWS Ami to a data of the data source maybe you want to enforce mandatory tags on taggable AWS resources restrict availability zones used by ec2 instances disallow a 0.0.0.04.0 basically anywhere address out to the internet restrict instance types of ec2 so maybe you only want people using T2 micros require S3 buckets to be private encrypted by KMS since that is a big um a big problem for people on AWS where their buckets get leaked require vpcs to have DNS host names enabled we're looking at gcp enforced mandatory labels on VMS disallow allow anywhere cider and force limits on gke clusters because those can get really expensive restrict machine types of VMS just like AWS for VMware required storage DRS on datastore clusters restrict size and type of virtual disks restrict CPU count memory of VMS restrict size of VM disks record NFS 4.1 and cure Burrows I never can say that properly on NAS data stores for Azure enforced mandatory tags of VMS restrict Publishers of VMS restrict VM images restrict the size of azure VMS enforce limits on AKs clusters restricts cider blocks of security groups for cloud agnostic allowed only say we can only use these allowed providers say or explicitly say what providers are not allowed limit proposed monthly costs prevent providers in nonroot modules require all modules have version constraints require all resources be created in modules and private module registry use most recent versions of modules in a private module registry that's more so like about the tooling around modules now let's take a look at an example and this is one for restricting uh available zones on ec2 instances so like what data centers you're allowed to use and so we first import our language functions that's going to allow us to use particular uh feature functions in this we're going to specify our azs we're going to get all the virtual machines we're going to filter that and restrict the AZ for those VMS we're going to Define that rule to make it enforceable so there you go thank you all right let's take a look here with Sentinel with terraform so Central can be integrated with terraform via terraform Cloud as part of your IEC provision Pipeline and where it's going to sit is between plan and apply okay so the way you do it is you're going to have to create a policy set and apply these to the terraform workspace so it's not that complicated to get it hooked up so yeah that's all there is to it okay hey this is Andrew Brown from exam Pro and we're going to learn a bit about Sentinel with terraform I'm not going to say I'm amazing at it but we are going to stumble our way through and see what we can accomplish we know we can download Sentinel box and there's also the ability to set policy sets and I do know that there are a bunch of premade Sentinel policies so we go send no policies here terraform uh and we go examples uh there we are probably here there are a bunch of ones that we can go in here so I'm thinking that there's something that we can do here um but we'll have to figure our way through here because I actually haven't ran any um policies myself so we have these two environments I'm not using Dev anymore I'm done with this I'm going to go ahead and destroy that and we're going to go down to terraform destroy I'm pretty sure I don't have any running infrastructure actually I'm going to double check by going to the overview everything has been destroyed and so I'll go back over here and we're going to destroy this I'm going to type in VCS terraform Dev great if we go into this workplace or workspace nothing is provisioned right now so I want to get everything running again because last time we ran a destroy so I think that if we want to get this working it should be pretty easy I'm going to go back to our workflows file here and we're just going to revert some changes so I'm going to go back and change this to name and I'm just going to go whoops we're going to go into our 120 directory here and we're going to check out Main and that actually might just revert those changes there I don't think anything really changed much other than this part here and so what I'm going to do is just go Um make a minor change it doesn't matter what it is maybe a space get add all whoops git commit hyphen m changes get push I'll have to do a good pull here get push sorry get push and so what I want to see here is a trigger for the Run there we go and I'll see you here in a bit when it's provisioned okay all right so after a short little weight there it looks like our branches Ran So I think our resources are provisioned it's cool we actually have cost estimation I didn't have to do anything to turn that on we already have it notice that it's giving us an hourly of Zero 12 cents the monthly is going to be eight dollars in you know 35 cents there if there was more resources there we would obviously get that I assume that it would show up here in the top right corner so we're not really interested in the provision infrastructure but more so looking at these Sentinel locks so I'm going to go ahead and download them there and that's going to download as a um a zip or an archive of some sorts and so what I can do here is just unzip it so I'm just going to make a new folder here and we'll just call these um Sentinel marks okay I'm just going to open up the zip and so here's all the stuff in here so we have a variety of different files I think some of them might be redundant I'm not sure what we have to do with them but I'm just going to go ahead and grab these and drag them into the folder here okay and actually what I'm going to do is um I'm going to just make a new section in my folder here whoops just give me a second here we'll just open up the Explorer to anything yeah we have a folder right here because what I want to do is just drop those files in so we can just see them in vs code the contents of them there we go and so now I'm just going to go down to here and we'll take a look so we have Sentinel HCL all right and so that's just defining a bunch of mocks we have this Central File here so I was hoping when we open this it would be able to figure out what to do with this and I have no idea so you know what what I'm going to do is I'm just going to do a little bit of reading and I'm going to come back to you after I finish reading this okay all right so spending a little bit of time uh watching some stuff so I was just going through the Deep dive of Sentinel here uh and just going through the documentation and as far as I understand it looks like that you write policies and then you can also write tests for your policies to assert that your policies are doing what you expect them to do and I guess those uh Sentinel locks are written in a form of HCL but it is a little bit confusing because you get this folder with a bunch of stuff in it and it can be either written as Json or like this htl like format but as far as I can tell it's just saying what it's done is it's generated out these the current state of exactly what your infrastructure is and I think that it's going to check to see is it exactly what you expect it to be so I don't know if MOX is that very useful and might be a little bit too much for this particular course so I'm just going to say okay let's just kind of ignore locks because they're just a little bit too too difficult and out of scope here let's follow focus on trying to get a policy implemented so I'm going to go back over here and what I'm going to do is I know that if I go to settings I mean I've seen it before I just can't remember if it's under a workspace no it's I think it's at the organization level so we're gonna go to the settings here and there we have our policies so we here we can create new policies so managing individual policy terraforms deprecated policy sets now supports VCS integration with direct API uploads this provides a streamlined policy management experience policies which includes okay so this is the old way of doing it and so we'll go here and create a new policy set so connect a new policy set um okay so I guess what we have to do oh boy this is a lot different than I thought it was going to be so I thought it was just like we're going to go here and create it and then dump our code in which apparently that's what it is but it seems like we need to associate with the policy set so just give me a moment because I do want to show you the the most uptodate way to do this I'll be back in a second all right all right so doing a little bit of reading here it looks like what we have to do is create ourselves a sendile.hcl file and this is going to say what policies we want to enforce so I assume this is basically the policy set as a file and here we specify the policies that we care about um I actually just want to go back to the files we were looking at earlier because we saw this HCL file so I guess this would technically be a policy set is that what we call that here but notice it says mock so these aren't policies per se these are just grouping mocks but in any case I think we'll have to create this file so what I'm going to try to do and I don't know this is going to work but we'll just stumble our way through here because it's the best way to learn is we're going to create ourselves our own Sentinel file here so we're going to say um Sentinel dot HCL and we're going to Define ourselves a policy this is going to be the one that we're going to use but I'm just going to grab it here notice there are different enforcement levels so um I don't really care we put in I just want to see that we can successfully get anything working here and I'm going to go back to the examples if we can go find that there so Sentinel policy examples and let's just go take one of those and see what we can do with it okay so if we scroll on down um this allows zero zero zero cider Block in the security group that seems like something that would be pretty relevant restrict instance type of ec2 instance that could be something as well that we could do so you know I just have to decide what it is we want to do here restrict owners so there's a few that are good here let's take this take a look at this one because I feel like this might be very simple so yeah this is perfect okay so what we'll do is we'll take uh this policy here so I wonder if I could just go download this file here it's probably like a download button well I can't find it so we'll just or maybe it's up here no okay we'll just create this by hand here so I'm going to go copy and it looks like we can just drop it in here so I'm just going to new file here and put that there and we will just go to Raw and we will go ahead and drop that on in there so I wish I had like sandal highlighting I don't know if there is such one for vs code if there is it'd be really nice so we would type in Sentinel um uh yes we do this one has more downloads so we'll go with that one no rating as of yet looks like it works so let's go give them a five star I think that's only fair because uh no one's done that yet might be a bit too hard to uh I've never written a review before but we'll go here and say works as expected thank you for this uh extension okay so what I'm going to do is go back over to here and so here we have some kinds now we're running a T2 micro I believe so this policy should cause it to fail and that's exactly what we want but I'm just going to go look up and down to see if it's all correct looks good to me so I think we'll have to change over here is the name so I'm just going to clear this out and we'll say restrict ec2 instance type we'll save that hard mandatory sounds really good to me um probably have to spell it right for it to work res yeah strict okay great and so what I'll do is just copy this up here okay and so we have our signal HCL file and it's referencing a local file now the question is you know can we use the same repository I assume we would be able to uh for our policy set but it almost seems like it might encourage you to have your policies separate from your repository that you're testing and that might be really good because let's say you have multiple workspaces or environments and they all require the same policy set you wouldn't want to have them in your code base like that but for the purposes of this we're just going to keep it simple I'm going to go ahead and open up terminal here and we're going to commit these uh these changes to our Repository and this will end up triggering a deploy even though we don't necessarily want that to happen but there's no way around that so get well I suppose we could just cancel it out but or not have the auto apply but I don't feel like changing that so we'll do get status here we'll go get add all git commit hyphen M uh simple policy here get push okay and so that's being pushed to our repository that's going to trigger a deploy and we don't care I I assume that it won't pick up the policy because we have to kick the policy set so um apparently use the API to upload your policy set which is kind of cool I suppose we could have done that but um well too late we probably should use VCS anyway you know what I mean so we'll go to GitHub here and we will find our terraform repository which is here um you know policy well we should probably name this right so we policy to enforce uh instance type I don't know if we need a description I guess we'll find it in a second here I guess we could have also put the policy in a um a subdirectory there that might have been okay to do it's going to default to the main branch which is fine policies enforced On All workspaces or policies and force on selected workspaces and we only have one but that's what we'll do down here so we'll say update the name is invalid oh uh it has to be like a proper name so restrict ec2 now again this is a policy set so you could just say like um you know basic server policy set that'd probably be better and then you probably want to list to say what it does it restricts um ec2 instances instance type okay and we'll go down here and create that policy set and that looks like we're in good shape so we applied it um now will it actually happen on this run because it's already running I believe we're going to this workplace workspace I like to say workplace it's workspace and uh we go over here this is already planned and finished so what I want to do is just trigger another uh um deploy here so there's nothing changed so I'm not sure what we do here um I guess what we could do and actually this is something that I'm I don't know but like how would you trigger a replace on here because if we were doing let's go to plan and see what happens I wonder if we could do that in the plan here reasons for trigger do refresh only plan because one thing I was thinking about is like imagine I wanted to replace an element you can do that hyphen replace but I don't know how you do that through VCS but anyway what I'm going to do is just go change anything in our code um so it could just be a space it doesn't really matter get add plus git commit trigger uh change and we just want to observe the um the policy working okay so I'm just going to open this up here I'm not sure if it's going to show up in the plan section or the apply section so we'll just wait here to watch see the plan generate out and so the plan finished um we don't see any Sentinel uh Central being applied there apply will not run let's expand that there this looks fine I guess technically we didn't change anything so that probably is not very helpful so what I'm going to do is go and change a variable because maybe that's that's what's going to help here so we have a micro here which is fine we're just going to change this over to Nano that makes sense why I didn't do it so we'll go back over to runs and I'm going to trigger I'm going to start a plan so uh changed ec2 instance type we'll say Start Plan okay so we have one change which is fine we just okay so that part pass is going to go to cost estimation that passed it's going to apply it because remember we have um Auto approve on the server so it's not even going to ask us to confirm it and so I want to see if that policy is in place well it's running I'm just going to go review our policy here just to make sure it's not like the opposite saying like you cannot have these so include now a loud easy to do instance type so it's small medium or large so it really should quit out on this one here but it seems like it's working like it's not uh it's not picking up the policy but I'll see you hear it back in a bit okay all right so I didn't see the policy trigger there so I'm going to go back to policy sets and notice here it says zero workspaces which is unusual because I definitely selected one but maybe I didn't click through or hit uh add so I'm going to go down here and click this one again and maybe I didn't hit this button here okay and now I'll probably have to hit update um policy set before we do I just want to read about this these parameters are past the central runtime on performing policy checks so I guess I'd be like a way where you'd have a generic policy and then you could kind of put parameters in so that's kind of cool so I'm going to go back here and double check to make sure that we have a workspace set and so what we'll do is just change the variable again um so we will go to our variables here and I'm going to go change this back to a micro and so I think this time we are going to have better success okay so we'll hit save we'll go back up to runs we'll go and start a new plan uh change instance type again here and we will save that plan and so that plan is now running I will see you back here in a bit uh when we see that Sentinel policy I don't know when it triggers so I'll see you back here in a bit all right welcome back so after our cross estimation it did a policy check and you can see that it failed um and here the error says import TF plans function is not available so I'm not sure why that's happening so I think that um I mean our set failed but not for the reason we wanted to so I'm going to go investigate this I'll be back in a moment okay all right so uh what I've done here is I've gone and looked up uh like how to create a policy set and hashicorp learn has this example project here and if we go into its GitHub project and I go here you're going to notice that it it's like this apparently does basically the same thing restrict AWS instance type and apparently tag as well but it doesn't have the TF functions the TF plan functions here so um maybe we don't need that function in there and maybe the uh the example is just out of date at this time so import common functions for Sentinel okay but this one doesn't have it it does it does have it for mocks right um so maybe we just need to kind of like walk through this really quickly and see how we can fix this so the policy uses the Sentinel TF2 plan import to require that all ec2 instances have instance types planned under the loud list but I don't see that import there okay and it is in here so I guess what we'll do is just grab this one okay and I'm going to go ahead and just delete this one out here um again this isn't working I don't know if this would work with that one so I'm going to take it out this is pretty clear what this does so we'll just have that allowed types it's interesting like here it's underscore and then here it's like a title case there's some inconsistencies there so they have a lot of types as well um and I'm just seeing if there's like find resources in here so allow types rule to enforce the name tag so I don't care about that rule to restrict the instance type so I'm going to go ahead and grab this one here and let's just take a look at the differences here okay so instant type allowed rule all ec2 instances as that instance change after instance type a lot type so this is way way different um so I mean I fully don't understand this but I do know that this one it will probably work so I'm going to go down here we have count violations I'm not really worried about that and the rule is different like if I was really serious about this I'm sure I could you know figure out the logic here but again this is just for the purposes of us learning so we don't have to go too crazy here now this says instance type allowed and mandatory instance tags we're not dealing with tags here so I'm just going to say this okay and so I think this will produce what we want so allows those types I don't know if it had this in here get all instant types from the module I think we didn't put this in here so this might be kind of the equivalent ec2 instances filter TF plan resource changes okay contains a create or an update okay um I mean this isn't bad we technically have a name set so you know what I'm just going to grab this whole thing because then we're just going to have a much easier time we don't have to worry about it but it was nice to walk through that file very quickly because the name tag is set in our project a because we can see we can see that's the server name so what we'll do is we'll just go ahead and add this to our repository here and the great thing is that since it's the vs code or it's in the same Version Control System I would think that it would update in time so what we'll do is just do get add all git commit hyphen m fix the policy git push okay and we'll go back over here and we will see if the policy check happens and when it does happen it's actually airing out because we're not using the right instance size right that's what we want to see a little bit of trial error it's not a big deal I also read like over here that the Sentinel file for HCL only contains module and policies but then we saw a sentinel file or htl file that clearly had mocks in it so I mean maybe maybe it just only used locally maybe it's not intended for um production um so we'll go down here TF plan so it didn't pick it up okay so what I'm going to do is go back to my policy set and maybe it's just like the order of how this happened so see this says it was updated uh last five minutes ago updated it a minute ago so this could just be like a race case where um you know this ran before the other one so I'm going to try to execute this again start a new plan uh trigger plan and we'll see if that works now because again this said literally updated a minute ago so maybe it didn't pick it up so you can see why it would also be good to have your policy set in a separate repo because if you're deploying this you don't want to keep triggering your deploys so I think probably that's what you know we should have done I mean it's a lot extra work but you know this way you kind of understand why SO waiting on that plan run I really don't care about cost estimation I mean you could make a policy to check based on that I I'm assuming we just turned that off if we wanted to and we'll go over to cost estimation here yeah we can just disable it but the thing here is that it set our policy passed so we'll go here so the result means that all Central policies passed so restrict the instance type so description main rule that requires other rules to be true ruleton Force name tag is on all instances that's true rule to restrict the instance type so maybe we don't understand uh maybe this works in the opposite way oh the t2 micros here okay so I just want to see it fail so what we'll do is go back up to our variables here and we'll go to our instance type and we'll just change this to Nano and we'll save that we'll go back over here to our runs oh this is still running the old one here that's fine we can just queue up another one here so we can just say start a new plan uh new instance type okay and if we go back over to here the last one wouldn't have done anything because the infrastructure would have been the same so the previous one we just did here right it would just been like oh no it's still trying to apply it so I guess there is a change maybe we changed the instance type last time I don't know so anyway I'll see you back here when this is completely done okay all right great so we got an error if we go into our instance type here right and we look at it we can see that it failed because uh it wasn't the right uh type so um I mean that's pretty interesting so the other thing I would say that we could do is also kind of check out mocks now because I kind of feel like I have a better grasp on it now that we have a test running so just thinking straight about it a mock really is a representation of the state of infrastructure at the time of so if we go back to our runs and we go to a successful run like the trigger plan here and this one was successful we could go to the plans here and then download these mock files so we do have the ones from prior and I think those are totally fine and valid to use so what if what we do is go back to our project over here and we have um the mock files over here but really where they need to be is within the workflow directory because looking at the documentation here what it's saying is that you get all these things and this basically represents the state of those mock files and then you need to make a test folder and then a test data folder and then there's gonna be something based on the name of the uh the mock file so what we'll do is we'll go up to this folder here and we'll say new folder test and then we'll make another new folder here test data those folders are files I think those are files so I'll delete that it's just out of habit to click the um the file there so we'll say new folder so we'll say test and then we'll say another new folder there test data okay and so we have our sendle file here so we need to have I think a similarly named one here so if we go back over here um this is Foo whatever so I think we need to have a folder in here because it's all based on convention and I just it's pretty not that hard to figure I don't have to read the docs to know that we'll just put that in here take out the word Sentinel and then I would assume that we need a file in here what's it called like this pass and fail so I'm going to just do a pass file new pass.hcl okay and then we have our test data so that was what we had down below here so I need to go grab that information I'm just looking for a folder where I might already have open here if I don't that's fine we'll just go ahead down below and just right click and reveal and explore we'll go over here and I need to move all these over so I just copy them over and we're going to go over to our terraform work flow here and I'm going to go here and paste that data in I don't know if these contain any kind of sensitive data because if they're based on the TF State file these might be something you don't want to share that might be a security vulnerability I don't know but I definitely won't have these available when I put this repository up for free so we have those files in the right place and we have all this stuff here so I I think that um like you notice it's not there so I'm assuming that we need to open up this file and copy into our main HCL file so we'll go down below here and then I think it's just a matter of copying all this stuff right we'll say cut and then we will go to um back up to here I suppose into our file it's getting a little bit confusing with all this stuff eh okay so that's in the right place our test data is there good here we are okay so what I'm going to do is just go down here and paste that in okay and so we didn't write any kind of pass data test so that's something we will need here I'm not sure what we'll get so we'll just scroll down here so you can find the contents of a pass.hcl it's not showing anything here so just give me a moment I'm going to see what we have to do for this this test okay all right so a little bit of Googling it looks like uh this one's on the same tracker so since we probably copied the mock data from this one or somewhere through here we could probably just go grab this so um this is pretty much what our pass file will look like so we'll go ahead and grab this here I don't know if we really need a fail to write a failing test I don't really care about that I just want to see anything pass here we'll paste that in here we do have to be sure that we are accessing our data correctly so if we're in test it's going to go up one directory to the terraform directory but wouldn't it have to then CD into uh test so I don't think that Source path is correct just going to double check that here they do have an example repositories let's take a look here what we have um yeah it's kind of odd so I think that if this is relevant it needs to go to test data because how else will it get there okay so we'll do that so test rules main equals true um okay so that's a pretty simple test and so I think the way we run tests is there's like a sentinel test thing here I don't know if we have Sentinel installed I don't think so so there's no Sentinel command so I guess that's something we're gonna have to install Sentinel um CLI terraform okay over here uh we're on technically Linux even though we're on Windows we're on Linux so here it's just saying uh download it and then put it in the correct path so install so we'll get the appropriate package here and we are technically on Linux and I guess we are 64bit it's going to download here scroll up oh it is already downloading okay great and so I'm just going to go to my downloads and I'm going to open it up here so there it is and so I need to um get it into the user local bin here so I'm just going to first get it in anywhere so because I'm just working here I'm just going to go open this up so reveal in the Explorer okay and this is not where I want it to be I'm just dropping it here for the time being technically we could run it from there I don't think it'd be that big of a deal so I'm just going to go back to my vs code here and I'm going to just type signal Sentinel is there right yep it's there I'm not sure if it's executable but um I'm just going to type in Sentinel here Sentinel test okay so it doesn't think it's command so maybe I have to do like chamod U plus X that makes it executable on Linux so note command not found well heck I'm right there maybe I have to put a period forward slash like that okay there we go so I mean of course you don't want to leave it in here you and this would also end up in a repository so this will go to like your user local bin probably so I'm going to say like move sendle to user local bin and so now I should just be able to type Sentinel it should get picked up it does great so here I can do test and down below it says open test no such file or directory so it can't find the mock data notice that it's going into the test test data so that is no good for us we did say to go up a directory so maybe if I go up back one more like this would that work no let's go put back in what they actually had there which I have a hard time believing that would be correct so open mock okay so that's definitely not right okay and so personally I just want this to work so I'm just going to cheat this is absolutely what you should not do but you know like I don't be fiddle around with paths all day here and so I'm just going to give it an absolute path and see if that fixes our problem okay and so just say test data here um so that should absolutely work I'm just going to expand this here this is mock TF plan oh but it says pass in the name okay so the problem isn't that it's the fact that the mock data isn't named it's because the thing is you could download two different mocks right so you could have a state that is successful and failed and you'd probably want to rename them to say passed or failed so we don't necessarily have that so I think my original thing was correct where we had this test data and so here we just have to make sure we match the name so mock TF uh V2 is fine here okay again I don't understand the difference between all these files I definitely saw the documentation to explain them all so you know that might be something we want to read through here um so this is looking a little bit better so mock TF plan hyphen version 2 Sentinel so that is correct but the director it doesn't like the direct it's going in that test again so again I can just go back up one more layer here okay there we go and it's passing so um yeah so that's all it takes to um do that again I think if we were to commit this to our code I don't think that these run so we can go like so we can just go add it and see what happens so we'll say get add git commit hyphen M validation and again I don't know if this mock data should be allowed to be committed into the Repository because we have a TF State file here right okay I don't know but I'm going to just do a push here to see what happens but again I I really think that we're probably not supposed to have it in there um so what we'll do is go back to our terraform i o sign in and we'll just see what happens here I mean we don't expect the uh this to pass because it's still using the wrong instance type but I was just curious to see if the mock would appear in any way here I don't think it does I think that's just something that you have to do uh beforehand and I think what you'd have is you'd have a pull request and the pull request could be used to run those unit tests because that's basically what it is okay so yeah that's exactly what I thought would happen but down below here it says the mock block is not supported so I wonder what you would do so if you can't have mocks in the file what would you do locally because you need to I guess the thing is is that the mock file the sentinel.hcl file would not be in this fold so you might have the central HCL file in your main repository for mocking right and if you committed it wouldn't run it because the policy set would actually be in another repository so I think that's how it's supposed to work so yeah I think really we want to have policy sets in their own repository like completely away from there because we're seeing we're running into a lot of problems but we pretty much accomplished what we wanted to do with Sentinel more than I thought we were going to do so that's pretty great so there you go um in terms of this we probably want to tear this down uh we do need to do something with vaults and stuff like that but I think that what we'll do is just tear this down and you know if we need to bring it back up we'll do that so I'm going to go to destruction here Ed we're gonna go ahead and just destroy the plan here okay and we're all now in good shape and so um yeah I'll see you in the next part okay but we're all done here for for Sentinel all right uh actually I guess we're not gone here just yet because it looks like our destroy run failed uh because we didn't pass here so um that is a bit of a problem so we'll have to go to the variables I guess it's a good Edge case to know about but um we'll go back and change this to a micro even though it's going to just tear it down anyway you know so we'll go and type in micro save variable and we'll go back to our runs we'll start a new plan we're sorry we'll go to settings here destruction cue the plan I'm just curious the community plan we'll redirect a new up output here okay cool um so I'm just going to type in VCS terraform again here okay and so this should work and I will come back and just confirm this with you okay so I'll be back in a second all right so the real reason we can't uh get rid of this is because we have those darn mocks in there so um what I'm going to do is go over to our signal file here um up to I mean we don't use this one so I'm gonna go ahead and delete that it's not even something that's going to happen and we need to update our HCL file here okay and I'm assuming that this supports uh this okay because this is not how we should be doing this um and here we go get add git commit hyphen m INE or change okay and this is going to trigger a run here but I really wanted to destroy so we'll just give it a moment there to start so we can kill it um did I not push oh maybe I didn't push and we'll go back here there's that run I'm going to go in here I want to stop it uh cancel run okay and so now what I'll do is go over to the here destroy this we'll run that okay we'll destroy that and I will again see if this is working and I'll see you back here in a moment okay all right so I just wanted to confirm there that everything is uh destroyed so we're all in good shape okay so uh yeah so we're actually done Sentinel now for real okay bye all right let's take a look here at hashicor Packer so it's a developer tool to provision a build image that will be stored in a repository using a build image before you deploy provides you with the following immutable infrastructure your VMS and your Fleet are all onetoone in configuration faster deploys for multiple servers after each build earlier detection and intervention of package changes or deprecationable technology so let's take a look at what that workflow would look like so you'd have your code you commit it to your CI CD Pipeline and within that pipeline it would start up a build server running uh Packer and that would trigger a build image so you'd use a something to provision it with so you could use ansible or a variety of different provisioners within Packer and then Packer would then store it somewhere so maybe this would be Amazon machine image because you're deploying to AWS and then what you do is reference that image in your terraform code and when you provision it would get deployed to your CSP so this would be AWS in this case so packet configurations is a machine uh Packer configuration configures the machine via oops hey it's Andrew Brown from exam Pro and we are taking a look at hashicorp Packers so Packer is a developer tool to provision a build image that will be stored in a repository so using a build image before you deploy it's going to give you the following benefits immutable infrastructure your VMS and your Fleet are all onetoone configuration faster deploys for multiple servers after each build earlier detection intervention of package changes or deprecation volt technology let's take a look at what that workflow would look like so first we'd have GitHub or or your git so wherever you commit your changes and from there that would trigger a CI CD Pipeline with within that cicd pipeline it would trigger a virtual machine so or a build server that's a running Packer and so that would trigger the build image process from there Packer would use some kind of provisioner like ansible to provision the image and then when it was done and and it was all good it would store it summer like in Amazon machine image once it is stored wherever you want it to go then in terraform you would just reference it using like a data source and then from there you could provision your resource okay so Packer configures a machine via a packer template and yes I know the E is missing um so sorry about that but Packer templates use the hashicorp configuration language HCL which we saw if you remember way earlier in the course and that's what we're going to review next is what that Packer template file looks like okay all right so Packer configures a machine or container via a packer template file and Packer template uses the hashic configuration language HCL so that's why it looks very familiar to terraform and a variety of other languages we've been looking at in this course and so what this file is doing is provisioning a virtual machine on AWS so here you can see that it's a TT micro and the US West 2 region that it's probably going to be installing Apache since it's named httpd and the way it's going to be created is via an EBS volumes let's talk about kind of the components that we're looking at here so when you have a packer template file you have to specify a source and this says where and what kind of image we are trying to build so the source is Amazon EBS so it's looking for an Ami image or it's being backed by that EBS volume there okay in this case it's an EBS back to Ami the image will be stored directly in AWS under the ec2 images and so we have the build step so the build allows us to provide configuration scripts Packers supports a wide range your provisioners so we have shaft puppet ansible power Powershell bash salt whatever you want basically has it and the post provisioners runs after the image is built so they can be used to upload artifacts or repackage them all right and the place where this is going to be stored is going to be on Amis okay so there you go let's look at how we actually integrate terraform and Packer together in terms of a CI CD workflow we kind of saw this in uh that overall graphic in the first uh Packer slide let's just kind of look at the code okay so to integrate Packer there are two steps they're going to build the image so Packer is not a service but a development tool so you need to manually run Packer or automate the building of images with a build server running Packer then the second part of that is referencing the image so once an image is built you can reference reference the image as a data source so if it's stored in Abus Ami we're going to just Source it from there and the way we select it is what we can do is say okay get us the most recent one and use this regular expression and the owner has to be us and and those kind of parameters to decide how to choose that image so that's all there is to it you're just using data sources to reference them after they've already been built okay hey this is Andrew Brown from exam Pro and we are taking a look at using Packer with terraform and mostly it's just about just using Packer uh and so what I want to accomplish here is to generate on an image and store that onto Amazon machine images and then load that into a terraform file or like reference it as a data source so I've never done this before but it should be fun and we'll figure this out so what we're first going to need to do is download Packer so notice in the top right corner we make your way to Packer however you want to and we'll go ahead and download and this one is for Windows it's a binary but we are going to be using Linux we've done this so many times these three two commands so I'm not going to do that again here but if you have yet to do so you can go and run that and so I'm going to go ahead and install Packer and once Packer is installed I will come back here and we will get to it okay all right so after a short little weight there Packer is installed and so what I want to do is go into my Packer folder here and I'm just going to run Packer and see what we get and so we have Packer build console fix format a knit so install missing plugins uh it looks kind of similar to terraform build images from a template that sounds kind of interesting so I think the first thing we're going to need to do is Define ourselves a template file so I remember I researched one and and put one in my uh slides here so let's make our way over there and see if we can kind of just like use our notes here as a reference so going down to this Packer file let's go ahead and just write one here uh I don't say what the name of the Packer file is that would probably help but I believe that they're just named as dot HCL files so what I'm going to do is go into this here and make a new file and we're going to say um uh I guess apache.htl since we are already very familiar with how to install Apache that seems like the easiest way to do it and again this is going to be very similar looking to terraform because it's you know all based on HCL so we'll do a type string and we are going to need some kind of default Ami so we can go grab the one we've been using all along here um I think we specified it we can just go back to count Count's always a good one to go to um so I just want to go and grab where is it um count count count where are you you see anybody see it I'm blanking today so I'm just going to grab it from AWS it's not a big deal I'm just pulling up AWS here we're going to make our way over to ec2 and we're going to go ahead and launch ourselves a new server actually I could probably grab it from the old one no I'll launch a new one just in case you don't see anything there that might not be fair I'm going to go ahead and grab that Ami ID and I'll just move that off screen here for a moment and we're going to place in that am ID because I assume we want one to override then we're going to say locals uh app name I think the example I wrote here is is Apache because that is what Apache is is httpd not sure how they came up with that name but uh that's how they call it so we need to provide ourselves a source so we're going to do Amazon EBS httpdd notice that like the source is not called Data it's just called Source if we go over to the documentation here just what I want to show you here Docs if it ever loads come on docs you can do it so down below here or on the left hand side we have sources so I believe if we were to go over to here and go over to Amazon Ami someone says Amazon MI overview uh builders ec2 EBS I'm just trying to find the same kind of information that it has there a it's not really doing what I want but anyway I know that this code is correct even though we can't seem to find this out probably just go type in Packer EBS Amazon EBS I really like to always refer to the documentation when I can here so it does say it's a builder Amazon abs source down below here we go all right so yeah um I don't understand this uh this Builder flag as of yet but uh we'll work our way through here and figure it out okay so I'm gonna go back and pull up my vs code here and we're gonna put curlies here and so we need our Mi name here so my server uh dollar sign local app name instance type T2 micro region this is going to be us East one Source Ami this is going to be the variable we set up above amiid then we are going to do SSH username that's going to be ec2 user that's the default that AWS always has uc2 user we can do some tags here not really necessary but it's good to probably give it a name right so we'll just say name Apache server and actually we could probably just do local.app name maybe instead and then we have our build step here so we're going to specify our sources and we're going to do source.amazon ebs.htpd and we're going to do provisioner Pro visioner shell and then we want to provide a script I think we can we can actually do it in line if we didn't want to do a script there but we know our script works so maybe we should just stick to that so I'm just going to call this userdata.sh because we already have that somewhere before so we'll do Post process we don't need a post processor so we just want to run that script um I believe we have that in our terraform workflow we go over there to our workflow wherever it is might also be under modules if we go into our module here didn't we create one there called user data oh that's a yaml file uh okay um I mean that's not a big deal we could probably just okay so we're not going to do it that way all right um if we're not going to do it this way we probably can provide inline things we don't probably have to do script equals so what I'm going to do is go back to the terraform documentation here or Packer documentation I should say and what I want to do is look at provisioners we're going to go look at Shell so it has this inline step and I assume that this is going to run in a sequential order so inline array of strings okay so what we will do here is we will type in inline and I've done this like a thousand times but I'm just going to go Google it Apache install AWS tutorial there's probably like one on the AWS website for it for like user data and this is pretty much has some of it here I was just kind of looking for these commands like the Yum install and the pseudosystem start so we're going to go ahead and grab that and then we're going to go and grab the next few lines here because we want to start and enable what's the three things that we need to do not complicated at all and so what I'm going to do is type in Packer build and see what happens now I didn't specify Ava's credentials or anything like that I assume it would pick up the defaults and we're going to go to the top here so it looks like we have to provide the template name so maybe we'll do Apache HCL here and it says error parsing Json invalid character V for the beginning of the value oh so it has to be pkr.hcl okay I'm really liking the user experience of the developer experience for these clis they're really good at telling us what's wrong with them PKR HCL if there's like a default file I don't know what it should be called uh so we got a bunch of Errors which is fine unsupported argument locals an argument locals is not expected here did you mean to define a Local's Block it's because I put an equals in front of it supposed to just be this not that we were really using locals for much here and looks like it is provisioning found in Ami it's going to use that as the The Source One creating a temporary key pair authorizing to Port 22 uh name Packer Builder so I don't know if this uses I don't think it does but I don't know if it uses Amazon uh but because there's like ec2 Builder image there might be a way to use it with um Packer directly but I'm not sure how to do that it's going to go through here I'm just going to see to make sure it's not running a pipeline here is it image Pipelines no okay that's good but what I will do is go over to my ec2 here and what I want to go do okay so Packer Builders is running as a virtual machine so it's actually um uh going to spin up a VM and then bake the Ami that way which seems a lot better um we'll go over to our Mis and see when that happens there um let's just unlock another those that red stuff doesn't look good seems like it didn't really matter so the thing like AWS has an entire pipeline for ec2 image Builder but it does cost money to run where I kind of feel like if all Packer is doing is spinning up a virtual machine temporarily to make that image that's going to be a lot more cost effective I mean we could go look up what the cost is to use ec2 image Builder while we're watching this Builder can't seem to type today uh it's pricing I just want to know the pricing happy free oh is it there's a no cost I could have swore there was a cost for this no cost image Builders offered at no cost other than the cost of the underlying AWS resource I think the thing is that it's that when you use um ec2 image Builder you have to use of a particular size you know if you don't really use AWS anymore in Azure gcp I can understand why this is not much of an interest but I'm pretty sure if I go here that the size that you get for the image what size of each image does ec2 image Builder use because I remember it was like really really large un like unreasonably large and that was the cost involved in it can't find it today it's not a big deal but waiting for the Ami to become ready so if we go over to our Amis here and give us a refresh we can see that it is spinning so it is provisioning that Ami while that is going on what we can do is just start setting up the next part of this so um Within our Packer here we can say new file and I'm going to say main.tf I'm going to go as per usual and grab some default codes from our account example which is for right here okay copy that we're going to go all the way down to the ground here and going to go into the main TF here paste that on in and we probably want to keep the public IP around we actually don't really care but I'm putting it in any way I'm going to take out the tags oh I want to leave the name in so I'll just say like server packer okay server Apache packer and uh this is the thing that we want to replace out this all looks fine so this is what we need to figure out is our Ami here it's probably going to come in as a data source it has to come in as a data source and I'm pretty sure that's what I wrote in our documentation here so yeah AWS Ami example things like that so what we're going to do is Type in AWS am I Packer image and we'll just Define that data source so AWS Ami Packer image and we have executable users executable users equals self I'm not saying I know what all these options do but like you just go to the documentation you grab them you got something that works true name regex okay and so we would do something like start with the little carrot character and what did we name this this starts with uh my server hyphen probably would have helped if we named it with like something like packer in the name but I think that's fine um we might as well might might as well go the full name here and say httpd because that's technically what it's going to be we might want to match for more values here so I'm not sure I guess like we do that because sometimes it's like three digits or whatever but I don't know what Packer is going to do if we keep pushing additional ones I'm not really familiar with with that so we'll just say owner's equals self and so now that should be all set up to go as that is running it finished so that's all good we're going to say terraform init and here it says block definition must have a block content Eliminator so we have a small problem here it looks correct to me uh this is not right okay we'll see if we can knit this now whether our build image works properly I don't know it'd be really good to write like some tests for it I imagine that there is some kind of way to do that um I guess it'd be like the postprocessor scripts maybe you'd want to do that where you'd want to use that as a means for testing I'm not really sure obviously different provisioners might have that kind of stuff built in so you know it might be just part of the provisioning tool you can use so it initialized here we're going to do a terraform plan because I'm hoping that it might complain about the data AWS Ami here if it does not exist properly and it did so your Curry return no results please change your search criteria and try again so however I wrote this is probably not correct so I will just take this out here try this data a to the same at Packer no results so what I'll do is go over to bc2 here and actually that's the only name that's here for the Ami so I guess I could just go here and grab the name but maybe that's not the problem oh no that might be fine so we'll just do this name reg X okay so let's go look up data AWS Ami ex couple users most recent name regex owners maybe we can just do like a filter here a regex to apply to an analyst returned by AWS this allows for more advanced filtering not supported by the AWS API this filtering is done locally on the AWS what returns so I suppose that is good but like I just need it to work so I'm going to try the filter instead and I'm actually going to put literally the name in my server httpd I'm going to take out the regex assuming that is the problem owners itself executable users itself um please change the criteria I don't know what executable users users actually does let's maybe look up what that is limit search to users with explicit launch permissions on the image is that required no so let's just take that out if more than one there isn't so let's just take that out for the time being who's the owner of this we're the owner right we have to be honors this IP address that must be us or sorry not IP but like our account number so I mean that should be fine incorrect attribute value type oh okay so that was fine so we'll do dot ID but you know if you're doing this like if you wanted a continuous pipeline you'd probably want to get the most recent and have a better regex um and so I'll do a terraform apply Auto approve and see if this works one thing I kind of Wonder is like with Packer how would you do like a versioning because that's what I'm not certain about so like I'm just kind of like looking through here and seeing what they would do for that I would imagine that uh you're probably supposed to like increment it and have it part of the name nothing's really speaking to me there but you know like the idea is that you want to have things like zero zero zero zero one zero two zero three but I imagine like there's some pragmatic way maybe there's like a builtin function or something that we can do to do that or what you do is you just have a variable probably that's actually what you probably do is you'd have like variable like version right string and then you probably set it and it would come through that way like you you'd set it over here it says our server has finished provisioning let's go C and take see if that actually worked we'll go up to ec2 instances here that is running copy that paste that in um the security group doesn't have any open ports right so it probably did work it's just we didn't create a security group with us so there are no open ports for us to check I'm not worried about this I don't care if it actually did work or not because we more or less followed all the steps there but I believe the reason it's not working like there is just because we don't have a security group but I just don't want to fiddle with that and put it into a state so that it does not match so anyway we're all done here so I'm going to do a terraform apply Auto approve destroy so there we go we accomplished that with Packer that pretty much wraps up all the main followons for the course so hopefully that was a lot of fun um yeah we'll just continue on here all right so let's talk about terraforming console because you're going to hear console mentioned throughout the documentation and you might think it's critical to the exam but it's not so I just want to make sure we understand its relation to terraform so console is a service networking platform which provides service Discovery so central registry for services in the network it allows for direct communication so no single point of failure via load balancers it has a service mesh so managing Network traffic between Services a communication layer on top of your container application so think middleware it has application configuration capabilities so console is useful when you have a micro service or a service oriented architecture with hundreds of thousands of services so these are containerized apps or workloads and so the way console integrates with terraform is in the following ways it is a remote back end because console has a key value store and this is where you could store the state of your terraform files then also there's a console provider because you can use terraform to set up some things in console for you but there's not much else outside of that okay all right we're taking a look here at hashicor Vault so vault is a tool for securing accessing secrets from multiple secret data stores vault is deployed to a server where a vault admin can directly manage secrets and we have operators also known as developers can access Secrets via an API Vault provides a unified interface to any secret such as AWS Secrets console key values Google Cloud KMS Azure service principles it provides tights access control so just in time which is reducing surface attacks based on a range of time and just enough privilege so reducing surface attack by providing at least permissive permissions we can also record a detailed audit log so we have tamper evidence so this is kind of the idea of our little hash Decor fault stack so you have your secrets engines these are thirdparty services or sorry cloud services that actually store the secrets you have your Vault cluster which act as the adapter to your resources and the resources which are going to access them so again vault is deploy to Virtual machines in a cluster and vaults can be backed up via snapshot so if you do provision them and you're worried about the state of those vaults you can definitely save those for later okay let's take a look here at terraform and Vault how they would work together so when a developer is working with terraform and they need to deploy a provider like AWS they will need AWS credentials so AWS credentials are longlived meaning a user generates a key in secret and they are usable until they are deleted so the Abus credentials reside on the developers local machine and so the machine is at risk of being compromised by malicious actors looking to steal this credentials so if we could provide credentials just in time expires or credentials after a short amount of time so shortlived we could reduce the attack surface area of the local machine and so this is where Vault comes in because Vault can be used to inject shortlived Secrets at the time of terraform apply so imagine you are you are the developer and you run your terraform apply at that point in time it's going to inject the secrets the way we do that is via data sources data source is always the way we get data into our terraform configuration file but let's look at that in Greater detail in the next slide here okay foreign let's take a look at how this Vault injection via data source works so a vault server is provisioned a vault engine is configured like AWS Secrets engine The Vault will create a machine user for AWS fault will generate a shortlived AWS credential for that machine user thought we'll manage and apply database policy and then within our terraform we can provide a data source to the Vault so that's what we're doing we're saying Vault Ibis access credentials and we are getting the output from our terraform remote State admin outputs backend and then from there we can reference them into AWS okay so when terraform applies run it will pull shortlived credentials to be used used for the scope of the duration of the current run every time you run apply you will get a new short lived credentials which is the whole point of the shortlived idea okay hey this is Andrew Brown from exam Pro and we are taking a look at Vault um and so the idea here is that we want to be able to inject secrets from vault in a secure manner for our local developer environments I really kind of wish I included this screenshot or this graphic within my slides I just found it as as of now because it does really represent all the types of secret engines and capabilities of Vault one thing in particular I wasn't aware of is that it has its own key value store so that's what we're going to be using we're going to keep it really simple here um but the first thing we're going to have to do is go ahead and install Vault so just down below I have a link here that I found and we'll go down below and it's not shouldn't be too hard to install so uh we are on Linux today I mean I'm on a Windows machine but I'm using Linux um as the windows subsystem there and so this is where we're going to start and grab our stuff so making my way over to vs code whoops um and I'm just trying to think should we use this for a new project probably so I'm going to just CD out here and I'm going to make my way into uh vault which apparently I don't have a folder for so I'm going to just go here and we're going to uh if I reveal and explore and we'll make a new one 200 volts okay and so we'll start first install something then we'll set up a project all right so um let's go through the installation process here okay so we'll go do a curl which is our first step and that's just going to grab the gpg I think we already have it because we did it for probably the the CLI 4 terraform there but we'll just do it again there it doesn't hurt I'll add the repository again I think we already did this when we installed the CLI in the beginning of this course but we'll let it go again there I remember this takes a little bit of time so we'll just wait here for a bit all right so now we need to run the last command which is actually going to go ahead and install Vault here for us we'll just go ahead and grab that line and I'm going to go ahead and paste that on in I'm not sure if I grabbed that properly we'll try that one more time it uh I got my consoles on response so there we go okay just happens when I um I stop and start recording it just for some reason times out like that so I'll go ahead and hit enter there and that will go ahead and install our vaults and then after that we're going to have to start getting it running um there is again a tutorial to inject secrets I'm not going to stick one to one with it because it does come with a repository but I find that it is a little bit more work than we want to do here we just want to kind of get a basic example working and I just want to make our lives a little bit easier so I'm just going to modify it as we go here but uh yeah we'll just wait for that to install I'll see you back here in a moment okay all right so after a short little weight here I believe that vault is installed let's find out if it works so we'll type in Vault once I get the responsiveness back from my console here just giving it a moment great nope nope there we go Vault and so vault is there and so what we can do is start it up in a developer mode and I remember from here they actually had some pretty good instructions on the starting of that so um like the way they do this project and I have the repo here is that they um they provision Vault with a bunch of different things so I think they're using like S3 here and that would probably be a really common use case for this but I really want to simplify and I don't want to have to provision that terraform and crossreference the stuff so we're just going to simplify that so I'm just looking for the command to start fault because I saw a good one here that was like vaults um ah here it is right there so Vault server hyphen dab that starts in the developer mode Dev root token ID there's something about like ceiling or unsealing stuff I don't know what that means but I assume that's a way of securing the Vault but we're going to go ahead ahead and just type that in so we're going to go Vault server hyphen Dev hyphen Dev root token ID and obviously you wouldn't want to do this for your production they call there's education I'm just going to stick with that to make our lives a bit easier and so what that's going to do is start up a vault server it is running on this port here so I suppose we should export that or or keep this because we'll probably have to reference it somehow notice we have this like unsealed key so the unsealed key and root token are displayed Below in case you want to seal or reauthenticate um developments should not be used in production so what I'm going to do is I'm just going to create a uh uh a readme file in our vault here so we'll just say new file read me because I just want to dump this stuff of course you know you should not share these with anybody but I just don't want to forget these while we're working through this so I'm going to go ahead and copy that and we will go ahead and save that and so what I want to do now oops did we lose our terminal did I close it okay I must have closed it so which one were we working in second third one which is it fourth okay it's the third one so don't be like me close out your old one so I'm just gonna close out these old ones so I'm less confused there we go and so it says that it started on this address here so I'm gonna go copy that address and we're going to open this up you can do everything via the CLI uh I just want to copy that there but they have a nice UI which is nice and so this is where we're going to put that token education and drop that down so there are some other options where there's a lot of options for authenticating but token is obviously the easiest probably not the most secure because the way we wrote it and notice that we have a couple things preinstalled so we have cubbyhole which is a per token private secret storage and then we have key value secret storage again I don't know much about these because this isn't a um this isn't a course on vault it's just kind of us showing a basic integration and more focus on the terraform side but here is where we can create our secrets we can of course use the CLI to do that and I think they showed in the getting started here and we don't have to do it this way I'd rather do it through your eye but you do like vault key key V put and then you put the name of your secret so here's secret forward slash hello and then the key and the value that's where the store I assume that this would go to the well this would specify we're using here so what we'll do is we'll go over here and we'll create ourselves a new secret because we're going to want to store something here so we want the path for the secret this is pretty common with um if you've ever used parameter store you have a path I don't know if it starts with a forward slash may not end in a forward slash probably can begin with it so I'm going to say AWS key because we'll do the key in the secret right so here oh okay cool cool so we can do forward slash AWS and then down below I would just add another one maybe I got to add each one at a time so we'll say key and I'll actually go grab our proper ones um oh I should have stopped that I'm going to start that up again okay and we'll add a plus there because everything lives in memory when you're in the dev one so you really don't want to shut that down or you'll have to redo all this from scratch so what I'm going to do is just go back here and drag this down a little bit more okay and I'm just gonna go see if I have to relog in because I might have messed this all up yes I do so we'll type in education so we really don't want to stop running that server during the duration of this follow along okay and so we'll go back into secret here create a secret forward slash AWS uh what do you want is it Json no I don't think it matters if we can add two keys that's all that matters to me and so what I'm going to do is cat out credentials of course this is not the secure way of doing it so you know again don't show people these things and so I want this and I probably should match the name I'm gonna like type in the whole darn thing and we'll grab this oops I want to see that value is correct good we're going to add another one here this is going to be our axis Secrets or axis secret access key I really don't like how those have been named and we'll go ahead and grab on this and um I mean we don't really need to really store the region here but why not because we're doing all the rest to here we might as well just throw them all in here for fun and uh here it says maximum number of versions I don't need anything beyond one because we're not going to be updating these um require check and set so rights will only be allowed if the keys current version matches the version specified in the cas parameter not sure what that means maybe just like you're passing something along when you are doing something but uh I think this is all good you know what I'm just going to leave that back to 10 just in case I've made a mistake and we have to go debug that I'm going to go hit save and so there are secrets um and so what we want to do is be able to access them and so maybe this is our opportunity to learn the CLI here a bit so I have it pulled up on the left hand side and so what I'm going to do is type in vault key V get and we'll do AWS I don't know if we can start with the forward slash there I'm going to hit enter and um the server gave an HTTP response to an https client so I'm not sure why that's a problem because like I mean I understand that it started up in HT http but I mean I'm in development so you know what else am I going to really do here let's see if I can just scroll up here and if there's anything else um hmm and I could have swore that it installed a private key as we were doing this because I remember seeing that there was like a private key I could have swore there was one something but private key so I'm not sure what the problem is here I'll be back in a moment and I will resolve it okay so the suggestion I'm getting is that we need to um export a couple of environment variables so see here where it writes this so we say you need to set the following so maybe we will go through and set those so I'll go grab that there but here's the thing is like how do I run that because these are I think these are like not the same so I mean I can't run it over here can I I don't think so uh well I guess if we're doing key Vault value there maybe we can um still no good what if we export The Vault token I think we said it was education here um let's do Vault status so yeah I'm not sure how we're going to do it that way I mean it's not a really big deal because I don't think that we have to access it that way but notice here like as I was reading here you know they're just saying down below oh we had to set this and that so I'm not really sure what I would do here so the output is like this run these commands and it should do it again the error message can be similar to different problems so that or maybe I'm just specifying the key incorrectly and that's why it doesn't like it so um let's just type in Vault and see what we have here so Vault QV maybe if we do like a list can we get a list list the secrets um AWS AWS clear I'm not sure what parameter it wants there uh let's go look it up so let's say like tariff or was it vault key V list option seems to want another parameter here I'm going to scroll on down so Secret forward slash my app um folders are suffixed with the forward slash the input must be a folder list of a file will not return um do I have to put Secret in front of it Secret AWS no so I don't know what the issue is there I just would have been nice to use it via the CLI but the thing is is that again we don't need to use it that way we just need to um you know set it and and get it but I thought it would be fun to kind of see a lie there so now that we have those set the way we're going to extract out these values is by using a data source and so what I want to do is just create a new local project and I think we'd like to always pull from our account repo here so I'm going to go all the way up to here and I'm going to go grab the main and I'm just going to copy the contents there we're going to go all the way down to the ground and we're going to make a new main TF file here we're gonna go paste that on in and uh we just want my server we don't need an output it's fine this is all fine this is all fine but uh the one thing is we don't want to use our particular provider there so what I'm going to do um is I'm going to just open up our credentials file there and I'm just going to change this to something else like other so that it doesn't load that profile there okay I just take these out of here um I think we can leave that alone and I think that's everything so what I want to do now we don't need that count we'll get rid of that count we'll go check out the documentation or the code base here because it gives us a bit of an idea how we need to implement this we'll go over the operator we'll go over to the main and so they're setting some variables here like name region path things like that but again we want to grab it from The Source there actually crossreferencing it like this other they provision the admin and grabbing it that way I don't want to do it that way I wanted to use just the data source like this so I'm not sure how that's going to work so let's go look that up okay so here it says read it was credentials from an AWS secret back end and I'm not trying to do that I'm just trying to read them from the key vaults okay so we probably want faults generic secret would this be from Key vault this resource is primarily intended to be used with the generic secret back end but it is also compatible with any Vault endpoint that is provided but is that the key value one that's not clear to me um so I think it is so let's see if we can figure that out here so I'm just going to move that off screen here and we're going to add ourselves the data source so I guess we're really not following the other tutorial at all because it we literally have to use a different um key value there a so we'll say secrets and this is going to be like AWS credentials Maybe there's creds they don't have to worry about spelling mistakes and we need to specify a path notice it always starts with like secret I don't know if we always have to start it with secret so I will just say AWS here and there might be some additional options I'm just scrolling through to hear that so you have paths so this is the fully the full logical path from which to request the data to read data from generic secret back in Mountain Vault by default this should be prefix with secret forward slash so we do have to do that reading from other back ends as data sources possible consult each backend documentation to see which endpoint supports the get version version of the secret to read we only have a single version so we don't have to specify that so technically that should be correct so what we will want to do now in our provider is specify all those options so again I'm just going back to the source code this is off screen but we need to set the region the access key and the secret key here and so this is going to be data and it's going to be Vault generic Secret and I guess it would be AWS and then we're accessing those things like region and so I'm going to go ahead and just copy that really quickly and we will go over back to our vault here because the names are over here so go grab that paste that in there we'll go grab that paste that in there and I'm just going to double check to make sure if I've made any mistakes this one it's showing it from the admin so it goes admin outputs but we're not outputting from anything we're just grabbing it from uh the Vault there so maybe what we need to do is just kind of review how this generic fault works so this does Data Vault generic and then it does data and then Square braces so I wonder if we always have to do data so for example The Vault there is a a key named auth token the value is a token that we need to keep Secret but yeah I don't understand is this a Json object or just a way of referencing it because it doesn't specify that so we'll just give it a try nothing hurts with trying right so we'll say data and this might again might not be the right way I don't know if it's single or doubles there it's doubles so I just wonder if that was like the one case where it's doubles okay and we will do this and so I think that that should maybe work don't know what I'm wondering is if I if I live with a forward slash would it have considered that and or is it now double but I don't think so because look here it looks like it's stripped it out because it just says AWS here so we got a secret since just AWS almost looks like there's a space in the front of it eh but it's not there so maybe there's not this is kind of like a little glitch so um we need to go and CD into this directory here and we just need to do a terraforming knit that's kind of interesting because like we haven't set up the provider I guess it's not going to happen until we actually use the provider so maybe it's not an issue just yet I'm curious to see if it pulls any kind of modules in for the vault generic Secret so we'll just give it a moment there to initialize okay so after there we can see that it did actually add vault in so it must be ready to take it from there um I'm going to do a terraform plan here and you know I'm going to just change this to like my server with vaults now remember it's not going to be able to pull from the um from our local credentials because we're not setting a profile and we overroad the default just in case so here it's saying a resource a data resource Vault generic secret AWS has not been declared in the root module um it hasn't I mean it looks like I did no maybe I typed it wrong so we'll go here I don't think it matters but I'll just put it above okay and I'm just going to double check to make sure nope it matches oh because it's eight of his creds that's fair um you didn't use the option o that's fine so my question will be will this correctly provision because we will not know until we uh use this right here I suppose if we try to use a data source for AWS that would probably also indicate whether it's working or not so maybe we should try doing that we do like data AWS VPC and then we just do like ID equals here because that would have to use the credentials right and so we'll just go well that's actually it's not specifying any of the the VPC here so maybe maybe we won't do that because it's just too much work um so what I'll do here is I'm going to do a terraform apply Auto approve and Let's cross our fingers and hope this works and while that is running what I'm going to do is just pull up my AWS environment here and apparently I'm not logged in so that'll give me a bit of time here to kind of catch up here while this is provisioning there and so it looks like it actually provisioned the server and if that's the case that means that our secrets are being pulled correctly right so if we go over to ec2 here and we go and check out this instance it is running so it worked um if we just want to do a sanity check to make sure it absolutely is working we can just introduce a bug into this so maybe we go here and we just say uh um I guess we'd have to make a new version create a new version and what I'm going to do is purposely introduce some mistakes so we're just going to put like an at sign here on the end we're going to save that and I'm going to make a minor change like Nano and so what I'm expecting is for this to fail let's see if it fails on the plan I don't think it will give it a fail in the apply and it does okay so the plan would tell us whether it didn't work or not so that clearly uh clearly means it absolutely is pulling from it especially when we're doing the plan so um I want to go back to our file there I just kind of lost the folder I'm just looking for it the I got too many um too many Chrome windows open here there it is okay so we'll go back here and we'll I wonder if we can just revert back to the previous version um see I don't know if I would delete there I don't want to I don't want to jinx it so I'm just going to go here and take out that at sign we're going to go ahead and save that and so that should be updated we're going to do terraform plan great and so what I want to do is just tear this down so we'll say terraform apply Auto approve and Destroy okay and while that is destroying I'm pretty pretty confident that's going to work I'm going to stop my Vault server oh wait is that going to still work did I get the credentials in time oh no I I made a big booboo okay so um I I Killed My Vault server before I was supposed to that's really embarrassing um anyway that's not a big deal because I kind of wanted to stop the server anyway but I want to go back into our it was credentials there and turn that back to defaults and I wanted to go back up here and just flip that back so that we can get rid of the server right so I don't want to kind of lose these for the tutorial so I'm just going to go here and just comment those out for a second profile defaults oops region Us East one and um we'll do that again that's embarrassing okay and I'm just going to preemptively I'm not going to save this file but I'm just going to do this for now um it's still trying to connect oh boy so just put these back in here because it's set to the Vault can I do a terraform refresh probably not no probably not what if I do a terraforming net because I did change like I was using Vault so maybe I just have to do that to fix that problem and let's try destroy again that was a big booboo on my part eh nope okay so let's go back over here and start it up again and I'm pretty sure there's like a way to back up your vaults like there's probably some kind of like snapshot or something um again I'm not that uh deep into it so I cannot tell you if that's the case um so I guess we'll just go back here and remake our secrets because it shouldn't have persisted right if it did I'd be so happy nope okay AWS we'll leave 10 in there and then we'll just have to copy all this stuff over again because of my bonehead mistake there so we have region which is Us East one U.S east one here and uh go over here well at least you know what to do if that happens to you okay I don't need the uh equal sign there go ahead and add this one okay and what we're going to do is go ahead and save that and we'll just quit out of that we'll do a terraform plan since we know that that will pick it up right and uh we'll do terraform apply Auto approve destroy Okay so again this only applies to development but uh yeah don't kill your Vault server before you're done destroying okay so I'll see you back here in a moment all right so that infrastructure is destroyed we can go back to here and then we can stop our server and for your benefit I'm just going to bring back these in here so you don't have to worry about that and uh yeah we uh we accomplished Vault for injections now you might say well how would you do this with terraform Cloud well the thing is is that terraform Cloud already uses uh Vault Under the Hood when you store your environment variables there and the idea is that uh I suppose you don't need to pull them in from all those sources but I think that was one of my my questions I had when I was talking to one of the DA's which was like okay it's great that terraform cloud has um uh you know uses behind the scenes but what if I want that to live somewhere else but maybe that's not really necessary um because I don't know but yeah that's it so we're all done with vaults hey this is Andrew Brown from exam Pro and we are taking a look at Atlantis which is an open source developer tool to automate terraform pull requests which you can find at run atlantis.io so the idea is once this is installed on your GitHub and you merge a pull request then it's going to go ahead and do a terraform apply so this would be a way for you to do um get Ops or to automate your uh your infrastructure as code and the interesting thing is that hashicorp actually maintains this project they didn't originally build it was built by two people from another company and it wasn't that they did not want to use terraform Cloud which can do this but at the time I think they had a hard time at the company getting procurement because it was a very large company and so they had to build something so they built out this thing and anyway these two people end up getting hired by hashicorp and hashicorp maintains this project which is really nice because it is an alternative for terraform Cloud um but uh yeah that's all foreign let's take a look at cdk for terraform and so to understand this we need to First understand what is cdk so AWS Cloud development kit is an imperative infrastructure as code tool with sdks for your favorite language so the idea is that you can use something like typescript python Java csharp go and Ruby Ruby's definitely there that's the language I like to use AWS cdk is intended only for AWS Cloud resources because cdk generates a cloud formation so CFN templates this is known as synthesizing and uses that for IAC but cdk for terraform is a standalone project by hashicorp that allows you to use cdk but instead of CFN templates it generates out it's going to generate terraform templates and so basically anything terraform can do you can do it through cdk and that allows you to do interesting things like use cdk to provision Azure resources so that is very interesting uh and a great development that I think that they're doing hey this is Andrew Brown from exam Pro and we are taking a look at grunt work which is a software company that builds devops tools that extends or leverages terraform the reason we're talking about them is that they produce a couple of very popular open source tools that work with terraform and you're going to see their name because um uh you know the cofounders there are very active in the community uh Jim has wrote in a really good book on terraform so you know it's no surprise that uh they are present but it's worth giving them a mention so you know who they are uh the first thing I want to mention is the infrastructure is the code Library so these are a bunch of reusable battle tested production ready infrastructure code for AWS gcp Azure um and so they have some free ones there and some paid ones there then there's teragram so a thin wrapper that provides extra tools for keeping your configurations dry we have terror tests a testing framework for infrastructure provisioned with terraform we have grunt work Landing zones for AWS this is a multicount security on AWS we have grunt work pipelines and then there's the grunt work reference architecture and so where we're going to focus our attention in here is just on Terra Grunt and Terra tasks because those are things I think are essential to know if you are using terraform because you know you'll run into those use cases where you might want to use them okay all right let's take a look here at teragram so this is a thin wrapper for terraform that provides extra tools for keeping your configuration dry working with multiple terraform modules managing remote State and this is accessible to tariff Terra grunt.gruntwork.io so the idea here is the concept of don't repeat yourself so it's a programming methodology to abstract repeated code into functions and modules or libraries and often in isolate files to reduce code complexity efforts and errors so the way that works is that you'll see these HCL files which are the Terra grunt code and they're actually named Terra grant.hcl and that's what's going to be used to abstract away or dry up your terraform files so here is an example of Terror run now Terra Grant does a lot of different things and you're going to find its use when you actually use terraform and practice and you run into these limitations in terraform and you go and I wish there was a way around it integrine like almost always solves that and so one example is being able to generate rate Dynamic providers and I don't mean like Dynamic values here in the sense that there's that Dynamic value feature of terraform but I just mean the fact that at the time of this it's very hard to inject or to write out providers so they have this generate function that allows you to get around that another really interesting thing is that Terra grunt supports better granular literary for modules by reducing lots of boilerplate uh the way they do this is is that you are referencing your terraform files uh via the source here okay so you're not including your modules within your code you're just referencing them and then you pass along their inputs and this is going to be very important when we look at wanting to write unit tests for your infrastructure because when you learn about how you test IAC you have to really break things down into smaller parts and if you have a lot of friction there it's going to make your team not want to adopt that or it's going to make that process really slow but again this is more like at scale or when you hit these kind of requirements okay oh all right let's take a look here at testing and terraform and so what we have here on the left hand side is our usual um pyramid that tells us the layers of testing and so I kind of want to walk through the layers there and talk about a bit of the tools that are available to the terraform community and you know the reason why we want to move up the pyramid here to get uh better tests and then we'll take a look at Terra test so at the bottom we have static analysis and this is where you test your code without deploying and you've been doing it all along when you do terraform validate terraform plan or you're using Sentinel you're doing static analysis and that just means that we're testing you know like the composition or the the shape of our code or like its outputs to what it says it should be doing okay but you can't catch all your problems there and that's where you move on to unit testing and unit testing uh you know traditionally means like in programming to test like a particular function its inputs and its outputs it's a little bit harder for infrastructure because um you know you have to have it connected to other things so it the definite sessions a little bit warped but the idea here and specifically with terraform is you're just testing a single module and that really says like okay well you need to really Pare down that module to be of the small scope and that's where you end up dividing your modules into very small units of work and so for tooling here we got Terra Test Kitchen uh terraform and inspec um and so uh yeah that's where that motivation came with um you know Terra Grande the last thing saying okay let's split them up into smaller stuff uh we have integration testing this is pretty much just using multiple um uh modules together you know so you say okay well I know that this Lambda function is working but do I know it works in conjunction with this sqsq or something like that then you have endtoend testing and this is where you're testing basically like business use cases so it's not just saying okay from a technical perspective but from a business use case do or the customer use case do we meet the requirements here uh and this uh is very hard because what you have to actually do is set up a persistent test Network environment but once you have one you're going to be really good shape one example of a test environment and it is paid but groundwork has their own called the grunt work reference architecture uh but you know if you had to do it without that you'd have to just roll your own kind of environment so you know if you do want a good breakdown of all these different kinds uh you know Jim from grunt work has a complete talk on automated testing for infrastructure as a code I strongly recommend it because it really gives you a better scope than what I can cover here um but let's just go take a quick look at Terra test so Terra test allows you to perform unit tests and integration tests on your infrastructure it tests your infrastructure by temporarily deploying it validating the results then tearing down the test environment and so here's an example of what a a test function would look like in Terror test it is written in golang I know golang can be very hard to use but you don't need to know much about it if you you pretty much copy and paste it and just kind of tweak the values to get the result you want so you know hopefully that helps to tell you how you would test in terraform and you know that about Terra test okay