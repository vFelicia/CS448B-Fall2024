hey welcome to neural nets in javascript with brain.js i am super excited to teach you this course the goal is to give you a practical introduction to problem solving with neural networks what you're going to be learning in this course propagation both forward and backward layers neurons training error what feed forward neural networks are what recurrent neural networks are and a whole lot more we're going to build azor gate a counter a basic math network an image recognizer a sentiment analyzer and a children's book creator and how we're going to do it is with 17 lectures where we're going to focus on practice over theory what that means is you are going to get your hands dirty but more than that you're going to walk away knowing the ideas behind neural networks there's as well a bunch of interactive challenges along the way and that brings me to our use of scrimba scrumba is a fantastic platform for learning and at any point during the entire lecture you can stop me it won't hurt my feelings you can just introduce brand new script and you can press command plus s if you're on a mac or control plus s if you're on linux or windows and it will execute exactly your code that is super important throughout this course as well i'm going to make regular reference to the console which is directly below here so if you see some numbers go down there like i'll go ahead and test that right now 0.05 just appeared that's super important anytime i start talking about if the neural net was good because it had a low error rate or if the neural net was bad because it had a higher rate just look down there and that will give you a little bit of reference as to what we're doing so let's get started this is going to be awesome this is our very first neural net this is going to be awesome so the first problem that we're going to tackle is called exclusive or and you can do some research on it if you like but more or less this is what happens you have inputs that are the same they result in a zero output when they differ it results in a one there's always two inputs there's always one output so let's take this very simple comment and let's translate it into something that the neural net or rather the javascript can understand let's have a variable we're going to call it training data and there's our very simple variable that represents all of our training data and let's go ahead and import brainjs brain.js is i'm just going to grab a link that imports it from a cdn content delivery network got that and next we want to instantiate a new instance of brain and we do that const i'm going to say net equals new brain dot neural network and down here we're going to say net dot train and we're going to give it our training data and now at line 16 by the time we get there the the net will have understood what our inputs and outputs are and so we can hear console log out net dot run one of our inputs so let's choose the first one got to give it our layers hidden layers three we'll get more into hidden layers later and now we're going to go ahead and hit run and now we have an output that's so awesome now the reason that this number here is not zero is because we're using uh a neural net and it's very hard for them to speak specifically zero and one they can speak close to that so that's exactly what we want is is a number close to zero which is 0.05 now here's a challenge for you go ahead and get the next outputs console logged out and just kind of play around with their values and and see how the net operates in our last tutorial we talked about how to build a neural net a very simple one to solve exclusive or and in this one we're going to discuss how it did it so the neural net has different stages you'll notice i use two different methods here the first one is train and the other one's run now in train we do something called forward propagation and back propagation those terms may seem scary at first but they're actually quite simple in fact we're going to reduce their complexity down to something that even a child can understand you'll take a look at my slides here forward propagation and back propagation we have a ball we're going to take a ball and we're going to throw it at a goal now when we do that we're going to make a prediction as to how far the ball needs to go uh how much energy to put behind it the pathway of the ball etc i want you to go ahead and pause the video here and to think about the different steps that happen when you throw a ball at a goal the first step is prediction now in prediction we're going to think about how we're going to throw the ball where it needs to land how much power we need to put behind it that first step and with my ascii art showing off that we did not go far enough with the ball this step is for propagation we ourselves are making a prediction from that prediction we can see how far we were off from the actual goal we can measure that and that that step of measuring that is back propagation now the next thing that we want to do is make a determination as to what we're going to do next that is our second step of back propagation that is our learning step and you know how the story goes we throw the ball again it goes too far we measure that we make another prediction we throw the ball again third time's a charm that illustrates this very first method and everything that goes on inside the net the next stage is running our net now in running our net we no longer have to measure how far we are from the goal we already know and because of that there is no need to back propagate so that step goes away now throughout this entire training of the neural net the net is measuring and that measurement is referred to as error check this out if we go to our net during its training we can actually enable something really interesting we're going to give it a log function we're going to console log error and we're going to have our log period set to 100 intervals check this out now we can actually see the error how far off the net was and you can see for a time some of these errors may go down or may go up but eventually the net catches on and it starts to accelerate its ability to learn until the error rate starts to drop to a ridiculously low number not zero though until training is completed and once training is completed there's no need to continue training as we discussed we can then just forward propagate in our last tutorial we talked about how neural networks learn using forward propagation and back propagation in this tutorial we're going to understand more the structure of the programmatic neural net neural nets are actually quite simple they are composed of a function that receive inputs as an argument and produce outputs if we think of our neural net in this very simplistic way then really we can reduce the complexity of it down to one of the simplest functions that you can write pause the video here and just look at the structure now we're going to talk about how the network initiates if you think about when you were first born likely you didn't know very much over time though you begin to know more and more the neural net begins with a bunch of random values so everything that affects the outputs is just random at first you may ask yourself why the reason is because mathematically we've proven that is an effective way to start off with knowledge the knowledge is very random at first we don't know the idea it's not zero and it's not one it's somewhere in between over time we can shape that random data so that it finally becomes where we store what's going on inside of the neural net each neuron is quite literally math.random go ahead and pause the video here and get comfortable with the idea that the net starts out with random data next i want to talk about activation a really popular and effective activation function that's used nowadays is called relu relu looks kind of like this if we were to put it inside of a function the function would quite literally look like this that is our activation function called relu now activation functions are measured in back propagation using what is called their derivative i'll go ahead and put a link here in our bonus material two i'll go ahead and post some links that take you to where relu and its derivative are used in brain our last tutorial we talked about the structure of a neural net and in this one we're going to be talking about layers take a look at my illustration this is a neural net each circle represents a neuron the arrows represent a bit of math stacked circles are layers and so here we have what are called input layers that's this first one this next layer would be a hidden layer it's composed of two neurons the next is another hidden layer composed of two neurons and the last is called an output layer now in brain the input layers and output layers are configured for you kind of automatically however our hidden layers can be configured by us our first neural net was composed of two input neurons one hidden layer that had three neurons and an output layer that had one neuron just as our illustration has two neurons for the input layer two hidden layers the first having two neurons the second having two neurons and the last one having two neurons what's interesting about hidden layers is that's really where the majority of their storage is if you likened it to a human the hidden layers are where the ideas are you may run into a scenario where your neural net isn't learning i'll go ahead and recreate that here i'm going to change the hidden layers from a single hidden layer with three neurons to that of one and i'm going to log out training data watch what happens we hit 20 000 iterations without fully understanding the problem and how to solve it now we can easily fix that by changing our hidden layers to a single hidden layer of three neurons you can see we're able to train in a short amount of time 4 800 iterations we can as well have more than one hidden layer our illustration has two hidden layers we could mimic this exact configuration two hidden layers followed by two hidden layers and this way note of caution though the more hidden layers that you add the longer it takes for the neural net to train let's try it see we hit 20 000 iterations without actually fully training there is no hard and fast rules when it comes to hidden layers this would be an invitation to experiment something i have seen though is to treat the hidden layers sort of like a funnel so if you had for example 20 inputs you could have 15 hidden layers followed by 10 hidden layers followed by two output layers that's just an example though and many problems take on different configurations switching gears for a moment take a look back at our illustration you remember that we have these arrows and i said these arrows represent a bit of math and a feed forward neural net that math can be described as this we have our input weights times our inputs plus biases activated now this is simple math but the implications of it are huge pause here and just think about how simple that is and let it sink into your brain this tutorial series is really about the practical application of neural nets but if you're curious like me you can take a look here to see how brain uses this math as another bonus take a look at the additional options that are available for brain neural nets can be widely configured to solve many different problems all it takes is experimentation time and enthusiasm up till now we've concentrated on the basics of how a neural net works and we've used arrays for our training data but in this tutorial we're going to be talking about sending different shaped data into a neural net now to illustrate what i mean by that let's take a look at my slides here we have an array now it's a very simple array but it's an array and what makes arrays incredibly useful is we can reference the values by index for example the arrays index of 0 gives us 0.3 the array index of 1 gives us the value 0.1 arrays are useful in neural nets because they represent a collection generally of the same type of values and we can use the index to look up those values if we look at an array beside a neural net we can see each neuron associates meaning with each of the arrays indexes now when dealing with a collection of the same type of value this is perfect but what about when our data isn't in the form of an array what about for example objects it just so happens that brain.js was built for this type of practical use and we are going to build a neural net that uses objects for training to get us started i've included the browser version of brain.js here in the index.html file next let's define what our training data will look like our input will be an object that is going to have the properties red green and blue and our output will have properties light neutral and dark it just so happens i have some training data i'll go ahead and paste it in and you can see our colors and brightnesses what's really useful with brain.js is you don't have to define all the properties you can but you don't have to when they're missing it simply uses a zero in their place so in this first object we see that red is missing well red here will just simply be zero and you can see a similar practice on the brightnesses let's go ahead and turn these two different arrays of objects into our training data so we're going to define const training data equals an array now we're going to iterate over the brightnesses and colors and build up our training data so four we'll say let i equal zero i is less than colors.length i plus plus or you could use a for each or even a map training data dot push we're going to give it an object each one of our training sets is an object and that training set will have an input and that input will be of colors and our output will be from the brightnesses and those indexes are equivalent next we'll define our neural net so const net equals new brain dot neural net work and we're going to give this hidden layers i'll have a single layer with three neurons and next we can basically just train our neural net so net.train and we're going to give it the training data rather than logging out what is happening inside the neural net let's just get our stats what happens at the very end and we'll go ahead and log those to the console now let's see what we get cool 1200 iterations it learned it fairly quickly and let's see actually what the neural net outputs so net dot run and a value of red 0.9 of red and we'll log those values out let's see what we get very cool so you can see in the training set we did not include dark neutral and light in every single one of the brightnesses however brain is smart enough to combine those together and it gives us with red being 0.9 that red is dark now as a bonus i could spell bonus correctly there we go what if we had to invert the problem what i mean by that is what if we are for example asking our neural net for colors rather than classifying their brightness in this scenario pause it here and think about how you would accomplish this so by inverting the problem our inputs would then be light neutral and dark and our output would be a color red green or blue for us to flip the values let's define our training data again this will be const inverted training data and we are going to for i equal zero i equals colors dot length we're going to take the inverted training data and push objects to it that are just like prior our input and output but we are going to change the input to accept brightnesses and our output to accept colors so that's our training data next let's define a inverted net those new brain dot neural neural network the same hidden layers and let's train it inverted stats equal inverted net dot train inverted training data we'll go ahead and train on this cool let's log out the stats there's our stats and we can see it actually didn't do a great job at learning the problem but that isn't the point of this exercise it's really just to understand the neural net from a different vantage point when you flip a neural net like this you're kind of generating values that can be really useful in predictions in this tutorial we're going to get a bit more adventurous and push the boundaries of what you can do with a neural net but doing so in a safe and easy manner but to help us understand take a look at my slides in our previous tutorials we used numbers directly in the neural net and numbers are just one of the types that exist in javascript and in other languages now javascript is fairly simple in its types in fact we have only boolean numbers objects strings null and undefined now it would be nice if we could feed these other types of values into the neural net so that it can understand context better and solve different and seemingly more complex problems so are we doomed then do they just speak numbers previously we used an object with a neural net and we did so using its properties defined with numbers but the principle of assigning a value to a neuron will provide us the answer for our neural net to speak more than just numbers now the question in your mind is probably how let me illustrate in a way that a child would understand this is a light switch it is off now if you were to ask a child to turn the light switch on they of course would but it wouldn't just happen like that it would happen more like my son does he sees that it is off and he becomes excited and he's taking gymnastics and so he will use that to his advantage he'll perform some amazing gymnastic maneuver over to the light switch turning it on and seeing that it's on that he just did something very useful he'll let out a cheer and do some gymnastic move off and away celebrating that he was a useful kid and that he has the ability to flip switches this ability to understand both off and on has huge implications now our computers they speak binary that's just ones and zeros so it's very very similar language to the neural net we could use this same practice we could say that zero is off and one is on now we sort of did this previously with objects via their property name but we fed the inputs directly into the neural net in this case we assign a neuron to a specific value that we're training towards either the input or the output and when that input or output neuron fires we basically just assign that value as one otherwise it's zero so just like our on and off we're taking these values like a boolean or null value or a string etc and we're simply assigning it to the input so here my potentially null value is being fired upon so it's a value of 1. my string 1 is as well the other values are not and as for output the net is going to try to learn those values just as before and so really the implications here are that we can send just about any value into a neural net so long as that value is represented by a neuron okay let's go ahead and get coding and then this will all make sense first off in our index.html file i have included the browser version of brain.js next we are going to get some data that we're eventually going to use to train on this initial data is an object with property names of restaurants whose values are what day we can eat free with kids and our objective is to find a way to get these string values represented as ones and zeros into the neural net and what we're going to do is give the neural net a day of the week and it's going to tell us where to go on that day of the week so that we can eat free with our kids now pause it here for a moment and think how you would accomplish this using that light switch analogy next let's go ahead and plan how we're going to input our training data into the neural net so if we are going to use the day of the week as the question we're going to ask our neural net that will be our input so our input is going to be a day of the week so monday tuesday wednesday etc our output is going to be the restaurant name so restaurant so that is our input and output for our neural net now next we're going to go ahead and build up our training data so let's go ahead and build that using a const that's going to be training data that's going to be an array and to put data into the training data from our restaurant so we'll need to iterate over our restaurants so for let grant name in restaurants and the day of the week is the value therein so cost day of week equals restaurants restaurant name all right so we've got our day of the week and now our restaurant and our training data we're going to push a value to it that has our inputs and outputs now our input is going to be this is where the rubber meets the road so to speak it's going to be our day of the week and we're going to assign that a value of 1. now just think about how simple that is if you need to pause it please do so but think about how simple what we just did is we are giving an input to the neural net of a day of the week assigned by its value of one now all the other days of the week because of the way that brain.js is built are going to initially be zero so only this day of the week will be one next let's go ahead and assign our output that's going to be it's restaurant name and we have just built our training data if you need a moment to pause and think about what we've just done please do so but it's a very simple principle the principle of represented values next let's go ahead and define our neural net that'll be const net new brain dot neural network and we're going to give it the same hidden layers as before single hidden layer with three neurons and all that is left to do is train on our training data so we'll do const stats equals net dot net.train training data and then we'll console log our stats out all right are you ready here we go look at that under 2000 iterations the neural net has deciphered what day of the week to eat for free with our kids that's nice but let's look at what comes out of the neural net console.log net.run we're going to say monday see what it says now this is where it gets kind of interesting all the restaurants are included with our result we just have a likelihood associated to each one of those restaurants but really what we want is to put a string in and to get a string from our neural net we're going to do that next if you can pause it just think about how you might be able to do that okay so we're going to create a function and its name is restaurant for day it's gonna get a day of week we're going to use that value with our neural net so net dot run day of the week this is going to be our result and from that result we'll have this collection of restaurants with the likelihood that we should eat there and the highest likelihood will be the correct prediction for the given day so what we're going to do is start out with a highest value and as well the highest and we're going to iterate over our results so for let rest name in result and then we're going to say if the result restaurant name is higher than our highest value we're going to set our highest value to that value name or is we're going to save the highest restaurant name close restaurant and from here we'll just return the highest restaurant name and so from this we're going to accept a day of the week a string we're going to put that into the neural net the neural net's going to give us its predictions those predictions are a list of restaurants we're going to iterate over those restaurants and then we're going to save the highest one and we're going to return the highest one we'll go ahead and log the results out so this is restaurant for day we're going to say monday and we'll test it all out there it is brilliant yellow coral perfect now let's let's add the rest of the days of the week so monday tuesday wednesday thursday friday saturday sunday tuesday thursday friday there we go we've got all the restaurants for the given days of the week so now we've got string in and string out for our neural net next as a bonus try and flip this logic the other way so that you are inputting a restaurant name and you are getting out a day of the week i'll leave you to it in this tutorial we're going to learn how to count and although that sounds kind of like an easy task at first it actually is a little bit difficult but when we use the right tools it becomes easy take a look at my slides and this will give us a background on where to get started this is exclusive or our first problem that we solved each of the empty squares is a zero and each of the black squares is a one now let's take a look at a different input one that may be a little bit more tricky it's hard to kind of see what this particular input means so let's rearrange it so that it's easier for us humans we can see this is a 4. now both of these inputs illustrate something that may have occurred to you already and that is that they have width and height or length now width and height is just sort of another way of looking at length width and height don't really change neural nets they are constant but in computers there are some rules that can be bent and others that can be broken and we'll start illustrating that now by going to the movies on your trip to the movies you're going to bring your best friend along and they're of course thrilled at going to the movies with you because it's the latest and greatest movie that you've been looking forward to and everything is going fantastic and in fact it's the cliffhanger scene right there at the middle but all of a sudden the screen goes black why why did this happen this the screen went black it was right as i was expecting something to happen next why were they expecting something to happen next well it's because they they built up a memory of what was happening up to that point that's important think about that just for a moment we'll come back to it back to our nonplaying movie your best friend looks at you and they are of course thrilled that they're at the movies but are saddened that the movie will not continue to play and then all of a sudden it starts to play again and they're of course as thrilled as can be and the movie ends just as you would hoped so that is our illustration of the movies now if you think back about what we paused in the movie every frame of the movie was the same height and width every frame no frame was different in size if you think about that over time though a frame being one part of a movie one frozen image of the movie each frame has that constant size but there are hardly any movies that are the same duration they all have different times that they play out that duration that's depth that's our frames plural that's mini frames that is really important with neural nets the depth the frames how long the movie is and what happens on each frame and what leads to the next one that gives us a context as to what is happening in the movie it's the same with neural nets this context and a neural net recurs it's something that happens over and over again something that has to in a sense repeat this terminology in neural nets is called recurrent now that sounds like a very complex word recurrent oh no what are we going to do next it's actually quite simple and to illustrate that let's go simple let's let's go to something that even a child can understand one now at its very simplest if i go to a child and i say one likely the child will not understand what i'm talking about unless we've trained on that in previous sessions so one to a to a child is is foreign and it's the same with a neural net i don't know what you mean by one that's essentially what the neural net will say however as soon as we start giving it context it being a neural net or it being a child they can start to decipher what we are trying to ask from them i'll continue we talk to our child we say one two three four and we pause what do you think the child will reply with likely a response would be five now this is where recurrent happens with neural nets recurrence is like taking each of these states one two three and four and sort of putting them together in a sense adding them together into a kind of a pool and that poll says you know the most likely thing they're looking for is probably and then out comes a five that is depth it's the same as our movie it's the same as being able to see each frame and that depth happens over time if the movie played out of sequence if the frames were shuffled in a sense likely would get very little out of the movie now this context is sort of a observer that that looks at each of these steps and can guess what comes next that context that depth that time that recurrence all refer to a very similar concept that depth that time that context it's all dynamic they're all the same width and height or even the same length but they're not of the same depth because we can feed in more than one and the context is dynamic two in the sense that we can say one two and ask for what's next and it'll say three or we can say three four what's next and it will give us a five or we can even reverse it and say five four three two what's next and it'll give us a one that's how dynamic that recurrent concept is in our neural net the ability to sort of take in those multiple frames that's called a recurrent neural net and in this simplest form the feeding of for example numbers is like stepping through time or a time step and as i said in this tutorial we're going to learn how to count okay now to get started let's go ahead and include the browser version of brain.js so we'll add that here our training data it's going to have two different outcomes one is going to count from one to five and the next one is going to count from five to one we'll define our training data manually that'll be a const called training data and it is going to be an array and in that array we'll have two arrays the first one will be one two three four and five and the next one will be five four three two and one that's it that's our entire training data next we'll define our neural net const net equals now this is a new namespace in brain new brain dot recurrent dot long short term memory or lstm time step now to train the neural net we'll give it our training data using the train method net dot train training data and let's see what actually comes out of the neural net while we're training it by logging we're going to give it a log function let's go ahead and see what happens all right it trained really fast very cool but let's remove the logging now that we know that it can train and let's see actually what comes out of the neural net so console.log net dot run and we're going to give it part of one of the arrays that we defined in the beginning so one two three four and that's it for the first one and we'll do the same for the second one right because we wanna as well count down from five net dot run and we'll do five four three and two all right let's see what comes out there we go awesome we got exactly what we wanted and that is how you count using an element in our first run we gave it an array of one two three and four expecting a five and that's what we got four point nine eight and in the second one we sent in a five four three two and we're expecting a one just like we have up here in our training data and we got a 1.005 so that's really exactly what we wanted now as a bonus try adding another training array that counts from 10 to 5. or even from 5 to 10. in our last tutorial we used a long short term memory time step neural network to count that's a mouthful and in this tutorial we're going to use that same sort of net and we're going to work up to predicting stock market data so let's take a look at how our data is shaped first our raw data is going to be where all of our values live now this isn't yet training data we're going to turn it into that our values are going to be from an object and that object is going to have properties open high low and close each one of those are numbers now let's take a look at our raw data for a moment now if you look for example at the open property you'll see it's quite a bit larger than numbers that we've used previously which were from 0 to 1 or 0 to 10. the values repeat and you'll see that open high low and close follow a similar pattern what we want to do though because the neural net was instantiated with values between 0 and 1 and that is sort of the language that the neural net speaks if we just send these values into the neural net it's going to take it quite a bit of time to sort of ramp up its understanding of these larger numbers if you can imagine it's like walking up to somebody who has only ever heard whispers and then just yelling at them it would be first off rude and secondly it would just be loud it wouldn't be what they were used to what we want to do is make it easy for the neural net to interpret this data and this is a very common practice so let's start out by writing a function and this function is going to normalize our data but since normalize is the most friendly term let's just call it scale down that's our function name and scale down is going to accept a single object and we're going to call that a step so that's a step in time now the same object that we have coming in we just want to turn down those values and so we're going to return an object and that object will have open and for the time being we'll go ahead and return step.open or define it rather with step.open and the same for et cetera and that is our scale down function however we're not normalizing anything yet and since if we go over to our training data once more and we look at these values one of the lowest ones that we can come to is this value 138 or so so what we're going to do to get these values easily into the neural net is simply divide by that value so 138 there and that's our normalize function quite simple and to prove that it works let's go ahead and console log it out console.log scale down we'll just grab the first item in our raw data there and we can see the values are fairly close to between one and zero now if you'll pause here just for a moment think about how we go the other way scaling up or as they say denormalizing okay so now what we're going to do before we do any machine learning we're actually going to write the inverse of this function which would be the denormalize or in practical terms the scale up function so function scale up and it's going to take a step and we're going to return that same sort of signature that same sort of data but rather than dividing by 138 the exact inverse of dividing is multiply so we will multiply by 138 and now we have our scale up function referred to normally as d normalize so normalize brings it down denormalize brings it up and to test them both side by side we'll go ahead and console.log scale up it'll look kind of funny scale down in our we'll have our raw data and we'll send that in and what do we get there we go our scaled up and scale down functions we're going to use these in our next neural net but this is a very common practice across neural nets in general not just for current neural nets it is normalizing our values a more common approach to normalizing your data would be to subtract the lowest value from all the other values that you're sending into the neural net and then to divide by the highest value minus the lowest value that sounds kind of confusing at first if we were to take one of these lines for example uh this first one had scaled down and we used it right here and the net result of this is let's say the step dot open was 140. we're going to subtract uh if 138 was the lowest and then we'll divide let's say the the highest value is 147 minus 138 we would get and we'll subtract 138 from 147 and that equals nine and so the net result is two divided by nine and that equals zero point two two two two two to two and what's important about this is it's the end value is between zero and one try and rewrite the scale down and scale up functions to incorporate the more generalized approach which would be to subtract the lowest value divided by the highest minus the lowest value in our last tutorial we talked about normalizing data and in this tutorial we're going to write the neural net and we're going to put that normalized data into it so first let's scale all of our raw data we're going to call this scaled data it's not yet training data but it's close we're going to say raw data dot map and we're going to map over all those values using our scale down function and so now our scaled data will have all of those new values that are normalized next what we want to do is rather than feed in one long array of all these objects these properties so that the neural net memorizes this one long pattern we want the neural net to understand smaller patterns and to predict off of those and so how we're going to do that is we're going to create finally our training data and our training data is going to be an array of arrays we're going to take our scaled data and we're going to slice it into chunks of five starting at the first index and we're going to progress by five indexes each time and so that is our training data and we can console log it out make sure it looks right very nice okay so it's an array of arrays that's an important concept okay so now that we have our data chunked and normalized and ready to go into the neural net we're going to write our neural net so const net equals new brain dot recurrent that long short term memory time step that's our neural net and we're going to define it with a few options now this is important our scaled down data has four different properties here open high low and close that represents one point in time or one step through time so our neural net is going to have an input size of those properties being them four properties our input size will be four and it's very rare to deviate from that with output size so we'll go ahead and put an output size of 4 as well and so now we want to define our hidden layers and our hidden layers are simply going to be eight neurons and eight neurons so input size of four hidden layers of eight and eight and an output size of four and now we can learn our stock market data net dot train training data out now we're going to tweak our training options just a little bit here we're going to put our learning rate at 0.005 and the reason we're going to do that is so it doesn't sort of shoot past the values that we're looking for we want very small increments uh toward our goal and the next is our error threshold now the longer and the more data that you end up using with your neural net potentially longer it's going to take to train and so for this being just in the web browser and we want to train to a sufficiently good error i'm going to turn it down to 0.02 and as well let's go ahead and log out our values let's clean this up all right and now let's learn let's see what comes out very cool all right so it trained let's log out what really matters so that's console.log and that'll be net.run and let's just give it uh the first item in our training data so our training data and let's see what comes out very cool so our net actually learns something and returns something now there's a problem here if we look at our original values they're all in the mid 140s or so but our values here are not they're close to zero and one so what do we want to do there well i'll give you a moment to think about it okay this is where we finally use scale up this is where we denormalize our values here we go i went ahead and added that as a wrapper around net run and we'll run it again and there we go the values that look very familiar our 140s or so one thing that would be really useful is to not just look one step into the future which is what we're doing right here that's what net.run would be it's going to take all of our existing steps and say hey this is the potential next step what we want to do is actually look and see what the next two or three steps may be in our last tutorial we predicted the next step for stock market data and in this tutorial we're going to predict the next three steps that's really interesting and cool and it's actually quite simple so we're going to actually just change one little method so rather than use net.run i'm going to comment this out and i'm going to say console.log we're going to do net dot forecast and let's say we just have a couple numbers to go on we're going to send in our training data but we're going to only send in a couple of steps of that data and then we're going to say with forecast that we'd like the next three steps and it doesn't stop there it's actually going to return an array and before we had wrapped run in scale up whereas here in net.forecast because we're getting an array rather than an object which would be the next step the array would be the next steps and so we can take this and map to scale up all right here we go and there's our data that's what the net has learned and it's its next prediction so we've got the beginning of one there's our our second and three i think the console doesn't log up very well with the cursor but the idea is there and so is the data in this tutorial we are going to take a recurrent neural network and we're going to learn math and we're going to do it character by character and at first that sounds kind of weird but you'll notice something interesting at first with our training data here there are no numbers not directly these are strings even though there are numbers inside of them and we are going to feed these directly into the neural net this is where it gets interesting especially with recurrent neural nets so the way that a recurrent neural net works is it has an input map and that map is kind of like an array and that array maps a value that is coming into the neural net to a neuron and it does so by index and this is how it works by first sitting in our training data the training data is analyzed and we pull out unique values like zero the next value being plus and the next value being equals because 0 is repeating up here and we've already established it equals would be the next one 0 is repeating again and zero and plus repeats again and the next unique value we have is one in the next item in the array and that happens uh throughout our entire training set so one two three four five six seven eight and nine and so we we build sort of an input map and the reason why that's important is the input map lines up with neurons so our input map is more or less the same size as our input size and that's calculated internally inside of the neural net so that's uh it's important but we don't have to think about it so much so input map is the same size as input size and what that means is for each one of these characters they get their own neuron and so if we step through a problem for example like zero plus zero equals zero to the net we feed in a brand new array each time with that one value activated and so our input internally may look like this so we've got a a bunch of zeros and so the the inputs uh literally look like okay so input length equals input size so each one of these values is sort of attached to an input neuron and this is why that matters each time we feed in one of these characters it goes all the way through the neural net and then we can do that over and over and over again so the math problem zero plus zero equals one literally looks like this to the neural net it looks like zero plus zero and that's the third one equals zero so that is our first math problem sort of internally to the neural net but it it does everything sort of automatically for us and this is a good kind of magic it's not the bad kind it's the kind that is predictable so we'll go ahead and comment that out and this out too all right so we're ready to go ahead and predict our numbers so this is what happens next we're going to define our net const net equals new brain dot recurrent dot along short term memory and we're going to have hidden layers of 20 and we're going to net net.train on our training data and we are going to set our error threshold to 0.025 five and we're gonna go ahead and log out our value all right so we'll go ahead and learn it and we'll see what happens very cool now a word of caution here it did learn it but if you crank down your error threshold that may be able to learn it but in the browser it can take a long time and a long short term memory neural net is quite complex in contrast with our previous neural nets there's a lot more going on in the long short term memory than the others so our net was able to learn it but of course that's not the fun part the fun part is actually getting to see what comes out of the net so let's do that net dot run and we're just going to give it some straight up old strings 0 plus 1 equals and we're going to see what comes out there uh but let's not stop there let's just think of a few let's see uh 4.1 uh and depending on the error rate too some of these values may be a little bit incorrect uh but they should be pretty close it's uh quite entertaining what a neural net can can actually give us okay so we're going to run these three values and see what happens all right zero plus one is one four plus one is five and two plus one is three we nailed it awesome so that is recurrent neural networks learning math now if you want to do some bonus material light it up with some math problems in this tutorial we're going to read numbers like you would from an image and for visual simplicity our raw data is going to be of strings like you see here spaces are what we don't want the neural net to see and this asterisk is what we do want the neural net to see now we're going to use this simple string and a simple normalization function to convert these inputs right here two zeros and ones so let's go ahead and write that first so we're gonna create a function and we're gonna call it two number and it's gonna take a character as an input what we're gonna return from this function is if the character equals an asterisk we're going to return a 1. otherwise we're going to return a 0. that's our character by character normalization function now we also need to create a function that normalizes for the entire input like the entire array that function's going to be called to array and it's going to bring in a string now the string needs to be a specific size and if that string dot length isn't seven by seven and we're going to throw a new error string in wrong size otherwise we're going to take the string and we're going to split it and then we're going to map it to number and that'll be our return value that is everything that we need to normalize our input value cool so next what we want to do is i'm going to paste in some number data but you'll notice the number of data isn't just zero to nine it's actually a string and you can see that these functions start to make a little bit more sense now two array is going to take this string in and it's gonna split up this long set of characters and it's going to convert them to ones and zeros so that the net can sort of understand what is is being said here now we have zero through nine and each of these you can see looks exactly like the character it's representing let's test at least one of these values so console.log we're going to put nine very good and we can see that represents what the neural net is going to speak so let's build our neural net so const net equals new brain dot neural network we don't have to mess with size in this because it's a feed forward neural net so let's build our training data const training data equals that's going to be an array of objects that have an input and each of those inputs are going to be one of our values above so the first one let's just say will be zero and the output is going to be an object and that object is going to be of the property that we're classifying towards with a value of one very good so let's go ahead and add the additional numbers here you see we've got one two three all the way up to nine and so now all we need to do is train net.train training data and we're going to log our results out all right let's see what happens very cool 190 iterations fairly low error rate very cool but we still haven't seen anything interesting yet let's go ahead and actually see what the net is outputting so net dot run to array and we're going to give this the number eight and now let's see what the neural net outputs we'll say const result equals and we'll turn off our logging up here because we know the neuron that's training just fine all right here it goes very cool now what you'll notice here is that the output is all of the properties that we used in the training data they're compiled together and the one that is most likely has the highest value so here 8 is a likelihood of 0.7 and that's really nice we don't have it though in a simplified format there is however a utility built into brain that is called likely that we can use here const or result equals brain dot likely and we're going to use our two array and we're going to send our net to it and here we're going to take this two array we're going to give it a string very good so that's our 8 and let's console log out the results all right here it goes very cool we got an 8 out of our neural net all right so that was a really simple example and it took a lot to work up to it because we've got a little bit of training data there some conversion etc but play around with this and see if you can get some different characters to be recognized by the neural net now a word of caution here this method will likely be a bit fragile in the real world without something like convolutions and those are coming to brain.js in version two but the thing to note here is that the principles still applies now there is a question to be begged here how resilient is a neural net why wouldn't we just use a bunch of if statements and a bunch of loops to build this example of an eight if i were to remove for example something that the neural net sees like one of these asterisks would the neural net still recognize this as an 8 or if i did the same with a 2 or a 6 etc well let's find out see it still found the eight this demonstrates one of the coolest parts about neural nets and that they are dynamic and they're resilient and that's why they're so popular and so amazing and for your bonus write three examples that still match like this eight but are not like your training data and that'll demonstrate the resilience of the neural net have fun in this tutorial we're going to write a children's book using our current neural network and we'll start with our training data here and if you'll go ahead and think about pausing it here what type of neural net that would use based off our previous tutorials okay likely you arrived at a long short term memory recurrent neural network we're going to go ahead and train on our data and we're going to give it a few options our iterations we're going to stop at 1500 our error threshold we're going to stop at 0.011 and we're going to log our details all right let's see if it rains very cool and now let's get it to output something interesting our first line from the training data net dot run is jane we're going to stop there with it and jumping to the more complex line i'm going to say net dot run it was just based off of these two lines let's see what the network outputs get rid of the log very cool so it starts out jane saw doug and jane looking at each other oh wow and then net.run it was love at first sight and spot had a front row seat it was a very special moment for all you see the net already altered a little bit of what was going on what you'll find is that depending on how you set up your neural net it can give you some really interesting outputs and the more data that you give it the more interesting it's going to get so your bonus here is to experiment with book writing in this tutorial we are going to learn how to detect sentiment from text directly and you'll notice our training data is a bit different than prior here we have an array of objects whose properties are strings rather than arrays of numbers and brain js is set up to go ahead and accept this type of input it's not a problem so let's go ahead and get started we'll build our neural net const net equals new brain dot recurrent dot long short term memory neural net and we'll go ahead and train net.train on training data now we're going to alter our training options we're going to stop at 100 iterations our error threshold is going to be 0.011 and we're going to log our stats we're going to cut the chase and go ahead and output something interesting we are going to use an input that's not from our list above we're just going to use something that's similar to it so net dot run i am unhappy go ahead and log that out let's see what we get very cool we got sad let's remove our log all right now let's add an additional item net dot run i am happy very cool now i want to point out that we're not training this for very long and that the error threshold if you were to bring that a bit down and as well iterations it's going to be quite a bit more stable but what you may have not noticed is that we did not send into the neural net of values that we trained it with and yet it was still able to classify them as happy and sad so again we're kind of highlighting the dynamic ability of the neural net and for your bonus tweak the iterations and threshold be careful because in the browser you can cause it to train indefinitely or for a very long period of time but add five new examples in the training data that would be up here and then log out of five examples that aren't in the training data all right have fun yelling at the computer sentiment detection recurrent neural network and in this tutorial we're going to explain kind of how we did it now if you'll recall we use both inputs and outputs for the sentiment detection recurrent neural network that is kind of a new concept when talking about recurrent neural networks because we explain them kind of like going to the movies now there are no inputs and outputs with movies we're just an observer sort of watching what happens next however we can bend those rules in order to fit the paradigm of an input and an output and i'll explain how now previously we mentioned that a recurrent neural network builds an input map and that is kind of like an array and each value in that input map corresponds to characters that are used in the training data but those rules apply here as well nothing has changed the input character one gets its own special neuron and its own special map its own special lookup and as well the same is with the output of character two however our input map is not complete what is different here with the training data is that there is an unseen character a character that tells the neural net to transition between an input and an output we'll call that character the new idea character all right and so if we look at our training data we have an input one and then we have our new idea and then we have our output of two and so if we were to look at a set of arrays that consist of what is being fed into the neural net they look much like this so our input map we have three indexes three neurons okay and the first one is going to have a value of one that first value is activated that input character one that is activated here and our value that's being sent through the neural net next we transition to the new idea character and so there new idea gets a one the next character is followed by two so there we have zero zero one so each one of these items in the array correspond to a neuron that correspond to our input map that correspond to our training data it sounds kind of confusing at first but what you'll get to notice with recurrent neural networks and neural networks in general is that they're actually quite simple and even the math that represents them is quite simple there's just a lot of it by taking advantage of those rules and that math we can bend those rules to our will now for our bonus here what would the training data look like if we start with 2 and end with 1. so 2 would be our input and our output would be one and then as well what would this set of arrays look like i'll go ahead and pause it here go ahead and write your answer and we'll compare notes all right and so now if we're to compare our answers they actually should look flipped and so our training data that has an input of 2 and an output of 1 will internally to brain.js look like this it'll start with a 0 0 1 zero one zero and then and finally with a one zero zero now this is all internal to brain js this isn't stuff that you have to learn it's just understanding the principles behind the neural net because again a neural net is simple there's just a lot of it in this tutorial we are going to use reinforcement learning this is a really exciting frontier of machine learning and we're going to use it right here you'll notice our training data is exclusive or right where we started originally and half of our training data has been commented out this is important what we're going to do is learn these first two items in our training data we're going to test against these first two items we're going to look at this next item and see that the net really doesn't understand it and then we're going to learn it so let's start by creating our neural net constnet equals new brain dot neural network and we had hidden layers of three and we'll do net.train that's training data we're gonna log out our results and let's see what we get very cool so we've learned these very first two items let's go ahead and remove our logging and then let's take a look at what the net actually outputs so net dot run and we're going to give it an input 0.0 we're going to console log that and i'm going to do array dot from all right let's see what we get very cool and that's exactly what we were expecting however if we add one of the examples of like one zero let's see what we get all right very cool and that's what we were expecting the net has not been yet trained on this data and so this illustrates why reinforcement learning is so important and necessary our training data may not be available all at once it may come over time and so we want to make sure that our neural net can adjust for that so let's go ahead and adjust our training data adding one brand new example the one zero outputting of one and you'll get to see how we use reinforcement learning in this feed forward neural net alright so training data dot push and we're going to give it an object that's an input array and 1 0 is our input and then output is going to be of one array all right and then really all we have to do is take net.train put it down here and we can give it some titles to be fancy console.log before reinforcement well we'll just copy all of this and then here we'll do we'll say after reinforcement all right let's see what happens all right before we have two very similar values and after illustrates that our net was able to reinforce now as a bonus we go ahead and add the missing item from our training data all right have fun in this tutorial we're going to build a recommendation engine we're going to do so using the simplest sort of methodologies this is one of my favorite examples because it seems so hard when i first started in neural nets but in fact it's actually quite simple we're going to start with our training data which is color preference and imagine that this list was built you just gave somebody these list of colors blue red black green brown and they basically wrote a number by them how much they liked that color so they like blue a lot they like red a lot however they don't really like black green or brown and that's how we end up with these numbers on both the inputs and outputs so that's our training data and we can learn that really quick using a feed forward neural net so const net equals new brain dot neural network net dot train and we're going to have our training data we'll go ahead and log out our stats see what happens cool our net was able to train really quick on that data let's turn off logging and see what we get console.log array.from net dot run and we'll say blue one now we're going to duplicate this line we're going to put brown all right here we go all right so the user has a very strong preference towards blue and not so much towards brown we can see that here from our output so here's the scenario over time you go back to that original user you show them this list and based off of their experience things they like things they dislike they now have changed what they prefer and now brown is one of their favorite colors so how do we get that into a neural net why don't you go ahead and think about that just for a moment and pause it here okay for us to get brown into that training data we have to put it there so training data dot and we're going to say push let's say brown one and output we're gonna put as a one all right and so now we have our training data in there so now what do we need to do to get the net to understand what this new training data means i'll pause it here and let you figure it out okay next what you want to add is net.train and we're going to give it training data and we're going to log out the results again stats and console.log stats all right and now let's see what happens and actually let's go ahead and console log out our values but after we train we'll give us a fancy title as well so before and you'll notice that we are actually using reinforcement learning a bit here just very simple it's not very complicated at all so before preference change after preference change let's see what happens very cool so we scroll through our training actually let's go ahead and remove the logging there we know that it logged now let's see what happens very cool so now before our preference changed you can see that brown was rated fairly low but after our preference change it was rated at a mediocre point five now why could that be we'll pause it here and let you think about it okay the reason is this our training data still has reference to when their preference was towards zero rather than towards one we want to ensure that we only have their current preference so training data dot pop that's going to remove the last item from our array so we'll pretend this is some sort of user interaction or server interaction something that happened to adjust their preferences that gave us brand new training data and now we're going to train on it again and then after that preference change we're going to have our brand new updated values here we go all right before our preference change brown was rated fairly low at 0.05 and after it came out of a 0.89 so this illustrates both reinforcement learning and also how to build a very simple recommendation engine now your bonus here build your own recommendation engine what's your favorite food where do you like to go does that change over time has it changed since you were a little let the net know have fun awesome job you got all the way through the course i am super proud and i'm very excited that you were able to get through listening to me but also building and applying and seeing these new concepts and how they can actually be quite simple but as we're progressing i'd like to give you some takeaways for this course to be able to remember and to share with others and that is this machine learning is moving really fast and that is super exciting that means it's changing and it's being adopted we're solving problems that we've never been able to solve before and you have a voice in that machine learning can change directions and a lot of that has to do with our understanding of how to use it we're also arriving at simple solutions are are so much more dynamic and powerful than complex ones when applying it so if there is a practice that you want to see more of or if there is something you like to change about machine learning try and introduce it study it prove it test it to see if it is worthwhile and not only will you benefit machine learning for you you're going to help all of us to have those new tools and capabilities so machine learning is moving fast and you have a voice and where it goes from this course to i wanted really to highlight that machine learning is actually quite simple the terminologies behind it we can get very lost in them but when we arrive at the logical foundation of machine learning it is simple there's just a lot of it a lot of numbers a lot of logic and i want to highlight where you go next with this simplicity with three illustrations and they are equals mc squared and ac motor and washing your hands these may seem comical at first but follow me the first is equals mc squared albert einstein discovered equals mc squared because he reasoned on that electrons moving around an atom would be affected by gravity kind of like when you throw a ball into the wind like a beach ball or something like that a child can tell you if you throw a beach ball into the wind that is going to be affected by it and that's how he reasoned on the matter so the point is that albert einstein used intuition use your intuition when you're solving problems with machine learning and solve for simplicity like e equals m c squared the next illustration was that of an ac motor now a lot of people know that nikola tesla helped to build and refine the ac motor but if you go back further in his career you'll arrive at that when he was in school he was shown this dynamo type dc motor that had these brushes and that arced it sparked everywhere and was really crude and noisy and he asked his teacher why it needed to have the brushes why it needed to spark everywhere and his teacher was insulted by him asking the question and made him write an essay and it's a really interesting story but the point is this he asked why it was even there and from then on he started to model his career to build a motor that didn't have those brushes and he arrived at the ac induction motor and refined it and he eventually used that same idea to help power both chicago and new york simultaneously from niagara falls it was a simple question a simple idea that got him started nikola tesla used intuition something wasn't right about using all that complexity solve for simplicity use your intuition this last illustration is one of my favorites and it's a washing your hands and the reason is because it's such a simple practice most people know washing your hands it's common knowledge it helps you to be clean but prior to the mid1800s it was not in fact in hospitals doctors would do all kinds of weird things like perform surgeries and then go help with births and they were wondering why their patients are dying left and right but it turns out that egonos symbolwise theorized not only that we were being infected by something but that we should wash our hands to prevent it and at first it was rejected the idea was absurd why why would you ever want to wash your hands which to us sounds absurd but eventually it was accepted the idea though is that ignosingwise did not have access to microscopes and it was not yet discovered what a germ was ignos symbolwise used intuition and it was a very simple problem and he used a very simple solution use your intuition find those simple solutions machine learning is being applied everywhere and that is super exciting because there is not an industry that is not directly or indirectly affected by it we are solving problems that we have never been able to as a race that is awesome but when you're applying machine learning use your intuition think problems through to the end and think about the simplicity and arrive at using that over complexity now this entire tutorial has been with brain.js and javascript and for that reason javascript thanks you and what i mean by that is until recently javascript really wasn't a very serious language with machine learning but that idea is changing and you are in part to be thanked for that in fact anybody who is looking at javascript as a potential solution for machine learning that is awesome and we should spread it like wildfire not just in javascript but in every language every computer language that is out there should have the capability of using machine learning because it is so amazing now i want to take this moment to invite you over to the machine learning movement in javascript which is the bri.im website and as well their slack channel there you're going to find likeminded individuals who are not only interested in javascript as a means of using machine learning but also challenging the ideas that are out there now and introducing new ones i look forward to talking with you there and there are many others that do as well thank you as well for letting me teach this course teaching using the scrimma platform has been a real honor and i really too thank the encouragement of the scrimba crew you know who you are for prodding me along to make this course and i want to thank you for your time and letting me talk about these ideas and try to arrive at some sort of simplicity with them if you're following the entire course all the way through to the end i look forward to seeing what you can build and now comes the fun part we get to use machine learning to solve real world problems i'll leave you to it