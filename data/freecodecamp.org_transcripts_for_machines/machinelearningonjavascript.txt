a little bit about myself before we start i'm from argentina uh this is my first conference outside south america as both as a speaker and as an attendee so i'm pretty excited about that i work coding and researching different things at movies we heard a booth so i talked with some of the guys here uh if you want to find me on the internet those are my github and trio profiles so if you're wondering a little bit about movie we are a software consultancy firm we are based in north in texas uruguay argentina and colombia we work on a lot of different technologies languages we build a lot of different things from mobile apps to websites and everything we have our first node.js react.js apprenticeship on austin we do that periodically so if you are from austin or you know someone from austin that might be interested in learning nobgs or reijs just check our site and see how that's going um that's our trio so before we start i would like to make one disclaimer uh this was originally a one hour long talk because a broad topic and i need to feed them in 25 minutes so bear with me on some things i hopefully will get through everything um so a lot of people ask me today why not js for machine learning especially because there are a lot of languages that are well known for being performed are they have better libraries for data data science you know python has tensorflow cycle learn air has a lot of math libraries as well as math lab uh my answer like personally was that after es6 came out i'm using javascript for everything uh all my prototypes and everything is javascript but if you want to you know talk to your boss about using javascript for machine learning you should go with this explanation we do web development so it makes sense for us to use node because we already using node we know like the ecosystem package management management manager and everything so it makes sense it was easier to import people because they already know es6 they already know javascript and they already know everything but the framework and a little bit about the theory so you don't need to explain like tensorflow distributed computing or extra things that you don't really need for the case we all love javascript because we are all here at javascript conference node.js has a lot of modules that are great for different things like normalizing your data working without output a lot of just general things we have module for everything so that's great i don't know um the first one the right tool for the job well for me work because i'm not ingesting the amount of data that facebook or instagram are using or ingesting so for me makes sense uh it's working now in production some of my products uh i had recommendation systems and a lot of things working they're fine don't have any cpu issues much so that's pretty cool so yeah what's uh machine learning anyway i was trying to find like a definition of something to put in here and i found this quote from arthur samuels he's like a pioneer in artificial intelligence intelligence he said that it's a field of study that gives the computer the ability to learn without being explicit program and this code is interesting to me because it draws like the difference between what's called weak ai and strong ai weaker guides you can think of that as when you code like a program to play chess or checkers as a user you get the impression that the computer is actually thinking of how to beat you or he the computer will learn how to play but actually it's just following a set of steps that you preprogrammed like trying out like foreign forcing or whatever uh but strong ai it's when you program the mechanism for the computer to learn to do something um it's up to the computer what they do next so that's kind of of what's interesting and hard about machine learning uh i'm linking here to a paper for from arthur samuels about game theory and ai and that's a pretty good article about the difference between artificial intelligence and machine learning so if you want to check those out there are different kinds of learning the first one is on supervised learning this type of learning is when you have a bunch of data that you know nothing about that maybe you're mining from your application from other places and you just want to try to figure out a pattern or some way to grow that data for example maybe you have a bunch of data from your users like their weight and their head and you just move things around and then you figure hey so all these guys are size s for tshirts these are guys this old set of guys are medium and so forth so that's kind of what this kind of learning is about it's pretty commonly used for data clustering and data mining and then we have supervised learning which is more early use which is basically learning by examples you will have some a set of data label data so you know what that data means and you're going to feed that data into your model and your model is going to try to figure out a function that can learn different patterns about that data so basically that will help you to solve a lot of different problems some problems that supervised learning solve its classification problems which is basically you taking an input and you need to classify that input among a set of labels for example an input being a picture and a set of labels being that's a hot dog it's not a hotdog our regression problems when you try to predict some continuous numeric output based on an input for example trying to figure out the price of a house based on the size of the house or trying to break your score in a test base based on your previous scores uh that's a regression problem there are a lot of different types of algorithms there are there's so and those are pretty popular but there are a bunch more uh i have been using all these in javascript uh for the first four uh key near network neighbors uh classification regression trees support vector machines name bias there is this package called machine underscore learning they have implementations of all of them so if you want to just play around you can download the package and throw inputs and see what happens if you are interested in how the algorithm works you can just go to the source and check the files they are fairly small and it's pretty interesting to just research and check how those are built and that paper it's about like a brief description of everyone every single algorithm i think there are more than those and why would you use one over the other and just like use cases in general just pretty cool so i'm time uh i'm going to try to do a brief introduction to neural networks in javascript i'm going to use this library for the examples it's called synaptic.js how many of you have heard about synaptic.js how many of you are using synaptic.js like okay so this library uh it's it's for me it's great it works on both the browser and node.js it's what's created by this guy juan casala which is from argentina he has a lot of examples uh pretty wiki with a lot of examples everything's pretty well documented so just getting there was just a brief getting from trying to learn machine learning in python and i was racing issues like asking super new questions and they're well super polite like yeah you need to do that or they were explaining everything to me i was pregnant so go and give him stars or asking asking questions okay there is another library called knit taptic which started as a fork of synaptic then they built their own thing using back propagation and no revolution so this is more for kind of gaming things it's more performant but if you just want to play around with things i would recommend start with synaptic and then move to knit a big so thing uh every time i think of neural networks that's the picture that everyone that has in his mind like about notes and arrows and that doesn't really explain what they do but what they basically do is uh split data into groups so what you're trying to get the computer to do with a neural network is he computer could you split this data in different groups it's like sure i splits the data into groups and then you have a new entry point of your data and you can just see where it fits and that's like the classification of the regulation problem so starting from like the basic unit of a neural network obviously it's a neuron i won't draw the parallelism between this kind of neuron and the real neurons because i really don't know how neurons actually work but i don't know i know how this works so uh yeah a neuron basically is composed of different parts we have these arrows coming into the neuron which is the red dot right there these these arrows are called synapses uh they could be an output from another neuron or just your input every single one of these synapses or the arrows are a value which is your input and they are all multiplied by a weight that way at first it's random and the whole thing of machine learning especially on neural network it's just finding the weights uh that makes sense for your data to get the input the output that you want uh then all neural networks besides their inputs they have one extra input called a bias which is always one and it has its own weight uh and this bias what it does is ensure that even if all the inputs are zero you're still going to get some kind of output that's why that's a one it has also random weight assigned to that then the neuron has a an activation an activation function that we're going to see a couple of slides uh after this one and then you have the synapses going out of the neuron that could be your final output or it could be the input of the next one so the activation functions uh what they do basically is grabbing all the inputs from the neuron they add them together the inputs of the neuron are basically your inputs or the input of the of the or the output of the previous neuron multiplied by the weight and the activation function grabs all the inputs add them together and then use that as an input for for itself synaptic.js by default uses logistic sigmoid functions which basically maps every value that you use as an input between 0 and 1 that's basically what it does if you want to know more about like the theory uh i linked some papers there and some an answer in quora that was pretty well explained there are some more uh activation functions i'm playing with rectified linear unit now a lot i didn't use the other two and i know neptopic has even more but sigma is pretty popular and you don't really need to change that unless you you notice that your use case is not like working so you can play around with the functions and trying to see what it's better for your use case but starting with sigma it's totally fine so a neuron can perform these four different operations they can project they can activate they can propagate and then gate project is basically setting a synapse between two neurons that's the red one it's projected into the blue one they can activate that's when they grab all the inputs add them together and call the sigmoid function with that value uh they can propagate which is the actual training of the of the network that's when you uh you said uh you get an output from the neuron that wasn't what you expected so you propagate back the error based on what you really expect though and that's going to change the weights of all the synapses back uh like on the uh to the first input neuron and that's what's called back propagation and that's how the network learns and finally they can gate that's an operation that's not pretty common it's just for one kind of neural network that if we have time we're going to see later but yeah this is a small example on synaptic how you can create this neural network based on two neurons we create two neurons a and b we project a to b that's the synapses between those and then b has an output then we activate a with 0.5 then when we do that a sends through the synapse 0.5 times random weight first and then we activate b b grabs that output from a performs the sigma activation function and we get like a lot of random data because we are not really doing anything so if we wanted to train uh b to output zero every time that a activates with one this is how we do it uh we do the same thing that before create the two neurons we project one two to the other one we set up a learning rate that will be important for all propagation and then we have a for loop uh that that's our training session this training session has 20 000 iterations and on each iterations does the same thing because a activate one then activates b we don't care what b is at this moment like what the output of b is because we are going to propagate that error so we say every time we activate a a uh you should propagate b with zero so what we are saying here is every time that a is one b should be zero and the propagate will change the way it's like 20 000 times until we get closer and closer to zero so when the training session session ends we activate a we want and we get that something pretty close to zero that you could do a math from and that's the training of your first two neuron based uh neural network uh obviously on real neural networks you will need like a bunch of different neurons and layers and this is all our real neural network looks uh you can see on like why um who why you should use a number of uh hidden layers and how many neutrons uh the hidden layers should have based on those there is a paper right there and a stack exchange link that explains that very well so let's build a small neural network as an example uh you are i guess all familiar with the xor operation uh what it does basically it takes two inputs if the two inputs are equal uh they output zero they are different they output one so we are going to train a neural network to perform this operation so based on this uh on this picture we can say okay so we have two inputs on our vector so it's going to be two neurons on the input layer we have one output on our vector so it's going to be one neuron on the output layer and then we usually have at least one hidden layer you could not have any but that's just for super simple classification problems and at that point you might not need neural networks i mean you can use them but it defeats the problems but yeah let's use one hand layer and the rule of thumb for selecting how many neurons should be in the handle layer and the hidden layer it's basically the mean between the neurons on the output layer and the input layer so in this case two so uh going on synaptic again we import the layer object the number of in the network object we create all three layers uh ignore that three right there there should be a two what yeah then we project one layer to the other one uh the input layer to the height and layer the hidden layer to the output layer and then we create the network using the network structure so we have network it looks something like this to when it runs from the input one of the on the output and or hidden layer and this is how our training looks we are going to use a learning rate of 0.3 this is like my starting point for every learning rate then i tweak that i play around with that until i get the output that i want and that's kind of how it works unless you have a phd and you know what you're doing but that's how i do it uh well again we have training session of uh 20 000 iterations and we say okay every time that we activate our network with zero and zero i'm expecting a zero zero one i'm expecting a one and so for it and that will loop uh twenty thousand times and now if i can get console torque i can do uh this is for example uh how it works it's pretty fast uh it's a small example and you can just play around with that like saying 101 and i will put someone uh yeah i will upload the code for for the examples uh later on my github but yeah this is how you can build a simple neural network uh one thing that you might notice is that all the inputs are zero numbers between zero and one so if you want to use like real data that you probably want to you need to perform normalization that means all your data should be mapped into values between zero and one uh i have an example for that but i had to put that up so go to synaptic they have a great guide about data normalization um yeah there are some other types of networks uh we have convolutional neural networks these are mostly used for image recognition uh because if you try to use a regular neural network like this one uh like with an image you will split the image into pixels but then uh the neural network won't have the context to make sense of those pixels because it needs a special con spatial context so that's why what this uh neural network brings into into the table you can see that link explains everything pretty well uh this is based on how the animals actually see pictures so it's pretty interesting you are into those things then you have recurrent neural networks these are neural networks that uh feeds themselves with their their own output so this is for trying to find patterns on sequence of data uh basically uh if you are like trying to teach the neural network the alphabet you will need to know which letter was before the one that you are doing now and that's that loop does that that gives that little context then you have uh another type of neural network that it's still recurrent but this one keeps uh it just that gate function on the neurons and it keeps uh track of things that happen long time ago this is used when you want to teach like a neural network to write like harry potter you can make the network like read all the books like 20 000 times and then it's going to remember yeah so every five characters i use a space i say hurry this many times between each word and there are a lot of cool experiments with that you can just go into that league and see there are a lot of people doing little interesting things with this kind of network so i have a couple of final notes this is like my main note uh i experiment a lot with node.js and just with every model that i found and i really like to encourage people to do the same because i didn't know that we had so many modules for machine learning until i started like the nickname on npm so i think uh everyone should just go and play around with synaptic and you know make your coworkers aware that that exists because maybe they want to learn about this and they don't want to learn python or math or tensorflow so now it's pretty cool uh and also there is a quote that i heard on the ireland conf a couple of weeks ago saying that if you are employing people give you should give them time to experiment because otherwise they are going to experience production you don't want that so that's another note um i know i there are people that's concerned about the performance of javascript in all these things so my answer is check gpujs hamsterjs gpujs selfexplanatory you can access the cpu the gpu with javascript that solve a lot of my problems with like huge amounts of training data i just connect the gpu and you said if you don't have gpu you can use hamster.js which is a native trading for node.js that's also solved a couple of problems for me and yeah if you want to play around with neural networks and you don't know what to do there are libraries for iot like journey five cylon and you can use that as inputs on your neural network and start doing like weird things you know and there is robot.js which is automation for the desktop on node.js you know you can just feed a recurring network with the movements of your mouse and try to regret your session i mean you can experiment with a lot of modules so that's pretty cool and like last thing i have a lot of meetings with clients that they say yeah i want this machine learning algorithm to predict uh stock trades or you know to be rich or something it's like yeah that's not how it works i mean your pro when you're working machine learning your product is not actually the machine learning algorithm because everything is open source there are papers for everything if you want to build a neural network that learns to play music there is a paper for that there is at least a hundred guys that implemented that in different ways so the product is the data if you don't have data then they will it's just not going to work and it's going to work poorly so if you are working on machine learning things your real product it's the the data uh my last advice follow this guy he posts a lot of things for machine learning for normal people like me so i understand that so you can understand that too so thank you for having me