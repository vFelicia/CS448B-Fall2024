one practical use case for artificial intelligence is healthcare imaging if you're interested in the fields of machine learning or artificial intelligence this is a great course for you mohammed who is a computer vision phd student will teach you how to use pytorch and monae for automatic liver segmentation my name is mustard amin i am a research assistant and phd student in computer vision today i am presenting to you my course about liver segmentation using monae and pytorch by this course we'll start by defining what is unit then we will talk about how to prepare our data we'll start by downloading them preparing them and doing the preprocess then as i told you during the preprocessing to data and applying all the transforms that we need to do for medical imaging using monae then we will talk about all the installations that we need to do from one eye by torch cuda dnn etc etc so we'll talk about all the packages that we need from the python packages into the other softwares okay then we will talk about what are the common problems or errors that you may face using one eye for medical imaging of course then we'll talk about the training part which which script that we will use how does it work extra etc then after that we will talk about the testing parts after finishing the training we will analyze our data not data but we will analyze our model and we will pass some testing passions and see what our model is giving us if it is going great or not and i will give you some advices how to fix or how to make your accuracy better if it doesn't go go well at the end and after that at the end i will show you how you can just clone the github repository if you understand everything i will say in this course you can just clone the github repository and try using the scripts so i will show you how you can clone it how to install the different packages and how to use all the scripts that i am providing you in this github repository a little bit about unit so unite is a deep learning architecture for semantic segmentation it was created first for biomedical imaging so when you if you are interested you can read the uh the uh paper so in their paper you will see that this architect architecture was created for biomedical imaging and because it is a great architecture and it has a good accuracy they started using it for the other image segmentation tasks so now let's talk a little bit about something else and we'll go back to the architecture after now maybe some of you die doesn't know what is the difference between image classification object detection or image segmentation so the image classification as you can see it is what is the easiest task in deep learning so image segmentation means the image classification sorry means that if you have an object in an image so you just need to know if there is no there is that specific object in the image or not so in this case we have a cat in the image so the output of your model or classification model will be a problem probability that means that you have a cat or not with a probability from zero to one more closer to one means that this object exists in the image but that's all what you need to do this object exists or not then there is the object detection which means that you need to create or to draw a bounded box in the image or localize the objects in the image not only saying that this image contains a cat but you need to draw a bonding box which means we need to localize it in the image so this is the object detection then the image segmentation means that you need to draw a mask in the image to refer to all the pixels that has that have the same object so in our case we need to specify which pixels have the uh the object which is the cat so in that in this case we need to draw all this mask to refer to the cut in the image so this is the image segmentation then in the ms segmentation there are two types that is here the first type is the image segmentation which is semantic segmentation and the second one is the instance segmentation now here in the left you can see this is the in semantic segmentation means that you need only two segments how many classes you have which means here we have only two classes we have the class person here and the class background so that's all what you need to do in instance instant segmentation you don't care about how many people you have or how many other objects you have in your image you don't you don't care about that you need only two segments the classes that you have here we have class person class background but in the instance segmentation don't only you need to create to segment the classes but you need to specify how many uh objects or how many people here we have in that image so in this case we have person one two three and so far which means that you need to segment the person and say this is a person one this is person two etc etc so if you have two three or more than that classes so and in each class you have more than one object in the image so you need to specify this is the object one from the class x this is the object two from the class from the same class which is class x etc etc so unit is an architecture to do semantic segmentation which means it will do only this type of segmentation it doesn't do this type you can see faster mask mask faster cnn to do instant segmentation but you net you can use it only for semantic segmentation and that's all what we need in our project we need to do a liver segmentation so we need to know what is the liver and what is the other part of the body which is the background so we don't need to have there is no two levels in the same person or something like that so that's all what we need segment the liver and the background so we will for that we will use a unit here now let's talk a little bit about the architecture the architecture is in the shape u for that it is called unit for this shape okay now units you need to know that unix is one of the easiest architectures in deep learning there is nothing hidden or there is nothing difficult on it you can see that there is only or there are only convolution layers and followed by a max pooling convolution layers max pooling convolution layers max pooling and here it will do up convolutions and max pulling up convolutions etc but why they are doing this because unit is divided into two parts there is first part called the encoder which is this one here the down we can we can we can call it the down blocks or the down part here for us which is called the encoder so we don't care about the names but this part here is going down which is the encoder so if you if you look clearly to this part it is looking like a normal image classification architecture okay there is nothing new that is only here convolution blocks because this one is called the convolution block but it is convolution layered followed by max pooling convolution layers max pooling and each output of these these convolution blocks there is a real function so if you understand what is happening here you can see that this is a normal image classification architecture and here this is the final output that we can put it we can pass it by a softmax layer or something to see the output but this is not what we need here we said that our output that we need we need it to be a mask with the same width and height of the input image so that we can specify specify each pixel uh and its class which means pixel one goes to class zero or class background or class lever or something like that for that we need to do this part which is called the decoder so this decoder we take the feature that we have extracted in this encoder part and use them here to build the output image so that you will have each pixel instead of having only one pro one probability for all the image no you will have a probability for each pixel so that you can classify each pixel how many uh uh to which class it goes for us we call this pixel probability not a normal image probability or something like that now let's take an example about how does the output of unit look like here is for example this is one or this is the output that i used for my project which was the tumor segmentation in the whole body so i took just this example to show you how does it look now this is the input mask which is the label or the ground rules you can call it as you like so this is the input mask i didn't have the time not time but i didn't have the space to put the image as well but i think this is enough to see so this is the mask that you have now these are the two outputs of not it is one output with two channels of the unis so if you have this output here or this output channels differs from how many classes you have so if you have two classes so you will have two channels you have three classes you will have three channels etc etc each channel will have the pixel probability for a specific class so in my case i had two channels the background two classes sorry the background class and the foreground class which has the tumor and in our project here we will have two classes the first class is the background the second class will be the level so this was the my outputs this is one of my passions so these are these are the channels for one output this one refers this is the output zero this is out this is the channel zero this is the channel one so this one refers to the background and this one refers to the foreground which is the tumor now the values that you see here more value more the color closer to the yellow means that the value of these pixels here is closer to the value one which because we said we have pixel probabilities which means differs from zero to one so more we have the value yellow more we have the uh the that's pixel goes to the class zero which is the class background and more the value goes to the purple here means that the value is closer to zero so if the value is closer to zero so means that these pixels doesn't go to the class zero which is the class background and here same thing for this part but this channel is the channel for the foreground which means for the pixel 4d for the i forget the name this channel is for the tumors so these values here you can see that they are closer to the yellow means that these pixels contain a a tumor and all these pixels doesn't contain tumor which means these pixels are background and same thing for here so you can use only one of these channels to specify your your predicted or your final prediction or you can use all both of them and use a arg max or you can use a softmax or anything you want to apply or only a simple threshold and get the final output so that's what we will do in uh in the in this course so but these all these parts will be will come later after doing the training and etc but just i am showing you how does the output of unit looks like so you will have this is the label you will have two channels or how many classes you have in our course we will have same thing two classes the background and level so you will have pixel probabilities of each color of each pixel and using arc mugs or a simple threshold you can specif you can get your final binary mask which is like this this values are one these values are zero so this is a binary mask or force and two you can use as anything you want depends to how you are uh doing the threshold or something like that because if you will do a normal threshold so you have force and two if you are using a normal arg max so you have zero and one but it is the same thing you don't need to care about that now that's it and thank you for this part and now let's do some installation now let's talk a little bit about the software that we need in our project we need only two these four softwares which are we need python vs code 3d slicer and etg snap i am not talking about the dependencies like python dependencies that we need like your monae et cetera but all these dependencies will not talk about them now but we'll install only the the software that we need the first one is python as you know because we'll execute our code using pytorch and monae and of course using python not plus or other programming language then we need the text editor where we will need to write our code for that we need to install vs code so this is my choice and you can use any text editor you want but my preference i preferably need to use vs code but if you want or if you prefer using another one or maybe you you want to use jupyter notebook or something like that it depends to you and it doesn't change anything just i am showing you what i will use this in this course so you can follow me if you want then we will use 3d slicer so this 3d slicer we will use only to display our data and we use it as well for something else we may need a conversion that cannot be done using python but we will talk about this in the image in the processing or in the preprocessing part but for that we will need this this 3d slicer software after that we will install it snap because we will need this type of software maybe we will not use it in this course but maybe you will use it because we can i will show you how you can do the segmentation or correct the segmentation using this bt case now because i don't know if you will use the same data set that i will use or maybe you will use your custom dataset so for that case maybe you don't know how to segment or how to correct your segmentation for that we'll use this atk snap software and of course i will show you how we can use it for now i have all these softwares installed in my computer but i will show you how you can do it by your own now let's go here we said that we need to install python first so we have python.org then slash downloads as you can see here this is the latest version which is 3.10 if you want to use this one it's different to you if you want to use another version so you can just click on windows and all these all these versions they are here but don't worry about this maybe i will show you in the following videos when we start coding and when we start installing dependencies we will i will show you that sometimes we need to create a virtual environment and where we will install a specific version of python in that specific virtual environment but at first we will install one of these versions and maybe you need to install the 3.10 doesn't matter because maybe we'll use it only for some preprocess not even preprocessing but we used for preparing the data because we will have for we will pass by three or four phases before doing training because there is preprocess but before the preprocess we need to do something with this data because you know that medical imaging are very very hard to use or to treat for that we need to do some preparation after that we'll do the play process because these are two different processes for that i am saying prepare and play process because uh i am saying i am i i want to say that there are there are two different types okay so if you if you want to install for example python 3.10 just click on this or you can just go here in downloads and download python 3.10 and just save it anywhere you want like this and it will be downloaded of course my internet connection is a little bit slow for that i need to wait a little bit so just you need to execute this command and follow all these steps i don't want to do it because i have already python i have a lot of versions of python installed on my pc for that i will not do this here but you can see that you just need to here because in my case i have already python so i need to install it then install it again but for you you will have only a button to say install and follow up all the steps and it will be installed so i will cancel this yes then here we said that you need to install python here is after that you install it now it is done now we need to install this text editor which is vs code and of course i have it already as you can see in my pc but i will show you just how you can download it and maybe try to install it so vs code download like this and you go here to code that vs code studio and there is order is this link both of them are official so you just need to click here now we have windows and it depends to how many which operating system you have so in my case i am using windows so you can just go here windows and windows 10 and click on download here or it will start the download by itself but if it doesn't start you can just click here on download okay now you need just to install the to to download this one maybe it will take time because as i told you my internet is slow these days so just download this and install it and follow the steps as you will do with python and it is very easy to install as any other software i will just cancel here now after sorry after that we don't need this for now now after installing this vs code let's talk about 3d slicer tree slicer is the same thing it is a free software that you can find here 3d slicer slicer download like this and this is the 3d slicer download just check which operating system you want just take the stable release don't take this one so just choose windows mac os or linux and for my case i am using windows so i need to download and install this one but but but as i told you i have already the software so i will not go and install it again especially my internet connection is slow but you get the point download this and install it step by step it is free and easy then after installing 3d slicer here because i told you that we will need it for some preparation of our data and visualization of course as well then we have the etk snap that we will use for segmentation by the way you can use etk snap for segmentation but sorry you can use 3d slicer for segmentation but i found this little bit difficult because you will see that etk snap is easy very easy it is old but it is very easy to do the segmentation than using 3d slicer but if you have already used 3d slicer for segmentation so you don't need to follow me doing this with etk snap okay so i am telling you with my experience i tried to use 3d slicer and i tried to use other softwares for segmentation but the easiest one was atk's not for me for that i am presenting you just need to etk snap okay and i cannot use use et case now for the uh some preparation for that i need 3d slicers so each one has a specific advantages and disadvantages okay now let's search for atk's not like here we have now we have this or we can just click on download downloads here you can see even the uh web page is too old but it is a good software okay so you can just choose for example windows or and all these versions you will take the latest one okay now you can use for windows mac os linux or something like that the best to you and your operating system so for me of course i would use this one but i told you i have it already on my pc so i will not take the time to download it and install it again so that's all what we will need for our course i am talking about the software we go back after to talk about the dependencies but for now you need to install python vs code i will leave all the links in the description so you need to install python vs code 3d slicer and etk snap and aft after installing this we'll go back and we'll continue doing our course now let's talk about the data set i will show you how you can find some public data sets otherwise if you have already data set in your projects then you can use it but if you don't have and if you maybe you are trying to do this segmentation just to improve your skills for that case in this case i will show you how you can find some public data set so the first source that i will show you that it was helpful for me and it contains a lot of data is the decathlon data set so this digital data set as you can see here there is i think nine tasks we will go here that is papers data there is more things but what we we are interested in is only the data set so we just click here in the guest data and you remember with me you just write the card long data set you will get the first link here but i will leave all the links in the description don't worry about that but when you click here go to get data and it will open the google drive here and you can see that all these tasks as there is 10 tasks as you can see here so all these tasks means that all these are group of data which means it is really you will find the volumes with the segmentation so everything is ready just need to download it and use it but here you can see that there is brain tumor there is heart there is liver as you can see here there is hippocampus there is pro proscad prost sorry prostate and there are all these things that is lung etc etc and this one as you can see here this task nine which is the spleen which was used by monae so if you go to my website here for example i will choose it because our course is based on moonlight as you remember so if you go here in monae and you see the project that they are doing here for example we go to github and most of the projects and most of the tutorials that they are using here you will find that they are using this data set and we see that the because i found this decathlon data set from monae website so when you go here you will find this spleen data maybe you want to to try it i don't know but in our project we'll use the liver segment the liver segmentation so but i am not using this one you can download this one and it depends to you and what you want to try okay so for me i found the data set from cargill i will show you as well there how you can find that and i i'm sure that there are other data sets but for now you can find the best ones here in this website and in kaggle i will show you the data set that i will use in this project if you go here in cargo go to datasets maybe you you need to if you want to search in general you can write just healthcare images or healthcare datasets or medical imaging and found all the tasks that they have otherwise if you are searching for the exact data that i am using or i will use in this course is lever segmentation so just write level segmentation like this so here you will get all these results but these are the the because i am saying these because there is this first part and the second part of the data that i used in my project in discord so if i will open this and this in the other another tab you go here and you found all the these segmentations and these are the volume segmentations are the labels and these are the volumes and you can see that they are not completed for that there is the second part that you will find the other volumes of the first one here so you can download this i have them so i will not download them but you can download this if you want to use the exact data that i am using so you can download this first part and second part put them in the same same folder or something and we'll go to them later now after that you choose your data sets it can be this one this one or other task but what i want you to know is while using monae framework you need to have data set with the extension nifty so it should be and i i dot and i or compressed nifties but you need to have the base the base extension nifty for that reason you need to search for data that has nifty or or you can search for data that can be converted into nifty for example it can be an ldd or an rd or it can be dcom or any data that can be converted into nifty otherwise you cannot use these kinds of data with one eye for why i am saying this because if you are using simple 2d segmentation you can use anything you want and you don't need one line because i am using monae especially for the preprocess part because you can't find a good framework that help you to do preprocessing as the 3d volumes in medical imaging i couldn't find something better than one eye for that i am using because mona is great thing they are not paying me to say this but it is a great framework for medical imaging they have some problems and some things that they need to fix i will talk about them in some in the future lectures or future minutes but before for now i am saying that it is great framework but some improvements does need to be done we will talk about them later so i if you you need to put this in your mind when you want to use mona you need to have nifty files if you don't have a specific niche device you need to find data that can be converted into nifties so how you can convert this data into nifty this is another question so some of the the some of the extensions can be converted using python for example like the dcom images if you have series of decode because a nifty file is a series of decomps because the decom here i will show you an example this one as you can see here this is all these decons that's that goes to one passion so all these d comes each d com is one slice of a ct scan when we combine them all these d comes together we get one volume that one volume is one nifty file because when you take one nifty file and put it into the slicer or any other software to visualize it you will see that it it contains a lot of slices so each slice is a decom file that's what you need to know i don't know if you know that but i am just saying that so as i studio try to find nifty files or files that can be converted into nifties now you get this data if you want to convert them for example if you want to if you have dcoms like these and you want to convert them into nifty you can use 3d slicer but i think that for this kind because there is a python uh the patent package that does help you to do this conversion for that we don't need to use this there is d come to a nifty package that you can use it install it using pip install but don't worry about it we will do this later because now i am just talking in theory but we will do the code to do this conversion after for now i am just telling you that you can do this conversion using tv slicer but i don't recommend you because it will take time to upload or to load the data and save it so don't think about this for now but if you have for example nld images or something like that for that case maybe you cannot convert them using python for that you need to pass by this software here now let me tell you something how you can convert data using this i i will just show you how i i did that so what you can do because i had a problem when i was doing some segmentations i couldn't save them as nifties so i had segmentation or labels they were in energy extension for us i needed to convert them into uh into the nifty for that i passed by this software so now let's take for example this is a nifty file we don't need to convert it but just to show you how you can do that imagine with me this is an nrd file to open it just pass it and put it here in the in your software and drag and drop it in the software and click ok and it will be opened as a volume here and if i will scroll with the mouse you can see here i am passing by all the cuts or all the slides which are already decompiled okay so that's what i was talking about when i am scrolling this here i am passing by all the decon files that have been combined to create one nifty file now imagine with me this was a nrd file for example now i want to convert it into an ec what you can do just put it here drag it and drag it and drop it here it will be opened or you can just open it here file open etc now to convert it click on save now just don't take this one and check your file here you need to see because this one is the project you don't need to uh to save it so just save your file here if you have multiple files you can drag them all together here and they will you wish you they will show you all the files here that you have been opened and you with one click you convert them all at the same time okay so here let's say that this was a nrd file so here you can see that there is the there are all these kinds of files and led like this one for example if imagine with me our file was energy now you want to easy to save it as a nifty file so just click here search for nifty it will be here so there is this one nifty this one the same thing but this one is complete compressed i recommend you to use compressed so that you will save some of your memory you don't need to worry about compressed files when you use monai because it will know how to i will show you how to do that because you don't need to worry about that so i recommend you to save them as nifty which means nii dot gz which is compressed so click here and click on save or you can choose the directory when you where you want to save your file then click on save and it will save your file if you have multiple files just change them all here in the place of nld puts nifty and change them all and click on save it will save them all together in the same repository that you want so that was how to convert any file i am not saying any but you need to see here you have there is nld meter image all this kind of files so if you have data set with this extensions and for that and you want to use monae so you need to convert them into nifties so you need to pass them by this software for example and change them maybe maybe you have some extension that doesn't exist here so you need to search another software or maybe there is a python script that does that so that's my recommendation but if you find directly nifty files of or if you will use directly the data set that i used here like this one and this one in this case you don't need to convert anything because they are already nifty's okay so that was about the data set and in the next uh in the next lecture on next minute we'll start doing some preprocess to our data and there is something we need to talk about before doing the preprocess but don't worry we'll go step by step until the end of this project now let's start preparing our data as i told you in the last parts of this course i said that there are two different parts there is the preparation of the data and there is the preprocess i am calling them this because there is the preparation that we will do manually and it will we will do it in another with script without doing the preprocess because the preprocess we need to do it directly before the training so before doing that we need to clean the data because medical imaging are a little bit confused we can't use them directly to our model or our segmentation or anything like that because if we use them directly we will have some problems and will not have good accuracy and even we cannot fix our problem and we cannot even know where is the problem there so for that reason we need to do some preparation to our data before starting the preprocess or the training or anything uh that we will do later on so as i told you there is the data here in the catalog data set and there is in kaggle let's go here and and i will show you that we will use this this card this decathlon data set i i have already downloaded prepare it and everything i have done but i will show you only with two or three passes to show you how does it work and so that you will have an idea how to preprocess your own data okay because if i will do the preprocess or the preparation of all the data it will take time but we don't need that because when you understand how to do it for one or two passions you can do it for all the buttons and don't worry about the code i will provide you everything uh that will use here in this tutorials so don't worry about that now as i told you you can you go you go here to get data and it will open this one and as i showed you we are doing lever segmentation so this is the details that you need to download as you can do just like this click with your right right hand and click here in download and it will be downloaded and you can use it directly okay now after that you will download this data it will look like something like this and after that you decompress it it will be something like this and when you enter you will find all these files we don't need them you can do it delete them but you will find three different folders this one is image tier which means image images for the training and this one are images for the testing and this last one is labels for the training which means you can see that there are labels only for the training images there is no labels for the testing images so in that in this case it is easy to understand what is delivered but in some cases it is not easy but for now we will not in this course will not need this training you can leave it here but we will not need it because at the end of our training we need a label so that we can compare the label with the images that we have with the output that our model will predict so in this case we'll take only the images training images and testing and training labels and we'll take few passions from from the training maybe we'll take 10 or 20 because we have here you will find that you have 130 these are only because it is redo it here after the completion but in reality there are only 130 passing so if you take 10 or 30 passes for the validation or for the testing so not all of the because validation is different than testing so because in our case we do training and testing will not do validation because when you go to monae tutorials you will find that they are using the word validation validation but i am not sure that this was the validation because because it is true that they will use that data during the training but it is not validation because they will not affect the training or the model they used only to calculate metrics and to uh to yes to test their model for that case we cannot call them validation they are testing data set not validation for that because actually we will not we will use almost the same code i am talking about the preprocess and the training we use almost the same code provided by monae but we will do some changes for example i will not use the word validation i will use testing etc etc but we will go to this uh real back to do this to go to this later but now as i do you will when you will download the data you will find or you will find all these passions but as i told you i will not do the process for all the passes because it will take time and memory and i have already this data so what i did i just took two end here of course the the images with the labels so what you need to do is just to uh follow me how i will do this uh process for two patients and after that i will show you how you can do it for more uh you will know how to do it for all your passions but there is something that i need to talk to tell you about is here in monae you will see that they are using something because when you want to train your data or your uh images here in medical imaging there are two ways to do it because we have images with 512 by 512 i am talking about the width and the height and the number of slices in different difference sometimes you will find 20 sometimes you will find 50 sometimes you will find 500 it differs from it differs from your uh task and your data set okay so in that case we cannot use directly the data because we need to create the same dimensions of each input so that will not get the model confused so when we will fix the width and height for five and five twelve by five twelve and for example slices by 100 so we we need to get all the pacings or all the inputs with this same dimensions for that when you see in monae's tutorials you will find that they are doing some crops so that they can get the same dimensions but that method work for some cases but it doesn't work for others and i tested that method in this lever segmentation it and it doesn't give a good result okay for those i will not use it but i will show you just a little bit explain to you how they are using that and why i will not you use it and how can we prepare our data to to use my my way it is not my way but what i found better than the more nice way so the method used by monae or monitors they take for example this is a passion i am showing you only one slice but imagine with me you have a number of slices here which is a volume which is actually a nifty file so what they do they do they create some crops they create random crops but i am showing you like this so that you will understand but they are doing random crops here for example a crop here or in the crop here which means they create a window with defined width and height and number of slices and they take this crop the the that they used they cropped using that window and they pass it for the training and the same thing they take in but they do they take one crop for one uh one epoch then in the next epoch they take another crop like this and the other one another couple from and they are random crops not as i am showing you here but just to know how does it look so that that's what they are doing in their tutorials they take only small crops and do the training on this crop and describe this crop etc etc for that they use 600 epochs so that they can pass by all almost all the passenger or almost all the slices but i tested this way but it doesn't work well for me for that i want to show you how i will do i will do it in my way which means we will create by ourselves uh this window but what i what we will do we will let the width and the height the same or we can resize the image but we will not crop it like this or so we will not take only small parts from the image but we will take the whole as you can see the whole shape or the whole content of the image maybe yes not maybe but we will resize the images because if we want to apply to pass them 512 by 512 to the model it will take forever to be trained for that we need to resize the images and what we can do maybe we can crop this areas so that we take only the places or only the area that has content of the image but otherwise we not need to take uh small portions as monai are doing so what i would recommend you i recommend you to not i am recommending you or i will show you how how i will do this on my way how to create the small uh passions or the small slices groups of slices and if you like it or if you want to try it out i will show you everything that you do all the scripts that we will use etc etc otherwise if you want to use the moniz tutorial like that so maybe you can follow me just to understand some of the basics and some of the functions that what i provide but in this way you can you want you will not use my idea and you can skip maybe one hour or something like that from this video because i will be explaining everything to do to prepare the data because if you will use this way you don't need to do any preparation maybe there is a process to change the contrast etc but preparation which means cleaning how many slices you have how how many groups you have you don't need to do all that but if you want to follow me so you need to see how i am doing this and after finishing the course you can try this one and maybe you can try more nice tutorial or more nice way in your data maybe the other way will work for you well because it doesn't work for me maybe it works for you okay so let's now let's go to show you what are the preparations we will need and how to do them so the method that i am proposing is to create small groups which means we will leave the same width and height for now before the pay process will leave the same width and height of all the slides of all the passions but we will create a constant number of slices which means if we have for example a passage with 120 slices what we will do for example we will create if we will if we will make a constant number of slices for example like 60 60 slices per group so what does it mean dispassion of 120 of 120 slices we will divide it into two groups so it will be the passion zero for example uh slash one for example this is the first part so it will be with 60 slices and the next part will be with another 60 slices and the same thing for all the passions if we fix the number as 60 slices per group or per input that means that we will pass by all passions and divide them into groups of 60 slices this is the idea that i found because maybe you can if you because i don't know how what is your data that you are using because if for example you have passenger with almost almost the same number of slices for example 100 101 102 or and something like this and all these passions have almost this range of slices in this case you may not need to do what i will do here because you may you can do in the training you can crop your passions and fix the number of slices into 100 slices per input which means if you have a passion with 150 100 slice so this passion will go directly as an input or if you have a passion with 100 one and one slices means that you will crop only one slice and one slice it doesn't affect your uh your data because for example if you crop your data and maybe you you will clear or 10 or 20 slices this maybe you will lose some information of your passion but if you just take off only one slice or two slices it doesn't affect your training or your data i hope that you are understanding what i am saying because if you have only you have almost all this the passion to have almost the same number of slices so in this case you don't need any preparation of this asians but if you have a random data set that has passion with 50 slices another passing with 500 another percent with 300 something like that because all the passing that you will all the data that you will find as public data sets you will find them like that so if you will find out like that you need to follow me to clean them and make them ready for the training so the first thing that you need to do is to convert these nifty files into dcoms so that you can convert or you can create small groups okay to do that for now there is no specific python package to do this because i searched for that i didn't find i i tried to create my own package to do this and you will find it on my github profile here like you will find i mean zero one one zero slash nifty to dcom so that was i tried to create and you will find it here it is useful for some cases but not for this case because there is a problem that i couldn't find how to fix it and if any one of you have a suggestion please you can leave it in the comment or you can just take the code and make it ready for you i will tell you what is the problem with this code and so that you will understand this code will create will take a nifty file and create your decon slices but the problem here is that it will give all the slices or all the decomp slices the same number of index what does it mean if you have a nifty file with 10 for example 10 slices so when you will convert it into deconfile it decompiles it should be each num each slice or each deconfile with with different index so for example the first nifty file will be with the index 0 the second one with the index 1 2 3 until 10 which means if you want to reconstruct or rebuild the nifty file after the python package will understand that this first slice is goes to the first nifty uh to the first item of the nifty the second one is the second cut third etc etc but the code that i i'm providing here will give the same index to all the passions which means not the passing to all the slices so if you convert one nifty file into ten sli nifty into 10 decom slices all these dcom slices will have the index 0 for example yes the first index so in that case you cannot rebuild the nifty file again so in our case we need to rebuild because we need to take groups of d columns and reconvert them into the two nifty files which means it doesn't work for us maybe this type of convergence if you need only to convert into dcom you don't need to or you don't need the indexes in that in that case you can use this but otherwise for our project we cannot use this even if maybe if you find a way how to change the indexes so you can take the code and change the indexes of all the deconfiles otherwise i will show you how you can do it manually without without python code for that this this is the parts that take a lot of time of this work but the others are just coding and everything will i will provide you all the scripts for everything but only this part needs to be done manually and it will take time sorry about that but it will take time for that i am saying if any one of you know how to convert nifty to dcom using python or something like that please provide this in the comments so that anyone who is using doing these projects can use this package as well okay thank you for now now i will show you the second way that you can do it but as i told you it will take time we will use 3d slicer for that when we was installing softwares i told you that we'll use 3d slicer for for some conversions so now it is the time to talk about that i will show you how you can do one or two not i have i i just choose two buttons here so i will show you these two passes how you can convert the images and the labels and you can do this you can see that it is easy but it takes time so you can do it for all the passings that you have so now let's start by before that i want just to create some folders so that we can know where to put our data because i didn't want to make everything with python script because sometimes it is very you can pass 10 minutes writing a script to do something so that you can say that it is automatically but you can create the folder with one in one minute so just click new and create a folder so it will take two or three seconds but if you want to write python script it will take maybe three minutes or more than that so in that case i prefer to do it manually instead of writing a python code to do it okay now let's call it for example dcom decom files maybe because what we will do in this folder we will take these passions and convert each of them into the com slices because nifty is group of dcoms now let's go here this is the decom which creates another folder here one for the images i will call it for example images and then the other one we will call it the if you want to do it directly with the keyboard you can just click ctrl shift and end which is new so we will create a new folder here so this next one we call it labels something like that this this files or these folder names will be changed after because we need them for our specific script but don't worry about that we will come to that later now we have two folders this one images and this one labels now let's do what i was saying to use this software 3d slicer let's start by the images let's take the first one just grab it here drag and drop into your slicer or just you can open it here and now okay open it and it will be opened here as you can see all these the slices you can just scroll down or just do like this so all these are the slices for example this passion has you can just you can read here you can see here it is 74 slices and you can go to other passions you will find maybe 100 slice etc etc so this is the problem you cannot use the same script for all the passengers for that we need to prepare them with the same slices after that we pass them by the to the training phase okay now how to convert them just click here insert and click or type here dcom creates the ad com series so search for create a dcom city so just go here in search dcom creates the comp series so when you click here click two times here you will get this window here the first thing that you need to do is there is nothing uh is hard to do it this is you don't need to change this because creating it becomes serious so you don't need to change that click here on select you need to select the volume or yes the volume or the image that you want to to convert so here you can see that we have volume zero this is the the passing that we are displaying now and this is the passing that we want to convert so you know you need just to choose it here level zero now you need to choose or to change the directory where you want to be to put your conversion now as we were saying we need to go to here to our folder that we have created called nifty files go here youtube yes this one dataset lever and deconfiles and this one is an image not a label or segmentation so we go to the image now we need to create a folder for because if we passed here everything will be here every every slice or all the decon files will be here but we need to to put them into one in one folder which is called with the same name of this button so we need to create a folder here so we can call it lever 0 for example and with the same thing or you if you want to change the name here it doesn't matter now choose now everything is set just click here in apply and you will see that it had the conversion have been completed let's go here and see what's happened here images we have created this and here are all slices as you can see we have 75 from 0 from 1 into 75 so everything everything is set and these are all the slices because here we see that the maximum is 74 because it starts from the index 0 so from 0 to 75 but here it is starting from 1 into 75 okay so there is no problem with that but these are all the slices for this is for the image one for the lever one now let's do it for the second just go here and the second here we have we had image which is level one now level zero now level one open it here and you can see now we have the lever one and for example this one this one have 122 slices which you can see it is not as the first one for that case it was it will pose a big problem when you want to do it or you will lose all the information of your passing if you do some crops for that we need to create groups with the same number of slices now let's select the second one which is what we uploaded now this one level one and here we need to change the path because we had the folder level zero now we need level one something like that and that's it choose and apply this so now we have the two passengers have been the have been converted here let's go images this is the second one now let's do the same thing with the labels let's go here we have label training let's take the first one here and as you can see this is labels with the same number of slices now let's select here you can see because they had the same name level zero level zero so they added this index so that you can know so this is the first this is the first label for for the first passing as well now we will not do it in images now we are in labels so create a new folder call it here lever you need to put it the same because we choose we choose to put the lever zero so we need to put the same thing lever and zero so another so that's the uh when we will do the training etc the the labels with their images will be the same okay now let's choose this one yes here we have the same thing choose and apply and the same thing for the second one which is lever one choose it here change to level then one and choose it apply and now everything is set for this step when we go here the confines you will find images here is for the first one second one and same thing for the labels this is the first one and the second one as well so that's what you need to do at first but for me i am showing you only two passions but you you need to do all the passing sorry it will take time but i didn't find another way to do that okay so as i told you if you have the number of slices sorry i am repeating the word but just to understand if you have if you have the same number of slices for all the passions or almost the same with a minus one or one difference between them so in this case you don't need to do what i am doing here but if you have the public data set as i am saying here as you see you i show you the first if i show you only two passes the first one has 74 the second one have uh 122. so in that case you can see that there is a difference so if we go or if you pass by all the passengers we will see that every passing has each its is unique if we can say unique number of slices which is a problem for that we need to pass by this way now after doing this what we have to do we need to create the groups that i was talking about groups of decom slices which is we can choose any number we want in this case i will choose 64. i don't know why i choose this white but this number maybe i found that the minimum of because i passed by all the passions maybe i found that the person that has less slices was between maybe 64 or 65 for that i choose that number but for you it depends to you and you need to choose the number of slices that you want or that is depending to your data set so you can do the same thing as i did you go by the the passes that you have you see the but the passing that has less number of slices and you take those numbers so that you will not lose that passion because if you take number more than the minimum which means that you will lose that dispassion if you choose for example number of slices unique number slices equal 100 and you have some passion that are having number of slices 60 for example so 60 past ends 60 slices can not be converted into 100 slides so you will lose this passion for that for this case i am telling you to see the person that has the less number of slices and take that number of slices as a reference or a constant number for all the other passions okay now for the next steps which is doing all the conversion creating the groups and reconverts into uh nifty files everything will do it using python so i will show you how you can do it but before talking about or before starting coding i am just telling you that everything is set for now all the code all the scripts all the functions are here in github which i will share with you after you can find everything here the preprocess and everything is here but we will write this code each line by code by ourself but after that i will provide you everything here and i will provide you the notebook jupyter notebook maybe you need you you you would like to use it because in our case we will use jupyter notebook in some cases because it is easier to follow the steps but you will find everything here in github which you will find the link in the description so now let's start creating the groups and converting them into nifties now as i was telling you that you can use jupiter notebook that i i will show you how you can use it i am sure that you know how to use it but maybe did you use it in different way that's what i want to say because you can install it easily in the command window like you go here in cmd you can open this command window just type pip install then jupyter and it will be installed and you can open it uses and there is no problem with that but the problem that you can you may have using this uh jupiter notebook directly here is not probably in the installation but if you want to use a virtual environment in your in your project in that case it is sometimes it is not easy to open or to yes to open jupiter notes book inside a virtual environment or to use gyptonium with virtual environments so the way that i recommend you because i always choose the easiest way and i will show you the easiest way if you like it you can use it otherwise you can use something else but as i told the jupiter notes book if you install it like this there is no problem but when you want to use it with a virtual environment you will have some problems so to make it easy to do this process what you need to do is just to go install anaconda navigator so anaconda navigator is as you can see it is a software that has multiple i will show you multiple software here that you can use and which is the is which is the best thing here that you can create your virtual environments with using conda not a virtual environment with python because there is python vms which is python vertical environment and there is conda virtual environment and when you use anaconda you can create your contact but your environment you can create them using command windows like this here click here contact install and or contact create you and you create your virtual environment exactly with a specific python version and all these things that you want to set but if you are beginner with programming maybe it will be easy to create your virtual environment manually using the gui here anaconda gui so to do that you just come here i will show you first how to down install it which is very easy you can just go here to anaconda dot com slash product slash individual i will leave the the link in the description don't worry about that so when you install your anaconda here and you you download it here and you you follow all the steps as we have installed everything else because i have it already so that i cannot install it reinstall it again but just download it because it is free download this open it and it will and follow the steps and of course you need to choose which operating system for me i am using windows so it is already windows here if you have mac or something else so just you need to click here and search for your operating system now after installing it just open it as here you can when you start it will be something like this now here if you open here this list you will you will see all the uh virtual environment that you have in your pc that you have created in your pc they will be shown here and this is the base when you will create or you will install an account you will find only these two uh vertical environment this is the base which is the base vertical environment of your pc this one mini contact is we can say that it's an example but you will not need it because we will install our virtual environment for our project this is testing i just installed it again but now how to create a virtual environment in anaconda as actually you can do it using the command window here cmd and you can create use the command line and install and create a virtual environment then activate it etc but the easiest way here while we are using the since we are using the gui already you can go here environments and you can see as i show you all the environment that you have here now to create new virtual environments that is here these buttons create a new cloud import backup remove if you want to remove one of these various environments so as we said we want to create one so click on create now choose the name of your virtual environment let's call it for example liver segmentation so this virtual environment will be the virtual environment that we will use in our projects and i will talk about this after but now when you use it check here in python then here you can choose any any python version that has been installed in your pc and just for me i have python 2.7 3.5.6 i have everything here so i will just choose 3.8 you can choose any version you want but i am going to choose 3.8 and i recommend you to do this because sometimes when using mulai if you go with latest versions maybe you will find some problems so three point seven three point eight is enough for this project so i will choose three point i ate then here create and you will see that the vertical will be created in millisecond not millisecond but in a few seconds and now we just have to wait and this is our virtual environment and now here you can see the uh files or the packages or libraries that have been installed already with the virtual environment as you can see we have pip we have python of course sqlite etcetera but we will not use these because we need other packages like numpy money etc but everything we need to install it by ourselves so the installed packages there is multiple ways to do it we can use conta install we can use pip install or we can just can come here we have here when we are checking here only we are seeing only installed packages we if we click here not installed updatable etc or we can click just in all we will get all the python packages that have been that are available in anaconda and search for anything here then click install but i when we are talking about installing packages i don't prefer this way i prefer using pip for that i will not follow this way i will show you how we can use pip to install different packages so now what we need click create a virtual environment now when you are selecting it here means that you are activating because if you have already used virtual environments it can be virtually environmental python virtual environment or a more conda inverting environment when you did it you have always to create it then activate it when you write virtual environments like script slash activate or source virtual slash bin slash activate but when you use the gy here when you select it here means that it is activated you don't need to do something else to activate your virtual environment now as i was saying we really need to use jupiter notebook so here as you can see there is jupyter notebook there is everything vs code there is pycharm there is everything here we can install it we will install this because we need this after but for now what we need is just to use jupyter notebook so you click here even if you didn't install it before in your life don't worry about it it will be installed when you click here it will be installed in your virtual environment which means that you can use it there so now let's create let's click in install and it will install jupyter notebook in this virtual environment now it is installed as you can see and this is the best thing when using anaconda navigator because you don't need to think about how to uh to link the your virtual environment with jupiter notebook or sunday lines you don't need to care about that the only thing that you need to do is select or create a virtual environment selected then come here and now it is already installed so you will not you don't need to install it every time now you installed if only one time in your new virtual environment now click in launch it will be launched and we will say here now there is jupyter notes book is working and now jupyter notebook is open with your or inside your virtual environment so you don't need to think or care about which virtual environment you have or anything else now all what you need to do is to create your folder to check or to make directory where you want to put your your stuff on your project and inside that folder you create a new notebook now for me i selected this so i will work on this repository which is labor segmentation here where we will put everything or all the code not the data data is somewhere else but here we will put only the code now to create a new notebook just come here click on new as you can see there is python 3 that is text file folder terminal but for us we want to create jupyter notebook for python so python 3 ipi ipu sorry iby kernel so ipwa i ipu y means that jupiter notebook and kernel now uh what we will do here we have this is our notebook just you can click here to rename it i will give it for for example prepare because we will use this notebook for now to do the preparation because we were talking now a few few minutes ago we saw we said that we need to convert our images here we had this labels and images they are decode now we need to create groups or yes create groups with the number of slices then reconvert these groups into into nifty files so that's what we will do in this notebook now to do the creation of the groups of 64 slices this was my choice if you want something else you can change it now these are my two parts this is the inputs and this is the output path the output parts we need to talk about it here i have i have because we had this dcom files where we have we had images and labels this is the input path file decon files and we have images and labels we'll start by labels for example then the output part i have created this folder called dcom groups so you need to create a folder you can call it anything you want so that we will take this labels from this that we will convert or because we will not convert actually sorry we will create groups of 64 slices so what will happen now we will create each for each group will create a folder but we will not do it manually all what we need to do is create this group where we will save all the passions all the groups which i call decom groups but we will write the script that will create folder for each group which is 64 slices so that we can after that we can convert this 64 slice into one nifty file but before that what we need to do is to create this decon groups which will be a which will be a folder now there is something else that we need to talk about because we have this decon groups but what we need to do we need to create another folder one for the labels one for the images i am sorry i know that i am doing a lot of things manually but i didn't want to do everything using python scripts because in sometimes you can do something wrong and everything went wrong because imagine with me if you mix only one one person which i mean if you ma you may you put wrong a one label means that everything will go wrong because in segmentation you need to be very precise it is not like any other thing it's not like any other task of computer vision so you need to be precise because if you skip only one slice or only one segmentation everything may be wrong okay for that i am doing much things uh manually so that i i will not make these things wrong there are some stuff that need to be using not need to be done using python scripts but for this i prefer to do it manually now as i told you i need to create a group a folder for labels i add another folder for the images so we just click here as i told you ctrl shift and n for new folder i will call it labels the first one and the second one for the images like this so now here i need to add labels okay so the input path is our labels when we have because for me i am using only two passings as i told you but you for you you have all the passings in your labels because here the confines i have only two passions but for you you have 130 if you use the same dataset or i don't know but you have all the labels that you have here and the output path is what we have created now beacon groups and labels now here where we will save our our groups of decons now to do this just run this one so to run it just click you can click in run or you can click on shift enter shift enter it will run this cell now to do this project we need to install some not projects but i am talking only about this part we will need some packages so the first one is globe so this package globe if you have already used it so you don't need to know what i am saying but if you haven't used before so we need is only to create some parts or to restore all the parts for example here i have this folder which has two passions so the globe function or the globe library will help us to restore the the whole link or the whole part so that we can open this folder and open this folder after you will understand when we will code it okay now i haven't installed it for this project so we need to install it to install in if you are using directly visual code or you are trying to install in a terminal just you need to click to put pip install then the name of the package for us it is glo but for me if you are using jupyter notebook so you need to add this mark okay because if you don't add it it will not work in jupyter notebook now if i will run this cell it will install there is something wrong could sometimes you can get something wrong we need to see about this why it is not installing now after that i checked because i don't know why i didn't notice that but when you want to install globe sorry about that but we need to check everything every time because i have installed this a long time ago for that i don't remember i didn't remember that i need to add this number two with the globe but that's that's what we need to do because this type of uh errors means there it is true that they are saying no matching distribution found for globe but what they are saying that there is nothing because they don't write that but there is there is no something like this library because the same thing if i i can put pip install i don't know one two three it will say it will give the same error it will not say that there is nothing called one two three but it will say that we couldn't find something matching with this version but that means that you are putting the name of the package wrong so you need to just choose because sometimes you can see the globe when you import it you just put import globe but when you install it there is something else all not all the packages but a lot of packages have this no problem but you need to see exactly what is the name that you need to use when you want to install for example pillow when you install it you click pip install pillow but when you import it you click just pip install pil so for that this is the same thing just click here pip install globe 2 then run it and now as you can see it is installed now there is no problem now the second package that we need to install is chantel shuttered sorry not chanted but because we need this package to move the files because what we will do we will move some lot some but we move 64 past 64 slices to a new folder which is a group of 64 slices because i didn't want to just copy them because we will lose a lot of memory doing this copy and paste but i will move them so i will take them from the old directory and post them and put them into the new directory so for that we will use we need this library so pip install shuttle i hope that you need to use the same name maybe there is something else but we will see as you can see the same thing here so what we need to do is just to search for it how to install shuttle something like this and as you can see when you import it you use shuttle but when you want to install it there is by test shuttle so you cannot just install it as i was doing so just take the name and put it here pip install test shuttle now let's see how does it work it will take a few seconds and now everything is good so i will just delete this so to delete them just click on the cell and click two times on d to delete and the same thing for this because i we have already installed them so we don't need them there now we need to import them so import globe and import shut d like this but but what you need to do to know is in globe function this is the name of the package which is globe but the function that we need has the same name which is globe so for that when we want to use the globe we cannot just make glo use globe and deer function we need to import another function or another class called globe from globe that we will use i know that it is strange but that's it this is the package they created like this so we need to write from globe import globe because the same class are the same in the same package so that's what we need because if you take just globe you cannot access to the packages or to the functions that we will need so just run this now there is no problem with that now let's start coding or let's start creating the groups for that the first thing that we have to do is to create a good not a good but a big for loop because that for loop is the most thing that because what we are saying we are we want to pass by all the passions because we can't do it for only one person but we need to run the code each time for 130 passes which is not good so we need to create a loop that passes by all the passions so for that we need to create just four and now passion which is a lever for for me i have two only two passes but for you you have everything but you don't need to care about that just for passing and we will use the path because you remember in the part here we have labels after that we'll use the images so in labels there are all the uh all the decon files that you have converted for now so what we have to do for passions in then here what we are saying in this folder but if we do this we will not have the because this in in part will be only one part but what we have to do we need a list of parts okay list of parts each part or each item of this list give us the part to one passion okay for that we need to use the globe this is the use of globe function so we have globe and when we put a part inside this parenthesis of the globe function what it will do it will return a list of all the items that it has in there in the directory not the list like os.list because here we are talking about lists of the parts not only the items so this is the role of globe function so what we have to do is in path input path but when you want to do this you need to specify which extension or which type of folders you want to put in this list so for that we need to add something like because always we have something or the name of the file that's the extension for example and i for the nifty but for us we don't have nifties but we have folders okay for that we don't need to specify the extension just put everything okay but this is something like this so what we are saying that in this input part slash everything if we want to say uh we want to specify the extension so we have to put everything that some that's the nifty for example this what does it mean everything which is we don't care about the names all the names or all the files that have the extension and ii take them but for us we said that we have folders so we need to take everything inside this folder so for passing globe in star means that everything inside that folder so this will return a list of folders now what we have to do is to start doing the conversion the first thing that i want to do is to return the patient's name so that we will use it after to save or to create a new folder for for each group of items because what we have what we will have for example we have a passion with 128 slices so this passage will be divided into two groups the first group is 64. the second one is 64. so what we have to do we want to keep the same name of passing for example pass into one in our case we have lever zero lever one so we will keep the same name level zero but we need to add a underscore for example than one and two three etc which is the sub groups so you have the passion zero sl underscore one lever then passion one underscore two that pass into i don't know passing two underscore one etcetera etcetera etcetera so you will know always that this group of 64 belongs to this to the passions one or passing two etc but it is a subgroup of that passion okay i know that i am talking a lot but i am just trying to explain everything here so as i told you i need to return the name of that passages before that we have to add a another library that we'll use so import os and you should know that in each time you add something in that cell you need to run it again because if we don't run it this os will not be imported okay so now after that we did this what we have to do we have to return the passion's name so i will call it for example passion's name so as we said this loop will take the first passion will return its name to return its name that is a function in the os library so os dot path dot base name okay this one will return the base name which is the name of uh of our passions which when we say this base name means that we have all this part this is the base name the last item of the path is the base name and that's what we need because now we have label so this globe will do slash than the first passion so when we return the first uh i will show you something let me just click here below now let me do for example past scenes list equal glow then in path plus this so this as we said this is the uh this list of passions will have for us we have only two persons so now if i will i want to print for example print the first item of the list which should be the path to the first passion so we have passing list then as we said the first item of the list so zero the index zero now you can see that we will have the input path here plus the lever which is the first passion so that's what i was saying if i will put here one it will give us the lever one which is the second passing etc etc now we don't need this so i will delete it now i understand what will be this passing in the first iteration i i forget here in so you know that now in the first iteration we will have the first passing which is the part of the passing so labor slash level zero so what we will do we return that level zero the only the name which will be a string we will use it after for that what we have to do now inside the parenthesis we need to know to normalize our path in case we have any problem or something like this so os dot path dot norm path which is normalizing the path and put here the name of the passing which is this one or not the name but the parts of the passions so this function will normalize the path if and there is anything wrong with that then this function will return the name or the last item of the path which will be the name of the passage and it will be here we will need it after to create a folder and to save the groups in our case now after doing this what we have to do we need to specify or to know how many folders we have or how many groups we will divide our passions so if we have for percent with 160 28 for example slice it will be divided into two so we need to create two folders each folder for us for number of four the first 64 and second one same thing if we have more than that we have to create more than that more folders etc etc so before we need to to know how many folders we need for this for this first passage for example so to do this we have just create number of folders folders then what we need to do is to ins because why i am putting is because we need an integral number because if you have for example 130 you divide it by 64. it will be a float number but we cannot create a fluid float number of folders we need to an integral so we need to put everything inside the function int so that it will convert the final division into a in into an integer okay now what we have to do we have the because what we need to do we have a globe of the passing that we have which is this one this one is the globe of the passion this will return how many passions we have but now we need to know how many slices we have in that specific passion so we need to create another globe which will be something like this globe but now we are not talking about the in the in part which is the input path now we are talking about the patch of that specific persians so globe of passions plus uh slash as slash forward slash then star which means everything we can here specify everything that's decom but we don't need to do that because we know that we don't have jpeg images or something like that in our folders so everything inside the part of the of the passing which are or everything is dcom so the globe will return a list of all that it will return a list of all that passions not passive but slices decom slices now what we have to do we need to know how many uh which will be sparked but we know we need to we need to know how many percent we have how many slices we have to do that we need to to calculate the length of this uh of this list because as i said globe will return a list of parts of each slice now we need to take this one here and calculate the length of this list which will be list of but i will just control x so land the same thing here so we calculate the land so let's what will be the land for example if we have 100 slices we will have 100 100 parts which will be a list of 100 item now this is the length which will return it will return 100 because as we said we have 100 now we need to divide it by the number of slices that we want to create which is 64 in our case so divided by 64 here so when we divide by 64 means that we will know how many folders we want for us we are putting here integers okay this 64 we can leave it 64.65 we can leave it 64 or we can create a variable for example that takes the number 64. then we use it but we don't care about that we will put it 64 but because as i told you i will give you the code at the end of this course and everything will be clean and all these for loops etc will be inside functions but you can you can just call them and i will show you how you can clone the github repository etc but at the end for now i am just explaining how does it look how does it work in case you have problems in case something differs from your project to my project in that case you can know how to fix these problems okay otherwise you can just use the final part of this course using github cloud repository and no problem with that now as i was saying this number of folders we needed to know how many folders we need to create so or how and not all and and i am saying and in how many groups we need to divide our passions now after having this number of slices what we need to do we need to move the slices from the specific folder which is here for example here we have all the slices what we need to do we need to take 64 from them and move them into a folder that we will create which will be a subfolder or subpassion of lever zero so now let's start doing that loop so it will be a for loop that range does go goes from how many folders at first because what we need to do we need to create the folder first and move the uh passing or the slices from the from each person into that folder that we have created so what we need to do we have to create at first they pass the folder where we want to to put the slices for that what we have to do we have four e in range for example now we said that we need to know how many paths how many folders we need to create so we have number of folders so we will pass by the number of folders we if we have four if this value equal to four which is the number of folders will be four so we this for loop will pass four times if we create the folder then we will write the part where we will move the slices into that folder but now we have to go step by step now we have to do that after doing this we need to create a directory but before that we need to specify what what is the final or the part of the output which means how where we want and how do we call the folder of our outputs of our of our group so what we will do here we need to give a name for example output but for example or output path name something like this what we have to do we need just to we will reconstruct it because we have the output part which is this one this one is the final output part where we want to put everything but we don't need to put just here we need to create another subfolder which will have the same name of the passing which is this one plus a underscore and the sub folder which will be the i the i here so it will be 0 1 2 3 etc so to do it is just to put here os dot path dot join this function always that part that join is something that just to join two folder two parts for example i have path one slash part two comma sorry if i have this so this from this function always that part that's joined what it will do it will do just part one slash but two that's what it will do this uh function so we don't need to worry about it so for us what we have we have the final output there which is out there outputs this one which have we have i have i am putting here then this is the main output of the labels then we need to put the name of the passion which will be here passion name then we need to add the underscore plus the sub folder which is here plus it is a string so we don't need to think about it you can we can put just plus here and it will add it to the part so plus and we said we have underscore then the name of uh not the name but the index of that subfolder so which will be the i here but now i is a antigua we need to convert it into string to do it is just to call the function str and i so what does it mean this it will create something we just i will run it to show you how does it look i have here print out put but name you will see what does it look this one just run it it will create this part which which doesn't exist for now for now we have this part which exists which is this is the output here output part but now we added this lever zero this is the name of the first passion and this is the underscore zero and now here it should be underscore one but for our case if we have a number of passes so i want just to say see something i think there is something wrong here because we should have zero and one not zero one here because we didn't go to the next one otherwise even maybe the i would just ah i know why because here we have for this first passing we have 76 uh slices okay so the first passion we will create the first because when we divide this by 64 it will give us one one comma something in that case we cannot create one comma something folders we create an antigen folder it should be one folder so we will we will take 64 first passing but the other 10 we don't need them and in this case you don't worry about the 10 slices is not a problem okay so this is why we have only one one passing one subfolder and same thing for the second one here we have 123 so in this in this case for example it will take the first 64 slices but the others it will not take them okay but don't worry about this there is no problem i am taking 64 because there is other passing that are having less than that we can put a number less than this for example we can put 50 or something but i don't think that it is a good idea because we lose some information for us in average in my case i took this number of slices because here if i will take for example 50 so in the first passing i will lose more than more than when i was 64 because if i will use 50 so i will lose 25 slices here so and the more we go with small number of slices more than the training will be will be slow and it will be it won't be accurate because we will put only number of slices like 30 or 40 it will not be something very accurate so the more slices we put the more better we have because in my project in another project where i was doing tumor segmentation i was using a groups of 128 slices because i had passage with much number of slices for that i could use 128 slices and it was very good number i tried more than that and less than that but it was 128 the best one if we if i put more than that it can be good accurate but it will take time talking about the training time the training because when we launch the training you will see that it will take time so more the more the number of slices you take more than the epoch will take time in each each time okay so for that i don't recommend you to take a very large number and not very low number in some cases you will lose some slices but it is okay don't worry about that so for that i am using 64 here now you see what will happen about this name just what we need to do that what this function will do just to create this name now what we have to do because as i told you this part doesn't exist so we need to make it exist so we need to create a folder with this part so that we can save our slices in this part so to do this just use the os library so os that's amca the which is make directory and here what we need to do of course the output parts name so this os library will make directory for this output part name so we will have these two folders created for me i have only two but imagine with me you have 131 or 30 baskets or more than that so this function or this loop will create folders for each group of bastions don't worry about this now after doing this what i have to do is now after making or after creating the the folder we need to move the images into that folder so to do this it is easy just we have four now we have we this because this first loop will pass by all the passions and this one will pass by all the groups or all the sub folders now we will pass by all the the files or all the slices that we have in each passion so what we have to do is just we have e because what we need to do we need to know where or when the file is when we are more because i'm saying that if we have something like we need to know in which index we are we are so that we can stop the loop when we pass the 64 uh slices so here we have four e because i tell how to use i will need it then i need to refer to the file because this e is the only the index but now i'm going to talk about the file which is the confirm so for e and file of course in because when we use only one variable here we use the range but now we are using two which i am talking about two the first one will take the index and the second one will take the five so we need to use the enumerate enumerate rate function and now here what we have to put that we have only the name of the passions with the part but before doing this we need to know always the path the passion sorry but when we we have a uh a we if i will put only the passings it will be just the folder but what we need to do we have to return all we have to return the list of the passings the same thing that we did just here we have the globe and because this one will globe and passing plus this star it will return all the passions or all the slices that we have in the group or in this folder or passions so i just need to copy this put it here so what we are saying now four e and five in enumerate so this file will have the the the part of each d com slice of the first pass hint for example in the first iteration so what we need to do we need to take it return it and then after that we need to move it into the new folder or to the folder that we have created so what we have to do now after taking the iteration from the group we need to move it so to move this file we have to use as i told you the function sharp till like this so shots will have a function called move this move function will move the file to the uh directory that we want which is now here we have the file and the directory or the output file will be here the output the folder folder that we have created the output part name so what i am saying here we have created the file now we will pass by all the files or all the decon files of that specific passing and move them into that into that folder which is the output name for name but there is nothing here that stops the loop we need something that stops the loop so how to stop it we need to know where we this the iterations of the loop are in the same uh number of slices that we specified which is 64. but we need to do it before moving because if we are already passing the 64 slices we don't need to move other by other slices so just here put but now we need to put here if we said that the i here is the index of the slices which is the iterations so if i equal to the number of slices which is in our case 64 plus one which is when we pass it by one we need to stop the loop which is using the break function so when we call the break it will stop this loop which means we will not move more slices and it will go back here and go to the next iteration to move the new uh so it will go to new iteration it will create a new subfolder and move the next 64 slices to the next to that new subfolder etcetera etcetera until finishing all the subfolders and go moves to the next passions etc etc now let's try this and see how what does it do so just put here and you can see that now it is done let's see our folders as we said here we have liver and we have decon files labels and you can see that it has created the lever zero we said that we couldn't create lever one because there is not enough number of slices to create it so we have zero and if we go we have 64 65 number 65 slices okay i think that i miss one so i maybe we can just leave that this one i can just leave it on but not a problem 64 or 65 not a problem but you can see here that we have created groups of 65 slices for this one and for this one and everything and if you have more than that i am i am using for example only two two buttons to show you but if you have more than that you will see that it will create number of folders or subfolders of each passion so if you have a spacing with 600 slices so it will create i don't know 10 10 or less maybe eight eight or seven subfolders each subfolder contain 65 number of slices and of course if you want to change this number of slices just change this number which is 64 here just changes i i didn't make a variable for that because i told you that i am just showing you but at the end of the course you will get a full function that has at the inputs the input path output part the number of slices and it will do everything so that was how to create the the decom groups now the next step is to convert these decom groups and of course i forget to to say that now what we have we did for the labels now we we need to do it for the images so what you need to do just to change here instead of labels you put images and the same thing here images and if i will rerun it this again this we don't need to run but otherwise now if i will run this again it will do the same thing but for the images now we have the labels if i will go to the images you can see that it has created folders with 65 slices so that's what all you need to do create put here labels and after that you need to put images and it will do for all your passions after doing all this now we will go to the next step as i was saying to convert this nifty group to 65 i just need to change this because i made this wrong so i need 2.65 now we have 60 groups of 65 slices we need to convert them into nifty files so that's what we will do in the next step now let's talk about how to convert the deconfiles that we have created which are 65 slices into one nifty file which we will use uh for the training etc etc so to do that there is only one function and you can do it in one line i am talking about only one file nifty file we can do it in one line and which we have multiple files we can create a loop to do that let's do it step by step with you i didn't want to write it and start talking about it i prefer to write these lines of code with you so that you understand understand each line what what what we are doing with each line of code and of course at the end i will provide the final code only in the training part it will be a very big loop for that i need to write it before start explaining but all these problems preprocessing parts i will explain them like this and i will write the code with you and if i will make some mistakes you will see it live with me so that you will not do these mistakes okay so to do this conversion that we will need a package called dcom to nifty so this library the continuity will do all the work so if you don't already have it installed on your pc we need you can install it using pip install here since we are using jupyter notebook so we need to add this and pip install and then rewrite the name of the library or or of the package for us i said that it is dcom to nifty something like this so when you do it we will run this cell if you want to run the cell here just click on shift enter and it will be run and we'll wait a little bit when you see this star here means that this cell is running we'll wait until this is the only problem with jupiter notebook you cannot see all the execution lines or what is happening you can just see the final output here and as you can see we have successfully installed nifty to decal so after installing it i will just delete this by clicking on the cell and click two times on the two times and it will delete the cell now let's import it here what we have to do just we click import dcom to nifty and we will run the cell because we need to we will need these two libraries os or basic operating system just to create the paths and this d com file or yes and this d com just we needed to do the conversion so the thing that you need to know is when we will use this library we need only one function called dcom series to nifty that there is another function but i don't recommend you to use it because it will not give you the access to to make it or to rename your files which mean if you have only one nifty file that you want to create you can use that function and in that case i don't remember the name of this function but i think it is the com the community but i think it will convert repository but uh i i don't recommend you to use it because as i told you if you have only one passive it is okay but if you have multiple passions you will not have the access to change the name or to specify the name of each passion so in this in this case if you have ten passions it will use the same name for all the passions in that case you will see only the final passings for that case you need to use the decom series to nifty so this function will has two parameters the first one is the part of the folder where you have your nifties and the second parameter is the part where you have when you want to save your nifties plus of course the name of your file now let's talk about our data here we have code the control nifties i don't remember what i put it is here level then the confines and when we did the confines we created the dcom groups we have the images and the labels here so the images and as i showed you i am using only two passions because i don't want to waste time running all these codes because i have already created and prepared all the data so i am using only two so that you can see but don't worry about that because the loops that i am creating will pass by all the passing so if you have two it will cover two if you have ten it will contain ten if you have 100 it will convert 100 so don't worry about that so as i told you we have two parts we need to convert for the images and for for the labels to do it what we have to do is just to take the part here so this part is the common part which that is the images and there is labels we will need it let's write it just here so i will write for example in path something like this and let's just save it and i recommend you to use the forward slashes because sometimes the backward slash make problems not for example here but if you have slash r or slash t or slash n it will make a problem so i recommend you to use these slashes forward slash so now this path is the part where there is the images and the labels now let's start by converting the images and you can see that in the folder of images there is two folders this folder contains 65 slices and second one as well now what we have to do what we will start by the images for example let's put here to make it easy we can just use the os but to make it easy here let's make images so this part is for the images let's make here images the same thing for for the labels something like this and the folder called i don't know label labels with s something like this so now we have the the parts of the input images and the inputs labels and you remember that in each part of these there is or there are uh all the uh all the passions or which are all the folders that having group of slices of each passion as like this here now what we need to do we need to return a list that has part of this file or this folder and part of this folder etc etc so if you remember we used this type of uh of groups of or of make of returning all the group of all the files or all the folders from each from a specific folder using this kind of functions because we said that globe when we put globe and we put a path inside that globe function and we add this forward slash then star means that this globe function will return a list of parts of all the files inside that folder so for us for example we have this part of images so the globe function of this part will return to will return a list of two files or two items the first item is the folder of this file and the second item would be a folder of this file like this so that's what we'll do so to make it easy what we can do we can just add the globe here but before that we need to add the forward slash star means that everything that uh that is in that folder which is images and here the same thing everything in the labels now we as i told you i need to return because here now we are writing the paths and the parts so the preferably we will not write it at the same line but you get it you can write everything in one line but i don't want to do it so that's just maybe some of you are not familiar with python so preferably i will write everything in each each thing in specific lines so that you understand how did we go from from the step to the next step etc etc okay so here we can create a new variable called list of images something like this and as i told you we could do it in the first line but i just want you to see how we will use this part to create the list and how we would use the list to create the nifty files now here as i told you we have globe and in the globe function what we will do we put only the parts for example now in images so this one here if i will run this code if i will put here list images if i will run this one as you can see as i told you we have two parts the first one is for the first passion and the second one is for the second and here we have images and the same thing for the for the labels if we create lists labels labels then here we have globe and in path i don't know what i can type labels okay now if we do the same thing here i will just put labels and now as you can see the same thing we have first passing second passing but here we have labels now these two lists contains the folders of each uh of the passing of each for the images and for the labels now after doing this we need i will delete this now what we need to do is just to convert each folder so the function i will just write write it here the function is d com to nifty as i told you the same name of the library now what we have to do is just to write the name of the function that we will use and as i told you the function is d com to the d com series to nifty so when we are we are using a library we want to call it to call a function you can just write decode then series then 2 then nifty very easy dcom series to nifty very easy function if you are using visual studio code maybe the the editor will suggest it for you but as you can see it is easy the com series to nifty this is the name of the function if it doesn't exist you will got an error but just try to search for it but this is the name the comp series to nifty as i told you there is two parameters or there are two parameters the first parameter is is when we put the input folder the folder that contains all the nifty files and the second parameter will contain the path where you want to save your nifty file and where and what is the name of your output which is 95 so the first thing as we said is the input part here we have this list which contains two parts and these two parts are the input parts that we need so if we take for example list images and we put something like zero means that we are talking about the first part if we want to take talk about the second one we will put one if you have 100 you put 100 or 99 because it starts from zero so 99 means the final or the last uh passing that you have in your 500 passengers so that means that this indexes will change the passing that we want to convert and in our case we said that we have i have two but i will not just just put zero and then put one because it is not general for us i want to write a generic code for everyone if you have two three four five any number of passings you have it will work for you i am talking about the code for that we need to pass this this function because this function will do everything all what we need to do is to create a loop that will pass by all the passions so for that case what i will do i will just write here for passions for example in then we said that in what in all the files that we have or all the passing that we have and the passion that we have we have we have the same thing for me i have two but we have two folders we have images and labels let's start by images then we will go to labels so the parts that we have are here list images this first one this first list contain the parts of the images then here we will put the same thing with the columns and just make space now this function this for loop will pass by my two passions for you you have more than that so it will do it for you now before doing that we need to create the output files or the output parts okay to do it what we need to do we can just do it manually or you can write a code i prefer doing my doing it manually because you so that you will know where you are where you are saving your uh your files so for me i will start by creating a new folder here i will give it the name for example nifty files so now we will have the nifty exact final nifty files in this in this folder now let's go and create two folders one for the images and one for the label so let's start by images and the next one is for labels okay now we have i will take just this part then we will add images and labels we can we can write it here so out path images something like this and now let's do the thing i know that i am writing everything here like maybe we don't need to write everything here we can make a script that does that create the folder and does everything but as i told you maybe some of you are not familiar with python so i prefer to use this so you will understand what why i am doing this and maybe you maybe if you are trying your this code because that happens to me when you are trying to use a code of someone else and you will get an error in your code and you will not understand where this error comes from because you you it is it wasn't you who write the code and you don't know where what are the steps and how can you fix your error etc etc for that case i am trying to write it with you so if you use it it doesn't work for yours for your task you will know how to change something how to change the folders or how to change the files etc etc for that i am taking time for that but sorry about this because i didn't like the old the old way which is just writing the code and give it to you because i don't prefer it okay now as i said we have images and the same thing for the labels i will just copy this and paste it here we have labels and the same thing here labels okay now after doing this what we have to do just to i will just rerun this because we need to save these files in the system now as i told you we have to pass by all the passions but before doing this as i told you here we have two parts or two parameters the first one will take the inputs folder the second one will take the output folder so for the input folder as we said we have parts that are in this list so here we have passions so because in each iteration this variable passions will take one part from the list so if you have one it will be of the only one if you have two it will turn two times the first part then the second part if you have ten parts or ten passions it will run t ten times etc etc for that case the first thing here we will put only the part of this uh passion then the next parameter or yeah next parameter on that argument will take the output path plus the name of your passion so the output part here because we are taking talking about the images so the output part here is the image so we can use something like os.pat dot join why i am using this so that we can join the output part plus the name of your passions so in this case the output part here for the images is out but then images this is the output part of the images then the name of your passions we will we need to return it we can just make uh the i here from the index and make passion 0 1 2 3 etc but maybe in some time because here there is something we need to talk about here for example not liver in the groups imagine with me you have maybe 10 or 100 passions and for example for the first person you have two groups so you have level 0 0 level 0 1 level 0 2 3 etc so something like this and at the end you want to know which path is exact because you have created maybe three or four groups but all of these groups belongs to the same passions so maybe at the end you want to know which person had that problem and i will not say maybe because you need it you should know because when you want to say that this passing for example if you are doing tumor segmentation you will you need to know which person has tumor so because if you just create groups and rename them you will not know at the end which pass it has tumor for that when you create these groups you need to know at the end which uh which passions for that you need to save the name of the passion plus the index for that case here when we will do the conversion we will not change the name we'll just extract as we did here you remember you remember here not this one remember this line what we did here just we returned the name of the pass hand and we'll do the same thing we'll return the name of the passage and use it in the saving here so i will just copy this and paste it in my for loop and now i have the password is the same because we are using the same this is very good thing when you do unique stuff so you in each if you will write 200 lines of code you will remember the name of variables because if you put multiple and or random names of variables you will get problems at the end of your uh coding because in some in some case maybe we are coding now after one month you want to read your code you will not understand what this variable is doing because all of us had that problem that calling your variables a equal and it will work but as i told you after one month if you will read your code you will not understand why did you put that for that i am putting in images in past images output images labels etc etcetera so now here we have the outward spots we need to join it with the name of the passion which is here passion's name and that's it passion's name but there is something else passing's name will be only the name of the folder which will be lever here for example lever 00 underscore 0 not that sorry so but we need the extension because this is the name of the passions so if we have images we need to put dots jpeg that's png that's steve etc and for our case we need to put the uh the extension of our of our files which are nifties for that case we need to add the extension which is a string of course so that's nii if you put just that and i i it will create a nifty file but it will not be compressed if you need to compress you need you need to compress it after but you can just add dot z if you do it like this it will convert the d columns into nifties and compress them at the same time so if you don't need the compressed files you can't put just that's an ii but if you need them converted so you need to put that g z something like this so now this loop it will convert all the passions or all the images or the passions but the images or their volumes then we will do the same thing for the labels so just let's run this and you can see that we have star here saying that this cell is running so it will not take a lot of time so don't worry about that let's just wait so that's it now let's go to our nifty files images and these are our two files that we have created let's try to open one of them we have 3d slices there just to make sure that the files that we have created are good let's try it it will open in any second now so let's take for example the first one drag it here and you can see that we have only the maximum here is 64 which is which starts from 0 into 64 which are 65 slices so these are the slices that we have created and this is the good point because you will have unique number of slices for all the passions so in this case in the training you will not have any problem with your data so now we are making sure that the function is great correct everything is good let's do the same thing for the labels here just change the name into labels and the same thing for the bot let's go here labels and rerun it again and it will convert the labels or to create labels you see that sometimes it take few times when i say a few times few seconds i am saying not few minutes or something like this because it is converting then compressing the file for that it take few maybe 10 to 15 seconds but it is working now these are two other files of uh of of these are the labels the file of the labels and these are for the images and as i told you don't worry about the number because here this for loop it will pass by all your passions so if you have 10 it will convert 10 if you have more it will convert more if you have less it will convert less so that was how to convert the comp files in the next step we'll talk about because all these things that i am talking about are when you have data already segmented or already already labeled but maybe let's suppose that you have passions but you don't have your labels so for that case i will show you how you can do the segmentation by yourself using etk snap now let me show you how you can segment your data if you segment or label your data so if you don't have segmentations because if you have already downloaded data from the net in this case you will find that the labels but maybe as we were saying at the beginning of the course maybe the data that you will download doesn't have the same number the same extension so in this game i don't know or maybe they are using another task for example they are doing uh liver tumor segmentation but you won't use that data for only liver segmentation not the tumor level segmentation for that case maybe you need to correct or to re label your data so for this purpose i am showing you how you can do it yourself for that i am using etk snap that i showed you how you can download it and install it now let's start by i will just make this window bigger i will take this here now let's go to deliver i am not a doctor but i am sure that this is delivered okay so now let's do some segmentation i will show you how you can segment some slices but you will get the point because you can do the same thing with 3d slicer but i found that to these slices is a little bit complicated in term of segmentation but etk snap is the easiest software ever to do this kind of stuff it is old but it is very easy for us i i prefer to use it for segmentation for example i will show you how you can create a new segmentation and i will show you how can you can correct the segmentation even for so if you have already some segmentation and you know you need to just modify it or collect it not to redo it again so i will show you how you can do it let's create one save it and load it to change it after now to do the segmentation you just need to go here you have clear label we'll use it after try to choose one label so for us we have only one thing or one organ that we want to segment which is the liver so we used label one if you have multiple organs that you want to create so you start by for example label one means that you will do or you will segment the first organ then if you want to segment the second organ you choose the label two so it will know it will give two different values to each label and two different colors etc but for us we are segmenting only one organ which is the liver so let's choose the first one which will be in red now let's choose our brush so click on this one here paint brush like this and you choose the shape the shape it can be square or circle something like this or something generally here i prefer to use this and this thing here just bar here just to control the size of your brush something like this and you can use these for sometimes i used i used to use this 3d check box here but what does it mean because i will show you with the 3d and without the 3d when you do without the 3d if you segment this slice means that you have segmented only the slice if you go to the next one you will not you you will not see any segmentation but using the treaty it will segment two or three slices at the same time depending to if the slices are similar or not i don't prefer to use the 3d while doing the segmentation but i use it most most of the time i use it when i want to correct my segmentation in that case i prefer to use the 3d or to delete the segmentation so that it will be fast but when doing the segmentation or doing the labels i prefer to use the 2d normal 2d i segment each slice by itself so let's show you how to do it for one slice and you will get the point for all the slices now just select as i showed you here the shape and everything is good first label the shape here and the the size of that brush here and let's start just clicking and labeling like this as you are painting i am not a good painter but let's try to do it try to make your segmentations as tight as possible and try to cover only the lever so that's the code will not get confused with the other organs because you see that it is in grey scale and everything is similar so if you don't segment very well the mother will start segmenting everything in the body well not too bad it is too bad actually but we correct it let's make it bigger here so that it will be fast oof we did this now let's go to the next slice to do to go to next let's just scroll something like this and you see that for this first slice is segmented the next one is not segmented so you do the same thing here like this i will just do it to have time because it will take time if i will start painting so the same thing for the other ones just like this and do not don't do the same thing that i am doing because i'm just showing you but all these things need to be corrected that i wish i will show you how to correct that but as you can see don't do it that's it's the same thing for all the slices okay so now let's save one segmentation and we will reload it to do the correction for example this part or something so that you will understand how to correct your segmentation now to segment to save it go here in segmentations and save segmentation image and that's it just give the name and it will be saved at the same part where you have your images otherwise if you want to change change the path just clicking browse and change the path let me give it the name for example test segmentation something like this and it will be saved with the same part of my image which is this one now let's just close all these images without saving we we just closed everything now let's just let's try to reload our uh segmentation that we have created now this is the segmentation that we have saved drag and drop here but here when you do it just click on load as segmentation otherwise you can go to in segmentation open segmentation and choose the path but if you have already the folder just drag it drag it and drop it here and click in load as segmentation okay and it will be opened put this one here i'm going in wrong side so these are the slices that we have segmented now let's i will show you how you can correct these segmentations for example let's try this one let's collect this part here and you will get the point and you will see that it is very easy remember when we want we wanted to segment this part we we clicked on segmentation or label one if we want to segment something else we click on label 2 and it will get in the green color and it will segments another organ now we want to clear the segmentation of we need to delete or edit segmentation for that case we click on clear segmentation that's easy click in the brush check the size and check the shape and the size for example and now if i will go here click you can see that it is deleting the segmentation like this it is clearing and if i will do this this we do the same thing so now you get the point how to do the segmentation how to clear the segmentation and how to save it now when doing this if i want to save it again i will just click here save you can just click here in save with the same name if you want to save another file so because here if you click here it will pass this plus this new segmentation in the last one so we will lose the first segmentation but if you want to save it as a new segmentation just click in save as and that's it so that was how to do this segmentation now you have you get the point if you don't have already the segmentations with your data you can do the labeling using this etk snap software after doing this you can pass by the way that we talked about before which is converting into groups and after that converting into nifties because we so i told you why we needed to do this because if your data is ha has the same number of slices for all the passions or something similar like 100 110 120 90 something like this maybe you don't need even to do this type of conversion because 100 or 90 or 110 is nothing you can just resize them and put them at the same at the minimum which is 9 90 slices and put all your passions at that's 90 slices but if you have passions with ones or with 90 others with 200 so if you do resize you will lose more than 100 slice for some passions for this case i recommend you to create the groups of specific number of slices as we did before 65 and it's up to you you can choose any number of slices you want so that was for this in the next part we will start doing the preprocessing because this part is the preparation of the data you see that we are just preparing the data in the next part we start doing the preprocess which will be before the training we do the preprocess after that we will do the training so let's see let's do the next parts in the next few minutes so before going to the preprocess there is something that i forgot to talk about which is the images or the groups that we have created there is something here i will go here data set label then the nifty files these so for example this is for the images that we have created and this is for the labels so there is something in some cases when you for example you have a passage with 600 slices or this is not strange because you will find dataset does have pass into its 600 800 and more than that so don't don't be confused about that but this is not the point what i am saying or trying to say is maybe in this 600 slices only 100 or 200 slices that are useful or maybe if you have passing with 300 slices only 100 or 150 slices are useful the others are not useful so when you create groups of 65 slices you will find some sub passions which are groups that we have created for example this one contain nothing which means that the labels are empty which means that part of the body that you subtracted doesn't have anything which means all labels are empty for that case these type of groups or these type of subpassions will cause a problem with the accuracy of your problem of your program or of your your mother sorry for that case preferably you need to take or to delete these parts because they are useful because in your 65 passions you will have indeed you will have some empty slices but if you calculate the difference between the empty slices and four slices you will find something like the same or that is not a big difference but when you take a sub subpassing which will be one input so it will be one input without any label so imagine with me that you are doing a program of classification between cat and dog and you put with your data you put images of rabbits or something like this in the training so the program will be confused we will say that this image of rabbits is not useful i will not use it you need it for the classification so why you are putting it in the inputs so i hope that you get the point for that case when you create and this is something good when you create small groups for this case you will delete all the parts of the parts that you don't need so for that case when you create the groups you need to find or to specify which are the slices that are empty or the groups or subpassing that are empty so that you can delete them for that i wrote a script for you it contains only two or three lines of code so don't worry about it which is useful just to show you which are the uh the the files or the passings that doesn't have any label or any segmentation for the 65 slices so to do it we will do it step by step just we need to import one library i don't remember if i think we have already installed niba bell let's try to import it and see there is no problem so we need this if you don't have it just write beep something like this pip install knee bubble and run it for me it is already installed so recommend already satisfied i will delete it so after importing it rerun this cell so this file is this library will be imported now let's use it so this new bubble is a function just to handle the nifty files because what we will do we will load each file which is a nifty file then we will see the values of the pixels if there is values between zero uh if there is values of zero one two and something like this more than only one value means that this uh subpassions contains labels indeed it contains this the zero values for the background and the one for the foreground and if you have multiple objects you have you will have two three extra etc and and if you will find only there is only zeros means that this part contains only the background which means there is no organ there is no lever in that part so you need to delete it okay this is my recommendation if you don't want to use it you want to use all your passions you are free to do it but i don't recommend you to use multiple uh groups or subpassions which doesn't contain anything in that case because when you put the patients directly with with random or with random slices having labels or not at the same time there is no problem but when you put one input without any label so this is the problem so when you create the groups you need to make sure that you don't have any empty labels or any empty passions when i say empty which means there is no parts that doesn't contain doesn't contain lever okay so let's start coding this as i told you the first thing that we need to do is to open the image which will be for example i will call it image or nifty file so to do it we will use the knee barbell i just need to use this i can use the shortcut like as nib it is a convention they are always but you can use directly bubble but it's convention to use nib as for knee bubble to make it short so nib then that's the function load this function load will load one pass hits so let's do it for one passing to show you how does it work then we'll create the loop that will pass by all the passions now let's do it let's start by taking this part for example here is the is this is the output part but for us we need it as an input here because we need this path but you don't need to use the parts or the files of the images because the images we are sure that images are have multiple values have zeros one and something between them but for the material for the medical images you will find values between minus three thousand or minus one thousand into plus one thousand don't worry about that this is the medical imaging welcome to the club so what you have to do is using the labels because we said that we need to see if there is label if there is foreground in that part of the body so for that we need just to check the labels because labels will specify the foreground and the background we cannot see that in the images so let's take the path of this output images which will be our input here so i will just put in put nifty file path for example and that's it's ctrl v so this is the all paths for now we take as i said it will take only one passion so i will just take the name here after using after trying with one passing i will show you how we will just add a loop that will pass by all the passes don't forget to add the gz because the value the files here are compressed so that's gz now let's what we will do just we will load this passions which will be here inputs in put something like this input nifty file but so if we run this cell there is no error no problem because we just loaded the image it is here in nifty file what we need to do now there is something in the medical imaging if you have already some knowledge about that there is not only the image exactly which is the array of the image we are talking about the nifties or the decons the same thing there are other informations like the passive information the name and age etc there are value or there are informations about the pixels the dimensions of pixels etc will use this in the preprocessing process preprocessing sorry we'll talk about them later on but for now what we need to do we need just to substitute to extract the value the matrix or the array that contains images which are the slices because what we need to do just to take this values or this matrix that has all the values of the slices and verify the slices of each passions where there is only zeros or where there is zero and one or two or something like that for that to to to start to subtract or to extract the array from the image which is nifty image there is a function called getfdata fdata means that frame data so we can just create as i told you we can do everything in one line but i am just writing every each thing in one specific line so that you can understand the steps that we are passing by so here we have f data which means frame data to do it just write the name of your passing which is nifty file dot get f data it is a function so we need to add the parenthesis so this fdf data will contain the values of all the slices so it will be an array of 65 slices because we have passage of 65 and each 65 yes slices or 65 items and each item is an array of of an image which contains the values so we need to know if these values are contains only zeros or zeros and one or zero one two three etc for that case we need to specify the dimensions of this f data but using only dimensions will not be the thing that we need because the images will just give you how many slices or something like that but there is a function in numpy called unique numpy that's unique so this function unique will return if there is or if there are unique values so if you have only zeros in your function if in your array so the unique values will be only zero if you have zero one two three but you have multiple one two threes in your image so it will return only the unique values that you have in your image so for us if the unique values will be only zeros means that this image or this passion is contained only zero that means that there is no lever so we need to delete it if this unique function returns zero and one or more than one value means that in that case that uh there is something in the image that is the background and there is the foreground indeed so to do it here what we can do as i told you we can choose the number the uh the function unique so here what we can do just i will create another function sorry about that but as i told you i want to write everything so i will call it numpy unique and now we can i don't remember if i have not by here we don't have it so if you don't have numpy just as i told you just something like this beep install numpy and it will be installed but for me i already have it i think so i will put imports numpy as and b something like this so it is already imported now let's let's use it so np dot unique and here we will put the array that we have and for us we have f data this is our unique uh our array so let's let's let's print this so and be while using japanese notebook you don't need to use the print function you can just write the name of the uh of your variable and run it it will uh it will just print it here like this as you can see and for us for us you can see that we have zero one two for us we have more than one value we don't have only zero means that there is the background and that is the foreground for this case we don't need to delete this passion if we have only zero here we don't have this one and two we have only zero means that we have only the background so this buttons need to be deleted i hope that you get it this is the point that's all what we need so the function that we need to do is only to specify the length of this return or of this unique uh so what we can do we can just say if np unique but as we said we need the length of this of this variable so length if the length of this and be unique is bigger than two which means the the length is not one if there is bigger than two means that we don't need to delete that passion but if this lend is equal to one means that this passion need to be deleted so if equal to one let's make just like print and let's print this this passion so for us we'll print this this part because we we are having only one but we do it for a loop now let's print it here there is nothing printed because this passion has foreground and background so if you are in the case where there is no foreground and background you have only the background so it will be printed now let's do it for all the passions you have data database for which with i don't know hundreds passions let's do it now so let's say that labels and just change put here star this mean that this part contains multiple files so this star will return everything inside that folder to do it let's start by creating the list as we did here we need to create a list of labels and it is equal to globe then here the parts input parts file uh a nifty file then here this this list of group of parts will be used in the for loop as we did before so now let's just write for persians in list labels then let's do what we have done here let's just we can just copy these and use them there is no problem let's just pass them here so they will be in the condition if condition now what will be happen but just we need to change this because we need to load that specific passion not the folder here so here load the passions which is here for the loop load the patient and get the frame data from that passion calculate this unique then calculate the length if it is equal to one then print it but we will need to print the passions so here sorry i am passions so we will read it we load it extract the frame data get the frame data then choose the unique calculate the new unique values then if it is equal to one the length then prints let's just run this and you can see that there is nothing printed because the both passings that i have here are with the foreground and background so there is no problem but if you have passions with more because for me or even my passions that i use in this test has only one hydrant and second one has 120 or 110 slices so when i created the nifty groups the nifty the decom groups and converted them into a nifty which is which are the sub passions here they have they should have slices with the liver because if i had the large number if i had pass it with 600 slices for example in this case i will get definitely definitively i will get three or more than three groups of decoms or groups of 65 slices which are empty so for this case i needed to delete them because in in this in this task i am showing you only two passions but i have already prepared the data and i had that problem and i have deleted all of them when we start doing the preprocess i will show you how i created the folders for the training and for the testing and we'll do everything together don't worry about that now as i told you this is the script let's verify if you have empty files in that case it will print them and you can delete them manually i wanted to do it with a script to delete but i had some problems sometimes if you do something wrong you may delete the wrong files but if you want to do it you can just add the line to delete that button but i don't prefer that i just want to print them maybe verify them but it's up to you if you want to delete them you can just add the delete or the remove function uh from the chantel that we used before here this function gentle you can use it to delete the file and just put the then call the gentle down here put the parts which is the passion of that part of that passing which is the empty and it will delete it for you so if you prefer to do this you can do it so now after doing i think that now we have completed everything about the preparation of the data let's start doing the preprocess and of course eventually the training so now before doing the preprocessing because all the functions that you will use or need to do the preprocess are included in muni and python so before doing that we need to install monae and pytorch and all the dependencies that we need at the beginning maybe in the process we will need some other libraries but not are they are not the most important ones but the important ones are for now monae and pytorch because they will use them for the preprocess for training for the testing etc for that we need to install them but before doing that we need to create to install code cuda which are the packages for the gpu and the tool case for the gpu so that we can do the training using the gpu not cpu because using the gpu and my training sometimes it took two days to two days to be completed because the images are very big so imagine with me if you have 60 or 100 passions and each passion contains 300 slices and these 300 slices we will divide them but i am talking about the at start so for example if each pass it will be divided into two or three parts so multiply your 100 percent by three so it will be 300 sub passions and each subpassion contains 60 65 maybe slices so imagine with me how large your data will be and we are we will use the 3d monae so we will do 3d convolutions so it will be tight it will take time it will be very slow for us you need to be careful not to be careful but you need to be aware about that you will prepare your data verify it if everything going well just run it and leave it for one day or two days depends to how many passes you have for me i remember one time the training took me two days or two days or a half when i say two days means that 48 hours not only two days just like that so i have a gpu with gtx 1080 but it does it it wasn't that fast so you need to be aware about that because maybe you will say you will say that i can use collab because when i they are using collab in their tutorials but remember that the images or the yes data that they are using in their tutorials are spacings with small number of slices and they have only 40 passings maybe i think yeah and for that the training doesn't take more much time but if you have data set with large number of passings and with large number of slices be aware that it will take time especially if you will run it in your pc because even if you want to run it in collab you you i i think that you know that in collab you cannot run more than 12 hours if you have a good internet connection without any cut or something like that it will it cannot go more than uh one run it one it cannot go more than 12 hours so you make it you can pay for call up pro so you will get 24 hours but as i told you something it took two days so be aware about that okay and don't be scared don't be scared if the training took two days because i am just telling you that it can it can do that okay depends on how many passings you have so to do the installation the first thing as i told you we need to install the cuda you can just go to their website developers.nvidia.com cuda downloads otherwise you can just write in google here coda download something like this and go to this first link and you will get cuda toolkit 11 if you have problems because we if we are using tensorflow it may be a problem because sensor flow with some versions of cuda or kodiana if you don't download or or if you don't install the specific some specific versions you will get problems at the end but with python don't worry about that because i will show you when we will install python you will see everything clearly so don't worry about the versions if you want to install 11 you can install it if you want to install 10 you can install it with no problems so here we want to i have already this uh qdn encoder installed in my pc so i will not download them again but i will show you how to do that to do that then we'll go to the installation part so for me i am using windows if you are using linux you can just click in linux so i will click windows this x86 then here the version of windows i have windows 10 then you want to use it in network on local i prefer use it in local and now everything is set you can just click on download and something i will just click to show you and you can choose the directory where you put your file and it will be downloaded successfully without any problem and after downloading this you just go here i have them here open your i will not do it again as i told you because i already have it but i will show you when you click on it you will get the window let's wait my pc is a little bit slow these days i don't know why but let's see so click on run then choose the directory i will not click because if i will click it will start doing the installation so everything is easy just click in next next next and everything will be installed after installing the cuda now let's go to kuden and korean is another package which will be used with cuda so just go here in developers.nvidia.com or just you can go here and press download typos press download to dna okay so here nvidia cdn the same thing and let's go on download cdn and now to do it you need to have an account and it is free don't worry about that you need to have an account developer account so once you create an account you can just choose version it depends to you so for us we have downloaded cuda 11 so we need to install this if you have already another version of cuda so you need to check the version that you need for your cuda so click on archive or korean archive so you just find all these versions so see which kudi which code that you have installed in your pc and install the available or the corresponding kudn version after downloading it what we will do we i will show you how to do it we this is it will be something like it's like a compressed file when you decompress it you will find this file this folders so that's what you will find so to install kdnn very easy you just need to copy and paste these kdn files into cuda where you you have cuda installed so if you want to see where your your cooler is installed what you need to do just go to your pc and go here in your desk then your program files and you will find the folder here nvidia gpu computing toolkit so this folder will be created automatically when you install kudi and cuda sorry and if you go here you have cuda and you have the version if you have multiple versions you will find multiple versions here but for me i have only one so you have you will find this one now i will just keep this here i will open another one we have three holdings here downloads and cool dnl so as i was saying what you need to do just to copy the files from the bin of the korean paste them into bin of cuda and includes of kodianen just copy them and paste them in includes of cuda the same thing for the lib copy these go to lib x 64 copy them and go to lib here and x 64 and paste them here i have them already so i will not do it again but you get the point because i have kudian and all the files are here so just select all copy them and paste them here that's all what you need to do and the last thing that you need to do is to go to your system environment and add your file the parts of the lib i will just show you here properties advanced parameters variable systems if available environment and now if you go in parts you will find that i have i don't know if i can yes i can move it here now for me i have these parts the path to the bin to do to the bin w uh to the bin and vvb and the the other one which is extra cool t slash lib64 where you if you will find them they are all here good version so this is the first part which is the bin so go to bin copy this part copy it ctrl c and come here click in new and paste it and that's it click enter the same thing for the other one which is the lib and vp this one and copy it create a new part paste it and the same thing for the extra copy tt lib64 and copy this and paste it here and you are and everything is set now you have installed the i will just close this now you have installed your kodi nnn we will go to this one here we have installed cuda kudi and now we need to install monae and python let's start by mulai the easiest one to install mona you can just do bip or conda install so here we install more light that's it it may take some few seconds it depends to your internet connection and because my internet connection is very bad so it will take maybe one minute or less let's stop it for a few seconds and now you can see that it is installed now let's try to install python so to install pytorch we just we need to go to the website pytorch.org okay that's it and now to inst to download it because when you go to python.org you will go to this page just scroll down here check the stable version for me i am using windows if you have mac or linux you can just select them after that i want to install them using pip install if you have you want to use it what really difference is when you click encoder it will be could install instead of beep install but you can see that some some things will be different but when you use for me i am using python pip install so it will download the packages from the uh from the website by touch the website okay so flip then python because you are using python now if you have kuda 11 check code 11 if you have kuda 10 check code 10 if you don't have gpu and you want to do your training in cpu i don't recommend you because it will take one week so you need to check on cpu so it will be installed or storage vision touch audio for us we have cuda 11 because we installed cuda 11.5 but don't worry about that 11.3 does the work because you don't you don't have 10 so we have the 11. then copy this lines and we will install them so for us we are using jupyter notebook i need to do it so here you can see that pip3 you can leave it pip3 or you can make just pip where we have pictorially because if we have installed pip 2 uh python 2 and python 3 in the same virtual environment so in that case we preferably need to use pip without number means we are talking about python 2 if we put pip 3 means that we want to install this package in the python 3. for us we have only python 3 we don't have python 2 so pip it will install in the python 3. so when we run this cell the same thing this installation may take some time depends to your internet connection so after doing this everything is set when we start doing the preprocessing after installing muni as you can see mona is installed and the cuda installed korean installed and now we are waiting for pytorch let's stay for a few seconds to see this message successfully installed yes we have to see it so now everything is set and you can see that the pytorch is installed without any problem now everything is set we don't need anything to install for now i will delete this and this if i will click for example import monae it will be imported without any problem so now you can see that everything is set because i i i started with this because i told you because we need we will need monae and pytorch for the preprocess even for the president only for the training for that i needed to start by ins by this installation so let's start doing the preprocess now let us let us talk a little bit about how to do the preprocess so i will not go to the to the steps uh each line of code by line because i have already done videos and blog posts about everything that we need to do for the preprocess so you can find the links here in my website that is in my picadco you will find a blog post about preprocessing in detail and also the youtube video youtube video about that so you can check it out so that i will not repeat everything in each video because i know that if i will talk about that it will take a lot of time because only the video about preprocess i have two parts each part for 40 minutes or 50 minutes so imagine with me if i will talk about the preprocess and this augmentation that we will come to it later so it will take a lot of time doing that but there are already videos that i have done about that and there are blog posts that you can read there are code etc but don't worry about the code because the code that we will use here is more i have i have just ordered it and it is well done because here it is you will find the code but it is only for the preprocess but here since we are going to do the training after the preprocess so i have created some functions instead of just scripts doing the preprocess i have created functions that you will find in my youtube repo in my github repository don't worry about that at the end of this course i will be i will be talking about everything so i will show you how you can just get clone this the git cloud this github repository and how you can call all the functions because you will find that every function that we will use is here for example how to calculate the dice matrix calculate weights everything we will talk about it later here is the function that will do the training because as you know in python there is no a specific function as in because if you have used tensorflow before you will find that there is that function that feeds mod that fit so it will launch the training and is a little bit easier but in python there is no function called that fit so you need to write the loop by yourself and almost all these things in the training part i took them from uh pythorg from sorry from monae tutorial but i just have done some changes to make the code clear but we go we'll come back to this later and here in the not in the preprocess we find all the functions that we talked about for the creating the groups and nifty to decom and find the empty and at the end we we have this function function prepare which contains the lines of code to do the preprocess so everything is here in github but i will make it clear at the end of this course and i will show you how you can just clone the repository use the functions but before that i just wanted to explain to you some of these parts because as i told you i will not go to everything line by line because you will find the explanation here but just to give you a small explanation i will give you here i will talk a little bit about some of the fun not the functions but only some transforms that we used here because if you go in monae's website you will find that there are tons of transforms that you can apply in your data for the preprocess and for the data augmentation but for us i will not use all these data all these transforms sorry i just took smaller few of them just to make the data clear but i didn't do like a huge things for the data because it will take time and it will take memory and i don't have that great gpu to do all these functions but i will show you how it will look using only these preprocessings and you can do it yourself like this if you want to add more functions of course it will be great because you will see the results at the end they will be acceptable but if you train your model for more data than i that then i am using or you if you do more preprocess or more data accommodation of course your model will be improved better than mine but we go to this later now let's talk a little bit about the preprocess as i told you here as you can see i have created four variables each variable contains the path for the training volumes training segmentation then the testing volumes and testing segmentation if you have already seen the tutorials of monae in their website you will find that they are not talking about testing they are talking about validation but i prefer to call it testing because when we see validation in deep learning most of the time means that these data will be used in the training and it can affect the model during the training but here of course we are we will because if you see the tutorials of monae you will see that they are using actually this data that they are calling them validation data they are using them during the training but they are not affecting the training for that they say always testing data because we just use them to see what happened but we don't use the result of that validation data to do some changes in the model for that i prefer calling them testing data and not validation data but it ups to you you can call them anything you want but i don't prefer to call them validation and if you want to leave the validation you can do that so as you can see here the there are some important things that you need to keep in mind the first thing is the name of your folders i don't i am not saying that you need to call your folders with the same names that i am doing but what you need to do or what what is important here is that you need to specify the name the exact name of your folders because here there is the first thing in your path or where you will find your data the first thing is the main path which means the directory where you have all the folders or all the passions for example here for me this is the whole or this is the main folder which contains four four folders i will just minimize this and this directory contains four folders the first one is the testing test segmentation where you will find the masks for the testing and the second one is the test volumes and this one training segmentation and training volumes volumes means the passions and segmentation here means the labels okay so these are the four folders that you will need so if you are calling them the same as i am calling them here you can just leave the code otherwise if you change these name then you need to change these names as well here so if you will go with me at the end and just fork the github repository and use it for that case you need to change your folder's name to make it easy or otherwise you can change in the code but maybe the best thing if you are using the same code the best thing is to change only the names and not all the uh not the code okay and the second thing actually i i will talk about this later on and i will show you some examples but now i will give you just small words about that you need to be specified about this thing here which is the extension of your files as i told you we cannot use something like other types but nifty so we need to use nifty files but the second thing here as i told you here when we add that gz means that this nifty file is compressed so if your files are not compressed you need to delete this dodge gz because if you leave this the gz but your files are not compressed means that this not this is just defining this line is just defining the part but here when you will load your data and you don't put the exact extension here means that the function bell that will open this volume will not find this file it will find for example passion one does nii but it will not find that gz in that case it will not recognize that it is the same passion for that case it will not open it and you will lose this passion and imagine me with me if you're if all your passion doesn't have this gz means that your your code or your program or your own function will not open any type of data and it will not open your passions in that case you will find your data loader here empty like there is no data and you can do nothing with that and the problem here is that you will not know this is the biggest problem with one eye you will not know where is the problem you it will not give you an error here if you will run this code there is no error but when you will try to print no print or you can if you want to print or if you want to upload your images in this case you will find that your data loader is empty and you will not know that the problem is with the extension this is what i am saying you will you will miss to delete this extension but the code will not tell you that you have missed something or there is something wrong or the directory is wrong or there is no such a directive like this because always when we do or when we put the wrong part always we get the error saying that this directory doesn't exist and in that case you will know what is the problem but with mona you will not know that you will find just the data loader is empty but you will not know that it is empty because you just forgot to delete or to add this.gz the same thing for other stuff but as i told you i will show you that in in practical but not for now now now i am just explaining but after that i will give you a small things that will cause problems and i spend a lot of time trying to to debug that because you will not know what is the problem you know you need to print everything in your code so that you may find the problem for that i will first case i will show you some of the problems that i found during my period not pid but during my uh master's thesis while i was doing this project not this project but something similar but uh in this case maybe if you will find or if you will be faced with these problems you will know how to solve them so i try to do there is four for variables each variable represents the path for the volume segmentation for the training volume segmentation for the testing the second thing here is to create two dictionaries the first one is for the training second one is for the testing dictionaries is only some rows and rows and columns and this these are the keywords and these may cause a problem as well but i will not talk about them now so this one is vol for volume this seg for segmentation so these are two keywords each one represents a column so this column is for volumes this column is for segmentation and in each column you will find some rows and each row contain the path for each passion so the first for example first row first column we represent the path to the volume of the first passion this the first row and the second column will represent the segmentation of the first questions etc etc these for the training and same thing for the testing and you will find all the explanation about these in my blog post and in my youtube video about that so just i am just giving you a small uh recalculation but you will find everything there and now let's talk about this transform function this transform function you can see that there is this function composed which is you can find this in python and idea are using the same thing here compose is a function that allows you to use or to apply multiple transforms at the same time not to apply a first transform to the image and the output image passes to the second image that the second function that will do the second transform etcetera etcetera but doing using this compose function you don't need above you don't need to worry about that you just need to define which are the transformers that you want to apply and it will do that it will do that by itself you don't need to specify which one the first the second but here it will take this order this one will be applied the first this one second extra extract until this last and about that some of these functions need to be in the exact order but others doesn't matter you can add them any way you want so the first one that need to be at the exact order which is this one which is load image load image because before doing any transform you need to load the image first so to load the image you need to use this load image d d is for dictionary because you can use more line with these dictionaries or you can use them just with opening images without using this dictionaries so when you do that without dictionaries you need to delete this d but if you are following my code or if you see the code doing by mona they are always using dictionaries because it's fascinating but it facilitates the ev everything in the code because if you use just script with all the parts it will be something painful but here you know that when you specif when you put you or when you use the keyword wall meaning you are talking to volumes here segmentation because you will find that everywhere when we talk about how to show images or how to train images everywhere will use these keywords so it is something that will help you and not be painful for you so i recommend you to use this way which is the dictionaries but if you prefer the other way of course you can use it and you need to delete this d at the end of all the functions okay so after loading the function the passion sorry you need to add a channel because as i told you in our case there there are two uh for us for now there are only two challenges for the output there is the first channel that represents the pixel for pixels or the mask for the background and the second channel will represent the mask for the foreground in that case you need to add a channel here so that you will have two channels okay okay but you will add another one for the for to specify the the batch size but it will be added here from the data loader don't worry about that and of course as i told you you will find everything here explained in this blog post okay now after adding a channel there is something that you need to do which is changing the pixels the dimensions the pixel dimensions of your passions this is as well one of the important things that you need to keep in mind because what you will do here i am using pixdem and this name here because i am using the speaks theme in this in the parameters or in the arguments of my functions that i have created and you can see that i am putting here 1.5 for the width 1.5 for the height and 1.0 for the depth of the pixel so in your case you will find maybe your because the problem here with the public dataset you will find that you will find some passions having uh two by two by two others zero five by zero five by zero five others one by one by one and if you use them as they are you will find we will cause a problem for that case you need to put them at the same dimensions okay for this case you need to use this function which is spacing which will change the spacing and puts all the dimensions the same and the problem that i told you here you will find the problem here with with the depth especially because with the width and height if you define just a constant number here it will fix the problem but with the depth it will cause a problem if you don't choose the right value here i am using one because i found that with data there is no problem with the value one but in others it may cause problem we'll come back to this later when we will talk about all the problems that you can face during using monae and deep learning for medical imaging now the next thing i will not talk about this because it's not that's important but here for example this one scale intensity range this is another important function which will change the intensity values or the intensity range of the of your images because if you print the maximum and the minimum value of your pixels you will find that it is from not all of them but some of them vary from minus 3000 into plus 3 000 others from minus one thousand five hundred into plus dollar one thousand five hundred they are huge values for this case you can never do a training with these values you need to put them from zero to one okay you need to normalize them but before doing that you need to change the contrast because if you don't do any changing of the contrast and leave them as they are the there is no visibility to the images for this case if you will you do a training or something like that you cannot recognize the different areas or different organs from the image for that you need to change the the contrast of your image for that here i am using because this b mean and b max are from what you you will normalize you the values will be from zero to one but this a mean and a max will represent the values that will change the contrast of your passions let me give you an example because for me now i am i as you can see here i am putting a mean equal i mean a max equal a max because these are the arguments that i will pass in this function for by default i am putting them minus 200 into 200 but i when i will call this repair i can change them otherwise if i don't specify them it will take these values by default okay i put this because i found that these values are the most uh the in average this is the important this is the best ones in the average but not all the time but how did i find these values now i will show you a simple trick that you can use to find these values for your specific data so let's open here etk snap and let me wait let's choose one of let's open this patterns for example now as you can see the visibility is little bit we can say normal we can see the different parts of the body so here we can see the lever with no problem but why because i am changing the contrast if i will not change the contrast i will go here to tools you need to click in tools then image contrast then contrast adjustments you will get this window if i will click in reset this is the exact or this is the the value that you can find as you can see here for example the minimum is minus 1000 to maximum is 140 for byte or i don't know what is the unit for this pixels but the value of that pixel there are some pixels that they are having the maximum value which is 140 for 1 1400 and others having minus 1 000 etc etc in this case the visibility is not that easy for us we are doing liver segmentation maybe we can see it but it is not clear imagine me if you are trying to detect something like i don't know this one or something you cannot recognize it because everything has the same color for now so to do that you need to change it and you can choose you can use these arrows and try to find something visible but when i tried this it wasn't that great but i tried just changing values here randomly and for that when i found these here and here where i found the values not this sorry i found here here what what you need to change you can change here values and these are the minus 200 and the plus 200 if you want to do some changes you can just adjust these values but you can see that the best thing is minus 200 and plus 200 okay and if i will change here you can see that the values here are changing okay but if if you need if or if you want to use this for example this parameter and as you can see here this one is better than minus 200 okay so we can't just take this in concentration but you you don't need to use everything that you can see maybe for my data it is working well but for other data maybe it will not work very well for that okay so you can do a training with this otherwise you can just do do any changes here for example i don't know 100 and here for 500 or something and when you see that the the image or the organ that you want to detect is visible you can just take these minimum and maximum and this minimum and maximum are the values where you will put here a minimum and a maximum that will be placed in the scale internship intensity range and it will be here for a minimum and a maximum okay the next function or the next transform is this one crop background the foreground sorry this group foreground is one of the i will not say important because if you don't use it there is no problem but it is it is one of the useful functions or the useful transforms because here you can see that this is the whole image because it is the black area but i will just reset here just make it clear but you can see that it is a black area but it exists in the image for that case preferably you need to delete all these borders that you don't need and just take this foreground part for that case this function crop foreground is useful for that it will do that because you can see that in each function we do here when we want to specify that transform for the volumes we call the keyword volume when we want to do it for the segmentation we do segmentation when we want for both we write both of them and you can see that most of the time we apply it for every for every keyword which is for the volume and segmentation because we want to load the volume segmentation channel to the volume and segmentation change the spacing for the volume segmentation etc etc but here for the spacing for example we need to do it only in volumes because our segmentations are values from zero not from zero but values of zero and one so if you do the if you do some this these changes you will lose all your mask because they are binary mask so you don't need to change the segmentations for that we write here only volumes and now as i told you here there is say the second keyword or second argument which is source key because if you use the source key like segmentation here in that case segmentation it will be only black alia only something white in the image so if you do that it will crop all your your image and you will lose all the information and you will get only the white area or the place where there is a liver in your mask and in the slices where there is nothing in that slice what i am saying it will crop all the image for this case you need to put here source m source key which is the volume for that case it needs to see or to look at the image not to the mask so it will look to the image and crop this parts and leave only the interesting parts from the image which is the foreground okay now after doing the foreground here there is the resize transform which will resize your images and masks as well so that's what what i am using this here you can find that there is partial size this partial size is what i am putting here in arguments spatial size is the new spatial size of your images or the new dimensions so you can see that i am putting 128 by 20 128 by 64. here i can put 64 or i can put 65 because our data that we have created are 65 but i will leave it 64 there is no problem but you know that you can put here you need not you can but you need to put here the exact number of slices that you have created so if you have created the same number as i am using here then you can use 64. if you are using more than that you can but you need to change this value otherwise if you didn't create the groups as as i was talking about in few not minutes maybe a few hours before this part i talked about maybe you don't need to create the groups because maybe you have some new some numbers of slices almost the same for that case you just use here or you just need to put the average number or the minimum not the average but the minimum number so if you have you have passions with 4 with 100 slices others with 110 others with 105. so in this case the minimum is 100 so we need to put here 100 so all your passions will be resized into 100 slices and for the width and the height you can put anything you want here but you you need to be um you need to be careful you don't need to put something that will make the image not visible and you will lose all the information of your image and i am putting it this smaller because if i will put it more than that the training will be very very slow and maybe will not be accurate not i think that if you put it 260 456 it will be more accurate because i tried this in another machine not mine but it will be slow okay but for that i don't want to put it in my machine because it will be slow for that i am using 128 because but if you have a good machine or good gpus you can use this you can increase this dimensions of your images when you do the resize okay and finally after the resize what you can do is to change or to convert these images into tensors so this one will open them do all these transforms and after doing everything you need to convert them also transform them into tensors you need to be sure that this function need to be the last function that to be called because you cannot convert them into tensors then resize them it will be an error and you cannot even run it for that you need to be sure that this two tensor is the final or yes the last function that you need to call okay so this all what we need to see but if you go here to the monas documentation you will find that they are they have a huge number of transform that you need you can apply but i didn't want to make it complicated i took only the necessary ones but if you want to put more you can put more and now let's let's talk a little bit about the data augmentation if you want to do some data augmentation then you need to see some transforms here from the exact page because their page of transformed here contains the transforms for preprocess and the transforms for data augmentation so you just need to search for it maybe you just need to search for the word augmentation or data or notation and find all the the functions because i used some gaussian noise there are some zoom there are some flip there are multiple transformers you can use and i wrote another blog post about that that you can see and take an idea about that i think i have some examples here for example this is the same passage with multiple transforms and i have created all these uh this one for with gaussian noise this one shifting this one with flipping rotation rotation everything you can find in the documentation and you can read this blog post just to have an idea about that and and of course of if you need or if you want to add some data augmentation you need to add it in the training parts not in the testing because in the test you don't need to do any augmentation augmentation have to be done in the training so you can find or you can search for the function add it here and of course before this to tensor okay so that's all about the functions and now let's talk a little bit about how to do the data loader deci loader is just to combine between the files which have which which we have been defined here and the uh the transforms that we will apply to each file or to each passions so this is the this is all what you need to know about the data loader it will combine the images or the files with the year transforms and it will apply to transforms and load them in your ram and you can use them after but there is something here which i am putting here cache this cache i am putting here in the arguments if it is false means i will not call it which is i am talking about this part if it is true i will call it here but what does it mean this cache function this cache function because there is you can use cache data set or you can just use dataset if you use this dataset after what i read and what i understand is that this function will load your data into the gpu memory in that case the training will be uh more fast or will be faster and it is true because i try that with the with the cash and without the cash with the cash is faster when i when i say faster is maybe five or ten times without the cash but although it will be slow because even with this crash it will be slow i don't know why but depending to how many percent you have how many what is the batch size that you are using and what is the how many epochs you want to train your model for that case you it will control your the speed of your training but using this cache will make your training faster but not all not always you can use it because if you have a lot of data and you have a small memory in your gpu in that case you cannot load it and if you do it it will start loading it and in some point it will give you an error saying that you don't have memory in your gpu so you can you may you can use it or you can try to use it at the beginning if it works but happy for you if it doesn't work just put this cache force or you can just don't touch it here and it is by default false and it will do the training directly we do without loading any passings in your gpu memory okay now after doing everything here what you need to do just to call it but for now what we need to do if we just call this function we cannot see anything we need to plot it for that i wrote this function for you i didn't wrote it to be honest it is i found this from the moonlight tutorial i just made some changes and i am using it as you are so i didn't do anything by myself i just did some changes i just write and write some documentation here because these are some problems of one eye there is not enough documentation to understand what they are doing and there is no raising well i am saying raising because when you will have problems you don't know what is the exact problem you need to spend days trying to find or to figure out what is the problem so these are two problems with mona if they are watching this video i hope that because you are having great framework but just you need to improve these things and thank you for that and now let's talk about how to ch how to show one passion and of course you can do it for multiple passions the same thing here i am creating a function called show passing that will show a passion you need to put in the parameter here the data loader that you have in your images so this email this part as i told you it will take the data loader which means it will take the output or the return of this function i did this species specifically because i wanted to make it easy for you you don't need to write the same code the same here at the same function here and but you can just call this function and take its output and use it as an input here and it will close your image or your passions for that i didn't want to use it as that's i just want to use it at the same function here i just made this function for the preparation or for the preprocess and this function for the showing one passes so this pass this function as i told you it will just take this data which is data loader and here we are returning the data loader for the training and for the testing for that i am taking here check passion training check passion to test because they here this is a list of two data loaders training and testing and now i am doing this view train view test and now what i am doing here this function called first it is from one eye this function first will just take the first passion from your data loader if you have 100 passes this one will return only one pass hint so that you can plot it or you can do anything you want with it so this first function will return this first passion this first one will return the first passing from the testing and now we have two passings to view them or to show them one from the from the training one from the validity from the testing and that's it i am using here if conditioned one for the training and one for the testing because if you want to see if a passion from the training or you want to see a passage from testing there is no specific thing because if you just want to see your data after preprocess so it doesn't matter if you see a training or testing passion but just i like to put everything here to make it clear for you maybe you you want to play with it for that you can just make this true force or you can put them both too so you plot one from the training one from the validation no problem with that so let's go with this here after doing that just you need to create your figure and i will put here supplies and as i told you these parts i took them from one eye and you can find them in my or other ways because there is just something like only pure python just create a figure figure and before that this much plots leave this function or this package here maybe you didn't have or you don't have it you know in your virtual environment or in your system so you you need to install it i don't know if i talked about this or not but don't worry about this at the end i will at the end i will give you the requirement.txt that you can use to install everything but if you are following the tutorials you can just install it by pick install install then mod plot lib i have it already so i will not install it and the same thing for this tkdm function this function is this library is not if i can say it is not one of the important things but it is included in some parts of the code not only my code but even in the code of monae's so you need to install it because it will just show you the progress so if you run a loop for loop for example it will be running the progress or showing you the progress in which iteration you are or something like that it is it is useful sometimes but for now mona is using it so you need to install it otherwise you will get an error okay so just delete this and now as i told you after installing the matplotlib just import it here much block clip as plt and for that we are using here plt.figure to create the figure plt that's upload to to supply our figure to divide into two parts because here i want one line or one row two columns and plot this first part in the first it's first deviation so if you we have window here we divide it into two so one row two columns and this is the first part where we want to upload the first passion or the first image and for for us the first pass the first image that we want to upload is the volume of that image which is the this part which is this volume and the second part here because this is the second part will be the segmentation of that same volume and here we specify the number of slices not numbers sorry the slice number so if you want to print the first slice second slice and the 64 or 65 slice which we have in my case if you have more you can print more otherwise you can even add a for loop if you want and bloat every every slice you have or every passing you have and you get the point this is for only one pass into one slice and if you want to do it for more you can just change it here as the arguments of my function i am putting here this is the required argument that you need to put the data loader which is the output of the preparation function then here you need you can specify the number of slice number otherwise it will take just the first one and here if you want to print a training passings or testing patterns and that's it that's all what you need now let's try to make an example about that let's run this cell by clicking in shift enter and the same thing for this one and the last one now everything is set let's do an example before that we need to uh we need to return the passion so i will just take this part i will give it in directory equal this here let's change this backwards slashes because sometimes it's give an example a an error so we'll just change them that's it now after having the in directory we need to create the passes so for example i will give it it is actually it is not passing there are passions so i can we can put spacings or i will put only one passing because we will print only one plot only one passing so let's just name it passions without that's s to make it complicated so passions equal now let's call the function prepare which we called here which we defined here this is the function prepare as i told you the first parameter is the in directory so we have called it the same thing in directory for the other parameters you can change them otherwise if you leave them as they are these are the the greater ones that i found in my case if you want to change them you can play with them and see what will happen but for now i will not change them because they are great for my type of data and now if we run this there is no problem you can see if we want to show one of the passing that we have so just call the function show passions i think this is the name show passions and now here we just need to give the passion as a parameter the other parts we don't need to to change them so for now it is one if i will run the cell it will take few seconds because it will do the data loader after that it will show you this passion now let me change this name this number of slices i think it is the second we can just write here for example five can see here now this is the fifth the fifth slice let's take for example 20 and that's it's let's try for example 40 and it will be the last one and that's it if you want to do more with that you can just play with this change the passings change everything you want and these are the two parts that that we need to talk about before the training because there is the preprocess and there is the second part which is the how to show one of your passing because we need this function for now and we'll use it after the training to print the results or to plot the results so that was how to do the preprocess how to show passions let's talk about now let's talk now about how to launch the training we're using one eye and paid off now before starting doing the training i will talk a little bit about the common problems that you may face because there are some problems that i found and i didn't know how to fix them because the error doesn't specify where is exactly the problem with my my code okay so i will show you only three of them which were common for me but maybe you will find others that maybe you didn't install numpy or something like this these problems are very common and you can find them but these problems with monae some sometimes you will not find any uh if you go in stock overflow or in even in monash repository in github you will not find answers about this these errors for that i will just give you these three errors that i found not i found but i faced during my project and others maybe if you will find other problems you may ask me in the comments or otherwise you may find them in google because these three problems are the only pro problems that i didn't find solutions after a while doing two or three days trying to debug the code and you will see that the error is something very stupid but you will not know does not cause the problem okay so let me just jump to the code and show you how i will do these mistakes with you and show you how you can fix them it is not it's not about fixing them because you may do everything good at the beginning and you will not face this code these programs but i just wanted to talk about them separately not in the in the in the code okay so the first thing is when you put you did when you put your uh input data to the path with the directory of your data if you do something wrong with it you will face a a problem that i will show you here how how does it look like the error and you may not know that the problem is your with your path because it will not tell you that you have a wrong directory or this directory doesn't exist you will not find this i will show you what is what type of error you will find and if you will get this type of error means that you are making the or you are putting a wrong part or wrong name of your folders or passings or something like this so here i am sure that this part is true but you can do a mistake with your path or some of the time you can you will not do a mistake with the path but i will show you where you can make or when you can do a mistake because it happened to me and it happened to a lot of people you will get wrong name of folders for example these ones because i told you when i shown you defaults i told you that if you want to use the same code you need just to name your folders as mine otherwise if you want to change them in your case then you need to change them even here because you will not get an error telling you that the problem is with the names of the folder but it will not work okay of course because the part is wrong so this first thing maybe you will forget an s here you may just write train volume you forget the s so in that case it will not work but it will not tell you that you are forgetting the s or you are you have the wrong part the second thing maybe you have nifty data not compressed which means you don't need this.gz and you are putting it here for that case the code will search for nifty compressed files and it will not find this nibs nifty compressed or zipped files in that case it will give you an error but it will not tell you that we didn't find this for this file or we didn't find a complex photo it will not tell you that so let me just leave it like this and i will run the code and i will show you how does the error looks like so now let's just run this cell the same thing this cell because i will try to show an image so that you can see because if we run only this you may not find the error because you will find the error when you call this function which is this prepare function so when you call it it will do the operations and it will find the error so to call it you can call it you are doing the training so you may face the problem during training but for us we didn't start the training yet so i will show you how you can face the error only when you are trying to plot one off or to show one of your passions so i run these two cells now let's go to the first problem which is this one as i studio everything is good here the directory is correct everything is correct only this name of passions which are everything does nii it should be that gz because for me all the passings are zipped but i deleted that so that you will find we see how how does the error looks like now let me run this cell let's wait few seconds so this is the error that you will find and it is saying that there is no object or the this because in reality what does it mean it takes this data loader which is the output of this function and take the first passion from that data loader and show it but it is saying that this data data loader or this view passion is not it's not talking about the opacity something called this check passing which is a output which is the data loader it is saying that there is there is nothing in this list it is like an empty list you cannot like doing the index zero index one it is not subscriptable so in that case you will see that your data loader is empty but there is nothing saying that the problem is before the data loader it is not saying that the path is wrong or there is no file name that's an i without the easy it is not saying anything so if you face this this problem you will not understand why your data loader is empty you may understand that your data loader is empty but why why it is empty because you forget this gz that's it maybe you can put that g and you forget z so this part doesn't exist so everything related with the part will not tell you that you have you are having a wrong path so in that case you need to check your parts check your files etc etc so that was the first error that you may face you may face this error saying that your data loader is empty in this case you need to verify before the data loader which are the path here maybe it can be these keywords but for the keywords i found it give you then it give you the specific error it will tell you key errors and it will tell you that the problem is with the key this is a good work but if you have problem with paths it will not tell you so be careful with that now let's go to the next next error which is when you put a wrong keyword in the dictionary so we are using here the same keyword vol for volumes sec for segmentations imagine with me if i will put here for example i do it wrong i put two l's so vol with two else i was writing my code very fast i didn't see this error so this of course i know you are python developer so this will give you an error so it will not work but sometimes you will not see it because i i remember one time i spent more than two two hours trying to debug the code and it was the pro the problem was here and i remember it wasn't even here because here it is very easy to see it it was inside my transforms i maybe it was here i don't remember maybe it was here so if you run the code where is the second error this one wrong so if i will run this code you will get this big error and you will get confused what is this error and i don't understand what is happening here and you can see that it is showing you the uh the arrays of your passions etc and you you for me i was like what is this what is all these writings i didn't understand what is the problem and the key and the problem is just here it will give you because for that you need to read the uh the error carefully this is not this is not my case sometimes when i see this big error i i don't i just stuck and i don't know what is happening here but actually you you maybe you didn't you don't need to read all this because you will not understand what is saying here but if you go just a little bit here you will see that uh where is it but it is saying that the drone is with key error and you come here to tell you that there is a missing key which is key was missing which is this v volume with two l's so in that case you see that's ah there is something wrong and because if you see the last error here because if you don't read that you go to the last error you will find that this is runtime apply and transform and you see what is the problem maybe i am i and it doesn't tell you even here what which transform is wrong so you may go to to all the transformers trying to change the values that's what i that's what i tried to do before i change these values of this big dimensions or maybe spatial size etc and the problem is little bit stupid because just you are putting an l here wrong and when you are stressed doing your project you may not see this type of error believe me i am saying this because it happened to me so but if you read the error carefully you you don't need to read all this writing because it's not needed but you go just here and here it starts telling you where is the problem and here you can understand that there is problem with the key error then you just go here little bits and you can see that problem with this transforms and of course there is here a keyword telling you that the key error telling you that this keyword is wrong and i think they may give you even the name of the transformers where there is the problem because here it is just telling you that there is problem with the keyword but which transform is having the problem i will just see which one if it give you or not i don't remember that transformed because the problem as you can see here is always telling you that the problem is with the transform okay we understand that but which transform is having this problem i think that it give you which transform having this problem but i cannot see it um no no there is nothing talking about that keyword dictionary yeah yeah that's it and you can see we spit spend time because i know that it exists and i spent few seconds searching for it imagine me if you don't know that there is this kind of errors you will not find it so you can see here runtime error applying transform at because at the end here it is saying the same error runtime error and applying transform but it doesn't say which transform is where which transform is having a problem but if you go a little bit here you can see that the problem is with the spacing the objects transform so you now you have two uh two heads or two keywords to see your problem the first one is you have a missing key with wrong key which is this volume with 2l and the second problem is this you see you know that which transform is having problem which is spacing d and you go just a little bit here now here and it told you that spacing d is having a problem and saying second thing is volume and you see now yeah this is a problem and you delete this and the same thing if you have a problem or we have missing key or wrong key in other parts it can be in the training or in validation or in testing because the problem if you have it in testing and you because all the time when we try to uh to to say not to say but when we try to test or to show passions all the time we use the training passage for that i added here training or testing if you need to you can you need always to use or to test your validation or your testing data so that you will understand because here when you will learn to launch the training because as i told you i am using the same code of the training used by monae so in this case not the same but i made some changes but you will see that in this case they will use the there is a part of which they are calling it validation i am calling it testing i told you why so during the training you will use some of data so that you can print or you can upload some of your uh validation metrics so we will calculate the loss of your testing and the laws of your validation the same thing for both for them they are not calculating the laws for the validation but i added it so that you will get the matrix for both validation and and for the notification for testing and for the training but in that case you will not see the problem only when you will run the code so the code will be run the training part will run without any problem when it comes to the testing which is the validation when it comes to the testing part it will try to load one of the passions and it will find that there is a missing problem with the part or problem with the keys or something like this and it will stop the training tell you there is a problem and you will not understand maybe you will not even know that the problem is with the testing only a key in the testing part so you need to keep in mind that if you get some of these errors maybe this one or maybe this one this one like talking about transforms or something like this you may get only the last one here you need to check your key for keywords in your dictionaries you need to just sure to check your parts of your data now after telling you about these two that is the third one which was one of the biggest problems that i faced in my project when you see doing the uh segmentation and of course most of the time you if you because if you do the segmentation by yourself it is easy and you may not get this type of errors but if you get a public data set or someone give you the public data set with the labels so in that case you may face these problems because maybe they are for us we are doing only liver segmentation but maybe you will and you will download data that have been used for liver and tumor segmentation or liver and heart segmentation which means two not two for three classes that is the background the liver and the heart or background liver and tumor etc etc so the data have been used for that case but you want to use it only for background and level only so in that case you you need only two classes background and foreground which will be level but the data has been haven't been done for that case so you need to change it you can change it before doing any training atk snap i shown you how i have shown you how can you just modify uh your segmentation so you can do it manually otherwise you don't need to do it because if for example you have data because if you have data for liver and tumor and liver tumor segmentation so the liver the tumor will be at the same part of the liver in that case you don't need to clean it before i will show you only in the code in the training part how you can just change it there but if the problem or if the the yeah if the error is in the tray in the for example the data has been made to segment level and heart for example so in this case you need to delete the segmentation for the heart because it will cause a problem but if the the same because sometimes even for if you have data only for labor segmentation you may get maybe the man or the person who was doing the segmentation maybe he did something wrong and in some cases at the same area of the liver he puts another color or another value or something like this so two if you have more than two different uh two different values so the code will will detect them as classes so more more values or more different values you have more the code will detect them different classes and that's what happened to me and you will get the error and you will never understand that error is happening from that and i wrote a code a blog post about that i will just show you but i will show you how you can do it in the good the the to fix this problem you will you will need to do it in the training part not before that because as i told you if you have segmentations for training and for the liver and heart so in that case you need to do it before the training and you need to delete all the segmentation for the heart but if you have the same you have only one segmentation but with different values i am talking values i am talking about the labels because they are masks binary mask it should be zero and one if you have multiple classes so it should be 0 1 2 3 etc each value represents what's one class but for us we are having only two classes so we need only two values which are zero and one and in my data here i have problems and i will show you how what are these problems i will just search for the problem uh yes this one you will get this type of errors it is this error is made from by torch when you will run the code you will get you will get something like this and you will not understand what is the problem you can read this blog post to see where is the problem and i i have here an example to show you if you have labels for example for us for me i was doing tumor segmentation so i had two tumors but for my case i didn't i didn't need to do instant segmentation which is the first stream or second tumor i didn't i did i just needed to know what is the background and which are the tumors so they should have the same value and the same color and here is the problem and now i will show you how you can fix it so as i told you if you have two different parts of the body segmented you need only one so you need to delete the second one using etk snap or any software you want to delete that part otherwise if you have only one organ segmented but with different values so you need to put them at unique value so i will show you one of the passions that i have where i have this problem so one of my passions for example this one has this this problem i will just print it here to show you so you can see that this passion here has two has three different values it has zero one two and in my code i will tell him that i have only two classes the background which has value zero and the foreground which has values one so the code will find these values too so it will detect them as a third class but in my code i will tell you that i have only two classes so in that case pytorch will have that error which is this one what is it this one this error you will get it and you cannot run the code with that error so all what you need to do is just to make a condition saying that all the values which are more different that's what i was doing different to zero i will put them true because i you can use zero and one or true and false because you have binary segmentation so you don't care about that so all what i did zero uh the values which are from uh different to zero i put them into true and the values which are zero i put them into false so that's what happened if you have multiple classes so you need to talk about that and you maybe if you have multiple class everything is good but for me i have only two classes foreground background and it is detecting something as it is giving me this kind of errors so in this case you need to change it okay so that was about the errors that you may face now let's talk let's start talking about the loss function that we will use and we run the script to do the training so for the loss function that we will use we will use the dice coefficient so that's coefficient which is or we can call it dice loss because sometimes you heard about dice coefficients and dice laws and i wrote a blog post about that it is this few months ago talking about what is the difference between them and you will see that there is no difference it is the same thing but you can use it as a metric or you can use it as a loss function i use it for both but you will see that it is stupid doing that but i just used used to both because i tried to use because even more like they are using dice laws for the loss function and they are using the compute they just function called compute dice metric but that's that dice metric the way they are calculating it it may cause an errors for me and maybe it can it may cause errors for you where you when you you have a lot of empty as i can see empty slices where there is no labels so i i understand what is the difference between them and i try to write the uh not function but it is it's a small equation in one line to calculate the dice coefficient from the dice laws actually we need to calculate the dice loss then we calculate the dice coefficients then we calculate the dice laws but monae are providing us directly the dice loss equation and it is working right good so we can go back from the dice laws into the dice coffee scenes i will give you just skew uh sorry not quick quick uh explanation about that and you will know that you can do it even yourself okay but of course i will provide you the code to do it but here the first thing that you need to do is to know is the dice what is the dice coefficient because all of you may be if you have done segmentation before or even you have the objective detection you know the intersection over union uh value or matrix so dice is not that different from the intersection of our union because the intersection of reunion is the intersection between the the ground root and the predicted mask divided by the union the ground root union the predicted mask but the dice value or dice coefficient is calculating the intersection here between the between the ground root and the predicted mask divided by the sum and not the union so divided by the sum and everything you will multiply it by two so i will give you this just small explanation that i have already done in the in this blog post so i am just reading it sorry about that but you will know that these graphs are more you will you will understand with these graphs more than just talking or writing so let's suppose that we have these two uh circles the first one for example a represents the predicted mask and the b represents the ground truth that we have so this is intersection of course you know it and this is when we say intersection over the sum multiplied by 2 means that we the intersection is only this yellow part divided by the sum we don't care about if they are the same or not we sum them and here we put the intersection so what is the the mean or what is the meaning of this case when you have or when you have a good segmentation or good model means that the intersection between the predicted mask and the the prediction and the ground truth will be almost the same so you will get only one circle here because they are supposed uh one uh one over one so you have the uh the ground rules is over the the predicted mask so in this case the value between them is the same and you sorry you will get only one circle which is in yellow here which is the intersection between them because they are the same and in the sum you will get the same thing because we said they they are the same so a plus plus b is the same thing which we are saying one plus one two plus two etcetera etcetera so you will get one thing here because only one divided by one plus one which is two times a or two times b because they are the same so you will get two times one circle or the intersection if you want to say and divided by two times the same thing so you will get one so one is the maximum value that you can get on the other side if you have for example the intersection is not your model is not is very very bad so the the predicted mask is very um it is not as the as your predicted mask so when you do the intersection between them you will get nothing so it will be zero so the intersection will be zero so when the intersection is zero divided by anything it give you zero so zero is the minimum value that you can get for the dice metric and one is the maximum value that you can get so the dice we are saying dice metric and not nice laws so when we say dice matrix so plus we are more we are closer to one more our model is good and more we are closer to zero means that our model is very bad in and there is no segmentation between the or there is no intersection between the predicted mask and the ground root and going from this case we can now choose the or find the the equation of the dice laws and the dice laws what we know about dice laws is not like those what the laws in general the dice the loss in general should be closer to zero so more we are closer to zero means that the error because the loss is an error between the predicted mask or the predicted thing which can be mask class or bonding box and the input which means the error between the output and the input so more the error is is slow which means which which means is closer to zero means that your model is good or your segmentation classification detection is good now we had only this nice value and this dice value we said that when it is closer to one is good and we need to know and we know that the dice loss more it is close to zero is good so what we can do is just to calculate the dice loss is one minus dice which is dice coefficient that we calculated so if this dice is good which means is closer to one or we can say one so one minus one is equal to zero so the dice loss is zero which means you have the minimum loss that you can get which will never get it but the dice law that this dice coefficients may be the maximum will be zero point nine nine nine nine nine nine something like this and one minus zero point nine it will be zero zero very good zero zero zero zero zero one or something like this so in that case you have a good loss good training or and good model so this type of those dice loss we will use in our case in our training there is another loss that you can use which is binary cross entropy laws for for them in in monae they are calling it cross entropy dice loss and it is the same thing i will just give you when we start writing the code i will just give you how you can calculate this crossentropy because i used it and it was useful in some cases because when you are trying to segment for us we are trying segment level it is something big in the in the image so we don't really need this binary cross entropy but when you are trying to do something because i used it when i was trying to segment tumors so the tumors are small area in the image so in that case when where the tumor is small area means that you will get the number of pixels of the background thousand times or ten thousand times the number of pixels or of the foreground which is the tumors so in this case you will get you will get a problem called imbalance data this problem imbalance data is very simple from very common in the classification and we said that segmentation and classification are almost the same but we are classifying each class each pixel not on all the image so you may face this problem so you need to use that binary cross entropy that will penalize the model when the problem when the error is in the class that has minimum pixel values or minimum pixel numbers not values so i will just provide you after the code to do it to do it but we will not use it in our tutorial we'll use only dice normal dice coffee scenes and dice which is and the dice loss but you if you want in your case maybe you want to use this binary cross entropy or cross entropy dice laws you can use it using the code that i will provide to you so let me talk to you a little bit about the cross entropy the weighted cross entropy that i was talking about when i talk about the loss functions so if you have already know what is the because this is my master's thesis i just wanted to show you what is the difference so if you have the cross entropy laws that you have seen before or used before you will see that you have this equation which is this ground truth multiple the sum of the ground roots multiplied by the log of the predicted mass which is the output everything divided by or multiplied by minus 1 divided by n so this is the normal cross entropy loss but the weighted cross entropy it's the same thing but they are adding this w here which is the weight these weights are the things that we need to calculate and i wrote the code for you to do it you will find just here in utilities so this code code will calculate the weights these weights are nothing but probabilities so if you have for example 1 million pixel of black black pixels which are the background and you have for example 100 000 of pixels of the foreground which are the levels for example level nozzle levels but level for example so in that case you will calculate the probability between them so of course you will get a probability of pixels or having having pixels of background bigger than probability of pixels having foreground which is deliver but this thing here when you want to to calculate the weighted cos entropy what you need to do is invert them use the probability of the black pixels for the error when you are having uh when you are calculating the the dice or the weighted cross the cross entropy of the foreground so here let's let's give it a step by step so let's say we are calculating the cross entropy or we can say the weighted cross entropy so if we are calculating the errors of the background so when the model is is not predicting the background so if you have background and the model is giving you that there is a there is a foreground there so which means there is a tumor a level but in your case you know that not you but the label stays telling that there is no there is no background there is no lever there so it should the output should be a background but the model is outputting a foreground which is a level so in that case you need to penalize it out in the in the back propagation so in that case because the mother will be penalized depending to the error so if the error is big so the model will be penalized a lot so it will change the weights and it will be very penalized but if the problem is in your uh if the error is small for example 0.001 so the mother will not change the with all the weights maybe a few of them or and it will not it will not do a big change because it knows that your model is accurate and it doesn't need more uh changes but as you know if the problem if the error is 0.9 or something is closer to one means that your model is very bad it doesn't predicting anything so all the ways need to be changed and that's it updated what i want to say not changed so the the idea here is if you have an error in the background or for us we are saying background because we know that the pixels of the background are maximum of the pixels then the boxes then the pixels of the foreground which is the liver because most of the area of the passions doesn't have a doesn't have a liver not doesn't have liver but the liver there is a liver in specific slices but all the other ones are empty which are for background pixels so if you calculate the uh number of pixels of the background you will find it ten times not ten times you playing this hundred or thousand times than the pixels in the foreground and even for this how to calculate the pixels because you will need them to calculate the probability there is a code that i write it there for you i think utilities show person yes this one this function which is calculate pixels it you will give it the data which will be the data loader which is the output of your of the preprocess function that we created which is prepared so the output of that function will go to this function and this function will calculate the number of pixels which are the pixels of the the the which which are the pixels of the background and the foreground so this function will output an array or a list of two values the first one is the number of pixels of the background and second one is for the foreground which are zeros and ones okay so the values that will be returned from this function you can use them here in the inputs of this so this val you one which will take the number of pixels of the background and this value too will take the number of pixels of the foreground which are the level in our case in your case you can you have something else or the same thing you want to segment but the background is the first one the further the foreground is the second one okay so just to make it easy because you can inverse them but you need to know that you inverted them so the output of your uh of this function which is the return of this function will be returned so you need to take care about that but you need to if you want to something clean you need to write them in the same order so your first class which is the class with the index zero needs to be one two to be here the second one is with the index one two three etc if you have only two so zero and one so this function as i told you it will return the probabilities but it will be inversed so of course we have the number of pixels for the foreground for the background are bigger than the background and then the foreground so what you will do you will use the probability of the background for the error in the foreground so for example let's say that the probability of the background is 0.9 and the probability of the foreground which is delivered is 0.1 because we need the sum of them equal to 1. so this one the probability of the background is 0.9 the the error of the foreground is 0.1 so what will happen when you are calculating your error here which is the weighted cross entropy when you are calculating the error of the background you will multiply the error by 0.1 means that your error will not be bigger so it will be like almost not almost the same but it will not be bigger a lot than it is so in the back propagation when the model trying to update the weight will not change or change them a lot because the problem is in the background and you will not get very big problems in the background because we have a lot of pixels in the background so it will it will be well classified for that you don't want to update the weights when the problem is in the background not not update them but not change them a lot but when the problem is in the foreground you will multiply your loss by this weight which will be the probability of the background which will be 0.9 for example so if we have 0.9 multiplied by something smaller so what will happen 0.9 multiplied by something here the with the error here or the loss value will go higher so when the value of the error will go higher what will happen the weights or yes the weight will be updated more than that because they see that even doing some updates but the loss is always bigger so it needs to update it and to make it more smaller so this is the road of the weighted cross entropy it will penalize the model which means we are when we make the value bigger means that the mother will be penalized in the error in the foreground otherwise if the problem is in the background it doesn't need to change a lot of the weights or and it doesn't need to update the weight so this is what i understand about that if you only if you want to read more about it you can read but that's what i understand about using this weighted cross entropy when you have imbalanced data when you have a class having 10 uh not 10 but 100 or 1000 times data than the other so you need to do this otherwise for for the liver segmentation i used only the normal loss dice loss i didn't use this dice cross entropy but if you want to use it you can just call it as we are calling this here you can just call it dice cross dice cross entropy loss and you give it the all the air not the errors but you give it all all the values here and it will do everything for you and here there is a parameter or an argument would call the weights cross entropy weights so this quantum weight will take the weight that as i i was talking about which will be calculated using this function calculate weights so the return of this function will be the input of this argument which is crossentropy weight so you just give us calculate weights which is the function that we have created and here in the argument of the weight of this calculate weights we need to give the values of the pixels which are the number of pixels of the foreground and number of pixels of the background and you can see here for example these values are from my tumor segmentation projects so you can see that there is a difference between them so you need to use this crossentropy uh weighted entropy uh loss okay so this is the idea if you want to use this you have just to change these values by calculating the weights from using this function not the first you need to calculate the pixels it will return the number of pixels of the background and foreground then use these values here to calculate the weights and the return of this weight will be calculated here in this will be used here in this weights chrosotrophy weights which is this one so that was everything that i can say about cross entropy weighted cross entropy loss now let's start running this script to do the training now let's talk about the training script as you can see here there is everything you need to launch your training but i will go a little bit talking about what are the difference that i did because as i told you i took the for loop that will do the training from one eyes so i will just which is with this one so i will just explain few things that i changed the few things that has changed are i added a function that calculates because for them they were calculating the loss for the training and the metric dies for the uh for the for the they are calling it validation i am calling it testing but for me i added calculation for the validation or for the metric of the training and the loss of the valid of the testing so i will get four uh four outputs not for output but four graphs the first one is the loss of the training second one is the metric of the training than the loss of the world of the testing and the metric of the testing so and i needed to save them all because i need to use them for uh to see to analyze our our results to see if the model is doing overfitting and everything or something something like that so and all what you need to know is these are the arguments that you need to put to lunch to launch your training the first the first one is the model which will be unit for us the second thing is the in the data in which is the directory where you have your data and yes you have your data and the second thing is the laws where you have which which loss function you want to use then optimizer and the max epochs that you want to you to do for us maybe we launch for 300 or 400 epochs then the model directory where you want to save your model trained model then here there is this test interval for them they are calling it validation because they are everything they are calling its validation i am calling it testings for that i just called it test by interval what does it mean this test interval will will uh control in what you know on in which epoch we want to save the new weights or the new training weights what does it mean for example let's just write here at the end let's just write for example as epoch 1 we will get a a loss value for example equal 0.9 okay and we will save this model or this checkpoint which are the weights then let's do let's go to the next epoch which is epoch 2 okay so in the epoch 2 we will get a loss equal to 0.8 for example so in this case the loss is is smaller than the epoch one for that mean so that means that the weights or the checkpoints in this epoch are better than these so we need to save the new epochs or the new model with the new ways which is in epoch 2. so we'll give the order that save i need to add a comment so save model in ebook too something like this okay then we will go to the next epoch for example let's go to the epoch tree and in this epoch we will get something like like for example let's say loss equals 0.85 so 0.85 is bigger than zero point so in this case we can understand that the model or the checkpoint in this part or in this epoch are better than these so we don't i will so we don't need to save these weights because we have already better than them so we'll skip the saving in this part so what we will do like don't don't save the model in epoch tree so we go to the next epoch etc etc so this is that's what's always due in the in the in the training but if you are using tensorflow for example this will be done automatically if you just clone the repositories but while doing uh the training using pytorch you can see that we are writing all the for loop by ourself so we are doing everything we are calculating the we give we need to give the order to calculate the to to calculate for example the first output to pass by the model then we call the laws to calculate the laws then we call the optimizer etc etc so we as you can see we are doing everything manually so in this case we need to do even these conditions manually and now what they are doing they are calculating this metric which can be loss or even metric which can be dice for example the dice value so something like this and this is what they are using actually dice and i use the same thing so this dice they calculate the dice so more they have maximum value of dice more than and in that time they save the the new checkpoints but they don't calculate this dice value for the training that's why they are calling it validation indus in the training after each calculator in each epoch they calculate the new or the the dice values of the testing data which they are calling it validation data so when they have a maximum value or bigger value of the dice from epoch to epoch and they calculate it for for the validation data or testing data in that case they use this thing that nothing but they do this this savings so if this for example i will go here like validation or for for me testing data okay so let's say that the first the first dice equal to for example zero point one for example and zero point one is is bad because we need it higher we need closer to one so the dice is 0.1 that's the ebook for example a book one okay now let's go to the epoch 2. so in the epoch 2 if we calculate this dice it will be for example 0.2 so the model in this epoch is better than the first one because here we have the epoch ctrl c control v and here we have epoch2 but what they are doing because if you calculate in each epoch i am doing it but it will slow your training a little bit because imagine with me in each epoch you calculate the dice of all your validation data so you do the training find the new model and pass all your testing data by the model and calculate this dice value and going from that value you will save that model in that specific epoch or not so to give the order if you want to calculate this dice or to do this verification in each ebook or in each two epochs or on each three ebooks or something like this this will be controlled by this what is it the training so that will be calculated by this test interval they are calling it validation interval for them they are using this value equal to so in each two epochs they calculate the new dice for all the validation data for them testing data for us and when they get higher value they save that checkpoint for me i used one because i prefer to calculate in each epoch but for you if you don't use that value if you want to fast little bit your training so you can put it two or three or depending on your cases so this value one is by default but when we will call the script or the training function here we can specify it here for me i am not putting it but if you want to give it you can just write test interval something like this and give it two or three or anything you want which will change that value by default and for me i want to leave it one and that was all the parameters that you need for this function and as i told you there is the first thing is the model for us we are using a mono uh sorry a unit but we will import it from one eye as you can see it is here monae monae.networks.net imports units there are other networks but we are using unit so there are these three uh important things that i will i will talk about the first thing is dimensions we said that we are doing volume segmentation which is 3d segmentation or 3d units for that we need to make dimensions equal 3 for 3d and the input channel for us it is one because we have masks with only one channel i am talking about slice each slice has only one channel and that channel have zeros and ones but the output channels we need them to be two each because the number of the output channels is the same number of the classes that you have so the first channel will represent the probabilities or the pixel probabilities for the background the second channel will represent the pixel probabilities for the foreground okay and when you combine them together you get the new uh you get the final output so these are the important things that we need to talk about these are the chain channels which which controls how many kernels or how many filters you want to put in the um how they call it in the convolution blocks and these are the strides and this will create the residual new units and this one to normalize the batch but we don't need to talk to you know everything about that but these three things that are important the first thing is the dimensions which is three for 3d the input channel is one because we have each slice has only one dimension the output is two one for the background segment for the foreground because we have only two classes if you have more it will be more etc etc but others here we have just to call the loss function here is the dice cross entropy if you want to use it i talked about it before and this loss function that we will use we are using a sigmoid here and then the optimizer we are using the adam optimizer with a learning rate 0. 10 minus 10 minus 5. so that's what you can use for you if you want to change it you can just change the values here you can change multiple to find multiple times or you can just make that function that's very which give you an interval of learning rate and it will be changed in each epoch on age 10 epochs or something like this but for me i am putting a constant number for you if you want to change it you can change it it depends to you but that's all what i will talk about here after all what you need to do is just run this this script and as i told you that in this type of training it will take time it may take two two days that's what this is strange but it may take two days depending to your machine and how many data you have and everything and that is other things that i have talked about in the preprocess part i told you that there is this parameter which is the cache it can be false or true and i told you if we put it through means that we will use disk function which will load the data in the memory of the gpu otherwise we will not do it so if you have a good memory you can just hear what is the data the this is this function prepare we call the data so we can just here make cache which is this argument and we put it as true so if we put it through it will load all the data in the memory of the gpu otherwise it will be false so if you put it through it will be the training will be faster faster than without the cache but sometimes if you don't have memory you cannot do it so i will just delete this because if you we do it i will show you that it will take time even before to load the data then it will start training i will just launch it like this so that you see that the training will start after that you can use the cache if you want so if i will run this script you just wait a little bit and this is because here i am putting 20 for 20 epochs so i will do 20 epochs and it will calculate the dice train dice and it will calculate the loss for each uh image as you can see here and it of course is starting by a higher value of loss but it will change it will be changed so that's all what you need to do to do the training so and but you need to wait as i told you with gpu for me i have gpu gtx 10 1080 or 1070 i remember but as you can see here you can define define the gpu that you want to use if you have multiple gpus so you can just change the index here otherwise you can leave it like this if you have only one so it will be with the index 0. so that's what that's all what you need to know about the training and nothing else you need just to wait for the training until it will be done and of course here you need to specify the model dear where you want to save your model or your checkpoints plus your plus all the things which are here the loss values or the lows yes the loss values for each epoch and the metric values because we are doing here a save train loss and there is a save a book so this will will save everything that we need so it will save the new in each epoch it will save the new values so the first epoch for example you will get 0.9 the second epoch it will be 0.3 so it will create a list containing all the values for each epoch and it will save them as a numpy list that we can load after and plot it to see what was happening in during the training so that's what i can talk about you need to wait for this training if you want to use google collab it it may work but if you are having a large number of data it may take more than 24 hours and you know that that google collab doesn't sell for i'm talking about the free one it doesn't allow you to to do a training more than 24 hours depending even to your internet connection it will not if it will not cut so you know you need to be careful about doing the 3d convolutions here using 3d unit it will take time you need to know that otherwise there is nothing else to talk about and we will talk after the training i will show you the results that you will get and you will see that you we will not get a perfect result because in medical imaging you will never get something like perfect or like in the other images or other tasks but you can just see the first results after that because for me what i was doing is i made tons of trainings i i launched the first one then i i tried to change something of the data i chose to try to add more data otherwise uh try to change the learning rate there are tons of things that you can change i cannot talk about them all here but because i am telling you only the basic thing and the basic code that you will find in mulai i'm just transforming some things here to make it easy but that's it if you want to make a better better better training you need to do these changes learning great or the the best thing that you can do is adding more data but adding more data means that the training will be more slow but of course at the end it will be better than less data so we will wait until the training will stop and try to analyze our results so now after doing the training let me show you some of the results or the results that i found for my project so i when i i launched the training i put 600 epochs but i stopped it as the epoch 100 because i know if i will leave it into 600 epochs it will take time and the second thing that uh why i did stop the training at the apoc 100 because i found that here at i don't know at the apoc 100 before 100 it was in 80 70 something like this we get this flood here which means that if we add more epochs of course the training loss it will go down and it will converge more than that but for the validation it will always stay here for that i didn't want to leave it to leave the training going more than this because we may get a overfitting or we may get a model which is not very accurate with the validation of with the testing data and for that i will i already will show you one of the passing that i passed it by the model and i will show you the results and you will understand why i should stop the training here okay so to do it i have this uh japanese notebook file that i will share it with you so that you can test your uh your model after the training so the things that you need to to change are only these two parts the path to the data and the path to where you save the model plus these files okay if you remember when we did the training we need in each one in each epoch because i i fixed the i put the number or the value interval test interval into one which means in each epoch it will calculate the through the training not the training but you can get the testing metric or the testing loss the same thing but it will calculate one of them but for for me i did it to to calculate the the test metric so when i get a higher value of this metric in that case i should save the weights okay so i should save the weights which which is the model but in each epoch i should uh save the loss trade the training of the loss uh sorry the loss of the training and the metric of the training the loss of the testing and the metric of the testing in each epoch so that i can plot it like this and you can see this evolution of the laws for the training and these are for validation after doing this now let's let's load one passing or we can load all of them but i will show you only one that i prefer to use not prefer but i will show you how does this look and you can test your test your final model with multiple passions otherwise you may not get the best or the yes the best or the great the perfect model at the beginning so you can do more changes and launch another training okay so for my 100 ebook it took me around five or six hours to be completed okay so you should put this in mind but but i was i was using the cache so the so the data was loaded in the gpu memory for that it took six hours if i didn't do that it will take more than that okay so and but it took six hours for only 100 100 apr i stopped it if i left it into 600 epochs it will take two days maybe okay so for you if you will launch your training in at 6 00 60 600 ebooks for example and if as the epoch 100 or before that you see that your model is doing well and you don't need more training so you can stop it okay you don't need always to complete the whole 600 epochs it is a choice and they are it is a huge number of ebooks so if you see that your model is doing great before that you can stop it okay now when you do when you want to load one of the passions of course you should apply the same transforms that you applied during the training and the testing of course so these are the different transforms that we applied for the training and the same thing i will apply here then we have a test loader because we want to load the testing files so we load them and of course you need to load your model which is the unit and after loading the model this part here will load the weights and put them in the model because you need to create the model first then put the weights or two yes to fill the model with your weights or with checkpoints that you have you have saved during the training so this one will create an empty model this one will put the weights into that model now you have the model ready ready model with the weight that you can use directly for your testing part so as i told you i took only one patient to show you so you can do all the changes to to bloat or yes to show multiple passions but you should you need to be careful with that because the data loader is not like a list you cannot just put data loader zero data loader one extract so you cannot do this you can do for example a for loop so you can do for example i will just write here for passions for example in test loader this one will will work and you can use this way for example if you want to to play to load the first one so you can just add an index here for example i and here you can put enumerate in this data loader and you can say if i equal zero then call this function that will plot otherwise don't do that if this is one way the other way that i use as well which is here when what is it here when you select here i am talking about the test but it should be test here for example so what i am doing here is just selecting a few passions from your data set so if you want to show for example the first one you can do for example zero to line for example if you want to show a second one you can just put from one two nine then from three to nine two twenty etcetera etcetera for example you can put here nine or anything you want so that's what does it mean you will get a new list of passions and always the first person that you will get here he is the passions that you want to show so this is one way that i found not found but you can use this way other thing that because you cannot do like like a list like here i cannot i cannot put here for example this order zero it will not work and it will give you an error about that for that you need to find another way which is for example as i told you before putting the data into the data loader select which passes you want to do the pre before the pre process you need to select which passion so you can do that way or the for loop way that i showed you it up to you but this is the way how you can do it and this script will run on it which will pass each uh it will pass all this like all the passions into the model because we said it is a 3d model 3d unit or cd segmentation so it will pass the whole passion which is here 3d the d volumes which is test volume it will pass it by all the passing for all the passing for with the 64 slices it will pass it by the model here in the model and it will calculate the the output or predicted mask and here this for loop is just to print all the slices of that specific passion so here you can see i will show we start from the wrong segmentation so you can see here for example for these four uh one two three four five six seven we can say seven until eight so this these eight four slices are not well segmented okay so you can see that for these uh the segmentation is great we i i cannot say perfect but it is great but for the the first ones it is not that good so these are the things that you need to keep your in mind in medical imaging you will never get something uh perfect because you can see that we as human and sometimes we cannot differentiate you can see this and this part is it not equal to this one so you can say that this is a level okay but the model fortunately it is not segmenting it as a level but you can see that it is not easy to know which part contain which is the the exact part of the human body so you can see that this is not bad it is segmenting etc but you need to keep in mind because you need to do a lot of changes to get more accurate so you can maybe test these values maybe you can change the contrast for now you can put it like this you can do another training with another values so the contrast will be changed so in that case maybe some some patterns will be better or will look better than these values for example so you can try to changing these or you can the best thing that you can do is try to add more data so you can try to add more data you can change the learning rate there are a lot of things that you can do but and of course you can do more uh more processing or you can add the data augmentation that i talked i told you about i didn't want to add it but you can add this augmentation and sometimes it works very well so why i don't want to try everything because as you see even only 100 epoch took me 500 500 5 hours if in my pc so if i will try multiple multiple trainings and multiple parameters it will take me forever to find the best model so but here in this tutorial on this course i am just showing you how you can write the code how you can use the different functions in monae but it up to you to do different changes to do multiple combinations to get the best results but you need to keep in mind in medical imaging you will never get something perfect but you can i am sure that if you do more changes more data etcetera you will get better than these here for this part it is good but for example here it is missing some segmentations okay and you can test it for other passions you will find that sometimes it is good perfect but others is not that's good so that was how to do the training testing how you can as you can see how you can see your segmentations in the in the final part what i will do i will show you just how you can clone the github repository and use it directly so maybe you don't need to write the code by yourself so you can just clone the github repository and launch the training from it so i will show you just in a few few minutes how you can do it so that you will get an idea about that now after that we have done everything step by step now i am telling because i told you that i will give you the code and you will find everything here in this repository so i tried to write some sentences here to explain some of the parts but i didn't have time to write everything but with time i will try to add more and more explanations and of course i am writing some blog posts about all what we were doing we were doing in this course so if you prefer to read instead of watching videos you will find them but i will publish them soon okay because i didn't finish all the blog posts for now so when i will finish all of them i will post them in my website and after understanding what we were saying now what you need to do is just to for example if you want to use the same code that i am using so you can just clone this repository using this part here so just go here and click in this button to copy this line and go to your terminal and cd or change directory into your workspace otherwise if you are using visual studio code so just open the folder where you want you to work and paste it in the terminal here not there and this terminal and paste your this git git clone this repository so this line will clone the repository which means it will download all the files that you have in this repository in this work space i will not do this because i have already this this repository cloned as you can see here so you will get this folder which contains all the files that you find here in this github repository okay so the first thing that you need to do is to install the requirements so there is the first thing here i am putting that and of course when you do this when you you can unders this repository you need to cd to that repository so that you will your new workspace will be this repository so that you can oh you can directly use the code inside that repository so just copy this cd like this and copy and paste it in your in your here in your terminal and it will go to the next repository as you can see here i have already that repository okay so that if i will just make cd and now if i will paste this cd then lever segmentation using mona and python and then it will go it doesn't go because maybe there is a problem with that because i am putting it here wrong so just correct this spider something like this okay so all what you need to do is just to cd to this directory after doing this you can start installing what you uh what we what we used and of course as i told you about the virtual environment if you need or if you prefer to install to create virtual environment or conda environment you can do it before installing any packages otherwise if you prefer to use your system you can do it directly but i don't recommend you to do that so just copy this to install monae after that all the the other requirements are will be found here in this file requirement.txt so you need to install must not leave numpy blob but when you install globe you need to do group 2 because if you do pip install globe it will not be installed because it is not recognizable then you need to install the control nifty then this channel but before doing it you need to you need to type this keyword because if you do install chat it will not be installed and the same thing for me bubble but don't worry about this you just need to copy this part which is this one pip install dash r then requirement.txt and it will install everything then after installing all the requirements that you need all what you have to do is start coding but as i told you there are some stuff which you will find here the first thing that you need to do is to convert your nifty files into dcoms so that you can create groups using this function that you can call with another main script which will call this function from this file so you can just do imports create or from from what is the name from preprocess that's pi imports create groups and you can just use it to create groups using this function the same thing to do the to convert from the dcom to nifty and to find the empty and finally for the preparation after doing all this stuff and creating the folders with the names that you need which which what i mean with the folder for the volume training volumes training segmentations testing volumes and testing segmentations after that you can just use this function which is prepared to do the preprocess and that's it if you want to do the if you want to show your passions you can find the function show in utilities here i will go here there is the function i think it is at the end yes yes this function will be used to do the or to show one of your passions the same thing all the functions that we were using will be found either in this in this file which is preprocessed the spy for the preprocessing and all in the utilities that you will find some functions to calculate the dice metric calculate the weights for the weighted cross entropy and this function train that you need to do and finally there is this function which calculate the pixels i talk about this as well for when you if you want to use the binary the weighted cross entropy you will need this function and that's it after knowing everything you just need to call this function which is train to to launch your training so for that there is this file which is trained as pi which will call exactly it will call this prepare for to for the play process and it will call the train from utilities import train to do the to do the training using that function train so the first thing is to create the model and launch the training so this this script is like a main script to launch the training but if you want to do the preprocess because if you want to create the groups etc you need to create another script called main or something like that to do all the preparation outside your training etc so after doing the training when you need to test your model you will find this jupyter notebook test that's ip notebook and b so if you open it it will take time some few seconds and you will find everything we explained in the previous minutes you will find them here and just launch this code but by change changing here the path to the data and the part to the result or the checkpoint and everything will work and that's it that's all what you need to know about this project but if you have any questions any problems please don't hesitate to send me emails leave a comment or contact me by er in social media on my website pycad dot co i have no problem answering you answering you but maybe sometimes it will i will take few days or day or one day or two days to answer you if i have projects working on so please don't hesitate to send messages or emails and i hope to s to answer you as soon as possible so i see you in the next courses if you have enjoyed this course please don't forget to thumbs up or leave a comment and i see you in the next videos bye