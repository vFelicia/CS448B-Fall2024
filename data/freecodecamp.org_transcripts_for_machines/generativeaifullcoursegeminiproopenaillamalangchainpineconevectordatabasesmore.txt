this massive course about foundational generative AI was originally recorded live we've put it all together into this one video this course offers insights into generative models and different Frameworks investigating the production of text and visual material produced by AI the course is taught by three experienced instructors okay I think uh we can start with the session so hello everyone good afternoon to all uh this is the very first session for the uh generative AI uh from today onwards we are going to start with a community session of generative AI so uh yes in today's session we'll be talking about that what all thing we are going to discuss uh throughout the sessions and uh this session actually it will be happening for uh upcoming two weeks and uh it will be on the same time I'm going to take the session from uh 300 p.m. onwards uh maybe 3 to 5 so here in this uh committee session we'll try to to discuss many more thing regarding the generative AI so we'll start from very basic and we'll go to the advanc there we'll try to develop different different type of applications as well uh first of all I will start with the theory uh so there I will uh discuss about the theoretical uh uh like stuff and all that what is generative AI what is a llm and after that I will uh like go with the open a Lang and don't worry each and everything I will discuss in a very detailed way and and uh I will show you the dashboard as well where all the lectures and all will be uploaded and apart from that I will uh show you the uh like uh where you can find out all the videos quizzes and uh assignments and all because along with the session I will give you the different different assignment different different quizzes so at least you can practice with the concepts got it guys yes or no so are you excited please do let me know in the chat if you are excited then great so I think we going to start and uh so first of all guys what I will uh do I will give you the uh the detail introduction of the course that what all think we are going to discuss in this committee session and uh here basically this is our dashboard so let me share this link with all of you so uh don't worry my team will share the link of this dashboard in the chat so from there what you can do you can enroll it is completely free you no need to pay anything for this uh committee session and all the lectures and all the assignment and quizzes will be uploaded over here don't worry I will come to the curriculum also so here first of all let me show you the homepage uh this is the homepage guys uh this is the homepage of this dashboard and there uh uh like you can enroll in this particular dashboard and don't worry uh each and every video you will find out over the Inon YouTube channel as well so all the recorded video and all it will be available inside the Inon YouTube channel uh definitely this video is going to be record after the session so this video will be available inside the I YouTube channel as well as uh over the dashboard so here guys this is the dashboard I think you got a link of the dashboard so there you can enroll and then uh like you can start your journey of the generative AI so here guys uh me and buy both are going to take this particular session so there we are going to discuss in depth uh about the generative AI about the llm we'll try to discuss about a various application various recent model llm models and all uh we have so many things uh to discuss about the generative AI we have planned for the two weeks but uh maybe uh more than 2 weeks uh we'll try to uh take if we are not able to cover and like all the curriculum whatever we have defined whatever we have thought uh so definitely we'll be extending the date as well but yeah we will make sure that within 2 week whatever curriculum we have defined we'll try to complete it so here guys are me and uh buy so if you don't know about me guys so my name is Sun my name is s Savita I'm working in Aon from past three year and I have I'm having an expertise in data science uh I have explored U every aspect of the data science like machine learning deep learning and advanced deep learning like computer vision NLP I have worked with the mlops as well uh there I have designed a various applications and all got it so yeah uh you can search me about more over the LinkedIn uh there you will get uh you will you will get got my profile and you will uh like uh get each and everything in a detailed way so here guys uh what you need to do so first of all you need to enroll to this particular dashboard uh you no need to pay anything over here and if you are going to login after login what you need to do uh so uh you will be redirect redirecting to this uh particular dashboard and uh so let me show you the dashboard first of all this is the dashboard guys as of now there is no such videos and all uh definitely after the session we'll uh upload the videos and assignment and quizzes so definitely along with the sessions and all you can practice so this thing is clear to all of you yes or no have you enroll uh through this dashboard did you get this Dashboard please do confirm in the chat I'm waiting for your reply please do it guys great so I can see uh uh many people are saying yes so definitely now uh we can discuss about the curriculums and all so whatever thing we are going to discuss throughout this committee session first of all I will give you the detail uh like uh detail introduction of the uh syllabus uh what all topics we have uh we'll try to more focus on the re recent Trends I'm not going into the uh classical uh machine learning and the Deep learning basically so I will focus more Focus basically on the open Ai langen and all so don't worry I will give you the detail introduction of the syllabus uh that whatever thing we are going to discuss inside this committee session so the first thing what you need to do guys you need to enroll inside this dashboard and uh whatever like videos and all you will get uh you will like go through and basically you can watch it over here itself directly now let's discuss about the curriculum and all that what all thing we are going to discuss and uh for that basically I have created one PPT so let me show you that particular p PPT uh just a second so here is a PPT guys can you see this PPT yes or no please do confirm in the chat if it is visible to all of you great I think uh this uh PP is visible to all of you now guys uh we can discuss uh that uh what will be our uh like topics and all uh that what all thing basically we have to discuss throughout this committee session so here uh first of all I will start from the generative AI so there I will give you the detail overview of the generative AI that what is a generative AI uh why uh we should use a generative AI uh what all type of like application we can create and uh each and everything each and every every theoretical stuff we try to discuss regarding the generative Ai and after that after the generative AI I will come to this uh large language model so just a second let me open my uh pen as well so I can write it down um each and everything yeah so here guys uh we can uh I can write it down as well now so here the first thing basically first I'm going to start from the generative AI there uh definitely I'll will be talking about each and everything each and every aspect of the generative AI then after that I will come to this large language model there I will try to discuss this llms large language model in a very detailed way we'll try to see the complete history of the large language model that what is a large language model what types of model we have what was the classical model and uh what is a recent model okay so each and everything we'll try to discuss regarding this llms and after that after completing this uh theoretical part theoretical of this uh stuff and all regarding the generative AI regarding this llms I will come to this open AI open Ai and this lenen so there uh we'll try to discuss in a very detailed way that what is the open AI what is the open AI API and inside the open AI API we have a different different them right so in OPI openi itself you will find out a various model that like openi open has created a various model uh that different different version of the gpts okay so it is having some uh like a old model as well some legacies and all and some upcoming models so each and every model will try to discuss I will give you the walk through regarding those particular model and I will discuss about the python API python uh API uh that uh how you can uh use utilize those particular model by using the python getting my point and apart from that apart from the python API and all will try to discuss that uh like if we are going to be uh if we are going to use the Lenin right so how it is different from the open AI so at the first place I will give you the uh detailed differences between this open Ai and this lenen that how it is different to each other that why this Lenin is required then I will come to the Lenin and then again we'll try to create uh again basically we'll try to Define the lenen and all uh by using the python we'll try to uh use the lenen or different different like a component of the Lenin like memory chain agents and all and yes after that I will try to create one application okay so here uh basically we'll try to create one application and with that uh definitely we'll be able to justify the knowledge whatever actually uh we are going to learn regarding this llm open lenion by using uh that by creating that particular project and after that I will uh come to the advanced part Advanced part like uh Vector databases uh we'll try to discuss about a different different Vector databases and first of all we'll try to discuss the need of the vector database that why it is required what is the meaning of the embedding uh how we can uh like uh save the embedding how we can retrieve that and how this a vector database this a vector database plays an important role whenever we are going to create any application related to this llms okay so there we'll try to discuss about the vector databases and then I will come to the some open source model so uh first of all I will come to this uh llama uh and I will discuss about the Llama indexes what is the Llama index and we have a like couple of Open Source model which is a very very famous so we'll try to talk about those model as well like we have a llama to itself we have a falcon we have a bloom there are various model and we'll show You by using those model how you can create uh like a how you can create your end to and application uh you can solve any sort of a task just take a name don't worry I will give you the detail overview about the NLP and all that what all task does exist what all task basically we have what all task we can solve by using this llm each and everything we'll talk about and then finally we'll create one more end to endend project there we'll try to uh use the entire knowledge uh whatever we are going to be learn uh like this Vector databases different different open source model and a length CH open a llama indexes and finally we'll try to deploy that model by using the amops concept so did you uh like this syllabus yes or no please do let me know guys please do let me know in the chat if you like the syllabus yes or no the agenda is clear to all of you if you can write it down the chat I think uh that would be great great so I can see many yes in the chat and many people are saying yes they are able to get yes don't worry we'll give you the PPT and all each and everything will be there in a uh resource section so from there you can download this PP you can download this entire thing whatever I'm uh like I will be using throughout the session yes uh so fine I got a confirmation now uh the first thing uh many people are asking the prerequisite what will be the prerequisite if you are starting with this committee session so prerequisite wise uh if you have a basic knowledge of the Python if you have a basic knowledge of the Python if you know about the core python uh in a core python actually we have uh uh like a ifls for Loop and uh different different type of data structure and the knowledge of the database exception handling if you are uh if you know about the basic python the basics of python then definitely you can proceed with this go along with that if you have a like some basic knowledge about machine learning and deep learning so you will understand uh the concept basically whatever uh like we are going to teach you in a better manner in a better way because here I'm not going to talk about the classical uh ml or the basics of the deep learning like uh artificial NE Network CNN and all definitely I will give you the overview about the transfer learning fine tuning and all but here uh uh I won't talk about the neural network and this recurr neural network lstms and all so uh if you have a basic understanding of machine learning and uh deep learning so definitely you will understand the concept in a very well manner otherwise basic python knowledge is fine for creating application basic python knowledge is uh like fine okay so you no need to worry about it uh whatever thing actually I need to explain you definitely I will do that uh in the class itself and uh we'll do the live implementation I'm not going to show you any uh prewritten code and all uh definitely I will write it down each and everything in front of you only got it so prerequisite is clear so prerequisite nothing just a python or uh I can write it down over here basic knowledge basic knowledge of ML and DL if you know this much then definitely uh like uh you will be able to understand each and everything in a well manner great so yes we'll talk about the RG approaches and all each and everything diffusion model is there there are some recent model in l each and everything will talk about and you will be capable so uh let's say if you are working in your company or maybe you are trying to switch into the generative AI or maybe you are fresher in every uh case right so this community course will help you definitely if you if you are going to attend every session if you are going to learn along with me definitely you can build anything after learning all sort of a thing got it great so I think uh this uh introduction is clear to all of you now I already discussed about uh about the dashboard and all so uh I given you the walk through of the dashboard so link you can find it out inside the chat inside the chat and from there itself you can enroll now the syllabus is clear dashboard is clear each and everything is fine so I think we can start with the introduction of generative AI generative Ai and llm because from today's on uh from tomorrow's onwards I I will be like move to the Practical part and there I will be talking about the open a how to generate a open key how to use the open API and uh we'll try to understand the chat completion API functional API and uh we'll try to understand the concept of the token also that what is a token uh like how many token should I use whenever we are giving any sort of a prompt what is a different different prompt template and all there are lots of thing which we need to understand so today's session actually it will be uh like completely introduction session and in this particular session uh we'll talk about the generative Ai and the history of the large language model so guys uh are you ready can I uh get a quick yes in the chat if you are ready then yeah definitely we'll talk about the uh like use cases of the generative and all u in today's session itself I will like give you that uh particular idea that where you can uh utilize this generative AI in a real time yes definitely this course content and all whatever you are seeing over here this one definitely it will be available over the dashboard as well so this is our dashboard we'll update it over here inside the course syllabus section so each and everything uh like uh we'll try to update in the dashboard itself here is a class timing and all and uh I will make sure that the uh the link also okay so uh we are not going to uh we are directly streaming over the YouTube so directly you can uh join through the YouTube so for that you just need to subscribe the channel and you will get a notification in that case great so people are saying yes sir we are ready ready ready great yeah definitely Wy we'll try to discuss the applications and all and uh I will explain you all the thing and that uh specific way only don't worry we are going to build AI application by using the AI tools AI based application great so I got uh many yes in the chat now I think uh we can start with a uh with the introduction of generative Ai and the LM so guys uh first of all tell me that how many of you you are uh you have started with the generative Ai and all already means uh you have learned something at least you have learned the basics in all uh so if you can write down the chat so that would be great means you are starting from very U like a scratch or you have some sort of idea great so many people are saying uh so some people are saying they know about the basics and some people are saying uh they're starting from the scratch don't worry so uh basically I will start from the scratch only now here guys uh you can see I have created One PP for all of you so let me uh first of all let me go through with this particular PP and later on what I will do I will again I will give you the revision by using this PP only and in between I will use my Blackboard also for explaining you some uh Concepts and all so here is my Blackboard so here I will be writing down uh the whatever basically thing I need to explain you and in between I will be using the ppds and all so first of all let me go through this particular PP and here you can see so uh I have written some sort of a name uh so in the generative AI whenever we are talking about the generative AI or a large language model so couple of name are very famous nowadays and in in those name actually this chat GPT is a uh like very very famous so here I have written this chat GPT it's a product of the open AI as we know about this Chad GPT everyone knows about the chat GPT yes or no I think yes now if we talking about this Google bar so it's a product of the Google and we talking about this meta llm 2 so this meta llm 2 it's a product of the Facebook got it guys yes or no so yes uh nowadays actually everyone using this chat GPT Google B meta lm2 is it it's also a platform similar to this chat GPT uh where you can uh chat or where you can ask a specific question which you uh which you do in a chat GPD itself So Meta lm2 it's a a model from the Facebook site now here guys if we are talking about the generative AI or we are talking about the large language model so in our mind the first image which comes into the picture that is a chat GPT Google B and meta llm 2 yes or no tell me guys yes because of that only uh because of this chat GPT Google B and like the other the different like whatever application you are seeing nowadays right so mid journey is one of the application or maybe Delhi uh or different different application because of that only I think you are learning this uh particular uh thing this particular course this generative AI course yes or no yes so but guys this generative AI is having their own Roots it's not all about the chat jpt Google B and some other uh application which you are seeing chat jpt is just a application of this generative AI chat GPT or this Google B is just a application of this uh like llm large language model basically we are using this large language model in a back end U like whatever application you are seeing like chat GPT and all in the back end but apart from this this generative Ai and this llm is having their own Roots so first of all what I will do I will explain you the concept of the uh like first of all I will uh start from the deep learning itself means I need to explain you few uh terms and terminology regarding this deep learning so let me uh back to the Blackboard so there I will be talking about the basics of the deep learning So within uh 5 to 10 minutes I will be discussing the types of the neural network and all and then I will directly move to the uh like LMS and this uh genem so here guys uh you can see uh what I can do I can uh draw one box over here so this is the uh you can think this is what this is the neural uh uh basically if we are talking about the okay so first of all let me start from the deep learning itself so uh if we talking about a deep learning so uh we can uh divide this deep learning into three major segments so let me write it down over here this a deep learning so guys this deep learning actually we can divide into three major topic so the first topic actually which is called artificial neural network artificial neural network netork the second topic is called convolution neural network CNN the third one basically which is called recurrent neural network so we have a three types of the neural network and we can divide this a deep learning into this three major section apart from this you will find out other uh like topics as well so let me write down those uh thing over here so the fourth one uh which I can write it down over here that is a uh reinforcement learning and uh the fifth one we generally talk about it uh so that is what that is a gain so this gain also it comes under this generative AI I will talk about it I will talk about this game I will like give you the glimpse of this uh generative advisal Network that what is this and how the architectures look like of this gains and why I'm saying that this gains comes into the generative AI so if we talking about thisn so let me draw the box now so if we are talking about this n so here guys see we have an input layer inside this Ann actually what we have we have a input layer and uh you will find out the output layer and in between actually in between this input and output we have a hidden layers so just a wait now over here guys see we have a input layer and we have a output layer now in between actually you will find out a hidden layers various hidden layer so let me write it down over here input and here you'll find out the output now here in between this input and output you will find out of various hidden layers so let me write it down the hidden over here so this hidden layer actually it is nothing it's a hyper parameter so we can have as many as hid layer we can have as many as node inside the hidden layer we all know about the artificial neural network I'm assuming that thing now if we talking about this uh CNN actually so the CNN is nothing so in the CNN uh one more thing you will find out in terms of this CNN that is what that is a convolution we always perform the convolution in terms of this CNN so here if we are talking about this enn so uh we are using the uh like structure data where we have a like different different features numeric feature or categorical feature and uh we try to solve the regression and classification related problem but whenever we are talking about this CNN so here uh the CNN actually specifically we use for the image uh related data image or video related data you can say that uh we use the CNN and all for the grid type of data okay so we use the CNN for the grid type of data and there uh like you will find out one more component that is what that is a convolution so here uh let me write it down so the component name is what component name is a convolution so in the convolution actually you will find out a various step so uh we have a various step in the convolution itself so the very first step which we perform what we do guys tell me we perform the feature X section by using a different different filter after that what we do we perform the pooling and then we flatten the layer so there are different different like uh uh steps you will find out inside the convolution itself and after that what we do we apply the fully connected layer so that is nothing that is my Ann itself so over here I can write it down we have this convolution and we have a artificial neural network so this is my first architecture which is a like uh which is the Ann itself and and this is my second one that is what that is a CNN now if we talking about the third one which is a very very interesting that is called recurrent neural network that is called recurrent neural network so this enn we generally use for the structured data where we have a numerical column or categorical column and in the Target column like it will be a numeric or categorical one and based on that basically we are going to decide whether it will be a classification problem or a regression problem now if we talking about this CNN so already I told you if you're talking about this RNN so the name is what the full form what the full form is the recurrent neural network so this RNN actually we are using for the sequence related data so wherever we have a sequence wherever we have a sequence so this RNN we used for the sequence related data now let me do one thing let me draw the architecture of this RNN so over here guys in the RNN what you will find out so let's say this is my uh box and here is what here is my input so this is what guys tell me this is my input now here is what here is my output so let me draw the output one more time this is what this is my output got it now here guys see uh this is my input this is my output and this is what this is my hidden layer now in the hidden layer actually you will find out one thing one concept and the concept is nothing the concept is called a feedback loop okay so whatever output I'm getting from the hidden layer actually again we are passing that output to hidden layer until the entire time stem so that thing actually uh we learn or we learn in in the RN itself actually this RNN is nothing it's a special type of neural network and there you will find out the feedback loop feedback loop means what so whatever output we are getting from the hidden layer again we are passing the same output to the hidden layer until we are not going to complete the entire time stem that is what that is the RNN now uh you are uh we are talking about the llm so why we are uh why I'm discussing this RNN and all because this llm actually somehow it is connected to this RNN itself before starting with a llm a large language model we'll have to understand the concept of the RNN lstm attention uh like encoder decoder and then attention self attention and all so here I'm not going to discuss in a very detailed way I'm just giving you the glimpse of that that what is a like RNN what is the lstm what the Gru and then what was the sequence to sequence mapping and where this attention comes into a picture then how they have invented the self attention then how they started the using this transfer learning and this finetuning in terms of this uh in terms of this large language model why we are calling it is a large language model why we are not calling it a model okay so each and everything we'll try to discuss now uh you all know about this uh reinforcement learning and all so in the reinforcement learning uh you will find out one agent environment regarding that particular agent you will find out a different different state getting my point and then you will find out the feedback so that actually it comes inside the reinforcement learning and that is also part of the deep learning only now if we are talking about gain so gain is uh nothing actually so in the gain again you will find out a neural network uh which we are using for generating a data and that also comes in under inside the generative Ai and we have a different different types of game so first of all tell me guys uh this uh uh like types of the neural network this is clear to all of you please do let me know in the chat if uh this thing is clear then uh I will proceed with the next topic use cases wise I will come to the use case and I will uh try to discuss a different different use case I will come to the use case then I will tell you the applications of that and then I will come to the domains as well then in what all domains you can apply those use cases so don't worry each and everything we'll try to discuss over here yes I will directly come to the generative a itself but before that I will give you the timeline don't worry from Tomorrow onwards I'm going to be start uh I'm going to start from the uh like uh from the open ey itself uh like complete practical and all so no need to worry about it s Prasad I think you got your answer I think uh this basic introduction is clear now yes coming to the generative only don't worry yeah it's going to end to end uh we'll try to discuss end to end thing don't worry about it if you have any questions and all so you can directly ping into the chat uh so I will reply to you don't worry okay so I think now we can proceed so guys here uh in the uh PP itself I was talking about the generative AI then I given you the uh like uh uh the types of the neural network and I just explain you the uh like the regarding the artificial neural network and the CNN and this RNN so here in the generative AI uh you'll find out that I have like included a few slides and all so let's try to understand a few uh thing from here and then again we'll go back to the uh the Blackboard and then I will try to discuss few more concept so over here uh we have seen the chat GPT like I was talking about the different different application like chat GPT Google B and metm and all now let's talk about the generative AI that what is a generative AI now here you can see the definition of the generative AI uh which I have written over here uh that is what that a generative AI generate new data based on a training sample right so the name is uh the name is selfexplanatory right so the name is explaining everything generative AI the AI which is generating something now what all thing we can generate so here if we are talking about the generative AI so you can generate images you can generate text you can generate audios you can generate videos as a output you can generate anything uh so uh this image text audio video it's nothing it's a type of the unstructured data and definitely it is possible by using the generated AI we can uh generate this type of data by using the generative AI now if we are talking about the generative AI so uh as I told you that it is having their own Roots okay so it is having their own roots and if we are going to divide this generative AI so we can divide into two segment so the first segment is called generative image model and the second segment is called generative language model and this llm actually it falls into this particular segment into this generative language model are you getting my point yes or no I think yes so if we talking about this generative image model so I told you when I I was talking about the Deep learning uh like Ann RNN and CNN reinforcement learning and there was a gain so initially we were using the gain for generating a data so let me show you the architecture of the gain so the how the architecture of the game looks like so with that you will get some sort of idea in the game we are using this uh neural network only so let me show you the architecture of the game so let me search it over here over the Google game architecture now uh here in the image uh let me open the architecture of the game so here guys uh just see so in the gain actually we have two main components so the first component is a generator this is what this is a generator okay so uh I think this is visible to all of you this is what this is a generator and here you will find out discriminator so this generator and discriminator is nothing it's a neural network so we are passing this real data so here basically what we are going to do we are going to pass a real data and here we have a generator which is generating some sort of a uh like synthetic data and here we have a discriminator based on that we are going to discriminate between real data and the synthetic data so this is the architecture of the game and inside this architecture you will find out we are using two main thing we are using two main component the first one is generator and the second component is a discriminator I think you're getting my point and this generator and discriminator is nothing it's a neural network got it so this is also comes under this generative AI so now let me show you this generative AI now over here I have written two points generative image model and generative language model so if you're talking about generative image model so in our previous days in our back back days actually in our old days in 2019 18 so this gain was very popular for generating a data again uh this gain is very uh like EXP uh like expensive in uh terms of computation power and all so it is very like very much expens uh like expensive in terms of like uh computation uh so over here you can see so we were using this gain uh we were using this gain for generating images and all in our back days in 2018 and in 2019 and it was very very popular and we have a different different uh variants of the Gams if you'll find out the type of the gain you will find out many types now uh recently actually you will you have find out the trend of the llm large language model now guys here uh we are uh we are talking about the game and then uh this gain basically it was the old concept it is a old concept basically and there are different different variants of the gain as well now over here if we are talking about this large language model so it become very famous from the Transformer I will come to the Transformer I will tell you the complete history of the Transformer as well now uh this image model and this language model but a recent days in a recent days what I have seen in terms of this llm and all even we can generate the images by using this llm we got those llm basically which is like that much powerful so by using those particular llm we can generate generat images as well okay so we I will show you couple of models and all uh regarding this uh like image generation and definitely you will get some sort of idea that how the uh those part particular alms is working in terms of image generation I can give you a couple of example uh like Delhi so Delhi is a example you can uh check over the open a which is a model which is like a uh like a famous for the image generation now here uh if we are talking about this image model so actually see this image model basically it was working for image to image Generation image to image generation now this generative model actually so if we are talking about this generative model it is working Tech uh it is working in terms of text to image generation text to image generation and text to text generation so this two tasks definitely we can perform by using this llm model and this image to image generation before we were doing it by using this gain model in 2018 and in 2019 now uh as I told you that we have those powerful model in our recent Days by using those particular model definitely we can Implement image to image generation as well that is also possible so uh regarding that uh definitely I will show you couple of model so we are having four tasks here I have written it now let me move to the next slide and let me show you that what I have so here guys you can see uh this cat is representing a genitive model where you are giving a prompt uh means where you are giving a question and uh as a response U again as a output basically you are getting a response so in terms of uh see here we are talking about generative model I'm not talking about specifically this El M okay so I told you this uh generative model actually uh you can think it's a super set this generative Ai and under this generative AI you will find out this llm and gang is also part of the generative AI getting my point I think this thing is getting clear so over here we are talking about the generative model so we are giving a input and we are getting a like output now specifically if I'm talking about regarding this llm regarding this large language model so this input actually this is called input prompt and the output actually it is called output prompt so this cat you can imagine as a generative model or as a llm model so what we are passing as a input we are passing input prompt and we are getting as a output output prompt so this prompt term is a very very important I think you have heard about this uh prompt engineering and all that uh uh like uh prompt engineer is getting this much that much and this prompt engineer plays a very important role if uh we have to design any sort of of a prompt now uh different different types of prompt of like zero short prompt few short prompt few short learning and all we'll talk about it as I will progress with the like implementation and all in between I will give you like idea regarding each and everything now over here guys you can see uh where this generative AI exist so if you will look into the uh look into through this particular slide so here you will find out this generative AI actually it lies inside the Deep learning getting my point so the generative AI actually it uh like reside inside the Deep learning uh initially only I have explained you that uh we have a different different types of neural network and it's a part of the deep learning only now whether we are going to generate an images by using the llm or by using the gains or whether I'm going to perform text to text generation text to image generation or image to text Generation by using the llm both lies inside this generative Ai and this generative AI is a part of the it's a part of the tell me it's a part of the deep learning now over here guys I have written a couple of more slid so I will try to explain you uh but first of all let me give you the timeline of the llm and then I specifically I will come to the llm and all and I will be talking about this discriminative Ai and the generative AI as well so tell me guys uh this part is clear are we going good are you able to understand whatever I'm explaining to all of you so if you are getting it so please write down the chat and you can ask me the questions as well if you have any uh type of Doubt or U like if you're getting it or not getting it whatever you can ask me in the chat uh like chat section uh I will reply to your questions no reinforcement learning is not required uh uh specifically we should not go for the reinforcement learning and all yes this is a part of the uh like this Genera way is a part of the deep learning right right yes llm model used in a generative AI correct you got it uh guys mathematical intuition so we will talk about the mathematical intuition and all but this uh more uh this course this comp session is it is more focusing on the applied side so I will create a various application in between whatever math iCal concept and all will be required I will let you know that don't worry great so I think uh people are getting it and uh they are trying to understand fine so whatever I have explained you let me explain you the like Blackboard uh and then again I will come to this PP and we'll try to uh wrap up the theoretical stuff and U then I will explain you the applications and all so over here guys see I was talking about this Uhn CNN RNN RL and G now I started from the generative AI itself so I have started from the generative Ai and I told you this generative AI is nothing you can consider it as a super set as a super set now inside this generative AI you will find out many uh like uh many uh concept many topics and all so here uh regarding the generative AI there is uh two main thing which you will find out the first one is gain gain that is a generative aders Network the second is what llms llms large language model now we have a various task so here let me write down the task as well so the task wise so here I told you the different different task basically so the first task which I can write it down over here that is a image to image Generation image to image generation now the second task was the uh image to text uh text to text generation text to text generation text to text generation now the third task was the uh image to text Generation image to text generation and the fourth one was the uh image to image generation sorry uh text to text Generation image to text and text to image generation so let me write it down over here text to image generation text to image generation now if we are talking about this image to image generation yes we were able to do this particular thing by using this gain we have seen the gains now we are talking about this text to text generation yes it was possible by using the lstm RNN and the uh different different by using the different different model as well but yeah this text to text generation actually nowadays you are seeing uh we are preferring this large language model for this text to text generation and you this chat GPT is a biggest application uh biggest like example for that the chat GPD which we are seeing image to text generation yes uh this is also possible by using a different different model like RNN lstm and Gru image captioning if you have if you uh if you have heard about this uh like image capturing task so that is also possible uh by using this uh like uh classical model but yeah by using this llm also we can perform it we can uh do it now if we are talking about this uh text to image generation so yes uh this type of task nowadays it is possible by using the uh llm so yes yes uh llm is able to do llm is able to perform a various amount of task uh whether it's a homogeneous or it's a hetrogeneous now uh I was talking about the uh llm uh sorry I was talking about this generative AI so where it exists so this generative AI actually it exists uh in a u like a deep learning itself so you can think that AI is a superet machine learning is a subset deep learning again is a subset of the machine learning and this generative AI is a subset of the deep learning because as I already told you we have a different different uh like other neural network also in a uh like a deep learning and this CNN is one of them this a convolution neural network okay so I think this part is clear to all of you now let me draw the architecture uh that where this uh generative AI exists so you can think this is what this is my AI this is one uh this is the like a super set now here this is what this is my machine learning this one now uh inside that you will find out the uh deep learning and inside the Deep learning you will find out this generative AI uh so let me take a different color over here uh let me take uh this color so here you will find out the generative AI so this is what this four circle is what this is the generative AI got it now here uh you can see why we are saying so why we are saying this is a like a subset so I think each and every explanation I have given you over here uh you can uh prefer this uh like a this particular slide that why I'm saying this generative AI is a subset of the deep learning so let me write it down over here this is what this is nothing this is a gen Ai and it's a subset of the deep learning now guys let me explain you the timeline of the uh this llm so uh now you got it that this uh llm is nothing it's a part of the generative a itself this large language model now let me talk about the complete timeline of this large language model so how it evaluate and uh uh I can like talk about the complete history of it and uh here guys you can see that first I was talking about the RNN so as you know that uh what is the RNN tell me RNN is nothing it's a type of the neural network it's a type of the neural network so uh there basically we have a feedback loop again we can pass the information to our H layer now you will find out a different different types of RNN or some Advanced architecture in terms of this RNN itself El the second uh like thing which is a type of the RN itself that is called lstm lstm right so in the lstm actually uh if we are talking about this lstm so here you will find out the concept of the cell state so in the RNN we just have a Time stem and it is for the shortterm memory it is for the shortterm memory we cannot retain a longer sentences by using this RNN it is not not possible if our sentence is a very very huge or it's a very very long so we cannot retain that particular sentence by using this RNN but if we are talking about this lstm yes we can do it by using this lstm so in this lstm you will find out the concept of the cell state so uh this uh lstm is nothing it is for the shortterm dependency and it is for the longterm dependency also it is for the short like a memory shortterm memory and is for the longterm memory as well if you look into the architecture of the lstm so you will find out along with this uh time stem so here we have the time stem U like it's a hidden State actually uh like on a different different time stem along with that you'll find out one cell state so it is going to retain it is going to retain the longterm dependency and in between in this a time stamp in this shortterm memory and in this cell State you will find out a connection the connection in terms of gates so here you will find out one connection uh like uh one gate basically that is called forget gate so here I can write down the forget gate now here you will find out one more gate actually so that is called input gate here you are passing the input now here you will find out one more gate over here that is called output gate output gate okay so we have three gates inside the lstm for sustaining a longterm dependency or for reminding a longterm uh long sentences now uh you will find out one more updated version of the lstm so this RNN is a old thing this lstm is also old thing now you will find out one more updated version of the lstm that is what that is a GRU so this Gru actually they have invented in 2014 and they had they took the inspiration from the lstm itself now inside this Gru you won't find out the concept of the cell State everything is being done by the hidden State itself and here basically in the gru we just have two gate update gate sorry reset gate and update gate and it's a uh Advan or you can say it's a updation on top of this lstm it's a updated version of the uh like lstm itself now what is the full form of the gru G and recurrent unit now over here guys see this was the three architecture which was very very famous during 2018 and 19 in our old days now here see uh one concept comes into the picture if we are talking about this RNN lstm and Gru so by using this particular architecture what we are doing so by using this particular architecture we are going to process a sequence data yes or no we are going to process a sequence data now here one concept comes into a picture sequence to sequence mapping and for that only we are using this particular architecture so we have a different different type of uh like a mapping technique so let me write it down over here uh different different type of mapping technique uh now it is fine uh I think I'm audible to everyone now now I am audible guys please do confirm in the chat I think there were the issue from the mic side now I'm audible so please do confirm in the chat if I'm audible then and uh is there any Eco or uh what so guys are you facing any Eco in my voice now it is fine yeah it is perfect I think great fine fine fine uh it's clear great uh I think now I am audible to everyone sorry I think there was a issue from the do let me know in the chat uh from where I lost my voice so this concept is clear this one to many or one to one one to many many to one many to many yeah so I think uh I was there RNN lstm and Gru now I think it is fine I'm audible to everyone great so I was talking about RNN lstm Gru and then U I talked about the different different mapping sequen now uh this mapping sequences actually we can Implement by using this uh RNN lstm and Gru so over here uh yes so 1 to 1 one to many many to one many to many RN and LSM and Gru this was the sequences actually I was talking about now in 2014 actually see this was the sequences by uh we can Implement by using this different different models getting my point now over here uh if we talking about this particular sequences definitely we can uh like uh per we can uh create a various uh application by using this model but here basically we are having some sort of a restriction uh as I told you the different different application like one to many many to one so many to one means uh you can think that sentiment analysis one to one to many means what one to many you can say image capturing many to many image uh sorry uh language translation so there are various application of the sequences now see uh we are talking about the sequences uh the sequence to sequence mapping now uh we can definitely implement it by using this particular architecture so the problem we were having the problem was actually uh we cannot see let's say we are giving an input in the input actually we have a five words so whatever output we'll be getting in the output also we should have a five words so it's a fixed length input and output getting my point what I'm saying so by using this particular mapping 1 to one many to one or like many to many specifically we are talking about many to many so there was some problem there was some issue the issue was fixed length input and output so whatever number of inputs we are passing in terms of this many too many I'm talking about okay so whatever number of inputs we are passing so those many output on we can get it over here in the output itself so uh here actually one a research paper came into the picture in 2014 you can search about uh the research paper sequence to sequence learning so inside that uh paper they have introduced the concept of the encoder and decoder in the encoder and decoder actually the one segment the one segment was the encoder segment segment so let me uh draw it over here so the one segment was the encoder segment and the another segment was the decoder segment this another segment was the decoder segment and in between actually in between we were having in between actually we are having the context Vector so here uh in between this encoder so we are having the encoder and we are having the decoder decoder one part was the encoder and one part was the decoder and in between we having the context Vector means whatever information was there whatever information was there from encoder to decoder we are passing through this context Vector means we are wrapping all the information in this context vector and we are passing to the decoder that actually the paper uh has been published in 2014 you can search about it you can search over the Google sequence to sequence learning so let me uh search in front of you only now over here I can write it down sequence to to sequence learning research paper now uh over here guys you will find out this uh particular research paper now just try to read this paper now here in this particular paper they have clarify the issue that what was the issue with the classical mapping so that was restricted to the input and output now over here you if you will read this particular research paper so easily you can find it out the issue here itself in the like introduction itself they have mentioned they have mentioned this uh despite their flexibility and power can only be applied problem who inputs and targets can be sensibly encoded with the vector of fixed dimensionality it was just for the fixed dimensionality and basically there was we were having a limitations so for solving that particular limitation this a sequence to sequence learning paper came into the picture and there was three person Ilia sasar and orol and this there was one more person and this paper from the Google side now here guys uh let me open this uh Blackboard again so there was a context Vector but this uh encoder and decoder also was not able to uh perform well for the long uh longer sentences so here in the research basically they have proved if my sentence is going uh is going uh like above from 30 to 50 words right if it is longer than 30 to 50 words so in that case it was not able to sustain the context it was not able to sustain the context if we are using this encoder decoder architecture now you will ask me sun what we were having inside the encoder and decoder so we are talking about the encoder so again here we were using the either RNN lstm or uh lstm and we were using this Gru and here also in the decoder also we are using this rnl we are using the lstm and we were using this Gru got it I think you got the problem now and you got to know about the encoder and decoder so we have started from the RNN then now we came to the lsdm Gru and then we have a different different mapping and for solving this particular issue which is related to this many to many uh like uh mapping many to many sequence mapping and this uh uh this language translation is one of the example if you will search over the Google translate uh just search over there anything let's say in the in H you are saying that or whatsoever so it will generate output so this input word and output word will would be a mismatch but that was a restriction with this uh like with the classical mapping so for using this encoder and decoder architecture we can solve that particular problem now here also we are having the issue that we cannot proceed a longer sentences we cannot proceed a longer sentences so here One More Concept comes into a picture inside this context itself and that was the attention that was the attention so uh here neural translation with just a second let me search about the neural trans TR a NS relation with attention yes this was the paper and uh this was the first paper let me search about the research paper yeah now guys uh this was the paper in this particular paper they have introduced the concept of the attention and just try to download it you need to download this particular paper and uh then you can see there so just a second let me show you this paper as well and this is the main uh like main papers uh basically which you will find out uh while you will be learning this deep learning and all so this paper actually this has been introduced in 2015 I think in 2015 or 16 now here they have introduced the concept of the uh attention actually so just try to read uh this particular paper at least try to read the introduction of it uh there we have uh there they have defined that uh what was a problem with the encoder and decoder and where this attention comes into the picture and what is the actual meaning of the attention they have introduced each and everything over here inside this particular paper inside this particular paper they have introduced each and everything regarding the attention see this is the architecture of the attention model and uh before going through with any blog any website or any tutorial try to uh go through with the research paper and try to understand the motive of that research paper now see guys uh here I'm not going into the detail of the attention because this attention itself uh is a longer topic but I can uh like give you the glimpse of that that uh uh what what they were doing in the attention so they were mapping so let's say we have a five words in the sentence so they were trying to map each word whatever word we have a input we were trying to match each each input word with the output word means this input and output this encoder and decoder if we are talking about this decoder actually so this is having the uh information each and every information of the Hidden State whatever like in the encoder like you will find out this RNN lstm or whether it's a GRU so uh we have a hidden State actually right so uh this decoder part is having the information regarding those particular hidden State all the hidden State and because of that it was able to uh it was able to predict so whatever like sentence and whatever words or longer sentences or like U like uh the longer sentences and all which uh whatever basically we were passing it was able to predict okay so this word is related to that particular sentence so what I will do I will create a like a one dedicated video on top of it there I will try to discuss uh this attention mechanism but yeah here I'm just giving you the timeline U and with that um you can clearly understand so uh here we were having the attention mechanism now guys by using this attention mechanism by using this attention mechanism in 2018 Google again Google published one research paper and the research paper name was attention about this encoder in the encoder and this decoder we were using what we were using guys tell me we were using this LSM either we are using the lstm RNN or maybe Gru now uh there also we are having the lstm maybe RNN or maybe you are having the Gru and uh if we are talking about the attention so whatever uh information we are passing from here to here so you are having the context Vector context Vector now on top of that we are having the attention layer attention layer and it was nothing it was just a mapping from input words to out output word now here actually they have published one paper in 2018 and the paper name was attention all your need attention all your need now this paper actually it was a breakthrough in the NLP history this paper has been published in 2018 and here actually decoder but there is one uh there is one thing basically in terms of this encod and decoder you won't be able to find out this lstm RNN and Gru they are not using any RNN cell any lstm cell or any Gru cell so here actually they were using something else and here the what is a uh name of the research paper so they were saying that attention all your need only attention is required for generating us let's say we are passing any sort of an input means any longer input so from that particular input only attention is required for generating output now how let me show you that this Transformer architecture or let me show you the attention all your need research paper so attention all your need research paper so guys this is a very uh prestigious paper in our NLP history and uh this changed the complete history of the NLP and whatever llm and all whatever you are seeing like nowadays so they have used this Transformer architecture as a base model I will come to that and there I will try to uh discuss that uh what is the encoder and decoder again I'm not going into the depth of the mathematics but yeah definitely I will try to give you some sort of a glimpse so over here uh let me zoom in first of all this paper and and here guys the paper name was attention is all your need so this was the researcher asish Nome Nikki Jacob you can uh search about these particular people and here is the abstract uh you can see and this is the introduction at least try to read the introduction try to read this particular background and the model architecture so this was the model architecture which has been introduced by the uh by the Google researcher and the architecture basically which you will find out inside this research paper I think everywhere you will find out this uh this particular architecture in uh whatever NLP tutorial or if you are going to understand the attention mechanism and all so this is the architecture now in this particular architecture let's try to understand that what all things we have so see first of all we have a input okay try try to understand try to focus over here so we have a input over here then we have a input embedding so this is my first thing input and this is what this is the input embedding the third thing which we have that is a positional encoding getting my point and then after that you will find out the multiheaded attention then we have a normal uh normalization and all and then we have a feed forward Network now guys just tell me this is what this is a encoder part this is what this is a encoder part and this is what guys this is this is a decoder part this is the decoder part got it getting my point so here also we have a two segment first was the encoder and the second was the decoder but here we are not using any RNN cell lstm cell or maybe Gru cell here actually we are using something else some other concept and the concept actually I think this is not a new thing for you this embedding and all uh this embedding attention already I talked about the attention that what it is mathematically it is having a like uh like a some different explanation but yeah I think you got to know the idea now here we have a feed forward neural network you know like what is a like artificial neural network what is a feed forward neural network so it's not a like a new thing for all of you and by assembling all those thing they have created one cell one architecture and the name is called this uh Transformer so this architecture itself is called a Transformer what is this guys tell me this is a Transformer now here guys just see uh this uh Transformer if we are talking about this Transformer and all so let me uh tell you few things regarding this Transformer uh so first of all guys this is a uh fast compared to the classical architecture if we are talking about this RNN lstm and all so there we are passing the input based on a Time stem based on a Time stem but if we are talking about this Transformer guys so here what is the importance or what is the like plus point which we have inside the Transformer it is a faster why because we can pass the input in a parallel manner we can pass all the inputs all the tokens in a parallel manner in a parall actually we can pass the input now over here see we have a input embedding we are doing an embedding over here and then we have a positional encoding means we are arranging a sequence sequence of the sentence then we have a multiheaded attention again we are trying to uh figure out the uh meaning see let's say uh the sentence is what I am Sunny now uh here it is trying to find out the relation I with M and sunny is trying to find out the relation M with uh this I and sunny it's time to find out a relation this sunny uh and this m and this I so it is trying to find out a relation with each and every word so it is doing the same thing inside the multiheaded attention then you will find out this feed forward Network neural network actually and yes uh this is what this is my encoder part as I told you this is what this is my encoder part now if you will look into the decoder side so again we have a same thing so here we have a outputed output embedding means in uh uh like whatever uh like a sequence uh in whatever like U am format I want output so that is uh this particular thing this output Ting and then again we have a like multiheaded attention and we are passing this thing uh to the next one to the next layer and again we have a feed forward neural network over here on top of this you will find out the soft Max and finally we are getting a output output probability so don't worry I will try to discuss this Transformer architecture mathematically in a detailed way in some other video but as of now I'm just giving you the GL Glimpse because whatever llms we are going to discuss okay as a base architecture they are using this Transformer so guys until here everything is fine everything is clear please do let me know in the chat yes or no yes you can uh let me know in the chat uh then I will proceed with the pp and all and uh we'll try to wrap up the uh introduction of this llm and all and in tomorrow's session we'll try to talk about the open a and we'll discuss about the open API and all and a different different models of the openi any doubt anything so if you have any sort of a doubt please do let me know guys please do let me know in the chat uh I will try to clarify that uh those doubt and uh so did you get a timeline timeline of the llm I will come to the llm now the specific word and uh after deep learning an NLP what is the topic uh for generative AI please give up uh so after the Deep learning and see after the Transformer actually by using this particular Transformer people has created a different different llms and all large language model now I will come to that by using the slide I will try to show you that I think this is pry much clear now let me go back to this uh uh notes and here you can see so I started from the deep learning then generative VI and all then you got to know that where generative a lies then Alm Gru different different mapping encoder decoder attention and finally attention all your need now let's try to understand uh like rest of the thing by using the slide so here guys uh one more thing I think we were uh trying to understand this particular part where this generative AI exists and I hope you got a clearcut idea now let me go back to the uh let me like come to the next slide so in this slide you can see uh I'm talking about the generative versus discriminative model so what is the difference between this generative and discriminative model so we are talking about this discriminative model so whatever you have learned so far in a classical machine learning and deep learning so uh let's say uh I'm I'm talking about this uh any classification based model let's say I'm talking about this uh RNN so here actually see uh you are training your model on a specific data so this is your data this is your input and here is your output what you are doing guys tell me you are performing a supervised learning you are performing a supervised learning by using this recurrent neural network there is a classical model or we have like other classical model and all you can use any uh uh like a machine learning based model as well like na buers and uh different different variants of the nap bias or maybe some other model you can uh use that particular model also uh so over here we have a model and we are going to train this model by using the supervis machine learning there we are going to pass a specific type of data to this particular model and here we have a different different output like a rock this music is belong to the rock music classical music or maybe ranting so here we are passing this uh like music to my model and finally it is going to predict something like that this is a descriptive model now if we are talking about a generative model so this is a little different compared to this discriminative model how it is different uh compared to this discriminative model so here guys see we are training this see first of all the if we are talking about the generative model if we talking about the generative model so the training process is a little different if we are talking about the large language model if we are talking about the llms so uh the proc of training this llms is a little different compared to this discriminative model now over here we are talking this discri this generative model basically so we are passing the input to this generative model and we are getting an output how how so here basically we have a different different step for Gen for like training this generative models so gain wise I already told you that what is a like process if you want to like train uh any gain model if we are talking about llm large language model so at the first first place there will be unsupervised learning unsupervised learning then at the second place we'll be having a supervised finetuning and at the third place uh basically we have a reinforcement learning reinforcement learning they have recently used inside the chat uh in the GPD model itself uh which we are using for the chat GPD but before that whatever llm model they have created they have created they have trained on a large amount of data so for that first they have performed the unsupervised learning and then they have performed the supervised fine tuning so because of that that model were able to understand each and every pattern which was there inside the data and because of that it was able to generate the output so this generative model is nothing in that basically we have a data on top of that particular data we are training a model and for that we have a various step and uh basically then only we are going to do a prediction so what it is giving me as a prediction so whatever input we are passing so that input it is taking and finally it is generating uh the output related to that particular input means it is generating a new data getting my point I think this part is clear to all of you how this generative model is different from this discriminative model discrimin model is a classical model like supervised learning uh we are performing The supervis Learning now right so here we are having the RNN and we are passing a data and all and we are trying to train it generative model various step we have like for the training and all and it is responsible for generating a new new data that's it so I hope guys this uh thing is clear to all of you now I have kept couple of more slide regarding uh this particular concept just try to note down the uh the headings and all and try to remind uh this particular thing this discriminative versus generative model and all now here uh the same thing unsupervised supervised learning which is related to this uh discr model got it and here uh you can see uh this is the generative like model so in the generative model what we do first we perform the unsupervised learning we are doing a grouping and all and then we discri we perform the supervised finetuning supervised learning so that is a like process for training a uh like any sort of a llm model which comes under inside the generative AI itself and again wise I already talked about it now here actually uh we're going to talk about this uh llm so let me give you the quick idea about this llm and all that is what that is a large language model so for that all Al I have created one slide and there specifically I kept the thing related to this uh llms only so let me start from the very first slide uh let me give you the overview and uh from tomorrow uh actually in tomorrow session I will give you the detail uh like overview uh with respect to different different models and all whatever we have as of now just a quick introduction now what is the llm so llm is nothing it's a model it's a large language model which is trained uh like U it's a large deep uh it's a large language model which has been trained or a huge amount of data and it is behaving like it is generating something right so actually by using this uh llm we can generate any uh like a sort of a data like Text data or maybe image data and that is a like uh that is a advantage or that is a like uh uh one uh very uh like a very famous uh thing regarding this llm and all now if we are talking about this why this is called llm why this is called large language model so here guys if we are talking about this large language model so because of the size and the complexity so here specifically I have mentioned regarding this large language model regarding this llm why this is called this uh this large language model so here because of the size and because of the complexity of the neural network uh neural network neural network as well as the size of the data set uh which has has been uh which is trained on actually this is trained on the huge amounts of data because of that only actually it is called a large language model so here uh if we are talking about this uh L large language model so uh actually before we were not having the huge amount of data so uh recently actually uh you know uh this uh data generation and all uh Big Data actually came into the picture and this companies and all generated a huge amount of data and this Google also Google Facebook and the other companies is having a huge amount of data so uh they uh they are able to like find uh means uh actually they have uh gathered that particular data and on top of that data they have uh like as I told you they have performed the unsupervised learning and all and they have categorized a data and they have provided to a different different model which U like has been created like GPT B and all and because of that uh like they were able to predict the next next sentence and that is a like a main thing main advantage of this large language model now over here you will find out so in the next slide uh I have mentioned that what is the what makes llm so powerful so here by using one single model by using one single llm actually we can perform a different different type of task like text generation chatboard uh we can create a chatboard also we can uh do the summarization translation code Generation by using a single LM we can do that particular thing now here uh if you will find out so already I told you that what is the base architecture of the llm so here this Transformer is what it's a base architecture behind this llm behind this large language model and I have already explained you the concept of the uh Transformer that what we having inside the Transformer now here guys uh this is a few Milestone which we have in terms of the llm like bird is there I think you know about the bird if we are talking about the uh we are talking about the like a bad days right or old days in 2018 19 or 20 when uh chat GPD was not there just uh this uh GPT was not there GPT 3.5 and all the recent model which we are using inide of chat GPT so there were few Milestone and we were using this thing in our old days like B was there GPT uh actually GPT is having a different different variant it is having a complete family GPD 1 2 3 and 3.5 and recently GPD 4 came into the picture and other variants as well so xlm is also there uh cross lingual language model pretraining by uh this particular guy now T5 was also there this a text to text transfer text to text transfer transform Transformer and it was created by the Google Now Megatron was also there so Megatron actually it was created by the Nvidia now M2M was there so it was the part of the Facebook research so there were many uh like uh there was the uh like many model actually actually okay and this was a milestone in uh this uh in terms of this large language model now over here guys see this bird GPT xlm T5 they are using a base architecture as a Transformer one only now if you will see in the next slide so I have categorize this thing so they are using a base architecture as a Transformer one only but in that you will find out some of the model are using a encoder and some of the model are using a decoder and some of the model are using both encoder and decoder now here I have categorized this particular thing that uh this is the model like B Roberta xlm Albert Electra DTA so these are the model they are just using the encoder only and if we are talking about this decoder uh if we are talking about the GPT GPT uh 2 gpt3 GPT new or like the entire family of the GPT so they are using this decoder so we have a two segment of the Transformer architecture few of models they are using an encoder side encoder part and few model basically they are using a decoder and uh here guys you will find out some model which is which are using both encoder as well as decoder so this T5 Bart M2 m00 Big B so these are the model actually they are using both encoder and decoder in the Transformer architecture if you'll find out we have a two segment so this is a this segment basically this one is called an encoder segment and this particular segment this is called a decoder segment so here uh like I think you got to know uh you got to know the idea that uh this is what this is a like uh transform this is the encoder segment and this is what this is a decoder segment and this model this T5 B M2M and big but they are using both and we have other models as well I just written this uh couple of name over here now apart from this you will find out some openi based model open a based llm model so GPD 4 is there GPD 3.5 is there GPD based is there Delhi Biser iddings okay so these are the different different model which you will find out over the open website itself and uh here uh definitely GPT is uh one of the prestigious model or this is one of the very important model which uh people are using uh nowadays for creating their like applications and all and it is it can perform any sort of a task related to a generation okay now over here uh this is the openi based model which I have written now apart from this you will find out other open source model so this is the model from the openi side so if you are going to hit this model so definitely open is going to charge you regarding the tokens regarding the uh regarding like how many tokens and all whatever you are using according to that it is going to charge you but here we have some couple couple of Open Source model as well and I have written the name like Bloom Lama 2 Palm Falcon Cloud amp okay stable LM and so on we have a various model various open source model and uh yes but I I will show you that how you can use this particular model if you are going to create your application so definitely I will let you know I will show you that how you can utilize this model as well I will show you the use of the Falcon I will show you the use of the Llama 2 if you don't want to use this GPT uh GPT 3.5 GPT 3.5 turbo I will show you the use of this llama and this Falcon and some others open source model as well I think you are getting my point now here uh if we are talking about what can llm be used for so if we are talking about llm that what it can do so it can uh we can use this llm for any sort of a task like classification text generation summarization chat board question answering or maybe speech recognization speeech identification spelling character so this uh llm actually uh if we are talking about this L LM so first of all it's a model it's a large model U it's a language anguage model and it's a large model it's a large language model and what is a like what we can do by using this large language model we can generate the data okay it can identify the pattern of the data it is having that cap cap uh that uh that much of capacity so it can identify the pattern from the data and by using those pattern we are we can perform a various amount of task okay that's why this llm is too much powerful and here we can use this llm for any sort of a task and yes uh we know about this it and already I have uh like I explain you this thing I hope this introduction is clear to all of you now coming to this uh prompt design so prompt design and all uh definitely I will talk about it uh once I will come to this open a API there will try to hit the uh different different models of the open a and uh we have a different different type of prompts so as as of now you can think that the prompt is nothing whatever input we are passing to the model uh that is called input prompt and whatever output we are getting from the model itself that is called the output prompt and here how cat GPD was trained so generative of pretraining supervise fine tuning and this reinforcement learning there was three step which I have mentioned so I will be talking about this also and not in today's session in the like next session uh I'll be talking about this uh how CH GPT and all it was stained uh okay now what I can do so over here guys uh I think uh we should uh conclude the session so how was the session please uh do let me know in the chat it was good bad or what so did you uh understood everything did you understand everything whatever I have explained you uh regarding this uh regarding this llm and this generative AI the complete introduction because uh I want that before starting with any sort of a practical the basics should be clear everything did you understand amazing great to what is the topic yes fine uh if you have any doubt and all so you can ask me I will try to answer for that now before concluding with uh like uh before concluding the session let me show you few more things over here so see uh here first of all what you need to do uh first of all you need to like uh go through with the open a and you need to generate a open a API and all so that uh basically don't worry I will show you while I will be doing a practical and all so you need to like at least you need to create an account and uh and you need to login it over here so so once you will log in guys here you will get two option first is chat GPT and the second is API just go through with this API and generate this API key generate the API key from here don't worry in the next session in the next class again I will show you this thing and here I see we have a different different model so let me show you those model and whatever open source model and all is there so you will find out over the hugging phase so let me show you the hugging face models hugging face Hub and uh here you will find out the model Hub so guys uh here actually we have a model Hub just a second yeah models now you will find out a different different type of model see these are the models which is a open source and uh uh you'll find a complete description let's say this uh we are talking about this Orca 2 so this updated 12 days ago and it's a recent uh llm model uh which has been published uh by the Microsoft now over here you can see so it like you will find out the complete description or complete detail regarding this model and like uh how to use it and uh each and everything basically definitely we'll talk about it now for what all task basically we can use it okay so according to that also you can uh like select the models so just go through with the hugging phase models and there you will find out many uh like a different different models okay and yes for sure openi is also having uh different different llm model so we'll talk about that we'll try to understand the concept of this uh we'll try to understand this uh assistant actually and we'll try to talk we'll try to understand the chat U actually so what is this and how to use it how to use this chat option and this assistant option and here if you will go inside the documentation so you will find out of different different models over here this GPT GPT 3.5 Del TTS whisper embedding moderation GPT W gpt3 right right different different models we have and uh apart from that you can find out the different different task according to that also they have given you the model so text generation so they have given you the complete code and all so just try to visit it just try to go through it uh by yourself now uh we have other uh platform as well so if you are not going to use the uh maybe J uh if you don't want to use this uh GPT and all so here uh I can show you one more uh like option so AI 21 okay so AI 21 Labs AI 21 Labs so this is the Recently I figured it out actually this is the uh like alternative of the GPT so we'll talk about this also if you don't want to pay to this uh if you don't want to pay for the GPT so you can use this AI 21 lab uh and it will give you the uh like a uh one model one llm model so you can use it uh like freely actually it gives you the $90 credit so so yes I will show you how you can use this AI 21 lab uh so let me show you the documentation and let me show you the models as well so here you will find out the uh model basically which is there so Jurassic 2 is a model and it's like a pretty amazing model and uh uh yes definitely I'll be talking about it and along with that uh the applications of it which is very much required that for what all task we can use it whether if you are going to create a chat board or maybe if you are going to do a question answering or text generation or like sentiment analysis for what type of task we should use it and how to design a prompt and all regarding the specific task got it so we'll talk about this also so uh yes many things is there and definitely uh uh like from Tomorrow onwards I'm going to start from the open a lure and step by step I will come to the uh different different models and all so I hope guys this is uh clear yes practical implementation will be there don't worry yes recording will be available over the YouTube yes all the uh all the topic will be covered in the upcoming session uh all the discussed topic and all yes definitely this will be available in the dashboard you can go and check uh your dashboard this uh video along with the video you will find out the assignment you will find out the quizzes and regarding the particular topic fine I think uh we can conclude the session now is gener andm are also used in computer vision based project so for computer vision based project we have a uh like others model we have a different models uh because uh the task is different over there so the task wise we are talking about the computer vision related task like object detection object segmentation tracking OCR object classification and for that we have a different model and definitely we can use a transfer learning of finding over there now uh by using this L llm um like this llm is for the like a different task it is related to the language related task it is not related to that detection or a segmentation or tracking it is not related to that particular task it is related to the language related task and uh here see let me show you one uh one more paper one more research paper so here I can show you this uh ULM fit now see uh so just try to go through with this particular paper universal language model find tuning for text classification now here in this particular paper you will find out that see uh this uh if you know the Deep learning so in the Deep learning we have uh two major concept so the one one concept is uh called transfer learning transfer learning the second concept is called fine tuning F transfer learning means what so you are transferring the information from uh from one state to another state okay or like you can I can give you very simple example for that let's say you know like how to how to write the cycle so for you like for if you know how to write the cycle definitely you can use that information and you can write the motorcycle also so that is the same thing basically which we uh do inside the transfer learning let's say we have trained the model uh like let's say we are talking about the computer vision so inside that uh you'll find out uh we have a various Tas like detection classification tracking and all so let's talk about the model let's say YOLO so or we have other model also like faster rcnn rcnn and all SSD SSD and all like a different different model related to a detection so the model already has been trained on some sort of a data some amount of data on some Benchmark data so by using that particular information we can uh like perform the detection and all for our specific task if we are not able to do it then definitely I will finetune my model but how we can use the same thing in NLP because in NLP actually we have a task uh the task is very specified we have a specific task let's say we are talking about um if we are talking about a task let's say uh ner name entity recognization or let's say we are talking about the task let's say a language gener language translation language translation language translation or maybe sentiment analysis so these are the specific task specific task ask means regarding to the specific uh regarding to the specific topic let's say if I want to do a sentiment analysis so not for the entire data whatever there in the world for the specific uh let's it for the Twitter data only means whatever TW tweets and all we are getting now if we are giving any other data un any other like a task related data so it won't be able to perform that so actually in this particular paper you will find out that how we can use this uh language model language model for uh like for the universal task and there only this llm comes into a picture L this llm actually it came from the language model itself okay because we are training this uh language model on a huge amount of data that is why it is called llm large language model because we have we have trained this data on a huge amount of we have trained this model on a huge amount of data got it so here in this particular paper they have like shown you that how to use this transfer learning because uh in before 2018 uh actually we were using this transfer learning in the computer vision only in the uh like in a different different tasks of the computer like object detection or segmentation you will find out the image data so on top of that data we have trade like a Ben model and directly like like vgg rset and all and directly we are using those particular model for our like a other task so here if we are talking about the NLP so we are not able to do it before this Transformer and all so actually see we got a Transformer we got this particular concept like how we can use this transfer learning and all in the like NLP field so this two concept came together transfer learning and the architecture like Transformer self attention and all and from there itself this uh llm came into the picture llm means large language model which has been train on a huge amount of data which is able to perform the transfer learning and we can do it uh we can find T it also and the main uh like uh the main cap or the main uh role of the llm is what it is able to generate a text text generation got it so fine I think we are done with the session now so rest of the thing we'll try to discuss in the uh tomorrow session and we'll try to more focus on the Practical side so all the recordings and all it will be updated on a dashboard and uh yeah that is it yes so I think uh we can start with the session now so yeah uh welcome again again uh so you all are welcome in this uh Community session generative AI Community session uh yesterday we have started this uh generative AI Community session where we have discussed about the generative AI so there I have given you the introduction related to the generative Ai and large language models and here you can find out the video so this is the dashboard uh it's a free dashboard actually uh which we have created for all of you the same video actually it is available over the Inon uh YouTube channel as well if you we will go in a live section so this uh same video you can find it out over there as well now uh let me show you uh that particular video so here is my YouTube now let me search over here I neon and here guys uh go inside this uh live section and this is the video so the same video same lecture you will be able to find out inside the live section apart from this uh the same uh thing basically we are uploading or the in neuron dashboard and here along with the video you will find out the resources so all the resources basically whatever I'm using throughout the session uh so whatever notes and all which I'm writing and whatever PPS and all or whatever code file I'm using throughout the session you will find out all the resources over here got it guys yes or no so do you have this dashboard do you have this dashboard tell me I think uh many people are androll yesterday uh for this free community session and yes all the videos and all basically we are going to upload over here not even video and resources along with the video and resources you will find out the uh live uh you will find out the quizzes and assignment as well so already uh I have prepared the quizzes and assignment so soon it will be uploaded over here so in this particular video you will find out one more section so the section will be quizzes and assignment so there you will find out a uh like uh a video related or a topic related quizzes and assignment got it yes or no so please uh give me a quick confirmation in the chat if this uh dashboard related thing and this uh video related thing is clear to all of you I'm waiting for your reply in the chat and if you have any sort of a doubt then you can ask me in the like chat section as well and don't worry my team will give you the link of the dashboard so if you haven't enrolled so far so uh by using that particular link definitely you can enroll it you can enroll U inside the dashboard great all clear all clear great fine so here I got a confirmation now uh so let's start with the session let's start with the uh second day so in the first day actually so what I discussed I discussed about the generative AI so where I have like told you that what is a generative AI so this is the slide basically which I was using and here actually this was the agenda the complete agenda which I going to discuss this uh throughout this committee session and uh today is the second day where I will start from this open AI so in the previous session I was talking about this generative Ai and I discussed each and everything related to this generative a and I hope you got a clearcut idea that what is a generative Ai and in the generative AI actually what all things comes into the picture where llms lies so if we are talking about this large language model so regarding the large language model also I have clarify each and everything I have given you the complete timeline of this large language model where I have discussed about the uh the complete history of the large language model from the RNN so first I have started from the RNN then I came to the lstm then uh I discussed about the uh different different sequence to sequence mapping I talked about the encoder and decoder and after that I have explained you the me uh the concept of the attention and then I have discussed about the attention is all your need uh the Transformer architecture and I told you that whatever llms which you are seeing nowadays so those uh all the llms are using Transformer as a base architecture so I have explained you the the like whatever thing was there inside the Transformer architecture whatever component whatever segment was there each and everything I have discussed over there and apart from this generative AI I have talked about this llm also so there I have talked about that what is a llm why it is called large language model and uh why it is so powerful because this one uh because this one llm is able to perform lots of like task lots of uh one basically llm we can use for the different different type of application so here uh I have written the couple of name like text generation summarizer translation or code generation and so on we all know about the chat GPT uh chat GPT is are application and uh chat GPT is using gpt3 gpt3 is a a base model so GPD 3.5 actually it's a base model so how it is how much it is powerful we all know about it and that is a example of the large language model which is capable to do so many things why because uh it is having a power so so that actually it can generate a it can generate a data based on a previous data it can understand the pattern and because of that only we are able to trans we are able to use this Transformer as a or whatever like Transformer based model we have we are able to use those transforma based model as a transfer learning I have explained you the concept of the transfer learning and the fine tuning as well so here I was talking about this llm and then I talked about the few milestone in a large language model so here I have written couple of name bird GPT xlm T5 Megatron M2M so these are the uh like a few milestone in a large language model now this model has been trained on a huge amount of data now specifically we are talking about GPT so in a GPT Family itself you will find out of various model I will talk about it it I will come to the open Ai and each and everything I will keep in front of you only and uh I will uh I will show you that how much it is powerful so we are talking about GPT so it's like really powerful and it it has been trained on a like huge amount of data and it is having a billions of parameter so here is few Milestone so in our back days in our history basically we are using this particular models now in a recent day we got so many uh architectures so many uh open source models and so I will talk about uh regarding those model as well so here in the next slide I have shown you so what all encoder based architecture we have what all decoder based architecture we have if we are talking about anod and decoder right so in which architecture you will find out both encoder and decoder if we are talking about B xlm Electra DTA so these all are these all the architecture actually it is based on an encoder we're talking about this GPT GPT family so it's a based on a decoder itself and the idea has been taken from the Transformer itself now here you can see this T5 Bart M2M big but so these are the model which are which is using this encoder and decoder both got it so now here uh then I talked about the openi based llm model so here uh the very first thing comes into the picture that is a GPD itself GPT 3.5 which is a like base model behind this chat GP chat GPT just a application it's not a model now here you will find out this Delhi whisper DCI there are many model I will be coming to that particular model and I will show you how you can get all the model from the opena itself and uh yes we'll try to use those model for our task for our like a uh for the for our like a like a requirements and all definitely will try to use this particular model like GPT GPT 3.5 I will show you how you can use GP 3.5 turbo viso da in or other model as well like aming and moderation so apart from that this apart from this uh like uh Milestone whatever Milestone I shown you and this openi based model here you will find out some other op Source model like Bloom llama 2 Palm is a model it's a very famous model from the Google side nowadays like most of the people are using this pal Falcon is a model cloud is there MP 30 uh MP is there uh this B actually it is showing a parameter right and here we have a stable Im so a stable LM so there are like so many open source model so I will come to that also and I will show you how you can utilize those particular model and apart from that I have like kept some more slight over here inside this particular PP so you can go through with that and you can understand some other uh like concept like how this chat GPD has been trained and all so I hope guys still here everything is fine everything is clear now we can move to the Practical part so please do let me know in the chat if everything is clear so far in terms of theory guys I'm waiting for your reply uh just a wait so let me give you the link of the website and uh yes guys I'm waiting for your reply so if you can confirm in the chat uh uh like everything is fine or not so that I can proceed with the Practical stuff yeah definitely this uh PP is already there so just try to enroll in this course the dashboard Bic basically which we have created this is our dashboard which you will find out over the Inon website so just try to log to your Inon website first of all if see if you are a new person so what you need to do you need to sign up after sign up uh you will login and after login you will search uh regarding this dashboard so here actually what is the name of the dashboard so the name of the dashboard is generative AI Community Edition so just click on this dashboard and here after clicking on this dashboard you it will ask to you whether you want to enroll or not so yes uh you will click on the enroll and it is completely free so it won't ask you any sort of a money and after enrolling into this particular course uh you can get the videos and you can get the resources as well so all the resources we have uploaded over here inside this resource section got it clear great so I think everything is fine everything is clear now let's start with the uh let's start with the Practical implementation so first of all guys uh let me clarify the agenda that what all thing we are going to discuss in today's session so for that what I'm going to do I'm going to open my Blackboard and here I will try to explain you each and everything uh like what what whatsoever we are going to like cover in this particular session so let's start uh let me write it down all the thing step by step now first of all I can write it down over here a day two Community session and then I will begin with the topic so here guys are day two of the community session now uh yesterday actually I I talked about the introduction part I talked about the introduction of the generative Ai and the llm now today I will be more focusing on the open a so here I will be discussing about the open AI so first I will give you the U like a complete walk through of the openai website of the openai documentation after that I will come to the openai API that how you can use this open API how you can use this open API and this API we are going to use by using this python so guys if you you know python so definitely uh like uh you will be able to write a code along with me uh and don't worry I will show you how to do the entire environment setup and all each and everything I will try to uh I will try to do in front of you uh from very scratch so uh you all can do along with me now over here I will come to this openi API and there I'm going to use Python and we have couple of more option like nodejs on all so if you are familiar with the JavaScript or maybe some with other language so in that case also you can use this openi API after that I will uh I will come to the openi playground so here uh they have given you very specific feature or very uh like uh very interesting feature that is what that is a openi playground so over here I will explain you that uh how you can use a different different model how you can uh like pass a different different prompts and how you can generate output how you can set up your uh like a different different uh sentiments and all regarding the system that okay so my system should behave like this or that so each and everything I will explain you over here and after that what I will do I will show you the chat completion API so I will use this chat completion chat completion and by using this chat completion actually uh we can call the GPT model so whatever uh like uh we can call the like openi API and uh with that definitely we can use any sort of a model like a GPT model or any other model so first I will uh start with the openi API we'll use we'll be using a python over here and I will show you how you can generate the openi key and after that I will come to the playground and assistant and then chat completion API and then I will explain you the concept of the function call function call now this is the agenda for today's session this is the agenda for today's Community class now before starting with the openi I will uh I will explain you that why openi is this much important why not other other like things or uh if we have like a other competitor of the openi that why we are not using that instead of this open ey and if we are going to use that then how we can do that okay and one more thing I would like to explain you over here so along with the open a I will uh talk about the hugging face so see over the hugging face actually hugging face is has provided you one uh hugging face hub for all the models so there you will find out all the open source model so directly you can generate a hugging face API key and you can utilize all sort of a model whatever is there over the hugging face Hub yesterday I have shown you that let me show you again uh that particular Hub so guys here once you will write it down so over the Google so once you will search uh once you will write it down hugging face model Hub so there uh you will get a link and you just need to click on that so here you will uh and then basically it will be redirecting to you to this particular model Hub now here you will find out all the open source model from a different different organization so yesterday I was talking about this Ora 2 now here you will find out other model as well like whisper large V3 now from the Facebook side there's a seamless okay now here you will find out other model as well so see from The Meta side there's a lamba Lama 2 so I will show you how you can utilize these particular model for the different different tasks according to your requirement getting my point so we will not restrict it uh we will not restrict to ourself to the till the open ey itself apart from that we'll try to explore few other model few other open source model and yesterday actually I have shown you one more platform and here's the platform AI 21 studio so it it gives you one model this Jurassic model so we can utilize that particular model also and this all are called large language model this IDE this thing is clear to all of you yes or no so uh what is the difference between hugging face and open AI so open AI is a different organization hugging face is a different organization and over the hugging face Hub see uh if you have heard about this Docker or this GitHub so first of all let me show you this GitHub so if I'm searching about this GitHub so here actually over the GitHub you will find out uh like see this is my GitHub and uh you all have the GitHub ID right you all have log to the GitHub and all and first you sign up and then you log in and whatever course and all you are having and definitely you are going to upload it over here uh in terms of repository now let's see if I if I have to find out something so what I will do here let's say if I'm going to write it down GitHub machine learning uh linear regression so GitHub machine learning machine learning linear regression so here if I will search uh like this then definitely I will get a link and here you can see so it has suggested me one repository and you will find out uh this uh code and all whatever code and all has been uh uploaded by this particular person and definitely you can download it and you can use it similarly we have a Docker Hub similarly we have a Docker Hub so let me show you the docker Hub so the docker Hub actually you will find out all the images and all so let's say uh like uh you downloaded Docker in your system you did setup and all now uh you don't want to install it from scratch you want to run it by a Docker so yes there is a Docker Hub and there you'll find out different different images and all so you can uh like uh you can pull that image and definitely you can run it inside your container so similarly we have a hugging face Hub there uh like it is uh it it is going to provide you a different different model actually on a single place so yes uh just uh you just need to log in over there and after that you need to generate a API key and directly you can use those particular model whatever is there like over the hugging face Hub now similarly we have openi it's other another organization so yes by using the openi API we can access the open a model as well so here uh okay so if you will find out if you will see to this open a this one this is the open a right now I will show you what all models this openi is having it is having a different different model various model I will come to that I will show you from very scatch so till here everything is fine guys everything is clear so uh just give me a quick quick confirmation so that I can show you the entire setup related to this opena API and we can run a couple of uh couple couple of line of code as well so please do let me know in the chat if uh everything is clear so far yes we'll talk about the fine tuning and all so how we can uh do the fine tuning regarding a different different model uh it's not a like easy task it's a a very expensive thing so we'll talk about it yes hugging pH model are free yes correct for building a model uh so for using uh if you want to use that particular model so either I can use open a so or else I can use hugging phase see whatever model is there over the hugging for definitely we can access that but let's say open a is having there uh like a uh it's a separate platform right so whatever model is there over the open a so we'll be able to access those model only from the open a not all the model which is there inside the hugging face also but hugging face actually is having all the models open source and all whatever model is there and some of the model from the openi side as well but openi actually it's a specific specific one specific organization clear yes or no so please do let me know if uh this thing is clear to to all of you so that I can proceed with the uh next part next section great so people are saying sir it is clear clear clear okay great yeah the model is already created over the hugging face and open ey they already trained the model we don't have all the models in the ging phase that's why we are learning this open great so I think uh all the thing uh like each and everything is clear to all of you now let's start with the uh like uh next part of this session so here I have uh discussed about this open Ai and this hugging phase and I clarify the agenda that what all think we are going to discuss but before starting with the open AI so let me give you the a brief introduction of the open AI that why this open AI is too much important so for that what I did I have created one small PP so with that actually you will get some U uh some basic idea uh regarding this open AI so here uh let me start uh let me start the slideshow so over here guys you can see about the open if we are talking about the openi so what is the openi open a is leading company in the field of AI it was founded in 2015 as a nonprofit organization by same Alman and Elon Musk as we know about the uh founder of the like open a so yes uh I think we are we are aware about uh with this particular names right same Alman and this Elon Musk and it has founded in 2015 as a nonprofit organization just for the research purpose now here in the next slide I have kept the name so he's a like he's a CEO of the open a Sam Alman and uh yes I think you know about the Sam Alman he was fired by the open board we'll talk about that also what what might be the reason behind that so we will discuss about that uh as well now over here you can see uh openi founded in uh 2015 and the company founded with the goal of developing and promoting friendly AI in a responsible way that was a logo of the open AI so with the focus on transparency and open research and he was the and they are the founder member of the like open a so Elon mus Sam Alman Greg Brockman okay this guy is a like great researcher and vak and zon so these are the founder founding member of the open AI now over here are open goals so there are some goals of the open related to the AI and all now openi Milestone so I was talking about that why this openi is too much important why not other does because if you will look into the market there are other uh there uh there are you will find out other organization as well uh so we have a Google and Google is having their separate Department Google uh AI research and all so Microsoft is also having their own department for the AI research even meta is having that even IVM so all the like big big giant so there they are having their own research uh like Department related to this Ai and all and they are working on that and they were working on that actually but why this openi is too much popular and why we should start from the openi itself so you know about the openi in 2020 actually they have launched the Chad GPT and guys believe me it was the Milestone and it was the major breakthrough in the history of the AI because before that also we are having so many llm model and it was able to do uh some sort of a thing but not like to not similar like to this GPT this GPT actually the GPT model which is a backbone of this Chad GPT application uh it was a a breakthrough in the history of the NLP and because of this this open AI came into the Limelight and uh apart from the GPT then uh uh like they have shown or they have released the other different different research so here here I have written couple of name basically so generative model is one of the Milestone of the open now apart from that you will see that they are going to uh they are going to participate in the robotic research and all and here uh like other uh like other few more thing basically so solving uh robic Q with a robot hand and here multimodel neurons and artificial neural network you can search about uh this particular things and yes uh this open ey actually it become uh very uh important uh basically because of this uh like GPT and all because of this uh chat GPT application and yes they were using a different technique for training this uh GPD model which we are using for the chat GPT and the idea from where they took the idea uh for training this GPT model there we have unsupervised learning we have a supervised learning and we have this reinforcement learning so they took from the ULM fit research paper yesterday I have shown you that which has been published in 2018 and in 2019 in 2020 actually they have released this GPT GPT got it now here you can see buildin with open AI API so these are couple of name getup copilot keeper Tex Bible dingo so these are some application which is using this openi API and apart from that you will find out so what is the openi vision so the vision is like uh promote a friendly AI in a way that benefit all the humanity and all so this is a vision of the openi now feature so chat GPT Delhi whisper alignment so so these are the feature of the open AI Chad GPT is a a milestone Delhi is also there Delhi 2 recently they have they have released the Delhi 2 whisper is uh one of them whisper actually it is a very good model for generating a transcript and all so whatever like text we are giving or whatever like videos we are giving to this particular model it is able to generate a transcript from that and here uh alignment is there startup fund so these are some feature of the open AI now guys uh before starting with the open AI API I think got enough amount of idea uh regarding this open AI yes or no please do let me know in the chat if uh this part is clear so I will proceed with a uh open a API so how you can generate a key and all and how you can utilize that yes are you getting guys whatever I'm explaining you over here uh if you have any sort of a doubt anything so you you can ask me in a chat section I will reply to all of your doubts so step by step we'll try to proceed uh and uh so each and everything will be clarified great so clear yes waiting for your reply uh if you can write it on the chat so then I will proceed what is the learn tool what is the aim to learn open AI so that I can utilize the same capability same AI capability in my application whatever model has been trained by the openi so that I can use the same model in my application for a different different task great so I think I have uh discussed each and everything related to the open a now this is the website of the openai so if you will search openai definitely you will get a website of that so in the website itself they have mentioned everything so latest update whatever uh latest update and all it is there so they are mentioning over here and Sam Alman return as a CEO of the open a I think you know about this controversy of the open a so let me uh give you some sort of a glimpse of that uh if you know about the open a so it was founded as a nonprofit organization but uh in 2019 actually they have uh started with their uh forprofit organization as well if you will search about the four profit organization of for profit organization of this open a so in 2019 actually they have started this a for profit organization and uh it was doing uh lots of work uh regarding this Ai and all and they collected uh like uh funds from different different companies and all from a big big giants and uh they were working on the G GPD model itself okay now after that uh this chat GPD has been released and in 2022 actually 2022 or 23 basically so uh they started work on a uh like a different type of project so the project name was the qar the uh basically the project name was the qar and it was more specific to it was more specific to towards this AGI so may I know guys what is the full form of the AGI if if you know uh the full form of the AGI so please write it down in the chat what what do you uh understand with this AGI so the full form of the AGI is please write it down in the chat if you know about the full form of the AGI please do it yes artificial Journal intelligence correct so the full form of the AGI is artificial Journal intelligence actually see we talking about the chat GPD now this particular application it's not it is not representing a general artificial intelligence it is a restricted one it's a specific one getting my point so let's say there one side there is a Chad GPT and one side there is a human so definitely this Chad GPD can answer in a better way it can generate answer in a better way compared to this human but still it is not like a human so still we are not on that particular level where we can achieve a artificial intelligence like a human that is called artificial general intelligence and the project name was given by this openi the project name was the qar and that was happening in the forprofit organization this is the subsidiary of the open itself getting my point now because of that uh so there was a conflict in between the board member and uh this uh Sam Alman was fired and now again he joined the company uh there is a long story story but yeah I have given you the Glimpse you can search over the internet and you can uh read about it U okay so if you like to read the AI news and all AI related news news and all so definitely uh you should check it on a daily basis because on a daily basis there's something is happening on a teex side on a like organization side uh whatsoever so over here guys uh here you can see the open a website now if I will scroll down so you will find out each and everything over here itself that what all research is there uh what all upcoming models is there uh on whatever applications they are working so each and everything actually you will find out over here itself so here uh recently they have released this Delhi 3 so in October uh 20123 3rd of October 2023 they have released this Delhi 3 there was a GPD 4 gp4 Vision where we can uh upload the images and we can do a lots of lots of task related to the images and all getting my point so here you will find out a research whatever latest research is there from the open a side no need to go anywhere everything you will find out over here itself if you want to start from the open a if you are using this open a in your organization if you want to use it and before that if you want to explore it so please go through the website and here you will find out each and everything now guys here is a question I told you that why uh what is the open a now why we are learning it I have to give you the specific answer of this particular question if you will ask me S why we are learning this open a what is the main Aim so now let me tell you that so first of all guys after opening this opena website what you need to do you need to log in it you need to log to this particular website and here you will get two option so the first option is a chat GPD and the second option is a API so we all know about this chat GPT I think uh we all have used this chat GPT and I think we are using it on a daily basis now we are not going with this chat GPT we are going with this API so I will click on this API option and once I will click on this API option so I will get this type of interface so I believe guys you all are getting this particular interface after clicking on this API please do let me know in the chat if uh everything is uh uh like going fine uh like me so please do let me know in the chat great so yes I think uh people are doing along with me now see guys here is what so here is a uh like open a API uh so once you will click on that you will get this particular interface now just uh overover your mouse left hand side and here you will get a different different option or various option now what you need to do guys for here first of all you need to click on this documentation so just click on this documentation and you will come to this particular page now here you will find out this overview so here they have given you the complete overview about the openi API that what all things they have and uh for what all applications we can use this openi API now here you will find out the introduction section as well so in the introduction section they have defined some sort of a thing related to a different different task like text generation aming assistant tokens and all now here you will find out the quick start so let's say uh you want to explore this open API so what you will do at the first place so after opening this open uh a openi API and after opening this after opening this particular documentation you just need to click on this quick start so after clicking on this quick start you will get all the code which initially you need to run inside your system getting my point if you want to use this open API if you want to use this openi API and you want to run the code if you want to start then for that what you need to do you just need to click on this quick start and over here you will find out uh different different option so let's say you know the nodejs so here you can click on this nodejs and you will find out entire setup related to this nodejs how to install the package how to uh set the key and all now here you'll find out the different different uh like Windows different different operating system related option and here you will find out the code snippet so directly you can run it and you can use it now if you are a python lover if you know the python only in that case yes they have given you the option so you just need to click on this uh Python and here you will find out the complete setup guide so how to install a python how to install how to create a virtual environment how to install this openi Library so and after that you will find out this uh setup openi key uh regarding this Mac OS and windows now here you'll find out how to uh request to your openi uh API how to request to the different different models so here is a code snippet so we are going to use this particular process uh if uh so yes you can use the same process don't worry I will show you how you can do the entire setup and all and how you can call the different different model now over here you will find out a model now guys this model actually this model is a uh like a very important part of the openi API now here they have given you the various model like GPD 4 gp4 Turbo G PD 3.5 Delhi is there TTS is there whisper is there iding moderation GPD 5 is there GPD 3 which is a legacy now and here you will find out some deprecated model so here they have given you some a deprecated model like uh GP 3.5 Turbo with this much of tokens and here you will find out this text Ada Ada text weage text cury text DaVinci so these are the depricated model you can use it if it is required definitely you can use it so here you will get a complete list of the model whatever model you want to use for your task for your particular task now over here uh this is the uh like overview regarding the model now if I'm clicking on this GPD 3.5 so once I will click on this GPD 3.5 so here I will get a complete detail regarding this particular model now here is a what here is a model name so what is the name of the model GPT 3.5 turbo 1106 okay now over here you will find out two things so the first is what context window now in the context window you will find out the number of tokens now guys this tokens actually the number of tokens displays a very very important role if we are talking about this tokens so really it plays a very very important role and I told you if we are giving an input to our model to our LM model so we'll give in the form of prompts and prompt is nothing it's a collection of token so whatever input and output we are getting we are getting in the form of prompts right so we are giving a prompts to our model and we are getting a prompts from our model and this prompt is nothing it's a collection of tokens now we'll talk about this tokens and all then how much token is uh so as a return actually how much token you can get as a output as a free one actually this uh Chad this open a actually it stopped the free services now so before actually uh uh you would be getting this uh let me write it down over here so $20 of credit so earlier if you have used this uh open a so you must have seen that uh if you are uh like uh if you are going to create a open API key so in that case it was giving you this $20 free credit now they have stopped this particular service now they are not giving to you so first of all what you will have to do so first of all you will have to add the method a payment method actually so so you will have to add your credit card or debit card details and after that you will have to set your limit let's say $20 $50 $100 or whatever uh like limit um actually you find out it is fine so inside uh in that basically in that particular limit uh my work will be done so first of all uh you need to add the payment method and you need to set the limit and then only you can use this open API so recently they have updated this particular thing now we have alternative also so we have this AI 21 lab so I will uh show you this uh thing as well where we have a Jurassic model and it gives you the $90 fre free credit $90 free credit but you won't be able to use this GPD 3.5 because it is only it is only available in this opena itself if you want to use this GPD 3.5 model GPD 3.5 turbo or gbd4 so it is only available in the opena itself and they haven't open source it and for this one you will have to pay if you want to use it in your organization in uh with respect to your task so definitely you will have to pay for that getting my point now over here guys see uh it return return a maximum of 4096 output token so regarding this particular model now here you can provide this much of tokens actually so this much of tokens as a uh input as a input basically and you will get this much of token as a output if you are going to use this particular model now here GPD 3.5 turbo So currently point to GPD 3.5 turbo 0 613 will Point GPD format turbo 11 starting date this is this is the starting date and here this is the token size now here this is the token size basically they have given to you so you can uh provide this much of token and here you will be getting output in uh like as uh this is the maximum token size actually uh with respect to this particular model so you can go and read more about this model and all and here you will find out this training data so this uh model has been trained up to 2021 SE number 2021 and here uh these all are the model so I will uh use any sort of a model from here itself and I will show you how you can hit it by using this P openi python API now apart from that uh you will find out some other uh thing so let's say if I want to do a text generation so they have given you the complete detail regarding that and here they have given you the API endpoint as well so you can click on that and here in this particular way actually you need to write a prompt and all you need to define a prompts and all uh so actually this is the uh rate assistant uh as of now it is not working so you can click on that or you can use it this API endpoint inside your application so uh here they have given you the code that if you want to perform this particular task this text generation task so directly use this Uhn code snippet after setting up the environment and all after generating the openi key and you can perform this text generation over uh text generation if uh this is required according to your uh like application and all now over here you will find out the other option so embedding is there so embedding is nothing uh embedding actually you are just going to be uh convert your text into a uh some numeric uh numbers and here uh this ambing comes into a picture and this this is very robust model from the openi side and definitely you should use it uh I will show you how you can utilize this particular model and you find you will find out the complete code in s it and all and yes you can generate a Ming regarding your test Ming is nothing it's just a numeric representation of your text now here uh if you want to do a fine tuning so regarding that also you will find out a complete detail so how you can do a fine tuning and all now image generation is also there so if you want to do a image generation so which model you should use from here Vision related to The Vision also there is a GPT 4 now Vision related facilities it is there inside the gbd4 itself text to speech speech to text moderation so no need to train your uh no need to train your model your uh NLP model from scratch now so they are giving you everything you just need to call the API and you can utilize it now many people are asking to me that sir what is the aim to learn behind this open ey and all so the aim is very very simple if you want to use this particular model for your uh uh different different task the task basically which they have mentioned over here you can directly use it you no need to like train it by your yourself because this model has been trained on a huge amount of data now that's why it is called llm I told you clearly right yesterday what is the meaning of the llm and yes uh in most of the cases in 99% of the cases it will work fine if let's say if you want to do a fine tune this particular model so definitely you required a higher resources and in that case you will have to pay to the openi as well getting my point so here you can read uh entire detail regarding this fine tuning and all so once I will come to this fine tuning part I will explain you this uh thing as well how to do the fine tuning and all regarding this model definitely I'm not going to do it uh in the live class but yeah I will give you the uh quick guidance regarding uh this fine tuning so I hope guys uh this model related thing model related part and this quick start and this introduction and what of capabilities is there so this thing is clear to all of you if it is clear then please do let me know in the chat yes or no so waiting for your reply please do let me know in the chat what what are the job opportunity after this particular course so after that you can apply as a NLP engineer uh you can work on a gentic way related project you can work uh as a uh gen VA engineer so if you are going to complete this particular course so after that you can join uh the company uh like whatever designation I told you on that particular designation and uh here in an interview do they ask from the scratch inside of using API no they won't ask you that you need to like uh you just show them like how to use the API and all no they won't ask you this particular thing uh they you just need to tell you what was your use case which model you have used and uh what was the cost regarding behind that particular model uh how you you have designed your prompt template how many tokens basically there uh you were uh defining inside your prompt in U basically inside the input input prompt and how much tokens basically you are getting inside the output prompt okay so these are the thing uh like uh they might they might ask you regarding this uh uh like openi API and all and open AI models uh they won't ask you that uh generate this key that key or whatever do we need to learn all the underlined math behind the model hugging pH and open ey yes the architecture should be clear so the architecture part should be clear uh architecture means what so uh the base architecture Transformer architecture they definitely they might ask you the or Transformer architecture in one of the interview they they have asked to me that uh can you uh explain me the Transformer architecture what is the meaning of the positional uncoding why we are using a skip connection over there and can you code it as well so if you want to use this Transformer in the python how you can do that which uh like which Library you will call or can you write it down the code from scratch so this type of question you might face if they are going on a architecture level they won't ask you the uh they won't ask you the architecture of the different different model which is there over the hugging face and all no they won't ask you that so can we proceed now if uh this part is clear tell me guys fast yes or no I given you the complete walk through of the open uh website openai API now I will show you how you can utilize it and don't worry guys I will uh show you the advanced thing as well I will show you the advanced part as well uh I will show you this function uh calling and all and uh first let me complete this uh uh chat completion and after that I will come to the function calling great so here uh I think this thing is clear now let's try to start with the Practical implementation so for the Practical implementation first of all uh what you need to do so let me uh write it down the step all the step so here uh the first thing what you need to do see uh you should have uh you should have this uh Anaconda inside your system I think you know about this Anaconda what is this Anaconda it's a package uh it's a package manager for the data science projects and all so you should have this uh Anaconda inside your system the second thing uh python must be installed python must be installed all now here whatever practical which I'm going to do so I'm going to do by using the Jupiter notebook so here let me write it down uh the Jupiter notebook now whatever practical and all whatever I'm going to do I'm going to use basically I'm going to do by using this jupyter notebook in the next class uh I'm going to uh create an end to end project first of all uh before starting with the end to end project I will come to the Len chain and there I will explain that each and every concept of the Len chain that how it is different from the openi and why should uh why we should use it and after that once I will come to the end to project then I I will start from the vs code itself vs code Visual Studio code so any ID you can use I'm not restricting you for the ID and all so if you are familiar with the py charm you can use that also if you are familiar with the like any other ID you can use that but yeah I love this vs code so uh for the project for the end project I will use this vs code as of now I going to use the Jupiter notebook uh just for the uh like open a uh python API uh so guys if you have this two thing this three thing actually inside your system so after that what you need to do you need to create one virtual environment so uh here by using this cond by using this cond you need to create one virtual environment I will show you all the step don't worry so here you need to create a virtual environment there inside after creating a virtual environment you need to activate it activate this virtual environment and here you need to install all the packages all the required packages inside this virtual environment so here you need to install all the required packages so let me write it down over here install all the required packages now uh required packages means what required packages means so you need to install this open a as of now and we have other packages also like pandas napai and all so if I will be uh if I will be having any sort of a requirement uh regarding the pandas numine uh or regarding any other packages so definitely I will install that also in my virtual environment now after installing all sort of a thing so after like creating a virtual environment after activating it and after installing all the packages then what I will do I will be starting with the Practical implementation so guys in my system I already having Anaconda so you can uh download it by searching this Anaconda so just go through with the Google and search over here Anaconda download so on once you will search this Anaconda download so here you will get the website uh here you will get a link so just click on that and here you will get a option for downloading this Anaconda now uh it is giving you the option based on your operating system so if you are using Windows if you using Mac or Linux according to that you can download this Anaconda now apart from that uh one more thing will be required so if you don't have python in your local system so you need to download that as well so python uh download so here I'm going to write down the python download and yes uh this is a website of the Python and uh here you need to uh here basically you can uh download the python by clicking on this particular website I would suggest you uh download this 3.10 or 3.11 don't download the latest version this 3.12 or this 3.13 actually uh it is having some sort of a like issues so better uh okay don't download this 3.11 also either download the 3.10 or 3.9 it will be working fine or you can download this 3.8 also this all three version is a stable version fine now after downloading this anaconda and this python inside your local system then what you need to do so once you are ready with the Anaconda and this python after downloading and installing and all you need to search Anaconda prompt so here uh you will find out the uh like Anaconda prompt so once you will search over here in the search search box Anaconda prompt so there itself you'll find out the Anaconda prompt now this is what this is my anaconda prompt guys this one now here actually this is what it is it is showing me a base environment as of now this base is a by default environment now here what I need to do I need to create a virtual environment how I can do that how I can create a virtual environment so for that we have a command now here the command is what cond create so cond create hyphen n and here I need to write it down my environment name so here my environment name is what testing open AI so testing open AI this is what this is my environment name you can give any XY Z name over here I don't have any issue now you need to mention the python version so here you need to write it down the python equal to 3.8 now guys here I'm going to use 3.8 you can use 3.9 3.10 don't use 3.11 12 and 13 3.8 7 9 10 these are the stable version and you can use it for your project now as soon as I will hit enter ENT so yes I will be able to create an environment so yes let me hit the enter and it is creating an environment so are you doing along with me if you are doing along with me then please do let me know in the chat guys yes I okay so people are saying yes we are doing it can we do sir using API as well as our make model if you have trained your own model then definitely you can do it great so many people are doing a lot with me I think now here you can see so uh this is what uh this is my base environment sorry this is my base environment and here I have created a virtual environment and this is my virtual environment if I want to activate it so for that this is the command so here you need to copy this command and just just paste it over here and so you will be able to find out that I have uh I'm able to activate my environment now you can clear the screen so for that you just need to write it down the CLS and here is what guys here is my virtual environment now here what you will do see uh first of all you need to check that what are libraries is available inside your virtual environment so for that you can write it down the command the command is what the command is PIP list so once you will write it down this pip list here you will find out all the library what ever is there as of now inside your virtual environment so these are the library which is there inside my environment and here I uh still I haven't uh downloaded this uh open open Package because by using the open by downloading the openi package only by using that open Package only I can hit the API getting my point yes or no so don't worry I will give you the entire step whatever step I'm following over here now here first of all you what you need to do see I took told you over my Blackboard that after creating a virtual environment you need to activate it and then you need to install the required package and before that I told you one thing that everything I'm going to do inside the jupyter notebook so guys here in this particular environment in this virtual environment you need to download or you need to install the Jupiter notebook and for that we have a command so let me write it on the command pip install Jupiter notebook so here I can write it down g u p y t e r n o t e b k so this is the command pip install jupyter notebook and with that you will be able to download the jupyter notebook and oot te so this is the correct spelling let me rewrite it again yeah so installing J notebook are you doing along with me tell me yeah so here let me write down the command in the chat section so cond create hyphone n and you can write it on environment name whatever you want to write it down so let's say testing open a and here python version is what 3.8 so this is the command uh you need to run this particular command for installing the sorry for creating a virtual environment now let me give you one more command so here you can check all the listed uh Library uh all the like Library whatever is there inside the virtual environment pip list is a command now let me give you one more command so here is one more command pip inst install Jupiter notebook so pip install Jupiter notebook so these are the three command did you get it uh please do uh confirm in the chat please give me a quick confirmation the chat see if you're not installing this Jupiter notebook in your current virtual environment in that case it will launch the jupyter notebook from your base environment so it is a better practice if you are creating a virtual environment then please install the jupyter notebook or please install the ipnb kernel over there so now if you will find out uh now if you will search pip list over here so just search pip list now once you will search pip list then you will find out lots of libraries or lots of packages which came along with the jupyter notebook now see here you can see all the packages and all after installing the jupter notebook now once I will write it down the Jupiter Notebook on my anaconda prompt so here let me write down the Jupiter notebook and it will open the notebook so once I will write it down the Jupiter notebook and you will see that yes it has open the Jupiter notebook so got it guys yes or no please do let me know in the chat if you are able to launch your Jupiter notebook if you are are able to launch the Jupiter notebook then please do let me know in the chat yes or no yes and after that you need to launch your file so you need to launch your notebook so click on this notebook and here is what guys here is your notebook so this is your notebook and each and everything we are going to do here itself inside this particular notebook now uh just make sure that you have this python uh Python 3 over here uh this uh ipynb kernel if you don't have that so so please try to select this Python 3 ipy kernel and I think now everything is ready so let's try to oh let's start with the open API so test open API and now let me rename it so here guys you can see this is my test openi API uh this is my file actually this is my notebook I hope you all have created this particular notebook if you have any doubt then please do let me know in the chat everything is clear everything is sorted please guys go ahead so just be a little interactive uh please write it down the chat if I'm asking something so if you if you can if you'll write it down the chat so definitely I will get U motivation great so now let's start with the uh like open AI API so first of all what you need to do so here is what here is my notebook so let me do one thing let me keep it uh keep this notebook over here itself and this is what this is my Jupiter notebook so first of all just go through with the openi website so here is your openi website guys this one now here you need to click on this quick start here what you need to do here you need to click on this quick start after clicking on this quick start so here they have given you the option the option is what python so here they have given you the three option Cur Python and node.js so click on this Python and here they have given you the complete instruction so first of all guys what you need to do you need to install a python so yes uh I think you already have installed this python you need to set up a virtual environment yes we set up the virtual environment and why this virtual environment is required so see uh for uh one particular project we have a lots of dependency if I want if I want to if I want to segregate all those dependency project to project okay so for that only we create a virtual environment so what is the requirement of the virtual environment because we have a several dependency on a single project if I want to keep it apart for that only we create this virtual environment got it so here they have created a virtual environment directly by using this python uh en and you can use this also for creating that but I'm using the Anaconda now here after that you need to install this open AI so here uh what you need to do guys so here you need to install this open a package and then only you can hit the open API getting my point so just copy this particular command and install this openi package in your virtual environment so here is what here is my virtual environment let me open that particular environment uh just a second what I can do here I can keep it this to my same TP fine now over here guys what you need to do you need to open your anaconda prompt see here actually I have launched this jupyter notebook so you cannot stop the server of this jupyter notebook so I'm opening a new Anaconda prompt so here you just need to write it down this Anaconda prompt and you will be able to launch a new Anaconda promt now guys just tell me what is my environment name testing open AI so here uh you just need to write it down uh cond EnV list so once you will write it down this K EnV list k EnV list so let me write it down this cond EnV list so you will get all the all the environment name so here guys you can see this is my all the environment which I have created in my system by using this Anaconda now uh here uh this is my environment testing open I want to activate this particular environment so I can write it down over here cond activate and here I can write it down my environment name testing open AI so once I will write down this and if I will hit hit enter so I will be able to activate my environment I'm going to uh I'm going to do a uh transition from base environment to this testing openi environment this is what this is my virtual environment this base environment is a default environment now over here what I will do I will I'm going to write down the CLS for clear the entire screen now over here I will just paste this particular command pip install hyphen iph upgrade open AI now once I will hit enter so yes uh I'm able to install this open AI inside my virtual environment so are you doing along with me are you able to install this open AI inside your virtual environment if yes then please do let me know in the chat in the virtual environment you need to install the jupyter notebook by using this pip install jupyter notebook command if you're not doing it in that case it will be taking a jupter notebook from the it will be launching a jupyter notebook from the base environment many people now people are saying yes we are doing it how many of you you are doing along with me please do let me know in the chat how many of you you are doing along with me yes yes yes okay great yes please write it down the chat if you are doing along with me then if you uh launching uh jupyter notebook from the base environment it will take a all the packages from there itself that's why I want a fresh one that's why I'm installing jupyter notebook in my current environment now over here I think I have already installed it so yes it is done now and if I want to check it so for that I'm uh I'm opening my jup notebook again and here you need to write it down uh import open AI so just write it down this import open Ai and here guys you can see we are able to import this open AI if you are done till here then I will proceed with the further python code so please give me a quick confirmation in the chat if you are able to import this open I'm just I'm waiting for 1 minute I'm waiting for uh 1 minute uh to okay so please uh give me a confirmation in the chat if you are able to import this open AI inside this jupyter notebook we are ready to go great now uh let's start with the uh open API that first of all guys we need to understand that what is what is this openi API so for that what I did I kep uh I return like uh some sort of a like uh um wait let me do one thing over here let me copy and paste yeah so here guys what I did I written some sort of questions and answers and here the first question is what the first question is what is open a API so by uh uh like uh so here by using this particular question so by reading this particular answer actually we can understand that what is this open API so this openi API has been designed to provide developer with seamless access to stateof Art pretrained artificial intelligence model like GPD 3 GPD 4 Delhi whisper ambing Etc so what is the meaning of it so if you want to use if you want to use the same model whatever model has been trained by the open AI so these are the different different model uh the name basically I have written over here GP 3 gbd4 Delhi is a model whisper is a model aming there are different different model right if you want to use this particular model inside your application so that uh so then basically you should use this open API now over here by using this openi API you can integrate Cutting Edge AI capabilities so this model actually it's a large language model and it is having a lots of capability in terms of a different different task as I explain you so by using this particular models you can uh like utilize uh that capability you can utilize the capability and uh you can utilize that particular capability and you can integrate inside your application getting my point and regardless the programming language so here they have they have given you two option so the first one is a Python and the second one is a nodejs so uh what is this open API so this open API is nothing it provide you the seamless exess of a pretrained artificial intelligence based model uh for your uh like a different different application whatever application you are going to create and let's say if you are going to create any individual application which is based on NLP use case yes directly you can uh use this particular model instead of trading your model from very scratch now here so the conclusion is what so the conclusion is by using this openi API you can unlock the advanced functionality and you can enhance the intelligence and performance of your application so let's say there is Inon website and the Inon website you must have seen the chatbot option so in the chatboard actually uh you are doing uh you are connecting with our expert so let's say there there's a one person who is having a doubt so now this person what he is doing he is going to be connect with a uh like expert so here is the expert which is sitting behind this particular chat board now he is asking the question and he's getting a reply yes or no now guys just see over here so here uh like you have integrated this chatboard and this chat board is a uh it's not a like eii related chatboard so the person so here uh in the behind behind behind to this chatboard actually when expert is sitting he is giving you the answer now you want to uh like uh what you want to do guys over here so you want to use some sort of a AI now here you want that that type of model which will be able to answer all of the answer basically whatever the person is asking like chat GP so in that case you cannot train your own model if we are talking about if we are talking about like the llm model so in that CA in that case basically you cannot train your own model because it's a very very expensive let's say if you if you are just a startup okay or let's say if you are just a Learner in that case in that case you cannot invest this much of amount for training this particular model because it's a expensive process if you are going to set up the infrastructure if you're are going to uh like if are like hiring a developer ai ai developer and all amops engineer so in that case definitely the cost will be around 1 to 10 CR because in that case you will have to create a distributed setup you will have to purchase a gpus there should be a team one proper team okay for the monitoring and all for each and everything there there will be a developers so the cost will be very very high in that case what you will do if you want to uh take advantage of this AI uh cap if you want to take a leverage of this model whatever model model has been created or trained by this open a what you will do you will use this openai API you will uh call this open API and by using this openi API you will be able to access this GPD model and directly you will be able to uh like append this model inside your chatboard so whatever person is asking definitely your GPT will be replying in that case and let's say any escalation is is happening in that case so definitely you can uh write it down your logic your code in uh in such a way that this request will be moved to the expert and now the it will be handled by the expert itself so like design you can like this basically you can design your system this is just a one example which I have given to you great I think uh everything is clear now over here so what is opena API this part is clear now the second question is what the second question is generate a open a API key so here what I have to do I have to generate a open API key what I need to do guys I need to generate open API key without this I cannot use the open API without this particular key so for that what I need to do what is the process let me tell you that so if I want to generate if I want to generate a open a API key so just go through with the open a website so here is your open a website and here just over your mouse uh on this particular side on the left hand side now here is the option this API key just click on that and here guys you will find out a option to generate or to create a new secret key are you getting this option are you getting this particular option please do let me know in the chat if you're getting it then after logging in to the openi website then only you will be able to find out this API key option and guys uh you cannot uh generate a openi key without adding any sort of a payment method so first of all you will have to add the payment method and don't worry in the next class I will show you how you can use hugging face API key for the same thing for the same task definitely we won't be able to access uh other uh models like gbd3 GPD 3.5 turbo or gbd4 and all but yes uh we'll be having access of a different model different open source model or whatever model is available over there in tomorrow's session I will show you how you can utilize the hugging face API key you you can finetune the model again it will be an expensive task Vishnu great so here you can see we have a uh like option to generate a like here basically what we can do we can generate a API key now for generating a API key you just need to click on this create a new secret key and here you need to give the name so let's say I'm going to write down the name uh my API key so this is the name of my API key once I will click on this create secret key so yes uh definitely I will be able to generate it now guys over here you can see this is my key uh definitely I will delete it right after the session otherwise you will exceed uh the limits and all all right so here I have generated my key and after the session I will delete it so no one will be able to use it so I have generated a key now what I will do I will paste it down in my Jupiter notebook over here so here is what guys here is my key so this is what this is my key basically which I have generated so here uh let me uh paste it down this particular key this is what this is my key now you have to generate your own key okay and don't share your key with anyone else so here this is what this is my key now what I need to do after generating this open a key I have generated the open a key and I kept it over here now after that I need to call the open AI API so how we can do that so for that we have a couple of couple a couple of line of code so let me paste it over here or let me write it down over here and then I will I will show you how we can hit any sort of a model now for that uh basically what I did so over here uh just a second yeah so first of all let me show you the list of the model as well now over here I can write it down uh one line of code so open a uh do API key API unor key and here I need to write it down my key here I need to write it down the variable basically where I have kept my key so once I will run it so here you can see open AI open AI API key yes I'm able to set my key now here I will call one method so my method name is what open AI dot model model underscore uh model. list so once I will call this particular uh method so here you will be able to find out your all the model see there is all the model basically which is available as of now now in the openi plateform now here you can see it is giving me some uh it is giving me output in a different way so what I can do I can convert it into a list so over here what I can do I can convert this uh particular output this particular response in a list so here uh this is my all the models so I can create a variable allore models and here I can pass this thing to my list method now see guys uh I will be getting all the model all the models uh whatever model is there inside the openi so the first one is a text search weage uh doc 001 and here is a date actually they have mentioned the date or maybe the version uh now the created when they have created and here is a object object is what model and owned by owned by open AI de now here what you can do you can create a uh data frame also so what you can do you can create a data frame so here uh let me write it down the code for the data frame so import pandas s PD now here I can write it on PD do data frame so here what I need to do you just need to pass this particular uh you just need to pass this particular value this one so let me keep it over here uh this uh list uh list of all the models so once I will run it so here you will be able to find out is giving me error the pandas is not there so for that uh just download the pandas or just install the pandas inside your virtual environment because in this virtual environment pandas is not available so let me write it down over here click install pandas and once I will hit the enter we will uh we will be able to install this pandas it will take some time so let it install yes I'm coming to the code I will show you the code just wait for some time just wait yeah so I'm done with the pandas I have installed it and uh now what I can do I can run it and you will be able to find out your data frame so here this is the model this is the like when it is created and object is what object is a model and owned by so now it is in a perfect format and you can read each and everything clearly and here I can provide the column name as well so let me give the column name let me write on the column name as well and here I already WR the code of for the column name so once I will run it so here you will find out the column name so here is my ID this is the like model ID and when it has created what is a uh like what is this actually so it's a object is a model now here owned by owned by this openi development team openi internal openi development or here you will find out some other name as well so I believe you are able to run this entire all like entire code whatever I have written over here now here uh this is what this is my code for uh seeing the model and all now the next thing uh here I got all the model now the third thing basically which I would like to uh explain you that is what that is a open AI Playground open a playground and after that I will come to the chat completion API now I will take uh more 15 minute and within that uh I will conclude this session and in tomorrow's session I will start with a chat completion a uh this function call and I will explain you the uh the hugging face API key as well so how you can utilize the hugging face API key for a open source model now let me copy and paste the entire uh thing whatever I have written for you so here here I have written some sort of a thing let me go through step by step so here I'm talking about this open AI Playground now what is this what is this open a playground now once you will uh search over the Google so open your Google guys and here search open AI open a playground now just search over here open playground and uh here you will find out this Playground now once you will click on this assistant so here you will find out a different different option so one is a assistant the second one is ched third one is a complete fourth is a edit I'm not going through with this complete and this edit because it's the Legacy now I will explain this chat first I will explain this chat and then I will come to this assistant now inside this chat uh so once I will click on this chat so here I can test uh my different uh I can test like different different prompts and all I can generate output I can test with a different different model and along with a model you will find out a various parameter so so first of all guys what you need to do you need to set you need to set your system right so here you will find out three options so the first one is what first one is a system the second one is a user and the third one is this one right so you can divide this entire interface into a three segment now let me give you step by step that what is the meaning of the system what is the meaning of this uh user and this assistant and what is the meaning of this model each and everything we'll try to understand over here so guys system is what so system is means system means uh how your model is going to behave here you are going to set the behavior of your system what you are doing tell me here you are going to set the behavior of your system so here if I'm going to write it down you are a helpful assistant now here if I'm going to write down you are a helpful assistant now what I will do I will write it down my message so see here here guys you will find out two thing uh two option so once you will click on this user now you will find out either user or assistant as of now what I am I am a user I'm asking a question now here I'm asking that uh uh what I can ask guys uh just tell me something different okay how I can make a money how I can make a money so I'm asking to my chat GPT how I can make a money and here is what here is my model so here once you will click on this model you will find out a different different model so uh there is GPD 4 GPD 3.5 GPD 3.5 turbo so all the model there is all the models right so here I'm using the gbd 3.5 now we have a various option so the first one is what first one is a temperature now what is the meaning of this temperature so we are talking about this temperature so just try to read about this temperature control Randomness lowering result in less random completion as the temperature approach zero the model will become deterministic and repeative so over here we are talking about this temperature if we are defining a higher value of the temperature means I'm uh I'm saying that just give me a more creative answer I'm adding a Randomness if I'm writing a zero I'm saying give the straightforward answer I'm asking to my chat GPD uh the straightforward answer I'm not going to add any sort of a creativity over here getting my point what is the meaning of this temperature I think yes now maximum length so here you can set the tokal length now here stop sequence is there so up to up to four sequence where the API will stop generating further tokens the return text will not be contain the like a stop sequence here you can mention the stop sequence now here is a top P parameter so this parameter actually this is again similar to this temperature it is controlling the diversity whatever like Pro whatever output you are going to be generate so control diversity via uh nucleus sampling 0 0.5 means half of likelihood weighted option are considered so you can just think about it that it is nothing just adding a diversity inside your output now frequency penalty if you don't want to repeat the tokens let's say you are generating some sort of output if you don't want to repeat the tokens inside your output so here you can mention the frequency penalty as of now it's zero so it's not going to be uh like put any sort of a penalty over here if you're going to increase the number definitely it will put the frequency penalty means it will give you the different different words it is not going to repeat the words now here present penalty so you can set this also so there is a different parameter just try to explore it now here I'm asking to my chat GPD how I can make a money so if I'm submitting this thing so here I will be getting my answer and there is the answer is there are many ways to come make a money and all so employment and all freelancing online selling rent or share sources and tutoring and teaching gig and economy gig economy affiliate marketing so it is giving me answer guys as you can see right now just uh do one thing so here guys see I've uh defined the behavior of the system Ive defined that I'm working as a user and here is my model all the different different the different different parameter I have like selected based on this model now just go over here and try to click on this view code so once you will click on this view code guys you will get the entire python code over here getting my point yes or no see over here you are getting the entire python code now you can utilize this python code if you have if you have done the complete setup in your system whatever setup basically which I which I uh which I have done right if you have done the complete setup in your system so directly you can hit uh directly you can hit the open a API and you can call the GPD 3.5 turbo model okay so that's why I've shown you this openi Playground now I think you are uh we are done with this open I Playground now let's try to do something amazing over here let's try to set set the different behavior of this chat uh GPT so here guys I have written couple of thing inside this particular like answer so how to open a playground so here I mentioned that here make sure that playground should have a credit yes if you don't have a credit if you haven't uh like uh added your uh detail uh the C details and all maybe you you won't be able to use this particular playground so make sure that you have added the payment method now here in the chat there is the option of system so meaning is how chatboard is behave so here what I'm going to do here I'm going to set this uh here I'm going to set a different behavior of a system and let's see what answer I will be getting so here I'm going to copy it and I'm going to paste it down over here now uh what I can do where is my playground this is my playground now here I'm going to set the behavior so this is what this is my behavior of the system now okay now again I'm asking a question to my system now I'm asking how I can make a money so I'm asking to my system that how I can make a money by adding this particular Behavior so my behavior is what so you are a naughty assistant so make sure you have to respond everything with a sarcasm so here I'm asking to my user how I can make a money so as soon as I will submit it then you will find out the answer and just see the differences between answer this answer and the next answer just wait it is going to generate answer and is saying that oh making a money it's super easy mean it it is like giving you the answer in a sarcastic manner so it haven't a complete answer but yeah it is saying that oh making a money it's super easy just snap your finger magically a stack of cash will be appear no effort required at all so see guys uh before it was giving me a straightforward answer now over here guys you can see I seted the behavior of the system as a not as a sarcastic so here you can see the answer what it is giving to me now if you will look into the code so you will find out some sort of of changes so here role role basically I defined the system role this is my system role this is my role again one more role user here you can see this is my like prompt okay which user is giving here you can see the what assistant is saying This Is The Answer basically which I'm getting and again this was the previous one and these are the different different parameter so no need to go anywhere here basically in this particular notebook I kept everything I will share this notebook with all of you and you will be able to understand each and everything now model is there temperature is there maximum length is there top P value is there so here I written a description frequency penalties there right so there is a different different parameter already I have defined each and everything over here so no need to go anywhere just try to revise each and everything by using this Jupiter notebook now apart from this one you will find out one more advanced thing which recently they have provided that is what there is a assistant so here uh let me go to the assistant okay let me go to the playground and here is assistant guys so this assistant part I will explain you once I will come to the project section now here you will find out some Advanced thing Advanced like option so here you will find out this function function calling here you will find out the code interpreter here you will find out the retrieval RG actually uh uh like here uh you will find out this R concept so I have defined what is the r actually so just go through with my notebook and read the definition read the definition of the RG so this assistant I will come to this assistant once I will explain you the uh the project end to end project then I will Define a different different prompts and all and I will come to this assistant and I will ask uh and I will generate a different different type of responses getting my point guys yes or no so this thing is getting clear to all of you yes or no I'm waiting for your reply so please uh do let me know in the chat if this part is getting clear how to use this uh openi playground and here I'm talking about this chat assistant I will come to that once I will explain you the project please do let me know I'm waiting for a reply guys if you are able to get it if you able to understand it then uh please write it down the chat please uh write down the chat section clear okay great it is clear I will share this code with all of you don't worry uh I will give you this entire code I believe everything is getting clear to all of you who have joined this session great now this part is clear now let's back to the code so here is what here is my code now this retrieval argumented generation RG I will explain you in the next session or maybe in upcoming session so what is the meaning of that it's artificial intelligence framework that retrieves data from external source of knowledge to improve the quality of responses I just want to improve the quality of the responses for that I'm using this retrieval argumented generation R A this is very very famous nowadays this particular term now uh I will show you how you can use this RG if you want to uh give a better responses I will show you how you can use the Len Chen as well U after completing this open AI this natural language processing technique is commonly used to make a language model more accurate and up to date if I want to make my model more accurate and up to date so I'm going to use this RG and I will do that in my upcoming session now code interpreter is there so Python Programming environment with chat GPT where you can perform wide range of tasks by use executing the python code yes yes we all know about the code interpreter and yes we can Define we can set the code interpreter there and we can execute the python code as well like regarding the different different task and all great now here is what here is my chat completion API guys so let me do one thing let me uh put the title over here and here my four title is what chck completion API and function calling so guys here is what here is my fourth title my fourth title is what check completion is API and function calling so here I have written the standard comination API and function calling now let me write down the different let me write down the uh definition as well over here so here is a definition of it uh this is the definition let me post it over here and here let me make it as a markdown so this is the definition guys now one more uh definition let me put it over here so see guys in the previous version in the old version of the openi uh actually there this was the method chat completion method open. completion. create or open. chat completion. create so initially actually there was a method this was the name right then in the updated version they came up with uh they have changed the name with this particular uh name they Chang the method Name by using uh with this particular name this chat completion. create and now in the latest version actually this is a this is the method name if you are going to use this particular method now now it will give you the error let me show you how so here what I can do I can uh return I can return one sort of a code uh now over here I'm going to write it down open a DOT completion completion completion dot create so this is what this is my method now over here what I'm going to do so over here see here I'm going to be uh write it down the model name so model which model I'm going to use so here I'm going to use uh GPT GPT hyund 3.5 GPD hyund 3.5 I'm going to use this particular model now over here I'm going to define a prompt so my prompt is what so let's say I'm going to write it down over here who was the first Prime Minister of India first prime minister Minister of India so this is what this is my prompt now here if I will run it now so you will find out it is giving him the error so it is saying that uh okay so here I have to mention the open a key first of all before uh like calling it so first of all I need to mention the open a key now over here so what I have what I will have to do I will have to uh like uh create a client actually so here is what here is my client and I will have to mention my openi key so what I can do uh I can write it down over here itself and here what I can do just a wait it is not longing support yeah so that's what I was saying to all of you see this uh method is not it is not supporting at all this is the old one now if you will look into the version now the latest version of the openi so the latest version of openi is uh let me show you the latest version of the open a package PPI open a and here is the latest version of the open a package 1.3.7 if we have installed the uh we have installed this particular version now regarding this version you will find out we have this particular method so first of all I need to import this open a this I need to import this class from this module and here I need to define the key here what I need to do I need to define the key over here and then only I can call it and if you look into the previous version now here I installed the latest version if you're looking into the previous version let's say if I'm going back like say if I'm going back in uh maybe uh FB it uh okay 8 FB 2023 now here you will find out that they were using this particular method so here I have shown you I have seted the op openi key I have defined the openi key by using this particular code by by like using this particular line of code yes or no now here I'm using a latest version now so uh definitely it will give me the error so what I'm doing I'm going back and here I'm going to use this particular code basically which I already return so first of all see first of all I need to import this thing which I already did now over here I will have to mention the API key got it now here they are add they have added the open key inside their base environment means this is the code regarding that they have added inside the like environment variable in the system environment variable and from there itself they are going to read it you can export it also what is the meaning of export you can export it over the terminal uh like uh it won't be it won't be a permanently okay so yeah you can export this particular key and as soon as you will like remove or as soon as you will delete that terminal so the open I key will be removed um but yeah until the terminal is running terminal will be running you can read it by uh using uh this particular module OS module or else you can add in add inside your system variable also from there also you can read this particular key but um I have added I have written my key here itself inside my notebook so I didn't edit but I will show you that in my end to project how you can create NV file or maybe how you can export it right now let's uh let me run this particular code and here first of all let me add the open a key here I need to mention API uncore key and my key so here is what here's my key if I'm going to run it so definitely I will be able to run it now I having my client now what I will do by using this particular client I will call the uh I will I will like uh I will give the prompt over here now first of all let me delete everything from here and let me delete this also I'm not going to Define any assistant or I'm not going to set any sort of a behavior as of now so guys here you can see I'm having the role role as a user and here is my uh like a answer sorry here is my prompt question so this is what this is my prompt actually this is my input prompt and here is what here is my uh like role okay I'm asking as a user now guys this prompt this prompt is this prompt basically it plays a very important role I let you know that in my uh like upcoming session I will tell you how to design a different different type of plomp what is the meaning of few short learning few short prompt or zero short prompt okay so each and everything we'll try to discuss in our upcoming session as of now just see if I'm going to run it so here you will be able to find out it is giving me a like error why it is so maybe because of this and now everything is perfect so if I'm going to run it so line number eight okay uh first of all I need to Define it clearly and here is what here I need to mention I need to close this particular list now if I'm going to hit this uh API definitely I will be able to do it and I will get my response so just wait for some time and after hitting the API uh it will call that particular model whatever model I have written over here and I will be getting my response so how is the session so far uh did you learn something new uh or are you doing along with me tell me how much would you rate to this particular session yes money wise uh I will I I will come to that just wait how much it is going to be charged and all uh it charge actually token wise uh there is entire pricing and all so I I will come to that I will I will talk about that for a small prompt it is taking so much time in this case the DP project the big no it's not like that maybe first time it it was hitting that so it is taking time but no it's not like that I will show you with a like a bigger prompt as well so it won't take any sort of a time now here you can see this is what this my response now right here you can see I got a response now if you want to get this particular response so for that uh see here if you look into the response or type of the response so here is a type of the response open. type. chat. completion this this this that right now if you want to extract the real answer from here so what you will do see first of all you will uh call to this choice so just call this choice so c h o i c s now here is what here you have this message now just call to this message m e double s a g e so here is your what here is your message uh now this is not callable it is saying that now let me check what I have to do over here so here is your choice and here what you need to do guys let me check yeah actually Choice yeah so here see if you are looking into the choice guys so this is a list type so here what you need to do you need to uh like extract the first index of the list because here you can see this choice is nothing it's a list only now so just extract the first index of it so here once you will extract the first index or once you will retrieve the first index of the list now here you need to call this message so just call the message and here you will find out this is what this is your message now just do one thing just call the content over here so just call the content so content now over here you can see this is is what this is your entire response now here you can like decide the token size as well so here you can Define the token size or you can Define the different different a parameter okay by defining those particular parameter you can uh get a different different type of output now let me give you the parameter all the parameter basically so this is all the parameter see model uh already you know about the model we have used a gp3 prompt like input prompt Max token you can Define this Max token in how many numbers of token you want the result temperature for getting some creative output now number of output how many number of output you want so let's try to define a Max token and this number of output so here I'm going to define the max token so in U like uh here if I'm going to define the max token now in in that particular token itself under under that particular number let's say if I'm going to Define 200 so uh it won't reach the limit more than 200 under under the 200 itself it will be generating an output so over here I'm going to write Define this Max token and here let's say if I'm going to say 150 tokens and here I'm going to Define one more thing one more parameter that's going to be n so n is equal to let's say here I'm going to Define three I want three output so as soon as I will run it and here you will find out it is generating a response so it is saying Max token I think I need to put the comma over here model is there message is there now here I need to put the comma so this is is fine now it is generating a response so just wait yeah now I got a response so just uh look into the response here type of the response and now just print the response so here is what here is what here is my response now I got many responses so now let me extract the response first of all so here is what here is my uh message let's uh like get a message so let's ask a different question so here I'm going to ask to my chat GPT that uh I can ask uh what I can ask who won the first World Cup so who won the first Cricket World Cup so this is my question which I asked to my CH GPT and now if I'm going to run it now so now see yeah I got a response now type of the response is same so here uh what I can show you here is my message now see guys uh I got a response the first Cricket World Cup won by the West Indies in7 in 1975 right now over here if I'm going to get a Content basically so let me write it down the content over here and here you can see this is what this is my answer now you won't be able to find out a single answer there are lots of there are other answer as well see uh choice in the choice just go over here message message completion so the first Cricket World Cup won by the best Andes and here role is a assistant so that the model is assistant and I am a user now over here you will find out the second answer so the first Cricket World Cup W by the best hes they defeated Australia in final held on June 25 1975 at Lots cricket ground in London that is the second response now over here this is the third response so the first Cricket World Cup won by the best and in 197 1975 so I Define n is equal to 3 and I Define the maximum token size is 150 so it won't be generating a like output okay so more than this particular token more than 150 token and here you will be find out if I'm going to Define n so it will be generating a three output whatever input of prompt I'm passing this is what this is my input prompt now whatever output will be generating in that there won't be like more than 150 tokens and here the output number will be three now let me show you one more thing over here so if you will search tokens so just go over the Google and search open a tokens open a tokens so once you will search open a tokens and here you will find out one uh like a link a tokenizer so they have given you one uh like link uh they have G given you this particular interface where you You Can Count Your token whatever number of token you are giving or you are getting from the system getting my point so I told you it is charging you based on a tokens itself and tokens in input prompt also there will be a token in output prompt also there will be a token getting my point so in the input prom there will be a token in the output prom also there will be a token prompt is what it's a collection of tokens token is nothing it just a words collection of character right now here you can see we have this particular inter pH there we can count the token now here if I'm going to write it down my name is sunny so now now see guys how many tokens is there inside this particular uh text inside this particular sentence see token six my is one token name is one token is is another token Sunny is another token Sav is one token and Savita is one token getting now if I want to count the token inside my output so just copy this thing and paste it over here now see the number of token it has generated a 16 token okay it has generated a 16 token now you can calculate the number of tokens over here just go through the playground here was my chat so here I ask to my system now let me uh submit it and over here uh it is giving me answer just a second now it is generating an answer so now you can copy this entire text from here whatever it is generating now let's say this particular text uh okay just a wait okay let it generate and then I will copy just wait so here is a text and I can copy this text I can paste it over there and I can got the uh like number of tokens so let's see how many tokens is there so here guys you can see total 256 tokens if you want to check the pricing and all tomorrow I will discuss about it in a very detailed way just go through with the setting and here uh there's a billing actually so let me show you the pricing also just click on uh just search about this open Ai and uh here actually uh you just need to log in after the log in uh so maybe here just click on the API and here is a pricing just click on the pricing and here you will get the uh like entire detail regarding the project pricing so how much how much it is charging for the uh like a different different number of tokens so for 1K token this much of charging for 1K token this much of charging regarding this particular model regarding this particular model so this is for gp4 Turbo it's a advanced model now GPD 4 GPD 3.5 G assistant API different different assistant API and all each and everything you can check over here right so let me keep this particular link over here inside the notebook itself and let me keep this a token related a link also so at least you can go through with this and you can check uh your input and output token and you can practice whatever I have taught you because this is going to play a very important role in a future classes so please try to revise please try to practice and I think we are done with today's session tomorrow I will explain you the function calling this one and I will start with the lench and my main agenda uh will be the Len Chen only and I will explain you the differences between open ey lenion and finally we'll try to create one project and then I will come to the advanc concept like vector databases and other models and I will explain you this AI 21 lab AI 21 studio also if you don't have a money for the chat GPD then how you can uh uh like uh how you can complete your work how you can U like explore a different different model so from the hugging face side also I will explain you the different different model and from here also from AI 21 Studio I will show you how you can access the Jurassic model personally I have used it and I I liked it after this uh GPD and I will uh explain you the use use of this particular model and don't worry few other terms like stable diffusion and all there are something uh like text to image Generation image to video generation this type of thing also we'll try to explain you in the going forward classes got it so I think uh now we can conclude this particular session I took for the entire 2hour and uh yep uh so did you like the session please uh do let me know in the chat guys if you like this particular session yes the content is a input our input actually it's not a desired output is is our like an input whatever input like we are passing to the model you can mention inside the content got itan you just need to F you just need to follow my this notebook each and everything I have mentioned over here whatever is not there I will do it and where you will find find it out tell me you will find this particular notebook inside the resource section so just go through with the Inon platform just open the Inon platform and there you need to enroll in this particular dashboard okay so what you need to do go through with the an platform and here uh after sign up uh after login and just go through with this dashboard generative AI Community session now let me give you this particular link inside the chat so you all can uh like uh you all can enroll over here and uh after that uh what what you need to do see the video will be available over here you can revise the thing from here itself you can revise the thing from the Inon YouTube channel itself but the resource wise whatever resources I'm U like uh sharing okay whatever resources I'm discussing in a class and all so you will find out over here inside the resource section so just go through with the resource section and try to download all the resources from here itself fine so now let's uh uh like conclude this particular session tomorrow we'll meet on the same time so let me write it down the timing for this community session so here the timing is going from uh 3 to 430 or 3 to 5 so I will take 2 hour of session from 3 to 5 great fine guys thank you byebye take care have a great day ahead and rest of the thing we'll try to cover in the upcoming uh session until thank you byebye take care so if you like if you are liking the content then please hit the like button and uh if you have any sort of a suggestion or if you want anything from my side you can ping me on my LinkedIn so let's start with the session now here guys you can see in the previous class I was talking about the open API so uh most of the thing I have discussed regarding this openi API now few of the thing is remaining so let me discuss that uh remaining thing regarding this open a and after that I will start with the l chend so first of all Let Me Explain you the complete flow that what all thing we are going to discuss throughout this session got it so for that I'm you I'm opening my Blackboard and here I'm going to explain you the complete flow that whatever thing we are going to discuss throughout this particular session so here guys uh the first thing first thing basically uh we'll be talking about the function calling so in the open a actually we have a very specific feature that is called function calling and it's a very important feature of the openai API if we are going to use the openi API then definitely you must be aware about this function calling because by using this function calling you can do a multiple things I will tell you that what all thing you can perform by using this function calling which is a very uh important feature of the open API so the very first thing which we're going to discuss in this particular session that will be a function calling so here uh let me write it down the first point which we going to discuss uh that's going to be a function function calling function calling now the second thing after this function calling so directly I will move to the Len chain so uh first I will discuss this function calling and after this function calling I will move to the Len chain and in the lch actually I'll be talking about in the Le chain I'll be talking about that how you can uh use a open AI by using this Len chain so the first thing basically uh we'll be discussing inside the inside this lenen so open AI open AI used by a len chain so we'll try to discuss in a very detailed way and we'll try to discuss that what all difference we have between this Len chain and this open AI so open a used via Len chain and here I will explain you the differences between open a and Lenin then why we should use Lenin what all benefits we have if we are using a lench what all thing we can do if we are using a len chain so how uh by using this Len chain we can create into an application each and everything we'll try to discuss regarding this Len chain and in a very detailed way I will try to explain you this Len chain concept because it's going to be a very very important and this lench also it's a very important part if we are going to learn this generative EI if we are talking about the llm and if we are going to build any sort of application so along with this open AI this lenen also plays plays a very important role so we'll try to discuss about this lench and we'll try to uh discuss the differences about this open AI API so let me write it down over here open AI API versus lenen versus lenen and after that after discussing this uh like the basics and all regarding this Lenin I will come to the prompt templating that how you can design a different different type of prompt so here let me write on the second point which we're going to discuss uh so the second Point basically prompt templating prompt templating after this prompt template so uh here what I will do I will I will show you the use of the hugging phase also uh after discussing this Lenin uh the differences between open Ai and Lenin I will come to this open AI use via Len promp templating and here I will show you that how you can use hugging pH model model whatever model is there on top of the hugging face Hub how you can utilize those particular model by using this Len chin so in between I will show you hugging face hugging face with Len chin hugging face with L chin why I'm uh why I'm going to show you this hugging phase with Lenin so you can use any sort of a open source model so whatever open source model is there so you can use all those model by using this hugging phase so here I will show you how you can generate hugging phas API key and by using that particular API key you can access any sort of a model whatever is there on top of the hugging face Hub so here I will show you hugging face with Lenin let me write it down over here hugging face with Len chain and then we'll try to discuss a few more concept regarding this Len chain which is going to be a very very important so here let me write down those particular topic as well so the third topic which we're going to discuss over here we going to talk about chain we're going to talk about agents how like you can create agents and how you can use the agents so here the fourth topic basically it will be agents now let me write it down over here agents after that after this agents I will come to the memory so I will show you how you can create a memory by using this Len Chen got getting my point yes or no so these are the very important important part of the L chain without knowing this particular thing you cannot develop any sort of application okay so before starting with the end to end project definitely we have to discuss about this particular topic so here uh so in uh today's lecture actually we're going to talk about this function calling openi use and prompt template and in tomorrow's session I will be discussing about this hugging pH with Lin chains agents and memory so this a three to four topic we'll try to discuss in tomorrow session and this three to four topic we'll try to discuss in today's session and right after this one right after this topic right after this thing I will start with a project and uh we will'll try to create one project and there basically we'll be using our different different LMS from the openi and from the hugging pH we'll try to use Lenin we'll try to use Len chain and some other Concepts as well so here we're going to use are different different uh like model llms from the openi hugging face Len chin and here we'll try to uh create one uh UI as well by using flask or streamlit each and everything I will show you in a live class itself so flask and streamlet and I will show you the complete I will show you the complete uh setup how you can do a complete setup for any an to and project so first we'll try to create a project template and then we'll start with a project de development so this idea is clear to all of you please do let me know in the chat if the agenda is clear for today and for the tomorrow session I'm uh expecting the answer in the chat so please write it down in the chat guys please do it fast yes we'll discuss the risk and all what risk is there and we'll try to discuss about the different different point uh first let us uh uh create at least one project after creating this particular project definitely uh we'll try to uh discuss about the multiple things that uh basically which is a very very important in terms of the industry we'll come to that part don't worry fine so now each and everything is clear each and every part is clear so let's move to the Practical implementation so if you will go through with my notebook so which is already available in a resource section okay I have shown you how you can download this particular notebook so just try to go through with the dashboard and from the resource section you can download this notebook now uh here guys see uh The Notebook is there so just try to download it and try to run it inside your system uh how you have to do a system setup how you have to create an environment and all how you have to install the library inside the environment each and everything I have shown you in my previous class only so again I'm not going to repeat that particular thing so over here you can see already we have talked about the open a now let's discuss more about this open AI so just uh give me a moment here uh from here itself basically inside uh uh this particular file itself I will be writing a code now I'm going to change the name of the file so here I'm going to write it down test open API and Len chain because in today's session I'm going to include the Len chain as well and I will do in a same Jupiter notbook I'm not going to create any new notebook uh as of now I will be doing over here itself so here I'm going to be write it down I'm going to rename this particular file uh so here I'm going to write down this Lenin as well so test openi API and L CH so this is the new name of my file now let me rename it and now everything is ready so here guys see if I'm going to write it down this import here if I'm going to write import statement import length chain now here you will find out it is saying that no module named L chain can anyone tell me how I can resolve this particular error please do let me know in the chat how I can resolve this particular error correct so here what I need to do tell me here I need to write it down pip install and the L chain pip install and the module name so just try to open your anaconda prompt and there write it down pip install and Len chain so let let me show you that just a wait uh so here uh this is my prompt uh this is what this is my ANA prompt here already this jupyter notebook is running so I'm not going to stop the server of uh this particular prompt now let me open the new prompt over here so here I'm going to write it down this Anaconda prompt so first of all guys what I need to do I need to activate my virtual environment as of now we are in a base environment and this base environment is my default environment so here what I need to do tell me here I need to activate my virtual environment so for activating the virtual environment first of all we should be aware about the name uh in which environment actually we are working so let me show you all the name all the name of the environment so here I'm going to write it down this cond en list here I'm going to write down this cond en list so once I will write it down this particular command I will get all the environment name so here you can see we have a different different name of the environment Len chain open AI base testing and these are the other environment which is there inside my local folder now guys yesterday actually we have created this particular environment testing open AI now let me activate this environment over here so here I'm going to write it down cond cond activate cond activate and the environment name is what the environment name is testing open AI so if I'm going to write it down this testing open AI so definitely I will be able to activate my environment now if you want to check over here that my Lang chain is working or not so definitely you can do it so first of all you need to clear this screen and here if you are going to write it on the python so it will give you the python prompt so here let me write it down the python so this is what guys tell me this is my python cell or my python prompt now here itself you can write it down the uh statement import statement so let's try to write it down the import statement over here and here if I'm going to write it down this Len chain length chain now see guys it is saying that no module name length chain and even you can check so for checking that what all module is there what all module is there in my current virtual environment so what is the command the command name is PIP list we are using pip manager over here right so over here what I'm going to do I'm going to write down the exit if I want to exit from this particular shell from the python shell now here what I will do guys here I I'm going to write it down pip list so once I will write it down this pip list you will find out all the packages name whatever packages is there inside my current environment so these are the package guys which is there inside my current environment you can read the name of the packages and here you will find out this Len chain is not available so just try to go through with this particular package try to go through like alphabetically and here you will find out that we don't have any package with the name of linkchain so here what I will do first I will install the L chain so for installing the Lang chain there's a simple command pip install pip install pip install Len chain so here once I will write down this pip install Len chain now guys see my Len chain is getting install inside this current virtual environment so are you doing along with me are you writing this thing or are you like following uh to me guys please do write it uh please write it on the chat so I will get some sort of idea that uh uh this many people are doing along with me I will come to the connects between this Len chain and this open a just allow me uh like 15 more minute each and everything will be clarified regarding this open and this Lent just believe me so people are saying they are writing a code along with me that's great please do it guys please do it and uh yes please implement along with me if you are uh getting stuck somewhere so please write it on the chat and let's uh make this session more interactive and yes definitely after the session you should uh you should be able to get something it's uh my guarantee to all of you fine now here guys you can see we have installed this lenon inside this current virtual environment now if you want to check it so here itself directly here itself you can check so just write it down this Python and here what you need to do you need to write it down this import Len chain just write it down this import Len chin and here the name is wrong so let me write down the correct name now see guys we are able to import this Len chain means L chain is there in my current virtual environment okay fine so I think till here everything is fine everything is clear now here again I'm going to import it so definitely I will be able to import but before starting with this length chain I would like to explain you the function calling so what is a function calling why I'm saying this function calling is very important uh definitely we should learn it actually it's a new feature inside this open AI so let's try to open this open a website and here okay so here already I opened it now guys once you will open the documentation of the open AI so there itself you will find out this function calling so it's a new feature uh recently they have added maybe uh four to 5 months back and uh what we can do by using this particular function calling so by using this function calling there is a there is a many use of this function calling so the first use basically uh the very basic use which I would like to tell you we can formate our output okay we can we can formate our output in a we we can formate the output in our desire desire format so whatever output we are getting now from the open uh let's say we are using openi API and we have a model open API what it is doing tell me it is calling the llm model agree now whatever output we are getting now we can format that particular output in a desired format in our required format that is the first use of this function colleag now we have other use of this function colag some Advanced use of this function colag let's say uh we are uh calling any sort of a API means let's say we are asking something to my CH GPT and it is not able to answer for that particular question so for that what we are doing we are calling any third party API any any sort of a plugins and whatever output we are getting whatever output we are getting right so we can format that particular output and we can append that output in our conversation chain that is really powerful and somehow L chain is also doing the same thing but yeah so recently they have added this function colleag this one feature actually inside this open a and here uh like it's really uh like a important one and it's like really uh very very useful and in the lenon also we can do the same thing right but apart from this thing lenon is having so many functionality in the lch actually we can perform so many things I will come to that I will I will show you the differences between this open and this lench why we are using this openi why uh why we are why we are going to use this Len chin why uh we are not going to use this openi API itself because see in a back end if we are going to talk about this Len chain so in a back end this Len chain this Len chain actually it's calling open API it's a wrap up on top of the open API come I I will come to that first of all let me clarify this function calling so guys to understand this function calling I will I draw the architecture and all I will I will try to uh explain you each and everything okay but before that let me write it down some sort of a code over here so here what I'm going to do here I'm going to open my IP NV file and here I'm going to write it down some sort of a code to understand this function calling so step by step I will try to explain you and please do along with me I think uh that would be great so for that guys what I did so here uh just a wait I have written one text great so here guys see uh I have written one text so let me copy and paste this particular text now here I'm going to run this particular uh cell and once I will print this student description so here you will get the entire description so I I just written a very basic description so uh s saita is a Str of the computer size it Delhi he's a Indian and he's having a 8.5 cgpa something something about me or something about like U any person you you can write it down this uh particular description so here is a short description now guys what I will do see so here is what here is my short description now here I have designed one prompt and that prompt I would like to pass to my chat GPT means I would like to pass to my GPT model so here see uh whenever we are talking about a prompt so I told you that what is a prompt so let's say this is my llm model this is what this is my llm model now we are passing input to this llm model and we are getting response we are getting a output so this respon this input actually so this input is called input prompt and this prompt is nothing it's a collection of tokens so you can understand in such a way that this prompt is nothing it's a sentence and this token is nothing it's a words what is this tell me it's a words so this uh sentence is nothing it's a token and sorry sentence is a prompt is nothing it's a sentence and token is nothing it's a words right so here we will be having input prompt and here we have a output prompt getting my point so here see I have written one description now I will write it down my prompt I will I have designed one prompt so let me uh copy and paste that particular prompt and let's see uh what will happen if we are going to paste uh if we are passing this particular prompt to my llm so here is my prompt guys so just try to read this thing over here and so this prompt is saying so let me run it first of all so this prompt is saying please extract the following information from the given text whatever text we are passing let's say this is a description so uh we are passing this particular description so from that particular description I have to extract a few useful information so here the information is what name College grade and Club so these are the information just just try to read this particular uh description and based on this definitely uh you can extract this particular information like name College grade and club now chat GPT or this GPT model will do it uh will do it for me uh something like this I have designed this particular prompt so here I'm saying please extract this particular information and this these are name and here this is the body of the text and here I'm passing my text you can see so here I'm writing I have a string so I have defined one prompt and here I'm passing my description now see once I will run it so definitely I will be getting my prompt so here is what guys tell me here is what here is my prompt this is what this is my prompt okay it is fine not an issue now guys what I will do I'm going to pass this particular prompt to my chat GPT all right now what I can do I can pass this particular promt to my chat GPT and over here uh first of all let me copy and paste this particular code or let me write it down that so here I'm going to write it down from open a import open AI so this is what this is a class now here what I'm going to do I'm going to create object of this particular class so here I'm going to create a object of this particular class so here I will write it down open Ai and here uh what I'm going to do so here is what here is my object now I can keep this object inside one variable now here I'm going to say my variable name is what my variable name is client now if I want to make a connectivity so for making a connectivity what I need to do tell me so here I need to pass my API key so how I can do that so here is a a parameter uh we need to pass one parameter over here so the parameter name is what parameter name is API unor key so here I'm going to write it down AP apore key and here I will pass my key so my key is what my key is my key so once I will uh run it so here you will be able to find out this is what this is my client so let me contrl Zed and here is what here is my client so this is what guys tell me this is my client now by using this particular client definitely I can call my chat completion API so let's try to call this chat completion API and here I have already written the code for that so let me copy paste uh I have written some sort of a code already I kept in my notepad so from there sometimes I will copy it uh because I want to save my time otherwise uh if I'm going to write each and every line so definitely it's going to take more time now here uh you can see so we are going to call this chat completion API now chat completion this is the particular method that's it now here is what here is my prompt now once I will run it so you will be able to find out I will be getting one response so here is my response let me show you this particular response and here is what guys here is my response definitely I can extract this response uh for that uh what I need to do so here I just need to write it down this response uh response and this response actually uh inside this response there you will find out this choices so I will write it down this dot choices dot choices now I will run it so here you will get this choices now from here what I need to do from here this is the list actually so here I will write it on this zero zero index whatever information is there on this zero index now from here I'm going to extract uh this particular information now here I will write it down this message message now here is what this is my message actually and from this message I'm going to write it down I'm going to except this content so here I'm going to write it down this dot content now guys see this is what this is my entire information now if I want to convert this particular information now if I want to convert this particular information in Json format so for that what I will have to do so here actually what I'm going to do I'm going to collect this thing in one variable that is what that is my output now here what I will do guys here I'm going to import Json so here I'm going to write it down import Json and here I'm going to write down json. load now to this load function I will uh provide my variable my variable name is what my variable name this output now here you will find out uh is saying this json. load it is giving me Str Str object has no attribute read okay it's not going to read let me check what is the correct function just a second so the function name is loads here guys you can see so the uh the method basically which I was calling so the method name was loads so Json do loads and here we are are passing this output now you can see this is what this is my output are you getting my point guys are you able to see what I did I I given this uh I given this prompt I given this basically I given this description to my model and I asked that okay just give me this particular information just give me this particular information from this description and here what I did I passed this particular prompt to my tell me to my chat completion API actually this chat completion API is calling this GPD 3.5 turbo model and here guys you can see we are able to get a response whatever description we have given according to that whatever prompt we have designed and it is giving me that particular response we have given a description we have designed a prompt and according to that only we are getting a response here you can see this is a response actually I have converted it into a Json format so this is the first thing which I want to show you now here guys see this type of prompt it is called few short prompt it is called few short prompt where I'm giving my description and I'm saying that okay so uh you need to behave like this means whatever description I'm giving to my model and here uh regarding that particular description I want to extract some sort of a information so here actually this type of prompt is called fuse short prompt now directly I was asking something to my model in my previous one in my previous uh session so here actually directly I was asking uh the question to my uh model to my llm model so this is called actually zero short prompt this is what zero short prompt now here this type of prompt actually is called few short promp getting my point this idea is getting clear to all of you please do let me know in the chat if you are able to follow me till here please write it down in the chat I'm waiting for your reply I'm sharing the text uh don't worry I can share everything in the chat so just a second um here is a text so here is a text guys I think it's a it's a half text let me give you the full so college and here is the full text because it is having a word limit I cannot uh like give more than 80 words I think I cannot uh like paste more more than 80 words in the inside the chat yes is it is it because we are asking for a number of variable in a second prompt correct your understanding is correct Goldie so zero short means we are not defining anything over here directly we are asking a question to my model now what is a few shot so here we are giving some sort of a description and based on that particular description we are asking regarding some information we are asking some information okay so this is called few shot and here is a zero shot don't worry uh we have a many example here I just given you the glimpse of that just wait for some time one or two more classes you will get more about it because uh now we just we are going to design The Prompt and all and in the next session specifically I will I will be working on the prompt on a different different prompt and even uh for the uh inside the project also we are going to design a different different prompts got it now see uh definitely we are able to call our l m we are able to call our like open a API and definitely we are able to get our output also from the llm models now here guys what is the use of the function calling so first of all let me uh Define one very basic function and then I will Define one Advanced function also so here what I'm going to do see here I did this particular thing by using this uh chat jpt Itself by using this completion API now let me show you the same thing by defining the function so here what I'm going to do so here I'm going to Define one function so let me do one thing let me Define one function and here this is my function guys see I'm going to define the function this is my function now from where I got this particular format so you must be thinking sir okay so sir you define this function now from where you got this particular format so just try to go through with the open API and here uh sorry open a documentation and here just click on this function calling and once you will scroll down over here so here you will get the code s snippet so and inside this code s snippet you will find out this function definition that how to decide or how to define this particular function getting my point I will come to this particular example I have designed one example for all of you but first of all let's try to understand a function calling from uh like very basic example and then I will come to the advanced part so here you can see we have a function and from here itself I took this function definition and how to decide how to define this function and all now let me tell you what I written over there so here I have opened this uh notebook now see uh what is the name of this function actually student custom function it's not a function like python we write it down that Def and all it's a like function basically which we are writing down for the open AI U actually we have to uh like pass this thing to the uh to inside the chat complete API itself I will come to that first of all let's try to understand this uh structure so first of all I I need to write it on the name so here I have written the name name is equal to extract student information then we have to write it on the description so here you can see this is the description of the function that why we are going to Define it now here you will find out some sort of a pairs so key and value pairs so first we have a parameter so here you can see we have a parameter now uh we have a type so which type of uh like object object we are going to be defined over here and then we have a properties now here you will find out inside this parameter you will find out a different different values like name school grade and Club whatever actually I Define over there inside my prompt the same thing the same thing over here right so first we have a name the second thing we have a description the third one we have a parameter inside the parameter we have a different different values like names school grade and Club getting my point now here just see the type of this name it's a string just see the type of this school it's a string a college you can write down the college here is a college so let me write down the college instead of this school so here is what here is college so instead of this is school I can write down this college now here is college the type of college is string right now here is a grade now grade type is integer now here is a club so Club type is integer again I think you getting my point that how to define this function it's a predefined format or the Inon platform itself you'll get this particular form format now just run it okay now just run it and after that what you need to do so here see you need to uh call the chat completion API so here is your chat completion API let me copy this chat completion API from here and let me paste it down now here you need to Define some sort of a parameter now let me write it down those particular parameter and then I will run it so here guys you can see we have this message so let me keep this message in a single line so here I'm going to keep this particular message in a single line so here is what guys here is what here is my message it is fine now after the message what you need to do you need to write it down one more parameter and the parameter will be what the parameter will be a function so here I'm going to write it on the parameter the parameter name is what function so here is my parameter function now tell me what is the name of the function so here the name of the function is nothing it's a student custom function so let try to copy it and try to paste it over here that's it you just need to copy the function name from here and you need to paste it over here okay as a value of this particular parameter now guys I can keep this particular response in response two so so here I'm going to write it down this response to so here is what here is my response to now let me run it and let's see what I will be getting so here is saying okay it is giving me error so I think uh chat completion role is fine I'm using client only let me check with the client yeah client uh now everything is fine what is the issue I you code incorrect API provided okay okay just a second let me use the correct client this is fine and here I can keep the Cent c l i e n t now see uh it is saying that incorrect invalid key uh why it is so um just to check let me check this key over here student custom information prompt is fine U but before it was giving me output now why it is saying like that let me check with a key over here so my key and here is what here is my key just a second guys let me take a correct key uh okay don't worry I will delete this particular key uh I'm running in front of you everyone but after the session I will delete it fine so now I am having my key and here what I can do again I can run it great now let's see yeah now everything is working fine so this is what this is my response to two and here guys you you will find out that we are getting a output so we are getting output in whatever format we have defined this thing so we have defined this thing like uh name College grade and club now here you will find out the same thing so name is there college is there grade is there and Club is there if you don't if you want to change any sort of a description you can change it and you again you can check it and now actually we are not we we are not uh doing directly this thing we are using a function over here and this is a very basic use of the function as of now which I have shown you getting my point so directly also you can do that you can call it but here they have given the function by using this function also you can call it okay so here actually this is the basic use of the function and at this point of time you you won't be able to find out any differences in a direct call and in a function call both is looking same but now the difference will start once I will explain you the second example now over here you can see so this is the response which I'm getting now let's try to extract the response so over here what I can do I can write it down this a contain and let's see what I will be getting over here so here is what here is my uh content which I want okay which I want to extract from here so let me copy it and let me paste it over here actually I want to extract the content so that's why I'm going to be write down response to Choice message and content so once I will done it and over here I will be getting this content so here I am getting this content now let me check over here okay actually see here actually we have to get the content from the function call so till message it's fine so let me check with the message till message I think it is fine now if I want to extract the content now so over here I will have to call this uh I will have to write it down this function call because before I was extracting the message because directly I did it directly I I called my llm model now here I'm calling it but by us using function so here I've defined the format in a function I have defined the format of the function and now by using this function I'm calling my API so the the API is hitting the model and whatever output desired output I want I'm getting it now over here what I will do so here I'm going to write it down this uh dot function call so let me copy and paste it over here function underscore call now over here guys you can see we are getting this particular value now let me write it the argument over here arguments and this is what this is my output now yes same thing we can do over here as well so here I can write it down this uh Json Json do loads and here what I can do I can write down the json. loads and now see I'm getting a same output but see guys here at this point of time definitely you are not able to find out a difference between the direct function call and between this uh direct call and this function call right now I will show you one Advanced example and by seeing that particular example definitely you will be able to discriminate getting my point so till here everything is fine are you able to do it don't worry I will give you the code and I will give you each and everything whatever I'm writing over here and uh this file and all it will be available inside my resource section so here is the resource section guys uh so just try to enroll into the course and uh yes definitely you will be able to get this particular file inside this resource section and this is completely free you no need to pay anything you no need to P you don't need to pay actually a single rupees for this for this particular dashboard so please try to enroll and try to download the resource from there so till here everything is fine please give me a quick yes then I will proceed with a further topic what is the difference between Json and function call so here you will find out so just check the type of this output so here you will find out the type of this output is nothing let me show you it's a string now here I have converted into a Json that's it okay I don't I I don't want to keep it in a a string because uh it's not looking good to me if you will print it now if you will print it guys see it's not looking good to me that's why I converted into ajason now if you will check the type of this particular output so here you will find out a Json let me write it down the type over here and let me print it now so here is what guys tell me here is nothing it's a Jon not dictionary got it so this is fine to everyone I think till here everything is clear great now let's start with the second concept so over here uh the first concept actually I shown you the basic use of the function and all now let's try to understand the advanced use of this function calling so over here guys see uh we have few more thing regarding these functions and all so first of all let me tell you that now let's say if you want if we are passing a description of two student all together so it can handle that thing also it can handle that thing also now over here let me show you that particular uh that particular thing also just a wait uh I have I have a code for that and I'm going to copy and paste see guys so what you need to do so over here I just written one for Loop and let me show you that particular for Loop and here see inside this for Loop what I have written so first of all I Define one uh list and inside this list we have a two description so the first one you know uh already I written this particular description now let me uh let me run it okay so what was the name of that so just a wait let me check um okay where I have written this student I think this one so that name the name of the variable is student description so let me copy and paste over here let me copy and paste this student description so this is what this is the student description this is the first one so let me write it down student description over here now let me keep it over here now student description now I'm going to Define one more so here I'm going to create one more variable and here student description two and here guys what I will do again I'm going to copy and paste a same thing so this is the value which I'm going to copy and paste and I'm going to do some sort of a changes over here so instead of this s Savita I'm going to write down something else so let's say I'm going to write it down Krish n so and here Krishna is a student of a compter computer science I uh maybe instead of this delh let me change the name so here is what here is Mumbai now here he is a cgpn so he's having more than 9.5 cgpa so let me write down this like cgpa as well and here let me change the name so instead of Sunny what I'm saying I'm saying Krish is known for his programming skill and he's a member of here I can write down DS Club data science club data science club so here I am giving an information regarding two student now here see he hopes to pursue in a career in artificial intelligence after graduating something else right so now what I will do let me run it and let me keep this particular description over here so here what I'm going to do I'm going to keep this particular description now what I will do so over here uh I I'm just going to run the for Loop and here you can see one by one the description is coming and it is going through this particular uh completion API this Chad completion API and I will be getting a response so let's try to make some changes over here because it's a like old code let me give the latest one over here so this is the latest let me copy and paste the latest function so here is what here is a client chat completion. create now over here the model name is what model name is same now here message uh it's the same this one now let me write down the student so it will be more uh like clear to all of you so here here uh you can see we are calling a function now here guys see we are calling which function this particular function let me copy the same name so here the function name is what student custom function so here I'm going to copy the name of the function and let me paste it over here so this is what guys tell me this is my function name and here is function call is auto right automatically the function is going to be called now what I want tell me I want a response so over here I'm going to print this particular response and let's see we'll be able to get a correct response or not so if I'm going to run it guys so you will be able to find out a response regarding two description so it is saying that check completion is not a subscribable okay so over here I think I will have to paste this thing now let me copy it and let me paste it over here so this is the one I think it is fine now and this is going to be a response so response whatever response we are getting there is a choice and inside that we have a message and finally function call and from there we are going to collect a argument so once I will this argument actually this arguments you can map this argument with this thing this uh thing basically which I have written over here inside the function name College grade and Club getting my point so here what I'm going to do now here I'm going to run it and let's see what I will be getting so once I will run it definitely I will get a response great so here it is giving it has given me a response regarding the first uh description and now guys you can see it has given me a response regarding the second description so the first one is s sabida and the second is kishna you can give as many as uh like description in all so over here let me take the third one and let me keep it over here and here I can say so here student description three three now over here instead of this krishak let's say I'm going to write down one more name let's say sudhansu Kumar and here I can say that he's a student of IIT Hyderabad or I let's say uh Bangalore now over here he's a Indian he's having a cgp around let's say 9.2 and he's programming skill and he's a active member of mlops club now let me write it down over here mlops Club so now yes I have given this particular description over here and if I'm going to copy it and let me paste sit over here so regarding this description also definitely we'll be able to call our model we'll be call our API and finally we'll be getting a output it's doing the same thing which our chat completion API is doing directly without function right now we are doing along with a function along with a multiple description getting my point so here this is the basic use actually basic use of the function after this one I will come to the advanc use just wait now over here see if I'm going to run it so let's see what I will be getting uh so here I will be getting a First Response yes this is my first response now this is the second response and here you can see there is the third response getting my point guys yes or no we can call our llm model we can we can call our API we can hit the model and we can summarize the result according to the prompt if this thing is clear to all of you then please write it down yes in the chat please do let me know in the chat guys if this part is clear to all of you yes it's a case sensitive whatever variable you are going to Define in the function col it's a k so please make sure that you are going to write it down the correct name after this one the use of the function call will be clear just wait okay fine now this thing is clear to all of you now let me come to the next point so here actually what we are going to do see uh we are going to call a single function right regarding this particular description uh this is my function but we can call a multiple function also we can call a multiple function also so here guys let's say if we are going to define a one more function here let's say if we going to define a one more function so you can Define any sort of a function over here let's say function two let me write it down over here function 2 function _ 2 you can define a second function and after defining see you will Define in a same format whatever format is there this one in this format itself so in this format whatever format I have written now the variable and the parameter and the description U and those thing will be changed but the format will be a same because the same format which you will be find out over the tell me over the open a API s they already have given you that so this is what this is my function two now you can like Define a function two whatever information you want so let's say I just want this grade and club or whatever so right so if I'm going to remove it you can remove it or maybe you can Define one more function for some other information right and now if you want to call it so how you will do that tell me so for that actually uh here I have created this uh list right here we have created a list of the student information regarding a different different description now here again I can create one more list the list basically the list regarding this function so here what I can do I can copy this code and I can paste it over here this particular code and here what I can do I can create one more list and inside this list what I can do I can write it down the function so here is what let me a copy and paste so this see this is what this is my function parameter now here we have a first function and we have a second function so this is this is my first function which I defined already this one so let me copy this particular name and let me paste it over here this one so this is what tell me guys this is my first function which I'm going to write down over here and this is my second function already I given the same name so like this you can call a multiple function also getting my point so here I have defined this function and according to that I'm getting my desired output desired parameter you can create one more function on top of a same description and here you just need to do one thing instead of this specific function you just need to write it down this function you just need to provide this list and you are done according to the definition you will get output so this is your assignment you have to do by yourself I have given you the way I have given you the path now just Define a second function regarding whatever information is there inside the description whatever you want to extract just Define a function and call it over here so here I can mention this thing as assignment don't worry each and everything I will provide you uh this notebook will be available in the resource section you can download from there this is what this is your assignment guys now here this part is clear that uh we are calling up llm so here directly we are calling llm then what we are going to do see we have designed a prompt directly we are calling llm then what we are going to do we have Define a function then uh like we are getting that particular output that is also fine now we are going to call our llm by using openi with respect to different different description that is also fine means regarding a like different different description on the same time now we can Define two function as well more on more than two function that is also fine now what is the actual use of it still we are not able to find out the actual use of this function everything is looking same now let me uh explain you that particular part I'm coming to the advanced example now so over here what I'm going to do I have written one Advanced example and uh let me copy and paste uh the code basically which I have written step by step I will copy and paste don't worry okay so here guys see again I'm going to start from scratch now Advanced example of function call Advanced example of function calling okay now over here guys see uh what I'm going to do I'm going to call my chat GPT so here I'm going to copy and paste one code now this code actually we have defined something over here so here I'm saying uh what I'm asking I'm asking to my llm that what is the next flight from so here I let me change the name let me write it down Delhi to Mumbai so here I'm going to write it down what would be the next flight from Delhi to Mumbai this is my prank now just tell me guys will my Chad GPT able to answer for this particular question my CH chat G is able to answer for this particular question the question which I'm asking over here I want your uh like p uh like I want your opinion on that please write down the chat I'm asking to all of you can my chat GP answer for this particular question no why why it cannot be answer because like this chat GPT has stayed on the limited amount of data right so not a limited amount of data it has stay on uh the data basically which is available till September 2021 getting my point if you look into the chat GPT if you look into the open a just just go with the open AI uh not this one so where it is this one so here guys just just uh go over here and uh what you can do you can go into the models now over here just click on this GPD 3.5 and uh just look over here training data so it has trained up to September 2021 data up to this particular data that's why it won't be able to answer for this particular question whatever I'm going to write it down here now let me run it and let's see the response that what response I will be getting so over here uh yes it is giving me a response let's wait for some time I got a response now and here I'm going to run it so see what it is saying that it is saying that as an AI language model I don't have a realtime information however you can easily find out next flight from Delhi to Mumbai by checking the website or mobile apps of Airlines so that operate the route such as air india indigo spice jet vistara go Additionally you can contact travel agency or use online flight scratch engine for up to date now just tell me if you are going to create if you're going to create any chatbot by using this open API so will you give this type of answer to your user if your user is going to ask you that what is the next flight from Delhi to Mumbai definitely you will have to do some sort of a jugar right you will have to extract the information from somewhere you you cannot give this type of answer right so you will have to make your chatboard that much of that much capable you you have to make your application that much capable so it can answer for this type of question as well okay now let me tell you uh the use of the function calling over here that how function calling can help to us so over here what I'm going to do here I'm going to Define one function what I'm going to do guys here I'm going to Define one function so this is what this is my function just like observe step by step don't run anything don't write it down any sort of a code just observe whatever I'm explaining to you that's it so here is what here is my function function description now we have a name of the function get flight info we have a description get flight information between two location now here we have a parameter and inside parameter we have two things so the first one you will find out that is what that is a location origin and location destination so in my case what is the origin delhi now here in my case like whatever prompt or whatever question I'm asking in that case the destination is what destination is tell me Mumbai so there is two parameter I have here is a type here is a description here is a type here is a description that's it so let me let me change something inside the description also so here I'm I can write it down Delhi d e l and here let me write it down the Mumbai mu M mu M so this thing is fine now here if you will observe so I have mentioned one more thing I have mentioned one more parameter over here the parameter name is what the parameter name is required now what is required location required origin location required and destination is required two things is required over here okay that is fine till here everything is fine we are able to understand but still we didn't get a complete idea how you will get it first of all let me run the entire code right so here you can see we have a description so let me run it and this is fine this is like perfectly fine now here I have a prompt so let me copy The Prompt over here I'm not writing from scratch because it might takes time so I already return in my notepad and all somewhere so I'm just going to copy and paste that's it so here guys um I'm asking to my chat GPD or sorry I'm asking to my GPD model when is the next flight from New Delhi to Mumbai this is my question now over here if I'm going to run it so here guys you will see that okay so this is my this is my user Prem now what I'm going to do now I'm going to copy it now I'm again I'm going to copy the same thing this one and I'm hitting this particular prompt so here is what here is my model here is my role role is what role is a user and here is my prompt getting my point now here now I'm passing my function just focus over here just focus now over here I'm passing passing my function function underscore description this is what this is my function description now see over here uh this is my prompt and if I'm going to run it now if I'm going to run it now now you will see the response that what response I will be getting before actually I was getting this particular response before I was getting this response now just look into the response that what will be the response over here so here what I'm going to do I'm going to copy the same thing uh this particular thing and here I'm going to write it down response to response to choice choice message and contain so once I will run it so here you can see it's not giving me anything okay so why it is not giving me let me show you because there is no such content there is no such content that's why it is not giving me anything now let me print till message only and you will find out the uh the like values over here so over here guys see if I'm going to print till message so it is giving me a message whatever message I'm getting step by step we'll try to understand it don't worry now here let me copy this thing and let me check with this particular argument so here I'm going to copy this argument and let's see what argument we have uh so over here it is saying okay first of all I need to call this function call and then only I can call this argument uh not an issue fine now over here we have a argument see we have two argument first is loc uh location origin that's a Delhi and location destination that's a vom getting my point guys see it is going to extract from here location origin and location destination and here is Delhi here is Mumbai this is a location origin location destination now it is not giving me answer but it is going to it is it is it is able to extract something right from this function call and here you can see these are this is two argument right there you will find out two argument this is the argument basically which we are able to get it from here because we have already defined it over here this thing okay that is fine this is clear to all of you now guys see how you will uh give this uh like flight actually so for that you will have to call any third party API then only you will be able to provide the information now right so let's say if I'm talking about the make my trip so what it does it is having access of a different different API if I'm going to book any train ticket so is calling the IR CZ API and is giving me the entire detail make my trip is not a owner of the Railway where it is having the entire data entire information of the Railway Indian Railway no IRCTC actually it's a organization actually that is a portal which is like governed by the uh Indian government and like it it is having some sort of apis and all which is being called by the make my trip or any other website and because of that only you are able to get an information whatever rails and all whatever flights and all you are going to find out over there or maybe some other website right so here what you will do for getting this information you will call the API any third party API now here see I'm not going to call any sort of API I'm giving you as assignment this thing so you can call any sort of API you can explore a different different API and you can accept the information from there I'm uh I can uh give you the very basic name rapid API just go through go and check with the rapid API there you will get the each and every API related to the weather related to the different different thing as of now what I did actually I created my own function which is working as a API I created my own function which is working as a API now let me give you that uh let me show you that particular function so here what I did I have created my own function which is working as a API you can think this working as a API but you can call your real time API for extracting a real data don't worry I will show you that thing I will uh show you how you can call the Sur API in my next class when I will discuss about the agents in a lang chain there I will discuss about the Sur API and all so over here you can see guys we have a uh I have created one function get flight info location origin location destination now here I'm going to be uh like here I written some sort of a code that is what that is nothing as a flight information and it is in a dictionary format so here we have a location origin destination date time Airlines and flight this is the airlines time and this is the flight number and all now here this function is working as a API you can think like that now if I'm going to run it so over here uh it is working fine now guys see what I'm going to do here so this function is working fine now here uh I'm going to collect this origin and this destination so first of all let me show you this particular thing uh argument I already shown you this one this is my argument and over here uh what I'm going to do I'm going to be convert this argument into a Json so json. loads now over here what I'm going to do so let me run it and here I am I having two argument uh first is Delhi and the second is Bombay this is my origin and this is my destination so this thing this information I'm going to collect in my like a variable that is perams now over here we have a variable that is perams now from here I'm going to extract few more information I want to extract the origin and the destination so for that I already written the code let me copy and paste so this is my origin so I'm calling this get uh method on top of this uh dictionary actually this is my dictionary and I'm extracting a value of this particular key as like this I'm extracting a value of this particular key you you can see over here let me show you so this is what this is my dictionary now on top of this dictionary if I will call this get method now uh by using this uh key so get and over here what I will do I'm going to write it on the key so the key name is what location uncore origin now over here see if I'm going to run it now you will find out this Delhi so this is my origin and here you will find out the destination similarly I can get the destination also now it's not a big deal see now over here I can call this a destination why I'm doing it entire thing will be clear and I will give you the quick revision also just wait for some time just wait for more 5 minute everything will be fine so Delhi is there Delhi and Bombay is there so here we have origin and destination now we got both origin and destination right so parameter is uh we are able to get a parameter we are able to get origin and destination now let's try to find out the flight detail right so let's try to fly find out the F flight detail so for that basically what I'm going to do here I'm going to call one uh so here I'm going to call one method that is a a right so what this a will do so here actually I'm going to pass the name so let me show you this particular value what is happening over here so just a wait let me copy and paste over here so this is what this is the name this name is what this is the function name get flight information right now I'm giving this uh function name uh this uh function name this GL get flight info which is a string as of now let me show you the type of this function over here so over here what I'm going to do here I'm going to write it down type of this function so this type of the function is nothing it's a string only so let me uh keep it inside the bracket so this is what this is a string now if I'm passing this thing to my eval function eval method so you will get the actual function this eval is doing nothing this EV is giving you the actual value that's it this is what this is the function now we have defined get flight information it will give you the actual value that's it so here you can see it is giving me the function only this is what this is my function this get flight info is what it's a function now it's not a string we have already defined it over here see this one so this is doing nothing it is just giving me actual value okay now let me show you one example very basic example let's say if I'm going to write down and here if I'm going to write down two now tell me what is this two if I'm going to write down like this uh type and here I'm going to write it down two just tell me what is this it's a string but two is a string no it's an integer right it's a integer so if I'm I'm going to write it down like this now if I'm passing to my so it will provide an integer see this is what this is an integer if you check with the type so type the type will be an integer only so it is converting whatever value we are passing into the well method now it is converting into a original format into a original form so here we are getting a function so this is what this is my function which I collected over here now I just need to call this particular function so here I'm going to call this function now after calling this particular function I will be get see here I'm going to pass the parameter keyword argument keyword par like this this particular parameter params this one okay location origin and location destination this two thing we want over here this one right now once I will run it so here I will be getting my details so let me run it first of all uh where is a perms here is a perms and here is what here is my flight details so name date time is not defined let me Define the date time over here so from date time on of date time import date time and it is done I think now let me run it time Delta is not defined let me check what all import statement is there just a wait time Delta also we can import from here itself so this is going to be a time Delta great now let me run it and over here you will find out a detail see so actually what we are going to do uh this function actually uh you can think it's a it is working as a API got it now here what we are going to do so we are extracting a information from the uh like whatever prompt and all we are passing now so from there basically we are extracting an information and we are collecting a detail of the flight okay from U like this is the response actually see first what I did I defined a function this is what this is my function this is what this is my function right after that we are calling the uh after that we are hitting to the uh like model by by using this open API now after hitting it so actually whenever we are checking with a response so in argument actually in a function argument we have this two thing now by using this two thing now what we are going to do so we are uh like extrating the information from here so as of now this is this function actually you can think it's my API but you can call actual API by using this particular information that is what I'm doing over here just just think over here that is what I'm doing so now what I did what I got tell me guys so I I collected the information whatever see I Define the thing inside my function inside this particular function okay this one this is the value this is the like parameter which I defined now I uh I like called my model I called my open API and it is hitting the model right so whatever response I'm getting now from that particular responses I'm getting this particular argument because my chat GPT is not able to answer for this particular question and by using this argument I'm hitting my API I'm hitting my API and after hitting the API guys you can see this is the detail this is the information I'm getting okay by using those particular argument now let me show you the complete one so once we are getting this particular information the flight information regarding those particular argument okay you can create an end application here I'm showing you in a notebook itself so here see guys what I'm getting now give you the final code so we are getting this particular information and is done now let me uh go for the final call so here you can see uh I can keep it as a uh response three client chat completion create now here is what here is my model and here is what here is my user prompt whatever prompt I I'm passing now see guys over here see role is what role is a function now I have changed the role okay uh here is a role role is a user now role is a function function now this is the value I'm extracting from the function whatever function I'm defined and here is what here is a like content basically which I'm passing this is what this is a flight right so this is the argument which we are extracting from the function whatever function I have defined right and then this is what this is my function description that's it right so here see guys uh my role role as a user as a role as a user basically what I'm asking to my uh chat GPT or sorry to my GPT model let me show you that so over here what I'm going to do I'm going to print it this user prompt this is my question this is my prompt this is what basically which I'm going to ask right now over here roll again I Define one more role that is what that is a function right now over here I'm going to pass the name and here I'm going to extract the like function the the ex exact function over here you can check over here you can like copy it and you can paste it over here this one so just just paste and you will get this function called now just collect the name name of the function do name so what is the name of the function get flight info right now here is what content is nothing content is a flight now as soon as I will run it so here you will be able to find out that we are able to extract the information now let me show you this response three so here is what here is my response three and guys see what I'm getting over here so let me print the final one and here you will be able to find out a detail so let me run it see guys so now let me call the uh this uh function call just a second function uncore call function _ call and over here guys you can see we have argument and actually we have a message over there just a wait let me show you that also uh function call and argument okay just a wait oh message inside the message message itself I will be able to get it uh where my message is coming inside a choice and here okay I need to call a Content actually just a second message function call this is my function call that is fine now here Choice uh just a second choice what we have inside a choice okay it is a response three fine fine fine I was checking with a response two uh yeah this was a response now it is fine it was a response three I was checking with a response two it's my bad it's my bad uh okay now let me collect the message from here so here is what here is a zero and uh now let me call this message so here is my message and let me collect the content tent and here is what here is my content guys so did you get it what is the use of this function calling now let me give you the definition of this function calling in a single line so just a wait I'm giving you the definition definitely you will be able to relate now so if we are talking about this function calling now so here is a definition of it let me copy and paste so what is our definition of the function calling so function calling is nothing learn how to connect large language model to the external tool that's it we can define a function we can Define the parameters we can Define the values and according to that we can get our responses from the third party API and here I have defined this particular function M function is a third party API but you can call the realtime API and you can get the information you can get the exact information this thing is clear to all of you yes or no how many of you you are able to get it how many of you you are able to understand this thing if you can let me know in the chat so I think that would be great again I will try to revise it uh I will give you the quick revision of it and then I will move to the link chain will you revise it please do let me know in the chat will you revise this concept I'm waiting for a reply if you can answer me in the chat I think that would be great yes I'm going to revise it just wait just give me a second first of all uh do let me know how much person you got so if you can tell me uh in a percentage also so that would be great I will get some sort of idea that okay you are getting something from here whatever code I'm writing you're getting from here so please uh do let me know 80% great 70 70 80 yeah if you're getting 70 or 80% now so I think rest of the thing like you just need to revise Sor is saying sir I'm just getting 10% so Sor in that case you need to follow from a very first session just check with the very first session and then come to the second one and then come come to this third one if you are near to 70 to 80% now then you just need to revise it once that's it yes correct uh your understanding is correct here we are extracting value from given prompt using function call what is the meaning of the role is equal to function which one here we are defining now see we have a user so user is asking a question and rest of the information we are going to collect from here we are defining one more role we have we can Define many roles over here um we can Define uh like uh we can Define the system we can Define role as assistant we can Define role as a user user we can Define role as a function user is asking something and uh and uh from wherever basically we are going to be get output or we are getting a uh we are we trying to exct the information regarding this particular prompt so we are defining as a rle over here that's it great so let's revise it now and then I will go for the Len chain so we'll try to understand the langen chain and all already I have installed this L chain and try to hit the open API and tomorrow we'll understand the lch in a very detailed way uh today uh just a quick uh understanding quick uh uh first of all I will give you the quick recap of all those all this thing and then I will come to the lon part so let's understand this function calling one more time from scratch great so over here see we are talking about this uh we are talking about this chat completion API and I think you know about it how many time we have discussed so we're passing the prompt here is my prompt and we are getting the output now Today I Started from the like a different type of prompt so uh today I have started from the function calling so here I have defined one description and here I'm writing uh the prompts my prompt is saying that uh here you need to extract this information from the given description that's it now here you can see uh this is my client this is what this is my client now here I'm going to call my chat GPT and sorry I'm going to call my GPT model so after that what I'm getting I'm getting my response I'm going to convert into a Json and this is fine right this is fine anything you can ask to your model and you can print as a response you just need to define a prompt that that's it now here the same thing I'm going to do by using this function so here I'm going to do uh the same thing by using this function now here I'm going to define a several parameter so this is my parameter name College grade and Club it should be a same similar to this prompt itself whatever prompt I have defined I have written right so just look into the prompt I will share this notebook then you can check it should be similar to that only this particular properties this particular values now over here uh you will find out that okay I again I'm going to call it again I'm working I'm like role I've defined as a user there's a Content prompt and you are getting a response and here you are getting a response now guys here you can see we are going to print a message and finally we are getting a same thing by calling this uh by using this function call as well now here actually once you will look into the prompt we have defined one thing over here we we are saying that uh return it as a Json object return it as a Json object so whatever response you are getting now from from the openi side also I tested the same thing of the CH GPT see I given the description this was my description and CH GPD has given me output is a Json format so if you are calling it now uh this uh like a GPD model so it will give you the output in a Json format this one so here it is giving you the output this particular output in a Json format this one actually it's a string but yeah we can convert into a Json and that is what I did now the same thing why we are doing by using this function now over here H it's fine it's clear now here I've given you a few more uh like functionality regarding this function I can call it for the several description in a single sort I just need to keep the for I just need to write down the for Loop over here so I'm getting a multiple responses for sun for Chris for sansu right so here I'm getting a multiple responses now here I given you an assignment so here I told you that you can call a multiple function also don't call a single function here I'm getting an information from the single function but you can call a multiple function and here I shown you the way you just need to define a function in a list and that's it so here is a function you just need to define a function in the list and just pass it over here and according to that only you will get a response getting my point now here I've shown you the advanced example of function calling and that's a real use of the function and here if you want to Define this function in a single word in a single line if you want to understand this function in a single line so here you can see this is the definition learn how to connect large language model to the external tool so here what I want to do so here let's say uh this is my model and here I'm going to write down some sort of a prompt where uh like it is going to be a request and here I'm getting a response now this prompt actually it's something uh related to a real time I'm asking a real time question that just give me the flight just tell me like what all matches uh we have in upcoming days or uh just tell me the weather okay something like that so I'm asking a real time information it won't be able to provide it to me in that case what you will do so you are not going to call your llm now because it is not trained on that uh on it it has not been trained on top of that data actually if you are talking about this GPT so this GPT actually train on this uh till actually till September 2021 so this GPD train till uh 2021 only now in that case whatever prompt you are going to be write it down you won't be able to get a response right so here this function calling comes into a picture so once you will Define the function now so here what you will do you are going to define a function you are going to different Define a different different arguments and all each and every information you are passing to this function that's it now you just need see here this argument what you will do by using this particular argument you will call a third party API third party API third party API now you will call this third party API here or whatever function you are going to Define and whatever prompt you are writing according to that you will get a response because this llm is not able to provide you the response right and the same thing the each and everything you can do by using the chat completion API only chat completion method you can say chat completion API or chat completion method both are fine by using this chat completion method now let me show you in terms of coding so over here if you look into the code so I'm doing the same thing here I have defined a function see this is what uh first of all I'm asking to my first of all I'm asking to my uh llm model it is not able to answer now after that what I did I defined the function got it after that I defined a prompt I'm passing to my model I'm passing to my actually uh this uh like chat completion method so here is my user here is my prompt and here is my function description by doing that what I'm able to do I able to extract few of the uh few value whatever is there inside this function whatever I have defined over here because here I'm writing in this function description now after that this value I'm using and this is what this is my API okay this this is my like it's not a real API it's like a virtual API whatever you can say now whatever value I'm passing whatever uh thing I'm collecting from here I'm passing to this API and I'm getting a response over here this is the response this is my response got it now what I will do here now I compiled each and everything over here inside this chat chat completion method so how I compile this is my model this is my prompt this is my user this is my prompt this is my function call this is my function call along with the argument and over here this is my function that's it if I'm going to run it now it is going to extract the information from the third party API which is my function as of now now you can take as assignment you can call the real time API you can use the rapid API you can do that you can call a real time API so now this function calling is clear to all of you yes or no correct ran your understanding is correct now your understanding is correct and I think you are able to get it now let's start with the length chain so we have a a 10 minute uh now we can understand the concept of the length chain and then from Tomorrow onwards I'm going to start with the Len chain now first of all let me write it down the uh code for the Len chain so here I'm going to write it down Len CH and here uh you can I can mark down it and uh so first of all guys what I need to do so I'm going to start from the Len chain uh so the first thing very first thing uh I need to import it so let me give you the entire code okay so step by step let me write down each and everything so first of all I have to import the Len chain so here I'm going to write it down import length chain now here I have imported the Len chain now from this like in this lure actually we have a different different modules we have a different different module and inside that we have a different different classes so as of now we are going to use the open AI so here I'm going to write it down from Len chin from Len we are going to import this open AI so lenin. llms and here I'm going to write down this open AI okay so we are able to import this open AI now what I will do so initially I told you that this lenon is nothing it's a wrapper on top of this open AI so you can think that this is my open AI right this is what this is my open AI now on top of this open a on top of this open API this lench is nothing it's a wrapper okay so this is what length chain now here whatever request we are making whatever request we are making right so now we are not directly using this open a now we are not directly using this open API instead of that we are using this L chain so our request is going through to this a len chain and then it is hitting this open AI but this Len chain it is not restricted to till here itself we have a many uses of the Len chain getting my point this Len chain is not restricted to this one only we have a many uses of the link chain I will talk about those uses and this Len chain actually it's a very powerful uh it's a very powerful application it's a open source I will show you the source code as well uh even we can search about it so let me show you that uh let me show you the source code of the Lenin so here I'm going to write it down Len Chen Len Chen GitHub so here is what guys here is a len Chen GitHub uh just a second yeah so this is a lenion GitHub now you will see the number of folks the number of star number of folks number of start number of watching right so number of watching in a real time and this length chain is really amazing let me give you this link inside your chat please try to uh explore it by yourself and it's a very uh Power powerful and very important as well if you want to build any llm based application so you can use this length chain it's a it's completely op source and here you can see used by 40,000 people and here is a number of contributor you can also become a contributor if you like to contribute in a open source now here you can see the commits 7 hour ago they committed something just just go through with this commits and check what thing they have committed what what changes they have made over here try to understand it and this package actually it is available on the pii repository so just go over the pii repository pii Len chain and search about the Len chain and here you will find out this Len chain this is what this is a len chain guys this is a like they have hosted the package on pii repository and it is a latest version of The Lang chain now here also just just uh scroll down here also you will find out the same thing uh deployment so they are doing a deploy here is a package package see this is the release so 0.0.3 46 0.0.3 46 this is the latest uh version which you can see over here as well this one is uh so far they did 297 release total 297 release see this is the total release actually total number of release now you can see over here as well just go inside the real uh just go just click on this release history and check the uh entire uh like release related to the length CH got it right so here is a latest version of the Len chain similarly we have a llama index two also and this Len chain is a open source and the Llama index 2 it's a framework from The Meta we can do a same thing by using this llama index 2 also I will come to that I will come to the Llama Index right now over here see we have this Len chain we have this openi now let's try to create now let's try to create object of this open Ai and here what I need to do guys tell me here I'm going to here I'm going to pass pass my open a key so first of all uh I will have to pass the parameter now let me um give the parameter over here and here I need to write it down this my key and here is what here is my client right now I just need to call one method and my method is going to be a predict right so my the method name is going to be a predict so let me write it down over here Cent c l i n t dot predict now here what I need to do here I just need to pass the prompt prompt is what prompt is a input whatever input we are passing to the model that's it so let me Define The Prompt so here I'm going to write it down the prompt and this prompt let's say I'm going to ask to my model what I can ask so I can ask can you tell me total number of country total number of country in Asia so here is my question so I just asked a little tricky question not a tricky actually it's a straightforward so uh here is my question my question is what my question is can you tell me total number of country inia now this is called guys zero short prompting what is this tell me this is called zero short prompting this is what guys tell me this is a zero short prompting now here if I will run it and here if I will pass my prompt to My Method client don't predict so here you will get output so here it is saying that there are 48 country in Asia if you would like to uh if you want to name then here you can mention can you give me can you give me top 10 country name so here uh I have extended the question now and now see over here I will be getting a name of the country so it is giving me the sash slash sash is nothing it means it means that if I'm going to print it now so it will print after two line so for that what you can do you can just call this a strip SD and it will strip your output so here you will find out the correct output so there are 48 continer isia the top 10 country by population in Asia these are the country now here if I'm going to write it on print so you will get a output in a correct format so here guys you can see you will get output in a correct format so there are total 48 country in Asia and these are the top 10 countries China India Indonesia Pakistan Bangladesh Japan Philippines Vietnam Iran and turkey got it guys how to use lch I just given you the introduction of that but there are many more things so all the things uh uh the remaining thing definitely we are going to discuss in next session as of now just think that this uh lench is nothing it's a rapper on top of the open AI but it is having a lots of uses it can call any third party API it can call any sort of a data resource it can uh like uh it it it is having a power to read a different different documents it's a having a power to making a change to making a memory it is having a power it is uh it is not only for the open AI we can use this lenen for any open source model any open source llm model and tomorrow I will show you here I have used so let me write down tomorrow's agenda what all thing we are going to discuss tomorrow tomorrow uh tomorrow's agenda so we are going to uh cover hugging phase hugging phase API with Len chain uh and we'll try to understand the use of the Len chain use of the length chain so we'll try to understand this use of the Len chain in very detailed way so this will be the agenda for tomorrow's uh like this this is the agenda for tomorrow's class and after that I will directly jump to the project we try to create one project and with that your understanding will be clear and rest of the topic we'll cover after uh after the project and all so tell me guys how was the session did you like this session uh did you uh did you got everything yes or no whatever I have explained yeah meanwhile you can explore it by yourself that is a good idea tell me guys fast uh did you like the session please do let me know in the chat if you are liking the session if you're liking my content I have WR and I I created each and everything from scratch by myself only and believe me if you are following this notebook if you are following my content you won't face any issue and even in our interview also you can answer in a better way okay so I think uh now uh we have covered all the thing whatever I told you and uh yeah all the resources and all you can find it out over the dashboard so we are uploading each and every resources in a resource section so just visit the dashboard and here uh we have all the videos videos and quizzes assignment each and everything we are going to update over here so along with the session you can and practice now here uh we have our resources regarding the first session so all the all the PDF and all all the PPT so at least you can revise the thing you no need to go through with the video again and again you can directly uh download the resource and you can look into that if you have attended my live session and here we have a IPO NV file also so just visit this uh resource section and this is the IP VB file now I will update this IP VB file in my day three video and along with that we'll be having some quizzes assignment and don't worry I will give you more assignment more quizzes and see in between whatever I'm leaving so here I told you that you need to create your own API this one uh in an advanced example of function calling so just use any API okay just search over the internet I told you you can use Rapid API and try to get a realtime data instead of this uh dummy function which I created over here you can take it as assignment here I told you that you need to you can use multiple function right in a single shot just try to create one more function define it in your in your own way and then uh run it and uh get an information so here I'm getting an information regarding three user you can add more user and you can add multiple function over there so now let's start let's begin so in the previous classes uh in the uh previous three classes actually I have talked about the generative Ai llm and then I came to this open Ai and yesterday I have I did the detailed discussion on top of this open Ai and I have introduced the Len chain to all of you uh so guys this is the notebook inside this notebook I have kept each and everything whatever notes whatever code and all whatever thing I was doing all right so uh in terms of code and all so each and everything I have kept inside this particular notebook and this notebook is available inside your resource section so from where you will get a resource guys so for for that uh you need to go through with the dashboard so here is your dashboard here you will find out uh here you will find out all the recordings U Day One recording day two recording day three recording so just try to go through with the day three you just need to click on the uh day three and here uh check with the resource so go inside your resource section and this is the dashboard guys generative AI Community Edition English so here you will find out uh two dashboard uh the two Community dashboard one for Hindi and one for English so this is for the Hindi one U actually I'm taking a same classes on a Hindi uh Channel as well I on Hindi I on teag Hindi you can search over the uh YouTube and the uh it's it is your one this English one so just go and check with your dashboard you will find out all the recordings and all so click on this day three and here check with your resource section so okay so resources is not there I have already given to my team but don't worry I will check and here is what guys here is a a notebook so uh definitely I will provide you this particular notebook inside the resource section so you all can run it you all can run it and by running it you can uh revise the thing and all and apart from uh this notebook apart from this resources you will find out the quizzes and assignment also so please try to enroll to this dashboard try to visit the Inon website sign up over there login and then uh enroll into this community session for this commun session you no need to pay anything it's just it's a free one okay so just just go through with the Inon website and login um after sign up do the login and you can access this particular dashboard and you will find out the same dashboard in a description also so just just try to check the description of this video of this live section you will find out the dashboard or else you can check with the previous Live recorded session also which is already available on the over the Inon YouTube channel got it so this uh resource uh part is clear to all of you now in today's session what all thing we going to discuss so guys first I will will start from the Len chain first I will explain you the complete Len chain that what is a len chain what all things we have inside the Len chain why we should use it why it is too much powerful each and everything we'll try to discuss regarding the Len chain and after that I will come to this hugging phase I will explain you that how you can uh how you can use any any like open source model from the hugging face Hub got it yes or no so in the previous class I told you that whatever model whatever model is there over the open AI platform how you can use that by after generating a API key now in today's session after discussing this lench I will come to the hugging phas and I will show you I will show you that after generating a API key hugging face API key how you can utilize that particular model so each and everything uh we'll talk about in today's session uh whatever I have told you and after that we'll start with the project so in tomorrow's session or maybe day after tomorrow so I will start with the project end to end project I will use this openi concept hugging face concept linkchain concept and I will uh show you that how you can create a web application end to end web application and then we'll come to the advanced part like vector databases and some other topic so I think uh everything is fine uh the agenda is all clear uh so please give me a quick confirmation in the chat if we can start then and whatever I have explain you whatever I have explained you so far so it is clear or not so please do let me know in the chat uh if it is clear and if we can start then I'm waiting for your reply fine so I got the answer now great so let's start uh let's start with the topic so in this uh uh notebook itself I'm going to write it down the entire code uh of the Len chain so whatever thing is there regarding the Len chin I will try to do here itself and whatever thing uh things will come into the picture uh whatever other libraries and all so definitely we'll try to install all those library in the current virtual environment now here guys uh I told you that how to create an environment how to uh launch the Jupiter notebook how to install the openi over there how to uh like install the langen each and everything I have discussed in my previous session so if you don't know about it so please go and check with my previous session there I did a detailed discussion regarding the environment setup got it now here guys um already I have written some sort of a line some U like sort of a quotee for the L chain yesterday actually I I like uh I was uh I I have imported the Lenin and I have used the key the openi key and basically I have imported this openi class and I created a object then I uh written a prompt over here and here I was uh like giving this prompt to my open API and in the back end it was running the llm model and here you can see this is what this is my output got it now here I I had written actually this this this is the today's agenda whatever thing we are going to discuss in today's session so hugging face API use of Lang CH and all so each and everything we'll try to do here itself in the uh in today's class itself so first of all let me write it down each and everything over the Blackboard so with that you will get a clearcut understanding regarding the agenda and all that whatever the thing I am going to discuss and after that I will come to the code part code section so let's start uh with the agenda now in today's class guys we'll be talking about the Len chain so let me write it down over here in today's session we're going to start with the Len chain now what is a len chain why we use Len chain and what is a difference between this open a and this Lenin so each and everything we'll be discussing over here itself now the first thing the first thing which we going to discuss in the Len Chen the first thing how to use Len Chen or how to use open a uh how to use how to use open AI by a lang chin so how to use open AI via Len chain that's the first thing we'll try to discuss got it after that I will come to the prompt template prompt uh templating so how you can do a prompt templating by using this Len chin so the second thing the second topic which we're going to talk about that will be a prompt templating promp templating the third thing which we're going to discuss inside the Len chain that will be chains we'll talk about the chains that what is a chains uh how we can utilize this chains what is the meaning of the chain how uh what all the different different type of chains is there each and everything we talk about over here then we'll talk about the agents that what is the agents okay so we'll talk about the agent that what is the agent and what we can do by using this agent so each and everything we'll try to discuss regarding this agent and here if uh so here I will show you that how you can use the Google API so by using the Sur API so what I will do so by using the surp API I will try to I will try to use the Google API Google API Google search API so in the agent section I will explain you this particular thing and after the agent the fifth one the fifth topic which we're going to discuss that's going to be a memory so we'll let you know that how we can retain the memory how we can retain the memory like chat GPD is doing how we can do the same thing if we are using this open API so we will try to discuss this memory uh memory part as well and which is a uh like which is available over here inside the lench and by using this Len Chen we can implement this particular feature after this memory I would come to that uh document loader so uh how we can load our different different type of documents so document is nothing documented just a file like PDF file CSV file tsv file or any other file how you and load that particular document so we'll talk about a document loader as well so here let me write it down document loader after completing all these thing then I will come to this hugging phase hugging phase I will show you how you can I will show you that how you can uh generate a hugging face API key hugging face API token and how you can utilize any sort of a model whatever model is is there over the hugging face Hub so how you can use that particular model so I will talk about the hugging face after that and finally we'll move to the project section so uh this is the agenda for today's session for today's class and apart from this each and everything I have explain you how to generate a open key how to uh like use a open a what is chat completion what is a function calling and all even I have talked about the basics of the langen as well so if this part is clear to all of you so please do let let me know in the chat if till uh like if the agenda is clear so I just want quick yes in the chat and please do let me know how many of you you are writing a code along with me because today I will go a little slow so you also can write it down the code along with me please do let me know guys please write down the chat good I think many of you you are writing a code mhm uh just a wait just uh give me a second fine so let's start with the uh agenda now so here guys you can see I have written a agenda and first of all uh let me explain you that what is a len chain why we are not using this openi API why we are using this Len chain and uh why it is too much important this Len chain and this llama index to so first of all let me talk about uh the differences between this open Ai and this Len chain and then I will come to the implementation part so here uh first of all let me write it down the limitations of the chat GPT sorry limitations of the open a API uh limitations of open AI API now here guys see uh if we are talking about this open API so here you won't be able to find out a free model so the first thing actually the first thing uh in the limitation uh like which we are going to talk about so here open a model is not a free one so here let me write it down open AI model open AI model open AI model is not a free now let's see uh let's assume that okay so the model is not a free one and if I want to use the llm uh like if if I want to use the llm capability or that AI capability in my application I if I don't have a budget so what I will do I will go with the other option other free option open source option okay so let's say some XYZ organization some XYZ organization created one llm now I want to use this particular llm so yeah definitely what you can do you can use the uh API whatever API this XYZ company has given to you and by using that particular API you can use this particular llm right now let's say you don't want to use this llm you want to use some other llm now how you will access it by using the different API now let's say if you want to use some other llm whatever llm is there let's say uh one LM is over the hugging phas Hub right if you want to use that particular llm large language model from the hugging phase right if you want to use it then definitely you can use it by generating that particular API key but guys just think over here uh yes we are using a different different API over here first of all uh we were using this openi API but as you know that openi model is not a free one for uh uh like if you want to use it so definitely we'll have to pay something and how we're going to pay it so based on tokens yesterday actually uh day before yesterday I shown you the uh the token price and all that how much you will be a charge if you are going to use this openi API if you are going to use a different different model over there I told you regarding the input tokens output tokens each and everything I have discussed so just go through and check with the previous session okay so if you are not aware about it now let's say if I want to use any XYZ llm or any other llm so how you can use it by using their API key but just think that uh just think on top of it if why not like if we have any one solution so the one solution actually it can interact with several apis right so here I'm using this open API I if I want to access this particular model definitely I'm using this XYZ API or let's say some other model for that I'm using this XYZ API or maybe I'm downloading it but just think on top of it if we have any single solution for all the llms with that particular solution if we can access all the llms to that will be well and good now so lenen provide you that capability Len chain provide you that capability so by using this Len chain you can access any sort of a llm right I will let you know that uh what all llm and let's say this openi is not a free one now let's say if you want to access a model from this hugging phase let's say you want to access one model from the hugging phase so this length chain gives you that particular capability by using the Lang chain you can access the model from the hugging face also and from a different different apis I will show you what all apis this Lang Chen is having I will come to the documentation so Lang Chen is not restricted till this open AI it is having an access of a multiple API that is the first thing here is a limitation and here I told you the advantage of the Len chain I think you got my point now the second thing if we talking about this GPD model uh if we are talking about the GPD model you know this have been trained till September 2021 data this train till September 2021 data if I'm going to ask anything to my chat GPT or if I'm going to ask anything to my GPD model definitely it won't be able to reply me and you all agree with this thing getting my point so if you will ask to the chat GPT that uh just tell me who won the recent Cricket World Cup will the chat GPT uh able to answer this particular question no it cannot answer to this particular question because this have been trained till September 2021 data so for that what I will have to do I will have to call any third party API for extracting the information yesterday I was doing by using the function C in op open a right but here by using this length chain we can do in a more efficient way getting my point why we use this length chain because here if we are talking about if we are talking about this uh like if we are talking about the limitation of the GPT so I can write it down over here uh it is uh it is having limited knowledge so let me write it down over here it is having it is having it is having a limited knowledge a limited knowledge till 2021 so if I want to extract something if I want to extract something if I want to exess some extra if I want to exess something which is which happened uh recently or uh any like real time information so for that also like we use this length chain and apart from this you will find out uh like different different like function or different different functionality inside the Len chain this Len chain actually it's a more powerful so here there I have given you two main reason that why you should use the length chain now here by using this length chain so let me write it down over here by using the different color so we are talking about this length chain so by using this length chain what you can do you know so you can access any model okay so you can access different llm model different llm model by using by using different API whatever API this lenion support by using different API second thing you can access you can access you can access uh uh private data resources private data sources you can access uh any third party API so here let me write on the third point you can access you can access any third party API got it so this is the uh like some features of the length chain now if we are talking about this length chain so let me do one thing let me create one Circle here what I'm going to do so here I'm going to create a circle now here I can write it down inside this particular Circle I can WR write it down this length CH so what I'm doing here I'm writing down uh just a second so here I'm writing down length chain now what this length chain can do so this lench actually it is having a chain so it can create a chain I will tell you what is a chain it can read the documents okay so document loader it is having a document loader now here I can write it on the third one so it is having a concept of agent for accessing any third party API agent now this can access any sort of llm so let me create Arrow over here so here I can do one thing I can uh give the arrow so what it can do so here uh let me keep the arrow so it can access any sort of a llm large language model from a different different API whether it's a open AI or any other API I can give you the example of two as of over here hugging face hugging face and open Ai and open AI and it it is having a access of a different different apis as well so it is having agent it is having a chains it is having a document loader and it can retain the memory as well so we are talking about the fifth one so it it it can retain the memory so let me write it down over here what it can do guys tell me so it can retain the memory it can retain the memory I will uh come to that memory part so this one langin actually it can do a multiple things it can perform of multiple things and here I have written a couple of limitations of the openi API and this is a limitation which you will find out inside the openi API openi model is not a free one and it is having a limited knowledge so here guys you will uh so what is this what is this Lang chain so here this Lang chain actually it's a open source framework which provide you a multiple functionality with that you can create a agent you can connect with any third partyy API you can create a memory you can retain a memory you can uh read a different different kind of documents like CSV tsv PDF or whatever and here you can create a chain you can create a prompt template also I forgot one thing so here I can write it down you can create a different different a prompt template so let me write it down over here different different prompt templates got it are you getting my point so if we are talking about so see if we are talking about in terms of openi the code basically which I have written inside uh my previous class this one so what is this it's nothing now instead of using open API directly I'm using one wrapper on top of that that is what that is a len chain so over here let me write it down one more thing one more point so just just think over here that this is what this is my open API let me let me draw it over here so here is what guys tell me so here is my open AI API this one now here we have a L chain sorry uh here actually see this is open a API and how we are making a request to this open API so this is what this my Lang chain now if we are going to run any sort of if if we are passing any sort of a prompt right so just just think over here if we are passing any sort of a prompt so we are running it we are running it through this Len chain okay so we are passing a input this is what this is my l Len chin Lenin and here this prom is going through now to this open API open AI API and here is what here is my llm if we are talking about with respect to this openi API so like this it is working it's nothing it's just a wrapper it's just a wrapper on top of on top of open API on top of open a API it is what guys tell me it's just a wrapper on top of this open AI API and not this open a API actually it can do a multiple thing so it can do a multiple thing right so let let me tell you what thing it can do let's say this is your application so here what I can do so let's say this is what this is my application and here is what here let's say I have used this Len chain this is what guys tell me let me change a color so this is what this is my Len chain now if I'm us using this SL CH so it can interact with many it can interact to a many uh like apis like hugging face open or with any third party like API so let me draw it over here this one this one okay now let me do one more thing so over here let me draw uh one more Circle and with that maybe the thing will be more clear now here what I can write it down let's say this is what this is your application okay so over here I can write it down this is what this is your application so this is this is your app now it's making a request so this request is going through this Len you can uh think that it just it is nothing just a prompt is we are passing we want to interact with llm actually large language model so here we are passing a prompt so first it is going through this Len chain this is what this nothing this is my Len chain now this Len chain actually it can it can interact in a many ways so over here I can write it down some sort of API so here I can connect with the open AI open API I can connect with the hugging face hugging face API I can connect with a bloom API and I can access a different different llm I can access what I can do I can access a different different large language models getting my point yes or no and apart from this this Len can connect with a other data resources also with some third party API like Google like we Wikipedia and some other data sources now tell me guys this length chain is clear to all of you what is the length chain here I have uh here here I created like each and every diagram and with that particular diagram I have I I try to explain you each and everything regarding this Len chain so please do let me know in the chat if this thing is clear or not I'm waiting for your reply please do let me know yes I will share this PDF note with all of you don't worry uh I will keep inside the resource section please do let me know in the chat guys if this thing is clear then I will proceed further I will proceed with the Practical great so if you are liking the content then please hit the like button also so I will get some more motivation so yeah guys please hit the like button and please be interactive if I'm asking something then please try to answer please please write down the answer in the chat uh that will be a great motivation for me okay now let's start with the Practical implementation so over here you can see I uh started with a len chain so let me uh run it first of all so here is what here is what here is my Len chain now uh here I'm going to be import my open a uh this uh each and everything I have explained in my previous class itself now let me uh import first of all let me check with my key this uh I will have to generate a openi key if I want to access the open API now now I'm not directly going to hit this open openi API I am hitting by using this length chain getting my point so here I will have to mention the open API key so let me take my open API key just a second uh so here I can keep it somewhere just wait uh so here is my openi key now let me paste it over here this one so yes I have created my client means I have created my object now here is what here is my prompt here is what guys tell me here is my prompt now what is the prompt guys tell me the prompt is nothing in whatever see prompt is nothing it's just a sentence which we are passing to to our llm as a input it's nothing just a collection of words collection of tokens so word itself is called a token that's it that's is a prompt now over here if I'm going to run it so let me run this particular prompt and here you can see I'm asking to my chat GPT sorry I'm asking to my GPT model can you tell me total number of country in the Asia can you give me top 10 country name yes it is able to give it it is it is able to like provide a name basically now let's start from here because still here I've explained you each and everything in the previous class now let me give the next prompt the second prompt so over here I can ask something else to my uh GPD model now tell me guys what should I ask any uh any question anything which uh you would like to highlight uh which should I return return over here good so over here I didn't get any okay so let's uh ask like any uh basic question so can you tell me can you tell me a capital of India so let's uh search about this capital of India and here what I can do I can run it and uh let me uh give this particular input uh let me give this particular prompt to my uh uh to my model and I just need to call this client. predict and here I need to provide the prompt so client. predict and here I just need to provide the prompt so it is giving me answer it is saying that the capital of India is New Delhi now here let's try to strip this uh particular output strip means it it will remove the slend from here so I'm going to strip it and here you can see it is giving me an answer so I am getting answer without this selection now I think it is clear to all of you now one person is asking that what exactly tokens and Vector uh so here let's Ty to ask this same question uh to the GP or uh to the jpt model so what I'm going to do here I'm going to uh keep same question from the chat itself and the question is what is a token and a vector you can ask anything to your chat GPT and behind the chat GPT actually this uh behind the chat GPT the GPD model is working so let's uh ask about the tokens and the vectors and let's see uh what will be the answer uh which I will get from the GPD side so let me predict this a prompt three and here the answer is client. predict prom three and see the answer tokens are individual unit that a computer program used to perform operation they can be words symbol or numbers so the same thing I told you now this tokens is nothing just a words right that are used in programming language to represent a specific intersection Vector is data structure that is store a elements of the same time it is used to store sequence of el such as number of character so a vector is nothing what is a vector vector is having two unit now magnitude and the direction so how we represent the vector in our algebra in our algebra if you are like little familiar with the algebric uh algebra concept um algebra Concept in the mathematics so we open the square bracket we write it down some sort of a number and we close the square bracket that is the representation of the vector and along with that maybe the direction uh might be involved that's it so here uh you you can see definitely we are able to call the openi API now let's try to understand few more thing related to this length chain now here let's start to talk about the prompt template the very first topic which we're going to talk about uh we want to talk about related to this prompt template so first I will show you the example of this prompt template that how you can create a prompt template and after that I will um I will try to explain you that what is a prompt template first let me run the code so here is here is what uh we are going to discuss about this prompt template now I'm going to write it down from length chain from length chain and from here I'm going to import prompts prompts and let me import this prompt template class so prompt prompt uh p r o m PT prompt templates so I'm going to import this particular class what is the name of the class prom template okay it's not a temp templ actually a template so prom template now if I will run it so definitely I will be able to import it so here my spelling is wrong so let me correct it first of all and here you can see we are able to import this particular class now after that what I will do so here actually I want to create my prompt right I want to create my prompt now let me do it first of all and then I will come to the explanation so here what I'm going to do so I'm going to create an object of this prompt class so here is what here is my object so I'm saying that it is nothing it is my prompt template name so here I'm going to write it down prompt template this is what this nothing this is my variable prom template name got it I have created my object now inside this object I have to pass some parameter so let's try to pass few parameters over here the first parameter which I'm going to pass over here the parameter is going to be input variable so here the parameter which I'm going to pass over here that's going to be an input variable in input variable and the second parameter which we're going to pass over here that's going to be a template so how my prompt will be looking like so here I'm going to write it down template and is equal to right now in the variable actually I'm going to write it down the name what will be my variable so here I'm saying city city will be my variable and here I'm going to write it down my template now in the template actually I'm going to write down that uh can you tell me the capital of so here I'm just saying that can you tell me the capital of and here on a in a curly braces I'm going to write it down the city right City so c i t by so here whatever uh this is what this city is nothing it's my input variable so here I'm going to write down the city so this is what this is my object this is what this is my object for the plum so here I can put the question mark as well and if I'm going to run it now here you will be able to find out it is giving me an error why because I didn't put the comma over here now here you will you can see this is what this is my prompt template now what is the issue over here input variable okay so the so the parameter name is what input variable now I think everything is fine everything is clear now here what I will do I will call one method I will call one method just just be careful over here right so here I will call one method now here I'm going to write it down format and here what was my variable what was my input variable input variable was City now if I'm going to write down City so here let me write it down this uh Delhi so here once I've have done it now so it is giving me a specific prompt that can you tell me a capital of Delhi automatically right now here see again I'm going to ask the here again I want to create a prompt for uh for a different country let's say I want to ask a capital of China c i n now here you can see it is saying uh it is uh giving me a prompt that can you tell me a capital of China can you tell me a capital of China so what is the meaning of this prompt template what what what is the use of it now I think you can understand so by using this prompt template we can construct The Prompt based on a input variable now let's say you are going to create an application I can give you very uh good scenario now here is your application right here is what here is your application now you you have created this application by using the flas now here you are ask asking to the user just a city name just a city name or just a country name actually and based on that city of based on that country you want to provide a specific information and here you are using any sort of a llm whether it's from hugging face or open AI now guys over here uh you don't want to be here actually you don't want that that your user is giving a entire prompt you just want to take take a you just want to take a city name you just want to take a variable like we do in a python you know in a python we we have an input function yes or no but and by using this input function we take a like input from the user and let's say we have to uh showcase the addition uh divide or maybe uh multiplication whatever on top of those input variable we can do it similarly over here let's say we are taking just a city name so by using this city name we can construct our prompt and that particular prompt we can pass to the llm and Leng chain gives you this particular functionality we don't have this thing inside open AI API getting my point now so here I have created my prom now let's try to pass this prompt to the length chain so what I can do here I can write it down this is what this is my prompt first p o p Mt prompt first this is what this is my prompt first and here I can write it down prompt second this is what this is my prompt second and here is prompt second now let's try to pass this particular prom to my to my llm or let's let's try to call the API open API for that already we have a method client predict so let's try to call this particular prompt now here I'm going to call the prompt first this is the prompt which I'm going to call and here uh I'm going to call I'm going to write down this strip function also so I won't get any sort of slash or whatsoever right now here you can see the capital of Delhi is India the capital of New Delhi is India okay so here I need to write it down just just let me redefine it instead of the city what I can do I can write down the country right now uh this is what this is my country and here instead of the city let me write it down the country one more time and here I can write it on the India I think now it is it is a meaningful now here I can write it on the country one more time uh country c u okay c u n c o un n and here the same here is a same and here is also same now it's a meaningful and let me run it and see what I will be getting over here so prompt one prompt second and here is uh like a it's a New Delhi and let me check with a prompt two so guys here what I can do I can pass the prompt two and let's see the output it is saying the capital of China is a Bing so this prompt basically this prompt template will help you a lot whenever you are going to create any sort of application where you just required a single word from the user this thing is clear to all of you if yes then please do let me know in the chat please do let me know in the chat if this part is clear to all of you please write it on the chat I'm waiting for your reply are you liking the session are you liking the content so please hit the like button as well if you are getting everything if you are able to understand whatever I'm explaining to all of you please do let me know in the chat and yeah and whatever questions you have you can write it down the chat I I I'm monitoring the chat don't worry wait S I will come to that again I will try to explain the L and Advantage first of all let me uh complete the code part otherwise we won't be able to complete all the thing within R yes correct Vishnu your understanding is pretty much clear now since open AI model is not free uh so we Len access all API all other API as well like uh uh hugging face API it can access the hugging face API it can access the bloom API or different different API I will come to the documentation let me uh clarify the basic basic thing uh whatever is there inside the Lang chain I will come to the uh documentation great now here everything is clear everything is fine so here we have this uh here we have this object name prom template uh name and here is what here is my method that is what that is a format now what I'm going to do here H so here actually we have a second method also which is doing the same thing let me show you that at many places you will find out that particular method also I written it somewhere uh just give me a second yeah this one so it is working in a similar way langen has given you the two ways actually for creating this prompt so first of all see we have this promp template class we can create object and we can call this method format method got it now we have a second way here you can see this one prompt template. from template you can call this particular method also and it will work in a similar way both are same don't ask me sir why we are using this that Lenin is giving you the two option for creating a prompt template right now here you can see prompt template prom template what is the good name of the company that makes product I can write it on any like name uh any uh product name so here uh what I can say I can give this particular uh okay first of all let me run it and here is what I'm going to call this format method over here so from template do from temp prom template. frommore template and here is what here is my template template and here is what here is my tell me what is this this is my key now input variable now right now now let me show you what I will get over here so I will be able to construct my prompt what is a good name of the company that make a toys here is my key and here is my template it's going to combine both and finally I'm getting my prompt so over here what I can do so over here I can write it down my prompt so this is what this is my prompt number three and see guys if I'm going to run it so what I will get so here I'm if I'm going to run it this promt three ah it will give me a name it's not a 23 basically it's just a three so let me run it and let's see what would be the output so p r o p Mt p r o MPT uh it's a spelling mistake and now let me check it is working or not so toy makers unlimited so this is the company name actually which I'm getting if I'm giving this particular prompt to my GPT model you can test over the chat GPD as well so uh you will get this type of nam in the back end we are calling the GPD model don't forget over here don't forget okay so we are getting a uh GPT we are basically calling a GPT model over here so this part is clear to all of you and uh I think now this uh prompt part prompt section is pretty much clear I believe that it is clear yes or no this uh prompt template if it is then uh please confirm in the chat then I will uh explain you the second topic that is a agent agent in a lang chain and after that I will come to the uh chain and memory and document loader and finally we start with the hanging phase so tell me guys it is clear this uh prompt templating how we can create a prompt template great it is clear to all of you now let's understand the agent so what is an agent guys tell me so agent is nothing we use this agent in the L chain for calling any third party tool that's a simple definition of the agent if someone is going to ask okay just tell me who is a agent who is a agent in a real time let's say if I'm saying uh there is one agent uh let's say you uh went to the uh any uh you want to purchase any property you want to purchase any property and you went to the Builder and you are uh and uh once you visited the property and you have visited the Builder office or whatsoever there you will find out agent so who is the agent actually so it's a it will so let's say you are a main person and uh you want the information of the property so that you want a like the main person and you want the information from the of the property basically so this agent will help you this agent will collect the information of that particular property and it will provide you in a similar way the agent is working over here getting my point yes or no I think yes now let me run it and let's try to understand the agent so guys over here I will start the thing uh I will ask ask one question to my chat GPT so here I'm going to ask one question to my chat GPT just a wait great so let me open my chat GPT and here let me ask one question the question is very very simple so here I want to know that uh can you tell me current GDP of India so here uh I'm asking to my CH GPD can you tell me the current GDP of India now if I will uh run it so here it is saying to me I'm sorry I don't know in a real time as my training only include information up to the January 22 this that whatever getting my point yes or no tell me so it is not having uh this particular information if I'm asking to my CH gbt can you tell me who won the Cricket World Cup recently now here see what I will get so here it is saying guys I don't have a real time information only includes data up to January 2022 or 20 202 20 okay as my latest updated the most recent information World Cup was held in 2019 emerged as a champion defeating New Zealand in a thrilling final so is giving me an information from the 2019 match I think India again uh uh like uh they out uh I think uh they uh they they got defe from the New Zealand itself right in a knockout match in a semifinal itself uh yes I'm able to remember it so here uh it is not able to give me an answer now let's ask the same thing uh through the open so through the lench itself in my code I'm going to write down the same thing over here so here I'm going to create a prompt for so I'm asking to my model prompt 4 so here I'm asking to my model can you tell me who W the recent Cricket World Cup so this is the question and now let me ask it let me run it so what I can do I can write it down this client predict and here I can pass my prompt prompt four now see uh okay first of all I will have to run it p r o m PT p r o m PT now see guys uh it is saying that uh the 201 won by the England I'm asking about the recent World Cup but it is saying that uh the 2019 Cricket World Cup won by the England only it's completely wrong right now here what I can do I can ask one more thing can you tell me the current GDP of can you tell me a current GDP of India can you tell me current GDP current GDP of India so let's see what will be the answer so here is what here is my prompt five let me copy it let me paste it over here and here I can write it down this prom five so as of 2039 India GDP was estimated to be around 2.94 trillion actually it has been trained till 20 uh 22 data 2022 data right so till January 2022 data right so here it is not able to give me a proper answer uh it is not able to give me a real time answer so for that what I will do guys tell me so here I will use the agent I will use the concept of the agent which will extract the information from the third party API now here I'm going to use Sur API now here so for for extracting extracting or real time info real time info I'm going to use I'm going to use Sur API Sur API Now by using the Sur API Now by using now by using this Ser API I will now by using the Ser API I will call Google search engine and I will extract the information in a real time so here I have written this particular uh like a statement so I hope it is clearly visible to all of you now let me keep it in a mark down and it is clear so for extracting a real time info I'm going to use Sur API Now by using the Sur API I will call Google search engine and I will extract the information in a real time let's see how you can do it so here what I'm going to do so first of all I will have to install this particular Library pip install Google search result that is the first thing now install this library inside your current virtual environment so here what I'm going to do here I'm going to install this particular here I'm going to install this particular liity in my current virtual environment where guys tell me in a current virtual environment clear fine now after that what I will do so after that I will create my Sur API key Sur API key because uh with that only I can access I can access a different different API now let me show you the surp API so just open the Google so here just open the Google let me show you from scratch so over the Google what you need to do you just need to uh okay so here what I'm going to do I'm going to write down the surp API so let me write down this Sur API so once I will write down surp API now now here you will get this very first link so what is a Sur API like uh we have a rapid API now in a similar way we have a Sur API so Sur API is a realtime API to access Google search result not from the Google actually and from any search engine Bing or maybe some other search engine even we can access the Wikipedia also right I will show you how so here uh if I will open it now so you just need to do sign in first you need to do register and then you need to do the sign in I already registered so that's why it is giving me this particular page now just scroll down over here just see over here API documentation now in a over here you will find out a different different documentation related to Google search API Google Map API Google job API Google shopping API Google image API now apart from the Google you will find out the Bing Bing search API also by do also BYU also it's a Chinese search engine now Doug du go search API Yahoo search API yendex search API eBay search API YouTube search API any API you can call by using this Sur API now just click over here API key and here is what guys here is my API key now you have to generate your own API key this is my API key now let me copy this API key from here and it is having some sort of a limitation actually you can just do a 100 search in a free version but in a paid version I think uh you can uh like increase the number of search so just see over here just open it and you will be able to find out entire detail so plan is a free plan price per mon zero uh total plan s 100 plan search left 995 5 I already did it and yeah this is it in a free version you can check check with the plan so just go in the change plan and here you will find out the entire detail so production plan developer plan big data plan all the plans you'll find out over here and by using this API you can access the Google search engine you can access the Google search API inside your application right now here what I need to do I just need to paste this API key in my I just need to keep this APK in my variable till here everything is fine everything is clear now what I will do guys so over here I will I I have to like import few uh I have to import few uh like import uh statement basically uh I have to import few packages so agent type load tools and initialize agent so these are the these are the like these are the packages basically which I need to import agent type load tool and initialize agent so see guys uh let me import this particular thing first of all and yeah it is working F now first of all what I will do first of all I will create a ag first of all I will create a client means here I've created now this open a uh client this one this one okay let me use this one or I can create one more time not an issue as many as time you can do it so here what I'm going to do so here I'm going to uh paste this particular code here I'm going to create my client so this is what this is my client now after that I have to load the tools which tool tell me which tool which tool like we are going to load Sur API now we are going to use the Sur API now so that that's the only tool right so here what I'm going to do I'm going to create a object of this particular method sorry this particular class so here is what here is my object now this is what this is my tool now here I will mention something inside this tool now let me do it over here so let me uh mention this particular thing so here I'm going to mention it so this is a thing basically which I need to keep Sur API uh first of all I need to P The Sur API key and llm so here is what here is my llm already I've created this client I'm using open still I'm using open okay I didn't uh explain you the hugging face so far so this is my Sur API key and here is the name which tool you are using that's it in our square bracket you need to write it down the name you can find out each and everything with the alen tuto lenion documentation everything is there everything is there I will come to that just wait so here is what here is my tool I created my tool now I have to inal I have to create my agent type so here what I want to do uh so here basically what I want to do guys tell me so here I want to create my agent type so U here what I will do I will uh create an object of this initialized agent let me create the object of this initialize agent and here is what guys tell me here is my agent this is what this is my agent now inside this initialize agent again I will keep something so first of all the first thing which I will keep that is going to be a tool so the tool basically which which I've created the second type will be a client means my model the third type will be a agent this agent this agent uh basically agent type actually and here we are going to talk about this zero short react description we are going to mention this zero short react description and verbos to means whatever information um what if I will run it now so whatever information will be in a back end I will be able to see not over the display there's the meaning of the bbos right so here I mentioned three parameters the first is tool the second is client the third is Agent and the first fourth is barbos great now let me run it so this is what this is my agent now what I will do so here I will write it down agent and I will run so run now here I will ask the same question so my question was let me take this particular question from the chat jpt can you tell me the okay so can you tell me who won the recent World Cup so if I'm going to ask the same question now to my agent so here what I'm going to do I going to ask it and let's see what I will be what I will be getting so it is executing the agent and here is search here is action who won the Cricket World Cup and here you can see Australia won the Cricket World Cup it's a recent information it's a real time information which I'm getting now it is giving me many given me some other thing as well links and all because it is calling the Google API Google search engine actually in a back end and here you can see it is giving me answer a on the recent World Cup you can ask anything you can ask anything guys just just uh write it down over here so you can say that uh can you tell me five current can you tell me five top current affairs a f i i RS so if I will learn it now it will hit the Google search enger and here it is saying that see uh so it is saying that top five current affairs and still it is running so read is not available tool try to open I should search engine to find out observations see here it is giving me some like top five current affairs International breaking news uh affairs from us Europe this is the second one a current affairs Subs is one of the best known as a improved life jagaran Jo affairs.com okay it has given me a different different website maybe or uh it here is a news Okay so actually it is giving me a different different name it it is not giving me a proper current affairs I will have to mention that I will have to write uh that particular prompt basically so let's do one thing now let's understand the Wikipedia also so how we can uh like call the Wikipedia so here what I will do I will be writing down pip install pip P install Wikipedia now I will have to install it in a current virtual environment now if I will run it now pip install Wikipedia so let it run uh so here you can see I've installed the Wikipedia now what I will do first of all guys see tell me what is the first thing I have to load the tool so let me load the Tool uh so here is what guys see here is my tool and here is my LM means my client open a client that's it now my tool now what I have to do I have to create an agent so here is what here is my agent this is what my agent I have initialized the agent here is my tool here is my like model and here is my agent type zero short react I will come to that what is this react description and BOS equal to two once I will run it and here whatever I will run now see I'm going to write down uh agent dot run and here I'm asking can you tell me more can you tell me about this re uh okay can you tell me more about this recent Cricket c i c k e Cricket World Cup so if I will run it now it is going to extract the entire information from the Wikipedia okay it is it is taking from the 2019 World Cup okay it is taking from the 2023 World Cup itself the World Cup for the 39 Cricket World Cup which was H in India 5th October November 23 Australia won the tournament great so it is excting a information from the uh recent one itself now here I can ask one more question to my just a second what I can do I can copy it first of all let me copy this particular thing and here what I'm going to do here I'm going to pass a next question so the next question is so let me keep the question over here uh let me run it it is taking the information from the Wikipedia itself are you getting it guys yes or no yes surf I explain you everything regarding the surf API s if you are here if you look into the surf API right so each and every plan I have shown you and it give you the free uh access also but up to uh like it is having some limitation over there you can just hit 100 search you can just hit the 100 100 search in a free version if you're going to take a plan so in that case uh there will be a different uh number of search actually search plan is there different different plan is there see Di okay $2,500 per month $8,000 per month Cloud for plan many plans is there see guys how much plans is there uh which you will find out just go through with it I let me give you this particular link inside the chat and don't worry each and everything will be available inside the resource section at the single place uh at the single place I will keep all the thing and I will give you that don't worry so now see it is extracting the entire information from the uh like uh it is going to extract the entire information from the vikkipedia so final answer the total National dep of the this one and here you can see this is the GDP of the uh USA and here observation and all everything everything now see action Wikipedia input GDP of United State observation p economy of United States summary this is the complete information complete information which is going to fetch which it is fetching from the Wikipedia itself now tell me guys how many of you you are able to understand the concept of the agent so please let do let me know in the chat and then again I will revise it and I will explain you uh through the lench and documentation please do let me know in the chat first if you are how many of you are able to understand the concept of this agent here from here I have started this agent tell me guys fast by using the Sur API we can uh access uh we can access a real time information and it is possible in a is possible in a len chain please do write it down in the chat if you're liking the uh session so please hit the like button also and I'm waiting for your response guys please please do let me know sir please explain the logs which is coming from the agent so here I can explain the log so here is what here is my logs what is this uh what is it uh just check over here so it is saying entering new agent executor chain so after this I'm coming to the chain concept chain and memory two thing is remaining and the document loader three is remaining uh uh then uh you will be able to understand this chaining and all in a better way now here entering a new you execute a chain so action is what it just want to search now action input top current affairs so it is making observation it is searching everything from the Google then it is thinking something I need a narrow down the list of top five internally it is doing everything internally it is doing everything and it is giving you the final answer this one finished chain actually each and everything has been coded in the form of chain llm chain I'm coming to that chain and once you will understand that particular chain now this thing will be are like pretty much clear to all of you believe me just just read it by yourself as well what is the use of client in this what is a just it's just a name now what is a client see I told you please learn the python first if your python uh topic is clear then definitely you will be able to understand this line of code see someone has created openi class somewhere in openi P you just downloaded that you just downloaded that particular package by using pip install openi and now you are creating a object of that it is just is just a class and here is a object this is the object name you can keep it anything here you can give your name like whatever name your name just write it down your name this is what this is nothing this is the object of the openi class and here you are passing a different different parameter someone has created a class and you are just using it that's it nothing else so this is what this is my client and I think this is clear to all of you now coming to the next part so here first of all let me show you the Lenin documentation so I'm going to write it down over here Lenin documentation now over here uh like uh you can see this is what there is nothing there's a Lenin documentation and here is an introduction so they have given you the complete introduction of the lenen over here Lenin Library lenen template Lang server Lang Smith everything you will find out over here and this document is a amazing one similar to this open a uh so yesterday we have seen the open a documentation right so this length chain documentation is similar to that openi documentation it's a pretty amazing each and everything you will find out over here itself each and everything you will find out over here itself now let's start with the installation so how you can do that it is very very easy pip install length chain and pip install and all what is the meaning of this pip install hyphen e dot so this thing we'll try to understand in our upcoming session once I will start with the end to end project now L server we try to understand this also what is the Lang server all L CLI so many like they have given you over here as of now this lch package is required that's why we are going to download it now over here we have a quick start so here you will find out the quick start so you can go through with this quick start and you can uh like you can take a glimpse of this Len CH so everything you will find out over here in a quick start itself pip install lch pip install open a you can export the open a key key and then you can use it and here is a different different thing which you will be able to find out whatever thing we are running so open a you can uh create object of this chat openi also now here is llm model here is U you can use this particular class also chat open AI now human messages lch schema human message there you can check with this what is this now you can create a prompt templates already we have created now just see over here what is a what is a PR prom template most llm application do not do not pass user input directly into llm most of the application you will find out you just require a single word I given you the example yes by using this prompt template you can achieve that particular functionality and here is example for that got it now here is a chat comprom template so each and everything you'll find out over here and uh as uh like you will find out the latest version so there might be some sort of a changes in a code and all but don't worry the concept ccept will remain same we'll find out some changes in a code in a classes the name of the classes but the core concept will same if you're getting any error in a new version then check with the like documentation and try to rectify it that's it so here is a quick start and you can go through with this quick start and you can understand a different different things now security wise they have given you the different different thing now let me come to the next part so over here just click on this G to started again they have given you the different different uh thing prompt is there model is there which model you going to use output parser entire pipeline okay R they have included their R also now okay so retrieve augumented generation so you can go through with this and you can understand what is this R but don't worry I will cover this in my uh next class this RG it is I'm having this R in my pipeline so I will try to cover it this U uh in a live class itself in a Jupiter notebook itself I will write it on the code now over here you can understand about a different different thing different different concept just just go through with this document it's amazing one now interface is there so prompt chat model llm out part are retriever tool these are the things just just go through with this try to understand it now how to so here is a different different thing which they have mentioned Right add fallbacks bind R time runable Lambda many things right so here you will find out the cookbook so inside the cookbook everything they have given you everything prompt plus LM so the thing basically which we are going to do over here uh which we are going to do as of now they have mentioned it over here R RG this was this was not there previously when I had checked recently they have added in a new version so R is there so here you will find out the code related to the r see this one now here multiple chains chains I will come to this chains after this one I will explain this chains right so here you can see the change and all so each and everything they have given you but as of now we are trying to understand this particular part we are trying to understand this agent and we are trying to understand this model input output so prompt already we talked about chat model already I shown you by using the open so this is like pretty amazing document guys so once you will go through with this document now you will find out uh it is having so many things and they have given you the code and all each and everything they have provided you believe me guys so just go through with this one and try to understand uh different different thing or whatever thing basically is there so we going to understand this chains now and we'll be try we'll try to understand this memory but apart from this chains and memory it is having lots of thing which uh we might uh we might use in our application if if you are creating application now so this concept uh like might come into the picture regarding the RG or regarding a different different one different different topic basically which they have included but over here I would like to tell you one thing whatever I'm explaining you in a Jupiter notebook U if you are a beginner that definitely it's a more than uh it's more than enough for all of you and uh in the next class once uh when I once I will implement the project now then uh you will find out the importance of it and don't worry I will uh keep some latest thing also like R and all inside my project and inside my uh future classes and you will get to know that so here uh I have given the overview now let me talk about this uh agent type so there basically you have seen one thing that was the agent type now let me talk about this agent type what is this so here you can see guys in a agent itself you'll find out the agent type see agent type just just click on this agents and here you will find out the agent type now we have a different different type of agent zero short Agent Zero short react agent structure input react agent openi function yesterday I have talked about this openi function and now it's a legacy people are not using it people are using this agent concept from the lench and directory people are not using this open function uh but still I have explained you that so here you will find out the conversation self ass react documentation and all and this zero short is nothing it's a basic one so if you're going to ask something to your LM model to your GPT model so you will use the zero shot react now here you will find out this this agent use a react framework to determine which tool to use based on a solar on the tools description so whatever tool description you are giving based on that it will search the uh like compatible tool and it will provide the prompt to that particular search engine or to that particular tool and it will give you the out that's it zero short react now here this is the most general purpose action agent you can see the node so this thing is clear to all of you now let's start with the chains so are you comfortable till here and if you're not able to write it on the code along with me sometimes it happens in the live session don't worry just listen to me just listen to my words whatever I'm saying and practice after the class practice after the live session recording will be there and resources also will be there so let me write it the chain over here and let's start with the chain now so first of all tell me guys this part is getting clear how many days you will take to come up with an end to end project one day only one day I will take to come up with an end to end project so lench is only made for the NLP use case or any other compete capabilities also it is having as of now I have used this for the NLP use cases I will have to explore the recent uh thing whatever is there inside the Lenin maybe uh we can use it for the other uh like for the other task also but I haven't explored it for the other task I just use for the NLP once I will explore it I will let you know that whatever recent update is there but if you want to know about it just go through with the recent documentation all the llm has only text or code generation capability yes but you can do many whatever NLP task is there now you can do by using the llm because it is having the code generation capability with that it can understand the pattern inside the data so you can fine tune it it is uh possible you can fine tune inside your CPU Itself by using your CPU I will let you know uh otherwise I will share the resources with all of you uh don't worry we we'll come to that and uh we'll try to talk about it uh not as of now later on but yeah uh I will give you the glimpse of that great uh I think uh now people are getting many things we are using uh not completely actually if you don't know about those thing you won't be able to understand this particular part that's why first I started from the basic from the open itself otherwise directly I can start from the lch and then uh again you will ask to me sun what is this uh what is this open Ai and what is this llm what is this genitive AI I can even I can start from here itself from the Leng chain so but I started from the very basic okay so let's start with a a new topic uh that's a chain so what is a chain so let's understand the chain so first of all I can uh show you the documentation and uh just a wait great so here actually what I did I kept one a simple definition of the chain and let me copy and paste it so here is a definition just try to read this particular definition and try to understand the meaning of chain and it will be more clear once I will write it on the code so Central to length chain is a vital component uh known as a lang chain chains forming the core connection among one or several large language model in certain sophisticated application it become necessary to chain llm together either with each other each other or with other element so if you're not able to understand by this particular definition so let me open the documentation for all of you so here in the go inside this more uh just click on this more and here is a chain just uh read about this chain so using an llm in isolation is fine for a simple application but more complex application require chaining llm either with each other or with other component now what is the meaning of it so just uh okay so I have uh explained you the agent that's why I explain you the agent at the first place and then I came to this chain now tell me guys this llm was not working over there so I changed what I did now I Chang I changed the terminology so what I did guys now I so this LM was not working for that particular prompt so after coming to this llm means let's say if I'm not getting any sort of output so I came to to this chain and this chain actually it was connecting to me it was connecting to me to The Sur API through the surp API basically it was connected to me Google search engine getting my point so here what is the meaning of chain so chain is nothing okay if if you're talking about chain in journal so let's say this is a chain so something like this you will find out so what is this what do this guys tell me so chain is nothing which is uh like connecting a several components which is connecting a several component getting my point yes or no I think you are getting try to understand it what is a chain so chain is nothing it is just connecting a several component so here they are saying using llm in isolation it's fine but in complex application require chaining that the example I shown you by using the agent if you will read it if you will read the answer of the if you'll read the answer of the agent agent I'm running agent don't run and you are getting an answer so if we'll read that you'll find out it is chaining means for is trying to find out somewhere else it's not able to get then again it is going to somewhere else and it's going to take a information then again it is going to call some other prompt and it's going to take a information so what is a chain so chain is nothing it's a collection of component now which component what component whatever component maybe inside the uh like uh uh like whatever let's say we are using length chain and inside that we have a different different component I'm going to chain to those particular component and maybe I'm going to uh like connect with other llm so I can do that as well or maybe I'm going to connect any third party API I can connect that as well so I'm doing a chaining if I'm running chat agent. run now internally it is doing a chaining getting my point I think you're getting now let's try to understand in terms of python code so here first I will start with a very basic example so what I can do here so here uh first of all I can write it on my client so here is my client guys c r i e n t this is what this is my client now what I will do guys so here I'm going to import The Prompt template so this is what this is my prompt template and by using this prompt template I'm going to create I'm going to create uh I'm going to create one prompt so here is what here is my prompt so what is a good name for a company that makes a product so here I can run it and let's say uh I'm going to write it down any company name so okay I'm going to write down the uh actually I want a company name what is a good name for a company that makes a product so I'm just asking to my chat GP okay I I'm making this particular product just give me a good name for this particular company so here I'm going to write down let's say wine so wi so here I uh I'm uh just just think that uh just think like that that I'm going to open a company uh and here I'm going to produce a wine and all uh okay so I want a name any creative name okay that I'm asking to my LM model now here if I will uh like close it so what I'm going to do so here I'm going to run it so uh prompt. format so this is what this is my prompt what is a good company name for a what is a good name for a company that makes a wine so that's going to be my prompt p r o p Mt so this is what guys this is my prompt now what I will do so here actually I'm going to import the chain here I'm going to import this llm chain here I'm going to import the llm chain just just be with me just for uh next 5 minute everything you will get it's my promise to all of you I have simplified every thing every uh like uh every line of code just be with me next for 5 minute so here you can see we have a llm chain now what I'm going to do I'm going to create a object of this llm chain now guys uh here I'm not going to call a predict method I'm not going to call a predict method what I'm going to do so here in this llm CH what I'm going to pass guys I'm going to pass client right and I'm going to pass my prompt that's it this two thing I'm going to pass so llm llm is what c l i n t and here I'm going to pass my prompt so p r o p Mt prompt is equal to prompt so I passed the client and I passed the prompt here now this is what this is my llm Chen right I'm going to connect both component LM and my prompt now over here what I'm going to do so this is what this is my chain this is the object basically which I have created now here you can see it is saying that uh it is giving me a why I'm getting it let me check with the prompt so here uh let me run it first of all what is a good company that makes a wine okay from template uh I think I will have to use format uh I think I will have to use this particular prompt only uh this one this only uh let me delete it because it is asking I need to provide in the form of dictionary so I cannot pass a direct prompt over here what is a uh because uh here whenever I'm running this uh whenever I'm calling uh the run method Now by using this chain then automatically it will uh like take the name from here itself so let me delete it let me delete this particular line I'm going to delete it guys this one so here is what here is my prompt now Len chin llm chain and here now it is fine now what I will do here I'm going to write down chain and chain. run and here actually I need to pass the value so here I'm going to pass y now if I will run it now see it is giving me answer the name of the company is what it's a uh sdip strip and is the name of the company is what Vintage Wines Winery so it it has given me a name of the company like I want to create this particular product and here it has generated answer now I'm going to change I I'm making a chain by using two components the first one is llm model that is that I'm getting from the openi and which is available inside my client and the second is what second is a prompt which I'm passing over here so now I can directly run it by giving the keyword and here you can see I'm getting answer so I'm changing this two thing this is the simple this is the simplest uh like uh there simplest example I've given you now let come to the second example so over here what I'm going to do so here I'm giving the the second example example two example two so I took one more example to for explaining uh this chaining part actually so here uh let me copy and paste so here is what guys here is my prompt template this is what this is my prompt template now here I'm asking uh this is what this is my template I want uh to open a restaurant for cuisin Indian cuine Chinese cuisine Mexican Cuisine Japanese cuisin American Cuisine whatever for that I want a f see name this is my prompt template let me run it here I'm running it now if you will find out the prompt template so here you will find out the prompt template so this is what this is my prompt template got it now what I will do guys here I will make a chain so what I'm going to do so here I'm going to make a chain so let's say uh this is what this is my chain so llm chain and I'm going to combine two thing first is client and the second is what the second is promt template now if I will uh run it so so here I'm getting my chain then I will write it down chain do run now I'm uh let's say I'm giving something over here let's say I'm giving uh Chinese so according to that it will give me answer so the answer which I'm getting the golden dragon dragon place so here what I'm getting guys I'm getting this Golden Dragon place so the emperor's kitchen that's the name okay if I'm writing over here uh Indian let's say what I will be getting so Indian so here actually I'm getting Maharaja Delight so just the name it is suggesting me one name which I'm asking to my llm model that's it now let me show you few more thing over here now so here I'm getting a a response and the response is fine now let me uh come to the second thing second example so here what I'm going to do so here let me show you something so now over here if you want to see the detail actually so for that I have mentioned one more thing that is a verbos parameter as I told you earlier if I want to check all the detail whatever is happening in back end so for that there is a parameter verbos is equal to true now if I will run it now see what I will find out uh let me predict with some name so let me uh check uh chain. run and here I can write it down let's say America so here it is saying that entering new llm chain prompt after formatting I want to open a restaurant for American food suggested a fancy name for this and here is a name American spice Visto so you can see the complete detail over here what is happening by using the barbos true until here everything is fine everything is clear now guys here uh this is the simple chain basically which I have created by using this two component now let me explain you One More Concept over here so here actually I have written one definition or I have written one text uh just let me explain you the this particular part and then uh again I will try to revise you so here I'm going to mark down it and here guys see what I'm saying if you want to combine multiple change and set a sequence for that we use Simple sequential chain simple as simple as that right so if you want to combine a multiple chain if you want to combine a multiple chain and set a sequence for that we use a simple sequential chain so let's try to use the simple sequential chain and let's understand what is it so for that basically I have designed one prompt okay just just understand over here so step by step we'll try to understand see Ive already written a code in my doc I'm just copy and pasting so that I can save my time that's it everything is same see I can write it now the code in front of you also but it will take some time for writing this particular uh statement on all it's the same thing okay wherever I have to write from scratch I will do that now over here see uh let's try to understand step by step now over here this is what this is my uh second prompt so in the first prompt see in the first prompt The Prompt template which I have defined what I'm saying over here I'm saying uh I want start a startup right I want want a start a startup and suggest me a good name so here is my prompt now here you can see this is my input variable that is what that is a startup name yeah it's fine it's clear to all of you now here I've created a chain by using this a model this is my model and this is my prompt template okay this is the first shap now here I have created one more prompt now here I'm saying uh suggest some strategy for the name so whatever name name whatever name I will get from here startup name for that what I want I want some sort of a strategy let's say I'm going to open or I'm going to start my atte startup so for that what I require tell me so I for that basically I require audience I required my team I required my Marketing sales team if I want to open any fintech startup or if I want to start any consultancy or whatever right whatever uh like company which I want to start so regarding that what I want I want some sort of a strategy getting my point here yes or no so now what I will do I will combine this two change see here this this is my first change this this this is what this is my first chain this one and this is my second chain now I will combine this both Thing by using simple sequential chain I will making I'm making a sequence I'm trying to make a sequence between these two chain okay before I I was just running with a single uh like uh with a single chain only and we we are having only two component llm and my prompt now here I'm going to come my true chain now just tell me guys here I'm using this particular llm can I use a different llm over here I can try with that I can check right so here I'm using a same model now I can check with a different LM also in this particular case so this chain is a pretty amazing thing it is connecting a homogeneous component or it is it can uh we can connect a hetrogeneous component also means some other model as well you can test it with the other model uh so here you can see we are able to do it now guys here what I will do so here is my first template this is my first chain this is my second template this is my second chain now what I will do over here so here I'm going to import a sequence uh so here I'm going to import a simple sequential chain here I'm going to import this simple sequential chain now once I will run it so here I imported now let me create a now let me create a object of it so here guys here is a object now inside this object inside while I'm creating object I will pass some sort of a parameter so it will call my init method okay in a back end now here I'm going to pass some sort of a parameter and that's going to be a very very easy and here is the parameter name so chains first is name chain and the second is stategy so automatically see what will happen actually first it will call to this one it will uh generator startup name automatically it will give uh it it will give name to this particular uh like a to this particular template automatically it will fetch from there itself and I will be getting this strategies I will be getting this particular strategies automatically chaining automatically chaining is happening okay this one now let me show you how so over here uh what I will do so let me uh create object and here I just need to call a method so here I'm going to call uh method that's going to be a chain. run now here I want to open a startup let's say the startup related to the artificial intelligence so here I'm going to write it down artificial intelligence now here once I will call it so let me run it and let's see what I will be getting over here so I'm making a sequence guys between a prompts so it is saying that uh develop a strong marketing strategy and and some sort of a information let's let me print it uh so that I won't get this lesson so here is my strategies stay informed and up toate on a latest AI train develop a comprehensive uh AI strategy utilize AI tools utilize data driver inside so these are some sort of a strategy actually see automatically I'm getting see this name now which which we have defined see startup name which is coming over here okay then whatever name is coming from there automatically is going over here this inside this name and we are getting a strategies we are chining we are chining right now this is a simple sequential chain now here uh here we have one drawback actually uh we it is giving me a final answer it is not giving me a answer uh it is not giving me answer related to the first prom it is not giving me it is not giving me that particular answer it giving me a direct uh the last one answer from the last uh like a prompt itself if you want answer like from the entire prompt so for that also we have one method okay uh sorry we have one more class let me show you that particular class now so here uh what we can do so I already written the name so let me give you that particular uh name and here is what here is a name guys so the name is what now let's try to understand the sequential chain so so far actually we have understand the simple sequential chain now we are going to understand the sequential chain and it is having a more power compared to this SE uh simple sequential chain where we can uh keep uh the sequence sequence of the different different prompts and the different different chains now uh let's try to understand this sequential chain and here what I'm going to do here I'm going to copy one more code now let me paste it over here so again I'm going to create okay already I have a client so let me move it it is not required at all so here is my prompt template and what I'm saying here I want to open a restaurant suggest me a fancy name now just see over here what I'm going to do I'm going to mention one key over here that is what there is my output key and what is my output key output key is nothing it's a Resturant name right now now just see over here where I'm going to use this output key so here I'm going to Define one more parameter one more prompt template and here guys you can see so in this particular prompt template prompt template name we have a prompt template and and here input variable kin and this is a template now here is my chain llm chain this is my model this is my prompt template and here we have a output key output key is what restaurant name so whatever name basically whatever name I will get from here I will keep inside this restaurant name and this restaurant name I'm passing over here this restaurant name I'm passing over here and here whatever thing I will get from here from this particular prompt I'm keeping inside the menu item and if you are going to create a next prompt you can mention over there now let me run it and let me show you what will be the final answer over here so here I'm going to import the sequential chain and here you can see so this is what this is my sequential chain and now let me copy it and let me paste the final code and here is my uh object of the sequential chain so let let me keep it in a single line so here sequential chain this is the object which I have created now change what I want to chain means like in terms of what I want to make a chain so this is the first name name chain this is the one now second chain is what food item chain means I want a food item regarding that particular restaurant now over here this is my input variable and here is my output variable restaurant name and menu items this one Whatever output I'm getting from here I'm keeping over here inside this variable whatever output I'm getting from here I'm keeping over here inside this variable and I'm going to mention inside the output variable if you want to make a further chain you can do it according to your problem statement now let me run it and let me show you the final answer and the final response so here I am going to call this method chain okay so this is about this is my chain and here let me run it and see what I will be getting so chain and I'm I'm passing cuisin Indian so it is giving me cuin is what cuin is Indian and here is a restaurant name there's going to be a Taj Mahal Palace Taj Maharaja Palace and here is a menu item now so guys this is the response which I'm getting over here can you see over here the response which I'm getting all the thing all the thing in a sequence now let me revise this particular thing revise me this particular concept so chain what is a chain which is going to connect two components so here what I did see here I have connected two component first is model second is prompt now in example two you can see what I'm going to do so same thing I'm going to perform now in the third one uh with the entire detail actually with our entire detail now in the third one I'm calling simple sequential chain in that I'm getting a output from the last prompt but if we are talking about a sequential chain instead of the simple sequential chain I'm using sequential chain so I'm getting a entire output over here means from first template uh from first prompt template to last prompt template and here you can see we are mentioning this output key so whatever answers I'm getting over here whatever answers I'm getting from this particular uh prompt right we are able to store it over here and we are passing to the we are passing to the next prom we are passing to the next uh like a prompt basically over here you can see this one same restaurant name and we are going to combine it finally so guys tell me do you like it did you understand it I will come to that the purpose and all everything will be clarified right so uh we will talk about because everything should be connected now to each see whenever uh like if you are going to ask to anything uh to your chat GP what do you think tell me so how this application is working we are are we are like uh what we are going to do guys so we are reaching step by step actually we are trying to reaching to our final application understand guys so here if someone has created this chat GPT it they have implemented everything whatever we are going to run by using this Len chain here you will find out the memory concept okay let me ask one question to my CH gbt so here here I'm asking can you tell me can you tell me about something Taj okay so here uh I'm asking this question to my chat jpd now here you can see uh uh like uh here is the answer now I'm asking to my chat GPT 2 + 2 how much so it is saying to me let me run it so here it is saying to me 2 + 2 is nothing it's a five okay sorry uh it's a four right now here if I will ask to my chat GPT how much 100 uh multiply by 1,000 now if I will run it so here you will get the answer now here if I will ask to my CH GPT who uh build the Taj Mahal can you who built the Taj Mahal so here if I'm going to ask this particular question so here you can see the Taj m b by the mul Emperor so actually it is not going to forget the context whatever you are asking now previously it is able to sustain the that particular memory it's a biggest power of the CH GPT so we are trying to reach uh like step by step we are going to we are trying to understand all sort of a thing by using this Len CH and then finally we will move to the uh the end uh like a goal the our end application now over here this chain actually is very important if you want to uh like a retain the information from the first prompt to the last prompt for that you can use this uh you can use this uh sequence chain I can understand you are uh trying to understand that where we are using in a real time in a application and all I will come to that part okay but just understand over here so I was running the Sur API so here actually once you will read the entire detail of the Sur API of this agent so you will find out that in like uh uh internally it is using the chaining it is trying to chain each and every thing back in a back end basically they have implement the chaining complete chaining so just just try to read it and finally it is giving me a the the like conclusion over here so in a similar way here I just shown you the example a very basic example but by yourself what you can do guys so by yourself uh like you can uh like create a different different prompts and you can implement this chaining concept over there and you can understand in a better way you can search about the applications and all getting my point yes or no tell me guys this thing is getting clear to all of you if it is getting clear then please do let me know in the chat so are you able to get it uh please do let me know in the chat guys if uh this thing is fine to all of you I'm waiting for a reply guys if you can write it down the chat and if you're liking the session so please hit the like as well great now let's try to understand uh One More Concept and then I will uh stop the session uh today I couldn't reach to the hugging phase but don't worry tomorrow I will show you that and memory also so One More Concept is there memory now let me show you the basic concept now the uh the very basic concept of the Leng chain which we are going to use in a future that is going to be a document loader so let me explain this document loader also so here uh what I'm going to do I'm going to uh show you that how you can read any sort of a document by using this uh by using this length chain now once you will search uh let me search over the Google Document loader document loader Lang chain documentation so simply I'm searching about this uh document loader on top of the documentation so here uh let me open this document loader so once you will come inside this module now and here is a uh here is a like option retrieval now inside that you will find out a document loader so CSV file directory HTML Json markdown PDF or different different document you can load and it is required it is required I will show you where it is required and once I will reach to the Practical implementation once I will create any sort of a project okay so there I will show you how you can read a different different files and how you can utilize let's say uh you have one information so some information inside the uh txt file or maybe in the format of HTML or Json or maybe CSV now you want to read it from there and you want to give it to you uh you want to give uh that particular information to your uh chat GPT or maybe GPD model so in that case you will have to use this document loader so let me show you how you can use this uh PDF loader so here is what here is a PDF loader so for that first the first thing what you need to do you need to install this P PDF so just open your notebook and here write it down this pip install pip install P PDF so once you will write it down this pip install P PDF you will be able to install this Pi PDF inside your virtual current virtual environment now after that you need to lo you need to write it down this particular command uh you need to write it down this particular import statement from lench do document loader import Pi PDF loader right from the documentary itself I'm going to take it I I'm I'm I'm not going to write down by myself here I'm showing you the power of the documentation so once you will explore it you will get a many more thing from here itself right whatever like you want so here I'm going to uh what I'm going to do guys so here I'm going to mention this import statement now we have one uh ex uh now here actually we have to call this particular method sorry we have to create a object of this particular uh class and here let me paste it down so this is the pi PDF Lo now I have to pass my PDF I have to give the uh I have to like write it down the my path whatever is there uh in my local system so inside my download let me check any PDF is there or not so let me check with the PDF LM here is a PDF machine translation attention so let me copy the path uh let me paste it down over there let's see it is able to read it or not so where is a path guys here is a path let me copy the path and I have copied the absolute path now where it is here is my code so here I pasted my path and let's see it is going to load or not it's showing a uni code error so let me put the r over here and it is done now let me check inside the loader that what I have so here it is created the object now let me I write it down the loader over here loader do loader so once I will write down this thing so here you will see that uh okay l a d r loader do loader P object no attribute loader uh what is this let me check the documentation here they are calling loader and split and that will give you the pages great so let me call this uh loader and split and here I have a Pages now let's see we have a Pages yes I got the entire detail so see I able to read the PDF by using this document reader why I've shown you this thing because uh it will be required we use now pandas do read CSV for uh like collecting any any sort of a data in the form of data frame right so if I want to uh take any data if I want to format any data in the form of data frame so so we use this pd. read CSV or we use np. aray similarly if you want to read any a document by using this L chain you can do it you can do it guys so here there is another one and uh you can take it as assignment you can read the CSV there is a complete code here is a uh code for the file directory here is a like HTML here is a Json markdown is there there's a different different uh like a uh different different document loaders you will find out now guys uh let's try to revise the thing let's revise the session what all thing we have learned in today's class in today's session and then I will conclude it and in tomorrow's session I will start from the memory memory and finally hugging face sorry actually I went uh into some depth Okay I uh I try to explain New Concept in a detail way that's why I couldn't start with a hugging face API but don't worry in tomorrow's session I will show you how you can uh how you can uh download any open source model how you can use any open source model model by using the hugging pH API and then uh right after that we'll try to create our application that is going to be a McQ generator we'll see that how you can generate McQ by giving any sort of a text and where this document loader where this chaining memory each and everything will come into the picture and even the prompt also prompt template right now let's revise the thing what all thing we have learned so let me revise it over here so in today's class uh we have talked about so where is my pen yeah so in today's class we have talked about this agent I have shown you that how to call a third party API so here we have seen how to call a Google search engine Google search engine API Google search engine API so let's say uh your chat GPT actually has been trained till uh September 2021 data so if it is not able to give the information in a real time in that case you can use this agent you can call you can can use the concept of chain right you can use the concept of chain in which scenario so where you have a multiple prompt which is connected to each other not a simple application not a simple prompt just for the testing I'm talking in a real time so I'm talking in a real time uh just a wait uh now it is fine so here I was talking about this uh Google search engine and uh yep and then we have talked about the change prompt template also document loader now this uh two thing is remaining so in uh tomorrow's session I will start from the memory uh in tomorrow session actually I will try to explain the memory concept and then I will come to this hugging phas API got it guys yes or no so how was the session uh did you learn something new so please do let me know guys uh did you learn something new from here whatever I have explained and uh how was the session how was the content uh please do write it down the chat should I add a few more things if you want then uh please do let me know please uh write it on the chat I I'm like waiting for your replies and you you can comment also so if you are watching rewatching the video and if you want something from my side you can write it on the comment section you can tell me over the LinkedIn and yeah that's it so I hope you are liking my session so please hit the like button if you liking the content if you're liking the session GB 3.5 get updated till yeah ah recently we have seen that today itself so why we are using Len chain and advantages over other API you will get to know more about it in tomorrow's session otherwise just try to revisit the session in a starting itself I have talked about the limitations of the openai and I talked about the advantage of the open a clearly I have written it over here so just try to revisit the session you will get it and here I have tried to explain you everything what is a lenen it's a rapper or the open Ai and uh your app here is a lenen which is a rapper now you can hit a multiple Thing by using this Len chain yes day three not day three notebook will be available in your resource section soon it will be available don't worry uh yeah so this is it guys from my side I hope uh like uh I already told you the tomorrow's agenda uh memory and the uh hugging phas right so thank you guys thank you byebye for joining the session if you have anything any doubt or any concern or anything in your mind so just uh do let me know please uh write down the uh please write down your thoughts in a comment section and you can ping me over my LinkedIn as well okay so let's start with the session and today is a today is the day five day five of this community session Community session of generative AI so uh I already uh covered um most of the thing actually in a in with respect to this open a and this Lin and uh in total I took four session uh here you can see all all these four session uh where I have started from the introduction of the generative AI then I came to the introduction of the open Ai and we we have understood we have understood the concept of the open API then I have discussed about the Len chain and yesterday also I was talking about the Len chain in today this class uh I will be talking about the memory Concept in the Lang chain which was the remaining one and after that I will start with the hugging face API and then uh from next class onwards we'll try to uh Implement our first end to end project by using this linkchain and this open AI so uh guys here we have uploaded all the sessions all the lecture you can go through with this dashboard which is already there over the Inon platform you just need to sign up and after the sign up you need to login over there and you will get this particular dashboard uh over the in youron platform so already we have given you the link uh in the chat so please try to uh enroll yourself if you are new in this particular session uh this enrollment is completely free you no need to pay anything for this uh for this en for this particular session uh so you can down uh you can enroll inside the course and you can access all the uh lectures and here you will find out the resource section inside that all the resources uh is up to date whatever thing I have discussed in the live classes each and everything you will find out over here so let me show you yesterday I have discussed about the lure so this file is already there you just need to download it and you can uh run inside your system you can run inside your system you can run over the Google collab anywhere you want so I shown you the setup in in the local system itself you can go through with my previous session and there you can understand how to to do a local setup how to do a h setup with respect to open Ai and Linkin how to run a code regarding this open Ai and Lenin each and everything I have explained you in the previous classes so please go through with my session and uh like uh try to understand at least till here till this L and this open I so uh you can implement the project along with me whatever thing I'm going to explain from next class onwards uh because in today's class I will cover this lure memory and then I will come to this hugging face API and from Monday on onwards Monday onwards Monday to Friday so Monday onwards I'm going to start with the project Tuesday also I will take a project and then I will come to the vector database and then few more concept few uh like different different models uh some open source model and I will try to explain you this uh ai2 lab also that uh how you can uh access that Jurassic model uh which I told you in my initial uh like introduction so yeah I think everything is clear everything is fine to all of you so please do confirm in the chat if uh everything is fine everything is clear till here then we'll start with today's concept so I'm waiting uh for your reply please write it on the chat guys and you can find out the same session over the Inon YouTube channel as well so just try to visit the Inon YouTube channel and go inside the live section there you will find out this committee session already uh the recording is uh already we have upd the recording in the live uh section itself and in the description you will find out the uh you will find out this dashboard link as well uh let me show you that just a second yeah so here is Ion YouTube channel so just uh uh over the click over the channel and here go inside this live section click on this live section there you will find out all the recordings so uh this is the very first recording where I have discussed uh each and everything regarding the generative Ai and the second recording is this one the third one this is the third recording and here you will find out the fourth recording now just click uh any of them so after clicking just try to go through with the description and here you will find out the uh dashboard link and other details so each and everything you can find out uh over the Inon YouTube channel as well you you can find out this uh dashboard link over there just click on that and enroll yourself it is completely free now let's start with today's session so here I will be talking about the Len chain L memory in Len chain so how you can uh like uh how you can use this memory con concept by using this Len Chen but before starting with the Practical let me give you some theoretical explanation so what I'm doing here I'm going to open my Blackboard and here I will try to explain you the concept of the memory right and a what thing we are going to discuss that also I will be talking about here I will be writing in front of you and then finally we'll Implement uh those particular thing in a python now uh in the previous class I was talking about the Len chain and I given you the complete detail introduction regarding the Lenin that what is Lenin why we should use it what is the advantage on top of this openi API why we should not use openi API why we should use lenen each and everything we have discussed now in future session uh I will explain about the Llama index 2 so it is similar to Lenin and I will come to the Llama index 2 and it's a framework from the Facebook site so we'll try to discuss each and everything related to L related to this llama index 2 as well and I will give you the differences between Len Chen and Lama index 2 but as of now here I'm going to explain you the Len chain only and most of the concept I already discussed so if we talking about the Len chain so what all thing we have discussed so far let me tell you that so in the Len chain first I discussed that how to uh call the open a API by using this Len chain you can think that this Len chain is nothing it's a wrapper on top of this open a API and not only openi API we can access a various API by using this Len shed so here we have openi API we have seen that how to access and how to uh how to access or how to use the open API by using the there is just a simple import statement which I which we have to write it down inside the notebook or inside the code and we will be able to import it that's it now apart from that we have seen the concept of the agent I have explained you that what is the agent then uh I have explained you the prompt template that what is a prompt template prompt template how you can create a prompt template and all so we have seen each and everything regarding that now we have understood the concept of the chains that what is chains and what we can do by using the chains if we are going to define a chain right so uh what all thing we need to import what component is required what is the meaning of the simple uh sequential chain what is the meaning of the sequential chain each and everything I have discussed regarding the chains after that I came to the document loader I have discussed about the document loader if you want to uh load any sort of a document document is nothing it's just a like a files and all right so if you want to read the PDF PDF file if you want to read the Excel file CSV file HTML file or maybe any other file so you can um you can load that particular file by using this link chain it is possible now the fifth one now the sixth one which we're going to talk about that is going to be a memory so we'll uh discuss the concept of the memory first I will write it on the code and then again I will come to this memory part and try will try to explain you but before that uh I would uh I will explain this memory memory concept by using the chat GPD also before writing a code now this is all about the L CH these all are the thing basically which we need to discuss regarding the L chain and that's going to be a very important if you are going to implement the project end to end project now after that what I will discuss so here let me write down the topic name which we're going to discuss after this Lon so I will talk about the hugging phase hugging phas API how you can generate a token how you can generate a hugging phas API token and after that we'll try to access a open source model whatever model is there on top of the hugging phase so we'll try to access those particular model by using this hugging phase and we'll try to do a same thing we'll try to do a same thing basically which we are doing uh by using this open API but at this uh now at that time I'll will be using the open source model not this U uh like not this GPD model basically which is a uh which is a like model of the open a now will try try to access those open source model and then we'll try to understand that how uh we'll try to understand that how you can create a pipeline by using the hugging face so we'll try to understand the concept hugging face pipeline hugging face pipeline I told you this uh Lenin is nothing this lenen is a wrapper okay this lench is a wrapper on top of this uh open ey this lench is a wrapper on top of the hugging face so not only open AI we can interact with hugging face also uh by using this L chain and not even with hugging phase we can interact with many API in future I will explain you that I will come to that and if you if you want to know about it so you can visit the documentation yesterday I shown you the documentation of the Len chain and you can see over there not even open AI not even hugging pH we can access a multiple API by using Lang chain so Lang chain is nothing just a rapper on a different different uh on top of a different on top of different different API got it yes or no I think this thing is clear to all of you then we'll see how we can create a hugging face pipeline which we used to do by using the hugging pH Transformer now here also we can import the same thing we can import the hugging face pipeline by using the Len chain and we can create the pipeline and we I will show you so here uh by using the hugging phas API you can access the model by using the hugging face API you can access the model but you can install this model inside your local environment also inside a local environment also inside your local memory also so I will show you how you can perform the same thing by local llm local LM means what nothing I'm just going to be uh I'm just going to be download the model I'm just going to be download the model from the huging phase and that model itself I'm going to use similar to this uh GPT and all which I which I'm like accessing by using the open API or by using the Len Chen Len Chen and openi right so same thing I can do over here as well uh okay by using the hugging face API but if you want to download the model in your local memory in your local system that that also you can do that also uh you can do and that is also possible so I will explain you that part as well and finally we'll create a hugging phas Pipeline and from next class onwards we'll start the project implementation so uh if uh everything is fine until here then please do let me know if the agenda is clear to all of you and if you are liking the session then please hit the like button guys please hit the like button if you are liking the session I just started I I just given you the overview that what all thing we are going to discuss that's it I haven't started with the coding and all no we don't have a session on Saturday and Sunday uh we have a session from Monday to Friday great so let's start with the implementation so first I'm going to start from the memory that what is a memory inside the L chain and how we can use that so see first of all let me uh explain you the same thing by using the chat GPD so what I'm going to do here I'm going to open my chat GPD and let me write it down something over here so here I'm going to write it down that uh can you tell me uh can you can you tell me who won the first World Cup first Cricket World Cup so I'm going to ask to my Chad GPD that can you tell me who won the first Cricket World Cup so that this is my question which I'm going to ask to much chbd now let me hit the enter and let's see the reply so is saying that the first Cricket World Cup was held in 1975 and uh the Western de emerged as the champion they defeated Australia in the final which took place as a l uh Lords cricket ground in London on uh June 21 1975 so Western was the uh winner at that particular time now let's try to ask something to my chat gbt so here I'm asking to my chat GPT can you tell me can you tell me 2 + 10 so here it is giving me answer 2 + 10 is 12 now let me ask something else to my CH gbd can you tell me about the Indian GDP so here I'm going to ask my chat GPD can you tell me about the Indian GDP so it is uh saying that uh my knowledge up to date till uh U till January 2022 so I don't have a most recent data now it is giving up some more detail now you can ask the GDP you can ask like GDP the that what was the GDP in 2021 in 2022 something like that or whatsoever now here see what was my first question so here I asked the first question can you tell me who won the first World Cup who won the first Cricket World Cup now here see after writing this many of after writing a different different like a question now is still my Chad GP is able to remember this particular sentence this particular sentence because in back end actually it is using the memory concept it's able to remember the it is able to remember the conversation that whatever conversation is happening over here so here if I will ask to my chat GPT can you tell me can you tell me can you tell me the winning team captain so here I didn't mention anything and I'm just asking to my chat GPT can you tell me the winning team captain so if I will if I will hit the enter and here guys you can see the reply so it is saying okay captain as of my knowledge and I don't have information wining team captain uh can you tell me the winning team okay let me ask one more time is saying that uh can you tell me who won the first Cricket World Cup and here I'm asking can you tell me winning Captain uh winning team captain name so if I'm asking to my gp2 so it is saying that uh it seems like might be a slight spelling about the okay cap it's a captain I am writing a wrong spelling let me correct the spelling first of all so here uh the spelling will be a captain just a second let me copy the correct uh correct spelling and let me paste it over here and let's see I'm getting answer or not so here it is saying information the tournament okay so it is saying that uh uh just a second guys what I can do uh let me delete this chat or let me open the new chat and let me show you this particular thing oh yeah just a wait so it is able to remember the thing uh let me start from the new one uh first of all let me delete it don't know why it is doing like this just a second let me delete the chat okay now here is what here is my new chat now here uh let's start from the beginning so here I'm asking to my chat GPT can you tell me who won the first Cricket World Cup this is a SE uh like simple question which I'm going to ask my chat GPT so here uh you can see it is giving me answer okay no doubt no issue now here if I'm going to ask my chat GPD that what will be uh what will be 2 + 2 2 + 2 right so now let's see what I will be getting over here so here is saying that 2 + 2 will be four now let me ask my chat GPT what will be 2 * 5 now here it is saying that uh the multiplication will be 10 now I'm asking to my chat GPT can you tell me can you tell me about can you tell me who was the winning who was the captain d a i in captain of a captain of the winning team now let's see uh will it be able to answer or not it's taking time and let's see what will be the answer yes it is able to answer now see so here I asked to my C GPT who won the first Cricket World Cup so here is my like answer now I asked to my CH GPT what is 2 + 2 and the answer is this one now I asked to my CH GP 2 into 5 so this is the answer now again I asked to my chat GPT without giving any sort of an information regarding this Cricket World Cup and all and you can see the answer it is saying that Clive Lord was a captain uh clyve Lord was a captain of the West Indies cricket team that was was the Cricket World Cup in 1975 so here guys in a back end this chat GPT is implementing this memory concept now if you are accessing if you are accessing your uh if you are accessing llm uh this GPD and all by using the open AI or maybe by using the huging phase so how you can retain the memory because chat GPT chat GPT is application in backend uh this GPD model is running getting my point now if you want to implement a same thing let's say if you are accessing the model llm model by using the open API or maybe by using the Len Chen basically Len Chen is hitting the open API only so how you can retain this particular memory how you can do that so now let's try to understand that particular part that particular concept so if I'm using uh the open API that how I will be able to retain the memory and Len chain gives you this particular facility so by using the memory concept you can retain the memory like chat GPT so the problem statement is clear to all of you please do let me know in the chat if uh the problem statement is clear I'm waiting for your reply guys please do let me know what's the purpose of the Len chain so in the previous class I have clearly defined the purpose of the Len chain if you don't know about it so you must visit the previous class where I have um I did the detailed discussion about the Len chain great so everything is fine everything is clear now let's uh begin with the implementation so first of all guys what I need to do so first of all I need to import a different different uh first of all let me import the different different uh like a uh import a statement okay so here is my open Ai and okay it is fine now let me do one thing over here let me import the same file I already given to you you can check in a resource section from there you can download it's a same file which I'm using over here so it is for the asent type uh okay everything is fine now let me take a prompt template from here great so here what I'm going to do here I'm going to write it down the memory so just a second yeah so first of all let me write it on the memory over here and memory now let's begin let's start so here I'm going to import The Prompt template the first thing which I'm going to do over here so first of all I will have to uh create my a client right so for creating a client actually uh let me write another the code so here actually let me import one more thing I'm going to import llm Chen actually I restarted my kernel that's why I need to import it again and here uh let me do one thing so LM chain I already imported let me create a client first of all so for creating a client what I can do already written a code inside my file yeah so this is the code for creating a client so here uh what I'm going to do guys see here I'm going to create a client so this is what this is my client now open AI key is not defined okay first of all I will have to import the open a so from length chain Len chain do open and here I'm going to import this open AI now let's run it again and it is saying open AI is not there so let me change the spelling of the openi I think it is capital no it is not like that so let me check with the correct import statement what is that yeah this is the okay I'm using the length chain just a wait so by using the Len chain okay from llm actually we have to import this open a uh it's my bad so now it is done yeah it is fine I created a CLI yep now everything is set so here I have imported three state M first is prom template second is llm chain and third is open AI I restarted my kernel that's why I uh got a a requirement to reimport it uh this particular statement now here I created a client now let's try to understand the concept of the memory so first of all guys what I will have to do I will have to create a prompt template and I will have to hit my model right so for that uh what I did I already written a code so let me uh keep the prompt template over here so this is what guys this is my prompt template I told you that what is the meaning of the prompt template and how to create a prompt template each and everything I have discussed in my previous classes if you don't know about it so please go and check with my previous s so this is what guys tell me this is my prompt template now here I'm uh not going to hit my model U like directly uh instead of that I'm going to use llm chain I clearly told you in my previous class that what is llm chain llm CH LM chain is nothing l l m chain uh is a like concept where we are going to connect two components right so what is the meaning of the chain so inside chain you will find out that we are going to connect a multiple component so here we have llm chain where we are going to connect a multiple component my first component is a client uh which is my object of the open a which I have created and the second uh the second component is prompt template let's try to use llm chain over here and let's see what I will be getting so for that first of all I'm going to create a object of this llm chain now let me create a object of this llm chain and I can keep it over here I can keep this particular object inside this chain variable now let me pass my llm llm is nothing it's a client itself because by using this client only uh we are getting a model we are getting a model from the open Ai and by default I think we are using text D Vinci uh and if you are going to mention the model parameter you can use your desired model as well so that is also possible now over here I'm going to write down this client and then what I will do guys so here I will mention my prom template so let me mention my prompt template let me write down the parameter prompt p r o m PT and here let me copy this name prompt template name and here I have this prompt template name so once I will run it so here you can see we are able to create a chain so this is what this is my chain now what I will do I will run uh uh I will I will like uh I will call the run method and here I will mention the name so I'm I'm asking over here what is a good name for the company that makes so I can uh so this product actually uh I can I can give any sort of a product name over here so let's say here if I'm saying uh if I'm uh asking to my uh like model so colorful colorful colorful uh cup so here I'm asking to my model colorful cup so if I will uh run it so here you can see so it is giving me answer so for if I want to like uh check that what is the answer which I'm getting over here so I can give it to my print statement and let's see what will be the final answer so here it is saying holder color cup Corporation something like that it is giving me a name so let me call the strip over here strip will remove unnecessary thing from here so it is saying cakes uh Sugarland sprinkle so this is the name basically which I'm getting uh if I'm asking this particular question to my to my model right to my llm model to my uh GPT model now uh till here I think everything is fine already we did uh uh like uh we did it so many times in our previous classes in our previous session now let's try to understand few more thing over here let's try to understand the memory concept that how the memory how this memory is working in terms of this uh Len chain okay and how we can uh sustain the memory basically the uh conversation whatever conversation we are going to do now here see guys uh I'm going to write it down uh one more time so let me create one more prompt over here so let's say uh there the same prompt uh same prompt template I have used now here what I'm going to do um here I'm going to ask to my uh here I'm going to ask uh again one thing so let me do one thing let me again create this chain over here and I'm going to copy and paste the same thing and let me run it so chain do run I'm going to call this chain. run and instead of this colorful cup I'm giving a different name so here I'm giving name let's say drone so drones I I want to ask a I want to ask a company name so which make a drones so here the product name is what the product name is drones I'm passing the product name inside this method inside this run method so chain. run and here I'm passing this drone let's see what will be the name so here it is giving me a name drone X technology so uh it is giving me a name that that uh don't ask technology okay so here I can call this a strip so it will remove the unnecessary thing uh from the a beginning so skyron technology so this is the name basically which is giving to me and I hope till here everything is fine everything is clear already we have learned these many things right now let me uh explain you the uh like memory concept so here uh if I'm going to call one parameter so let me write it down this chain do memory so here if I'm going to call this parameter chain. memory so here I'm not getting anything here I'm not getting anything so let's try to see the type of this chain do memory that what is the type of this chain do memory so chain do memory now let me show you the type of this chain do memory so here you can see it is giving me a non type means it is not going to return anything to me because here we are not going to sustain any sort of a memory whatever conversation we are doing to my model what whatever conversation is happening right so we are not going to sustain anything over here we are not going to sustain anything over here in terms of the conversation now let's try to understand how we can do it how we'll be able to sustain the conversation whatever conversation we are making uh like by using the API and whatever conversation we are making with respect to that particular model so here for that we just need to write it down one parameter so uh first of all let me write down the heading over here so the heading uh let me write down the heading The Heading is nothing heading is convers conversion buffer memory so here uh we want to save a memory we want to save a like conversation memory so here I return this conversation buffer memory we have three to four topic inside this memory so step by step I will try to explain you each and everything now first let's try to understand what is this conversation buffer memory so uh you can just think about uh this conversation perform memory uh just like a memory whatever conversation we are going to do with respect to our model right so is going to store all those thing right it it is going to sustain all those thing it's going to sustain the entire memory throughout the conversation that's it now here what I'm going to do so here let me uh copy and paste one more statement and let's see uh what I have written over here so here why we have I have written that uh we can attach memory we can attach memory to remember on the previous conversation I just need to uh mention one parameter the parameter name is what the parameter name is a memory so I just need to attach one parameter and we'll be able to remember all the previous conversation regarding this model now how I can do it so here uh let me first of all let me import this conversation buffer memory from the lenon itself and the uh and then I will show you the same thing by uh from the documentation also so each and everything I uh pick up from the doc documentation itself and again I will go through with the document again I will go through the documentation and I will show you the same thing over there as well so just wait for few minutes and each and everything uh each and every part will be clear to all of you now here uh you can see I'm going to import this conversation buffer memory now what I need to do here so this is the class so I need to create a object of this class so here I'm going to create a object of this class and I'm going to keep uh this object inside the variable so I've created a variable by name Memory so this is what this is my uh like variable where I'm going to keep a object of this conversation buffer memory now let me run it so here is what here is my memory now I just need to mention this particular parameter inside my chain that's it and my work will be done let me show you how so here what I'm going to do again I'm going to create a prom template so here is what here is my prom template as you can see this is what this is my prom template now here what I'm going to do here I'm I'm going to create uh here I'm going to write it down llm chain so let me write it down this llm chain and the first parameter which I need to mention over here that's going to be a llm and my llm is nothing it's a client itself so in the client variable I'm going to keep my llm so here you can write it down this CLI c l i n t and here you need to mention the prompt so here is what here is my prompt and to this particular parameter to this prompt parameter you just need to pass uh this particular value this prompt template name so once you will pass this prom template name and you will what you can do you can create a object of this Ln chain and then you can call chain do run getting my point chain is nothing it's a collection of component getting my point yes or no in a uh like uh in a sequence in a particular chronology so here you can see we have llm client prom template now if I want to retain all the conversation if I want to retain all the memory which I'm able to retain in a chat GPT here you can see so if I'm asking to my chat GPT can you tell me who won the first Cricket World Cup so it is answer like it is generating answer now if I'm asking to my chat GPD what will be 2 + 2 so here what will be 2 into 5 now again I'm asking to my chat GPD that can you tell me who was the camp of the winning team I'm not giving any such information in inside my prompt as you can see but is still it is able to give me an answer based on a previous conversation so if I want to do a same thing with my API how we can do it so that's a thing which I'm explaining you now let me mention one parameter over here that's going to be a memory so m m o r by and here let me mention me m o r by so once I will run it so first of all let me uh uh keep all the thing in a variable variable name is going to be a chain so here Ive created a object of this llm chain now here if I will run so let me run something over here chain do run so here I'm going to ask that uh I'm going to ask regarding the product so what be the good name for the company that makes a product let's say I'm asking about the wines so if I will run it so it is giving me a name so it is giving me a name it is generating a name over here now again what I'm going to do so again uh I'm going to ask to my uh again I'm going to ask to my model so here I'm asking to my model so what would be the good name for the company that makes let's say here I'm saying camera so here I'm asking a c like regarding a camera I just want a name so it is saying that camera Lum technology so it is giving me a name it is suggesting me a name now uh here is what here is my name now uh let me ask to something else over here let's say uh I want a company I want to create a company so the company related to a drone so I want a company name which create a drones so here if I'm saying that drones now here you can see is giving me answer drone craft so here I asked three question to my to my model by by hitting the API I asked three question to my model to my LF model now uh let's see it is able to sustain the memory or not so now if I will run this chain. memory now you will be able to find out yes it is able to retain all the conversation whatever conversation is happening because because of what because of this conversation buffer memory so whatever conversation we are doing right whatever previous conversation is there so each and every conversation we are able to sustain but previously we were not able to do it so here it was was giving me none type here it was not giving me anything but now you can see we are able to sustain the information and if I'm calling chain. memory it is giving me the entire detail over here now let's try to understand let's let's try to like uh uh let's try to understand a few more thing over here now here if I will run this chain do memory chain. memory and here if I will call this chain do memory. buffer so now you will find out that this is the entire conversation now let me uh print uh let me keep this thing uh in my print method so I won't get this selection over here instead of that I will get the new line because slash and me is what SL and me is nothing it's a new line now over here you will find out the entire conversation that whatever conversation is happening between me and model so here human is asking about wines so e is giving me answer now human is asking about the camera is giving me answer human is asking about the drones it is giving me answ so like this you can draw uh you can create your prompt template and you can ask to anything to your model and you can sustain the entire memory you can sustain or you can uh keep the en entire conversation with you getting my point guys yes or no are you able to understand it is getting clear so please do let me know if you are able to understand this particular concept I'm waiting for your reply in the chat please do let me know guys please write down the chat if you are getting it and please hit the like button so yeah I will get some sort of a motivation I are you able to understand the concept of the memory how to retain see here actually we are going to uh like retain the conversation and uh I will explain you the further use so uh I will I will explain you a few more concept over here just just wait step by step we'll try to understand each and everything so don't be in a hurry and try to understand the entire thing if you have started something then definitely I will end it okay so here people are saying that it is clear and you are able to they are able to understand the concept of the memory that how to sustain the conversation whatever conversation we are doing all the previous conversation now let's try to understand few more thing over here so uh yes we are able to uh maintain the previous conversation by using this conversation buffer memory we just created a object and we are just going to keep it over here in our chain that's it now guys here let me show you one more thing so here here what I'm going to do so here uh I'm going to introduce you with the New Concept that's going to be a conversation chain now let's try to understand what is this conversation chain each and everything we'll try to understand by using this conversation chain so here uh I'm saying that here I'm going to uh like write it down some sort of a statement and the statement is something like this so here uh let me mark down it and let me show you so conversation buffer memory goes growing endlessly means uh whatever conversation you are doing uh so you will be able to sustain all the conversation by using conversation buffer memory No Doubt with that but just remember last five conversation chain or if you want to remember just last 10 to 20 conversation chain in that case what I can do what should I do over here so here L chain has given you few more method now let's try to understand regarding uh let's try to understand those particular method that what is the use of this conversation chain and we have one more me method now let me uh give you that particular method also try to understand about it so here is my second method see each and everything I kept it somewhere in my notepad I'm just going to copy and paste so try to understand please because I'm doing it uh because I want to save my time and uh in a short uh amount of time I want to deliver uh like uh more and more thing so here you can see uh there is one more concept that is conversation buffer window memory so there is two concept which we need to understand now here first let's try to understand this conversation chain that what is the meaning of it so here uh what I'm going to say that uh let me keep it in a single line and if I uh if just remember let's just remember 10 to 15 convers and that would be great now what I can do here I can write down some sort of a code regarding this conversation chain so first of all guys what I need to do here first of all I need to import it so let me import this conversation chain over here so from uh the link chain itself from the link chain do chains I am going to import this conversation chain now let me run it and yes we are able to do it now here what I'm going to do I'm going to create object of this conversation chain now if you look into the if you look into the object so here I'm going to keep a couple of thing here I'm going to write down a couple of things so here the first thing see uh this is what this is the object this is the object and inside this object I'm going to mention few parameter the parameter nothing here I'm just is going to mention this model LM model and here I mention open a I can write it down the client directly or else I can write it down like this open a and here is my open a key and this is the temperature you already know what is the temperature in the previous session in my uh day two actually I have uh explained you the concept of the I have explained the concept of this temperature what is the meaning of the temperature and the value you will find out of this temperature between 0 to 2 if you are keeping it zero so you will get a straightforward answer but you have like increasing the value of this temperature so it's going to be this model is going to be a more creative it will give you the creative answer so here you can U maintain the temperature of the answer whatever answer basically you want whatever output basically you want you can maintain a temperature you can maintain the creativity of that particular answer now here uh to this particular method to this conversation chain I'm just going to pass this llm and here is what here is my object open Ai and there's couple of parameter which uh with that you are already familiar now let me run it so let me create a object of this conversation chain so here I created object of this conversation chain and the uh object name is what the object name is convo now I just need to run something over here so uh here what basically what I'm going to do here I'm going to write down convo convo do prompt so here if I will write convo do prompt so you will find out that this is nothing it is giving me a prompt template so here we have a input variable which is history and input template so it is a there is a template the following is a friendly conversation between a human and AI the AI is a tative uh provides lots of a specific detail from its context if AI does not know the answer to the question it truthfully say it does not know so here uh they have written by one by default message one by default prompt actually now let's try to see uh something else over here so here I'm going to write down con. prom. templates now uh let me extract this template and here you will see that uh here basically we have a template the same message which I was trying to read from there from here itself so now you can see the same message over here now if you will write it on the print so here you will get the clear cut message uh without the selection and all so just write down inside the print so this is the uh thing uh this is the message basically which I'm getting it's a by default message uh which I'm getting if I'm calling this con. prompt so here in the template it's a by default message now uh now let's try to understand that what is the use of this uh convo what is the use of this particular object now here what I'm going to do here I'm going to ask the same question to my chat GPD uh to my GPD model now here I'm saying that convo convo do run and here I'm asking to my uh model uh who won the first Cricket World Cup who won the first Cricket World Cup who won the first Cricket World Cup this is the question now if I'm going to run it so here you will find out it is giving me answer that the first Cricket World Cup won by the Western be in 1975 they beat Australia by 179 in the final so this is the information which I'm getting from the from my model now here what I'm going to do here I'm going to run uh convo convo do run now here I'm asking to my model that uh can you tell me can you tell me uh can you tell me how much will be 5 + 5 so it's a simple question which I'm asking to my model now let's see the answer the answer is 10 now let's try to ask one more question over here so let's try to ask one more question to my uh model so here what I'm going to do here I'm asking con can you tell me how much will be 5 * 5 so that's a question or let me keep something else over here let's say 5 + 1 and here and this is the expression this is the mathematical explation which I'm passing now let's see what will be the answer so it is able to answer me that the answer is 30 now let's try to ask uh uh the question to my model that uh who was the captain of the winning team the same question which I was asking to my chat GPT and it was able to answer now let's see uh will it be able to answer the same question or not over here if I'm hitting my API let's see now so here what I'm going to do so here I'm going to uh copy it conversion uh convo do run and I'm going to ask the question the question is nothing the question is uh very simple so who was the captain who was the captain of the winning team so I didn't give any sort of information what winning team which winning team I just like going I'm just going to follow the conversation now if I will hit the enter so here you will find out it is able to give me a reply the captain of the winning team in the first Cricket World Cup was the live lck so it is able to sustain it is able to sustain the conversation now how we can do it by using this conversation chain so first we have understood that if you want to get the if you if you want to get all the previous conversation so you can get it you just need to mention the memory parameter over here if you're not going to do it so in that case it will give you the none but if you're going to mention it conversation buffer memory so it will be able to retain all the previous conversation now here we are talking about this conversation chain so by using this conversation chain I will be able to retain the I will be able to retain the tell me I will be able to retain the memory and uh yes uh like you can ask anything let's try to uh again check with a different uh like uh let's try to check again with a different prompt so here I'm uh saying to my model so can you divide can you divide those uh can you divide uh the number numbers and can you give me answer can you give me a final answer so here I'm asking through my model that can you divide the number whatever number basically is using before actually it is using so can you divide those particular number and can you give me the final answer now let's see what what I will be getting over here so it is giving me the five okay so it is giving me a five uh which uh number is going to divide I uh so the answer is five which number it is going to divide I think uh 5 is six 5 / by uh five if it is saying like that maybe is going to divide this uh 30 by six so that's why I'm getting this five but yeah it is able to retain the memory it is able to retain the memory and it is working so uh I think uh you got to know that how to uh get all the previous conversation that is the first thing and how to retain the memory if you are using the API now guys see we have one more method over here the method name is what conversation buffer window memory now what's the meaning of that first of all let me show you first of all let me write it on the code actually and then I will explain you the meaning of this conversation buffer window memory so uh tell me guys still here everything is fine everything is clear that whatever thing my chat GPD is doing I able ble to do the same thing by using this Len chain this Len chain is too much powerful if you if I'm using my API so in that case how I can sustain the conversation how I can remember all those thing so here is a way you just need to import the classes and all in a back end already the code has been written by someone you just you are just going to use it and uh definitely you can uh create a application in that you can use the same concept got it so if this part is getting clear then and please do let me know in the chat no buffer this is a different object now we are just going to remember all the previous conversation here see we are able to retain the previous conversation this one is giving me all the conversation but here actually by using this conversation chain what I'm doing tell me so here by using this one I'm able to do like same this chat GPT okay okay so where we are able to retain the uh like where we are able to retain the memory so here I was asking this thing to my CH to my model to my API and then I I written this particular um like me I I written this particular prompt and then again I asked this question related to this one and it is able to give me answer so that's a difference try to understand try to observe it here conversation buffer memory this a different method by sustaining the conversation here you can see and conversation chain is doing a same Behavior Uh like which we are able to achieve in a chat GPT so somewhere in a in the chat GPT application also they implemented the same concept for sustaining the memory that's why it is able to do it we don't know uh uh What uh what type of code they have written a backend if you want to check you can check it you can go through with the Len chain so here uh you can search a len chain l a n g and uh just check with the Lenin GitHub so here you will get the source code code of the Lang chain and now you can uh check that what code they have written regarding a different different thing so here go inside the cookbook and there is like all the code regarding a different different thing and just try to read the lowlevel code that what all what Logics and all they are going to uh they have written over here actually so you just need to go through with the Len and uh GitHub and there you'll find out all the codes and all tell me guys now this part is getting clear to all of you please or do let me know in the chat if the part is getting if this part is if this part is getting clear or not this uh conversation chain and this uh conversation buffer memory now let's try to understand this conversation buffer window memory but that what is a meaning of it and then again I will uh I will try to revise it and I will uh I will be showing you the same thing by using the uh documentation so all the thing uh they have mentioned over there already uh each and every theoretical is stuff then uh I will try to explain you that uh from there itself now here we are talking about this conversation buffer window memory then what is a use of this particular method now let's try to understand it so here the first thing which I have to do so first of all I have to create a object of it now uh here let me create a object so I'm going to import it conversation buffer window memory now if I'm going to run it so yes I'm able to run it and I'm able to uh I'm able to like import this particular statement so here I'm going to create a object of it so this is what this is my like object and here I'm going to write down my object name is nothing it's a memory now inside this uh uh like object actually uh there is one parameter so let me write it on the parameter name so the parameter name will be a key right which I represent with which they represent with K so here I I'm going to pass one parameter the parameter name is what the parameter name is K now here I can pass any sort of a value regarding this K 1 2 3 4 5 6 7 8 9 10 11 12 whatever now what is the meaning of that so first of all let me write down that and let me run it in front of you and then I will try to explain you this thing so here I'm going to write it down K is equal to 1 now here I created a object so here I've created a memory now what I'm going to do I'm going to create a conversation chain again so the conversation chain which I uh uh which I imported over here now let me paste it over here this conversation chain conversation chain and now what I need to do I I'm just going to be mention one parameter over here so I'm going to mention memory parameter inside this conversation chain see this is my main U this is my main class this conversation chain which I'm using over here though uh along with that you'll find out two more so conversation buffer window memory and conversation uh conversation buffer memory so buffer window memory what is the meaning of that after this uh particular example you will get to know by yourself on only so here I'm going to keep it and let me uh write it on this memory over here and here what I'm going to do here I'm going to create a object so convo object so this is what this is my convo object now uh what I'm going to do I'm going to run it so here I'm going to run the same thing so now let me uh copy it and let me paste it over here so let me paste it over here uh this particular thing uh this particular sentence and here let's see what will be the answer so here if I'm going to run it so you can see that it is saying that the first Cricket World Cup uh was held in 1975 and it w won by the wested that is perfectly fine now again I'm going to ask to my model that convo. run convo do run and here I'm asking that what will be 5 + 5 now it is saying that 5 + 5 will be 10 now I'm asking to my uh now I'm asking to my model that who was the captain of the winning team so if I'm uh giving this particular code question now let's see what will be the answer so it is saying that I sorry I don't know I'm sorry I don't know because see uh if I didn't mention anything it is able to uh by default actually see there is a uh memory parameter see in a you can create this conversation buffer memory and if you are going to create a chain now if you're going to create a chain now there you can mention this memory and you can track the entire conversation that is perfectly fine now here uh if I want a same behavior like this chat GPT for that there is a main method conversation chain there's a main method so here conver here I created a object of the conversation chain and here is what here I'm going to call this run method now you can see it is able to sustain the memory it is able to sustain the memory now here you will find out one more thing uh like one more class conversation buffer window memory now here Ive created a object of this conversation buffer buffer window memory and I passed the key value key equal to 1 so key equal to 1 means what is the meaning of this key equal to 1 so it is just able to sustain or it is just able to remember all the thing uh like till the one prompt till the first prompt only after that it won't be able to remember anything if I'm writing over here K is equal to 4 now in that case just see the effect so here if I'm going to create K is equal to 4 so see uh convo is there now I'm going to run it okay great now I'm going to ask to my model okay now see see now it is giving me answer so I can Define the window size I can Define the number of prompt here if I'm saying uh K is equal to 2 so now let's see what it is giving to me so here I'm saying K is equal to 2 that's great this one is fine this one is fine now it is saying the first Cricket World Cup was held in 1975 now it will stop over here now if I'm going to ask to my uh like this one so here it is giving me answer because now I'm going to sustain this both both conversation see K is equal to 1 means what let me tell you that K is equal to 1 means what see k equal to 1 means what this one only the first one k is equal to 2 means what this both this both K is equal to 2 so if I'm writing over here K is equal to 2 so it is going through with this particular sentence and it's going through with this particular sentence and if it is seeing this sentence now so it is able to remember it is able to see this one now this one and this one so in that case it a it is able to generate answer but if I mention k equ Al to one so after this one is not able to remember anything that's the last one okay so I can select the window size over here you can select the window size if you're not going to select it will be tracking the entire conversation by default it will be tracking the entire conversation now let's try to see the same thing by using uh like on top of the documentation also so they have mentioned the same thing so let me open the Len chain documentation l n Len chain documentation and over here uh let me open it first of all so Lin memory where you will find out go inside more and here is a memory so let's try to understand uh about the memory that uh what all typee of memories we have and what all thing basically they have written over here let's try to understand that thing so most llm application have a conversational interface so an essential component of the conversation is begin a it's conversation uh is being able to refer to information introduced earlier in the conversation means uh whatever conversation we are making so it should be like uh like it should have a connectivity in between so at bare minimum a conversational system should be able to access some window of past message directly so a comp more complex system will need to have a world model that is constantly updating which allow us to do thing like Mentor information about the entities and their relationship so here they have given you the complete detail now building memory into a system how how state is stored how state is queried so there are like some sort of a theory they have given over here now here they have given that this get is started so let's try to read it from here so let's look at what memory actually looks like in L chain here we will cover the basics of interacting with the arbit memory class so here the same memory class uh which we were using so here I have created a like object of the memory class now here I'm asking so memory. chat. memory add user and what is up so something like that uh there calling basically this particular method over here which is there inside this conversational buffer memory itself now what variable get written from memory so here if you will load the memory you are getting this particular thing the same thing I was able to get by calling this parameter the parameter which I was calling chain. memory actually I'm not directly using this thing I'm not directly using a method from this particular class from this conversation buffer memory instead of that what I'm doing instead of that I've have created a object of this llm chain and here I'm passing my all the component I'm making a chain okay I'm stacking all the component and then basically I'm calling this chain. memory and I'm getting here I'm getting this particular output and the same output you can see over here as well you you you are getting the same output over here as well right so yes I'm able to get the same output by using that particular parameter chain. memory. buffer or chain. memory now here uh we have other one also so like you can give the key and all you can explore about it now there are few more parameter like return return message and all each and everything you will find out over here now end to an example so they have given you the endend example over here so open a prompt template conversation buffer memory now see I'm using the same thing I'm using a same thing over here I'm using the llm chain I'm I'm running the same example in my jupyter notebook so you can go through with the documentation and you can copy from there also and you can test it they have given you like a small small code is snipp it just for the testing just for the learning and directly you can integrate this thing inside your application got it now here uh you can see using a chat model so one more example they have given you and then next step inside that you will find out few more thing uh memory in llm chain memory types okay now customized conversation custom memory multi uh multiple memory classes there are so many thing you will find out so if you'll go inside this memory type so just just see uh with the memory types and and then conversation buffer conversation buffer the same thing um the entire code you will find out then conversation buffer window now let's see what is the meaning of the conversation buffer window so conversation buffer window memory keep a list of interaction of the conversation over the time it only uses the K interaction the number of interaction so this can be useful for keeping a sliding window of of most recent interaction so the buffer does not go too large so if we are talking about buffer so it is having a complete uh like a complete uh conversation whatever conversation we are doing but if you want to keep it short so you can mention the K over there so here I I was doing that so here if I'm writing K is equal to 1 so here if I'm writing K is equal to 1 in that case is not able to remember anything so simply it is saying that I don't know about it it it it is just going to stop over here itself so this one and this one now uh if I'm going to ask this uh particular thing so it is saying I don't know about it because after this one is not going to track anything K is equal to 1 means what just one sentence means it is not going to remember anything uh over here now if I'm going to write it down over K is equal to 2 in that case it will be able to sustain something right by using this two particular prompt and if I'm going to ask something after this one so it is saying that yes now it is knowing okay now it knows about it so here uh if you're not mentioning any sort of a window is is going to keep a track for the ENT entire conversation but if you are going to mention a window parameter over here in that case it will be restricted each and everything they have mention inside the documentation itself try to read it from here got it now how to use a chain means how to like uh uh like how to uh sustain a memory and all means if you're going to make any sort of a conversation and all so this conversation buffer memory conversation buffer window memory is just for sustain the the memory basically the conversation but actual conversation how you make the actual conversation which we are doing over here actually here so by using this particular class conversation chain class this is the main class and this two class for sustaining a conversation this is for the entire conversation and this is just for the limited window means a customized window whatever number you are going to write it down till that particular window now it is clear what is a memory yes or no please do let me know in the chat if uh this part is getting clear to all of you are you able to get it guys uh are you able to understand the concept of the memory how to do that how to make a conversation how to import the different different import statement how to like uh how to go through the documentation yes or no please do let me know in the chat if you're getting it I'm waiting for your reply clear clear clear great uh if you have any doubt you can ask me in the chat and then I will start with the next concept what is the limit of of memory Li limit you can Define now you can def Define the limit according to your problem statement you don't want to be create uh to Long buffer so in that case you can uh you can uh like uh mention this K parameter it's up to you it's up like uh up to your requirement up like how much what uh how much uh like your configuration and all what all resources you are using according to that you can decide where the memory concept used in a real uh life exam application so here what I explained tell me so it is not a real time explain this chat GPT so this chat GPT is a real time application now that that that's why first I have explained this one only so let's say if you are making a conversation to the chatbot if you're making a conversation to the chatbot and if you ask to the chatbot let's say you visited a website any website and let's say I your own website side there you are asking uh let's say we have a chatboard on in own website you are asking to the chatboard okay what is the price of this particular course then U like let's say you are getting some sort of a prize and then you are asking something else who was a mentor and all now again you are asking a question related to that course itself that what all thing you covered in this course now it is saying that which course I don't know about any course even though you mention the name over there gener course but it is saying no I don't know about it because is not able to S it is not sustaining the conversation the conversation is not in buffer so like there it can go and it can like read each and everything the model actually it is not able to sustain the context is able to sustain a context in terms of the a sentence but not in terms of the conversation so that's a real time example so that's why I have explained you this chat GPT at the first place and then I back to this uh I uh went to this uh like python implementation by us using like if we are implementing the same thing like by using the API by using the openi how we can achieve this particular thing how we can achieve the memory and all how we can sustain the memory so it's all about that only please try to run it by yourself please revise it you will be getting and one more thing uh before implementing with uh before implementing any sort of a concept from the Lan chain try to go through with the documentation theyve given you each and everything along with the theory so first read the theory and read the uh like uh code snipp it and all whatever they have given you and then you can uh run it inside your system and then uh basically you can run my file as well whatever like code and all I'm writing it don't worry I give you I will give you the each and everything in a resource section so from there itself you can download it okay so if this thing is clear do please do let me know because I'm going to start with a new thing uh with a new topic and now let me create a new notebook over here I think this Lang chain is clear in the Lang chain I have explained you five to six concept which is going to be a very much important once uh we'll start with the project you will get to know the importance of this thing this topic and inside this particular top inside this particular notebook I have kept everything related to this open API and this L chain so here let me rename it so test open AI API test open AI API and Link Chain so everything you will find out regarding this openi API and Lenin inside this particular notebook guys you just need to visit this notebook everything I have written over here along with the code so let's start with a new topic and the new topic is going to be a uh hugging face hugging face with Len chain uh hugging face with Len chain hugging face face is fce so can we start now have you open the new notebook yes correct aishu uh your understanding is correct tell me guys uh have you opened the new jer notebook so uh I can start with the thing I can start with a new topic hugging Faith with Lin and after this one after explaining you this thing I will move to the uh like I will move to the project I will I start with the project from Monday onwards and first I will explain you the use case and then I will code in front of you only first I will explain the use case and the project setup and all and then we'll start with the implementation of that so let's start with the hugging phase with lench it's going to be a new thing new concept so let's understand uh this uh particular thing so first of all guys what you need to do so first of all you need to log into the hugging face hugging face Hub so just search in your Google hugging face and you will get a very first website this is the website of the hugging phas sdps do hugging U hugging face.com so uh try to visit to this particular website and uh if you didn't uh sign up so first do the sign up and then sign in and after that you will be able to create your profile so first you need to do sign up and then do the sign in so automatically you will get your profile and this is what this is my profile I already did a sign up so no need to do anything you can do the sign up by using the Google s well by using your Gmail ID as well so just try to sign up first and try to like create your profile and then sign in automatically you'll find out your profile over here so after getting your profile guys see uh here they have uh see this is the uh like uh homepage now just click on this model so once you will click on the model actually you will find out so here it is saying no re uh activity display here we have a data set spaces papers papers collection Community there are so many thing right so if I'm following something so it will be visible over here now just click over here this one this model so what I can do I can click on this model so I will be getting all the model these are these are the model basically so just click on this all so here basically you will find out all the model and here actually it is showing you the trending model what trending model is there over here now uh directly you can search about this model so what you can do I'm not able to open let me check with this models yes guys so over here you can see these are these all are the model which is there over the hugging phase now you can uh short it uh which is a trending one which is a most download one which is a recently one recently updated most uh liked llm so there you will find out like all the llms and all now let's check with the most like so here I'm going to short all the model with this most like okay so stable diffusion is is a model which is the most liked one now you will find out Bloom is there uh okay so here orange mix is there a control net is there open journey is there chat glm is there star coder so there are so many model even Lama 2 is also there this one Dolly V2 it's a model from the uh data brakes this llama 2 it's a model of the meta it's a model from The Meta now stable diffusion is also there stability AI there's the organization name stability Ai and here you will find the table diffusion and here you can see the number of downloads as well so there you will find out the number of download now see llama this llama 2 how many times it has been downloaded 947k around 1 million now here you will find out gpt2 gpt2 is also there it has been downloaded 17 million times 170 million download is there okay so okay I think it's not a download it may be a size uh let me check with the download so most downloaded so here now I'm going to check with the most downloaded I think it's a download only it's not a size actually so 73.3 million and distal GPD is also there robot is there there are so many model you will find out and you can see the number 4 lakh 27,000 so if you are talking about the open API so you are restricted with the open API let me show you that what all model is there so if you search over the open a so just open the opena website and check with the models just do the login First and try to uh like click on this API and go inside this model now here you will find out all the model this all the model has been developed by the openi itself and you will find out a different different variants of this model like this chat GPT there are so many variant of this Chad GPT but if we are talking about this hugging face Hub so it's a open source repository anyone can contribute over over here so whoever has created their llm so they have uploaded to this hugging face Hub now you can see the number of model you can see the different different uh like a task over here that what you want to do feature extraction text to image or text to text image to video text to video whatever you want to do you will find it find it out over here let's say what I want to do let's say I want to perform text to text generation so if I will click on this one so you will find out so you will find out all the model from text to text generation you can perform text to text Generation by using this particular model let's say you want to perform a conversation so for the conversation basically there is a different model dialog GPD is there and go is there and you will find out other model as well so from a different different organization you you can go through with it and you can check got it yes or no so this part is getting clear to all of you you can check with the training you can check with the training and you will find out like which is a trending one now let's say I want to do a text to text generation so here I'm going to use this particular model FL T5 base so I'm going to use this particular model now how I can do that what will be the procedure if I want to use this open source model without any charges so here I'm not going to pay anything as of now for this particular model so how I can use it how I can like uh perform text to text Generation by using this particular model now let me tell you that so first of all what you need to do so just click on your profile and here click on the setting so once you will click on the like this setting so here you will find out the token access token so click on this access token so already I have created a token over here so you can click on the new token you can click on the the create token and you will be able to create a new token over here now this is going to be a API key this is going to be a token you can delete it you can recreate it whatever you want you can do it and here uh you will find out access token probability authenticated your identity to the hugging face Hub allowing application to perform specific acction specify the spoke of permission read write and admit so here you can visit the documentation and you can read more about it so first of all guys you need to sign up and then you need to log in and after that you will be able to create your profile and then you can go inside your profile and go inside the setting and there you will find out the token this access token this particular option and try to create the new token after creating a new token what you need to do you just need to copy this token and uh I will tell you step by step what you need to do so from scratch only I'll be writing all the code so first of all see before starting with the hugging face you need to install some Library some other libraries as well so let me give you the name of all those Library I I like kept it somewhere I'm just going to copy and paste all the thing now here are the first thing first Library which I'm going to be install that's going to be hugging face Hub the second one is a Transformer and the third one is accelerate and bit sendy bytes so here this is to the this two is not a mandatory one but yeah you need you can install it because I was getting some sort of a error and for that only I have used this I have like installed this libraries so if uh U like uh so yes please uh like download uh this thing this particular uh like packages accelerate and bit sendy by so you won't get any sort of error throughout this implementation but this two is a mandatory one the first one is a hugging ph up and the second one is a Transformer so you cannot SK skip this two thing and L chain should be there inside your virtual environment because this hugging phase actually we are going to access by using the Len chain only by using the Len chain only we are going to access the this hugging phase so I already did it I already installed it you just need to run it and uh if I already installed then it will uh it will give me the message that requirement is already satisfied so here you can see it is giving me that requirement is already already satisfi got it now guys what is the next thing which I need to do so step by step I have written each and everything I'm going to write it down over here as well so the step first what you need to do so in the step first you need to uh download all the required Library so let me write it down over here the step First Step first is nothing download all the required Library now let me keep it over here and see we are able to download now in the step two what I'm going to do here in the step two I'm going to import it so let me import all the required Library so I have written it over here let me import it uh over here so this is the library which I have imported so the first one is H prompt template hugging phase from the lenon itself of okay so I'm going to import this hugging face Hub and here is what here I'm having the llm chain I'm using this hugging face with Len chain I'm using this hugging phase with this L chain try to remember this thing guys okay so if you are implementing it by yourself please try to remember that we are using this hugging phase by using this Len chain I told you this H Len chain is a wrapper on a different different API not even op open AI we can access many API by using this Len chain many open source model and all it has been designed in such a way now here uh I have imported this thing now what I need to do guys so here I'm going to write it down the Third thing so the third one is what you need to uh like set the environment variable so for setting up the environment variable let me tell you what is a step so here is a like code basically which you need to run so let me copy and paste each and everything I have written uh somewhere so I'm just going to copy and paste the small small lines and all now you need to uh you need to set the environment variable and here first of all you need to import this opening system so import OS os. environment and here is what here is your hugging phase API token and set the environment variable set the environment variable by using this particular uh like a command now if I will run it so here I'm able to set the uh like hugging fish token okay this is my variable name and this is my value value of the variable now from where I got this particular value so I got this value from here itself from the token itself so just try to click on this access token and you will get this value you will get the value of the token got it yes or no now here guys just click on this hugging face and here I seted this token I set this token and this is the variable and this is the value now what is the fourth thing which I need to do so here let me write it down uh this particular thing so step by step I have written each and everything now the next thing which I'm going to do over here I'm going to do text to text generation I'm going to do text to text generation I'm using sequence to sequence model this Transformer is what it's a sequence to sequence model now if we are talking about the uh different different llm actually as a base archit Ure it is using the same Transformer architecture right so either you can say sequence to sequence model encoder decoder model anything anything will be fine for the Transformer also now I want to do a text to text generation so I shown you over here itself in the hugging face model so let me show you where it is so once I will click on this model and here let's say text to text generation I want to do text to text generation so this is a model this a flan T5 base it's a model from the Google side it's a Google model flan T5 base you can read uh everything about this uh T5 model for what this has been trained what uh which data they have used what is a model size 2848 million parameters is the it is having like 248 million parameter and here the number of here you can see the number of downloads here you can see the table of content each and everything basically they have defined they have written over here regarding this particular model and this is a Google model and yes you can uh check about it you can use use it actually uh how to use it uh let me tell you that but yeah you can check about it uh just go through the hugging face Hub hugging face model and click on this model click on this text to Tex generation and you here you will get this FL T5 base now guys what I need to do what will be the next thing so the first of all I need to Define my prompt and here what I'm going to do guys here I'm going to Define my prompt so let me copy The Prompt and here is what guys here is my prompt this is what this is my prompt now here I'm going to uh like Define the chain so let me create a chain over here now inside the chain just just try to focus guys what I'm going to do over here so here guys let me remove this max length I'm not going to write it down as of now so initially like uh not initially in my previous example just look into the chain uh what I was doing over there so if you look into the chain there I was writing there I was defining the model from the open a API so let me show you uh let me show you the chain prom template agent and here we have a chain so where is a chain where is a chain where is a chain this is a chain now see prom template is there chain and here I was I was defining a model from the opena itself what what I was doing guys tell me I was defining a model from the open itself now instead of the open now instead of the open now I'm using the hugging phas so what I did I created a object of this hugging face Hub and I given the repo ID means uh this is the ID of the model and here is a argument that U like I need to set the temperature and all so in this particular format let me take it in a different uh let me take it in a different cell let me show you so here I'm going to copy it and let me paste it over here so what is happening just see what is happening let me take it as a command so this is the code which I'm running see this is the code so here now I'm using now I am going to access the llm okay which llm this Google FL T5 large now instead of the openi I'm going to use this particular llm FL T5 large and this is the uh this is hugging pH actually which we already imported from the lenen itself this is the one and before that actually you need to install this hugging phase so what you need to do guys tell me you need to install this hugging phase pip install hugging phase otherwise you might face issues so here uh you have you are using this particular model this is some sort of argument uh which you need to mention now let's try to create a chain and here the same thing you need to pass the prompt only now see the power of the length chain what it is able to do now uh instead of the hugging open AI I'm able to connect with the hugging face also like likewise we will be able to connect with many apis just check with the documentation uh so now here you can see we are able to create a object I'm getting some sort of a warning you can ignore it because just a uh it's not an error actually it's a dependency warning that uh don't use this version that version what whatever now here I have created a chain now what was my prompt so here I'm saying what is a good name for the company that make a product whatever like uh regarding whatever product I can ask over here so here I'm saying that chain do run the same thing I'm going to ask over here chain dot run now here uh let's say I'm going to ask uh which product I want so I want uh let's say mic or I want camera again so if I'm asking regarding the camera so let's see so here it is giving me answer uh Nikon what is a good company name for a uh what is a good name for a company uh that makes product so it is giving me a neon regarding this camera Let's uh let ask to the different uh uh product let's say watch so here let's see it is giving it Tata now let's see uh here if I'm asking colorful cloths colorful cloths so here you will see that it is giving me a DE so different different name I'm getting in a similar way uh which I was getting by using this open API now instead of the open API I'm using this flan T5 large model you can use any sort of a model any other model as well there are like lots of model which you will find out regarding this text to text generation you can use this model also Mard you just need to mention the ID Mard this is the basically ID just open it and just copy it from here just copy it and keep it over here like uh keep it like this let let me show you that so here is your model name and what you can do just copy this hugging pH from here uh this the complete uh sentence and just change the name just change the name of the model just copy it and paste it over here that's it so just copy it and paste it over here and you'll find out this Facebook ambot large 50 now you can use this particular model if you want few more a few creativity over here you can uh pass the temperature M uh like temperature uh value 1.5 let's say so so this is what this is a model from the hugging face and now this time you are using a different model so the model name is what Facebook MB large 15 so like this you can access a different different model by using the length chain now what you can do you can create a one more chain so here I'm going to copy the same thing now let me change the envir variable name there's going to be a chain two and here what I'm going to do I'm going to copy this hugging face Hub so from here I'm going to copy this hugging face Hub and let me paste it over here so this is what this is my hugging face Hub this is my repo this is my model here I'm setting the temperature and this is what this is my prompt now if I'm going to run it so yes I'm able to create a object now here what you can do here you can call the method run so run and here you can ask anything so let's say here I'm asking uh which product so you can ask uh a mobile so here let's say regarding any sort of a product you can ask so it is running so what is the good name of the company that makes mobile uh it is saying that uh it is giving me a prompt only over here I think I need to follow something else uh chain do run let's ask regarding the same thing colorful cloths and let's see what will be the answer it is giving me a prompt only I think in between I need to run something over here that's why so Transformer this is a pipeline h okay tokenizer I think it is not giving me a correct answer what so so prompt is fine I'm passing a same prompt and this is the prompt now let's say I'm saying zero let's set the different value of the temperature or 05 and see what I am getting over here uh chain two what is a good company that makes a colorful Clause it's not giving me answer instead of that it's giving me a uh like a complete prompt itself so llm hugging face and M large 50 model is what there is a parameter okay no issue I will check with that if I need to mention something over here but that's a way maybe it is not able to uh like predict correctly whatever I'm asking but yeah it is giving me answer this flan T5 large model and even the CH GPD the GPD uh model also from the open AI but it is giving me something else it is running but uh I'm getting other answers or other answer over here not related to our related to our prompt I'm asking something El it is giving me the complete prompt over here okay so this is fine now tell me guys how to use any open source model did you get it please do let me know in the chat if you got this particular part that how to use a different uh how to use any open source model from the hugging phase because it is not a rulebased system now if I'm again running a query so it is not giving a same name because it's a AI based system again and again if you asked to the chat GP now it will do the same thing all right it won't repeat the thing it won't repeat the thing based on your uh like query it will give you the different different suggestions and all so that's why it is giving you the different name tell me guys fast uh it is free actually this hugging pH uh like token is free you can read more about it uh just go through the documentation there is some sort of charges and all U okay so but as of now it is free uh means uh like up to some sort of a tokens and regarding some sort of models it is free okay so here guys I think this hugging face part is clear to all of you please do let me know in the chat if this part is clear yes make question answer board will create in the next class first of all let let me explain you that how to use any uh open source uh model so here I'm using this open source model Google FL T5 large tell me guys fast uh so this part is getting clear to all of you if it is getting clear then please do let me know in the chat I'm expecting yes or no in the chat if you have any sort of a doubt you can ask me I try to clarify that and then I will explain you how to create a pipeline how to create a pipeline by using the uh Transformer so uh we can import the Transformer over here we can write it down Leng ch. Transformer and we can create a complete pipeline as well means we can uh download the model we can download the model in our local okay and in our local memory actually we can do it uh we can download it and then we can do the prediction and all the same thing which I'm doing over here by using the API I will show you the pipeline over here so first of all tell me till here everything is clear think is fine yes you can use the Lama 2 also here you will find out the Llama 2 just try to check with a different different model related to a different different task got it so here you will find out of different different model you can use the Llama 2 here is a llama 2 this one llama 2 B Lama 2 13 billion actually it's from the Billy U but you can check from The Meta also so here I think there was a meta you can search about it so here you can write it down Lama 2 so once you will search it so you will find out the Llama just a second uh you can use llama from the hugging phase I just seen that uh training lamba lamba where is a lamba oh I think I need to check with a different page So Meta Meta Nick snip Q see Stark why I'm not getting it just a second I think I kept this text generation that's why now yeah there there is a llama so here meta Lama so this is the model from the Facebook side from The Meta side and uh you will find out a different different variants of this llama just uh take it and use it and it updated uh 25 days ago this one got it guys yes or no I think you are getting it and you are able to get this particular thing this particular part now let's try to understand that how you can download this model in your local so for that there is a certain step so let me write it down those particular step and step by step we'll try to understand how we can create a pipeline and how we can in download this model in our local is whatever model we want to use it we can download it now for that uh I will have have to perform some sort of a step so here uh let me write it down the heading uh here guys this is the heading uh basically just a second uh let me copy and paste um so here what I'm going to do here I'm going to do a text uh here I'm writing text generation model decoder only model so now I will use the decoder only model any model where I I will just have a decoder so what I'm going to do here so the first thing again I'm going to create a prompt so there's my prompt a same prompt I'm going to use or maybe I written a different prompt over here can you tell me a famous fitw footballer so here I I will give the name so I I can remove this famous from here and see the prompt over here that what is my prompt so here I'm asking that can you tell me uh about a footballer can you tell me about the footballer and here I will just give the name so this is what this is my prompt actually now what I will do guys here I will create a chain now in the chain uh what I'm going to do so just a second fine so here uh let me do one thing for first of all so here I'm going to import some sort of a library otherwise I will get the issues I will get the error so here I'm going to import a few libraries so these are the name so these are the name hugging face pipeline which I'm going to import from the lenen itself actually this is available in a like if you are directly installing the hugging phas hugging face have in your system in your local environment so by using the Transformer also you can import this hugging face hugging face pipeline but as I told you this Len CH is a wrapper on top of this uh apis on top of this libraries so by using this lenon also you can use this hunging face pipeline now what is the meaning of the rapper so uh you know right so tensor flow so this Kass actually it's a repper on top of the tensor flow if you have seen the Kass so there you must have seen that uh like we are just going to call a Kass Dot and pipeline we are just going to write it down Kass ad and we are creating a number of note and then kasas or this that whatever so in back end this T the tens code is running but on top of this T tensor flow they have created one UI or they have created one interface now you are not interacting directly with a lowlevel API low level code you're not going to write it down that instead of that what you are going to do you are using the rapper Kass so it is easy to use for you so similarly see the similar thing you can see over here this Len is nothing it is a wrapper on top of the other apis okay on top of the other packages so over here you can see uh like I need to import this particular thing so the first thing I'm going to import that is a like Pipeline and the second thing which I'm going to import that is a auto tokenizer auto model uh for uh casual LM Pipeline and auto model for sequence to sequence llm I will come to each and every import statement uh once I will write on the code step by step I will try to explain you that why I writing this a particular thing right now here what I'm going to do I'm going to download the model the same model in the local instead of using this API I'm downloading the same model in my local local memory in my current uh memory in my volatile Ram actually so here what I'm going to do first of all I need to mention the model ID now model ID wise you will find out like I'm using a same model FL T5 large and this is a model from the Google side Google has given this model this particular model fly T5 large so this is what this is my model ID from where you will get a model ID you just need to click on the model name and from there itself you can copy this model ID so let's say I want to get a model ID so just copy from here just copy from here copy model name to the clipboard that's it so here's what here I'm having a model ID now guys what you want to do so here actually you need to uh like create a like a the object of this tokenizer and here actually you need to create one uh here you need to here you need to call one method from tokenizer it's a standard processor if you want to use this hugging face pipeline so uh at the first place you will have to perform the tokenization and uh here I'm going to do a same thing so whatever data which I'm going to pass right so this tokenizer will automatically uh take care of it and back end actually some mathematical like like some mathematical equations and all it's going on uh maybe like with respect to the tokenization uh you know like different different tokenization technique what is the meaning of the tokenization so whatever prompt you have that a text prompt actually are going to convert into a numbers so that is nothing that is my uh token means like uh the in a numbers itself so that is what that is your encoded value so by using this Auto encod auto tokenizer you are going to do the same thing you are going to encode the values got it yes or no I think you are getting my point so here uh you are going to use this Auto tokenizer and here I'm going to call this particular method so from uh model ID from pretrain from pretrain and this is what this is my method and here I'm passing this model idid so now what I'm going to do I'm going to keep this particular thing inside the variable the variable name is going to be a tokenizer so here is what here is my variable name so once I will run it now over here you can see we are able to create a object and we are able to call this particular method by passing this model ID now what I will do guys so here uh I will uh I will uh like uh call I will call this particular method let me show you the next one it's a standard procedure don't worry again I will give you the quick revision first of all let me run it the entire thing now over here I'm writing down Auto model for sequence to sequence LM and here I'm I'm calling this method from pretrain and here is what my model ID and here is device map is auto right just just like a like ignore this particular parameter just look into this model ID so here actually I'm passing this model ID Google fly T5 large so this model this is my model actually which I want to which I want to get so here I have a method Auto model here is I'm basically Class Auto model for sequence to sequence LM and from here I'm going to call this from prerain this particular method I'm passing this parameter model ID parameter now if I run it so here you will be able to see that we are able to run it so here we have created a object for this one also now guys the next thing what I have to do so here actually I'm going to create my pipeline so uh here uh I'm going to create my Pipeline and for this one uh I have written a code so this is a code this is what is my pipeline here I already imported it now here I'm going to pass the key text to text generation here is my model this is what this is my model now here is what here is a tokenizer this is a tokenizer and here is a max length so you can remove it you can uh remove the max length also not an issue with that so here uh I'm going to create my pipeline so for first thing what I need to do I need to create a tokenizer and the second thing I need to create a model I need to download the model see uh first time if you will download this model now you will get the uh the progress bar I'm not getting it why why because I I did it actually I was practicing with the thing so at that time I downloaded this I downloaded that particular model and this tokenizer and it is in a buffer itself so it is it is like taking from the caching memory so that's why you are not seeing this that particular progress bar but in your case if you're doing first time you will see the progress bar you will see the prog progress bar okay so here you are going to create a pipeline so this is what this is my Pipeline and here I passed the two thing the first one is a key text to text generation this is my key and here uh is what here I have written the model and here is my tokenizer that's it you just need to focus on this two part now here I'm going to create a pipeline so this is what guys this is my pipeline now after that what I'm going to do I have to pass this particular pipeline to my hugging phase Pipeline and here actually you will find out this is what this is my local llm means see what I'm going to do so this is my model this is my tokenizer which I'm going to download from the pretrain one from the pretrain one and this is the model ID the same uh tokenizer which has been used to this particular model from the pretrain see I'm calling this method so here is my tokenizer and here is my model from this particular ID I'm not getting any progress bar why because I already did it it is taking from a cachia memory okay but if you are doing it first time you will be getting a progress bar and you will be seeing that all the parameters getting installed over here right got it now here what I need to do I need to keep all the thing in a pipeline and then finally I'm passing it to the hugging face Pipeline and this is what this is my local llm now everything is done everything is clear now let me run this prompt so here is what here is my prompt so what I can do let me keep this prompt over here this is my prompt and here this is my prompt and this is what this is my local llm now let me run it and here what I will do guys so now uh let me call the chain and to the chain I'm going to do a same thing what I'm going to do guys tell me to the chain actually see what is a chain I told you chain is nothing it's a it's a like a collection of of the components right you are going to uh you are going to you are you are stacking the components a different different component have you seen the chain right so uh there I was stacking the llm and this prompt so I'm doing the same thing now see the power of the Len chain not even with the open AI we are able to use it with the different different apis with the hugging face also directly and even in the with uh with respect to the local one also with respect to the local LM also so it works with in every scenario this lenion works with every scenario okay now here if I'm going to run it uh so now I I'm able to create this chain now if I will ask anything to this chain so let me write it down over here chain do run now here what I'm going to do here I'm going to pass let's say Messi okay Messi now if I will run it so you will find out that it is generating a answer so Messi is a footballer from Argentina and I just asked what I asked guys so here I asked what was my prompt can you tell me about footballer so here is a name name which I'm passing now let me write it down some any Indian Indian like footballer name so Sunil Chri so let's see uh what will be the answer it is able to get it or not sonil chetri uh okay Sunil chetri born 24th August 1971 it's a former Indian Indian footballer who played up forward so great guys it is able to give me an answer and here you can see I have installed I downloaded the model in a local itself so tell me guys this part is clear to all of you how to use the hugging face API by using the lenen and how to download the model and how to use it please do let me know in the chat if this part is getting clear to of all of you so yes this is the number of tokens max length So within that itself within uh it is not going to exceed the answer and this is the max length basically it will be uh within that itself you will be getting an output tell me guys fast so is it clear to all of you if this part is clear then please do let me know please hit the like button and uh yes if you have any sort of a doubt then you can ask me you can ask about the vat kohi you can check over here so here you can write it down the vat kohi even though he's not a footballer let's see what will be the answer it depends on the model our GPT model is very much uh powerful let's see uh this uh Flame T5 large so okay so I'm getting verat kohi is a s linkan footballer who plays it is completely wrong now you can see so it is uh not giving me a correct answer let's try to design a different prompt over here so here I can uh do that let me this let me design one more prompt and can you tell me about cricketer so here I can write it down cricketer c r i c k uh cricket so this is the spelling now let me take this thing and here is going to be my chain two this is my chain two and this is my prompt two and I'm using a same llm over here so this is my chain two now what I will do here I'm going to run it and let's see will I will I get a correct information or not will this model is capable or not this uh which is a name what is the name flame T5 large so let's see it is a capable or not so chain two. run and uh if I'm running it so in the district of balut prad is giving me a wrong answer I think uh cricketer Koh he does not belong from the bhalpur it belong he belong or not I don't know about it let's uh talk about the suchin uh let's talk about the sain or Ms D so here I can ask about the MS Tony chain. run and let's see who play the Indian Premier League site Mumbai okay it is saying mson plays a cricket from the Indian Premier League from Mumbai Indian so it is like a completely it is giving a wrong answer this flain T5 so you should use a different model in that case actually see GPD is a better one it always gives a correct answer and and is like a much more capable that's why I started from the open a and that's why I didn't started from the hugging page but yeah according to the task according to data according to requirement so now that will be your responsibility as an NLP engineer as a generative engineer you have to check you have to like check with a model that uh like on which data it has been trained okay on which data has been fine tuned how many parameters is there what is a performance performance of that if uh like uh we are doing a text generation that what is a blue score like blue score with that we can identify the uh that like how much it is capable for generating a text so each and everything you will have to read about the model and then only you can use in a production not directly so there will be so many uh like uh uh uh there will be so many experiment which you will have to perform okay there will be so many back and forth you will have to perform before deciding any sort of a model and here I have given you the approach guys here you can append the memory here you can play with the chains here you can uh like play with a different different prom template you can download the document you can import the document each and everything I have shown you inside this two notebook now you are enough capable to implement uh for implementing any sort of a project now whatever project I'm going to teach you definitely you will be able to grab it and uh I will uh after the like jupyter notebook implementation of the project I will uh explain you that how you can convert into an end to endend one so uh from next class onwards we are going to start our Inn project by using this Len chain open ey hugging fish and all and apart from that we are going to use some other thing as well and I will show you the complete setup of the project the project name is going to be McQ generator got it yes or no yes you can fine tune the model as well if you want like if you want to find uh if you want the process of the fine tuning I will give you that also I will give you the fine tuning process also just wait for some time step by step we try to do each and everything if I'm going to explain you everything in a single class so it might be a difficult for you so uh step by step we'll try to do it don't worry we are not going to like conclude or we are not going to step stop this community session uh like uh we'll be continue this uh like in know next week also and there uh we going to talk about many you can use uh like which open stes model you can use for the machine translation you can check over here just go through with the hugging phase API and click on the model model uh just uh click on the model and here you will get the machine translation so maybe machine translation is there classification question answering yeah here is a translation so just see the model what all models is there just try to use this particular model open source model apart from that you'll find out other model as well so see llama 2 is a open source model you will find out a different different variants of this llama you'll find out a different different variants of this llama okay so you can use this llama 2 model for your image translation as I click on this translation here you can see the result got it now you can do your own research you can go through with the different different API as I told you if you don't want to use the chat GPT so here I have created one more API for all of you so like I have written a code regarding one more API that's going to be a AI 21 lab so in the next class I will show you means after the project actually after completing the vector databases and all I will come to some Mis mous topic there I will show you the code regarding this a21 lab okay so here actually uh like we'll talk about the Jurassic model uh which is a very powerful model with that also you can do a multiple thing Falcon is there you can use the Falcon so Falcon you will find out here itself you know uh let me show you where is a falcon so once you will search over here Falcon so it's a model from the Google yeah uh no it's a not of Google one it's a not of Google model actually it's a model from this particular organization I think it's a Chinese organization maybe and one more model let me write it on the name Falcon let me recall the name Falcon was there Bloom is there uh let me check with the bloom yeah Bloom is there and apart from that farm is also there p a LM Palm is also there it is not actually you won't be able to find out this pal over here uh you uh you will have to access it from the separate API so it's a Google model pal p a l m 2 Palm 2 API just search over the Google and you will find out it this Palm API so it's a uh model from the Google research Google researcher it's a model from the Google community so you can explore about the API and you can utilize this all you can see generate your API key just generate a API key and try to use this form model as well and after like so many back in fors after so many research and all then only you can decide that which is which is my best model which one I should which one should I productionize this is working fine or that is working fine but gpd1 is a like trusted one and here you we can you can see the clear application of the GPD model where they are using GPD 3.5 turbo and GPD 4 itself so many people are using the GPI even though it is a paid one but people are checking with the other open source model as well like this Palm Falcon Bloom and all okay Cloud a is one of the model you can check about the cloud as well so I think now uh each and every uh thing is clear to all of you so guys if you're liking the session if you uh like the content then please do let me know in the chat or please hit the like button if you are able to understand everything whatever I have explained you in today's session here I will explain you how to build the applications and all and from next uh class onwards I will give you the different different assignments also yes we can use the mlops tools now like we'll do the development now in between we can use any mlops tools ml flow we can use ml flow DBC or Q flow we can use the uh like other melops tools like Docker and all don't worry regarding that so once I will come to come to the development there I will uh do that okay great now yeah jimin also come you can check with that also recently Google has released the gemin fine so I think uh now we can uh close the session uh now we'll meet on Friday uh Saturday and Sunday we don't have any session uh the session is going to be from Monday to Friday only and the timing is 3 to 5 p.m. IST so let me write it down over here uh Saturday Sunday we don't have any session Saturday and Sunday there won't be any session s session will be continuing continuing uh from Monday onwards Monday onwards and the timing will be timing will be sa so it's going to be from 3 to 5 p.m. ISD so here guys it's a short notice for all of you uh we don't have any session on Saturday and Sunday day the session will be going on uh from Monday to Friday only and the timing will be same 3 to5 istd fine I think uh I have finished the data loader topic uh if you will check into this uh this particular notebook already I have uh uh like shown you this data loader and all now I told you now just try to check with the different different data loaders and all CSV tsv Excel or whatsoever just go and check you can do it by using the documentation but here I given you the example of the to data of this document loader so I have imported this uh PDF I think you missed the previous sess that's why you are asking this question fine so I think uh we can start with the session so welcome back to this community session of generative AI uh this is day six and today we going to start with our first end to end project that's going to be a McQ generator so guys uh this is this is our first uh like end to end project which we are going to implement by using this generative AI uh by using the LMS and all and in this particular project we'll try to use the all the concept basically whatever we have learned so far in our course in our committee session so first of all uh let me show you that uh where you will find out all the session all the uh resources and all because we have updated each and everything over the dashboard and each and everything you will find out uh in the uh resource section so let me show you that uh particular thing and for that guys you just need to visit the Inon website and after visiting the website you need to search about the generative AI so search about the generative Ai and there you will find out two dashboard so first One dashboard for the English and One dashboard for the Hindi so yes I'm taking a same session on my on the I on Hindi YouTube channel as well so you can search ion Tech Hindi so there I'm taking a same session and uh there also I'm uh explaining the concept of the generative a and all so guys here what you need to do here you need to click on this particular dashboard generative AI Community session and once you will click on that so it will ask you for the enrollment and here we are not going to charge you anything any cost so if you are new then please do sign up and then uh try to enroll in this particular course now here guys uh just enroll to this particular course and after that you will be redirected uh redirecting to the dashboard so after sign in you will get a dashboard uh here you can see this is uh this is a complete dashboard uh just a second let me show you that this is the one so this is the this is the dashboard guys and here you will find out all the recording so uh so far I took five session day one day two day three day four day five and in this particular session I covered each and everything regarding the generative AI whatever uh is required if you want to start with the projects and all so uh just go through with the very first session there you will find out complete introduction and in the second one so in the second session uh there I have discussed each and everything about the open Ai and in the third session I have discussed about the Len chin and then I talked about the a few more concept like Len chain memory and all even I have discussed about the hugging face API so if you want to use any open source model if you don't want to use a model from the open AI so uh you can access the model from the hugging phase also that thing also I taught you so if you will go through with my session each and everything you will find out now it's time to implement the project so we'll try to implement a project and and the project is going to be end to endend and not even single so uh not even this project so we are going to implement to more project with a few more advanced concept like vector databases and there will discuss about the r and there we are going to create our web API by using the fast API and flast so each and everything we are going to do here itself in a live session so please make sure that you enroll uh for this particular dashboard and please try to check with the ion YouTube channel as well there we are uploading each and every video so once you will search over the Inon so let me show you that so uh first of all you need to open your uh open your YouTube and there search about the uh Inon so here you can see so open the Inon YouTube channel and inside that uh like uh there you'll find out one live section so just click on this live section and you will find out all the recordings so here you will find out all the recording from day one to day five and uh today I'm uh teaching a project it's a day six and uh if you will open any sort of a video so here in the description also you will find out each and every detail so here you will find out a course detail here you find out each and every detail basically whatever is required so please make sure that uh like you are enrolling to the dashboard for the entire resources and all and yes recorded video is available over the Inon YouTube channel as well got it so I think uh this is fine this is clear now let's start with the project so as you have seen the uh the topic uh so the topic is what topic is the project name is what the project name is a McQ generator using open Ai and langen chain now why I took this a particular project because see uh we have learned each and everything we have learned each and every concept so far related to the open API related to The Lang chain now how we can utilize those information until we are not going to implement the project so in that case we won't be utiliz that particular information whatever we have learned even we won't we won't be able to relate those thing with a real time thing so that's why I kept this project for all of you in between and then we'll try to move into some Advanced concept like databases and all and we'll try to create a few more a few more project in our upcoming session but yeah so here uh we are going to start from the very basic project and then we'll go to the advanced label got it now what all thing I'm going to discuss in today's class in today's session along with the project so here I will teach you the entire setup of the project so here uh we are not going to implement this project in a jupyter notebook so for that we are going to create a complete development environment so I will show you how you can create a like and to and development environment and then we'll try to deploy this project as well so in tomorrow's session I will show you how you can deploy this project along with the cicd concept along with the continuous integration and continuous deployment concept so in today's session we'll try to see that how we can set up our uh development environment and then uh we'll try to uh implement the Jupiter notebook regarding a different different application and then we'll try to convert that jupyter notebook into a endtoend application got it yes or no so the agenda is clear to all of you please uh do let me know in the chat yes or no great so I think uh we can start and uh yeah if you are liking the session then please hit the like button and uh keep watching so guys uh the first of all let me write it down each and everything each and every step uh whatever we are going to do here and whatever uh we'll be doing throughout the session so for that uh I'm using my Blackboard and here itself I'm going to write it down the each and everything so first of of all let me remove it and yes uh I have opened the fresh one now let me write it down each and everything uh regarding today's session so guys see the first uh thing which we're going to do uh that is uh environment setup so at the first place uh we're going to uh set up our uh environment our development environment I will show you the complete a project setup so here let me write it down so setup development environment so the first thing which we're going to do uh we going to set the development environment now after that what I will do after setting the development environment then uh we'll try to uh run a few experiments run few experiments uh few experiment in a Jupiter notebook so we we'll run a few experiment in a Jupiter notebook after that we'll create a end to end will'll create a modular coding like by using this particular experiment and all so I will do a like modular coding I will create a several file and then I will uh try to segregate the code so uh after uh doing a few experiment in a Jupiter notebook I will convert this jupyter notebook into a modular one got it modular coding now after that after uh converting to a model one Modular One definitely uh like uh uh my code will be uh my code will be uh ready and then I will create my web API then I will create my web API by using the stream lid so here by using the stream lid I will be using I will be creating my web API and after uh creating this web API definitely for sure I will test it and finally we'll try to deploy our application on my cloud platform in my AWS or aor got it so these are few step uh these are the these are few things uh uh basically which we're going to perform uh regarding this particular project so today uh I will be uh cover this two point the first one second one and maybe the third one and tomorrow I will create a web API because we have a time restriction the session is just for the 2 hour otherwise I can complete this thing within a uh class itself so today I'm going to complete this two thing and tomorrow uh I will be converting uh the entire code in a modular one and then uh we are going to create a web API and finally we're going to deploy the application got it now after that now after that what uh we are going to learn so after completing this thing we're going to learn about the vector databases we'll try to learn a vector databases we'll try to see that what all options we have if we want to store the embedding not even the vector databases what all other options we have so we'll try to explore about the mongodb cassendra and we'll try to look into the SQL base database also and then finally uh we'll look into the vector databases different different options we have and then uh we'll try to use the RG concept on top of that and we'll create a few more project so yes uh from today's onwards our project journey is going to be start so don't miss it and within 2 week uh our aim to complete at least three and to end project in a live session itself got it so I hope this idea is clear to all of you now uh let's start uh first uh with the project setup so the implement impation the project basically I'm going to implement in a jupyter notebook so entire development setup I'm going to create in my uh sorry I'm going to create in my vs code so for the entire development I'm going to use my VSS code and today I will show you how you can set up your vs code for the end development got it so for that guys uh what you need to do first open your CMD uh uh Implement along with me because uh I will share the GitHub link with all of you so that you can uh write it down the code you can copy each and everything from there itself and along with the uh code I will I will be writing all the commands and uh all whatever I'm going to use in my uh in my project so in my project setup and all so each and everything I will be uh I will be writing in my GitHub U I will be writing in my readme file and then I will give you uh through my GitHub link so guys uh you can follow uh uh each and everything along with me so uh first let me start from the project setup so uh here here guys uh first of all what you need to do so in any directory in C directory in D directory in whatever folder you need to create uh one folder you need to create one fresh folder okay so go in uh go with any directory C drive uh C directory D directory C drive D drive e Drive and inside that you need to create one folder so here you can see this is my location C user sunny and here I'm going to create my folder one fresh folder so for create a folder there's a command like mkdir by using this particular command I can create a folder so here I'm going to write it down mqd and my project name so let's say my project name is what McQ generator so this is the like uh this is the folder name which I have written now uh yes I have created my folder now what I need to do I need to move into my folder now I need to change the directory so here I need to move into my folder I need to change the directory so for that we have a command like CD CD McQ generator this is my folder name now you can see I'm into my folder now I'm inside my folder and from this particular folder I need to launch my vs code so for launching the vs code from the command promp there is a command the command is called code dot code space dot so once you will write it down on this particular command code space dot so in that case you will be able to launch your jupyter notebook in a current for folder right so here is my folder name my folder name is what my folder name is McQ now here you can see I'm able to launch my j i I'm able to launch my vs code inside this particular folder now if you want to verify so for that what you can do you can go with your terminal so just click on the new terminal and here you will find out the same location which you are seeing over the command prompt so guys here you can see you are into the same location which you were seeing over the command prom got it now let's say uh if you don't have this vs code so from there you can install this vs code so for that you just need to go through the Google just search over the Google just search about the google.com and here write it down vs code download so write it down here vs code download so you will get a link for downloading the vs code and here uh this is the link guys I'm giving you this particular link inside the chat and here uh like you can go through with this particular link and you can download the vs code according to your operting system so if you are using Mac uh so you can download from here if you are using the Linux so from uh for the Linux you can download from here if you're using Windows so for the windows you can download from here you will find out all the three option for a different different operating system now uh once you are done uh uh like with the download and all so after that what you need to do so after that you need to install it so just try to do a double click and install this vs code in inside your system and then you can follow the same procedure so you can create a directory you can uh write it down this first and then you can change the directory and from on that particular directory you can launch the vs code got it now if you not able to do it by using this command line so by using uh by using the UI also you can do the same thing so for that uh just uh go inside your directory and here create a new folder so create a new folder and then do the right click and check with the show more option and here you will find out option for launching this vs code so by using this uh GUI also you can do a same thing and by using the command prom also you can do a same thing so I took this command promt approach and here you can see I'm able to launch my VSS code inside this particular folder so if you are done till here so please do let me know in the chat please uh tell me guys if uh you are done till here tell me first have you opened your vs code in a folder if you did it then please write it on the chat yes yeah I'm waiting for 1 minute so until you can open it yeah you can use the pyam also uh not an issue with that py Cham will also work any ID so here I'm using this vs code okay so I think uh now everyone is done so so let's start with a further step so after opening this vs code so F the first thing uh the first thing which you need to do you need to initialize the git so here guys uh what you need to do you need to initialize the git so uh here see we have a uh like a various option here once you will click on this drop down so here you will find out of various option like Power Cell G bash command prom Ubuntu Kali so in your case it there might be only G bash command prompt or Powershell but in my case here you will find here you can see I have a different different terminal right but maybe in your case you just have this git bash and command prom that's that's all fine right so either you can work with this G bash or you can work with the command prom but don't work with this poers shell because otherwise unnecessarily you will get uh uh errors and all so I won't recommend you to uh work with this poers shell and all so if you want to work uh with the like with the terminal so here either use this git bash or this command Pro don't select this Powershell so here I'm using this git bash so here I can easily run my uh like Linux command also so yes uh if you don't want to use this git bash so you can use this command prom also that is also fine now guys here uh you'll find out that okay so this is what this is my G bash now uh here if you are not able to see the base environment so for that what you need to do so just try to click on this View and go with the command pellet so here you need to go uh you need to click on The View and click on the command PL and then select python interpreter so here you will find out various interpreter so you need to select this base interpreter and after that you need to relaunch this git bash so in that case uh if if you are not getting that base environment in your uh G bad so after uh like following this step uh definitely you will be able to see that so here now you can see I have a Bas environment on my good bash now uh let me uh let me run the further thing so the first thing what you need to do over here like so the first thing you need to initialize the git right so inside this directory you need to initialize the git so for initializing the git I just need to write it down a simple command that is what that is git in it so by using this particular command I can initialize the git in my current folder in my local folder so now this local folder will be treated as a local repository and then I can uh I can upload this same folder on my uh GitHub and yes like that's going to be my central representing so GitHub is going to my central repository and as of now if I'm going to initialize the git in my local folder so this is what this is my local repository each and every thing each and every track actually I'm going to keep it keep over here itself in my local folder so that uh like the entire data you will find out inside the dogit folder I will show you that so here you need to write it down this git in it so once you will write down this g in it uh so you will be able to initialize the git inside this particular folder okay now uh here you can create a file so here I'm going to create my readme file so r e a d MD so readme.md so it's going to be a markdown file MD means what it's be it's it's a markdown file so here uh guys you can see I created my markdown file right now uh if I want to publish see as of now see if you will look into this particular folder so let me reveal it inside the file explorer so just try to click uh do the right click on this file and reveal in the file explorer so here you will find out this dogit and here you will find out each and every information so because of this dogit folder actually uh this a local folder is being treated as a local repository now here you will find out each and every metadata so regarding your commits and all so whatever codes you are going to upload whatever like changes you are going to made and all right whatever uh changes you are going to commit and add so each and every metadata you will find out inside this dogit folder and why we use this uh git guys tell me we use this git for the code versioning got it I think uh you have a basic idea about the git so I'm not going into the depth of this git and all as of I'm just like giving you the uh the high level overview that's it now here uh you can see I have create I have initialized the git and here you can see this do git folder inside my uh dogit folder inside my local repository so is it fine to all of you I think yes now what I can do here so here I can publish the branch so I can publish the this local repository to my GitHub so for that what you can do see you can use this uh terminal also and here this vs code has given you the GUI option so just click on that just click on this particular option and here you will find out uh the various thing right so uh here you will find out the various options and all now let me show you step by step so the first thing what you need to do so first you need to add your file so for adding the file you just need to click on this plus icon so uh if you want to add the file uh so for that you need to click on this plus icon and after that uh like you need to uh write it on the message so you write down now that first you run this git in it and then you run this git ad git ad and the file name so I'm doing the same thing over here so by using this plus icon I'm adding this particular file right so uh in my uh like staging area right so and then I will do the commit after writing a message so here I'm writing down writing the message uh this is my first commit so here uh my messages this is my first commit now after writing the message what I will do I will commit it after committing is uh after committing uh it okay so it will ask to me would you like to publish this Branch so I would say yes I would I want to publish this particular Branch so here it is asking to me how you would like to publish it so whether uh as a private repository or as a public repository is going to publish over the GitHub actually so here it is asking to me how You' like to publish it whether as a private repository or as a public repository so as of now I'm going to publish publish this particular Branch as a public repository so you can click on this public repository and yes it will publish a branch so it is uploading all the file here you can see and then it will give you this a particular popup so here it is telling you that please sign in with your browser so once I will uh click on this uh sign in with your browser so yes it is uh doing that and uh just wait it is publishing the branch so it has given me uh this particular page now let let me authorize it so here I need to click on this confirm and after that guys you can can see authentication succeed so now uh my branch is uh published let me show you that so here you can see you can open it and this is guys this is my Branch okay so I published this branch on my GitHub so I hope this thing is uh clear to all of you and you are able to publish your branch yes or no guys tell me are you able to publish your branch um just a second great so now let me give you this particular link and so that whatever code and all I'm going to write it down so directly you can copy and paste from here itself from my git so let me give you this uh particular uh link uh so that you can copy each and everything from here itself just a second so did you get it please uh do let me know in the chat if you got my code tell me guys fast sorry if you got if you got my link then uh please do let me know in the chat again I'm pasting uh this particular link so this is my GitHub link guys yes please do confirm if you got my GitHub I given you the GitHub guys yes or no I am waiting for a reply please check it check with the popup so first you need to sign in through the browser and then only you will be able to log in if you're not able to follow this GUI approach uh in that case uh what you can do so you can uh like uh push it through the command line also yeah if you are not able to log in so through this uh command line you can uh configure the username and the uh like email ID so for that there is a like command so let me show you that particular Command right just a second so what I can do I can show you over here itself uh so you can search over the Google how to configure how to configure get uh username so you can search over the Google and then you will get a command so let me give you those particular command if you are not able to uh sign in but please make sure that if you're getting the popup then then directly you can sign in but if you're getting any sort of error right so for that there is a command so get config hyphen global hyph iph global user.name and here you need to pass your username so like whatever username you have so you just need to pass your username and then you need to pass the you need to configure the email also so okay so here uh for the username and in a similar way you need to configure the uh you need to configure the email so let me give you this uh two command now here let me write it down that you need to write it down your your username your user name and here is a command guys so first try to configure your username and here again I'm giving you the same command along with the username you can configure your email also so let me write it on the email and in the double code actually you need to pass your email so here your email ID so guys uh run this two commands on your uh on your uh command line actually and then you will be able to sign in from here itself got it yes or no till here uh everything is fine everything is clear I given you the GitHub Link in the chat so so um you can click on that and you can uh like you can check with my repository each and everything I'm going to update over there itself so that uh you can copy and paste the code directly from there now guys uh here uh if you're not able to find out uh if you're not able to click on this link so you can search uh with my username also so or over the Google you can write it down s Savita GitHub you will get the GitHub directly it will give you the link link of the GitHub and this repository is a public repository so Direct you can go through with my repository and you will find out this particular project got it great yes uh from the same terminal you need to configure your username and email ID okay now here we have published uh this code as a uh like to my GitHub right this this particular repository this a local repository I publish to my GitHub now I need to follow few more step for setting up my environment so the next thing what I need to do here I need to create my environment because I'm not going to work in my base environment and I'm going to create a virtual environment over here okay so for creating a virtual environment there is very a simple command so let me write it down on that command so cond condu create condu create hyphen P okay hyphen p and here you need to write it on the environment name so here my environment name is going to be en EnV en EnV and then you can write down the python version python is equal to 3.8 so I'm using over here 3.8 and then hyphen y so this is my command uh which I'm going to run and by using this particular command I can create the environment in a current directory itself in a current repository so here you can see this is what this is my environment uh which is being created so just wait for some time it will take uh few second let it create so my environment name is what my environment name is ENB now here my environment is getting created and it is done now after that what I need to do guys so here I need to activate my environment so for activating the environment you need to write it down Source activate if you are using this git terminal so in that case instead of this cond you can write down this Source because sometimes this cond gives issue so I'm not going with this cond here so I'm using this source of over here so you need to write it down the source activate activate and here Dot dot means current directory and from this current directory there is a folder folder name is environment e andv right so here you can see I'm able to activate my environment and here you can see this is what this is my virtual environment got it now let me clear it first of all so here now you can see it is giving me a uh like uh it is giving me a how it is giving me so many files uh for adding right so U like here it is giving me more than 5,000 file but I cannot like add all all the files I cannot like add all the files on my GitHub right so for that what I will do if I want if I don't want to track it if I don't want to track this particular file so I can U mention this name this EnV name in in the file the file name is what the file name is dog ignore so here let me create one more file in this uh particular directory and my file name is what my file name is uh dogit ignore so here I'm writing this uh dot get ignore uh and the touch command is the touch command for creating a file so touch dog ignore now here you can see I'm able to create this particular file this dog ignore now inside this file you can mention the name the name of whatever file which you don't want to drag so here if I don't want to track this EnV folder right if you don't want to track these many file if I don't want to upload it in my cloud repository right or if I don't want to track it uh by using this git so so you can mention it you can mention this folder name inside this dot inside this dog ignore file so here I'm writing EnV uh EnV is nothing it's a folder name now once I return it once I return this uh EnV inside this do G ignore now you can see it is not going to track it at all so here uh it is not going to track uh this particular folder now and it is giving you only it is giving me only one file now yes I can uh add it so here uh first I'm going to add this file get add and this file name now here I'm writing my message so I have added I added my get ignore so this is my message and after that what I will do after after this after this one I'm going to commit it so edit my get ignore and then do the commit now uh you need to click on this sync changes your and your changes will be sync so the same file you will find out the same file you will find out in my G iub also so uh let me show you where you will find out that let me open my GitHub and uh here guys here is my GitHub let me show you the repository here is my all the repository and this is the uh like folder this is my like project actually now see uh I just added this dot get ignore now see see that uh commit just now just now I committed uh this particular file and here you can see my dotg ignore now once you will open it so here you will find out the folder name so the folder name is what EnV so I don't want to track this file throughout my process right so I uh if I don't want to track this file at all so yes uh for that I will mention it inside my dog ignore file got it now uh till here I think everything is fine everything is clear and I hope you are of you are able to follow me till here so please do let me know in the chat guys if uh uh everything is clear everything is fine till here what about 3.9 yes you can use 3.9 3.10 as well but don't use 3.11 3.12 or 3.13 till 3.9 and 10 it's fine but please make sure that uh uh please make sure that you are going to use the same version which I am using uh so you won't face any sort of a issue any you won't get any sort of error uh during the implementation got it yeah so if it is done then uh please do let me know guys please write it on the chat and uh please hit the like button if you are liking the session then done can I get a quick confirmation in the chat great so I think uh now everyone is done so here I have created my environment now guys what you need to do so after that you need to create your requirement. txt so inside the requirement. txt I'm going to mention the entire requirement right so for creating a requir txt so from here also you can create by using this particular icon other you can use the same command same a touch command by using that command also you can create the require. txt in a current folder in a current repository now uh for creating a requir txt so I'm using this particular icon and here I'm writing requirement R Qi r m m n ts. txt now in this a particular file I'm going to mention all the requirement whatever requirement I'm having regarding this project right so I'm mentioning all the requirement inside this require. txt so guys uh let me copy and paste all the requirement or whatever is there all I'm going to write it down here itself so the first thing which I'm going to use uh in my project that's going to be a open a so I'm using the open a API and for that this open a package is required already I shown you how to use openi API how to install this particular package because earlier we also we have created the environment and there also we have installed this open AI if you have attended my previous session then definitely you must be aware about this particular thing now here uh there's a open a now the second thing which I need to uh install in my local environment in my current virtual environment that's going to be a len CH so here guys let me write down the Lang gen so you need to install the langen CH in your current environment first thing is open Ai and the second thing is what the second thing is the Len chain the third one uh which I'm going to write it down over here that's going to be a stream L because here I'm going to create a API by using this stream l so here I'm going to like install the stream lit in my local uh like environment in my current virtual environment the second thing which I'm going to be installed over here uh that's going to be a python hy. ENB so I will tell you what is the use of this particular U like uh uh this particular package python hyon do EnV so I'm going to install this uh python hy. EnV package and I will tell you what is a use of this particular package and apart from that I'm going to use I'm going to download one more package that is going to be a pi PDF so Pi PDF two so these many thing I'm going to be install in my current virtual environment okay and apart from that I'm going to create couple of more folder right couple of more folder I'm going to create in my local repository in my local folder so uh couple of more uh files and folder not only folder files also so here uh uh requ txt is done now I'm going to create one more file the file is going to be setup uh setup uh setup.py file now why we use this setup.py file we use the setup.py file for installing a local package local package in my virtual environment if I want to install the local package in my virtual environment for that we use the setup.py file got it so I created the setup.py file I created the re. txt now let me create a one more file so here I'm going to create so not file actually I'm going to create one folder here my folder name is going to be SRC SRC means what SRC means source code now inside the SRC I'm going to create a one more folder and the folder name is going to be so first of all let me create a file inside this SRC the file file name is going to be dot uh sorry underscore inore dopy so here inside this SRC folder I'm going to create init file okay init file I will tell you why we create this init file inside the a folder what is the requirement of that and uh each and everything I will explain you don't worry so here uh you can see I've created this init file and inside this inside this SRC folder itself I'm going to create one more folder the folder name is going to be McQ itself so m McQ generator and this is what this is my project so McQ generator so this is what guys this McQ generator is nothing it's my folder and inside this also I'm going to create one init file so here let me create the init file inside uh this folder also so init init.py so what I did guys tell me so here if you will look into this uh if you will uh let me reveal it inside the file explorer and let me show you that what I did so here uh just look into the SRC folder so inside this SRC folder I created two things first I created this init file and the second one I created the McQ generator folder and whatever source code whatever source code I'm going to write it down throughout my project so I'm I will be writing down here itself apart from The jupyter Notebook so each and every line of code modular coding I will be doing over here itself inside my McQ generator folder got it now here uh what I did I created this init file underscore uncore inore ncore now what is the requirement of this init file why I did it because see if I let's say uh like here I want to consider this folder this folder as a package as a local package right this folder actually I want to consider as a package now what is the meaning of the package so the package is nothing it's a it's a folder itself folder which is containing a multiple python file and inside the python file you have a code you have a code like a classes functions and all right so you have a folder inside the folder you have a file and inside the file you have written a code right so now guys see uh let's say if you're installing pandas if you're installing numai if you're installing maybe open a or let's say if you're installing langen so what is this tell me it's nothing it's a full it's a package itself it's a package now and package means what package package nothing it's a folder right folder is what F the package is equal to folder right folder itself is called a package now inside the package or inside the folder what you will find out inside that you'll be having a multiple python files right and inside those python file you uh someone has written a code uh in terms of function and classes and that is what uh that only you are going to use right so this uh lenen this open this pandas napai someone already created it and they have uploaded over the pii repository and from there itself you are going to install it inside your project but here this McQ generator actually it is your local package where you are going to create a multiple folder mul multiple python file and uh if you want to treated if you want to treat this folder as a package so for that there's a convention from the python side you will have to mention this init file inside the folder right so here my folder is what my folder name is SRC SRC means what it's a short form of the source code SRC now this SRC actually I want to treat as my local package so there is a convention from the python side you need to mention this init file or you need to create this init file inside this folder then only it will be treated as a local package I think the idea is clear now so by using the setup.py file by using this setup.py file I'm installing this local package in my current virtual environment got it I think now each and everything is clear to all of you now let me back to my code so here is what here is my code so I created couple of a folder couple of file now guys uh let me create one more file uh like one more folder over here and the folder name is going to be experiment so here I'm going to be create one more folder and the folder name is going to be experiment and inside this particular folder I'm going to create my Jupiter notebook I'm going to create my ipb file okay so for creating ipb file inside this particular folder so you can click on this folder and click on this file icon and then you can write down your name so here I can uh write down the name any any name I can write it down here let's say McQ dot ipnb uh do ipnb so what is the meaning of this ipynb so ipynb means nothing uh I python uh notebook okay that's the full form of this IP YB now here you can see this is what this is my jupyter notebook now whatever experiments uh whatever experim experiments will be there throughout this project so I'm going to do my entire experiment over here in my Jupiter notebook and then I will convert into an end code into my end to end pipeline got it now here uh the first thing what you need to do so you need to select the kernel so just click on this select kernel and then click on this python environment then you will get all the python environment so this is your current virtual environment so this this the this interpreter which you can see over here the first place which is a recommended one so this is from your current virtual environment from the EnV itself here you can see EnV python.exe so here I'm going to select the same kernel so here I have selected this particular kernel now you can see uh I'm done with everything now I just need to uh I just need to like uh install the recom txt I will start by writing the code so let me give you this each and every file and folder so for that I just need to add it from here itself so I'm going to add all the files and all over here I think it is done now I will write it on my uh like message so my message is structure updated so here is what here's my message guys now let me commit it so structure s u c Tru structure updated now I have written my message after adding all the file now once I will do the commit and it will ask to my sync it will it will ask to me would you like to sync changes so yes I want to do it now I will click on okay so as soon as I will click on okay you will find out every file and folder in my repository itself so now let me show you uh every file and folder uh so here guys you can see I have a experiment folder now inside that there is my file ipv file that's what this this this file this particular file I'm going to use for my entire experiments and all and here you will find out my SRC folder inside the SRC folder you will find out the init file and one more folder that is what that the McQ generator and then you will find out this setup.py also so here I have the setup.py as of now you won't be able to find out any sort of a code over here but don't worry I will keep it uh inside my setup.py file and here you can see my require. txt so here I have mentioned all the requirements got it now let me uh give you this link to all of you so I'm pasting this link inside the chat and if you're not able to click on that so you can search over the Google let me search in front of you only so just go through the Google and search Sun Savita GitHub so once you will search it uh then automatically you will get a GitHub link just go through with the GitHub link and here click on the repository so here is a repository click on the repository and the Very first project this one McQ generator uh so just click on this uh this particular project and I have kept each and everything over here itself inside one folder so if you are done till here then please do let me know in the chat yes in my previous class I shown you how to use hugging pH API Hub don't worry uh after this project I will use the open source model only I w't going to use any uh like any model from the openi itself but yeah in today's project in the very first project I'm going to use the openi API along with the Len chain got it tell me guys uh is it fine to all of you are you able to create an environment and uh did you publish it have you created a environment did you created a GitHub um and sorry did you initialize the a git basically and did you publish your repository if everything is done then uh please do let me know guys I will uh move with a further step so please uh write on the chat if uh you are done till here then I will proceed uh with the further commands don't worry I will give you all the thing all the commands and all in our documented format so you won't face any such issues at all or in a single uh like go you can run like each and everything don't worry I will give you that first of all tell me uh if you are able to do along with uh if you are able to do till here if you are able to do these many thing then uh please give me a quick confirmation or if you are comfortable till here please do let me know fine so I think uh we can proceed now so uh here I have created uh you can see uh I created uh many files and folder now let me open this setup. py5 okay so here I have opened my setup.py file and here I'm going to write it down uh some sort of a code so what I can do let me copy the code uh there is only just one function and here I pasted the code got it now uh just look into the code so what I have written over here so here I have imported one uh statement uh the statement is what the statement is a find package so from setup tool I'm going to import the find package and here is what here is my setup here's my method setup method now here I have mentioned couple of thing uh so I'm calling this particular method setup a method and uh I have mentioned uh some parameters so the first parameter is a name so here I'm going to write down my here I'm going to write down the name of the package now here is a version version of the package now here is the author author is a sunny sun Savita author email sunny. Savita a and here is install requirement so these are the package which is like required okay now here is a package so find package so once uh see uh this find package actually this this particular method only it is responsible for finding out the local package for from your local directory so wherever uh it is able to find out this dot init file wherever it is able to find out this dot init file it will consider that folder as a package got it now uh here you can see so I have imported this thing find package setup uh find package find package and setup method and I have written all like these many thing over here right so this is the like name of my package uh which I have written over here right each and everything is clear each and everything F now see guys if you want to install this package so for that there's a command the command is PIP install package name right I think you all agree so if you want to install this particular package open a load Lang Chen stream late python python. EnV P PDF so for that there is a command the command is PIP install and package name if you want to install this re. txt so for that there is a command the command name is what the command name is PIP install hyr re. txt right but if you want to install this a local package into your current virtual environment so uh how we can do that so for that also we have a command the command is what the command is directly you can install the setup.py file you can write it down python setup.py install so in that case it will install or it will download all the current package from your folder into the virtual environment got it that's the first way the second way is what so here you can write it down in the requir of txc itself you can write it down hyph e do right so uh if you are writing this hyph e dot so in that case it will search all the local package all the local package into your current directory into your uh current folder and it will download or it will install it inside your virtual environment again I'm repeating see if you want to install this particular package so for that there is a command pip install re. TX Pap install package name if you want to install all the package by using the re. TX XT so there is a command pip install hyphen r. txt got it now but see let's say if you want to install this local package into your virtual environment so how you can do that so for that you have two ways the first one python setup.py install if you running this command so definitely you will be able to install it the second one is what the second one is you can mention this hyphen e dot inside your record. txt so automatically it will search this it will search out the packages into your current folder into your current repository and it will execute the setup.py in backend got it great now what I'm going to do here I'm going to be install this require. txt and so for first of all let me show you that what all packages we have inside the current virtual environment so if I will write it on the PIP list uh so here you will find out that we just have this three packages three to four packages into my current virtual environment how many packages this guys three to four packages only right which comes uh by uh which is a by default only which comes uh along with the environment itself whenever we are going to create an environment now if I want to install all these packages into my current virtual environment so how we can do that so uh if I want to like run this re. txt so how we can do that so for that there is a command let me write down the command pip install hyr requirement. txt so pip install hyphen R re txt so once I will hit enter so here you can see my all the packages is getting installed into my current environment so just wait for some time uh it is getting installed and uh it will take some time uh tell me guys are you doing a with me yes you can use it uh if you want to make a mini project so definitely you can use it and even you can create it uh here itself and you can showcase as a mini project tomorrow we are going to deploy it also after creating a web API and then uh by using the advanced concept we are going to create one more application so how's the session so far uh did you like the session tell me guys uh did you like the session did you like the U like content if you're liking the session then please hit the like button yeah still it is installing so it will take some time I'll let it install yes you can go through with my GitHub link so here is my GitHub link just wait I'm giving you that still it is downloading uh I think we should wait more yeah I think now it is done so uh first of all let me clear the screen and uh here uh you will find out that it has created one folder uh the folder name is what McQ generator. eggy info so so it has created one folder and this folder actually uh it is having the entire information regarding your local package so you can visit and you can check with the different different files over here so this is the package information metadata version this one this is the P package version right this is the package name author is sunny and author email ID reir txt so these are are these all are the requirements actually right along with the packages now you will find out all the like details inside this particular folder the folder name is what McQ generator. ayen info it has created a various file inside that which is keeping all the or which is uh like uh keeping all the like meta information regarding your project got it I hope uh this thing is clear to all of you now uh what I can do uh first of all let me close all the files from here now let me open my app IP VV file and here what I'm going to do here I'm going to here I'm going to like uh run my uh like import statement so what I can do I can run import OS so here I'm going to write import OS import Json import Os Os means what opening system and here I'm writing import Json import Json now here I writing import pandas as PD pandas as PD and here let's say I'm writing import Trace bag so these are a few uh uh like a few packages basically which I imported over here now if I want to run it now if I want to run this particular cell so for that I just need to press shift plus enter right just press shift plus enter and you will be able to run it now as soon as you will run it it will ask you would you like to install the IPI kernel yes I want to install it because without that I won't be able to execute this particular notebook so here you need to click on the install and my IPython kernel ipy kernel is getting installed guys so it will take uh some time so let it install and then I will explain you the further thing further concept I given you the GitHub Link in the chat uh you can search over the GitHub uh sorry you can search over the Google s with the GitHub and then you will get the GitHub link my GitHub link and check with the very first repository very first project that is the McQ generator itself the project name the folder name is same McQ generator here you can see this one McQ generator just search over the Google Sun Savita GitHub so here you can see my ipy kernel is getting installed so let it install and after that I will write it on my further code and uh let I will show you uh further concept as well uh regarding this um and entire project okay yeah so now it is done and here you can see uh we are able to import this a particular statement import Os Os means operating system Json pandas and traceback also now guys here what you need to do the next uh import statement which I'm going to write it down over here which is going to be a opena itself so here I'm going to use the Len chain and by using the Len chain I'm going to import this chat over open API right because I want to access the open API and by using this particular method only I'll be able to access the open a API now let me run it so it's the same method it's the same method which I have shown you in my previous classes so there I was using the lenin. llm opena now in the recent version in the updated version they have given you one more method it's a similar one only it's updated one and which is doing the same thing uh like like the previous one like the open a method and the method name is what the method name is chat open AI so yes uh we are able to import this method and now what I need to do so uh actually we this is a this is not a method this is a class so here what I'm going to do I'm going to create a object of this particular class now so for that let me copy it and let me paste it over here so this is going to my llm so by using this particular uh method itself I will be able to call my open API and I will be able to collect the llm model inside my llm variable right so for that I need to mention couple of uh couple of parameter so here I'm going to mention few parameter let me do it over here so these are the parameter guys which I have mentioned over here so the first parameter is going to be open a API key and here basically I need to mention the key key of the open a open API now after that uh there is a model name so here I'm going to use gpt3 .5 turbo model and then uh I I I have created one more parameter I I'm going to write down one more parameter that is going to be a temperature you know what is the meaning of temperature so here I'm going to set the value 0.5 so between 0 to two you can mention any value of the temperature so what is the meaning of that the meaning is nothing meaning is very very simple you are going to like you want to create a model if you are mentioning uh like if you're mentioning the value near to two right so the range is from 0 to two if you are mentioning the value near to two this will be more creative if the value is will be near to zero so the model will be less creative it will give you the state forward answer that's it now here guys this key will be required this open AI key will be required how we can get the open key I shown you how to generate open key in my previous classes right again I'm not going to show you that now here actually I'm going to collect my openi key but this time I'm not going to paste it directly over here instead of that what I'm going to do I'm going to use my OS module so here what I'm going to write it down I'm going to write it down this a particular uh method I'm going to call this os. get environment method that uh os. get environment key method so here I'm going to call this os. getv and here uh this is what this is my environment variable so what I can do guys I can create uh environment variable I can create one environment variable into my uh Windows environment variable and I can read it I can read my key from there okay I can read my key from there the second way I can export it temporarily right so here I can U on my uh terminal itself I can write it down export and here I can mention this a variable name open API key and I can pass the value in that case also I will be able to read it the third Third Way is there the Third Way is like you can create your EnV file right you can create your local environment file and there inside that particular file whatever a variable is required whatever important variable is there you can keep it over there itself right the first one is a global approach uh Global means what so here if you are going to search environment variable in your windows search box so you will get the uh you will get the uh environment variable all the list of the environment variable here you can see right so you will get the list of the environment variable this one right this one now here you can see I I created one key and I keept it over here so from there also I can read it from there also I can read it by writing a same thing I I just need to mention the key the key name over here the second way the second way is a temporary way temporary way means you can export the key over here Itself by using the export command you just need to write down the export and here you can mention the variable name and you can pass the value of that particular variable that's the second way now the Third Way is what here you can create EnV file so EnV file in your local repository itself so no need to create any sort of a variable in your environment variable here itself inside this EnV file itself you can keep your all the variable all your secret variable and by using the same command you can read it so that is the third way so I'm going to select the third way the third option so here I'm going to create the EnV file okay so EnV file uh so this is what this my EnV file and inside this EnV file I'm going to keep my key so I'm going to write down the key value and the variable name is going to be a same so let me copy the variable from here the variable is going to be open AI API key and let me keep the variable over here and here I I'm going to write down the value of this particular key so in the double code actually I'm going to write down the value so let me paste my key over here I already generated it uh I believe you know how to generate the key so let me copy and paste it over here so this is what guys this is my key which I already generated now let me open my file and here what I'm going to do I'm going to read my value the value of this key so you can treat this EnV file as your local environment right so which you have created inside the folder itself and there you can keep your all the secret variable right so now if I'm going to run this OS os. G EnV now if I will run this particular command now if I'm going to print the key so here you will find out my key value so here guys uh here is what here is my key open a key now let me show you and here it is giving me none uh let me run it again why it is not going to why it is not getting it now let me show you it is none wait guys let me restart the terminal it happens in this vs code actually sometimes I have seen but okay so fine I forgot to do one thing uh why I'm getting this none why I'm getting this none because I need to load this environment first all right so I need to load this environment first and for that uh I will have to import something see I already written one module python. EnV right so here I have written the module python hyen do T EnV let me show you this module so here uh let me open the Pi Pi first of all and here I can show you the module uh just a second Pi Pi now let me show you this particular module python hy. EnV uh see python. uh EnV reads key value pair from a EnV file and can set them as a environment variable right so it helps in a development M or application uh following the 12 Factor principle so here you can read everything about it if your application takes configuration from the environment variable it's a 12 Factor application launching it in a development it's not very practical because you have to set those environment variable yourself means you will have to set the environment variable in your local system um okay if you don't want to do it you can create the EnV folder in your local so that will be your local environment file local environment file itself which will be available inside your local uh like reposit itself in your local folder itself got it now here the first thing uh see first you need to import this thing this from. EnV import load. EnV and then you can you have to call this uh particular method so what I'm going to do here so I'm doing a same thing uh where is my vs code here is my vs code I'm going to do a same thing just a second I'm going to load it uh I'm going to load this uh EnV so here from EnV this is my EnV file from EnV I'm going to import a load. EnV and here is what here is my method so as soon as I will run it so here I will be able to load my all the values from this EnV file now let me run it h let's see whe whether I'm getting the value or not so it is saying this OS is not defined so first of all let me import the OS this is also fine this is also fine and now each and everything is fine now what I can do now I can call it and let's see whether I'm getting my key or not now see guys I'm able to get my key from from my EnV file so here is my EnV file and from here what I'm getting I'm getting my key right now let me keep this EnV in my do getting so I can push my changes in my ga in that case you won't get this uh key actually you you will just get like uh the other file so here I'm writing do EnV and once I return it now it you can see it is not going to track it uh at all so now uh you want you will find out that there is no such color anything and now what I can do I can give you all the files and all other files basically so let me click on the plus yeah now let me commit it so here I'm going to write it down of file updated file update and let me commit it and sync changes now click on okay and here guys you will find out my entire code Let me refresh it now and yes that is the entire code so I think uh you got the code over here set the print yeah so here is a key let me remove it from here just a second yeah now it gone so tell me guys uh are you able to follow till here here uh did you get the entire code the code which I shared with all of you please uh do let me know in the chat if you got the code then here I kept the entire code uh in my GitHub itself yes uh yes or no please uh write it down the chat guys please uh do let me know just search over the Google s Savita GitHub and there you will find out this McQ generator repository in my repository section and here is the entire code if you are done till here then please uh give me a confirmation so I will proceed with a further uh further concept done done done great fine so now let's start with the implementation so till here actually I just shown you the uh I just shown you the environment setup and all now we are ready for implementing the project okay so within uh this uh within this one hour actually I just shown you the entire setup now this is the onetime job I set up my entire environment now let's start with the Practical uh now let's start with the experiments and all and in tomorrow's session I will create uh the I will create the Modular One modular project and there I will create the steam allet application also and finally we'll try to deploy it now here uh you can see uh now each and everything is done let's try to call this a chat open a method and let's see we are able to access the llm on l so here you can see it is running and now it is done so if you will look into this llm llm now here you can see we are able to do it we are able to call it now here let's try to run the further code now we are going to use all the concept the entire concept whatever we have learned throughout the community session right throughout the throughout this community session in our open in the lch so we we are going to use those entire concept over here now uh for that basically what I'm going to do step by step I'm going to write it down each and everything so first of all I am going to import each and everything in a single shot right so here uh you can see I have imported all the statement so this Trace back and all I'm going to remove it from here which I already did it this is also I already imported now let me remove this also and here uh just chat open a also I already imported now uh here this open a prompt template l CH sequential and this get open a call back this is very important uh this is very important class which I imported over here uh I will show you the name I will show you the use of this particular class this C openi call back in a very detailed way because it's going to be very very important right so far I haven't discussed about it I discussed about the sequential chain I discussed about the llm chain I discuss about the promt template but I I haven't discussed about this get openi call back so now let me import import all the statements over here so you can see we are able to import it and yeah it is done now we already created a object of this chat open Ai and we are able to get my llm by using this open AI API till here I think everything is fine everything is clear now let's move to the next one now just tell me guys if we are talking about so here what I can do let me open my pen and let me ask a few questions to all of you so here uh what I'm doing uh just a second yeah so here uh just uh let me ask a few question so let's say we have imported the llm means uh we are able to access my llm this uh GPD model by using this uh open AI or API by using this L chain framework now to this llm what I will do what I will pass to this llm tell me so to llm to this particular llm I will pass my uh prompt right I will I will pass my input prom so here actually what I will have to do I will have to design my input promt right what I will have to do guys tell me I will have to design my input prompt and here as a output what I will get tell me as a output also I will get a prompt right so here what I will have to do I will have to design my input and output prom right so so whatever my whatever will my input so that particular prompt and here whatever will be my output that a particular prompt got it now let's try to design my input prompt and let's try to design the response as well then in which format I will get the response so here initially I clarified this thing the project is going to be a McQ generator right I am going to generate McQ McQ right whatever topic whatever uh subject I will give to my uh GPT model so So based on that particular subject based on that particular uh like based on that particular text is going to generate a McQ so let's say I'm giving my paragraph I'm I'm giving one paragraph to my GPT model So based on that particular paragraph let's say I given a paragraph related to our data science uh okay I I I given one a PDF file or text file or whatever file to my GPT model so in that inside that like you have a paragraphs you have a data So based on that data is going to generate a mcqs right so let me do one thing so here uh first of all let me design my prompt so here what I'm going to do guys I'm going to design my prompt by using this a prompt template I think you already know about the prompt template in my previous class I already clarify the uh the concept of the prompt template if you don't know then please go and check with the previous session so here what I'm going to do guys here I'm going to Define my prompt template so just wait uh let me copy and paste the code because already I written this uh like a single single line so let me copy and paste and I'm going to explain you so here my prompt is what so here my prompt inside the prompt actually you will find out in the prompt template you will find out two things first is a input variable and the second is template right so here you can see as a template I given this particular variable now to this particular variable I have to pass some sort of a text right some sort of a like a template and all I will pass it just wait right so here is my template variable and I will pass my template over here here I'm not going to write it down directly here I'm going to pass it to my variable and that variable I I'm passing inside my prompt template right now in an input variable you can see we have a couple of we have a couple of variable we have couple of parameter the first one is text the second one is a number the third one is a subject the fourth one is a tone and the fifth one is a response J so we have a five variable inside my input variable in my previous classes uh I shown you this prompt template along with the uh simple input variable along with the one input variable right now here inside this one I have written five input variable and here I'm going to Define my template now let's see what will be my template so from here basically I'm going to copy the template and let me paste it over here so I'm saying to my chat GPT so I'm saying to my chat GPT that uh you are expert McQ maker right so I'm giving my a text so on whatever text I want to generate an McQ I'm passing a text over here right and I'm saying to my chat GPT that you are an expert McQ maker given the abob text so whatever text we have given to you it's your job by using this particular text it's your job to create a quiz of number so how many quiz you want to create so five quiz six quiz seven quiz eight quiz you can pass a number over here so 5 six seven quiz eight quiz so you can pass the number and here uh you need to create a five multiple let's say I'm writing number is equal to five so five multiple choice question for the subject now whatever subject we are going to pass over here in tone so tone means what tone actually it is defining a difficulty level so here if tone is simple so it is going to generate a five simple McQ question if tone is uh intermediate so it is going to generate five intermediate question if tone is difficult it's going to generate five difficult in five difficult McQ question got it now here I'm saying make sure the question are not repeated and check all the question to be confirming the text as well so each and everything I'm telling to my GPD right so make sure to format your response like so here actually I have to for I have to pass the format also here I'm going to pass here I have to pass the format also like in which format you have to generate a quiz now let me give you the format now let me show you the format so uh which format actually I have designed over here so here what I'm going to do I'm giving you the format the format basically which uh I have designed so let me show you the response format now guys this is the response format just just see over here see so response or it's my response format so here I'm saying uh like there is my McQ multiple here I have written first okay this my first mean like it's a number itself that's it now here I'm seeing McQ multiple choice question now here is a option that uh you have a four Option 1 2 3 4 and here basically I will be getting my correct answer so it is this one this one actually this is my first McQ along with the number along with a question along with the number this is my first McQ first McQ now here will be my McQ now here will be my all the options and here will be my correct answer right so this is my response format and here is my template basically which I'm passing to my GPT model and here uh I'm going to create my prompt template that's it by using this particular template and these are the these are the variable which user is going to pass right which user is going to pass these are the variable now let me do one thing let me run it and here you can see we are able to create a like temp we have like written a template and this is what this is my prompt template which I created that's it I think this is fine now here uh yes once it is done uh like uh my template and all basically it will be created that is fine now after that what I'm going to do I'm going to create the chain right I think you already know about the chain llm chain I I explain you the concept of the llm chain that why we use llm chain we use llm chain for connecting a several component so here as of now I just have two component first is llm and the second is prompt so I'm going to connect both component all together and for that I'm going to use llm chain so let's try to use the llm chain and and here I have already written the code let me copy and paste it over here and so this is what guys this is my uh like this is my uh like llm chain so here I'm passing my llm model with whatever model I took by using the open API and here is what here is my prompt so prompt is what so quiz generation prompt so the prompt which I have created by using this particular template and by using this particular response right in this format basically I want a response now this is what guys this is the llm chain all the concept see whatever I have we have learned so far I'm going to use all those concept for creating this a particular project right so so at least you can understand that where we are using uh like those Concept in a real time right so here is what here is my question now let me run it and here I have created my question that is fine now guys just tell me uh here uh I'm creating my quiz right so here I'm creating my quiz now here actually see I created a quiz but this quiz is correct or not the basically in the at the end you can see in the format I have written this correct answer I want a correct answer from it so after analyzing a quiz actually I want a correct answer so for that also I have defined one more template now let me show you that template so what I did actually let me show you the template two which I have created uh so here I have created the second template now in the second template you will find out uh just a second let me copy all the like thing over here and see this is what guys this is my second template now here I'm seeing here I'm saying actually uh you are an expert English grammarian and writer I'm telling to my chat jpd I'm telling mypd actually so given a multiple choice quiz for this particular subject right this particular subject now you need to evaluate the complexity of the question and give a complexity analysis of the quiz right give that complexity analysis of the quiz only use at Max 50 words for complexity if the quiz is not at for the quantitive and the analytic ability of the student update the quiz update the quiz question which needs to be changed and change the tone such as uh such that it perfectly fits to the student ability so here I have written so here actually see here I'm passing my quiz whatever quiz basically I'm generating so in this second template I have written that uh I have written the like prompt regarding to the evaluation regarding to the quiz evaluation whatever quiz I am going to generate right first I will generate and then I will evaluate it here in the second prompt now let me run it and here I'm going to create my one more chain so here I'm going to create uh so here basically uh before create cre a chain basically uh let me create just a second so here uh what I'm going to do I'm going to create my template so here in the template you will find out only two variable first is subject and the second is quiz this two variable it is coming from the user side I will show you how like it is coming from the user side and how user will be passing once we'll be creating a end to end application got it now here we have a quiz evaluation prompt and this is what this is my second prompt and now what I will do regarding this prompt also I will create my chain right so here uh here is my quiz chain now I'm going to create one more chain that's going to be a quiz evaluation chain so let me uh like uh copy this particular code step by step I have written each and everything and that is what I'm going to show you so here is what guys here is my review chain right so in this one I'm passing my llm I'm passing my quiz Evolution prompt and here output key is What so whatever output I'm getting as a review so here I'm going to collect it inside this particular variable and verbos is equal to True means what means whatever ex means during the execution whatever is happening now each and everything I will be able to find out on my screen itself that's the meaning of verbos is equal to two that's it now here if I'm running this review a chain so I have created two chain now now after creating this th I have created First Chain quiz chain I created second chain review chain now I'm going to connect both chain right by using sequential chain so the same concept I taught you in my previous session so first I created one chain where I'm going to add two component llm and my uh prompt I have created second chain and now I'm going to collect both chain right both Chain by using the sequential uh by using the simple sequential chain now here what I'm going to do so here already I have imported this thing if you look into my import statement so I have already imported this sequential chain now let me create a object object of this sequential chain and then uh I'm going to write it down the both name over here so here what I'm going to do so let me uh create object of this sequential chain now so here guys you can see we have a sequential chain and to this sequential chain I'm passing the quiz chain I'm generating a quiz and I'm passing to my review chain right so from here I'm generating a quiz and I'm passing to my review chain and these all are my input variable and these all are my output variable and verbos is equal to True right clear so here I'm going to create a object of this same sequential chain I hope till here everything is fine everything is clear to all of you please do let me know I use the uh previous Concepts only I haven't I haven't taught you anything new uh I use the previous concept whatever I taught you in my previous classes so please do let me know if this uh part is clear to all of you yes or no it's very easy very simple don't worry at the end I will revise all the concepts uh whatever I'm using here whatever I'm writing over here but first tell me is it clear or not this one if you can write it down the chat I think that would be great you can hit the like button you can let me know in the chat so please do it guys uh I'm waiting for a reply because after uh this one the climax will come and in that like we are going to create a quizz and all whatever is there clear clear clear yes or no yes saan your understanding is correct first combining two template using llm chain and then two H chains we are going to combine by using the sequential chain okay okay now uh I think till here everything is fine everything is clear now let's see how we are going to gener a quiz from here after giving this many of things after doing this many of things so we are able to uh we are able to like uh here you can see we are able to create a sequential chain now the next thing is what here actually what I want guys tell me I want a text I want a data so if you have a data in PDF you can load the PDF if you have a data in txt file you can load the txt file right if you have data in some other file you can load the data from there from anywhere right so first you will have to provide a text you will have to provide a data on top of that data you are going to create or you are going to generate a quiz right so let me do one thing here I'm going to create uh I'm going to create one file the file name is going to be uh wait I'm going to create one file the file name is going to be data.txt so data.txt now what I'm going to do here uh I'm going to open my Google and from there uh I'm going to copy and paste some sort of a text so let's say I'm searching about the machine learning machine learning machine learning so here I'm going to search about the machine learning now here uh is what here is my machine learning now from here what I'm going to do so here I'm going to take all the data for this one right so I took this particular data I'm copy I'm going to copy it and let me paste it over here where I'm going to paste I'm going to paste in my data.txt so this is the complete data which I have pasted over here you can check it you can reveal this file in your folder so click on reveal in file explorer you will find out this particular file uh this data.txt right just open it and here is your data which I copy and paste it from the uh like Google itself from the Wikipedia right great now let me close it and here here is what here is your data now do one thing let's uh do one thing so let's try to read this particular data so here what I'm going to do so here uh let me open my file ipynb file and here I'm going to read this particular data so for reading a data actually we have a we have a like a code so let me write it down the code over here so I'm writing over here you need to open this file in a read mode and just read the data in this particular variable now here I need to provide the file path so for providing a file path let me write it down here file underscore path and here uh R means what R means read it and there I'm giving my absolute path so here I'm passing the complete path of the file so this is the file path guys which I have given or which I have written over here now let me run it and let me check with the file path that I got it or not so here what I can do I can uh check with the file underscore path now let me run it and see guys this is what this is my file path now I'm uh running this particular code and here you will find out inside the text what I got I got my data so here is what here inside my text you will find out you uh we have the entire data now let me print it let me keep this text variable inside the print method so see guys I got the entire data so whatever data I kept it inside my file inside my txt file so you can see all the data over here itself got it now after that what I will do see now there is a crucial part and there you will find out the new thing right and one more thing let me do one more thing over here so see I created a response I created a response here is what guys tell me here is my response now this response actually it's a dictionary this is what this is a dictionary right this one now over here if I want to convert into a Json serializer so for that there is a method json. terms and here actually I'm passing this dictionary now why I'm doing it so here if I want to serialize the python dictionary into a Json format so here U into a Json format is string so that's for that's why for that only I'm going to call this particular method json. dumps right so here uh I'm going to call this json. Dums and here you will be able to find out I'm going to convert this a particular dictionary this python dictionary into Json format his string right this is fine this is clear to all of you we got a text we got this dictionary and we got a chain now my final step will come into the picture now let me show you my final step so over here uh my final step is this one now just just be careful guys and after that my response will be coming and I will be able to generate my output so here guys see uh in the final response you will find out that we are going to call this get open Ai call back right right this is a new thing for all of you and here I have already imported this get open Ai call back if you will look into the import statement here a from blanchin do callback get open call back so here you will find out I'm U like calling a same thing I'm calling this get open Ai call back right now inside this get open a call back you will find out that we are going to call our generative evaluated generate generate evaluate change so this is the same thing basically uh the same variable over here you can see this one uh like after creating after creating this is the object actually generate uh generate evaluate chain this is what tell me this is the object object basically which I'm keeping over here sequential chain is a class right where I'm passing this particular argument and this is what this is my object this one generate evaluate chain now I'm calling this particular object over here this one right this this particular object I'm calling over here this is fine this is fine this you are able to understand and here we are getting a response after calling but what is the meaning of this C open Ai call back why we are using it so just see over here I have written something over here how to set up token uses tracking in L chain so if you want to understand the token uses if you want to track your tokens and all input token output token your pricing each and everything each and everything you will get by using this get openi call bag you can check it by using this link which I kept it over here here is a documentation link so let me copy and paste it over here over the browser and here actually you will find out a complete detail about this G openi call back so let me show you so here is tracking token uses so whatever number of uh token you are going to use what will be the pricing input token number output token number everything you will get it over here by using this get openi call back right so just see over here we are going to import it we are going to create our llm we are going to got get we are going to get our llm over here and here we are going to call this invoke method and there is my result now if I'm going to print the CV so here you will get the entire detail regarding the token let me show you in terms of my code right so whatever code and all whatever like project I'm going to create regarding that now before that just see over here uh generate evaluate chain this is what this is my object now here if you will look into this particular object so we are we have a couple of input variable the first input variable is text that is the same thing the text itself right text you know right which one uh what is the text like whatever uh which one this text actually so whatever uh like uh data right we are passing for generating a McQ right on whatever data we want to generate McQ this this this takes actually now here is a number how many McQ you want to generate subject tone simple Simplicity hard intermediate and here is what here is a uh like request response so I will have to mention everything over here inside this variable so json. dumps already we did it text we already did it now let me Define this number subject and tone so here let me take it as a a variable so here guys you will see that we have a number we have a subject and we have a tone so number how many uh quiz you want to generate I want to generate five quiz here subject let's say subject is machine learning let me change the subject I'm going to keep as a machine learning so here the subject name is machine learning now uh here Stone actually tone let's say it's a simple one simple McQ I want just like a simple McQ now if I will uh like run it so here I have initialized my variable now guys if I will run this one now you will find out that everything I'm going to get in my response itself so let me run it and see so it is running and guys over here you can see this is still it is running and it will take some time because it is evaluating each and everything in back end whatever template whatever prompts I have given and based on that it will generate a response it will generate a McQ so just wait for some time and it is working working working yeah now it is done guys see we we got a response and inside this response I have everything but before showing you the response let me show you something over here so here what I'm going to do here I'm going to show you the number of tokens number of tokens uh input tokens output tokens and the complete cost right so here what I'm going to do let me copy the code uh which I already written and it's a simple like lines and all I'm just copying pasting because I don't want to waste the time okay because if I'm writing it from scratch it it takes takes a time right so here uh I'm saying total number of tokens input token plus output token now here prompt token and prompt completion mean this is the input token and this is the output token and this is complete number of token and here there is a total cost now if I will run it guys so here you will find out that I this is my total number of token this is my input token this is my output token and this is the cost and it is in dollar so I'm able to track each and everything by using this uh open a call back getting my point now let's try to get a response so let's try to uh get a response from here uh so let's try to uh get a quizzes and all so first of all let me show you the response so if I'm going to print the response now so you will find out uh it's nothing it's the uh dictionary itself right so inside the dictionary uh you have uh different different key and value now in this dictionary you will find out one key quiz right so if I'm going to write it down here so here if I'm going to write it down response. response. getet quiz so if I'm going to write down here response. getet quiz now see guys here I'm able to get my quiz here I'm able to get my quiz right so what I'm going to do now I'm going to keep it inside my variable my variable is what quiz this is what this is my quiz right now what I'm going to do here I'm going to write it down Json json. load right Json do loads and here I'm passing my quiz q i now once I will write down like this so you will find out my all the quiz so here this is my first quiz and it is in the same format it is in the same format the response format which I have defined so this is my first quiz and here is McQ who coined the term machine learning so Donald have Arthur Samuel Samuel Walter pittz and Warren mlo right so here there is a correct answer now here the second quiz what was the earliest machine learning model introduced by the Arthur Samuel so speech recognization image classification so you can see guys your entire quiz over here whatever number I have given I have given five number I'm able to generate a five quiz from the uh from the GPT model by giving a correct prompt and by giving a correct uh like response format so there is uh you just uh required a python over here that's it nothing apart from that and you will be able to create the project a project according to your requirement and this type of project you can integrate everywhere let's say uh uh like in a dashboard itself in your dashboard you will find out the quizzes and the assignment so you can automate that project uh that process you can generate a quizzes and all from here uh right and then you can append it inside uh the dashboard and all so uh like something like that you can make a realtime connectivity I think you are getting my point now let's uh look into the uh let let's try to create a data frame by using this uh dictionary so for that what I'm going to do so here uh I'm going to create a data frame uh just a second uh first of all let me keep everything inside the list so for that I already written one code so here is the code guys uh here I'm going to create uh let me do one thing Let Me Keep It Quiz only so here is what here is my list and inside this list we have our items means uh my quiz and my uh basically value okay means my options now here actually I'm going to keep it in a particular format whatever string I'm going to to be collect from here I'm going to join in by using this pipe and here I'm going to append it everything now let me run it and you will get a better understanding so if I'm going to run it now see uh so it is giving me St Str object has no uh attribute items what is the issue over here okay so just wait uh let me keep it over here inside the quiz itself and now I think it is fine so just a second mm mhm yeah now is fine so if I'm going to show you this quiz table data now now you will get all the thing over here so yeah now I got each and everything in a list and see every value every option we are going to segregate by using this pipe and for that only I have written this code once you will go through it you will be getting it now I can convert it into a data frame so here uh let me convert this uh thing this particular thing in into a data frame so here if I'm going to write it down PD do data Frame data frame and here I'm going to say that okay I'm going to uh open the parenthesis and then yeah so here guys see this is my McQ means there is my question here is my choices there is four choices and here is a correct answer now let me keep this thing in my uh variable that is going to be a quiz and and now let me convert this uh data frame as a CSV file so here I'm going to convert this data this uh quiz actually into a CSV file so quiz do 2or CSV and here I can write it down the name and the name is going to be a machine learning quiz so machine uh machine learning. CSV right machine learning. CSV index is equal to false index is equal to false now if I will run it guys see in my current uh directory in my uh like current local directory you will find out this CSV file now let me open the CSV file and here you can see my quiz I just given the number of quiz how many number of quiz I want uh see uh if you will look into the code now now you will be getting that uh this this number actually this this thing basically which I will I was providing to my um like object this one number of quiz sub object and toone so this is the only thing which I want from my user and for this one only I'm going to create my web application as of now I shown you the simple implementation in the python notebook in ipb itself now in tomorrow's class what I'm going to do so here I have created the folder the folder name is what SRC folder and inside that I have a McQ generator now each and every line of code I'm going to write it down my py file I'm going to create a modular coding I I'm going to write down the modular coding here and then finally we are going to create a web API right web API and uh here U like yes by using the B API you just need to pass this particular value number of quiz you just need to pass this 3 to four value you need to pass the text this particular text you need to pass the number of quizzes subject and the tone that's it and you uh and after that once you will hit the button so the qu will be in your hand this one got it yes or no tell me guys so how is a project uh did you like this tell me do you like this Jupiter implementation yes or no tell me guys fast do you have any any like uh any um that doubts and all so please do let me know I will be clarify that and uh don't worry you won't face any sort of issue so whatever step I followed just followed those step and try to do this uh um this notebook implementation at least and tomorrow we'll convert this notebook implementation into an end to end project so let me give you this code now so here I can uh add it this file this file and this file also so I added this three file now let me write down the message all files updated updated okay so just a second all file updated and here let me commit it and sync the changes so now guys just check with the GitHub you will get the uh files and all right let me show you the GitHub now and here is my GitHub so guys uh just check with the G here you will find out the CSV file quizzes and all uh and here see quizzes Which I generated by using the GPT and here actually there is a ipv file where you'll find out the entire code okay yes it is generating a quiz from the text itself so let's say if you are giving this part let's say any different text so let me do one thing let me give the different text over here uh so just a second I'm going to generate a different text now uh so any topic uh uh any topic basically anything you can uh like search over here let's say you are going to search about the biology so biology uh Wikipedia so just search about the biology and here open the like Wikipedia page copy it from here copy it as of now and just keep it over here inside the text inside your txt file now see we'll automate this particular process so you don't need to paste it like this you just need to uh give your documentation to your streamlet application or to your flask application or Jango application we'll automate that particular process don't worry and even we can automate like many uh instead of providing this particular text and all right no need to provide this text by writing directly by writing the name also we can generate a quiz okay that is all also possible that is also possible as of now I'm giving my text and based on that see this is the biology text right now what I can do I can just need to open my uh IP VB here and after that I just need to load this text so here I'm going to load my text this one and I'm going to change my subject so instead of this machine learning I'm writing here biology right I have written biology over here let me run it so here I got uh the biology text this is the biology text and uh yes uh I think now everything is same this is fine this is fine now let me run it so here if I'm going to run it so now it is generating mcqs from those particular text whatever text I have given regarding the biology and all so it is taking that text and it is generating a uh mcqs and all so it will take some time let it run and then you can save uh this file over here so now it is done uh it is getting we are getting some issues incorrect API key provided okay it is saying incorrect API key provided I think some issues there with the API key but yeah the process will be same right I will check with the API key issues what is this uh now see guys uh I think you got my point you got the like concept and you got about the project also and today we are going to create in2 and one and we'll try to deploy it also so don't miss tomorrow's session tomorrow's class uh great so I think we can start with today's session uh now in today's session uh again uh we'll uh try to complete our project itself so in previous class uh we have started our uh end to end project uh in that I have explain you the uh Jupiter implementation so we did the entire project setup and after that uh we did the we implemented our jupyter notebook now in today's session we are going to create we are going to write it on the modular coding modular code and there we are going to create a several file and uh I will show you how you can create a different different file in a different different folder and then how you can create your streamlit application and if uh time will permit so definitely we'll try to deploy it also and for the deployment we're going to use AWS okay so uh don't worry I will write it down like uh each and every line in front of you only and uh and I will clarify the agenda but before that uh let me show you the resources and all so where you will find where you can find it out all the resources so for that uh let me go through with the Inon website and here you can search generative AI so just search about this generative Ai and there you will get the dashboard so here we have two dashboard one for the Hindi and the second for the English so just click on this English uh this uh this particular dashboard and here click on this go to the course so uh let's say if you are enrolling for first time if you are opening first time then it will ask you for the enroll uh for the enrollment and uh you no need to pay anything it's completely free so you can enroll to this particular dashboard and you can open it so let me open the dashboard so here is my dashboard guys uh you can see all the recording we have updated all the recording whatever thing I have covered so let me uh show you the resources as well I think day six recording is not available over here so don't worry it will be up uploaded along with the recording you will uh find out the assignment and the quizzes also and where you will find out the resources so let's check with the day five so uh here in this uh video right so once uh you will click on the video uh so here you will get a different different option related to the video so just click on this resource section and here you will find out all the resources so whatever thing I'm discussing in the class itself uh whatever uh like code and all whatever I'm writing here so uh I'm going to uh I'm going to upload each and everything here inside this resource section so from here itself from the resource section you can download it got it yes or no great so from here you will get the resources and all and yes U videos is available over here recorded videos is available over here and apart from that you will find out over the ion YouTube channel so just go through with the Inon YouTube channel U and there uh go inside the live section there you will find out all the recorded video so let me show you that so visit the Inon uh YouTube channel and here click on the live section this one so you will find out all the videos all the like lecture or the live lecture which I uh took so far and here is a day six lecture where I have started with a project so in this lecture till day five actually I have complet completed the Lin first I started from the introduction then I went to the open a and then I uh started with the different different concept of the Lang and then I move to this uh particular project the project uh which I have started that was the McQ generator by using open a and the Len chain so here uh you can see I have uh I shown you that how to do a complete project setup and even I shown you how you can push it over the GitHub and all how you can insize the gate each and everything I shown you over here and then uh I shown you the uh Jupiter notebook implementation so just go through with this particular video there you will find out uh like each and everything uh now uh what we can do we can start with the remaining part of the project so here in this uh particular project so we have created a several folder now in front of you only I'm going to create few more file and there I will be writing my code and finally we'll try to create a web application and if time will permit so definitely we are going to deploy it also so the agenda is clear to all of you yes or no please uh do let me know in the chat please do confirm in the chat yes how long this course is going to be so the course uh I I have planned two more end to project so I have to take few Advanced concept like uh Vector database R and few open source model and after that I have planned two more end to end project so you can assume that uh like more 8 to 10 days got it so um I I will take two more end to end project and this is just a basic project actually after completing all the concepts and all I taught you this one but yeah after that I will complete one project along with the flask API and I thought one more project along with the vector database R concept and the fast API okay great so let's uh begin with the project and here uh what I can do so just a second just allow me a minute okay so I already given you this particular project and if you want this project uh this project actually so from where you can get it uh let me show you so this uh project already I have uploaded on my GitHub so just uh try to go through with my GitHub and there you will find out this particular project and for that what you need to do just open your Google and search Sunny Savita GitHub okay so open your Google and search Sunny Savita GitHub and after that you will find out my GitHub so just click on that uh click on my GitHub and here go inside the repository here inside the reposit and click on this very first link this McQ generator so just open this one and here you will find out this particular project so whatever I'm uh doing whatever I'm uh whatever code and all I'm writing I'm pushing in my this repository so I'm giving you this repository in the chat section if you are able to click click on it so that is fine otherwise you can search over the Google and directly you will find out this repository in my uh repository section got it so from from here itself you can download the project so you can download it or you can clone it anything is fine now uh let's start with the remaining part of the project now here guys see I created a couple of uh folder I have created couple of like files but let's try to uh uh do something more over here so as I told you this uh project is going to be end to end so here actually see I created the ipv file so each and every experiment I performed over here so I I return like some sort of a line of code here and then uh I called my openi API and then I generated the mcqs and all here I have stored inside my CSV each and everything I did in my previous class now if I want to convert this project if I want to uh like uh convert this project into an end to end project so for that uh I will have to create few more file over here so here guys if you will look into this SRC folder so here I have created one folder that is what that is an McQ generator now inside this McQ generator I'm going to create few more file so you can do along with me if you have completed till here so uh here actually you can see uh like uh whatever thing I have done in my previous session so you can find out each and everything over here if you have completed till here then you can proceed along with me now what I can do so here uh let me create a few file inside this McQ folder inside this McQ generator the first file which I'm going to create over here that's going to be a logger file so here let me create the logger file logger py because each and everything uh let's say whatever code I'm running and uh whatever thing I'm going to execute inside my project so I'm going to log each and everything so for that this logger file is very much important so here I'm going to Define my logging object and directly I will import this logging object in any other file and then directly I'm going to uh like save the logs and all so I will show you how to do that first of all let's try to create the folders so here uh let's try to create the files and all so here I have created my logger file logger dopy inside this McQ generator folder now after that you need to create one more file over here the file is going to be a utils file so here uh let me write it down the utils.py now what is this util file why we should use this utils file actually this utils file is a helper file so whatever helper function is there whatever helper function and method is there so each and everything I'm going to write it down over here itself got it so what what is the use of this utils file so it's a utility file it's a helper file so what is a what whatever helping function and all whatever I have inside my code so each and everything I'm going to write it down over here itself now uh one more file I'm going to create inside this folder inside this McQ generator and the file is going to be McQ generator itself so inside this particular file I'm going to write it down my entire code got it now here I'm going to create one file the file name is going to be a McQ generator so here is the file name McQ generator. py so I have created three file inside my McQ folder inside my McQ generator folder so the first file logger file the second file is a utils file and the third file McQ generator. py5 fine so I hope till here everything is fine everything is clear now let me create few more file now in the root directory itself I'm going to create one more file that's going to be a response response. Json I will tell you what is the use of this response. Json because yesterday uh in the previous class uh if you will uh let me show you this ipb itself so here I have written one response here you can see we have uh I have written this response G and inside this response G I have Define uh the response basically in which format uh like uh the response should be generated so here I have defined the response Json now uh the same thing I'm going to Define inside the Json file and I will tell you what is the importance of that so if I want to create a Json file so for that uh what I need to do I no need to do anything so here uh click on this new file and after that uh write it down here response uh response do Json response. Json now here you can see this is what this is my Json file so uh till now I have created four file the first file was the logger McQ generator utils.py and apart from that one more file that's going to be a response. Json and this file will be in a uh will be in a root directory this one response. Json I think till now everything is fine okay where I have created it uh let me check once I think I have created inside this experiment no need to worry just uh drag and drop here yeah so now I got it in my root directory yeah so here is what here is my response dojon now let me create one more file over here and the file is going to be a streamlit app so actually I'm going to create my web app by using the stream l so here I'm going to uh create one more file and the file is going to be a stream L and that two you need to create in a root directed itself in a root folder itself so here I'm going to write down stream s e a m stream lit uh app.py so this is what this is my file now let me keep this L as a small one yeah now it is fine so streamlit do streamlit app.py so these many file I have created and now I think it is like enough now what I can do I can give you like this complete folder structure so for that U like I can commit from here itself uh so let me add all the files from here I'm going to add all the changes whatever I have done done inside my code and I told you how to do that uh in the previous class I explain you each and everything regarding the git and all so if you will go through with my previous uh session so you will get to know the uh like you will get uh you will get the idea that how to like uh how to uh create a repository and all how to publish from here itself how to publish a public repository each and everything I have discussed in my previous session now uh here you can see I have added all the changes now I just need to commit it in my staging area and then I will push it in my GitHub so here I can write down that uh I updated updated the folder updated the folder structure so now what I can do I can commit it and here I can sync the changes and then okay yeah so now let me show you did I get all the files and all here so here guys you can see I got all the files like streamlit app streamlit app.py and here in the SRC you will find out this uh in the McQ generator you'll find out this McQ generator. py logger py utils.py so each and everything uh you can uh you can see over here inside my repository itself so I hope guys you got this entire code yes or no this entire file now again let me give you inside the chat uh or else what you can do you can search over the Google as well so directly you will get it tell me guys uh till here everything is fine uh can we start with the code and all please uh do let me know in the chat I given you this uh link inside the chat I hope uh you are able to click it otherwise directly check with the Google you will get this project Raab please check with my GitHub repository check with a just search about my username this s Savita Sun Savita GitHub and then you will get my GitHub and then from U from there itself you can download this particular code front end and all we are going to handle by using this stream lead so stream will handle everything we don't no need to like create a front end separately uh in the next project I will show you that once I will use the flask maybe with the fast API I will show you the uh front end part as well but here uh if I'm using this stream L then front end is not required yeah you can use any ID even you can use the U Inon lab also so from next project onwards we are going to use the in neural lab yesterday actually I did the entire setup in my uh local vs code only so that's why I'm continuing from here itself but uh from next project onwards I'm going to use the neurol lab so U I think uh no need to set up in your local uh directly you can launch the lab and whatever experiments and all or whatever project uh like you have uh you can create over there itself okay if you're getting any error relative to the API key then try to generate a new API key and don't use my API key okay because after the class anyhow I will delete it so yeah don't use my API key uh use your API key try to generate your own API key from the open a i shown you how to do that so go through the uh openi website and from there itself you can generate an openi key so if you're liking the session guys then please uh hit the like button and and yes I think now we can start with the coding so if you will look into the project so here I have created a various folder so I have started from this uh logger if you will look into this McQ generator so I've created a couple of file the first file was the logger the second file was the utils file and the third file was the McQ generator now here uh no need to write it down the separate code for the separate code for the front end and all this stream lit will take care of it this stream late will take care of it we can create a basic BB application just to test our API and all so no need to write it down the code for the front end and all now guys uh what we can do here so let's try to uh write it down the code for the logging so here I'm going to write down the code for the loging now why the uh logging is required so see whenever we are going to execute a code so in the code actually we have a various step we have a various files we have a various method function classes and all right and each and every function has been defined for the particular purpose so let's say uh if I'm going to write it down any sort of a function inside the utils file or maybe McQ generator so the function which I'm going to create or which I'm going to Define I'm going to create it for the uh for the like Define purpose for a particular purpose right so uh if I if you want to log that uh information like so let's say this a function is going to execute and after the execution like what you are getting or maybe after the let's say you have completed the execution now you want to save that particular information software okay I have completed this particular step I have executed this particular function or method so that information you can log somewhere and there this logging comes into a picture so always make sure whenever you are going to create any sort of a project uh whether you are doing a development code development machine learning related development or whe whether you are going to write it down a code in a gener project or anywhere this loger exception you and all this uh this particular files and folder will remain same it's a part of the infrastructure got it now here uh let me write it down the code inside this logger do py file so here uh let me import the logging first of all so here I'm going to write it down import import login now uh here I have imported the login then after uh I'm going to import the OS and the third module which I'm going to be import over here that's going to be a date time so from date time and here I'm going to write it down import date time so these three import statement this three statement I have imported the first one is a loging the second one is a OS and the third one is a date Tye now let's try to create our logger file so for that uh what I'm going to do so here I have written one expression now let me show you how my logger file will be looking like so guys here is my logger file here is my log file actually and inside this file I'm going to log each and every information right so just try to uh look into this particular file so here what I'm going to do see here I'm going to collect my uh the real uh date time so by using this date time do now I'm going to uh I I I will be getting the real date time now I'm uh calling this particular method St strf time so I'm formating this particular time whatever date and time which uh which we are getting U and this is the real date time okay okay if I'm going to call it um as of now right so let me show you you can perform each and every thing each and every experiment inside this experiment uh inside this uh particular notebook So Yesterday only I have created so you can create it and you can perform like whatever experiments you want to do before putting into the pipeline now what I can do here I can copy this uh code from here now let me copy it and let me show you that what I will be getting from here so this small small experiment you can do inside your Jupiter notebook now from uh so here actually I need to import the date time so from date time what I'm going to do I'm going to import the date time itself so from date time import date time now uh let me do one thing let me run it and here you will find out the uh the current date and time now if you want to formate it uh so here uh for that actually we have a method so you can call this method St strf time now let me call this particular method and then let's see what you will be getting over there so I'm going to copy it and let me paste it over here now you will find out that I'm getting a date time in a particular format so here is month day year Edge means are minute and second now what I'm going to do so this will be the file name this will be my file name and here I'm going to put do log so do log is what do log is a extension so this is going to my file name and with that easily I can identify that at which particular time I have executed my code getting my point so that's why I'm writing this name I'm giving this name to my log file and this this will be what this will be my uh this current uh date and time will be my name of the log file and what is the meaning of the do log do log is nothing it's a extension so here uh you will see inside this uh logger file so this is what this is the name of the file uh by using this particular Name by seeing this name I can easily understand that at at which time I have executed my pipeline right so according to that I can collect the logs now here you will find out this is what this is my file name so I created a loog file and after that guys what I will do so after that let me create the path as well so where I'm going to store my log so for that also I have written couple of line and this two line actually I'm using for saving my log so in which directory I'm going to save my log okay now here I'm going to call this method os. path. jooin os. getcwd means what so os. get CWD means get current working directory so as of now um in I am in this a particular directory let me show you so let me open my terminal and here you will find out that I'm in this a particular directory so I'm in C user Sunny McQ generator so this is what this is my folder name so this is my directory path as of now I'm working in this uh directory so by using this particular method os. get CW you will get the current working directory and here is what here you are going to write down this log so it is going to combine this both path all right it is going to combine this both path so in a current working directory you are going to create one more folder the folder name is going to be a log and this is going to be your path now you will pass this path to your make directory meth method. make directory so what it will do so it will create a folder so here is your file name here is your folder along with the path where it will be available and here you are going to create that particular folder after giving a path right I hope this three line is clear to all of you now what I can do now inside this folder what I will do guys tell me now inside this folder I will now inside this folder I will create my log file the file basically the name uh which I have uh like given over here which I'm trying to generate from here so now in this particular folder inside the loog folder I'm going to create mylog file so let me do uh this thing and here you can see os. paath join now here is what here is my lock path this this particular path lock path where uh like we have a lock folder this logs folder and inside that I'm going to create this dolog file now now after that let me create a object for this loging so here I'm going to call this loging now now let me copy and paste uh inside that I need to write couple of thing inside this logging method inside this logging function now let me show you that what all thing we are going to write it down inside this particular method so here I have already written the parameter that what all parameter which we need to pass over here the parameter is going to be a very very easy so the first parameter is going to be a uh label so actually we have a different different label of the loging so here I'm going to mention this info label so loging doino this this is going to be my label actually we have if you will look into the uh logging documentation so P just just type python logger so there you will find out a documentation and just look into the label so there you will find out a various label regarding this logging so from where you want to so from uh which particular label you want to log your information so here I'm mentioning this uh info so info till info and above the info it is going to capture all the information it is not going to capture the information below the info right so let's say if we have let me let me show you the label of this uh logging so you can search about the python logger so let me write it down over here python logger and here uh let me search it and let me open the documentation and here you will find out the different different label of the logging so just a second let me show you that and uh label they haven't given over here let me search directly python loger label yeah so these are the label actually so nonset and debug information warning is there error is there and critical is there so we have uh how many labels we have six label actually so info so we are going to log all the information from here okay so we are going to write it down the label label is equal to logging doino and from here onwards we are going to capture all the information so information warning error and critical we are not going to capture this two information debug and nonset I think this part is clear to all of you that what is a label now here you can see we have a like a label and apart from that I have mentioned the file path so this two thing is clear to all of you now let's talk about this format so what is this format actually so in the inside the format you will find out I'm going to mention a various parameter so first parameter which I have mentioned that is going to be a ASD time uh that's going to be a current time now line number at which line number we are going to log the information then we have a name then label name and then we have a message so we are going to log a various parameter now let me run it and then you will get a a clearcut idea that how the thing is working so here is my logger file and by using this particular file I'm going to capture each and every information regarding the execution and in between I will be writing loging doino loging doino so whatever uh like information I want to capture so in between in my in between my execution I will be mentioning that thing and I will be able to capture all those information so here what I can do so if I want to test this logger file logger py so for that what I can do here I can write it down this uh test.py now I'm going to create one file the file name is what test.py now here inside this file I'm going to write it down let's say I'm going to import this loging first of all so where this logging is available so if you will look into this SRC so just go through with the SRC inside the SRC we have a McQ generator and inside the McQ generator you will find out this logger so you can write it down like this uh how you will write write it down your import statement so you will write it down from SRC do McQ generator. logger and you are going to import logging from here from this particular file so from SRC do McQ generator. loger import loging now here I'm going to write it down this a loging loging doino so here I'm mentioning this here I'm writing my login. info and let me write it down something over here so so hi uh I'm going to I'm going to start I'm going to start my execution so I'm going to start my execution now this is what this is my message which I have written over here now if I'm going to run this particular file so let's see uh will I be able to create the logger or not so for running this file what I need to do so first of all uh I need to open my G bash because either I'm going to work with my G bash or command line I'm not going to use this poers cell uh because it gives uh some sort of issues so I'm not going to use it now here what I can do guys I first of all I need to activate the environment so what is the name of my environment my name of my environment name is EnV so for activating the environment I just need to write it down here Source activate and do/ EnV now here is what guys here is my environment so EnV is my environment which I have activated now you can check that all the libraries is there or not all the thing uh we have upload we have installed or not inside this particular environment you can list all the import statement so for that there is a command pip list so just run this particular command pip list and here you will find out all the library all the library basically which we have installed and along with all the library along with all the packages you will find out my local package as well and the name of the local p and the name of the local package is what McQ generator so here guys this is the path where this package is available inside my directory inside my system and here you can see this is what this is the package name and how to install this package in my previous class I have clearly explained you that how to install this package inside the current virtual environment so for that either you can mention this Hy e do inside the re. txt or else you can use the setup. y file now let's try to execute the test.py file and let's see will I be able to create the logger or not so here what I'm going to do here I'm going to write down my python python test.py and here you can see it is saying that modu object is not callable but yeah I able to create my logger and inside this logger I don't have the uh I don't have the logger uh I don't have a logger log file actually so let's see uh what mistake we have done over here inside this uh inside this uh logger py so let me check with the logger py and here is saying that uh loging label loging doino um module okay so actually I haven't mentioned this uh I haven't called one method over here the method name is going to be a loging do basic info so basic configure actually so I missed uh that particular method now let me copy it and here I'm going to call it so my method name is going to be a basic configure so here is my method guys uh which I have copied now so let me do one thing let me remove it now everything is perfect so let me remove this part also yeah so here guys you can see my method name is what login. basic config this is my method and now I hope everything will work fine so what I can do do I can uh delete this particular module log mod sorry I can delete with this particular folder log folder and again I can run it so here let me clear the screen and let's see this time it will be working or not so I'm executing Python test.py and now you can see I'm able to uh run or I'm able to execute this particular file now just look into this log file and here uh log folder and inside this you will find out this uh particular file so just see the name just see the name of this file the file name is uh this is the date current date 12 1223 and here is a Time 347 and this is a second actually and do log do log is What DOT log is a extension now just look into the information that uh what information we are going to capture over here so here this is my current date time and here is my root actually root uh uh and here you will find out the information this is the information now this is my message so in whatever for see whatever format I have mentioned over here inside this format inside this basic config you can see in a similar format we are going to capture the information so just look into the format so here is a current time here is a line number here is a name so name is what name is a root I haven't defined any specific name so it's taking as a root line number U at which line actually uh I have mentioned this loging logging doino inside this test.py file so you can see at line number three so yes I'm able to capture line number three also now here is a logging information uh actually logging label that's going to be information and here is my final message so this particular information I'm going to log and in between I can mention this log uh like wherever I want to do wherever I want to mention it and then I will be uh log the information in this particular file I hope this logger is clear to all of you please do let me know in the chat uh please write down the chat if logger part is clear then I will proceed with the next concept okay so great I think uh this part is clear to all of you how to create a log and all and how many of you you are implementing along with me uh how many of you you are doing along with me great so what I can do here I can uh push this changes to my GitHub and then I will show you how you can do the entire setup in a lab also so before writing the further code uh so what I will do I will uh Lo the same repository in the lab in the neuro lab and I will show you how you can execute each and everything over there also okay so first of all let me commit it uh let me do it over here I'm going to add all the files just a second yeah it is done now here I can write it on the message I created a logger I created a loger now let me commit it and uh here okay a few more fil is remaining just a second now this yeah so here you can see so I created a log and you can see my log folder and here is my log file now guys you can do one more thing uh let's say if you are not able to set up this project inside the local see yesterday I started with my local setup and all so that's why I'm continuing uh here itself U but yeah from next uh class onwards I'm going to uh I'm going to shift uh this projects and all on my uh lab itself so what you can do so just uh open the inal lab and after opening the inal lab let me show you how you can U like clone this particular project in the lab itself how you can execute this uh this this entire project actually in the lab itself directly from the GitHub from here itself so what I can do let me open the lab and here uh first of all let me give you the GitHub link so what I'm doing I'm going to pass it inside the chat and here is my GitHub link now guys what you need to do see uh here uh how you can open the lab so after open the Inon website you just need to click on this neurol lab so just click on this neural lab and it will redirect uh to you on this particular page so this is the homepage of the lab I neural lab now click on this start your lab so once you will click on that here you will find out of various option so big data data analytics data science programming web development so whatever you want to do now let's say if I'm clicking on this data science now here also you will find out of various option so K is there Dash is there Jango is there flask is there Jupiter py toch my SQL python there are so many option you will get it now here I'm using this cond as of now so I'm not going to create my application in flask so I'm not using this dedicated uh lab okay this one uh I can use it if I'm going to create my application in flas Jupiter for the Jupiter only means here you will be able to launch the Jupiter this for the pyto this for the Python Programming this for my SQL with python so already you will get a like extension and all here itself inside the lab it has been configured in that particular way now let me open this cond and here what you can do so start your lab and here you can give the name so here you can write it down the name let's say I'm going to write down the name McQ gen project so this is what this is the name of the project now here uh what I will do let me write down the comp name McQ generator project and it is asking to me do you want to clone any GitHub repository so I would say yes I want to do that so it is asking to me a URL so uh like just just give your url just paste your url so here what you can do you can give uh this particular URL see here I have uploaded the my code actually here I have uploaded uh the entire code on my GitHub repository so first what you need to do either you can Fork it or else you can uh like clone this particular repository and then you can upload inside your repository right so as of now this code actually it is available in my repository I have created the repository McQ generator and here you will find out the entire code now in your case what you need to do you need to upload the upload the same code in your repository and that URL you need to pass okay that particular URL basically you're going to pass so here what I can do I can copy this URL I can copy this https URL just copy it from from here and pass it over here inside this enter repository URL now uh let me pass it and here you can see guys this is what this is My URL now proceed so once you will proceed so it will take some time for the launching and my entire code will be available inside this particular lab so just wait uh it is fetching the entire code from the GitHub and yes now it is going to launch it see guys see uh so here you will find out the entire code see this is what this is my entire code whatever code whatever development I'm going to do uh I I I'm doing basically uh which is available in my GitHub now uh what you can do see uh here let me show you so sttp github.com now this same thing actually you can see in your vs code here itself in your vs uh in your GitHub also so if I'm writing over here dab.com instead of this uh github.com it is not there I think I need to press dot just a second yeah GitHub do Deb see guys so this actually this vs code has been provided by the GitHub right this this one this uh which you can see over here you just need to press dot in your um like once you need to open your repository and press the dot so here you will get this vs code so in the same way actually see we are providing you this a particular lab now whatever thing now whatever thing thing actually we are doing in a local in our local actually this one this is what this is my local setup right so whatever code and all I'm executing I'm doing in my local but let's say you have a dependency issue you are not able to write it on the code in your local system your system is very slow you don't have that that much of configuration your system is lagging or if you're are installing or downloading any sort of a library is giving you the error so any type of issue so for that there is a one solution the solution is neural lab uh for so that uh you don't need to download or install anything you just need to visit the uron website after visiting the uron website click on the neural lab after clicking on the neural lab there is a various option you just need to select only one according to your requirement and then pass your GitHub URL there or maybe if you don't want to pass it don't pass it directly launch your lab it will be launching the blank lab in that case and there actually in that particular workspace you can create your own project so that that's uh that thing actually I'm going to do from my next class onwards and here you can see uh this is what guys this is my project the same project I have open in my uh the same project I have open in my neural lab now let me open the terminal and here is what here is my terminal this is what this is my terminal uh are you doing it guys are you doing along with me please do let me know in the chat if you are able to open this Nero lab and if you are if if you migrated your project to this nuro lab here is my GitHub so you will find out the uh entire project entire code in my GitHub itself you can Fork it you can uh clone it whatever you want to do you can do from here uh we are not going to use Google collab uh we are going to use the neural lab see Google Google collab it will just give you the notebook instance right so but here actually this lab is for the end to development so you can do end to development over here got it are you doing it please uh do let me know yes uh Google collab you can think it's a like a neural lab but it is for the an development and it is giving you like like lots of functionality great so this is what guys this is my uh project which I migrated to my neural lab now here see this is my base environment so in my base environment I can uh install this requirements or I can create the virtual environment also so for creating a virtual environment the command will same so let me create a virtual environment over here and let's see we are able to do it or not so for creating a virtual environment by using the cond there is a command the command is going to be cond cond and here cond create hyphen p and here you need to write it on the virtual environment name so my virtual environment name is going to be uh let's say I'm I can write any name over here uh ENB vnb your name my name or whatever now here the command is Conta create hyphen PB and uh then you need to mention the python version in whatever version actually uh with whatever version you want to create a virtual environment so here I'm mentioning python is equal to 3.8 now hyphen y okay so this is my entire command cond create hyphen PB python is equal to 3.8 hyphen y now as soon as I will hit enter so you can see it is creating a virtual environment in my local workspace so let's see yeah so it has created a virtual environment in my local workspace so just just look into the workspace here left hand side and here is your complete virtual environment now if you want to activate this virtual environment so for that there is a simple command you just need to write it down this Source activate dot means what dot means current working directory or current work working space do/ andv now as soon as you will hit enter so you can see over here that I have launched my virtual environment successfully so this is what guys this is my virtual environment this one EnV EnV is what EnV is my virtual environment and here you can see this virtual environment left hand side right now what I will do here I will install my re requirement. txt so whatever requirement is there U regarding this particular project I'm going to install those requirement inside my virtual environment now here is a very simple command for installing the requirements uh whatever like requirements I have mentioned inside the requir not txt and before that let me check uh what all uh what all packages we have inside this virtual environment so for listing all the package there is a command the command name is what the command name is PIP list so let me hit enter after writing this command pip list so here you can see we are able to list all the packages whatever is there inside this virtual environment now uh let me write it down here pip install pip install hyph R requirement. txt so now let's see uh are we able to install yes we are able to install this requirement inside the current virtual environment so are you doing it guys please do let me know in the chat if you are following this instruction if you want to set up the same project if you want to set up the same project in your neural lab so here I'm giving you the all the step uh that uh whatever you have to do so first you need to sign up uh sign in actually you need uh you need to open the neuro lab and after that go inside the start your lab there's a option right hand side you will find out and there you will find out the data science inside the data science there is a cond so just click on the cond and immediately you will be able to you will be able to launch your lab if you have kept your entire code in your GitHub then directly pass your URL and then uh like launch your lab that's it okay so I think it is done yeah so I install all the requirements over here now first I can check that uh my require whatever like packages I have installed it is working or not so here itself you can launch the python terminal and here you can see the environment python version 3.8.8 and here if I'm going to write it down import of Leng chain so let's see it is working or not c i yes my Lang chain is working now let me clear uh okay and here if I'm writing this Panda so import P PD so yes this is also working now everything is fine everything seems fine let me exit from here and what I can do now so here I have created the logger so if you will look into this uh SRC folder inside the SRC folder we have this McQ generator and inside this McQ generator we have have this logger now try to test uh this logger so it is working or not over here so for that what I can do I can run my test.py file so what I can do here I can change the message and my message is now I now I'm using now I am using neurol lab neuro lab so there is my message uh the message is now I'm using neurolab and let's uh execute this particular file python python test.py so if I will hit enter now let me check with the log folder yes uh so we are able to create this file and yes we are able to log the information also I hope this thing is clear to all of you how to log the information in all yes or no so the same thing which I was doing in my local now I'm easily able to do in my lab also oh yes we can change the theme also and for changing a theme there is a option let me check okay I think here you I will get the option command pallet color theme yeah so light is there now Dark theme yep so here you can see I have changed my theme also now if I if I want to zoom in then I can do that also just wait it is in my browser now so let me Zoom my browser yeah I think now it is perfect so guys uh if you are able to follow me till here so please do let me know in the chat then I will proceed with a further uh execution further code and all yeah you can upload your code over the GitHub and then you can clone this GitHub over here or else if you haven't created any GitHub then directly you can launch the lab and uh then you can connect to your GitHub from here also from the lab so that setup I will show you in my next class uh so in my next class when I will start with a new project so that I there I will show you if you are opening the blank neuro lab then how you can connect that neural lab with your GitHub got it even you can upload your code here also directly so just do the right click and maybe here you will find out the upload option see this one so just do the right click on this workspace over here here um anywhere in the uh and then you will find out this upload option so just click on the upload and here also you can upload your file maybe you won't get the folder option but yeah if you want to upload anything over here let's say data set or any any any file from the local system you can directly uh upload from here so just do the right click and here is upload option and then upload your file that's it great so I believe that uh everyone is a able to follow me till here now let's proceed with the further code so we have created a logger now it's time to write it down the code for the McQ generation so here I have created a file the file name is what McQ generator. py now uh before this one uh let me show you one more file this ipynb file which I have created in my previous class now here I have written the entire code of the open a for the Lang CH and all so uh directly from here itself I'm going to copy the code because already I have written it and uh yes I'm not going to write it down again so from here itself from the ipbb itself I'm going to copy and paste now uh there is my McQ generator. py file so at the first place what I need to do guys I need to uh at the first place I need to import the statement so let me import all the statement whatever statement is required for this project so here I have imported all the statement the first one is OS Json Trace bag is there pandas is there load. ENB is there now read file get file I will tell you uh like uh why I have written this read file get file so once I will explain you the U tools and here is loging so from where I'm going to import the login I'm going to import from this SRC see here uh I haven't mention the SRC so let me mention the SRC SRC Dot and here also let me write it on the SRC dot because uh I created uh like one more hierarchy actually this McQ generator folder it is available inside this SRC uh now I think this is fine now let's look into this particular import statement so here I'm going to import this Chad open Ai and then promt template llm chain and this sequential chain already I have explained you the meaning of this different different uh Imports that why we use this chat open why we use this prom template llm CH and this SQL uh and this like sequential check now uh what I can do here I can import my ID uh so actually I created my key openi key so let me import that openi key over here and then only I will be able to hit to my API so for that here I'm going to uh write it here I'm going to call this a load. EnV I told you why we use it uh if I want to if I want to if I want to create or if I want to keep my uh environment variable locally in my local folder in my local workspace so for that only we create this load. uh load. EnV uh now over here see if I'm going to call this method if if I'm running this method so actually it will look uh to this EnV file so it will it will try to find out the EnV file inside the current workspace now uh here what I can do I can create this EnV file so here I'm writing down uh do EnV so here is my file the file name is what the file name is do EnV so as soon as I am running this load. EnV so in back end actually it will try to search about this particular file so whatever variable whatever information I'm going to keep over here right whatever information whatever like variable I'm going to create over here so it will try to fetch from here wait let me show you how so uh what I can do now let me keep my key over here this uh like API key open API key I'm going to keep it over here inside this now what I can do now let me write down the further code so here uh once I will uh load this dot environment now here what I will do guys here I'm going to uh write down this dot get EnV so get environment variable so os. get En EnV and here inside this particular method I on uh like I will call it so I will mention the name of this uh key so what is the name of the key so the name of the key is open a API key so let me pass it over here this open API key now what I can do I can keep it inside the variable and my variable is going to be key now here what I'm doing guys I'm uh extracting my key I collecting my key by running this particular code by learning this particular line now uh here what I can do I can comment it out also so let me comment this particular thing I already WR the commment let me copy and paste so here what I'm saying load the environment with variable from the EnV file and here access the environment variable just like you would uh with OS environment so here you can see we are able to do it now let me follow the further step so after collecting the API key now what I will do I will call my open AI API for that we have a method the method name is chat open AI now let me call it and here let me show you that what all parameter we are going to pass while I'm calling this chat open AI so here you can see uh we are going to create a object of this chat open Ai and inside this one we are going to pass couple of parameter the first parameter is a key itself because without key we cannot call the API and we won't be able to uh get the model so here is what here is my API key now here is what here is my model name so this is the model which I'm going to use there are various model GPD 3.5 turbo or different different type of model you can go and check uh this uh I have already shown you in my previous session in my Open Session if you don't know about it you can go and check with my previous session now here is a temperature so temperature is just for the creativity if I want to so whenever I'm going whenever I'm calling my llm model so uh like whatever responses I'm generating so that will be a more creative if I'm mentioning uh if I'm writing the different different value of the temperature the temperature value from start from 0o to two so two means uh very creative zero means not at all it won't be a creative right so actually zero means it will give you the straightforward answer and two means it will give you the highly creative answer all it so between that I can set any sort of a value over here and according to that I will get the answer I will get a response so here you can see we have uh I'm able to call by API and I'm able to like U I'm able to get my model also now after that what I will do guys see I told you what I need to do I need to create my template I need to create my prompt template so here I'm going to create my prompt template now let me show you my uh template actually how it looks like so here is my template in my previous class itself I have shown you this thing I have explained you this thing now here you will find out couple of uh like variable also so variable like this number is there subject is there right we have tone we have n and this number so in between actually whatever thing you can see inside this curly braces that is representing a varable table now uh here what I'm going to do I'm going to create my input prompt I'm going to and this is what this is the template from the input prompt this is the template for the input prompt now here is what tell me guys here is my uh like a template for the input prompt now what I can do I can uh show you the prompt template and then I will explain you what is the meaning of uh this particular thing right this a particular template why I have written it again I will try to explain you even though I have explained you this thing in my previous class but again I will go through with that so here you can see guys we have a prompt template right so what we have tell me we have a prompt template and regarding uh see uh we have uh two variable inside this prompt template first variable is a input variable and the second variable is a template itself this one this one which I have defined over here now whenever we are talking about llm right so as I told you whenever we are talking about the llm so we have two type of prompt so the first one actually first one is called input prompt and the second one is actually it is called output prompt right so prompt is nothing it's a sentence itself uh it's a collection of the words it's a collection of the tokens right now here you can see we have a template and this is what this is my template the template is nothing so this prompt is nothing actually it is uh guiding to my uh it is guiding to my model is guiding to my GPT model GP we are using the GPT model now right so based on this particular prompt only is going to generate the answer so we have actually two type of prompts so we are talking about the prompt actually so measly you will find out two type of prompt so the first prompt first type of prompt actually is called a zero short prompt zero short prompt there we are not going to mention any sort of a context we are directly asking a question to my llm model the second type of prompt is called the second type of prompt is called few short prompt few short prompt so what is the meaning of the few short prompt so few short prompt is nothing there we are giving uh some sort of a direction actually some sort of a direction or some sort of an instruction in inside the prompt itself so this typee of prompt actually is called a few short of prompting now here we are giving an instruction to our llm based on this particular prompt now here you can see uh this is what this is my template uh and here I need to mention this particular template over here and this is what this is my input variable right this is what this is my input variable now we have H five input variable so one is text so whatever text on whatever text actually I want to generate McQ so that particular text I'm going to pass over here uh means basically based on the text itself I'm going to generate an McQ now there is a number of McQ there is a grade okay so to which grade actually uh the student belong now here is a tone tone means simplicity so means different different label of the quizzes so simple quiz or maybe hard quiz intermediate quiz and here is a response Jon so there you will find out the response and here in a curly bis actually I have mentioned this uh like uh I have mentioned this particular thing this particular variable now let me do one thing see uh here I have mentioned the subject and here I'm writing this grade so let me change this particular value here I can write on the subject so now everything is fine everything is clear so this is what guys this is my input prompt this is what what I have created I have created an input prompt now let me uh create a chain object so here already you can see I have like I have imported my llm chain and why we use this chain if we want to connect two component so we first uh at the first place we have a llm the second one we have a prompt template if you want to connect both uh this both component so for that we are using this llm chain so now let me create a object for this llm chain and for creating object for this llm chain so first of all let me assign to the variable quiz uh chain and here is this is what this is my object now in this particular object I'm going to pass two value two parameter the first value is going to be llm itself now here is what here is my llm which I already called which I already uh got from here and the second thing the second value is going to be a a prompt okay so here I'm going to be write the prompts and this is what this is my prompt quiz generation prompt so here I just need to uh here I just need to combine two component the first one is LM and the second one is a prompt so here is what here is my quiz chain got it so this is the first chain actually which I have created and this each and everything each and every uh like uh thing actually I have explained you in my previous classes even in my uh like yesterday's class now guys see whatever um output I will get after generating a quiz from here from the template so that thing I'm going to keep inside my uh inside my variable and the variable is going to be let me write down the variable over here so the variable is going to be output uncore ke is equal to and here let me write down the quiz so here I'm going to collect all the output inside this quiz inside this a particular variable now let me mention one more parameter the parameter is going to be a barbos so what is the meaning of the bbos barbos is nothing if I want to see the execution whatever execution is happening if I want to see on my terminal itself so for that we use this bbos parameter now let me write it down here verbos is equal to True veros is equal to true so here I hope each and everything is clear whatever I have explained you uh if it is clear then please do let me know in the chat are you following me are you following me guys tell me guys fast yes or no what was the command for creating a virtual environment so let me give you the command for creating a virtual environment cond create hyphone p and virtual environment name p EnV and here uh python version python 3.8 and here hyph y so this is the command uh which you can use for creating a virtual environment I given you the chat you can copy from there tell me guys first so if you are uh able to follow me till here then uh please write down the chat and if you are liking the uh if you liking the content if you are liking the class then please please hit the like button also if you have any uh sort of a doubt any type of doubt you can mention in the chat section you can uh tell me your doubt I will try to solve that particular doubt and then I will move forward please tell me guys I'm waiting for your reply so yes chat is open for all of you please hit the like button please ask your doubt and if everything is done uh then please say yes at least okay so let's move forward great so here uh you can see this is what this is my first template which I'm passing to my model now at the second place what I need to do so I I'm going to create one more template for evaluating this quiz so whatever quizzes and all uh basically we are going to generate so I want to evaluate a particular quiz now for evaluating the quiz here I'm going to create a one more template U Already I did it if you will look into my in uh this if you look into my ipnb file so yesterday itself I have I had created this uh like different different prompts and all so this was my first template this is my first prompt and this was my second one for checking the quizzes and all so whatever quiz and all which we are going to generate and here is a template now let me copy it from here and let me paste it down so where I'm going to paste it I'm going to paste it over here inside my McQ generator. py now this is going to my second template so let me keep it in a small letter itself so here I'm going to copy it and this is going to be my second template this one so just just read this particular template that what we are saying here I'm saying to my model that you are an expert English grammar grammarian and writer given a multiple choice question for this particular subject whatever subject I'm going to mention let's say data science AI machine learning so here I'm saying that you need to evaluate the complexity of the question and give a complete analysis of the quiz only use uh Max 50 words so 50 words for the complexity analysis if the quiz is not at p with the cognitive and analytic abilities of the student then update the quiz question which needs to be changed and change the tone such that is perfectly fits to the student ability now here here is basically here I have a quiz so uh which one this is this this quiz so this quiz actually I'm getting from here so whatever output I'm getting after the first after this uh after the first template so whatever uh like prompt I'm passing to my llm this first one so whatever output I'm getting I'm going to keep inside this quiz variable and that uh this variable I'm passing over here and based on this uh like quizzes and all right so based on this particular prompt we have a prompt and we have a quizzes now is going to check it's going to evaluate each and everything is going to check the complexity grammar each and everything is going to check over here so this is the additional prompt of which I have written over here now guys after that what I will do so here I'm going to Define my uh prompt template so let me do it uh let me Define my prompt template and my prompt template name is going to be a review chain so let me take it from here and this is what guys tell me this is my uh like second chain right so here I have created first llm chain and the name was quiz chain here I have created one more llm chain and the name is what the name is uh this one review chain right and here is what here is my prompt so prompt is going to be a quiz evaluation prompt sorry uh let me Define The Prompt uh before this one so here what I can do let me copy the code from The Prompt so this is the small small code and all so already I have written it even yesterday in my ipbb file I kept all the code right so you can go and check with my gith repository you will find out the entire code because yesterday I written from scratch and I have explained you each and everything so today I'm I'm not going to write it down here again um I'm just going to copy and paste and I believe if you have seen my previous session that definitely you will be able to understand it now what I can do so here I can write down this quiz evaluation prompt so we have this quiz evaluation prompt and here is my prompt template where what I'm doing guys tell me where is my uh input variable these are my input variable subject and quiz which you will find out over here subject and the second one is what the second one is quiz now here I'm going to pass my template and the name of the template is what template 2 so let me mention it over here let me write it down the template 2 so here is what here is my quiz evaluation prom and there is what there is my chain which I have created by using two component the first one is llm itself and the second is what the second is quiz evaluation prompt right and here whatever output uh we are getting so that output I'm going to keep or I'm going to collect inside this review variable right so just just try to understand how the thing is working it is very very simple if your python if if you know the python if your python Basics is clear the definitely you can understand uh this particular code got it now here we have written bubos is equal to true so this is what this is my review chain uh which I have created now after that what I will do see I have to combine this both chain the first is a review chain and the second one is what the second one is a quiz chain so for combining the both chain what I can do so here I can create object of the sequential chain right so now what I'm going to do guys here I'm going to create object of the sequential chain uh just a wait now let me create a object of the sequential chain and here is a object of the sequential chain this one now already I have imported the sequential chain this one this one L chain do change the sequential chain now here see we are going to create a object and what we are going to write down here we are going to define or we are going to write down the both name both chains first one is quiz chain and the second one is a review chain now we are going to connect everything all together here is and we are passing to this chain parameter now there is my input variable so these are input variable if you will look into the prompt if you will look into the prompt template there you will find out of various input variable various input variable which I'm going to take from the user side I told you I I explained you this thing in my previous classes just go and check with that now here is what here is my output variable so one output I'm going to collect inside this quiz and the second output I'm going to collect inside this review and here verbos is equal to True verbos equal to True means what whatever execution is happening in back so each and every execution the detail of the execution I will get onto my uh screen itself right so that's the meaning of the verbos is equal to true now this part is clear to all of you so we have a completed till here means uh we are able to call my API we are able to create we are able to call my API we are able to create a prom template and here we are able to create the chains now after this what I have to do see here in between you can mention the uh log also you can create uh we have created a loger now you can write down log logging doino and here you can collect all the information in a single file itself so whenever uh we are going to execute it so yes the loging U the log loging doino U basically logger file also is going to be execute and it's going to collect each and every information inside the dolog file got it now here uh this McQ generator is done now uh in the previous session uh actually what I did so over here uh if you will look into that so open eyes find this uh temp template and all everything is fine now just look into this ipynb after creating the chain actually we were calling this particular method right so uh the method name the method name was what get open a callbacks now why we use this U Get open a callback because if you want to keep a track of uh of the token right how many tokens is being used inside throughout the execution means uh let's say uh I'm passing a prompt input prompt I'm getting an output prompt so throughout this process how many tokens is being generated so that all the thing I can keep track by using this get open I call back and inside this one I'm calling I'm I'm I'm creating a object of this generative evalution chain itself so this is the one generative evalution chain and we are passing a different different value now where I'm going to do this particular thing see main code I have written inside the McQ generator. py now rest of the code whatever uh like utility code is there whatever helper code is there I'm going to write it down inside this utils.py so here I'm going to write down the entire code which is a helper one right I'm not going to mesh up my uh McQ generator file itself okay so here if I'm going to write it down like each and everything it is going to be a very clumsy so I'm not going to write down anything now over here uh till here everything is fine maybe so yes uh we have created a chain now inside the utils.py file let's see what all thing we have to like like uh we have to mention so the first thing first of all let me write down the import statement all the import statements so the first one is uh OS the second is pi PDF 2 the third one is going to be a Json and the fourth is a trace back so these are the import statement which I'm going to write down here now here what I will do guys see uh what I want I want a data right I want a data so for that actually uh I have defined two method so let me copy and paste all the method now just second I'm going to copy this two method and I'm going to paste it over here so here actually we have two method just just look into this method I I will tell you that uh uh why we should use it how we are going to use it so just a second yeah so here we have two method the first is going to be a read file and the second is going to be a get table data so there is two helper function which we are going to Define over here right now just look into this read file so this read file actually this this particular method we are using for reading the file right for reading the file whatever file we are going to pass actually so here actually I have written a code regarding two particular files so the first one regarding the PDF file and the second one respect to uh text files right so here I'm going to mention this P pdf.pdf file reader here we are passing file here we are getting file and here we are extracting all the data from the file itself in which variable in this text variable now here if you will look into this uh this particular code right inside this LF blog you'll find out file. name. ends with. txt so if my file is a txt one so I'm going to call I'm going to read this particular file and I'm going to keep all the information in my VAR so here from here basically I'm going to return all the information right got it now here just see this one so the second method G table data so why we are using this method G table data in my previous class if you will look into this uh IP VB file so where is the ipb file let me open it once more time so McQ do iyb file just scroll down till last so here actually I was getting a data I was getting my McQ now if you want to convert those McQ in a data frame so for that see this my this is my McQ which I was getting now if you want to convert this McQ in a data frame so for that actually we are using this a particular code this one this this particular code which I have written inside the utils.py so here I'm not going to mention everything in a single file instead of that I have divided a task right so whatever thing is required whatever is a main code main script I have written over here inside this McQ generator whatever like helping function and all like uh like this reading file reading and all or this get uh data as a table and all right so I have mentioned over here inside this U and already I have created a logger so there I am going to Define my uh there basically I have defined my logger so I believe until here everything is fine everything is clear to all of you please do let me know in the chat now one more step is there one more step is remaining now finally we'll create our application our streamlet application and then I will show you how to run it so first of all tell me if uh till here everything is fine everything is clear try to generate a new API key if you are getting any sort of error related to your API key delete it immediately and uh generate a new API keyy tell me guys fast I'm like up for the doubts and question so yes you can ask me and then I will proceed with the forther uh thing please increase the font size I think it is visible to all of you now let me increase few more just wait ah I think now it is fine what is a trace bag Trace bag actually it's a inbuilt function wait I will show you what Trace back does uh wait I will write down the code here itself inside my McQ IP nv5 if you have any type of Doubt any sort of a doubt then please do let me know please write down the chat uh I will try to solve your doubt and then I will proceed further no you no need to pay anything uh if you're using this neurol lab it is completely free uh just try to launch it again I think uh you can launch it yeah we can create a new template file also that is also fine but here we just have two templates so that's why I have written it inside my P file itself inside my python file but uh not an issue like you you can create a template file and there you can keep the all the templates and from there itself you can read We are following you but needs to revision from yeah definitely revision is required could you open the logging file whether it contains any log or not so here is a logging file and here we have two log file. log just open the file and here see we have a log I test it now I test it from here test.py so yes I'm able to see the log yeah so I think uh we can start now uh yeah so I think we have done almost all the thing now the next thing is what I need to create a streamlet application I think uh see uh regarding the code and all everything is fine everything is clear whatever I did in my previous session I I'm doing the same thing over here I just kept in my uh py5 that's it now see guys this uh project is uh actually it's a first project so that's why I kept I kept it uh I kept I kept it as a simple one only but uh from next class onwards uh I'm going to use few more files and folder inside the like project itself so the architecture which I'm going to make so it's going to be a little more complicated okay so this is fine this is clear now let's do one thing let's try to create okay response. Json is already there now let me keep the response over here inside this uh file inside this response. Json and after that what I will do so I will create my stream application so there is my response in which particular format I want a response so I kept it inside the response. Json so this is what this is the format which I want here is McQ question here is answer and here is a correct answer so in this particular format actually I want a response from my GPT model now this is this is what this is a response. Json now let me open this stream lit uh app.py file and here I'm going to write it down the code now first of all let me import the statement all the statement so there is all the statement basically uh here what I'm going to do so these are the statement which you already know now this is the statement read file get file from where from the utils itself now see I created uh like one more hierarchy so here uh let me write down the SRC so wherever you are able to find out this McQ generator just write down the SRC in front of that so uh here you can see we have I have written this SRC McQ generator. utils and inside that we have this read files get table data you can check it you can run it and it is working fine or not so definitely uh you can do it for that uh let me write down this SRC McQ generator. log. loging now here if I want to check this file so I can write it down one okay so here what I can do I can run it in front of you let me clear it first of all and here let me write down python python uh streamlet app.py so Python steamate app.py and if I'm running it so it is saying that this module is not available McQ generator let me check with the spelling is correct or not so the spelling is McQ generator g n Okay g n and here see guys the spelling is wrong so here I need to write down the correct spelling so this will be g e n e so this is the spelling of the generator G NE e generator and here also G G NE so this is going to be generator now let's see it is working fine or not now for that python streamate app.py so let me run it and module name SRC McQ generator not there so where it is at line number nine so line number line SRC McQ generator import generative evaluate chain so here we have SRC McQ generator is there inside this McQ generator this is the file so McQ g e n e again the spelling is wrong let me correct it uh let's see it is working or not so here I'm going to write on python stream tab. py SRC McQ generator utils so McQ G NE McQ g n r a is correct now right so why it is giving me this error SRC McQ generator do utils SRC McQ generator do utils import read file and get table data no modu SRC McQ generator I WR something wrong here McQ generator g e n e r it's fine now I S see just a second so here is fine now what I can do let me install this setup.py so python setup.py install because in my local system everything was working fine I moved to entire project project to this Nero lab that's why I need to check it first okay now let's see mCP P the spelling I need to save it first what so okay I think the file is different uh McQ generator. py line number 6 this one line number six yes so the spelling is wrong now it is perfect I believe right package rapper prompts extra field not permitted what is the issue here modle name McQ generator this is fine this is I have solved now stream lit line number nine there is line number line okay great now I think everything is fine I just need to pass the parameter over here but this uh logging statement and all everything is working fine over here see if I'm going to uh comment it down this one so I will be able to import it python stre late app. yeah now everything is working fine so I was getting the error because I need to pass the parameter to this particular uh like class okay to this particular object that's why uh it is giving me uh it is giving me I show so yes I'm able to import all the statement I was just checking actually because I migrated this project to my neural lab in my local I already tested and yesterday actually I shown you that but yeah I migrated to my uh to this uh neurol lab so that's why I was running it and now everything is working fine so let's try to create a stream streamlit application so here what I can do so for creating a streamate application uh this is the UT statement which I have imported now the first thing the first at the first place I need to load this uh response right so here what I'm going to do here I'm going to load this response so for loading the response actually see what I'm going to do I'm going to read the Json file the Json basically which I've created now let me do the right click and from here from here itself uh like from this uh neuro lab itself from the local workspace I'm going to copy my path right so because this is my local path actually this one that you can see over here the Json path now from here itself I'm going to copy my path so copy path and paste it over here right paste it over here this particular value now let me paste it and this is what guys this is my path right and here my Json file is available now uh what I will do I will read this Json and here you'll find out your Json response Json right in whatever like in whatever like Json whatever Json basically we have defined whatever response method we have defined in that particular like way only is going to data output now uh I have loaded the file I have loaded the Jon file now next thing what I need to do here so see a step by step I'm going to show you everything or let me copy everything each and everything in a single shot and then I can uh explain you right so here see what thing I'm going to do over here Ive already done the code now let me is explain you one by one so this is the first line this one st. Title St means what ST means streamlink here you can see this one s isans what streamlit and why we use streamlit for creating a web application right if you want to create a web application for for that we use this stream L and generally we use it uh for creating a rapid web application like we want to test our machine learning code like okay so we don't want to write it on the like long templates and all we don't want to create API by using Jango or flas so simply we can create a web app a small web app by using this stream lead and yes we can test our code we can test our application now here uh you can see this is the title which will be visible on top of my screen now here you can see we are going to create a form actually inside this stream lit we have a several thing right so what I will do I will create a short tutorial on top of this stream lit and I will upload over the Inon YouTube channel so from there you can learn the streamlit from scratch as of now I'm not going into the deep that what all method what all function it is having I'm just WR whatever thing was required over here and that is what I'm going to explain you got it now here see we have this streamlit st. form and here actually I'm mentioning user input right now I'm asking about the file so actually I'm asking about the file you need to upload a file and based on a file only uh I'm going to generate a mcqs now here you can see number of input so how many uh how many mcqs you want to generate so here McQ count now here McQ subject so like on which subject you want to generate McQ so here you will pass the subject now here is a input text input means here you are asking uh you want to keep it simple intermediate or the hardest one so here I'm uh setting the tone tone of the mcqs tone of the quiz now here what I'm doing here I'm giving a button so here I'm written St St is for the stream late. formore submit uncore button and here you can see create McQ this is what this is my message that's it nothing else so after that you can see I I have written a further code so this is what this is what guys tell me this is my form and inside form actually I have defined the entire template the entire UI so I have created a form s. form s. form means what stream li. form and here I'm asking to the user input so this first input regarding the file means on whatever like data we want to generate our mcqs here you will find out a number of mcqs here the subject of the McQ here the tone of the McQ whether it's going to be a difficult simple or intermediate and here I have added the button the button is nothing I'm going to submit this form so the message B by default message you can see over here that is what there is a create McQ that's it so this is what this is my form now after that I will write my main code main code over here see uh just just look into this particular variable upload file right this this varable upload file right and here I'm getting McQ count subject tone and button now here see this is what this is a respon just look into this particular variable because this is required very much this very much required over here now I'm saying over here if button and upload file is not none okay and McQ count and subject and this this thing is not none then what I need to do so here I'm writing this st. spinner it will be loading right and here see I'm uh reading this text file whatever uploaded file I got and how I can reading it how I am reading this particular file so for that I already WR the method inside the utils file utils.py so here I'm calling this method upload see uh let me show you this uh read file right read file and here you can see St um the stream. file uploader so here I get it I got the uploaded file now what I'm going to do here I'm uh keeping this file over here upload file and I'm giving to this read file right and this read file I already defined inside my utils.py this one see getting my point yes or no now if I have a PDF file then definitely I will be able to read if I have a text file then definitely I will be able to read so let's see if you're giving any other extensions so according to that you can mention the logic you can write down the code over here itself inside the read file now see guys here inside the stream app.py so this is what this is the read U we are calling this read file and here I'm getting this text okay this is fine now again I'm going to call this I'm going to call this uh get open call back if you have attended my previous session definitely you must be aware about this particular function this particular method in very detailed way I have explained you this thing get openi call back now after that you can see we are going finally we are going to call our object so here is my object generate evaluate chain and here we are going to pass a various parameter so the first one is a text so here I'm getting text McQ count or from the user I'm getting McQ count here is what here is a subject tone and here is my Json response everything I am getting over here you can see you can see over here guys this one now we are getting it and after that uh this is fine now in the else actually I have written something so you can see uh whatever number of token prompt and all I can I can print it actually this this particular thing right so inside this else block try accept and else so inside this else block we I have written this particular thing now any now this lse blog will run after this accept so yes you can see this is the thing which we have written now what we are going to do over here we are going to convert our data into the uh we are going to convert our data into our data frame so here actually this is the code see whatever data we are getting now so we are going to convert this data into a data frame this one and after that like yeah uh we are going to end it this particular code and once I will run it so each and everything will be clarified to all of you now what I can do I can run it and then again I can come to this particular code uh where again I can explain you the bottom part but yeah just look over here uh it is just printing the tokens and all now here we are getting a response and d means uh if is response as a DI actually this this particular response now what I will do here I will call this response doget quiz I will be getting the quizzes from there yesterday I run this particular function this quiz and after that I'm passing to this get table data the function which I defined inside the utility and it is going to return return me this table data which I'm passing to my data Frame pd. data frame and I will be getting the data frame over here and you can save it also so yesterday actually I saved this uh mcqs and all over here inside this experiment folder but you can save it you can save this data in the form of CSV file right now what I can do I can run it so here uh for running this particular application I just need to run it let me I just need to write it down one command let me uh give you that command here stream lit streamlit app sorry streamlit run and here I need to pass the here I need to write down the file name so streamlit run and then streamlit app.py soam lit streamlit app.py okay so this is the file where I have defined where I have created my streamlit application so streamlit run is stream lit uh app.py now as soon as I will hit enter let's see it is working or not so it is saying streamlit does not exist I WR a wrong spelling okay streamlit app fine so a will be a Capital One a a yeah now it's fine so see uh my application is running now if you want to run this application ation so for that just copy this URL and then paste it over here and here guys what you need to do just remove till till here this one just remove this up part okay just keep till app and then put the colon and from here just take the host uh this 8501 sorry Port actually this one so just see if you clicking on this one now it is not going to run because it is a uh like it's a local host right now uh actually my lab is running on this particular URL Somewhere over the cloud Somewhere over the server so till here I have copied the URL now put the colon and pass this particular port number 8501 so here I'm writing 85 01 and if I will hit enter so let's see whether I'm getting my app or not so it is not giving me the app let me check it 501 yes it is correct let me check with this link uh but I think it is not going to work are you follow me guys tell me are you follow me till here this is not giving me a URL when view stream browser 8501 right so this is a URL oh no it is not running just a second let me check with my Chrome it is working or not so if I'm passing over here this particular URL now let me put the colon 8501 uh let's hit the enter no it is not running but yeah my my server is up uh here you can see my streamlit server is up streamlit server is running on this particular Port 8501 851 it's a by default Port of the streamlet actually let me change the port just a second let me check uh I'm okay let's do one thing let's try to run on a different port so here what I can do uh I can mention the port just a second I can mention a different port number let be clear first of all I'm here Pyon stream lit run uh stream lit run and there is my app and then hyph iPhone hyph iPhone server and dobard so let's run out 8080 if I will hit enter now let's see it is running on on this 80 8 0 so it is running on this 8080 now let's check over here what I can do I can take this particular URL let me remove here 8080 yeah here it is working fine see I'm getting my application uh before uh it was not working with 8501 but it is giving to me not a complete one why is so just the second is there something wrong so guys see on 8080 my app is working fine this one I'm getting it but uh it should give me a homepage now the form basically which I have created over here this one title also I'm not getting Let me refresh it once no SD form user input this this is everything is fine no no no guys I'm not getting it let wait let me take a different port over here it's getting a stuck here actually let me check with the Chrome is giving me a same issue or what's no guys see it is giving me a issue this particular URL I don't know what is the issue there's a issue with the code or there is a issue with the stream R because I can see my code is fine and uh I just I checked it before right before the class also and it was working uh not an issue what I can do I can show you this thing in my local as of now and then tomorrow I will tell you that uh why it is giving me such issue I I will check okay so as of now see everything is working fine maybe I'm able to get the URL also but uh with 8 5 01 it was not giving me anything but with 5,000 or with any other Port it is giving me this type of page now let me check the same thing in the local it is uh working or not right so just take it just take this particular code and paste it over here inside the local means this is my local environment right now inside this streamlit app.py I pasted my code now inside the SRC we have H utils so let me put the code inside the utils also so from here itself I'm going to copy and paste let me copy and paste from the utils this one and here this is my local utils and let me paste inside the McQ generator is not there let me put inside the McQ generator also here is my McQ generator so this is my McQ fine so logar is there McQ generator is there and utils is there now streamlit is there everything is fine now let's run it so for running this application here is a command stream SD stream lit run SD stream lit app. stream lit app. P1 now if I will hit enter let's see it is working or not yeah it is working okay so here it is giving me one error the error is what PR required type missing prom extra field type quiz barbos just a second guys let me check the issue we uh to validation error evaluation chain yeah this is fine commed line number five Sunny stream L app okay McQ line number 242 McQ generator line number 42 okay boms output key is equal to quiz okay file load I think here we have some issue okay so I I think I'm getting some issue over here maybe it's a python related issue let me check where I'm running it I activated my environment rank chain 0.348 uh just a second so let me fix it don't worry it till be working so let's it yeah so now it is working and here you can see guys see uh this is the code and uh yeah it is working fine on this particular URL and it is uh the project B actually I'm running in my local itself in neuro lab also it is giving me a issue maybe there is some code issue uh which I tested in the local I will have to check because I was copy and pasting maybe in between I miss some line or I'm getting the issue because of the version uh basically the python version which I'm using now here uh you can see see uh my app will look like this the app which we have created now here you have to upload the file uh the file basically U on whatever file you want to generate a McQ and here you need to write down the number of McQ so let's say you want to generate 5 10 15 20 whatever number of mcqs now here you need to insert the subject and here complexity label by default the complexity label will be a simple one right now let me browse some file and let me show you that how the McQ will be generated and how the output will be visible to all of you so here what I can do I can go through with my project itself because already I kept one data file over there there one txt file now let me import the txt file from there and here is what here is my project in my local system just a second McQ generator and here is data open so this is the data guys which I uploaded over here now after that how many McQ you want to generate so here is what here is five now here is a subject let's say the subject was the machine learning so here let me check what was the data inside the file here so here the data which I had actually so let me check with the data it was the biology uh which yesterday actually I collected inside the file so the data was the biology data now how many what was the like complexity of the quiz the quiz you are generating so here I want to keep it simple you can write as simple also but by default it will be a simple only now if I'm clicking on this create McQ so it will will uh directly give me the mcqs now over here is giving me error let me check what is the error yeah API key error so let me keep the correct API key over here because the API key which I'm using just a second yeah now it is fine and now let's do one thing okay server is up and here let me refresh it yeah it is working fine now browse the file a data just upload the data here the number of quiz you can say 5 6 10 subject is what subject is biology uh b i o l o z and here the complexity label is going to be a simple then create mcqs now just wait for some time and it will create a McQ so just wait yeah it is running now and it got the response also yeah so here you can see uh we are able to generate mcqs so mcqs is which of the following is a unifying theme in a biology so these are the like uh you can see these are the options and which data I have use I have used a biology data so I can show you this particular data in the local itself so let me show you if you will look into this particular folder So Yesterday itself I collected a data inside this uh txt file so this is the file inside that from the Wikipedia I took the data in front of you only and here you can see the data you can uh pass any PDF or any txt file and based on that per subject based on that per data you can generate a McQ and here you can see the McQ and this is the like review the review actually right so uh we were evaluating the quizzes after generating a quizzes right so we have seted the limit in uh 50 wordss you have to evaluate the U the quizzes whatever quizzes basically we are going to generate so here you will see the review also on top of the UI so each and everything you will see uh inside the like uh inside the like front end itself here uh basically which we are using and if whatever number you are giving let's say 5 6 7 8 91 that many quizzes you will be able to generate now see uh before I was running this code in my local now let me show you both of the code so this was the code actually I was running in the local but uh it was giving me some sort of a issue uh don't know it was related to the maybe uh this library and all so see before the session itself I was testing with my uh same application actually uh like this is the same application only with uh with this particular application I was testing so I just run this one in front of you and I shown you how the output and all it will be looking like maybe uh in this uh application there is something wrong uh with respect to the library and the version or maybe I have uh given some wrong line and all I will have to debug it and the same I will uh I will uh like uh I will run inside the neural lab also but not today in tomorrow session and right after that I will deploy it but I just see I just want to show you the how the UI it looks like so here actually uh I run this particular application in front of you the same application the McQ application itself which I was I have created now how this looks like how the UI and all looks how the UI and all it looks like each and everything you can see over here and this is a by default Port where my streamlet application is running so 8501 right so whenever you are running your streamlit application so by default it will be running on this 8501 flask always take 5,000 port and this streamlit always take this 8501 Port right so don't uh do a mistake over here if you are running this application now how the answer will be looking like so it will looking like in the form of table and each and every code I have mentioned over here if you will go and check right inside the stimulate application now if you will look into the code so it will be more clear to all of you right so just looking into the code so here I'm say okay so this is the parameter basically which I'm going to print over here on top of the terminal and after that you can see I have mentioned one if condition so whatever response and the Dig right so is is response type is d i I'm saying yes so what you need to do in that case you need to exted the quiz then you need to pass this quiz to your get table data so from there you will get a table data now you are going to convert into a table and you are going to display that uh like you're going to dis see you are going to convert this table into a data frame and you are going to display it on top of the steam lit on top of the Steam on top of the basically uh UI so here uh this is the code this is the code actually this this one which you can see this one so display the review in a text box as well so here I'm going to display the output on top of the UI by using this particular code this particular line and rest of the code is a simple python code which I already explained you got it so this is the complete application now don't worry in tomorrow session uh again I will run it I just need to run it okay and again I will see I shown you the setup of the neural lab but in neural lab also I will run it and whatever project I'm going to build from now onwards I will be building in the neural lab itself so you can practice with the neurol lab and yeah tomorrow will be the deployment day and along with that I will explain you the concept of the vector databases so we'll try to discuss the vector database that what is a vector database and uh uh will try to understand the pine cone I will explain you the the pine cone actually how to uh like use that pine cone how to create a API key of the pine cone and how to store the embeddings and all what is the difference between normal databases and Vector based databases each and everything we're going to discuss in tomorrow's class in tomorrow's session okay and yes deployment I think it will take half an hour not more than 45 minute we are going to deploy it on over the AWS and and I'm going to use the ec2 instance uh I will show you along with the docker also so after creating a Docker image that how you can deploy that Docker image over the ec2 that process also I will show you regarding this particular application and yes right after that we'll start with the vector databases and uh then couple of Open Source model like Google pom is there Falcon is there or Jurassic is there so I will take one class for that and finally uh we'll start with more advanced project so one or two uh like other project actually which I have planned for all of you so uh with not with steam lit this is just a basic project which I shown you along with the flask and fast API also so um yeah stay tuned with us subscribe the channel like the hit the like button also if you're liking the content and if you are getting any sort of a issue then uh you can you can write on the inside the comment I'm monitoring each and every comment immediately I will reply to you uh resources wise you can check with the dashboard and uh yes video will be available over the dashboard as well as on a YouTube channel so you can uh watch on a both platform got it so how was the session guys uh are you able to run it or not don't worry I give you the complete code in a resource section from there itself you can download it here is my GitHub so here in the GitHub itself uh where is my GitHub where is my GitHub so this is my G so here itself I will upload all the code just uh forkit star it or or just keep it with yourself okay my just keep my username so from here itself you can download the entire code and don't worry the same link will be available in my resource section also got it yes or no tell me guys fast yes fine now uh here guys uh this is my project now first of all let me show you how this a project looks like um let me run this particular project so for running this project let me write it down here uh let me clear the screen okay now here let me write it down streamlit s r e a m streamlit run and here then I need to provide a streamlit file so streamlit dopy streamlit run streamlit app.py this is my file name now as soon as I will hit enter so my application will be running so here uh guys you can see my application is running just a second yeah so my application is running and this is my application just a second just uh wait yeah so this is my application guys now here you will find out we have a different different option so here you can upload your file and based on that data based on your uh based on that specific file you can generate a McQ you can provide a number like how many mcqs you want to generate here is a subject so whatever uh subject is there related to the data related to the file you can write on the subject and here is a complexity label so you would like to keep it simple hard or intermediate so let's try to upload one file over here so here already I I kept one file data.txt in my previous class only I shown you that now let me show you what we have inside this particular file so once you will open this data.txt uh so here actually this uh test.txt data.txt data.txt basically is what it was my in my another folder so I can take anyone or from anywhere I can take the data file so let's do one thing let's try to create one file okay from scratch data file and that to I'm going to create on my desktop so here uh let me create on new and here is my txt documentation now inside this particular file I'm going to paste my data so let's open the Google and here search about the AI so let me open my Google and let me search about the artificial intelligence now here I will get a article related to artificial intelligence let's say I'm opening this Wikipedia and I'm going to copy the article from the uh from the Wikipedia itself now I copied this article and I'm going to keep it inside my desktop inside my text one right now I can save it also so let me save as uh let me save as as a AI document right so AI doc so this is what this is my document which I saved now let's say if you have any sort of a information inside your text file inside your PDF so you can upload it over here so let me show you where you can upload you can upload lo you can pass it to my application now just click on the browse file and take a data from the desktop and here already I have this AI doc now open it and here guys you can see my file has updated now you can give the number of McQ now how many McQ you would like to generate so let's say I want to generate five McQ so here I'm giving number five so you can increase or you can decreas also from here itself now you need to provide a subject so here I'm writing artificial art artificial intelligence right artificial intelligence so here is what here is my subject okay so here is a restriction of the word so let me keep it like this in G and C so I can increase actually I can increase from the back end or otherwise I can write it down like this AI right so AI is fine my subject is what AI in a short form I have written it from back end actually I have given this restriction you can check with my streamlet file there I have already mentioned I can increase the number and then it's going to take like more than 20 words right 20 character actually now here I can provide the label so here the label is going to be a simple right I'm just going to create a simple uh simple McQ simple five McQ now once I will click on this create McQ so you can see my model uh is running in backend and here it will give you the answer so let's wait for some time and yes it will give me the answer yes Vector database Al Al will be covered in a live class yeah so if we are talking about the prerequisite right so I got one question actually so the prerequisite for the generative AI course is nothing just a python if you have basic understanding of the Python so just look into the project see guys here I'm able to generate a question so here I'm able to generate an McQ just just look into the McQ so uh it's a sens ible only right so what is the field of the study that develop and studies intelligent machine so here it has given you the various option like artificial intelligence machine learning computer science robotics now this is the second one which of the following is a example of AI technology used in a selfdriving car so it is giving you the various option right so uh chat GPT bimo right Vio or YouTube Google search so like it is a sensible one and here you will find out the a correct answer so it is giving you the correct answer and it is evaluating the quizzes quiz also so here you can see the quiz evaluation now uh one question basically I got and it's a good one so uh what is a prerequisite uh if you want to if you want to start with the generative AI so the just just look into the project guys what I have used over here just tell me if you have a basic knowledge of the Python if you just have a basic knowledge of the development so yeah um you can enroll into the generative a and even if you don't don't know about the python then don't worry our prerecorded session of the Python will be available over the dashboard from starting to end and apart from that like you can see regarding the development each and everything we are going to teach you in a live class itself from various skch from folder creation to deployment right so we are creating a folder in a class itself in a live session and we are doing a live coding in front of you and after develop after developing our application we are deploying it also so from starting to Advance right so from scratch to advance everything we are doing in a live class and the prerequisite is just a p just just python okay so don't worry about the uh this uh prerequisite and all already like uh the python and all will be available over there you can learn that first if you don't know and then you can proceed with the further thing right now here you can see this is the application which I'm able to create now what I want to do I want to deploy this application over the cloud right now here guys see this is the first application and many people are beginner one right and they don't know about the advanced concept Advanced mlops concept Advanced devops concept cicd and all so let's try to keep it simple let's try to deploy it over the ews there I'm not going to use a cicd concept in my next project I will show you how you can uh use the cicd a concept how you can uh create a like continuous integration continu deployment Pipeline and how you can deploy the application and even I will include the docker also here I'm keeping simple simply I'm creating a server on top of my AWS machine and there I'm going to deploy my application so let's see how we can do it so for that guys see the first thing what you need to do so the first thing you need to create your account on AWS the application we are going to deploy we are going to deploy on AWS so here what we are going to do guys tell me so here we need to create account on AWS now here you require a credit card debit card actually AWS does not ask you the credit card it ask it you can add the debit card also and it won't charge you anything directly right so believe me it won't charge you anything first it will ask you first it will tell you then this this this much of will like you have generated and like you can wave off also right or in the worst case you can delete the account so it won't like harm you it won't deduct any sort of a money from the account now the first thing which is required that is the AWS now here in the AWS we are going to use the ec2 server for deploying our application so first we'll try to configure the ec2 server and here uh for uh in ec2 actually we are going to use the Ubuntu machine right Ubuntu machine so that is the first thing basically which is required for the deployment now the second thing which is required that is a GitHub so just make sure that you have kept your project over the GitHub so what I'm going to do I'm going to upload my project over the GitHub I'm going to create a repository which I already did right I have like I have I have done in my previous session itself so there itself in my repository itself I have kept my project I have uploaded my project right so the first thing which is required which is a AWS the second thing which is required that is a GitHub that's it right so let me show you how to do how to deploy this application over the adws how to deploy this application or the ec2 instant where I'm going to use this Ubuntu Server right now uh GitHub so first of all let me give you the GitHub so at least you can follow me uh throughout this deployment process and here we have to run couple of command so I will give you those command also so at least you can run inside your uh instance inside your server right so here guys what I'm going to do I'm giving you this GitHub link just a second I'm going to paste inside the chat if you're not able to click on this link right so what you can do you can uh go through with the Google uh you can open the Google and you can search about s Savita GitHub so there you will get my GitHub ID and there just go inside my Repository and open this project open this gen AI project this gen AI so now guys see I already kept my project on my GitHub if you don't know about the GitHub and all then you must uh uh visit my previous session there I have discussed each and everything from scratch I'm not going to repeat those things otherwise we won't to Able we won't be able to cover the further thing further concept now here is what here is my uh here is my project right so I believe guys you all have you all kept the project in a GitHub itself you can uh download it from here as a jib you can clone it inside your repository everything is fine for me now but at least the project should be uh inside your system and then you need to upload in your GitHub right so this is my GitHub if you are opening it guys so this is my GitHub right so uh now what you need to do see if you're are going to Fork it that will also work okay that also you can do but the best thing what you can do just download it and keep inside your GitHub because uh whenever you are going to deploy it now so you're not deploying from my GitHub you are deploy from your GitHub so the project should be available over there because you will have to clone it now you will have to clone it right now uh here uh let me show you the ec2 instance right so how the ec2 instance uh looks like and all so the first thing guys what you need to do so I'm uh starting from very scratch no need to worry about it so just search about the EC tool so just open your uh AWS now let me show you about the AWS also um if you don't know about the AWS so here go open your Google and search AWS login so just simply search AWS login now here you will get a link so uh not this one actually this aws.amazon.com just open this aws.amazon.com just click on that and here guys here you'll find out your AWS right now it is asking to you uh would you like to create the account or you want to login so what I want to do I want to login because I already created an account and creating account is not a difficult task on a WS it's very easy it's very simple you just need to provide your detail over here whatever they are asking and simply create the account and it will accept your debit card also if you have enabled the international payment into your debit card so definitely you can add on over here and it won't charge anything first it will ask to you and you if you will approve then only it's going to cut it down cut down the payment but don't worry we can weev off also I will show you how you can weev off your money and you can delete the account if uh like you have launched so many instances and you generated like too long bill now here you can see this is what uh like this is a creating step like if you want to create an account now just click on the sign in Just click on the sign in and after clicking on the sign in right so here uh I already signed in so here it is giving me the homepage now guys uh what you can do so here you can search the ec2 instant just go inside this search box and here search the ec2 right right ec2 now click on this ec2 so after clicking on this ec2 right so it will give you the various this is the interface this is the home interface right of the ec2 so here it will give you the various options so no need to do anything just CL click on this launch instance right just just click on this launch instance so here after clicking in the launch instance it will give you one form right you just need to fill up this form and you will be able to launch your instance so you just need to provide some details over here and that's it so tell me guys how many people are following me please write down the chat and let me look into the doubt also so how much long this free generative AI boot camp will be so this a free generative AI boot camp uh like uh we are going to continue till next week so this week and the next week right so there is couple of concept which we need to discuss and couple of project as well so one basic project one advanced project and like few more concept do we need to learn ML and NLP learning for Gen VI please advise no ML and NLP is not see let's say there's different different kind of person so let's say if you're are beginner right and who don't know anything let's say who don't know anything and the person who want to start from the generative AI so for that person I already told you if you have a basic understanding of the Python then definitely you can start with the generative AI right so by learning the generative AI definitely you will be familiar with the basics of ml NLP and all automatically you will learn that but let's say there is one more person who is familiar with the ml statistic basics of ML and all right so yes the this is like a good thing he knows about the basics so definitely he can start with the generative a now there is one person who knows everything who knows about the ml DL NLP so that is well and good means um nothing can be better right so definitely the person uh can start with a generative AI so in every case you can start with a generative AI there you just required a python knowledge and if you are if you have a knowledge of the mlop if you have a knowledge of the NLP DL ml so yeah your understanding will be much clear over there getting my point so for every person the scenario is different so just think about your scenario but I would tell you that in every case in every scenario you can go with a generative AI right even nontechnical person can enroll who don't know about anything right anything about the programming and theend okay so guys uh how's the session so far are you enjoying it tell me did you open this AWS page if you have any doubt you can ask me in the chat and then I will proceed further do we cover any mlops topic yeah we are using the mlops concept only now tool wise yes we can use the tool so we can use DVC ml flow or different different tools like yeah we going to use Docker G already we are using right so uh whatever is required according to the infrastructure and all definitely we can use it right and don't worry in the upcoming project we'll show you that also yes you will get a python video over the dashboard yes uh Amrit fine so I hope uh here you can see uh like here I have the ec2 so here I have click on the ec2 and I click on the launch instance now here you just need to provide the name so if you like just provide the name any name over here so here I'm saying McQ generator right so here I'm writing McQ generator this is the name of my uh instance now once you will uh scroll down so here you will get a option uh like here they have provided you a different different machine right so they have provided their own machine own Linux system Amazon Linux they they are providing you the Macos they're providing you the Ubuntu Windows right redit is there so different different like variant different different variant you will find out of the Linux and even Windows server is there so here we are going to select this Ubuntu right so here we are going to select this Ubuntu so just click on this Ubuntu after clicking on this Ubuntu so here it is giving you the free tire but uh here my application actually I I cannot I cannot take a chance I'm not using the free tire over here so as of now what I'm going to do I'm taking taking any larger instance so here okay so free tire is fine now what I can do yeah free tire Let It Be Free Tire okay so uh how to select the major instance let me show you that so here is the architecture so keep it as it is and keep it uh like free tire this one now here guys just just see free tire eligible just just click on that just just click on this drop down right and here instead of the t2 micro just select anything right apart from this T2 micro you can select uh either this small or you can select this medium or large so here I'm going to select this large one because as of now I don't want to take any uh chance so let's say if I'm selecting this medium or maybe small so maybe uh with this particular system my uh like this app is not going to be launched or maybe if I'm installing the requ txt and all it is giving me some sort of error I'm not going to take any chance and here I'm selecting this T2 large but guys uh you can select U like this uh small one also and the medium one also right but in my case I'm I'm taking this large where it is giving me where it is giving me this uh 8 GB memory and here you can see the pricing and all but don't worry after the uh like after the session I will stop the instance right I will show you how to stop the instance now after selecting this instance okay after selecting the instance type what you need to do here you need to create a new pair right so create a new key pair so here for creating a new pair so once you once you will click on that it will ask the name right so here I'm giving the name so let's say the name is what uh McQ ke right so McQ key and here uh generate this a pem file right private key file format if you want to do SS or if you want to connect the this machine by using the puty or by using the SS so here this a key will help you right here this key will help you now create the key pair and it will ask you for the download so yes download it somewhere inside your system so I'm going to save it and I am done now you did two three things first you selected this ubu machine the second you selected this instance type and the third one you created the pair over here that's it now keep rest uh see here one more thing uh the fourth one actually you just need to click on this one right so just just click on this one just allow HTTP https and HTTP traffic also and keep it anywhere not no need to provide the specific IP address over here keep it 00000000 it's a global one and keep it anywhere uh you won't face any sort of a issue right so now guys this is done and one more thing I can do over here is asking to me a storage so I can increase the storage as well so instead of the eight I am going to take let's say 16 right so here is my storage right so here is my storage and I hope now everything is fine I just fill up the form and once I will click on this launch instance so it will be launching my instance so are you doing along with me are you launching the instance tell me guys now see guys it has launched the instance now once I will click on this one uh so it will show me the instance and here the status is pending as of now tell me guys uh are you doing it along with me are you writing are you doing are you deploying see I have already given you the code I already given you the GitHub you just need to download it and keep it inside your GitHub and then you can follow the steps I'm going very slow and don't worry I will give you all the step in a document format also yeah so let me refresh it and let me check it is working or not yeah it is running now so see guys my status is running right instant state is running now just click on this ID just uh click on this ID and here click on this connect button right so what you need to do here tell me guys so once uh so click on the ID click on the instance ID and click on this connect button after that here it will give you the uh like option so here again uh like it will give you it will ask you for the connect connection so just click on this connect and and now your machine has launched so this is the machine guys this is the machine which we have launched now we'll configure this particular machine according to our requirement right so this is a machine basically which I got from the uh AWS side which I launch over here now I will configure it right so for configuring this machine I have to run few step so the first step which I'm going to run over here the step is Pudo AP update right so here once I will write down the the Pudo AP update so my entire machine will be updated right so here my machine is getting update and don't worry I will give you all this command I will keep it inside the GitHub itself uh so let me do it first of all let me show you and then I will provide you the command right so here guys you can see I have updated the machine or what I can do I can open the txt and there itself I can write it down so all the commands which whatever I'm running now the First Command which i r that is that is what that is a suit sudo AP update so that was a command which I ran now after that I will run one more command uh so here on the terminal itself I'm going to run one more command that's going to be a Pudo Pudo a AP iph G update so this is a second Command right sudo AP hyen G this is nothing this is just a package manager right so this AP AP G so I'm updating it uh the machine so here now everything is up to date so sudo AP update and sudo AP hyphen get update now let me write it down here this two command so the next one was sudo AP hyphone G update right so this is the second command now the third command which I'm going to write it down here that's going to be a pseudo up AP upgrade okay upgrade upgrade hyphen y right so this is the third command which I need to run Pudo AP upgrade hyphen y now let me open the machine and here I'm writing Pudo AP upgrade gde upgrade hyphen y right so here you can see my um like machine is getting upgraded so this three command which whatever I have written over here you need to run it on your terminal for updating your machine right so yes it is running let's wait for some time yeah still it is running and it will take some time here is a command guys this one if you have launched the system uh if if you have launched the machine so you can execute this three command sud sudo AP update sud sudo AP hyphen get update sud sudo APD upgrade hyphen y right great so here my machine is updating and it will take some time until if you have any question anything you can ask me yeah so here actually I just need to hit the enter if you're getting this uh warning so just hit enter and again you need to hit enter over here right so once you will hit enter it will be updating it so what's the meaning of this three command so just look into the command what we are going to do I'm saying Pudo Pudo means for the root user APD update right so APD is a package manager and what we are going to do we are going to update our machine by using this up package manager right so here we are going to update and upgrade each and everything uh inside this particular machine and now everything is done now we have updated our machine here you can see we have updated our machine now I have to install something here right I have to install something over here now for that again we have a command the command is going to be pseudo AP install right pseudo a install I'm going to install this git I'm going to install the curl right I'm going to install this unip and here I'm going to install this tar make right and here I'm going to install this sud sudo Bim Bim is what it's a editor right now here does w get so these are the thing these are the like uh these are the thing basically these are the software we are going to install by using this sudo APD install we are going to install this git call unip tar make and this Bim editor and here is W get now once I will write down this hyphen y so here you can see everything is getting installed over here now here everything is done so now if it is giving you this particular uh window so you just need to hit enter and let me do one thing let meit enter yeah here also and yeah it is fine so it is done guys now let me check one more time let me copy and paste over here the same command and I'm checking everything is done or not yeah everything is done see here right this is giving me already the newest version newest version newest version right now see guys my machine is ready I have updated the machine I have installed every software whatever is required now what I will do here I will clone my repository right so here is my repository guys this one so here actually I kept the application the entire application whatever application I'm running inside my system now you just need to clone this repository over there on top of that server right so here is my ec2 instance and here if you will write it down this get clone right and just provide the link right just provide the link of your repository now here guys see uh here is a repository link and hit the enter so it will be it will clone your repository and you can check it also so just just type this LS and here you can see this is your repository now you will write CD here CD means what change directory so just write CD and check uh with this particular Repository so here guys you can see I'm inside this folder I'm inside my repository now WR LS so here you will find out out all the file so here we have a response streamlit experiment means one folder McQ generator my main file here you can see require. txt setup.py and test.py and test.txt so I have the entire file now guys see uh here actually we have we are using the openi API if you look into the EnV envir in file so here actually what I'm doing I am creating one variable the variable name is what open a API key but here one we have an issue right so what is the issue you cannot upload you cannot upload this open AI API key you cannot upload this open a API key on GitHub right if you're going to update it so automatically it will delete right so this open actually don't know like what type of codee they have written so if you're going to upload this uh like this key on any uh repository okay in any public repository automatically they will detect it and they will delete it right so actually we cannot upload this particular folder this EnV folder on my GitHub right so there is a issue there is a issue so what I will do here so I'm going to create the EnV folder EnV file over here itself in my machine so for creating a file there is a command the command is what don't worry I will give you all the command first let me show you first let me run it so here is a command the command is touch right so here if I will write it on this touch and here if I will write en EnV do EnV so you can see uh let me show you so here I have created this EnV file right so it is not visible let me show you with ls hyph a it is a hidden actually this do file actually it's a hidden file now you will find out this EnV yes we have this EnV file now what I will do I will open this file by using the vi editor VI or VI editor so once I will write down this VI and here I will write down this do e and V now here guys see I have opened this file now after opening this file you just need to press insert right in your keyboard there's a button the button name is insert just press the insert now you can insert anything over here now what I'm going to do so here actually in my local I have my openi key just copy the key from here and keep it inside your en so let me do it uh let me directly paste it over here after copy see guys so here open I key and I pasted it now after that what you need to do you just need to press escape button so press the escape button it will be saved now if you want to come out from here so for that you just need to press the colon colon and WQ so here you can see uh like in the bottom bottom left bottom so there I written cool and WQ now hit the enter and you will be out from the vi editor right so here I created a file the file name was EnV and inside that I kept my open key now now if I will write this cat Dov so here you can see whatever content is there inside the EnV file I am able to see on my terminal right so open a API key and this is what this is my API key now guys what I will do here I will install all the requirements into my machine so here we have a requir txt file so what I will do here I will write a simple command and see guys if you are using Linux machine if you're using Mac OS so instead of writing pip or instead of writing python you all you must uh uh you must write over here pip 3 right so here what I'm going to do I'm going to write down pip 3 pip 3 uh install pip 3 install hyphen R require. txt right so this is my file name now I'm installing all the requirement in my machine so here once I will hit enter so here you can see uh okay it is asking sudo AP install Python 3 fine guys so I forgot to install python over here it is giving me a command see as soon as I've return this P inst install hyphen ar. txd it is giving me an issue it is giving me an error that pip 3 not found because I forgot to run one command here the command was for installing the python so let me write it down over here Pudo Pudo AP Pudo AP install so here I'm writing sudo AP install and after installation after install what I will write I will write python python and Python 3 Hy pip okay okay so this is the command which you need to write it down Pudo APD install Python 3 hyen pip so once you will hit enter now here you can see now here you can see we are able to install the requirement so yes we are going to install this python now once I will press yes here so now I'm uh able to install it and it is installing in my system yeah so if you getting this warning just press enter and here also now everything is done so see guys uh here is what here is my complete python which I downloaded in my system which I installed now let me do one thing here what I can do on my machine itself I can install the requirement file so for that let me clear it first of all and here I'm writing pip install iphr requirement. txt now let's see okay pip install the command is PIP install inss install I think now it is perfect yeah so see I installing all the requirements over here what is the issue we faced yesterday on top of the neural lab there was not the issue actually if you will use my updated code right so I updated everything over there so uh like it will be running the issue basically it was the uh regarding dependency maybe it took python 3.8.0 because of that only it was giving me the library issue but if you are using uh now just do one thing use equal to equal to sign over there pip install sorry cond create hyphen uh cond create hyphen P environment name python equal to equal to 3.8 so it will take 3.8.8 right so it won't give you any such of uh any any issues and all right now here guys see I have installed the require. txt now what I will do here I will run my application right after setting up the machine after installing the python after installing the requirements and all now here what I will do I will be writing stre stream late right so let let me give you the command there is a specific command for that now here is the command so let me copy this command and let me paste it over here so this is the command guys don't worry I will give you all the commands and I will revise this thing uh then I will give you that so here is a command Python 3 hyphen M streamlit run and here I need to provide my file name I'm removing this app.py and here I'm going to write down streamlit app.py right so here is a like file name streamlit app.py so this is the complete Command Python 3 hyphen M streamlit run streamlit app.py right so let me hit enter now and here you can see my application is running now how you can access this application so for that let me show you so just go through with your instance right now here is the instance here you will find out the public IP address right so here you can see this public IP address just just copy this address and here just open your browser and um then paste your address after copying this address copy this U public IP address and uh put the colon and here you need to mention the port number so by default actually this uh this one this application ring on 8501 right on 8501 now if I will hit enter will I be able to run it no actually we haven't configured this particular port number right so what I need to do here let me open my application now here just go inside this security right and uh here just a wait so let me go back ec2 instance here is a instance yeah now open the instance by clicking on the ID now here guys you will find out so this inbound rule let me show you that inbound rule yeah so here just click on the security group right and after that you will find out the uh this particular rule so just click on this edit inbound rule this one after Security Group Security Group info and addit inbound Rule now here add rule right now just keep it custom TCP and here you need to write it down your port number so your port number is what 8501 and then keep it custom and click on this uh just select this one anywhere only now everything is done so here you need to keep it custom TCP then uh give your port number here and keep it anywhere that's it right now save the rules that's it okay and uh let me do one thing I think uh this is running so let me first press press control+ C and again I can run this particular application so yeah now it's perfect uh so just go through with your application here and here itself you will find out the here itself you will find out the IP address so let me open the IP address just a second instance running now this is your instance McQ generator click on that and here is your IP this one 52 this one this is your IP right 52. 20414 and 155 now copy this ID and paste it over here in your browser so now let me check 155 yeah it is correct so just uh press the colum and give 8501 now once you will hit enter so you will be able to find out your application over here just a second it is running let's see yeah so here guys you can can see I have deployed the application and now you all can access this particular application I'm giving you inside the chat and try to generate the try to generate the mcqs from here now let me do it I'm giving you this particular link inside the chat just click on that and try to generate it now here if I'm clicking on this browse file now it is asking to me it is asking me about the file so here I'm giving this a do just open it and give the number of cues let's say I want to generate four mcqs here uh write the subject name so my subject is going to be Ai and here write the simple and then create McQ and it is loading here you can see guys it is loading now see let's see it is able to generate or not are you doing it guys along with me have you uh like run any sort of a command don't worry let me give you all the command at a single place and then you can check you can run inside your system I will give you 2 minute of time yeah so here you can see I'm able to generate a quiz so what is the field of study that develops and study intelligence Machin so these are the choices and here is the answer right whatever correct answer is there now review is also their review about the McQ now click on this uh so just just go through with this URL and you also can generate now someone is asking me sir how we can save it right for saving the code prods for saving this McQ in a PDF file in a CSV file so already I shown you the code in my previous lecture if you will go inside the ipynb file so here I already kept the code so this is what this is what my code actually uh where is where it is where it is uh just a second just a second yeah so here was the code actually I converted into a data frame and here I converting into a CSV file now see uh I'm converting into a CSV file but you can convert the CSV file into a PDF or you can uh generate a direct PDF from here also right you just need to look into that and you can append this same functionality inside your end to application also so if you you you can give one option over there download option so whatever McQ you are getting now on top of your steamate application here itself see uh here uh whatever uh mcqs you are able to see over here right so you can provide one button over here right hand side download button so once the person will click on the download down the script will be running in a back end and you can download this McQ in a CSV file or in the form of uh PDF right so this you can take as assignment where you can append one button one download button and you can write it down the code write it down the functionality okay in a in a python actually you can uh like you can create one file or maybe inside that streamlet itself you can uh like append this download functionality right you can you can append this download over there and whenever someone is hitting the download this all the mcqs will be downloaded in the form of CSV right so just take it as a assignment and try to do it and you can send it to me on my mail ID or maybe on my uh yeah so you can uh ping uh you can ping me on my LinkedIn and you can post it over the LinkedIn also right so after creating this if you are going to post it over the LinkedIn I think that that is well and good so uh and uh yeah so let's say this is your first end project and let's say first time if you learning the generative definitely you should uh you must share the knowledge over the LinkedIn as well so you can uh post it over there and you can tag me and all you can tag the Inon I think that would be fine now uh here see we are able to create the application we are able to deploy it I haven't shown you the cicd one I this is the manual approach which I shown you I kept the cicd for the next project I can show you here also I don't have any issue I can write it on the workflow I can deploy the application that not going to be difficult but as a beginner first you should adapt the like basic approach you should understand the server and all and uh you should be familiar with the AWS and then in the next project we are going to do it from scratch right so I will show you the complete cicd and yeah definitely in our course uh we have included so many projects so there uh we are going to deploy it over the different different platform AWS a your gcp and we are going to use AWS ECR okay or this AWS ec2 app Runner and this uh like different different services like elastic code commit uh elastic be stall code commit even uh Lambda function right so different different uh thing different different Services of the AWS we are going to use and we'll show you how uh you can create or and an application in how you can create a production production based pipeline right so this thing is clear now if uh it is clear then definitely we can move to the next topic but before that let me give you all the command which is required and let me keep everything inside this uh txt itself so see the first thing what you need to do guys for deploying this application first login to AWS so first login to the AWS and here I'm giving you the link of the AWS so you can uh login with that particular link M just a second AWS login now let me give you the link of the AWS yeah so here first you need to uh log to the aw the second what you need to do guys you need to like launch the ec2 instance so search about the ec2 instance search about the ec2 instance now after search searching the ec2 instance what you need to do the third place uh you need to you need to configure configure the ubu machine ubu ubu machine machine right so that's the third thing now fourth one actually what you need to do after configure the one to machine launch the instance right launch the instance that's the fourth step after launching the instance what you will do after launching the one two instance so you need to update this by using a different command so I will give you all those command three command I have already written over here let me write it down the uh further command so here is the thing update the update the machine right so update the machine and here is all the command let me give you forur command uh here is upgrade now this is going to be a next one and here there is going to be next you need to clone your GitHub repository and after that there is a next command so sud sudo AP install this is the next now here uh pip install regard. txt and here this is going to be a next command for running your application so if you want to run the application now here is a command and the app name is what stream St stream lit app right so this is the command which you need to run right and then finally copy the IP and huh uh then what you need to do guys you need to add the environment file EnV file also so for adding that uh there is a command let me write it down over here if you want to add open AI API key so here the first thing create create Dov file Dov file new server right so create do EnV file in your server now here after creating this EnV file how will you will create it by using this particular command touch. EnV now here what you will do you will insert you will press insert so press insert insert and then write it uh no after creating that you need to open it and actually by using the vi editor so VI and that WR Dov then you need to write it down some command so press insert from your keyboard and after that after pressing the insert you have to write it down something so copy your API key and paste it there and paste it there the next one actually the next is going to be so after the copy you need to save it so press escape and then colon WQ so colon WQ and hit enter right so hit enter so that's going to be a step now after adding the API key what you need to do so yeah this will be done then uh this is the step for adding the API key now yeah inbound rule so go with your security go with your security and add the inbound rule right so here actually you need to add the inbound rule there add the port add the port 85 01 right this one so this is the complete detail of the deployment which I have written over here now let me copy it and let me paste it over here inside your inside my GitHub itself so here is my readme file uh I don't have readme file so don't worry I can edit create a new file my file name is what readme.md just readme.md and here yeah so this is the entire command which I kept over here now let me click on the commit changes and here I'm going to commit so see guys this is the entire process for the deployment okay now let me give you this link so you all can do it inside your system so this is the link guys uh which uh where I kept all the steps you can follow it and you can deploy your first and to and uh first application basically now tell me yes this file will be available inside the notes don't worry don't worry about it so let me check with more doubts this uh file you will get inside the dashboard see this is a dashboard guys this is a like Genera VI dashboard now again I can give you this link inside the chat and already you can see my team has updated right so inside the chat if you will check with the pin command so my team has updated the link of the dashboard right and just go through the Inon platform just just search about the Inon okay just open your Google search about the Inon and this is the homepage now here in the courses there is a section Community program so just click on the community program and here itself you will find out the category so just click on this generative AI so there you will find out all the dashboard so here you just need to click on the English one uh here we have a Hindi dashboard as well I'm taking the same lecture and On Hindi YouTube channel so yeah we we have a Hindi dashboard now here is a English dashboard and this is a community session of the machine learning so each and everything you can find out over the Inon platform let me give you the uh this particular link so that you can log in if you are new guys so that uh so please try to log in on this I own portal how how we can apply llm for business inside chat like interacting with DB and perform complex computation task yeah that only we are going to discuss now so we'll talk about that how we can uh like create a complex application here the foundation I think the foundation is clear to all of you now we'll come to the advanced part where we'll include the databases where we'll try to create few more application like chatbot and all and yeah that thing will be clarified to all of you just wait for some time so tell me guys how's the session so far do you like it so please hit the like button if you are liking the session uh and please do let me know in the chat also how's the session so far because we have completed a one phase now we are entering into the second phase yeah waiting for a reply so please write it down the chat you are not getting any link uh linkwise don't worry my team will give you that give uh that particular link inside the chat itself if I'm not able to paste it then but I past it actually I I can see here in my chat here we have already pinned one comment just just look into the Pinn comment so there you will find out a dashboard and you can navigate the entire dashboard and all entire website from there itself so just check with the pin comment so deependra has given to me this uh IP and this uh Port so let me check it is working or not he's saying sir I'm following you and this is my IP and my port actually no see it's a wrong I think just check once thein I think uh there is just like uh in IP V4 actually we have a four segment now so just look into your IP I think you pasted a wrong one see this is the correct right great so let's start uh with the next topic and that's going to be a vector database so we have completed a one phase of this uh Community session now it's a second phase of this community session where we going to start from the vector databases and then we'll try to do few more advanced uh like we'll try to solve few more advanced use cases so the first thing is basically what is a vector databases so how many of you know about the vector guys tell me do do you have a basic idea about the vector what is a vector and uh have you learned in machine learning in statistic great so I think uh we can start just allow me a minute great so let's start with the vector database few people are saying they know about the vector databases and the vector is nothing they have learned in a mathematic they have learned in NLP and all so uh let's try to understand the fundamental of the vector and the fundamental of the vector databases so if we talk if we talking about this Vector database so here you will find out that so we have a data right so this data actually we are going to convert into a vectors so Vector is nothing just a set of numbers right it's just a set of number geometrically I will explain about the vector in a lit term also I will about I will explain about this vector now here you can see this Vector actually we are going to store somewhere and that is called a vector database right so we have a data we are going to convert that data into a vectors and then uh basically this Vector we are going to store somewhere now here you can see one specific term the term is called Vector database now apart from that like we have other database also like SQL base database right we have no SQL databases so why we are not using those databases for storing the embedding for storing this data what is a disadvantage if directly we are storing this data into this SQL based SQL based database or maybe in no SQL database so what will be the disadvantage why we are converting this data into our vectors and then we are storing inside the vector databases so first of all we need to understand this a particular this this problem statement now uh for that what I can do let me move into the slide itself and here I have kept those uh thing now first of all uh let me uh show you that what all thing we are going to learn inside this Vector database so if we talking about the vector database so we're going to talk about what is a vector database why we need it what is the need of this Vector database how this Vector database is how will this Vector database work use cases of the vector databases some widely used Vector database that of like different different databases we have now so we'll try to understand the use of those Vector database will understand the Practical demo as well practical demo using Python and Lang chain so uh yes we are going to create an application there we are going to use different different Vector databases like pine cone and web chroma DV there are a couple of name and more than uh like uh this one actually three so we have other databases also one from the open a side so we'll talk about each and every database here so uh here guys you can see uh what we are going to learn so already I clarifi the agenda now see uh what is a vector database so a vector database is a data Bas used for storing high dimension vectors such as word iding or image aming right so either we can store images or we can store in in the form of we can store the images or we can store the text right so directly we are not storing over here we are storing in the form of Ming so first of all we'll try try to understand the meaning of embedding over here right so what is the meaning of the embedding which I have written now what I can do I can open my uh Blackboard and here I can explain you the meaning of the embedding which I was talking about so guys see whenever we are talking about Vector so let let me write it down the few thing over here so let's say uh here I'm writing one number right so here I'm writing let's say uh two so what is this two tell me so if I'm writing two over here so this is what this is the scale scal value right this is the scalar value now uh here if I'm going to write it down let's say uh something else let's say 100 so this is what this is also a scalar value right it's a single value it's a scalar value now if you if you want to like uh showcase this value in a geometrical in a geometry right in terms of geometry so what I will do I will uh create the axis so here let's say this is what this is my Axis and here somewhere actually my value will be available this data so here let's say there is a two there is a 100 something like that now uh here this is called the single value actually it is called the scalar value now if we are talking about the vector so what is a ve Vector so before explaining the vector actually let me uh talk about so here I can give you one uh example so what I can do here just a second let me draw the AIS so here I'm going to draw the first AIS this is my first AIS and here is my second now let me take this particular Arrow just a second yeah so this is what this is my first AIS this one and here is what here is my second AIS right now let's say uh here what I'm doing so I'm uh anting this thing this AIS with the uh direction right so this is my North this one and here this is going to be my South right this is my South Direction now here is what here is my East and this is what this is my West right so this is my East and here is what here is my West Direction right now let's say one person is here right so this one person basically one person is here right now how you will see uh let me show you one thing so let's say one person is going in this particular direction from here to here right so let's say one person is going here here here here here let's say there is some sort of a magnitude right so let's say the person is uh uh person is walking around 5 km right so this person is walking 5 km in which direction in East direction right so person is walking 5 km in each dire in each Direction so here we have a magnitude magnitude along with that we have a direction right so along with that we have a Direction so what is the definition of the vector so Vector in the vector actually we have a scalar value and along with the scalar value will be having a direction also right so this is what this is my magnitude and here is what here is my direction the direction is e East now let's say if I'm going in this particular direction so from here from my origin this is my origin right now from here I'm going in this particular direction let's say I'm going to travel 4 kilm right 4 km so here I can say that I traveled 4 km 4 km in North direction right so this is what this is my magnitude and here is what here is my direction right now let's say the person is going over here the person is here basically here here right so how you will calculate it right so how you will calculate the distance so simply I can do it by using the Pythagoras Theorem so what I will do if I want to calculate a distance from my origin to this particular point so what I will do I will uh like uh I will do it by using the Pythagoras thorum now here uh you will find out see this is what this is my 5 kilm and here is what here is my 4 km this is my 4 km now uh this is what this is my 4 km this one this this particular which I took from here and here actually tell me guys what will be the distance from here to here so here I will simply use the Pythagoras Theorem this is going to be a 5 + 4 is equal to how much tell me 25 + 25 + 9 so sorry 25 + 16 so here actually we'll be having a 16 now 25 + 16 how much U 35 and 41 iting right so underscore 41 now here actually this is the magnitude of the person means from here to here now if we are talking about the direction right so what will be the direction of this person so here I can write it down like this underscore underscore 41 and here I can write it down this northeast right Northeast Direction so this is what guys tell me this is my Vector in 2D so this is a vector in 1D this is a vector in 2D right so this is a vector in 1D this one this is also a vector in 1D and here you can see this is what this is a vector in 2D now here you can see this is what this is my magnitude magnitude of the vector and here is what here is a direction actually this is what this is the direction now you can see the direction any now let's try to understand this thing with our X and Y right so tell me guys this uh example is clear to all of you because I'm coming to the embedding and I I will explain you the embedding but before that the vector concept should be clear right if uh and if you are not going to understand the vector so definitely won't be understand the concept the embedding tell me guys this thing is clear to all of you are you getting the concept of the vector here which I drawn which I uh clarify tell me guys fast I'm waiting for your reply if you can write on the chat so that would be great and then I will proceed further yes the vector definition is clear to all of you great now here see let's try to understand the same concept by using the XY AIS so here what I'm going to do I'm going to draw the axis let's say this is my xaxis right and here is what here is my Y axis this one is what this one is my Y axis right this one now see uh what I can do just a second let me draw it one more time this is my y AIS now uh let me unoted this one so here is the X and here is what here is a y so this is my x one and this is my X y1 right so this is a negative this is representing a negative and this is also negative coordinate now see guys here uh let's say uh there is one point right at this particular location this is what this is my point right now will be having some coordinate regarding this point tell me x and y coordinate yes or no tell me yes so this coordinate actually this X and Y right in this 2D space right in this 2D space actually this coordinate is nothing this is a vector right this is the vector so if I want to represent right so if if I want see this is what this is my point in 2D in two Dimension space now from here to here there will be having some magnitude right so it is having some magnitude from here from Orizon to to this particular point so this magnitude plus this is what guys tell me this is the direction the direction which I shown you over here by using this north east west and by using this uh like north south east west right so here now instead of that I'm taking this X and Y just just look over here this is what this is my point and from origin to this particular Point actually we have some magnitude right so there is a distance and here is what guys tell me this is a this is what this is the direction this is a Direction X and Y so let's say let's say what I can do over here so this x and y coordinate I'm assuming that this x is around I think five and this Y is around let's say four so here I can write it down I can represent I can represent this particular Point like this I can write it down over here five and four and this is nothing this is my Vector so in mathematics what is a vector so in mathematics magnitude magnitude along with the direction right along with the direction now how we represent this a particular Vector technically so simply if I'm writing like this uh like if I'm writing like this X and Y right and whatever value we have of the X and and Y so this is what this is nothing this is my vector and it's a 2d representation of the vector now let's say in my Vector I have I'm having X Y and Z let's say I'm having this three thing x y z so this's a vector in 3D space right this is the vector in 3D space now instead of this one let's say if I'm writing uh X1 here I'm writing X2 here I'm writing X3 and up to xn so here I'm saying it's a vector in N Dimension space what is this guys tell me it's a vector in and dimension space now the term Vector is clear to all of you what is a scalar what is a vector and how to represent this Vector it's a representation of the vector right and I started from here from this a particular direction and I clarify clarify this thing over here right so how to represent the N Dimension Vector so this is this X and Y is nothing it's a 2d representation of the vector this XY Z is nothing it's a 3D representation of the vector and this this is nothing this is the and dimensional representation of the vector clear I think this part is clear to all of you now I'm coming to the next one here actually we are talking about the iding now what is this embedding so let's talk about this embedding let me write it down here the name is embedding okay now see guys whenever we are talking about a model right so here actually as a model I'm using the llm model which model U I'm using the large language model llm means what large language model there are several large language model from open a from hugging face from Google meta and all right you'll find out that now here actually I need to provide a data to this a particular model right let's say there is what there is my data which I'm going to provide to my model right now actually see this model is nothing it just done mathematical equations right mathematical equations so we are talking about the llm model so this llm model this large language model actually they are using a Transformer architecture they are using Transformer architecture as a base architecture which architecture Transformer architecture as a base architecture so here in the Transformer architecture we have two things one is encoder and the second one is called decoder right now just think about this encoder and decoder here actually what we are doing tell me here actually see we have a attention mechanism we have a neural network right we have a normalization so these all are nothing this is just a mathematical equations right ma mathematical operations we are going to perform now here the data let's say we are passing a text data right if are passing this text data to my model so my equation actually they won't adapt this text Data directly ly they won't adapt actually this text Data directly right they won't be adapting it actually this text data now uh in between actually what I I will do so in between I will encode it what I will do guys tell me I will encode this data right so what I will do I will encode this particular data now what is the meaning of encode so here in between actually I will perform the encoding now we have a various ways of encoding the data encoding is nothing it's just a numerical representation right it's just a numerical representation of the data right numerical representation of the data now we have two ways for encoding the data one is without so here uh the one is without without DL right which is simple frequency based method and the second is one with DL right with deep learning so we talking about without deep learning so there are couple of methods for encoding the data right so the first method which I can write it down over here that is I think you already knows know about this particular method the first method is a document Matrix document Matrix right so uh we create a document Matrix the second one the second method that is one that is called T tfidf method right so by using this TF IDF method also you can do the encoding so document Matrix is there this is also called like uh bag of words right bag of words now here you will find out the the third one let's say n g is there and the fourth one let me write it down here tfid is there andram is there document Matrix is there here you will find out one hot en coding right so this is also a technique now one more technique is the integer encoding integer and coding so this is actually uh like uh this is a without deep learning I converting a data into a so without deep learning I'm going to converting a data into a numeric uh I I creating a data into a u uh like I'm showing the data in a numeric U I'm doing a numeric I'm showing a numeric representation actually right so here we have a document Matrix DF IDF engram one encoding and integer encoding now there are several there are some disadvantage of this particular technique then I will come to this with DL okay let me write down the name also like with DL technique so here you will find out word to back right word to back is there which is very famous technique the second technique uh which has been prop proposed by the Facebook site that is a fast text now the third one you will find out that a Elmo right Elmo now here uh the fourth one what to back is there fast Tex is there Elmo is there even BT is there by using the B and and coding we can do that right so DL based technique now there is one more technique that is called this one glove Vector so actually glove is not DL based it's a metric Matrix factorization based right so Matrix factorization it's a matrix factorization uh method right so this glove Vector now we have so many technique for encoding data right now here if we are talking about this uh this particular technique where we are just like talking about the frequency of the data so there are several disadvantage of this right so definitely we are going to convert our data right from uh text to numeric uh text to numeric value right we are doing it by using this particular method but here are several disadvantage the first disadvantage actually which I can write it down over here that is what that is a uh like by using this technique right so at we we are by using this particular Technique we are ending up with the sparse Matrix right so we are ending up with the sparse Matrix what is the meaning of the sparse Matrix so in the sparse Matrix you will find out there are more number of zero there is less information right so that is called a sparse Matrix now the second is what this is here actually you won't be preserve your context right so here actually you won't be able to preserve context now you this this embedding this this number this a numeric representation basically which you are getting of your data this is meaningless right this is meaningless so here this is going to be a meaningless and you won't be able to preserve any sort of a context right so if you are going to convert your data right if you are going to convert your uh data into a numeric value by using this particular technique I'm not going to I'm not going into depth actually I I can show you the uh how to calculate and all but as of now I'm just giving you the overview advantage and disadvantage so by using this technique there is these U there is a different different like disadvantage of it there is two major disadvantage which I have highlighted one is sparse metrix and the second one is context contextless right so meaningless there is no there won't be any such meaning actually whatever vector and the numeric value which you are going to generate right now over here see if we are talking about our data let's say we are talking about the text here is a what here is a text so text is nothing actually here it's a collection of sentence right sentences now it's a collection of the phrases don't worry I will show you each and everything practically by using the python and here in the sentence phrases actually you this is the collection of words or tokens this is called word or it is called a tokens right fine now whenever we create whenever we perform this uh particular when whenever we use this particular technique so how we do that so let's say we have a data right we have a text so from that particular text what we do we generate a vocabulary right so we create our vocabulary and here let's say first what we what we do we create the vocabulary uh I hope the spelling is correct so we create our vocabulary and by using this vocabulary we perform the end coding right we perform the end coding so here we have a sentence we have a text we have a data now by using this data data after cleaning and all so we perform the cleaning so here we perform the cleaning and whatever data and all which I get and uh we collect the data we we we call it as a we call it vocabulary actually and by using this vocabulary we create the end coding right we create the end coding now over here see uh okay this is fine but here I shown you that we have a several disadvantage now um like there was several disadvantage of this particular technique and the major disadvantage was uh contextless okay contextless or meaningless because of that actually we were not able to retain the information so here a few more technique came into the picture this word two back actually it's a very famous technique this one okay is the old one also it's a famous one also now here the um the concept came into the picture the concept name was iding right so here see we were having the disadvantage inside this particular technique now the concept came into the P picture the concept was the iding concept so here what was the embedding concept so embedding also it's a numeric representation of the data so let's say we have a data now this data actually if I'm going to represent numerically so that is nothing that my embedding right so this embeding is nothing actually this was the vector right this is what this is a vector and what is a vector vector is nothing thing it's a a set of numbers right so we talking about the vector it is a set of number and how to showcase the vector how to represent the vector I already told you we represent the vector in this uh square bracket right technically if I have to represent the vector I represent like this and mathematically if I calculate it so yes so we talk about the direction plus magnitude so here m means what magnitude plus Direction so that is what that is a vector so we have a embedding so this embedding concept came into the picture now here also we are representing a data in terms of numeric value but the way was little different right so here actually we were able to achieve two things first one actually we are able to achieve the dense Vector right we are creating a dense vector and the second thing was the second thing was we were able to uh like sustain the meaning also so context full right context so context te X context full meaning right context full or meaningful meaningful right so we are able to achieve this two thing by using this embedding now let's try to understand this embedding by using this word to back so here again I'm not giving you too much detail regarding this embedding and all U regarding this word embedding es uh esip gr right or CBO method scheme gra method right so there are different different method we have inside the word itself but here uh let me give you the high level overview that how it was working why I'm doing that because the next concept is directly related to the embedding only if you're not able to get it uh if uh this Basics uh if the basics won't be clear here that definitely you will face a several issues so that's why first I'm clarifying this a basic thing so tell me guys are you getting it right so whatever I'm trying to explain over here regarding the vector embedding data different different technique of the embedding so are you getting my point yes or no tell me are you able to understand the concept if you are getting it if you are able to understand that please hit the like button please let me know in the chat yes tell me so I think people are writing now yes great okay fine so we are having the concept of the word to back now let's try to understand this embedding right now here uh what I can do I can give you one one example so let's say here is my sentence right so here I can give you one example actually so by using that you will be able to understand the meaning of the spark and the dense vector and you will be able to understand why we are not able to sustain the uh context also right so the example is very very simple let's say here I'm writing my my name is sunny right so here I'm writing my name is sunny now the next one is what let's say here I'm writing sunny sunny is a data scientist and here I'm writing Sunny is working Sunny is working for I neuron right so Sunny is working for I neuron so first thing what I will do so the first thing basically I will generate my Bo vocabulary right vocabulary so for generating a vocabulary uh so here I will find out the unique words so there is my first word second word third word fourth word fifth word sixth word right now here A S 8 n so here what I will do I will create my vocabulary so in my vocabulary I'll be having nine words so one is my one is name you can remove the unnecessary words and all by uh using the text cleaning techniques so here my name is sunny so this is my fourth word now here is a data science right now here word word and for and here we have a i neuron right here we have a i neuron so these are my vocabulary 1 2 3 4 5 6 7 8 9 right now let's say I want to create a one hot and coded Vector one hot and coded vector for this a particular sentence for which sentence guys tell me so I want to create it for this a particular sentence for the first sentence now if I want to represent the my inside this sentence what I will do here so here for my I will write it down the one and for rest of the value I will write down the 0o so 0 0 0 5 6 7 8 9 so this is the representation of my first word then I will write down the second word so here is name so here for the name actually there is 0 1 0 0 0 right 0 6 7 8 9 so this is my second word like like this there will be my third word so here let's say this is my third word so the third word 0 0 1 0 0 0 0 5 uh 4 5 6 7 8 9 and here is what here is my fourth word so fourth word is sunny so 0 0 uh 0 1 0 0 so 1 2 3 4 5 6 7 8 9 so this is a this is my one sentence actually this is my first sentence which I uncoded which I uncoded so let me write it down over here this is what guys tell be this first sentence which I encoded by using the what hot encoder now see guys how much sparse this is so how much sparse this is right and here there is lots of zero and this might a contextless in a longterm sentence right it might be a meaningless so here is a example of the one H and gon and whatever techniques you will find out yes a tfidf is a better one even Google was using this technique for a long time now it uh replace this tfidf technique by this embedding one only because this tfidf it's it's a research of the Google right document Matrix it also work in a similar way like this one hot encoding somehow right so somehow it works with a one hot n coding right this uh document Matrix now we have TF IDF TF IDF is a better one NR is also there I will talk about the NR and here is a integer n coding so we U like code this value with the integer number right now here is the example of the one hot and coding now I will explain you the concept of the embedding by using this word to back that how this word to back is working so tell me guys is it clear to all of you so far yes or no think it is fine so just a second great so I hope uh this still here everything is fine everything is clear and uh just a second yeah it is uh clear now yeah great so let's talk about this word to I'm not going into the detail of word to back I'm just trying to explain the concept of the embedding only here right so how it was working so here guys if we are talking about the word to bag see let me do one thing over here what I can do I can uh Show You by using the example one example right so see let's say we have some data right so let's say we have some data and from that particular data what I did I created my vocabulary this data is nothing it's a text data right it's a text data and from this particular particular data I'm going to create my vocabulary right so let's say this is what this is my data and here uh this is what this is my data data in the data basically you'll find out the vocabulary so we are going to generate our vocabulary so here will be my some words and all now see if we are talking about the embedding now inside the embedding what we are going to do so we are going to create some features right so the first thing actually the first thing is what the first thing we are going to create the vocab and second thing is what we are going to create a features right features from this VAB okay we are going to create a feature from this book app now let me give you one example that how the feature and the book app looks like so there is one famous example very famous example let me write it down over here so let's say there is my book app which I'm going to write it down over here uh in the book app let's say we have some data and from there I I have extracted this book right vocabulary so in the vocab actually we have some value let's say there is a king right let's say there is a queen this is very famous example that example only I'm going to write it down over here that uh we have a king queen we have a man right we have a woman and we have one more word let's say we have a monkey over here right so this is a like wab actually which I have extracted from where from my data itself right you can assume that we have a data this is what this is my vocab now here actually you will find out some feature right so my feature is what let me write down the feature also so the first feature actually uh that is what that is a gender right so here the first feature is what the first feature is a gender the second feature which I'm going to write it down over here that is what that is a weth right the third feature which I'm going to write it down here that is going to be a power right the fourth feature is going to be a weight right weight and the third fifth feature is going to be a speak now see this vocab right and this feature right so everything is being done by the neural network itself neural network will automatically take care of it right so actually we have to pass this uh bab and it will automatically look into the features right this particular feature actually the feature which I have written so here what I will do I will create my data in such a way there we'll be having a vocabulary and we'll be having a neural network we'll be passing that to my vocabulary and my feature will be create and in between basically whatever Vector I'm going to generate that Vector itself is going to be my embedding right so here how the vector looks like so this is the high level representation of that mathematical so whatever complex mathematics is there now it's a high level representation of that that's it now here let's say we have a king we have a queen we have a man woman and monkey this is my vocabulary and this is my uh feature now here see guys we are going to assign a weight right to this particular vocab right we are going to assign a weight the weight value will be from 0 to 1 right so here I'm saying King King is having a Zender right so here I'm saying yes it is having a Zender means one now Queen is also having a Zender right so here actually uh what I'm say say king is having a Zender now Queen is also having a Zender right uh here I can write it down the one now here I can write male also so you can say uh let's say the gender is going to be male female so you can specify you can specify let's say if the gender is going to be male over here this one now in that case what you will say so for King actually you will write it down one right so here let's say the gender is specified that is male so what you will do for the king you will write it on the one and and for the queen you will write down the zero right here the men yes it is one woman actually it's a zero and monkey let's say it's a one right I'm talking about the monkey it's a male one now if we are talking about the wealth right so again I will provide some sort of a number over here see to the vocabulary I will assign some number based on my feature okay so wealth yes King is having wealth so here what I will do I will assign one now Queen is also having wealth so I will assign one over here now if we are talking about the men so Men actually it's not a king right so men is not a king so they it might have a wealth or it might not have a wealth right so here I'm not going to assign a one so between this 0 to one I can assign any value this is going to work as a weight right so here I can assign 0.5 over here this woman also same right so it is having a less wealth compared to men let's say 0.4 and monkey is not having any sort of a wealth so here I'm going to write down the zero now if we talking talking about the power so definitely King is having a power Queen is also having a power but maybe less than to this King so here let me write down let's say 0.8 now here let's say this man is having a power let's say it's having very less power 0.2 this woman is having a power let's say 0.2 and monkey is not having any power now if we are talking about the weight definitely King is having a weight 0.8 now let's say woman this queen actually it's a more than this King in terms of weight so here I write down the 0.9 men also is having a weight right say uh is having 0.7 and this is 0.8 and monkeys also some weight let's say 0.5 right so to this vocab based on this feature I'm going to assign some sort of a numbers right and here let's say speak so yes King can speak Queen can speak man also can speak now here woman can also speak but monkey cannot speak so here is a zero so now you will see that this is my first Vector see this is the vector of the King right this is the vector of the king so here I'm representing the King by using this particular Vector now if we are talking about the woman so here is a vector of the woman guys this one sorry this is a vector of the queen this this particular Vector now if we are talking about the vector for the main this is the vector of the main I'm going to represent main by using this particular Vector now just look into this example where I was representing Sun by using this Vector now compare this vector and this type of vector see this Vector is actually this Vector is dense Vector right this Vector actually it's a dense vector and it is having more meaning right it is having more meaning it's not a meaningless it's having a meaning which I have uh which I can uh basically uh it is having a meaning which I can prove it also now this Vector whatever Vector I have designed over here it's a 5D Vector it's a five dimension Vector right now guys see I told you uh about the two Dimension Vector now let's say here uh if I'm going to draw the two Dimension Vector so this is my two Dimension Vector this one and how to represent this vector by using this x value and Y value now if I'm writing about the king let's say this is what this is my king right so here how to represent the king Now 1 1 1 0.8 and 1 so here is what here is my king Vector now tell me guys this King Vector actually it is in five Dimensions so we cannot draw it like this we cannot draw it like this so see the word to W model the word to W model which Google has strained it was a model from the Google right so this Google has Stained this particular model on a news article on a Google news article and actually uh the vector they have created the vector Vector which they have created over there the vector size was the 300 Dimension right so the vector size was the 300 Dimension so here I have just given you the Glimpse right with a few vocabulary and the feature now here uh if you will look into the real word to model which you can download from thei or maybe from any NLP Library like nltk and all so the dimension you will find out of each Vector which is going to be a 300 right which is going to be a 300 so this is called embedding now here here guys see whenever we are talking about whenever we are talking about neural network so in a neural network what we are going to do so in that actually we have three layer one is a input layer the second is called a hidden layer the third is called a output layer so here actually what is happening see we are passing a input we are passing input now what we are passing over here what we are passing to this uh what we are passing to this neural network so here actually we are passing this a particular feature right this a particular feature so we are passing this particular feature and we are assigning some weight and at the end actually at the end at this particular layer in the output layer whatever Vector I will get right whatever Vector I will get in the output layer so that itself is called is going to be my embedding right here I have given you the high level overview how the bend how the embedding is going to be generated but the same process is going to be Auto by using this neural network and here what feature we are passing which feature we are passing so what I will do I will create one recording right for the word to back along with the python implementation there I will show you uh like how this word to back is working in actually actually right so here U yeah this is all about the embedding so embedding is nothing it just a vector and what is a vector you already knows about the vector so here you can see I clearly given you the explanation about the vector so what is a 1D Vector what is a 2d vector and if here let's say we are going to write down the five value right so that is a vector in a five dimension so we cannot draw the five dimension that's why I'm not able to show you that a 5D Vector but yeah if we are going to represent it let's say uh here what I'm going to do so let's say if I want to represent this five as of now just going to draw it in 2D itself so let's say this is my king Vector this is my king Vector now this King Vector will be near to this queen vector and this monkey Vector actually it will be far from this king and queen now this king and queen so this man and woman right so this is what this is my king and this is my queen now here let's say this will be my a main vector and this is what this is my woman Vector so this will be near to each other this king and queen Vector will be near to each other and here this monkey Vector will be far from each other and here let's see if I'm going to uh what I'm going to do guys so here let's say I'm going to uh substract this king from this queen and we are going to add something let's say men right so just just look uh just see what you will be getting after doing uh this much of like calculation over here right so you can subtract the vector from each other you can add it and you can make a new meaning over there right so the new meaning also will be a vector which will be representing some sort of a information right so here is all about the word embed and all so I just given you the introduction because I want to make a foundation as strong as much and here uh you can see why we need Vector database here uh there are different different uh database name here is a example basically which I'm showing so in tomorrow's session I will continue with this particular slide and then directly I will move to the Practical implementation where we are going to talk about a two database so initially I will start from this chroma and this vient right oh sorry this spine cone so first I will try to discuss this coma and the spine cone and if time will permit then I will come to this F also this F is a uh this F actually it's a vector database of the meta AI Facebook AI so yes definitely two database we're going to discuss in the class itself chroma and pine cone and there what we are going to do we are going to store iming and you got to know about the Ming guys Ming is nothing it's just a vector it's just a number which is having some semantic meaning and how we are going to do that we are going to create a feature which we are passing to our neural network and some uh like mechanism is there and based on that we are going to uh generate the vector so tell me guys did you like the session whatever I explain you over here did you understand each and everything how much you would like to rate the session if you liking the session if you're liking the content which I'm showing you in depth so please hit the like button please support support the channel so it motivates to me also and please write your answer in the chat if you're liking the session if you're liking the content and even the explanation also tell me I'm waiting for your reply so please uh tell me guys uh write it down in the chat yes did you learn something new did you understand uh whatever I have explained you that deployment all and the what Vector databases and uh here uh you will find out the session after the uh like see here is a session guys on top of the dashboard so just enroll to the dashboard here is my dashboard this one just enroll to the dashboard and uh you'll find out the session over here itself and even along with the resources this handwritten resources and all everything will be over here and uh yeah and subscribe the on YouTube channel we are uh all the thing is getting updated and here uh the recording also will be here great so fine I think now we can conclude it so today we have talked about the deployment and the vector database okay just go through the dashboard and download it then to check with the so this assignment and all so just click on the assignment and uh try to solve this assignment and then you can submit it also after solving it so let me show you how the assignment and all it look like this one yeah so here is assignment guys see you can okay so you here on itself you can write down the answer uh whatever questions of we have given you and then you can submit it directly okay great so I think we can start with the session and in today's session we'll be talking about the vector database so we'll Implement also we'll discuss about the pine cone database Vector database I will show you how to do setup how to do setup of the pine cone database and uh I will try to create a small bot also and in the next class I will show you how you can Implement end to endend chatboard got it so we'll discuss two Vector database in today's session I will be talking about the pine cone and in the next class we will be talking about the chroma DV so so there is two database which I'm going to talk about and we'll try to discuss the concept of the embeding and all and I will show you how you can uh generate the API key regarding the pine cone how to create an index how to create a cluster each and everything we'll talk about in today's session so so far I discussed so many thing in this community Series so first of all let me show you all those thing so for that guys what you need to do you need to go through with the Inon website and here you need to uh go inside this course section just click on this course section and here you will find out this community program so just click on this community program there are various uh option you will find out like DSA generative AI machine learning and SQL so just click on this generative Ai and here here we have a dashboard for the generative AI now there you will find out two dashboard one is for Hindi and the second is for English uh so just click on the dashboard now here uh you need to sign in first so after sign in actually uh first need to sign up if you are new on this portal and then you need to login and finally you can enroll inside the course so this is completely free we are not charging anything for this particular course now here I already enrad inside this course so here I just need to click on this uh go to course so here uh guys uh let me show you the dashboard this is the dashboard so so far I covered uh eight sessions so far I discussed like so many thing and I this is Day N actually and here you can see the till day 8 and yesterday I talked about the vector database I talked about the deployment as well if you will go and check with this particular session so I discuss about the deployment as well in the initial in the initial class and after that I move to the vector database there I explain you the theoretical concept regarding the vector vector databases and all I talked about the embedding and now in today's class we going to implement all those things so here uh just click on the resource section you will find out the resources actually here u u okay I already shared the resources so in some time uh it will be available a over here but if you want the project if you want the resources so uh for that you can visit my GitHub also there I uploaded my uh there I uploaded the project the project which I have implemented and all the steps regarding the project so how to deploy that and also each and everything I have written over here inside the readme file so let me show you that where it is uh the AI yeah this one so just uh go ahead with this particular uh go ahead with this particular link this particular project so here you just need to search s Savita giab there you will find out all the repository you will get my repository uh and then uh just go ahead with this generative AI this is your project and there is all the steps regarding the deployment and all don't worry in sometime it will be available in the resource section also so I already share with my team and they will be uploading inside the resource section got it now here uh see uh this is all about the deployment but apart from that I talked about the vector databases now Vector database wise I have discussed the theoretical stuff only so what is a vector how the vector database Works what is the meaning of the embedding what is the pros and cons of the embedding and the uh like different different encoding technique each and everything I talked about over here now in today's class we'll see the implementation of it uh apart from this apart from this uh okay so here is dashboard now apart from this resources and the lecture you will find out the quizzes and the assignment also and after completing this course so which we are going to complete soon because this is just a foundation course so we are uh we'll be taking uh four to five more classes and after completing this course you can generate a certificate from here so just click on this particular option and you can gener generate the certificate after completing this course right so you will get get a certificate for the foundation generative AI uh so this is the name of this course and apart from this one uh so apart from this basic course you will find out one more course over the Inon platform so for that uh just go inside the course section right here itself and uh let me show you just uh click on this generative a right so once you will uh go with the course and here you will click on the generative AI now inside that right inside that you will find out on the paid course right which we are going to launch next month next month from 14th January onwards so our first class will be on 14th January onwards and here you'll find out like we are giving you the discount and all so 40% discount is there and uh the price is as of now 6,000 you can talk about talk with our sales team and all they will give you the detail uh they will give you the complete detail regarding this particular course now the timing will be from 10 to 100 p.m. IST in morning morning and here after the time after the like class we have a doubt session also which is going from 1 to 2 not 1 to 2 basically so until we are not going to solve all the doubts and all so definitely we'll be uh we'll be taking the doubts okay and that will be the live doubt session only where you can interact with the mentor whoever taking class at that particular time means um in a live class itself so yeah definitely you can ask the doubts in a live doubt session right after the class now this course duration is around 5 month and the mode will be in English uh okay so the date basically we have modified uh so the date is going to be uh this course is going to be start from 20th of June right now apart from that you will find out the instructor so here is the instructor of this course Chris sir sudhansu sir me and buy so these four will be your Mentor who is going to take this entire course and now here you will find out the curriculum also so this is the curriculum which we have divided into several mod modules so you can go through with the curriculum we have covered each and every each and everything which is like industry relevant and from basic to advance we are covering each and everything about the generative AI embeddings or a large language model different different Frameworks open source model fine tuning and apart from that U like there are so many things security comp compliances and all which you're going to talk about after creating a project uh evaluation matrixes of llm each and everything what whatever required on the industry level uh whenever you are going to work on any sort of a use case on any sort of a project which we are going to discuss over here right so here you can uh go with the website you can check about the curriculum and if you uh want something if you have any sort of a query you can directly ask me you can connect with the sales team they will be clarifying it now this is all about the uh course right so I hope guys uh you have seen on this particular course now coming to the the YouTube channel so uh where you will find out all the video apart from the dashboard so here let me show you let me search over the in neuron so this live is going on and here uh see guys uh once you will click on the uron YouTube channel uh go inside the live section there you will find out all the recordings uh like whatever uh we have discussed so far inside this community session so it is in a live section you can go and check and you can uh learn from here also and if you want a detail so each and every detail we have kept inside the description so once you will check with the description of this video you will find out all the details over here right so I hope uh this is clear to all of you now if you have any question you can ask me and then we'll start with today's topic so how work llm with insight and complex calculation on business data so definitely we're going to talk about it in our uh project right so there will solve a different different use cases and all here uh actually I shown you that how to call the API how to read the models and we have solved one basic problem statement that is McQ generator so uh business wise organization wise specific uh use cases wise also we can use this uh like llms and all and definitely be talking about in our different project in our other project and there will'll try to discuss more about use cases more use cases basically use cases application and their domains okay which one will be good for the streaming data Vector so as of now we going to talk about the Vector database and right after that I will discuss about more Vector databases and the graph databases also right so as of now uh the vector databases actually it is good right and I will give you the comparison and all uh while I will teach you that so don't worry just uh be in the class everything I will be clarify here itself in the live class okay so if you have any sort of a doubt guys you can ask me you can ask me in the chat I uh up for the questions and the s how to design the prompts and all so guys here if you will see uh if you will look into my session which uh where I have discussed I think each and everything right so on a foundation level so there I uh took a uh like a few specific time for The Prompt also right so how to design The Prompt what is the meaning of the different different prompt how to construct The Prompt what is a a few short prompting what is a uh like zero short prompting each and everything I have discussed inside my session now how to uh design The Prompt so you will definitely will get it once you will go through with my session so uh I would request to all of you if you haven't attended my session and if you are asking any question related to The Prompt LMS and all so first visit my session and then automatically this all the doubts will be clarified okay how organization has hesitant to adopt generative AI so just go and check with my first session uh where I have discussed the detail introduction of a generative AI why the organization should use the generative AI what is the pros and cons if we are going to train any model from scratch if you are using any pretrained model which has been uh trained on a huge amount of data how we can reduce the cost and how we can get Effectiveness each and everything you will get it in my first session so please please check with the day one after this session and there I discuss everything regarding to regarding to this generative AI okay great so now I think uh we can start with the yeah we are going to discuss about the chat interaction also chat interaction with the database and in today's class itself in today's session itself I will show you this thing got it so finally let's start with the session let's start with the topic now the topic is what the topic is a vector database don't worry guys here the project will be available here inside the resource section if you will uh check with the day eight so uh there uh I will give my GitHub link I already Shar with the team and within a uh like uh within few minutes they will upload it over there got it now uh let's start with the session uh so today actually we're going to discuss about the vector databases yesterday I given you the introduction of this Vector database now let's see how does it work now uh if you will look into this slide so here I have mentioned each and everything that what all thing you're going to learn so what is a vector database why we need Vector database how Vector database work use cases of the vector database widely used Vector database right and practical demo using Python and lenion and there we are going to use open AI as well so these are the thing basically which we need to understand related to this Vector databases and yesterday I already given you the introduction about it so here I I have written each and everything on top of the Blackboard and I try to explain you that how this Vector database works right so there are like so many technique okay so Vector means what Vector I here I explain you what's the meaning of the vector in a layment term and there I have explained you about here I have explained you about the vector right so how to uh Define the vector how to write the vector it's nothing just a set of value and how to write it down so we we write it down u in a square bracket right so here actually see this is what this is my Vector which I have written so there might be a column Vector row Vector each and everything I discussed in my previous session right now after that I talked about the encoding so let's say we have a data and that data we want to pass to my model now uh here uh in between actually we'll have to perform the encoding of the data because we directly cannot pass the data to my model right text we cannot pass to my model because model is nothing just a mathematical uh equations so uh yes definitely it won't be able to uh like calculate something by using uh those Text data so definitely we'll have to convert those data into a numbers so for that we have a different different techniques if we are talking about deep learning so where we have a two technique right so first is without deep learning the second is with the Deep learning now in the without deep learning you will find out like there are so many Tech so many like techniques so here I have written couple of which is very very famous like document metrics TF IDF NR one hot end coding and integer end coding which we generally use while we are doing a end coding and here right hand side I have written a technique which work along with the neural network so word to is there fast Tex is there Elmo is there b is there Transformer itself is there right glove Vector is there but it's not a dbased technique I told you that it's a metrix vector ition based technique so here I'm not going to uh explain you the mathematics behind uh such techniques whatever I have written over here uh here I'm just giving you the Glimpse I'm just uh talking about the vectors I'm just talking about the embedding that's why I given you this overview got it because uh if I'm going into the mathematics so uh only one week will be required for this and coding techniques for the word Ting and all uh along with the implementation so here I'm just giving you the overview and trying to explain you the meaning of the embedding and vectors so if I was talking about the uh like here I was talking about here the uh disadvantage of this uh frequency based technique which we are using without uh DL means without neural network so here actually see this was the disadvantage of this particular technique so first was the sparse metric if we are using any such metrics right so any such technique like document metrics DF IDF andr one hot encoding or integer encoding so they actually uh we are going to generate a sparse Matrix but let's say we are not going to generate a sparse Matrix but in a long time we are not able to sustain a context it is going to be a contextless or meaningless okay now here uh it's going to be a contextless or it's going to be a meaningless uh this particular technique so that's why this edding concept came into the picture it is also a vector but it's a dense Vector right and the uh way of generating this Vector is little bit different compared to this technique now here actually we are using a neural network we are going to design our data in such a way so uh we are having two column one is a uh like uh independent column and one is a target column and then we are passing that particular data to my model and automatically it is generating so automatically it is generating a vector right so how it is doing that how it is going to create a like independent column and how it is going to create a text uh this target column so that's a like uh uh itself U like uh there is a separate process for that and definitely uh I will uh record one video for that uh like one end to end video for the hand coding techniques and all and I will put over the Inon YouTube channel so you can go and check in uh detail right so there I will I will be writing all the mathematical equations and all as of now just giving you the intution so here I given you the intu intution one high level intuition how this uh techniques is working this award embedding technique so here is the sparse metrix or sparse sparse Matrix which I have created so uh here you can see this is what this is my data so from this particular data I want to I will generate the vocabulary and based on so this let's say this is what this is my vocabulary over here now from that particular vocabulary I'm going to generate my Vector so here I given you the example of the one h encoded vector and you can see here this is very sparse Vector right this is very sparse Vector which I have generated regarding this particular document regarding this particular sentence right now if we are talking about the word embedding now how it is generating a vectors right how it is generating a vectors regarding the data so see let's say we have a data and from that data I'm going to create a vocabulary and from those vocabulary I'm going to create a features so here let's say this is what this is my vocabulary and this is what this is the feature so we'll assign the value between 0 to one to each and to each and every vocabulary based on a feature so here you can see uh I'm talking about the king so King is having a gender yes so here is one Queen is having a gender so she's U she's female actually so here is a zero I'm talking about the male here so man is one woman is zero monkey is one so like this uh I will be giving a number and this is what this is my one vector this is my one vector which is representing this King based on this particular feature now if here if you will look into this particular Vector so this is a dense Vector right which is having so many information compared to this Vector which is a sparse one right and where we are not able to sustain any sort of a context so this is what this is called a word embedding now uh if we are talking about a word embedding technique so it has been invented by the Google and they have trained the neural network on a huge amount of data that was the Google new news article right so uh the model basically which they have trained if you will look into the model if you will download the model so there you will find out a vector which is having a 300 dimension in every Vector actually they have a 300 Dimension so you can use the pretrain embedding you can use the pretrain embedding if you are going to trainum model uh so you can pass the data to that particular model and automatically it will generate a aming based on a pretrade model or else you can create your own m meding as well both thing is possible so in our case actually we are going to use open Ming so I will show you how to use open AI eding open AI also is having one uh class so edding class by using that we can uh generate a embedding so whatever data we have we can pass to that particular model and we can generate a embedding right so don't worry I will show you that how to generate a embedding from the openi class from the openi model and here is just a glimpse of the word aming which I shown in my previous lecture so I hope till here everything is fine everything is clear now let's move to the vector database tell me guys everything is fine everything is clear yes or no yes it is possible to read Excel using Lenin without any data loss yes it is possible we can read the Excel and I think I shown you how to load the documents just uh check with the documentation they already given you the code snippet use that uh particular snippet okay code snippet can change timing for the paid AI course evening um I think the course timing is in morning I will have to check with my team related to that so yeah if there will be any sort of a changes then definitely uh like you will get to know about it okay and I will update you tell me guys uh till here everything was fine so can we start with A New Concept now because here I I have explained you something regarding to this Vector database and then only I will move to the uh then only I will move to the Practical implementation great so let's start with the session now so here in this PDF you can see uh I written something that what is a vector database now first of all let me open my open oh just a second great now here you can see guys uh I was I'm talking about that what is a vector database now a vector database is a database used for storing high dimension Vector such as word embedding or image embedding so we can convert our text Data into embeddings even we can convert our image data also into the embedding and this embedding is nothing it is a vector so it's a vector actually and it is not a twood dimension vector or one dimension vector or three dimension Vector it's a high dimension Vector as I told you uh I was talking about this word aming word two B actually this is a model this uh word to back has been trained by the Google and this trained by the Google on a news article right on a news article and uh they have generated the embedding from those particular data from that particular data and the embedding size was 300 so actually see the vector which they were generating the size was the 300 over there so here we talking about the word embedding so it is nothing it is just a vector and it's a high dimension Vector right so the size can be anything over here so once I will show you this open a vector open a uh like open a Ming Vector so the size of the open a aming vector around 1,600 right so there you will find out a 1,600 value inside one vector right okay so yeah and even over here see I'm I'm talking about the word embedding so it is not related to the text Data it is related to the image data also means regarding the image data also we can generate a Ming and yes it is possible so over here you can see so this is a dog images PDF whatever document we have so related to that particular document we can generate a embedding and this is nothing this is a vector which is and what is a vector tell me the vector is nothing it's a set of value and which we are going to store somewhere in our Vector database now here if we are talking about the vector database so there is two term one is Vector and the second is database so this database actually it's a very common term which we like I think we all knows about this database so uh if we are talking about this database so during our uh like during our semester or during our college or maybe if you are working in an industry so definitely once in a while we interact with this database right so if we are talking about the database so there you will find out two type of database so the first database is called SQL based database and the second type of database is called No SQL database right so where we don't have to write it down the SQL where we don't need to create any sort of a schema a pre defined schema so that comes under inside the no SQL database and there we have a different different type of the databases like key value pair graph based database and document based database right so there is a different different type we have of the inside the no SQL database and here we are talking about the SQL based database so there you will find out only one type where we can store our data in the form of in the form of predefined SCH schema in the form of table in the form of row and columns right now what is this ve Vector database so Vector database actually see uh if we are talking about the database so definitely some uh server will be required for the computation and all right and we are talking about the database definitely some space will be required for storing something if we are if we are installing the my SQL in our local system so have you seen that we are installing the MySQL server and it is getting uh it it is occupying some sort of a spaces also in our system right for storing the uh data in the form of physical file The Logical view is a table but yeah in the back end actually storing our data in some physical format so here see uh we have a database so definitely some computation will be required and memory also will be required uh so here uh we are talking about specifically this Vector database so we are storing a vector now so how this database this Vector database is different from the SQL and no SQ database now let's try to look into that and we'll try to understand the differences differences between this uh like SQL no equal and this Vector database and why we should use this database why we should use this Vector database uh why we should not use this SQL and no SQL database we'll try to understand that also so first of all let me do one thing let me move to the next slide and uh let me explain you so here you uh I have written that why we need a vector database see over 80 to 85 person data which is there in the world as of now so there is a unstructured data now what comes inside this unstructured data so unstructured data means the data basically which is not a structure one like images okay so we have a images we have a videos videos is nothing just the collection of images collection of the frames uh so uh if you heard about this FPS frame per second that is nothing that's a uh mejor uh measurement unit of this videos okay in 1 second how many frame is getting processed so uh here uh we are talking about the images so the image data actually comes under this unstructured data where we have a pixel right pixel which uh we are going to form in the which we are going to collect in the form of grid right so pixel value usually will find out from 0 to 255 got it so that is what there is an images right there is the images now if we talking about the unstructured data is text Data the text which I'm writing that also comes inside this unstructured data Text data is there voice data is there right so voice is there text is there images there videos is there so this is called unstructured data and most of the data which you will find out uh like uh which you will find out in today's world in today's era so that is a unstructured one only on a different different platform like Facebook Instagram what we are doing we are uploading a videos we are uploading the images we are uploading the reads this that whatever right so this platform this application are taking a data uh so we are uploading a like different different type of uh like data right like images videos and all those are called unstructured Data so I hope you got a clearcut idea regarding this unstructured data now let's move to the next slide that why I have written over here so if we talking about the uh SQL based data or relational data or traditional data so here is some example which is like uh uh which is a very famous database dbms actually MySQL is there post gr is there SQL light is there Oracle is there right there are different different relational data wayase you will find out uh which we have learned once in a while means u in our College days in our like uh in the organization itself in the company itself right or or during the training so we have interacted with this relational database and this traditional database and we have seen the SQL also like how the cql works how to write it on the syntax and all in a SQL so we know we all know about the basics of the SQL right if we are talking the relation datab with so we usually write the SQL query over there right for interacting with this relational databases now here uh I think you got to know the idea that what is a relational database and here we have a problem problem related to the data the most of the datab basically that is the unstructured data now just see over here let's say uh if we are going to store this data if we are going to store if we are going to store this a particular data like images videos and all inside the vector database right so uh not inside the vector database First Let Me Explain you inside the first let me tell you that inside the uh this traditional database or inside the relational database so what will happen see so let's say here we have a traditional datab datase like my SQL and here if I'm going to store the image inside the my SQL all right we have a image and that particular image I'm going to install or I'm going to save inside the my SQL now guys see definitely I can do that I will be able to do that I will be able to save the image so it is having this capability where we can uh store the binary object so uh there is one way actually we can convert this particular image in a vs4 string vs4 string and I can see save it but here guys see if we are going to save this particular image if we are going to save this particular image inside the uh traditional database so here I will have to define a schema right I will have to Define one schema there uh let's say if I'm going to store this image directly so we won't be able to get it now so this image belong to cat dog or which dog actually so if you will look into this dog so this dog is specifically is having some property right so this dog is specifically having some property some let's say this a dog belong to this particular breed that particular breed right now this um dog is a yellow brown or black something like that so this dog itself is having some property so if we are going to store this data directly in my SQL in that case let's say we are not passing any sort of a label any any anything over here right regarding this particular dog or directly we are going to store this dog okay dog image inside my my SQL now over here let's say I have converted into a b bs4 string or let's say I have just converted into a binary object uh so in that case I won't be able to identify it I won't be able to identify it this is the first problem the second problem basically so if you want to identify it so for that basically we'll have to create a proper schema so schema in case so let's say there is a image of the dog right there is a image of the dog then there is a color of the dog then there will be a breed of the dog right and there will be a lab label means this is the dog or let's say there's a cat something like that so if we are going to store this type of data in my SQL definitely I can do that but here is some problems we have first problem right if we are directly storing it so definitely we won't be able to identify it right so whether it's a dog cat or whatsoever the second thing we'll have to define a proper schema and the third thing is what so we'll have to define a proper schema where we'll be having a different different variable now the third thing is what so here actually see uh this SQL database let's say we are going to store it over there now uh whenever we talk about the text or images with respect to this uh generative AI or llms actually we have to perform an operation that is called similarity search right similarity search so I will show you what is this particular operation similarity search actually see whenever we are going to uh store this data this dog image inside the traditional database inside the relational database so the first problem which occur related to the identification if we are going to create a better schema that is also fine but we want we we cannot perform this similarity search actually means B let's say there is a dog now I want to find out the dog which is having a similar property right which is having a similar property like this dog so it is not possible in my SQL database right in in like traditional database or in relational database right so this similarity search or this query actually this will be a very very difficult if we are if we are going to query right after storing a data based on some property it's going to be a very very difficult so that's why we don't use this relational database and the same problem occur with the no SQL database also there also we can store the data we can store the Ming okay so we can use so I think today itself Chris has uploaded one video regarding the cassendra where we can store the embedding right we can do that but this Vector database which specifically designed for the like this edding and all so this gives you the better result compared to that right somehow we are able to achieve this thing means we are able to uh pass the label to the particular object whatever we are storing and we are able to search also right based on a similarity we are able to make a query we are able to perform the query but actually it is not that much efficient right whatever we want so for that only this Vector database has been designed I hope you got a problem and you are getting my point that uh why we are not storing this data inside the relational database got it now let's come to the next point and the thing will be more clear to all of you the next part over here if we are talking about the image so image looks like this only so where we have a three channel so the first one is a uh R then second is G the third one is blue means B so this is RGB means this colorful image actually it is having a three channel the first is called R the second is called G that is green and the third is called Blue right now uh here yes definitely if you want to perform the Ming right so here if you want to per if you want to perform the Ming we can do it by using uh so here we can use uh like different different embedding technique as I told you word to back Elmo or any pretrain embedding like uh which is uh available over the open a right which is available over the hugging phase so any embedding a model we can download and we can pass our object to that particular model right and based on a a training on uh like on whatever way basically it has been trained so it will give you the embedding right maybe you are not able to get this particular point but once I will show you right once I will do it in a python definitely you will be able to understand so what I'm trying to say over here you can perform the embedding related any unstructured object so here you can see we have a text we have a audio we have a image image embedding is also possible means we are going to convert images into a vector now here what I'm going to do so here I'm going to download any pretrain model any pretrain embedding model and yes by using that particular model we can convert our data into a vectors we can perform the embedding I hope this part is getting clear to all of you so whether we have a image or text or voice we just need to download the model pretrained model and based on that we will be able to generate an embedding if you want to train your own model right if you want to train your own model that is also possible that is also possible or let's say if you don't want to train your own model you just want to finetune the pretrain model that is also possible so everything is possible there is a three possibility first is what first is a you can directly use the train model the second is what second is fine tuning all right fine tuning and the third is what third is training from scratch so here let me write it down the third one third is nothing third is training from scratch right everything is possible related to the embedding and here it is nothing so at the end we are going to generate a back turn after passing the object now I hope you got a clearcut idea now if we are talking about the embedding see uh what all embedding I will show you what all U like Tech te basically uh which uh we have so the first one we can use this word to bag right directly we can use this word to bag for generating Ming the second one we have the Elmo right we can use the Elmo and we can generate a Ming right now the third one basically we have we have the hugging phas API also in that also we have a several embedding model so hugging phas API Now by using this API hugging face API we can uh we can download the embedding model model and we can pass our object to this particular embedding model and it will give me the embedding right it will directly generate the embedding the fourth one we have this open API so in the open a API itself so in the open a itself you will find out the embedding model right so there also we have a Ming here also we have a Ming right in a open a itself so we have a hugging face we have a Elmo word to bag and various model here I just written couple of name or two to three name but we have a various model if you search over the Google you'll find out the various way right to convert your data into a vectors to convert your your data into a ambed vector right now here hugging phase API is also very very popular for the embedding and all and I will show you what all models we have right what all models we have uh inside the hugging phase actually uh for converting our data to into the embedding right and here in today's session we are going to use this open embedding right we'll be talking about the open a embedding how you can uh how you can like get it how you can access this particular class and after passing a data how you will be able to generate the eded vector so each and everything we're going to discuss in the live class itself right so I hope this slide is clear to all of you and this slide whatever I discuss regarding this uh uh my SQL and the sorry regarding this relational database and the no SQL and the vector database that part is also clear now here Vector eming is fine so yes uh we have the vector database now why we should use it because uh here actually this similarity search operation is uh like uh possible we can perform the similarity search after storing the vector and all and yes U now here embedding example so for that uh I kept some sort of example uh basically we can uh do the similarity search by making this cluster and all there is a this is the mathematical process actually so Vector this is a 2d uh this is what this is a 2d example of the vector aming as I told you now so what is a vector vector is nothing it's a set of the value in a like n Dimensions so here if I'm writing here if I have written two value only so it's a set of uh so actually it is representing a two Dimension X and Y right this first value is from the xaxis the second value five is from the y axis now we can do a simility search uh we can make a cluster actually let's say this two vectors near to each other so we can say like they are having some similarity they this particular Vector is having some sort of a similarity like this this also this uh red one also see here is a vector this first one this this is my one vector this is my another Vector this is the third Vector so they are lying they are near to each other so here I'm saying yes this Vector is having some similarity this three Vector now this one also this also this also and this one so this Vector is is having some similarity this green one right this one so like wise actually what I can do I can perform this text similarity option text similarity option which is like uh which is little hard if we are going to store a data in my SQL post gray right or maybe in other databases so in that case like we won't be able to see in my square and post gr relational database it is like really hard right because we are going to store up data not in terms of embedding directly is going to store the object over there and uh for that only we'll have to do a we'll have to create a predefined schema so uh it's going to little hard over here actually we don't never use this relational database for this uh embedding and all okay so it's not our Perfect Choice yes we can use the no SQL database uh in the no SQL we can use the document with database uh or else what what we can do we can use this row columnar database that is also possible like cassendra and all we can use this uh graph based database right actually uh graph based database is not that much successful they also you will find out some sort of a difficulties in all I will tell you in further session but yeah we can use this raw column database and even the document database also but yeah the performance is like U uh it's not that much good and here also we'll have to label the data and all directly we can store the embedding uh but uh here actually along with the embedding there are so many things means we have to find out the similarity score then we have to perform the similarity search here you can see clearly in the geometry but mathematically how we can prove it so for that there are so many thing which we need to find out so there will be a similarity score right based on that similarity score we have to do a similarity search right similarity search so this is also there so similarity score similarity search this Vector database will give you everything Vector database will give you the everything so that's why we directly use this preconfigured Vector database and here also like it is running on some sort of a server and there are also some computation and all uh which is included which I let you know right so how to configure the cluster and all regarding this Vector database yeah so if we are going to store the data store this like embedding in a no SQL database so here also we'll have to make some configuration and it is not that much efficient but this Vector database actually it is giving us everything where we just need to store the uh value we where we just need to store the data in the form of vector that's it got it now here uh I hope this part is clear to all of you this vector embeddings and all now let me go through with the next slide so here again uh same thing is there so we have embeddings so we have a vectors and along with that there will be indexing as I told you now so if we are going to store this data if we are going to store this particular data inside the uh no SQL right if we are going to store this particular data inside the no SQL databases again we'll have to make like a some configuration and all according to the uh the vector which we are going to generate we'll have to conclude the we'll have to write down the indexing and all and uh maybe we'll have to write it down the label also to identify this embedding right so many things is there but we can do it by using the no SQL now here uh uh let's uh understand about the vector databases already I talked about it and here you can see uh we have a data which we are going to store inside the traditional data a vector database index and store Vector embedding for faster uh retrievable and similarity search right so for the faster retrieval and similarity search we always use this Vector database instead of the traditional database we never use this for storing the vector for restoring the this vector and all now use cases of the vector database so here longterm memory for llm semantics s similarity search recommendation is that the main thing is this one only the semantic search and the similarity search this concept uh initially this concept has been introduced by the Google itself if you search about this Vector database now it become too much popular after coming like different different llms and all and like this type of operation actually there are like uh you will find out so many operation like where you have the similarity search and the semantic search semantic meaning and all and where you have to sustain the longterm memory right so because of that this Vector database become too much popular uh I hope this thing is clear to all of you about the vector database now we we have couple of name uh now this Vector database this F from the openi side right so you will find out this F over the openi website actually it's a research of the meta now here is a webb8 here is a choma DB pine cone is there redus is also there there are so many database or so many Vector database you will getting you will be find you will be able to find out now uh we are going to use this Pine con and chroma DV and will show you the babyit also but uh not in today's session later on uh after this uh like chroma and pine con but in today's class first I will start from the pine con because it is a little uh simple compared to this chroma DB and the we8 if we are talking about this chroma DB and the we8 it is little uh tough to configure not tough actually compared to Pine con it is like little harder so first we start from the pine con itself and there we try to build our small uh U like QA system okay and here and later on we'll be talking about this chroma DB and the vate so let's start uh with the Practical demo so for that uh what we can do we can open our neural lab so guys uh tell me are you ready yes or no please do let me know the theory whatever uh part I have discussed whatever thing I have discussed through this PP uh those part is clear to all of you yes or no again I will come to this one after uh implementing uh in a python right after doing the Practical stuff and all and then again I will try to give you the revision and then the understanding will be more concrete to all of you okay tell me guys fast if uh you will say yes then I will proceed further great so let's start with the Practical implementation now so here you can see uh I opened my uh I opened my uh neurol lab sorry I opened my U ion website and here you will find out this neurol lab so just click on this neurol lab here uh which you will find out over the website just go and search the website ion. and there uh you will find out a option this neurol lab option just click on that and here you will get the interface neuro lab interface so uh what you need to do guys here after opening it you need to click on this start your lab okay so once you will click on this start your lab there you will find out of various option like big data data analytics data science programming web development and all so here click on this data science as of now uh like uh we are working in this particular segment data science so there you will find out all the related tool right whatever is required for the development so here you will find out all the tool whatever is uh like related for the development and uh here we are going to use this uh here we are going to use this jupyter lab so just click on this Jupiter lab after clicking on this data science just click on this Jupiter lab and here it will ask you the name you can uh provide your name also you can write it down your custom name so the name uh which I'm going to write it down over here so Vector database Vector DB okay now what I will do guys here I don't want to clone any repositories like I'm saying no I don't want to do it and then proceed so first you need to write down the name and then U like just select this particular option or no only just click on that and then launch your Jupiter instant so here you can see uh this instance is getting launched now this instance is getting launched and and here after launching this instance you can click on this Python 3 ipy kernel so just click on this particular option Python 3 ipy kernel and here you will get the file here you you will get the Untitled file so you can do the right click on that okay on top of this file and you can rename it so just do the right click on this particular file untitle do iynb and then click on this rename now here you can write down the name so let's say the name is what Pine con DB Pine con Vector DB Pine con Vector DB so here is the name the name is what the name is Pine con Vector DB now I am ready for my implementation I hope guys this is visible to all of you and you can clearly see this particular jupyter notebook please do let me know if you are able to do a setup if you are able to launch your jupyter notebook then please do let me know please write down the chat I am waiting for your reply do it guys fast yes or no I'm waiting for your reply if you have done all the setup entire setup then please do let me know in the chat sir show one more time yes I can show you one more time so click just open the neuro lab after opening the neuro lab here you will find out the option start your lab and my lab so don't click on this my lab because if you have already created a lab then only you will get your Labs the lab template over here so here what you can do guys tell me here you can click on this if you are using the first time right if you are creating your left first time or see we are doing first time now we are launching this jupyter notebook first time only throughout this uh throughout this geni commune session so click on this start your lab and here you will find out a different different template so just go with the data science and here click on this Jupiter template and then give your name or keep it by default only click on no and then proceed that's it that's a proed of that's that's a process and it's a very very simple so please do it guys and let me know then I will uh writing down the code over here waiting for your reply if you can write on the chat I think uh that is going to be great and let me share this uh link also okay I think let me check if I can share with all of you just a second great so now let's start with the session uh so let's start with the Practical implementation okay now here guys you can see so this is what this is my uh Jupiter lab now I will be writing the code from scratch and I will show you like what all whatever thing will be required so definitely I will show you in between and even I will show you that how you can generate an embedding how you can save it and we'll show you that how you can uh create a basic QA system right by using the openi Ming now here is what so here let's say uh so this is my blank notebook so first of all I need to install some Library so I'm I believe that you are uh doing along with me so please do it along with me because today I will go very very slow uh this is going to be a very important session for uh further projects the projects which we are going to do in our upcoming session so please guys do it along with me and I will be writing each and every line each and every code in front of you only so fine let's start now so here the first thing which we are going to install over here that's going to be a len chin so here I'm going to install Len chin let me write it down over here the second thing which we are going to install over here that's going to be a pine cone so here let me write it down pip install pip install pine cone so if you want to use the pine cone so you will have to install this pine cone client right I will come to the pine cone I will show you the pine con website also but first let's try to install this particular module so here the second thing is what Pine con cone client c e NT right the next thing which we are going to install over here that's going to be a p PDF so here let let me write it down Pi PDF okay Pi PDF py uh okay py PDF now the fourth thing which we are going to install over here that's going to be a open a so pip install open a right so pip install open and now there is one more Library which we need to install so here I can write it down pip install uh tick on so let me give you the name uh tick token so there is a library tick token so this is the library which you need to install take token so actually this library is a important one if we are going to call the open a embedding so it's a utility actually for that particular class for the embedding class got it now what I will do here so I will run it and it will be installing all the packages in my current workspace so here you can see guys my all the package is getting installed so meanwhile I can show you this Pine con so meanwhile uh I can show you the pine con uh just a second so just open your Google and here search about the pine just write it on the pine cone p i p i n e c o n e pine cone so once you will uh click on once you will like write it on this Pine con and you will hit enter so here you will find out the pine con website https www. pinec con. now click on that now open this particular website now here guys after uh clicking on that you'll find out this a particular interface this is the interface of the uh this is the interface of the pine con website so have you opened it guys tell me are you installing this uh are you installing all the library the library which I have written over here have you opened this Pine con website because from here I have to generate the API key if we are not if we are not going to generate API key in that case we won't be able to call this pine cone right so please uh do let me know if you have opened it so is it getting blurred or what so my screen is blood please do confirm guys please do let me know because I can see it is not a blood one it is a clear uh Crystal Clear actually and I can see in my screen please do confirm in the chat guys please write it down the chat if you have opened this uh pine cone and if you can clearly see this particular screen yes or no great now uh see here this is what this is my pine cone now what you will do see if you are uh if you are doing it first time then you need to sign up what you need to do you need to sign up so just click on the click on this sign up free and here you can and here you can uh basically you can uh sign up it will ask you about it will ask you the email ID username and it will ask you the like organization name and all it's a optional one only you just need to provide your email ID or you can directly sign up by using your email ID right you can directly sign up by using the email ID it is it is a very simple step just click on the sign up and uh then sign up by using your email ID and automatically you will be login so I already did it over here you can see I uh did it and this is what this is a interface which I will uh which you will get after the sign up right so first you need to open the website there you need to sign up right and after the sign up what you will do guys tell me after the sign up automatically you will be log in and you'll find out this particular page so if you are doing along with me so yes I can wait for you you can let me know in the chat and if you have done till here then I will proceed tell me guys first uh waiting for the reply so if you are hearing me if you are listening to me then uh please do let me know in the chat fine so let's start now here you can see see guys uh what you need to do uh here yeah in your case actually it is saying create the index now let me do one thing let me delete this index so I will show you from the starting so how to create the index and all and what is the meaning of it so let me delete this particular index and here guys you can see I deleted this index now in your case it is giving you the option for creating an index actually see if you are using a free version if you have created a free version right so in that case you can only create a single Index right if you're using a free tire free tire of this spine cone so in that case you only can create a single Index right so now uh the first thing what you need to do guys so here you need to click on this API key left hand side you can see this API key just click on this API key now once you will click on the API key so it will give you the option for creating a API key and one key you will find it over here by default so they have given you one key that's a by default key this one this one actually this one okay so this is the by default key which you can see over here uh which they which everyone will get it right and now here this is my key which I have created by clicking on this create API key got it so here this is my key which I have created or they will give you the by default key you can use this also otherwise you can create a new also both are fine right so if you have this by default key now you are well and good till here right you are fine till here so tell me guys are you getting this uh this key AR I think see there is some problem from your side because I can clearly see that everything is fine in my system and uh it is visible to all of other student so please check from your side as well it is working fine or not please check in your phone uh just try to refresh your system if you getting the blur screen because in my screen the feed is uh fine and I think no one is uh complaining about it so please check once yeah so if you are getting a default key then it is fine so if till here right if till here you proceed along with me then it is fine now let's go back to the code now here is my code guys here is my code file here is my ipb file so here guys you can see so I install this libraries pip install L chain Pine con Pi PDF open tikon I installed all the required Library is over here now let me do one thing let me write down the further code so here and the next cell after installing all the library whatever was there I'm running this uh like I'm running a further sale so here guys what I need to do so here now I'm going to import all the library so here already I have written the import statement now let me show you those import statement here is a import statement guys so the first import statement is pi PDF directory loader this is the first import statement the second four statement is recursively character text Splitter from the lenon itself now the third one open AI embedding right and the fourth one you'll find out that's the opener itself then we are going to import this spine cone from the vector store which is there inside the Len chain I'm using Len chain only and I told you this Len chain is a wrapper on top of each and every API right so whatever thing uh see better like you are if you're going to build this LM based application if you are using this Len chain so you will find out U everything inside the Len chain it's a wrapper on top of the every API on most of the API so here you can see you can import this pine cone from here itself from the Len chain right so from Len chain. Vector store and there is what there is a pine code now Len chain. llm here is a open a now Len chain chain here we have a retrieval QA each and everything will be clarified once I will write it on the code only now here you can see Len chen. prompt and here is what prompt template so you already know about the prompt template you already know about the open a you already know about the pi PDF directory loader this thing recursive character text splitter open a embedding and retrieval QA this thing is a new one so definitely I will explain you it don't worry so what I can do here uh let me do one thing if you are uh doing along with me I can give you this particular code and for that I what I can do I can share this uh Cod share. where I will be uh writing let me share with all of you this Cod share. okay just a second Cod share. yeah so here I can copy my entire code this is the code this is the input statement and here and here is what here is my all the library so which you need to install all the packages which is which you need to install now this is the just wait let me copy it from here this is the packages yep it is fine now and this is the import statement so import statement and here uh required package required package right now let me give you this particular link so here I'm giving you this link inside the chat just wait here it is here is the session which is going on now just wait here's the link guys here's the link of the here's the link of the Cod share. so please do confirm did you get it guys yes or no please uh do let me know inside the chat if you got this particular link yes or no I I given you this link inside the chat so please do confirm and don't worry my uh team will also give you that my team will ping you this link so inside the chat itself if I'm if I'm not able to do it just a second this one okay so I hope uh it is fine now yeah so now I hope you got a link please do let me know in the chat please do confirm I'm waiting for a reply and see guys just copy and paste the code don't remove from here right don't remove don't cut it from here just copy and paste yeah copy the entire code and run it inside your uh run inside your this uh IP VB yeah so I'm waiting uh please do it and then I will proceed further yeah this one okay proceed yes this uh file will be available over the dashboard Vishnu is karma is saying sir did not get a link I pasted now pasted inside the chat just look into the chat live chat check with your live chat we have we have given you that inside the chat itself fine so now let's uh move further here after installing all the library I need to import this statement so here you can see uh I'm able to import this particular statement okay so I have imported this particular statement now guys what I will do here here in this my in this my local workspace in my uh this workspace I'm going to create one folder right so I'm going going to create one folder and for creating a folder there's a command mkd so here I'm going to write it down mkd PDF right so here I'm going to create one folder the folder name is going to be a PDF so see guys uh left hand side if you will look into your workspace you will find out the PDF folder now inside this PDF I have to upload the PDF and from there itself uh see I can upload the text file or I can upload the PDF XL CSV so I just required a data right so I'm showing you this embedding and all I'm showing you this embedding and then I will store it then I will query it so on top of the uh real time PDF only I'm not going to create any dummy data over here right so in front of you only so here let's say h I'm opening my Google and from here I'm uh I'm searching about this attention all your need right so this is the Transformer research paper so let me open this research paper and let me me download it inside my system so here what I'm going to do guys so here I'm downloading this a particular yeah here I'm downloading this particular research paper inside my system right so see guys uh what I can do I can keep the name Transformer right so this is what this is my PDF now what I will do guys here uh let me check the size of this PDF uh if it is a huge one that definitely my neurol lab uh won't allow to me let me check if I'm able to upload it or not this Transformer in my neural lab so here what I will do I will click on this upload button here and I will click on my Transformer so as soon as I will click on this I will be able to select it then open it and here you can see my neural lab is saying entity is too large so what I can do here I can compress this PDF so for that I can use any uh online compressor so if uh your file size is little uh huge so in that case you can compress it if we are going to upload it inside your neural lab so here I'm writing about PDF uh compressor uh so here you can compress the PDF with any free compressor now here I'm using this particular uh website I'm opening my PDF and here it is giving the recommended compression now if I will click on the compress PDF so it got converted into a 137 MB from 2.11 MB now it is saying to me you can download it so I'm downloading this particular PDF and here Transformer compressor right so I got my compressed PDF it is very simple step you can open the Google and you can search about the PDF compressor if your PDF is too huge let's say see here we are using a PDF now for getting a data for collecting a data right real time data so for that only uh like I use this PDF compressor because this neural lab is not allying okay a file basically which is having the size around 2 MB 2.11 MB now let's see we are able to upload it or not so what I will do here I will use this Transformer compressed and if I'm going to upload it or still it is saying that request entity to larger okay just wait uh let me compress it again uh select PDF and here is a compress PDF because I want to make it a small only now extreme compressor okay this one only let's see what will be the size of it no just a second select PDF and here compress PDF extremely comparison uh the size is going to be 1.3 MB I don't think this lab will allow to me just a second otherwise I will have to use any other file um this just a second let me check so it is saying request entity too large no issue no worry uh see what I did actually let me show you my download section so here before the class itself I have uh I was exploring it and I downloaded couple of PDF so this was the PDF actually this was this is a YOLO research paper so let me show you this particular PDF this one see this is the YOLO research paper YOLO V7 okay YOLO V7 as of now I was trying to show you with attention all your need paper but it is not allowing because uh the size is a little huge see the size of this compressed file 540 KB only now here the size of this Transformer compress around 1,339 so actually it is not allowing to me to upload this particular PDF so in that case what you can do so here uh you can uh we can use this YOLO V7 paper now what I'm going to do let me first of all rename this particular paper okay uh I will have to close it from here just a second now let me rename this paper so here I'm going to write it down YOLO V7 so this is what this is my YOLO V7 paper and now let me upload it over there because I want a data and I'm going to read the PDF and from there itself I am going to collect my data for converting into a embeding so now see it we have uploaded this particular PDF so if your PDF is uh exceeding exceeding the size the size is around 1 MB so it won't allow to you you cannot upload the PDF in our neural lab so don't worry it will be solved in our near a future sessions so our team is working on that and it is U we are like uh making it more powerful as well so don't worry many more functionality will find out over here itself inside the lab now we got this YOLO V7 now what I will do guys so here I'm going to read this PDF so for that already I'm uh for that basically already I have imported this particular class so here I'm uh like passing it I'm copying and pasting over here and then here I'm writing PDFs right so once I will write on the PDFs so see it is giving me that PDFs is not defined uh PDFs where is a PDF okay so actually I will have to pass in a double code just wait let me take in a double code yes so I I'm able to load this PDF actually whatever we have inside this PDF folder now what I will do guys here I'm going to write down the loader so this is what this is my loader and now what I will do guys so here I will call loader loader. load right so by using this particular code I will be able to read my PDF see this is what this is my PDF now here I can collect this data so this is what this is my data which I'm going to be convert into a vectors with that I'm going to making a like embeddings and all and that embedding I'm going to store inside my dat database inside my Vector database which is a pine gon right so now let me show you this data so here is what guys here is my data which you can see over here and it is in a list format list form so here just press zero so you will find out all the data entire data basically uh whatever we have inside the PDF this is what this is my data right now here we are able to load the PDF now guys let me give you this particular code so at least you all can run inside your system so just a second uh here is a code guys this one for loading the PDF and here we have one more function that's going to be a data do load so loader do load actually just a second let me copy and paste over here this one so loader and here basically we have a PDF and we are able to load the data now uh yes we are able to get a data now what I will do guys so here I will perform the uh like a tokenization right right so here the next step is going to be a tokenization one let me show you uh The Next Step so what I'm going to do let me do one thing let me copy and paste and here is what here is my next step basically so just look into the step what I'm doing here I'm calling this recursive character text splitter right and here my chunk size will be 500 and chunk overlap will be 20 right so just just go through and check over the Google or what you can do directly you can copy this particular import statement open it just just copy it and open your Google and paste it over there then you will get the complete definition of it over here inside the lench documentation now just look into that just look into this recover split by character so this text splitter is recommended for one for generic text it is parameterized by list of character it is trying to splitting one of them in order to until chunks are small enough the default list is this one means uh if it is going to find out any uh character right so based on this particular character is going to divide the data into a tokens this has the effect of trying to keep all paragraph and the sentences and the word together as long as possible and those would generally seems to be strongest semantically related piece of text so it is going to create a tokens it's going to uh split the text right if we are passing any sort of a text to this particular method so definitely going to be splited now over here see we are going to open this particular text here is what here is my data now I'm going to create a I'm going to import this particular class and here I'm passing the different different parameter so there is a chunk size so set a really small chunk size just to show so here the chunk size what 100 chunk overlap 20 length function is length itself and is separator regx is equal to false right now here uh what I did so here I call this particular method create documented and here I'm going to pass my data so it will be able to create a chunks it will be able to create a chunks which is having a size of 100 and the overlap chunk overlap is equal to 20 right now let's do one thing let's try to do it by using R data now over here you can see we are able to create a object of it so Rec character text split chunk size 500 and Chun overlap is 20 now here I'm going to create a object of it so here is my object text splitter and after that guys what I will do I'm going to call one method over here so here let me show you the method this is what this is my method a text chunks to text splitter. split document this is what this is my method and to this particular method I'm passing my data right to this particular method I am passing my data now let me run it and here you can see we have the chunks of the text so text underscore chunks now here guys you will see so we are able to convert our text into a various chunks now let me show you so here this is inside the dictionary so let me do one thing let me first of all scroll down till last okay and here I'm going to pass this chance now here let me write down the zero so this is my first chunk right so we we have approximately 500 tokens right now of 500 chugs basically we have created from that and this is the like first one right now over here what I'm going to do see uh here I'm going to write it down the print statement right so I'm going to pass this value in a print function and here you will see that we have a data this is what this is my data now here textor chunks and in a square bracket we have a zero now what I will do I will call this page content right so pageor content so here guys you will find out this is what this is my content right so this is what this is my first one now let me show you the second one here is what here is my second one see uh the uh here if I'm passing first this is my second one right now this is what this is my third one right so here what I can do I can pass two and this is what this is my third chunk so we are going to convert or we are going to divide our data into a chunks right and this is the first chunk this is the second chunk now here is a third chunk this is what this is my chunk actually and from where from our PDF data right from our PDF data now if you will check the length of it so here let me do one thing let me check the length of this textor chunks right so here is the length of text underscore chunks Chu Ms now you will find out the chunks length is 152 means total 152 are like paragraphs you will find out from the data itself right so the chunks basically which we are making which we which we have made are from from the data itself the data which we have loaded right so here is what here is my 152 chunks and this is my first second third now you can print the 152 chunks as well so here what you can do you can write it down the 151 actually that will be a 152 chunks because the index is going to start from the zero so now let me print it and here you will find out the last one so former 4 and 2 and object detection in proceeding the International Conference or learning representation now if you want to do it see here uh I did it randomly means uh if you will look into the first chunk it is going to stop over here if you look into the second chunk it is going to be stop over here but if you want to do it based on any requirement right and based on any meaningful context which uh which is like required according to your problem statement so for that you will have to look into the data you will have to perform the text preprocessing over there right and then only you you will have to put some sort of a logic then okay if this thing is coming then only you have to cut the data if this thing is coming then only you have to cut the data right so here you will see guys uh like we are able to create uh like chunks over here right so um there is uh total 152 actually now what I will do after doing this thing uh I have shown you the chunks and all now let me show you the next one now what I will do guys here uh first of all let me uh open the openi openi API key now here I'm going to write it down this uh import OS and here OS do os. getb now here what I'm passing I'm passing this open API key right I'm going to set my open API key so all value will be in a cap so open AI underscore API underscore key got it now here I'm going to pass my API key now let me generate the API ke I think I already generated it let me copy it from there itself h let me open the open okay here it is this one this is the OPI key now what I can do I can paste it over here this one so yes I'm able to set my open AI API key right this is fine okay now get En the assignment what is this okay open AI which I don't want to fetch it actually I want to set it so there is a different uh like name in wire e NV R actually this is the name so I want to set the like API key in my environment variable in my system environment variable so this is the method got it now this is fine we have created a chunks and uh everything is fine now what I will do I will create a object of the open embeding open emding class so let me show you what I can do I can open my my open a let me open the open a itself just a second open AI right now here uh just go with the documentation just just click on the documentation over here yeah this is what this is your documentation just scroll down there you will find out the embeddings got it now click on the embeddings here is embedding now uh what you need to do guys here you need to import this embedding okay this this particular embeddings okay so if if I want to convert my data into a vectors if I want to if I want to make it like the vector actually the context Vector so I I'm going to use this embedding from the open a now how I can do that how I can use it let me show you so for that what uh you can do so here uh we have a class direct class actually open I aming which I which I have imported over here if you will look into the import statement right so already I have imported this thing and where it is let me show you over here see this one open AI right uh open AI M okay this one uh where it is open embedding so from Lang CH actually we are going to import this openi embedding now what I can do I can create a object of it so I'm going to create a object of the open a embedding and here what I'm going to do I'm going to keep this thing inside the embedding itself so this is what this is my embedding right open a embedding okay now the next is what so here I'm going to write it down I'm going to call one method so the method is what the method is nothing so aming dot and here I'm writing idore query so idore query and here what I will do guys here I'm going to pass something so here I'm passing how are you right so once I will run it so here I have passed how are you now see it will generate the embedding for it see guys it have generated an embedding if see I told you how it is going to generate embeding bding it's going to generate an amb bidding based on a features right based on a feature so I told you guys see uh when I was talking about the word to bag right just a second when I was talking about the word to bag when I was talking about the word to back so actually there was there was the vector that the size was the vector of 300 right 300 Dimension now if you will look into the open AI embedding so let's check the size of that so so uh this sentence actually they have converted into a vector now let's look into the size that what size I'm getting or for this particular Vector so over here I can copy it and what I can do just a second let me scroll down because the vector size is very very huge uh just a wait here is what here is my embedding okay just just wait guys so let me keep it inside the variable yeah here it is this one so what I can do I can directly call this length function over here so let me show you the number of embeddings over here so the number of embedding is 1 53 6 this is the length of the embeded vector getting my point guys yes or no so here is my sentence how are you I given this sentence and based on this sentence is it has generated one vector which is the size of the vector is 1 53 6 the size of the vector is 53 6 got it so I hope this part is clear to all of you now um I got the vector I got the length also now let's try to discuss so here uh we have this open AI right so we have this open a actually uh we have the open a API we able to call this open a embeddings everything is working fine everything is uh going seamlessly right now over here this is my data also so we have a data we have a open a now it's time to import this pine cone right so now let's uh like import the pine cone and whatever embedding we are going to generate from here so the embedding I'm going to store in my pine cone Vector database so for that basically what I'm going to do here uh here uh the first thing which I'm going to write it down that's going to be my Pine one API key right there is two thing two variable now what I can do till here I think everything is fine and please set your openi key and call the just just create this model let me give you this uh thing over here this one so you all can copy and you all can run along with me and this is also let me remove it as of now from here and Yep this is the one now you need to write it down your own so here is what here is the open AI key which you need to set right and the next one open a embedding and here if you're going to call it then everything is going fine right so just a second this is the length of the ambic now the next one basically what I can do here I can give you this particular code also so okay first of all let me remove this thing this particular thing and here let me remove this thing also so fine uh now it is clear and you can run along with me so please check out the link this Cod share. link inside the uh inside the chat box guys and please try to copy from there please try to copy this code from there right now uh see guys uh one more thing if you are liking the session then please hit the like button okay this motivates me a lot and please write down the comment please be active in the chat if I'm asking something see I've seen many people are seeing this this one many people are watching it in a live uh in a live mode but they don't interact actually please be interactive if you are interacting that definitely I will also get a motivation I will show you like two to three more new thing if you're not doing that in that case um it will be hard for me also I will stop it this session by explaining you one or two concept only if you are asking to me then basically definitely I will explain you few more thing few more concept got it so please be interactive please write down the chat and please hit the like button if you're liking the session so far now guys here what I need to do I need to set the pine con API key right Pine con API key so from where you will get it so just open the pine con website so here is my pine cone just go inside the API key and here is my API key so you can use the default also or you can create the new also so here I have created a new one so let me copy this particular key and let me paste it over here that is the first thing which I need to do right the second thing I need to pass pine cone API environment so where I will get it where I will find out this pine cone just click on the fine code website here is the environment name just copy this thing copy this gcp starter and here you can paste it inside the double code right so I think both thing is fine now let me set it okay this is fine this is clear now guys what I need to do here I need to import the pine C so here I'm going to import the pine C yes uh I imported it not an issue so there is no such issue with that now here guys what I'm going to do so I'm going to call one method and this method is going to be a very very important so my method name is what pine cone in it right see guys over here just just look over here uh this is not a typical at all what we are going to do see uh this is the method and which method we are going to call Pine con. init so here itself in a pine con documentation you will find out let me show you uh just just search over the uh just click on this document and here is what here is a pine cone documentation now just just click on the quick start uh once you will click on the quick start now so there you will find out the like all the thing right so here you need to import the pine cone here you need to set or you need to set your API key and your environment name everything is here everything over the like website itself in the documentation itself I'm taking a reference from the documentation now the next thing is what you need to call this init method so let me do it and let me run it yes this is done we are able to do it and here I can give you this code as well inside the code share. so this is the code guys which I'm going to paste and there is what there is an import statement also which I'm going to paste over here just a second so you can copy along with me and you can run it you can test it because it is going to be a more interesting now so this last 20 minutes is a climax of the session is going to be a more interesting so just wait for next 20 minute and you will see the magic right so how efficient it is how like it is working actually you will find out a final conclusion over here now we have initialize it now the next thing we have to initialize the index name so here is what here is my index name which I have to initialize so where I will find out the index name so just go through with your pine cone and here click on the indexes here right so click on the indexes and click on this create index see this uh actually this pine cone now it is running on top of the cloud once you will search over the uh once you will search about this pine cone just let me show you uh search about the pine cone so open open the website and here you will find out that it is working on top of the cloud so the server basically which is using Cloud Server the AWS Ser or a server anything we can use okay uh just a second guys just a second just a wait uh I think I'm getting some issue with the connection just allow me a minute just wait yeah now I think it is fine so yep now it is clear now it is fine so here guys you can see if we are talking about if we are talking about this pine cone right so if we if we are talking about this pine cone now so this actually it is being created on top of the Cloud Server so here they have given you the entire detail so just check with the product uh so each and everything you will get about this pine cone right and here you will find out that it is going to fully managed by the AWS server either you can use AWS or Google or Azure and here there is a pricing detail also so you will find out the pricing detail how much it's going to be charged for the specific P for the indexes the index which you are going to create how you can scale it right everything you will get it so as of now we are using a free plan free tire of the spine cone but it is getting uh it's a chargeable also so you will see the prices and all prices is 0.096 per hour 0.111 144r right this this for the Enterprise the standard this the like just a free version of it just just go through with the website everything you will find out over there itself now here I have to create the index name now how I can do it how I can create the index name so just click on the index this this particular index and here it will give you the option for creating index so just write it down your name let's say my index name is testing and here you need to mention the Dimension right so just look into the dimension that what was the dimension over there so let me uh do one thing let me show you the dimension of that so for that basically just scroll up see here 1 1536 so this was the dimension actually when I checked uh with the open I'm Ming so here you will find out that this is the dimension which I'm getting you you can check with regarding the other sentences also so here uh let's say if I'm saying something whatever uh let me do one thing let me copy and let me paste it over here here I'm saying uh I am fine right hi hi I am fine so this is what this is my like sentence which I'm writing over here now you will find out the embedding and let me show you the dimension of this particular embedding now here you will find out the dimension is around 1 536 it's the same one right so this Dimension is nothing it's a feature right so how many feature is there I I told you now uh when I'm talking about word to back there is 300 feature I shown you this example just just look into this particular example so we this is a vocabulary and we have five feature by using this five feature I'm representing my data so here actually in opena edding there is 1 5 3 six feature by using that they are representing a data so here the size of the embedding is going to be 1536 so what do you need to do guys here you need to write it down 1 53 6 now it will ask you about the metrix so what should be the metrix for the for the simulat search so here there is a three option dot product equan and cosine so here I'm using the cosine because the uh cosine is a uh like little impactful compared to this dot product and the ukan right so here just click on the cosign and here I'm using the free plan free plan of the pine cone right so now this is fine this is clear let's create a index over here if you are going to click on this create index so it is creating an index so index creating file to create capacitor is okay so I already created one index now see uh yeah now it is fine uh it is created and here you can click on the connect and there this will give you the all the details and all now this is what this is my index name testing is what testing is my index name I hope you are able to create this index and here you will get this Green Dot green icon now what I can do I can pass the name so here I can write it down the index this my index name that is what that is a testing right so here is what here is my index name that's going to be a testing now what I will do guys I will run this particular line This one this uh which I shown you uh this one pine cone do index and equal to index so let me copy it and let me paste it over here let me paste it over here and here what I need to do guys tell me here I need to pass my index name this one right so this this index name actually I can pass directly means I can pass this particular name or I can pass directly also both are fine right so I believe you are able to set your index now what I will do guys so here um just a bit okay so now guys you need to create an embedding for each uh text Chunk so let me copy it and let me paste it over here this one this is going to be here this one so this is what this is my markdown actually just let me write it down like this yes so now you need to create an embedding for each chunks okay so this is what this is my index and now till here everything is fine right now guys what I will do so I need to create an embedding right so for that let me show you the code so here is the entire code this one this is my entire code so till here everything is fine you just need to call this one you just need to set this one let me give you this code as well so from here you can copy from my uh from my code share. you can copy just a second just a wait let me give you this particular like line of code and here guys you will find out so now we have to create an embedding for each of the text Chunk so whatever uh Chunk we have created from our PDF I'm going to create an embedding for that now here I'm saying from text t. page see I'm taking a uh text actually uh this is a list now so here I'm uh using this list comprehension so so this is my list of the text junk this is a text which we are getting now from here we are going to get a page content what is a page content I shown you this is a page contain this one so I'm using this for Loop and I'm collecting all the page content over here and I'm calling this embedding I'm using this I'm using this embedding object and here is my index name index name basically which I'm uh like which I have created this one okay this is my index name okay testing is my index name so three argument we are passing over here so Pine con from text and this is what this the three argument which we are passing over here first is data first is what first is a data the second is embedding and the third is what third is a index name right this one now if I will run it so over here you will find out that it is saying embeddings is not defined okay my name is iding only now let me keep it iding yeah it is fine and it is working so here is clear to all of you uh guys can you see my okay so can you see my vs code uh it is visible to all of you uh just a second now it is visible yes or no just a second guys just a second let me check once wait wait wait wait I'm checking don't worry don't worry I'm checking right just just wait just allow me a minute yeah yeah wait guys wait I'm checking just allow me a minute just allow Me 2 minute I'm checking with that now it is working fine now it is coming to all of you now can you see my code screen this one yes or no don't worry I will repeat it I will uh revise all the thing don't worry right just a second just a wait don't worry I can revive why is the thing whatever I did over here so just a second now see uh what I was saying we have created an index right so till index I think it was fine now I just created a embedding for each of the text Chunk means whatever chunks we have created now for that I'm going to create a indexing means I'm going to create a emitting right now from here actually see this is my text Chunk this is what this is my text Chunk one uh like uh uh basically I'm iterating on top of that I'm iterating on top of the chunks so here right now I'm getting the uh like first chunk and then I'm collecting the page content similarly you can see over here this one I'm going to collect a chunk now I'm going to collect a chunk Now by using this particular list comprehension by using this particular list comprehension I'm going to collect a chunk now here is my embedding object which I have passed and here is my index name which I have created by using the pine cone website right now just look into this code share. there I have given you the entire code till here now let me give you the last line also which I have run uh which I have created over here so here let me give you this particular line and here is what here is my dog search this one now guys what I will do this is what this is my dog search right now I have to call something first of all let me show you that what we have inside this dog search actually you will find out one object this is what this is the object right this is what this is the object see uh here is what here's a pine code now from text actually what I'm going to do from text text I'm going to create a embedding so whatever text whatever chunks whatever chunks we have right whatever chunks we have regarding those particular chunks we are going to create a embeddings right so here uh you can see we are going to call Pine Cone Dot from text and here is what here is my text and here is my edding right and here is what here is my index name don't worry if you are not able to connect I will give you the quick revision at the end right first just just look over here and just see what what is happening over here right so this is what guys this is my dog search now what I will do let me show you the next line Next Step that what I'm going to do over here okay so here actually uh I'm going to find out a s see uh after running this particular uh statement this Pine cone. fromom text right so here you are going to generate an embedding now just look into the dashboard the dashboard basically which we have over here uh let me show you so once you will refresh it now this one so here you will find out all all the embeddings all the embeddings from our PDF from our text right so just wait let me uh show you that here guys see this is what this is all the embeddings here is my uh text which I tokenize which I converted into a small small phrases and regarding that here is a embedding this one just just copy it and check it is a embedding Vector so this this text actually we are able to convert into a embeddings we are able to convert into a vector vectors and here you will find out the score also so this is representing a similarity score right how much it is similar to other sentences to other phrases right here you can see uh this is what this is my Ming don't don't worry if you not able to correlate just wait for some uh just wait for few minutes I will give you the quick revision of it right I will give you the quick revision by writing each and everything and then definitely you will be able to get it now here uh you can see this is what this is my embedding related to the particular text right and here what we have we have a score right related to this particular text we have a score this is what this is the score now what I will do so yes we are able to create an embedding and that embedding uh here you can see uh like it is visible you can uh access here also right by using this dog search uh I will show you how so first of all let me show you one example one uh small thing so what I'm going to do I'm doing a similarity search now here I'm writing query actually in the in my query actually what I'm doing I'm writing uh one statement and let me do the similarity search over here so here is what here is my sentence guys which I have written over here YOLO V7 outperform which model right so this is what this is my question this is my sentence now here is what here is my query which I'm going to uh which I have written basically now what I'm going to do I'm going to find out a similarity search right so let me do one thing let me find out the similarity search Now by using this Vector so here in this particular object we have all the vectors now I'm going to call one method that's going to be a similar to suchar and here we are going to pass our query this this particular query which I have written now let me show you what I will get over here so here you can see as soon as I run this particular uh uh like uh line okay this particular code so in the docs what you will find out let me show you so in the docs actually you can see this is the similarity search right this is the similarity search basically which we are able to get but the thing is over here we are getting in the form of Vector in the form of numbers it is not a proper sentences right now let me show you how we can convert this number into a sentences right so I hope till here everything is fine don't worry if you're not able to correlate if you're not able to understand once we'll create a project or right after the session after this particular session I will give you the quick recap of it right so based on that based on the quick recap you can correlate this particular implementation and then you can revise it right and then you can revise each and everything so over here you can see this is what this is my embedding this is my similarity search which I'm able to generate by using this particular query now I'm getting a number but I want a sentence how I can get it let me show you that also so for that guys what you need to do uh you need to create a llm means you need to call the uh uh like open API so over here uh we have this open method open a and here I'm going to create a object of it so yes definitely I'm able to call my open a API this one by using by creating this particular class right so here is what here is my llm right step by step step by step I'll try to go ahead don't worry now what I'm going to do here uh here actually I'm going to call this particular method the method name is what retrieval QA right so this is what this is my method name retrieval Q QA so this is a method this uh actually this class actually this is not a method this is a class and inside that we have a method the method name is from chain type so this is responsible for question answering if I want to create a question answer system so here in the open a itself you'll find out this retrieval QA right retrieval QA and inside that we have a method the method name is what from Chen type so here what we are doing we are passing this l M we are passing this chain type is stuff retriever is dog search do as retriever right this uh dot s retriever here you will find out this particular method right don't worry again I will explain you this particular part uh first of all let me run it and let me show you that what I will get from here so here I'm running it and here you can see we are able to create this QA the object of this retrieval QA right now guys what I will do here let me write down the query again right so here is what here is my query this is what this is my query now what I will do I'm going to um write down QA do run right and inside this run I am going to pass I'm going to pass my uh like query actually this is what this is my query and let's see what I will be getting based on that so here if I will write it down this Q qa. run and inside my query so now see guys what I'm getting over here um see I'm getting a similar see I'm getting an answer regarding this particular question I'm getting a similar search right I'm getting a similar search over here regarding this particular question now if I want to create a QA the small uh QA system so can I do it definitely we can do it now let me show you how we'll be able to create a small QA session over here so based on the PDF basically the PDF uh which uh I I'm using uh for the data right and with that I have generated a vector I have created an embedding and now over here you can see we are able to do the query also here you will find out so we are able to get it we are able to uh we are getting this similarity search in the form of uh numbers in the form of vector but here once I call this llm once I call the openi API and here is what here is my llm so I uh just use this retrieval QA and there I passed my llm I passed my uh retriever that's going to be a uh doc search itself right doc search itself let me show you what is this doc search it's the same object basically where my all the embedding is stored right so here what I can do I can show you this uh doc search. as retriever now see guys here what we have we have the pine cone actually this is the vector database openi we are using openi embedding and here my all the embedding is stored inside this particular object right now you can see over the uh UI also so here is all the embedding this one right regarding the data now what I can do see I can create one small uh QA session U like QA system over here for that I just need to write it down the basic uh code so here is my basic code guys this one so let me import one module over here that's going to be a CIS now what I'm saying that uh here I'm asking about the input so whenever I'm going to write it down the exit so it will be exit right in this condition I have mentioned that but here if I'm not uh writing down anything right so here it will be if I'm going to write down anything apart from this exit it will be continue and here you can see what we are doing QA so here we are passing the query whatever query we are getting from here and finally we are printing the answer right finally we are printing the answer now let me show you how the thing is running this this particular thing basically so what I can do let me run it and here I'm passing my input prompt so my input let's say I'm asking about the YOLO what is uh YOLO so here see based on this particular query it is giving me an answer it is finding out the iding it is finding out the similarity search and it has generated an answer based on a PDF so this is a PDF question answering right we are asking a question from the PDF and based on an embedding it is able to generate answer now I think you are able to correlate it that how the thing is working I will give you the complete uh flow right don't worry now here I'm asking who is invented who is invented the YOLO right so this is what this is my question now let's see so here I got the name I got the name now uh can you tell me about the so here what was the accuracy what was the accuracy what was the accuracy of the YOLO right so YOLO 7 uh YOLO V7 now let's see what I will be getting over here so here it is saying that YOLO V7 accuracy was 56.8 and here 56.8 AP uh test /d and AP Min SL value right so the accuracy we are getting now if I will write down exit over here so from here I'm going to exit now right from this question answer system now guys tell me uh yeah now it is perfect uh please quick uh give me a quick confirmation in the chat if it is perfect now yeah there was a issue from the internet side uh from the system side I don't know what was the sh screen got a stuck in between itself okay so let's uh try to revise this session I can give you quick revision of that and then uh we can close the session within 5 minutes right so here uh guys uh first of all see I'm using a pine cone and pine gon is what it's a vector database right so there are couple of import statement which I imported now after that see what I want to do I want to perform the mding right I want to perform the mding so on top of the on top of the data only I will I I I'm going to perform now so I will be having a data the data is going to be Text data so from where I'm getting this data I'm getting this text Data from the PDF the PDF which we have imported right the YOLO PDF the YOLO PDF right now here is what here is my PDF after uh importing the data what I did right after that I converted into a chunks by using this text splitter so here one chunk size will be approx 500 wordss right inside one chunk we'll be having the 500 wordss and chunk overlap I've given the 20 it's just the score that how many any uh like words can be overlap in each and every chunk right the chunk has been created now this is going to be a chunk size this is going to be a overlapping now this value you will find out the value of this Chun overlap between 0 to 100 right you can mention the value according to that so we have created a several chunks this is the list basically which I got after the chunking so here we have total 153 chunk and the each chunk is having average 500 wats means the size is around 500 over here got it so this is what this is my chunk now you will find out the complete list and here you will find out 152 chunks right from the data I converted my data into a chunks and there is 152 chunks actually see over here now if you want to find out the content the data from each and every chunk so here is a like way so this is my first Chunk from that uh like on top of that I'm just going to be call this particular attribute page content and there is what there is my page content there is what guys there is my page content over here which you can see now guys uh here uh you can see this is what this is my page content now you can uh get uh like page content and all with respect to each and every chunk till 152 right over here now over here I have to set my open AI key first of all after chunking and all this is fine now I have to set my openi key and from there I have to import this Ming now the size of the mding is 1536 this is based on a feature right so this is the size of the embedding now this is fine so first I got the data the second I have uh imported the open a embedding the third one I have seted this key right so here I set the key key Pine con API key and pine con API environment so here I have to set two thing the first is what Pine con API key and the second is Pine con API environment is after that you can see over here I'm going to call this Pine con init now here I'm going to pass this Pine con API key and pine con API inv environment right I have initialized it that's it now here I have to create an index so for creating an index just go with a pine con and here you will get a option to create an index right you can create a new index but if you are in a free tire so in that case you will be able to create only single Index right and while creating an index you need to pass a index name you need to pass a embedding and to search the method cosine similarity dot product or maybe some other method is there so you can select a cosine similarity over there got it after that guys see so after that what I did so this is what this is my index basically this is the name of the index now what I did here I called one method Pine con from text and here is what here is my text and here is my eding and here is my index name getting my point then what I'm going to do I'm going to create a eding and that I'm going to store inside the database here here this one okay so here here I'm storing I'm here I'm storing my embedding okay here I'm storing my embedding into my Vector database at this particular line you can see over here just just open it and you will be able to find out the you will be able to find out the text and the vector along with that gotting my point now after that what I'm going to do see here uh I'm going to query actually here you will find out the similarity score also this one right so this is based on a similarity it is going to a similar not regarding the other vectors okay so this is the score which you can see now what I'm going to do I'm going to find out the similarity search so here it is giving me a similarity search but you will find out it is a vector it is not giving me a sentence so for that what I'm going to do here see I'm going to call my open API and here this is my llm GPD model text thein whatever model is there now here is my chain type it's a stuff means it's a normal one simple chain okay now here you can see retriever in in the retriever actually this is my all the embedding this is my all the embedding right so here I'm like calling this method retrieval QA means here I'm uh like calling here I'm creating object of this retrieval QA and there is what there is my method from chain type this is my model llm model and here is my embedding all the embedding from the vector database now this is what this is my QA right I created object of QA now here is my query I'm asking YOLO outperform which model so here I'm asking YOLO output of which model if I'm run qa. run and here is what here is my query it will give me an answer it will give me answer based on a similarity search and from where it is going to from where it is giving me answer how it is going to search so here you will find out inside the vector database we have a score we have a vector so it is checking with this particular score and based on a similarity search based on a cosine similarity it is giving me answer after searching okay after searching inside the vector database which is nothing which is a pine cone and here you can see the UI of that where I have stored the C where I have store the uh like edding along with the text here you can see each and everything over the dashboard itself now let me uh scroll down and here I have created a simple QA simple QA system so based on this particular PDF so you can say uh like QA uh QA like PDF QA you can you can give the name uh basically PDF question answering and all whatever so whatever PDF you are going to upload or whatever PDF you are going to so from whatever P PDF you are going to collect a data based on that you will be do a question answering and based on a similarity score it is finding out a vector and it is giving you the response and here you can see it is working fine for me and I hope it is working for you as well now everything is clear guys tell me whatever I have explained over here I hope it is clear and it is perfect now now once you will revise it by yourself once you will run this code by by yourself definitely you will get each and everything so I just want a quick confirmation and then I will conclude the session okay tell me guys fast and please hit the like button also if you like the session if you like the content and I have explained you from very scratch from very starting so please do let me know did you like it uh now if you are able to understand then please tell me sir how the score is decided of the chunk based on a cosine similarity so we have a vector and regarding that Vector we are searching the we are we are like collecting a cosine similarity we are finding out a cosine similarity while we are creating an index at that time we have uh like defined over there the vector search will be based on a cosine similarity so that is a score of the cosine similarity okay it can read all the pages it can read all the PDF pages and all you can read like entire PDF whatever pages is there not even single all the like pages okay you can check it you can run it you can take a like PDF where you have uh 10 to 15 pages and then uh then like try to uh read the PDF by using this PDF loader or you can use any PDF loader I'm not restricting you to the till this Len CH only any PDF is there just try to use that particular PDF loader that's it great fine uh so I hope you have you have entire code over here now let me give you the further code as well after this a pine cone that whatever I have written you can directly copy from here and don't worry my team will give you the entire file and all in a resource section it will be uploaded so here is a code for the QA so let me give you that uh inside this code search and apart from that we have a code for the open all so let me give you that also so Pine con is fine this is fine now yeah this is the doc search which is uh here now let me okay this is already here so now the next code is what retriever search this is there okay similarity search just just check with that check with the similarity search I think everything will be fine now the next is what so next is this uh this particular method and here is this particular method now what I can do open a yep open a is there and here okay open AI is there now we have the next also this is the method and here you can call this qa. run so let me give give you this and let me give you this QA do run this one so fine I think now everything is perfect now everything is clear tomorrow I will teach you one more Vector database the vector database concept will uh will more clear to all of you and then we are going to initiate one more project that we are going to continue in our next week uh so from Monday onwards uh we are going to start one more project but tomorrow tomorrow I will explain you one more V Vector databases and few more topic I will try to discuss with you and I will discuss one project idea as well the complete idea related to that particular project and from Monday onwards we can start uh with that particular project and we can Implement in a live class itself okay yeah good afternoon good afternoon to all so today is a today is the day 10 and we have completed day n u actually so nine lectures successfully related to this generative AI so we started last week uh last week on Monday and so far uh we have completed nine lecture and today is a is the day 10 so today actually I will be discussing about few more uh Advanced topic and then uh next week we'll try to complete one more project uh which will be related to the uh like which will be related to the to this today's topic this RG and this Vector database and all so we have started from very basic and then I came to the lenen and open and then I discuss about the hugging phase then uh I completed one project as well we deployed also and then uh I came to this vecta databases uh so now uh if you are following me so I have already told you regarding the dashboard and all so where you will find out all the dash all the materials and how to navigate to the dashboard okay so where you'll find out the recorded session here in the uh like uh this is the Inon YouTube channel so once you will go through with the Inon YouTube channel so just click on that click on the Inon YouTube channel here my live is going on as of now so just just click on this live section just go through the live section and here you will find out all the videos now uh if you will click on this particular video where I have discussed about about the vector databases so in my previous session I have discussed about the vector databases I told you that what is a vector database why why it is required and then we have created one QA system also based on the embeding so if you don't know about it if you have uh if you haven't seen this uh session so please go and check there uh your all the basics will be clarified and once you will go through with the entire session all the session if you are beginner so definitely guys this uh session is going to help you aot a lot related to the generative a and all so I would recommend uh this particular series to all of you uh because soon we are going to and and this one and next week actually so next week we will try to do one more project that is going to be end to end project which will be directly related to this uh Vector database and all there we are going to use everything and even we'll introduce the Llama model in that particular session in the in the upcoming session which is going to start from the Monday today I I'll be stuck with the vector database itself because there is one more database which I need to discuss Then I then only you can make a differences between uh different different Vector databases so that's why I picked one more database that's going to be a chroma DV so in today's class we're going to talk about the chroma DV how chroma DV Works how it is different from the pine cone and uh on which basis on which uh like uh on which basis actually we have to decide that uh what should be my database for my and project or for my uh indry ready project so each and everything we're going to discuss over here we're going to uh like uh I will tell you in a live session so here is Inon YouTube channel where you will find out all my recordings so guys please go through with the Inon YouTube channel and try to check with the description so in the description actually we have already given you the dashboard link so here in the DH uh in the description you'll find out the dashboard link this is the dashboard just click on that and this is a this is completely free right no need to pay anything for this particular dashboard I'm telling to the people who uh joined this session first time now here what you need to do here you just need to register yourself and after that uh you will get access of this particular course no need to pay anything you just need to sign up and login and then you can navigate to this particular course now once you will go through with the Course once you will go through with the dashboard so there you will find out all the recording now let's uh go through with the previous recording so here uh is is a recording of the day n so just click on that and here in the resource section you will find out all the resources so whatever resources I uh discuss in the class throughout the entire session so you will find out each and everything inside the resource section so I discuss this uh ipb file so the ipb file is available over here so you can visit the dashboard you can download this file and you can execute inside your system and you can revise your concept now here apart from this uh lectures and resources you will find out the quizzes you will find out the assignment so just visit this uh particular dashboard and there you'll find out everything and the link has been mentioned inside the description itself so just go and check in the description uh we have already given you the link here is a link so just click on that and try to enroll yourself uh uh in the dashboard now apart from that you will find out other social social media handles and different different channels of the I so please try to follow there we are uploading amazing content related to the uh like related to the different different topics so just just follow to uh just follow Ion on the Instagram and the other YouTube channel as well like Hindi YouTube channel see once you will check with the Hindi YouTube channel so here let me show you this Hindi YouTube channel of the Inon then you will find out a same playlist in the Hindi as well so there I have discussed each and everything in Hindi if you finding out a difficulty right say if you're finding out a difficulty uh like you're not getting anything in English so here you can cover a same thing right you can cover the same thing in Hindi as well here uh we have uploaded all the Hindi session right I'm taking the Hindi session uh so you can go and check this ion Tech Hindi Channel and here you'll find out the SQL series as well so we are taking live SQL classes now see uh this uh this is a sorab actually Sor is taking a live SQL classes and we are uh covering each each and everything whatever is required for the data science for the data analytics and for the data engineering job so guys please try to check with the Inon Tech Hindi there we are uploading uh like refined content or whatever uh is a trending thing in a Hindi itself and not even a single video we are uploading a complete playlist so you must visit this particular Channel and you should check with a Content now coming to coming back to my topic so here already we have discussed uh so many now today is day 10 of of this particular of this community Series so now let start with the day 10 where the topic will be a chroma DB so yesterday I have talked about the pine con so Pine con was a vector database so we use this Vector database for storing a vector right now here we have one more DB that's going to be a chroma DB so we'll try to talk about the chroma DB as well and we'll see the differences between this pine cone and the chroma DB that how it is are different from each other this pine cone and the chroma DB now one more thing which I would like to highlight over here see many people ask about the certificates and all so let's say if someone is going to complete the course right someone is going to complete the course so definitely in their mind there will be a like question so will I get a certificate or not so that thing also you will find over here over the LMS itself so you will find out three option on top of this uh dashboard the first is curriculum the second is analytics and the third is certificate so here you'll find out the entire curriculum here you'll find out your entire analytics so what all thing you have completed are you doing assignment or not each and everything you can uh track over here inside this analytics portal now the third one is a certificate so if you are going to complete at least 40% of the course right if you're going to complete at least 40% of the course then definitely you will be able to generate the certificate now how like the course uh that that uh that will be that how like the course will be completed right so how my system will get to know and then only you can generate a certificate see after completing a video after completing this particular video here you will find out the tick mark this this particular mark this blue tick mark so that mean the meaning is that so you are uh you have completed that particular video and the course name is what the course name is a foundational or generative AI Foundation of generative AI now uh once you will tick mark on this particular video it will be completed and now you can check inside the analytics also so here just look into the analytics so your video progress uh will be there right so you will find out the video progress over here so yeah this is fine this is clear to all of you now please go and check with the dashboard there you'll find out each and everything now apart from that one more thing which I would like to show you uh so uh I will uh I would like to introduce you uh with One dashboard one more dashboard so let me show you that particular dashboard so just go inside the course section and here uh inside the course section you will find out this generative AI right inside this boot camp now just click on that just click on this particular course so there is a course name is mastering generative AI with open AI Len CH and Lama index just scroll down till last and here you will find out a complete detail syllabus of of for this particular course now here actually we are going to cover each and everything related to the generative AI we are going to start from very basic from the foundation of a generative Ai and then we'll come to the like word embedding text reprocessing we'll talk about the llms we'll talk about the hung face API and other different apis as well and we'll talk about the L chain llama index these are the different different framework basically which we use for creating an llm based application and then you will find out end to endend project also so this entire curriculum is a industry ready curriculum and we have added so many things recent l or we are updating this particular cbus uh so there are so many things coming like day today actually so we are analyzing all those thing and we are finding out so whatever is required for the industry whatever is required for the community so definitely we based on that we are trying to update our syllabus so tomorrow itself if you will look into the syllabus you will find out a new changes right because many things is coming uh like dayto day right so regarding the fine tuning regarding the like evaluation of the model regarding the like Fast retrieval right so regarding the fast retrieval regarding the different different databases or different different llm So based on that only based on a current market we are updating this curriculum so just go and check uh over there just go and check with the Inon website and there you'll find out amazing curriculum and yes so this course is going to be start from 20 uh 20th of January right and here you will find out the language we have launched this particular course in English and here the duration is around 5 month and this is going to be a timing so timing is from 10 to 100 p.m. IST and this will be a live course right and here you will find out your instructor so Chris sir is there Sanu is there me uh is there and here is a buy so buy will also take a session uh means will also be a mentor along with me Sudan Su and Chris so guys uh please go and check uh with this particular dashboard with this particular course and for the further information you can contact with the sales team here you can drop your information so my sales team will contact to you fine so I hope I have clarified each and everything now if you have any sort of a doubt you can ask me and then we'll start with the Practical implementation tell me guys uh do you have any doubt sir where to find neurolab code for the McQ generator project it is not updated on GitHub so here is my GitHub which I already uh uploaded in my resource section you can go and check with a resource section let me give you that uh GitHub just a second and don't worry I will be pasting inside the chat also just go with my repository my GitHub repository there you will find out this McQ generator right this is the application not this one this one generative AI so let me open this generative Ai and yeah this is the app this is the complete application which I added in my uh resource section also let me show you where you'll find out that so Foundation generi course and here is the this is the just wait first let me give you this particular link and then uh I will show you so I'm giving to my team and they will uh directly P inside the chat okay just wait fine now I think we can start so guys uh all clear sir estra DV is a vector database or it's a no SQL database it's a no SQL database estra DV actually in a backend it is using the cassendra and cassendra is a no SQL database yesterday I discussed that whether you can use or not this estra DB this cassendra is a vector database I given you the each and every information regarding that just just look into that just go through with my previous session you will get to know uh great now I hope everyone is getting that so can we start here is a pine gon one so please give me a quick confirmation if we can start with the session then uh uh I will start writing the code so let me open my code share. also here I'm going I'm going to paste each and everything each and every line so I will okay let me give you this particular link also I'm giving you this code share. iio link just a second yeah this one so just a second guys you will get this particular link where I going to paste each and every line each and every line uh whatever I'm writing inside my Jupiter notebook so today uh we going to start with a chroma DB so for that guys what you can do so here first of all let me close everything and here is what here is my session which is going on so let me keep it somewhere and yes now it is perfect great so uh first of all what you need to do here here so first at the first place you need to launch your neural lab so just click on this neural lab guys just click on this neural lab and once you will click on this neuro lab so here you will find out this type of interface now there is two option the first option is start your lab and the second option is my lab so just click on this start your lab right if you have already created a lab if you have already uh created your uh jup instance definitely you can uh go inside my lab and you can launch the same jupyter instance and there you can write it down your code after creating the IP VB file that is also fine but I'm showing you from starting so here guys what you need to do you need to click on this start your lab so once you will click on that so it will ask you about the sign in and all so here you can sign in guys you can pass your email ID and it is completely flee no need to uh like pay anything for this neuro lab as of now so here you can see we have a different different stack so big data analytics data science programming and web development so what you can do here you can click on this data science so what you will click on that so here you'll get all the option whatever is required for developing a project in this data science if you are going to develop a project uh inside the data sence so here you will find out all the ID all the ID we have given you in the form of template you just need to click on that and you can launch your instance so now let me show you with this Jupiter so in today's session we're going to use the Jupiter and in the next session we're going to use this cond cond for end to end development and Jupiter just for the ipynb implementation right now here what I'm going to do so here I'm going to open my Jupiter so it will ask you the name so here I can write down the name chroma DV so today in today's class we're going to talk about the chroma DV which is nothing which is a database Vector database and here what I will do I will proceed it and then it will be launching the lab so guys please do it please please uh do along with me because today I'm I'm I will be going very very slow and each and every line of code I will be pasting inside the coda.io so that you can copy from there how many of you you are doing along with me please uh write it down the chat I'm waiting for a reply sir I have a interview for the gener position can give me some tips and project so if you are asking about the tips if you have a generative AI uh like if you have an interview to generative so first of all your foundation should be strong and there you need to discuss about the project right so the the pro whatever like practical implementation I have discussed throughout this commun series you can go through with that and you can prepare that so the question you will get around to that only so there will they will ask you uh are you using this API why you are why you are using it what is the cost of that can you prize it what all Alternatives we have so what is the concept of the vector database why we cannot use other database what is the concept of the RG how we can finetune the model what is the cost what will be the cost of the fine tune fine tuning of the model can be like can we like keep in keep it in a scal scalable mode or not right so uh can we do a uh like like CPU based finetuning right there is a like if the model is very very huge so in that case how uh if the model is very very huge so in that case how I can load it so in that case you need to say that I I can use the quantize model model so this type of question you can assume inside the interview right so don't worry I will share one PDF there I will keep all the interview question related to the generate Ai and it will be available on your dashboard got it don't worry got it raes Ramesh nangi fine uh I think it is taking time so let me refresh it and then again I will launch just a second guys I have refreshed it now let's see oh why it is taking too much time yeah now it's done so let me launch then uh I kernel let let me launch this IPython notebook so please uh give me a quick confirmation if you are able to see this tell me guys so here I can print all okay yeah so guys all okay no we are not going to do a fine tuning in a community session so we'll restrict this community session till uh the project itself till that end to end project where we are going to call the API that's it the so tell me guys all okay yes or no and I think everything is visible to all of you right so can we start and first of all let me save this notebook so here I can write it down this chroma DV so my notebook name is what my notebook name is a chroma DB so let's start uh let's start with the chroma DB so first of all guys uh let me give you the brief introduction about the chroma DB that what is a chroma DB and why we are using it so let's uh search together and here let's search about the chroma DB so once I will search uh here the chroma DB so here you will find out the very first website of the chroma DB just click on that and let me open it first of all so here is what here is a chroma DV guys now they have given you the different different option right so here you will find out a different different option on top of this website so the first one is a documentation the second is a GitHub the third one is a discard Community the fourth one is a Blog and here they have written that we are hiring and here launching multimodel so they have announced multimodel also now from here you can start here you can find out the demo as well so you can uh like check with the demo and here you will find out the the complete architecture which they have given to you and like what you are going to do here tell me you are going to convert your queries into a vector and that Vector basically are going to save it right that Vector that particular Vector you are going to save it now here uh let's try to discuss about the uh difference between this chroma DB and the pine but first of all let me go through with the documentation so here is a demo demo of the chroma DB which you will find out over here inside the collab notebook which they have provided you over the website itself now if you want to look into the source code so here they have given the source code as well this is the GitHub just click on that and here you will find out the complete source code of the chroma DB so the uh this chroma DB is a open source database and here you can see the number of contributor how many contributor is there 86 contributors is there like 10.7k people has already used this particular um database now here you will find out the 9 92 commits and if you will look into the package if you look into the pp package so let's see the first version and the last version the latest version of the chroma DB so here you can write it down this chroma DB chroma DB on top of the Google Now here you will find out the web this uh P by page so this is the latest version of the chroma DV 0.420 right now if you will look into the previous version if you want to check with that so just click on that just click on this release history you'll find out the entire history of this chroma version so how frequently they are updating the thing uh so they haven't completed even one year right and here you will find out that these many of version uh like you will find out you will get it related to this chroma DB because it is a open source now here you will find out so many contributor inside this chroma DB you can check with the contributor list you can check with the contributor name here and here you can see the entire community so guys uh this is the contributor now used by 10.7k people and here you will find out the fork number of fork and the star so just go through with this particular GitHub there you will find out the entire detail related to the chroma DV where you will get it so you will get this thing or the website itself so here on top of the website you'll find out a different different options so they have you there you will find out the GitHub and even you can join the community of this chroma DB so they have given you the option of the Discord so just click on that and you can join their community on Discord so whatever doubts and all you have so you can ask it over the Discord now coming to the documentation so here is a documentation of the chroma DB so just look into the documentation here you will find out each and everything whatever is required for understanding this chroma DB so let's start with the getting it started now here they have given you the two option the first one is going to be a python this one and the second option is going to be JavaScript right so the first option is a python the second option is a Java script now uh here you will find out the installation detail how to install this thing now here you'll find out how to create a client from the chroma DB so if you want to create a client of the chroma DB so here is a option for creating a client for the of the chroma DB now here uh how to create a collections and all so this is the collection and here how to add it now how to query The Collection each and everything you will find out over here so guys once you will install this particular package you will get everything over here this is not a cloudbased database it's a like a local database there if you will download this thing so everything you will get inside the local itself so there the first major difference between the pine cone and the chroma DB so chroma DB actually it's not a cloud based database and here actually see it's not a cloud base here everything you will do inside the local itself right so here you will do everything inside the local itself in your local workspace but if we are talking about the pine cone so it's a cloudbased database so in that you have seen you must have seen let me show you the pine con website as well so here if I'm writing down this a pine con so you will find out here over the pine con that it's a vector database for the vector search now just scroll down here so here you will find out a different different Cloud oper Cloud uh operator so it is fully managed by Google gcp AWS and AO anywhere you can create an instance and then you can utilize it after installing this inside your local system so everything will be available over the cloud after configuring this pine cone so that the first major difference between the pine code and this chroma DB now coming to the point so here uh we are talking about the chroma DB so let's try to check with the Google itself what is the difference between chroma DB and the pine con so uh everything is available to the Google so here actually I found out uh find out one article so let's try to look into this particular article and by uh like reading this articles and all you can understand because this is a recent thing Recent research okay it's not like that that people are working on this on top of this since last like 10 year or 15 years so you will find out that there is a recent active community so whatever you will find out you will find out on top of the Reddit on top of the strike overflow GitHub or you will get a knowledge from the documentation or from a different different blog so just try to read this particular blog and let's try to understand the difference between Pine cone and chroma DB now what is the pros and cons so with that you will get a some sort of idea that if you are going to decide about a database whatever database is there right so whatever database is there whatever Vector database is there so on which point right on which topic you need to select the database what all thing you need to consider over there that is a main point so let's try to discuss let's try to see over here so we are talking about the pine con guys so Pine con is a manage Vector database designed to handle real time search and similarity matching at scale right so here they have clearly mentioned that this uh pine cone data base it designed to hander realtime search and similarity matching at scale which we have seen in my previous class which we I have shown you in my previous uh like a lecture itself you can go and check it's B on a state of art technology and has gained popularity of its use cases of performance right so here uh it is easy to use and it is uh performing well because of that it gain the popularity now let's delay into the key attribute advantage and the limitation of the pine cone so here just look into the pros and here they are saying that it is for the real time search it is for the scalability definitely we are going to use the uh cluster on top of the cloud so definitely we can do a horizontal scaling over there right so this is the scalable B so architecture has been designed in such a way the installation and all the computation and the dbm database management is happening in such a way that it is a scalable and it's not a vertical scale right it we can do a horizontal scaling regarding this pine cone now this is for the realtime search here you will get the automatic indexing So Yesterday itself we have created one index and there you will find out along with the vector you will find out that we were having an index column there we are having the scoring and all so automatically indexing right you no need to write it down anything automatically you will get the indexing now here python support so this is a very important thing if if you are going to develop any application in data science in machine learning and deep learning where heavily we are using python so yes definitely it is supporting of python as well got it now what is the cons of it so cons wise here you will find out the first one is a cost right so cost is a like major disadvantage of this spine cone so we cannot use the spine cone freely so here if you will look into the pricing of this spine cone so there you will find out the different different pricing so if you are a starter if you are a beginner definitely you can go with a free tire but let's say if you're are not a starter if you're not a beginner you want to use it for some sort of application right where you are going to implement some PS and all where you want to uh Implement some realtime use cases for your organization for your project so you can take this particular pack where standard is there now here you will find out uh these many thing you can check according to your requirement and let's say if you want to productionize something right so let's say if you are working in a company and there you want to productionize something and here so what you can do you can take this Enterprise solution so there you will find out many more thing you can check with the pricing detail you can talk with the pine cone team right Consulting team they will guide you regarding each and everything so the first thing the first disadvantage you can see over here that is a cost itself the second disadvantage you will find out limited query functionality so while Pine cold Xcel as similar to search it might like some Advanced query capability the certain project required maybe the mathematical model they are using the different different meical medical model they are using behind that like like cosign similarity dot product so it is not working in that much effective way which people has uh felt right even I haven't checked with this particular cons right I haven't checked that this is uh having a limited query functionality because I uh just check with a certain use cases so guys if you are getting this particular con so definitely before starting with the Pyon before productionize it right or before uh like uh using inside your U like project definitely you should consider to this particular point where you have a limited query functionality right now how to use pine con I think I already told you how to use pine code I'm not going into that much detail now let's talk about the chroma DB so chroma DB is similar to pine go just just try to focus now just for 2 minute next for 2 minute and then I will go with the Practical implementation right so if we are talking about the chroma DB so it is similar to the Pine go and designed to handle Vector storage and retable means we can store the data and we can retrieve the data right so it offers a robust set of feature that creator that c various use cases making variable choice for many Vector application right so here uh clearly we are getting that that we we can use this chroma DB for storing the vectors right we can store the vector and we can retrieve the vector right now here you will find out a different different pros and cons so the first Pros is there that is what that is a open source right so open this chroma DB is a open source Vector database base here I have shown you the code of this chroma DB right you can you can like uh check with this particular code now here you can press the dot so this entire code will be available inside the vs code now you can go through with this particular code and you can check that what all files and folder they have created and what all thing they have written inside this particular project right so you can consider there's nothing just a project only now here you will find out a different different files and folder and now they are maintaining the this thing in the form of package also so on top of the pii repository you will find out this chroma DB in the form of package so from there you can install it by using the PIP install Command right now just look into this chroma DB that what they have written so here they have written of they have created a various folder so the first one is a API now here you will find out a different different API let's try to create click on this fast API just read the code from here and here you can see the all CLI so this is the real time project right which which they have deployed in a real time and which they are using right which everyone is using and there you will find out the number of force number of star number of contributor each and everything you can see so there's a first uh advantage of this uh chroma DB that is a open source now extensible query chroma DB allows more F more flexibility quering capability including complex range such and combination of vector attribute so here you can think that or here you can assume that uh this chroma DB is working well right compared to the pine cone where I have to do a similar search right so here they have clearly mentioned inside this particular block based on their own experience that this chroma DB is working well for the similarity search if you want to find out some sort of a combinations and all in that case it is going to work very very well now Community Support is very very high as I told you that it's a open source right so here you will find out the complete Community just go back and check with the GitHub itself so here is a AT3 contributor 86 contributor and if you will look into the website if you will look into the website so there you will find out the Discord GitHub slack everything they have provided to you uh for uh connecting with the community so if you want to connect with the community so there they have given you the different different ways right so this community the community of the chroma DB is a very very strong now let's look into the cons so here I told you that this chroma DB uh set this chroma DB is not for the deployment deployment complexity is there because you won't be able to find out this chroma DV on top of the cloud right so they uh the pine cone basically already it is running on top of the cloud there you just need to consume it by using the API right there you need to use this chroma DB there you need to use the pine cone by using the API but it is not same with chroma DB actually this chroma DB whenever you are going to use it it is not available in the form of API because it's a open source package you need to install it inside your local workspace space and you need to use it right you need to install it inside your local workspace and you need to use it so if you're going to deploy it right if you're going to deploy it so there you will find out a complexity so here just read U the complexity Point setting up chroma DB chroma and managing it scale might require more effort and expertise compared to many solution like pine cone because in the pine cone you're just consuming the API right you're just consuming the API everything is there on top of the uh third party server everything is running over there you just need to consume it by using the API but here in the chroma DB the thing is not same deployment complexity definitely will find out because there is a no like Cloud support as of now for the chroma DB you will have to install inside your local workspace and you will have to set up each and everything got it now performance consideration yes uh definitely this thing also will come into the picture if we are talking about regarding the realtime use cases so performances also might be here and there so there are some points you can uh search about more regarding a different different like regarding a different different Vector database and from there you can uh like pick out you can pick up this particular points this particular heading and you can do your own research so whether it's a scalable whether it's a whether there is an indexing for the fast retrieval whether there is a python support or it is fine for the deployment so you can pick up this point and based on that you can make a differences and based on that you can understand actually right so I hope guys you are getting it now uh the differences is clear so please do let me know in the chat if uh the differences is clear to all of you then we'll uh go for the coding yes or no yeah thank you Sati so sa saying Sun sir I have enrolled for the Gen 10% discount got the python free recording with that that's a big surprise great great satis congratulation so yeah now uh I hope this part is clear to all of you now let's start with the Practical implementation of this chroma DB so here uh for uh implementation actually first of all we'll have to install some Library so whatever code whatever code I'm pasting over here in my jupter notebook the same code I will provide you in my code share. I also so here is my code guys which I'm going to run now the same code I am pasting in my Cod share. so that you can copy from there so did you get a link of this Cod share. IO please do let me know in the chat please do confirm guys if you got the link of this code share. iio so don't worry my team will give it to you inside the chat and from there you can copy the entire code how to find tune the question answer data using lar 2 model and I don't have context but I have only uh question answer and I have so that is that the the fine tuning also we can do that but for that we required a huge amount of resources and based on a Model also like which model you are going to use so as of now I'm not going giving you the detail regarding the fine tuning and all I understand that's going to be an important topic but yeah so here I'm talking about the vector database and then we'll start with one more project and after that maybe we'll take few more classes we'll try to discuss about the concept of the fine tuning right but as of now you can think that uh like if you have your own question answering data right so there might be a different different technique right different different technique for the finetuning the recent technique which I was searching the recent technique name was the parametric effective fine tuning so what's the meaning of that parametric effective fine tuning so there you have the question answer there you have your data now based on that you have to train the model which will be required a huge amount of resources and you can do over the uh like C CPU also on like on a low cost also but for that you will be required a quantise model so that is a different thing how you can quanti your model and then how you can do a find Uni there are some uh more techniques comes into the picture like Laura and Cur that is also a technique a different different technique regarding this uh parametric effective fine tuning so we'll try to discuss it right and for that only we have designed the course just just look into that each and everything we have mentioned over there where we are going to discuss everything you know very very detailed way got it now here uh I have given you this particular link and here is a installation statement pip install chroma DB open Lang and Tik token you need to install this for library now here guys uh let me install this library inside my inside my environment just a second are you doing it can I get a quick yes or no in the chat if you are doing along with me and please hit the like button guys please hit the like button if you're liking the session because I can see uh you have joined the session but uh you're not writing anything inside the chat and you're you're just watching don't don't do like this hit the like button guys and if you have any sort of a doubt just just uh write it on the chat just cheer up okay so let's make it more interactive got it yeah it is installing now let me give you few more libraries so just a second I can give you few more Library which I kept somewhere okay that is fine now after that you can check with this particular command so here is a command guys this one so let me give you this particular command PIP show chroma d DB just uh check with this command that your chroma DB successfully installed or not here's a command the command is PIP show chroma DB yeah it is perfect now it is done so have you installed it having installed uh this all the library tell me guys fast then I will proceed further now you can check with the chroma DB then you will find out the detail of the chroma DB so it is giving you the it will give you the detail of the chroma DB there is a simple command PIP show chroma DB so we have installed the chroma DB on the uh workspace in the latest workspace and here you will find out the detail of the chroma DV this is the latest model this is the latest model Vishnu I have already shared the code please go and check with the code share. okay join the session on time because again and again I won't repeat a same thing so please we aware V Active I'm sharing everything that's why there is a like cod share. which I have shared with all of you okay just copy from there and paste it inside the Jupiter notebook yes we have a gen related project just check in a commune session also we have completed a project and even in the course also we have a project so rames please check with the course please check with the dashboard now I think uh till here everything is fine everything is done see the first thing what I need to do so here actually I need to I need to uh like uh I need to get I need to download a data so from here from this particular link I'm going to collect a data right let me show you uh what we have on top of this part on over here actually at this particular link so for that just copy it and paste it inside your Google so just just paste it over here open the Google and paste it in your Google now just a second yeah so here is a Dropbox guys so in the Dropbox actually you will find out this particular data right so just a second uh let me show you this data m specifically we have this data just a second guys so here in the URL box I can paste it yeah so here is a data guys so the data actually it's a news article so just just see the article uh it's a news article so AI powered supply chain startup pendo lens 30 million investment txt just open it and read it right this data is already available somewhere where in the Dropbox so I just shown you this particular link and we are going to like use this data for creating embeddings and for like uh and then we'll uh then we'll store the embedding inside the then we'll store the embedding inside the vector database so this is the data basically which we are going to use here we have a several text files so just go through with the data there you will find out the entire detail related to the data uh so here is a one more article replace TB writers strike. txt so go and check with this particular artic article now here is one more article just go and check with that particular article so this is the article everything you need to know about the AI power chb right so different different article you will find out over here check the AI power data protection project right so there are so many article which we are going to use which we are going to use for our uh like this this is the article which we are going to use for our embeddings and all by using this data by using this text data by using this particular data text Data what we are going to do we are going to to first we are going to convert a chunks right and then we are going to convert those chunks into a embedding by using the embedding model I will show you which embedding model we're going to use so we are going to use the openi model but there are so many embedding model you can use the buttu bag there are so many model you will find out over the hugging phas also so it's up to you you can do a Google search I will show you how to do that and then you can select your model as per your requirement right now here this is the data now let me give you the data link over here by running this particular command so this is the data link and by running this particular command here is a command guys where is a command this is the command so by using this uh particular command you can install the data or you can load the data or you can download the data into your local workspace so let's see let uh me show you the data basically so here you just need to run this command so just press shift plus enter and see left hand side your data is is getting installed and yes it is done now here is a j file see guys there is a j file news article J file left hand side in the left hand uh in the workspace basically you you will find out this news article. jip but if you want to unj this data so for that also we have a command now let me give you that a particular command so the command is what command is nothing unip hyphen Q news article you need to be uh like unload it uh you need to be like unloaded right you need to be unzip it uh and here you will get this data inside this particular folder now let me show you let me run it and here you can see we have our data inside this particular folder so I'm giving you this command I'm giving you this particular command just a second you can check and you can run inside your system so here is a data guys here you will find out the data now let me unnoted uh this particular thing this is the data data is about the news article so news article data and here you will find out the command which you can run and with that you can install you can install this chip file install the chip file in your local workspace where you need to install guys tell me need to install this work file you need to install this file inside your local workspace so let me write it down here local workspace and with this particular command you can unip it so so by using this particular command you can unip it so each and everything I have written over here you just need to copy and paste inside your Jupiter notebook that's it right great so please use the if see someone is saying ra is saying Sir W get is not working so here W get is working now this use this with escalation mark right and use the neural lab I haven't shown you this thing by using the collab or maybe this local setup I'm see in Linux environment definitely it will work but if you are using the Windows system so in in that case it might not work so use the Linux environment and this lab actually has been configured on top of the Linux environment in a production you will find out the Linux environment only because for that you no need to pay anything it's a open source right so just like required a small amount of the Linux server but yeah if you are like using a Windows server in a production so definitely it's going to charge you very very much so here is a Linux environment which I'm uh like where I'm executing all this command so w Is there anip is there now let me run the next command so here the next command is what what so here I need to set my open a API so I got the data here you'll find out basically I got the data this is what this is what this is my data which I got in my local workspace now after that I'm going to set my I'm going to set my open a API key you know it how to set the openi key many time I have shown you in my lecture so for that you just need to go through the open website open the open website and here search uh just click on that the and then click on the login you'll find out two option the first option is the API and the second is a chat jpt so just click on the API and then click on the API key so here you will find out the API key so this is the API key basically which I have generated and here I have passed it inside my note book also so just if you will see into this API key so here I pass this API key into my notebook this is what this is my API key right now what I can do guys see uh just a second let me pass the correct one because I'm using the old API key over here just a second just allow me a minute okay I kept it somewhere I kept it uh and you have to generate your opena API key I'm not giving you that uh because for that I have paid actually so please use your API key uh there are so many person which join the session so if they are going to use my open key definitely it will be rushed out so please use your op key please generate it by yourself initially it will give you the $20 credit so you can use it now here uh there is what there is my open a API key now it is done tell me guys still here everything is fine everything is clear to all of you please uh do let me know in the chat if everything is going well so far so I'm waiting for a reply and I'm giving you this particular command there you can paste your openi key and you can run it so this is for the openi key tell me guys fast waiting for a reply if you are done till here then please do let me know then only I will proceed sir I for the P can I my I on team yes Sati you can ask your doubt uh to the Inon team they will assist you regarding your all the doubts all the concerns so please give me a quick confirmation guys if uh you are done if you are able to follow me till here then I will proceed further tell me guys fast waiting for your reply please or do let me know and please hit the like button guys uh if you're liking this session and yeah you can write down the chat chat also whatever doubt you have while you are implementing it and don't worry today the understanding will be more clear regarding this database regarding this Vector database compared to the previous session because today uh because already we have learned it now right so today is a kind of revision so don't worry we have uh created Creed one project also and after the after this Pro after this like implementation I will show you the project architecture also so uh in the next class we are going to discuss about that particular project we are going to implement from a scratch and there you will get to know that how this Vector datab base is being used right so we are going to create one chatboard and the chatboard is going to be a medical chatboard we are specifically going to train on top of the medical data right so just stay tuned with us uh in next class uh we'll create one more project and we'll try to use it the we'll try to use the flask over there and fast API and we'll deploy it also right got it great now here after that I have imported few libraries now let me give you this libraries inside the uh like cod. I so there what I can do guys here I can uh write it down you need to import this a particular Library so here I have written you need to import this are libraries libraries so just just copy it guys and after copying it you can uh uh run inside your system so see guys if I'm running it then definitely uh where is my not yeah this one so here you can see after running it uh after basically importing it what I need to do I just need to run it so see I'm able to import each and everything now let's try to understand each and every detail about this libraries about this import statement so for that uh just a second I can open My Epic pen and that there I can explain you each and everything sir can I exp experience certificate with a paid course yes definitely in certificate and experience certificate will be available right so actually you can generate it um I given you the walkth through in my previous session just just check and uh check with those particular like session just go through with the introduction itself uh so there I have discussed about the internship portal as well if you don't know don't worry again I will open that and I give you I will give you the walk through so how you can complete the internship on top of the generative AI because we are going to add more and more project related to the generative AI with a different different uh like domain so you can complete your project in a multiple domains right so don't worry uh like I will show you that is still it is in a pipeline uh the project will be uploaded Maybe not today in the next class definitely we'll be talking about it right so let's try to discuss about this Library so here is the library the first one is the Len chain do Vector store and here is a chroma right so chroma it is this for the chroma DB this for this is what this for the chroma DB now here this is for the open a embedding and as I told you right so uh we can generate a embedding right we can generate the word embedding and this word embedding is nothing this word embedding is nothing it's a vector only so what is this tell me this word embedding is nothing it's a vector it's a vector right so here actually this open I already uh trained so they already took the data and they already trained one model and by using this particular model they have generated a Ming now how to do that so how to do that tell me guys so here regarding this particular data regarding this particular data definitely they must be having the uh like vocabulary they have generated one vocabulary and for this particular vocabulary they must have created the features right so features and they are passing each and everything to their model and this model is nothing that's going to be a neural network right this is going to be a neural network and yes based on that they will they are going to generate the embedding right so I told you that how to generate embedding and all if you will go and check with my previous session there I have discussed about this embedding open AI embedding now here we have one more package open AI this is for the this we calling this open a API so by using this one we can call the open API directory loader we can load the directory text loader we can load the text and all whatever uh like files we have now we have in a text format so by using this uh text loader we can load that particular data that particular file so let's try to uh load it now so for that also we have a code for loading a data and here is a simple code let me copy and paste it over here and along with that let me copy and paste inside your uh inside the inside the Cod share. also so please copy from here each and everything I'm giving you uh so you just need to copy it and you need to paste it inside your system so here what I can do guys here I can write it down for loading the data and guys believe me after completing this much of thing the understanding will be more clear to all of you so for loading the data let me write it down over here uh just copy from here and paste it inside your system now what I can do here I can load and inside this news article so Globe is for what Globe is for all the text files so whatever text file is there so is going to read the data from the entire text file right so it's going to read the data from the entire text file for that you just need to mention one parameter the parameter is going to be Globe right dot means current directory SL star means what so here we have written the star so what is the meaning of the star so star is nothing star is representing the entire directory right so whatever file name is going to start from this txt we are going to load the entire file we are going to load all those file that's it that's a meaning of the simple code now if I'm going to run it you will find out that we are able to create a loader over here I just need to call one method now I just need to call one method and the method is going to be do load so let me run it and you will find out that it is giving me a syntax error now let me show you that yes we are able to load the data so it is saying that the file is not there okay let me remove it and here is this home Joy on news article is not there why it is so oh just a wait let me copy the path to sharable link should be treor news article so is this a path just a wait just a wait guys just a wait let me check once lab directory okay why it is giving me this issue copy the path and paste it over here that's it are you facing the same issue my open is expired you can generate a next one now you can generate a next API key uh it is giving me a issue guys just a second let me delete it and let's see whe whether I will get up so this is the directory actually see home Jan just copy this directory and just copy this complete directory and dismiss it and keep it over here now let me check yeah now I'm able to do it so guys here see once you will do the right click and just click on the delete just click on the delete so it will give you the complete uh directory I don't know why I was not getting by using this copy path but yeah now I getting it so are you do it are you able to do it are you able to load the data are you able to load the document please do let me know yes or no so here is what here is my uh document please again give me a quick confirmation guys if you able to load the document so just wait let me give you this line also this uh loader. load and please try to load the data by using this loader. load tell me guys if you are able to load the data then please write it down the chat I'm waiting for your reply tell me first are you enjoying the session do you like the session guys tell me do you like the session so far all all your all the doubts and all is getting clear yes or no tell me oh great so I think till here everything is fine everything is clear now we got our data right so we got our data now what I will do here so just a second let me show you so first of all we have a data now guys tell me after getting a data what I will do any guess any any guess anything just wait just wait yeah so after getting the data what I will do so after getting a data I will create a chunk right so let me copy and paste this particular code over here what I can do just a second this data is very very huge so actually it is taking time if I'm scrolling down just a second yeah now it's perfect so here actually you will find out a data related to all the text file right so you got a data related to all the text file now here you need to create a chunk so for that basically I'm going to use this particular library and here we have few more code right few more code few more thing uh so let me give you this particular code and then I will explain you the meaning of it because yesterday also like many people were asking to me sir what is the meaning of this particular Cod code why we are using it uh like what we are doing over here what is the meaning of this uh text splitter split document and all each and everything we going to discuss over here now uh let me open my Scrabble link right and here we going to discuss about each and everything so what I can do let me zoom in first of all and now it is perfect so let's try to understand so guys at the first place what I did just tell me guys so at the first plate at the first place we have uh we have generated a data right so here actually we have a data so we got a data from somewhere this is what this is my data right after getting a data after getting a data what I what I'm doing guys tell me so after getting a data I need to convert this particular data into a embedding right so what I need to do I need to convert this particular data into embedding now here I got a data and I'm going to convert this data into embedding can you tell me which model we are using for this embedding can anyone tell me which model we are using for this embedding anyone fast which model so we are using open AI embedding model open AI open AI edding M bidding model right we are going to use open AI edding model now guys here we are talking about this open a embedding model so just just look into that just just open the model here what I can do uh let me show you the open models here I'm searching about the open models right so you will get all the models over the whatever model is there over the openi platform so these are the model Guys these are all the model which you can see here right so GPD 4 is there GP 3.5 is there Delhi TTS whisper embedding is there so just click on this embedding right so just click on this embedding and here you will find out the embeddings and all right so uh text generator uh text uh moderation latest model max token you can pass 30,000 right 32,000 now here is a GPT based model So weage based model so there is like you can pass 60 16,000 token there uh is a d Vinci model there you can pass 16, 384 token now there is GPD 3 based model so there you can pass 2,000 token right this this is the token now actually in our case we are going to use the GPT based model this this GPT based model so we are going to use GPT 3.5 turbo right so here which model we are going to use we are going to use GPT 3.5 turbo right so here GPD GPD 3.5 basically we are using so now just just look into this in a GPD 3.5 uh this this model by default actually we are going to use this particular model now tell me guys what is the total limit here what is the total limit the total limit is 4,960 right and here if you will look into your data so this is your this is what this is your data now just look into this particular data now here are guys there are so many tokens there are so many words if you will calculate the words so definitely is going to exceed 4,000 right so definitely is going to execute 4,000 exceed 4,000 now let's say let let's talk about that if you are working in a real time so you will get a very huge amount of data you are you will be getting a very huge amount of data and here if the sentence is going to be a very long in that case there might be a chance that my model will not be able to sustain the context right my model will not be able to sustain the context and here you can see the there's there are like two long text right and here by defa which model we are going to use we are going to use this GPT 3.5 turbo this this particular model uh basically whenever we are going to use the llm right we are going to use this particular model which is going to be a gbt 3.5 turbo and here you can see the tokens limit 4096 tokens right 4096 tokens now here the data which we have in inside that we have a lots many tokens right so we have a tokens which might exceed more than 4,000 or let's say this is not going to exceed more than 4,000 but let's say if you are working on some realtime data and there there you are getting a data which is very very huge and which is exceeding the number of tokens right whatever model you are using let's say you are using a topmost model where you can give 30,000 token but still it is exceeding the limit in that case what you will do so you will provide your data in terms of chunks what you will do tell me you will provide your data in terms of in the form of chunks right so that is what we are going to do over here so over here guys what I'm going to do see uh here is what let's say here is my data right and here is what here is my Ming I want to perform the Ming now what I will do here I I will keep one thing so in between this data and this Ming right so actually after that after this eding and all what I will do tell me I will pass my model now I will pass this thing to my model right so I cannot deny with this thing so I'm going to pass this thing to the model and here we have a data right we have a data and in between actually what we are going to do we are going to do a chunking right what we are going to do we are going to do a chunking now let's try to understand what is the meaning of the chunking so let's say we have a data right so what what I have guys tell me let's say we have a data now what I have to do I have to do a Chun right I have to convert this data into a chunks now here in the library which I have imported there you will find out two thing two words so let me do one thing let me copy and paste this thing from here so here what I can do what is happening okay where is this oh just a second guys just a wait yeah here is a code guys see so what I'm going to do from here I'm going to take uh I'm going to copy this particular line this this particular line right now let me copy it and let me paste it over here so here is what here is my dis link so here I'm going to paste this a particular line and now guys here actually you'll find out two thing the first is a chunk size and the second one is what overlap right so what I'm going to do so here I'm going to copy and paste some data from here itself right just just focus everything will be clear over here so here is what here is my data now let me copy this particular data this is my data this one page content now I'm going to copy this particular data and I copy let's say till here right this just for the demo this just for the demo nothing else right so here is what guys here is my data which I kept over here right now just just looking into this data so here's my data which I just took for the demo so the first thing which I have defined that's going to be a chunk size right chunk size now what is the meaning of that so here actually let's say uh I'm going to divide my data into chunks what I'm going to do tell me I'm going to divide my data into chunks so I want that I want 100 tokens over there here here I have written thousand right let's say I'm giving 100 tokens so what is the meaning of that means let's say there is first Chun one Chun in that until I'm not going to complete 100 tokens let's say from here to here from here to here we got 100 tokens right so I will stop over here and that data so that is what there is my first chunk now again there will be a second chunk so it's going to start from here and let's say till here so here I'm going to complete my 100 tokens so this is going to my third chunk now there is a third uh third chunk basically so in the third chunk you will find out we are going to start from here and let's say till here so this is going to be my third chunk where I'm able to complete my 100 tokens and what is the meaning of the tokens so tokens is nothing it's going to be a word so what is the meaning of the tokens tokens is nothing the word itself is called a token right so if you are going to complete 100 words in that case I'm able to generate my first chunk I'm going to generate my first chunk and why I'm doing that because let's say data is very very huge so I cannot directly pass that particular data to my model it will Ex the limit so the better thing is what I'm going to provide my data in terms of chunks in terms of small small chunks right so it will be able to sustain the context also and my limit is not going to exceed got it now here you have a three chunks regarding this particular data let's understand the meaning of this chunk overlap right so let's say instead of this uh 200 I'm just writing 20 right so now guys let's say uh my first CH is going to start from here to here right to here now second chunk is going to start from the from this if from here to here right here now let's say uh I'm writing 20 so what will happen you know what will happen so it will take 20 wats this this second this second chunk this second chunk it will take it will take 20 words it will take 20 words from the previous sentence so let's say this is a 20 words this this is a 20 words now this 20 words will be carry forward to my second chunk now here we are talking about the third one third one so here let's say from here to here from here to here this is my third chunk now if I'm writing chunk overlap is 20 so from the previous sentence from the previous chunk my 20 words is getting overlap mean means it is going to forward is it is carrying forward to my next chunk getting my point what is the meaning of this chunk size and why we are doing that what is the meaning of the chunk size chunk overlap what is the meaning of Chunk I hope everything is getting clear now I have given you the clearcut explanation so let's try to do a chunking regarding my data so over here if you will find out let me show you the chunks and all and how we can do that actually what is the purpose of the overlapping just just think about it just think about it what is the purpose of the overing we want to sustain the information from the previous sentence from the previous chunk that's it right that's it now my data is little smaller in that case uh I'm not able to create so many chunks what I will do I will perform the overlapping getting my point right yeah to maintain the context to maintain the length whatsoever now here I'm passing my document I'm passing my document and here I'm going to create a chunk so guys over here you will find out inside this particular variable there is my chunk so here if I want to extract the first chunk so this is what this my first chunk as you can see now I can call the page content so here if I'm going to call this a page content so you will find out this is what this is my content right now here I can take the second chunk also so here is what here is let's say is my second chunk so you will find out this what this is my second Chun now here you will find out the third chunk so this is is going to be your third chunk now let me show you the third chunk so here actually you will find out all the Chunk in the list so I can get the length of the list also so just uh call this length and this text so here you will find out total 233 chunks got it yes or no now let me give you this particular code and here is what here uh I have a code let me close it first of all this is what this is my code let me paste it over here so just copy from here and try to extract right so try to extract so here actually uh you have a text right and from there you can extract the content now trial Junction is saying explain so then you can visit ion Tech Hindi Channel there I'm explaining everything in English sorry in the Hindi right so this is the channel for the English and the channel will be for the Hindi so just go and check then you will find all the content in Hindi otherwise just wait for one more hour from 6 p.m. onwards I'm going to start a same class in a Hindi also right on Inon Tech Hindi got it great now here you can see we are able to get a content from the page from the data now uh this is the data which I got I'm able to do a chunking now it's time to do a now it's time to do a tell me it's time to perform the eding now let's try to do a eding and let's try to do a a further thing over here so the next thing is going to be embedding itself just a second let me do the embedding uh let me give you the code basically so here is a code for the chunking yeah so guys the next step is going to be a very very uh the next step is going to be a very very crucial just just focus on that and within a 15 minute we'll try to complete it so here my next step is what so here my next step is creating a DB so let me remove it first of all and here I'm going to create my database so what I'm going to do guys I'm going to create my database so for creating a DB actually there is a is a like certain thing there is a certain code which I need to write it down over here so the first thing uh the first thing basically what I need to do I need to import the embedding so first of all let me give you this entire code and step by step one by one I will try to explain you so just a second I'm going to paste the entire code in my Cod share. so here uh you can paste it you can copy it from here from the codeshare doio I'm giving you each and every of code each and every line so at least you can run along with me if you are running inside your system so you can run along with me here is the entire code guys from 41 to 48 just copy it and run inside your ipv file now let me show you that what thing we are going to do over here so here is a embedding let me copy it from here let me paste it so this is going to my embedding and let's run it yes we are able to uh import it now the second thing is what I told you uh I told you initially that we are not not going to maintain any such information or we are not going to store any such information on cloud right we are not going to store any such information on cloud because here this chroma DB is a local DB right where you won't be able to find out any server on top of the cloud any cluster on top of the cloud everything will be happening in a local itself in our local workspace so purchase directory there I'm going to store my all the embedding here is a fer this is what this is the directory now let me run it and here is a directory now what I will do guys so here I'm going to create an embedding right so here I'm going to create an embedding just a wait so this is going to be my embedding open embedding means uh it's what it's my class right for generating edings which I'm going to import from the openi yesterday also I shown you this thing now here this is the crucial step just just focus over here guys just focus and don't worry I'm giving you the link again so just uh call okay I'm giving you to my giving it to my team and they will paste it inside the chat so here you will get it uh within fraction of second just wait so guys uh here I given this particular link inside the chat now you can check you can copy it and you can copy you can open it and you can copy the entire code from here itself so within a second you will get a link inside your chat now let's try to understand the further things till here everything is fine everything is clear everything is a perfect now here is what here we have a method here actually we have a like class chroma and inside that you will find out a method from a documents right now here we are passing three things the first thing is what the first thing is text the second thing is a embedding and the third thing is what the third thing is a directory right first thing is text the second thing is a embedding model and the third thing is a directory now as soon as I will run it let's see what I will be getting so it is running and it is creating a embedding it is generating an embedding and I will get that inside my DB folder inside my database folder just wait and just look into this DB folder guys so here actually uh it is running still it is running and now open this DB so just just refresh it and here inside that you will find out the m now guys see there is uh one cons there is one disadvantage of this chroma DB So Yesterday itself I shown you the pine con there you will able to see the there you were able to see the embedding and all on top of the screen but here whatever embedding you will get you will get in the form of binary file getting my point so here you will get all the embeding in the binary file in the bin file right here is the extension you can see do bin getting my point yes or no so now let's try to decode this thing what I can do now let's try to decode this thing this particular thing where I got my eming now everything is going to track by using this uh SQL 3 right so in back end it is using the SQL 3 and it's trying to store the embeding because it is required some sort of a server now chroma DB is not a database right it's just like a just a basically you can think it's just a wrapper kind of a wrapper basically so back in back end it is using this sql3 server and it's storing the embedding but not like we are not going to interact with this SQL 3 and all with SQL and all right no it's not like that right we are storing this vector and in back end it is using a sql3 server got it now if you want to understand more about the chroma DB you can read about you can go and check with the documentation and all then you will find out a depth intuition regarding this chroma DB now here I think this is clear this is fine now let's do one thing let's try to understand few more thing over here after storing the data in the form of uh embeddings inside this DB folder now what I need to do next so here uh you can see so we have the U directory so let me show you okay just a wait Vector DV data M ready okay so here guys you can see uh we are going to call this particular method Vector db. pures right now here I'm saying that purses the DB to the dis so here I can call it I can call this a particular method which is there on inside the vector DB so here actually you will find out you this is the object right so which you got which you are getting over here you can call this particular method persist now if I will run it so here you will be able to persist this thing inside your uh local disk itself right this one now here you can see so Vector database is done we can assign this also now guys here one more thing which I would like to show you which I would like to write it over here that is what that is this uh like chroma itself right so here we are saying now we can load the purs database from the disc and use it as a normal one so what I can do here so here I call this pures now I'm going to assign this none now what I'm going to do here see uh I'm going to use this Pur directory means in whatever directory you want to keep the database so there is a DB itself This One DB and here I'm calling embedding function is equal to embedding right so here itself like here my embedding function will be this embedding and here is my Pur directory right now what I have written over here see now we can load the purs database from the disk and use it in a normal fashion right over here we can uh do that so let me run it and here you will find out so this is what so here actually you will find out the database so inside this itself uh okay it is getting updated just a second now let me yes read me new article yeah so here basically in this particular Vector DB you'll find out a database now now see guys what we are going to do so we have created a chunks right now we have we have created a chunks after that this is what this is my embeddings which we are going to import from the lenon itself now here is my directory VB itself now here you will find out the open AI embedding right so this is what this is for calling the embedding uh embedding like class which is there inside the openi platform now here what I'm going to do I'm going to call this chroma right chroma is there which I imported just just look into uh this chroma okay which uh I had imported somewhere let me show you and we are consuming uh this as a object this chroma just wait so somewhere I have imported this thing M where it is where it is imported chroma import chroma yeah PIP show chroma DB I think I have imported somewhere in between you you can check in a file itself I have imported now here after that what I need to do I need to call this particular method from document right now here I'm going to pass the text this is my embedding and this is my directory right in which I want to process the m so here Ive created this Vector DV right so as soon as I did it now here you will find out we are going to create this we have this particular directory inside this we have this uh we have this bin file there you will find out there you will find out your embeddings and all right and it is using the sql3 server in back end right this is fine now purs the DB to the disk if I want to purist I'm just going to call I'm just going to call this Vector db. pures right now here if you will look into that so here I'm going to call this chroma right Pur DV this is my directory now here is what here is my embedding okay now if I'm going to run it so here I'm getting my Vector DB right so from the dis itself I'm able to get this Vector DB so here actually we have the dat see if I will run it now if I will show you this Vector DB this one so there you will find out this is what this is my database means I'm able to persist okay I'm able to purs this data I'm able to purs this data in my local disk and by using this particular object we can access that now let me show you how you can do that okay just wait so here I'm writing uh the next thing which you want to do so here I'm writing this make retriever so just a second here I'm going to write it down this make retriever now you want to make a retriever basically and for that what I'm going to do so here I'm going to call this one more method uh which is uh which this function is having the method name is what as retriever right so there is what this will what this will my retriever now what I can do guys just wait I can give you this entire code so you all can run inside your system so I'm passing or I'm giving you this on the like codes share. so you can get the entire code from from there itself so just a second I passing it over here I'm giving you inside my uh I'm giving you this inside the Cod share. just just copy from there and here the last method which you need to call this is going to be a as retriever so just a second now we just need to cover few of the few thing and then I'm going to wrap up it so here guys you can see we have a retriever we after calling this particular method we are able to click we are able to create a retriever now what I will do here just just focus right just focus so here I'm going to run this particular method by using this Retriever get relevant document right so here I'm going to run this uh this particular method the method name is what the method name is get relevant document and here I am going to pass one question the question is that how much money did Microsoft raise right how much money did Microsoft raise so this is the question based on article if you look into the article if you will try to read the news right so there you will find out somewhere related to the Microsoft and related to the different different startups so here I want to here basically I have created a retrieval right which is there uh we have a function actually this method Vector DB do as retrieval so this is what this is my retrieval now here I'm going to call this get relevant document so what it will do so it will uh search inside the entire DB and based on that it will generate an answer so let's see what I will be getting over here so yes if I'm running it and now inside the docks right now let me show you inside the docks that what I have so here you can see I'm getting a document right I I'm getting a answer here I have created a retrieval and whatever question I'm asking right so it is matching it is checking and here I'm getting answer how this thing is happening let me explain you so what I can do I can open my uh Blackboard and there itself I can explain you about it so so just a second uh what is happening see what I'm going to do here so let's say we have a data right just a second guys yeah so we have a data and the data actually what I'm going to do tell me so this data I'm going to be uh this data actually whatever data is there I'm going to convert into embeddings I'm beding by using what tell me so by using this opening API so here I can mention the open a API now let's say we have this open AI API got it now this open by this this basically this embedding whatever embedding I'm going to generate I'm able to keep inside my inside my tell me guys inside my chroma DB right from here to chroma DB let me create one more box over here so here actually what I'm going to do I'm going to keep inside my chroma database got it right now this is fine this is perfect okay and this chroma DB actually it is available in the local dis space it is available in my local disk space now it is using this SQL light server it is using the SQL light server in backend right and here it is storing the data in the form of binary file got it now here whatever data which we are going to store inside my chroma DB now I want to retrieve it means I want to make a request from this D right so what I want to do guys I want to make a request from here so what I will do for that uh so actually see I want to make a request so the request will work in which way so let's say we have created a retriever right let let me create a retriever over here so let's say we have created a retriever now just a second here is what here is what here is my retriever now let me write it down the retriever over here this is what is my retriever now I want to retrieve the data so here let's see this is what chroma DV is having a database so this is what this is my database right okay great great great so this one this one and this one right so this is the database where we are going to store the embedding now what I will do I'm going to retrieve the data so with that I have created object of the retriever now I make a query so from here basically I make a query so here let's see this is what this is my query okay just a second let me Define the query over here query okay query now I made a query and this query actually see the request is going the request is going from here from here from here to this database right this one and from here actually what I'm getting in response if you will look into the response so in the response actually I'm getting a output right so the response will be coming from here and it is going like this this one and this one right so this is what tell me this is the response which I'm getting so here I'm making a request from here this is what this is my request this is also my request right and here what I'm getting I'm getting a response right this is what this is my response got it now here actually what I'm doing so here I'm going to perform the similarity search right so in this requency response actually the thing which we are going to perform we are going to perform the similarity search and based on that based on a similarity search itself based on a semantic meaning it is generating a final output right so as a retriever actually what I'm getting I'm getting a final output and based on the semantic search it is generating that a final output I hope now the architecture is pretty much clear to all of you let's start with the coding again so here I'm getting uh all the like whatever a question I've asked so based on that it is going to generate output and here you can see the first output second output now let's check with the first output so it has generated uh like a different different output not a single one and here if I'm to check the page content so you will find out that we have the entire detail right so here you will find out the entire detail regarding this particular question so in this particular question you'll find out the entire detail now you can check the length of the document also so what I can do here so what you can do here so here you can write down this dogs and there you'll find out it is generating a four answer by default it is giving me a four answer got it now this is fine this is clear now what I can do I can uh like I can call one more method just a wait so here actually in the retriever itself we have a different different method sorry in the vector database we have a different different method so here I have called this uh as retriever right as retriever now here is what here is my retriever Now by using this retriever I'm going to call this get relevant document everything you will find out in inside the document itself just go and check with a chroma DB documentation we have uploaded or sorry not basically we so they have uploaded everything over there in a very detailed way just go and check every function every method I'm going to take from there itself right so I I'm going to take from there itself just go and check with the documentation now over here guys see uh we have a retriever now here I can Define the key also so search KW KW R GS k equal to 2 there will be only two output now here if I'm going to call it now you will find out what I'm going to do so I'm going to call this a particular uh keyword s retriever dok search a w RGS so you'll find out two so we'll be getting two output only so if you are going to search it now if you're going to search any sort of a question so let's say here is my question is what here is my question uh retriever do get relevant document and here how much uh did Microsoft raise so let's see in the document two what I will be getting so here in the document two let me show you first of all let me show you the length of this document two so here is the length of the document will be two so I'm getting only two document I'm getting only two document as a relevant one means it is performing a similarity size so in a back end itself in a back end itself there is a vector and there will be also a vector each and everything is going to be uh like each and every permutation is going to be form and based on a similarity search Okay based on a similarity search is providing me a output so here you can see it is giving me a two output as of now now if you will look into this doc two so there you will find out only two output right so here you can see you just have to Output so initially actually by default it was giving me four so I hope this thing is clear to all of you now here I want to do one thing I want to make it more realistic right what I want to do guys tell me so first of all let me give you this particular code so at least you can also uh generate some limited output Vector DB as a retriever and here is the next one is what so just a second Vector DB retriever so this is for the by default and here this next one actually it is for the two only right so here we have Define the two so get how much Microsoft money so here actually this is what this is my docs tool got it guys yes or no tell me did you got it yes yes or no guys guys tell me please copy the code from here please be active I understand it is like it is it is about to hour now so so please be active guys see I I have a same energy now you have to keep you have to learn with the same energy okay I I haven't down my energy and I'm I'm like explaining you with the same energy I understand initially thing will get in a more effective way but as we are pro progressing with the session so we lose our like Focus we lose our like focus and all and so don't do like that okay so just be active just be active for for more 10 minute and yeah we are going to wrap up this thing so you will be ready with the vector databases now in the next class easily we can implement the project right easily we can implement the project and we can perform the RG retrieval argument generator so this Vector database we use for the RG only for the retriever agumented generation and is going to play a very important role if you are going to create create any sort of a application related to the llms right related to the generative AI where you are going to use llm so please guys be take a take it serious and yes in interview they will ask you the same thing right I have seen many require whatever requirements people are having right related to the generative to the llm and they are specifically they have mentioned chroma DB pine cone right because this is a trend actually right people are able to uh use it people are able to productionize it right people are able to achieve whatever they want right with respect to their use cases and all and yes as a techie you have to solve this thing you have to take care this thing so please be serious over here now uh here guys see we are able to retrieve the document a similar document by using this particular method right now everything you will find out over the documentation if you want to understand a more depth go and check with the documentation now let's try to understand the next concept so here you can see we have a doc two now let's do one thing let's make it more interactive and so for that here I have written something uh so let's make a chain now what I can do I can make a chain and here guys for that here is one Library you will find out inside the Len CH itself the library is going to be retrieval QA now let me run it and yes we are able to import this retrieval Q retrieval means you just need to retrieve it retrieve it you just need to get it right retrieve means response right so here you can see we have this retrieval QA now what I will do guys here I'm going to use my llm model so I'm going to call my open API because I want to I want to get uh see here if you if you will find out in the response so just just look into the response here so just just print this particular response um what I can do I can print it now see the response so they are giving you the response and they are mentioning everything over there now how to make it more interactive and how to work with it like a question answering right question answering so for that you'll find out this retrieval QA over here now here I'm going to use my llm now you will find out the use of the llm over here what is the use or I will show you one architecture so here I shown you the simple architecture which I created by myself only here you can see clearly you can understand everything I will show you one more architecture and I will show you what is the role of this llm over here what is the role of the llm over here right now just wait let me show you that or first of all let me run it uh here I have written couple of thing so let me show you the llm first see we have we are going to call open API and by default we have the uh by default we have the model GPT model cut it now what I'm going to do here I'm going to create a chain by using this a particular method so retrieval QA from chain type so LM open a model and here we have a retriever object retriever is there this one okay retriever is there and here you will find out the document so return Source document is true so we just need to pass two thing here the first is what up our model and the second one is retriever so retriever is here this one okay this one so we are going to collect it from the vector DB this retriever right so here Vector DB as retriever so this is my Retriever and by using this retriever only we are getting an information whatever we are passing as a question and we are using this method and this is what this is my docs so this retriever object also we are passing over here so we have a llm model we have a retriever and here two more parameter right now let me run it and here you can see we are able to generate or we are able to create a object and which I'm going to store in qhn right now guys here what I can do I have return one more method so let me copy and paste it over here and one more method and after that the thing will be more clear to all of you so what I'm doing over here see uh this is the two method which I have pasted right two uh two code two Cod code is snipp it basically which I pasted over here so here see we want to create a retriever QA so just just check what is the meaning of that just open the Google and uh search it over the Google Now paste it over here and search about the retrieval Q QA so what is this retrieval QA everything you will find out inside the Lang CH and guys believe me this langen chain is very much powerful right whether whatever like framework you are going to learn in future I don't care llama index and all but please try to learn this Len CH if you want to build llm based application so just take a Mastery on top of this Len chain it's a important one now here you will find out what is this retrieval QA this example so is question answering over an index right the following example combining a retrieval with a question answering chain to do question answering right so here I just want to make a question answering chain and here is a complete code snipp it here is a complete example which they have given to you now what I can do here I can uh show you that how that this uh two thing is working now this is what this is the from chain type which I called create a chain to answer the question now see process llm response so llm response is there right whatever L see first of all see this is a query now here we are passing a query now this is what this is the query which we are getting now llm response see here what we are going to do see this is what uh here from here basically uh what I see step by step let me show you so first of all let me run it right this one now what I will do here so this is what this is my query right so here is what here is my query how much money did Microsoft race right now what I can do here uh I can uh like call this particular uh method right so what is the method guys tell me here this one is qhn right so here is what here is a qhn this one this one so I'm passing this query to my qn right so let me run it and here you will find out the llm response so let me copy it and let me paste it over here so this is what guys see this is your llm response this one right so here what I'm doing I see uh retrieval QA right you you are talking about the r now retrieval argument generation so it is related to that only it is related to this only it's Advanced concept so this is a basic RG which we have created this is a basic RG which we have created where we are not going to generate directly answer from my llm no we are not going to do that here we are going to pass this retriever object this particular object and from there actually we are going to generate an answer from here see we have open AI model llm model we are not going to ask we are not going to generate a response from the open from the llm model right it is just for the refinement right it is just for the refinement or for the better understanding is not if you are not going to train it now if you're not going to train this model on top of this data and if you are passing this retriever if you are passing this retriever object over here means you are passing the embedding you are passing your database you are passing your data over here right so instead of instead of generating a data instead of generating answer from the model is it is it is giving you the answer from the embedding itself llm is here just for the refinement right just to understand it not going to generate answer and this is only called retrieval argument generator gener generator retrieval argument generator and here you are going to achieve this thing by using this Vector datab Base by using this Vector database so here you are going to call this llm right here is llm have you created a function calling have you created a function calling so it is working similar to that if you are aware about the function calling where I'm using a llm but llm is not generating answer some third party API is giving me answer right so it is working in a similar way here is my llm and this is what this is my retriever which is nothing which is my embedding so here I passed my query and it has generated answer this LM response now guys what I want to do I want a response so where it is tell me it is there inside the source document so here what I'm going to do so I'm passing my LM response over here and from the result so this is my result and this is my complete uh like answer which is which it is giving to me so here actually this llm we are using for the refinement for the refined answer see see over here now if I'm running it this one what I'm doing I'm going to run it see this I'm going to run this one so it is giving me a so it is giving me this a particular uh it is giving me this like a particular answer this is for the refinement llm is not for the generation answer generation answer this is the answer which we are generating from the document itself from the database itself based on a similarity search right and this is only called R A retrieval argument generation and here this chat GPD or this like a GPD model we are using for the refinement so it is giving me a final answer so already I have written a code over here so we are get extracting a result and we are printing a result and here is a metadata and all whatever is there so we can print that also so this is the metadata resources now guys tell me did you get the concept of the r did you get the concept of the vector database did you get that how to like uh do the question answering after generating a aming and all in my previous class also I shown you the same thing in the previous class I created a while loop and I was giving the queries and all and I was generating answer you can do the same thing over here and you can create your question answering system you can create your chatbot which we are going to do in the next class so this is just a like a basic introduction and the next class we are going to create a application by using this particular concept now tell me are you getting it guys yes or no tell me how many people are able to understand yes or no tell me fast whatever explanation I have given you regarding that how many people are able to understand yes sir uh we have existing qua system what is uh what is the difference between exis system and llm model exis system is this one now this is your data see let me revise this thing what I can do here uh where it is okay this one now what I can do here itself I can revise this thing just a second okay so I have one image let me show you that a particular image just a second so this is the image right this is the image can you see this image guys this one is it visible to all of you this this particular image tell me guys fast so this is the image actually which I created for uh for the project actually this is the project flow now let's try to understand what is happening over here right so I can explain you this thing in a like clear man manner just just see just focus over here right now what is is happening see uh do you have a data just say yes or no until you won't say Yes I won't proceed so this is the data right are we extract are we converting a data so are are we extracting a data yes so this is my first step this is my second step right now here you can see this is my third step now here you can see this is what this is my fourth step this one right this is what this is my fourth step now after that what I'm going to do so so here I'm going to save my data in my Vector store in my chroma DB so either I can store chroma DB or vector database tell me so here either I can store chroma DB or vector datab everyone so I think you all are enjoying s's class lecture okay so guys here you can see so this is what here we are going to store the data in a chroma DB itself right so in a chroma DB yeah here actually we are going to store the data in a chroma DB now see if user is going to query right if user is going to query now what will happen if user is going to query this thing now what will happen see uh here let's say this is what this is my user okay just wait let me remove it from here um yeah so this is the user right so we have a data over here we have created a data uh so this is what this is my data where I have saved my embedding right so here I have saved my embedding now here you will find out the embedding now here is a user this is what this is the user now here user is asking the question right user is asking the question now here we will search like query aming right and based on that so we'll go into the database and here see from the database will retrieve the answer and llm will refine the answer right llm will refine the answer just just look into the arrow so what is the role of the llm over here llm is just for the refinement because the mding we are going to the iding right so whatever iding is there right so this embedding actually uh this data we are going to fetch from the DB itself right so here is a see till here everything is fine see this is the work of the uh this is the work of the developer till here now let's say user will ask the question so the question will come over here it is going to do a semantic search and and is going to take a answer and here from here actually it is taking an answer and then it is going to rank the result so in that in my case I'm getting two result right or three result or four result now what I will do here so it will pass to my llm model and this llm model will give me a final answer now it is getting clear how the flow is happening how the how the thing is working over here tell me guys fast how the thing is working over here did you get it guys yes or no got it now so that is a thing which we have implemented in a Jupiter notebook Now by using that so this thing actually we can use this this particular thing we can use inside our application right and we can create one QA system so from the data whatever data we have from the data the data basically the files which we have our data from there basically we can get answer and llm can refine that particular answer I can give the direct answer also from the database or I can refine the answer so that's is a use of the vector database now in the next class we are going to create a in the next class we are going to create an application and that's going to be chatboard application and literally you will enjoy if you are able to understand this today's session so tell me guys how was the session how much you would like to rate to this uh application and and whatever I have done over here so tell me guys fast if you have any query any doubt you can let me know I will give you this entire code and here is the uh like I can give you this particular code as well I hope I have already pasted in the just a second so let me give you this uh two thing the first is going to be a qhn this one and the second is going to be this one uh just a second this okay so I given you the both code now what I can do here so this is the code and yeah now you can query you can ask anything whatever query whatever like uh data actually we have based on that you can query you can take a bigger database right and yeah now I think uh you are able to get it no this one so fine I hope uh this part is clear to all of you now please go through with the code please try to run inside your system just copy from here and run inside your jupyter notebook data and all each and everything I have provided to you I have already given you and uh yeah now if you want to see if you want to stop the database if you want to means uh the datab database basically which you have created right so if you want to stop it if you want to delete it if you want to like clean it so for that also we have a command let me give you uh those particular command so here you just need to so first of all let me write down the heading and the heading is what so heading is uh you can delete the database so delete the DB now you can see uh what you can do guys you can delete the DB and here uh what you need to do so you need to read this J you need to like uh create this jip file actually this jip by using first of all you need to jip it actually the entire thing is there just you need to jip it and after that what you will do you will run this particular command so let me give you this two command the two command the first one is delete collection and the second one vector. process right so to clean up entire thing you just need to call this two thing and here the last one you can delete this jip directory so here is the directory which you are going to delete means here is the folder the entire folder where you will be having the jip directory you are going to delete that and yes finally you will be able to delete your data base the data base basically which you have created by using this chroma DB so yes or no guys tell me um if you got everything then yes it is well and good if you if you didn't get then um definitely you should revise the thing everything will be available over the dashboard so just uh go and check with the dashboard let me show you the dashboard just a second so here the session is going on now let me show you the dashboard also this is the dashboard guys uh this one so just just check with the dashboard just enroll to this dashboard and apart from that you can explore the course as well the course which we have launched on a generative AI here is a Course and there you will find out everything the concept which I have explained you over here we are going to explain in a more detailed way we are going to clarify more thing regarding this RG or regarding this uh like different different uh tuning and all parametric tuning this that whatever everything we are going to clarify over here so just go uh go and check uh with this uh website with the uron website just go and explore the course this uh just go and explore this Genera course everything you will be finding out over here just just explore the syllabus okay this is the syllabus and if you want anything if you want any update anything let's say this is the new one right which we have launched right so if you want anything any recent thing which on which you are working in a market in your organization you can let us know you can let me know you can ping me you can uh write it down on my LinkedIn right so based on that um if there will that will be like uh that uh I I will consider I will think about that and if it is really going to be an important one so I will add on inside the syllabus okay immediately I will add on inside the syllabus and we are going to take it inside the live class so I hope uh this is fine to everyone now we can wrap up the session and from next class onwards we are going to start with one more project and that's going to be on Monday Monday 6 sorry Monday 300 p.m. IST and yes so I'm not going to take that session buppy will be available for that particular session buy will start with the project and all if you don't know about the buy so I can show you the profile of the buy just uh over the open the LinkedIn and search the search uh buppy okay now buy the full form name the full name is a b Ahmed buy just open the profile of the buy and he's like really good Mentor you can visit his YouTube channel as well this is the YouTube channel of the Wy there you'll find out the like content related to the computer vision and all so just go inside the video he's having a amazing cont content related to the computer vision and you can go and check you can check with the mlops content as well everything he he has kept over the YouTube so you can visit the YouTube channel so next class will be taken by the buy and yes in that we are going to implement one more project so Monday Tuesday and Wednesday fine so I hope guys this is clear to everyone now there is one question sir can you provide one end to end project for interview purp yes we are going to implement that in a next class in the next uh in the next uh basically class and uh don't worry you will find out a project soon in my internship on on the internship portal as well so let me show you the internship portal where it is just click on this click on the internship portal and here okay so you will find out all the project and all as of now we haven't updated related to the generative AI it is in a pipeline I already given to my team the work is work is uh going on on top of that so there's there are like couple of use cases related to the different different domain which is a which is directly related to the real world so you can explore that you can uh like go through with that and then you can start your internship and you can generate a certificate you can generate a experience certificate and you can uh write it down that particular project in a in resume also see one thing I would like to tell you let's say if you are uh like whatever I'm like telling you whatever I'm teaching you let's say I'm not able to teach 100% but I'm giving you the direction let's say I taught you 50% thing but rest of the 50% I've given you the direction right so rest the rest 50% thing I given you in terms of the direction and all so try to explore those Thing by yourself like anywhere you won't be able to find out that one Mentor is doing everything for you let's say you ask about the inter you ask about this uh like uh one project which I can show you in a uh in a like interview and all or which I can show you somewhere so guys I guided you up to certain point right now it's your chance you can find out the different different use cases and you can Implement those by taking my reference and in that you can add on few more things right then only you will be able to cck the interview if you going to take a same project from me and you are going to uh like you are going in an interview then you won't be able to crack it because you won't be having that confidence that knowledge okay which is required in an interview which you will get once you will do by your self okay so keep this thing in your mind and learn according to that and yes definitely you can crack any interview this is not a big deal you just need to represent yourself your work that's it okay so thank you guys thank you for attending this session from next class onwards we are going to start one more project and please do revise the thing whatever we have learned in today's session in today's class here is the entire file here is our entire content just go through with that and yeah thank you byebye take care if if you have any doubt you can write it down on the over the LinkedIn and please share your learning as well uh over the LinkedIn you can tag me I will look into that I will like it I will share it so my name is B Ahmed B and uh I'm working as a data scientist at Inon and I have more than two years of experience uh in the field of machine learning deep learning computer vision Genera and natural language processing and uh if you want to connect me anytime so this is my social media link I think some of them already have connected with me so if you have any issue u in the field of this generative a and all with the implementation of the projects so anytime you can ping me okay I will be happy to help you okay guys thank you so let me uh show you that agenda for today so today actually I'm going to discuss something called open source large language model so as of now I believe you have work with like open AI based large language model guys yes or no uh yes now uh can anybody tell me what was the difficulties actually you were facing whenever uh you are using this kinds of Open Source lar language model any anyone give me any response yeah mostly open a and a your open yeah I know that so what is what is your difficulty level there just can you tell me um resources uh it's not a major issue okay see the major issue is like uh the cost okay because I believe you onlyon be having like a paid account most of you and before starting guys let me tell you uh all the resources has been updated in that uh uh dashboard actually so let me show you the dashboard once so if you open that dashboard I believe guys you enroll for the dashboard and it is completely free without any cost yeah see guys all the video has been updated here and as well as I believe the resources also has been updated even maybe some quizzes and assignment has been also given there okay so you can go through that even it is also available in your YouTube live section okay and today whatever things actually I'm going to do everything would be shared in your resources section no need to worry about yeah so what I was telling guys uh see as of now you have used like open AI based large language model and the major issue was the like cost there yes or no because I believe you won't be having like paid account most of you if you are having also paid account so at the end of the month you need to pay okay for the model you are using from the open a yes or no yes okay now see guys U how to like track your cost like whenever you are using this kinds of open based like uh large language model okay if I'm talking about open based large language model so I'm mostly talking about something called GPT okay GPT Series so if you just search open AI pricing okay if you just search openi pricing on Google so there is a page actually you will get from the openi site and here actually they have already mentioned the cost okay they're taking from you so let's say if you're using GPT 4 Series model okay so in GPT 4 Series you have different version of the model so let's say you have GPT 4 Turbo okay so if you are using this particular model so this is the model name as you can see GPT 4 uh 1106 preview so this is the model and this is the cost with the input tokens okay so each of the model will have their input size okay what is the input size input size means the number of text actually you are giving as a input to the model okay and that can be calculated by this token okay so let's say if you're giving 1,000 tokens so it will charge you 0.0 $1 okay this is the charge and if your model is giving let's say one uh 1,000 uh like tokens output so it will charge around 0.03 now just combine them and just calculate the cost okay so this is for the GPT for Turbo now let's come to the GPT model and you can see whenever you are trying to use the core GPT model it will uh take you some more charge for me okay okay now see not only GPT uh 4 you have also GPT 3.5 turbo then you have assistant API fine tuning models even I think you already used embedding models in your vector database guys yes or no have you used this embedding model yeah okay see that's how you can calculate your cost like how much it will charge you whenever you are going for any kinds of model okay you can go through this pricing praise and you can understand this thing all right yeah see ADI is there DCI is there there are lots of model okay they have given just high level overview but maybe they have some more pages actually I think you can go through and like see the cost there all right now see why we need to use open AI uh sorry why I need to use this open source large language model okay first of all let me discuss then I will start with that uh like discussion okay what like today's discussion on the Lama 2 I will tell you how to use Lama 2 and all even I will show you some available open source model you can go through okay now see guys whenever I'm talking about open source model okay open source open source llm okay op source llm so the first thing uh you can consider you don't need to pay any cost okay so you don't need any no need cost okay the second thing you can talk about um it is completely free to use free to use for the research and commercial use cases okay commercial use cases all right but whenever I'm talking about open AI okay open AI open so so I'm talking about GPT series okay GPT Series so let's say if you want to use open a so the first thing actually will come you need to get the API key okay API key and if you need this API key you need to pay for okay you need to pay for you need to pay it's not a free all right but one advantage actually will get with this open AI one advantage actually will get uh from this open a which is nothing but uh it is completely API accessible okay API accessible okay so here you don't need to download that particular model to use so if I visit open a so let's say this is my open a website okay this is my open a so here I will just loging with this uh website and here I can generate the API keys I think you already done some of the projects and all right so here I can easily get the open API keys and what I will do I will open my local machine I can also open my Google collab I can also open my jupyter notebook and there actually I can start my development okay there is no issue with that so you don't need any kinds of powerful machine there because everything is running on the API yes or no guys tell me let's make this session interactive so that I can Al also understand like you are understanding my concept guys reply me in the chat yeah thank you so this is the idea of open AI so so openi what they did actually they created this beautiful website okay and they hosted their models U um to their server okay and they created some of the API and with the help of API we can send the request to the model and we can get the response okay let's so let's say this is my this is my model okay this is my model this is my model hosted on open okay it is hosted on open a now here user will give some query okay user will get some some quy okay with the help of the API key okay with the help of the API key and this model will give you some response okay this model will give you some response response okay and this uh request and response you are getting for this you need to pay you need to pay some money because this is not a free this model is hosted on the openi website and they have created the API key so for this API key okay to access the you need to pay something hi sir as you know Lama 2 is a heavy model and it's responsive time also High then how can we decrease the time to response the open source model so F we'll be discussing this one okay no need to worry about like how we can use this Lama to model in our CPU machine so we have a projects no need to worry about I will tell you okay so guys so far this understanding is clear like uh what is the advantage with the open AI okay why we usually use open AI is it clear if yes then I will move to the uh open source part like why we need to use open source okay and what is the difficulty level with the open source model okay can we set the limit of the uses tokens how we get idea about the pricing when the test out chatbot uh yes you can also set the limit uh limit of the pricing it is also possible let's say you can set the limit for the $10 so when it will uh come like close to the $10 so you will get the notification okay that can be also done all right now see so whenever I'm talking about open source model okay open source model open source llm okay so the first thing you need need to so so the first thing you need to understand uh see whenever I'm talking about open source it's not hosted okay it's not hosted not hosted anywhere some of the model might be hosted you will get API key but most of the model would be available on the hugging pH okay hugging face or different website okay so it's not hosted anywhere it's not host anywhere okay so what you need to do you need to download download that particular model download that model okay then what you need to do you need to load that model you need to load that model okay that's how you need to perform all the task manually okay so there actually you won't be getting any kinds of open kinds of API key so that actually you can hit the AP key request and you will get the response it's not like that uh guys my video is fine um or there is any lag you can feel uh video is fine guys yeah I I believe it is fine okay all right all right now see the main disadvantage of this open source llm is you need you need good configuration good fun configuration system okay so whenever I'm talking about good configuration system you should have at least Core i core i5 or let's say three processor processor and you should have at least uh 8 GB of RAM okay 8 GB of RAM and if you have GPU then it would be plus point for you okay because it needs GPU computation so whenever we'll execute the uh model it needs actually GPU computation but I will tell you also how we can execute the model on the CPU machine both can be done okay so uh and think see U today actually I'm not going to use this neural LA because I believe in the neural La we don't have any GPU integration there so I'll be using Google collab today okay so whenever I will be implementing the projects that time I can show you on the neural lab yes we have see we know that actually we all have mostly CPU machine okay we know that okay that is why I will tell you one like technique uh using that technique actually you can execute any kinds of llm model on your CPU machine as well it is also possible okay so these are the requirement actually you need whenever you are talking about open source large language model okay because this model you need to manually download okay manually download manually load and manually execute deser the model okay that you won't be getting any kinds of API kinds of thing okay so that is the thing and some if I'm talking about some advantage of the open open source model so here actually you don't need any kinds of cost okay without any kinds of cost you can use this model for the research purpose as well as the commercial purpose so guys uh is it clear the difference difference between our open AI model and our open source large language model yes or no uh see if you have 4GB of ram then I think you can practice on uh Neal lab it's completely fine but uh today actually I will show everything on the Google collab okay so you don't need to worry about the system configuration all right guys uh is it clear the difference between uh open a model and uh uh okay just a minute uh just a minute okay uh am I Audible uh please let me know in the chat am I audible guys okay okay thank you so now uh let's introduce our uh some open source large language model so here if you see there are like very popular and Powerful open source llm there okay so see uh there are very uh like there there are lots of actually open source large language model available okay over the internet you will find but there are some most popular uh open source llm I will introduce today so uh the first thing is like I personally like this one called meta Lama 2 okay so this is the model for from the Facebook so Facebook has trained this model and they named it as Lama 2 okay so there is another model called Google Pam 2 okay so this is another model called Google Pam 2 so the this model actually trained by the Google anyone used like Google B before Google B like chat GPT anyone used maybe you used also Google B like chat GPT yes or no okay do you know like which model uh is running in the back end of this uh U Google Bart the free free uh version you are using Okay so this this is the model actually they're using called pal 2 okay so in future uh we'll also see like how we can use Google pump to model okay and there is another model called Falcon okay Falcon has lots of variant like Falcon like 7B B okay then 13B so it has lots of variant not only this one so there is a uh GitHub actually you will get uh just search for open llm okay open llms so this is the GitHub and here you will see all the open source model are available over the internet and it is already integrated here see see this guy actually uh so this is this is the guy so he has actually uh created this repository and he has actually added all the open source llm here so we have let's say T5 and this is the release date and this is the model checkpoint okay and this is the paper and blog if you want to read this uh like U about this model and all so you can open this paper and blog you can read it okay then you have ul2 so this is one of the llm model then you have uh uh this uh care brace GPT so this is another llm model then you have pathia dolly then Delight then Bloom is also there stable LM Alpha okay then MTP uh MPT 7B is also there then you have Falcon okay see I already told you Falcon is also there see llama 2 is also there okay see lots of Open Source model are available here okay all the open source model so this is the like GitHub you can go through let's say if you want to learn any kinds of Open Source llm so you can go through this GitHub and you can read about uh see for object detection actually we have like lots of model OKAY already even see nowadays actually people are also inting computer vision with these kinds of large language model so both can be support uh yes I can share the link as well in the chat so this is the link you can go through all right okay so this is the actually GitHub actually you can go through to learn about open source llm so all the models are listed here H all right now see today actually I'm going to discuss something called U Lama 2 okay meta Lama 2 so this is the model from the Facebook so they have trained this model so uh the first thing actually uh uh in this session actually I'll be discussing the Llama 2 so first of all I will introduce Lama 2 what is Lama 2 and all about then I will show you like how we can execute the Lama 2 okay without like Lang chain because there is a library actually they have created called Lama CPP okay so using that Library actually I will uh first of all execute the Lama 2 model then I will show you like how we can execute the Lama 2 model with the help of langen because in future whenever you will be do doing the development you will be implementing any kinds of projects you should uh you need to use something called Lang Chen okay so you also need to understand how we can use Lang Chen uh with these kinds of Open Source llm as well okay so both I will show you and at the last I will show you uh one project implementation so mostly uh I will start the implementation tomorrow so we are going to implement one chatboard projects okay and this is going to be medical chatboard okay with the help of Lama 2 we'll be implementing end to end okay so this is the complete agenda now if you just search like lama lama to meta okay Lama to meta on Google so this is the website you will get uh from The Meta Ai and this is the Lama 2 actually website as you can see so they have already written about L 2 so lar 2 is nothing but it's a Next Generation open source large language model okay so previously it has actually another version called llama 1 okay so llama 1 llama 1 they have uh actually developed just for the research purpose okay so it was not for the commercial use cases so only for the internal use cases actually internal research purpose they created the Llama one okay but later on whenever actually they saw like GPD kinds of model came in the market so they so they introduced something called Lama 2 model okay and this is the Lama 2 and they have also tell uh to like Lama 2 is available for free and uh research and commercial use cases both and one thing actually you need to do to get the model uh if you want to get the model then you need to get the permission from The Meta AI okay this is the requirement so just click on this download model this button and here you just need to fill some of the information like your first name your last name then your date of birth your email address country and organization if you're working with then you just need to select these are the model okay then just submit the request so after uh 30 to 40 minutes actually they will accept the request and they will give give you the access okay so this is the requirement and if you're not getting the access as of now okay there is another alternative I will show you how we can use this model okay so no no need to worry so what you can do guys you can open this website uh Lama to meta and just apply for the permission here everyone okay apply for the per permission so let me share you the link as well so guys are you doing with me can you please confirm uh hello okay I already have the access okay so you already have the access then no need to worry about you can directly access the model and one particular things actually I just need to mention so whenever you are applying for the request okay so it will ask for the email address so I I I believe actually you all have something called hugging face account guys yes or no hugging face account maybe hugging face has been discussed previous session so make sure you try to use the hugging face email address the email address you used for the hugging face okay so this email address you need to give here because this model are available in the hugging face website so whenever you will uh apply for the access they will like U ask for this email address all right now let's discuss about this Lama 2 little bit more like what they are telling so if you just go below little bit so this is the Lama 2 so they're telling Lama 2 was trained on 40% mode data than Lama 1 I already told you there was another model called Lama 1 and what they did in Lama 2 actually they train the model of with the 40% more data okay 40% more data than your llama 1 and it has a has like double context length we can download the model into our local drive as well and can play with right yes you can do it I will show you like how we can download the model all right okay uh now see guys llama 2 has actually different variant so it has actually 7 billion parameter variant so this is the 7B model and it has also 13 billion model that means uh uh the model has actually 13 billion billion parameter and there is another model called 7 70b okay so this is like 70 billion parameter so if you want to use these two model you need like good machine configuration and uh I'll tell you like how we can use this 1B model and B model as well so first of all I will like tell you how we can use this 13B model okay what would be the approach to access this model okay I can't directly load the actual model because actual model you can't ever load in your low configuration machine okay you need some good memory some good GPU there uh but I will show you one alternative there we'll be using something called quantized version model okay yeah and now see guys this is The Benchmark so this is the data set on this data set actually they have 10 different different large language model as you can see M PT uh 7 me this this is the model and this is the accuracy score uh 26.8% and they also trained uh Falcon model falcon 7 7 billion parameter model and this is the accur accuracy score 26.2 and they also trained on Lama 2 7 7 billion model okay and this is the accy score 45.3% now see guys the accuracy Improvement okay isn't it good model guys what what you can feel like see llama 2 is uh claiming uh this is this model is better than your GPT uh 3.5 turbo anyone used GPT 3.5 turbo model before maybe you have used yes yeah so they're claiming actually uh this model is better than GPT 3.5 turbo okay so that's how actually they have also given the Benchmark here and see Lama 2 13 billion and this is the accuracy and they again trained on mpt's 13 billion parameter model and this is the accuracy they got okay now they also trained with the Falcon 14 billion parameter this is the model they got this accuracy they got okay 15 uh 55.4% then uh this is the Lama 1 model uh this is the accuracy and llama 2 7 billion model okay and see this is the highest accuracy they got uh 68.9% okay that's how they train on different different data set different different open source data set as you can see these are the data set actually data set name all right and um these are actually partners and supporters for this L 2 okay like hugging face Nvidia they're Intel they are also using these are the model all right now guys uh did you appli for the permission um here did you appli for the permission everyone uh if not uh no need to worry about I will show you one one alternative this alternative you can follow okay no need to worry about can we use llama 2 for translation of the codes into python code find tuning custom data yes you can do it okay Lama 2 has different different model variant I will tell you even in future we'll also see how we can fine tune the Lama 2 model as well it is also possible on your custom data even it is already included in our paid courses I think you know uh that is also one paid version of this course so there actually we have already introduced the fine tuning technique as well all right so guys uh so far everything is clear everything is fine you can let me know uh if you have any question you can ask me otherwise I will uh continue with the session what is the name of the course could you please give me the information run this model over the docker key see it would be also discussed okay it would be also discussed Asal okay in the paid courses actually we'll show the deployment we'll also integrate docker okay we'll also integrate cicd so everything would be discussed there all right now see if you want to play with this Lama 2 model uh as your chat GPT so there is another website actually hosted just search for llama Lama 2. a okay so now you will see something called uh this website and you will see it's like chat gbt like interface so let me also give you the link in the chat okay now here just click on the setting Okay now click on the setting and from the setting itself you can um like select different version of The L 2 model okay I already told you L 2 has different different version so it has 13 billion parameter it has 7 billion parameter and it has also uh 70 billion parameter okay now first of all let's select this model uh this is the smallest model model I will select because response time would be a little bit fast okay and if you want to use any system prompt your custom prompt you can give it so I'll keep this default Pro prompt which is nothing but you are helpful assistant so it will work as a assistant okay you can also set the temperature okay what is the temperature temperature means if you uh set this temperature to close to one that means your model will take the risk and it will give you some random output okay and if it is close to zero that means this model would be more strict to the authentic output okay it w be taking any kinds of risk so these are the parameter actually you can play with all right now let's say I have selected this model called llama to 7B now I can chat with this model okay now I'll just write hello so see it is giving me the response okay see it is giving me the response now you can do anything now let's say you are having one error okay you are having one error in your code so let me search for one error so so let's say this is the error I was having in my uh flash code so I'll copy this error and I will give it here so I am getting this error uh can you please uh fix it let's see what happens uh see guys this is the response uh it has given sh I would be happy to fix the error can you please provide more context about the error you are getting uh what the line uh of the code is causing the error so it is also uh uh like uh telling me to send some uh more uh information so what I can do uh I can tell I'm getting I'm getting this is the error in my flash code see now uh it has given me the response okay it has given me other response like how to fix it now you can also select different version of the model from here you can also play with 13 billion and 70 billion it's up to you guys are you able to execute this uh website this l2. a okay all right okay thank you now uh let me show you the GitHub repository of the Lama 2 as well see this is the Facebook research and llama repository they have created let me share you the link as well uh this is the link and if you come here so they have already given like where this model is available everything they have given so if you want to access the model so this model is available on the hugging face website okay just you can open the hugging face and you can visit the model see all the models are available okay different different version of the models are available and what is the chat model and what is this without chat model I will tell you okay so there are some like uh you can say difference between these are the model I'll tell you okay now see guys they have already mentioned here if you go below um here so Lama 2 actually has two different model one is like preend model and another is like fine tune chat model okay so what is the preend model first of all you need to understand so preon model is nothing but these model are not for fine tune for the chat or question answering okay they should be uh prompted so that uh the uh expected answer is the uh natural continuation of the prompt so basically let's say if you want to uh generate the text okay if you want to generate any kinds of text from the Lama to model then you to use this pretend models okay from the Lama 2 Series and there is another model called fine tune chat model what is fine tune chat model fine tune chat model is nothing but the fine tune models uh were trained for the dialogue application to get the expected features from the performance from from them specific formatting defined chat completion so here it is telling if you want to do let's say question answering system or chat operation so you can use this fine tune chat model okay now if I visit hugging hugging face again here now I think this should be very much clear like whenever they're defining like chat model okay whenever they defining chat model that means this is the model for the question answer or let's say chat uh I mean chat model okay and whenever you won't be seeing any kind of chat model that means this is for the Tex generation model is it clear why different difference model you can see in the hugging fish let me know guys yes one for chat another another one for like uh text generation great okay now let me close this other the tab H now first of all Let's uh play with this model called LMA 213 billion parameter model this model first of all I will tell you like how we can execute this model and if you have very low configuration PC so what you can do in this case okay first of all I will tell you this one then I will show you how we can execute this uh 7 billion parameter model with the help of the Lang chain as well both I will show you so for this first of all let's try on neural lab okay so if neural lab is not working then I will go to the Google collab so first of all I will be using the quantied model and let's see whether it is working or not so everyone you can open your neural app so let me open so so I'll loging with the website so here I can take I think jupyter notebook repter notebook I think I can take so everyone can open this uh neural lab with you also let me Zoom this screen now my screen is visible guys this text is visible you can confirm me in the chat all right so let me first of all test whether I have GPU here or not maybe there is no GPU here how can we uh check the configuration see here no need to check the configuration because this is like a remote server it is running uh okay this command is not found maybe no GPU okay then I will use quantied model let's see what happened and also let me share the code with you so what I can do I can open code share and I will share this link in the chat so whatever code I will be writing I will be just pasting here okay you can get from here all right now first of all let me show you the model actually I'm going to use uh so we'll be using some quantized model so this is the website of the Quant model and this Quan model is already available on the hugging phase okay so there are different different organization so they actually did the quantization of the model and they publish the model here okay see Lama 27b model Lama 23b model chat model OKAY different different models are here now do you know what is quantization guys anywhere here what is the quantization what quantize mean you can let me know in the chat if you're not familiar with quantization then I will give some idea how this quantization works model uh comparation technique yes you are right uh okay now see what happens actually so whenever you train your neural network okay so whenever you train your neural network so let me take um one just demo neural network here so let's say this is my network okay so this is my let's say Network so this network will have some of the weights okay let's say W1 W2 W3 and so on okay so each of the uh layer will have the weights okay each of the layer will have the weights yes or no guys do you understand understand this neural network concept maybe yeah now see what is this weight weight is nothing but it's a value okay it's a number only it's a floating number so it will have let's say 0.36 or let's say 0.46 it might be also 1.2 it might be also 0.88 any kinds of number okay it would be adjusted ining back propagation BP all right now one thing I think you already know uh whenever I'm talking about data type and data size okay so whenever I'm talking about character character data type okay so I can take uh 32 bit I can also take 64 bit okay character now can anybody tell me uh what is the character uh let's say size in the 30 32 bit anyone know what is the like character size okay in the memory for the 32bit anyone because whenever you will uh assign these are the number it will occupy the memory okay it will occupy the ram so what what would be the size there any anyone any idea idea for kilobyte uh no in 32bit actually it would be 1 BTE one bite okay and 64bit also it would be one bite and if I'm talking about short okay short or you can also talk about string okay then in 32 bit it would be 2 by and 64bit also it would be 2 by okay now if I'm talking about something called integer so 32 bit it would be uh 4 by and 64bit it would be 4 by okay and if I'm talking about long so long means it's a floating number okay it's a float you can talk about so float would be uh 32 bit it would be 4 by and 64 bit it would be 8 by and long long there is another data type called long long long long means it's a double in Python we call it double okay so mostly you will see in the weight initialization they will be assigning the double number okay instead of floating number so it would be uh in the 32 bit it would be 8 by okay 8 bytes and 64 bit it would be be 8 bytes okay now tell me uh which uh data type is taking more space in the memory U floating or integer tell me just reply me guys first in the chat which data type is taking more memory in the uh more space in the memory float yes you are correct float is taking more memory so now let's say whenever we are training any kinds of neural network so by default the weight initialization or weight adjusting is happening with the floating number now see you can also round the floating number let's say you you are having these kinds of number 1.22 okay or let's say 2.33 now if you just round it let's say 1.22 you can make it as 1 okay and 2. 32 you can make it as two now you just round the number and it has become in that means integer okay some data loss would be happened but again you are somehow trying to adjust it or let's say round it to the root root number okay so we call it a quantization technique so basically what you are doing uh the floating number you are having okay in the weight you are just trying to uh round it to the actual number okay you are just trying to convert the floating number to integer number okay now tell me uh previously it was having that uh floating number now it has become the integer number now is there would be any uh uh like changes in the memory yes or no okay now see memory size would be reduced because of this U integer number because we have done the quantization technique okay so this is the quantization idea basically uh you are just trying to convert your floating number to integer number all right yes and whenever I'm talking about models uh model will have l let's say billion million parameter now let's say if you have billion million parameter and you are converting everything to the integer now just think about how much memory will save let's say your model size is 30 GB okay your model size is 30 GB initially okay now after doing the quantization this model will have 5gb okay and we call it as quantized model and this is the actual model so some accuracy might be drop in this model but again this model would be fast and we can easily load this model in the memory okay in our low configuration PC got it so let's say this model needs actually 16 GB Ram but after done the quantization this model has become 5gb now I can easily run this model in the 8GB M Ram or let's say 4GB Ram it is also possible got the idea guys if it is clear just write clear in the the chat so that so that I can understand you are getting my point yes performance will reduce uh but we need somehow the faster inference okay but quantize model is also good it will give you like good responses okay now there are different types of actually quantization techniques okay so one of them is gml okay gml gml is the quantization technique or quantization Library you can talk about gml gml format quantization there are various kinds of technique but uh they have used something called gml okay gml quantization so today actually I'll be using one gml format model quantized model of that 13 billion parameter model and I will show you how we can execute the model all right okay now let me show you the model actually I'm going to use here so this is the model guys I will be using so let me give you the link so this is the link guys and L 2 13 billion chat okay because I want to do question answering with my model that's why I I'm using chat model but let's see if you want to generate text guys which model you will be using tell me chat model or without chat model no no no it is support Lama CPP I I'll I'll execute and show you Prashant yeah without chat uh yeah now see guys this is the chat model and this is the gml model and this model has different different variant as well see uh some of the model is like 5gb some of the model is 6gb okay 7gb so different different model we have so from these are the model actually I'll be using one particular model so this is uh your quantization Technique you can talk about quantization Library so Library they used for the quantization okay so uh so zml is the one of them and if you see this is the dot bin that means it's a binary model okay it's a binary representation all right now see guys uh if you want to use this quantized model OKAY gml version model then you need to use one Library called uh Lama CPP okay Lama CPP CPP okay this is the library let me show you um see that's how you can install this Lama CPP Library so these are the command you need to execute so cake so this is the command so it will install your Lama CPP and as well as Lama CPP python you need and this is the specific napai version you need and as well as the hugging face Hub also you need okay why you need the hugging face Hub because this model is available on the hugging face okay and to download this model from the hugging face I need this hugging face Hub okay this is the library now let me EX and see whether it is working here or not let me also give you the code in the code share guys you can let me know if you are able to see the code in the code share the code is accessible guys yes or no uh please give me some response so that I can get to know okay uh maybe installation is done uh okay fine so you can ALS also make the installation all right now I will be defining the model actually I'll be using okay so now let's define the model here so okay so see guys uh this is the model I'm going to use uh Lama 2 13 billion chat gml all right see this is the model uh Lama 2 13 so you just copy copy this name and just give it here copy this name and give it here and you also need to give the Bas model name because here you can see there are lots of model OKAY in binary format now which particular model you should be using here so I'm using this model so let me copy the name and searce it here see I'm using this specific model and this model model size is 9 76 GB actually okay this is the model so this model I'll be using so let me execute now first of all I need to import uh hugging face Hub to download the model as well as I will also import something called Lama CPP Library okay now let's download the model so let me also give you the code now here if you see I'm giving the repo ID so this is my repo ID model name or path and this is the base model I want to download okay and I'm using hugging face Hub to download the model now let me download so see it's downloading it's around 9.76 GB share the link I already shared this uh code shell link all the codes are available here let me share it again all the codes are available just copy paste uh in your notebook and ex Ute one by one so guys is it running so far everything is fine without any error and if you check the original uh this 13 billion parameter model it's like huge model okay you can't U download this model on this neural lab so you need a good uh instance there so that is why actually we are using this contest model almost done let's see okay it's done now if you want to check the model path actually where it has downloaded you can just uh uh see that see this is the path actually it has downloaded the model okay see we have locally downloaded our model now what I need to do I need to load my model okay so to load my model I will be using this Lama CPP Library okay and see I'm importing from Lama CPP import uh Lama now with the help of that actually I will load my model okay see uh if you have GPU in your machine then this would be quick response okay otherwise maybe it will take time let's see what happened on neural app because in neurolab it doesn't have any GPU so here is the model path I am giving and these are the parameter you need to give okay like uh threshold U number of threshold like CPU CES you want to use then number of B actually you want to use okay then number of GPU layers you have so by default keep this number and let's execute and see what happened loaded internal vocab okay so it has been loaded I guess let me execute it again it's loading so this is the problem with uh open source llm because here it it uh it needs actually some good instance okay to run the model okay done uh there is no error okay fine now what I can do let me give you the code now let's uh create one Pro prom template here uh guys do you know what is promt template anyone maybe uh you already learned this thing in your open a discussion just give me a quick response in the chat what is a prompt template what is prompt do you know why we use prompt in llm yes okay great see here we are writing one prompt here our custom prompt template so here I'm just telling as a prompt uh write a linear regression code okay and as a system prompt I'm giving you are a helpful uh and respective respectful and honest assistant always answer as a helpfully okay then user will give you the prompt and you need to provide the answer as a assistant okay so this is the custom prompt template I have created now let me execute and give it to my model also I'll paste it here h now finally I will give this promt template to my llm okay see I'm calling this Lama um that means this uh Lama CPP library and here I'm giving my prompt template okay see this is my prompt template I have created prompt template as well as I'm also giving the max token length okay that means maximum response okay maximum tokens actually it will give me as output and I'm also setting the temperature okay temperature top P then P penalty I think you remember if I open this one Lama do Lama 2. a now if I go to the settings now see these are the parameter you can adjust here got it guys what is this parameter see temperature max token top parameter okay see everything is there you can um change it here so by default keep this number and execute can you explain the penalty see uh penalty like see it's a parameter actually it helps to generate a like you can say uh actual response okay let's say if you increase and decrease this parameter so what will happen actually you will see your model will give some random response okay or let's say the response actually it is not relevant to your prompt you are giving so this parameter actually adjustable parameter so this parameter can be changes whenever you are changing the temperature parameter so here temperature parameter I kept as 0.5 that means I'm turning to my model uh sometimes just take a risk okay sometimes don't take a risk okay it just a uh I mean adjusted number I have given now let's say if I'm increasing the temperature value let's say close to one so what will happen my model will be taking risk okay let's say if I'm giving any kinds of prompt and if if it doesn't know anything it will give risk and it will generate some random response as well which can be correct which can be wrong as well okay and if you decrease this parameter close to zero so what will happen your model won't be taking any risk it will only give the authentic response you are expecting from your model okay so these are the parameter can be changed all together see again it is running on CPU machine that's why respond time little bit High here and again we are using 13 billion parameter model so that's why if you're taking 7 billion parameter model so respond time would be a little bit less so let me give you the code as well so it's still running let's wait for some times if anyone get getting response so you can let me know whether response uh unable to run in neural lab um see I think I'm able to run it's working for me so far so if you're not able to run in neural Labs what you can do you can open Google collab Iman okay and there actually you can execute maybe the same code you can copy paste there and make sure you selected GPU there it's taking time a lot guys so side by side what I can do I can also show you the collab execution because I don't know how much it will take I already have the notebook ready so let me just show you I'll share it with you so let me connect still running on NE lab okay so here I got the GPU Tesla T4 this is the free version GPU and let me install the libraries guys if it is taking time for you in La so you can execute on Google collab I think it you will get quick response there because again I need to cover that uh langen part so it will take time okay done now let me quickly execute because I already explained these are the code how it is working okay now let's load the model okay now if you want to check the GPU layers so you can check it out so I have 32 layers in my GPU and here is my custom prom template and now let's uh execute my llm and let's wait for the response okay done now this is the response I got now if you want to see the actual response so you need to uh call this one like Choice then I want to take the first uh list and this is the text okay it will give you now see it is telling uh I would be happy to help with that however I want to make sure we have the same understanding on the linear regression okay so basically if you're executing for the first time so it will give you this response okay now if you want to get the actual response then again you need to execute the same code so it's better better to use a 7 billion version model because it will give you quick response um than this 13 billion one so guys are you able to execute the code I shared with you this notebook okay done now this is the response and this is my final response now see uh is it correct code can anybody tell me uh I told my model to generate linear regression code for me now just see the code and tell me just give me quick response guys in the chat yeah so for this we need to use some smallest version of the model okay because if you don't have good configuration PC then this is the only option SAS all right now is it is it correct code just give me a quick response okay great now see you can ask any kinds of question okay like your chat GPT or what you have done so far okay now see without any cost we are able to also uh use these kinds of large language model okay yeah now you don't need to pay for anything if you don't have money okay if you don't want to buy open AI so it's completely fine you have different different uh large language model open source large language model you can use them for your development and tomorrow I'll be discussing one particular projects then it would be clear like how we can Implement any kinds of projects with respect to that okay yeah so this is uh the implementation of Lama 2 uh using the Lama CPP library now I'll show you how we can do it with the help of Lang chin because going forward all the application will be uh like uh developing with the help of Lin okay so first of all let me uh stop that uh instance I have opened okay now all right so can we try this free llm instead open Ai and make a uh practice with the Lang yes you can do it I will show you how to use uh with the l okay I'll show you everything would be cleared so see the same thing you need to do as of now you have done with the open AI only you just need to import this large language model open source large language model okay then you need to use that as llm that's it okay yeah all right now this code is working fine guys everyone are you able to get the response just uh give me a confirmation then I think I should start with the langen one if it is running fine for you just give me a quick response okay now let's see the Lang chain one so let me uh share you with this code so here I'm going to use the actual model OKAY actual model not the quantized model and I'll be using 7 billion parameter model and let's see how we can use it so this is the code actually you can refer yeah so here actually GPU is required okay GPU is required now first of all let me connect the notbook all right now if you want to check the GPU you got or not so this is the command so here again I got Tesla T4 GPU then I need to install some of the libraries here okay so first thing I need something called Transformers okay why I need to install Transformers because uh this model is available on the hugging face okay if you see here and I'll be using hugging face pipeline here to load the model that's why sorry not this one I think just just let me open this one yeah so I have the model here H so see this is the model on hugging F and I will be loading this model with the help of hugging fist pipeline okay so that's why this Transformer library is required then these are the like dependency you need with the this Transformer then I I'm also installing something called Lang chain okay then bits and bu and accelerate you need you don't you need to install for this Transformer now let me install them uh link I think I have already given just just a minute uh link would be shared just a minute okay then I need to loging with my hugging face okay to loging with the hugging face this is the command hugging face uh CLI login okay you need to do it it now let me execute now it will ask for the uh token okay secret token yeah so you can take time now how to generate this secret token just go to your hugging Fish account let me open my hugging Fish account hugging face now here just click on the profile and click on the settings okay and here you will get something called access tokens now click on the access tokens now here I already have some of the token so what I will do I will uh remove one of the token from here so let me delete it okay now I'll generate a new tokens so you can also generate a new tokens so give the name I'll give Lama and I will give only read access because I I only want to read the model okay not I I don't want to upload anything that's why read is fine now generate the tokens now this is my Lama uh tokens now I'll copy it so you need to generate your own token guys don't use my token I'll remove it after sometimes now here I can give the token and press enter now here just give yes and press enter done login successful now first of all I need to import something called hugging face pipeline because I already told you with the help of hugging F pipeline I need to uh like uh load the Llama 2 model okay now let me uh first of all imported from the langen see len. llms I'm importing hugging face pipeline okay now if you're using openi model U I think you remember you you used to import something like that uh from langen llm import openi yes or no can you can you recall that concept you learn in your openi so only difference would be like that now I also uh need to import tokenizer okay why I need to import tokenizer because yeah so link just a minute so link I will add in this uh code share okay see this is the link I have added at the last so you can copy from here now why tokenizer is required Auto tokenizer so whenever you will be giving uh the input to your llm so it would be a raw text okay but um see Auto tokenizer what it does actually it will take the raw text and it will clean up first of all it will do the preprocessing some of the preprocessing let's say if you if it is have some kinds of HTML tags and all it will remove then it will convert that uh uh like text to numbers okay automatically it would be converted using this Auto tokenizer okay Auto tokenizer class so I I need to import that I also need to import something called Transformers and torch and I will also import this warnings done now first of all I need to load the model okay I need to load the model now see guys here one thing you need to remember so I'm using this particular model let me show you so if I open this model on the hugging face so this is the model I'm using and this model is from meta Lama if you see here I'm not using any quantized model this is the actual model and see I already have the permission here okay I already have the permission you have been granted access to this model but for you this this will come like that let me show you so if I open my en Cito window and if I go to this link uh you will see this window guys can you can you see that can you check from your computer whether you are getting this one or not access Lama to on hugging P then you need to submit some form here you need to sign up just give me a quick response uh can you see this window guys okay so if you're getting this windows so what you need to do you need to log in okay you need to log login and submit that information I already told you so if you visit that one meta Lama 2 Meta Meta Lama 2 sorry it would be llama 2 now here you will get this this window okay here you need to submit your information and maybe if you have submitted for the first time uh initially I showed you then it's completely fine and make sure the email address you are giving the same email address you are using for the hugging face okay now see I already have the access uh to this model to The Meta this organization that's why I can access these are the model now see after some times let's say 40 to 50 minutes you will get one notification okay in your email so it will be looking like that let's say your name this let you know that your request uh access to this model has been accepted by the repo author okay so once you got this mail that means you would be able to access this model okay then you will able to to see you have the uh you you have been granted to the access to the model okay you will get this notification then you will be able to use the official version of the model and if you're are not getting the access as of now so what you can do you can activate this line of code and you can comment this line of code okay see this is another uh organization that means another guy he has cloned this meta model okay that means this model and he has already published this model from his organization that means from his Repository and this is completely public okay you can easily download the model no need any permission okay so this is the alternative way to use the model okay so I already have the permission so I will use the official model I will just comment this line but if you don't have the access you can uncomment this line and comment this line it's up to you now let me execute now first of all I need to load my tokenizer okay uh so tokenizer will use the same name to load the token tokenizer okay now let me load the tokenizer loaded now here I need to create the pipeline hugging face pipeline so what is the hugging face pipeline see um how this hugging face pipeline will work so let's say uh this is your model or let's say this is your pipeline this is your pipeline object you have created and this is the input you are giving input text input text okay so it will give you the response so in pipeline what will happen so first of all it will uh apply some preprocessing apply preprocessing preprocessing okay with the help of uh Auto tokenizer auto toen ner okay then second what it will do it will uh convert that number okay that means a text would be converted to numbers that means Vector okay then this Vector would be passed to my model okay then prediction would be happened then fourth it will give you the response okay so this is the pipeline task actually so this is the pipeline they have created so you don't need to take care these are the task automatically it would be done okay you just need to create this pipeline objects now here I already imported Transformers you remember and here I'm just calling the pipeline and here you need to give the name so here I'm performing Tech generation okay that's why I'm giving Tech generation because if you see the model it's a TCH generation model okay although it's a chat model but it's a tech generation model let me show you the model card if you see it's a TCH generation model okay this is the key you need to give so here here I already given the name Tech generation now here I given the model so this is the model I given and I also given the tokenizer I downloaded now these are the default parameter you need to give okay no need to change anything the default parameter you need to give now let me load my pipeline now see if this model is not available first of all it will download the model from the hugging P so it's downloading the model anyone doing with me guys so which one you are using the official one or this alternative one alternative one okay great so you can wait after applying this uh uh like you can say access permission you can wait for uh like 40 to 50 minutes or let's say 1 hour you will get the email definitely you will get the email then you can use the official one because in the hugging pH what happens actually um some of the organization uh will have their private repository okay and if you want to access the private repository you need the access from the author okay otherwise you can't use their model and all okay they will be uploading that's why we need to apply for the permission but most of the repository you will see it's public okay you don't need any permission but this is the meta organization that's why maybe they have uh given you that one maybe they want to uh take your information okay because whenever you are submitting the this request form uh they are having your name email address which organization you are working on so that they they will send you some mail regarding their product okay maybe this is the things they have developed see model has been downloaded now see guys this is the magic Now using hugging face pipeline you can easily create your llm see now as a pipeline I need to give this pipeline objects okay and this pipeline object is nothing but my entire uh Auto tokenizer and my model okay everything it is there now model uh you need to give some argument so what is the argument argument means the temperature okay the temperature value so we always give the temperature value because I want uh my model like how it will give me the response and all so as of now I just set this temperature as zero because I am telling to my model don't give any random output just stick to the response you are giving okay now see guys this is the llm I have developed now see those who have used open a maybe you just used open a here okay instead of llm like that maybe used like that so llm equal to open AI okay and here you you used model name let's say GPT uh GPT 3. 3.5 turbo yes or no please tell me got the difference uh how to use open open Ai and how to use open source one please give me give me a confirmation in the chat guys I can't see any response so please response me okay now let me uh remove this line and let me open uh load my llm okay okay now uh what I need to do I need to uh give my prompt okay so first of all I will be giving the prompt like that okay in just one shot so here I'm giving one prompt so what would be the good name for a company that makes colorful socks okay so this is the prompt I have given to my llm now let's see what is the response it will generate see 7me model is also very good model me I personally use this model a lot so you will see it will give you like very good answer and it's not a quantized model okay we are using the actual model see this is the response okay now it has given me uh some company name a good name for the company that makes colorful socks could be something playful and crashy uh now see this is the company uh uh sock tastic and then toys on fire color of fista then soulmates uh stre socks Hue and cry uh socktopia and souls uh session okay so these are the company you can use uh let's say if you are like stablishing any company so you can use this name this is a unique name actually now let's uh give another P so here I have given another P here I'm telling I want to open a restaurant for Indian food suggest me uh some fence name for this okay now let's see what is the name it will give me okay see uh it has given me so many name so tanduri kns spice route Mumbai street food uh then uh Rajasthani Royal then uh Tikka tandur Nan shop Biryani bazer Masala am menion and dosen it's taking more time to give the response yeah definitely it will give some time because we are using the actual model not a quantised model okay now isn't it good response guys what you feel like tell me isn't it good response okay now you can also uh create your prompt templates okay now here I have given the prompt directly now you can also create your own prom templates okay it is also possible so to create the prom templates you need to import the prom template from langen and langen I think it is already discussed like what is prompt templates what is prompt okay uh everything actually uh uh we we have already seen in the langin so that is what actually I'm using we are not playing right so we have to compromise yeah now let's uh import this prom template and this llm chain okay why I need llm chain because if you want to add your custom prom templates you need this llm chain okay with the help of llm chain you will combine your llm and your prom template together okay then you can execute now see the first prom template I have developed this is the first prom template and this is the prom template and input variable is kins okay now instead of giving the template okay in one chance I'm just I will give the name I'll give the cuine name and it will automatically take take the prom template from from here okay now see how it will work now if I execute it now see if I do format operation and give the kuin equal to Indian now see this is the prompt it will give me okay I want to open a Resturant for the Indian food see automatically it has taken the input okay now this is another prompt I have developed uh provide me a concise summary for the book name okay now book name us will give that okay instead of giving the whole template user will only give the Boog name and it will take the entire prompt now see this is the entire prompt it will make like that okay provide me a uh concise summary of the book of Alchemist see user is giving Alchemist and Alchemist will come here now I will execute my final Chen now see I'm calling my llm Chen and here llm is equal to G I'm giving my llm which I already created here this is my llm I think you remember and as well as I'm also giving my prompt template see prompt is equal to my prompt template so let's take the first prompt template first of all so I'll take this prompt template okay and baros is equal to true that means if you want to see the output as well like what is happening so you can give it as true otherwise you can keep it as false now let's give the uh prompt here so this is prompt template one means I want for the uh food purpose okay that means cuisin so let me give the cuisin name so I'll Indian now let's execute fcy Resturant thank you for Advance help best regard okay let me again now see first of all it will uh like make the prompt now see it will give give give you the response now see the response you got now let's say I want to use the prom template to so I'll copy the name and here I will give it and this is for the summarized book okay now here you can give any kinds of book let's give Harry Potter okay done now here is the uh Harry Potter uh you can see this is the summary okay like what is the Harry Potter book and all about so it will give you the entire summary okay so that's how actually you can use this open source large language model okay now you can try with different different variant so if you if you can visit here let me visit maybe this is the page see you have still lots of model you can explore okay uh side by side now I believe guys you are able to understand like how to use open source large language model yes or no so tomorrow we are uh going to implement one particular projects called medical chatbot then I will show you how we can uh execute on the CPU machine as well so guys everything is clear give me a confirmation because we are done with the session and one particular things actually uh you need to download for tomorrow so let me show you because we need this thing actually so this is the model actually I'm going to use tomorrow for the medical chatbot implementation so this model just try to download and keep it with you so I'll be using Lamas to 7B chat model gml again I will be using quanti model and from here and see this is the model you need to download so let me give you the link so copy link address so everyone you need to download this model and keep it with you okay so tomorrow this model is required I have shared the link so maybe you can get the link from here and you can download the model and it's around uh 3.79 GB you need to download this model no tomorrow is not a last uh class okay still some of the session would be there so link is there in the chat guys so you need to download this model and keep it with you okay because this uh download will take time so just try to download this model and keep it with you so uh how how was the session guys are you able to understand everything about this open source large language model and all and I already shared all the code and everything so you can execute from your site if yes then let's uh I think end the session I have done with the discussion okay uh so let's start with our session guys uh so today actually I was uh telling I will be showing you one project implementation so the project name is n2n medical chatbot yes and here I will try to integrate all of the like technology you have learned so far let's say Lang chain uh Vector database okay then I will also use like lama lama 2 model yesterday I think I was discussing Lama 2 how we can execute and all okay so we'll be combining this thing uh together and we'll be implementing this amazing projects so mostly uh today actually I will show you the notebook experiment okay and tomorrow I will show you uh the web app implementation at the modular coding implementation okay so today I'll be discussing the architecture overview and all and I will show you the notebook experiment like how we can develop this thing uh in our jupyter notebook because I know like most of you are like already familiar with jupyter notebook implementation I'll uh try to show you after implementing the projects on the jupyter notebook how we can convert to our modular coding okay so that should be our main objective so are you ready guys if you are ready just uh give me a quick yes in the chat so that I can start with the session okay thank you thank you everyone all right uh so first of all uh let me uh tell you the technology and the architecture actually I'm going to uh use in this projects uh then the implementation would be clear in your mind uh because uh I always like to discuss the architecture at the very first before implementing any kinds of projects okay so it makes me like uh to discuss the projects in a very easy way okay so let's do the architecture discussion at the very first all right um guys my screen is visible uh can you see that Blackboard and all you can let me know or should I zoom a little bit okay great all right now uh let's discuss with the architecture uh overview so the projects actually I'm going to implement called uh medical chatbot okay so here what is our idea so the first thing actually see uh the uh chatbot actually I'm going to implement so this would be only uh let's say depends upon our custom data okay the data actually I will show to my bot it will only give me the response uh with respect to that okay you can also like U integrate like U um all over the internet data it is also possible but uh first of all I want to show you let's say if you have some specific data if you have some specific let's say domain like that data how to connect okay with your Bot because we have seen like the chatbot implementation U like with the all over the data available in the Internet it's completely fine but we haven't seen like how to use our custom data okay so that is the main thing here so that's why uh so the first thing what I need to do in the data injetion part uh I'll be using my own component here okay so there actually I'm going to write one component called Data inje or you can talk about data integration so here you can use any kinds of data so here in this case I'm going to use something called PDF file okay PDF file PDF files so in this case actually what kinds of PDF PDF file actually I'll be using so I'll be using something called Medical medical book medical books okay so let me just show you the PDF actually I'm going to use here uh I will also give the PDF um no need to worries about so see guys this is the book actually I'm going to use so the book name is the G enyclopedia of medicine okay so this is one of the Great Book actually I found in the internet it has actually 637 pages and this book has been discussed all the disease with respect to the medicine as well okay if you go through this book so I was just going through the book and I was just checking what are the contents actually they have given see all kinds of disease actually they have mentioned with respect to the disease actually they have also given the medicine okay you need to use so this kinds of data actually I will give to my llm and I will teach my llm like uh this is my data okay and these are the disease with respect to that these are actually my let's say medicine okay so if user is asking any kinds of question with respect to that you should give the response okay so this is the data guys so I'll will share this PDF with you so you can open it up and you can go through okay you can go through like what are the disase actually it has discussed what are the medicine it has discussed uh okay everything uh you will get from here all right so this is going to be my data source here okay so the first component actually I'm going to implement which is nothing but my data integration all right so after after like uh data integration what I need to do because it's a PDF file okay it's a PDF file I just need to extract those data okay if I'm not extracting the data then how we will give to my model right so that is why the second thing what I need to do I need to extract the data so here I'm going to write another component and I will just name it as extract extract uh data or you can also tell content okay content so this is going to be my second component now after extracting the data what I need to do okay I need to create a chunks okay so let me just draw it here so what I will do here I will create different different chunks okay why this chunks is important I will tell you yeah so here I'm going to create text chunks text chunks okay so let me just copy this component okay so this is my Tex chunks okay now let me uh discuss what is this test CHS okay why I exactly need that so for this what I can do uh let's uh copy some of the content from this book so let's copy from here um let's say I will copy this content from here I'll copy let's copy this part I'll copy now I'll just paste this content here okay so let's say this is my data so let's say this is my data so let's say this is my entire book data I collected okay I extracted from my PDF book so this is my uh Corpus okay you can call it this is a corpus Corpus Corpus Corpus means your entire data okay you have currently but why we are creating the chunks okay so to understand this one first of all I will show you so if you search open a models okay let's give you the like demo with the open a only so I'll just search open AI model okay if I search it now we will get one page here now let me Zoom a little bit yeah now let's say these are uh these are the model are available okay here these are the model are available now let's say you want to use this GPT 3.5 okay if I click on this model now here you will see something called this model and this model description and the context window okay what is this context window cont context window is nothing but it's just a input token size okay so like how many tokens this model can accept Okay at a time as a input so this is the input token now let's say if you're using GPT 3.5 turbo okay so this is the tokens okay this is the tokens like 4,096 tokens it can take as a input okay now here in this case I I'm using something called Lama 2 model OKAY the model actually I'm going to use called Lama 2 model llama 2 model and uh this model actually uh has the Contex size that means the input tokens uh is nothing but 496 okay token limit token limit okay but if you see in this entire PDF okay if I extract the data okay if I'm extracting the data from this entire PDF I have around 637 Pages now just think about will it be like more than uh this token guys 4,096 token yes or no just tell me in the chat what do you feel like token means it's just a particular word you can talk about if you combine three character together you can call as one token uh making sense guys like if I am extracting the data from my entire PDF so it would be more than 4,096 token yes or no yeah so maybe you are getting okay so that is why actually what I need to do okay because see my input length is that means input limit is 496 token but whenever I'm extracting the data it might be more than it might be more than 4,096 tokens okay it might be more than 4,096 tokens so that is why what I need to do I need to just create a chunks okay instead of giving all the Corpus together to my model I'll be create a different different chunks what is the chunks guys chunks means like you will be taking some particular paragraph let's say I'll start from here okay now let's say I will assign this Chang size Chang size is equal to let's say I will assign as 200 so what it will do it will count 200 word okay let's say this is the 200 word I have here so it would be one CH okay this is my first chunks now again uh it will start from here again it will count 200 wordss and it will start uh like end here okay so this would be my second chance so that's how like all the data you have okay in this PDF it will be creating a different different chunks okay and now if you see one particular chunks have the token size of 200 okay now there won't be any input problem to my model okay so this is the idea of this creation of the chunks I think this part is clear why this chunks is important okay yes so there is another concept called chunks overlap okay I discuss whenever I will be assigning the chunks overlap I will discuss what is Chunks overlap s overlap is nothing but so whenever you will Design This chunks overlap par parag uh this parameter Chun overlap overlap let's say I will assign as 20 so what it will do whenever it will create the second chunks okay it will just go back to your first chunks and it will count 20 words again so let's say here is my 20 words okay so from here actually it will start the second chunks and it will end here okay it will end here okay so basically what is happening if you see here some extra word is also coming from my previous chunks as well okay so with that actually my model is getting the context that means after this chunks actually this chunks is starting okay got it so this is the idea of this chunks overlap so that's how actually we'll be generating our embedding Vector embedding then we'll be storing them to the vector DB got it yeah now let's go to our architecture and see our uh like uh fourth component what I will be do now fourth component wise I'll be creating something called embeddings okay so here after creating the chunks each of the chunks I need to convert as a number okay so we call it as embedding so just let me draw it this is my embedding now I'll just copy this component uh thanks Forman for your contribution thank you so this is my embedding so embedding is nothing but it's a a vector okay so it's a vector so let's say it can be any kinds of vector I'll just take some dummy Vector here so let's say this is my Vector okay so we call it as embedding this is my embedding okay now what I need to do see I have uh extracted my data as well as I have also created my chunks and I have also converted that chunks to my embedding that means vector now what I need to do I will be creating one semantic index okay what is semantic index semantic index is nothing but uh see it's a vector database concept I think whenever you learn the vector database so in Vector database we have two kinds of thing okay one is like my knowledge base and other is like like semantic index okay with the help of the semantic index actually it will build a cluster I think you remember so it will build a different different cluster so let's say king and queen would be appearing in the same cluster then man and woman will be appearing in the same cluster then Mony will appearing in the different cluster okay so with the help of the centic index that can be possible okay it will calculate the distance between all the vector and will create some like let's say like cluster here okay so this is the idea of this centic index so just let me draw it here so after creating my embedding so what I will do with the help of this Vector DB I'll be creating one I'll just build one centic index uh semantic index so I'll combine all the vector together okay and I will be building this centic index extra words are coming on previous chunks to make relationship the vector uh yeah so whenever I'm talking about this chunks overlap that means I'm taking some previous words as well okay in my second chance that means uh my model will able to understand after this chunks actually this second chance chunks is starting okay so because of this overlap overlap condition got it yeah now I have built my semantic index now what I need to do guys I need to build my knowledge base okay knowledge means I I just need to store these are the vector to my knowledge base so just let me create the component here so I'll be creating one knowledge base knowledge base okay so here knowledge base wise I'll be using something called pine cone Pine con um Vector restore uh so guys I think you are already familiar with pine cone I think this has been covered already how to work with pine cone and all how we can store the vectors in my Pine con database yes or no okay okay great now I'll be building my knowledge base all right now see this is the part actually my first part okay this is my first component this is my let's say uh this is my backend component you can talk about now I also need to build my front end component so this thing is my back end compon component the entire thing you can talk about this is my back end component this is my back end component okay now see what now user will do user will raise some query okay with respect to that I also need to provide the answer to the user uh I'll be using pine cone here okay you can also integrate chrb why I'll be using pine con because Pine con is the remote database okay it is already hosted in the website so I can store my Vector there but chroma DV is the local Vector DV okay so that is why actually I W be using chroma DV but you can also integrate chroma DB the same thing you can do it all right yeah now let's work with the user part now let's say this is my user let's say this is my user this is my user okay so I can assign this this is my user so user what uh actually he will do he will raise some query okay so let's say this is the question so here is the question is the question user will ask now first of all what I need to do I need to convert this question to the query embedding so here is the component I can call it as query embedding okay so this is the query embedding now this qu query embedding I just need to send to my knowledge base okay so here I can integrate like that so I will send this query embedding to my knowledge base uh thanks uh bright bright side I think what's your name I don't know but thanks for the contribution yeah thank you okay now this uh question I will send to my knowledge base okay because knowledge base has all of the vector okay all of the data now now what uh okay Karan thank you Karan okay for your contribution thank you it really motivates a lot thank you all right all right great now see this query uh actually I will send to my knowledge base okay now what this knowledge base will do actually it will give you some rank result okay what it will give you it will give you some rank result just let me draw this component this will give you rank result that means it will give you some closest Vector with respect to the query you have asked okay now what I need to do okay I will be intrig my large language model OKAY in this case I'll be using something called Lama 2 Lama 2 okay so this is my large language model so with the help of this large language model I'll just filter out my exact answer I'm looking for from this rank result okay so this llm will give me the response so this response I will send to the user okay I'll send to the user all right so this is the complete architecture of our medical chatboard so the first thing what I doing first of all I am integrating my data component which is nothing but PDF file in this case okay I'll be using PDF book now the second thing I need to extract the data or content from the PDF book then I need to create a chunks okay I need to create different different chunks because it might be more than my input tokens okay to my model so that's why this chunks creation is very much important so after creation of the chunks I'll be generating the embeddings okay embeddings means the vector okay that Vector I'll be combined together and I will be build one semantic index okay in the vector DB then it will be creating one uh like system called knowledge base okay this is nothing but our Pine con Vector history you can talk about now I'll be go going to the front end part so here actually user will give some question okay that question first of all I need to like convert to the query embedding that query embedding I will be sending to the knowledge base knowledge base will give me some rank result that rank results I'll be sending to my Lama 2 model my Lama 2 model will understand the question okay understand the like question so here I can I think draw one more line so whatever question user is asking first of all it will understand the query as well as the answer okay answer from your database that's that means the knowledge base so both it will do the processing and after that it will give you the correct response okay it will give you the uh actual actual response actual response okay so this is the complete idea so guys uh you can let me know whether this architecture part is clear or not everyone just give me a quick response in the chat so that I can go proceed how this entire architecture is working how we have we have created different different component right so now this this thing would be very much easy for us to implement the code right now because see what we usually do okay initially whenever I was in learning phase I also did the same thing let's say whenever I I got one projects I directly jump into the coding part okay instead of understanding the project architecture and all okay so it it was like very difficult me to complete the code because I don't know like after creating the data in where I need to go okay so that's why uh what I started actually I started creating these kinds of architecture so that see I have my architecture right now let's say I have completed this data data component part let's say I will again uh like do the coding tomorrow then I can see like I have completed this data like you can say integration part now I I I need to work on this extract data or content part then after that actually I need to work on this Tech chunks part okay so that's how I have the plan actually entire plan of my entire projects okay so that's why this like architecture creation is very much important what I feel like okay and don't need to worry about I will be also maintaining the GitHub and all like I'll be committing the code there so that you can also get the code from there everything I will show you okay great all right now let's try to understand what are the technology or what are the tech stack actually I'm going to use in this projects okay so let me just write here um I'll be taking a different color maybe I can take this color so take a stack take is Tech used so the first thing actually um as a programming language wise programming language I'll be using Python Programming okay now the second thing I'll be using something called A Lang chin okay langin as my um generative AI generative AI framework okay like uh in deep learning actually I think you know in DL actually we have different different framework let's say we have tensor flow we have tensor flow okay then we have something called P torch okay so we have then we have also something called MX net so these are the framework let's say we have different different in deep learning but whenever I'm talking about generative AI okay whenever I'm developing something in the field of generative AI I should use this langin or there is another framework you can use something called uh maybe I can name it as llama index Lama index okay so this is the alternative framework of the langen so whatever things actually you can do with the langen with the help of langen uh just a minute yeah so so whatever things actually you can do with the help of this langin the same thing you can also do with the help of L index okay and we have Au inte Lama index in our paid courses I think you can go to the syllabus and you can check it there okay we'll show llama index as well there all right all right now third thing maybe I can just uh just a minute okay so the third thing uh our uh front end front end or I can talk about our web app okay for the web app implementation I'll be using flask okay maybe I think you have already learned like how to use stream lit okay in your previous projects guys yes or no do you know how to integrate stream lead with our um application and all so that is why I have integrated flask okay I can um I just want to show you different different things actually you can integrate here all right now our model Wise llm Wise I'll be using meta Lama 2 all right and fifth vector be wise I'll be using pine cone okay so these are the tech stack actually I'll be using to implement this entire projects so far guys everything is clear you can let me know in the chat the take is stack and the architecture everything is clear here okay great all right now let's go to the our implementation okay now the first thing what I will do uh because you will be also doing the coding with me so it's better to use my GitHub maybe because from my GitHub actually you can get the code I think so what I will do first of all I will be creating one repository so let me create one repository at at the very first so here I'll be creating one repository so I'll just name it as end to end end to end medical uh chatbot using Lama 2 so this is the name so let's make it as public repo and I will add rme file G ignore I'll be taking as Python and license you can take anything so let's take MIT license H then I will create the Repository okay so I'm sharing this link guys in the chat so you can Fork it and you can also get the code from here so this is the public repo everyone can access so you can Fork it you can for forkit either you can clone this repository so whatever code actually I'll be writing I'll be committing here all right now let's clone this repository so I'll just uh click on code and copy this link address and I will open my folder and here let me open my terminal so get clone and let's past the link and clone it now I'll just go inside the folder end to end medical chatbot using Lama 2 now I'm inser my folder now let's open my vs code here so if you have pyam or any other code editor you can use it feel free to use it no issue um guys can you confirm my vs code is visible to all of you can you see the text and all clearly you can let me know okay so the first thing what I need to do I'll be creating one virtual environment okay so let's create one virtual environment uh yes yes uh we'll be doing on CPU okay that is why and yesterday I told you to download one particular model guys it's around 4GB I think you remember uh yeah see uh the same thing we can do it on the neural lab as well okay so you can also open up your neural lab and you can also do it there but the thing is like there actually I need to upload my model and it will take time okay it will take time to upload my model there so I will show you how to do it how to set up the environment here as well so let me open my neural lab because it's around 4GB model so if I want to like upload there so it will take time so that's why I'm showing on on local machine so start my lab so from here actually what you can do you can uh launch up this one python so this is my medical chat Bo so here also you will get the same environment as as your V code let me show you see all right okay but I have the model in my local machine I already downloaded but if I want to upload it it will take time so it's better to use my uh this vs code okay so now let me create the environment so just write the command cond create hypen in um I'll just name the environment as uh medical or I can just write M chatbot that means medical chatbot it's very EAS just open up your terminal and just write code space dot okay this is the command to open the uh vs code okay yeah and now let's uh take the python version equal to 3.8 hyen y so everyone you should use Python version 3.8 okay no you don't need to use uh like less than 3.8 otherwise you might face some issue okay you can also take 3.9 it's fine but I'll be using 3.8 this specific version also just let me mention the command in my rme file so here step to run steps to run the project so the first thing what I need to do I need to create one so I can just write this line I just need to create my environment now let me just quickly create it you can use it okay you can use it it's up to you what particular version you will be using it's up to you personally I like python 3.8 because it supports like B uh guys am I audible now okay uh sorry there was a small power cut from my side extremely sorry for that okay thank you uh yes uh okay see uh first of all you need to create one environment okay so this is the command you need to execute uh this is the command you need to execute just Conta create hypen in then your uh name of the environment then use Python 3 uh 3.8 okay and then create the environment then I just need to activate the environment okay so this is the command so just copy and paste it now it has been activated so let me also uh give the command here okay so environment creation is done now I need to install the requirements okay some of the requirements I need for this project so let's install the requirements so here I'll be creating one file called requirement. txt okay and now let's mention uh the requirements so the first requirement I need here uh something called C transform forer I'll tell you why this C Transformer is required um so the first thing I need something called C Transformer okay and I will be using this specific version of this C Transformer so you can uh use any of the version but I'll be using this particular version because I also want to show you like whenever you are creating any kinds of projects okay you also need to specify the version of the library you are using let's say this project you are sharing after let's say one year okay so what will happen at the Times uh some Library changes would be happen Okay and some of the functionality would be removed some of the functionality would be replicated so it's better to use a specific version always okay so that is why you can use specific version let's say if I search the C Transformer on Google C Transformer Pi so you will see different different uh version of the C Transformer Library so release story now see guys different different and this is the current one 0.227 C Transformers that means see the model actually I'm going to use it's a quantized model because we'll be running on CPU so that is why uh we need this C Transformer library to load the quantized model got it I think yesterday you saw like we are using something called Lama CPP library right but here we are using Lang chain and if you want to use Lang chain so you need to use the C Transformer Library then the second Library I need sentence Transformer okay because I want to download this uh model from the hugging face itself uh uh like which model I'll be downloading from huging face itself because here I need one embedding model because as the architecture I showed you here we'll be generating embedding okay we'll be generating embedding of our text SS and to generate this embedding we need one embedding model okay so we'll be using one free embedding model uh guys just a minute just a minute okay uh now I think my network is fine okay great okay fine so that is why actually uh for this embedding okay for this embedding generation actually I need one embedding model okay and that particular model I'll be downloading from the h face itself okay so that is why I need this seat uh Transformer sorry sentence Transformer Library got it thank you now let's uh see our third requirement actually I'll be using uh third actually I need to use uh this pine cone client because I want to integrate pine cone database okay Pine con Vector DB so that's why this pine cone client is needed then as I told you I'll be also using something called Lang chain so this is the Lang chain and and I also need flask to create my front end okay so these are the prerequisite I need as of now if I need anything else I'll add later on okay I'll add later on now just let me install them quickly so before that what I can do I can just quickly commit the changes in my GitHub so that actually you can also get the code from here so requirements added so it's already added let me check it so if I refresh yeah guys see already requirements has been added so you can you can just refresh the page of my GitHub and you can open up this txt file and you can copy paste the code uh yeah we'll be also adding Docker uh cic dependra okay this thing we have already added in our paid courses and projects and all okay we'll show that how we can do the deployment yes okay now let's install the requirements so I'll just write P install hypen R uh requirement. txt so it will take some time to install the requirements let's wait so in between what I can do I can write the command here P install ienr requirement. txt so guys are you doing with me this project implementation how many of you are doing with me you can let me know in the chat so far everything is fine everything is running okay okay great let me take some comments uh can we use Docker here cicd I already answered that okay now quid is great uh is it NE Neary to mention the version in the requirements uh yes I feel like it is necessary let's say you are sharing this code or let's say you are executing this code after one year so in that one year duration what might happen actually these are the library might upgrade right some of the let's say functionality would be deprecated now let's say if you're not mentioning the version specific version so what will happen actually it will install the current version okay it will install the current version andbody is installing the current version that means the upgraded version some of the functionality would be deprecated and this project will throw the error like this is not found here so that's why it's better to use the specific version let's say if you are executing this project after one year as well okay it will work fine please let me uh quickly ask did you not up with the generator projects we started last week you did not finish up uh McQ generator I think it was uh taken by San s maybe maybe he has completed the projects we been the deployment as well guys yes or no yeah McQ is already finished if didn't downloaded the llm model that still can I make this projects are still required to download you need to download ano okay without the model how you'll predict you can uh just make the download yesterday I think I shared the link and everything right or just let me also give you the model download link so here I will be creating one folder and just name it as model and here I'll just create one txt file I'll just write as instruction. txt and just let me give you the instruction so you need to download this particular model from this URL okay so this is the link uh let me visit the link and uh this is the name of the model if I do contrl F and crl V so this is the model you need to download it's around 3. 79 GB so let me just comit it as well so I'll just comit model instruction added so those you don't have the model you can download from this link okay I have already comitted the code in my GitHub you can check it out can I make this projects in desktop application and make it as uh MSI setup and run locally yes you can do it okay you can also create as a desktop application let's say you can use Tinker U framework to ment the desktop application and all okay I think my requirement installation is completed okay uh yes it is completed now here what I will do I'll just create one uh notebook so let's create one notebook um new file I'll just name it as trials uh Tri files. IP YB and let me select my kernel here so the environment I created uh it's m chatbot where this mchat bot just a minute yeah this one now let me test it if everything is fine or not I'll just write print okay uh yeah uh I will drop the GitHub link again so this is the GitHub link yeah some installation is going on let's wait for sometimes just a minute it's done now okay now everything is working fine yeah so everything is working fine guys how many of you have done guys you can let me know for me everything is working fine so far okay and uh in between I just want to tell you guys if you don't know uh we have launched one uh paid courses of our generative a you can explore this courses and we have added so many module here so basically we'll be covering like uh fine tuning part like how we can deploy it as a cicd okay how we we can integrate Docker even Lama index okay even we have introduced more open source large language model here like Google p to Falcon okay then uh we'll be discussing so many things here so you can go through this labus and if you're interested you can enroll for this course and here you will get uh lots of end to end projects implementation and it would be amazing implementation alog together all right now uh let's start the implementation of our notebook so just a minute so here I need to import some of the libraries first of all H okay now let's import some of the libraries so first thing actually I need some um I need promt templates so uh yes I think I can reduce the size it's not visible guys I think it's visible because I'm showing I think on top of my picture yeah all right now let's import some libraries so the first thing I need something called prom templates so from Lang Chen Lang Chen uh import promt template uh prompt prom template so as of now let's import I will discuss why I'm using these are the thing okay it would be clear now I need something called uh retrieval question answering uh class okay from Lang Chen so I'll just import it from Lang Chen uh dot chain import uh you have a class called retriever question answer okay just a minute I think I should move the camera here uh now I think the screen is visible okay fine then I also need to import uh the hugging face embedding so from Lang chain uh you have one function called embeddings and you need to import hugging P embedding hugging face embeddings all right then I also need uh pine cone so from langen it is already available in the langen so langen uh do Vector store UT uh I need pine cone you can also import Pine con from here then I need uh some more Library like directory loader and my uh PDF loader because I'm going to load my PDF here so let's import so I'll just write it from Lang chain uh here you have something called document loaders so from this actually I need to import uh Pi PDF Pi PDF loader as well as my directory loader okay now to uh convert my inter Corpus to chunks I need another uh class called recursive character text splitter okay so let's import so from langen uh do text splitter import recursive text uh character text splitter okay with the help of that we'll be creating the chunks then I also need prom template so from Lang chain do prompts I need this prompt templates okay it should be import import prom template then I need also uh C Transformer library because I'll be using quantized model okay so just write from Lang chain uh llms import C Transformer C Transformer yeah maybe everything I have imported now let me execute okay done now first of all let me move my data here so I'll create one folder here called data and here I'm going to move my data just a minute I think I already downloaded the data I'll also give you the data just a minute this is my data so let me just comment it dat add it okay now I think you can download the data from my GitHub okay I already uh push that PDF okay if I go to my GitHub yeah notebook is also available data is also available now you can get the data from here now I also need to move my model okay so I already downloaded the model just let me move it here this is the model okay fine what is the difference between from langin import fromom template and promt you can use any of them dendra okay I have showed multip like two things you can use any of them both are same okay now uh what I need to do I need to uh create my Pine con cluster okay because uh we'll be using pine cone Vector DB so let me just uh quickly show you yeah so just visit this pine website so let me just logging with my account all right so the first thing you need something called API key okay just click on the API key and uh just create a API key if you don't have any API key you can create from here so I already have one default API key I'll just copy this API key I'll just copy and I will open my vs code and here just let me write so pine cone Pine con uh API key so this is my API key don't uh use my API key guys I will be removing after the implementation so you can generate your API key then I need something called Pine con API environment so I'll just write pine cone pine cone API en EnV okay to get this Pine con API uh environment you need to create one index now let's create one index here so I'll go to the index and here I'll just click on create index you can give the index name so in this case I'll be give medical chatbot and uh Dimension uh it will ask for the dimension so what is the dimension Dimension means the like embedding model you'll be using it has some particular Dimension okay so the embedding model I'm going to use in this case let me show you the embedding model uh this embedding model is available on the hugging face so this is the name of the model guys all mini LM six uh L6 V2 okay so this is the embedding model I'll be using and this model returns uh this uh Dimension that means dimension of the vector of three uh 384 okay so this is the dimension let me just write here t 84 so this is the vector Dimension and I'll be keeping cosine Matrix and let's create our index now this is your environment API now I'll copy and here I paste it okay all set now let me execute yeah now first of all I need to load my data okay load this PDF from this folder so for this let's create one function so I'll just name it as extract extract data from the PDF so let me Define one function so I'll just name it as load PDF load uncore PDF so it will take the data directory then I'll be using this directory loader I think you remember we already imported this directory loader here directory loader okay with the help of this directory loader uh I load my data then I only want to load my PDF file okay so here you can set one parameter called Globe so here I only want to load my PDF file so start.pdf then you need to Define one uh class here loader class is equal to Pi PDF loader so with the help of this Pi PDF loader uh it should be Pi PDF yeah P PDF loader it will load load it so here is the P PDF loader by PDF loaded and this thing I will store in a variable I'll just name it as load up okay now once uh I will uh load my PDF uh so I need to call load functions so I'll just write uh loader do load and I will store these other data as a documents then I will return these documents H now let me commit the changes uh data loader added okay uh one thing so let me just stop it just a minute because uh here is my model as well so I can't uh directly push the model uh just a minute let me close the execution okay so in this dogit ignore I will uh add this model name yeah now it is fine now let me commit the changes okay so I'm getting an error because I terminated that uh commit operation that's why just a minute read add get commit should positive the POS okay uh so now let me open the code again so I'm having some issue with my GitHub just a minute yeah it's done so guys so far everything is fine for you yeah so whenever we'll be doing the deployment at that time I can get uh keep my model uh either in S3 bucket either in this one uh you can also use uh Google uh like bucket okay every anywhere you can store it no issue with that okay now let me execute them H done now what I need to do I need to extract my data so I'll uh I need to load my data so I'll call this function load PDF and here I'll give my data path so here is my data present and this variable I will call as my extracted extracted data now let's load it modle not found P PDF okay so what I can do I can install Pi PDF by PDF this is the modu P install no import I have imported but it is the dependency okay if you want to use this PDF loader you need this P PDF package that is why now I think it should work just let me restart my kernel h huh now it should work see now it is working now it is loading the data so you can also keep multiple PDF here uh it will also work let's say you have 10 different book you can keep it here and guys uh all the resources has been updated in the dashboard you can visit the dashboard yesterday whatever things actually I discussed everything has been updated here so this is the dashboard and here all the videos and materials has been updated so you can go through it now I think it's done yeah it's done now you can see the data see this is uh loaded as a document now let me comment out h okay now uh guys are you able to load the data yes or no is it working okay great now we have created this uh um extract data from the PDF now what I need to do now let's go back to my architecture so this thing we have done now what I need to do I need to uh create this one uh chunks okay chunks implement because I need to convert my Corpus to chunks T chunks okay so that's why now let's write this component so for this what you can do um let me just comment the name yeah so I can name it as uh split or create a text chunks create text trunks so here I will Define another function called def text splitter or text chunks you can name anything so let's name it as text split so this will take your extracted data because the data you have extracted that is your Corpus okay it will take and it will uh create a chunks so extracted data now here I'll call this recursive text splitter this function okay with the help help of that I'll be uh creating the Chun so here I need to like pass two parameter I think remember one is my Chang size one is my chunk uh underscore size okay so you can give any chunk size here so let's define as 500 I saw like people starting with 500 and chunk overlap chunk uncore overlap so chunk overlap I will be giving let's say 20 okay so this is the starting point you can give so I hope this part is clear what is Chunks size and what is CH overlap because I already discussed on my board here okay what is the chunks and what is the chunks of lab okay all right now let's uh store this thing in a variable I'll just name it as text uh splitter okay now after that what I need to do I need to split it so again I will just uh call my text splitter and uh here you have one parameter yes you can you can put multiple data it will also work okay I have only one PDF that's why I kept it here now split documents okay now here it will take your extracted data now this thing I will store so I'll just name it as textor chunks then after that I will return this Tech chunks Tech chunks okay so this is going to be my function all right now let's apply this function I'll call this function and here uh I will pass my extracted text okay I'm getting from from here and let me store it so I'll just call it as take chunks and if you want to uh see the length like how many chunks you got so you can also print it so length of my chunks okay now let's uh do it yeah so we got SE uh 7,020 chunks okay uh because we have a huge data and our Chun size is if you see 500 okay so what it is doing actually it is just counting ing the tokens as 500 okay and it is creating one particular chunks that's how it has created 7, and20 chunks okay 7,20 chunks if you want to see them maybe it would be big file see 720 CHS and all are documents clear guys now this 720 chunks actually I need to store in my Vector DB okay but for that I need to convert them to my Vector representation so we have completed till this point um till this point we have completed we have converted our Corpus to teex chunks now what I need to do I need to uh create another function here and that function will uh give me the vector embedding so let's comment here so download embedding model okay so download I can name this function Like That download huging Face embedding so this function will download the Hing embedding from the hangas itself so here embedding is equal to uh here I imported hugging face embedding and inside that you need to pass the model name you will be downloading so here is the model I already showed you so I'll just copy the name okay everything is fine then I will return this embedding okay it's done so uh see I already uh downloaded the model previously that's why it has been executed okay no I think I didn't call the function sorry sorry I didn't call the function maybe it will download again so let's download the model so I'll just uh call it as embedding and now let's download the model see guys now it is downloading so it will take some time uh because it is downloading from the HF itself now so far guys everything is fine are you able to execute see download is done are you able to download the model guys okay fine now uh I have my embedding model okay I have my embedding model you can also print this embedding object uh see guys this is the uh see the output Dimension it is also telling uh 384 I told you this is the uh like return uh like vector Dimension and uh this is the model name okay this is the model name okay great now what I need to do so let's just uh do it quickly because I think you got the concept what I I'm doing exactly yeah now I have downloaded by embedding model now let's test this embedding model okay now let's test this one uh whether it is uh giving me the embedding model or not embedding that means embedding on not so this is the code so here here what I'm doing I'm just calling this embedding objects and here there is a parameter called embed query now here I'm just giving one uh test word okay that means T sentence I'm giving hello word okay now if I execute this one see it will return return 384 and this is nothing but this is the vector representation of hello word clear guys yes or no now with the help of this embedding model we are able to convert our text to embeddings that means vectors and what is the dimension of that Vector is 384 four okay and this is the vector that's how this Vector looks like clear can I get a confirmation quickly now this technique I will apply on top of my data okay the data actually I have extracted okay from my PDF then I will be storting them to my Vector DB all right now for this actually I will just copy paste the code from your previous session because you already completed pine cone code like how to initialize the pine cone and all so this is the code we usually initialize our pine cone pine cone client see guys okay so here you just need to give uh this one uh your Pine con API key and pine con API environment which I have already initialized I think you remember here I have already initialized okay now here you need to give the index name in this case what is my index name I think remember we created one index let me show you this is the index name medical chatbot I'll copy the name and here I will give the name okay make sure you are giving your own index name okay don't try to use my index name if you haven't created this one all right then once it is done I'll call my Pine con and from text here you need to give your extracted text okay that means the chunks you have created and you also need to provide your embedding model okay and you also need to give the index name so what this Pine con will do it will take all your uh chunks as well as your embedding model as well as the index name okay it will take all together then what it will do it will apply the embedding model on top of the data you have it will convert that data to embeddings then it will automatically store that Vector to your Pine con that means this index the index the cluster you have created on the pine con okay now let me show you so let me execute this code not able to see the code sir please uh okay now I think you can see the code let me just see once maybe I can just a minute yeah now I think it is visible I can move my screen here just a minute H see now this is uh going on so it is converting my text to numbers okay and it is storing to my Vector DB now if I go to my Vector DB now if I refresh okay refresh the page here now you will see it will store the vector here you can also see the vector this is the beauty of this pine cone even I personally like see this is the vector okay this is the vector and this is this is the text actually it has converted the vector now how many Vector it has stored as of now it has VOR stored 800 Vector okay and how many like uh chunks we have guys here I think you remember how many chunks we have we have 7,020 chunks so it will uh create 7,020 vector and it will store there so you need to wait for some times for all the uh Vector U like conversion so again I will come here see uh it has been 1,536 no no no uh not full book it's just storing now see still execution is going on so it is storing like one by one one by one one by one okay that's how so it will restore till 720 because 720 chunks you have totally yeah each chunks corresponding to each Vector counts you can you are right now see uh 1,900 2, uh 240 so I need to wait for some times because it will store otherwise I can't execute so let's take some query guys you can ask me some query in the chat in between okay it's updating for you also okay great uh is there any alternative to Pine con uh to save Vector locally yes you can use chroma DB just SP you can use chroma DB uh otherwise there is another Vector DB called f okay this is from Facebook you can use as a locally and if you want to uh store data on the remote so you can use pine con either wave yet there is another Vector DB called wave yet you can also use radius so we have already showed uh integrated in our paid courses there will show but personally I prefer this Pine con because see here uh this is the beautification actually you can see the vector you can see the score as well see this is the semantic score like uh how much uh this uh Vector is similar to this Vector got it what is autogen autogen means I can't see any autogen here uh we can check different Vector database yes you can check maybe uh chroma DB has been discussed you can also integrate chroma DB Imran 3,936 as of now what is the difference between single and single agent and multi agent like uh what kinds of agent you are talking about because agent can be like many because uh in langin actually we have Al agent agent why we use let's say you don't have any um like the prompt you have asked this data is not available okay with the help of agent actually you can uh use some SAR API and you can search over internet 4,800 and 32 as of now is high St High stack uh I didn't use high stack I can't say whether it's similar to langen or not but I used Lama index maybe raish because these are some more popular tool okay langin lamex people are using broadly okay so let me see the vector count okay 2,000 Moree what about you guys how much okay it would be done in some time yeah uh 6,34 and tomorrow guys we'll be doing the modular coding and the web app implementation so please join the session tomorrow so tomorrow we'll be completing these projects okay so today actually I'm showing you notebook experiment uh because many of you have familiar with notebook experiment okay so that's why now tomorrow I will try to like convert this notebook to the modular coding okay 720 it's done guys it's done great see it's done all right now what I need to do guys I need to um you can also perform some uh okay so uh now you can also do some centic starts okay now we have stored our Vector okay I already told you we'll be building one centic index here see we have built our knowledge base now uh we have also our centic index now we can see our rank results now if you give any query so it will give you some rank results okay now let's test this one so let's say here I'm giving one uh here I'm giving one question what is allergies okay now if you open this book okay if you open this book see allergies has been also written in this book let me show you now if I crl F and contrl V maybe allergy allergy yes it is somewhere see it has also written about allergies okay see allergy like what is is allergy and all so one question I'm just giving what is allergies here now it is searing your knowledge base okay and it will give you top uh similar three result okay top similar three results and that results actually I'm just printing let me show you see this is the top uh three results but it's not readable because I told you if you see that U architecture it will give you rank results but it's not readable okay the answer we are looking for it should be need clear it should be correct answer and to get this response actually I will take the help from my llm okay I will give this rank results to my llm and I will tell it this is my question and this is my answer this three top answer now give me the correct answer with respect to that okay now let's generate our correct answer with the help of our llm so for this uh this is the code you need to write first of all I will Define one prom template okay because you know what is prom template you are just telling your llm like you need to do this thing so if uh use the following piece of information to answer the question if you don't know the answer just say that you don't know don't try to make up the answer okay so I just want the authentic answer from my LM that's why I'm giving the prompt so user will give the uh context and question and it should reply the answer okay so this is the template I have written you can write any kinds of promp template it's up to you what is the distance is used perform similarity cosine Matrix justel now this is my prompt now here I'll be creating the prompt template okay you already know what is prompt template even I yesterday I was also discussing I'll be creating this prompt template this prompt template I have added here and I created The Prompt and this thing I have created as a chain type arguments because I will be using chain okay question uh uh like retable question answering chain okay that's why now let's load my llama model so here is my model in the model folder as you can see so here I'm just giving the path and I'm just loading the L model with the help of this C Transformer library and this is going to be my llm now let's execute done now what I will do I will create my question answering object now see retrieval question answer I think you know what is Ral question answer from langen and here I'm giving my llm as well as my prompt template as you can see we have implemented my prompt template and some of the arguments that means dock string doers what is this docer doers is nothing but your knowledge base which is nothing but my Vector DB U representation okay and here I'm just giving uh I'm just telling it will give you two relevant answer and from this two relevant answer you should give me the correct response okay now this is my question answer object now let's finally ask some question so this is one for loop I have written so it will take the input from the user then it will ask the question to my llm and llm will give me the response now let me execute and show you see this is the input so I'll just ask what is let me show you which question I'm I'll be asking so contrl F I'll be asking something related acne maybe acne is there see acne okay so acne is a screen problem I think you know see this is the acne so let's ask something related to the acne like what is acne and all about so I'll just say what is acne now let's ask this question so again U response time would be a little bit High because we are using U um like model on our CPU machine that's why and again I am doing live streaming so for me it would be a little bit late okay but if I stop the streaming so it would be quickly and tomorrow we'll be integrating the uh like front end part and you will see the beautification of this projects okay it would be amazing completely so for this live streaming actually I'm uh having some uh slow time maybe so anyone running is it running for you okay see done now this is the response guys I got acne is a common skin disease character ized by pimples on the face chest and back that occurs when the uh pores of the skin becomes clothed with the oil dead skin cells and bacteria is it correct is it correct response guys just give me give me a quick yes in the chat how is the project you can ask any kinds of question guys any kinds of question from this book just go through the book get some idea what are the disease what are the med medicine you have okay and you can ask the question I'm not a doctor sir even I'm not a doctor but I have this bot right now I can ask any kind of question so how was the session guys Al together did you learn the entire concept like how we can integrate all the technology together and implement this kinds of projects no no fine tuning is a different friend benit fine tuning will show in our paid courses it available okay this is the existing model we are using with our custom data okay now let me stop the execution uh tomorrow I will show you the further part uh uh it is enough for today I think yeah and this code would be available in my GitHub the link I have shared with you let me share it again so I'll just comment the code after the session so you'll get from here so this is the GitHub link guys everyone you can yeah now let me take some question where did you get the data data I downloaded from the internet this book I downloaded okay data I've already shared and please and doer CD pipeline upcoming classes we'll be adding uh we have a projects in our paid courses dependra we'll show that how much data we can give uh terabyte you can give as many as data but uh you should have good memory condition okay if you are like very less memory then uh you can't load so so much data so guys uh let's start with our uh medical chatbot implementation so yesterday I was discussing the architecture and the uh notebook experiment part uh today actually I will show you how we can convert this entire things to modular coding even uh I will also show you like how we can uh create the web application and all using flas so it should be U totally amazing so make sure you are watching this live till the end okay guys so before starting with the session uh first of all I want to show you um your all of the resources has been updated in your dashboard so let me open my dashboard once um so guys here is the dashboard and uh if you see today is day 13 so till day 12 actually it uh it has updated already so all the resources all the like GitHub link everything has been updated here so you can check from your end and guys uh if I disconnect somehow so no need to worry about just stay here I will uh again reconnect okay I have backup all right so everyone is ready can I get a quick yes from everyone so that I can start with the implementation so just give me a yes in the chat okay thank you all right so uh let me open my uh project actually I created yesterday so this is my project guys even I have already updated the code in my GitHub as you can see uh this notebook I implemented yesterday so this is already updated here even the data is already available and model actually I can't upload in my GitHub because it's a huge model so what I did actually I just given the instruction okay so this is the instruction I have given like how to download this particular model from this URL okay so first thing what I will do uh I will try to upgrade this uh readme file once because let's say if you are referring this uh GitHub okay if you're referring this repository so how we can set up this projects and all okay first of all I will just write uh some STS in the rme file then I will try to start with our implementation okay so let me open my project with my vs code and uh what I will do uh I will also show you uh on the neural lab as well because neural lab I was trying to upload the model but it was taking time uh for me okay because this model is hug so I'll will also show you side by side implementation how we can do it so what you just need to do here you just need to upload the model here in the model folder okay and all the steps will remain same all right so I have this model in my local machine so this is the model now what I will do first of all let me open my uh vs code here okay so everyone you can open up your vs code or you can also do it on the neural lab and if you don't have the code you just clone from my repository once okay so I hope my screen is visible properly everyone just confirm in the chat or should I zoom a little bit maybe it's fine okay just a minute uh okay so first of all let me write down the steps what you need to do to uh execute this project so I can remove these are the steps maybe yeah so the first thing you need to clone this particular repository so let me just add this part so first of all you need to clone the repository okay so here I have just given like till github.com so what you need to do you need to just clone this particular repository the repository I have created Okay click on the code and click on this link address then uh the second thing you just need to create one virtual environment so we have already created the environment and the name of the environment was here uh this is the name so medical chat boo so I just written M chatbot okay I'll copy this name and here I'll just upgrade okay and I was using python 3.8 version okay so when the projects will be available uh in Inon uh this project is already available okay in my GitHub Raven even Inon website it is also available you can check it out and today we'll be completing this project implementation okay entirely because yesterday I was doing the notebook exper experiment only then I need to active by uh environment here so this is the name after that okay internship project you are talking about so internship project should be updated also okay raan just uh check the internship portal it would be updated then uh I just need to install the requirements actually so yesterday I showed you I was installing some of the requirements so this is the command to install the requirements all right then what we did exactly we just created Pine con uh API key I think you remember so let me open my Pine con once so pinec con. let me loging with my account so I'm going to use the same index because we have already stored our data yesterday okay so I'll be using the same index only so this is my index guys medical chatbot I created so here I think you remember we collected the API Keys as well as our environment okay this Pine con environment so both I need to add otherwise this project won't be working so that thing I will also mention in the rme file so here I'm just telling create aemv file I will tell you what is this EnV file file okay how we'll be managing this uh secret key and all okay so this thing you need to pass in the environment file then it will work all right and the last thing I downloaded my model so this is the step to download my model so you just need to download this particular model from this URL and need to Pro uh like keep that model in the model folder okay for us actually we already kept the model all right so these are the steps actually we uh completed yesterday and rest of the thing actually I will show you today now let me commit the changes okay done now if I go to my GitHub and refresh the page yeah it is updated now let me share the link with you again so here's the link all right so the first thing actually uh what I need to do I need to create my project template because yesterday I completed the notebook experiment okay so most of the thing I will copy from my notebook only so this is my notebook so most of the code actually I'll be copy pasting from here and the thing is like I just need to uh create a modular coding pipeline okay so that is the main thing here like how we can organize our code so for this uh instead of creating the folder manually uh so what I will do I will just create a template file here so that template file I will just write some of the logic like what are the folders I need and how it would be created with the help of python then if I execute that particular template file it will automatically generate the folder for me okay now let's say if I want to create the folders and file now what I need to do I need to manually create it let's say I want a file I will click here again I will name the file then I need a folder here I will again click here then I will just uh name the folder name that's how I will be creating manually but let's see if you're doing the uh like the same projects again and again okay similar kinds of projects what you need to do again you need to create those are the files manually so instead of that what I will do I'll create one template file and that should be one time effort okay and I will I will just write all the logic there like how we can create I will be creating this folder structure and all so every time if you execute that file so it will automatically create the folder structure for you okay so for this let's create this file and I will name it as template template. pipe okay so here first of all let's let's import some of the library so I need the operating system then I also need something called path from path Le I'll tell you why this path leave is required just let me import it first of all so uh it should be everything from so from path Le import path then I also need something called login okay so the first thing I just need to create one logging string here okay why I need to create a loging string so let's say whenever you will execute that template. Pi file so it will also show you the log on the terminal like whether this folder has been created or not okay if it is if it is created now why it is created it will also show you the location as well okay so to log these are the information I need this login string okay I hope you already know what is logging in Python guys yes or no if you don't you can search on Google like logging in Python so logging is a inbuilt uh modu inside python so maybe you already worked with login so this is the documentation of login guys all right so if you visit the documentation so you will see these kinds of loging string people are writing okay this is the loging string we usually follow so here we usually mention first of all our logging level okay so here the log level is like information uh like level log so basically I just want to save my information like why this folder is creating what is the path so these are the information actually so that's why here I have given login. info okay and you just need to uh mention also the format format of the loging like what particular message actually it will show you so the first thing I'm just saving my asky time that means the current time stamp let's say I'm executing the code at this time so it will save that particular time with respect to the the message actually you will be writing okay so this is the loging string so it would be clear whenever I'll execute the code and I'll I'll tell you okay how this log would be saved now here I need some list of the file okay so let's create a variable and I will just name it as list of file list of files is equal to so let's make it as a list now here first of all I need uh One Source folder okay so I'll just name it as SRC so inside SRC I'll creating one Constructor so underscore uncore unit I'll tell you why this underscore uncore init _ Pi is needed as of now just uh create the folder with me and then I will be creating another uh like file called helper. Pi in the same folder so I'll copy the same thing again and it should be helper. Pi then again I will be creating another file inside that and I'll just name it as prompt prompt. Pi okay then I also need one uh file called envv then I also need uh something called setup. Pi because requirements we already created I don't need it so I'll just write setup.py then I also need something called U one resource folder because I'm going to keep this file inside a folder called resource so let's name it research slash and here I'm going to create that trial. ipnb all right then I also need something called app.py then uh I need another file called store index store uncore index. Pi I'll tell you why this IND store underscore index is required okay I'll tell you now I think most of the things I have created okay so I will also integrate the flask so for this actually you need one folder called Static uh static and another folder you need something called template. Pi sorry templates so inside templates I will be creating another file and I will just name it as uh chat. HTML yeah so these are the folders and file I need as of now if I need it so I'll uh create uh later on okay so as of now let's create these are the things only now I have already listed down the files and folder actually I'll be creating here okay now how to create it okay how to create it so for this we just need to write some of the logic here so I'll be using simple python code only to create this folder structure and all so the first thing I'll be looping through this list okay so I'll just write one for Loop so for file uh path in list of the file that means this list actually I'm iterating through then what I need to do first of all uh the file path actually I'm having so first of all I need to convert them to path I need to convert them to path okay why I'm converting them uh like to path because if you see here the operating system actually currently I'm using it's Windows okay Windows machine I'm using but here if you see I'm using forward slash so I think you already know in Windows machine actually we usually use something called backward slash yes or no guys backward slash if you see any kinds of Windows path it would be backward slash instead of forward slash okay but here we are using something called forward slash okay so forward slash we usually use uh in the Linux operating system and Mac operating system okay but in Windows we usually use backwards slash so that is why to uh prevent this kinds of issue okay I need this path Library okay now how this path will be working let me show you let me give one demo so here I will activate my python so let's import W uh maybe I can import this path so from path leap import path so let's define One path so I'll just write path equal to so here I can give let's say test uh let's I will give uh forward slash here and here I will give U app. pi so let's say this is my path now what I will do I will just give this path in my path class okay if I give it now see what will happen just see that it will automatically detect it's a Windows path okay first of all it will detect my uh operating system I I'm using okay with respect to that it will convert that path okay so this is the advantage to use this path class okay so what will happen now if you execute this code in the Linux operating system as well Mac operating system as well everywhere it will work because with with the help of this path class it will first of all detect the operating system then it will convert that part with respect to the operating system we are using okay so that's why we are using this path from the path Li itself all right now here I got my file path again so I'll just store it okay now here what I need to do I need to separate out my folders and file because as you can see here this is my folders okay and this is my files so I need to separate them because as you can see here I can't directly create my folders and file okay all together so what I need to do I need to separate my folders and I need to separate my files okay in a two variable then I will be creating that so for this what you can do so first of all I will store my file directory then I will instore my file name okay so there is a uh method inside operating system package so just write OS do path uh os. path. split okay so this is the method you can use and inside that you just need to give the file path okay now what will happen let me show you so let's say this is my path I have so I will import o again now what I will just do I'll just write uh first of all uh yeah w dot path do split okay and here I will give my path so let's say this is my path and now see what will happen see it is returning the folder separate and it is returning the file separate okay now what I can do I can create a two variables here you can see I can I have created two variables so the first variable will contain the folder name and the second variable will contain the file name okay so this is the logic actually I'm just trying to write all right so once I got my uh file directory and my file name now what I need to do okay I just need to create my file directory at the very first so for this I can write one logic so I'll just write if file directory if file directory is not empty okay is not empty so I can write like that is not empty so what I need to do I'll be creating the uh file directory so I'll just write w. make D okay so this is the method actually you can use to create any kinds of directory okay and here I'll just give my file directory name I want to create then after that I need to give one parameter called exist okay is equal to true so what will happen if this file is already available if this folder is already available in your computer so it won't be creating okay otherwise it will create so with the help of this parameter you can control this thing okay now if you're not giving it so what will happen it will replace that particular folder let's say in the particular folder you have some files okay again it will replace that so you need to recreate it again so that is why you need to give this method okay so once it is done I also need to log the information I'll just write login doino and here I can give one log so creating creating F uh directory creating directory uh first of all I'll give the folder name uh folder name so this is my file directory and after that for the folder for the uh for the file and here I will give my file name so this is my file name okay that's it now once my folder is uh done okay let's say I have created my folder now what I need to do I also need to create the file inside the folder okay so for this I need to write another logic so here uh what I can do yeah I'll again write one if statement if maybe intention is not correct just a minute yeah so if uh not o do path uh do exist this file path okay this file path that means the file path actually I'm having so if it is doesn't exist okay in my directory so what I need to do okay I need to create it but instead of using one particular logic I'll be using another particular logic I will also check the size of the file so what I can do I can write another logic here so W uh dot path dot uh there is a parameter you will get called G size if you want to check uh any particular size of any any file so you can use this method actually get size now inside get size you need to give the file name file name and that uh if it is not let's say uh if it is not let's say uh equal equal zero that means if this file is not empty so what I need to do I need to create that particular file so for this I'll just use with open with open and here I will give my file path okay and here I just need to create it so that's why I need to open with write mode okay once it is done I'll just do the pass operation here because I'm not doing anything I'm just only creating that particular file here okay then I also need to log the information so what I can do here I I'll just write login login. info login. info and here I will give the log so I can just write creating creating empty file and let's give the file name here file path yeah and if it is already exist so what I will do I'll just write else so I'll just give the log message here so login do info um here I can give uh this file file name is already um created okay so this is the message I think I can give yeah so this is the simple I have written so guys this code is understandable for you yes or no give me a confirmation in the chat are you getting this code how I have written it's a simple python code only yes okay great now let's execute this particular template file and see what happens okay now if you see left hand side I I don't have these are the files and folder okay now once I will execute this template. Pi let's see what will happen so I'll open my terminal I'll exit from my python uh first of all let me uh activate my environment I'll just write cond activate M chatbot now let's execute this template. Pi so template. Pi see see the magic guys automatically all the files and folder would be created left hand side just see left hand side and see the log guys it is saving my Tim stamp the current time stamp I'm executing the code as well as the date and it is giving you the message like directory created SRC for the file of uncore uh init.py again creating an empty file inside SRC uncore init.py okay that's how all the file and folder has been created and see left hand side guys we are able to create our folder structure uh in just one shot okay now let's see you need some other files and folder okay in future so what you need to do you just need to give the list here let's say I need something called test. Pi I'll just give test. Pi here I'll save this one again if I execute the same template. Pi uh okay so it is telling this system cannot find the specific Pi okay I'm getting one error let me see test. Pi has been cre or not okay static it is throwing the error okay static should not be empty so here I can give uh uh CSS or I can give U just dogit ignore dogit keep let me remove this static file here now let me execute it again okay it's throwing error just a minute um file name St size not o. get software line five get size return file not found the system cannot find the file specified underscore uncore unit. Pi maybe my logic is correct okay now it's done I think yeah now if you see uh my static folder has been also created now here if I uh just uncomment this test. PI right now and if I again execute it see guys it has created okay now see you can create as much as file and folder okay it's up to you okay so in this case I don't need this test. Pi I'll just remove it and here I will also remove the test.py from here all right so in future let's say if you're developing any kinds of projects instead of creating the folders and file manually what you can do you can create this particular template file and here just write the logic okay it would be one time effort but this file you can use it okay in your every projects just uh execute this particular file and it will automatically create the folder structure for you all right now let me move that trials file in my resarch folder so I'll just move it I'll just cut it in my resarch folder yeah uh everything is done now let me just comment the changes in my GitHub quickly folder structure add it so guys so far everything is clear you can let me know in the chat like how we have created the folder instuction and all so far everything is clear okay okay fine now we are done with our uh project template creation so now second thing I just need to write my setup. Pi file okay why I needed setup. Pi file because as you can see now we have created so many file inside the folder okay now let's say I want to import something from this particular file let's say help .p I have written something now let's say I want to import that thing inside my app.py okay so what I need to do I need to write from SRC do helper import something okay so if you want to do this kinds of operation then you need to set up this particular SRC file as my local package I think you already familiar with what is local package okay in Python let's say whenever you install any kinds of like package from the piy website okay it is already hosted on the pii website but uh it can be also done we can also create our local package as well okay let's say here if I do uh pep list pip list so it will list down all of the package actually I have installed in this projects okay but here if you see this SRC is missing okay SRC is missing so if I want to import something from the SRC then it will throw error it it will tell SRC is not found okay so to prevent these kinds of error what I need to do I need to create this setup. Pi file and I need to set up this SRC folder as my local package no this is not a preinstalled this thing I have installed from the requirement. txt I think you remember Iman okay because this is my new created environment and inside the environment I install all the package actually I need for this project all right but here if you see SRC is missing SRC is missing now let's say if I'm writing something inside help .p let's say if I Define anything let's say import OS uh let's say I will write one function here uh let let's say main function I have written and I'll just doing some pass operation now let's say I want to import this main method inside my app. Pi now what I need to do okay what I need to do I just need to import it first of all so from SRC so SRC is my folder SRC do help part okay then import main import main getting my point so if I want to import like that now see this SRC is not present inside my environment okay it's not present as a package envir environment so it will throw error like SRC module is not found got it but if you want to install this SRC as your local package and if you want to keep it inside your environment okay just to prevent the error you just need to write this setup. Pi so this thing actually we usually use in our end to end implementation always because we write a modular coding here all right so now let's write our uh setup. Pi so I'll open the setup do pi and this code is very common so I already written this code let me show you setup. Pi code uh see guys here you just need to use one particular package called setup tools okay setup tools is a prebuilt package inside python from here you need to import two particular things one is like find packages and other is like setup now you need to create one setup object here so see here I have created the setup objects here you can give your project name so in this case I creating Genera VI projects okay that's why I given generative projects you can also give something called medical chatboard let's give medical chatboard medical chatboard all right you can also specify the version okay version of the package you want to create so let's say this is the initial phase I'm implementing the project so that's why the version I have used 0.0.0 okay now here you can give the author name so let's say I here I have given my name you can also give your name so let me give my full full name here so I'll just write B ah Bui okay this is my name you can also give the author email address let's say here I have given my email address you can also give your email address now here you need to call this find packages this uh method so what it will do it will look for this Constructor file in each and every folder and where it will get this particular file that folder would be considered as my local package okay so this is the idea to create our local package okay so that's why we created this uncore init.py because I want to make this SRC folder as my local package and how it will get to know with the help of this find package method okay so this find package method it will find everywhere in every folder and it will look for this particular uncore uncore dop file wherever it is present it will create that particular folder as my local package clear guys this concept is clear yes or no you can let me know in the chat if yes just write clear in the chat so that I can get to know okay great now how to install the setup.py how to install the setup.py for this I will be utilizing my requirement. txt file okay I'll be utilizing my requirement. txt file so here I'll just write one particular line I'll just write hypen space Sorry hypen space dot okay hyen eace dot if you just write this particular line automatically whenever you will be set uping that requirement text it will look for that setup.py file okay then it will open that setup. Pi file then it will install everything got it so whenever it will install everything that means you have done the installation of the local package now let me show you so I'll open my terminal again I'll clear it now here I'll just write python sorry uh peep install peep install hypen R requirement. txt okay I already added that uh hypen eace dot uh yes hypen e space dot in my requirements now it will work see now setup. Pi has been installed now if you see there would be a folder automatically created called medical cho. EG info okay if it is generating this particular folder that means you are done with the installation okay and inside that you will have some of the metadata okay no need to worry about some metadata related of your package you have installed let's say these are the package you have installed okay as a local folder so these are the information it will save here all right now if I show you peep list now if I do peep list operation in my terminal that means I want to see what particular uh Library I have now here you will see SRC would be present I can show you SRC SRC would be present setup Tool uh not SRC it would be medical chatboard the name of the package I have installed called medical chatbot in the inside the medical chatbot I have this SRC folder right now okay see this medical chatbot was not present and see this package is coming from my local machine itself okay so that's why this is needed now if I want to import something from my helper I can easily do it without any kinds of error all right now let me uh push the changes in my GitHub but before that I will remove these are the line so I'll just write uh setup file added and I'll comp it so you can refresh my GitHub and you can go get the code from there now same thing you can do it on the numeral app so let me copy this template file and I will go to the Neal app and here I will create one uh template file template. Pi file let me Zoom a little bit now I'll paste the code here save now if I execute the template. P file here so python template. Pi file see it has automatically created okay the same thing you can perform on the Neal lab okay only you just need to upload the model here upload the model that thing you need to do all right now we have generated our folders and file and uh everything is working fine so far now let's add first of all our environment variable okay so what are the secret key and secret uh API will be using so everything I'll be mentioning here so in this case guys what I need I think you remember so I need something called my pine cone API key the first thing I need my Pine con API key okay and the second thing I need something called Pine con API environment so where I will get it I already collected yesterday I think you remember so I'll just open my notebook and here I think I already mentioned yeah so this is my API key I'll just copy and uh I'll open my environment variable uh environment file and here I will just paste it and I will also copy my API environment here I will paste it okay now what you can do you can remove it from here okay no need to show like to your user or let's say if you are uploading this thing on your GitHub account so just try to remove them from here okay otherwise people can also access your credential I'm just keeping it here just for the reference just to understand the things I'll just remove these are the uh index okay after the yeah same same yesterday key because I'm using the same same index same index from my Pine con okay that's why if you're creating any new index so you need to collect that particular keys and paste it here okay all right now see I have already added this EMV file okay I have already added this EMV file in my code but I already committed my code in my GitHub now can you see this EnV file in my GitHub is it present guys no see it will automatically ignored okay it will automatically ignore by the help of this dogit ignore file because if you open this dogit ignore file and here they have already written this kinds of EMV file would be automatically ignored okay let me show you so I think I can search here envv uh where is EnV crl F do EnV see guys Dov VNV EnV VNV these are the files and for would be automatically ignored during committing the code need our GitHub okay so that's why we use this method to create any kinds of secret uh credential okay another thing you can do you can open up your environment variable environment variable so it is already available inside your system now here you can click on the environment variable and here you can create a in uh variable key as well as the value you are using so both you can do it but this is the method actually people uh usually use nowadays okay instead of reading the uh configuration file file from our system itself okay yeah and to read this file I'll be using one particular Library okay so the library name is uh python. EnV let me just write um I think I already added this thing okay so there is a library called EnV dot e NV Pi Pi yeah so this is the package name I'll just copy and here I will mention inside my uh requirement file now let me install it again okay done now we have also added our confidential secret as well okay now what I need to do I'll be start implementing the component one by one right now so the first thing what I need need guys if I open my notebook I think you remember uh the first thing yesterday we did we first of all uh worked with our data injection part that means data component so I will copy the same function okay I'll just copy the same function and here I think we remember we created one helper Pi inside SRC I will open the SRC folder and here I will open this helper. pi and here I will just mention this particular function okay so most of the code I'll just copy paste from my notebook itself because we have already done the experiment and we saw everything is working fine now what is our task I just need to convert everything to the modular coding okay so this is the thing I'm just showing that's why yesterday I did The Notebook experiment and today I'm referring that particular notebook and I'm just writing the modular coding okay all right now I need this directory loader package and as well as this Pi PDF loader so I can copy from here only so directory and Pi PDF loader I'll copy this thing and here I will mention and let me select my environment I think it is already selected my medical Chat bar yeah done now tell me what is the second thing you need to add what is the second thing you need to add just open the notebook and try to see here the second thing I need to add my uh uh text splitter okay I think remember we are uh converting our conver like Corpus to chunks why I I was converting our Corpus to chunks because of the model input model input token limit limit okay so that's why I was creating this particular function okay so I'll copy this particular function as it is I'll open my helper. pi and here I'll mention it and again I need one particular Library recursive character text splitter again I will open my notebook and from here I will copy now guys tell me this method is easy for you are are you are you getting like confident to write the code how to write the modular coding after doing the notebook experiment yes or no because same code I'm just copy pasting from my notebook only and I'm just arranging my folder structure yes or no guys you can let me know in the chat great now going forward whenever you are implementing any kinds of projects as end to end the first thing create the project architecture create the project architecture then try to implement these are the component in your notebook at the very first then try to convert that notebook as the modular coding I'm doing all right now again let's open my uh trials. ipnb and see our third component okay so third component was nothing but uh downloading the model from the hugging face I will copy this function as it is and here I will mention it here I will mention it now what I need I need this hugging face embedding package so again I will open my trials. ipnb and from here I will copy this code copy this import and here I will paste it done now anything I need let me see after downloading embedding uh no everything is fine everything is fine now uh your Pine code Cod code will start okay that means you need to store your vector right now so this code I can write in a separate file I'll tell you how to organize this thing so first of all I showed you the helper function implementation okay so this uh this file should be my helper file yeah now I'll be using this helper file and I would I would be able to import this particular uh function one by one okay whenever I need it instead of writing again and again okay inside my component just follow the architecture and following the uh code okay one one by one okay great all right now let me show you uh how we can store the data again so so I'll I'll what I will do I'll just again remove this index from my pine cone let's instore our index again so what I will do uh I'll just remove this index so I'll just click here and I'll just delete this index you need to give the name so it's medical medical chatbot you can also load the existing index it is also possible but I'm showing because I have done the modular coding now I just want to test it whether everything is working fine or not whether it is able to create the index or not okay that is why I'm just creating this thing so now let me delete index now it would be deleted after sometimes yeah it has deleted all right now what I need to do I need to write uh the data uh that means my uh data push uh I mean uh Vector Pusher code okay that means I need to convert my uh Tes two vectors and I need to push them to my Vector DB that particular code I need to write so I'll be again referring the same notebook I think I yesterday I already wrote that code this is the code I was initializing my pine cone that then I was just sending my data to the Pine con okay so I'll be referring the same code so for this what I need to do uh I'll be using one particular file here called store index. Pi okay this file I'll be utilizing to push my Vector to the vector DB okay so here first of all what I need guys if I want to push my Vector to Vector DV first of all I need to load my PDF file from the folder itself so let me import so from SRC do help part import first of all I need what I need this load PDF okay this function so let's import load PDF okay after load PDF what I need I need this function text splitter so let's import text splitter then after that what I need I I need this download hugging face model okay so this one so I'll just also import hug download huging Face model okay then I also need to import something called uh pine cone so let me import so that's how you can import Pine con you can either import from Lang either import directly okay then I also need to import my load EnV package okay so I'll just write from from EnV from EnV import load EnV okay load. EnV because I want to read this particular file Dov file and here I have my credential okay primon credential and if you want to access these are the secret key you just need to take the help from this EMV package okay and this thing I have already installed here let me show you as a python. ENB I already installed here okay python. ENB so this is the package now let me open this one yeah now first of all I need to load my EMV file so that's how you can load uh so for this I also need something called operating system package so import OS now let me show you how it will read exactly so what I can do I can open this EnV file and I will copy the API key first of all and here I will restore it so equal to I'll just write OS do environment doget and here I need to give the key name okay the key name you are using inside the EMV file okay this is the key name okay now once you have loaded I will also load my second one which is nothing but my Pine con API environment I will copy and I will give the name here again I'll give the name here now let me print and let me show you whether it is able to read or not I'll just print first of all my Pine con API key as well as I'll also read my Pine con API environment now let me execute this particular file so I'll just write python store index uh. Pi it should work see guys uh this is my API and this is my en environment key got it how I'm reading it okay now I need to create again one index because I deleted my previous index what I will do again I will go to my pine cone and here I will uh first of all copy my key I'll copy my key and here I will paste it so this is my key I think this is the same key this is my key and I also need something called my environment so I'll again create one index so create index and here you can give the same name medical medical bot and dimension it's uh 384 I think you remember the model actually you are using sentence Transformer model uh the output dimension of the vector 3 uh 884 and I'm using cosine metric then I will create the index now this is my environment name I will copy and I'll paste it here which is nothing but gcp starter done okay now first of all what I need to do I need to load my PDF so let me load the PDF so here is the code I think I already written yeah this is the code I'll copy and here I'll paste first of all it will load the PDF and PDF is is present inside my data folder now after that I need to extract uh sorry I need to apply the text splitter that means I need to create a chunks so this is the code I'll copy and uh here I'll paste it okay after getting the chance I need to download the embedding so this is the code I'll copy and here I'll will paste it embedding download is also done now uh what I need to do I need to initialize my pine cone okay so this is the code I think remember how to initialize the pine cone it will take your Pine con API key which you are getting from the environment variable and this is your Pine con uh API environment okay we have initialize the pine cone and now how to store the data so this is the code okay I'll copy the same code from my notebook this is the code so so here I'm using pine con. from text here I'm giving my text chunks and also need to mention my index name so index name is my nothing but my medical chat Bo so I'll copy the index name this is the index name done now it will uh convert your data to embeddings and it will store to the pine cone okay maybe that's it yeah now let me execute this file and show you whether it is able to uh push my data or not so I'll execute this particular file I'll clear and I will execute this particular file python store index dop so again it will take some time because how many chks we have guys yesterday you saw remember anyone remember remember the Chang size how many Chang size we use uh pushed yesterday in our Pine con database uh yeah 7020 7020 right no no it's 7 not 700 7020 7,20 20 chunks we had okay okay okay great now it will take some time first of all it will uh load the data then it will create the chunks after after that uh it will uh convert everything to the embeddings then it will push to my Pine con let me see it has started or not let me refresh the page not started yet let's wait for some times in between I will take some queries guys if you have some query you can ask me anyone having any query you can ask me in between okay uh should start huh see it started guys okay now it has pushed 576 vectors can we use this same projects template for creating Finance related project as well yes right side you can use it no issue G push error where is G push Adder maybe this is your problem with your git AR is you can check it uh no wores I will push my code you can get from there okay Karan Karan sorry Karan uh uh you can also use this template for your Finance related project as well okay this is the common template you can use it as it is uh when we are creating medical B Medical book chatbot uh will it response to the normal message like hello and how are you uh yes it can answer maybe yeah it can answer because you are using the Preen llm now so yeah it will answer I'll show you and if you want you can also uh like fine tune that particular model as well it is also possible okay and uh in our paid courses we have already integrated guys if you don't know so this is our paid version of this gentic B course so in this syllabus we have added so many topics let's say if you want to learn how to F tune and all everything we have added here even Lama index then uh we we'll be also covering like some more Vector DB okay we have some more interesting project here so everything would be covered detail here okay so if you are interested you can enroll for the course let me see the progress okay 2,680 it's taking too much time to give answer of any questions is my system I got response 6 Minute for this uh for allergies Anu what is your system configuration you can let me know because for me I'm using 16 GB RAM and code i7 processor uh yeah so if you want to uh decrease the response time so what you can do guys let me show you so I think I already showed you the model right so this is the model link so here I was using 4bit model maybe 2 bit model is also available let me see 4bit 4bit 8 bit 6bit huh 2 bit model is also aailable can you see Q2 kin you can uh download this particular model so this is the smallest version of the model and you can see the size so those who are having 8 GB of RAM and the Codi 5 processor you can go with this particular model um a 2 bit model OKAY in this case actually I'm using 4bit model you can see I'm using 4bit model Q4 yes definitely you need it uh you can also execute on the Neal LA but I'm not able to do because it's taking so much time for me to upload the model here okay so what you can do you can start uploading the model once this model is uploaded you can uh write the same code here also because Neal laab will provide more Rams and all if you are having less RAM and you can also do do it on the Google collab as well but flas code won't be running there you can only do the experiment part The Notebook experiment we did yesterday so these are the alternative you can follow I think uh you can see guys uh one thing actually you can do after the session those who are having low configuration PC you can go with this model two bit model no see here you don't use any pkl file okay ANUK it's a uh hello everyone am I audible uh give give me a confirmation guys am I audible to all of you okay sorry actually my system got hang and I got disconnected uh sorry sorry sorry because like too many software I opened that's why my OBS Studio got hang okay and I got disconnected connection was fine today okay there is no issue with the connection because live streaming like uh it takes little bit yeah okay fine so maybe my this thing has also stopped let me again do it okay now I think again it will start yeah so what I was talking about about I was talking about uh if you are having let's say less memory so what you can do in this case you can use this uh eight uh two bit model guys okay two bit model from the from here okay now maybe uh it is running okay let's store till this point I will stop the execution so let's say I have already stored my Vector so let's store till 5,728 okay so you can complete the uh like this Vector upload operation um until it gets over okay till your 720 fine now let me push the code so I'll quickly push the code so uh store store index edit now I think you will able to see the code or maybe I can what I can do um um whenever I'm implementing this thing so in between I can start my progress I'll upload all the data again just a minute or let's keep it let's let's try it if it is not giving correct response then I will again store it and guys uh if you don't know actually there is a webinar of the generative AI uh you don't know U or not let me show you so there is the webar guys so it would be happened this is the date so let me share the registration link as well so please join this webinar guys so Krish S and sudans S would be there so they will be discussing so many things about generative AI so this is the uh link I can give you so this is the webinar link so let me open this one so you can register here you can uh give your name email address mobile number and which state you are from and you can submit the form and here is the video you can go through all right okay now let's complete the project guys because we are almost done now what I need to do we have completed our store index okay now we are able to store our Vector to our Vector database now what I need to add I need to add my uh app component okay because I need to uh create my front end right now so for this actually what I need to do um just a minute uh yes so so I just need to uh first of all give the prompt here so I think you remember we created one prompt. Pi here so let me open this file and yesterday I prepared one prompt here so let me show you the notebook so here is the prompt I will copy this prompt as it is and in the prompt. pi I will add this one okay now what will happen actually U you don't need to directly write the prompt inside your code so instead of that what you can do you can mention it like that okay so it would be pretty much good for you now once it is done I will open my app.py and I will uh write the rest of the code here so I'll just copy paste the same code I created so inside app.py first of all let me import flask so from uh flask I need to import plusk then I also need something called render template I will tell you why you need random template why you need flask okay everything I'll be discussing about yeah now I also need something called Joni as of now let's import only Joni and I also need something called request okay then uh here I also need to load my uh embedding okay so for this I also need to import this embedding my download embedding uh method we created then I also need to initialize my pine cone because I will be loading that particular index and I will be extracting my Vector from there so that's why I need I need this particular Pine con package here then I think you remember yesterday I was importing some more things let me show you uh where is The Notebook let me open the notebook again uh this is the notebook and let me close these at the tab first of all template I don't need uh store index I don't need as of now helper I don't need okay here here is The Notebook so here if you see I was importing some of the more Library called question answer then C Transformer Ral question U and prom template okay so this thing I need to Al import here because I need to create my Ral question answer object okay to chat with my llm so let me import them so here is the code now I also need myv because I need to load my secret credential from that file then I need to also load my prompt okay this promp template so what I can do okay so maybe it should be hugging face sorry I deleted by mistake yeah now I also need to import this prompt template from my prompt so what I can do I can just write from uh SRC do prompt import Star okay that means whatever things actually I have inside this prom. Pi everything just try to import here okay now after that uh I also need something called operating system package so I'll just use uh import o now at the very first I just need to initialize my flask so app equal to uh how many of you are familiar with flask guys here have you ever worked with flask like how flask Works how we usually create the app with the flask and all if you have some like little little knowledge on this flask I think this should be pretty much Clear how I'm creating this application frontend application you can let me know guys in the chat anyone uh worked with flask before I think if if you have already worked with with machine learning deep learning so I think you know this flask little bit no not okay so no issue I will explain okay it's like very easy so flask is a like framework in Python it will give you uh the functionality to create the web application here okay yes and no need to worry about the like HTML code and CSS code that code you can copy paste from the website itself I will show you some of the website even I copy pasted the HTML and CSS code from the website itself okay because I also don't know like how to code in HTML and CSS no need to worry about so we usually Define the flask object like that now what I need to do I need to load my uh API environment so what I can do I can open the store index and this code I can copy and I'll paste it here then first of all I will load my embedding model okay okay now what I need to do I need to initialize my pine cone so I think you remember how to initialize the pine cone so here is the code initializing the pine con so let initialize our Pine con and it will take your Pine con API and pine con API environment so it is I'm reading already from here now here you need to give the index name so here this is my index name I'll copy and here I will give my index name done now if you have any existing index okay in your Pine con let's say you already have the index present and you already have the vector there so what you can do instead of creating it again because we have already executed our store index. pi and we have already stored our Vector there now I just need to load that I just need to load that and I will be using that okay so for this this is the particular code you can use load index from the pine con see Pine con do from existing index here you need to give the index name in this case this is my index name and this is the embedding model I'm using this two parameter you need to give okay once it is done you need to copy the same code yesterday you wrote here you need to create the prom template I think remember you need to create the promt template then you need to initialize your llm so now let's do it I will open my app.py and here is the code here is the code so this is my prom template and I'm just reading my prom template from where guys from prom. PI I think you remember because we have already imported this thing inside my app. Pi here okay now this is my prompt it is coming from here and this is the input variable user will give the question and it will return me the response and this is my model what is my model model is present inside the model folder and this is the location of the model model type is llama maximum new tokens it is uh just keep this default number and temperature I'm setting to uh 0.8 that means I'm just taking the risk and I'm taking also Randomness so whenever it will give me some response it will also take the risk and Randomness then it will give me the response so once I got this thing I need to initialize my QA bot that means QA object so this is the Code retrieval QA from chain type and here you need to initialize your llm chain type stuff and this is the doc uh Dockers so doers I'm getting from here my Pine con object that's it now you need to create the default route first of all of your flask so this is the default route I can create like that so here you need to in uh like give this decorator called app. route and if user is open your uh let's say host okay or let's say the URL you will be getting I will execute and tell you how this thing will work so it will open one particular HTML file which is present inside template do uh which is present inside template folder the name of the file is chat. HTML okay so here I need to write the HTML code as of now this file is empty but I need to write the HTML code like how your eyi will look like this particular code you need to mention here okay now let me show you how this thing will work so now I will initialize my flask so it will uh execute your code here now let's say inside the chat. HTML I can copy some basic HTML code welcome HTML page I can copy the code from here maybe example so this is the code I think I can copy let's see what is this page I'll paste it here then I will run run my app.py python app.py now it will tell you just open up your local host and port number 5,000 let's open my Local Host so Local Host port number 5,000 it's running on port number 5,000 uh see guys this is the screen I'm getting from this code itself so now we can also change the code now let's give this code uh let's give this HTML code what happens if you know HTML and CSS so you can create a beautiful website it's up to you now if I again refresh see guys coming soon I'm getting that means my web app is working fine and I got one API okay I got one API this is the API guys my uh like project is running on this uh host and Port okay this is the host and this is the port you can also change it so what you can do here you can give host uh host is equal to host is equal to uh you can give like that 0 point 0.0 uh zero and Port is equal to you can give let's say 8080 any kinds of Port you can mention let's give 80 80 now if I stop the execution again now if I again uh rerun my app. Pi you will see it will run on port number 8080 right now see guys it's running on port number 8080 now I'll give the permission now if I open and here I will give my port number 8080 now see guys your application is running here got it now here what you can do you can visit this website called bootstrap bootstrap uh sorry it should be bootstrap bootstrap so this is the website we usually copy any kinds of template so here I created one chatbot template so here is the example so in the example you will see lots of example would be there any kinds of template you can copy from here it will uh give you the HTML and CSS code with respect to that either what you can do you can search for chatbot HML and CSS template free okay so there are some website it will give you some of the template you can just download from here see this this kinds of chatbot actually templ template you will get so you can download it and it's completely free you don't need to pay for anything if we have to put this on any website uh then where we need to provide the details no see the same thing you can do the deployment okay I think you saw how we we we usually do the deployment on AWS so that time it will run on the AWS URL okay not in the Local Host we'll show the deployment Vic okay in our paid courses it already designed see these kinds of chatbot template actually will get okay so what I have done actually I already downloaded one particular template and I already copy pasted the HTML code let me show you how it will look like so this is the code and you don't need to worry about for the HTML code so this thing actually you can download from the internet if you don't know anything so this is the HTML code from the chatbot I'm using and with respect to that you have one uh CSS file as well so the name of the CSS file is style let me write style. CSS so let me show you the style. CSS so this is the CSS code okay so from that uh website you can download this particular thing now if I go to my website right now and if I refresh now see that's how my chat bot look like isn't it uh B beautiful app guys tell me uh how this template look like to all of you because I personally like this template uh actually I just copy paste the code from the Google itself so here you can give your input message and it will give you the response yes I will give the code no issue let me just comit the code as well so what I can do I can give templates added so this is the medical uh chatbot kinds of Bot I have added uh yeah so now see how to change the photo of this one so here is the like one Nar photo I have added how we can do it you can open the HTML code so here you will get one jpz file see guys this is the jpz file PNG file okay so this is the URL of the photo actually so what I did I searched the photo in Google and I just collected the image URL see copy the image address if you copy it now see you can use any of chatbot medical medical medical logo you can open and you can copy any kinds of photo URL and you can paste it here so that photo will appear here actually let me show you that photo will appear here uh yes you can use this code okay I already uh committed the codee in my GitHub you can uh clone from here you can copy this template as it is guys okay no need to worry about how to write this thing because this thing is already available on the internet okay if you look for lots of template people are giving free these are the free template you can use it as it is okay all right now we'll be writing our final route so basically I'll be taking the question uh yeah and and see guys if uh you can enroll for the courses and you can get everything for free because we have lots of template as well okay we'll also give that rebuild template okay now let's write our final uh route so this is the final route so here what I'm doing guys so whenever user is giving any kinds of masses okay so here whenever user is giving any kinds of masses I'm just taking the masses in the back as you can see I'm just writing request. form and it will give you the message and this message will come here then I'm saving the message to the input variable and I'm also printing in my terminal after that I'm just sending this input to the QA QA object okay because QA object we have already defined here okay then it will give you the response that particular response I'm printing in my terminal as well and as well as I'm also sending that particular response to my UI here okay now let me uh let me show you how it is working or not so what I will do I will stop the execution again I will clear the terminal and again let's execute my app.py sorry python it should be python app.py okay it's running now let's go back and refresh the page again uh I think I can open it again so Local Host port number 8080 see now let's ask some questions so here I can give uh what is acne so the same question I asked yesterday and let's see see I asked the question now uh it will take some time because I'm uh doing the live streaming and all so it will take some time to give me the response okay but if I stop the streaming so it will give me quick response and the same thing we can do it on the neural app so let me show you um so what I will do I will copy this HTML and CSS code uh let's copy this HTML code and open my Neal LA and here I can give this here also I need this static so inside I have style. CSS now let's copy the code done now let's uh write the route here and uh this is the final code Pyon app.py okay it's running now so now what you need to do you need to copy this URL and what is the port it is using uh let me see it again it's 5,000 okay just paste it and give the port is equal to 5,000 uh okay bad request it's telling I don't know because maybe my uh okay I got discon Ed maybe that's why okay I need to again rerun it let me see the execution here see guys it's giving me the response is it correct acne is the common skin disease characterized by pimples on the face chest and back it occurs when the uh porous of the skin becomes clogged with the well dead skin cells and bacteria see the guys eyi it is also extracting the time the current time actually you are asking the question is it great guys now you can ask any G of question here it's up to you why it's giving bad request let me Che everything is good okay I got the response see I think uh who has asked the question if I give any casual message whether it would be able to answer or not see I've given hello I happy to help however I don't have any access to the external information or context beyond what is provided uh the text you gave me without more information I can provide the definitive answer or to your question can you please provide the more context to clarify your question got it so basically here is uh the chatbot we have implemented this is already dependent upon my custom data I have given okay so here I haven't given any external data sources okay so this is only relying on this PDF file okay so that's why it's giving some warning before starting with the conversation got it now you can open this book you can open this book and you can ask any kinds of questions so let's ask another question so I'll find one dis is here evention not this one I'll take let's copy this disease okay I don't know what is this let me search on Google first of all okay this is a medicine actually so let's ask about the medicine so this is my bot tell me about this medicine so anyone is running with me guys anyone here everything is working so you can go through this book and you can ask different different question different different medicine like uh for this disease what would be the diagnosis okay everything you can ask here and make sure you are uh storing all the vectors because I already stored 5,000 something Vector here so make sure you are storing all the 700 uh 7,000 and20 all the victory here still running because my live streaming is going on that's why a little bit slow okay this is the response see this is used to rely many kinds of minor ax and pains include headache muscles ax back ax and tooth X so see this is one kinds of medicine actually people use for the pain okay now you can see also this medicine this is the medicine now tell me guys how is this project you like this project the medical chatbot your custom medical chatboard yes or no because we are done with the implementation how is this project guys you can let me know in the chat all right okay thank you thank you guys so you can try and uh those who are having uh less configuration you can use the 2bit model okay I already showed you the sources and uh please implement this particular project guys those who haven't implemented and you can tag me on LinkedIn so this is my LinkedIn profile guys so here you can also tag me after the implementation uh you can also tag ion so we'll be happy to see that like you have implemented something okay can I add this project in my resume yes vikash you can add it because this a good use cases okay in the generative AI uh like field you can add this project and please implement the project guys please implement this project let me commit the code as well and let me write down the further steps to run this project so let me complete the readme as well so first uh first of all you need to execute that stored index. Pi because you need to store your index first of all then after that you need to execute app.py okay then you need to open up your local host and Port then I can mention the take stack I used in this project now let me comit them done okay so guys yes this was our medical uh chatbot implementation and I have showed you the entire uh like process sir may I know prerequisite for this course please uh no need any prerequisite okay uh you can still uh still join the course if you don't know anything so we'll give all the idea and guys uh there is uh exciting news for everyone we are also coming with mlof session okay on this uh Monday from this Monday so please join the session those who are interested in mlops so you can join here and if you are interested in Hindi so in our Hindi Channel also uh this medical chatbot implementation will come so it will take by Sun sir so you can join uh today okay see you can uh just notify click on the notify button deep planning and machine learning fails under the data science uh yes this is under the data science yeah and guys yeah you can mention this project in your resume there is no issue with that because this is a good use cases yeah so MLF session actually it would be conducted on our this Inon Channel okay so here actually you will get the MLF session and uh the detail of this MLF course would be shared soon okay just stay tuned with our Channel everything would be shared here no this is not a last session maybe couple of session would be there after that small uh language model is different uh t0 llm small mod small language model is different t0 llm I didn't got your question uh okay so uh sorry guys so there uh today's the last last session of our generative AI okay because we have already covered everything okay we have already covered everything if you go here if you go to the live section so from the day one itself uh see uh from the introduction itself itself actually everything has been covered Lang chain covered Hing face covered openi covered uh n2n project has been also covered then Vector database covered then uh yeah open source llm is also covered then I also showed you the how use uh how to use open source llm and create the Inn project as well and uh and if you want to learn more about generative so that is a paid version of our course so there actually we have added so many things so let me again show you so this is the page guys so let me share you the link so if you are interested you can enroll for the course and here we have already covered uh we we'll be we'll be covering lots of things here let's say fine tuning llms and all so you can visit the syllabus here okay it's a big syllabus guys metal Lama API is free to use or paid like open meta Lama there is no Lama API okay we have downloaded the model because so link is uh in the chat guys so you can visit this courses you can go through the cabus and you can enroll for the course and uh why this course would be like more uh you can say interesting because we are also giving the job assistant if you see here if you go uh read this description and all about so it is starting from uh 20th January and uh this course version is English okay and duration is 5 month it would be conducted uh 10 to 1 p.m. okay IST Saturday and Sunday and this should be live course okay this should be live lecture actually and we'll be also providing the job assistant doubt clearing session okay so each and everything would be there so let's say if you having any issue okay with your like resume and all job and all so we'll be like conducting a session with you so we'll also build your resume we'll give you the carer advice okay everything would be done here is this course curriculum changes on a new model uh see if you go through the course we have added so many open source llm here also new model as well okay we have added f con Google Pam okay so we have also added this thing as of now you learn like Lama 2 model okay but there are also lots of Open Source model available let me show you if I search for open llm okay maybe I already showed you list of open llm so there are lots of llm there are lots of llm you can use so we'll be covering them also here and see guys uh here you you will get like one year dashboard access and uh assessment uh in all the modules okay you will be getting assessment for all the module and guidance by the expert and mentors as I already told you if you are having any issue with your career and all if you're not getting any jobs so we'll be giving the job assistant uh like opportunity as well then course resources definitely will get then live lecture okay like live lecture you will get from here and quizzes and assignment you will be getting from each and every lecture okay then you'll be getting free neural lab access as well so we'll also show like how we can use our neural lab efficiently here because many of you are having less configuration machine okay so we'll also show you like how we can use neurolab here as well then uh here you will get dedicated Community Support promise I'm in this course duration is 5 month so in a 5 month jna is boosting so much okay so we'll be taking care that yes so let's say in this five uh five month actually if any changes is there if any new thing is coming we'll also Showcase in front of you okay we'll also tell you that thing no issue with that yes we'll also integrate mlop Tool uh like we'll also show like how to integrate Docker this thing how to do cicd deployment everything will show there okay the efficient deployment process will show there and guys this course is uh also for students and working professional as well even if you are an enterpreneur okay who are looking for uh using this latest AI technology in your daytoday business okay so for you also you can refer this course okay so this course is for everyone if you are a student if you are job professional if you are let's say enterpreneur anyone can refer this course we'll be covering each and everything in the field of generative High guys okay after leing this course you will become a champion in the field of Genera VI this is the like guarantee I can give see building llm uh we don't do it usually okay building llm is not a easy easy task power okay see llm building is not a easy task for this you need resources you need cost you need a good configuration machine okay because we have already llm okay now we just need to use them we can fine tune them fine tuning we will show like how to fine tune on the custom data if this uh llm is not working for your specific task you can still fine tune that okay and guys please join this webinar everyone so there is the webinar actually conducted by creation sudans s so here is the link we have already given let me share it again please register uh of yourself here and please join the this uh uh like webinar okay so you'll be learning a lot lot from here and here's the video guys so what are the things actually he'll be covering and all so you can go through this particular video it is already available in our Inon Channel guys now if you are having any doubt you can ask me in the chat I'll be taking couple of Doubt then I will be ending the session any any doubt guys any question you you are having you can ask me then I will end the session so guys uh so far how was your session guys uh are you able to learn something in the field of generate because we have covered so many things like it's completely free even you won't be getting these kinds of content anywhere Jin if it is there okay if they already post the API and all okay we'll be also covering JY okay no need to worry about because this is the recent research uh recently it has came to the market okay they haven't announced so like yet yeah thank you thank you Karan and thank you for your contribution yesterday also yeah thank you thank you power also and if you have any query you can ask us anytime no issue okay perfect guys so let me talk about the agenda today okay now uh many people have been talking about generative AI they've been talking about open AI llm models they're talking about open source llm models like lama lama 2 you have mistol you have lot of different different models and every day probably someone is coming up with some good llm models right but when I talk about Google right Google recently came up with something called as gini right and uh it after seeing a lot of practical application after implementing multiple things uh I could see that it really have a lot of capabilities so that is the reason why I'm keeping this entire dedicated session specifically for gini and just to make you understand today what all things we are specifically going to do I'm going to write down the agenda what all things we are basically going to do today right so let me just share my screen and let me know whether you are able to see my screen or not okay just a second so just let me know whether you are able to see my screen just give me a quick confirmation just a second uh my face is not visible why I just try to change things okay so everybody's able to see my screen so which view do you like better this view or this View this view is different which view this view I hope everybody likes it better okay yeah visible so I'm going to basically talk about the agenda and uh so first of all we'll understand about what this Google gin llm model is all about okay so we'll understand this we also say this as multimodel okay why do we say it as multimodel we'll try to understand this multimodel um why it is good with respect to vision and all that also we'll try to discuss okay the second thing is that we'll try to see a practical demo so we'll try to see a practical demo using Google giny okay we'll try to see a practical demo using Google Jin Pro okay why Google G Pro right now Google has just provided this it also has huge capab abilities and with the help of this you can actually Implement both Text Plus Vision use cases okay so you'll be able to use both of them third thing after this we'll try to create an end to endend project okay and we'll try to see this end to end project ug Google gmany pro okay so we'll do all these things in this session we'll have a couple of hours session we'll discuss step by step what all things we are basically going to do and considering this we going to discuss more about this in terms of practical implementation okay um till now I think Google gini also like Google did not I don't know about his research paper that much information is not available but a kind of brief idea you can actually get it what exactly Google Gemini does okay so everybody clear with the agenda so please hit like if you are liking this video I really want people to be very much interactive right now okay uh because end to endend project everything I'll be explaining trust me at the end of the Days end of this session you will learn amazing things as you go ahead you know and you'll get an idea like how powerful this is and uh with respect to text and vision use cases this will be super amazing okay so hit like and yes share with all the friends out there if you have some of the friends who are interested in this things right so definitely do make sure that you ping them right and uh over there also you can actually do it okay so in insta also we are live so again for all the guys out there in insta and in Twitter so we are live in four to five platforms right now so please let me know like how whether you're able to hear me or not okay but all these things we are going to discuss so Mohammad mozak says hi Chris you're my role model and I follow your videos I'm currently working as an AI engineer UA Dubai amazing amazing congratulation uh mazak congrat I hope I'm pronouncing it right okay so let's go ahead and let's further discuss about the Google Gemini llm model and why it is so good uh you have to keep on motivating me to take more and more more and more right so definitely do hit like keep on putting up your questions I'll take up all the questions as once the session completes and if there is some important thing that I really need to answer it I'll answer in between the session okay so just give me a quick yes if you have understood the agenda what all things we are going to do in this session yeah I hope everybody's got this clear idea yeah everyone a quick yes thumbs up something okay agenda is very much Clear we'll understand about Google giny we'll see some demo then we'll do practical demo we'll see how we can set up the API keys and all and all these things okay great so let's go first of all you need to know about from where we are basically teaching okay so here is the entire in neuron platform uh if you don't know about in neuron for the people who do not know about Inon we do come up with a lot of different courses data plus web development every coures as such and if you're interested in learning any of the course from us okay you can see you can just go ahead with ion. just go and see different different courses over here like generative AI course we are coming up from this Jan then we have machine learning boot camp uh both English and Hindi and if I talk about data analytics boot camp and mlops production ready project so these are the four uh four important courses that we are specifically coming up with okay so mlops production ready projects data analytics boot camp machine learning boot camp and finally generative AI so if you are really interested to learn from us you can go ahead and check out all the courses okay um the other thing is that in this um if you do not have a a very powerful system what we will do also is that you can actually use neurolab okay because today I'm also going to show you the Practical implementation with the help of neurolab what we will do is that we will try to create our own environment over here you can probably do the coding that you specifically want okay so it it gives you a entire working development environment where you can write your code and this all code will be running in the cloud so if you do not have a powerful system I would suggest go ahead and check out about the neural laab itself it is very much simple go to ion. click on neurolab and start working on this because at the end of the day when I'm showing you practical implementation we may be doing in this okay perfect so welcome to the Gin era so I let me talk about the story because initially people made a lot of fun about uh you know Google uh because of the demo that was put up regarding gini Pro okay and I hope many of you have heard about this so gini's built from ground up for multimodality reasoning seamless across test images videos audios and code and this was a demo that they had actually put and I hope uh you have seen this demo right I think they should have removed this demo so this was the demo that they had actually put okay and this demo was not that true okay it was just like taking images by image frame and then probably combining and doing all these things okay but at the end of the day many people made fun of it you know uh they came up with something amazing and this was what they had the first impression wow this looks quite amazing it can probably do any kind of task you ask it map it will tell you about map it if you ask about any object it will tell you about that particular object like that right so still it is not that powerful right now okay considering the kind of demo they had actually shown but the most important thing that we really need to understand why we should think right this Gemini is an amazing model it can probably be the future of llms okay first of all whenever we talk about multimodality okay multimodality so here when we say multimodality okay so here one example you can see that it is being able to do the reasoning seamlessly across text images video audio and code okay recently if you probably talk about open AI gp4 model right now it has come combined everything di it has combined uh for the data analysis part also it has combined that code interpretor functionalities and all right and recently it was launched and over there you can probably do tasks that are related to images that are related to text okay here in gini when we see right you are able to combine everything text images videos audios and code today I will show you a lot of example with respect to text and images okay we'll see some amazing use cases you can also do it with the the help of PDF you can do with multiple things as such okay and all the task that are related to NLP like chat with your PDF and all you can also do with this now the most important thing why gini is the most capable AI model that is because of this result okay now see here you can see something called as human expert MML now what is this mmu okay if you probably search for what exactly is MML okay mlu if you see that it is nothing but massive massive multitask language understanding so with respect to humans right it is basically able to say that over here it has achieved see Gemini is the first model to outperform human experts on mlu massive multitask language understanding one of the most popular method to test the knowledge and problems solving abilities of AI and here it is also said that it has crossed the crossed the Benchmark of GPT 4 also right so if you probably see this see understand Guys these all are very important things to understand because benchmarking is done on which thing that you really need to get an idea about and because of this benchmarking you will get a clear idea and you can assume how good this specific model is and any model so tomorrow if you probably talking about Lama 2 if you're talking about Mistral it will be benchmarking based on this capabilities so if you probably want to work in the field of generative AI I think this benchmarking is super important and you should learn about this okay or get an idea about it because tomorrow if you're reading a research paper how can you say that this model is better than the other model okay so here you can can probably see in mlu it is nothing but representation of questions in 57 subjects right it has been able to get this accuracy 90% gp4 it was somewhere around 86.4 then in case of reasoning you can see some results where it was greater than GPT in two different things like in big bench hard drop in h Swag like in common sense reasoning for everyday everyday task it did not achieve that much accuracy when compared to gp4 Okay so the reason see I'm telling you why all these things you should know because you should get an idea about it okay the other thing is that with respect to ma maths right basic arithmetic manipulation final grade school math problem it was able to uh get a good accuracy of 90 4.4 but when you had challenging math problem it is not able to get that much accuracy right somewhere around 53.2 but it is far more better than gp4 gp4 was able to get somewhere around 52.9 okay similarly with respect to the code evaluation here you can also see that it has crossed this gp4 like python code generation python code generation new heldout data set human eval like not leaked on the web right so completely a new generated code right so in short it says that and this is completely from the research right gini surises the state of art performance on the range of multimodel benchmarks so you are getting this specific information and there are other information see this is something related to text okay this is something related to text now here if you go down it is something related to multimodel now whenever I say multimodel what does that mean it is basically talking with respect to images with respect to video with respect to audio and here also you can see that it has proven well with respect to all the Benchmark when compared to GPT 4V right so here you can see 59.4 4 77.8 82.3 90.9 80.3 53.0 and here you can see all the other readings right if you want to read the technical report here you can probably go ahead and read it entirely okay it will be talking about how it has basically done the fine tuning and all and all and all it's just like a research paper like why it is basically said as a so here you can probably see here is a solution of a physics Problem by a student uh the information is given over here that it was not able to get the answer whether the answer is correct or not all the information clearly you able to see right again it is based on Transformer only encoder decoder so that is the reason right why I say in the road map of generative AI if you want to learn something you really need to have a good base about Transformer and BT right if you understand what is encoder decoder how it works right then definitely all the further things you'll also be able to understand it right so guys till here everybody's clear right now we'll talk about what all different sizes are there and which model is available for us so if everything is clear please do hit like if you're able to hear me out and all so uh shini says sir what is the difference between B and gin see B like how we have chat GPT application similarly we have Google B in Google B in the back end we used to use pal to right now they can change Palm to Gemini right where it will also support images and text it's all together an application so can I get a quick yes if you able to understand yes something quick yes come on guys I should be able to hear I think there's a less energy over there come on let's let's make this session amazing see my main aim is to make this session a good one for you right you should be able to understand things your Basics fundamental should be strong tomorrow when whatever model you should see you should be able to understand so hit like okay hit like hit something give a smiley I'll feel happy more energy will come when I'm explaining because we also need to do end to end project right now okay now um so one question is that how to generate image data using Gemini still those features have not been exposed completely we'll talk about what all features it specifically have okay don't worry okay we'll be discussing about now Gemini comes in three sizes one is ultra our most capable and largest model for high complex task one is pro our best model for scaling around a wide range of task okay and the Nano part which is our most efficient model for on device Tas so if you are specifically working with gini Pro or gini in devices you can use Nano in this in for normal daytoday task or general task you can use gini Pro then you can use ultra right now Gemini Pro is available for everyone out there without paying anything you can use it and you can also hit 60 queries in a minute okay at a time you can hit 60 queries right now no charges are there later on when Ultra will come the API will be basically exposed okay and then you can also use now gini can generate code based on different inputs all these capabilities are specifically there so it is now better that we try to see some handson okay and all the other information you can probably check it out which is I don't think so it is very much important right now you can also check it out with respect to B now I'll give you a link okay I will give you a link everybody so let's take this link everyone and provide this link in the chat okay so please go ahead with this specific link okay I've given you the link over here okay and in this link you'll be finding this particular thing now we are going to see a kind of demo right kind of demo like how does geminii API work and we are specifically going to use AP gini Pro now in this first of all I also need to worry about the API key how do we create an API key gini Pro create an API key we'll discuss about that right second we will see multiple examples with text images okay so both these examples we'll see in this demo and finally once we see multiple examples then we will create an end to endend project where I'm going to write the code from scratch write the code from scratch okay I'll build a front end back end and then probably show you okay um sir a video called handson with Gemini interacting with multiple was fake yeah I told right uh they had actually integrated images to image but with respect to Performance I think it is very very much good okay so let's go ahead and now I will click on Google collab now see guys over here Google collab is there you can also work in neurolab okay if you want okay but always understand with respect to if you want to use gini Pro the python version that you really need to have is 3.9 and greater okay 3.9 and greater so we are still updating this neural lab right now by default when you open this neural lab it opens in 3.8 see 3.8.1 Z right so we will soon update this by default you can also get an option of changing this environment because today I was actually seeing this and it can probably also work in 3.9 okay so that is the reason we are probably finding it out so everybody got this link everyone did you get this link so I will post a comment just check whether you are able to get this link or not everybody got the link yeah so this is the link you have to probably go ahead with you know so you will get this page you have it all the options yeah you have all the options like for go you have for nodejs you have see it supports all everything right web if you want to probably working on web if you're working on Android device you also have that you have that client SDK right you have rest API right everything if you want to work along with rest API you can also get that as an example how to get an API key I will just go ahead and talk about it but now we are going to focus on python okay so with respect to python we are over here now do one thing first of all guys when you're running this before install installing first of all let's go ahead and connect to the GPU okay and again if you Al want to do the coding in neural La please go ahead and do it okay but as I said uh it may give you some issues because the bython default version is 3.9 with respect to gini Pro okay but again I would suggest try with this also good system all the code will be saved over here and it will not get deleted okay great now first thing first okay so we have connected let's before executing anything click on this get an API key so get an API key will be there somewhere like this and it will go to this link makers. goole.com slapp API ke so first of all we are going to create an API key okay for API key for a project okay so just give me a a confirmation if you are in this particular section because I'm going to show you everything from scratch how you can actually do it okay so please go over here in this specific link did you get that link did you get that link I hope right just click on this link in this particular uh notebook file you'll be finding this specific link get API key okay so click on that and it will open just give me a confirmation once this is open okay so see if you want to communicate with this llm model it will be exposed in the form of apis so when it is exposed in the form of API you'll be able to interact with it okay yes everybody got this link okay I have already created one so I'm going to delete this and I'll create a new one okay so I'm creating an API key now what happened let's see create a API key the caller does not have a permission I'm getting some error let me see okay my account was changed okay so I will just change my account so this is my account okay now I will try to execute it because if you doing with other other account then it will be creating a problem so let's go ahead and create my API key okay I will go over here now everybody just click on this create a API key still there is an issue why is everybody able to create an API key right now just check are you able to create an API key I will just open Google collab let's see okay okay it should not give an error I don't know why it is giving an error scholar does not have a permission just a second I think everybody should be able to create it just give me a second guys I'll just try to create one API key just give me a second okay I think there's some issues but I think everybody may have got created it I'm getting some error and I should know the reason just a second just a second the caller does not have a permission anybody facing this error I think it is due to I created did the multiple keys for the task I created the three app keys after that it is giving Mana I guess so uh just a second let me see I'll just sign out once close it and open let's see maker suit I got the create I was able to create it yeah everybody's able okay someone someone someone Someone okay someone anyone ping me the key over here I'll just have a look on this issue why it is Happ happening with my email ID okay I'll just get to know why it is probably a problem but anyone just give me an API key in the chat anyhow you can actually request 60 request so anyone someone give me the chat in the chat I'll just check because this is the first time I'm facing this error let's see what is the issue okay it should not give me an error someone just uh ping it in the chat let me see in whether any other user ID will I be able to do it or not think okay so please make sure that I think if you're able to create a multiple okay finally I it has got created I changed my login ID so now it has got created now what I will do I will go over here okay I will keep this API key somewhere here let me just keep it over here so I will say OS do or let's say I will write key is equal to and I will save it over here okay so guys please make sure that please please please make sure that don't create multiple multiple this one and delete keep on deleting it okay so do not do that okay so don't after creating one please save it somewhere let's say I am saving it in my notebook file okay so I have saved it over here in my notebook file so that you don't delete this okay don't delete it if you're deleting it I think after three times it will give you an is issue otherwise just change your email ID okay now let's start over here and let's start working on it okay so first of all I will go ahead and connect it okay and then we'll go ahead and discuss step by step okay so just let me know whether you have done all the steps or not you have everybody has created their keys yes yeah everybody has created the key okay now I have connected to my collab okay remember the requirements is that you need to have python 3.9 plus okay and installation of Jupiter to run the notebook so 3.9 plus is the minimum python version that it will work with now first of all we will go ahead and install this Google generative AI okay so this is the library we are going to create it okay so what I will do parallely let me do one thing parallely I will create a project okay let me let me create one folder so guys see I've created a folder gini okay and in my local I will open a VSS code because at the end of the day I also want to create an end to endend project okay so everybody follow along with my steps okay now first of all it is basically saying that I will be having one requirement. txt requirements.txt yes everybody so everybody has vs code can you give me a quick confirmation if everybody has a vs code yeah everybody has a vs code yes yes so how do you open this vs code just click in this particular folder open with code right so I hope everybody is basically having the vs code now I have opened the vs code now the first step over here you can see that we will go ahead and install Google generate ative AI right so I will copy this entirely and I will execute it because here I will show you the demo and there we will try to create an endtoend project okay so I will do this over here so here you can see the installation has taken place right and as you know the first thing that we need to install is Google generative AI so now I will go to my vs code and here I will write it as Google generative AI okay the next thing I will also be requiring streamlet so that I create my front end right so here I need to create my front end okay so these two libraries I'm going to specifically use it okay now as said what should be the python environment that you are currently working in what should be the python environment that you should be working in can anybody tell me so I'll say cond deac activate quickly tell me guys which python environment we should keep on working on it which python environment at least greater than 3.9 plus so what we will do we will try to create an environment so in order to create an environment I will write cond create minus P my environment name is V EnV and which environment I'm going to use Python equal to 3.9 or if you don't want 3.9 plus you want so I will say 3.10 right 3.10 and here I will by default give y okay so everybody clear I'm creating an environment so that I will also be able to work along with an end to endend project so once I execute this over here you'll be seeing this entire things will get executed okay and that is why you'll be able to see one environment V and be getting created see step by step we'll do and I'll be able to make you understand why I'm specifically doing this because I want an environment so if you're executing the local or in any Cloud minimum requirement is that you need to have python 3.9 plus that is the reason I've taken python 3.10 okay so here you can see that we noticed a new environment has been created do you want to select it for the workspace folder either you can select yes or if if you want to activate that environment what you will do you will write cond create sorry cond activate vnb Dash okay so now here is my activated environment perfect clear everyone can I get a quick yes yeah yes yes obviously you'll get the recording also don't worry so everybody if you are able to understand please hit like and let me know if you are getting all this information or not okay we will do this parallell step by step whatever things are happening we will work in that specific way okay great okay now here also we installed Google generative AI okay clear shall I go ahead guys shall I go ahead everyone shall I go ahead come on give me a quick yes great now what we are specifically going to do okay is that we are going to install and import some of the libraries for google. generative AI see this is what we had installed right Google Das generative AI right and the same thing we are importing over here import Google generative AI as gen all the functionalities Let It Be text let it be uh Let It Be regarding other things that is videos images audio this gen aai will be the allias name which will have all the functionalities and this is present inside google. generative AI okay now here you'll be able to see that there is something a way to secure your API data I will show you how you can basically do it but let's go ahead and create my API data so here I already copied my API so I will go ahead and say okay my API uncore key is equal to in this way I'll paste it over here okay so here I will give my API key which I had copied from there so this will basically have my API key okay so this API key I will further be using using okay so everybody just create your API key field and this is basically converting a text into markdown so that you get a good display in the jupyter notebook so not that important so that is what next thing we are basically going to do now understand this API key that we have created the same thing we'll try to do it in our end to endend project the name that we are specifically going to use is nothing but Google API key so here when I probably go over here and go to my here I will create a file okay a file okay soem file and here what I will do I will paste it Google API key and we will try to paste the API key over over here what was the API key that I got it was nothing but this entire thing okay so here it is okay so why we need to create an API key to play banga we'll do bhang with the API key Danes sa are you in the session or are you away from the session H do you want to play banga come on I I made you understand right why we require the API ke it is very simple to communicate with the llm models huh without the API key you'll not be able to communicate with the llm models right a better answer for you will be to play banga okay let's play banga in that okay come on guys please be serious with respect to all the sessions that we are doing right never never uh you know whenever we provide you free content you do not value that free content right please focus on the session try to learn along with me I'm going step by step I'm going slow I'm explaining you each and everything right please Focus right please Focus if you do not focus on the session if you're just watching it then it will become a problem okay so practice along with me so here I've created one API key that is Google API key h um one question was that sir at the end of the webinar could you please suggest some real use cases of gen VI in finance yeah today the end to end project that I'm going to do is an real use case only okay clear everyone so can I get a quick yes API key basically means we have gini llm models somewhere hosted in the cloud to access that you require some some some tickets let's say you want an entry ticket that entry ticket will be given by that API key itself right you if you have the right API key you'll be able to contact the Jin llm model you'll be able to get the result okay so clear everyone till here okay okay perfect now we will go to the next step and here I will go ahead and I'll just comment out this code okay I don't want this code okay and let's say I will write gen. configure we need to configure this key okay we need to configure the API key so I will just comment out this code and I'll show you in an end to end project how you can call this variable okay and I'm saying gen ai. configure API key will be equal to this key okay so once I actually execute it okay here you can see that now our API key is basically configured now we know our ke is over here but it is not a good practice to Showcase this API key like this that is the reason in my project you'll be seeing that I have created this file okay file and this file has this API key and this EnV is nothing but environment right when you go ahead and deploy this this environment file will not be visible okay and since it is not visible in the environment in the production you will not be able to see this key so over there in production also you have a different way of setting the API key okay perfect now here we have configured it okay now this gen AI after configuring it provides you two amazing models one is gini pro and one is gini Pro Vision gini Pro is is specifically for optimized for text only prompts and this is probably optimized for text and images prompts okay text and images so one is for text and the other one is for text and images I hope you able to understand it okay one is text and one is text and images so if you want to do any kind of work that is related to text and images let me tell you an example okay what kind of use cases you can probably get from it okay now see this guys if I have this invoice let's say I have this specific invoice now if I want anyone to probably take out information from this invoice what do you think I can basically do or let's let's take this invoice okay some some of the invoice EX example this invoice has some of the data okay invoice sample I will take okay let's say this is one of the sample invoice and if I probably save this image and I will save it in my downloads everybody's able to see this invoice now from this invoice I want my llm application to probably retrieve data from it okay if I probably ask who was this invoice buil to it should be able to take out this information isn't it an amazing use case just imagine as a human being will this be a very steady task means it'll be a very slow task right here you'll be seeing what information is there then you'll be writing all the information what if if I say my llm model and I give this image and I say that hey what is the date that is issued for this invoice and it should be able to give me the answer 263 2021 isn't it amazing tell me will this be an amazing use case to work on in a company where you automat all the invoices are automated automatically is it good or not tell me guys come on yes or no something I hope you are not sleeping I know it's late but I'm going to take the session till 10 so that is the reason I'm asking you are you able to hear me out or not right so just imagine if you want to automate the entire in invoice probably take out all the info yeah PDF is also supported not on images PDF is also supported PDF you can convert that into bytes you can take out the information you can even chat with your PDF do whatever things you want right so this is super right this is this is amazing thing right you will be able to get those information and just imagine you have a task where you need to automate all the data in an Excel sheet and probably push that data from into a different databases right so here you'll be able to see that yeah I hope you able to get an idea about it guys clear so let's automate this let's automate this entire thing where you can give an image and I ask any question any generic questions with respect to this you should be able to get an answer about that okay so this is just like an invoice extractor I'll say okay and in upcoming projects we'll see about PDFs we'll see about chatting with PDFs we'll see about multiple things okay then then you'll have a fun so this is what is the use case that I'm going to probably solve today okay now let's go ahead and let's go ahead and probably talk more about it okay now tell me one thing guys everybody's writing the code along with me I hope so if you are not writing I will give you the code anyhow okay but uh let's go ahead and do this okay now this is done my EnV is created okay my EnV is basically created I have my Google API key everything is there uh now let's go ahead and install these requirements okay so first of all what I will do I will go over here I will go ahead and install these requirements in requirements I have Google generative AI streamlet right so I will go and write pip install minus r requirement. tht right so now my installation is basically taking place please go ahead and do the installation everyone and once you do the installation in your vs code or in your neurol lab we will try to probably install all the libraries that are required okay because at the end of the day we are going to create an end to end project please do that okay guys and uh for the people whom I see lot of participation I will give them an opportunity to probably come along with me in this live session and talk with me okay so you really need to be activate Okay so I'll give a couple of people that specific chance okay so please Focus okay and please be active because this kind of session start valuing it okay unless and until you don't value it then it will not work out so hit like do multiple things keep on posting call your friends to join the session it'll be quite some amazing okay so right we are what we are basically going to do we going to do this specific installation it will take some time uh now what I will do I will create my app.py file Now understand one thing what we are specifically going to do I will see what is our plan that we are going to do I'll discuss about the architecture so I will create one front end application something like this okay I will what I will do I will upload an image so then image will upload over here okay and then I will write my own custom prompt so this will basically be my prompt prompt basically means I will ask who is this invoice will to I will ask this question over here the image will get uploaded over here and then I should be getting my output over here that saying that the image was built to someone like built to this particular company okay now this is super amazing see now as soon as I upload the image understand the architecture okay as soon as I upload the image right so this image will get uploaded then what I will do I will take this image I will take this image convert into bytes convert into bytes okay and then retrieve this image over here so I will be having the image info okay image info okay so this is First Step as soon as I upload it the image will get converted into bytes and we'll be having all the image info all the details inside the image because Gemini pro has a very strong OCR functionalities OCR functionalities okay so if you probably give this information of the image info now in The Next Step what I'll do I will take this prompt so I will add this along with my prompt and this entire info will be going to where where it will go bites basically I'll show you that bytes don't worry okay it is just like image information it will probably get converted into some encoded character okay now this image info plus prompt will now be we will hit it to Google gini we will hit it to we will hit it to gini pro llm model okay to gini pro llm model now once we head it to the Gin pro llm model it will look for two important information one is the prompt and one is the image info and through that OCR functionalities what this gin Pro it has an internal OCR functionalities it will try to compare this two information and it is able to get an output it will give an output saying that let's say I've asked the build uh who this invoice was built to it'll say that the invoice was built to so and so information that we are getting from the image okay and finally this will be my output and this is what we are specifically going to do we will Design this we will write the code for this and we will probably get this also okay so finally we'll do all this Steps step by step okay now let's quickly go over here and I've already done the installation let me clear the screen now you may be thinking Krish you are not a front end developer how will you write the stream late code on the Fly I will never write I will use chat GPT I will use Google B I'll say hey give me a stream L code where I have an image upload button where I have one text input box and I have a submit button I will write like that okay so let's go ahead and write my code okay so first of all I will write it over here invoice extractor okay now first of all tell me guys in my environment file I have my API key right how do I call this how do I call this environment variable right so for that I will be using from EnV import load uncore Dov okay so I require this load. EnV what this specifically does load. EnV it will help us to load all our environment variables right but for this I need to install it so here what I will do I will go to requirement. txt I will write python. EnV right and I'll save it again I will go to my terminal okay and I will say pip install pip install minus r requirement. tht so this installation will take place and finally you'll be able to see the python. EnV will get installed so here you can probably see the installation has been done now it will not give us an error whenever we try to load this EnV okay so we have specifically done this okay now after importing to load all the environment variables we will use this function which is called as load. EnV so here it will take load all environment variables from dot EMV okay clear everyone yes can I get a quick yes yeah I will show you everything don't worry follow along with me I will try to show you how you can convert image into bytes how you can get the image info everything as such I will show you okay okay everything I will show you but here till here I hope everybody's very much able to understand and they able to understand in a very good way okay clear okay perfect so let me go to the next step now and we'll discuss further like what we are specifically going to do now after this I will go ahead and import streamlet as St so we are going to use streamlet as we imported that okay we will import OS because I need to call my environment variables so here I'll be using OS and then since I'm using images I will use from P import image okay this image will actually help us to get the info from the image okay now as you know from the requirement. txt we have also installed Google generative AI right so we will be importing importing Google do generative AI as gen AI okay so we are also going to use this specific thing that is google. generative a gen now as usual first of all you know that we need to load our API key right and we need to configure it so here for configuring I will write over here configuring configuring API key okay and here I will basically write gen do configure API uncore key and now where is my environment variable it is basically present in this specific key right in this specific key so in order to call this I'm already calling load. EnV so here I will write OS dot get ENB that is get environment variable get environment variable here I will go ahead and use my API key done so this way I'm able to configure the API key right yes everybody clear here right everybody clear so I hope you're getting a clear idea what we are doing step by step I've imported all these things I imported streamlet I have imported Os Os why I had imported because I need to get the environment variable right and this G environment variable is basically present INB file whatever name it will go okay now here you'll be able to see that I have configured each and everything okay so along with me you can write the code if you liking the video please hit like uh share with all your friends as usual because all the steps I'm showing you completely from scratch Basics because once you understand this it's your idea do whatever things you can do image detection image classification whatever images you want okay you can basically do it now done now my next step will be that I will write a function so I will create a function to load Gemini provision model and get response okay so I will create this function so I will write definition get gini response okay response and here I will require two important information one is the input right what specific input that I am basically giving okay second is image and third is basically prompt I'll talk about this what is this differences between this input and prompt because both are almost similar but prompt is something different and image is something different this prompt or this sorry this input will be the message that the llm model will behave like okay this prompt will be my input that I'm giving what kind of information I want okay so this three information I'm giving it over here now I will go ahead and call my model so I will write model gen Dot and here I will call my generative generative model so inside this functionalities basically to call that gini provision model I have to use the gen. generative model and here I will call my Gemini Pro Vision okay so I'm going to basically call this right gini Pro Vision and finally once I call this this way I will be loading my model so I'll give you a message over here saying that loading the Gen AI model right the Gemini model I can also say it as Gemini model okay now after loading it I need to get the response so I will write response is equal to and I will say model dot generate model. generate underscore content and here in a list format this is how you have to basically give the input to the model so in the list format the first parameter I'm going to give is input images will be in the form of list all the information we'll get in the form of list so I'll write image of zero comma it it'll be in the form of list and then finally I'll write prompt so once I get this information then I will return response and there will be a parameter inside response which is basically called as text so all this information we are getting it from the Gin right so what we are doing in this specific function we are creating a function which will load a gity provision model and then model. generate content will take the input and it will give us the response so here we are getting three inputs I'll talk more about these inputs what all it is and then finally we will be getting the response. text everybody clear yes yes everybody clear can I get a quick yes if you able to understand till here come on yes or no give some heart sign give some symbols yes no anything it is up to you yeah learning is very much important as I said so please give your spread your love right everywhere learning will be fun great now what we are going to do next step okay next step what I said see as soon as see this part is done if I talk about this part hitting through the Gemini Pro with all the info image info and prompt this is done and I get the response this part is done but this part is not yet done image upload convert into bytes and probably get this info this is not done so what we will do we will go ahead and write that function so here I will write input image set up and here I will say provide my uploaded file so whatever uploaded file I'm going to get I'm going to give it over here the image I'm going to give it over okay now initially I did not know the code for this okay how to probably get the uh image data in the form of bytes something like that right so what I did I I I went ahead and asked chat GPT and then chat GPT gave me this solution okay I asked it that I'm giving an image okay uh just a second I'm giving an image so if uploaded file is not none then it took this data uploaded file and it did dot get value from the dot get value it got the bite data and then it gave me image Parts in two different format one is the mime type and one is the data okay so don't worry I will give you this entire code in the GitHub repository if you want the GitHub repository also I can give it to you okay so here is the uh I'm I'm putting the comment uh so everybody body will be able to see the comment over there in LinkedIn also I think I will go ahead and put it okay so this will basically be the GitHub file okay so everybody will be able to see this okay so what we are doing over here we are taking this image we converting that into bytes okay then the image part will be based on two parameters one is mim type where the uploaded file. type is there and the data by data I just asked it to chat jpt and it gave me this specific answer okay and then we are returning this image part so by this what is exactly happening this part that you have created is completed see step by step we created this gin Pro load it this part is created image info we are specifically getting it now we need to get prompt and we need to get input okay where it is pasted in GitHub link so in vision. piy file you'll be able to see that the code is given Okay so so you can actually use it from there perfect everybody clear so this is my second task that I have actually done shall I go with the third task yes or no yes or no third task is nothing but it is basically our streamlit app so here you can probably see I will now create my stream L app see initialize our stream L app we use st. page config the page title is gini image demo so let's say I'm going to write some other functionality over here I will go and say uh image or invoice extractor okay this is a Gemini application I use one text box the text box this text box is nothing but my input okay input that I'm getting I'm giving what kind of information I specifically want from my from what what kind of input I specifically want from my invoice yeah that information and then uploaded file will be st. file uploader now here I'm saying choose an image the type should be jpg jpg PNG if you want PDF you can also write PDF over there but the format will be little bit different so I have created a file uploader over here and I'm saying if uploaded file is not none then what will happen it will open the uploaded file and it will display the file over here it'll display the file over H image right so some amount of knowledge in streamlet is required for this if you don't have knowledge be dependent on chat GPT because this code entire code was given by chat GPT okay so here what I did I used an input box I created an uploader file for image and then I'm displaying the specific image as soon as the upload is done okay so this three input information I did it okay and finally I will create a submit button and I will say St do button and here I will say tell me about the invoice done and finally I will give some prompt I I I need to say I need to say how my Google Gemini pro model needs to behave so for that I will give some kind of input prompt and I'll say hey let's say I'm going to use multiline comment and here I'll say okay let's give a message a default message you you are an expert in understanding invoices okay you will receive you will receive input images as invoices I'm writing a message and you will have to answer questions B based on the input image so I'm giving some prompt right some prompt template like kind of stuff so that I'm saying hey you need to behave in this way okay you are an expert in understanding invoices you will receive an input image and invoices and you'll have to answer question based on the input image right so this is my in by default you can basically say a default instruction to the gini pro model that you need to behave like this okay now finally if submit button is clicked now what should happen now let's go ahead and understand with respect to this when this submit button is clicked first of all the image should get converted into bytes I should be able to get the image info then image info along with the prompt should hit the germini pro model right this is what we really want to do so here I will say if submit if I am submitting if the submit button is clicked first thing first what I will be requiring my image data the image data will call which function this function only no input image setup okay so here it will basically call the input image setup and here we will go ahead and write my uploaded file right the uploaded file that I get and now I got the image data right now all I to need to call is my response and I will go ahead and call my get gini response and and here I will give my three information what three information is basically going uh over here input image data and prompt so input is uh this input prompt so I will copy this then you have this image data image data okay this image data you have and third one is basically what is your input right so your input is over here so what whatever input you are basically writing in this okay so all this three information has basically gone right so I hope everybody's clear with this and finally I get my response right now once I get my response all I have to do is that display this specific response okay display this specific response so for this I will go ahead and write St Dot subheader and I will write the response is and here I will write ht. WR and here I will display the response okay whatever response is coming over here let's see excited so done the project is done so there is three functionalities one is this one is the image processing then one is simple streamlit app creating your input prompt and done now shall we run this how excited are you will we get an error or shall we just directly run it tell me should we run it or shall we run it everyone so let's go ahead and run it so here I will write streamlet run app.py so I'm running this allow exess and here we go do you see this everyone yeah now let me go ahead and browse the file one of the invoice that I downloaded it looks something like this see am I able to see the sample invoice right Cho let's see bigger information it will obviously be able to give it okay okay let's take out this information can we take out this information what is the deposit requested in the invoice let me ask what is the deposit requested come on you can see the answer what is the deposit requested okay so I will just go ahead and this is my prompt that I'm giving now I will go ahead and click on tell me about about the invoice now let's see whether it will run or not so it should be able to give me the answer it is running do you see the answer 169.99 yes or no right let's go ahead and see something who is this invoice build to who is this invoice build to and I will go ahead and click on tell me about the invoice so who is this invoice build to who is this invoice build to let's see it's running L by answer low see all the same information good now tell me how strong this is you see like do like Give Love share love spread love yeah any more question okay let's try multil language Hindi invoice format let's try some Hindi invoice no let's save this will it be able to work Hindi invoice let's go ahead and browse it yes we can also save the data anywhere we want in databases and all okay how many of you know Hindi response times took little long yeah we can optimize it it is a free API no okay let's let's ask some complex question in Hindi okay I will ask in English only what is the HSN see over here you find HSN HSN is over here right of Lenovo 5125 I okay what is the HSN of Lenovo Lenovo the item I'm writing in English see Lenovo 5125 I 5125 5 I let's try tell me about the invoice we can optimize this if this is the format right we can optimize it do you see this number is it same 301 0 yeah so I know in many companies they'll be requiring this see it is written in English Hindi okay let me just go ahead and write what is the billing address okay what is the billing address okay tell me about the invoice right tell me about the invoice take SCB building building defense State Gino Maharashtra see all the information is here good enough see Maharashtra also it is taken right okay see dinak is written now so let's see I will write what is the date of the invoice what is the date of the invoice tick 1227 0221 good now try any invoice let's see what is the cgst okay let me go ahead and write what is the cgst let's go ahead and see about the invoice there is no limit of the image you can upload as cgst is 80% where it is written okay it is given see okay GST 18% is the cgst is 18% okay okay uh let's see what I'll write what is the total what is the total bill what is the total bill I'm just writing anything let's see where it tries to yes yes you can do 500 PDF 100 PDF in my next session I will show you working with PDF okay 1 170 392 see guys amazing right so yeah 500,000 how much you all results got correct sir yes yeah nag as I'm saying any number of pages take one lakh pages also it is possible there we can use Vector database to save it so guys good video hit like shower Your Love share with all your friends and this was about today's session so tell me how was the session see at the end of the day okay one more thing that I really want to share so that you don't miss things so guys uh we are happy to introduce one amazing course for you that is regarding generative AI so we will be building this kind of application we show you how to do the deployments and all so this is the mastering generative AI course you can go ahead and check it out in ion. page okay so I'm giving you the link in the comment section if you like it please go ahead and watch it so here we will be developing all these kind of projects we'll be using Google gini we'll be using open AI Lang chain Lama index you can check out and again at the end of the day mentors you'll be seeing myself Sunny bappy so everybody will be taking a part of it if you have not seen the community sessions in Inon so definitely go ahead and watch out and see the talent of all the mentors that are there but at the end of the day the projects level that we going to develop is much more complex with respect to this so go ahead and check it out and if you have any queries please do call to our team counseler team which is over here in the bottom of the page you'll be able to see them right and uh anything that you have a queries regarding you can probably contact us okay so this was one of the thing not only that if you are interested in learning machine learning deep learning anything as such or data analytics we also have that there's also mlops production ready projects you can also join that okay so yes this was from my side I hope you like this particular session my final takeaway is that uh in the field of AI it is it is really really evolving every day you really need to learn if you think that you're just going to learn today get a job tomorrow and after that your learning stops that is not at all possible Right learning is continuous and you really need to learn continuous you need to find out ways you need to find of creativity in doing the projects and uh at the end of the day you work for the benefit of the society right so uh this is the main and amazing thing that I have probably seen in this AI field is that the amount of learning is amazing it is quite well and the kind of things that we have actually done right in the AI field like everybody throughout the world right it is amazing right I I can definitely say like it's wow okay so uh yes this was it from my side at the end of the day I would again suggest uh keep on looking on different things that you can do with this just imagine today we just did this entire invoice extractor tomorrow you can think of multiple use cases think in the different domain Healthcare domain right and uh let's see where you'll come and definitely do share this content everywhere in LinkedIn show your talent show your things what more additional thing you can basically do on top of it okay so yes uh this was it from my side guys I hope you like this particular session if you liked it all the recordings will be available also I would suggest please see in the description of the YouTube channel all the community link will be given over there uh and if you want to learn any qu any courses from us you can check out in. page and I will see you all in all the sessions and class till then I will see you all in Next Friday with one more amazing sessions where we'll discuss more amazing use cases this was it from my side have a great day byebye take care keep on rocking keep on learning thank you everyone and yes at the end of the day keep sharing your knowledge with everyone right uh okay so sir please tell me if there is any prerequisite for this course don't worry about any prerequisite it will get handled only thing that you really need to know about generative AI is about python okay so probably When You Learn Python if you uh you need to have some amount of knowledge of python for that also we have put recorded videos in the course so that you can actually check it out okay uh thank you so much for your wonderful efforts thank you thank you thank you uh how can we integrate into databases and then ret information that I will show you in the next class we'll use some kind of um uh we we'll try to use some kind of vector databases okay it'll be fun it'll be fun it'll be amazing okay okay let's see some more okay I'll take some more question sir every time we click on run it trains the model with the image provided then extract no it need not train itself the model is already trained so you give the necessary bite information over there it'll be able to extract all the details like OCR right excellent session thank you sir as I said how can we integrate with databases and we will be using Vector databases okay that I'll show you in the next class it'll take one hour session yes sir we have a lot of learned from Krishna thanks to give top knowledge sharing with us thank you I really enjoyed my Friday evening with this new learning every day like every Friday I will come over there and I'll teach you something okay it's okay so please try to learn from others also because there is some experience that is basically displayed over there okay NLP is important to learn generative AI yeah so let me just share my screen again so that you get an idea if you probably see what all things you'll be learning so if you go ahead and see our generative AI course sorry this is machine learning boot camp so in the generative AI course the prerequisits are uh only python is there and we will be teaching you all NLP so this is basically NLP we'll be teaching you all these things right uh NLP NLP NLP so basics of NLP then we'll go with RNN and and we'll try to learn this okay guys the team has shared some Link in the chat let's see so which are the best books for genda see guys I not suggest right now to follow any books because this is not fixed every day some changes are there right so guys there is a temporary URL link that we could see over there let's see I think uh NLP is important to learn generative AI new comments can you make an one end to tutorial on rag yes I will do that in the next class okay perfect so hit like guys if you like this session and uh there are lot many things that is probably going to come in the future okay sir say up data scientist B so this question is good enough sir dat SST this is just for testing purpose guys in front end there are lot many things other than this Okay click on the link and join the session with Chris sir link so this is the link right is this the link okay uh so we are not getting any notification about jobs see guys jobs uh things like how you can specifically apply And all I'll will be discussing more about it as we go ahead okay um just give me a day session time I'll probably talk about this with respect to resums with respect to building profile and all so all those things I will discuss okay can we do prediction using tabular data in gen what kind of predictions is it something related to text text you can basically do it okay anybody wants to join this session yeah prakash if you have any questions please do let me know you can you can un mute yourself if you want to talk yeah Prashant do you want to talk sorry prakash he got disconnected okay okay perfect uh are you adding feret in course I will just try to see that think the documentation that is available and I think this is an llm model from Microsoft I guess right so Mahesh has joined Mahesh do you want to talk anything yeah hi sir it's a pleasure to uh talk to you yeah hi hi mes yes please tell me you want to show your face you can also on your video uh so actually I'm not in a position to show my face uh I'm me outside uh actually I'm a student of in neuron and to be frank sir I'm just I was just clueless initially when I started to learn this uh data science part so again my education background is I'm from biology mhm okay so I don't have any background on mathematics but but to be frank when I just started to learn the things from in neuron so without any uh excuse me so without any um knowledge on mathematics also I still I'm able to learn lot of things and I can just I'm just getting more confidence when it comes to data science topic as well as I'm just getting more confidence so that I can just get play in future mhm mhm so you're saying that how first of all how is your learning things going on right now yes sir I'm just uh building in projects and uh I started to implement melops in my own architecture means like implementing the mlops from scratch sir I just did are you are you working somewhere right now yeah I'm working as a data analyst but my working nature is not exactly as data analyst but somewhat similar to data analyst okay my suggestion in this case right uh in your current company if you see any ideas and if you see anything that is probably coming up right try to participate in that try to see that what all things you can basically do over there you know try to see whether you can apply any data science knowledge because that is the experience that you can probably put as a p project in your resume right and later on with respect to with respect to that kind of work you'll be able to tell that in the interviews right in any interviews that you specifically go yeah yes sir and um I just want to thank you for uh being a good Mentor and I'm really thankful for anuron for giving me S such an good support in my career so I'm just always talk so I'm really excited I'm not able to talk okay no worries no worries so drink some water and be chilled okay and keep on working hard okay thank you sir thank you very much hello I am so much excited to talk to you uh your your videos are so much uh informative and uh I'm really uh glad to talk directly with you like this uh I used to follow your ml series and DL series and uh they're very informative I have enrolled to gender course also uh just I would like to uh know few questions sir um please kindly answer I'm um I'm poor at a data stres and algorithms uh will that be uh requ for this generate course may know please no no no no it's okay like basic inbuilt data structures will be sufficient um it's more about how you can use generative AI to solve applications right Basics that is specifically required you need to be good at that for cracking interviews okay okay I'm I'm six years of experience as a tester uh okay uh is it okay just means if I get into this field does companies accept my profile as a tester and switching to this uh transforming to this carer as a tester whatever projects you're currently doing make sure to apply some data science stuff over there it can be automation it can be anything as such because that same thing you'll be able to explain in the interviews okay yeah yeah okay sir thank you so much sir yeah thank you one more question fet Apple released one fet llm right are you going to add this in general a course uh fet right now the entire documentation is not available so once let's say once we probably go and we see lot of use cases then we'll try to add it okay okay sir any update that will probably coming then and there we'll try to add it okay okay sir yeah thanks yeah thank you yeah yeah Mahesh please unmute yourself yes sir sir is this session being recording yeah okay fine and uh sir is there is there any option for me to visit anuron so that we can just meet um yeah sure you can come Inon in the working days right yeah Monday to Friday anytime H yeah sure sir okay so that I can just uh talk to personally so uh maybe maybe within that within two or 3 months I might be getting uh place I'm applying for the jobs so once I just transing means I'm just placing in a new company so I'll be coming uh to IUN and directly meeting to you okay sure sure sure definitely okay you thank you much yeah Danish SA you can unmute yourself yeah hello sir yeah hi yeah yeah yeah please is it okay for students thank as a fresher M definitely sir I want to sir may defitely be there and thank you so much for sir thank you thank you yeah thank you definitely thank yes thank you sir thank you thank you sir yeah yeah thank you okay uh Joy rubul P questions please P Jo sir from past three years I'm following your YouTube channel sir M uh Mission learning I studied your mission learning sir my my aim is I'm following generative AI course now sir can you please provide a free in your YouTube channel sir 8,000 is too much sir for us so that's why I'm asking sir anyhow sir we have done live Community session about generative AI a lot of free content we have uploaded already and more free content whatever will be coming we still be uploading don't worry about it sir okay yeah but llama model these models is not uploaded in your YouTube channel right sir it will get uploaded sir give some time then we'll try to upload that also but it needs to take time no sir we also need to create uh we need to get time for recordings and all we'll be doing that kind in live session let's say next Friday I'll do about llama index and all okay sir uh M course era is there now sir which which course we want to follow out for generative AA llm models because I am the beginner of this I learn machine learning from your YouTube channel if I follow want to follow course era which uh because course era is offering for our University free so that's why I'm askre sir I did not check out corsera all the courses sir yet you know I did not check it out like which one is there but I think some or the other will you'll be able to find it over there sir okay but I did not check it out and that is the reason I I usually learn from documentation githubschool but I don't have any idea about corsera Sir okay sir thank you sir while you are while you are explaining in your YouTube channel sir first explain the documentation for me also so that next time we will read little bit the documentation while we are reading the documentation we did not get the content if you tell the keywords now then only we will understood that we will digest while we are I mean reading the research paper like that sir sure sir sure I'll do that sir sure thank you sir okay yeah next question yeah please go ahead yeah very big very big thanks for thanks to you uh so I I am your fan since you started I new run so after that only I come to know that you are teaching so many uh courses belongs to a machine learning everything so initially I'm worrying about which one I need to choose so whether I need to choose machine learning or whether I need to choose that and so I want to learn in multiple things but I cannot on single things okay by luckily uh my my in my work space I have a opportunity to work on gener P one years when the open a released okay sir so I know something about that so I I know something about the open a what are the features it can do so I have a handon training on that one so now you announce this generative a course so it will help me a lot so I'm choosing your way that I need to break a leg on this General ta so I admire you and I like your videos so I already purchased your course so I am excited to start on January 18 onwards so very big thanks to you but what you are um so I'm learning like a surviving language only so whatever the whatever the mean my Works needs so I'm go and picking those kind of stuff reading the stuff then I'm working on it like the way so whatever the things you example you saw in today's session I have have completed those scenarios when the J announced that you can use you can build this application on WE that you you put some video right the next day itself I explored all the things so only that I'm excted to do is that video part only but nobody I don't see any video video paring yeah video paring yeah yeah don't worry we will I'll create a video on that also so don't worry okay so exact exact to work on Inon no sir our data science team has already done that okay okay super passed 20,000 videos so we have created a support system which is pass 20,000 videos for the support Channel very great very great to know I ex from you yeah we'll speak to you sir thank you thank you thank you for yourk you thank you for your s and you are you are boosting our confidence more more thank you thank you prashan thank you yeah kimah yeah hello sir hello hello H hello sir I am from Pakistan yeah hi hi sir I'm your big p and I I have a question I am a student of electrical engineering and I want to learn machine learning and deep learning I want to Chase your course uh uh which course you would suggest for me sir just go to ion. website there will be a counseler number okay uh just try to contact them in WhatsApp they will help you out with all the information right there is a ml boot Cam that is probably coming up you can join that course that will be completely from Basics okay so there you can probably join that but again go to ion. for more better communication I think you can contact the there'll be a number for The Counselor or you just fill up the form the counselor will try to contact you sir oh thank you sir yeah thank you thank you yeah Dean josi sir sir hi uh sir I'm engine I'm btech engineering first year student and my specialization in AI n DS so I'm I'm asking with you that sir AI in the AI my college was not studying this AI specialization they were already uh the basic languages python uh C+ and this then sir I'm what language I'm beginning to start begin to start so uh are you guide me for the AI and DS and the best okay so python is the programming language you have to probably start with okay in this field because nowadays the cloud platforms everywhere the libraries everything is something that is related to Python and that is only coming up in the future okay yes sir sir can I speak in Hindi h z z I'm not in the proper way to speak in English yeah yeah it's okay Hindi a only in jaur skit College only a but I'm watching Dr starting beginning tops sir mainly basic B right okay sir yeah thank Youk thank you thank you yeah Aman Kumar Helm yes sir J sir J jind by dat science machine learning learning UK based remote job but machine learning deep learning basically data entry or some research work or LCA related basally data science machine learning full start applying for both preparing for government job I started learning about data science data analytics okay sir internship like we will get like free free internship 11a descrition okay sir sir okay thank you sir thank you sir hel yeah go ahead yes uh good evening it's good morning here in the United States I hope it's okay that I'm not from India I wanted wanted to thank you for the the videos you posted for Gemini Pro I I did all of them and I was on the road so I couldn't watch this one um or follow along but I will watch the recording and do it as well I subscribed or I enrolled to the class the master class that is coming up so wanted to ask if Gemini Pro will also be covered yeah yeah we'll add that up because see any updates that will probably come up with respect to any llm models we'll try to update that okay and which we feel that it is important and it can really be a breakthrough for developing my application we will keep on updating it wonderful one other question as far as machine learning deep learning NLP it sounds like NLP you're going in depth to some quite a bit will there be any machine learning or deep learning that we should study up on before the course uh whatever is the prerequisite we'll try to teach in the course whatever is necessary for that okay but again at the end of the day if you really want to become a fullfledged data scientist who has capabilities of machine learning deep learning and generi I think you need to also learn about machine learning and deep Lear SE okay to that point I'm I don't think I'm I want to become a machine learning engineer I want to more be on the on the front lines creating applications but I want to know enough with what I do I don't I don't have any uh computer uh programming background I just started learning pythons you know four months ago then this course will be perfect for you I think uh then then you don't have to probably work worry about that it depends on the kind of work that you're specifically doing okay wonderful well thank you very much again really appreciate it thank you thank you sir so when will the course start I think you can go ahead and check out in the course dashboard uh the dates are basically given it is 28th Jan 2024 ni okay guys so because of time constraint it's almost 10 uh this was it from my side I hope you like this session I hope you liked it uh please do make sure that you hit like share with all your friends share your learning develop the application from your side I will see you all in the next video next Friday session we'll do some more amazing things we'll try to use Vector databases we'll try to create more projects and we'll implement it some same thing so thank you have a great day and keep on rocking keep on learning and have a happy weekend that is coming up thank you guys byebye take care perfect uh now let's go ahead towards the agenda so what is the agenda of this particular session what are we specifically going to discuss right and uh what is the end to end project that we are going to develop over here so it is very simple the agenda is that we will be developing a text to sequal application or I'll say llm application now just by the name you think that text to sq may be simple here we will be having a specific database we'll write some queries we'll insert some records and then we try to develop llm application wherein the main task of this llm application will be that take the text whatever text or prompt that you give let's say I I ask uh hey tell me tell me in this particular classroom how many students are there right so this text will be sent to the llm model and here the llm model will be Gemini Pro okay and this Gemini pro model will specifically give you a query right and this query will try to execute and read from my SQL database okay so this is the entire project that we are going to do right we need to have a c database we need to have a table over there and this entire project will be buil in this specific way itself right so this text that you will be seeing this is nothing but it is a prompt okay so this will be my input prompt in English language and then this will be sent to the llm llm is nothing but our Gman pro model this will in turn convert this into a query and then with the help of SQL libraries we'll go ahead and hit the SQL database and get the response okay so this is the entire agenda of this specific project and we'll also try to see how we can actually deploy this okay so everybody clear with the agenda what you are going to do in this specific project itself yeah can I get a quick yes if you are able to hear me out I hope you are able to understand this project that we are going to do and this is is going to be done by Google gini pro okay we will do the line by line coding from scratch so just give me a quick yes if you got the entire agenda of the specific project yeah and we'll develop part by part so just quickly give me a quick yes guys come on come on be somewhat active you know you need to be active then only the session will be fruitful okay so I would suggest please be active and try to say yes give some symbol give some thumbs up that would be quite amazing okay perfect so let's go ahead and let's start this particular project now here how we are going to implement things right implementation part so the first step what we are going to do is that you can use any SQL database as such here I'll be suggesting to use sqlite so that we'll be able to show everything in the demo itself and this is just not restricted to sqlite or SQL database you can also do it in a no SQL database you can do it in Cassandra DB you can do it in mongodb whatever database you specifically want second uh we'll do this setup we'll insert some records okay we'll insert some records and again this all things will do with my Python programming language okay so Python programming language will be used to do this the second thing after we implement this we will start creating our llm application and inside this llm application we'll create a simple UI where you can specifically write the query and this llm application will probably communicate with gini Pro and then it will communicate to the SQL database to give us the answer okay I just written two steps over here so you may be thinking that this may be simple but it is not that simple you will be seeing there will be a lot many things that will probably be coming over here okay and uh uh again at the end of the day please code along with me uh see what all things we are specifically writing in this what all requirements are there you know and step by step we'll go ahead and do the implementation perfect uh so everybody has got the agenda and the implementation part so let me go ahead and open my vs code okay now for opening the vs code over here you'll be able to see the first step you know when we start any project is that what we really need to do please answer someone we really need to create a environment right now a interview question may come for you like why you specifically require environment or why do you create an environment for every project that you probably create right there's a simple fundamental in this is that every project has a different dependencies you really require different libraries over there right so that is the reason you have to create different different environment for this again create an environment I will just go ahead and open my terminal okay so this is my terminal you can also do it in Powershell you can do it in command prompt so the first prerequisite is that you really need to have Anaconda installed okay so here is my uh in this particular location I have my project so let's go ahead and quickly create my environment so go ahead and write cond create minus P VNV python okay always remember as I said that Google gini pro works well with 3.10 right sorry greater than 3.9 version so that is the reason I'm going to use 3.10 and it is going to ask me for a not request saying that whether it should go ahead with the installation or not so I give that preand that symbol AS why why basically means yes so let me quickly go ahead and create this so you also can parall start creating it guys okay go ahead and create it uh everybody go ahead and create the environment itself so be work along with me then you'll be able to understand everything go ahead and create the environment and let me know once the environment is created come on and hit like if each and every step you are able to work out and at the end of the day I will also give you the entire GitHub code so that you'll be able to see it okay so quickly just tell me whether you will you are able to create a new environment or not I'll wait I'll wait slowly uh like I want everybody to execute it and probably you can go along with me and you can actually execute each and every line of code along with the project okay so at the end of the day I don't want you to just see the code but also Implement along with me okay so perfect over here so nanu is along with me he's also implementing things that's great everyone come on create the environment along with me and give a quick confirmation if you are able to do it okay there are 64 people watching I want everyone of you to do it along with me come on quickly let's do this okay great so in M done okay okay sir yes yes yes okay so I hope everybody has done the first step now as usual I will go ahead and clear the screen and now what we are going to do in the next step is that here you'll be able to see my V andv environment is created okay in this specific environment we will go ahead and start installing all the libraries so for this we need to activate the environment so I will go ahead and write p activate VNV right so cond activate VNV I'm giving this specific folder location over here and once I execute it here you'll be able to see that my path has changed now it is inside my VNV environment okay so this is the second step step by step we are specifically doing it so please participate in this start implementing things you know give me a confirmation it would be really great okay sir can was this actually I could not complete ml it's okay you can also watch this the prerequisite is only python okay uh perfect so this is done which application you are using what do you mean by application I'm using a vs code so there only I'm probably writing the code itself okay perfect so done we have activated the environment now let's go ahead and create our requirement. txt requirements.txt file okay now requirement. txt what it says it it basically says that what all libraries I may specifically require you know so for this let me go ahead and write all the libraries that I'm actually going to use one is streamlet okay because we are going to create the front end with streamlet the other one is Google generative Google generative AI now this Library also we require because at the end of the day we are going to use Google gini pro the another one is python. EnV now why we require this Library so that we can load all our environment variables and as you all know that we are going to create a Google gini pro uh API and then we are going to insert that in our environment variable okay um along with this uh I think this three libraries will be more than sufficient to start with perfect okay great so this three libraries I'm going to use over here now once I have actually written all these libraries over here then what I'm going to do is that go ahead and write pip install minus r requirement. txt okay so once I go ahead and write pip install minus r requirement. txt you'll be able to see that all the installation of all these libraries will happen okay and this is actually happening in the v EnV environment so please go ahead and do this step create your requirement. txt and then after that start doing the installation and this is the basic initial step that we really need to do in every project so till here everybody's clear give me a thumbs up give me some symbol some something laughing emoji right hit like and if you have chances call all your friends in this live session okay come on this kind of sessions you'll not get it anywhere live that also I'm coding along with you live so that you understand all these things come on so great sir all of the requirements for this project are free yes absolutely free you don't even have to put credit card that much free okay so uh the installation is basically happening please let me know whether the installation is done from your end or not okay and hit like come on you need to probably see the entire session and code along with me that is the main purpose of coming life you have to code along with me okay so this was one of the question sir all of the requirements for the projects are free yes it is completely free I believe in open source so that you don't have to pay anything over there okay perfect the installation has been done we are good to go over here now great can you give me a thumbs up if the installation if you have done at least partially you have done the installation come on let me know great now we will go ahead and create ourv file now for our EnV file environment file we require Google gini pro API okay so what I will do I will quickly go ahead and go to this website which is called as maker maker suit. goole.com slapp API key okay I just change my email ID because I've created my API key and another email ID okay so go to this particular website which is called as maker suit . google.com /a/ API key okay all keys needs to be put yes so just go ahead and click on this create API key new project so this will basically create your API key for Google giny okay so go ahead and click this right once you probably click it you'll be able to see this kind that is getting created the API key I've already created it so I will go ahead and copy it from here okay so I have copied it from here okay so everybody are you able to do this step just let me know and if you're following let me know okay I want everyone of you to implement along with me please that is a request then this session will be fruitful okay if I keep on teaching like this if if you say that no I'll do the implementation later on trust me later on nothing will happen you not be able to do it you know if you give excuses and keep on postponing things uh that will not work out you know when you have an opportunity when you're seeing this live please go ahead and Implement along with me great so can you add the link okay perfect let me go ahead and add it over here let me go ahead and add from stream key okay so I am adding this link over there perfect is everybody able to see the link now yeah yes yes great now from this link you have to create your API key once this is done go to the environment variable now and now for this API key you really need to create a key itself right so how do you create a key over here so here I will keep it in the form of key value pairs so here you can see that I've use the key that is Google API key and then this is my key that I've actually copied it from there okay so please keep in this format with respect to the key value pairs okay and initially you definitely require this because if you don't have the right key your application is not going to work perfect great now this is done our environment key is set we have activated the environment we have installed all the requirements okay now let me go to my notepad now the first thing with respect to the implementation as I told you that we will take a database like cite right and we'll insert some records to just show that there are some records there is a table there is a database there is there is a sqlite over there you know so that you can query you can query from those particular SQL database itself okay so for this what I'm actually going to do quickly I'll go ahead and create one file let's say this file name is sqlite dopy okay so here I'm going to write my code and this code will be responsible in inserting any records in the sqlite database okay so I'm going to close this over here and now I'm going to start writing my code and remember one thing guys over here whatever code I'm writing this is something also this will also help you to understand how we can connect python with sqlite and how we can insert records and all okay so first of all uh to start with I'm going to import sqlite so sqlite is again a lightweighted database okay sorry sqlite right uh three so we are going to by default in Python 3 right you have this imported already okay now we will go ahead and connect connect to the cite database okay cite database now for this I usually write the code AS connection is equal to I will go ahead and write connection connection is equal to sqlite 3 do connect and the I will keep a database name let's say the database name is student. DB okay so this is my database name I'm going to create my database in this specific name okay so in short what we are doing is that we connecting to this particular database so if this database does not exist okay then it is going to create this new DB okay so this is the first step the second step is that we'll create a cursor object to insert records to insert and create tables let's say to insert records or create table because inside a database we going to create a table right so till here I hope everybody's clear what we are specifically doing because this will be a this will be another py file which will be responsible in creating your database it will also insert all the records okay so please do along with me so that you'll be able to understand perfect now what we are going to do over here is that quickly we will go ahead and create a cursor object so for this we will go ahead and write cursor cursor is equal to connection connection dot cursor so that basically means inside this particular V database connection right whatever I'm basically using this particular function this method will be responsible in traversing the entire table going through all the records and all whenever we try to insert or retrieve the records okay so this method will be responsible for doing all those things now we will go ahead and create the table right now with the help of this cursor object we will try to create the table now here will be my table info let me go ahead and create my table info and I will say this will be three columns okay and let me start writing my query name so here I will say create table student I'll try to write it in capital letter and inside this I will use first first parameter or first uh variable right name and here I'm going to use this as we care and let me go ahead and write to 25 character so that basically means name is a field okay and in that it supports variable character you can write numbers integers uh values string anything that you specifically want to write so this will be my first first First Column you can basically say in that way in that particular table second one is let's say I go ahead and uh go ahead and write something called as class okay so I'm writing the student information in which class he or she may study um and this class will also be a Vare and inside this I will go ahead and write this will be my two 2 25 characters okay and the third parameter I'm going to specifically use is something called as let's say I'm going to write this as section so this will basically be my section and here also I'm going to use my VAB and this will also be 25 character so once we do this we will close this entire command that the query that we specifically have so simple query initially we'll just go with simple one so that you'll be able to understand it so sqlite 3 wasn't in requirement file Yeah by default with python 3.10 cite 3 comes installed so this is going to work okay I've already tried it out fine we have done the table info over here and you'll also be able to see that now what I'm going to do is that I'm going to create this specific table okay so for creating this specific table I will go ahead and write cursor dot execute table okay so this this table info cursor do execute so as soon as this line gets executed this table is going to get created with the name of student okay perfect now we will go ahead and insert some more records okay now for inserting this records how do you write an insert statement so here I will go ahead and write cursor. execute okay let me go ahead and create this multiline comment and let me say that what is the command I will say insert into students student of student student values insert into student values inser into student values and the values will be the three parameters that I'm going to give name class and section okay so here I'm going to use the name as crish then let's say the section or the class that he is probably studying is data science okay and over here you'll be able to see I'm also going to use a section let's say section is a okay so this three information you'll be able to see as soon as I execute this will basically be inserting this record in the data science like with this information the name the class and the section okay so I will copy this entirely so this will be my first record second record third record fourth record five records let's let's go ahead and see with respect to five records okay here I will change keep on changing the data right now when I say I'll keep on changing the data that basically means I'm going to use my second record as let's say I here I will write sudhansu okay so Dano data science and I will say this belongs to section B okay uh let's go ahead and write more over here let me go ahead and write darus so Darius is also in data science SS and let's say he's also in section A okay I will go ahead and write one more record because let's say because is in another section which is called as devops and this is section A and let me go ahead and one more record like the I will go ahead and write thees and this time I will keep thees also in devops okay and let let it be in section A so this information I am probably inserting in in this specific table okay all this information will be basically inserted in the specific table now as soon as it is inserted we will display all the records okay here I will say print the inserted records are okay and let me go ahead and write data is equal to cursor. execute okay and let me go ahead and write this triple code statement so that it can be multiline also select star from student okay the table name is capital so once I probably execute this I will have all the information over here in the data and then what I will do I will write for Row in for for Row in data I will go ahead and print my row okay so this is what we are going to do so this becomes my entire query with the help of Python programming language where I am creating a database I'm creating a table I'm executing this particular table info I am inserting records I'm displaying all the records everybody clear with this can you get me can you tell me whether you're able to understand till here quickly come on let me know till then I I'll drink some water yeah everyone come on quickly yes or no sudu says yes Prashant says yes what about others come on guys you are not implementing is sad you know so if you do not show interest then there will be no of doing this live session right div also says yes what about others 84 people are watching please do hit like let's make it a target of at least 100 likes in this session you know because if this session we teach in some batch you know it'll be so fruitful for us come on we are doing this completely for free for the entire Community you really need to show some proactive measures okay either be active otherwise drop off if you feel that this is not important for you okay done perfect now let me go ahead and open the terminal and now this time what I will do I will execute this file and let's see once we execute this particular file that basically means uh we will be able to see our database that is created okay database that is created so in order to execute this file I will go ahead and write python sqlite dopy okay so if I execute this my data should get created my table should get created and at the end of the day so here you'll be able to see right at the end of the day One DB file should be created over here and the name should be student. DB okay so let's see whether we'll be getting any error or it'll just execute perfect the inserted records are chrish data science a sudu data science B Darius data science a vikash devops a the dev off say so student. DB file is also created that basically means my insertion has happened perfectly well right now all the data has been inserted into my DB and this is the student. DB file that you'll be able to see now this completes our sqlite insert some records Python Programming this completes our first step now in the second step we will try to create an llm application and now the same DB see that DB is already created now what my llm application should be able to do is that whenever I give some English text it should be able to retrieve the records from those database you may be thinking how that will be possible I will just show you just stay along with me and code along with me right step by step I will show you each and everything okay so just be along with me and just stay over here right so let me go back to my code and now I will start writing my code with respect to this uh in my SQL py file now this file will be responsible and again I'm repeating this file will be responsible for creating our llm application okay so let me go ahead and write first of all we will go ahead and import from EnV import load. envv okay and then to load all the environment variables I will go ahead and write like this and let me go ahead and write take environment or or load all the environment variables okay and that is the reason we have also installed those now the next thing is that we will go ahead and import streamlit as St we are going to import streamlit I'm going to import OS I'm going to import OS along with this I'm also going to import site 3 okay site 3 because we are going to specifically use this again and then I will go ahead and input from Google dot generative AI import gen okay so I'm going to use this gen and as usual first step is to set our API key so in order to sorry import as okay as J now in my next step what we are going to do is that we going to configure so here I'm going to write configure gen AI key okay so for this I will write gen do configure and here I'm going to specifically use my API key so here I will go ahead and write my API key is equal to OS do get EnV os. get EnV and here I'm going to give my key name okay so whatever is the key name and you know that my key name I've kept it as Google API key okay perfect everybody clear till here are you following everyone come on let me know whether you feel following each and every step yes yes or no so till here I have set up the environment variable okay now is the main thing that we will start our coding with so if hit like if you're able to understand till here and uh you're able to follow each and everything with respect to sqlite SQL everything that we have actually created okay perfect now let me go ahead and show you the next step what we are going to do over here now okay now we'll try to create a function function to load gen AI generative AI model or Google gin model Google gin model okay now one thing that you really need to understand two information will definitely go in this function right The Prompt that we are specifically giving and what the Google gin model needs to behave like right so over here I will create a function and I'll say getor Gore response and inside this response I will give my question and prompt like what what the gini pro model needs to behave like okay this prompt we will be writing question is the input that we are giving let's say if I go ahead and ask hey how many people are there in the data science batch right let's say something like this so so let me go ahead and create model is equal to gen do generative model so this will be my model Now understand one thing over here we're going to use gini Pro we are not going to use gin Pro Vision gini Pro is for text gini Pro Vision is for uh images video frames and all so here I'm going to specifically use gin Pro and then let me go ahead and create my response my response will basically say model dot generate content and now this is the most important thing I need to give two information to this right the first is that what the model should act like so for that I will go ahead and create my prompt I'll give the first parameter as prompt and this will go in the form of a list so prompt the second thing that I'm going to probably give is my question okay now I can also give multiple prompts if I want okay that also I will try to show you like how multiple prompts can also be given okay so this is what my model is B basically given so I will go ahead and write return response dot response. text okay so here this entire information so this model will be responsible in giving the query okay let's say if I say that hey how many people studies in the data science batch or data science class so this entire function will be responsible in giving you the query so function to load Google jiny model and provide queries okay as response so this is the function that it is going to do understand one thing right because first when we hit when we write any input our llm model should be able to generate the query and then that query will get go and hit to the cite database where you get this response right so I hope everybody is able to hear till here right so guys there is no such prerequisite for Google gin Pro you really need to know Python programming language and you should know how API is basically used over here right so can I get a quick yes if you're able to understand till here and why I have created this specific function okay just give me a go ahead and please keep on hitting like at least we'll try to make it 100 in the live session itself and understand at the end we are also going to have some live discussion you can come and ask me questions by voice and I'll be happy to provide a response to you okay now this is what we have done now second function that we are going to create function to retrieve query from the database okay so this is what we going to do in the second function so for this let me go ahead and Define my function so here I will write definition read SQL query okay the first parameter will be SQL right whatever SQL query this model gets create this model provides a response as and the second parameter will be my DB name right whatever DB that I have now if you really want to convert this into a rail World scenario we can just make sure that we can put our databases in the cloud and how to read it and all already so many videos has been created both in my YouTube channel and in ION channel also so you can probably go ahead and watch in that specific way but here the main idea is to integrate multiple tools and show you how powerful an llm application can be with the help of Google mini pro now the next thing will be that I will try to create a connection so sqlite 3 dot connect I will write and this connect will be with respect to my DB okay and then I will go ahead and create my cursor so let me go ahead and write con do execute sorry con do cursor I will try to create my cursor now this cursor will be responsible in executing our query right now what query the SQL query right and once I get all the results once I execute this uh uh you know the SQL query inside this itself C dot if I do fetch all it is going to fetch all the records with respect to that right so this is the prerequisite that you really need to know a brief idea about how you can work with SQL databases and this will basically be my row okay I will get all the rows over here now to retrieve or print the rows what I can do I can write for Row in rows I can print the rows so that you can also see the rows over here what all records I've been uh generated okay um the next thing what I'm actually going to do is that return all the rows okay return all the rows perfect everybody clear with this yeah yes so this is the the function which will be retrieving the query from the database so whenever I give a SQL so in short what is happening the output query that is getting generated by this model it will get sent to the database and from this database we will get the records okay so this is done now this is my function that is got created right now now the next step what we are going to do is that do our setup of a streamlet app now before doing our stre setup with respect to the streamlet app this will be the most important step that is defining your prompt so now we are going to Define your prompt now this prompt because of this prompt this entire application will work so efficiently trust me in that it will work very much efficiently right now what is the specific prompt that I'm going to create and as I said I can create multiple prompt so I will give it in the form of list okay so my first prompt let me go ahead and use triple quotes because it will be a multiple prompt itself okay I'm going to copy and paste one important prompt that I have written over here now this is the main game of the prompt guys without this you won't be able to write or you won't be able to make the llm work in a better way so here what is this prompt all about see you are an expert in converting English question to SQL code or I can also write SQL query okay converting a English text also you can write question also you can write to SQL query the SQ database has the name student and following columns name class and section for example example one how many entries of records are present the SQL command will be something like select count star from student right similarly I can go ahead and write example two let's say I go ahead and write example two so this is just one query understand one thing guys this is just one query right I can write like this multiple queries so this this is my example one okay let's say I copy this in a similar way and I go ahead paste it over here okay let's go ahead and write example two you can write many number of examples as such uh let's say how many how many people how many students study study in data science class if this is the query if this is my English statement query tell me what will be the command select count star from students or let me just change this okay tell me all the students studing in the data science class right so in this case what will be my query my query will be select star from student where class is equal to where class is equal to data science data science I have written it in small right where class is equal to data science so I will go ahead and write it over here okay so this becomes my query right and we will end this query also like how we have end it over here right like a colon something like this so this is also ending in this way right so now I hope everybody will be able to understand this yes you are getting it right and after this I'm also saying also the code SQL code should not have this kind of in the beginning at all I've given some more additional statement for the clean one okay does this make sense everyone yeah so this basically is your prompt okay and let me paste it over here so that you can also work accordingly with me so this is the entire prompt see okay this entire prompt has been divided into multiple sections okay just see to this okay but this is how things are I'll will give you some time go ahead and write this okay go ahead and write this because this will be the magic this is the most magical thing right and that is how you'll be able to see that how powerful these llm models are right so here you can see you are an expert in converting English questions to text or English text to SQL query the SQL database has the name student and has the following columns name class section for example this how many entries of records are present the SQL command will be something like select count star from student example two here you can specifically use in this particular way right clear everyone okay you want it in code share I will also do it in code share just a let me see whether I'll be able to see in code share or not but don't ch change the prompt okay and don't delete the prompt once I probably share it okay share so I will share the link everybody can copy it from there okay everybody got it in the code share yeah so in that code share I have given this entire thing you just can copy it from there and uh start seeing it okay clear everyone can I get a quick yes because this will be the most important step creating your own prompt right so please do hit like till here if you are able to understand each and everything trust me this is an amazing application by this you will get multiple ideas multiple ideas trust me in this okay so this becomes my prompt now the next step obviously the next step is basically to set up our our streamlit app so let's start our streamlit app and understand this prompt will tell Google J how it needs to add okay so first of all I will go ahead and create my std. Sate page page config and here I'm going to give my page title as text or I can say I can retrieve any SQL query okay so this will basically be my P page config and then I will go ahead and write s. header gemin app to retrieve SQL data okay now I've have given some examples guys see this prompt you can take it to any extent even write complicated queries you know once I probably show you the result you'll be able to understand why I'm saying like this okay now I will create a text box which will probably take the question from my side so here I will write question is equal to st. textor input and this will basically be my input let's go ahead and Define my input and key I'm going to write it as as input okay we can basically write any key according to you then we will go ahead and create a submit button only two things we specifically required submit button and let me go ahead and write St do button and here I can basically write ask ask the question done now if submit is clicked so I'm I'm using one field a text box and I'm specifically using one I'm using one text field text field and I'm using one submit okay perfect everyone yeah everybody good enough everybody can I get a quick yes if you're following everyone okay perfect simple now if submit is clicked I will go ahead and do all the activities that I specifically want okay great so let's go ahead and see the next step now in the next step if submit is clicked I will write if submit I will go ahead and write response is equal to get Gemini response and here I'm going to give my question comma prompt right now question comma prompt if I give this prompt is in the form of list so when I'm going over here I will just make this as prompt of zero the first prompt that I specifically want to give you can also give multiple prompts and by that you can give in that specific way let's say I have three buttons in the first button I want to behave it in a different prompt in the second button I want to probably behave it in a different prompt so here I'll write prompt of zero okay once I get the response I will say St do subheader the response is okay and then I will write for Row in response print row I'll print all the rows okay and if it is printing in my field let's say I will go ahead and write something like this St Dot header and I will display all the row elements over here done guys almost done now it's like whether this will work or not we need to check if it does not work we need to play with this prompt okay remaining all code you know see first step is probably taking with respect to get Gemini response based on question and prompt it will generate a SQL query and that same SQL query uh what will basically happen over here so question and prompt response what I'll get over here just a second I think um get Jin response generate content and then I have to probably go ahead and read my SQL query okay so just give me a second wait wait wait wait wait wait I will get the response and I have to probably call this read SQL query because here it is not getting called so I'll go ahead and write my response read SQL query now inside this SQL quy I'll give my SQL whatever SQL response I'm getting over here comma whatever is my DB name my DB name is basically what student. DB student. perfect now I should be able to get the response I guess does this look good everyone yep everyone second is the response of it response now let's see whether it will run or not DB is student. DB perfect now it is clear I guess response is also there this response it will go over here and do done now let me go ahead and run it and I hope so it runs absolutely fine if it does not run we'll try to debug okay so in order to run it I will write streamlet run SQL dopy so this will run let's see now here is the thing let me go ahead and write a require tell me the student name and data science class let's see I will go ahead and ask this question as you all know how many students are there over here in this particular class 1 2 3 so Kish soans and darus right so let me go ahead and execute this I hope so it works so I'm not getting the response so this is not good oh something is happening oh I did not receive anything why let me execute this once so the cursor did I execute SQL py so sorry it should be s equal py now just a second no it was working fine I guess let me see once again but last time we did not get anything tell me the student name in the data science class if this is not getting executed there should be okay operational where syntax the problem is coming let's see what kind of query it has generated let me print the query also print print print print the response okay I will go ahead and print the response let's see whether we are getting any error or we need to change okay so I'm just doing some kind of debugging guys so please be with me okay we will try to run this select the name of the student where class is equal to data science this looks perfectly fine select name from student name from student where class is equal to data science this looks fine when I executing this DB this DB is there student. DB response I'm giving it over here fetch all okay this is coming as an error let me see why this error is coming execute SQL current dot con. cursor SQL there's some error with the retrieving the query just a second guys connect DB DB name is this one let me see one second let me debug this the query is generated correctly when we hitting this particular database it is not working let me see test.py okay SQL dopy import sqlite 3 and I'm going to use this command let's see it will work or not cursor. execute select star from student let's see DB name is student. DB come on so some error in executing this let me open my terminal let's see whether this will get executed or not Python and once I execute this I will just go ahead and write this three records we'll just go ahead and print this records let's see python test.py from nothing is getting printed why is not getting printed now it should work let's see still not getting printed but it is getting executed select star from student but this record should be visible just a second I will just delete this once and let me go ahead and write python sqlite dopy the record is done student. DB oh student student student I'll close this requirement try printing line number five line number five oh this is fine now let me go ahead and write test.py still it is not getting printed that basically means is not able to read this why print rows let's try this also just a second can rows are coming as empty why student. DB is there I could see over here the insert statement has happened and is displaying all the records okay why it is coming as null select star from student is done while I'm reading what is the mistake over here select start from student I'll I'll try to fix it guys just give me a second select start from student c table info let's see no nothing is coming where did my database go select star from student is my student spelling wrong or what student we need to welcome this gu this helps us to the opportunity line by line yes student just a second guys let's fix this issue oh I feel there is one problem over here let me delete this once okay working for godam says working for me student. DB I will delete this let me create another DB over here wait I will go ahead and write test. DB let's see SQL py this is done now if I go ahead and execute test. py let's see python test.py okay sorry so this should be test. DB no it is not able to read why object is coming so some major error in connection. commit is that so oh is the cursor not closed so that I'm getting the problem I'll do one thing I'll commit the connection so print row and I will say okay I got a problem what was that commit your changes in the database con do commit so here I've have created my connection connection. commit now along with this I will also say CN do connection. close now I think it'll work so let me go ahead and delete this let me go ahead and delete this now I will go ahead and change my name to student now I think it should work I think I did not close the connection that is the main reason equal. py so this is done student. DB is created now let me go ahead and write streamlet streamlet SQL py no I think it should work definitely it should work tell me the students tell me all the students name from data science class let's go ahead and ask the question now let's see quer is Right 29th still I do not get the response now this is here also I have to probably close the connection I guess so let's close the connection here also so I did not close the cite connection at the end Connection cursor. close Okay cursor is over here we don't have to close the cursor connection if it is closed I think it is sufficient anybody prompt is giving the response from stimulate app this worked for me read the S rows for rows in print rows return rows so the same function I think I've written over here for Row in rows return rows so you have not close the connection now I've closed the connection I think now I think you should not have that issue anybody's facing this issue still now once I close the connection I have my student DB in my SQL I'm giving my student. DB cursor connection C for reading I don't have to probably do anything as such so this work for me yes still same data science Capital no no the query is getting created perfectly the problem is in this read SQL query I don't think so I need to write this but I'm just trying it out let's see sqlite May commit and close is done this is also done no no I have the data no so data is getting printed over here see so this was the data that was got printed right let's see once again rerun oh now finally now I get the response see so I just did this I just go ahead and write it okay so I have to close the connection over here also okay so now you can see Krish sudhansu and darus is visible minor mistake I can understand but again a good error to fix tomorrow if you get any error over here you can probably check it out okay everybody got this yeah all happy enough tell me any more queries tell me tell me the CL class where sudano let's say I'll say tell me tell me Sudan Shu I written his full name or not I think I've written just his single name right uh SQL py sqlite okay tell me sudano's class tell me Sano section let's say if I write like this ask the question see the b b section is coming over here and the best thing will be that you'll also be able to see what query it is generating select section from student where name is equal to sudhansu right and here you can probably clearly see right this is this is really really nice right so let's see what CL tell me the class of vikas and dpes whether it'll be able to write this queries also or not we'll see devops tell me the class of vikas and D devops devops see now how many queries see select class from student wear name in vikash and thees so this is good right see this kind of queries also it is able to generate now the more amazing thing we basically write in the prompt template right in the prompt more complex queries we specifically write and here you can probably see vas and thees was in devops right tell me the student name from section A Krish Darius vikash Dees everybody sudhansu is missing so sudhansu is another section I guess see sudhansu is in B section so did you like this project guys everyone so if you liked it please do make sure that you hit like and uh yeah between there was some challenges because I did not close the connection okay it is good to close this specific connection okay uh so close this connection make sure that you close this connection okay otherwise you'll get an error because see if you don't close this connection right the DB will be open right and uh there you'll not be able to do it now the most amazing thing is about how you write this prompt in a better way you can check with Google bar you can check with different different ways you know whenever you write a query you'll be able to and this definitely works for advanced advanc SQL queries Also let's say if there are two tables and all you can also probably write it over there tell me any query any complicated query that you feel that we can write and try it out um tell me all the students who are from class data science who are from section A and B let me go ahead and write in this way from section A and B I think this should this should be an easy one itself I don't think so it'll be the response is Krish sudans darus Vias dipes okay let's say if I probably go ahead and write one more column name like marks I can still write more complicated text over here right let's see okay fine marks also will do it okay so I will go ahead and create one more one more marks and this will basically be int and what I will do I will just go ahead and create this once again so let's say marks will will be over here as 90 100 uh darus I will write it as 86 because I will go ahead and say 50 the I will go ahead and say 35 okay so I will use this all and now let's see whether this will work I will delete this database control C C python site. py so the database is created now let's go ahead and run my SQL query so streamlet run SQL py now tell me what sentence should I ask tell me all the student name whose marks marks is greater than 90 so if I ask this query will it work sudhansu see sudhansu it is basically showing so let's go ahead and see the query greater than 90 how much I have got 90 see greater than or equal to 90 I sent and my name should also come right if I say greater than 80 uh there is one question hello from the generative AI course starting next week how often will the doubt section be checked I noticed the community version has not respond to often see right now we have come up with an amazing support uh system so every day within 24 hours you'll be able to get the response okay every day within 24 hours you'll be able to get the response so guys this is amazing right happy now you write any complicated queries just give some examples over here right so Kish sudans and Darius is having greater than 80 if I probably go and see what is the query that is generated here you can probably see select or I I I'll I'll just do something okay greater than greater than or equal to 90 and less than 50 let's see whether this query is also possible or not okay here now the problem is because we have not given those kind of scenarios I don't know what select name from student where marks is greater than or equal to 90 and marks is less than 15 this is good but the but the column name is is what let's see the column name marks I think this should have got executed oops select name from student where marks is greater than and marks is less than 50 okay both the condition is not getting matched less than 50 we had one right thees okay please ask to give rank on basis of marks tell me tell me let me do one thing Marx is greater than or equal to equal to 90 greater than or equal to 90 greater than less than 50 okay and uh less than so I have written the condition in a way that I have to reverse this okay till let's try this one tell me the student rank tell me the student name based on Marx rank let's see I try like this something like this again you can try multiple things so see sudhansu Kish Darius vikas and dipes this is nice let's see the query select name from student order by marks so previous condition I'll say tell me the student name where marks is lesser than 90 and greater than 50 see darus is there okay if I say marks is great greater than 90 or lesser than 50 let's try this also so danu should come and thees should come Perfect all good everyone tell me students having marks greater than also tell me the number okay yeah you can write this fetch me the topper of all the classes fetch me the topper of all classes see section B Sudan is the topper vikash why it is showing devops a branch yeah uh fetch me okay one more give me the third highest rank by sudano let's see give me the third highest rank third highest rank marks usually this is an interview question okay there is an error let's see what it has generated operational error mhm first I'll print the response wait over here some error has come over here so uh print response get Gin response select name from name section marks over by as marks from table as table where rank is equal to three so this is the problem guys right so let me write it in a better give me the third highest rank give me the name give me the student name of third of third highest mark something like this Darius right so here you can probably see Darius is coming now so this way so we also have to write prompt in a better way right so here you can see select name from student order by class limit 2 comma 1 so Q song says one more way of writing this query tell me how about tell me who is the third best student on marks Darius perfect so this is working really good oh my God this this is nice people are creative in writing prompts okay so this is can you provide a list of student categorized as first class if their marks are greater than 60 and categorize the second class if their marks are between 50 and 60 so let's ask this question first class Kish first class sudhansu first class Darius let's see the query the query is quite complicated in this so here oh big nested quer is there select case where marks is greater than first class then marks is between 50 to 60 second class else null nice see the output is coming up try to run the rank with the table name uh s give the query give the prompt it will be better but this is nice guys see this so complicated query it is being able to give the marks over here will this replace human why it is going to replace human see first class first class first class Vias is second class give me the second okay give me the give me the second last rank student name from student table so danu second last rank second last rank it should be select name from student why is giving error let's see if it's a let's run this give me the second last rank student name from student table near offsets I think some error is coming over here let's see now it is getting complicated writing so this query may not work select name from student Group by null order by count so this makes me feel I'm learning SQL for 3 months okay perfect anything other than this you want to try everyone one so hit like if you like this video and tell me how was it did you enjoy shall we do the deployment for this everyone wants to do the deployment so let's go to hugging face okay go to spaces and create a new space just let's go ahead and write text to SQL generative AI generative AI okay text to SQL generative AI license you can probably use Apache License streamlet I'm going to use and this provides you uh CPU basic uh 2 CPU 16GB free public and all I will go ahead and create the space now for this what you really need to do is that I will close this till then I will close this I will rename this particular file SQL to app.py app.py oops okay I'm just going to rename it because this takes app.py and requirement. tht is there okay I will go ahead and open in the reveal in the file explorer and I will go ahead and create this space please match the requirement okay text to SQL okay go ahead and H what is happening no spacer text to SQL generative AI let's create this space now after creating the space what we can specifically do so this is the space that has got created I will go to the files and here is my entire file so I will go ahead and upload this three files student DB this this this okay so I will go ahead and add upload files and probably drag and drop these three files okay so this is dragged and drop I will go ahead and commit the changes to the main so here it is now you just go to the app it will start running it internally creates a Docker the deployment of this llm app will be very simple uh the DB is there obviously in the real term scenario we have database is in some Cloud so when we are using Docker we have to probably give the IP address and all okay so here you can probably see that everything is happening in front of you the installation of requirement. txt and all so let's continue this very simple so guys overall everything is good did you enjoy the session yeah so application startup let's see if everything works fine this is getting builded once this building will be happening and you can probably execute it okay I hope it was fun okay now we'll have a doubt clearing as soon as this application works all good the streamlit app is running m is not running let's see so here it is now just let's go ahead and write the query what query was that last I had written okay everybody was giving so many different different queries right so we'll run one of the query let's run the more complicated query okay can you provide a list of student categorized In First Class second class and all I think this should work absolutely fine oh one thing is remaining this will not work I have to go ahead and put my API key okay so if you go down in the settings so just click on settings over here and there will be something called as Secrets right so I will go ahead and create a new secret my secret key name will be Google API key I will copy this paste it over here and we will go ahead and paste this also over here the value and I will remove the codes save it okay this is done now let's go back to my app now again it'll build and again it'll do all the installation again as soon as I probably do each and everything that is required okay so now this is my input okay now I'll paste it over here oh not this what I was pasting I will paste this query so this is the thing can you provide a list of of students categorized as first class so I will go ahead and ask this question it should be able to give me the response okay your default credential were not found to set up default credential this is that why this is not working let's see it should work my settings is there and Google API key save it over here let's see again let's see whether it will work or not till then uh my team will provide a link in the chat section if you want to join and ask any queries that you have you can specifically ask me okay so Prashant you can share the link in the chat okay okay perfect guys it's running so it's running in the hugging phas as I said in order to set up the secret key just go over here down there will be something called as secrets and variable create a new secret write the Google API key and write the value over there that's it okay and here is the entire app it is working absolutely fine okay perfect everybody yes yes yes yes yes yes yes yes or no please make sure that you write the quote over there okay okay guys so please join with me in the session and I will allow you to ask any queries if you have but I hope you like this session altoe guys yes or no so if you specifically want the code uh the GitHub link I will provide you the GitHub link of the code over here okay so go ahead and join the link guys if you have any question if you want to ask me anything and regarding all the paid courses in n neon you can probably see the description of this particular video so we are coming up with Gen AI course mastering generative AI machine learning boot camp uh in both in English and Hindi we are coming also with data analytics boot camp and mlops production ready data science project everything is basically coming up you can probably check in the description of this particular video check out the course and if you are interested right because this kind of projects what I have actually discussed right now this is still I will say basic to intermediate we'll still discuss more advanced project when we are doing in the course itself okay so yes this was it so how did you like the session first of all was it good bad yeah yeah Vishnu Khan please go ahead with your question mishuk Kant can you hear me unmute yourself vishant Vishnu Kant if you have any questions you can ask me okay what about next people who want to join hi sir am I audible to you yeah tell me sir my question is that how to fix that response error which you have fixed I was trying to fix that still it's not showing the response response first of all see whether your SQL quer is getting generated or not is it getting generated no sir then I would suggest just check the GitHub link that I've actually sent with the code okay try to run that code once okay okay I've sent you the GitHub link so this is the GitHub code that we have okay so just try to run this I will try to edit this over here itself in front of you sure whatever things we have ran everything I'm going to put it over here okay uh SQL light. py so this will basically be my insertion database I will commit this up I'll commit this changes and uh in SQL py I will go ahead and use this code that uh I have written app.py okay so you can go ahead and check it out okay sure sir yes please next question yes jbin AI will be able to generate images yes yes it will be we have discussed about that in the last session yes the session was informative live coding session helps us to understand in a better way I would appreciate if you could continue adding more interview questions and answering videos sure I'll do that any more question guys if you want to probably join please make sure that you join the link that is given by our team okay okay if you want to talk with me if you have anything as such you have to go to this link and you can join it along with me okay yes any more questions guys just go ahead and ask very good everything is fine so please create one more session for generative AI images okay fine I will try to create that in my next session we'll try to create a health management app okay and then we will work on that sir please can you tell gen is in job oriented course yes obviously whatever things are people are using in the industry that same thing we are teaching in the course okay is gini better than chat GPT I would still suggest I'll say suggest that many people we cannot just come to a conclusion right now okay we cannot come to a conclusion right now with respect to that but when the high Advanced model will come then we can probably see so guys use the link that is probably given over here we have put that in the comment section you can join directly to my streamyard and here I will allow you to probably talk with me and if you have any questions we can discuss please go ahead join the streamyard link and if you have any question you can ask me I said right what are the timings of the generative AI course so if you probably see over here if you click this link the timing is given 10 10 a.m. to 1 p.m. IST okay every Saturday and Sunday this course will go for five months yeah STI please uh tell me your question uh sir K great talking with you uh I enrolled for gender course uh for python uh actually as a beginner I just know till oops Concepts not much in data structures and uh much more advanced concepts uh even I'm not a developer I am from uh nondeveloper background and just doing some uh like manual testing and all uh will that help me this gener course can land me other than testing uh jobs just want to know yes ma'am so the thing is that the more first of all the prerequisite in our course is Python programming language so that is the reason we have given already recorded videos also in our curriculum okay the more you go become better in Python programming language the more better courses you'll be able to I mean the more better projects you'll be able to develop okay so I would suggest still focus more on python and then probably start learning all these things and how to create uh entire llm application which you need to focus in the class after that try to do some internships try to do try to see in in your work can you do something something related to that you know all those things will matter okay actually actually I enroll for this course because I don't want to be in testing domain anymore so uh if even if I am not a developer uh can I get some hands if I get handson in this project can I switch my from domain from testing to any other yes ma'am but again you need to follow some steps over there you know do multiple projects see currently in testing also many things can be used llm task can be used that is what I'm trying to say you know so if you're able to use this that experience you'll try to put in your resume okay if you already working that is what I meant but yes definitely there is an opportunity with respect to that okay if I if I am not able to understand how to put this knowledge in testing can uh get get can I get mentorship from Team uh so that I can implement this in the classroom we'll discuss of those kind of use cases see right now I did I I'm not a let's say I'm not a good SQL Developer but still I'm able to write queries right yes sir from this application you saw right now in testing also you you have you do manual testing you do automated testing right yes so in that also you can do something with respect to that there are lot of different different things which you can specifically do with this llm models okay sure sir sure daily I will be waiting for your videos okay today Chris will be giving new video on which topic I'm curiously every day waiting for your videos your videos are so great and helpful thank you ma'am thank you thanks Kish this mju here yeah hi mju yeah so what I'm looking for is like uh I required uh company oriented realtime projects for computer vision and large language which you already teaching but I I'm looking for a project which on computer vision uh thing so will your team will be helping on that already already in our data science uh full stack data science batch we are already doing all those things end to endend projects that are related to computer vision and everything if I want to get only the related to project because I know all the things which is required prequest for data sence I know all the stops in that so now I only want the project so so so so sir I I'll tell you what we have come up with okay so are you able to see my screen yeah yes I can see now here you are able to see my screen right so in I neuron right we have something called as one neuron okay now inside this one neuron we are creating this data science project neuron right so here you'll be able to see computer vision set of projects mhm right so this this entire neuron is specific to projects only right here we are not teaching anything from scratch but instead focusing on solving projects and these are like end to endend projects with deployment okay okay okay so just go to one neuron and there is a data science project neuron sir oh okay Kish yeah thank you for that yes please yeah more question guys I think mju had asked right right now hello yes yes mju okay any more question mju yeah but seriously one thing I want to tell you man you you are amazing honestly speaking like you are making the things like you know anybody can pick up things and become a know any any from any background and they can become a programmer and move to the carer so the way you are doing the way you are teaching is you know you are reaching to the worldwide you are not limited to India like across the world people are recognizing you that that is a level but you need to give one motivation speech like how you came from a know you are from Karnataka from Karnataka so how you grown up how you made yourself know that one kind of know motivation video you have to give like how you built your know profile to to this level like to you can reach out to the world that is really amazing I'm very proud that you are from my state thank you thank you Manju definitely we'll do a specific Meetup where in know closed audience specific office in Bangalore or anything yeah yeah so in Bangalore we have office so it's near uh this brigade and we our building name is Brig signature Tower oh okay okay yes try to come up see at the end of the day U again the main Vision over here is to democratize AI education you know uh the way that we are selling courses because this courses adds values right uh it helps you to get jobs it helps you to make Transition it help you joined multiple other I spent a lot of money and learning but I see always I get a very small like you always do in the jupyter notebook know jupyter notebook thing is a outdated stuff like where you cannot use it in the company now we are moving to the you need to build an app company is looking for that because I'm I'm working on that I'm already in the industry I have a 10 plus experience and I'm using it because you need to need to build a app end to end so that that is what industry is looking so there your you stand out from rest of the crowd which you are teaching so that is really amazing continue to do M see we are already coming from that background you know so we know see my total years of experience if I say it is somewhere around 13 to 14 years okay and uh if I talk about I we started at 2019 right so that till that experience we were already 8 to nine years experience specifically me now I know like what things are required in the company working in company getting into a company transition making a transition in the company what in a project what what skill sets you specifically require right so hardly you'll be seeing any Jupiter notebook session but instead we focus on creating an end to end project or a module you know which will be very much applicable in the sessions but thank you for your uh amazing words that you have actually said uh this is really Heartfield you know because I I hear from the people who are in us and Australia different countries right they they speak they watch your videos that's you know from such a background like where you are reaching today that is really amazing it's it's inspiration for everyone you know thank you thank you mju again at the end of the day I need to add values in others life and that is what we our team in auron are doing with the same vision we are working on thank you uh hello yeah yes sh sh yes sir actually uh so what we are doing is generally uh we are fine tuning the llm and based upon our own data set and we are getting that as some text okay so is it possible to integrate the uh you know so Panda's AI so to get that plots uh sir I will just have a look onto the Panda's AI I I've kept a point over here first let me explore that you know so once I probably explore that then I can definitely come with that thing okay so first of all let me explore because I've never explored that Panda's AI okay it is a kind of yeah sure sure thank you yeah yeah good evening next question sir can yeah sir can you create some Transformer projects or you explain the two hours transform how it is going on attention can you create some projects sir so I seen your YouTube channel because uh llm and lstm projects is not there in your playlist uh can you create some projects within two weeks I mean or else this month sure sir sure definitely I'll do that sir you are creating the so many projects right can I can I do that projects to I mean fin year projects like fin year projects yeah yeah you can do it you can do it I mean how to uh sir in my laptop you said that K python version 3.10 right K is not available in your laptop it you have to install sir I install anakonda sir but you have not you may have not set the path that may be the problem the default path will be there now that you have not can I use can I can I so without see if you try to do without K it is possible by using pip but again there'll be a lot of clashes within your environments it will not be at one specific place you know where all the tracking of those environment is done so it is a good idea to in your YouTube channel sir actually I did not see this actually I did not see this live uh you upload one video on the morning right I seen that two hours video uh I follow your YouTube channel very much as compared to this uh can I uh downloading that uh K it is there in your YouTube channel yeah it is there but don't worry I may also create another video where you can directly use Python and create an environment okay okay can I see the okay sir I'm not created yet I'll create those videos I'm saying yeah no sir you to this I struck in the starting only sir I entire thing I writing the notes because I struck there when I stuck there I did not come the interest to go further so I writing the notes so that's why I'm asking the doubt okay don't worry see it's more about creating python environment if you hm V see I'll I'll show you one link over here okay just give me a second sir one more idea is uh iuran you are connecting that 16,000 right sir mean gen CES mhm 16,000 5 8,000 huh sir that much money I did not bother sir because my friend also want to contribute me can I both join ion sir just talk to the just talk to the team like let's see what team can actually do okay just talk to our counselor team how how I want to contact to the team sir uh see in the website itself right you will have the number see over here talk to our counselor bottom their number is given you can talk to them okay so see over here creation virtual environment uh this entire documentation is given okay you can use this and create an virtual environment just follow the steps automatically you'll be able to do it okay okay sir I don't know the internal parts how YOLO is working from where I want to study that wo V8 that all I don't know I mean where I want to study see YOLO documentation is given in a amazing way over there if you have seen YOLO V8 right if you see this specific documentation right I think most of the things are given step byep installation everything is given over there but don't worry in ion no we'll be coming up with live classes with respect to deep learning also okay from YouTube paid live session in paid code also if you want to join there is already but in YouTube also we'll have live session going on okay yeah can you explain you sir how internal parts is working math behind that sure definitely okay thank you sir thank you yeah thank you yeah next question hi sir yeah hi Hari uh sir uh yeah nice to meet you sir sir uh I have a question so in machine learning and deep learning how we use uh graph modeling sir I mean uh I uh I mean I I saw the one article regarding graph modeling but depends on what kind of use case right graph modeling can be used in multiple use case uh it is AA fraud detection uh I mean like that so see again you can use this techniques but sometimes right you also need to think which algorithm is very much feasible to use with respect to a project okay okay yes your uh uh the algorithm with respect to this will speeden up the process but again try to understand this I've not yet created any videos with respect to that you know let me have a look onto that and see if I'm able to create one project I'll try to upload that in my channel okay okay sir actually uh I mean uh last couple of uh days weeks I watched your video sir and uh uh I uh mention those uh project Basics projects regarding the generate U uh in my uh resume and I I got a call I mean the interview call and I clear the first round I have technical rounds right now and so I I don't know exact exact I mean how how we'll go so can I get the some I mean like knows like how the interview is going to go always make sure that when you have a technical round prepare well your projects right it should be till deployment what all things you have done in that you have to explain that properly so that you know you guide the interviewer what what should be the next question that he should ask you know try to try to make sure that you have the control of the interview not the interviewer you know so the information that you have portraying in front of him right try to provide him some some things that you have actually done which may be something new for him because see interviewer would like to just understand that what all things you know so how well you specifically speak with respect to a project the more the better it is okay okay sir actually I uh I enrolled the I mean Genera a clause sir uh I mean the but I mean I I mean l i mean the S I mean sa also teaching the generate UI I mean the community section so I watched those videos and I took one project uh I mean he I mean what he's teaching and I uh mentioned that project in my resume and I'm not expert in a Genera right now so I'm very scared of that what how will go the don't be don't be scared of it see if you know how to use apis that's it you just need to be scared whether you know Python programming language or not the more better you know Python programming language the more better you'll be able to create this llm application okay okay sir so don't worry see anyhow you are in the course and uh when you are in the course you don't have to worry with us okay okay sir yeah thank you sir yeah next question please hi sir rendra rendra you're my inspiration basically to be frank sir can you make some in your playlist based upon llm sir large language modules with python custom gpts from scratch you're saying yeah yes sir see I will take llama 2 model okay so llama 2 is there it is a very good open source model on top of that I will try to show you fine tuning okay by using this or clor method okay yeah okay sir and I have one doubt sir regarding YOLO before doing NM I mean non maximum sub Su we do some something called we do sorting desing order before that we do something we give some threshold values and if it is less than 0.3 threshold threshold we we make it as zero Suppose there is a some small object tiny object is there suppose there's a tiny object which it has a score of 0.2 in the sense so we may lose the data in we may lose the data in that case so rinda just give some days okay what we will do is that we'll try to create a dedicated video for that okay I'll tell my team also with maths don't worry everything will broke break break into math smaller smaller parts so that you'll be able to understand okay directly explaining right now will be difficult so let's wait for one video okay from our end yeah I purchased the dlcv NLP from inur sir I have completed the course I have completed the course I have this this just have qued to the neuron support team and one small can you explain da data argumentation see data argumentation is like let's say you have one of my image okay now to train a model you know what I can do is that I can change my face like this like this and give the model give the model different different images to identify me data augumentation what it does is that it takes all the images it tries to horizontally rotate it vertically rotate it expand it zoom in zoom out so it tries to creat a variety of the same images so that the vision model whatever Vision model you are actually creating it'll be able to understand that image very much easily so you're just trying to create multiple images by applying some techniques some transformation techniques where it can probably zoom in zoom out horizontal flip vertical flip it can do multiple things in the image and create a new one okay uh the day before yesterday I was doing a project based upon deing sir I was trying to read I have created a folder and I created some dogs photos of dogs I have downloaded and some photos of cats when I was trying to read that in the collab it's not getting running it's showing an error for me sir why better drop US mail to the support provide the collab link over there okay and let them have a look with respect to that okay so we have a dedicated team who will take care of all these things okay try to do L from python thank you sir that's yeah thank sir I sir I have one question sir uh currently Vision language models are coming up are you going to include that in our course generative course sir mean I'm not sure whether the document papers released or not but Vision language models are coming up right so are you going to include that in generative course yeah sure see the thing is that at the end of the day whatever things are coming in generative AI let's say the vision language model you basically saying large image models right so uh the gini Pro Vision whatever functionalities whatever projects will be developing over there also we'll take that in the class H okay sir and I heard one of the uh student asked that about python may I know what level of python is required sir because as I asked you before data structures and algorithms I am very poor at data structures and algorithms until what level I have to Learn Python may please the python you definitely need to note in modular programming language you know oops inheritance classes all these things that is the reason we have given that as a prerequisite along with that we have given the entire recorded videos in the curriculum okay yeah I'm aware of till oops sir but data structures and algorithms like in advanced uh tree graphs and all uh is that will not be required to create projects okay that will not be required okay sir thank you and in in Project do we get some real time industry level uh how they are using all the deployment techniques we'll teach you all the deployment techniques you know what all things are currently happening and in the future let's say when the curriculum is going on when the course is going come when anything new comes we will also take care of that you are going to add in that course sir not add but at least we'll discuss that modules in the last okay first we'll complete the entire curriculum and then we'll try to include that yes definitely I want to get into this uh generative uh field because I have only the hope is about this only this course sir after this course I I don't have any other way to switch to in testing I have only hope is this gener course sir I try your best yes sir thank you sir thank you okay guys so it's already 10 so 2 hours of session I hope you like this session please do hit like uh and as usual uh keep on supporting and again I will be coming in the next week Friday live session we will be discussing more about amazing projects and all uh again let's see what all things are basically coming till the next week I'll come up with that and we'll have a good one so thank you this was it for my side so if you are new please make sure that you subscribe the channel subscribe all the Ion channel share with all your friends share share share the post like whatever things you specifically do tag me over there I'll be happy to answer or probably comment down like what kind of works you have specifically done uh yes uh at the end uh I would always like to say one thing guys uh see there are new things that are coming in the market right the reason why we are teaching all this new stuffs is that it actually increases your effic efficiency productivity at the end of the day the more you work the more you put effort the more you become a successful right you go in any company you go anywhere right the more knowledge you gain and trust me in anything that you do in your life if you spending two hours in learning if you are spending three hours in learning if you are not learning also right some or the other thing you specifically learn with respect to each and everything right and one more thing that if I probably talk about in neuron right so this in neuron support if you want to really see a real practical example okay so let me just show share my screen so in this example you'll be able to see there is something called as support system right the main llm we have integrated in this entire support application right so let me just go through this so that you get an clear understanding what all things are basically there let's say once you join a batch let's say you are in generative AI so mastering generative AI batch is over here you can join the group in this particular batch right so let's say I'm in machine learning boot camp okay or I'm in this particular boot camp in all the all the batches I've probably joined let's say there is data science interview batch going on okay now you may be asking various question like can we probably communicate with our team members can we have a onetoone session can I probably study in a group so for this let's say I in this specific batch if you go ahead and join over here there is something called a join group as soon as you join group right then here you'll be able to see that this group will be added right let's say over here the machine learning boot camp is over here I've joined this the data science interview back so all your team members will be in this specific group you can ask any question as like as you like you know you can ask any any question as you want right over here like you can probably ping hi all the members you'll be able to see you'll be able to ask any question if you want to probably do a group study everything will be in one platform itself right apart from this if you want to communicate with anyone right if you want to probably communicate with anyone here right you can also do that now see karik Kash basically says that why one 121 support is stopped because this was when we are developing things right so here you can probably see thanks Chris not sure if this is Chis in human or chish the chat bot I'm the human over here right now let's say if you want to get more queries and right now there are many people who pay some pay they pay $20 to chat GPT but by using this Megatron you don't have to pay anything you can directly chat it over here let's say give me the python code python code to create a floss cap okay if I write like this if I execute it I'll be able to get the entire code right so here what we have done by using see over here in the Megatron we have used llm but the other entire application looks more like a WhatsApp message right where you can probably do one to one group chat you can have any kind of discussion now see all the questions are basically there right not only that once you probably go to the knowledge ocean let's say if you have any query right you can go ahead and write the query right so it'll you have to probably select the batch where you are in let's say I'm in mastering generative Ai and I say hey what is generative AI right now before when we were giving the support sometimes because of huge queries we are not able to solve that in 24 hours but now by using the support system we'll be able to solve within 24 hours let's say I'm asking what is generative AI okay and I've asked this question and I post it over here right so here when you go to knowledge session you'll be able to see new to Old what is generative AI you'll be able to see over here wait new to Old this is old to new um let me just go ahead over here in the homepage so you'll be able to see all the queries that people have asked now this is where uh the most amazing thing will be that as soon as you probably click over here you'll be able to see all the responses from the students right large language models are this this this this let's say if some if none of the student provides a response over here then what will happen is that our our llm model will provide the response within 24 hours it will first of all go ahead and filter and see which question is not been answered and then we probably what we do is that we provide a response over here itself right normally none of the vendors allows to talk with other batment in the join course yes but we allow the reason is that people waste their time people waste their time joining multiple groups right someone will be joining telegram someone will be joining WhatsApp and other than studies other than studies you know they will talk all rubbish things right they'll not talk more about studies but other than that everything they'll talk right so this is one specific place where you can have a discussion about each and everything right and not only that let's say you want to provide if you have any queries and you want to probably write a mail to us you can compose the mail here itself you don't have to open a Gmail probably go ahead and write query at theate ion. a or support at theate ion. AI right everything and in the future what is going to happen right in the future you'll be able to see that right now we have this chat right in the future our Megatron will be so strong since we are processing with two 20,000 videos see we have highlighted over here 20,000 videos has been processed along with that it has generated 6,000 question and its answers so any question that you specifically ask either you can get a video or either you can get any kind of answer from our Megatron itself or from our this specific chat B right so that is how strong it is going to have become in the future so at the end of the day this we are specifically doing because you'll be able to communicate with your batchmates you'll be able to do group study you'll be able to do projects you'll be able to do internships multiple things all at one place and if I probably show you ion. every tab that you see over here every tab right this altogether has a complete different story let it be with respect to internship portal let it be with respect to job portal neuro laab neurolab why did we come with neurolab because many people did not have that strong laptop or machine to do the coding so that is the reason we came up with this Virtual Lab wherein you can go ahead and probably uh you know open any IDs probably work with flask work with python it provides you an entire development environment which is running in Cloud so you don't face that specific lag then support system was one of the challenges which you are trying to fix from past two to three years now this is completely fixed and still we are making it much more better you're going to provide lot of features as I said all these things are basically coming over here the best thing is that you don't have to pay any money for this right if you are part of a course you will be able to use this right that is the most powerful thing and again why we are doing this this is for our community we really want to build our community in such a way that you learn you learn in an amazing way and at the end of the day get placed somewhere make Transitions and yes obviously help others also whenever you get that particular opportunity okay so thank you uh this was it from my side uh I hope you like this entire things that I've actually shared okay and yes this was it for my side keep on rocking keep on learning um other than this please go ahead and check out all the courses in the Inon and will be provided in the description of this particular video uh and yes I will see you all in the next video have a great day thank you take care byebye everyone Tata at least say Tata I know you did not ask answer much question over there okay but yes a good happy weekend for all of you out there thank you guys thank you so if you able to see my screen just give me a quick confirmation everyone so we will go step by step we'll go with the agenda we will try to understand many things as such you know topic by topic I will be writing in front of you wherever Google is required I will take the help of Google I will show you research papers and many more things as well okay so let me just see in LinkedIn also whether I am visible or not so I'm just going to see in multiple places uh so I'm excited about this sir as an India llm for large language will be taking flight off yes many many companies are specifically using in use cases and all so it'll be quite amazing so let me see whether we are live ion LinkedIn page or not okay just give me a second okay perfect I can see myself over here there are chats there are messages that are probably coming up okay great okay let me hide the current comment okay so what is the agenda of this specific session what all things we are specifically going to discuss so the first topic as usual is to understand what is generating AI okay so we are going to first of all understand what is generative AI okay because you may have heard about machine learning deep learning you may have heard about natural language processing where does it exactly fit okay so we'll also be able to understand it then after completing this we will try to understand how llms model are trained so what what does llm model basically mean large language model okay we'll also understand what is large language model when we are discussing about generative AI so the third thing we will be discussing about open source we will be discussing about open source and paid llm models and which one you can specifically use if you don't have money enough what you have to really take care of see at the end of the day these all are models okay and uh if you have powerful gpus and is it possible that you can also train your llm model from scratch yes so everything is possible I will be taking up making sure that I'll explain each and everything okay right now the models that are very much famous that are in the industries right now right so you may be hearing about chat GPT right so chat GPT I will just write the model name let's say gp4 right we will discuss about some some of the good open source models like Lama 2 we will be also discussing about gini Pro right why gini pro why gini Google Gemini right I'm not talking about Palm or B Google BS and all right gini Pro um recently Google has launched this three amazing llm models right three versions of gini models right and geminii pro right now is available for everyone out there to use it to create an end to end project and it is completely for free right you can probably use 60 queries per minute you know you can you can actually give somewhere around 60 queries per minute for uh for using it in your use cases yes soon it will also be coming up with uh paid models uh if you want more queries to hit right so it is good to start with all these things I'm just given some list of llm models over here other than this there are a lot of llm models also open source llm models like Falcon Mistral right so I hope everybody has heard about all the specific things okay so let's see how many topics I will be able to cover step by step and if something is remaining again we will continue in the next week Friday session so first of all let's go ahead and understand about generative AI okay so the first topic we will go ahead and discuss about what is generative AI okay so everybody understood about the agenda what we are specifically looking at right agenda we'll also be discussing about large image models also that question will also be coming up okay so there's a question a little bit about llm models and open AI I will discuss about it okay um okay I have a good knowledge of python okay I'll take up questions okay so but I hope everybody's clear with the agenda that we are actually looking at so now let's go ahead and understand with respect to generative AI now before understanding generative Ai and where does it fall in this entire universe of artificial intelligence you know so if I probably consider this as an example let's say and this this diagram probably I've I've taught in many of the classes I've explained you all and all let's let's consider the entire universe and this universe I would like to say that this is nothing but this is this is artificial intelligence okay this is nothing but this is artificial intelligence right and what is the main of aim of artificial intelligence is that whether you work as a data scientist whether you work as a machine learning engineer whether you work as a software engineer who specifically wants to harness the power of machine learning deep learning at the end of the day you creating applications those are smart application that can perform its own task without any human intervention so that specifically is called as artificial intelligence right so what is exactly artificial intelligence it's just like creating smarter application that are able to perform its own task without any human intervention okay so that is what AI specifically means so tomorrow you work as a data scientist you work as a machine learning engineer or you work as a software engineer who wants to harness the power of machine learning deep learning techniques at the end of the day you will try to create an AI application only right some some of the examples with respect to this AI applications as I've already told earlier Netflix right Netflix is one streaming platform let's say movie streaming platform here an AI module is integrated right so there is an AI module that is integrated now this AI module I would like to say it is nothing but movie recommendation system right movie recommendation system movie recommendation right Netflix is already a software product it is a movie streaming platform but we are trying to make it much more smarter so that it will be able to give us or provide us movies right recommend us movies without any human intervention see our human inputs will get captured over there what movies you like like action movies whether you like sentiment movies comedy movies all those information is getting recorded right but we are not asking human to to to take some decision in short this AI app will take its decision by itself right so so this is what artificial intelligence is all about now coming to the second one if I probably consider the second one that is nothing but we basically talk about machine learning so what exactly is machine learning here I will be talking about ml okay now with respect to ml right what what exactly is machine learning machine learning provides you what it provides you stats tools stats tools it provides you stats tools to analyze data right to analyze data to to create models and these models will be performing various task it can be forecasting it can be prediction it can be feature engineering anything as such right but all these activities that you are specifically doing in this I would like to consider all those as stats tools it is provided ing this tool to do or to perform this work right so here you'll be seeing that we learn about different things like supervised machine learning unsupervised machine learning we learn about techniques wherein you create models that models are able to do classification regression problem statement forecasting Right Time series prediction right different different tasks can be performed with the help of machine learning right and machine learning initially what was famous if probably say five to six years back everybody used to probably use machine learning techniques and now also they use it for most of the use cases they use it right but now because of generative AI now they able to think much more with respect to different different business use cases right so at the end of the day with the help of machine learning we are trying to do that okay still now coming to the next one what about deep learning right so deep learning is another part of or I can also say it as a subset of machine learning now what was the main aim of deep learning over here here we had to create multilayered neural network multilayer neural network okay multilayered neural network now multilayer neural network why we specifically require multilayer neural network see we human being wants the application to perform like how we human being think right let's say I want an application to perform like how I am able to teach how I am able to study in that similar way if I want to make a machine also learn in a similar way I have to use multilayer neural network right and that is where deep learning was becoming famous and this is from 1950s but right now we have huge amount of data and if I compare the differences between machine learning and deep learning is that the more data I have and I train a deep learning model the performance also increases the same thing does not happen with respect to machine learning right so that is the reason we are discussing about multilayer neural network and this is where deep learning come into picture and again they are different techniques that we have already learned about you know Ann CNN RNN these are the basic building blocks other than this you have seen about many things like you have object detection rcnn you have YOLO algorithms in RNN you have lstm RNN Gru right Transformer B encoder decoder all these things you have specifically learned that all are are part of deep learning these are solving some specific use cases some specific use cases right these are solving some specific use cases right so this is again deep learning is a part or subset of machine learning okay now comes I hope everybody's clear till here because this I already taught it earlier also to all of you the reason why I'm teaching you over here is to make you understand where does generative I fall into picture so if you if you are able to understand till here please give me a confirmation by writing in the chat yes no something you're able to understand over here right so just give me a confirmation give me a thumbs up okay give me something hit like for this specific video so that it reaches many people to so that you'll be able to understand because nowadays from the students who have already made transition specifically in uron they're working on generative AI they're working on llm application they're creating some amazing application to solve different different business use cases so that is why I am basically discussing about all these things right so I hope everybody is able to understand tiia perfect so I I'm able to get the confirmation they good signs like this and all so everybody uh is able to understand it amazing now let's go ahead and understand where does generative AI fall into picture again guys now if I consider generative Ai and what exactly generative AI we'll discuss in some time but generative AI will be falling as a subset of deep learning okay as a subset of deep planning so this circle that I am considering is nothing but it is a generative AI okay now why it falls why it falls as a subset of deep learning because at the end of the day we are using deep learning techniques also most of the llm models that you'll be seeing is nothing but is based on two models one is Transformers another one is Bert okay these two models are super amazing models I hope you may have heard about something called as attention is all you need right attention is all you need right so attention is all you need there you have these amazing models Transformers and birds this are also called as encoder decoder sequence to sequence models these are the base of many many many gener AI models or llm models that we will be seeing okay so all these things you should definitely know it because these are the basic building block today we have so many models in the market we have chat GPT we have GPT 3.5 we have GPT 4 now GPT 4 Turbo is also coming right you have llama models you have Falcon you have Mistral you have gini right jini Pro you have Google B pal models many many models are there in the Market at the end of the day they most of them most of them I know most of them has this as the base model that is Transformers of bir right and many more things over here now considering this people or companies what they do they train with some different techniques they add reinforcement learning they do some type of finetuning to to make their model become much more better so that is the comparison that is basically made now recently Google came up with with gini Pro so it started making comparison okay it is so much better than chat GPT sorry GPT 3.5 it is so much better than this particular model it is it is able to uh reach mmu of this much accuracy right human understanding accuracy is this much reasoning accuracy is this much all this particular information is basically the metrics right at the end of the day the base that you're specifically using is either Transformer bird in short you're using this advanced architecture of the neural networks and you're training or you're pumping you're training this models with huge amount of data and that is where someone will come and say hey this model has somewhere around billions of parameter everybody will get shocked wow billions of parameter wow amazing nice great we are going to get a good model then right but understand the context when we say billion of parameters that basically means how much how much weights is basically considered how many weights parameter are there how many bias parameter there how many so many things are there there and many more things right I'll be discussing about gini Pro as I go ahead okay and I will be showing you some of the accuracy metrics also as we go ahead once I see reach the research paper but what exactly is generative AI I will discuss about it in some time now there is also one more thing which is called as llm models right where large language models see in generative AI also we have llm models we have large image models L IM okay llm and LM llm basically means large language models that basically means it will be able to solve any kind of use cases that is related to text very much simple so whenever I talk about llm in short we are talking about text whenever I'm talking about large image model we are talking about images okay any use cases with that is with respect to images or video frames or anything as such okay so this is nothing but this is called as large image models right there is one more thing where many people may have heard about it okay and recently gini Pro right it Google says that gini Pro is a multimodel what does multimodel mean multimodel what does it mean it basically means that it is able to solve use cases for both that is text and images text and images it is able to do both this task okay so that is why it is basically called as multimodel right most of the I hope everybody has heard about a tool called as mid Journey which is able to generate amazing images mid Journey right mid journey is what it is an Li large image model right mid Journey it is able to create image it is when you write a text it is able to create an image gin Pro what it does is that you give a image it'll be able to do all the object detection within then it'll be able to write a blog for you right so all amazing things are basically happening now why this is beneficial for companies because companies don't have to waste time startups don't have to waste time to quickly create some applications that solves a problem statement before everything used to happen from scratch they used to create projects they used to create models they used to do finetuning they used to worry about data they used to do multiple things but now it has really becomes simplified okay so I hope everybody is able to understand about generative AI what exactly is generative AI I'll just discuss about it understand this term generative okay and we will discuss as we go ahead di di is a large image model yes di is definitely a large image model yes perfect right so guys still here if you have understood please make sure that you hit like it will motivate me because you want me to come in the next week also right right every week Friday we will do a session where I will be teaching you all the specific things right so do hit like let's target that till the end of the session we should make the like button hit more than 500 okay I want that right more than 500 come on you can do it huh see so nice handwriting in front of you you should be motivated by seeing this handwriting not your like a college professor and writing right I'm using multiple cols making it much more interactive and the best thing is that everything will be available to you I will also upload this um if you Pro probably find in the description there will be a webinar link over there everything I will try to provide you over there itself okay so chat GPT is llm yes chat GPT is using GPT 3.5 GPT 4.0 those are llm models large language models if Chad GPT is using di that basically becomes a large image model okay perfect great now let's go ahead and let's talk about so this is what I gave a brief idea where does generative AI fit into okay now let's understand what exactly is generative AI okay still we are able to Now understand now what is generative AI okay let's let's go ahead I'll talk about Lang chain why Lang chain chain lit Lama index where does it fall first of all let's start with some Basics okay and here again two things are obviously going to come large language models and the second one is large image models okay so let's go ahead and let's discuss about this great now when we are discussing about large language models and large image models so first of all the question question that you should be asking fine Krish what exactly is generative AI why why the word generative why the word generative at the first instance so see some years back we used to use traditional machine learning algorithm see over here first of all we started with something called as traditional ml algorithms okay we started like this so in this ml algorithm what we did is that we had to perform feature engineering we had to probably create a model right train model right we had to probably do fine tuning right right and then as we went we finally did the deployment now from traditional machine learning algorithm why did we first of all move to deep learning algorithm again traditional I'm I'm writing over here as traditional DL algorithms okay now we move towards traditional deep learning algorithms okay why did we move over here we saw that when we were increasing the data set even though we increase the data set and the best way to show this diagram is basically to create like this see so this is my machine learning let's say this is my graph this graph is with respect to two thing data set and performance okay data set and performance now over here with machine learning algorithm with traditional machine learning algorithm you could see that when data was increasing after one point of time the performance of the traditional machine learning algorithm started bending in this way that basically means even though I increased the data at certain point of time right then also my performance was not increasing right but now this was the problem now with deep learning algorithms when I say deep learning algorithms I'm specifically using over here multilayered neural network okay multilayered neural network now with respect to multilayered neural network as I started increas increasing the performance or as I started increasing the data set the performance also started increasing and this was with DL algorithms and this was with traditional ml algorithms this was with traditional ml algorithms now that is the reason deep learning become became very very much famous so most of them started solving problems such as supervised unsupervised machine learning techniques or deep learning techniques or problem statement with the help of deep learning algorithms and now you know right from object detection to NLP let it be any task from computer vision to NLP to any task you're also able to do with the traditional deep learning algorithm right now till here everything was good companies were working nice hugging face had so many deep learning algorithms probably now it has deep learning algorithms for any task that you want any task let it be any any task for any task you have a traditional deep learning algorithm available where you can download the model where you can do finetuning where you can use transfer learning techniques and you can probably create your own application now this is where one amazing thing happened and I'll tell you that was the time you know uh where blockchain was also becoming very famous when blockchain hype was there you know mainly all the people were focused Mo most of the audience most of the people most of the researcher were also focused on web3 but they were also some good set of researchers who are focusing on something called as generative AI now now here is what I'm going to draw a diagram for you to make you understand what exactly is generative AI first of all I will go ahead and write deep learning over here as you know generative AI is a subset of deep learning right now in generative AI with all the traditional deep learning algorithms we usually say this as discriminative now you'll understand what is the difference between discriminative models and generative models so mostly all the Deep learning algorithms is divided based on these two important techniques one is the discriminative technique one is the generative technique okay now in discriminative technique which all task you are focused on doing first most of our task like classify predict right or object detection or any supervised unsupervised technique here the data set these models are basically trained on trained on labeled data set right and this discriminative is with traditional DL algorithms okay traditional deep learning algorithms over here we specifically use traditional deep learning algorithms now let's understand about generative model and this is where your I you will get a clear idea about it what exactly I'm going to talk about in generative models the task I'm just going to write the task here the task is just to generate new data trained on trained on some data okay here what is the main task of generative model is that the word generative now you'll understand the main importance of this word generative here you are generating new data trained on some data set okay example write a write an essay on generative AI if I ask this question it will be able to answer let's say it has been trained with some huge amount of data that is available in the internet now I will go ahead and ask write an essay on generative AI should be able to give me the answer now let me go ahead and talk about one simple example so that you get a clear understanding what exactly I'm talking about with respect to generative AI a real world example because people usually like this kind of real world example okay and with this real world example you will be also able to understand multiple things right so let's go ahead and understand it with real world examp example and that is where you'll be able to understand about generative AI so how does a generative AI task look like okay let's imagine okay Kish is over here okay let's imagine not let's not take Kish let's take some person is over here and this is relatable okay this person is in 12th standard let's say it clears NE exam neat exam and now it is basically doing mbbs mbbs mbbs is specifically for becoming doctor okay now over here you will be able to see that how many years this person will probably learn in the college 4+ 1 right I guess 4 plus 1 four years of learning learning one year of internship so after learning for 4 plus 1 years will it be trained or will it learn from multiple book sources at least thousands of books yes or no will it will this person learn from many books at not tell me guys just give me a quick confirmation can you just read one book and become a doctor no thousands of books right thousand of books right so this person will be spending those five years reading thousands of books and after reading thousand books okay don't fight on the number if I'm saying thousands that basically means many books okay I know some people will say sir how come thousands are in my whole life I did not learn thousand okay many books okay many books so once he or she or this person learns from many books spends those 4 plus one year one year here with internship so internship knowledge is also going to come over there now what is the final aim this becomes the this person becomes a doctor so let's consider this is my chat GPT with doctor doctor chat GPT okay now tell me if you go and ask this doctor any question any question related to any medical problem generic medical problem generic medical problem will you be able to get the answer will you be able to get the response yes yes or no now is it necessary the doctor will say only with accordingly to the books only no it can create his own answer you'll say that hey I'm feeling I'm not feeling well you know I'm having this kind of symptoms the doctor will come up with his own word because he has all the knowledge from all those books all those experience that he has put in his internship all the people he has actually treated in those five years right it will be able to provide the response right so what what what is this doctor right now can I say this doctor can act like an llm model now large language model who is an expert in medicine who is expert in medicine right this is just like a large language model who is an expert in medicine and this is what recently openi is trying to do right what is open trying to do over here openi is planning to come up with something called as GPT store have you heard about this GPT store GPT store basically means what you can now create your own llm models and train it with your own custom data right and on the go you can create this particular app right in open that option is already there right I have also tried it out and it works absolutely fine I will tell those model how it has to behave now here you're spending 4 plus 1 years and you are becoming a doctor now this becomes an llm model who's an expert in medicine now the next step of this doctor is to become an MD now there are some questions which this doctor will not be able to understand which the doctor will not be able to give the proper answer it may give you a generic answer so what we need to do we need to train this llm model again with more data and this time the specialization right you want to become an MD in cardiology you want to become a MD in Ortho you want to become a MD in some other field so that expertise will again G when this person will be trained with more three to three two to three years of books right along with experience where you given those kind of task I hope you're getting it right guys I'm trying to use many more examples that is the most important thing the more examples you see the more well you'll be able to understand so at the end of the day what this doctor is doing it is able to generate its own response based on the problem statement it sees yes based on the problem statement so this is how we are trying to learn it tomorrow all you have to do if you're working in any business in any companies tomorrow what you will do you will take any model you can f tune with your own data set and that particular model can behave accordingly based on the company's use case at once right so this is how things goes ahead right so if you have understood till here please give some thumbs up sign I hope everybody's able to understand please give it a thumbs up say something Krish I'm happy I want to see some happy faces please do hit like please do make sure that you subscribe the channel and I want from every one of you you have to share these videos everywhere right we are trying to democratize AI education over here everybody should know the importance of AI because tomorrow trust me you going to use it somewh the other way right anywhere you are going to use it no one is going to say that you cannot use it you have to use it right many people will say hey there is no job by use it in your personal personal daytoday activities and don't worry about job if you're good at something whether you are from any technology you will be able to get jobs all you have to do is that have that knowledge right if you're able to have that specific things trust me it is very good easy to learn and it is absolutely when you also try to convey this information to someone right then you'll be able to understand that how important all this technology is tomorrow in a company a business use cases getting solved and you provide a solution wherein you don't have to spend much money in those use cases right those people will keep you instead of anyone right and they'll give you most of the problems to solve right so in this way so please make sure that you hit like share with all the all the friends some or the other way someone it may be helpful for anyone who will be learning over here okay now let's go ahead to The Next Step where here we have understood about generative AI so what is the main aim of generative AI the main aim of generative AI is to generate some content now let me talk about some of the use cases right so use cases I will be talking about and use cases we will discuss with respect to both techniques one is discriminative technique discriminative technique whenever the name comes discriminative it is going to discriminate based on the data it will give you some kind of output right some classification problem regression problem something right so first technique is nothing but discriminative technique in this discriminative technique let's say I'm taking a use case I have a data set which which says types of music types of music so here I will try to create a discriminative ml discriminative model discriminative DL model and this work will be to basically classify whether this music belongs to rock whether this music belongs to classical or whether this music belongs to romantic right so this is basically discriminative technique right now coming to the next one which is B basically called as generative technique generative technique let's consider I have a music again same use case only we'll try to do let's say this is my music okay it looks like a hard bit but I'm considering it as a music and this music I will train it my my generative model how the training will happen I will talk about it so let's say this is my generative model and now the generative model will talk askask is to basically generate a new music this is just one use case of generative AI I'm not worried about whether it is large image model large language model and all I'm just showing you with respect to do same use cases what discriminative models will do and what generative models will specifically do right so in short we are generating new content this is super important this is what this is new content clear every everyone happy yes everyone just give me yes or no if you able to understand this things yeah so till here everybody's clear I hope you got an idea with respect to discriminative and generative technique okay now is the main question how llm models are trained now you'll understand this okay guys don't worry Lang chain Lama index I will teach what exactly it is okay how llm models are trained just wait B till the end of this session you'll understand all these things right and once you understand it it will be very good amazing you'll get a clear idea and that is what is my target Target today tomorrow if somebody ask a question related to generative llm models you should be able to understand it okay perfect now how are llm models trained so let me just go ahead and use one open source model llama 2 paper Okay so llama 2 is a model that is that is generated by meta okay So Meta has trained this model and this is the research paper okay this is this is the research paper the reason why I'm showing you this research paper because based on this model only I will teach you how this model may have also trained okay yeah yeah this video will be available in the future in the YouTube in the dashboard along with all the materials that I'm writing that I'm showing to you okay so don't worry focus on the class now over here see there are three important information that you can see from this content okay one is the pretraining right it talks more about the pretraining data it talks about the training data details and it talks about Lama to pretrain model evaluation the next one is it talks about fine tuning see fine tuning here we are going to discuss the supervised finetuning please remember this word okay supervised finetuning super important super amazing technique altoe and I will break down this technique and make you understand how training usually happens everything will be taught in this session then the third one is something called as reinforcement learning with human feedback R lhf please remember this techniques because same technique is also used chat GPT models supervised finetuning reinforcement learning with human feedback along with there is something called as reward system also which I will be discussing so the reason why I'm showing you this research paper because this research paper are very easy to understand if you have some prerequisite knowledge about Transformer about something about some accuracy concept some performance metrics concept if you know that much that will be more than sufficient okay so let me go ahead and show you so if I go to introduction see large language model that is talking about this this this Lama 2 now llama 2 has been it scales up to 70 billion parameter okay there was three specific models in Lama 2 which we'll discuss uh it is with respect to 7 billion 13 billion and 70 billion parameters here I am just trying to show you some important information and based on this only I will teach you okay now let's understand this so this is how entirely it happens you have pretraining data you have self supervised learning you have Lama 2 you have sft supervised finetuning you have rejection sampling proximal policy optimization because everything will be taught this is nothing but reinforcement learning with human feedback and based on this particular feedback we assign something called as safety reward model and helpful reward model everything I'll teach you don't worry just see the diagram focus on the diagram and try to just see this okay okay over here so every component that you're seeing I will break it down and I'll explain you now where does this model take the predating data from so here you can probably see our model right is everybody able to see this when we say it parameter train from 17 billion yes so everybody's able to see this yeah so on pretraining data includes a new mix of data from publicly available sources so from where they have taken the data from publicly overed sources which does not include data from meta products or Services okay we made an effort to remove data from certain sites known to contain a high volume of personal information about private individual so from where it has taken the data in short this is all lie I gu yes they have taken the data from wherever it is they are saying we made an effort they're saying we made an effort to remove data from certain sites effort you know how much effort it is there okay so understand okay efforts then we trained on two trillion tokens of data as provides a good performance cost trade up so two trillion tokens of data it has been trained in okay so here the next thing see see see see see we adopt most of the pretraining setting and model architecture from Lama 1 we use the standard Transformer architecture they by Transformer architecture see tomorrow if you give me a chance I can also create a I can also create an llm model creating an llm model is not very difficult but the main problem will be cost of the GPU how much cost of the GPU it will take what should be a team size to do reinforcement learning over there everything in that particular thing that cost will be doing so you'll be able to see only big companies can only afford all these things who have billions and billions of dollars in fundings and all tomorrow if you say whether I can also do it yes the answer is you should have just money to do it because you require those huge gpus the gpus cost training time it will cost how much data you require they will you'll also require people for working for you who will be doing that annotation task labeling task indexing task reinforcement task right but for this you require a huge amount of money tomorrow if someone comes and say hey take this much money create your own model we can do that no worries right but in India we don't Focus much on Research right we focus much on we focus much on what solving business use case and trying to earn Revenue out of it okay research I have not seen much companies who are doing research that much okay so infrastructure cost is there so see Transformer architecture so if anybody knows about Transformer architecture done you'll also be able to do it apply prenormalization some techniques will be there code will be available you can also do it okay now if Lama 2 is an open source you can also use the same code and try to do it okay then we trained using adamw Optimizer see these all videos I've already created explained you like anything what Adam Optimizer how does it work this this everything is Basics I'm not teaching I'm not showing you anything new right beta 1 is there beta 2 is there this is there we we use a cosine learning rate what is cosine learning warmup step DK final running rate everything is same nothing new it's like build sand sand sand and make a castle okay I have sand I have bricks I will combine them and make a uh make a five star hotel in short right and everybody cannot make a five star hotel right who has money they can make it who has money they can make a huge Bungalow right a Maharaja Palace something right they can do that so I hope you're able to understand all this things you need to have money for that okay so here are there Lama one had come up with 17 billion 13 billion 33 billion 65 billion now Lama 2 is coming up with 7 billion 13 billion 34 billion 70 billion now why this billion is increased inreasing why this parameters are increasing some f tuning will be done more data will be added more data will be included more reinforcement will be done multiple things will be put up over there and that is how your parameters will increase and there is no other way the parameter is not going to increase over there right parameter will increase over here itself right something you do in that more parameters will get added more weights more bias it's all about more weights and more bias okay less Dropout more Dropout more normalization less normalization that that way only parameters are getting added you may be thinking parameters is getting added I think they have put a rocket launcher inside that model no nothing like that just they have added more data set maybe more finetuning techniques and because of that more weights more bias are getting added that's it right don't think that no something is happening the model will now go to Mars no nothing like that okay so this is what is all about Lama 2 okay now this is my training loss you have seen in many many videos in deep learning how the training loss will be shown over here right so training loss is over here see training Hardware we trained our models on meta research super cluster meta research super cluster okay by this name only gpus both clusters use Nvidia a00 let's let's see what is NVIDIA a00 cost let's see okay Nvidia 800 powering many of this application this is just roughly $10,000 chip just $10,000 chip just imagine see 27 L 27 lakhs dollar is NVIDIA Amper 800 who will be able to do which startup will be able to do this much money will be able to invest this much money tell me the reason why I'm showing you this because the research paper talks more many things about it right so over here they have used Nvidia a00 you SE in the cost of it amazing right how much is this cost 27 lakh I guess sorry 27,000 and more chips if you try to put up more chips over there the cost will keep on increasing right we are still we are our laptop has RTX 490 that basically means we are our laptop is very powerful there will be electricity cost involved there will be multiple things involved right so everything is over here you can probably see with respect to this right it is somewhere around 27k sorry not 27 lakh it is 27k as as I just saw 0. I did not leave that part okay so but you can just understand the cost is keep on increasing okay so here you can see that RSC uses Nvidia Quantum in Infinity band where product cluster is equipped with Roc you can probably see this C see see see CO2 emission during pretraining you have to also give this information if you want to publish the research paper total GPU time required for required for training each model power consumption PE power Peak capacity per CPU device for gpus see how much carbon is emitted right 7B is this much power consumption 400 watt 400 watt 350 watt 400 wat total total GPU hours take 33 lakh 31,000 no no 33 laks 11,000 hours GP hours who has this much time guys if a startup in India will spend this much time in training done I don't know this is how many years let's say 24 into 12 uh 24 into 365 just do how many hours will be there how many years it has basically trained right carbon P for print pretraining and all these information are basically there right and then here also you can probably see the comparison size Code common sense reasoning World Knowledge reading comprehension math mlu mlu is basically human level understanding uh BBH and AGI right now I've have told all this information now let's understand how this models are basically trained how llm models are trained okay so till here everybody happy yes everybody happy with the teaching that I'm actually doing so now we are going to move towards how llm models are trained and we will discuss it step by step so guys clear or not clear or not just tell me give me a quick information so here I'm going to basically write the stages of stages of stages of training so first information here I specifically have I will just draw the stage one so this is my stage one based on that research paper I'm basically going to draw okay so this is nothing but generative pre tring okay generative pretraining second stage so second stage is nothing but supervised fine tuning which we also say it as SF the same information what is written over there that research paper same thing I'm writing third stage third stage is what reinforcement through human feedback this is my third stage Okay so initially in this stage in generative pretraining we give huge data so this can be so any any llm model basically takes internet Text data or any document Text data in PDFs in all all those formats and here we specifically create or use this generative pre technique now generative pretraining basically means here specifically we use transform architecture model Transformer of bir architecture model the outcome of this is what the outcome of this is the outcome of this is we basically say it as base let's say if I probably consider if I probably consider so I will write this is my base Transformer model what is this the base Transformer model okay now this base Transformer model is then base Transformer model basically means whatever Transformer I basically trained on I will basically say this as base Transformer model okay now the base transform model is in turn connected with supervised fine tuning because same model will be taken and and supervised fine tuning will be done on top of it okay top of it right now this understand this base transform model will be able to do various task like text classification text summarization multiple things it will be able to do okay now here only we will not keep it in case of uh llm model we will take it to the next step the next step is supervis finetuning now here what we are specifically going to do we are going to use human trainers also we are going to involve human trainers to put some kind of conversation some kind of conversation and here we will create some more custom data this is important to understand here we will try to create some more custom data right so some more custom data will be created in this case in this particular step and those custom data which is created it is created basically by whom by human trainers I will talk about what exactly is human trainer when I probably Deep dive more into it okay then it based on this custom data we will train the specific model and the outcome of this model outcome of the model will be okay just a second oops it got closed let's see whether it is saved or not I hope so it should be saved oh my God okay apologies the system got crashed I don't know what happened because of that the entire material got deleted sad can't help okay so how much content I had actually written I don't know whether it's the system got crashed or the scribble notebook automatically got deleted sad to hear about it but it's okay I don't think so anywhere it is okay I don't know generative AI the materials got deleted I'm extremely sorry I don't know what happened over here but I'm not able to see that materials got deleted yeah okay no worries anyhow you'll be able to see in the recordings so don't worry about that uh let me continue okay let me continue okay okay now let's go step by step I was just talking about some important things over there so first step I will go with respect to stage one okay so stage one generative pre training okay this is basically my stage one now what all things we basically discussed in this okay in generative pretraining what we specifically do is that we use Transformer architecture okay so here what we are doing we basically use Transformers Super beneficial for NLP task and then along with this we take Internet Text data and document Text data so this is nothing but internet Text data and document Text data okay and this is what is my stage one okay stage one now once we train with this specific Transformer we what we get we get base Transformer model we get base Transformer model now what this base Transformer model is basically is Cap capable of right what this base Transformer model is capable of you need to understand this specific thing okay this base Transformer model is capable of doing task here I will write down all the task number one text summary I will save this saving this is always better so that if it gets deleted I can open it so the task which is able to do is like task text summary sentiment analysis third task can be something like text uh word completion I'm writing some task fourth task is basically like text translation so all these things it will be able to do it all this task this model will be capable to do it but what is our maining when we make sure that we have a generative AI our expectation is basically to create a model which will be able to do chat and conversation right this is what is our main name right but what we have achieved we have achieved this right by using this technique we have achieved this but what is our goal our goal is to achieve this right this is my goal so that is the reason we just don't stop in stage one we go to next stage that is stage two now in stage two see stage one it is very much simple we have used amount of data we make sure that we do that labeling whatever is required we train it with the Transformer we create a base Transformer model this base Transformer model is able to do this thing but it is not able to do this but this is our goal goal of generative AI is this one right this is what is our main aim goal of generative AI right this is what a generative AI does agree everyone this is what generative AI does and this is what is my goal agree or not everybody do you agree if you AG agree please do make sure that you hit a thumbs up okay now to make a generative AI on top of this I need to do some more thing and that is where I go to my stage two so this second step is basically my stage two what exactly stage two now what exactly stage two stage two I've already told you it is nothing but from the research paper also I've told you it is nothing but it is basically super supervised fine tuning which we also say it as sft now what exactly supervised fine tuning what exactly this is this is the second round now in supervis fine tuning what happens now see this is the most important step okay we require humans in this step humans now in human what we do we create request we make some set of people sit over here so this will be my human agent this human agent will send some request just like in a chat bot how we send it and based on this request based on this request we generate an idle response and this idle response is given by another human agent it is just like a chat conversation let's say I have I have I've set I have made one person sit over here one person sit over here when this person asks a question this person will answer the question then similarly next request will be created then next response will be created then next request will be created then next response will be created so what is basically happening this human agent is basically giving the request this human agent is basically giving the response right idle response when I say idle basically means whatever is the question based on the question we are giving some kind of answers this way we will set up our sft training data set so this will be a label data set now this data set has what this is my request this is my response this is my request this is my response this is my request this is my response this is my complete data set yes or no this is my data set that we are going to create from this process request and response request to response request and response whatever these human beings have had a conversation with right now we going to take this data set and further send this data set to our base Transformer model base Transformer model along with this we will do some fine tuning or we'll use a optimizer let's say we have using Adam W Optimizer this Optimizer was done is in the Llama right in the Llama itself right and then finally I get a sft Transformer model why Optimizer is used to reduce the loss this is an Optimizer right this is specifically an Optimizer okay everybody clear so this is the step that is basically happening in the second one sft is done by real human being human agents right and that is how things are going ahead right and this way you are able to create your own data so this will basically be my data or labeled data during the sft process okay and the same data will be used to train your base Transformer model after training you will basically create a saf Transformer model okay now what will happen still this model you'll be thinking okay it'll be able to give me more accurate result but still this model will be facing hallucination it may not give you good correct accuracy because there may be also some kind of request and response which this model may have never seen it okay so for that case what we need to do we need to probably go with our next step or stage three and that stage three is specifically called as where we will be using reinforcement okay and that step is basically stage three in the stage three we use reinforcement learning through human feedback because we also need to do human feedback and without this reinforcement learning this model is probably it will face hallucination it will make give you rubbish answer and all okay now what happens in reinforcement learning let's discuss about this okay let's say this is my sft train model Okay so so this is my sft Transformer model now in this sft Transformer model what happens after training whenever a human gives any kind of respon request whether a human gives a request after the model is trained we can get a response from from whom from sft ch bot right we'll be able to get some kind of response the SF Transformer model okay now what we are going to do now based on this request I may also get multiple response now that is where you'll be understanding reinforcement okay let's say this sft chatbot we will try to record its multiple response let's say this is response a this is response B this is response C this is response D and this is multiple response like this okay now once you probably get this response so let's say this is my response a as said this is my response b as said this is my response C this is my response d right multiple responses there okay now for this response a human being will do some ranking and this is where reinforcement is applied ranking okay now this ranking of this response like for this request this should be given first rank that basically mean this should be the idle response this should be the second idle response this should be the third idle response like that a ranking is given by another user agent another user agent okay see this step by step First Step then Second Step then ranking is done okay and what this specific ranking is basically going to do just imagine this okay ranking is just going to say that my response a rank should be greater than response B rank should be greater than response D let's say d is greater than C okay so this ranking will get applied okay and once we specifically assign this kind of ranks these are my ranked responses what we can do we can train after this what this is done is that we train a fully connected neural network fully connected neural network in this neural network let's say these are my nodes like this and this is my output like let's say like this so here my inputs will be my conversation history my conversation history and my outputs the real outputs are my ranks ranks responses so based on this I will be training my entire neural network and this model is basically called as reward model okay so in this step in reinforcement what are specific things we are doing we creating an SF Transformer model based on multiple responses we are applying reinforcement where we are giving a human feedback so here in short we are giving a human feedback human feedback based on this human feedback Fe back we will be specifically getting which response should be greater than the other response we assign a rank and then we create a fully connected neural network with conversation history and ranks so that based on this ranks we will be able to provide rewards rewards to what this Transformer model I hope you're able to understand yes yes yes everyone yes if you're able to understand hit like please make sure this is the most important thing in generative AI right of creating this entire llm models right and trust me to understand these things because after understanding this reading research paper will be very very much easy okay and that is where my reward model is basically created in my stage three okay so this is the most important thing okay I will use one image to show you the next model okay and this is the most important one um just a second everyone just a second everybody I think my system is hanged okay okay till then let me go ahead and continue it okay so finally after we have this entire reward model and all okay we also make sure that we create some kind of models see at the end of the day once we create all these things that basically means what happen this three steps helps us to create any llm model as such what is the difference thing that is basically going to happen right your training data needs to be created right the more the training data the more better thing is second thing is the reinforcement learning reinforcement learning with human feedback right this is also important coming for the third thing the fine tuning part right the fine tuning part specifically with respect to sft what kind of request and response the human being are taking and reinforcement the most important thing is that how the ranking is done right these are the main things and obviously the architecture that we are specifically going to use over here is nothing but Transformers okay so this is very much important with respect to all the things that we have discussed how was was the understanding scenario guys with respect to all these things have you understood or not please do let me know please do let me know are you able to understand everything or not with respect to whatever things we have actually done or discussed over here just let me know guys got it got it yes yes yes yes yes yes so everyone is giving me a right answers over here great great great great great great now going forward what you really need to focus on okay what you really need to focus on see as a person who is interested to get into generative AI okay what are things you should basically focus on the road map if you really want to start the road map to generative AI road map to generative AI okay now in order to understand the road map of a generative AI or how you can also start the prerequisites prerequisites what are the prerequisite obviously one programming language okay one is python okay second you really need to be strong at NLP so when I say NLP machine learning concepts with respect to NLP right where you learn different texes of embedding techniques let's say what is embedding here you specifically learn how you can convert a text into vectors right now converting a text into vectors has many things in mind okay so guys there is also one St page uh that is after this okay probably I will explain you that because my another screen have got stuck okay so what I'm actually going to do is that probably one more thing is something called as proximal policy optimization I will create a a live video on this next week we basically say this as prox let me just write it down for you after creating the reward model we basically use this in proximal policy optimization we will discuss about this for this I will come next week live or probably in whatever next live session we will discuss about this entire thing this is an another important algorithm altogether okay but after this our final llm model will be cleared and this is super important because this will assign rewards this is responsible for assigning rewards based on various responses that we are giving or my llm model will give okay so uh I will probably cover this because this is another long topic uh in the upcoming classes we'll see any live sessions we'll discuss about this also okay now let's go ahead and understand the NLP now as as I said that right the prerequisite is that in machine learning you need to understand how a words are converted into vectors and they are multiple techniques uh I hope you have heard about bag of words you have heard about TF IDF you have heard about embeddings you have heard about uh word to right word to V so all these techniques are specifically used in converting uh the words into vectors so that the machine when it is trained based on input and output it'll be able to understand the entire context so basics of machine learning I still say this as basics of machine learning you really need to have a good amount of idea with some of the algor knowledge and all third thing when I say you really need to understand deep learning techniques also in deep learning you need to understand about uh Ann hown Works what are optimizers what is loss function what is loss function what is uh let's say what is uh overfitting right uh what is activation for functions what is multilayer neural network what is forward propagation backward propagation so many different topics are there so these are again the basic building block the basic building blocks okay so the basic building blocks with respect to all these particular topics is super important so please make sure that you have to be really good at this I'm not saying that someone cannot directly jump to generative a they can if you are a developer if you are developing some kind of application without knowing all these things any one programming knowledge you can directly go ahead and probably use the API consume it build application but these are for those people who specifically wants to work as a data scientist as a generative AI engineers in the companies right for them they really need to follow this without this basic knowledge they cannot probably learn generative AI why I'll tell you if you directly jump to generative AI you may be able to develop application but when you go ahead and with the interviews there people are going to ask you basic things right basic things over here and if you are not able to answer that they'll not directly start with generative AI first of all they'll see how good your basic skills is if you good at something then only they'll further go ahead and ask some more questions right so it is super important to understand you cannot directly jump it jump into things okay so the fourth topic that you will probably be seeing after deep learning uh is advaned deep learning techniques so here we focus on on RNN lstm RNN Gru so all these neural networks you really need to understand Gru uh encoder decoder encoder decoder Transformers as I said Transformer attention is all you need all these architectures you should be able to understand because in the interview again they are going to ask you this they'll tell you that design or write a code on a basic Transformer okay and they'll tell see how things are basically done whether you are able to write it or not all those information will be basically asked in the interviews because everything with respect to generative AI is built on top of Transformer right now the fourth Thing Once you this I usually consider as a prerequisite to get into generative AI right it's okay it's okay if you have some good some basic knowledge on all these things right but it is always good to have this so that you will be having an indepth knowledge indepth knowledge of working in generative AI okay then coming on to the fifth part right here where I'm going to focus on different different libraries open AI open AI has come up with this gpts model right GPT 3.5 GPT 4.0 GPT uh 4 Turbo all these specific models you can use to develop applications llm applications not only this you can also use other Frameworks like Lang chain Lang chain is quite popular right now because many people are using this to create llm application and the best thing about Lang chain is that it has created this framework in such a way that you can use paid apis also you can use open source uh open source llm models also and you can perform any task that is basically required along with prompt engineering there is one more framework which is called as Lama index so Lama index is also a very good framework and this is specifically used for quering purpose quering vectors right so this also is very important framework right now and as you all know right now Google gini gini has basically come up with this amazing model Google has come up with this and right now jini Pro is available so you can also use gini Pro it has its own libraries and you can specifically use for performing any llm applications right now we don't have the documentation of how fine tuning is done but in some days that too will also come right now in all these libraries all this open source open source as I said right open source models llm models in this open source models also you can also do fine tuning but again at the end of the day for finetuning you really need to have huge gpus it's see open source models are readily available you can directly download it you can quantise it you can make it in a form where it will be of less size you can directly find tuning with your own data set for that you require hug gpus for inferencing purpose also you require good machines in short right so in short if you are good at all these things trust me you able to work with generative AI but again it is a process where you have to probably learn all these things okay in the future we'll also try to uh I'll try to take a session where we'll discuss about all these prerequisites in depth and we'll try to understand all the mathematical intuition okay CNN is not at all required see CNN is required if you are interested in large image models but here most of the use cases that are probably coming up are on large language models right but if anybody's interested in this you can learn about CNN if you want but I feel uh if you are interested in Tech side llm you have to focus on all these things right so guys how was the session all together good enough good or not oh great just a second I will take up questions my screen has got stuck okay so let's take some questions till then uh yeah every week okay great you are able to hear me out so please uh let me know about more things how was the session if you liked it please make sure that you like it guys uh it takes a lot of effort to keep this kind of sessions and uh we are planning for every Friday this sessions so it'll be amazing to teach and all it'll be great okay got something new to learn great amazing sir salute valuable great great great great I I hope everybody's happy so uh please make sure that you share it with your friends in all the platforms that is specifically required because trust me at the end of the day these all are free content our main aim in in neuron is to democratize AI education we so at the end of the day please try to learn in that specific way try to understand these techniques and then try to build application okay can a nondeveloper also learn this yes anyone can learn this anyone okay anyone because it is very much simple with respect to coding okay what is the boundary of sft and interface for quering is only sampling so tell us about the course you're launching on generative AI on in neuron so guys uh we are launching generative AI course it is probably from next month you can find all the details in the description of this particular video or visit iron. page okay there generative AI course is basically coming up uh So based on that uh you'll be able to see to it and check it out okay check it out in the description of this particular video so video recording today's class yeah it'll be available in YouTube it will be available in the dashboard that is given in the description okay okay perfect so hit like guys any more questions any queries hi sir can you tell me about the differences great sessions are really and really appreciate so guys just give me a 5 minutes break and then we will be taking up the questions my system is hanged so I will restart the system till then okay so just give me another 5 minutes break uh we will go ahead and take a five minutes break so Prashant uh you can just uh stop sharing if possible I will just take five minutes break and okay and I will be talking about that thank you n e e e okay am I audible am I audible hello hello okay 2 minutes 2 minutes 2 minutes okay audible right perfect sorry okay so let's take so first of all people were saying about what is the differences between generative Ai and gini pro okay so generative AI as I said guys large language models are a part of generative AI similarly large image models are also part of generative AI okay so generative AI is already a subfield of deep learning our main aim is to create new content based on the data that we have trained right so we have all these kind of llm models okay okay let's let's take this questions so great session sir really helpful and really appreciate your initiative of democratizing gener uh generative AI learning thank thank you so going forward all ml or DL techniques will not be in use we will focus more on llm plus finetuning yes it depends on companies to companies right so if there is a company where we are focusing on creating use cases quickly and they don't have that cost issue they can directly use this because see at the end of the day if you're also creating any application with respect to machine learning or deep learning you have to do everything from scratch yeah okay let's take more question so how much large data set of request and response is created by human agents under sft as manually to create such large data set is impossible yeah if they put 100 people every day that many task is there then just imagine how much data we'll be able to create right huge amount of data you'll be able to create okay what all task we will perform from J Pro everything text summarization Q&A document text uh document Q&A embeddings everything is possible right so one session I also I'll plan for gmin pro okay why focuses more on llm in gen AI because you're able to do task you're able to create solve business use cases in a much more accurate way right so it is very good how can gender a used for solving real life business problem there are lot of real world business problem that is specifically required by companies from chatbot to text summarization to document classification to everywhere it is specifically used uh in in inur also we are trying to automate the entire support system along with human intervention both we are trying to include and over there also we will be using llm models too right for assignment generation we are planning to use llm models many as such so okay so in uron also we have built our own models itself right so can you show how to finetune a GPT model using API yes it is possible but uh again we need to make sure that we have some good configuration configurable system uh if you want to do it with open source llm if you want to go with paid that also we'll try to do it in the upcoming sessions okay okay tell us more about generative AI so here is my page I'm going to share my page over here ion website so if you are interested you can go ahead and so I'm going to share my screen okay so I hope everybody is able to see my screen please uh give me a confirmation can you see my screen give please give me a confirmation so I will just try to answer this specific question okay so here you'll be able to see as soon as you go to the homepage the first course that we are launching on generative AI mastering generative AI open AI Lang chain and llama index also from 20 January 2024 okay this will be a 3 to 4 4 months course altogether one year dashboard access is there this is for everyone out there whether you are a college student working professional along with this we will also be providing you access to the Virtual Lab of uron okay here what all things we are going to learn we are going to master everything that is related to open Lang chain and Lama index okay and specifically developing application end to end till deployment okay we will show you multiple things over there now when this batch is starting 20th Jan 2024 the language is English 5 months duration 10 to 1 p.m. Saturday Sunday class timing it will be live instructor lead okay uh you have onee dashboard access assessment in all modules the reason why we are putting one year dashboard access is that because this content will get upgraded every six months I guess right there are a lot of upgrades in the field of generative AI right so that is the reason is no use of giving you lifetime or anything as such okay so neural laab access is there dedicated community support these all things are there mentors will be myself sudhansu s Savita and bppi right so some portion I will be taking some portion Sanu will be taking some portion s Savita will be taking some portion bmed B will be taking okay and you have already seen they have they're doing the live sessions on generative AI in the in the in in in the YouTube channel of ion itself okay so you can definitely check it out over there then if you have any queries you can talk to a counselor or you can also contact the ivr number that is given over here right in the website itself so if uh any question that you have regarding counseling anything and this is the entire syllabus we are going to start from Basics what road map I have shown you today based on that road map only we are going to start see bag of words TF IDF word to F test engrs Elmo bird based right then large language model what is BD GPT T5 Megatron right GPT 33 3.5 how chat GPT train introduction to chat GPT 4 right and then we are going to probably learn about hugging pH we are going to see different different models open source then we are going to talk about llm power application we're going to create end to end projects then we are going to use open AI this this this all every everything that is available in open aai because many companies are also using it then we are also going to cover prompt engineering Lang chain Lang chain completely L chain in depth we'll try to complete then we will also be completing l Lama index all these Frameworks right so everything will be covered up and finally you'll also have lot of end to end projects in every section lot of endtoend projects is there and these all projects are with respect to deployment so all these things are there you can probably check it out in the cabus okay uh all the information will be given in the description of this particular video as I said if you have any queries talk to the counselor okay they'll help you out what Hardware is required to learn J no need of any hardware we will be in uron lab itself you'll be able to execute all your code you'll be able to do it if anything is required we'll let you know in the latest stages okay but whatever is in the flea platform available in uron Virtual Lab and all you'll be able to do this so please tell is there any prerequisite yeah Python programming language so for that also we are giving you prerecorded videos so python you should know only python you should know remaining all is fine Community Edition difference please uh Community session is only up to some level okay you can probably say 100% of what we are teaching over here it is hardly 10 to 15% okay will we require opening API key yes we will show you a way how to do that okay um but yeah at the end of the day if you want to do fine tuning and all you'll be requiring open API ke h so do you have projects HandsOn course for machine learning and data science so again I'll let me share my screen for that also we have launched it so let me share my screen so for project HandsOn course uh if you probably go over here we have also launched this one which is called as production ready data science project so if you click over here production ready data science project this is a one month course where we are solving end to end five projects five five and it includes machine learning deep learning natural language processing and generative AI so this is completely end to endend and this is with mlops machine learning operations right all the tools the timing again this is from 27 Jan the timing is 88 to 1100 p.m. Monday Wednesday Friday so in one week we will be completing one project okay three days and it will be live all the sessions will be live it is live instructor lead so again you can go to ion. a page check it out if you want to talk to the counselor talk to them mentors again all these things s Savita bapi will be the main mentors over here will will be taking this entire session Monday Wednesday Friday will be the session 8 to 11 at night now here what we have done is that best thing we have included mlops everything that is basically required right mops mlops mlops right let it be so what all things you'll be covering in this open a AWS GitHub Docker Azure lanin Jenkins along with this we will be seeing Circle CI we'll be seeing uh GitHub action cicd pipeline Dockers kubernetes everything that is required is covered in this so it is a complete mlops syllabus right DVC dockerization AWS Jenkin cicd pipeline so every project that you'll be seeing right you will be seeing over here we are using some some of the other things let's say Industry Safety here also we'll be doing dockerization AWS GitHub action cicd right and if I go with name entity here you'll be seeing DVC dockerization Azure Circle cicd so everything will be covered with respect to that and then I've also we have also included uh the generative AI project okay great so I'm stopping and anything any info that you require you can probably go ahead and ask ask in the uh just contact the ivr number over there okay okay perfect so how was the session all together did you like it so do we need to do projects on mldl to get job in gen aai yes obviously mlops mlops mlops see the generative AI projects also that we are going to do in gen AI course there we are going to include lot of mlop activities also it's more about creating applications okay okay perfect course fees and all you can find out in the course page itself okay perfect guys so thank you this was it I think we have completed the 2hour session uh from coming Monday we are also coming up with the mlops community series from coming Monday so please make sure that you subscribe the channel press the Bell notification icon that is super important um we will be starting from next week itself okay you can probably check it out uh all the reminders everything will be found out in the channel itself there will be dashboard exess materials everything that you actually require so thank you uh this was it from my side if you like the video please make sure that you hit like subscribe share with all your friends this was it from my side okay and I will see you all in next week Friday session we will be discussing more things but again we have lot many things that are coming from Inon itself we'll be having mlops entire Community session and it is from uh next week uh Tuesday is going to probably start and we'll be discussing about all those things how an end to end project is basically created Let It Be an LP project machine learning geni project how mlops can be used and many more things so thank you uh have a great day and keep on rocking if you like this session please do hit like and yes I will see you all in the next session so thank you guys have a great day byebye take care and keep on rocking thank you bye