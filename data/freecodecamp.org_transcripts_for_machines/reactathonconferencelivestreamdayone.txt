i know that you're starving for something you can't touch but you'll be honest with me right now there's something in the undercurrent i can feel it coming up don't you want to feel it don't you wanna feel it don't you wanna don't you wanna tell me that you wanna stay baby just don't walk away i need you now faded out all the time we spent alone fighting through the fires don't don't let me down i need you now cause i'm feeling worn out it's getting to me lost some heart trying to get on my feet caught in the madness i feel you somehow don't let me go i need you right now i wanna be next to you you wanna be next to me holding our paper hearts fading out broken dreams i wanna be next to me broken dreams uh tell me that you wanna stay baby just don't walk away don't let me down i need you now cause i'm feeling don't let me go i need you right now i wanna be next to you you wanna be next to you me be next to me you wanna be next to me held your hand i don't have a clue because i'm missing you because i miss blue i was chasing all the wrong sides trying to hold on to something that i couldn't find now don't because i'm missing because i'm missing you because i'm missing you is okay i was running to the on a saturday night i was doing just out on my own for me hello everyone have you ever made a forum like this or maybe made an api request and then had an error like this turn up in your application later on down the track yeah i have and i've seen it plenty of time and it's a pain in the ass and you'll eventually end up like this guy just like annoying of these errors like ah just stop well there is a better way and by the end of this talk i'll promise my promise to you is that you'll know a little bit more about functional programming and in the library fpts and then where to go from here and where to learn more about it if you're interested so first let's look at an example this is a simple function which just goes to an api and downloads some data and returns it as a result um and i want you to look for a few uh errors or air places where this function can fail i'll wait i mean it's a simple function right all it does is it just saves some data and returns it well i see two areas for problems to arise firstly this i just blindly assign the result to a type assuming it's of a certain type uh i've seen this fail countless times um even when the api we can trust the api or whether it's our api stuff goes wrong somewhere so this this is bound to cause errors and then also secondly i have a bit of a problem with uh this return type promise this is more of a technical one but this function returns an error right and this promise doesn't really tell us whether or not this function returns an error so as a consumer of this function you either have to you know look into it and check and then go that way or just program defensively and so that means you have to assume that every promise can fail and by extension you like why do you stop at promises you have to assume that every function can fail and so are you just going to wrap try catches around every single uh every single function that happens um what if you look in this function you see it doesn't fail so you don't handle it and then down the track it gets changed um by by yourself or someone else or even it's a dependency you have no idea that this function change and it can now throw an error and then boom your application blows up to me this seems like a sub a sub optimal solution and i think we can do better so let's look a bit into uh before we look into the solution let's look a bit into functional programming and fpts and their pros and cons so the way i like to explain functional programming to someone who already has typescript knowledge is it kind of does the same for typescript as what typescript does to javascript so if you go from javascript to typescript you kind of get data contracts so this means that touchscreen says hey you know i'm going to handle making sure that all the data flows around your application correctly and that you know all these all these return types and parameter types and everything you set up they all match together perfectly i'm going to handle that for you and so you can lean on the the the compiler to to help you ensure that your data flows around correctly and then if something breaks it will tell you if you're a factor or something i see functional programming working the same way except with behavior so now no longer are you just encoding your how the data flows around your application but you're also encoding how the errors and the success states and how your app how your functions and applications actually behave you're encoding that into the type system and you can start to lean on the compiler to help you ensure that your your function your application kind of fits together these these behaviors fit together so if a function can throw an error you're forced to handle it you have to handle it and also lets you know if something changes or things like this in the future so it can be very very useful uh and set up with the right kind of framework it's not super cumbersome as we'll see and another thing i like to say about functional programming is let's let's you know often you'll be writing nonfunctional code so object oriented or something like this and you kind of will be adopting best practices uh having guidelines and you try to get your code to a good state and sometimes it can feel like you're pushing a ball up a hill so then when you actually get to the top of the hill it can feel like your your your code can kind of fall out of this happy state super easy if someone just doesn't follow the code guidelines or the you know some code review is missed like this ball can very easily roll off the top and you're back in a bad state where your code isn't correct or test testable or isolatable etc functional programming is often seen as a pit of success um because of how it forces you to architect your applications since it forces you to write your applications in a certain way and then it has the compiler to help you out it's seen as a lot easier to uh get your um your code into this pit of success where it's kind of harder to push to put to get out of it if you if you step outside the compiler says hey look that's not going to work buddy um and and it pushes you back into there there's you know there's no there's less room for error that's why it's called a pit of success and i believe there's actually three pits of success with um functional code uh isolation correctness and testability this talk will focus mostly on correctness but if you're looking for an explanation about other um other or even looking for an explanation about how uh function functional programming leads to the other pits of success check out this talk from mark seaman uh honestly it's really really good it's now long and his other talks are also amazing honestly let's go just go check it out it's great so on to fpts this is a library for typescript which implements functional programming it's written by a guy called giulio kenti uh it's been around for a while it's got 4.7 k stars so it's pretty um pretty stable and it has a an ecosystem of libraries which we will see later on some pros and cons in my eyes i think that functional code is more correct because of the the types and the and the behaviors and how it's encoded there's less code based just by design refactoring becomes easier because you can lean on the compiler to ensure your behavior and errors are handled correctly validation becomes easier as you'll see in this talk code becomes more isolated and thus becomes more testable on the downsides unfortunately typescript wasn't made for fp so the experience won't be quite as elegant as it is in languages like haskell or fsharp which are designed for functional programming but don't let this sway you i think it's still uh there are still benefits to be had but maybe if you're you know if you're sold in this function think you'll you'll switch to one of those languages in the future but it's i think it's nice to be able to to try it out in typescript anyway without having to change everything um and also in the same way that typescript isn't really recommended for super small projects this also isn't really recommended for super small projects um it's recommended for big projects because it helps you maintain projects over time and lastly uh my another downside is your qa team might not have any work to do so your manager might come to you and say hey man like give me some bugs so the qa team can like check them and you're like sorry dude got nothing imagine that not running any bugs well functional programming won't stop you writing all your bugs but they'll definitely help you stop writing some so let's look and look a little bit into how functional application is architected usually we have this kind of pure area where everything is nice and perfect and we have this impure layer which is the interface the outside world where your validation your side effects and so on happen and you have this little guard that stands there and let's look at what's a simple example of how we can kind of fix our problems from before so you probably already have this type for your api response and how we would do this with fpts and its system library iots if we would rewrite that type using iots iots is like a type system excuse me ots is a type system and we can just straight modify that across iots is really powerful it has lots of custom types you can define your own types honestly it's great and then we can also pull that touchscript type out at the bottom you see type i use it so we're pulling that pulling out an actual state the same type out of it uh in the end but what this allows us to do is that if we look at our function from before rewritten we have this user.decode function uh which now what it will do is it will go and check that whole api response and check every single key in value to make sure that that is as we expect um and you can use this all over the place in form validation api requests uh also on your back end is mostly where it's used um and it's great and you can now be certain when you uh use this in your application that it's going to be passed around perfectly then it will be perfect but if you write this you might hover over you might look at the user the user and see i wonder what type it is and it's turns out to be this either type you think uh what fred what is that well an either type is simply a type which can represent a failure or a success and the left is the failure the right is the success so in this case if there's an error right is would be user type um and how we kind of handle this in this example is we're just going to collapse that down to one value when we return it so we're going to fold how we do that we call this fold thing fold method we get from uh fpts we import from fpts and we fold the user down and we have we say what do we do when it's an error what do we do when it's a success whatever return so what this looks like written out is when it's a left an error we return a user not found error when it's the user we just return a user pretty simple and then this will return as a promise um to to the consumer now the second area i talked about before or um wanted to look at was the promise and i said that this doesn't really encode um doesn't really show that it's functioning an error well what would that look like with under functional programming well we had this eta type we could just say this function returns an ether so now we say this function either returns uh either a success that's either an error or a success which is an eye user so uh now we've kind of encoded into that function contract that this this function can error and so the consumers one they can see that it errors and two they're forced to handle it because of how functional programming um happens um but they and so what we what they do oh and what the function body looks like here is we can actually just return that that's either we get from the b code to the to the consumer to the parent and then you know if the thing is they're they're informed that there's this error but they don't have to handle it they can also keep passing it up um and they could just return like the result of this um function to their parent as well and so on and there's there's various uh ways that f various patterns that exist to help you do this in a pretty elegant way briefly want to show that there's a bunch of other types that exist in functional programming which have relationships to javascript and typescript um and there's even some types which kind of represent behaviors which don't even exist in javascript or typescript and so you can define your applications more expressively with with functional programming um but yeah that's that's been most of my talk if you're interested and you want to learn more i have a longer talk half an hour long where i really go uh somewhat in depth about how to build an actual functional application and what these kind of patterns look like and how they help you so go check it out um and then also there's this fiveminute talk from robin mccorney when he talks a little bit similar to what i've done about form validation with fpts there's also these two libraries which might help you integrate fpts into your react application um and yeah i wanted to take a moment to thank my company imogex a sponsor of this conference for letting me put on this talk and personally i enjoy working imagex a lot they're a a great team and there's some good people on the team and everyone really knows their stuff and if you're interested in our service come check out our booth um and you'll get some account credit otherwise that's been my talk i'm pretty foggidy uh and i wish you all the best of you for the rest of your conference take care hi everybody i'm matt billman cofounder and ceo of netlify it's great to be back at the reactathon this time in this online virtual edition to talk about the jam stack architecture and netlify our endtoend platform for managing modern web properties when we think about web properties 10 years ago if i had gone to most designers and told them that today uh their mean design tool will no longer be a desktop application like photoshop and illustrator it'll just be a url they open in the browser they probably wouldn't have believed me but with tools like figma that's really becoming the case office suites coding environment the modern browser is an amazing powerful platform that we can build deep and engaging user experiences with but traditionally to build these we've had to manage provision operate tons of infrastructure database servers application servers web servers load balancers cdn distribution setting up caching rules to cash purchase invalidations all of this it's traditionally been a really complex system to operate web properties at scale this is one of the things that we've really worked to try to change with netlify and with jamstack as an architectural approach the idea behind both notifying the damstack is this idea of like how much can we prebuild up front instead of running this whole stack with all these complex servers all this infrastructure can we run a build step and then take the output as a prebuilt web application a website and distribute it to a cdn with nodes all over the world and at nutify we really saw that if if we could do that we could also tie it into this git centric workflow that most of us as developers have already adopted working through branches pull requests commits and so on and just expecting that their deploys will flow to the edge from each of those we also quickly started seeing that content updates could be pulled in during build time from headless cmss like contentful or sanity or cosmic and deployed directly to the edge as well and build an orchestration system for tying all of that together the same even with data updates a lot of those can be accessed at build time preprocessed and deployed globally now this approach with the jam stack it's not just about like building static sites from different data sources and so on it's really about a mental model where we start reversing the traditional flow of a web request response cycle so with the traditional way we built web applications every request from the browser would go through this whole stack of a request and response cycle involving sometimes a cdn then passing through to a web server an application server that would then talk to all of our apis and services to our main database into our search cluster generate html and then send that html back to the browser now with the new sort of modern serverless world of course we can keep the exact same architecture we can run serverless functions that just connect to our apis and services to our database to our search cluster and send to respond back to back to the client and that's one way of of using serverless but it comes with all of the sort of traditional tradeoffs of this architecture and the time it takes to go through this request response cycle with the jam stack approach we try to really shorten the distance to the user and sort of reverse the flow of the request response cycle so instead of having the browser talk to an application server they'll talk to an api on every request we try to just have our precompute step our build service that just talks to apis talk to databases talk to our search cluster prebuilt as much as possible up front and then send it out in advance to each node and and this means that the actual request to from from the user's browser just hit an edge note get a prebuilt html site and and we'll get a response to the user in milliseconds incredibly fast great user experience now of course we might still have a whole runtime we might be building an application like app.netlife.com that we can't completely prebuild up front um but there's no reason that we shouldn't just shorten the distance to the apis and services as well why go through that whole stack of cdns of load balancers of web servers application servers to talk to our apis and services if we can just do it straight from the browser all through the net its network this allows some of these services like algolia or fauna db or the like to in themselves be globally distributed and to the in themselves build really advanced hard to imitate caching infrastructures that will give the user incredibly fast response times now for this build step where we prebuilt everything up front we've seen this whole movement of different frameworks and site generators emerge tools like 11c or scully for angular or next for vue hugo as a really fast scopebased generator and chapter grid sum next year is less like if if you go to jamstack.org you can find a massive list on them if we take next year's as an example it's become like a really important uh site generator tool and application framework for the for the react community it it allows you to group pages just based on on the convention and based on the name of your file it'll generate like a prebuilt page that we can distribute directly to the edge at build time um you can fetch data at at build time through the git static props method and and we'll know that like we if you use netlife netlife's build system will run this it'll prebuild all the different urls and distribute them with an atomic deploy directly to the edge in handling all the all the assets now traditionally when we had web servers we didn't just use them to serve responses we also had a set of of like sort of typically declarative compute rules around like routing rules redirect rules rewrite rules and so on and on netlify we will we allow you to do all of these things directly at the edge as well through our netlife counterfeit format or our underscore redirects format again we really tie into this git centric workflow so it's this core idea that you can just add a file to your repository either in idlify tamil file or redirect file this is just a really simple example of a redirects file that just defines simple like 301 redirects from one destination to another this is an example of a terminal redirect that's a bit more complex that will say like if the language of the end user is set to english and the country is the united states then do this redirect and otherwise don't do it so we can build like complex localized version of our app and have the edge nodes directly handle this logic apart from distributing these prebuilt html pages and running routing rules of course sometimes you also have to actually build custom api endpoint that that your front end can talk to sometimes you'll have services like stripe that you can talk to directly but often you might even even when you're talking to those need a secret and need something um that runs server side at netlify we've we've embraced this serverless paradigm in terms of serverless functions where you can just add a functions folder to your repository and every file there will be set up a with routing based on conveying conventions so in this example we just have a hello js they'll automatically respond under dot netlife function slash hello now if you're using next test you can also use these functions to actually go back to sort of the traditional serverside rendered approach just by saying get serverside props instead of get static props you do the same cycle talk to your data source but by marking this as as get server side props we'll actually like delegate this to a server side function that will generate the page you request on demand this comes of course with a lot of the same tradeoffs that that we've had with traditional serverside architectures we can add layers of caching in front of it and so on um but when you can you should still try to see can we prebuild as much as possible upfront that'll always be the fastest the most secure and the most predictable sometimes you'll also need to run background processes in like let's let's take the subscription example you might have a have a function that's a quick api endpoint that adds a new subscriber to a plan but then once you do that you might do a bunch of steps you might send a new email you might add them to a marketing automation system and so on with netlify we have a concept called background functions and it's just as simple as serp as serverless functions you just append dash background to any function and now when you trigger it instead of immediately giving a response you'll just trigger a background process that can run up to 15 minutes great for scheduled tests or these kind of background operations that you do when something happens another really interesting aspect of this architecture is again like this edge layer where we just talked about routing right like language based versioning and so on we also just that netify introduced a new a new functionality that we talked about as edge handlers this is for when the declarative set of routing rules just don't cut it let's say you want to really build advanced personalization or authentication based on very detailed rules or you want to build api gatewaylike functionality where you can route to authenticated services directly from the edge node with a netifies edge handlers you can simply add an edge handlers folder to to your git repository and start writing a handlers just let you just like you would write your serverless functions these can really intercept this request response cycle and you should typically use them for things that you can do within a few milliseconds again we don't want to go back to this old style architecture of everything being part of a very long request response cycle but for example let's say you just want to check an authorization header if someone access a secret part of your site and you want to do some custom logic in in in response to that this would be a little exchanger that you could write that that do this imagine you want to serve like a specific set of javascript a specific bundle of javascript to mobile browsers and another one to desktop browsers i don't recommend this but you would totally write an and an edge handler that would just look at the user agent and then decide which bundle version to serve in directly from the edge network so just to put these different pieces together like when you build with the jam stack and when you build on netlify the types of primitives we offer is first of all the precompute layer that's really our build service you can run a long process here that can stitch together hundreds of thousands of html pages and our service will push the ones that change directly to the edge and prepare them there these will deliver be delivered to the end user almost instantly and it's always sort of the fastest the most secure the most the the simplest to reason about that you can do then we have this layer of routing and transformations that split between like our declarative route engine in tunnel files so underscore redirects and then edge handlers where you can fully program the edge layer then there's the serverless functions that can run in a few seconds like typically great for api in point micro services or glue layer or even for serverside rendering like with get serverside props in next and then background functions for when you need compute that takes longer when you don't want to be trapped inside a request response cycle when you want to trigger a job and just run it in the background do actions and and trigger requests as you can see like at netlify we're really building out this whole platform around the jamstack architectural approach that makes it incredibly easy to write great user experiences with great performance without ever having to work with um operating servers maintaining infrastructure or thinking about complex deployment systems or pipelines you just work in kit you follow a few clear conventions and our platform will take care of all of the operations and infrastructure for you if you're interested specifically in in how we handle next year's is since this is so focused on react and next year's is of course really popular in the react world right now go to netlify.com slash with slash next years and reach read much more about it thank you so much have a great rest of the conference hi my name is max i'm a software engineer at flexport today i'll be talking about how we streamline mobile development using react native and expo there'll be four sections first some background then three deep dives into different areas where we're using these tools um to improve our development lifecycle so a little bit of context flexport is a freight forwarder we help facilitate the movement of large shipments of cargo across the world this is an example of an ocean container moving from an origin factory to a destination warehouse the section on the right with the green uh shows destination trucking and that's where our mobile app is being used this part of the shipment life cycle is really important for our customers because it's when their warehouses need to get ready to prepare to receive the cargo and then package it and send it out to customers of theirs so to help facilitate gathering data on this section of the lifecycle we built products called transmission transmission is a software suite that trucking carriers can use to manage their fleets internally as well as to provide updates to flexport and flexpose clients and so this mobile screen these mobile screenshots so what this is like for a driver or one of these trucking carriers they can enter a container number and then provide pickup and delivery events and then this data is useful both for flexport and also for the trucking carrier because the trucking carrier can see data like where their truckers are at a given time when they're due back things like that and so transmission is an important part of our ecosystem for managing destination trucking but i included this slide because i want to show that it's not the only thing that we're working on in this area so you can see that on the bottom containers are going from ocean ports sometimes to rail terminals and then filing to client warehouses we have a lot of different data sources including ocean carriers terminals api integrations we built apps for the warehouses and so we're doing a lot of different stuff to get this data and the mobile app is just one of the things we're doing and so this is one of the reasons we decided upon using react native is because we can increase the leverage of our team writing one code base in javascript that we're familiar with and deploying native mobile apps to both android and ios really really awesome expo allows us to make changes to these applications and deploy them to our clients phones without needing to make binaries and go through the app store approval process and things like that so it's much easier to add small features change copy fix bugs that sort of thing using exposed deployment lifecycle so we expected these benefits going in but the thing that we were surprised by is how much is possible to build on top of expo's um javascript bundle management system for our own internal tooling and so that's what these next three features we'll highlight so the first is the mobile sandbox so some context here is we have at flexport internally something called the web sandbox so here you can push a feature branch to get to github and then take your branch name put it into a sandbox tool and then launch a version of our web app running within obfuscated development database and uh but kind of fully functional and and then share share that with customers ems designers things like that um and get feedback on it before you merge into master so here you can see that this is a pull request from a few years ago it used to be called staging instead of sandbox but there's a url generated for your branch in particular that anyone can load internally on the vpn um to test things out so you wanted something similar like this for mobile but it turns out it's not a onetoone mapping because with web there's a client code running in a browser right we have a wrapped front end and there's server code running on aws there's a rails backend and so when we push the sandbox for web code we just push the front end and backend code to a single server and then when the client code running in the browser fetches the javascript bundle to run the web app it's fetching the code from your branch but with mobile the react native front end code isn't coming from our backend it's coming from the mobile app stores in the form of downloaded app binaries as well as from expo's bundle servers where expo is sending javascript bundles to the phones to change behavior on the phones and that's where most of our business logic is leading and so if we want to create something like a sandbox we it's insufficient to just push the front end code to the same server as the back end code so we ended up doing is using exposed servers and creating different release versions of the app for each sandbox that makes it possible to replicate the sandbox experience on um on mobile and so the code is something like this it's like hey deploy the sandbox um set this mobile app to talk to this particular sandbox backend publish the mobile app and then you can see that's just standard we're just running the standard expo cli commands but we're doing it in kind of a programmatic way and so the experience from a developer's perspective is you can just check this box i want a mobile sandbox and then you'll get a link to expo and you can paste the qr code into your pull request your designer or pm can review it there so really cool feature and it's just something we were very we were able to build on top of xbox javascript bundles automatic deployment so for web we have continuous deployment every time we commit to master we're taking off the deploy pipeline um we wanted something similar for mobile um we built one so we have two versions of the operating one is production and one is release candidate and so the release candidate one is these are this is unlike the sandbox in the sandbox we're just using separate um release channels within the same expo project but here we actually have two server expo projects two separate app binaries two separate listings in the stores we actually have four store listings total um android and ios and then prod and our prod and rc for each of those and so our continuous deployment pipeline every hour is cutting master building the javascript bundle pushing it to expo and then for production we're using a similar code path but you have to click the button to do it just because we don't want to be doing that every time there's a commit and so the architecture here is like we have you can have a phone running both the prod app and the rc app because there's separate listings in the app store and then get updates independently and they are both they're both talking to the rails backing so it's production light in that sense so the code for this is you know running in our in our deployment pipeline and it's it's similar so build the mobile app publish the expo you'll notice the release channel is default here and then we persist the app manifest i'll talk more about that in a second but first i want to talk about why the release channel is default that's because in our code base in master the javascript uh the configuration of the expo app is for the release candidate so this is what the source code looks like everything is released candidate and so the default release candidate release channel for expo is the thing that has our javascript code for so when we push to production the code is a little bit different we send some slack alerts which are useful and then we set production values in app.json that basically takes the master code you see here and then replaces release candidate with production so this way we have one version of our app.json checked into master no one is ever manually editing this or trying to keep it in sync between release candidate and production instead as part of our build pipeline we programmatically update the values into app.json and then we build the app push it to the default release channel for the slug transmission production in this case and then persist the out manifest and so this is it just feels very clean and there's only one way to push to production and that's using our builtin pipeline and it does these things in a programmatic way so there's no risk of manual messing up so the mobile app manifest has data about the version that was pushed to expo and we persist this in our database and i'll talk about why that's useful in a second so here's a quick screenshot of the um slack notification so what do we do with the persisted data we prompt users to upgrade so we can ask users hey um your app is out of date please upgrade and it's kind of an optional thing they can still use the app but there's a spanner up top or if we are like really you know we see a bug in a previous version or there's some new functionality that we really need all users to have we can block access to the app and say hey you have to upgrade this to keep using it and so here's some of the code in our configuration for this and then we prompt users to do upgrading and we can prompt not only to upgrade binaries but also to prompt update the javascript bundles if it's just like a lightweight refresh so in that case a user can tap this thing tap the red banner it'll just refresh the app they'll get the latest javascript bundle good to go um and so all of this stuff was just very easy to layer on top of expo's manifest system and so hopefully this is useful to others uh we really like using these tools check out this blog post if you have any questions i want to give a shout out to some of my teammates derek and yongfu for helping to work on these features thanks i was waking up the rest of my life to see nothing else matters on great days i've been waiting all day to let you i want to stay know forever is the space between us is hi everyone my name is benjamin dunphy and i'm the organizer of reactathon and i just wanted to personally welcome you to reactathon online worldwide you know when i started reactathon back in 2017 i could have never imagined the amazing community we would have built and i also could not have imagined what has happened here in 2020 and so i want to thank you for your understanding for your patience and for your trust as we move this event online to a remote worldwide safe atmosphere as we wait the next inperson event where we can all come together until then please enjoy reactathon online worldwide 2020. have a great conference everyone hello everyone welcome welcome welcome we're here we're worldwide we are coming at you through the interwebs and we are so excited to be here with you today my name is anjana vakil i'm going to be one of your mcs for the next few days i'm a software developer and developer advocate at observable really excited to be here uh coming at you from san francisco today jonathan oh i'm sorry we've got a little bit of a tiny delay i think because i'm in tennessee uh so we have just that little bit of latency so you might see that amongst other things my name is jonathan catrell i am a director of engineering at pbs i am also the host of a podcast called developer t and i will also be an emcee over the next couple of days we're very excited for everything that's getting ready to happen you know this has been a difficult year for everybody probably everybody who's connected to uh to the to the conference today has their own story about 2020 and uh it's been a unique year it's it's come with its challenges challenges always make us better but we're not going to focus on the challenges for this for this conference instead we're going to focus on kind of geeking out together about react and uh the various kind of things around the react world and there are people around the world who are connected to this conference today and we're really excited about it yeah we are super excited to have you all here with us today we are also really grateful to the sponsors that make this event the next few days possible so we just want to give a huge shout out and thank you to our sponsors flexport course hero imagex verso off xero hasera vonage netlify and mux thank you so much and if you didn't get a chance to hang out with our sponsors already at their expo boost this morning you'll have other opportunities to do so this afternoon and over the next two days we encourage you to go and learn from them and uh it's it's not just because they're the sponsors and we want them to be happy with us as a conference is because they have some of the world's top engineers uh and and some of the hottest companies in the bay area but also with remote work uh around the world so make sure you go and check those out by the way we're on a platform called hop in uh this is a a new way of doing uh conferences for a lot of us but i encourage you to go and click around a little bit there's a lot to learn uh about hop in i guess there's not a lot to learn there's a lot to explore i guess is a better way to put it it's pretty easy to use but certainly don't sit back if you're just sitting back and watching the talks you're not going to get all that you can out of this conference there's a lot that we can and we'll talk about it a little bit more in the kind of interim between the talks as well and you know suggest that you go to certain parts of hopin but definitely go and check out those uh sponsor expos yeah absolutely and again we are all really excited to have you all here with us uh virtually with us in hoppin the really great thing about hopin is that it allows us all attendees at the conference speakers mcs everybody around the uh reactathon world to be able to connect and get to know each other and there's even some cool features you can explore like to be randomly paired uh to meet somebody just like you would maybe bumping into them at a sponsor booth or uh in line for the bathroom between the talks at a irl conference so we're hoping that hopit allows us to all connect in the best way that we can uh given the virtual constraints of our environment here so really really thankful to all of you who are here with us today whether you're joining us live in hopin or whether you're tuning in through the live stream hello and we are super super grateful especially to everybody who was planning to attend reactathon in san francisco back in march i know i was and has been waiting the better part of a year uh for this uh really exciting new addition to happen so we could not be more thrilled to have everybody here together today in the constraints of our virtual world but we do need to keep in mind that we are still all in a community so jonathan is going to give us a special update about uh how we can be mindful of each other's experience yeah there's there's an excellent way that we can kind of come together and uh and hold each other accountable and that's a code of conduct you know it's a very explicit thing that we have in real life conferences and this is no different we want to respect each other whether we're behind a screen or not so there is a code of conduct the tldr is please be considerate respectful and take responsibility for your actions and please read the full code of conduct at reactathon.com conduct yeah and we want to make sure that this just like an inperson conference would be that this is a really safe welcoming learning focused environment uh for everyone so in that interest we want to make sure that if anyone if you ever feel unsafe harassed or someone is trolling or otherwise making your conference experience unpleasant or unsafe you can reach out to the organizer so that we can act on that so if you find someone is harassing you or making your experience unsafe in hop in there's actually a feature you can click on their profile and you would have an option to report user when you do that the conference organizers will receive a report which then they can investigate and take the necessary actions as per the code of conduct so once again please make sure to check out the code of conduct at reactathon.com conduct and here's the great thing we have three days of content three days of amazing content and networking learning education it's all planned for you and each of these uh days follow a similar format that anjana is going to talk about yeah so as you uh have already seen we're going to start out the day with some morning workshops and then a sponsor expo we're going to hear a little bit some from some sponsors and there'll be time for everybody to reach out to each other and do some networking on the hopin platform also talk to the sponsors visit their booths all that good stuff and just get yourself really excited for the rest of the day which is going to consist of some stage talks on the morning and jonathan and i will be here with you on the stage uh for all three days uh to to guide us all through it and we will also have following those stage talks we will have 90minute topic table sessions with experts and speakers and folks who you can connect with more directly around specific topics of interest then at the end of the day we're going to cap things off with another hour of some stage talks to really make sure that our brains are chock full of new ideas and exciting information uh when we leave at the end of the day so that is what our next few days are gonna look like but jonathan i think we've been yapping and we should just uh you know get this show on the road as they say what do you think yeah it's time to hand time to hand the stage over to our first guest for the day guillermo rauch uh guillermo is the founder and ceo of versailles uh he is uh the cocreator of now uh if you've ever used now if you haven't it was pretty awesome uh and next js and former cto and the cofounder of learn boost and cloud up acquired by wordpress in 2013 he created the first mongodb orm for node.js uh and mongoose.js before that he was a core developer of the mootools javascript framework that's a throwback if there ever was one and he's been working on react since its early days all right and and here's the cool thing he's gonna share with you a post jam stack uh talk today uh the post jam stack world and the rise of hybrid frameworks yes so please join us in welcoming guillermo rauch for the opening keynote of reactathon worldwide hello everybody uh this is guillermo and i'm really excited to be here with you today hope you're all staying safe i'm here to talk about today about the post gemstock world and what that entails and the rise of uh hybrid frameworks like nexjs so i like to start by contextualizing kind of uh the state that we're in today and the problems that we're solving and perhaps starting with a little bit of a green message but later on turns really optimistic i promise which is that the web is in jeopardy and to illustrate that i look back to 2018 uh really interesting tweet that i have since kind of memorized almost which talks about the this website usa today and this gentleman gentlemen marcel went ahead and did a before and after performance audit by just removing a lot of junk from that website a lot of unnecessary javascript requests a lot of unnecessary downloads a lot of unnecessary craft and yes he did remove the gdpr banner but that's not really entirely what's wrong with it so what he found is that before it would take an akitio nod 14 000 milliseconds so that's 14 seconds to get to the first paint of this usa today website and after removing everything pretty much other than the text and we'll get into why this concept of craft or additional js is important or not later in the presentation he found that he could bring everything down to three seconds so he went uh from a load time of uh 45 seconds to three seconds so this is why i think the web is in jeopardy and by the way this was in 2018 but the situation has really not gotten a lot better since because if you look at the progression of key metrics like first content full paint and on load and largest content in full paint which is a metric that hasn't merged most recently it's pretty much it's gotten better for sure but it's pretty much been a very slow improvement and when it comes down to metrics like first contentful paint and largest content for paint we don't see that big of a difference so we would hope and that's where that's what really this presentation is all about is i think we can make this a lot better but we need to understand the problem fully and we need to attack it in the best possible way with the best possible tools and with the best possible approaches and before i go too much further i think something that perhaps not a lot of presentations go into which is this concept of what do we mean exactly by the web right like we obviously all talk about it but there's three properties that i think about when i think about the web that i would love personally to see improve and a lot of organizations and businesses and individuals i think throughout the world would love to see improvement one of the key things is that this web is global so when we look at the data for how things have changed in terms of performance over the past few years and we look at you know this orange bar line at the top we'll see that india is possibly you know twice as bad as for example south korea in this case um and interestingly enough india is where a lot of the growth is a lot of where the best tech companies and unicorns have been created it's where a lot of the people are coming online so this matters a lot and interestingly enough that web that i'm talking about is also increasingly mobile right so i like to talk about this more recent uh data point which i found uh from josh camille where he talks about you know the most common device in the world today and guess what that device is not the iphone 12 pro max super m1 duper it's actually more like this phone that you see on the screen here which is a xiaomi redmi 8 and it's the most common budget smartphone in india which is one of these key areas that we're taking a look at and one of the things he finds is that the web side by side so on the right hand side you have an iphone and on the left you have this xiaomi redmi average indian smartphone so you can see that there's quite a bit more spinning on this website on the left and that's a very very optimized website with a lot of resources behind it that in this case happens to put up almost entirely on the client side right so it's not something that has compre rendered from a server which will get into the benefits of it later and actually that's still pretty good because all things considered because he goes on to say things get problematic when we visit news sites and i think because of all the tracking snippets and such it's a pretty good guess these sites take forever so here's the new york times and before we go on uh for a lot of those of you that have already in your personal experience identified this problem with the web because we all notice that when we just use the web every day uh yes this is gonna be a little painful to watch so let's take a look so he's tapping on on a story here and you can see on the right hand side that actually still took pretty long for my liking personally but notice that on the left and speaking and is still going uh so this is kind of the reality of today right like you can you can buy one of these phones on amazon and run this test yourself and what we're taking a look at here is a what in our minds uh in in an oversimplified model we could say well this is a super simple website right it's just like it's literally an online newspaper how how could it be like this right so he goes on to make a lot of interesting observations one of them is that ad heavy wordpress sites and like modern web apps seem to be really really bad for him so it's actually an interesting concept there like the idea of ads and thirdparty scripts then he mentions every major react tab and we're going to get into why this idea of that major react app happens to be really relevant here since it's either server rendered or other forms of pregeneration so he notices that that boot up time is actually not bad he does mention the time to interactive is slow and we certainly need to fix that so another great observation there and he says that next js for example has done a lot here because nexjs in particular offers both server rendering and prerendering so gatsby's more focused on the latter but he says that that's a property that is making that web feel faster especially when you first load the page and the the third property i think about when i think about what is the web to me is that and it goes into this concept of he makes the observation that major websites built with react are not as bad is that the web is not all evenly distributed nor build a like so another interesting tweet that came from one of the team members of the google chrome turned me to this idea of what does the traffic distribution of the web look like and this is why i use the dragon emoji is that i try to find an animal that both had a very long tail and b had a lot of potential that we can unleash so one of the key insights from this telemetry that came from google chrome is that the head of the web which is just 10 websites represents 33 of global page views and those are actually discrete page rendering so we're not thinking traffic here because we've probably heard the data like netflix has tons of the internet's bandwidth or whatever this is in particular pages so where are you opening a web browser to go to and then the tours of the web which is a lot of other websites in particular 10 000 so the body of this dragon the torso is 10 000 that's also 33 and then what's kind of interesting is that the long tail of the web is up to 3 million websites depending on the device and that represents 33 so just torso and head which is not that many websites represent 50 so if you consider like the top thousand actually that's like the head and a little bit more that's 50 and if you consider head and torso entirely that's you know nearly 66 or so so what's interesting too is that if you correlate it with if you go and look how these things are built you start noticing a pattern or a trend that i think is really interesting in the context of thinking about jam stack which is the static web is more of the realm of that like long tail where there's more individual creators or perhaps you know you fire and forget you build it or perhaps you use some sort of um static generation tool and you just not updated as frequently and for example like long build times don't matter as much but then as you start traversing into the more you know heavy traffic web we know it's actually the opposite it's super dynamic lots and lots of pages you could never possibly build them all in in a build process through ci cd and also we notice that it's hyper personalized so each user is getting a different page so there's not much that's a static there and that correlates a lot with what we're seeing in terms of that you know where people are spending time and what technology is best suited for that so in conclusion the larger the site the more likely that performance matters a lot right because like if you're the new york times you're everywhere and you have a big business at stake and then and unfortunately what we're seeing from all this from the data and the anik data so the things that users are reporting or recording performance is not really that great that great so this made me think i'll spend a lot of time thinking about like okay what is the difference between this monster diamond and called fagozon uh it's pretty cool i hope i'm an inventor of that so what's the difference between that fagozon uh so this top 10 websites that seemingly have figured it all out they're both dynamic and super performant and they keep evolving fearlessly and their page loads are fast so what's the difference between them and the rest of the web and some of the conclusions that we found is that if you look at like for example how they consider frontend development they have lots of teams supporting fairly advanced front infrastructure and they have a unified approach a unified framework a lot of automation um it when it comes down to go into production that's also very much automated so the front end developer doesn't have to figure out the production environment and they can usually reproduce that production environment really well throughout the development process and they're assisted by a lot of data and finally there's this idea of reusing so reusing components reusing design systems and learning from the past so there's a lot of um sort of intelligence and historical data has been built up because frankly those top ten have had a lot of you know uh a lot a bit of a head start no pun intended because they've been around for so long so to fix it we i think we can take a page and we can learn from this so what we're trying to do uh in our company is give you the framework that unified frontend infrastructure solution that unified tooling that continues to get improved without you having to deal with webpack configurations and other implementation details in a platform that you can fearlessly evolve the evolution of your front end in through preview deployments constant benchmarking testing your site and results in a real production environment a global cdn and so on and one of the things that we notice as well is that nexus demonstrated that it has quite a bit of a fit specifically in this top segment of the web this most common side so once we're frankly you want to spend the most time optimizing because like i said number one they have a reason to constantly invest in better performance and their performance is not there yet so our approach consists in wrapping react which gives you this incredible unit of collaboration in the component so you build a component and you can reuse it and your entire team benefits from every improvement that you make to that component i like to call it the lego brick of the web then you can constantly preview your front and so every time you push to get when you import your project into versailles you get a url you can see it here at the shop get new checkout url and you can share that with the rest of your team and then when you ship everything around performance has already been figured out automatically for the entire team but most importantly what we've noticed what we've been noticing is that even though our motto is developed previous ship it really is in this iteration phase and collaboration phase where a lot of the value in making the web better really resides and when it comes down to iteration and when it comes down to understanding performance deeply i think one of the most important things is to have a very very good lens of the reality of the state of your front ends and your websites so the common expectation that i've seen sometimes in the ecosystem is okay so this is the sort of the image of the web and i know that if i have a cdn that will ensure that everything is fast and especially if it's been prerendered or statically generated it's all good it's fast and then i think the only thing i need to do is figure out the size of my js bundle which that is like the other big thing there's only there's these two things is that i have a fast cdn i use jam stack static generation whatever and as long as i don't have a lot of js in the client side i'm good reality however is really quite different from that oversimplified model that a lot of us used to have in the past so a cdn nowadays is kind of table stakes most websites nowadays have it and we go to great lengths to automate it and make it available and free for you but then performance becomes quite an interesting subject quite an interesting rabbit hole i'd like to start with this example of box shadow because when facebook rewrote their facebook.com in the latest and greatest technologies in 2020 using react and for the first time they were using the entirety of react very similar to how nexjs works where the entire page is driven by react whereas in their past it used to be a combination of php and legacy technology and all that so a gentleman went ahead and started doing what every web developer does right we inspect the open web so they went ahead and like took a look at like how this new facebook thing was being built and this gentleman ahmad noticed that the background at the very top was not box shadow with css it was actually a background image yes so the new facebook this experts of the web the creators of react in 2020 were using an image which for all of you that have been using the web for many many years like myself you remember that this is how we used to do this like 10 to 15 years ago because we didn't have the box shadow properly so they're they're sort of going back and why was that so one of the performance engineers at facebook uh graciously uh noted that it's for performance a box shadow in the floating header like that was killing scroll performance in browsers and mateos goes ahead and asked so i don't know if this is a question but how do you guys test that and this again we're like expectation reality or a little bit um uh not what we expect which is honestly you just scroll the page and you would notice so like i said teams like facebook spend a lot of time worrying about performance and obviously they get great results from that and sometimes it's very sophisticated and sometimes it's very much that good old you know feeling test so and here's why i'd like to use this image of the iceberg which is this mass of complexity that we tend to ignore in our oversimplified models has so many things that contribute to performance like the latest web font that you copied and pasted from somewhere in the web with lots of css files and js files and so on your gdpr popup that comes from some thirdparty script and your marketing team as an analytics script and then your product teams as analytics script and as uh josh was mentioning earlier the ads and trackers play a big role in exception reporting scripts and session recording scripts for product teams and images and your js bundle and i think here's where you know the solution which that tweet from usa today was kind of alluding to is where also i think we have to be on the side of reality which is it's very easy to say well just throw all that away and then your website will be fast and i'm actually willing to bet that that would be the case for the most part if you throw all that away then i'm sure your website would be fast but then i think these things got there not because we're intending to make the web slow but because we didn't have the right workflow in many cases we didn't have the right tools so for example if you now use the nexjs image component that image which was a big part of the iceberg because for example you were giving a gigantic image that was unoptimized to a very small screen now that gets fixed so um it's not that you had to remove the image instead of how to make it optimal and and that's where my sort of perception here is you have to focus on real solutions deleting them deleting all that sounds good but it's not very realistic for most businesses and one of the solutions really ends up being the good all cloud computing and i like to use this stock photo that i found in google images because notice that like the cloud is streaming ones and zeros to a screen which is actually pretty different from how the actual cloud works but it's a good metaphor for okay instead of trying to run everything on my device perhaps i can start doing some things at different times i can start doing some things earlier in the life cycle i could do them on the edge i could do them on my server i could do it at build time sometimes and then it begins sort of a streaming one one unified painting of the web that i want to deliver so one of the strategies here that's quite obvious is okay so instead of doing competition the device shifted to the cloud so all those spinners that we saw when the app was booting up on a slower device would have happened on a more powerful device a more powerful literally machinery in the cloud so and this is where for example combining and starting to introduce server rendering or server less rendering like in our case where you define a page that is not static and is also not deferring all the computation to the client side but instead we leverage this asymmetry of computing right because the computing on on the cloud is more powerful than the one on the device and this is really what the new generation of hybrid frameworks are enabling so next knox and zveltkit are examples of frameworks that can say well yes this one page is a static but this other page can also do server rendering so you're not locked in to a local maxima to a peak of performance that could be done with static generation and you're only out outlet it's not just to put everything on the device is to also put it where it belongs and this also comes from the conclusion realization that your cdn is not enough right so that time to first buy that that connection to a to a city and edge and getting some html there is a very simplistic view of the problem and it's very limited and it's not how we're going to accomplish great performance one of the ways that we can do this because server rendering is also not a silver bullet or just saying well i'm just going to use a hybrid framework i'm done that's also not the right solution so when when i mentioned the post gems at world and the rise of hybrid frameworks i'm not saying well just use a framework that comes with all these batteries included you'll have to measure continuously as well but this is why next js is also focusing on not just giving you for example a better image component that optimizes that part of the iceberg and we have tons of other efforts ongoing for optimizing a lot of the other parts of that mass of ice but one of the things we wanted to do early on is put you on a workflow and give you a workflow where you constantly get feedback about how you're doing but from the perspective of the real world so we call this a real experience score and what we do essentially is we take a subset of the same inputs that lighthouse uses when you do a synthetic manual test but we collect them from your devices and then we give you a picture of like how well you're performing across mobile desktop how you're doing across different countries how you're doing across different dimensions so this is gonna help you for example not ship that box shadow because then perhaps it was slowing you down and like i said the nice thing is that it's integrated into the nexus data source so we know for example what pages and we can help you find out what pages are contributing to the different breakdowns of scores and what's really cool is that it's not just unique to next.js so we are working to enable this for all frameworks starting with gatsby and more are coming very soon where for example if you import your gatsu project into versailles you're gonna start getting a lot of these benefits of continuously thinking about performance from the perspective of your real users so all that said does it mean gemsec is bad doesn't mean that putting a lot of like that j that encourages putting javascript in the client is bad no i don't think so i think it really depends on what you're building and it really depends on what are your ambitions are ambitions are and furthermore it's not just that gemsec is not bad is that a lot of the ideas that were built in into that stack like the idea that the markup the m can be cached at the edge and that you should leverage a lot of prerendering that's a great tool as well and you can start there for example in his you can make some of your pages completely gems and completely static and then you can combine it with a performanceoriented workflow where you're analyzing your metrics and you're really starting to ascertain if it makes sense for you or not but you also always have that possibility of adding more so my advice in that regard is you can use subsets of these ideas whenever possible so when you define your pages you say well this one is a static and nexus automates all that so you don't have to say well for this build process i built statically and then i wrap it with a server and cache and purge so the beauty of it is too that you really have to just define your pages and you're off to the races and again it's all about not limiting what you can do or how good your performance can be if you want to learn more about nexjs and learn how this hybrid capabilities work you can go to nexus.org learn and later in in the conference lee robinson will be talking about specifically how this page generation and data fetching components of flexjs that enable prerendering server rendering and much more work and you can deploy all kinds of front ends whether fully static and jump stack or the new generation of hybrid technologies you can deploy to the versailles for free and by the way you also get the ability to measure continuously so it the the journey doesn't end at just deploying but it really ends with and continues with learning from your users and ensuring that they're happy no matter where they are in the world thank you so much and i hope you have a great rest of your conference awesome i always love you amazing uh it's it's so good to hear guillermo uh in these discussions uh performance is such an important thing so uh please go back and rewatch that talk um these are going to be available after the conference but now we're going to move into our next section our lightning talks these are four talks in less than 15 minutes i love lightning talks what do you think boom boom boom boom can't wait to hear some of these great lightning talks that we're about to dig into here and following the lightning talks we're going to break up into topic tables so we can get up and close and personal in live sessions with some of these speakers and sponsors and some of the instructors of the workshops as well and other folks that we just can't wait to connect with so more on that and how that's all going to go after the lightning talks but first first up first up yeah is uh lydia holly um lydia is is uh an independent software engineer and you can see her work at the avocado.com that's like avocado uh with er at the end i guess yes um she will be explaining and visualizing the life of a script for us and it gets really technical and really cool and the visuals are awesome so please stick around for this awesome lightning talk with lydia alley i'm lydia halley and today i'm going to give you a pretty like high level walkthrough of basically everything that happens going from our human friendly javascript file all the way down to something that computers can understand and they're like there are so many parts to this process but for now i'm only going to focus on two things namely the browser side of things and v8 side of things and v8 is the javascript engine used in chromiumbased browsers and in node as well first let's go all the way back to the beginning so we're trying to load a website that uses a small calc.js script and as we're trying to load the website the html parser encounters a script tag and tries to fetch the calc.js file from either of the network or maybe cache or a service worker that prefetched a file either way a stream of bytes get returned that gets sent to the bytestream decoder relaxer and this is part of the parser that takes care of decoding the stream of bytes and generating tokens based on the data it received for example it sees that the bytes decode to funct ion it generates a token say like hey i know this function is a keyword in javascript and it creates a token based on that and it'll just continue to do so for the rest of the stream as well and as it's generating these tokens is actually sending them all down to the parser and the parser then goes ahead and creates notes based on the tokens that match a certain syntax rule in javascript for example a variable declaration or a function statement and based on these notes a parser generates an abstract syntax tree that represents our program now this one is uh very much simplified because in real life it also contains some extra information about a program but for now this will suffice um and also while it's doing that it's checking for syntax errors because the tokens themselves may be valid but maybe they may not actually match a certain syntax rule finally it's time for the javascript engine to do its work because this est is actually sent down to v8's ignition interpreter and this interpreter is responsible for generating the bytecode that it based on the ast that it received and we can actually see the bytecode that gets generated with the print bytecode flag in node so for example this bytecode for our calc function if we invoke it with an object containing an xy and z key it would look something like this and this may seem like a lot of data but there's actually only two parts here that are really important so ignition uses registers in order to execute the bytecode and there's registers like r0 and r1 but there's also an accumulated register that the byte codes use for their input and output or both and then there's also registers like a0 that are used for the values that got passed to the function and this makes more sense as we're walking through the bytecode don't worry so in this case we passed an object containing an x y and z key to the function so this is where the second part of the generated output is important because a0 points to a shape table that contains information on where to find those properties on the object that we pass to the function all right so now let's see what those bytecodes actually do so in the very first line we see lda named property by code so lda specifies that a value gets loaded into the accumulator and that the value is the named property from the object that we passed to the function stored in a0 and the property itself can be found on index 0. so we see that the value on index 0 maps to x so we load the value of the x property of the object that we passed the function so the numeric value 10 in this case then we multiply the current value in the accumulator by the small integer 50. and then star r0 specifies that the current value of the accumulator has to get stored in register r0 then again we load a property and store this into the accumulator but this time it's from the second index which points to y and y has a value of 20. so the value of the accumulator is now 20 and star 2 specifies again that the current value of the accumulator has get stored in register r2 we again load a named property from a1 or sorry a0 into the accumulator the value in the third index this time which maps to z has a value of 30. so we multiply the current value of the accumulator with the value that's currently stored in register r2 so one more step we have to add the values to it and register r0 to the current value of the accumulator so this means that we're adding 500 plus 600 is 1100 and finally we return the value of the accumulator which is 1100. now the bytecode that is generated by the bytecode generator also goes through some smaller optimizations after which the bytecode actually gets executed and it's possible to run this on our machines so finally we have something that our machines can work with now you may have noticed that i skipped some things in a bytecode um so let's see what's up with them this is actually part of v8 optimizations because when we pass an object to v8 such as the x y and z object in this case it creates a shape for that specific object structure um and if you're reading like documentation or blog posts this is also referred to as a hidden class or a map but it's kind of confusing because we also have classes in javascript and we have maps in javascript but it's not a javascript class or a javascript map so shape is the way to go because we don't have those natively in javascript so a shape is basically just the structure of that object and this shape contains pointers to the offsets on which we can find the values of the properties on the object because even though we only specify the x y and z properties there are many many more builtin properties and objects that also all have their location somewhere stored in memory so when we're trying to access a property on the object for example x um it can now just get it quicker by checking okay does this object have the same shape yeah it does okay cool uh now i i want to get x so i know the offset shapes are really useful for an optimization technique that va uses namely inline caching with inline caching we basically store the results from previous operations so that the next time we call the exact same operation we already know the result now each time we do a property lookup it can just simply store the results for the offset that the last time it didn't look up so in the future when we're trying to perform the exact same action it can simply just get the result from the inline cache instead now these inline caches are not only beneficial for the interpreter but they also generate really valuable feedback for the turbofan optimizer so finally we can go back to the bytecode example because these values are actually references to a feedback vector slot where it stores information about the execution of the function and this includes information from like arrhythmic operations such as the fact that so far we've only added numbers which result in a numeric value one useful example of this is the fact that in javascript you can also concatenate strings with the plus operator which would have to be handled way differently internally but so far it knows okay i've only had numerical values that's fine now let's say that we're invoking the calc function hundreds of times this function is now considered hot um because although the bytecode is already really fast v8 actually uses turbofan the turbofan optimizer in order to generate machine code that's even faster so based on the bytecode and the generated feedback for specific code blocks it can generate optimized architecture specific machine code that can run directly on your machine so the next time that we invoke the function it can just skip over the by code and immediately execute the machine code instead however there is one problem in javascript namely that it's dynamically typed so we can invoke the calc function with the same object like hundreds and thousands of times but there is absolutely no guarantee that this will always be the case in the future for example we can also invoke the calc function with an an empty object or just with an x key or just an x and y key i don't know why you would do it but it's possible so for all those different types of objects va generates a new shape that contains the new different properties so previously we saw that the inline cache contained a field with a value of the shape of the object and then the corresponding offset however if we passed multiple objects so multiple shapes got generated we also have to update the inline cache in order for it to point to multiple shapes and they're offset so now when we're trying to load a property from a specific object it first has to walk through all the possible shapes in order for it to find the object that contains that specific property which could result in a linear search which is not very optimal but now previously we generated machine code for the calc function when it's only gotten invoked with one type of object namely the object with the x y and z keys however if we call the calc function again but with a different shape turbofans shape check fails in which case we can no longer use this optimized machine code and we actually have to deoptimize back to the generated bytecode and this is a pretty expensive operation that you mostly want to avoid so the inline cache of the calc function is also updated to say like hey it's actually got multiple shapes now um now the calc function again can get hot and optimized even after deoptimization although turbofan has to handle it a little bit differently when it's encountered multiple shapes and these inline caches actually also have multiple states because if an inline cache has only seen one type of object it's considered monomorphic which is pretty much the best case scenario because in that case we can just generate optimized machine code and assume that in the future this function will just get invoked with the same object shape now if a cache has two or four different shapes it's considered polymorphic and if we're continuously just invoking it with whatever random types uh it's considered megamorphic in which case it's like you know what never mind i won't try to optimize it so as you can see although it's pretty nice for us sometimes as developers that javascript is dynamically typed it's uh it's not so great for the compiler and it can really only work with speculations and just assume that in the future we will use the same type of data now even though i had to walk through this pretty quickly we went all the way down from loading the script in our browser all the way down to running optimized machine code on your machine and i just want to quickly mention that there are so many great resources out there um if you want to know more about the internals of v8 and it's open source so you can just check out the source code if you want anyways thank you so much for watching and have fun coding wow love that oh man i love that we are digging so deep into the internals of javascript so early in the day getting down to the bite code love it love it all right but we should probably keep these lightning talks rolling yeah yeah those visuals are fantastic um got so many great talks for you today this lydia halley's talk just now is so awesome and uh we are going to keep the fun rolling with our next talk from our next lightning talk speaker swizz teller who is a software engineer at tia i'm also a blogger at suzek.com and creator of the serverless handbook that you can find at serverlesshandbook.dev and so it's also created uh an open source library called use off and i believe we are going to be learning more today about adding off to jam stack apps and you can apparently add off to any jamstack app in five minutes jonathan does that sound possible it is uh just spoiler alert i've seen it and it works it's incredible um off is a hard problem this was going to talk about why it's a hard problem um and we're going to get into some some details in a short talk which is really cool we also hear that he's going to make an exciting announcement today um and i i really hope you all stick around for that as well so let's get straight into this talk with zach teller hello everyone i'm swizz and today i want to talk to you about a pesky little topic called authentication it's one of those things that you're going to need to add to your react app whether you're using create react app next js gatsby or any of the other frameworks that you like you are going to need to add authentication at some point it sounds pretty easy in theory right you need some way of saving who the user is you need to check with the server whether they are the person they say they are you need to potentially save their password maybe their username and you gotta do some little you know it's pretty easy talk to the server hey is this person logged in i have these credentials the server saves them and then things kind of just work out that's how that's how it usually works but good authentication is where things get really tricky because with good authentication you have to deal with things like security you have to deal with authorization whether this person even if you know that this person is this person do they have access to this page or do they have access to that page are they an admin or the user are there a meta admin whatever else you might want to think of authorization is really the hard part of a lot of authentication where authentication is who are you authorization is now that i know who you are do you have access to a particular topic or a particular resource that's that gets tricky and then when it comes to saving all of this stuff on the server it gets even trickier because well what if you're what if your database gets licked leaked can people read your passwords or can they not read your passwords how is your hashing structure are you still using hashing from many many years ago or are you using a modern salt and encryption and whatever honestly it's really hard to even keep up with what you should be doing how you should be doing it and then when it comes to saving the authentication state on the front end because the front end needs to be like hey i know you're already logged in and i know who you are so i need to tell the server to check with the server whether this is still true do you save that in cookies do you save it in local storage there's a lot of tricky little things that come with that one of the big ones is that once you split your app into multiple apps you're going to want to have an authentication service or some sort of authentication provider that can work with multiple services like if i log in on ios do i want to still be logged in in the browser if i switch browsers do i still want to be logged in usually as a user i do but you as an app developer get into a tricky situation where you have to have api based authentication you can just be passing cookies around because you need to have you probably want to use the same authentication for multiple different clients whether they're a server trying to do something in the name of your user whether it's the web app trying to do something in the name of the web app all of that gets really tricky so people start building authentication services and they start trying to think about how to do tokens when you really get start reading about it it kind of blows your mind i honestly you just should never roll your own authentication you should rely on a service that already provides authentication because there's a lot of little tricky things that you get you can get wrong and you don't want to end up like equifax which leaked something like many many 100 million users you don't want to be the person who everyone laughs at for oh wow they rolled their own authentication lost everybody's data and now you can just go to the dark parts of the internet and get everybody's social security numbers because equifax had a breach oops you don't want to roll your own authentication you want to use somebody who already exists who's out there and whose core business model it is to make it easy for you to add authentication and authorization and user management and all that fun stuff to your app so you have a lot of different options you have off zero as one of them you have netlify identity as a simple solution there's aws cognito which is kind of tricky to set up you have firebase authentication and there's probably a bunch of others you can build your own that follows the same protocols but unless you have a team of experts on authentication authorization encryption jwt tokens and really you have time to do this and it's your core business model you should probably just use somebody else once you start using somebody's authentication provider this stuff still is kind of tricky to use um especially on the jam stack or on the browser you need to you have this weird authentication flow where the user clicks a button gets redirected to somebody else's authentication page and you want that page to be somebody else's because that guarantees security and make sure that you as the application developer aren't sniffing people's passwords and usernames which you don't want to do well you might want to do it but you shouldn't want to do that so you redirect them to a different page they log in they authenticate and then that page redirects them back to your page and you have something called a callback page which then processes the the authentication looks at the looks at a bunch of data in the uh in the url sends it back to the api for for your authentication provider says hey is this data correct did you send me this or is somebody trying to hack this poor person and the authentication provider says yes that is okay and you have to then put it into your global state you have to make sure that every component that needs to check hey is this person currently logged in should they be seeing this authenticated content should they be seeing this authorized content and there's a lot of little tricky things that you still have to do even though you're using somebody's authentication provider and most of these have to do with global state management and making sure that you have the right access and the right info and you everywhere so what i started building about a year ago and has now just reached version one yay use auth v1 is significant because it now has support for multiple authentication providers yay also it's there's been a lot of changes behind the scenes so it's now easier to use and configure and it just works better i built this hook called use auth which makes it really easy for you to add authentication and authorization anywhere in your react app it works with nexjs it works with gatsby i've tried it with create react app rather than have you trust me at my word that this code snippet is the best thing since sliced bread when it comes to adding authentication to your react app i'm going to show you we're going to do three minutes and we'll have authentication added to a completely blank gatsby app i started it with the gatsby default starter i installed a couple of dependencies and now we're going to add authentication we're going to start by creating a config auth react component that renders on every page load this part has also gotten a little easier since i recorded this talk you can see it in the documentation page that's going to be linked at the end of the talk if you're not familiar with gatsby going into gatsby browser adding a react a react component there helps you add something to every page and ensure that it's always rendering we don't need to wrap it in anything because we're using x state behind the scenes so there's no context provider or anything like that that you need with use auth everything is completely independent we're going to take the dispatch function from use use off this is a helper that's returned from the use auth that's returned from the user hook so that you can send events to the xstate machinery behind the scenes we don't need to render anything because again this is not a wrapper and we're going to have an effect that runs or on every initial page load but does not run on subsequent re um rerenders we're going to dispatch a set config event we're going to give it an auth provider that comes from providers.net life identity we're going to send use off our navigate function this is so that it can work with any routing solution that you want to use you can always use use auth regardless of what you're set up as long as you give it the whatever function it needs to call to navigate because it needs to change between pages sometimes now to show that it's actually working we're going to go into index.js and we're going to create a login login component which doesn't need to get any props it's going to take is authenticated authenticated is a method that comes from use off and tells us whether the user is currently authenticated if the user is authenticated we're going to return a logout button button which on click calls logout which comes from use off log out and we're going to say that we are currently logging out else we're going to return a button that on click calls the login function login and we say login so now a button should show up here let's see if it does oh we need to actually render it duh so we're going to render the login button here we now get a button and when i click this the netlify identity should pop up and ask me whether i want to log into this page in theory that should work but it's not five minutes later i don't know what i did wrong because it now works without me changing anything computers right so i click login and it asks me for the netlify url that i'm using for your for netlify identity i'm gonna copy it so that i don't type or anything and set site sites url i can now log in as myself and i am logged in see the the button changes to logout i'm still me if i reload the page use auth looks at the local storage and make sure that it checks the when when my session is expiring and preemptively puts me in the logged in state before it talks to the auth provider and verifies that that is still true what i can also do here is instead of just saying hi people i can say hello to myself so we're going to return this layout stuff and i'm going to uh user equals use auth again everything everything connects to the data in the background without me having to really think about it i'm just calling use aust wherever i need something about being being authenticated or about the current user and if i'm authenticated i'm going to show user.email otherwise i'm going to say hello people i need to get is authenticated as well let's see so it now says hi swizzads blah blah blah i can log out puts me back in log in and it just works now let's say you want to change your authentication provider you're tired of netflix identity you want to use something a little bit more powerful with better administration features or whatever what does it take right now when you think about your current app what does it take to switch to a different authentication provider it's usually a lot of work right so what we're going to do now is switch this app to using auth0 instead still using use off and yes those are the only two authentication providers that are currently supported it's this takes time so let's see we're going to go back into gatsby browser and instead of netlify identity we're going to use alt0 as the provider we're going to give it the dispatch function and it's going to need a little bit more configuration because we need to set application keys and stuff like that we're gonna have to create a new all zero callback page as well this page makes sure that all xero when it redirects you back to your app has somewhere to go we're gonna call it all0callback.js put it in source.pages and yes i'm copy pasting from my old code because you don't want to watch me type all of this it's basically taking the handle authentication function from use off and calling it whenever that function changes or the page is loading now let's see if this magically starts working five minutes later giving you more power than netlify identity but also a little bit more responsibility click login go to the auth xero authentication page see this is fully secure it's on their domain so i can't steal anything i'm going to use my existing user it's going to redirect us back yes i'm authorizing the app to to be used comes back to the callback page and it should me should redirect me immediately but it is not so i'm going to switch to the old mode because use auth v1 is completely backwards compatible with the previous stuff so we're going to render this off provider which the auth provider is designed to magically set you up with aut00 so now this is reloading and it's redirecting me back and yay it works so obviously v1 still might have some bugs by the time you watch this i will have fixed them i can log out it redirects me to the home page to make sure that everything is fresh log in yes see it works as promised we got that working in less than five minutes using both of the providers that are currently supported netlify identity and auth0 it's all use auth is designed so that you can easily add different providers i've created a an interface that is sort that seems to be working for multiple providers so i would like you because this is open source you can add new providers maybe add your own add your favorite there's um i'm going to add documentation on how to do that very soon you can go to use auth.dev to learn more about how all of this works to learn more about how to provide how to add different providers to read the documentation and start using it in your own app i'll be hanging out in the chat room if you have any questions off in five minutes that's uh that is impressive on its own it's so incredible um with this is like the the problem that i hear about with uh with these uh static static site builders and that kind of thing uh so it's it's really cool and what's even cooler is that we have swiss here to talk with us uh and so i'm i'm excited about that welcome sweetie yeah hey everyone hi welcome we're so excited you could join us for this live chat after that awesome talk wonderful um we are we are really uh thankful to have you here with us and especially now you know we've heard so much about this um this auth library we're gonna talk more about it um in this chat right here but for me i'm curious you know there are so many things you've worked on so many things that you do as a developer and as an educator what uh made you want to talk about this topic here today with our audience yeah so it's a funny story actually i created the library itself it came out of trying to teach people how to build this stuff how to build full stack apps and by my second or third time i was like this is stupid it's just always the exact same thing this shouldn't be something that you learn it should be something that just works for you so i created that library and i figured it it's taken me a while but now that it's v1 i wanted to talk about it at reactathon and encourage people to contribute and somebody asked in the chat room about um adding more providers you can add those providers and i would really love it if you did so that's the official the official request here is is for other people to come along and and bring their own providers because now that it's in in uh 1.0 stage uh it's ready for that right yeah exactly the that was the big thing that we that everyone's been waiting for i've had a lot of people ask hey does it support anything other than odd0 can i use it with my own thing can i use it with traditional sessions and now you can i've only tested it with netlify identity and all zero but the idea is that there's a an api layer built into the library that lets you add more providers like almost like a plugin system kind of there's an abstraction layer and you if you follow that abstraction layer you should be able to magically make it work with everyone but like i said in the talk this takes time yes and so important to get right as we saw yes um absolutely so if folks are you know wondering like oh man i would really love to use this but it doesn't have a plugin for my uh provider of choice provider that i'm tied to they can actually go in and add it themselves that's so exciting so other than extending this to work with more different auth services is there anything else that you're hoping that folks um you know come in and help out with or things that you're thinking of for v2 now that v1 is done yeah i mean honestly i just want people to use it try it out tell me how it is um examples are always great i love it when people like i originally built it with just gatsby in mind and then somebody came and added the create react app example somebody added an xjs example so i would love to see more of that because i can't do everything myself and examples in particular can be really tricky to build but if anyone wants to pitch in i would be super excited about that awesome enough i assume that oh go ahead good job here we are um so i i assume the best place for people to contribute would be uh in the official repo and where else can they find you and your work yeah so i'm super excited to push other people's work as well i we have the all contributors spec we follow it everyone if you add code if you have documentation you will be on the github readme as for my other stuff you can follow me on at swizzits on twitter if you put swizzits into the internets in google you will probably see the first three pages of results are about me i have serverlesshandbook.dev which is a free resource if you want to get into serverless and full stack stuff and i blog at swisses.com i'm taking a break right now but in general i post relatively often awesome very thank you so much for joining us yeah thank you for having me thanks again oh man that's cool jonathan we got we got so many cool speakers yeah official official call for um for people to go and create their own auth providers that's that is one of the hardest problems and that's that's so exciting that that is uh that that's getting better in the react uh ecosphere i suppose ecosphere is that a word it is now it is now today you're here to hear first folks the react ecosphere coming at you live and what i love about this is that um you know i love uh venues like this conferences you know in real life or online where we can hear about these exciting new libraries and tools that are coming out that can make uh developer life easier and folks can actually go in and get involved in things that they're excited about so really hoping that some folks get to connect with swiss after this on github um that folks are able to use this library successfully in their own work and don't have to worry about off and breaking it so that is a super exciting takeaway from this i think um but yeah shall we keep it moving and keep on with our our next amazing talk here yeah absolutely let's go let us go okay so our next talk is going to come at us from alex krolick who is a software engineer at box and a maintainer of the react testing library and that i believe is what we're going to be talking about today yeah you're going to learn how to use uh async code in your react apps you're going to learn how to use react testing library to test that uh this talk will show you how to test async code such as network calls timers and promises and react these are the things of nightmares for a lot of engineers especially when you go to try to test them so you're going to learn how to put those nightmares out of your mind and sleep better at night hopefully uh so let's get straight into this talk with alex kralik hello everybody and welcome to this talk about testing async components i'm alex scrollick i a good box and in my spare time i help out with react testing library before we get into timers promises and api calls i want to do a quick recap of component testing 101 so what that looks like is you'll have a ui element and you'll go through three phases to arrange act assert steps so in testing library terms that's render the component then find elements and fire events on them and then use your expectations to do assertions about the final state so for this example we have a comment box and we're going to pass in on submit prop that's a just mock function um into its own submit handler then we're going to find this uh element the text box element we're going to enter a value into it then we're going to click submit and then finally we are going to move into the assertion phase and we're going to assure that our our click handler has been our submit handler has been called with the right data and that our text submitted has appeared in the document one thing you'll note so we're not using act here because react testing library wraps fire event with that automatically so any effects that are generated there and microtasks are cleaned up by react and rendered before we move on to the next of the test the difference between this component and components in a real app is that it's fully synchronous so there's no delays everything happens immediately whereas a real test is full of sources of asynchronicity from timers promises and networks you're going to see animations browser apis are going to be using promises and everything is basically sync all the time so i'm going to walk through each of those three elements timers promises and network and talk about how you can deal with them so first timers i'm going to extend that previous example a little bit and say that we've debounced the change handler for the input box that's inside of this comment modal form thing so what a debounce does is it makes sure that the function isn't called until the user stops interacting with the thing so we're now at a 200 millisecond delay to prevent that change handler from being called in every single key press that will affect our test because we can no longer immediately click that button after we stop typing because we're waiting for that delay to kick in so what do we do about it strategy one we just get rid of the timer completely so we can find anywhere on our code that has a timeout and replace that constant with a zero and the other thing that we can do is mock out any functions that are creating timers i.e the low dash debounce function and replace it with a mock function that we can then assert about so since blue dash debounce is fairly well tested and we we kind of trust it to work this is a pretty good candidate for it because we can say was that function debounced was that callback debounced yes because of this this mock but we don't care about the actual implementation of that code running so it doesn't affect our test anymore it's no longer asynchronous the other strategy that we can do is we can use fake timers meaning it's like driving a stick shift you're taking full control of the test and all the time inside of it so uh the way that just handles it and there's an equivalent signon is that there's an api called fake timers just use fake timer startsit and every time you want to advance time you have to call one of the apis it's either run all timers which runs every timer that has been created or advanced timers by a time and that will allow it to move forward just only by that specific amount so in our test after our change after we're triggering that text box is change event we would advance the time by our debounce amount 100 milliseconds and then after that we could finally click the putt the disadvantage of this is that if you have uh advanced timers by time a round timer is all over the place in your test it gets a little bit hard to manage because um now you have to know everywhere that a potential asynchronicity is happening and kind of manually work around it and it can you kind of end up with manual time and control all over the place if this is something you use wildly so the alternative and this is kind of the preferred testing library pattern and something that's very much enabled by testing library apis is to make the whole test async and then if you want to do uh any optimizations around individual dbounds or anything like that you can but anything small is going to be glossed over single ticks or 20 20 100 milliseconds that'll that'll go off without hiccup in the test so the big difference is in how you write a test that's async versus synchronous are these so first you've got to rewrite your test to await syntax so by changing it to an async function you can then use a weight anywhere which kind of resembles a synchronous thing but it's actually using promises under the hood and then the big difference is that anywhere where you think that you may have something that's going to take a certain amount of time or certain amount of ticks you want to replace that manual weight like you know wait 200 milliseconds or advanced time or 20 milliseconds with an assertion about the the next step um and when it's ready to proceed so in this case what we can say is that that button is disabled well the input box is empty once we type the value in there it will become enabled so what we can say is we can add this little assertion inside of the wait for callback that expects that button to not be disabled and then after that becomes true we'll be able to move on to clicking it so that's just a retrial assertion that signals to us when we can continue the test if the assertion that we're talking about is that an element is appearing we have a shortcut which is that we can replace any get by queries with find by queries so we're replacing our get by text with a find by text which is an awaitable assertion that will retry until that element is in the dom this pattern is basically what you're going to use for promises as well as most timers it works pretty well in both scenarios so if you have promises the first thing you're going to do rewrite async tests but the big difference between a timer test and something that's dealing with promises the promises typically affect control flow so the code needs to be testing both the resolve path and the reject path so just mock functions can do that for you so if i have a mock function like the one we passed in on submit what we can do is we can say mock rejected value once that'll say that when that function is called to return a rejected promise with this data which is a 500 status code a server side error and then we can have our async find by text query that's looking for that server error to be shown to the user in the dom now moving on our final source of asynchronicity is the big one the actual network so in a test you really don't want to be hitting real servers because for one they're unreliable um you don't want your frontend test code to be totally reliant on the entire backend system and for a vital reasons you might not actually be able to access it and then of course as we've just shown there's a good chance that we're also wanting wanting to be able to test you know error error paths or bad data being passed in finally of course it could be pretty slow so the way we can deal with network api calls in a unit test um first approach take whatever interface that we're using to call the api and mock it usually they have a promise based interface so we just use the same patterns that we've been using um so if we're using window fetch we replace that with a mock function and then we treat it like a regular promise anywhere that we want to call that api we replace the value with some data that we've mocked out and then we respond to the mock results normally if we want to pass in bad data we change it to a rejected downside of this approach if we change our mind about using window fetch we change it to axios or something um now we kind of have to rewrite all of our tests to conform to that new test uh a new data format so for example fetch you always have to call res json do you want to mock out you know the json methods on all this stuff not necessarily um so it might be kind of over constraining your test a little bit if you're always using these interfaces but to get started if you just have a few calls that you need to mock out this is definitely what you can do it a bit more sophisticated approach is that we could actually mock out a fake server so there's a few libraries that i am aware of so mock service worker and mirage js they both seem to work fairly similarly the idea is that you have a service worker that can intercept calls to certain routes and then replace them with fake responses so in this example which i pulled from the testing library docs um we set up a server that is responding to this greeting route and it's sending back a bad bad status code to 500. so every time somebody calls slash greeting that's what they're going to get back and then in different tests you can change the response to something else um this works pretty well the only real downside here is that now we're kind of couple to the network interface rather than the specific library so potentially if we're thinking about refactoring big chunks of the app we may want to have some kind of abstraction between our actual network calls and what we're doing in the app so here's how you could do that so creating an api module is as simple as creating a file let's call it api js and then you put all of your code design network in there so in this case we've got something called get user that's an async function takes an id and then it does window fetch for a certain endpoint if we later replace that with a different library or we introduce something some response handling in there or even rewrite it to hit a graphql endpoint instead this will keep working because the app code is insulated from that at the same time the way that we use our tests uh we use this module in our test is we can generate create mock from module which will take all of these functions and replace them with mock functions and then we can say okay get user let's change the value to return say on authenticated status code uh 401 or we could change it to return or actual user data um the downside with that again is that now we kind of have created this additional interface here so we do have to both unit test it and validate that it actually is correct um and then also if you're working with state management code that is very intelligent that makes api calls on your behalf it's not necessarily going to want to go through this intermediary module so um so for these like very intelligent new libraries that might not be the way to go so that said we've been talking about just we've been talking about unit tests i'm talking about the downfalls where interfaces can kind of not be quite right between what we thought we were testing and what actually happens when we build the app so sometimes testing in a real browser in an endtoend testing scenario is the way to go cyprus is a pretty good library for that cool thing about cyprus is that all of its uh assertions all of its uh queries for elements are already async so more than the get queries they resemble the find by queries in react testing library um so the builtin.get.contains methods they're async so they'll retry until that album exists which is very good if you have asynchronous code anywhere um if you want to use the exact queries the testing library exposes the role query for example an accessible assertion or an accessible query or a label text or placeholder or anything like that we have a plugin called testing library cypress and you can then use all of those commands as well and they behave in the exact same way if you do decide that that intent test maybe has a few paths that you weren't able to test maybe you want to test errors or something you can do network mocking in cyprus 2. so they've iterated through this api a few times but where they've settled now is called cypress intercept in older versions it was called router route 2 but they are acting very similarly to the service worker methodology that we were talking about before where you say an individual route and then when it's called certain arguments it returns certain values so very powerful very useful and ultimately you have kind of a whole suite of options available to you as far as testing all the steps all this code so that's pretty much everything i have i'm hoping that these techniques were useful to you if you want to read more they're up to date guys on the testinglibrary.com website as well as react.js.org and justjs.io if you want to get in touch with me my website is alexcrolic.com and on github i'm also alex frolick thank you so much a huge thank you to alex for joining us and talking about that asynchronous testing and cypress and all of those good things uh of course testing is always becoming more important as we build more and more complex applications with react they're they're about as complex as they can get uh and um hopefully you know the observability of applications is a big deal right now and that's kind of what we're gonna hear about in the next talk right on jenna yeah so our next speaker is going to be brian manuel who is a software engineer at flexport and is going to be showing us how to quantify the health of a react code base which i am really excited to learn about so without further ado let's welcome our next lightning talk speaker brian manuel all right let's jump right in so to kick off this presentation i want to begin by telling you a story that takes place in the year 1993. now the year 1993 is a pivotal year in computing history because it marks the beginning of what is known as the browser wars now just three years prior tim burns lee at cern had just invented arbinet uh thereby birthing would later be known as the internet and in this year the year 1993 we have uh the creation of three major browsers the links browser the arena browser and the mosaic browser each find to become the first viable user interface to world wide web each bringing with them their own opinions on what a browser should be and how the markup language of the web should be and each rapidly innovating eager to bring about the new wave of the internet links browser was the first scene it brought with it the concept of html followed by the arena browser which brought the concept of the gui for the web and also introduced the concept of the image tag and last but not least the mosaic browser brought with a whole slew of new tags such as form tag nested lists etc and also not so desirable tags such as the blink tag and the marquee tags and so 1993 was a period of dizzying innovation in the browser sphere all these browsers had uh wonderful ideas on where the specs should go for html uh and sometimes these ideas were at conflict so in the year 1994 all the major engineers and academics behind the browsers decided to convene in geneva for what was known as the w3c or the world wide web consortium and here's a picture that very first meeting and 3c essentially hashed out what the spec for html and the web should be and because of what w3c and what they did uh we now have a standardized spec for html javascript and css and we can pretty much have a very consistent experience across all the major browsers and one thing that the introduction of the w3c would introduce extra overhead to the various browsers but it really hasn't uh browsers are still innovating at a rapid pace here we have a picture of the web gpu experiments that firefox is running on firefox nightly here's an image of html portal element which is experiments that chrome is running on chrome canary and what w3 c brought to the table is process invisibility into its innovation cycle and so you're able to track how web gpu is uh progressing uh via their website uh and how portal is progressing uh it's very cool and the reason why i bring up the story about uh the browser wars and the forming of the w3c is because it's a story about an ecosystem and ecosystems share a very fundamental concept called ecosystem life cycle every ecosystem starts from some sort of solid foundation it will then go through a period of rapid growth and then finally consensus and best practices will emerge in that ecosystem and if it it's so called for standards will emerge as well and it turns out that a react code base is also an ecosystem and a subject of this talk us react code base will grow over time and uh the team members that write in that reaction code base will grow over time and these team members will introduce new best practices new concepts new packages entire new ways of thinking into react code base at some point we'll want to start tracking these ideas and how they evolve we want to identify trends emerging best practices and where we need to improve just as the w3c did for the browser sphere back in 1994 and once we understand these trends we can begin to remote them and reinforce them and if it's so called for answer to standards and guidelines and so the person's talk is to get you to a point where you can be the w3c for your own react code base and learn some strategies on how to manage and guide the growth of your code base and the process by which we'll be doing so is this three step process we'll first go over how you can ask quantifiable questions about the health of a react code base how you can answer those questions using stack analysis and finally how you can crystallize those best practices by turning your analysis queries into say lint rules or into code mods and what we won't be going over so this is react define after all and we will be focusing prominently on react and anything outside this cover react it won't be covered so bottle stats code styling ci cd all these things are important but you can get information on these elsewhere and a little bit about me before we begin my name is brian uh my alias is for me to rock sometimes just drock and i work on the front infra team at flexport and i've been working here for about the last two years um why she listens to this talk is flexport has one of the largest and oldest react code bases we adopted react five months after it came out and we're pretty much react monolith on the front end i also contribute to react and react like projects like doc gen alright let's begin so code base health before we begin before we can begin at quantifying anything it's important that we ask ourselves where a cobase is in its history and also where it's going what is the state of our code base today when we think about these questions it's important that we pose them in terms of code based health uh how stable how readable how maintainable is our code base and by asking these questions we can begin to understand and get a better feel for what's working what isn't working what needs improvement and how we can improve those things that need improvement and so in this slide since this is reactifon i have some examples of questions that you can formulate around the health and save your react code base so let's just go over them uh our teams creating too many redundant components is our design system library over generic or overly or or not generic enough our engineer is still using a legacy approach to certain systems say css styling and if so why are we uh achieving are we adhering to accessibility standards and should this particular category of component be generalized into a shared component so all these are questions subjective questions that you can ask about your react code base in the next slide we'll go over an exercise on turning one of these questions into an injective question with objective answers so let's focus on one of those questions is our design system library overly generic or not generic enough and to paint some context let's say your company has an internal design system team and that team wants to understand the adoption of their component to library uh i always urge to probe deeper uh go talk to that team figure out exactly what they want and figure out metrics based on your conversations with them so let's say you go talk to that team and you figure out that they're working on a slew of form ui components and they want to understand their adoption rate and what they need to do in order to drive adoption well now we have something to work with we can formulate a question off that what percentage of forms in our code base used to form ui components from our design system and of the forms that don't let's just list them that way the team can go talk to those form code owners and figure out what they need to do with drug adoption and that gives us some quantifiable data that we can track one the adoption rate of form ui components and two uh a list of forms that are not using form ui components and though these queries seem to be nebulous it turns out that we can answer them though very loosely with a stack analysis and the tools of choice i will be using are ast explorer and js code shift ast explorer is a tool that will help us mock and test out our stack analysis queries and js code shift is a library that we'll be using for actually writing these queries all right so this is ast explorer ast explorer is a tool we'll be using to explore running stack analysis queries with it consists of four panels the top left panel is some source code we'll be testing against uh here we have an example form called my form which imports some form ui components renders some stuff and then it returns the form on the right hand side we have a tree representation of our source code so if i were to for instance highlight this import decoration on the lefthand panel it highlights the stringful import decoration uh if i were to highlight this block statement it highlights block statement to the forum it's essentially a true representation of our source code and then on the bottom left hand corner we have our transformer so transformer for js code shift takes some source code and outputs resulting source code so here uh it's parsing our source code looking for any identifier and then reversing uh the text of that identifier and you can see that in the output on the bottom right panel all the identifiers are reversed for the sake of this presentation we're not interested in a transformation so we can delete this and it'll default it's just returning our source code as is going back to our formulated question statement what percentage of forms used to form ui components we can now break this question down into two distinct steps step one get a list of the form components in our code base and in step two from that list determine which forms contain any form ui components and the way we'll be doing so is by looking at the opponent's import statements so for step one it turns out for a theoretical codebase that we're working on doing this is pretty simple all forms have the convention of ending in form.jsx so we can simply walk through a project directory and match for any component file that matches that regex for step two in order to determine whether a form contains formula components we'll do what i described earlier check the forms import statements and the way we'll be doing so is via js code shift um so the first thing i'm going to do is i'm going to copy over this list of form ui component import paths into this file this is a list of all the known form ui components in the report paths and our strategy is going to be uh first find all the import declarations in this file and then uh check if any reference the above import paths and so it turns out with js code shift this is actually quite straightforward we simply call tree.find jscodeshift.import declaration and uh we care about this uh import path so we call.find again uh this import path is a literal so we call find.literal and if we run for each on each of these literals and console.log each of them or rather their value let's open up our console we can see that we are indeed hitting these uh import paths this is what a full implementation ends up looking like now for those of you who want to read this code and dig in don't you worry at the end of this presentation there is going to be a link to github just with the full implementation that you can read play around with and do a fashion please so i hope this section gave you a quick taste of what it's like to write a stack analysis query i hope it didn't go by too fast the final section crystallizing best practices i'm going to show you a scenario say your company is doubling down on internationalization and through analysis we found that we really like i18n we don't want to have any freefloating texted rules in our jsx everything must be passed through i18n for internationalization and our company wants us to enforce this as a standard so there are two ways we could go about this um the first way is we can introduce an eslint rule here we've introduced a new rule called no string literals and it'll create a violation whenever it finds a string literal uh free floating in your jsx this is extra work for your engineers because it means that they'll need to dig into the code and remove these violations and fix them themselves and the other approach is we can write a code mod now the query we wrote was in js code shift and the purpose of js code shift is for writing code mods uh and what codebond is is essentially a transformation of code you go from one type of code to another type of code and here we transformed all these free flowing text rules to be passed through i18n now using uh codemod isn't always possible uh there might for instance there might be too many edge cases or a lot of complexity uh but uh in general you should always hear writing code mod and if you can't definitely go for an eslint rule um so yeah those are two ideas on how you can crystallize best practices and that's it for my presentation reach out if you have any questions i'm going to be at the topic tables later today uh so you can talk to me there uh or reach out earlier it doesn't matter and as promised there are links to the code samples um that's all have a great reaction find everybody and thank you for listening to my talk awesome react uh quantifying react code base is difficult uh but luckily brian has made that seem much easier much easier for us now we are going to move into a very fun part of the day um as a special part of this conference which is our live topic tables this is where you can get up up close and personal with the speakers uh the workshop instructors sponsors and other experts on a specific subject just click on the sessions button if you don't know where that is it's in hop in on the left side of the screen the sessions buttons in the left menu to browse all of those topic tables you could talk about the jam stack with guillermo for example uh you could uh go talk about going from junior to senior engineer with swix or next js with joe uh you can talk about data visualizations with janet beck and many more talks will start up back in a little over an hour at 1 30 pacific time we'll be back here talks will start up back then so we'll see you back here shortly thanks for joining us i've had my heart broken into but something's different next to you it's like my soul is i'm starting to feel tired cause i can is i know feelings that i know i can't keep on this road alone and all this time i thought all this time bottled up inside is is feelings to feel is wanna know is are you ready for the ride what have i been waiting for oh i can run but i can't hide the feelings that i know so so so so so so so next so without you baby is tell me i'm baby is is nobody is tell me is give me me baby there's a song in my head so i love you so bad every single crowd and i know you love me is an open sky full of dreams till the sky falls down since i met you i didn't know is so pick me i think you're perfect for me so so so so so so so so so so so so oh um it's i was watching you show me something singing through the windows like superheroes i couldn't see it until you showed me is through the windows every night on fire tonight is is is is oh is i've had my heart broken into it but something's different next to you it's like my soul cause i is that i know the feelings feelings that i know the feelings that i know i can't keep on this road alone and all this time i thought up inside is feelings that i've known is is is bottled up inside and all the feelings that i know so so so so so next living in the light you're giving out without you tell me never gonna let you down baby home here in your eyes without your baby is nobody is tell me is tell me is baby me when you're with me and i realize what it all means so i love you so bad every single crowd and i know you love me is sky full of dreams oh till the sky i was doing just when the lights is gonna so pick me every day i'm with you i think is so so so you so so so mr so so so so so um i was watching show me something new as each morning underneath is still singing is this is come with us don't hold back tonight is is is it's is so i've had my heart broken into it but something's different next to you it's like my soul is know is the feelings the feelings that i know the feelings i can't keep on this road alone and all this time i thought i knew up inside is that i've known feelings this that i know i can't keep bottled up inside is are you ready for the ride what have i been waiting for oh i can run but i can't the feelings that i know so so so so so do next so space tell me never gonna let you down baby without you baby is nobody all this is welcome back everybody i will give give folks a few seconds here to get back in and settled uh for our next talk this is we're going back to a a bit of a longer talk here with jana beck janet beck is a data visualization engineer at stitch fix in previous life she was a phd candidate in linguistics doing a lot of scientific computing in python now you may be wondering okay we're doing uh data visualization engineering with react uh this this could be a uh a difficult thing to do in the browser and that's exactly what janna's gonna be talking about how to actually do data science in the browser how to perform those kinds of tasks that are typically reserved for cloud computing so let's get straight into the talk with jana hello reactathon and welcome to escaping flatland a romance of data science in the browser now this title is a reference to a mathematical fable that we'll get to in a bit and we will torture the heck out of as a metaphor in this talk but first let me introduce myself my name is jana beck i'm a data visualization engineer at stitch fix which is a company based in san francisco california we are an online retailer we offer personal styling so for women men and children so you sign up you fill out a style profile you can also play a game we have called style shuffle to tell us about your style preferences and a sort of tinder for clothes kind of way um and and then we match you with a stylist who picks out things and sends them to you you don't pay upfront for all the things that are getting sent you just try them on and pay for what you decide to keep and ship the rest back and then in the last year we also launched a sort of personal store type of service where you just log in and we will show you a selection of all of the things that we think based on what we know about your style will be the most interesting to you and then you can just shop at your own convenience item by item now i work on the algo ui team which is a sub team of the data platform engineering team that supports about 120 data scientists in our algorithms department or data science department at citrix and this is a pretty unusual role for frontend engineering but it's pretty fun so we basically operate as internal consultants we float around from project to project partnering with one or more of the data scientists on the team to surface their work in whatever way is necessary but usually through a web application of course to their business partners in the company so it's it's internal tools um or tools might be the wrong word sometimes it's things like prototyping a algorithmically driven experience like something that might even be client facing one day sometimes it is just putting together dashboards of business metrics or operational metrics uh that business partners throughout the company need to see so it varies a lot we create a lot of new applications all the time which is pretty interesting and a little different for the typical frontend engineering job so coming back here to the subtitle of this talk a romance of data science in the browser we're not going to talk about doing all types of data science in the browser though you can do a surprisingly large amount with something like tensorflow.js which is an implementation of the tensorflow framework in javascript what we're going to do in this talk instead is focus on one particular technique that's very useful for visualizing certain types of data sets that occur in data science data sets that we call high dimensional data sets so this technique is called dimensionality reduction now what is dimensionality reduction there are quite a few examples that are actually probably pretty familiar to you so one is maps maps are a way of reducing the threedimensional globe to two dimensions so that you can print it out or display it on a screen and there's lots of different map projection algorithms and they're all very specific to the earth and and making the earth from two dimens three dimensions to two right so you have the much maligned mercator projection you have newly developed projections that are much better than the mercator projection like the equal earth projection and you have exotic projections like this one the watermen's butterfly projection and these are all of course extremely specific but there are more generic algorithms for doing dimensionality reduction on any data set and indeed on data sets that have hundreds or thousands of dimensions work we're going to look at in this talk is doing one particular dimensionality reduction algorithm that's pretty newly developed this is pretty cutting edge and doing this in the browser so this algorithm is called umap and that's an acronym for uniform manifold approximation and projection but we're not really going to get into what that means because that's not actually relevant here okay so let's dive into umap and see it in action and we'll start with something that should be pretty familiar to you as frontend engineers and that's color spaces so the rgb color space has three dimensions red green and blue and so as i'm sure you probably know you define millions of colors by encoding three different numbers from zero to 255 for each of those channels those red green and blue channels so we can visualize this in the proper three dimensions for those three channels by uniformly sampling from the allowed values 0 to 255 for each and we get this uniform cube and then we can actually just apply umap to this telling it to map it onto two dimensions and it will get flattened out just like this and you can still sort of see some features of the original geometry here in in that you see these like corners it's pretty interesting and you'll get a different result if you do the same thing on the hsl color space visualized here in its three dimensions but it's not a cube it's a cylinder because the hue dimension in hsl is an angle from a circle the the hue circle so if we flatten this one out we get a very different result and again this is just applying umap from three dimensions to two and and again you kind of see some of those features of the original geometry you get these curves here with the hsl where you didn't see those with the rgb so now that we've looked at something pretty familiar color spaces let's look at something that's more data sciencey and that's the mnist digits data set so this is a data set that has as we'll see a hundred dimensions so much more high dimensional than three and it's commonly used to test a variety of machine learning techniques so what this data set is is a set of images of hand drawn digits and each image is reduced to being 10 pixels by 10 pixels so there's basically a grid of 100 squares and each square is one dimension and what all we're encoding here is whether that square that pixel and the 100 pixels how filled in it is with black versus white so here's an example of one of the handdrawn digits a number eight and here's the grid of 100 squares and so if we look at a particular location like 2 2 here this one has a value of 0 because it's all white whereas 3 2 has a value of perhaps 0.825 because it is mostly black so if we apply an algorithm like umap a dimensional dimensionality reduction algorithm to a data set like the mnist digits data set that has 100 dimensions what we expect to see is clustering of the handdrawn digits together by digit value because what the uh algorithm is doing is comparing each of those like dimensions so comparing pixel 0 0 across all of the 5 000 examples that we're going to give it here uh the 5 000 hand drawn digits and then it will categor it will put all the similar ones the ones that are similar across all those 100 dimensions it will show us that by clustering them on the two dimensions of our screen so if we look at the result that's exactly what you see here applying umap to 5000 of the mnist digits and what's interesting and uh what actually makes umap a better dimensionality reduction than some that are similar is that you also get similar shapes appearing the the cluster for each digit and for each shape um the relationship between those clusters is also relevant which sometimes it isn't with other dimensionality reduction techniques so for example the fours and the nines are right next to each other which you can see because they're very similar shapes um just differ basically and the a9 is like curved on the top whereas the closed portion of a four is has sharp angles on the top um so those are very similar and they appear right next to each other similarly down um the red ones here are threes and the sort of citrine color is is eights and those are also very similar of course you just three is basically an eight with a couple bits erased from it right so that's one of the advantages of umap that you can see very clearly in this example so i told you before that escaping flatland was a reference to a mathematical fable and that fable was the book flatland a romance of many dimensions written by edwin abbott abbott and first published in 1884. now this mathematical fable a romance of many dimensions uh is the story of its pseudonymous author a square a square is a square as you might imagine who occupies flatland a twodimensional world this land is also populated by other polygons and lines but all the beings that occupy this world are twodimensional now the climax of the story spoiler alert is when one day flatland is visited by a being from spaceland which is a threedimensional world and a square witnesses this visitation now how does a square know that this being is from another uh world with a greater number of dimensions well basically because the sphere is able to apparently teleport because he's able to move into the third dimension and then intersect flatland in a different location seemingly by magic so here's the part where we torture flatland as a metaphor and we're going to use it as a metaphor for the web browser itself now the web browser started out as something pretty simple and not very powerful it was a way to view hyperlinked text documents nothing more images came later video came later things like webgl came way later but today the web browser is pretty powerful as i mentioned before tensorflow has been implemented in javascript as tensorflow.js we'll be working with the javascript implementation of the umap algorithm that i introduced you to briefly um in a library called umapjs and these are computationally expensive things almost by definition and if you just implement them in the main thread the main execution context in the web browser you're going to cause jank you're going to freeze the ui it's not going to be a happy experience for the user but what the browser has today is the ability to accept visitors from space land from a larger more dimensional world a world that has concurrency basically is not limited to one single thread of javascript and that technology that we have today is the web worker so let's talk about web workers if you're not familiar with them so the the worker context is very similar to the main javascript execution context in every browser but there's a few differences so just like in a in a regular main thread context you can make xhr requests to get data asynchronous asynchronously but you do not have access to dom or even a dom and you don't have a window global instead you have a self global all data transfer between a worker and the main thread is done by message passing and this data is not is copied with one exception that we'll go to later um and instead of being shared across the worker and the main thread and it's serialized and then deserialized via the structured cloning algorithm so what are all the things that are serializable by structured cloning well it's basically a whole host of things that you'd expect all the primitive data types of javascript dates blobs array buffers but some things that it would be useful to pass back and forth that you cannot pass back and forth cannot serialize by a structured cloning are things like dom nodes error objects and functions the basic web worker code would look something like this it's just a big on message handler that receives data from the main thread and then you can do anything you want probably something computationally expensive and then there's a global post message handler that you just use to pass the result back whenever it's done on the app side you instantiate a web worker with the new keyword and then you call the uh uh the postmessage method on that instance that you've just created to pass your initial data to the worker or any message at all of course you could have a more complex system of message passing where you have types for all your messages and they do different things and then you have a you just define an onmessage handler to receive the results whenever the worker is done as far as tool chains the support for webworkers is quite good in my experience so the worker loader from webpack is what i've used for many years you can just tell it that any file ending in worker.js should use this worker loader and it bundles it up appropriately i've also heard great things about the worker eyes loader which you can be used on any you know file that's just a single function and you don't even have to write the sort of webworker message passing boilerplate it will just as it says workerize that function and make it into a web worker parcel i haven't used personally but i found a codepen example that used uh parcel to bundle up a uh webworker so i think that works uh the only thing that i haven't had great success with is roll up um if you're building a a library and you want to have a worker that people can use um roll up uh the plugin i tried a few years ago didn't work for me i do think there is a new plugin out in the last year or so so that may work now but it didn't before in my experience so let's dive into some demos and these demos are going to be on a thousand of those mnist digits that we saw before running umap to cluster them by similarity by digit and the first demo is going to be the one where we run umap in a webworker and you will see a couple other things on the screen there'll be a frame rate meter in the upper left and a keyboard input that i'll be typing in in the upper right and so with the computation happening in the worker you'll see that my keyboard input is active the entire time while the computation is running or active in the sense that the ui will be updated my input is being accepted immediately as we hope and expect there's no lag no jank so let's give that a try and see how it goes so we'll just start it up here and there you can see 216 frames per second very responsive and that keyboard input was updating the entire time because that computation was happening off the main thread and not interfering with the main ui at all now in contrast same initial conditions a thousand imnis digits but we're going to run this umap in the main thread and try to do the same thing look at the frame rate and watch the lag and drank on the keyboard input so here i'm typing away as i'm sure you can hear but don't see anything from the keyboard until it finishes at two frames per second because it couldn't even update uh while it was computing sadly that's what happens in the main thread okay so for a third demo here this is basically just the same as the first we're going to do the umap in the worker for performance but bump up the number of digits to 2500 and you'll see that we do start to see performance implications even with the worker implementation here so the final frame rate there was 86 frames per second quite a bit slower than before and now for a fourth demo which i'll just leave my face off for this one because it takes a little bit longer um we'll just bump up the end to 5000 and see how that goes so here you see that there was an initial period of time when the keyboard input wasn't updating on the screen but then it's kind of like all the others just again with a lower frame rate we're in the 40s now four frames per second okay so there's a little bit more that we can do in a web worker to optimize performance and we're going to talk about two more things basically transferable objects and then one type of transferable object or one specific instance of that which is an offscreen canvas so transferable objects are the exception to what i said before about data passing between the main thread and a web worker being exclusively a copying operation transferable objects are zero copy they are basically the conceptual equivalent to path by reference in other programming languages so here's an example of using transferable objects to pass the result of a umap computation back without having to copy it so it's a little bit faster so here i'm just taking the result the embedding which is what you call it when you reduce a high dimensional data set just taking that embedding and storing it in a float32 array and then in the post message there's a second argument which is an array and you put everything in this array that is a transferable object or is of an appropriate type that can be a transferable object and that just tells the the worker to not copy it and treat it differently and pass it to the main thread instead of copying it to the main thread so then the second transferable object or specific type of transferable object that's not an array buffer is an offscreen canvas and this is a weird thing and it's not transferable objects in general the array buffers those are supported in every browser but this is something special and new and only a couple browsers have it so far um it's basically like a canvas element that is a nondom version of the canvas element um so here's an example of some some code of how you would actually use this you you know you want to you just you do render a canvas element in your dom like normal so here we've rendered one that has the id off screen and instantiate a render worker we'll call it because we're going to render onto this canvas and the word her then grab a reference to that canvas element that's been rendered and call this method transfer control to offscreen then you also have to post a message to the worker and include in the body of the message that you're passing this reference to the canvas and then also include that that reference to the canvas in that array of transferable objects that's the second argument to your post message then in the worker code remember a worker is basically just a big on message handler you pull that canvas out from the message and and then you just render onto it using the canvas api or the webgl api how you would normally render onto any kind of canvas and here you don't even have to pass it back like the worker rendering onto this canvas is just this it's kind of like a multidimensional wormhole back to the browser it just appears that rendering just appears in the browser where that canvas element was rendered so this is total magic in my opinion it's very cool okay so now we're approaching our final demo here where we're going to have the main thread and two workers one to do the umap computation and one just to do the rendering of each iteration of this algorithm as it converges on the result so the conditions here are the same as the fourth demo that we saw with 5000 of the mnist digits and now you can see with the comparison of the embedded one in the upper right corner that this one has gotten responsive a lot faster than that last one and the reason also that there's no framework meter on this one is because all the frame rate tools are not compatible yet with offscreen canvas so i couldn't actually put that in this final demo so to conclude in my opinion the combination of web workers especially with offscreen canvas gives you something that is basically an escape from the flatland of the browser because you can just do much more computationally intensive and exciting things and if you have any questions i'm happy to answer them on twitter where i'm i pancreas i'm jebec on github and also in various slacks or discords that's usually the name i'm under and you can also look at these slides again online if you want all the demos are live embedded in the slides so you can just play with them if you feel like it at janetbeck.com flatland and then if you also take a look at these slides you can go through these details of what i use to put together the demos and this whole slide deck in general if you're curious about that thank you so much for your time so we can do machine learning in the browser or maybe not machine learning but uh these these pretty interesting kind of intensive uh computationally intensive things in the browser off of the main thread that's really cool thank you jana for the fantastic talk and obviously the kind of stunning visual display that we saw there that was cool yeah how amazing i also love that jenna has this uh prior background in linguistics because that's also the background that i come from so love seeing folks uh go from uh studying things like dimensionality reduction in the language world and bringing that into uh computing and data vis and whatnot super cool thanks so much jennifer that awesome talk and now we've got another an amazing talk for you to to round out our day um our next speaker i feel like perhaps needs some introduction uh sean swixwang uh who you may know as an infinite builder is uh formerly of netlify and now developer advocate at aws who works on developer experience and developer developer communities and is also just an amazing speaker writer teacher who i've had the pleasure of running into a various conferences myself and today uh swix is going to be talking to us about typesafe full stack react and we're going to be live coding an apt with react and typescript and graphql to demonstrate during his talk so wow get ready for some fun with uh full stack type safety in this next talk by swix hello reactathon i'm really excited to be joining you today i hope all of you are safe and at home and today we're going to talk a little bit about typesafe full stack react it's a broad introduction for those people who haven't considered it and a live demo for people who have and hopefully you might learn a new thing or two so let's get started so for those of you who don't know me hi i'm sean i am sitting here in singapore but i could be anywhere as far as you're concerned and i also go by swix on the internet that's my english and chinese initials i've had the privilege of giving some wellreceived reactive talks in the past in 2018 i kicked off my react conference speaking career with why react is not reactive at react rally 2018 and then in 2019 i followed it up by giving my talk on hooks and cloning uh react clone from scratch in 29 lines of code live on stage and that was pretty much the scariest and best received talk that i've done in 2020 i also extended that to concurrent react so giving an explanation and live code demo of react fiber as well as the implications of that with time slicing and react suspense but more recently my interests have turned from react internals towards everything around react the tooling and the developer communities around react and that's what we're here to talk about today the stunning evolution and adoption of typescript within the react ecosystem and why is type safety so important to react well i can pretty much make that argument in two words and that's shifting left shifting left is this concept that's kind of new to web development or obscure in web development but it's not new to software engineering in general so if you look at ibm who did a survey of their hundreds of thousands of consultants and consulting projects they discovered that there's a correlation between how late in the process of the software development cycle where they catch a bug versus how much it takes to actually fix that and it's also nonlinear so if you arrange the software process from design to implementation to testing to maintaining a production application from left to right the further right it shifts towards something that's already shipped then the more expensive it is to fix that bug so a bug in production is like 100 times more expensive than if it was caught at the design stage i like this quote that people have that you can save weeks and weeks of coding with just hours of planning and i think that that's a really true statement even more than that you can automate a lot of that planning and checking with type systems so the way i pitch this is it's not just type systems it's also about building automated developer tools so let's translate this shift left concept into terminology that we understand because we're not ibm so instead of relying on user bug reports and manual qa we can actually run tests inside of ci cd setup environments but instead of running that entire test suite we can actually just run tests on incremental commit hooks and diffs so it's even faster so what else can we do that increases the feedback loop even faster than that we can shift left again and we can run formatting on save that's what prettier is about and that actually unlocks another order of magnitude improvement in our software development cycle but what can we do that shifts even further left than that well while we read our code our ides can actually tell us if we've written code that's wrong so that's what the typescript language server and syntax highlighting and ides do for us they tell us when code looks wrong while we're writing that code we don't even have to save we don't have to commit we don't have to build or run it we can just look at it while we write and that is the highest possible version of shifting left in terms of our error detection everything that we're doing here is to try to reduce the length of time it takes to discover code errors and it should directly translate to dollars spent as well the shift left idea also trickles down in terms of other features that are also nice fearless refactoring is this concept i really like which says that the only way to avoid techdab is to not be afraid of refactoring your code base at any point and the only way to not be afraid of refactoring your code bases at any point is if your developer tools help you refactor so i can refactor any part of my code base and if anything was forgotten or if i broke any code i don't have to run the code again the ide would mostly just tell me what i need to fix typescript and type safety also helps you generate autocomplete because that's another implication of type checking it's kind of the inverse typescript also helps you inline documentation so you don't have to remember what exactly each name means you can just hover over variables and functions that it tells you what it does in terms of type signatures or type annotations but i do want you to know that types do not replace tests i actually wrote a post on css tricks on why types and tests serve overlapping but different purposes and i encourage you to check that out i'm personally quite tired of this discussion because i think it's a solve issue that you should have both my ultimate sales pitch to you on why type safety is that you can go from moving fast and breaking things to move fast without breaking things and that's ultimately what we all want right okay so let's talk about typesafe front ends i've helped to maintain the react and typescript cheat sheets for over two years and i've learned a lot about this so normally i just give a screenshot of what this basic component looks like but because this is prerecorded video i can go one step better and actually show you inside of a typescript playground so here i have a basic function component and it's being used inside of an app this looks exactly like javascript because it is and that actually shows you one of the benefits of typescript which is that it is a superset of javascript any valid javascript is valid typescript under the right settings obviously you can make it a little bit more strict and that's a little bit of what we're going to do so here we're going to turn on the no implicit any check and that's going to start causing errors so it's going to start telling us that props implicitly has an any type so we need to give the type and specify the type of the component so let's go ahead and say that my type of component is going to have an id and the id is going to be a string so let's put that in there and this is going to type check properly properly so when i hover over props.id it's going to tell me that is a string okay so that's a simple reactant typescript app but what if we wanted to do a refactor that's exactly what we're trying to go for right so let's say i wanted to change my id into a number so if i change that number here it's going to light up accordingly so for example here i wanted to say i i'm running around a specific number function like two exponential i don't know what this is so it's going to document what i need to put in there so it must be in the range 0 to 20. excellent okay i can just say 15. i don't really care what it is but now i can just see that this code type checks because this the this returns the appropriate value but also i can see that here i have another place in my app that i need to fix as well so i need to change this instead of supplying a string into a number so that's a very simple demonstration of what the refactoring workflow looks like and what designing with types helps you consider when you're doing development with react and typescript typescript types are basically instructions to the typescript language server in compiler that says you know id is of a certain type so let's try something a little bit more complicated with our stateful component we're annotating both props and state and i'm doing it both in terms of the class component style as well as the function component styles using hooks you can see how hooks are a lot more concise to type with typescript that was not a motivation but it was definitely a nice to have and a plus in favor of adopting hooks the classes versus hooks discussion is also something i'm not very interested in discussing so leave your flame wars in the comments but in general what applies for props also applies for state if you try to refactor anything in a state then the rest of your app is going to update accordingly and that's a very useful thing to have in your reactor so that's a super brief introduction there's a lot more for example when you're making custom hooks here i have a custom used loading hook which covers a used state hook but then also has some custom behavior going on this hook just helps to wrap any promise so that it tracks the loading state and then unsets the loading state once the promise completes and it returns that loading state as a boolean and it gives you a function which you can call to use generically the trick here is that you cannot just return is loading and load in an array like you would in regular javascript because typescript would infer this weird type that is very hard to use and union type of both boolean and load instead you actually need to specify this special as const syntax of typescript and that actually tells typescript to infer as a tuple so in each place instead of assuming that i'll have a general type that matches each of the locations in the array and here is where we use it in a app as a sample where i can wrap any promise and get out that loading state which i can use to show a loading indicator there's a bunch of these little tricks that you need in typescript in order to do these things so it's not exactly clean there is a learning curve but hopefully it's worth it and you know what most of the ecosystem has decided that it's worth it so here i have a tracker of the react ecosystem libraries that are either written in typescript or have rewritten their code types here so they don't just offer typescript types or indefinitely typed or like a separate type to file their internals are written in typescript and so that's next.js react native react router expo redux yarn jest and so on gatsby i think now fully supports typescript as of november 2020. the other thing that's very gratifying is that it starts to bleed over from open source into closed source largescale production systems one of the most compelling stories comes from rebunge at airbnb where she drove the adoption of typescript at airbnb and according to their own study because they keep very rigorous postmortems 38 of airbnb bugs were preventable with typescript it's also a very compelling story for those who think that you don't need typescript if you test enough because of course airbnb also tests very very rigorously if you were around tech twitter last year when this became a story and it was announced then you probably saw this version of this photo and it spread pretty virally around javascript twitter the reason was this talk wasn't publicly streamed and i just happened to be in a room so i'm happy to have my little contribution to reaction typescript lore if you want to get started learning then definitely check out my repo it's completely free it's called react and typescript cheatsheet there's a github version where you can just read in pure markdown but there's also a hosted version with search i definitely like using the search feature for anything i need to look up we definitely need contributors so please dig through the issues and ask questions or answer them as they come up okay so that's the front end i think that's more of a solved problem the harder problem is actually typesave backends which is something that we're not so clear about i think probably the winner in this space especially for the js ecosystem is graphql graphql itself has a schema definition language instead of a type language but it's pretty much the same thing this is part of the spec of graphql and you can see how they're used on the graphql.org site you can declare enums you can declare types types can have ids or strings or numbers or they can also embed other types and as for queries you can also have a type of query or you can have a type of mutation and that is all wrapped up in your overall schema that's essentially the raw spec and there's extensions that we can do to that spec but based on these type declarations we can start to generate tooling everyone who's used graphql probably knows this but there's a tool called graphical if you haven't come across it definitely check it out because this is probably one of the most effective inspirational influential tools that i've ever come across it's like a repo for your query so it actually runs against a real graphql endpoint you can do queries see those sample responses you can also check out inline documentation even if it's deprecated we can note that it's deprecated and we can tell people what else they should be using every single graphql request is validated before it runs so if you get a badly formed request it won't even go through there's a very standard error resolution process that happens when a bad request comes in so this is very similar to how typescript works for the front end but applies to the back end additionally if you use graphql right you can also get savings in data transfer that makes your app work faster and your bandwidth go down there's a lot of pros and cons to this design and it's hotly debated so i'm not going to cover it all but i just want to make sure that the point is made that because you have type save backends then very good tooling can be generated based on your type safe backends and because it's an industry standard we share the cost of developing things like graphical and that makes graphql a lot easier to work with so from back end to front end we then need to hook it up and that's the tricky part one of the cool projects that i like to see in this space is called graphql code generator it says what it does it takes graphql and it generates code in our case it generates typescript code and that's exactly what we need to take types from backend to frontend this isn't the only strategy in the space you can also go from typescript to graphql and that's what these two popular projects do type graphql and graphql nexus they both have different ways one uses decorators the other uses standard typescript functions but both are ways of describing what your types are in a way that can also be parsed to generate graphql there's also smaller solutions like type gql and deck api that are exploring different solutions in this problem space however i just want to step back a little bit and address the elephant in the room which is that we want to enable all of this in order to get better user experience by creating more reliable apps without tech debt but in order to get there we need to stitch together all of these tools and our developer experience goes down especially at the initial part when there's a learning curve and we have to figure out how to make all these tools talk together because they weren't designed with a single coherent mindset there's a lot of complexity in order to get all your ducks in a row to get a full stack type safe experience you need to pick your backend resources and then you need to write graphql resolvers for them you need to generate typescript types and then you also need to have client graphql or typescript libraries and then for everything else that you might need like offline syncing or realtime websockets you have to write custom custom code and probably your the open source ecosystem is not well developed enough for you to do all of this out of the box so the end result of reaching this type safe full stack react goal is that we either glue together our own framework and have to maintain a lot of glue code or we use an integrated framework designed for this workflow and that's something i'm interested in exploring at aws and working on so for each of these solutions we have aws absync that provides our backend resources like database but it also acts as a graphql gateway graphql transform which is an open source library that helps to write these graphql resolvers and typescript types and aws amplifier helps to do the code generation but it also provides the client libraries that you can use to access the resources that you've provided so let me show you what this looks like and the ultimate vision of how we can reduce all the boilerplate but actually still achieve this user experience of full stack type safe react so at aws we've actually extended graphql graphql is made to be extensible and one of those ways in which it does that is this cool idea called directives directives are anything with an at on top of them so for example if you write a type in standard schema definition language and you have this all these fields with standard graphql sdl we can actually just add an add model and that's some that only means whatever we make it to mean graphql has no opinion on that so we can just throw it onto here and if we have an integrator toolkit we can actually spin up the resources that are required to make this into a crud enabled model so we can say all right we have a type post inside of our graphql let's spin up the functionality to create posts read post update and delete posts and do that on the back end as well as the front end and that's a fair amount of value add typically the hard part of implementing graphql backends is that you have to write a lot of boilerplate for spinning out all these things these are all generated for you just by writing at model just six characters and it saves you a lot of code now i want to stress that this isn't the only solution that does this so hasura and fauna db both offer similar approaches where you can just specify the graphql schema and it spins up the required database resources they just have different underlying databases backing them so for sure this is not at all a unique insight but this is appsync and this is the aws solution if you want to use aws infrastructure so all right we have add model what other directives can we try we can also try adding off right because you know you want to have some authentication when you do crud the only trick is you do need some off service so of course if you have an integrated tool chain then you can add in something like amazon cognito which is aws's standard off service in front of appsync the main trick that you have to figure out when implementing such a solution is you have to figure out how to let users specify rules for who can access what so for example you need ways to specify if the whole model is private or if anyone can read but only the owner of the model can write and you need to be able to do this at the model level as well as the field level how about search imagine adding search capability with one more directive and then auto generating search posts functionality with the exact same workflow as everything else that you use so these are all really interesting and there are other directives you can check out with the graphql transform library we're not going to cover everything exactly but i just want to introduce you to this concept because you've done the sdl definition work whenever you use graphql but you might as well use that to spin up a back end and then you can flow the types to the front end with an auto generated toolchain so for the amount of work that you do just to do that it's actually very powerful to express your full stack type save react that actually brings us to the demo that i've set up and i have just enough time to do it so let's get started i have here a simple create react app it's been set up with typescript and chakra ui for some nice styling it's pretty much an extension of what i already showed you with reactant typescript here it's running and i already have all the client side logic in place and i can submit and it's going to load uh some values the only issue is that there's no persistence so if i refresh this app it's not going to remember anything so our task is to wire it up so it becomes full stack and type safe the first thing i'm going to do is i'm going to initialize my back backend so i'm going to run amplify init and that actually asks me a few questions to get these process started i'm just going to enter the defaults for all of them but obviously you can customize it however you like and it's going to auto detect my create reactive settings so i don't have to modify any of these but i could if i wanted to all right the next process is to add our backend graphql api so i'm going to run amplify add api which is the standard workflow amplify add whatever category i'm trying to add i'm going to pick graphql and again i'm going to use choose the defaults for whatever they offer me by default they're going to offer me a todo model i should probably replace that with something that i'm expecting so it's just going to slightly extend that into a simple blog post model and now i can run amplify push to provision those resources that i just established as part of the push process we also get to configure the code generation for frontend types so we get a full stack all the way from graphql all the way to our front end types so let's say yes to generate code and we're going to pick typescript because and we can just hit enter to select all the defaults for the rest so the push and code generation does a couple things and i'm going to talk you through them the first thing that you should check out is inside of your source folder you have an aws exports.js file and this contains all the configuration information that is automatically set up for you by the cli so all you really need to do is import it just importing it at the root of your app sets up your app to connect with the aws backend resources the other thing that's changed is that we have a new graphql folder where all the typescript types have been generated by default based on our models so for queries we have get blog and list logs and the mutation with create and update and delete so everything as you might expect so inside of our app we can actually import whatever queries have been auto generated by our cli and then we can use them inside of our reactant typescript code as you can see here i make use of api.graphql and i need to import that from the client library which i also need to install so yarn add aws amplify that gives us the api.graphql function as well as its typings and we can also use this to do a create operation so you can import create blog and set the variables to the new values that we've set in our react app we should also make sure to import the create blog function from mutations all right let's have a look at what happens when we run this app now i'm gonna let it take up the full screen and let's just autofill some content autofill some more and now when i refresh all the data should continue to be there something else that i really appreciate about this workflow is that it decomposes nicely to the underlying aws services for more control if i need them so i can type amplify console here and it's going to open up the raw services for example here we added the graphql api so i can actually view this in appsync and perform the exact same graphql queries that i was doing in my code uh inside of this little ui that we have over here so i can say list blogs and i can just say give me all of them body title image let's go and this is exactly the query that i was performing and you can actually play with this but also you can see inside of our data sources i can see that it's been provisioned by dynamodb i can use other data sources like aurora and inside of dynamodb i have access to all the other capabilities that regular dynodb has as well as the cost and scaling benefits so here i can access all the raw data and access without amplify and i have full ability to eject from whatever setup has been created so that's a really nice fallback option if i need it now i realize that was a really quick demo and it has no time to cover all the really cool stuff like realtime subscriptions or offline caching but you can check that out on your own mostly i just want to introduce you to the overall concept of an integrated toolkit right amplify provides the cli that you saw the client libraries that you saw and the things that we didn't see are ui components for you to get set up quickly so for example authentication you might want to have an authentication component in your favorite framework so using this unified workflow we can access all the other categories that are exposed to us via aws like analytics aiml predictions uh authentication data storage for with amazon s3 and uh amplified data store all of these are really really cool features and it just take 10 hours to go through all of them but i encourage you to check it out if you're interested in this idea of a full stack integrated serverless approach that is typesafe amplify only started about two years ago and it's getting a lot of traction it's one of the fastest scoring services within aws and new categories are getting added all the time so in fact this year we actually added live streaming video just in time for the madness of 2020. it's almost like we planned it but we did not anyway i want to bring it back to type safe full stack react and i want to acknowledge another reactathon speaker lauren tan who actually gave me this idea that she first wrote about the strongly typed graph and she says that the strongly type graph builds upon endtoend type coverage and connects diverse domains into a single graph and that's a little bit of what we saw today just get to give you a sample it gives teams near realtime visibility of how changes in a larger graph affect your entire organization and that's the ultimate vision of how we can shift left our error discovery and resolution and improve our developer velocity and increase user experience without the cost of developer experience so thank you that was a really quick woven tour throughout all of reactant typescript and graphql all in aws and i hope you stuck through it with me i'll be around to answer any questions see ya and have a great day tomorrow wow we did it the first day of reactathon worldwide thank you so much swix for that last uh talk to finish out our wonderful first day here and thank you to all of our speakers um and our workshop leaders and our topic tables hosts and our sponsors and most of all thank you all for being here with us today uh whether through hop in or through the live stream um we're just so glad you all could join us today and we hope you had a ton of fun so that is a wrap for our talks for the day however there is still a lot more happening jonathan you want to tell us a little bit about what's going on yeah so for the next hour and a half you can check out the sponsor expo talk to the engineers there at the sponsor companies and they're there for the next hour and a half uh you can also continue to network with people in the networking session or the sessions section session of the app uh and anjana is going to give us a good reminder uh here as well yeah so the um the the sponsor boost the networking sessions the um the chat on the app all of these great places to connect with people um and as always we want to make sure that everyone is adhering to the code of conduct um again that is there to protect us all and to make this a really safe space for all of us and so as always please keep that in mind don't forget it's available at reactathon.com conduct and you can report any violations should the event arise by clicking on somebody's profile and then clicking report user to send a message to the conference organizers so let's all make sure that we are staying respectful and safe and protecting each other's experience as we continue to engage with each other and we're excited about tomorrow we're going to have more great content both tomorrow and wednesday but tomorrow morning uh starting at 7 a.m pacific time we will have our workshops kicking off at that time and sponsor expos start at 8 30 and then of course sponsor talks start at 9 30 a.m pacific and then back on the main stage here you will see us myself and angela around 9 55 pacific time absolutely so really excited to see everybody back here again tomorrow and in the meantime you can stick around for the next few minutes uh before you jump off to the sponsor booths and to chat with everybody that you got to connect with today you can also stick around to to catch some nostalgic shots from san francisco where we're hoping fingers crossed with a little luck and a lot of vaccines we might be able to see you all uh back in person next year but uh for now that's uh myself anjana vacheel and my wonderful comc jonathan signing off for this day one of reactathon we'll see y'all tomorrow bye so my foreign so