the great thing about this opencv course is that you can follow along from any computer without installing any software by using google colab in your browser mspa who teaches this course makes it super simple to follow along if you already know some python hello everyone welcome to this opencv tutorial series here we will be using python in google collab to create opencv projects understanding the basics of opencv we will understand the color profiles doing edge detection image manipulation these are all simple applications of opencv and then gradually move into the intermediary applications like color detection writing drawing shape detection we'll also try to do some projects using the knowledge that we have embossed in this particular tutorial to create ball tracking face recognition and so on this tutorial series is designed for people who are beginners intermediary and people who just want to enhance their knowledge in the opencv field we are using golab which will allow us to create these applications right off of the website on the google collab library we don't need to worry about downloading some dependencies installing libraries making sure things run or not having it on collab makes it very easy plug and play for us with that let's get started hello welcome to lesson one i'm going to quickly make the screen big and i will also upscale this thing so the visibility is right good for you in the description you can open up this link and it will take you to this page and the basically the first step we're going to do is simply run this clone so we're just cloning the repository we're just downloading all the files that we need for this program it makes our lives easy if you go into this folder you'll see this opencv tutorial folder created for us and it has some sort of images that we will be using for this particular set so the first step the first lesson we want to look into is changing a color profile of an image so the first thing you want to do is import opencv and that's the mother father of everything of all the images you want to download opencv first make sure opencv is happy and it's take case takes care of all our images to the best of its extent now we also want to display the images and since we're using google colab it's in order to display it right in the browser there is a different function and for that purpose we will import from google because google had created this patch for opencv and you say google collab dot patches so you have patches from google cola patches import cv2 i am show then the purpose of this guy cv2 im sure is just to take your image and display it on the browser as simple as that now you have opencv and you have opencv i am sure now what do you need you need the images to work on so the first thing is to read the image and i'll say okay i have an image and show me how i read the image so opencv has this command called i am read and this is basically stands for image read this image read guy can take whatever image you have and just read it in the program in this python application what does imd need from you it only needs the path of the image file so where is our image located our image is located this is the color.jpg this is the image that i am interested in and it is available inside this images folder of color.jpg so we will say okay i have my image it is in the images folder bracket and then you slash and you put down color dot jpeg but that is my image so i am read just needs for you to guide and let them know where the image is stored i'm just saying it's under images color dot jpeg so it's as simple for now now let's try to read this image let's try to display this image for now so we can use this i am cv to im show command and will do i am show and this i am show only needs you to tell what image you want to show and in our case we just want to display this image so we see this is the image you want to show us once you have this just go ahead and run this and it should open up the image for us you can see it's a very colorful very vibrant display image for us right here in the browser now i am interested in what is the dimensions of the image what are the properties of the image and for that purpose let's not display it again we write a opencv tell me what is the dimension what is the property of the image that is stored under the function under the variable called shape so i will run this and it displays this function in this number and what is this what what does this stand for so 476 and 640 are nothing but the number of rows and number of columns or the width and the height of the image and this number three represents the number of channels that are available in the image now since this image is a colorful image it has three channels which is nothing but the red green and blue channel and that is what defines a colorful image so this is basically a colorful image now the first thing we will look into since we are talking about colorful profiles or changing the color of the profile of the image the first thing we will look into is making an image grayscale now grayscale image what is this it's basically a black and white image now let's see how opencv can do it for us we will call a new image called gray and we will say hey grey image make this colorful image turn into gray for us how would you do it you just going to open cv2 and opencv has this amazing function called as cvt color and this color function is capable of converting the color of any image that you give so you need to just let the function know what image that you need to provide in this case you say our colorful image from the previous section please convert that into gray for us so we say image but it also needs to know what kind of color you want yes i know you have given me the image the colorful image but what do you want in return from me so for that purpose we say open cv convert it into a color from color to gray so we say convert color in caps luck and then underscore we say hey opencv convert it from bgr to gray we just say this and it converts it for us and we see bgr because our original image is in the format of blue green red all the three channels separate and we convert it into a grey image coming down let's display this image for once again now let's see what does the gray has in store for us and let's run this and voila our colorful image is now turned into a grayscale now you might ask hey mister you had a very beautiful colorful image why did you bother converting it into a grayscale image why does why do you even need to do that aren't you spoiling the image why aren't you going to spoil the program what is the purpose of converting into a grayscale image the purpose for that is these three channels you can see the colorful image had three channels and these three channels store information about the red color green color and blue color that is a lot of information for us when you're going to be using opencv algorithms and computer vision programs you have to do complex processing pixel level processing you're going to be opening each bit each and every bit of the image and that's too much of information for us so in order to reduce that one of the techniques is to reduce the number of channels so like this colorful image had three channels if you were to display and ask opencv hey opencv give me the number of what is the shape of this gray color shade gray color image and if you print this you can see that the colorful image had three channels and the black and white or the grayscale image has no channels you can see there is nothing available here because it's only one one matrix all by itself it doesn't have any channels you have reduced you have compressed all those three channels into one channel which is defined by a gray color profile so you have reduced information you have reduced the number of pixels you have made opencv happy because now it doesn't need to handle three different channels for your images just one image this is one channel and that's all it needs to take care of so you're making opencv happy you're making your computer happy because it doesn't have to load so many bits of information for you and this makes life easy for you and for the program so let's go into the basics now we have the grayscale image let's look into another print another type and that is the hsv image now you might ask okay so we have we took out all the color profiles we took out everything we needed from the color images now we brought them into a gray image but what if i was interested in color i'm a colorful person and i am interested in identifying different colors in my image and that is my project but you made it into grayscale now how do i how am i going to work on it well to answer it for that is your hsv image and this hsv image or this hsv channel is capable of holding all the color profiles under one channel now what do i mean by that to appreciate that fact remember this your colorful image had three channels right blue green and red the hsv image will also have three channels but the channel that defines the color is only present in one bit so i'll explain what that means but let me say hey opencv i'm going to create a new image called hsv and for that purpose i want you to convert my original image i'm going to use again this convert color profile function and i'm going to pass opencv the colorful image that we had image and we're going to let hey opencv this original image that i have converted into a hsv image hsv color bgr to hsv and if i just print the shape of this hsv hsv dot shape and let's run this so you can see hsb also has three channels so what are we doing then well hsv stands for hue saturation and variance and the hue is defining all the color profile in the image all the colors that are available blue green red everything all the colors of the rainbow are going to be available in this just one channel called each so if you can control if you can pinpoint h to give you red color you can also pinpoint it to give you yellow color green color blue color so this hsp guy the hatch channel of this guy can hold all the colors of your image so previously this colorful image had three channels and in order for you to define a color yellow you would need all the three channels to define what a yellow color looks like but a hsv image can only use your h channel to define what color you need and that makes your life in detecting colors very simple very easy and very very easy for the computer to process so your complex algorithms that we will look into the future will be very easy to run you might ask how does this hsv image look like well you don't want to see it but i'm going to do it anyways and you might regret let's run this and you can see that this hsv image looks nothing like the colorful image nothing like the grayscale image it has its own legend and it's it's running it's it has an own property it has its own way of displaying images and that is what we are interested in we are going to look into the h value the s value and the v value separately to define the color that we are interested with that we come to the conclusion of our first chapter which is changing the color profiles and these are the color profiles that are going to help us in our later projects welcome to lesson number two here we're going to look into what edge detection is all about so the first step is to go ahead and import opencv so we can see we can take care of all our manipulations image manipulation that we're going to do right now and we have this image which is right under this directory if you go into opencv tutorial you have this images folder and under images folder you have this image color.jpg we will work with that image today we will say hey opencv i want to read this image and i want to save this in this variable called image so image is equal to cv2 im read and you need to tell opencv what is the image file path so in our case we saw that it was under the images folder and it's called color.jpg that is the file path for us we just go ahead and write down the image path name which is under images bracket and just specify what to stay after the slash and you say color dot jpeg you are now specifying what is the image that you want to read once you have this if you want to just simply display it you can use cp2 i am show and that's how you display it but since we are not able to use we are using the collab version we cannot directly use cv2 dot i n show and for that purpose we will import something called as or from google google has this patch that created in order for us to use the cv to imp i am show we will use google collab dot patches import cv2 i am shown we are just importing cv to im show and we will say hey cv2 i am sure please display the image for us we just specify the image and if we run this it will display the image for us right here in the browser we can see our colorful image is right up and running for us now let's understand let's go into the edge detection so we have this image you know let's for now we'll comment it now let's make it into a canny image we say can image and the scanning image is nothing but the edge detected image we're going to be using a edge detector called scanning edge detector i'm going to be using this function from opencv which says a opencv pv2 please do the kanye edge detection on my image so opencv has this function called kanye you just need to specify what is the image okay i have the image the canon edge detection also requires you to specify the size of the filter that you're going to be using so the filter size in our case will specify hey let's go to be 150 by 200 it doesn't matter what filter you're using you can always test it out and see what kind of a result are you getting so if there's no hard and fast rule behind the 150 and 200 which i mentioned here you can always test it out and see and now we can simply display this but before we display there is an issue canning image does not run does not run by its own it needs to run on a grayscale image like the grayscale image that we learned in the previous lesson where you are converting the grayscale using the color bgr to gray we need to convert our image into a grayscale image before we do anything so let's copy this let's copy this line from here and come back to our can edge detection now we know what is the purpose what is what is one of the uses of grayscale image we save this here and we convert our image into a gray image and we specify the gray image to canon because scanning is only able to work on grayscale image it only assumes that the image has one channel and for that purpose we need to make sure you're only providing one channel grayscale images and let's see how this image runs out to be now you can see the whole image is gone and it's only specifying the edge profiles of the image isn't that amazing that is what the canon edge detection is capable of there are a few more adjectives there are a few more things that we can do with this we have the candy image and it has it's able to detect all the linings able to detect everything all the edges that are available in the image but say we were not interested in everything we were only interested in the highlighting features of the image because right now it's very difficult to understand what this object is even about so we can use some filtering methods and for that purpose let's import numpy import numpy as np and numpy is our brother to opencv who is able to do some matrix manipulations for us which is also very very much similar to what opencv does in fact np can also be uh another format of opencv because it does also works with matrices but opencv has already made very things very easy for us but we are not going to ditch it we're going to use it simply and run our application with the help of opencv now you have np the next step we're going to look into and understand erosion and dilation we'll say erosion and dilation right here so let's first do erosion of our image now we can do erosion by saying hey erode my image which image the canon image eroded so that you can remove some of the filters that i'm not interested in you wrote the image by using opencv's your road function and this erode function is capable of taking your image which is the canon image you have the kanye underscore image but it also needs for you to specify a window size because this window is going to move over your image and wherever that window matches or falls into the property of erode it will eradicate it oh you know what i just found my mistake so i missed the e over there and we are also needed to specify the window size which is also called as the kernel the kernel equal to np which since we are going to be using numpy to create our matrix then kernel is a small window a small matrix and it's going to be a matrix of ones and we'll give it a size of maybe pi by 5 and we'll say np is of unsigned integer of bit size eight but that's basically specifying what our image is going to be looking like and this five space five by five is nothing but the tuple so it should be under brackets and you have your kernel defined right here we use the kernel into our erosion format we say kernel and it can also take you can move the window over the image multiple times right now we're just interested in one time so we'll say iterations equal to one so erosion going back to the function there are a few things happening so the erosion function is able to take the image that you're interested in it also needs the kernel and it also needs the number of iterations you are going to specify it so let's display this image as well pb2im show erode image so let's erode image and now run this so we are going to run this image and for some reason we're getting an error and the error for here it says that as a substitution consider cv to underscore i am show and we as the user of opencv on the desktop we used the dot i am show function let's convert that into the underscore and let's run this and you have a new image which is which has nothing but basically eroded everything so let's reduce the kernel size and say two by two and let's see what kind of a result we will get so it has some information you can see some dots available of course it's taking out most of the information and now you might ask why do we why do we even need to do this because it's taking out all the information that is available in our image let's make it by one by one and see if it can display some more information yes it's displaying a little bit of more information but if you compare with the previous image there is not much of a difference and it makes us think or doubt ourselves about why do we even use erosion well erosion is used in order to reduce the noise level in the images and it also comes and it's very much useful when we are when we can pair it with dilation so let's look into what dilation stylation is nothing but the opposite of erosion so let's go into dilation uh let's uh maybe comment this out for now and we say this is erosion and this is going to be dilation so dilation also needs the kernel yes so we can put maybe the kernel on the edge side so we'll put the kernel right before everything so it's the main guy because it uses it uses both erosion and dilation so we'll have kernel in both now we say hey dilated image use open series dilate function dilate and use your can image let me move this out of the way so you're using opencv's dilate function and it also requires the kernel that we created the kernel and we also use the iterations equal to one so what we did is we're using the dilate function which is very similar to what the arrows function is now we are using it again on the canning image we are making the kernel where you're making use of the same kernel and we are using iterations of one by one let's see what we can get if we have the kernel size of five by five and let's display this for us i am sure opencv dilate image let's run this and we can see this is the any kanye edge detection image and this is the dilated tv what is happening here you can see that the edges or all the edges that were visible here now they have been emphasized they are made more they are increased or you can say dilated they become very big now now if we were to use erosion after dilation let's uh let me remove this kernel we don't need the kernel or we can keep it for your purpose that's fine and let's do erosion after dilation so we have here dilated image and we'll use the dilated image instead of the canning image and then display our eroded image so let's run this so you have for the original can image again then you have going down you have your dilated image and now you have your eroded image so you can see there is a difference between the canyh image and the eroded image but there's a little bit of doubts here so if we increase let's see what else we can do to make it more simpler for us to understand we have the canning image in the eroded image we are basically converting we are basically making or displaying them one after the other what if we do it horizontally stacked so we have this np dot head stack we use display this is the image that is going to be displayed and numpy has this function called hedge stack and h stack is going to take three values and our values are the can image we have the dilated image and we have the eroded image we use all these display images and we say cv2 i am sure display this image instead of displaying the eroded image instead of displaying the dilated image instead of displaying the canning image altogether we will display all of them under one horizontally stacked we just run this and we can see all the three images right here in front of us so you can easily compare what is happening to the original canon image the edge detected image has made it dilated so it becomes big and now you're eroding some parts of it so it can become more and more visible and you're just trying to basically erode some of the more abundant information available here so this is more about erosion and dilation and the number of the number one use of antiage detection with use of erosion and dilation is in the process of making lane detection application so you you have a row you have a picture of a road or you have a video of a road and you are interested in understanding where the lanes are available and for that purpose you want to use the line detection the edge detection and then provide dilation and erosion if you if there are any kind of noise you want to remove so the erosion and dilation is nothing but to use or work with noise for our purpose and uh that helps us that helps us in making the image more visible so that you're not focusing on the un necessary information but focusing on what we need maybe it could be the edges maybe it could be a certain region within the image so you can specify your filter size and then focus on the area that you are interested in hello everyone how's it going today we're looking into image manipulation now image manipulation has a variety of things that you can do if you're just going to open cv and type in image manipulation you'll open up this open cvs program and let's look at image calculation of opencv if you just go into image processing and open you will see that it consists of color spaces changing color spaces doing some sort of geometric transformation thresholding smoothing of images which is nothing but all these noise and blurring images morphological operations which include of erosion dilation and opening closing etc erosion dilation is something if you recall in the previous video if not if you haven't seen them i'll put the link in the description uh you can look into this erosion and dilation and this will be this is basically removing the noise or adding or emphasizing those pixel values similarly you have image gradients you have canny edge detection uh you also have image parameters so these are all different types of image manipulations that you can do and we will look into some of these important ones which we need to know for sure yeah into our subsequent uh chapters but right now let's look into one particular aspect which is denoising or which is also called as removing the noise removing the issues that you across you come across in these images now in order to run this once you open the collapse link you can go ahead and run this code which is in the very top and it's basically the github clone and you're just cloning the repository that we need here so it will take a few seconds and we'll clone the repository and if you open up this folder which is the directory folder you'll have this opencv tutorial and it'll have this images under images today we have this new image called the lion image lion.jpg image and the reason we have this lion.jpg image images because i i wanted to choose i wanted to get a very grainy and a very noisy image and yeah animals because of the amount of hair present on them it seems to be very noisy on a camera especially line with all the big hair available on it it becomes very nice we'll look into the code and see how this image really looks like so we have we're going into lesson number three image manipulation and let's read this image for us so we are importing opencv we're importing cv to our underscore i am show and we are also importing numpy now let's look into displaying this image first the image equal to cv2 dot i am read and we want to read the image under the opencv folder because our image is under the opencv folder urban cv lion dot jpeg let me maximize this a little bit so it's easier for you to read in fact i can close this as well now we know it's under the opencv images i think we are already under the email opencv folder we just need to be under the images folder because we already changed the directory right on the beginning if you see we have changed the directory to opencv tutorial so the cursor is somewhere in here we just want to go under the images folder so for that purpose i'm telling the images that image which i'm opening it's under the images folder the images then you have the line.jpg so this image should be read into this folder in this variable called image and once we have this image we will now display it we will say cv2 underscore i am show image and if we just run this it should display the line image for us you can see it has this big image and it has so many hair on it and it seems very noisy if you look it from a camera perspective from image perspective of course those are the definitions of uh the hair of the alliance i don't know what it's actually called but you can see the number of grains the number of noisiness available here now consider that okay this is something a noisy picture and you're not interested in looking at all this images looking at all these hair profiles of the line how do you remove this thing how would you remove or blend all these hair profiles into one and for that purpose we have something called as fast error mean denoising color and this is a part of open series denoising profiling so if i go under opencv image denoising you can see that it's taking a grainy image and this is from the website or this is from the opencv's website so it is a very grainy image you can see the amount of noisiness that's available and once you apply the denoising filter on it it removes the noise to a large extent and how it's doing it is because it's averaging the pixel it is taking the mean of the pixel in that area and whatever is available which is more important it then denoises it and just takes out what is important for us and this is what the denoising takes care of first we'll come here and we'll apply the same denoising filter on our image and uh the denoising filter is looks like something like this fast and means denoising colored and it's the reason we are putting colored is because this is colored image similarly opencv has something for grayscale where you can do more about binary images where it's only black and white and they have their own functions which will act in a separate way in this case we're using the colored profile and we need to provide the image that we want to do in our case it is image and these are all the filters that are available so because this is it's kind of a filter it's kind of a window that goes over all across the image and it displays all these images for us so uh there is a filter which basically goes through all these images and then this is the size of those filters the these are the threshold values so all these values are something right now at this point you don't need to remember what this is about but when you're using this program this particular this particular function in your realtime code or project that may just play around these values until you get the result that you want now there is no hard and fast rule in knowing what is correct and what is wrong because every size of every image is different the project that you're working is different the type of uh images that you're using is different the size of the images are different as well so all these values will differ from the different images that you're using in my case for this particular image that i'm playing with today if this particular value is worked out and uh but it could be different for different and we'll see how this thing works a little bit as well now coming down here uh let's display this image so you have the original image which is the image and the destination image which is dst now you let's use a numpy to create a horizontal stack of this so we'll create a horizontal stack which we will be displaying and we'll call it as a display and horizontal stack is basically adding both these two images destination and image and making it look like one image so the numpy has a function called h stack and it can take two variables or two or many variables of similar size similar matrix size so we can say okay hey uh i want to add the image and i want to add add the destination together and both of them please combine and give it to me under this variable called display so we have display come down here and we will use open cvs underscore iron show display and it will display this for us let's uh comment this thing so we don't we're not displaying it two times because already we are displaying the image and the destination here for our case now let's come here let's play this and it should run both the commands and it should give us the output right here oops jumped up okay so you can see both the images are available here and this is the original image which has all this grainy profile of the lion in this case you can see that all the greens all the hair are blended and they're joined and you can only see the gradient color out of it and all the hair profile which was basically defining the features of the line here are gone and it's only emphasizing the gradient profile of this so it's basically considered considering all these hair profile as noise and removing them and giving it out to us so it looks like a more of a cartoonish cartoonish display of an image and converting it or cartoonizing the image but it's kind of a representation of those images here for us so uh now coming down here let's play with these values a little bit so you have 20 let's see what happens if we do it as five and let's run this again and we'll see what kind of an output we get here and since we reduce the size of the window you can see that the grains are now much more visible there is of course a little bit of blurriness available here you can see this portion here and this portion is different whereas the long hair available here are also available here because the size of the filter reduced and it's only now removing small small amount of noises because the texture you see here on the nose it has small noises and those noises are being blurred out however the big hair profiles that are visible that are still visible in this final image and that's because you have reduced the amount of the filter similarly if we increase to this thing say for example we were to do 50. let's see what kind of an image we make we may get uh let's see even if we can even recognize whether it's a image of a line or not and you can see that it's fully blurred out there you can hardly identify any kind of features uh in this image and it looks like more of a painting without much uh without much definition of the original character and uh you can see this this is this thing more looks like uh something from a 3d or something from a cartoonish drawing and all these features all these things has been blurred out and it's only showing the gradient of it and that's how it affects all these filters all these values affect the value and similarly you can play with all the other values and see what kind of an image you get out and uh this is basically helpful when you're doing some sort of image or foreground extraction or background removal where you want to specifically segment or specifically emphasize on the objects and remove all the types of noise available in the image and uh that's how it's very helpful so the way that with that we come to the conclusion on image noise removal hello everyone welcome to lesson number four here we're gonna try how we can draw shapes and write text on images so opencv has their own drawing functions and own writing functions and we'll see how we can use that to our own images the first thing you want to do here is import our opencv so you can see we can take care of all of our opencv overall manipulation functions once you have image maximizes a little bit once you have open cv the next thing you're going to be using in this project would be numpy import numpy as np and i'll go into why we're using numpy in a little bit we're also going to be using google collabs cv2im show so that we can use and display the images right here in the browser for us we are importing from google collab patches input cv2 underscore im show so we have all these three libraries right here now normally we go into the directory and right try to open one of the existing images but in this case we will create an image from the scratch from the basics so the first thing we will do is we will use numpy to create a matrix for ourselves so we'll call a matrix called img okay so this is our matrix with img and now what is numpy going to create a matrix for us a numpy has this function called zeros and this zeros function is capable of creating a matrix of just zeros so the zeros function is going to create return a matrix which is just filled with zeros and with opencv language 0 is nothing but black color so now since we could be using a colorful matrix we will create a three channel matrix i'll go into that right now so let's first define the size of the matrix we'll say okay let's call it a 5 by 12 and 5 by 12 matrix so it has about 5 12 rows and 5 12 columns so that's the definition of our matrix and this matrix is also going to have three channels these three channels are representing the red green and blue color of a colorful image but in this case we know we are initializing it with zeros so all those three channels will basically be zero at the moment but we want that and the reason we want that is later on we can fill in the colors that we want so we have our matrix which is 5 by 12 5 by 12 and 3. and we are also going to say okay numpy this matrix is going to have a property where the numbers are going to be unsigned integer of byte size 8 now what does that mean unsigned integer of byte size 8 means the range of the values inside the image or inside the matrix are going to be anywhere between 0 to 255 that is the meaning of unsigned integer so basically you're just defining matrix and you're telling that this matrix is yes it is zero in color but later on in the future when you're going to be adding new colors it's going to add in this range only and it can take a range of values only between this 0 to 256. that's because colors are represented in a 256 range which starting from 0 goes to 255. so you're just defining that this is unsigned integer okay now let's display this let's see how this image looks like we've been talking about zeros we're talking about see black in color but let's actually see how this function works oh you know what it should be i am sure we have our image let's display this we have run this and you can see it's nothing but a black and black color image not even white black black image altogether so we have taken care of the image and now our image is present so let's try to do some manipulations on it like some drawing functions so opencv has couple of drawing functions it can do draw or draw a circle for us it can draw a line for us a rectangle it can put text so the couple of things that opencv allows us to do now let's see how we can go about doing that opencv has a function called circle so we'll use the circle function ros will call it as draw a circle let's see how we can do that opencv has this function called circle cv2 circle and this function can define you can see it takes the image name the center of the circle the radius of the circle the color the thickness the type of the line shift and then it defines gives out the result in your image function so this is what the circle function does now let's define the circle function needs the image which is the img it also needs the center of the coordinate of the image so we will say okay the center of our image in this case is going to be at maybe 100 and 100 so x and y are both hundred okay good we have this then let's the next step you want to put down is the radius we have the radius let's say maybe 50 okay we have a radius of 50. next thing you want to do is the color so you want the color now color is represented by three variables which represents the bgr value so in this case let's make it uh green color circle we'll call it as because since it's represented as bgr where b is for blue g is for green r is for red we will call it as zero and since we want green color we'll put green as 255 which is the highest value and the red is again 0. once you have the color defined the next thing you want to do is the thickness the thickness of the line so the thickness is also something you can define and we will call in our case a thickness of size 10 okay so let's see how this function works for us and then immediately after that we are going to display our image and let's run this and you can see that now we have a circle it's a circle which is green in color and it has a thickness of about size 10. so that's about drawing the circle you can always play with these values these are nothing too crazy about you can make it a size thickness of five and you can see the thickness as radius from the circle so that's pretty much about this drawing a circle once you have drawn the circle let's see how we can draw a rectangle again principally has a function called rectangle cv2 rectangle and this function also takes something similar it takes the image it takes the points of the rectangle and it takes the color the thickness of course the line time and shift and we can then draw the rectangle now point one and point two it says that it draws the rectangle the between the two opposite points so point one is on the top left corner of the rectangle point two is on the bottom right corner of the rectangle coming back here we will see cv2 rectangle yes you want to draw the rectangle on the image img and you want to define the point one in our case the point one is going to be should we draw at 100 by 100 no but that'll be intersecting with the circle so let's bring it a little bit away from the circle we'll call it as 200 by 200 okay so it's a little bit further than the circle and we are going to say that it's going to end at maybe 400 by 500 this is just random you can choose whatever you want to draw the point here is just to understand how we can draw these parameters these rectangles and geometrical shapes on the images so we have point two defined now we want to define the color let's make this a red color rectangle so we'll call it as zero for blue 0 for green and 255 for red let's minimize this a little bit so we can see what's going on in the other part of the stream so we have 255 we also want to specify the thickness of the rectangle the thickness of the rectangle is going to be five for example let's run this and see what we can do on the image and now you can see that there is a rectangle coming up and this rectangle has about the same thickness as we had for the circle because both of them are 5. so once we have this circle let's let's see what happens if we put the same coordinate as the circle 100 by 100 same 0.1 and let's see what we get and you can see a rectangle that is intersecting the circle and then it's also bigger in size because the point two has not shifted let's bring it back to where we are so it doesn't messes you up when you are trying this code on your own okay so we have the rectangle we have the circle what are we missing the line function let's draw a line so opencv has this function called let me put down the comments here so we know what we're doing here draw a rectangle draw a line okay so cb2 has a function called nine now line can also draw something on the image and uh you know a line can be defined between point one and point two so as long as you know where the points are you can draw a line so you are going to be using the image the point one the point two the color the thickness by now you might get the pattern so it first takes the image it takes the parameters of the coordinate of the geometrical shape and the color and the thickness the line temperature is something that we're not looking into but you can have a dashed line you can have a broken line a dotted line for different types of lines by default it will take a solid line come down to cv2 line so it takes the image and it takes the point one and we'll call 0.1 is some random value 160 by 160. okay now what is 0.2 0.2 let's put it as a random value of 359 29 so you have 0.1 and 0.2 and this time we will give it a color of blue color so we'll see 255 for blue 0 for green zero for red so you have the blue color and we'll give it a thickness of again maybe three and let's see how we can run this we run the play button and there seems to be an error because we've missed the comma between the thickness and the color so we've specified that and now we can see there is a line drawn right here between point one and 0.2 so we have the line drawn we have the rectangle we have the circle coming down to the last point is how to write a text on the image and we can draw a text or we can put down a text on an image by using cv to put text so it has a cv2 dot put text function and this function can put down this the text that we want to put down so this also takes the information where it's going to be putting it's going to be putting on the image it's going to take the text the text you want to be putting down the origin of the text so the initial coordinate of the text the type of font you're using the size of the font the color of the font the thickness of the font and then it draws the text for us and this text right here is going to be a string it's going to take a string value and then display it on the image for us so let's come down to cv2 put text and we will say okay the image img is going to be using to display the text and the text is going to be open cv and the next step is going to define the origin of the text and let's say you don't want to be putting it at 280 by 150 so we have defined the origin of the text now we're going to be defining the font phase the opencv has some default fonts that we can use at the same time if you want to use your own font yes opencv does allow us to use some external fonts but you can see that it's giving me an option of putting down font underscore hershey complex small duplex plane so it has couple of options let's go with what we have here and we can put down okay font hershey complex you're ready for us and the next thing you want to put down is the scale now the scale is the size of the font and we will put down just for the safety we'll say 2 because we don't know how big this text is going to be we have 2 and then the next thing is the color now we've already used blue green and red you can see the blue is for the line the green is for the circle and the red is for the rectangle let's use something different now well we can put down blue as zero we can have green we can also have red i wonder what kind of a color this might give out now the thickness let's say the thickness is two and we can now display this and see how we can what kind of an output we can get so you can see that it is generating this text opencv it's starting from the origin that we have specified but it's going beyond the size of the image that's because opencv does not know from especially the font function does not know where the image is ending so it keeps continuing printing the text on the image and if the text is beyond it simply truncates it but it does not raise any errors so the only solution for that is you reduce your image you reduce your text so you can either make it as small as text by making a size of one okay if you made the font size is one so it's within the scale or you can also use or move your origin instead of 280 you can say okay we'll put it at the same point where the line is so we'll say 160 by 160. oops 160 and let's close the bracket right here and we'll put the form scale back to size now let's see you can see that's not generating the opencv it's of course on top of the line original line but it is at least within the image per se i guess that does the job for us in the last here we are displaying the image for us so that's the simple function these are simple functions that can be used but again they help us in displaying the data on the images for us we'll see in the future projects how we're going to be using these functions in our realtime projects hello everyone welcome to part two which is intermediate exercises of this opencv tutorial series and we are going to look into lesson number one which is color detection the first thing you want to do is come under the top of the most the earliest thing come here where it says cloning the repository and also changing the directory let's run this function by itself and we are only interested in this just because we do need this opencv tutorial folder and it has certain images and we're going to be using one of these images here for our project so let's come down here and let's look into the intermediate exercises and we are under color detection the first thing you want to do is import all the libraries that we need and we need import cv2 we also need numpy as np let me maximize this a little bit so it's easy to read so import numpy as nb we are also going to be importing the google collab library for our display we'll say from google dot co patches import pv2 underscore i am sure let me show you what i have done here so from google collab patches we are importing pv to underscore i n show now we have all these images we have we have everything in our folder if you go back to this directory and under the opencv tutorial folder under the images you have certain images and we are going to be using this image called shapes.png so coming back here we will say okay i open cv you know what i have this image called shapes.png and i want you to read it for opencv to read this image we use opencv cv2 dot i am read so opencv will tell me okay i'm going to use i am read to read but give me the file name what's the file name okay the file name is going to be shapes.png but this shapes.png is inside the folder called images so i will also need to provide the folder path this images with the slash images that shapes.png is where the image is available for us okay so that will read the image and it will save the image under the image folder variable now let's display this image by using cb2 underscore i am show image and we just display this image here for us so we're just reading and displaying the image okay good let's run this and we can see that it is displaying this set of image it's a big image and which has all the shapes and different colors present in here okay good now coming back to the code so we have the image right now and we are just displaying it now see if i was only interested in particular colors i have this blue color here let's let's say that i'm only interested in this blue color for now okay so we come here uh the easiest way to select blue color is to first convert it into a new hsv image instead of a bgr image currently image is a bgr image it is represented in blue green and red channels okay now we want to convert this image into a hsv image so we have okay coming here let's come down here let's convert this into an hsv image and we'll call it hsb image equal to pv2 convert color we used this function in i believe it was lesson number two it was right here in the lesson number one i believe yes it's changing the color profiles we used it here for our convert color bgr to gray bgr hsv if you haven't watched that part go back to the page where it displays the hsp image we have given description of what hsp images are and how do they look like coming back to the color detection aspect coming here we are just using the convert color function to convert our bgr image to a hsb image and this convert color function requires us to tell what's the original image original image is the image variable right here and we specify the image one after that we do need to provide what kind of a conversion you're doing now since we're going to be using bgr to hsv we're just going to say convert color bgr to ray so we have p g r two h s v i'm sorry v g r two h s v this function right here h s v is going to be converting a bgr image to an hsv image now we have the hsv image let's do you want this do you want to see the hsp image if you have watched the previous video you don't want to do it but just for the sake of understanding let's run this there seems to be a function error yes because we use the underscore uh we did not use the underscore instead we use the dot version so you can now see that this hsv image is different it's different to what's available here this this original image has different colors for the different shapes but here it's almost the same but it's not the same uh mind you on that it's a little bit different yes it is in yellow in color but they have different color profiles different ranges but oh and we'll see how we can utilize that factor okay let's remove this just play this so we have our color image here okay now what is the next step the purpose of hsv is because you are converting a bgr a three channel image into a hsp image where hue saturation variance you represents the color profile so you can now control the value of hue to display what color you want so i will say okay i have this image it has different colors and i'm only interested in this blue color so i can isolate this blue color in the hsv range by saying okay my lower blue color so you need to provide the range of your blue color values and i'm going to say okay my lower blue color it's under the array it's going to be an array and this blue color array is going to have a value of say 65 0 and 0. and i'm going to supply another upper range now stay with me on this and explain you what this is what's happening here and i'm specifying another array and this array is going to have a value upper bound of 1 255 255. so i'm having two upper right so i have a lower bound and an upper bound and i use this lower and upper bound to pick out or extract just the blue color basically what i'm saying here is okay i have an image and i'm only interested in the blue color which is between these two values lower blue and upper blue and this lower blue is specified by the hue value between 65 and 110 so my blue color is between 65 and 110 and the rest the saturation and the variance is maybe between 0 to 255 i don't care right now i'm only interested in my u value which specifies the color and my color which is the blue color is between 65 to 110 and this is what opencv will look for anywhere where blue color or the hue value is between 65 and 110 it will extract that and ignore the rest basically the value of on this color can go anywhere from 0 to 255 0 to 180 but we are only interested in 65 to 110 okay so we have decided to find the boundaries of our blue color now we are going to be using a range function to create a mask okay i am creating a new mask now this mask is going to have the value only of the blue color the opencv has this function called in range in range and this range can take these lower and upper bound range and return the pixels that lie between these ranges this range so i say cv2 in range and i you want to find the range between in the hsv image using the lower bound and the upper bound you can see the source image the lower image lower bound and the upper bound coming back we've supplied the image which is the hsb we are now supplying the lower bound which is lower blue and we are also supplying the upper bound which is the upper blue and it's it will create the mask for us let's generate this and we can see how the mask looks like it's it'll be a black and white image which will only consist of blue color so you can see that this is this is the original image right from here in the bottom but the upper image only is specifying the triangle which represented the blue color original so it's now creating that mask is created where it's only representing the triangle now i mean let's not display the i am show original image so if we don't we don't get confused we can see the image now only is creating a mask around the blue color rectangle okay so good now the next step is to create to use this mask to extract the original blue color from the previous image so we can use a bit wise operation on this we can say hey result equal to cv2 bitwise oh did i move out of it now i hope it's visible now so we have bit wide and and wherever your original your mask has an image wherever your mask is white in color like this case wherever the mask is white color it should return the original color of the image and wherever it is black it should just ignore that that's what the bitwise hand is going to do wherever white color is present it will give out the original color and wherever it's black it will ignore that area so we'll say okay you're going to be doing bitwise and on my image and you're also going to be pre you're also going to return the image in my same image folder and we are going to use a mask which is given by our variable here mask this is my function and we have defined the result image now let's display this result image okay we are displaying this result image now let's run this and let's minimize this a little bit so we can see so you can see the original mask looks like this and the final image looks like this where it has extracted the original part of the image it has the blue color similarly if you were interested in the different types of colors you need to specify the different lower and upper range values so like we did lower blue here instead of blue we can say lower hue and upper here because we are actually converting or we are actually using our playing with the hue values so we'll say upper hue and lower hue so let's run this back again to make sure our code is fine we did not break anything yes everything seems to be working fine and we also don't need to display the mask anymore since we know how the mask looks like basically a black and white image and you can see that this image is only representing the blue color rectangle similarly our original image had different other colors like it had the red color the yellow color and we'll see how we can extract the different colors with this lower and upper bound range we find the blue color triangle now similarly there are different other color profiles which can represent different other colors that you might be interested in similarly like we have blue we have the red color red color and you can use the red color by conv by using our lower view and our lower q is equal to again with the np dot array and this array is going to have a range of values between 0 to 20 because this red color is basically zero by zero it's in the original spectrum of it's in the initial spectrum of the hue value similarly we are also specifying upper hue equal to np dot array and this function goes from 0 to 20 u is between 0 to 20 and our saturation and variance we don't care it can be anywhere between 0 to 55. once we have this let's comment this it doesn't affect our original part so we have the blue and now we're looking into the red color let's run this and you can see now that it's only showing the red color circle so it's extracting it's only isolating the red color from the original image similarly there are different other profiles so we had the red color now we can also look into green colors now green color also has its own lower and upper hue which is given by np dot array and this function of green color goes from 46 to 91. now you might ask how am i getting these values how do i know that red color is between 0 to 20 well how is blue color between 65 to 110 similarly how is the upper range of green color between 46 to 91 this is more with trial and error and again opencv also has a function called trackbar now i'll show you what it looks like cv2 trackbar and this track bar it's something which cannot run on a collab but you can also but you can run it on a standalone desktop application so this track bar basically creates this kind of a range track bar and you can change the values of your color the red the green and the blue and you can see what kind of an output you're getting and that output then you can take that and then represent it in your own code so you know what the upper and the lower bound limits are using this trackpad you can always play with it it's something which is not too complicated to work with we will see it in the later future projects if we ever get to use it but uh if in case you're interested in identifying what kind of upper and lower bounds are you can always use a track part to run with it so looking into green color pink color is between 91 and we are again not interested in the saturation and various values we have let's comment the red color now and let's run this just for the green color so you can now see its green color is being displayed very nicely uh now say if i were to display all the three colors or maybe red color and green color together you know the red color starts from zero and ends at 20 and the green color on the other hand starts from 46 and goes to 91. so if i were to say okay instead of 46 let's put zero it should give us both the red and the green color and maybe some other colors also yes you can see it can give out the red color the green and also the colors between both of them you're getting this color also let's let's change this back again to where we were so we have 46 to 91. now let's come back and now try to define try to discuss or identify where the yellow color is now again lower blue lower hue which is given by an np array and this array this is a numpy array and you're defining this numpy array between 21 0 for saturation 0 for variance and you also have an upper u and np array which has 21 to 45 and 0 255 and 255 so you can see it's ending up at 45 and then starting at 46 for green color that's the reason you had both when you tried to represent between 0 to 91 so you were getting yellow color as well okay let's comment this and let's run this and this yellow color is now being extracted or isolated so you can see again if i were to change instead of the 21 if i were to put down zero it would give us the value of all the three colors which is the green the red yellow and the green now why is the green missing because the upper bound is 45 whereas the green color is starting at 46 so if we were to say okay instead of 0 45 let's say 0 to 91 and if we were to display this you can see that it's also giving all the three colors what if we needed the blue color as well again you can play this value you can see that the blue color starts at 65 and ends at 110. so if we were to change the upper bound limit to 1 1 0 and if you just run this it should include all the four colors that we wanted so any any color that you're playing with any color that you're interested in in your own images will lie between that range 0 to 180 so identify whatever color you are interested in and then work accordingly okay let's convert this back again to what we wanted so we needed the yellow color and the yellow color is between 21 and 45. so if we just needed the yellow color let's run this and you can see that it's only giving us the yellow color hello everyone welcome to this face detection intermediate lesson number two under the opencv tutorial series in this tutorial we're going to see how we can do face detection and the first thing you want to do is come here where it says table of contents open part one and just before part one the list is cloning of repository this is basically just copying all the files that we need for this project so we just click on the play and it will download all the files that we need so if you come down to the directory folder you can see there is this folder called opencv tutorial created for us and under that there is a file section so this file section has this hard cascade file if i maximize this a little bit you can see that it's showing her cascade frontal face default xml this is basically a cascade classifier that we are going to use in order to do our face detection coming back to the table of contents going to part two intermediate series lesson number two now under lesson number two here we're going to code our simple face detection application it's a simple 4 5 line code very easy to follow so just stay along with me now the first thing you want to do is import opencv so you can see we can do all the image manipulation for us i'm going to maximize this a little bit and remove this so that's easy for you to see so you have open cv the next thing you want to do is import cv to underscore im show from google so that we can display our images right here in the pod back in this browser you have google collab dot patches import oops cv2 underscore i am show so you have underscore then you have all the libraries that we need the next thing you want to do is you want the library for cascade classifier and that's cascade classifiers who are going to help us in do our face detection so let's initialize that and face cascade is a variable that's going to hold the cascade classifier for us we'll call it as cv2 dot cascade okay face cascade now you are a classifier so opencv has this function called cascade classifier and you just need to specify opencv hey opencv you got the gasket classifier for us but i also need to tell you where my cascade classifier is located but we saw that it was under this file section under the hard cascade frontal face now this is a very big name so you can see it's called our cascade frontal face with a bunch of underscores in between very difficult for me to remember so i will just go ahead and say rename file now press my control c to copy the file name and i'll close this now i do need to specify okay i got cascade classifier frontal face here however we knew that was not just the by itself it was inside this folder called files so i didn't do need to provide the file path name as well which is files so view you have specified that okay the cascade classifier is inside the file section files not just file the file section and under this hard cascade for default dot xml so you can do a lot of mistakes here so just pay attention so you have files and then you're specifying this thing one last thing is you want to specify this as a string because cascade classifier is expecting this as a string you want to specify under quotation marks and that's done with the fair face cascade classifier okay so that's done with the cascade classifier and trust me i think that's the most complex part everything else moving forward is very easy now the next step is to read one of the images that we have now under this directory here under the images folder there is a couple of images and this image with your person.jpg is basically a human face and that's the face that we are going to use to test our face detection today we'll call it as image okay image now opencv you have this function called i am read please read the image for me and the image is inside this images folder and it's called person dot jpg going back showing you images person dot jpeg which is specifying that okay it's an images.person.jpg file and once you have specified the image let's simply display the image so we know everything is working out perfectly so far so let's run this and it's able to display a person's image right here in the browser for us coming back here let's the first step you want to do is convert this colorful image into a grayscale image because this cascade classifier is designed only and only to run on grayscale images so you have to convert that into a grayscale image and how you do grayscale image conversion going back to our table of contents you have changing image color profiles if you click on that this section where we learned the conversion of color this color bgr to gray this is what we are going to use today in order to convert our bgr image to a grayscale image so we'll use that same thing we covered that in the previous lecture going back to face detection let's use our convert color function so we'll call it as a grayscale image gray image and we will use opencv's convert color function to help us convert our colorful image to a grayscale image so you want to specify the image that you are using you also need to specify the type of conversion you're doing so since you're doing pgr to create you are going to let opencv know that it is a color conversion and it's converting from bgr to gray so this right here is what we are going to use and now gray is going to be nothing but a grayscale image so if i change this img and instead of that we display this gray it should be a grayscale image for us so you can see now yes it's a grayscale image displaying for us so very simple now this grayscale image is going to be sent to this face cascade classifier and this guy has been waiting for us to do our face detection so we'll say okay no more waiting you're ready to do our face detection so this face detection is going to be run through this face cascade and this face cascade is now since it's a cascade classifier it has its own functions it has its own builtin functions you see the moment i put the dot it's giving me a couple of options convert detect multiscale detect multiscale 2 3 mt these are all builtin functions that the face cascade classifier can perform for us in our case we are simply going to be using this detect multiscale and this multiscale is nothing but a detection function which can do image detection for us so let me go back close this back again i'll show you a few things so the moment you go into that function this function is going to take the size of the image also the image file name whatever image you want the scale factor basically you're trying to tell how big your image is compared to the original training images the number of neighbors that it can have a couple of other flags minimum size maximum size which are not so much of concern but the image the scale factor and the minimum neighbors are what we are very much interested in go back here now you are specifying the image which is the grayscale image then now you are specifying the scale factor so the hard cascade classifier was trained on a couple of images a group a lot of group of images in the past but it was those images were of certain size certain colors certain shape so the those training images were of a different property and it's very different to what we are using right now so you're just specifying that okay my new image could be of a scale factor of 1.3 well it could be anything else this is just a random number that i chose and it seems to be working but if you notice that this number is not working for your own images just change that a little bit and play around you'll get the right resource next thing is you're specifying the number of neighbors in our case we do have we don't have any other faces in this image it's only one face here but we're specifying okay this could have five because we're going to be using the same code to do some group detection as well so it seems to be five is working out even for a single image but we'll see we have the faces now we use the face casket classifier to detect all the faces that are available in the grayscale image and this faces has information about all the faces so this function is a very important function this variable has information about all the faces and let's draw those faces now we are going to be using another function another system that we learned in the past and this lesson where we saw lesson number four under the basics fold section drawing shapes and text so if you come here we learned how to draw a rectangle a line even putting a text so we'll use one of these functions to do our face detection coming back to the directory oops table of contents coming down to the face detection aspect let's come down here now we will use these faces to draw the information about where the face is so this faces has nothing but the coordinates so if i print this print faces let's comment this it will have information about the coordinates of where the face is but these coordinates are nothing but the pixel values of where the bounding box of the face is so let's come back here now let's we don't need to print this we will now use these coordinates to draw our bonding rectangle but we'll say okay for x y w h so this information in faces so what what is that i'm doing here so this x y w h is nothing but the coordinates that are available inside the faces so the 208 and 73 are nothing but the x and y location of the top left corner of the rectangle and this 161 161 is nothing but the width and the height of the rectangle of the bounding box which houses the face so coming back here we'll say hey cv2 you have this rectangle function which we saw in the previous lecture and this rectangle function is able to take the image the point one and the point two which is the top left corner of the rectangle and the bottom right corner of the rectangle the color the thickness and the line type line time it's not something we're interested in we'll go under the path of thickness so yes so we have cv2 rectangle and you are going to be drawing it on the main colorful image which is the img image instead of the green scale image now you are also going to specify the point 1 which is given by x and y and you're also going to specify the point 2 which is given by x plus w y plus each so you're just going and pointing it out to the bottom left bottom right corner of the rectangle so once you have specified the points you also need to specify the color and we'll say okay let's use green color it will say zero 255 for green and zero for red everything else is green is zero except the green color which is 255 we will also give it a thickness of size 3 pixel level 3 and it should now draw the rectangle on the face for us so let's run this oops we are still displaying the grayscale image instead of the grayscale image now we can display the img image which should hopefully have the face detection for us you can see that it's automatically detecting the face of the person and it's also drawing the green colored rectangle that we wanted in this chapter so it's a very simple chord you can see it's a hardly a few lines the only thing you're doing is you're doing some cascade classifier you're initializing the cascade classifier you're reading an image you're converting it into a grayscale image then you're using the cascade classifier to detect the faces that are available normally if you have multiple faces it will go through all the faces in the face section and then draw the rectangle on all the faces but in this case in this particular image the person.jpg image that we used it it's only of it it has only one person in it and that's the reason you're you don't need to go through all the faces but if you had more faces this function will just loop through all the faces draw all the rectangles and then display the output for us so that's where the phase cascade classifier comes in i also have another image called group.jpg i'll quickly run this for you so let me change this in fact let me copy this and oops let me copy this so i don't mess up your original code in case you're going to be running this and here i'm going to change it to group dot jpg the group.jpg is now a different image which has a couple of people in it instead of just one person but let's see how this function operates it's this one is going to take a little bit more time just because it has too many faces in it and you will see that how what's the kind of output you're going to get here i'm going to skip this a little bit so now we can see that the image has come up here you can see the amount of images amount of people are present here and the face detection that is running through it let me maximize just a little bit you can see the intricacy of the face detection this is a very noisy image it has so many information there's so much of information here but it's still able to detect the faces in this image and this cascade classifier is very lightweight it used to be run in the old camera phones the camcorders the old camera phones which did not have any much computing power unlike the phones that you'd use now this gasket classifier was capable of running face detection in those small low end profile you can see the accuracy the level of accuracy that's able to detect yes there are some misses there are some people who are not being detected and some errors and mistakes here but the most part it is able to give out the right information hello everyone welcome to lesson number three of intermediate opencv tutorial series and here the first thing you want to do is clone this repository by running this command over here it will clone the repository all the images that we need for this project so once everything is done go back and open this table of contents and go under the lesson number three shape detection that is what we are going to work on today so let's import let's start the project by first importing all the libraries that we need we need opencv we need numpy which will import us numpy and b and we also need the collab version for cv to underscore im show we'll use google collab dot patches import cv to underscore im show so this function i am sure is just for displaying the images for us let me increase this a little bit so it's easy for you to see we will also make it full screen so we can clearly see what's going on so we have the shape detection and we are just specifying all these libraries right here the first thing is let's read the image and the image is inside this folder opencv images and shapes.png so this is the image that we are interested in today and we'll do that by reading this image for us so we'll say opencv please read an image and save it into this variable called img and you want to use opencv's i am read function and this function just needs the name of the file the file name and the file path wherever it is located so it's located inside the images folder in the directory and we call it as shapes.png so this will just read the image for us we can always test the image whether or not it read the right image by using the cv2 im show function and we just run this and we see there is an error right here so it looks like we missed something uh google collab patches from so we need to import from google collab patches import cv to underscore image no worries we fixed it now we can just simply rerun this and we can see that it's able to read the image and it's displaying it here for us so good now the first thing you want to do is since we're doing shape detection we wanted to discuss and identify what kind of shape it is so we know i mean from a human eye that is this one is a circle this is a hexagon this one right here is a square this is right here a triangle so we from a human perspective we know what these images are but if you were going to give this control to a computer program how would the computer read through all these colors and identify these images so of course we need some sort of algorithms in order to do this and we'll see how we can do that so we'll try to read these shapes and images through opencv or image processing perspective so the first thing you want to do is convert this into a grayscale image and we'll use opencv function convert color so convert color cbt color this is just going to convert the color from whatever color we want to whatever color profile we want so you need to specify the image that you want to convert this to so img is the original image and we also need to specify what kind of conversion you are doing so we are going to convert from color to grayscale so we are going to use cvt color bgr to gray you have bgr to gray and this color profile is just going to convert the colorful image into a grayscale image we can always use the cv to im show function to see what kind of an output we get and you can see that it's already converted all the colors into a grayscale profile it does have the shape and the boundaries of the image but it's all grayscale okay so we have the grayscale image now now the next thing we want to do is understand some of these functions some of these images some of these values in a more clearer way and for that purpose we'll use open series thresholding function this thresholding function is responsible for converting anything that you are interested in anything that your your profile is interested in into white and then the rest into black in color so this is basically a filter and you can say hey okay okay open cv anything which is light like this hexagon the circle the square the triangle these are all lighter colors compared to the background which is black so anything which is light please make that into white in color and everything else black so i'm not interested in them i'm only interested in the white in color profile for that purpose we use opencv thresholding function and we'll call hey threshold used this opencv function called threshold this threshold function is a builtin function from opencv which can take the source and threshold value and the filters and then convert that into a black and white image so it basically filters the image to the values that you are interested in so you specify the image which is our grayscale image now you want to specify the threshold values so we'll say okay anything which is between 50 to 255 because we know white color is 255 so anything which is 255 and 50 is the lower end and we'll see 50 should be okay in our case and we are also specifying the type which is not too much of an initial we just specified one and we take care of this now let's see if we can display this image here for us so cv2 i am sure thresh let's see how this kind of an image looks like and you can see that it's already converted everything into black and white and yes it's everything that we are interested in it's all converted into one color and the background is in another different color so this threshold function has already used a filter and everything that we're interested in it has specified them into one color and the background into another color so that's the purpose of this shoulder so it's converting that into two different values and now we can use that to our advantage so now we have all the functions that we are interested in we have all the images that we're interested in now let's start reading these different values from an opencv perspective so opencv has a good function called as find contours so this find contours function is a type of function that's able to go through all these images and go through this right here you can see the circle and it will find all the contour the outer contour which differentiates these two colors the black color and the white color these are differentiated by this circle right here and it will find that contour which is differentiating these two colors so these two color pixel values that are being changed or being differentiated it will identify the border of these pixels so we'll use this function called contours and these are just the h and this thing is nothing but just specifying the history and the flag values so we're not interested in that we're just interested in the contours and the threshold so cd2 find contours and contours is given by contours so you're just specifying the different types of contours that we are looking into and we are specifying okay the contour should be taken out from the threshold image and you're also going to specify what kind of contours you're interested in and this is of course a binary image since we can we use the threshold function and we are now you're going to use different types of filter and pixel values you're saying okay it's going to be between one and two and uh right now you don't need to understand you know these two values it's it's as long as you're putting one into it will work fine you don't need to worry about why or not so let's go into understanding what these contours are so these contours are just specifying all these outer boundary of the pixel value of the shapes when we have the contours detected these contours are specifying information about the circle this hexagon the square and the triangle so it has information it has the contours for all these shapes that we see here and we will just loop through all these contours and go through the contours that we are interested in so we'll say okay for ponds which are contours or the contours or for a counter or inside these contours for a counter which is so we're just looping through all the contours one by one by using the for loop and you want to identify what kind of what are the points that are specifying the contours so these these are the points in case of a circle there are too many points since it's a circular image but in case of a hexagon you can see that there are six points that you need in order to define a hexagon so this we use a function called as approximate poly dp which is able to identify the number of coordinates or the number of points that you need in order to define your contour so whatever shape you're working with whatever it could be how many points do you need in order to identify or in order to draw your shape so we have this function called as approximate quality b which can give us an approximation of how many points we need in order to define our image or shape so we have this function's name is aprox poly dp and this dp this dp is defined the dp is actually the name of the person who invented this algorithm and uh his first name starts with a d and his last name starts with a p i believe is daniel pickard if i'm not mistaken uh my might maybe i'll put it in the i'll put some text here to identify what's the right name of the person but uh this approximate poly is able to give out the nerd minim on the number of points that you need in order to identify your contour so this approximate poly just needs the information about the contour that we are working with and it also needs some sort of an epsilon value this epsilon value is nothing but the error or the amount of error oh you know what they have the name here it's douglas pecker the douglas specker is the name of the person who invented this algorithm and that's why it's called aprox polytp so this function takes this information called as an epsilon this epsilon is nothing but the approximation value or it could you could take it as an amount of error that you're you're okay with when you're identifying this function so uh it's one of the best ways of identifying or one of the best ways to denote the function or the epsilon value is by using the arc length and the arc length if you multiply it by 0.01 whatever value you get it will be more or less acceptable for our error purposes so as for now just understand we're just converting this we're just specifying the amount of error that we are okay with and we say okay arc length and we see we tell the counter name and true so let me encode this on this side so you can see what's happening so we specified the contour this we are specifying the epsilon value which is given by this and we're just giving by the arc length of that contour and based on that now we need to just specify okay maybe it's just going to be whether it's a closed curve or an open curve in our case all the curves are closed so we'll just say true for close or closed so we are now specifying all the approximate value and this approximate will be able to read all these contour values and give us the value of the each and every shape so let's print this so we'll see what what is happening here so we'll run this and you can see that it's able to go through all of these and it's giving us the points for each and every contour so now let's see okay we have the up approximate which is giving us the coordinates of the shape of the points and let's uh and these are you can see it's form of an array it's an array which is going through all of these points and giving us so if we go through the length of the array instead of printing the whole array if you just print the length of your array you can see that's giving 4 6 3 16 4. and i wonder what that is so let's go back and print this image or read this image for us cv to underscore im show and threshold and just rerun this again so you can see that this is a shape and it's giving us four points which probably represents a square and it's giving us six points which is probably representing the hexagon here then three points for the triangle and 16 points for the circle because circle is you need too many points in order to define the circle and the last is again four points and these four points is nothing but the outer image the whole bigger the bigger boundary of the image which it's not visible here since we the background of the code and this thing is all inviting color but that's the outer boundary so it's given by four here so good now you are able to differentiate and you're going to identify okay approximate is able to give us the length of the coordinates not only the length of the quadrant also specify the coordinates of the points that can define your shape so you have approximation and now you're going to say okay if the length of approximations or we can say okay number of points n is equal to length of approximate so if if n is equal to 4 then this is a square so you are reading a square so once you have the square written you can draw the contour across the square and you have this function called as cv2 draw contours and this contours function can draw a contour of whatever size or whatever shape you want based on the values that you are interested in so draw contours using the for you know on the image called img and we have since we had this image right here the original image img we will draw the contour on this image we'll say img please draw the contour using the contours that we have with inside the cnp function inside this in the variable and once we have this specify what where or whatever the size or shape of the contour is so we'll say zero the contour index and the color which is 255 for our case and then the thickness where we're just specifying what kind of contour image or what kind of a thickness it is but we'll say okay for now we're only detecting the square and drawing the contour across the square and then displaying the image for us so we'll say cv2 underscore i am sure img okay we don't need the i am show threshold function we're just interested in the img function and let's run this so you can see that it's now fully black in color and the reason for that purpose is we are not able to read the image we have already converted that into a image here for us and we are also drawing the image with the minus one and this minus one has basically drawn uh it's it's uh filled the whole image with the color that we were interested in and the image the square was the big rectangle the big boundary box of the image and for that purpose it has colored everything into that a black black color or blue color value now if we were to say instead of minus one let's say five let's see what kind of an output we get you can see there's a boundary right here which is almost blue in color and it's specifying that it's a thickness of about five if i were to put 50 maybe let's run this you can see there's a bigger boundary which is much more visible and it's all there's also a boundary right across this right this square box here and you can see that it has a boundary of about blue color right across the square which is green in color and also across the big square of the image now you have the square if we were to say okay instead of the four instead of the square i'm interested in the boundary of the hexagon let's run this and you can see that it's drawn a boundary across the hexagon so we are using the approximate function using the length of the approximate you can identify whether it's a hexagon or a square or whatever it is since we put n is equal to six we'll say it's a hexagon and we'll reduce the thickness of this say to maybe 10 and we'll rerun this and it's able to draw our contour across the hexagon and it can also write down that yes print this is a hexagon so this function can now tell us that this is a hexagon now once we have this i will say we have a hexagon here so we have a hexagon here now it's able to decide tell us that this is a hexagon okay good now let's go through all of these so if lf n is equal to we had the triangle which is given by three variables you say okay this is a triangle and we can print triangle okay we found a triangle and we can also draw the triangle by using the contours function and on the same image with the contoured value that we found and here in this case we will use a different color we'll say okay maybe you can specify the contour index and we will use a different color so 0 comma 255 2 0 so it'll be a green color contour for a triangle and is there a triangle blue in color yes so we can use a green color rectangle triangle and we'll give a thickness of about maybe three size and let's run this and see if we can see a green color boundary across the triangle so yes there is a boundary of green color right across the triangle which is very good now once you have the image now you're specifying okay so lf if n is anything greater than or n is equal to or nine so that's basically your circle so this is a circle and print we found a circle cv2 dot draw contours circle on the img image function using the contours that we are interested in and then you just specifying the index we'll put it as zero no nothing nobody's on that and then the color profiles in this case we will maybe use 255 255 i think this is a pink color let's see what kind of an output we get and let's run this you can see oh it's giving us a yellow color circle boundary right across the circle so you have everything just the square is left so square we will say okay lf n is equal to four which is given by square this is a wire say print e okay good we are also going to draw the function contours img c and d c and d and you specify the index now you're also specifying the color we want we say 255 comma 255 comma 0 and a thickness of 3 size let's run this and it's giving the sums of an error because we missed the bracket here instead we put it to here so it should be fine now and yes you can see there is a boundary right here and there is a boundary over here as well so you are specified you are able to differentiate all these colors and it is able to differentiate and see what kind of a shape it is and you can identify what kind of shapes that we are working with in this particular image so the if we do a quick recap on this we did a quite a bit of things in this lesson we looked into the thresholding value so where we can threshold we can filter the image of a grayscale image into whatever color profiles that you are interested in and you can also use the find contours function which can go through the image and find all the different types of contours that are representing the shapes in the image and then using the approximate poly dp you are able to identify the points the approximate points that you need in order to identify in order to draw your contour once again and once you have the contours then you go through all of the length of the approximation and based on the length of the approximation you're identifying what kind of a contour with is it if it's a six you know if it's a six coordinate contour it's a hexagon if it's a three coordinate contour then it's a triangle similarly you can identify it with a circle or square so this is basically helping us to identify the different types of shapes from an opencv from an image processing perspective hello everyone welcome to this part three of the opencv tutorial series here we are going to try and attempt to do a project this is about tracking a ball you can see this video in front of you the ball is moving around and the idea is to track the movement of the ball at any point from a human perspective we know where the ball is moving it's moving right left right in random fashion but how would you do that from a computer vision perspective how would you make a computer understand where the ball is moving so let's get into that so the first thing you want to do is of course import opencv let me make this a little bit big maximized is everything so it's very easy for you to read okay we have import cv2 import numpy as nd and from google collab patches import cv to underscore the intel before we do all this let's go ahead and clone the repository if you go into the table of contents and open cv six the first step just above the part one is where the github repository is and we do want to clone this repository this will allow us to access some of the project files that we are going to be using in this particular project so you have the opencv tutorial folder and inside this you will see this videos folder and in this videos folder there's a video file called video.mp4 and this is what the file or the ball tracking file is that we'll be using okay let's come back to the table of contents let's go into a project which is the tracking above let's continue our coding so right now we have just imported the libraries that we need the next thing is let's open the video file that we just saw so we can call opencv has this function called video capture which is basically able to read a video file for us so we'll create a capture variable called cap equal to cv2 video capture and this video capture is able to read a video file or even a webcam for that matter if you wanted to read a webcam of course you can't do this on a collab you can do this on your own desktop computer and if you just put down zero it will start reading the default webcam that's connected to your computer but instead of that let's read a video file that we have here in this call app so we have it another folder called videos slash video.mp4 so coming back again just to make sure we are under the opencv tutorial folder and inside that there is this videos folder slash video.mp4 that's the file that we are going to read through our capture variable this capture variable is capable of reading through every frame of the video file for us and the way we do that is by reading hey capture give me a frame from your video file and cap has this function called read this read function is able to read through the video files and then give out the frame that we want but now a video file is consist of multiple frames it has millions of frames hundreds thousands many frames that are stacked on top of each other then when they play in a sequential format it looks like a video so if we just read it once it'll just give you the first frame if you read again frame equal to cap dot read it will read the second frame similarly if you read it again it'll read the third frame so you have to keep going and throwing and reading through all the video frames that's a very cumbersome format and you really don't know how many frames there are so instead of reading them individually we will read them through a vial and we will open up a while loop will you say hey while loop please start reading the video file for us but you want me to you want to read the video files only and until the videos start or spitting the frame files so it should read only until the videos have enough frames to read and once the video comes to the end of it file you should stop reading otherwise you'll be running in an infinite loop so we'll say file cap is open and this flag is capable of reading whether or not there is something reading through the video file or not and then now we will read the frame we'll say frame equal to cap dot read so it will read through all the frames of this particular read function it will go through all the frames that are available in the video file and then give it in our frame folder now opencv also allows us to do some debugging it allows us to make sure what we read is good or not so it has a flag and we'll call this the red fact flag and this flag is capable of letting us know whether or not there was a frame read or not so if there was a good frame and if a real frame came out of this video file then this red will be equal to true otherwise it will be false stating that no there was no frame red so you don't need to take care of anything the frame is nothing so this red flag helps us also keep a checkpoint stating that a if is there a frame or not and if there is a frame continue with the next of next process of the project but if there is no frame then don't bother so we'll keep a if statement will say if red is false don't bother don't bother the while loop don't bother continuing with the project just break out of it and this is a condition that we will create just reading the red flag this flag is able it's whether or not there was a success or not of whether a frame is red or not that's all we're doing here and this frame is now going to be read through all the frames of the video file and subsequently sequentially it will have all the frames one by one now let's see what we what we should be doing with this frame file this frame file we are interested in identifying the color of the object and we are identifying it we are also interested in identifying where the object is in the video so we lit in the previous projects in the previous lessons we looked into color detection in this color detection we saw how we could detect particular colors like you had the yellow color the green color the red color now we know our ball in this particular video is of yellow color so we can maybe use this particular chord we can create a mask we can do some bit wise and and find the position or where the yellow color is located that's a cool cool thing to look into now coming back we'll use that same system for our current project and we will do some yellow color detection and for that purpose what do we need to do first thing we have to do is convert the color into a hsv image again the reason i'm going through this is because we have already covered this in the previous lessons and if you need you can always go back to the color detection color changing profiles and you will understand what we are doing here so we are now converting it into a hsp image and we use cv2 color bgr2hs you bring it here so you can see that it's now converted into a hsv image from a rgb or a bgr image in opencv format to hsv image this hsv is now able to help us detect the yellow color specifically and we saw there was a lower bound and upper bound of u and we will use that here so let's go back to this code and you have the color detection and it's easy to copy and paste the colors that we saw here we have the lower hue and the upper hue and we'll copy this i'll press the ctrl c button and coming back to where we were oops the table of contents we want to go into the project folder and here we will paste what we need here this needs to be a little bit indented so here lower hue is representing the lower bound of the yellow color and the upper hue is representing the upper bound of the yellow color the next step we want to do is create the mask and the mask would be given by using the cv2 in range function so in range is going to look into the image and wherever the hue value lies between these two ranges and the hue saturation and various values lies between this range it will give out all those pixels in a different color so it will highlight those pixels for us particularly so we'll say okay cv2 in range function do your in range magic on my hsv image using the lower heel and the upper hue range that i have created for you so good job you have created the mask you've now identified the yellow color specifically in the video good now what is the next step next step is to identify where this yellow color is residing and for that purpose we used a function called find contours and we did fine contours just in the previous function if we go right here in the previous function where we did draw contours draw contours fine contours so this this is the previous lesson that we covered where we were doing shape detection when we were using fine contours to identify the different shapes that are available different colors and then also draw those contours and we will use some of these functions in our project as well so coming down coming back to the table of contents project coming back to this place so we have the mask and we have now going to create all our contours so the contours function we will create okay contours and on whatever x the contours function is able to give us we're not interested we are only interested in the contours that find contours function is going to help us find so there is a function called cv2 find contours contours function is now going to help us in identifying the different contours that are available in the image and this function needs the mask that we just created it also needs some sort of functions that are inter that are going to specify what kind of a contour detection it's going to do so in this case we are going to be using the pre function and we call it as the cvt retr tree this is just understanding these are different types of contour detections and we're just using a specific type for our project it doesn't matter it's it's a simple contour detection that we're doing here and it's not going to affect what type of contour detection you use and this the approximate approx simple so these are different types of filters that are used a different algorithm altogether and we will be just using that to detect our contours once we have the contours detected well good the next thing we want to do is then try to identify these contours are so we'll say okay for now i don't know where the contour is so i'll say that contour has a center point which i don't know and for now i'll put it as just none now if my frame has contours so if my length of contours is greater than zero which means that i have contours in this otherwise it will be zero so if my contours is greater than zero yes let's go about and identify where my contours are located and for that purpose we will first identify which is the maximum the biggest contour in my image and for that purpose we'll say hey c which is the maximum contour use the max function of python to detect which is the biggest contour of all the contours and you can use the key function when for how do you identify which contours are big the biggest you are going to use the cv contour area function the cv2 contour area is able to give a give you out the different types of contours and their areas and it will give out the maximum size of the contour and you can store that under this variable called c once you know which is the biggest contour good now let's find out where this contour is located so we in initially we detected that it's the center of none but now let's try to identify where exactly what is your coordinate so now we can use a tuple called x comma y which is going to be the center coordinate and the radius and opencv has this function called minimum enclosing circle and this minimum enclosing circle can take a contour whatever contour you give and in our case we're going to keep this contour called c and it's going to take that contour and identify what would be that circle what would be that minimum circle that can enclose the whole contour and what the circle is defined is by defined by the center point and the radius that is the circle which will be enclosing this conduit that we have here so now you know where the center is you know where the radius is so very good now we also i want to identify where exactly the moment file is so we have the moments which can be given as m equal to cv to moments so this is another way where you can identify the center of the quad in the contour by using moments moments is nothing but uh specifying where the center of the mass is where the centroid or where the main center of the contour is located and for that purpose we'll use a try function because it's prone to errors and we will say hey try to find the center and i'll say center is equal to there is this formula and it's going to be it's going to sound a little bit confusing here but stick with me what you're just basically identifying is the moments of different types of contours of different location of the different coordinates of the contour and based on that it can identify where the center or where the centroid of that contour is located and that formula is given by int moment and this is an array which is given by 1 0 which is nothing but the corner one corner and then you are also dividing this by moment which is given by m 0 0 so these are two moments which we are just defining and that's the x coordinate similarly the y coordinate is given by in moment and specifying which moment is this the next coordinate and then you're also dividing this by the base which is given by m and you have m 0 0. you're just defining where the center of the coordinate is but once you have the center now you can also identify where to draw these centers so we can draw the center cv2 circle good and your frame you're going to draw on the frame the original frame that we had and we're going to draw using the center of the image good so we have the center and we're going to say okay the radius of this circle is going to be say 10 and we are going to give a color of maybe blue color 255 0 0. and we're going to fill this for the thickness thickness is going to be minus 1 which is nothing but specifying that the whole car the whole circle should be filled with this color okay good so now we have drawn the circle now this circle this center is specifying one location one point of the ball now we are interested in identifying all the different types of contours that can be available so uh we want to store the center of this ball at every instance so for that purpose let's define an array an open array will say ball is equal to an open array right now we don't know what this ball is going to have but this ball is supposed to have all the coordinates of the center of the ball at any instant of the video so this ball array is going to host or have the center coordinates of the ball wherever or whenever it is moving in the video so we'll say ball dot append append is just adding to the array append the center which is the coordinate of that ball so you just right now storing storing the location of the center into the ball array so good and if there is an exception go ahead and pass we don't want to bother about it now we have the center of the coordinate we drew the circle at that instance and we are also appending the center which is very good now let's use this ball array to draw the track or the movement of the ball so for that purpose we'll say if the length of ball is greater than 2 because the reason i'm saying greater than 2 is because you want to draw a trap a track is nothing but a line and the line can be defined only by two points a minimum of two points so in order to draw a line you need to have at least two points and for that purpose i'm saying i'm asking hey ball are you length of 2 or greater if you're 2 or greater let's go ahead and draw so i'm just going to draw this now for i in range of i in range 1 to length of ball so i'm just going to loop through all the elements all the center coordinates of the ball right from zero to the length of the ball and we're going to say let me put the colon here and we'll say draw the line or the track that i'm interested in on the frame using ball's initial coordinate which is the minus one which will be the zeroth or the index zero and the next point which is the ball ball i between these two coordinates between these two center points go ahead and draw the line that i need and give me a color of red i will say zero zero 255 and a thickness of say five okay so now you're able to draw a line perfect now this is where we are able to show that yes our opencv project is able to draw not just detect where the circulars but at the all at the same time also draw the line showing where the ball has moved so very good now how do we take this information how do we show it to the end user that we were able to do this since it's a video file if you start displaying it here on cola it'll be a big mess instead of that we will not only we will read this video file but we'll also save it as a video file and opencv allows us to create videos so using a video writer function so we'll call it call a variable like we call the variable capture to read videos we'll call a variable called output or out and we'll say opencv use your video writer function to write a video file for me and for that purpose you're going to create an output avi file and this output api file is going to have the type of the video that we are interested in you're going to store all the new frames that you just created into that so we'll say okay very good i'm going to create this output.avi file but what kind of a video file do you need different types of video files there's the there's different types of compression of video files i should say so there are there is the mg mjpg which is nothing but moving jpeg moving jpg images so we'll use that and there are different other types of compressions and we will use mjp g which is moving jpeg we're going to say cv2 video writer and this 4cc oops for 4 cc this 4cc is nothing but the video codec that we are interested in and in our case we'll say m j b g oops capital g so we have mjpg which is the type of video coded that we are interested in we are also going to specify the number of frames per second in our case it will be 10 and we also need to specify the size of the video and the original video that i had created the video.mp4 that we used that was at a resolution of 1920 by 1080 so this create the same video file same size you can use whatever size you want but just so because i'm doing a screen recording if i do something lower it might come out very bad on the screen so i'm saving it as a 1920 by 1080. now this output file oops it's jumping out okay so this output file is able to write whatever frame that you are interested in in this output.avi folder or avi file video file so we have this output function like we use the capture function and we use capture.read to read through all the frames similarly this output function is capable of writing the frames so we can say out dot write frame and this out dot right will just simply write the frame that newly created here into the output.avi file and it will loop through all the frames until this while loop is finished until the red flag saves no more frames available you went through all the frames so you're done now until it does that it will go through and write all the output frames for us and once everything is done it will go ahead and you can release the output file i think this should be indented a little bit on the left side because you're doing it in the if length contour side if you want to do this once it's out of the if statement at the final end of the while loop once you've done all the manipulations that you want to do on the frame and then just simply write the file onto the output.avi good now let's go ahead and run this let's see if we come across any errors and it's taking a few seconds it's running through all the frames for us okay so it seems to have run and we can now open this file and we can see under the videos not only the videos under the output main or opencv tutorial folder you have the output.avi and i can simply click here and press download and it will give you this output for us hello everyone welcome to project number two of our opencv tutorial series here we are going to try to attempt face recognition so for that purpose the first thing you want to do is going to run time and this is the link which will already be there in the description for you just go ahead and click on change run time and you want to make sure you are under gpu and then just save because for this purpose we would be using open the gpu cloud from the collab and i'm going to maximize this a little bit so in order for you to go into the project too if you're going to the contents page and you have projects right here on the part 3 section and we are under paste recognition part so once we are in this section we want to run this particular code here we are basically cloning the repository the face recognition repository and we have some images and some files that we are going to be using for this particular project we are also going to be installing the face recognition api and this was i believe designed by adam gateke that's the name of the person if you just google face recognition i'm just going to google and we'll do adam base recognition so this is considered to be one of the one of the easiest one of the fastest and one of the most accurate face recognition libraries out there and it was developed by this gentleman and we are going to be using it in our project right now so coming down here uh once we run this thing it will go ahead and clone the repository it will also install the face recognition library for us and we are also asking collab to change the directory to face recognition that we can access the files directly so it'll take a few seconds and here in this section now you can see there is a face recognition folder and right here in this section you can see all these files are now available for us to test so this project is basically divided into three steps one is cloning the repository installing all the dependencies that you need for this project the second is encoding finding the encoding profile of the face images the third is using those encoding profiles to now detect unknown faces so we'll go into the basics of each of them and try to understand what it is so basically a face has its own properties a human face the way a person looks is defined by their eyes the shape of the eyes the distance between the eyes the nose the size of the lips the play of placement of the ears compared to the rest of the face so these are all features that define a person's face and encoding is just using those features in order to create a profile for a person and those encoding details are specific to that person so it's not going to be common it's not something which can be replaced with another person's encoding a person's encoding profile is his own his or her own encoding profile and we are going to be using that for our project today so the first thing you want to do is import face recognition library that we installed up there we are also going to be using numpy today numpy as nb and before we go into further details let me maximize this a little bit also move this guy up so it's much more readable for us a little bit more i think okay perfect so import numpy as np we are also be queuing could be using google collapse cv to underscore im sure so that we can display the images here in the collab and for that purpose we will be using google collab patches and from there import cv to underscore im show we might also use of course opencv so don't forget about opencv that's the bread and butter of this project so once we have opencv and all these libraries imported for us we will now go ahead and create the encoding profiles for each face images so if you go into the project folder under the face recognition you can see there are some images like the donald trump image elon musk image earthworld jeff bezos and these are all images of people who we already know and these other set of images right here unknown unknown unknown unknown these are all images that the computer or the program does not know and we will be using these images to use for face recognition in the next step so now for now we will use donald trump's image and elon musk image and jeff bezos image to create the encoding profile so the first step is creating the encoding profiles and for that purpose let's create the encoding profile for face one face number one and let's call this maybe elon musk's face number one and we will call the facebook ignition library up there hey face recognition library please come to our help and we want you to imme load this image file of elon musk i have elon musk in my project folder and it's called elon it does let me come back here it's called elon dot jpeg and you just use elon jpeg to load the image file for us and good good job okay so once face recognition has loaded the image file now we will also request our face recognition library to create the encoding profile for us we will say phase one your encodings are given by face recognition please face recognition library come back again and we need your help this time to create space encodings and codings and for that purpose we will call phase one use the encoding profile from face one and once we have face one you're gonna call okay only use the add a zeroth element of the face one that's now created the encoding profiles of phase one encodings perfect similarly let's create the face encoding profiles for the other gentlemen and for that purpose we'll just copy the code from here and paste it here do another paste here now this one we will call phase two okay paste three base three we will change this to phase two it will change to phase three and instead of elon we might say donald trump and that's the file name donald trump the next is jeff bezos given by this spelling so come back here and instead of this we'll call jeff bezos dot jpg so it has now created the encoding profiles for all the three images let's bring them in an array so that the program can later call them individually so we'll we'll say i will create an array called known face encodings so these are the encodings that the program already knows and we will call them inside an array okay so under this profile we'll call face one encoding comma phase 2 encoding comma face 3 encoding good so this is my known face encodings now i will also give these encodings names in the same order so we'll say known face names and these are the names of our people who we are training them oops okay come down here so we'll say the first guy is elon musk the second person is donald trump and the third person is jeff pesos okay so we have all the three images we have created the encoding profiles and now we have all the image names also inside an array so whenever this encoding one is called it will refer to elon musk whenever encoding two is called it will refer to donald trump similarly for check pesos so in this section we only created the encoding profiles now coming down to the next section this is creating the run face recognition so we are now going to use those encoding profiles to create and start running the face recognition aspect so let's call let's use one of the unknown images that we have we will probably use unknown el and el is basically the abbreviation for elon musk do is donald trump er is earth rule from here and je is jeff bezos i don't know why i left it as je and you might also notice a spelling mistake here just be mindful of this particular image it's already already an error so i'll try to remove it in the repository later on but for now for the purpose of this video we'll roll with it now the first file name we will call okay let's read the first file and we'll call the elon musk's image which is to one here unknown el dot jpeg and we'll call unknown el camino we're gonna test you and to see your who you are and whose name you carry so you have file name and we'll say this unknown image is right here for us oh it looks like colab doesn't like us to use gpu runtime it's giving us an error but don't worry because very soon we are going to be using your gpu collab and at that point point they won't be so angry with us but let's come down so we are now reading this unknown image of elon musk and we will use face recognition dot load image the same thing that we did here in fact we might copy this whole section from here and we will just load this image that we grow this function we have here so we'll say load image file and we'll use the file name that we created up here perfect now we have unknown image to draw recording calls this image as something that we are going to be using to write down in fact we don't need to draw this image let's call the encoding profile for this guy so we'll say okay where are your face locations and where are your face encodings so you have your face locations which are given by face recognition dot face locations using the unknown image that we have up here now we are also going to be creating the encodings and we'll use the encoding function face encoding so this new image that we just uploaded is going to have face recognitions encoding and face recognition face encoding unknown image and face locations okay so we have now created the encoding for this unknown image very good so let's now try to compare this face encodings with the encodings that we already have here for that purpose we will now use a for loop for and we'll first zip the face locations and the face encodings so we'll do zip face locations and face encodings the reason for that is because we want to compare both of them together so we have face encoding and these face locations and face encodings can be compared to two different formats also so we'll say face locations will give us the top the right so these are the top right bottom and left corners of the face so you have bottom and left so this is referring to the face locations which we will get it from this zip file and we also have the face encoding for individual you have the face encoding and the face locations including this for the individual phases and this is just the array called face encoding so you're reading through each one of them looping through the for loop once you have that now we will try to create a match and we try to compare our face encoding from here to the face encodings that we already know from here so let's go ahead do that for us we'll say matches and matches is equal to the comparison between the face encoding of this new image versus the face encoding of the images that we know already come here face recognition dot com here and this is space function so it's going to compare the faces from our known face encodings and the face encoding that we have here perfect now initially we will call our face your unknown phase as unknown unknown i don't know initially we call it as unknown because later on once the program is able to identify or recognize whose face it is it should automatically replace this name with one of the names that we have here okay coming back now we are trying to compare the distances from the comparison that we created here and say face distances which is equal to face recognition dot phase distance known space encoding comma phase encoding now here we're just creating again that distance and then now we'll drive using this distance we will try to now identify which one is the best for ourselves coming down here we'll say the best match index now this is the index of these three images so this is zero one two so you're just identifying which index items we will say it is given by the numpy of minimum distance between the face distances so all the phase differences but it's identifying all the phase differences and now it will give us the least face distance we'll say okay the least face distance from the face distances array will be my best match index okay perfect now if matches best match index is available give me the name of our known face names so we'll call you just call this known face names and we'll say the best match index is your new name so this is basically the space recognition aspect so you're first identifying the phase distances and from the phase distances you will come to know which is the minimum which is the least distance between the original phase and the unknown phase that distance will be considered as our will come to know our index and we will use the matches that we use here to then call that particular face name and we'll use our known face names array to iron to get the name of the real person once we have the name of the person now we can go ahead and draw the bounding box on the face and also put the text so we as the user can identify who this is so you we will use opencv's draw functions which is the rectangle and the put text function to put down the text in the bonding box on our image we'll say cv2 rectangle unknown and you're drawing it on the unknown face here the unknown image in fact let's read the unknown image that we have here we're reading it through the file name we will also read it through opencv we'll say unknown image to draw and this function that we will use cv2 file name here we are reading it in the opencv format so opencv we can use this image to draw our rectangle open cv here come here put it down here once we have the opencv image you can draw the rectangles and the rectangles are defined by the bottom left or the top right corner so we say left top right bottom perfect so now you're defining the color you'll say green color 0 to 55 0 and a thickness of 3 it will take care of the drawing of the rectangle for us similarly we'll now draw the write the text of the person that we know we'll use the unknown image to draw here and we'll write the name whatever name that we want to put by using this name string we'll say name and we will say let's write it on the top left corner of the rectangle which is given by left top but we will give it a little bit of indent on the top so we'll say minus 20 it's just above the top left corner of the image and opencv has certain fonts that we can use so we'll use the basic font which is the font hershey simplex one zero color we'll give it as maybe red color and we will use the thickness of two and the line format of double a cv2 line underscore this will just simply write the text for us once everything is done once the for loop is also completed we will ask our collab to please go ahead and display this unknown image to draw that we just created here so once we have this thing opencv should go ahead and run this so we'll go ahead and run this and it looks like there is an error here the error says invalid syntax and it is probably because we did not say where are we getting this from so we should say face encoding top right bottom in z we have to say in zip and that should take care of our error looks like there is still an error and they are not happy because we put down too many rectangles at most six arguments and it looks like we gave them eight arguments how come do we have the unknown image oh did we say rectangle instead of rectangle we should have put put text because we're putting up a text here and that should take care of our thing so we can now see that it is able to detect the person and it's also able to put the bounding box on it and if you go ahead and open this folder and open the unknown el folder here you can see the original image is right here and this is the face recognition image so let's try some other image we have a couple of other options we'll open the unknown which is basically donald trump's image and we'll see if the file is able to detect it for us we will say unknown do here so it can read this new image and it's able to draw the bounding box on donald trump's face this is able to do the face recognition aspect and you can see it's pretty fast it's able to do it almost in real time now this is something which is done in collab now if you want to do the same thing on a desktop or through a webcam the same thing can be applied where we are reading a file name instead of that you will be supplying it through a webcam and you can use a file a while loop a true while loop which would continuously loop through all the images of the webcam and then pass this as a function this whole code right here can be made as a function we will say okay def and you can say function some function and you can pass the image that we want and instead of this image we'll say file name so we can then replace this file name with here just uncomment this instead of taking it from here we just call this as a function you bring everything in this as part of it as part of this particular desk function so we'll say okay you're part of this dev function and once we have it here we can now instead of show displaying it here on the browser for ourselves we can then return this variable and that will go to go back to the desktop where who's that while loop who's calling the images to return go back and undo our changes because that is something which we cannot do here in cola but just an idea if in case you are interested