this deep learning course is designed to take you from beginner to proficient in deep learning IU sing created this course he's an experienced data scientist and popular course creator aush will teach you the fundamental concepts architectures and applications of deep learning in a clear and practical way so get ready to build train and deploy models that can tackle real world problems across various Industries what if I tell you that there's a deep learning course that teaches you deep learning from very scratch to a core level so what I really mean by scratch is teaching you the core and the Crux of the mathematics which is required for deep learning like linear algebra single variable calculus and much more and not only this we give you detailed lecture notes along with the Practical assignments on data Wars for absolutely free so that you can follow through this course and become the master hi this is aayush I'm cofounder of second brain laps and in past worked as a lead data scientist at triplate a UK based esteemed organizations working on large scale career economy product as well as I've worked as an emops engineer in a core ziml team in order to streamline mlops Frameworks and furthermore I worked in several usbased companies as a contractual roles as a data scientist and not only this I love teaching my courses has got millions and millions of views throughout the internet and I've helped several thousands of students in order to get their first paycheck or their first job and but why you should consider learning deep learning and what is the core problem which is coming into the deep learning content throughout the internet now it is all of the companies are asking for a deep learning skill set into a particular candidate and to be honest people think deep learning extremely hard and pretty hard to understand and it's my personal opinion I feel that because of the instructors on YouTube it's becoming a little bit hard to understand it's not because it is very complex I agree that the whatever things are little bit difficult or hard to interpret it but if taught in the right way deep learning is the most I think easiest subject as compared to even core machine learning I will teach you deep learning in a very core way from very scratch we will mathematically do every iteration by our mathematics so that you understand okay this is how the flow is going and this is how each steps is helping your model to learn or become better let's get started with our course hey everyone welcome to this first lecture on linear algebra so today we are going to talk about uh vectors and we'll be exploring vectors A bit okay so uh first we'll start off with what is linear algebra why do we even bother to study this as some of you all already are familiar with algebra you you just want to uh just re refresh your memory of your algebra or you wanted to uh you're from very scratch and then s so that's why let's let's start with the definition of linear algebra so I've written one definition of linear algebra is it's the mathematics of the data yeah you heard me correct I saw this definition online and I found this a very basic definition to tell you uh rather than taking too much of uh mathematical terms is algebra L linear algebra is the mathematics of data and why I'm saying it's mathematics for data because uh L linear algebra contains of matrices and vectors so so these uh these these two are the language of the data so whatever we are going to study you which you will see in your machine learning or deep Learning Journey whatever you are going to study so that's why we we just say that is it's the mathematics of the data because in machine learning data is so much of uh basic component or or a mandatory component the same way the we use algebra or L lar algebra to work with the data mathematically okay so this is a simple definition of linear algebra over here so let's get started with the first uh first uh the component which first thing which we'll study in this video is vectors okay so so we'll start with the vectors so we starting with vectors so if you if if you have any definition of a vectors please please please stop stop this video pause this video and then go down in the comment and please tell me what are vectors so the the we will start with very scratch uh you can assume a vectors as an arrows as an arrows we we have an arrow so these These are the geometric inition of a vectors so the definition of a vector can be it's it's an arrays of a numbers okay so vectors are arrays of a number or a tuple of a numbers okay or or or you can you can take it as an arrays okay so you can consider a vectors vectors can be arrays of a numbers arrays of number or you can consider this vectors uh as an as an arrow you can consider vectors as an arrows as an arrows or you can consider a vector as a tuple of a numbers you can consider ve Vector as a tuple of numbers okay so these are you you can just imagine this an an array is maybe an array can be 1 2 2 3 this is called this is this is called the draw Vector which you'll study you can safely ignore this so this is this is also a vector which is special type of vector which is called the row Vector this can be tle of a numbers or it can be arrows okay so so so the way I like to represent uh vectors or to make you very very much comfortable with it is to to make you familiar with an arrows so this is the geometric division of a twodimensional Vector so let's see how the vector looks numerically okay uh in in terms of mathematical so let's see let's let's see how the vector look so let's name the vector as U okay so let's let's name the vector as U equals so let's store 2 and four so U is a vector where you have the elements so the the numbers inside the vector you you enclose into a a square bracket so here here is two and here is four okay so why I'm saying we have this is this this is like a an arrow so the first element is called X component and the first element is called X component and uh second element is called a y component it's called a y component so let's let's see how this looks on on a graph paper or or to or an X and Y plane so let me plot let me plot that so 1 2 3 4 5 1 2 3 4 and five okay so this is my y plane and this is my xaxis okay so let's plot this Vector onto this uh X and Y plane so so X component is 2 and Y component is four okay so X component is two and Y component is four so here's the point and it passes through the origin so so this is your vector U okay so this is your vector U where you have 2x 4 where two indicates the X component and four indicates the Y component okay so this makes sense I hope so okay so and vectors are arrays of a numbers or you can say the the Tuple of a numbers which which which consist of numbers where it is it has only it is here here our Vector is two dimensional okay but but uh here you can have M number of a rows here you can have in vectors you can have M number of rows you can have M number of rows but and you can and in vectors you have only one number you have only one column okay so so so you can have any number of you can have M number of rows for for for example for example let let me show you a vector U Can Be A B all the way around to the N okay so it can be n dimensional Vector so here our this Vector is two dimensional Vector this Vector is 2D Vector okay and geometrically I showed you by plotting on this XY plane that this is the the two two dimensional plot means first of all X we we we we we go through x x is the four the two units on the xaxis and the four units on the Y AIS and then we and then we uh taken the from the origin and that point okay so so this is this a graph for you but let's take an example eight so this is our Vector a where you going store n dimensional Vector uh it's not key that you should only have two two dimensional Vector you can have n dimensional Vector okay so so but but showing you geometrically you can show three three dimensional Vector geometrically so you can just draw a straight line over here and this is your Z okay so you can plot a threedimensional Vector so so so you can plot it for example you taken K as a vector and you can plot 2 32 on this threedimensional plane or the three threedimensional graph but you can but you can kind plot your you cannot plot your fourdimensional or or five dimens Vector over here so for geometrically understanding I have just just showed you how this Vector looks like but it's not a manner that you can only have a twodimensional vector or or only three dimensional Vector you can have nend dimensional Vector because scientist or researchers most care about your uh or nend dimensional uh your numerically rather than uh most of of course they care about geometrically as well but uh but I just showed you it's not possible for me to draw a FL four dimensional and show you how this how how how we are going to plot but but geometric contribution of a vectors are are we can plot it like this and for example for example you you you have a 2 4 3 so here your K here your K is 3x 1 so first is what are the number of columns which usually denote as three number of columns and you have only one row of course in vectors you can only have one row okay uh okay so so so here you have X component here you have X component here you have y component and here three is your Z component which is in threedimensional and so on okay so this is how you represent vectors so the whole so the whole intuition about vectors so I hope that you understood what I'm trying to convey you over here okay so so so let's so let's see so let's see uh so let's let's go further into understanding uh some more intuitively one last examples of a vectors to to get us what is trying to convey and and and it's it's it's it's much better for for for us to understand okay so I'm going to just just just draw an X and Y plane over here so I'm just just going to draw an X and Y uh X and Y plane like this X and Y and I'm going to take one I'm going to take 2 3 4 5 and six 1 2 3 4 5 okay so this is our X and Y plane now now what what I'm going to do is make it for for example you can you want to plot the vector one 2 okay so how so here you go one unit or X's unit or one unit on the X because this this is your X component this is your X component this is your X component so you go on X unit over here so we'll we'll go till here okay and then two units above so this is your this is your final vector v okay is a final vector v and and to for denoting the Y always the name of the vector should be in lower case with one Arrow Above So this this indicates that it's it's a vector okay so this is this is how you can you have to practice so just try to plot a vector U where X component to be 4x4 okay and a vector can be nend dimensional it can be 6 7 8 9 it can be in dimensional so this is this is how you this is what the vectors are okay so vectors are a two polar array of numbers which we which we just shown shown you today okay so now let's see how we can take out the length of a vector so for example you just draw this Vector so the v v Vector so how do you how can you take out the length of this Vector it's it's a good good good good good way to think about this okay so what I'm going to do now what I'm going to do now is to just remove this and show you uh so take another another example so I'm I'm talking about how do you take out so let's take one example that you have a vector U you have a vector U you have Vector U we have a vector U where your X component is four and 4 by 4 and four okay so here you have here you have a twodimensional Vector twodimensional Vector so you can you can also write w with the member of R2 okay so uh so this is the this is the w u is the member of twodimensional real numbers okay so this is this is this this is your example so what what you want to do is plot the or just let's plot the vector on this okay so 4X 4 I should see over here so X unit four over here and four units of Earth okay and then let's touch this point I think it's wrong bit but no problem this is so how how are you going to take out the length of this Vector this is a good good question to ask to you so for taking out the length of this Vector okay so what you can do here you can see here you can see here you can see that this is also four units this this is also four units and this is also four units so I'm just just going to change the this this is also four units this is also four units okay and you can see this forms a right triangle right triangle at a 90° okay so this forms a right triangle so you know this this is so you know this so which is four units you know this which is four units and you know the this x which is which is here the base four units so here height is 4 units and your base is four units can't you take out the hypotenuse okay or the vector length by using Pythagorean theorem of course you can take out so you can use the Pythagorean theorem you can use the pytha Pythagorean theorem Pythagorean theorem to take out the hypotenuse so for taking the hypoten so the the u² equal to b² + h² okay so you don't know U Square you know b square which is 4 you know the H Square which is 4 okay so U ^2 = 16 + 16 which = 32 and then U ² = 32 now want to U equals to square < TK of 32 that is actually 5.6 5 and and and nearest 100 okay so this is your length of the vector this is the length 5.65 is the length of the vector so so the norm you you usually say the norm okay so in in linear algebra terms so the norm of the vector which is equivalent to length of vector is equals to 5.65 which is your an which is your the length of the vector okay so I hope that you understood what I'm trying to convey with geometric intuition over here okay so what if if we have n dimensional Vector okay so what if we have n dimensional Vector so we will we will see what if we have n dimensional Vector but but let's see let's let's go further let's understand a bit more intuition about um the the how many number of elements what what are the terminologies and then we'll see how do we take out the length of an N dimensional Vector okay so uh just as a notation or terminology or to to remember so that everything is clear everything is clear uh the elements in the vectors are the dimension of the vectors I'm not saying that uh elements it's the the number of elements in the vector is equivalent to the dimensions of your vector okay so the number so the number of elements elements here is numbers okay so elements are usually the numbers like four is an element four is an element okay the dimension are the dimension dimension of the vector of the vector okay so this is the first terminology so here here you can see that you have Vector U which has a and b so here it has two two elements so this so so here is two elements so here it the U the vector U is a 2d Vector is so I I am forgetting is a 2d Vector is a 2d Vector two dimensional Vector so you can plot it if it is three threedimensional you you'll be having a bit difficulty in plotting in a threedimensional plane but you can plot it if it is fourdimensional you cannot plot it on on over here okay so this is a number of elements are the the are the dimensions of your vector okay the next terminology vectors can be n dimensional as I stated the vectors can be vectors can be can be n dimensional Vector n Dimension and dimensional so you can have the U Vector as a b or all the way around to the N okay so here it can be n dimensional Vector so as I stated that it should not be only 2D Vector it can have a n dimensional Vector okay so so as as I left you hey hey how you're going to take out so you take out the length of this Vector U by just uh by just using the Pythagorean theorem but how you how you are going to take out the length of vector U which is an N dimensional so how do you take out the length so the norm of U so I'm talking about this U the norm of U is a square root of U1 2 + U2 2 + u3 squar all the way around to the U N squ okay so it's it's just equals that not nothing much deeper which which we have talked or i u i s okay so this is the this this this is what I want to convey over here this is what I'm going to convey okay so you can actually actually think think about it and in in that way that you want to take for taking the length you just Square U square plus u Square all the way around to the whatever the number of elements in your okay so over here what we were doing we can simply do like this we can simply do over here if if you want to take out you can simply use this of course you are it's just related to some Pythagorean theorem okay so over here you can just add a square root of your b² + h² which is b square is U1 H square is U2 okay means this one four and four okay and then you take out so it's just equivalent whatever whatever we had seen over here okay so so the same way we take out the the dimens or the length of our Vector uh U okay which is an N dimensional Vector I hope that understood till now whatever I taught Okay so so so so let's so let's see so let's see uh bit more so we have studied the how what are the vectors how do we take the length how do we represent the vector v vectors can be n dimensional so now let's see some of the let's do some of the operations on our Vector okay so so we'll start doing the operations on our Vector so I'm just just going to give a headline uh doing operations doing operations on Vector okay on Vector so it's a it's a very great it's it just not too much hard it's very very easy so so the first operation which you want to do is addition of a vector so how are how are we going to do the addition of a vector the first component is addition so you are given you are given so let me State the problem you given the vector the vector a which is 2x 2 and you're given the vector B which is 4X 4 got it you want to what you want to do you want to calculate you want to calculate you want to calculate Vector C by adding a + b means you want to calculate the vector C by taking out the the the uh adding by by summing this to Vector okay so how are we going to sum some this 2x two and 4x 4 means so what you can do you can do the element wise you can do the element so so you can what you can do c c will will be equals to 2 + 4 and 2 + 4 2 + 4 2 + 4 and then also 2 + 4 okay so two element wise addition so it will be nothing but equals to 6 by 6 okay where you add the one you when when you add the vector 2 by 2 by 1 + 2 by 1 2 * 1 which is the the dimension of the resulting Vector will be also 2x 1 okay so what what do you do you you 2x 1 uh which is the dimension of your a vector and then 2 2x 2 * one where the there is two elements and the one one one column so that is also B and then the resulting Vector is 2 * 1 okay so it is the 6X 6 so you get you calculate C to be 66 where your X component is 6 and Y component is 6 so the 66 is your resulting Vector so your resulting Vector C is a twodimensional Vector okay some of the things which I want to highlight is your dimensions of your both the vector which is a and b should match okay if for example for example if your a vector a vector a vector is 2x two and your V vector is 446 then you try to add it the resulting Vector will be undefined will be undefined okay so your dimensions of the addition of vector should match okay otherwise it is undefined operation okay so so this this is this is what I to convey over here so let's see how you add the vectors how you add the vectors uh how you add the vectors geometrically so we seen the numerically how we add the vectors so let's see how you how you add the vectors geometrically okay so let's let's do something let's do something is uh we will do now some geometric because people tend to understand more geometrically rather than numerically okay so we'll understand geometrically so here I'm drawing I'm going to draw One X and Y plane like this okay X and Y plane okay so so let's see so let's see that you that your vector a that this is this this this is this is your vector a so let's let's let's keep uh let's make it total okay so this is so this this this is your vector a and this is your vector B this is your vector v okay this this is your vector v and this this is your vector a you want to add this two Vector geometrically speaking you want to add add this Vector a plus Vector B okay you want to add this so when you do this geometrically okay so what what you going to do you're going to take this Vector a so I'm just just just going to say you take this Vector a take this Vector a and put the tail of this Vector the tail of this Vector onto the onto the top of the vector B okay you put the tail of this Vector onto the top of the vector B okay and then you put this this this one onto the head of this okay what what you want to do is uh take this VOR whatever whatever the length okay whatever may be the length you just put it like this I'm I'm not drawing correct but no problem in that so the length of the length of this should should be same as whatever you are doing you're just taking this a vector and putting it over here okay you just um you're just taking this Vector a and putting this tail onto the head and and then you are and then you are putting it over here and then what what you do you take this vector v you take this Vector B and put the ta onto the top of a and put the and and just match this uh with this okay so take a vector B and then you just put it like this I think it's not correct too much but this is how you are going to do you first to take the vector a put it on the the the tail of that on the head of B and then you whatever the length you just uh you just put put that over here and then you take this and that and then put put put this state onto the head of this and then you match the heads okay and then and then and then the head the the the resulting Vector so the resulting Vector so the resulting Vector I'm just just just going to take this so so you just take you just this is this will be this will be this will be your resulting Vector we are blue one in the case A+ b a vector plus b Vector okay so this is this this this is how you add the vector geometrically and then it makes sense as well okay if Ison don't worry let's see one more example to make more clarity okay so over here which you let's plot so this is how you just take this and then you draw and then you are done with this and then you attach the the here's the tail on the origin okay and then you attach and then you draw a straight line on like that okay so this this is called the parallelogram method okay so this is called the parallelogram this this is called the parallelogram method for showing the geometrically for showing the geometrically let's see triangle method that that will make make more even sense okay so that will make more even sense so here is your vector a here is your vector a and here is your vector v here is your vector v okay here is your vector v you want to add this up so what do you do you simply you simply what you what you don't do anything extra you simply attach this to make a triangle to make a triangle like this and then this resulting Vector is your addition of the two vectors okay so this the resulting Vector which is which I'm going to highlight with this is your resulting vector and this is this is the this this this is how you do the addition geometrically speaking okay so this this is called the triangle method this is called the triangle method for addition of two vectors okay try to play with it a much much more better way so that it could make sense to you as well okay so try try try to play with it try to draw some diagrams of it and then show and then try try try to little bit juggle with it and then then and then you will better better understanding rather than uh just seeing okay so you can you will be getting some assignments on this as well so you can approach the assignments uh in geometrically speaking okay so so let's see one more operations which is the vector subtraction Vector subtraction okay so I'm just just going to show you Vector subtraction subtraction so what this Vector sub subtraction will do so let's say you want to subtract Vector U minus minus vctor V okay so that will be simply we can frame it as an addition of a vector U plus minus B okay so then it will be much easier to show it geometrically speaking okay got it so what I'm going to say over here is you have a vector so you can simply do like this for showing it geometrically now it will very easy to show it geometrically like this by adding of the vector okay so what what what what you do you just make this and then just for for showing it geometrically speaking okay so for example you have a vector U which is 2x3 and we have a vector and and you have vector v which is 1x 1 subtracted so resulting Vector the resulting Vector will be 2 1 and 3 1 that will be nothing but equals to 2 okay it's 1 2 okay so X component y component so this is your resulting Vector okay so let's let's see how it looks like uh so it it would make more sense to you as well okay so let's assume 1 2 3 okay 1 1 okay so let's plot the U Vector so I'm just just going to plot the U Vector which is 23 okay okay so okay it's two now so it's 2 three so okay I think I done wrong it's 2 three so just going to okay so this is your vector U so this is your vector U this this this is your vector U and you want to plot the vector v v so this is your vector v this this is your vector v okay this is your vector v and the resulting Vector is 1 by 2 okay so this is your resulting Vector which is your after subtracting okay so after you subtract uh uh this from this the vector v from U okay so that will be your resulting Vector that makes sense geometrically speaking as well okay so this is how you do the vector subtraction geometrically if you don't understand geometrically it's no worries but it's not more than tough which which which is is very very easy not more than tough okay so this is your vector addition and Vector subtraction so let's see the last concept which you which I to make you familiar with is is is Vector scalar multiplication Vector scalar multiplication Vector scalar multiplication so I'm just but but first of all what is in scalar what is an scalar so scalers are give scalar such as constant or a numbers for for for example four is in scalar two is in scalar one is in scaler or or or or anything okay so this is scalers are just constant okay so it is it's a number but in algebra or linear algebra term we call it as a scalar okay so it plays an important role when we stud about L linear combinations or linear Transformations it plays a very important role so so so this is so what if if you multiply a scalar for example you have you want to multiply scalar a times the vector U you times the vector U so let's let's take the you you take the scalar a to be two and the Vector U as a 2x2 okay so multiply 2 * 2x 2 so it 2x2 so it do the element wise Product 2 * 2 4 by 4 that will be equals to 2 * 1 okay so Dimensions will be 2 * 1 that that is simply the vector scalar multiplication so what it actually does in geometrically speaking it stretches the vector so it doubles the vector so for example you have this Vector 2x two okay and then you multiply with two then it will be doubled then then it will be stretched okay then then it will be stretched means transformed the vector okay or stretched the vector by by following the linear structure it stretched the vector like like this so this this this was your initial Vector so after applying the a times the vector U that is stretch which is your final Vector after applying your uh the scalar and Vector multiplication okay so this is your stretch stretched Vector so please please please please ensure that it's stretched so before applying it was U and after applying is doubled okay so this is this is this is the vector scalar multiplication and the reason why we are studying these because this helps to build a very good foundation the stretching the geometrical speaking this helps a very good foundation when when we talk about Transformations con combination combinations uh igen values I vectors these these plays an important role in that so so this was uh so so so we have seen a bit about vector and scalar multiplication the last concept the last two concept which I want to introduce to you is the unit vectors is the unit vectors is the unit vectors and the zero Vector okay so the unit Vector so unit Vector is any Vector with a length one so so the definition States the unit Vector the unit Vector is any Vector is any Vector for for example any Vector okay any Vector with length one whose length is whose length is one whose length is one that's a unit Vector okay what is a Zero's Vector Z's Vector is whose length is zero whose length is whose length is whose length is zero whose length is zero okay so that is the zero Vector you usually denote the z z Vector in very bold way okay that is the zero vector and that is the unit vector vector and vector okay so these are the two basic basic very very basic ter terminology which you need to know about okay so so we have seen a lot about our vectors in this video so I hope that you understood every Everything whatever we had have have have a talk on this so just just just to make sure that everyone understood this so what what what you actually do so let me show you one one more example of that so so for example you have this okay so you have this Vector a and you have this vector and you have this Vector B okay so what do you do for addition of these two vectors you can just you can what you can do you can just uh make this make this a triangle okay but let's approach within using a parallelogram method okay so what do you do you put you take this you take this vector and put on the this tail out of the head and then you just draw a parallel to this and you take take this and then you take this and then you join the and this this A+ B is a result in Vector okay so this is how you go further into approaching these stuffs and I hope and maybe you can solve it using a triangle method to show you how it works geometrically speaking okay so I hope that you understood whatever I'm trying to convey you over here okay so I hope that you understood geometric intuition the triangle method what the unit what are zeros what are scalers what are what are what are vectors and etc etc etc okay so I think that we are done with this lecture um on it's 30 minutes so I hope that you understood vectors what are vectors uh so you you can find the notes of this the lecture notes maybe all of these in the description round box below uh the the or in LMS and the assignments will will be also related to this will will be released at the end of this week and I hope and I really really really hope that you understood this and if if not please feel free to ask the question in description down box below or in our Discord server we are we will be very really happy to answer your questions the next announcement is you can simply uh the next the next lecture will will be based on matrices okay so we'll talk about a bit about matrices okay and then and then we'll talk about after after completing a bit of mat matrices we'll talk about linear combinations then trans linear Transformations okay so we will be studying these things so don't worry we'll gohe very slow pie and very easy way okay so thanks for seeing this video I'll be catching up you in the next video till then byebye and have a good day hey everyone in this lecture we'll be talking about mates in our pre previous lecture we talked about vectors and I really really really hope that tat to understood about vectors I know this these are very very easy concept for you but but uh let me tell you these sets a foundation when we study about combinations or Transformations and other other stuffs so that's how we are prely focusing on this so from this video we'll be starting stepping up a bit difficult note from matrices and then we'll talking about some some matrices operations and then we'll talk about some properties of matrices multiplication and then I will just end up with this video with Matrix Vector products and then I will show you the wide results at the end of the video that the linear combination of the column Vector okay so we'll be talking about I'll just introducing a notion of a linear combination so that in the next video is totally based upon your linear combination so that's why I will just give you a taste of linear combination at the end of the video so let's get started with matrices so today we'll be talking about matrices so let's let's recall a bit about vectors so so vectors are uh n dimensional where where it can have n and where where it can have n number of rows but only one column okay so we were having this it can have one two all the way around to the n and here this is n * 1 so the shape of this vector v the shape of this vector v is n * 1 and it can have n number of a rows and one number of a column and this is a vector specifically we can call this as a column Vector okay so so so we specifically call this as a column Vector okay so so it is given a new name and when we when I will introduce you a notion of a matrices then then we will use extensively in the in the later videos but but this is also called the column vector and and for example your vector can be in this 1 2 3 all the way around to the end okay so this is called the row Vector this is called the row Vector okay okay so this is called the row Vector so this for this these are the two two things which I want to in introduce to you so we'll be covering this again just after we complete the matrices okay so let's start with what are matrices so matrices are a are a set of numbers or or a multidimensional l okay where it can have n number of rows or n number of rows and M number of columns it can have a multiple columns and multiple rows okay so in vectors we we in vectors in vectors we were have having only we were having only n n rows and one column which is the example of the example will be 1 2 3 okay so this this this is an example of a vector v okay so the matrices so the matrices can have can have n number of rows as usual but n number of columns but can have M number for column so as an example we can make that Matrix a equals to 1 2 three so one column 2 3 4 second column 3 4 6 third column so it can have M number of M number of a row M number of columns and and and N number of a rows and N number of a rows okay so here the shape of this a is 3x 3 uh where three is number of a rows number of a rows and this one is number of a columns number of columns okay so so over here this this first first indate the 3X3 Matrix so this is the example is 3x3 Matrix so the formal definition of a matrix is is matrices are a set of numbers okay mates are a set of numbers arranged in a rows and a columns which is n rows and N columns so to form a rectangular array okay so here here it on the rectangular array in other words matrices can have n number of columns and M number of rows okay so let let me write a formal definition of matrices over here so and the definition which is just let me write the a good definition of this so that everyone can can Define what a matrix is so matri so here's the definition of a matrices where it it it is arranged in a rows and a column so I'm going to give the name of a rows going to give the name of a rows to n and columns to M so to form a rectangular l so for for for example we can have here it can have a b c d e f g h i okay so it's can have any here we have this is this this is an example of 3x3 Matrix where we already have one two three rows and one two three columns okay or we can say in other words it's going to have n number of rows and N number of columns M number of columns okay so I'm again I'm saying n is for number of rows number of rows and M is for number of columns number of columns all those are in small small letters okay so this is your form formal definition of a matris and the lecture notes is in description box below please go there and assess your lecture notes for you to better to to just revise in the meantime Okay so so so just let's write a formal notation of how the maor matrices are so that so that it it is uh easily inter interpretable so I'm going to make a matrix a going to make a matrix a where I'm going to make a matrix a where it I'm going to make this a11 so the how do we assess the the first element so here it is in first row and First Column so this a is in first row and First Column so that's why I written I and Z okay so a i and Z indicates I what is the row number and g z what is the column number so for example for assessing the elements so over here you have this you have this Matrix we have this Matrix a and what you going to do is assess three so how do you want to assess so the you the formal the formal assessing things is a i j or or yeah so a i j where I indicates the row number and J indicates the the column numb okay so over here you can see the three is on is on we start with 1 2 3 okay not from zero so 2 2 A 2 means a A2 means the row number is two and the column number is also two column number is two that is nothing but equals to three okay so here's how you assist so first of all you write the row number then you write the column number so I indicates the row number and J indicates the column number okay so I hope that you understood what I'm trying to say so it is telling go and this is the first element where is first row and First Column then it is second first row and second column then uh all the way down to the first row and N column okay or M column okay and over here it can have 8 2 1 okay so second row First Column second row second column all the way down to the A2 m m second row M column okay uh so uh this can be a31 a32 a3m here all the way around to the a N1 so n is number of rows or a N2 all the way down to the all the way down to the a n m okay so here it is the formal notation or or a definition which we can write over here which is the formal notation for writing uh so so this is a matrix okay so here's how I developed this so it can have M number M number of a column A rows n number of rows so 1 2 3 4 all the way down to the N which is n number of rows and it can have only it can have only M number of columns okay it can have only M number of columns so this is your formal formal formal definition which you have which I have given to you for uh matrices okay so I hope that you understood now what I'm going to talk about is I introduced a notion of a row vector or a column Vector is it so I introduce you so can you just go and just type me what is a row vector and what is a column Vector so let's take one example so let's take one example is you have a you have a matrix but just just just one thing that the vectors are subset of matrices okay so the the the vectors are a n * 1 Matrix or n * 1 matrices okay so the vectors are a subset of matrices okay so if you if you extract this extract this extract this row that this is just a vector okay so what I'm going to do now is uh is going to just make a vector make a matrix a make a matrix a which contains just just don't relate I'm just taking examples I'm just taking examples you have a vector a I'm going to store 1 2 3 4 5 6 okay so this is my this is my 2x3 Matrix okay so so what you do you take the first row okay and then stored in another so C okay that is 1 2 3 okay so what is C over here C is called the the the the the the the Matrix with one row okay the Matrix with one row is called the row Vector this is called the row Vector this is called called the row Vector The Matrix which has only one row is called row vector and the Matrix with only one colum which is nothing but called a column Vector okay so so so if we if you take this 1x4 okay in D that is 1x 4 it has only one column that is nothing but equals to column Vector which is nothing but is column Vector okay I I hope that you are understanding whatever I'm trying trying to tell here so so these are the size of a matrix over of size of a matrix where we have row vector and what is row Vector row Vector are nothing but the Matrix with one row with one row is called the row vector and the matrices with one column is called the column Vector okay so if you take one example so just just just just assume that this is your this is so this is your first of all row Vector sorry column column Vector because you have uh you have so so you have sorry column vector so this this this this one is a column Vector which is V1 so V V1 over here is a column Vector okay so if we take this one if we take this one so here you have only one row so that is B2 which is your row Vector okay so this is this is what the notation of the notion of a row row vector and column Vector means and I really really hope that you understood about this okay so if not please please feel free to ask ask a question below where you're stu please please please use Discord server or whatever that's the doubt support which is provided to you so that you can get most out of out of this course and if you need any guidance for absolutely free please feel free to reach out to me via email Discord comment we can get on a meet to help you solve the doubts it's it's for Okay cool so let's so we have we have seen what some matrices are so just just want to Recaps youate everything so matrices are a set of numbers arranged in a number of rows and number of column s to form a rectangular array where it can have an m n number for rows and M for mango number for columns okay so so the notation for for the definition of geometrically over here is the a so I I have made this as an example the show showcase shoe and we have we have seen some of the Matrix size where you where the the the terminology which is where the Matrix has only one row that's the row vector and with the Matrix has only one column that is a column Vector okay so I hope that you understood what I'm trying to convey over here cool so now let's talk about so now let's talk about so now let's talk about some of the operations because in pre previous video we talked about vectors and then operations so the same day I'm going to talk about operations on a matrices okay so operations on matrices just just just just just going to show you show it to you operations operations I think my handwriting is not good too much no problem operations operations uh on matrices okay so you want to do the operations on matrices so the first operation which you're going to do is Matrix and a scalar multiplication okay so what I'm going to do is Matrix Matrix scalar multiplication okay not a not a big deal it's very very easy to understand okay so assume that you have a matrix a you have a matrix a you have a matrix a 10 6 4 3 which is your nothing but a 2x2 matrix okay 2 rows and two columns okay and you have a scalar you have a scalar a which is nothing but two okay so you're given these two now what you want to do is uh you want to multiply uh a a okay so we multiply a scaler with a matrix which nothing but 2 * 10 6 43 okay that is so what will be the result please anyone please please please feel free to to pause this video so what you're going to do is multiplying a scaler with a 2x2 matrix so what will be the result anyone please please please in the comment okay how how do you tell okay no problem but please please free to ask say in the comment box I will be very happy to see the if you're still here so the answer of this is first of all what do you do you you simply do the element wise product with this scalar okay so 2 * 10 which is nothing but 20 which is nothing but 20 2 * 6 which is nothing but 12 2 * 4 what it is 9 no it's 8 okay 2 * 3 which is nothing but six okay so the resulting the resulting Matrix is 2 * 2 Matrix so what you do you transform or or or not a transform I would say you just multiply a scalar with a a matrix and and then you get a 2x2 matrix which is the same size of your a okay so 2 * 2 = to 2 * 2 which result when you multiply with any scaler okay so what it does is simply do the element wise produ product okay so the so the formul notation for this is you you multiply C with with a okay and a have I and J row okay so what it will do it will simply M do the element wise a c * a i j that is nothing but what it will do first of all it will uh so in more more notational terms it will just for for for example you have a vector you have a a scaled a and you multiply with c d e f okay so what do you do you simply uh a * C A * d a * E and A * F okay so this this will be the form this is this this will thing and then you'll be getting some values 2 by two okay which with your values okay the same this is this is what it is doing so this is your formal definition formal definition of your Matrix Vector multi multiplication sorry uh scalar matrix multiplication and I really really hope that you understood this let's go on to the next operation which want to see let's go on the next operation which want to see is addition of our matrices okay so the next operation which we are going to cover is addition addition of matrices okay additions of a matrices so let's Zoom so we are you are you are given a matrix a you give a matrix a which is 1 3 1 uh 1 0 0 okay and you have and you are given Matrix B okay and Matrix are always written in a capital letters make sure and the vectors are always in small letters okay with one over here uh and the scalers are also in like this yeah so that's B is 05 75 okay so what you want to do you want to add these two matrices A + B add this two matrices so this is the operations which you want to do this is the operation which you want to perform so how how are you going to perform this operation how are you going to perform this operation so for performing this operation so for performing this operation you will just what what you will do you wanted to just have this 13 1 1 0 0 plus 05 750 what you what you will do you will nothing but uh 1 + 0 at element y some okay in scaler you doing so you will do the same 1 + 0 3 + 0 1 + 5 okay element wise sum okay 1 + 7 0 + 5 0 + 0 okay so this is this this is what you do and then you'll be getting your answer which is 1 3 6 6 and then you getting 8 5 0 that is a resulting U Matrix okay which is also 3x3 Matrix okay so what you do you simply do do this and you're getting a 3X3 Matrix okay so so when you what you do you you just added a 3X3 Matrix 3x3 Matrix and then and then you and the resulting Matrix is also 3x3 okay so so this is how you do the addition of a matrix and the formal definition for this I which which which which I can state so because definition is very very important for fundamentals for for making your fundamental strong okay so the definition is your given a matrix a which can have a uh b c d e f okay that is nothing and your B is also some some kind of k g i h o p okay so add these two so you what what you will do a + k b + G C + I D+ D + h e + o e + O and F + P that will be nothing but equals to 3x3 Matrix okay so I have just taken example your your Matrix can have n dimensional the can have any number of rows and any number of columns but there are some constraints which you you need to there are some properties like Dimension property which you have to take care while adding the matrices okay so it can have it can have uh ABC you can it can have a 10 x 10 matrix the size of the Matrix and then you are adding the 10 x 10 matrix with another 10 by 10 matrix and that would resulting in another 10 by 10 metri okay so that is the that is the thing uh so some of the property which I want to highlight which you all have to focus on so some of the properties of a very very very very uh simp simp simple property that commutative property commutative property so addition of a matrix is commutative commutative and all of these is written in your notes please please please feel free to write see from there if you if you wanted to just just just revise it up okay uh in in future but I would highly highly recommend to complete this video V plus so you so you have a matx say you have a matrix you can do B+ a okay uh the next thing is associated property your your your your addition of a matrices are associ associative as well okay so associative associative property associated property I'm not writing a lot of properties over here but the one who are important I'm writing over here A + B+ C which is nothing but equals to A + B plus C and all of these can be proved very very easy the proof is very very easy not a hard please feel free to search on internet about the proof it is very very easy associative commutative it's it's the proof are available on internet okay so so the last thing what I'm which the first property is commutative the second is associative the last one is dimension property the dimensions are be the dimensions the dimensions the dimensions of the dimensions of your of your uh uh the two two two Matrix would be same The Matrix the matrices would be same the matri should be same okay the dimensions okay if it is not then then it will be undefined your operations will be undefined Okay cool so so now we have we have we have talked about one one of the operation which is addition of a matrix and I really really hope that you understood addition you you understood a scaler but one thing which I'm going to spend some some two minutes talking about is you may be thinking yeah you do we really really need to know about these stuffs uh so I would say yeah you need to know about although you don't need to just worry about how I'm going to code it you can actually develop it from very very scratch not a big deal but there are some libraries like numai which would be in this course we'll be using in this course or or pytorch that'll be doing using uh the LI library for S computation for addition of a matrix for multiplication of a matrix which they handle which they are very efficient okay because in real world your Matrix are not 3x3 Matrix they are they are they are billions size size is millions okay Millions by millions so so they are they are very very large so so so Maj mag multiplication with your own for Loops are very very time taken okay so that's that's that that's a big deal okay so your your time complexity will increase as your input size increases okay so that's a big deal so you we are learning this to understand the inner workings of our of our function so that we can we can know how how our algorithm is doing and how everything is working behind so that it it becomes very easy to debug something or you get some error or or or to to have very good or decent knowledge of what your code is performing Okay cool so addition of a matrix is also done now let's you can do you can do the same with sub subtraction of a matrices please try it out by your own the next thing which which I'm going to spend some time talking about is matrix multiplication okay bit bit I'll spend some time talking on this okay so the first the next next thing which I'm going to to talk about is Matrix uh Matrix Matrix multiplication Matrix Matrix multiplication okay so this is your uh next operation which is which is one of the most important important uh important what do you say uh the operations which you which you need to learn okay so you given a matrix a you're given a matrix a I'm going to take very easy example 1 7 2 4 okay and you're given a matrix B given a matrix B which is 3 5 3 2 okay now you need to now what you need to do you want to multiply Matrix a matrix B okay so how do you do you may be thinking here you here is 2x two here is 2x two is 2 by 2 1 * 3 7 * 3 2 * 5 that's that's that's that's that's not how you do okay so the matrix multiplication the way you do is like this you take the first row of that a matrix you take the first row I'm going to change my pen you take the first row of that a matrix and multiply with the multiply with the First Column of the b b Matrix multiply with the First Column with the B Matrix okay so so here's here's how you do so resulting resulting M Matrix c will 1 * 3 okay plus taking the dot product of your of your row Vector times the column Vector so what you what you are actually doing is taking out the dot product dot product which you'll see in our later videos don't don't worry about that dot product of this this is your because if if you see this is your it this it it has only one row okay so of a vector of a vector of a of a vector of a row Vector of a row row vector and column Vector column Vector so this this is your column Vector where it has only one column so specifically you're taking out a DOT product of a row vector and a column Vector what is dot product so dot product is element one so what what you do you simply multiply and add it up but element wise adding and add it up okay so over here what what what you want to do you one * 3 and 7 * 5 1 * 3 7 * 5 and then you will add it okay now take this again this row again this row with this row row vector and multiply with this column Vector multiply with this column Vector so that that will be nothing but equals to 1 * 3 + 7 * 2 okay now what do you do now what do you do you you now you have this The Taking of the dot product of row row vector and the second column VOR which is V2 okay now what do you do you go go go further into this the second row Vector which is 2x4 and then you do the same 2 * 3 dot product of the 2 4 with row Vector with the column Vector okay 4 * 5 okay and then 2 * 3 4 * 5 2 * 3 2 * 2 okay so 2 * 3 + 4 * 2 okay that will be nothing but equals to C which is nothing equals to uh 1 * 3 which which will be how much 1 1 * 3 which will be 3 + 5 35s okay 1 * 3 3 + 14 2 * 3 6 + uh 20 which is 26 2 * 3 6 + 8 which is nothing but 14 okay cool so this is your resulting and then what you do you simply make your 38 17 26 14 will be your resulting Vector which is 2x2 matrix which is the 2x2 matrix okay so when you multiply with this you will be getting uh your favorite the after after multiplication of the Matrix this this is your answer of this of your particular question got it and I really really hope that you are that you understanding what I'm what what whatever I'm trying to say but you it may you you can use you it can have any dimensional but some properties are there okay so let's let's visit the property I'm just going to constraint that Dimension property is very important in this so what dimensions should match to be so that the matrix multiplication is not undefined okay so so the properties of for MRI multiplication so the first property which I'm going to talk about property the first property is for for example you're given a matrix a b and c so these are three Matrix which are n byn Matrix which are n by n Matrix where you have n n byn Matrix okay so where you have n rows and N columns okay so the first thing which holds is commutative property of multiplication of this multiplication does does not hold okay so M multiplication is not commutative is not commutative is not is not okay so when you multiply a b ba a which is which will be totally wrong it can be proved it can prove it it can prove very easily then the next property associative property of matrix multiplication is is is there okay so associative property associative associative property is there okay so a b + C which is nothing but uh a okay so I think it's I have written for this distributive I written for a c which is nothing but equals to A B C okay it can prove rigorously and of course you're multiplying it over here okay it can it can prove very very easily it is distributive property distributive property this this it is also distributive property so what you want to do a B+ C that that will be A+ a c and you can prove these you can prove this very very easily which which can be found on internet the next thing is the most important Dimension property Dimension property Dimension property so the dimension property is you can have M number of a rows you can have M number of rows you can have any number of rows but an N number of columns okay this is for the dimension of a matrix a your dimension of a matrix B should be your your your number of a rows should be same as uh number of columns in that Matrix okay times K any okay so your resulting will be M * K okay so so it makes sense as well if you have you can have M number of rows at the a a matrix but you can and N number of columns okay but with here you can have only n number of columns n number of a n number of rows sorry n number of rows okay so here you have two 2 by two so here it has two and the resulting will be the resulting will be 2 by 2 Vector sorry Matrix okay so that the the the resulting size will be this okay so this is your dimension property of your matrix multiplication cool so we have talked a lot about Matrix and and and and you seeing that you're are going and then and you are seeing that that you are going bit up bit bit little bit little bit up so the last thing which I will end this video which I promised you is is talking about Matrix Vector product is a matrix Vector multiplication okay so what I'm going to talk about is Matrix Vector multiplication yeah so let's let's let's let's do that then so let's do that so you have a matrix a you have a matrix a which is nothing but which is nothing but so I'm just just going to define rigorous very very definition of Matrix Vector product so I'm just just just going to write it very very fast a11 a12 all the way around to the A1 n and a12 a22 A2 n uh a M1 which is is N1 okay N2 okay that be A and M okay so this is your Matrix this this is your Matrix so it is having M number of columns and N number of a rows okay this is your Matrix a and you want to multiply with multiply with uh a vector a column a row L row a column Vector okay X2 XM XM okay so to do the multiplication of it so how do we do it how you how you how you will will will you do it so you want to multiply a matrix which is a which is M * n Matrix times the vector a scalar uh sorry Vector col color Vector X which will be the definition will be so so what what it be the answer of this so how will you perform the so for performing the operations is nothing but equals to a11 X1 so what you are actually doing you can take this a11 okay and you multiply this with this multiply this with this okay so what you actually doing what you what you are actually doing you're are multiplying you're multiplying the the column Vector the column sorry row Vector sorry row Vector to the column Vector okay element wise and adding it up okay so the dot product between your row vector and a column vector and adding it up okay so a11 plus you're adding plus over here see a12 X2 plus A1 3 X3 all the way around to the A1 M A1 M * x m XM okay then you do the same A1 2 X1 + a uh plus A2 all the way around to the A2 uh n okay so you're multiplying with X whatever the X so what what you're actually doing you're multiplying you're taking this column Vector taking this column Vector so row vector and multiplying with this so you are taking on the dot product between taking all the dot product taking all the dot Dr taking out the dot product and giving your answer that's it okay taking taking out the dot product of between the row vector and the column Vector so let's see with one of one of the example so it it it would make more sense so here you have 3 0 3 2 1 7 1 9 okay and you have a vector column Vector 2 3 4 1 okay so what what will be the output so the answer will be uh minus 3 * so so we taking this you're taking this and multiplying with this okay 3 * 2 + 0 * 3 okay 3 it's minus + 3 * 4 + 2 * 1 it's yeah it's 1 okay now you go for the 1 * 2 1 * 2 + 7 * 3 + 1 * * 4 + 9 * 1 that will be nothing but equals to after after you add it everything after calculating okay after calculating that will be a and b which is 2x 2 2x 2 sorry 2x one vector so which is a column Vector which is 2x one so after after after doing the Matrix Vector you transform you what what you do you have this R4 R4 we is four dimensional vector you transform it to D after doing the after using this V using this Matrix say you transform it into a a and b which is the 2x1 okay which is from R4 to R2 okay so here you transformed using this Matrix a so so so we'll see in our four videos that matrix multiplication are a linear transformation okay so we'll see in our later videos but but now as of now I I hope that you understood the mutrix Vector product okay so in the next video which what I'll be showing you a wired thing over here or not a vired thing a very useful thing over here is the linear combination using the help of Matrix Vector product so I will take an example of matric vector product as a linear combination of uh of so that it would make more sense and then we'll complete the linear combination now in in our next video and then and then we'll end up uh this uh uh so we'll be completing and then then we talking about the linear transformation I really really hope that that you understood this I'll be catching up you in the next video till then byebye have a great day and and please please and one more thing attendance is you have to mark your attendance so please please feel you to do so byebye have have a great day okay so welcome to this lecture in this lecture we we'll be discussing about linear combination of a vector so and this is this is one of the most important concept as you will go further and you will understand okay so it sets up a very strong fundamentals to mathematically understand or to see the Deep learning or machine learning into a linear algebra point of view so this is one of the most important concept which we'll focus on so in this video we'll talk about that specifically so uh as so I'll in this video I'll just give you I'll be giving you some definition of linear combination and then I will giving you some some examples and then we're talking about a matrix Vector product as a l linear combination because in previous video at last we talked about Matrix Vector product so that's why we are in this video we'll be talking about the as an example taking that as an example for linear combination of our Matrix Vector problem okay so so the definition States so the definition of a linear combination States uh so let's let's do something let's start with an example let's start with an example and example States and an example States key that you have so first example that I want take is you have a scalar you have a scalar and you multiply with the sum Vector U okay and then you have and then plus two with some vector v okay and that will be some resulting Vector that will be some resulting vector which is just the scale version of u and v which is nothing but uh for example D okay so that is the resulting Vector of our uh after applying off first of all we we added it up sorry mult M multiplied and added the vector okay so that that will be the resulting Vector so the resulting Vector is a linear combination of vector U and a v okay so again listen me that what you we we have taken this example and and this in this example we have one scalar three and then we multiply with the vector U so for example we can have a vector U to to be 2x two so when when you multiply three times okay that would be nothing but 3 six six that would be the six okay 6 six okay plus you have some some Vector B it is nothing but 4 4 okay so 2 * 4 so when when you multiply or do the scalar scalar Vector multiplication that will be simply element wise product so 2 * 4 which is 8 and 2 * 4 which is 8 okay so when you uh now you add 8 by 8 okay so that will be 8 by 8 that will be nothing but 8 by 8 okay so the resulting Vector will be 14 by 14 okay so that the the resulting Vector will be 14 by 14 which is your D which is your vector D so this the vector D is a linear combination of your vector U of your vector U and of your vector v okay so the the the resulting Vector is a linear combination of these two Vector which is u and v so I hope that you that that you are understanding what what whatever I'm trying to tell and this 14 is just the the 6 + 8 which is okay so this is the D is a result resulting Vector uh after after you do so what you specifically done is multiply there is some scalar so there is some scaler so you are given any number of a vector so the I'm writing the definition so what you specifically done you're given you're given any number any number of any number of vectors we given any number of vectors and the linear combination linear combination linear combination of the vector of the vectors so you are given any number of a vector but the linear combination of this Vector means these vectors are simply the result of are simply the result when we multiply when we when we multiply when we multiply each Vector each vector by a scalar scalar and add the vector vectors so so how you get the linear combination is you are given any number of vectors okay so you are given any numbers of vectors and the linear combination of those vectors the given vectors is simply the result is this in this case the result of when the the result when you multiply when you multiply each Vector which is you are you are given u and v over here so when you multiply each each vector by a given scalar which in in this case is three and two okay and add them up that the resulting Vector is your linear combination of those vectors okay the formal notation which I can write is you are given a vector a you are given you are you are given a vector B you are given a vector C you you given a vector D okay so you want to find out the linear combination of these vectors so so the linear combination of these vectors will be simply uh when you multiply with some scalar okay with some scalar so I'm just going to write it uh uh a okay so this so let me write a different name of this so I will just so your given given vectors given vectors are are I think uh v u g okay so this these these three are your uh given Vector okay uh now what you do uh you simply multiply with some scalar a okay so so what what will be the so we want to ask what will be the linear combination linear combination linear combination of these vectors so what is linear combinations so the definition states that a linear combination is the result when you multiply the given vectors by some scalar and add the vector okay so that is the resulting vector so what you do simply multiply a scalar with a vector plus b with the U Vector plus C with a z Vector the resulting Vector D which will be nothing but your linear combination of v u and G okay so that will be the resulting that will be the linear combination so let's see more of the example to get comfortable with this so that you could get uh you could get a good feeling okay this is the linear combination Okay so so another example can be you can have a vector U you can have a vector U and you can have a vector v you can have a vector v so so what you do you it can be like this any number minus one * U Vector which is a scaler plus z b the answer whatever the resulting Vector will be will be the linear combination of these two vectors which are the given vectors okay so it can be fraction as well your it for the the the scalars can be fraction and fraction as well 51 7 by 11 it can multiply with some some some some some Vector U and 1 195 by 2 with some vector v the resulting Vector the resulting Vector the resulting Vector will be your linear combination of these two vectors which is U and which is V okay so whatever the resulting Vector is will be the linear combination of u and v Vector okay so let's take one formal example so that we we could understand this much much better okay so one formal example of linear combination say you given a u uh say you given a vector U say you given a vector u u which is which is uh which is two two dimensional Vector which is a 2x1 vector or we can say it's a column Vector minus 5 by 0 because column Vector is what what the the vector the the matjes is with only one column and over here this is we have only one column so so so so that's why it's called a column Vector so that's why we are telling it to the column Vector please see the previous video to help us understand to help you understand much more better way okay uh and you have a vector and you have a vector v which is 02 okay so you so you given a vector u and v okay this is also a column Vector this this is also a column Vector so what you want to do is to take out the linear combination of these two vector and and and the linear combination can be uh we can multiply this this this is this uh U Vector so what we can do we can multiply any scalar with this U Vector plus any scalar with this V Vector we will'll be getting the linear combination of these two vectors so let's take an example so let's let's take one example you multiply 1 with 5 0 okay 5 0 plus uh you multiply you you you have a scalar one which is place of v and you have 0 by 02 okay that is your VV and the resulting Vector which will be nothing but 5x2 okay and this is the linear combination of these two vectors and you can you can you can go ahead you can try it at different different scalers and and the same will be so you triy first you can try different different scalar with two with the a 5 0 + 2 it it can be any number 02 that will be nothing but when you do do this to which is 10 and then 10 0 + 0 4 that will be nothing what equals to 10 4 so this is 104 is a linear combination of these two Vector yeah you heard me correct this is the lar combination of these two Vector as well as this is the lar combination of these two vectors you heard me correct it can be you can multiply with some scalar 4 okay with 50 0 Plus plus I think okay you can do with one uh 02 the resulting Vector whatever the resulting Vector after doing this a will be the linear combination of these two vectors you heard me correct yeah exactly so your linear combination will be is it it it can be it it can be anything okay after the whatever means you take any scaler multiply with a given Vector uh you will and add it up you will be getting a linear combination so linear combination cannot be over uh some some finite over here okay except some exceptions which are there okay so over here linear combinations are said to be a vector if there exist a scalar a b okay and then whatever the resulting Vector will be will be the linear combination of those two vectors okay do not think that linear combinations can be one one is line combination of any two Vector can be only one no it can be anything it it can be any number of a linear combination of that two Vector what you need to do simply multiply the vector with some scalar A or B whatever and add it up the resulting Vector will be your linear combination of those two vectors so again I'm writing one formal formal definition so we have already written one formal definition but let's write one definition which will give you a more idea about what we have seen so far so the so the definition States so the definition States a vector R okay so a vector r a vector a vector r a vector R is said to be the linear combination is said to be a linear combination a linear combination a linear combination a linear combination of a b C okay uh a a vector is said to be a linear combination of a vector a b and c Etc okay so a a vector R is said to be the linear combination of these given vectors A B C which in this case this was u and v in this case this this was u and v these are the given these are the vectors okay these are the given vectors so the same way a b c d these are the the given vectors okay if there exists if if there exists if there exists scalers if there exist scalers x y z Etc whatever the means whatever how whatever the number of your vector is such that such that your resulting Vector is equals to x a plus YB zc all the way around to the n so so a vector R is said to be the linear combination of these vectors of these vectors if you multiply the scalar with a given vectors respectively respectively and the then then the r is said to be the linear combination of these two vectors of these all the vectors so again I'm repeating what's the linear combination means it simply means that it simply means that the the vector R is is is is we can call it as a linear combination okay how we can call we we are given a vector we are given these vectors we are given these vectors and if there exists exists some scalar and such that in such a way that your that the resulting Vector is equals to the multi the the the r is the is the multi when you multiply a scalar with a vector and add add the add the vector the resulting Vector will be your linear combination of that uh given vectors okay so let's take one example one simple simple example is uh is let's you want to you want to say is 1x 4 so you're you're you're given a vector U so I'm just going to take take one example so that everything is um make you understandable so your your your example you you're given a vector U you're given a vector U which is 5 which is a two two dimensional vector and you given a vector v you're given a vector v you're G given a vector v which is 02 which is 02 so you want to show you want to show is is your 1x4 which is your R the vector R is the is also a linear combination is also the linear combination combination of vector U and vector v so you want to show is this Vector is the linear combination of these two Vector okay you want to show this you want to show this this is a problem so you want to show this is this the resulting which is r 1 by4 is the linear combination of these two u and v Vector is you want to show it so how you going to show it so for showing it we we will see the systems of equations solving the systems of equations later on but we can I will just give you a tool so so 1X 4 so this will be the resulting Vector so if there exists some scalar which which is 1x 5 so this is this this is my scalar times your vector 5 0 plus there exists the second scalar times the 02 so your resulting Vector is 1x4 and hence and hence this 1x4 is the linear combination of this U and of this V Vector okay so I hope that you that that you are able to understand what's I'm talking about the linear combination of these vectors I hope so okay for a linear combination of a vector U and a vector v and I have given you also the formal definition of a linear combination so so let's let's see one terminology the terminology States terminology States terminology states that terminology states that the constants or the scalers which is here 1.5 this is two so these These are called the weights of the given Vector so in we we don't call it as a scalar we we call it as a weights rather than calling the scaler so if you have seen your if if you have seen your uh your hypothesis function so you have a Theta so that's so so so that is so that is the weights weights of your vector so the same way over here we don't call it as a scalar we call it as a weight of that u and v Vector okay so I hope so that you are getting a point uh to towards linear algebra and viewing machine learning or deep learning into the view of linear algebra okay so I hope that you are understanding so let's take one example to understand the weights so for example for example for example 1 by 5 is your linear combination of vector 1 4+ 1 one when we multiply with the some weight this is called the weight so three that will be the this is the linear combination of these two vectors these two vectors okay and over here over here that 1 4 1 14 which is a vector and vector and 1 1 with weights with weights which is 2 and 3 okay so 1 by 5 is the linear combination of a vector 1 4 and 1 one with weights Min 2 and 3 we don't don't we we don't call it as a scaler we even call it as a weights of that thing okay so I hope so that you are understanding whatever I'm trying to say you over here so I'm just going to talk about one last thing if I have a time I do have a 10 minutes time so what I what what I can talk about today is is the next concept which is the span of a vector okay so I'm just just just going to just make you familiar this is this this is just very easy so the we be talking about a span of a Vector I'll just giving you a small introduction to span and in the next video if possible I can show you some some some geometric intuition of a span okay so what is a span so let me let me write it span of okay so what is span span is a set of all the possible linear combination of a given group of vectors so for example we showed you over here we showed you you can have a multiple linear combination of a given Vector u and v you can have a multiple L your combination are you getting me so you can you can you can have multiple linear L linear combination of that given vectory U and B or u and v so the same so the group of all the or the set of all the linear combination of a given group of Vector in this case u and v is the span of those vectors I hope so that you're getting me okay so let me show you within help of example or or before that I'm going to give you a formal formal definition of this span because I think I I I TR some definitions also so SP definitions gives you a clear way of thinking this so I'm going to just give you a definition this this definition of a span the definition of a span the definition of a span is the set of all the possible the set of the set of all the possible all the possible possible linear combinations I'm just just going to write linear combinations linear combinations L linear combinations of given of given group of vectors okay so group of vectors what do I mean with this that uh how the the like in in this for example you have a vector U and you have a vector v so you want to take out the linear combination so these are the group of vector to for for which you want to take out the L linear combination okay so that given group of vectors is called the span is called the span of those vectors the span of those Vector which is a group of vectors span of those vectors so we'll see see one example to help us understand is much better way so let's take one example of that the example which I'm going to take is this is not a very hard example just just going to take a simple example but given a vector U 22 and then you have and you given a vector v which is 1 1 okay so this is the two vectors which is and any any and you can take out the linear combination you can take out the linear combination where when you have 2 3 4 9 10 may you another Vector is also the same stage same size okay so but should be the same Dimension so you can take out the linear combination of this just you need to multiply with a scaler and then add it up and then you'll be getting your L linear combinations so so over here so over here so over here if you so first of all let's take out some set of linear combinations so what I can do if we can multiply this U Vector with some weight I'm not talking I'm not taking the name of scalar just for practice a good practice so we can multiply with some weight two uh 2 two which is and here I can multiply with I think one one one and you can add it up that that will be nothing but 44 going add it up I'm just being transparent so that everyone follows the same is because I think trans being transparent uh just for a sake of it's it's very very important so that the conceptual CCT Clarity uh will be very very easy for you all okay so this is the the first the first for this is the let's take an example this is your l l linear combination so uh your L linear combination is this for for example we written V okay no not V we have already already given so this is your first V your combination let's take out the second or third let's take out a second you can multiply 3 2 2 plus I'm just sticking anything 2 1 1 which will be nothing but 3 6 6 + 2 2 that nothing but 8 8 okay so this is your H which is a second L linear combination let's go on taking the third so this which is the last one for us 4 2 2 3 1 1 which is 8 8 + 3 3 which is nothing but 11 11 okay so this is your I which is your another Vector okay not I let's let's let's give it as okay not J as well let's give it as a key okay let's give it as K Vector okay so these three are just you can take out any you can you can take out lot more l combination you can just go ahead just multiplying with some scalar and then multiplying with some vector and then adding it up you'll be getting your linear combination of that two vectors so I'm not I'm not arguing you with that so I've just taken three linear combination so these three the five 58 5 five this is your G just taking z z h and k is the span it's a span a span of vector U and B instead of saying lot of Lear combination so you can just say okay that this these are the span of those two VOR so span if if you see geometrically speaking if you see over the it just your your V combination span hold to the space okay so please see some for some visualizations to to from three three blue one brown they give but I have given a geometric intuition that all the possible linear combination is called the is called the span of those vectors so the notation for writing this is just a span of the vectors V1 V2 V3 is written as a span of V1 B2 V3 okay just I've shown you over okay please see the notes the notes are also given to you just for your own good okay so this is this this is what I talked about a bit about span and I hope that you really really understood this let's go on a last topic of this video is Matrix Vector product okay so Matrix Vector product so what I'm going to do is uh I have already talked about Matrix Vector product but just the last thing which I'm going to just talk about so I do have time so let's talk about Matrix Vector product Matrix Vector product so so let's say you're given a vector a you're given a vector a where you have some a b c d e f g h i okay this is your uh Matrix a and then you have a scale uh then you have a vector X then you have Vector X which is X uh for example one X1 X2 and X3 okay so you want to take out the majri vector product so how do you take out so it will be simply what you do so what you do you will simply uh you will simply this is your a x which is simply nothing but uh you you take take this you take this column you take this column you take you take this column which is the column vector and you take this uh sorry row Vector you take this row vector and you take this column Vector you just multiply it or you can say you can take we'll talk about the dot product just don't worry so what we can say we take out the dot product of a row Vector of a row vector and a column vector and a colum Vector okay so what you are what you are specifically doing is taking out the dot product between between two with between a row vector and a column Vector so what does dot product mean means it is just element wise product and sum it all up okay so that will be nothing but uh that that will be a * X1 + B * X2 + C * X3 okay and then when when you add it so let me write a resulting Vector as well okay so that will be a d okay so after you multiply and add it so that's is just a DOT product of of of of two vectors of two of of a row vector and a column Vector which is this we'll talk about the we'll talk in detail about the dot product and a transpose later on okay so and then you do the same D * X1 + e * X2 + f * X3 I'm going to do the same G * X3 + H * X2 plus okay this one uh I * X3 okay so you'll be getting e f so whatever the answer is and this is your final uh Matrix Vector product product okay so which you have seen in in our previous video but I'm going to relate as a linear combination so I'm just just going to do what what what I'm going to do just see over here so you have a vector a you have a vector a you have Vector a where I'm going to what I'm going to do a b c d e f g h i j k l okay and I'm I'm going to multiply this this Matrix with a vector with a vector X1 X2 X3 and X4 okay so we have this a vector and X sorry aain Matrix a and a vector X okay so what you going to do you just just going to do the same thing you to multiply ax okay so I'm going to show you how you can do how how I'm going to represent this okay so what I'm going to do is to categorize this Matrix in into column Vector different set of different set of column Vector okay so we can take this we can take this the first First Column the First Column and say this okay okay this is the so you take it a V1 okay take the second column you say this V2 take the third column you say this V3 take the fourth column you say this V4 okay so so so specifically you you you are not taking as a as a as a as as a as a DOT product or or the element wise product of row and column Vector here what you will do here what you do categorize your Matrix a into a different uh into into a set of uh column Vector which is V1 vs2 V3 and V4 okay and then when you multiply when you multiply ax ax which is nothing but what you will do what you will do you will simply do uh X1 * V1 X1 * V1 okay X1 * V1 you multiply all X1 with this a okay X1 * V1 okay and this is your scalar this is of course your scalar so let me write in small X1 * V1 okay so V1 V1 + X2 * vs2 + X3 * V3 V3 + X4 X4 X4 * V4 okay so that whatever will so this is whatever the result will be for example R will be your linear combination so just listen what I'm try what I'm trying to say you converted this now what you do you take the you take this X1 and multiply X1 * X1 * X1 * C and X2 * X2 * X2 * X3 * X3 * X3 * and X4 time so what you do you given a weight of these column vectors so the resulting Vector will be the linear combination of the column Vector a so this this R will be the linear linear combination linear combination of vector a okay of a vector uh of of of a m of a column Vector a okay of a column Vector a so so so these this result resulting Vector will be the linear combination of the column Vector a of the column Vector I just just just have read column Vector column Vector which is V V1 V2 V3 the V4 so you have seen me how I done this as is to to Showcase you in in the form of linear combination so I hope that you understood a lot from this video and I really really hope that you will uh try to try to do the uh try to mark your tendance as well because it is an LMS so try to mark it your notes are in the description on box below please feel free to assess the notes uh it is very very important to to to work from that uh uh and and also and in the next video we'll be talking about uh the the linear transformation where we'll be introducing the notion of a transformation when when we multiply a two Matrix so that the the that that is th a transforming one Matrix into from one dimensional space to another another dimensional space that is a transformation which we'll talking about in the next video and then and then I hope so that we'll be able to complete the uh chapter number one in some days and then I hope uh it is it is much clear to you as well uh the next the one of the announcement that I want to give is please please please share the video and and mark your attendance in your in your quizzes okay uh uh by by going to the assignment Tab and your LMS if if you are in LMS so please go there and please please please try to try to search for some some some problem set or try to search for some resources although you don't need I talked a lot about more than enough okay for for your journey so so thanks for seeing this video I I I hope that you enjoyed this and you have taken your own notes please feel free to assess the notes on the description I'll be catching up your next video till then byebye and have a great day okay everyone welcome to this lecture on L your transformation so in this video will be is specifically talking about linear transformation in the pre previous video we talked about Matrix Vector product or or or in or a linear combination which which was the very fundamental concept and we also talked about span of a vectors now in this video we'll be talking about linear transformation one the most amazing concept or the beauty of algebra or linear algebra which you will ever see and also this this sets a very Foundation of your of your algebra skills or after study as of now okay and and it is used extensively in the field of deep learning uh when when you read research papers or or when when you staring some algorithm so if you want to understand by the point of view of linear algebra then then I think uh linear transformation is one of the best thing uh to study and and this is a compulsory topic to study as the most most most concept is related to this but you may think hey you just transformation so can you just Define what a transformation is I just want to you to search on Google what a transformation means and then put that in a comment box please give the time stamp so that I could I could know okay you you're here okay so please go on YouTube try to search about transformation and then come back okay so transformation like like just transform something or or do something to that function or or if you know about function so linear transformation can be thought of as a functions okay as the new name given when when we deal with in lanar algebra okay so lanar transformation is nothing or can be just thought of as a functions can be thought of thought of thought of as a functions can be thought of as a functions why I'm telling this in in functions what you do you give some input value you give some in input value and you want your F and you want your F to map this input value to the output value y okay so this is this is this is what the L transformation is doing linear transformation take some some some some some Vector as an input maybe two two dimensional Vector which is two dimensional Vector it wants a function it wants a function T that maps from n dimensional to M dimensional Vector okay this is the definition of linear transformation again let's will see see some of the definitions to help us more clear what actually linear transformation means but in but but in but in big picture uh linear transformation can be thought of as a functions like it takes some some some some sort of vectors or vectors and transforms from one di to n dimensional Vector to another dimensional vector or a different space in that uh plane okay so this is the this is the basic thing which you need to study about so u l transformation can be thought of as a function that takes some some some some vectors or or just transforms that just transforms this Vector from n dimensional space to M dimensional space and that can only be possible with a t which is a function T so the functions are the one which we take some value and Maps input and input values to Output values but in transformation we take we transforms xn means n dimensional Vector to M dimensional Vector okay so that's a linear transformation with you the definition so let's let's let's start with an example so that we could understand it's much much much much more better way okay so just I'm going to write a definition and what in what we do in a case of functions and what we do in a case of uh linear transformation so in functions we take some values we take some values we take some values input values and we map our input values and we map our input values input values to Output values okay so to make a function f that take some Val Val and output the square of X which is Parabola if if you plot it out okay then that in in case of linear transformation we what we do we make a function T we make a function T we make a function T we make a function T that takes the transforms the transforms from from one vector space transform the vector the transform the vector uh from from RN from RN and this is the RN from one from n dimensional into a vector into a vector to RM okay so it just transforms one one one vector from one one vector space to another Vector space okay so this is the basic thing which you need to which which will which will see I just prove prove you out this equation so why it why it seems to be legit so let's start with with an example so that I could just prove you that what whatever I'm telling is correct okay so let's let's take one example let's take one example say you have a you you if for example if you multiply example if we example will be say you multiply your M by n Matrix so you have an M by n Matrix you have your M by n Matrix this is your favorite Matrix you have your m m byn Matrix and what you want to do is simply multiply with a column Vector which is n * 1 which is a column Vector which is n * 1 so we'll just multiply this this Matrix with a column Vector n * 1 so let's let's multiply it out with the column the column Vector n * 1 okay so here it has only one column and the resulting Vector what we are specifically doing we we are taking we are multiplying our Matrix with a vector okay and then that that will be nothing but your n by one column Vector M by m * 1 column Vector okay m m * 1 column Vector which is your which is resulting Vector resulting Vector that that will the resulting column Vector resulting column Vector okay so so what so what it does so what it does it take it it it it took your it took your um just is to took or or or in other words we see over here that an N M * n Matrix that an M and M * n Matrix transforms an n * 1 Vector into an n M * 1 resulting Vector which is another space okay so using this Matrix we transform this Vector into different Vector space like this okay so for example let's see some some example to make sense here we are taking the taking the the the the the Matrix Vector product which we have already seen in our previous videos so let's consider consider this Matrix a let's consider this Matrix a as we as a 3X3 Matrix so 1 2 0 and 2 1 0 which is nothing but 3x three Matrix okay now I want to show you want to show show you want to show that by matrix multiplication by Matrix Matrix Matrix Vector multiplication or that matrix multiplication matrix by matrix multiplication by matrix multiplication you want to show by matrix multiplication a transforms this this Matrix a transforms transforms transforms Vector n r R3 vector and R3 mean is which is the which is the column Vector which is which is three threedimensional Vector like this have Vector which is a three dimensional x y z which is from R3 from from in from R3 to R2 or to R2 okay into into a into into a vector into Vector in R2 R2 so you just you using a you want to transform this Vector X X you can transform the vector X and then that will into into an R2 which is nothing but your X and Y one two two dimensional rather than being a three dimensional that's that's when we call linear transformation of a matrix okay so let's see so with with an example you have a you have a vector so so R3 so over here R3 R3 are a vector of a size is a vector of a size 3x1 which is a which is the 3x1 threedimensional vector while Vector R2 R2 which you want to transform you you want to show is 2x 3 2 * 3 which is the two sorry uh 2 * it's it's 2 * 1 it's two dimensional Vector so it's trans it's using the a you want to transform your your your your vector means you using a or or a transform you just show that a transforms the vector means from R3 in R3 into a vector R2 okay which you want to show up okay so when you do this when you do this so this this this is of size 2x1 which is which is your uh which is your row Vector I I think it's column Vector column vector and then you if if you multiply a which is your 2x3 Matrix which is a true two okay it's 2x3 okay it's 2x3 matrix by a 3x1 vector by a 3x1 vector by a 3x1 vector the resulting Vector will nothing but 2x one so you just showed using the what you do using a you multiply this a with uh which you want to show means R3 and then the resulting Vector which you can see that you showed okay using a you transforms the vector in R3 which is uh three which is this one into a vector R2 which is 2 2 okay or or or a which is a twodimensional Vector okay so that that is what it is telling so let's see one of one of one of one of the example just to numerically show you so so 1 2 0 2 1 0 and and what you and and you have this metrix a and you want uh um and you and and and you have a threedimensional vector XYZ and you and this is an A and this is a vector X and you want to show you that a transforms of in a trans means uh what do you see the a transforms and and a matrix which is from R3 into an R2 okay using a you want to transform R from R3 R3 into R2 so that will be nothing but x + 2 y and zero of course we don't write it out and and of and and 2x + y okay and that and then it it will be after after you add it up add it up it will be either A and B which is your R2 okay so that is the following that what you done you simply transform your f one one one vector space to another Vector space using a function a or or using a which is your Matrix okay so let's let's let's define it out so what you done what you done you made a function T the transform F and and from from n dimensional to M dimensional means a function T transform the vector M transform the vector RN into a function a function T which transform from RN to RM which another dimensional space got it the linear transformation should satisfy your two constraints the two constraints are the first constraint the transformation t x + y it would be it would be is equals to the TX plus Ty y transformation of X Plus trans transformation of Y and then your trans transformation and then this this is scalar a and this is a vector X and then it's should be and then then it should be a uh a and transformation of X so these are the two conditions which you need to satisfy okay uh these are the two basic conditions which you will ever see okay but but the more form formula which I which I could State over here is linear transformation is the is the the function that transforms your Vector from onedimensional space from RM to RN okay that is your linear transformation of your vectors or Matrix or of of of of of a vector okay so um one one theorem is there one theorem is there the theorem States uh your let T be our let let T be a function or transformation that transform from one vectors RN to RM um which is the transformation of your transformation of X which transforms RN to RM okay so I'm just just just going to write the theorem which I'm not going to prove rigorously but you can prove it you can prove it t equals to R to make a function T you want to make a function T to transform RM to R RM okay uh be a transformation defined by the trans transformation is defined by T of X okay trans you you give uh you give one vector which is of n dimensional and just what it will do using a which is a matrix just transform that Vector means the Matrix Vector product so I just showed you that a matrix Vector product is a linear transformation okay so what you use if even you multiply to u a vector with the Matrix that that that will just give you the linear transformation just it should satisfy the conditions which are listed over here the geometric understanding is also so not it's is very very easy you can you can consider watching three blue one one Brown videos for this I hope that will make more sense there okay so that was a short video On LAN transformation about fth 15 minutes and I really really hope that that you like this video uh in the next video we'll be talking about transpose of AMS and uh and and and and and and and uh uh dot product which which which which is one of the most important concept so let's get on to the next video okay everyone so today we'll be talking about transpose and a DOT product of a matrix or a vector so we we we'll be talking about that because in the video of linear combination I have taken one example of Matrix Vector product and I showed you how you can represent that Matrix Vector product as a DOT product between the column vector and a row Vector so we'll be talk talking about what does it exactly means uh what is a DOT product and a transpose of a matrix so these are again two most important concept which you will ever see in your journey of linear algebra again it's just one of the basic concept which is very very easy to understand but still it's is very very uh good to know about these things which gives you an extra tools to work efficiently uh and and your deep deep learning problem or machine learning problem or or or other stuffs okay so let's get started so so the what is a transpose of a matrix so I'm going to start with a transpose of a matrix what is a transpose of a matrix so the transpose of a matrix is a kind of operator which flips over the diagonal which flips over the diagonal okay or make all the rows or make all the rows uh for example if I could show you the the the visualization so for example you have uh you want to take you have a column vector or row Vector like this 1 2 so it's if the diagonal is this one the diagonal is this one so it simply flips it okay so it simply flips it then it would be if you take all the transpose of this so it will be 1 2 so what it does it flips over the diagonal for example let's let's take one one more let's take one more let's take one more you have 1 2 3 4 which is a 2X two Matrix now if you take all the transpose of this Matrix so what you do you have this diagonal you have this diagonal you have this diagonal so if you flip over this diagonal if you flip this over the diagonal if you flip this over the diagonal it would be nothing but one if you flip this over a diagonal if you slip flip it there 1 3 and 2 4 okay and two four so what you done you simply flip it and then above going down and down going above so that is what it is trying to tell or or in other words what you can interpret is you make every row or sorry every column as a row and you make every column as a row okay so that you can that you can expect Ed so for example you have another so so if you have another Matrix let's let's take an example that is 6 4 32 and you apply the transpose onto this Matrix so what will be the output so the output will be what you do you take this uh you take this um or you say the row sorry the column or the column vector and make it a row Vector like this make it a row of row Vector six and three and you take this another you make this four and two or other wasse what you can interpret is you flip over the diagonal you flip over the diagonal you make this three above and you make this four down okay so what you specifically doing is to flipping over the diagonal like this okay so you will get the same result as you are doing so it's just not a big deal to understand these things is very very easy to understand okay so I hope that that that you are able to understand what the transpose of a matrix is so let's try a formal definition let's write a formal definition of your transpose of a matrix so the transpose of a matrix the transpose the transpose transpose of a matrix transpose of a matrix is an is a type of operator or operator is a Operator Operator which flips which flips over the diagonal over the diagonal over the diagonal okay so this is the transpose of a matrix so what is does is it the definition states that it is it just flip over the diagonal or to the main diagonal to obtain the a transpose so for example you are so for example you are given a vector a so what you do what you do you reflect a you reflect a you reflect a over its main diagonal to obtain the a transpose or it is just a tech technical verse to flip or reflect but specifically what is doing making the column Vector as a row vector or and and a row Vector as a column Vector that's it okay okay your visce Versa it can be anything so making a colum Vector to a row Vector that's it okay so that is what it is telling and a row Vector to a column Vector whatever whatever seems good to you so a transpose just exactly doing the that okay so for example for for example you want to take you have your Matrix a okay you want to take out a transpose you want to take out a transpose where it either presents your row and J represents your column so now if you after this after applying the transpose at this Matrix now your will be Aji now your column represents your rows and uh rows represents your column again again this is this is very easy to interpret so you have this 2 two 2 two and you have this a matrix what you what what you do you apply the transpose on this Matrix after applying the transpose of a matrix here you are having a transpose okay and you have I which is two or I and G okay you have I and J which when you do that when when you apply the operator this will be nothing but or I could say 0 0 Let's Take This 0 0 okay so when you when you sorry we should not take this 0 0 let's take it as a let's take take it as a one let's take it as a six okay just for understanding okay so what if if you have transpose over here after applying the transpose of a matrix over here your col your your row becomes your column and column and column becomes your row or yeah so so your row becomes your column so your row is the first row becomes your column so after flipping over the diagonal so when when apply so is two two and then your second second column becomes your second row okay one and six okay so what do you specifically done you flipped over or or reflected the main diagonal or flipped the over the diagonal and then you obtain your transpose of a matrix so that is what it is telling so you can do in high dimensional spaces as well for for example you have a m s we have 64 4 9 10 11 12 13 14 15 okay so if you want to apply the transpose on this Matrix that will be nothing you take this take this and put it over there 649 and then you take this 10 11 12 and you take this 13 14 I think 15 okay so this is this this is what you are doing is flipping over the main diagonal flipping over the main diagonal okay to to to or reflect it or reflect it over the main diagonal to obtain your transpose of a matrix so we have we have done a lots of examples so we'll see one or two more and more examples to make you more sense so let's make one or more example so I just hope that you are able to make sense for actually transpose of so that is the transpose of a matrix so it is just what it is doing reflecting a over its main diagonal to obtain the a transpose that set what the transpose doing so if if you take more examples we have a one two okay if you have one two if this is a A or a okay a column uh row Vector if you transpose this a transpose that will be nothing but one two okay uh just flipping over or or or making the row as a column Vector okay the next thing can be for example you have a I want you to solve this I want you to solve this one 2 3 4 apply the transpose on this and see me what the result result would be in the comment box comment box write this answer in the comment box it will very very easy to understand uh so I could say I could see whether you're watching or not okay so that is the that is the transpose of a matrix so just just I'm going going to write out some of the points some of the points please please pause this video and write your answer of a transpose of a matrix so just I I want you to write it out okay so let's see that some some of the properties some of the properties properties of the transpose okay so you want to take out a transpose and then you take out the transpose that so tell me what it will be tell me what it will be tell me it would be nothing but a it would be nothing but equals to A you you first of all transpose it okay and then you take the transpose of that so for example you have a which is 1 by 2 okay you have 1 by two okay so what you do what you do you take the transpose of this which will be 1 2 and then you take the transpose of this which will be 1 2 so these are equals to or not these are equals to so that's why we are telling that is the one of the property of a transpose of a matrix another property of a transpose of a matrix another property of a transpose of a matrix is A + B A transpose which will be nothing but a plus b transpose is nothing but a transpose plus b transpose okay so that will be equals so you have a a 1 2 3 4 okay and you have a b and and you have a b uh 1 2 3 4 you want to add it by taking all now you want to take all the transpose of these three so what you can do you can take the transpose of you can take take all the transpose of this and that will be your answer okay so let's do this we going to take the transpose of this that will be nothing but 1 3 and 2 4 okay plus uh 1 3 and 2 4 okay which will be nothing but 1 + 1 2 3 + 3 6 2 + 2 4 4 + 4 8 okay that will be your final answer which is 2x2 matrix and this is this is what this property States you can even what you can do you can prove it you can prove it extensively you can prove it you have a you take out the transpose and then you and then what you do first of all let's do the same thing you first of all add it up so when you add it up 1 2 3 4 plus 1 2 3 4 okay when you add it up so 1 + 1 1 2 + 2 4 3 + 3 6 4 + 4 8 it is 2 4 6 8 okay that that will be your answer of this particular and then what you do you take out the transpose of this because you added it up now you take when when you when you take out the transpose it would be nothing but 2 6 48 and this is your answer so these both are equal so these both are equal so you can you can you can do ex you can do separately transpose and then add and yeah or yeah or you can or or you can do just first of all add and then take out the transpose both are equ equivalent your answer will be equivalent okay so let's see another uh let's call it another page let's make another page how do we add another page yeah let's add one one one one one one more page so another property is another another property is AB transpose AB transpose which be nothing but equals to B transpose and a transpose okay so you have a let's say let's for the sake of an example let's take a vector 1 2 1 2 and then you take a and you take a v v Vector B Vector you take a b Vector which is 22 okay and then what you want to do you want to take out the transpose of this okay so let's first of all do this so one so that would be 1 * 2 1 1 * 2 which is which would be nothing but 2 2 * 2 which is 4 okay and then what you do you take out the transpose of this so when you when you take out the transpose of this that that will be 24 that will be 24 which is a column Vector okay so that will be your first understand this is your first now let's let's check for equivalent for this so you have B so which is b 2 2 if you if you take the transpose of this which will be nothing but 2 two okay and then you and and then what do you do you first of all do this 1 2 okay which after taking the transpose of this that that will be 1 2 and then when you multiply it out that will be nothing but 2 4 2 4 which which is both equivalent so so we have proved this we have proved this which we have proved this let's fourth let's go on Fourth property the fourth property is you have scalar C and you have a matrix a when you take the transpose of it that will be nothing but C A transpose okay what you can do you can first of all rather than after multiplying and then taking the transpose you can first take out the transpose and then multiply by the C both will be same okay uh fifth the fifth you can you can actually verify this you can actually verify this is not a big deal okay just the way I'm doing okay so you to take out the determinant of a transpose that will be nothing but determinant of a and if you if if you don't know about this please ignore which we will be studying this extensively in our VAR okay you can ignore this the determinant is is just the area of the parallelogram so you can easily ignore this as of now okay sixth one the sixth one is the last one which I'm talking about a transpose minus one okay uh 12 the^ of1 a one transpose so these are equivalent okay so you take the transpose and then and then inverse it first of all you inverse it and then take out a transpose both will be equivalent okay so these are some of the some of the most uh used properties in your transpose and I hope that you that you are able to understand this it's not a big deal to understand okay these are the transpose which we have talked about let's go on to the dot product to understand much better so let's let's let's talk about a bit about dot product so what is dot product dot product what is do what it do what it do it do element element wise product element wise product and sum it all up that's it that's what the dot product is doing is to do element wise product and add a summ that's what the dot product is doing so for an example so for example the dot dot product so the so for example let's let's let's take for the sake of an example you have a vector a where you which is your which is your row Vector so A1 A2 all the way around to the a n all the all the way around to the a n and you have a b Vector B row row Vector which is B1 B2 all the way around to the BN okay so this is your two two vectors now what you need to do if if you want to take out the dot product between these two Vector if you want to take out the dot product between these two vectors so how do you take out so what you you simply add a submiss so you take out the a DOT you write dot b is nothing but equals to I = to 1 all the way around to the n a i b i so what it will do first of all a a A1 * B1 + A2 * B2 + A3 * B3 plus all the way around to the a n * BN and your final output will be one is scaler C which is your dot product between these two row Vector okay so that is the the particular the the algebraic definition so this is the algebraic definition of your dot product and or or or or in other words what you can tell is the dot dot product between two vectors is nothing but a b transpose the dot product the product between A and B transpose that that is your algebraic definition or this is your formal definition of your dot product product so for example for example you have this and you have another Vector like this your output will be 8 a b c d e f your output when when you take out the dot product between these two A+ d a * D + B * e + C * F and your output will be a scalar okay so if you have seen our Matrix Vector product Matrix Vector so we have we were having we were having so let's let's see which we have seen already in our previous videos so let's say let's say let's say of for for the sake of an example you have a b c d e f g h i okay and you have a vector which is X1 X2 and X3 you want to take out the product between these two so what you do you categorize this into a different categorize this into a different what do you say uh the the the column vector or sorry row Vector yeah column Vector V1 V2 V3 then what you do you take out the dot product you take out the dot product between V1 and a vector X so when you take out the dot product between a column Vector with uh with a column Vector so when you take out the dot product between these two that will be your answer which you have already seen in in our previous videos okay so I I don't think that we should uh that we should care about this so I hope that you are able to make sense of these things and please feel free to review the previous video on L linear combination which I talked in detail about these things okay so this is this is what the dot product is simply say simply take off take take out the element wise product and sum it all up okay and that will be your simple scalar okay so that is what the dot product means and if if you have seen our videos on on on hypothesis function which if if you know about hypothesis function of linear regression if we talked about hypothesis function so in hypothesis function what you were doing we were and we were taking out the dot product between our X and W we are taking out the X or a Theta we take Taking of the dot product between X and W that that was resulting in our prediction y hat okay so X was also maybe a matrix or vector so you have a matrix or a vector so a vector of X can be uh uh other met for example 2 4 6 7 and your W can be also 2 4 6 7 whatever these are the weights of this feature and what you do you take out you take sorry it's not matrix it's a vector it's a vector do product so you simply multiply it up you simply multiply it up and then what do you do you simply add it up and that will be one scaler which is your answer for for example 2 * 2 + 4 * 4 + 6 * 6 + 7 * 7 and then after doing plus all those stuff then you'll be getting your answer C which is an answer of this particular question okay I hope that you are able to make sense out of it so we have seen our algebra definition of a DOT product now it's time for seeing the geometric definition to help you more make more sense of your dot product of two vectors okay so let's see let's see of that so let's see uh the do product let's see uh let's take let's take an example you want to take out the dot product take out the dot product between two vectors between two vectors which is Vector a and Vector B which is geometrically speaking I'm going to I'm going to talk about geometrically now I'm going to talk about geometrically so for the sake of an example understand let's take an example that you have a vector like this so sorry it's bad you have like this and you have this okay so this is your vector a this is actually Vector a and this is actually vector v and just one thing if you're a calcul student there is a small fun quiz is it continuous is it continuous function we have a function let's take an example that is a function okay is it a continuous function um if is it differentiable if it is continuous function if is it differentiable that is your question okay so please feel free to put in comment just for just for those who are calc student just tell me just ignore this A and B just say uh just say this this is a function and then just tell me it is a continuous and if if it is then if it is differentiable or not okay this is this is your question to ask answer but the one who is studying Le your algebra please filter stick me with this okay kindly ignore the question which I told you cool so the angle between these two Vector the angle between these two Vector is nothing but the angle between is 59.5 De okay so that is the angle between these two Vector okay so this is the angle between these two Vector so you want to take out the dot product between Vector a and Vector B so taking of the dot product between Ang Vector a and Vector B which which will be nothing but it should be nothing but I would say uh it should be nothing but Norm of a norm of a times the norm of B the norm of B time cosine of theta cosine of theta so Theta the angle between them is Theta so the norm of a so for example let's assume the the length of a is uh 10 okay length of a is 10 and your length of B is 13 so here your vector a is nothing but 68 and when you take out the length is 10 using the pythagore theorem Pythagoras Theorem and then uh the vector v is 5 and 12 when you take out using the Pythagoras Theorem that will be or or the or the norm of a vector when you take the norm of a vector that would be 13 okay so the the the length of these I have already told you okay that is 10 and 13 and when you multiply with a cosine of 59.5 okay so then you'll be getting then what you then what you will get 10 * 13 * 0.575 and then when you multiply that will 65.9 whatever and then it is approximately 66 if you want to uh what do you say take out now if now we got 66 now if you want to take out the algebraic the algebraic definition States 6 8 and 5 12 when you do this 6 + 5 11 8 + 12 20 8 + 12 20 when you add this so sorry uh we are actually taking we are actually taking all the okay that's 6 6 * 5 it should be 6 * 5 why I'm doing 6 6 * 5 sorry it's 5 yeah 6 6 * it's 6 it's not 6 it's 6 okay so when you do this 6 6 * 5 and + 8 * 12 6 * 5 + 8 * 12 and you will get 3 + 96 which will be 66 and this this is equivalent to this and you can also do with this this this one with a high dimensional spaces okay so I hope that that that you are able to make sense out of it and I also hope that uh you you are able to understand a little bit about this okay so that is the dot product between these two Vector just you need to understand the numeric understanding of dot product that element wise product and add it all up that's it okay so I hope that you are able to make sense out of it and I also hope that that you are able to understand everything this was the dot dot product between these two vectors and a transpose of vectors and a matrices and I also hope that that till now you're you're able to understand most of it out of it and I also hope that uh you will utilize this resource and share this resource to everyone that motivates me to work on this content s and so in the next video we'll be talking about some of the types of mates and then and then we'll talk about rank Trace operators determinant I Val igen vectors and solving the systems of equations and then our L linear algebra will be done so I hope that you like this video I'll be catching up your next video till then byebye hey everyone welcome to this next lecture on linear algebra and M 2 and I really really hope that you are enjoying this course first of all I want to thanks thanks you and congratulate you as well that you had first you had completed your first week and I'm I'm very much happy to see so much of enthusiastic students who are watching these lectures without any kind of problems and they're able to understand and leaving their great feedback in the comment box and I'm seeing the watching hours increased so I would like to thank it's giving me a lot more motivation to make these such videos for free as well as um I would just salute you for your consistency and I would also salute for you m utilizing these kind of materials uh who are who are for free and one thing which I wanted to say that we recently in yesterday we uh we we we released our first homework assignment of the previous week which is the the homework assignment consist of the questions from the five lectures previous five lecture lecture 1 to five that is your first week lectures so basically in that we included the homework homework assignments all the questions from the topics which are already taught okay so if you go and see and I and and I would like to thank vayak Vishnu who has contributed 70% of prepar preparation of these questions who is one of the teaching assistants of our uh of our CS M2 so I would like to thank you thank him and I would also like you to thank him on the Discord server or whenever the comment box thanks vayak Bish so it it would motivate him as well he's doing the community work for free so so let's so here is the pro programming assignment to sorry not programming assignments homework assignment where you're getting around 32 questions and these questions are covering from very Basics to a conceptual understanding of the particular subject having in mind to have a good practice of yourself of the topics which are already taught so you may think hey are you you're doing this stuff the reason why I'm I'm making you practice these stuff is the reason one is mainly when you go in deep learning to have a conceptual understanding of what are vectors and how it is performing computations and what are the resulting Vector size and etc etc etc so it will help you to to to to practice a lot and it would also help you to understand the conceptual understanding or on the very depth understanding of these vectors and and and we we also seen some matrices and then we are performing something and then uh I also taught you about linear combinations xx and 3 contains of linear combination where we are talking about various stops over here and the these These are the questions which are very very very very nice questions which are prepared by vayak Vishnu and as well as I had also added some questions over here which are also related to your deep deep learning context and then you finally have a transformation and this this this is also a great amaz amazing uh uh the questions which are there and it will help you in deep deep Learning Journey that how actually the linear transformation works and behind that and then the we we we talked about transposing the dot product of two matrices or vectors okay so that is the specific thing and then we we ask you to verify this property so I would definitely ask you to visit these things it will it Sol it assignment upload it in your LMS learning management system if you have enrolled into that it's absolutely free for everyone please please see the student handbook in the description down box below and go over there and into the LMS and and Summit your homework assignment and then you'll be getting the detailed feedback on what questions youve done wrong and what question you haven't done wrong okay so let's get started with this video so the title of the video you might have already imagined is the types of a mates types of mates so what are the types of matrices that that that we will study and and and some of the types of matrices are maybe not come in your journey of deep deep learning but I would say ke whenever you're studying the something let's study full of that okay so do not let's let's let's not study the partial stuff so let's study full but most of the thing which I'm going to teach is is being used frequently not too much frequently but it's being used sometimes me when when you talk with some great mathematicians or a deep learning Engineers to take these kind of words so it so it should not might confuse you so that's a VA I asked about so the types of matrices so the T first types of matrices which you already know about in other words like row Vector which is something called as row matrices okay or a row Matrix a row so let me add one thing over here row row Matrix row Matrix okay so what is row Matrix so can you define what is what is a row Vector can you just Define it so the row Vector is the is the is the Matrix which have only one row so the same way row Matrix are the one which has only one row so it you you can say just a row Vector uh yeah so the matrices which have only which have only one one row is called the row Matrix so for example for example the example can be 1 2 3 okay so this is the first this is your row Matrix okay so because it has because it it only have only one row so we can mathematically we can we can write that a is equal this is a matrix where a i g where we have a m * n Matrix where M denotes the number of rows and N then denotes the number of columns in this you have m equals to 1 you have m equal to 1 then it is called as a row Matrix so what is a row Matrix row Matrix is a one which has only one row let's let's talk about second second kind of Matrix which is column Matrix column column Matrix so sorry for in in on the eve of diali many the people are just busting up the crackers in India so yeah don't no no problem in that so what is a column Matrix so column Matrix which have only one column so uh and you have you have heard about column Vector so the same way we have column Matrix which only have only one column and these are these are used very frequently in the in the era of deep learning and and and it is very precise to use these names in deep learning to have to to follow the mathematical conventions ra rather than saying it is a it is a it is a call this the shape either shape you can just say that okay it's is a row Matrix or it is a column Matrix or it is a row vector or it is a column Vector okay so here you have a matrix a where you have a matrix a where you where you have M * n which is a size and where the M can be anything you can be any number of rows but you have only one column okay so here here n n should be equals to one so you should remove this and write one to be considered this as a column Matrix okay the next kind of Matrix we should talk about is zero or null Matrix so as you have already uh imagined about this zero all n Matrix and these are very very easy kind of remembering it's not a I'm not teaching teaching any Rockets science is very very easy to understand so so if in all the matrices or all all the elements into that matrices are zero okay so all the all the elements all the elements in the matrices in the matrices are Zer then that Matrix is called zero Matrix okay so for example you have a where you have 0 0 0 where 0 0 0 0 0 0 where you have a 3X3 Matrix and this is called a zero Matrix or sometimes you call it as a 3X3 null Matrix okay so when someone tell you hey can can you can you just tell what types of Matrix this is okay this is a zero Matrix okay when someone ask you hey you're given a null Matrix what what happened when you multiply this new Matrix with another Matrix where the Matrix satisfy all the Mator multiplication property or Dimension property so you you will say okay uh you will say okay what is a null Matrix so null Matrix are nothing but a zero Matrix okay so that is just a zero Matrix which which is given another name which is called null Matrix then the in in that you have all the elements to be zero okay the next is the next is your favorite single ton Matrix okay so in in in Java one of my friend was uh taking a single turn double turn so in the same way we have single turn matrices okay so single single turn matrices so so in single ter matrices your all the matrices are are or or you say you have only one element into that Matrix okay not all the matri you have total of one element in that Matrix okay so that's why we call it as a only one element only one element in the Matrix in The Matrix and so sorry I'm not too much of creative I don't follow the rules of changing the color and then writing it out I should develop that uh thing so let's so let's use different different color then so the fifth one is the fifth one is horizontal Matrix so let's give some examples of this because I I I I I haven't given example of this which is two then it can be one then it can be three these are the for example a is a matrix where we have this is a single turn m matrices Matrix etc etc etc so these are called the single T Matrix you may have St single ton in in your sets or discret mathematics if you have if you have take taken the course on discret mathematics so I would ask you to do not take the course but yeah remember remember the single T either it is not used too much but yeah you you should know the you should know what a single T because when someone ask you you should be able to answer it horizontal Matrix horizontal Matrix that is a that is a good deal so horizontal measor so C and Define if anyone has taken the linear algebra class please feel free to go down in the description box below please so no description it's comment okay so please feel free to go in comment box please write what is a horizontal Matrix and and it's very very easy it's again very very easy so for example so for example uh for example here you have 1 2 3 4 okay and then you have uh and then you have your favorite and then you have uh 6 9 8 2 so I'm going to consider this Matrix as a horizontal horizontal Matrix you may ask why you should consider this as a horizont horizontal Matrix so just tell me the size size of the Matrix is the size size of the Matrix is what uh 2 by 4 two uh rows and four columns and here the The Columns is greater than rows so that's why we that that is a horizontal Matrix so whoever Matrix where the number of a columns is greater than the number of rows then that's called the horizontal Matrix got it so that is the horizontal Matrix where your number of rows Sor not rows number of number of columns is greater than the number of her rows so that that that is one of the example of a horizontal Matrix now let's see some more examples some more uh some more Matrix types which is something called as vertical Matrix so can you tell me what is vertical Matrix just Define me what is a vertical Matrix so let's make a matrix let's make a matrix let's let's let's make a matrix where you have 1 2 3 4 5 6 7 8 9 10 11 12 okay so this is your this is I'm going to consider this as a vertical Matrix now tell me why this is a vertical Matrix the reason why is a vertical Matrix so let's let's count the size so we have a total of 4x3 Matrix and here your number of rows is great greater than number of columns so that's why this is a vertical Matrix in horizontal your number of columns should be greater than uh greater than number of rows to be called as a horizontal Matrix but in vertical Matrix totally opposite of that here your number of rows should be greater than your number of columns okay to be called as to to be said as a vertical Matrix or in formal definition which is Tau in a school is a a matrix is said to be a vertical Matrix if and only if its number of her rows is greater than the number of her columns it's it's it started my school I just I I I just want to thank my school to teach me these definitions no not exactly definitions of vertical Matrix but yeah the definition format or template to tell is that this is said to be this because this okay so I follow the template of my school so thanks to my school H shout out to Sunan cat okay cool the square of Matrix so what is a square Matrix I would say pay attention to this Square Matrix is used extensively whatever we'll study in the like diagonal matrix or or whatever okay like determinant or or igen vectors and IG values we are going to take this Square Matrix so what are square Matrix so let tell me what are square Matrix The Matrix which looks like square is that it yeah so so the Matrix where you're or just wait now here's here's your Matrix here's your Matrix 1 2 2 4 and here the here's your a matrix and here's your B Matrix which is 1 2 3 1 2 3 okay or let let's consider this as a let's consider let's let's cons consider this as a okay so here you have a total of 2 by two Matrix and this is a total of uh what do you say a 3X3 Matrix so here your number of rows matches with the number of columns so the square Matrix are the one where the number of rows matches with the number of columns okay so the square Matrix is which where your number of rows where your number of rows is equals to the number of columns okay so the the square Matrix is is in which your number of rows is equal to the number of columns then it is said to be a square Matrix so again my school form of definition a matrix is said to be a square Matrix if and only if it's it's it's a real number for rows should be exactly equal to the number of a columns in your Matrix okay so that is your Square mat again shout out to Sun uh just just for your information uh this these are the things which are not taught my school till now I'm in class n so till now they haven't taught this but yeah I know the form I I know I know the definition template because I and in in my school I used to study a lot more definitions so I know the definition of this they the definition is starts with this the same way uh this is said to be this because this and that so that's why we got it this so the same way I frame a square Matrix is said to be a square Matrix a matrix is said to be a square Matrix if and only if your number of rows is matched with the number of columns and so thus if it is follows then it's a square Matrix so so we we know about the square Matrix now so let's go further into understanding the the the diagonal matrix so so what is diagonal matrix what is diagonal what what is diagonal matrix can anyone tell me what a diagonal matrix is anyone try it out so all the elements except the principal diagonal or or let's start with let's start I just want to scho that guy who is bursting the crackers I don't want to see him I'm making my video why is bursting his crackers outside oh my gosh no no problem in that as well Okay cool so let's make a matrix 1 2 3 0 0 0 0 0 okay so this is called the diagonal matrix because your your your all the elements in your diagonal matrix except the prpal diagonal this is this principal diagonal and this is the principal diagonal so all the elements into that Matrix except the principal diagonal of a square Matrix so diagonal matrix should be a square Matrix because it is a 3X3 Matrix so it is a square Matrix R Zer so all the elements into that diagonal matrix of a square Matrix are zero then that is called as a diagonal matrix so let's see some more so for example you have uh Z 1 2 oh my gosh zero I think I I I I done wrong so 1 0 0 0 2 0 then 0 03 so this is oh I I I made the same thing again no problem in that oh this is left okay so that is the all the principal diagonal is your is your uh what do you say the the the nonzero and every every elements of except that is your not zero then that's called a diagonal matrix so I hope that you're a able to make sense out of it so the diagonal matrix should be a square Matrix and a square Matrix is nothing a matrix which said to be a square Matrix if and only if your number of rows match with the number of a columns and thus it is called the square Matrix because it looks like square but what is rectangular Matrix so one thing which I'm to mention rectangular rectangular Matrix so what is a rectangular Matrix here where your number of a rows does not matches with number of a columns oh my gosh there's a contradiction so that is nothing but called a regular Matrix sorry oh my gosh it's rectangular Matrix so let let me Define this from my school work so thanks thanks thanks my school sit down sit down yeah so uh what is rectangular Matrix a matrix is said to be a rectangular Matrix if and only if it's it's number of rows that's not match with the number of a columns so that's the rectangular Matrix so so the follow following example is a rectangular Matrix so maybe you may have 2 1 3 4 2 1 3 4 that is your number of rows is 2x 4 where 2 is not equals to 4 so that is the rectangular meter that looks like rectangle so that's why we have written the rectangular Matrix cool so let's go further into learning about scalar Matrix so what is scalar so first of all Define a scalar and then try to identify what is scal or Matrix please go ahead and write your answer let's give you give the guess guys U I'm just here to have a fun with you all so give a guess what do you mean by scal or mat because when I started first I given a very good guess and that was totally wrong because this this is like a scaler Matrix so I was little little bit okay scaler is just a number and scaler and these Matrix are are the are the aray of a numbers so how I can consider a scaler as ARS of a numbers that is the best assumption that I made at that point but no problem the scalar Matrix here's the here's your scalar Matrix in in front of you here's the scalar Matrix in front of you so you have 7 0 0 0 7 0 0 0 7 0 0 7 so listen so this is called scalar Matrix this is called the scalar Matrix this is called the scalar Matrix but now you will say hey I use just now you taught the diagonal matrix in the diagonal matrix you all the elements except the principal diagonal are equal or are zero then it is a diagonal matri so here also your all the elements all the elements except your principal diagonal are zero so why not be calling at as diagonal matrix so I would ask you to have a closer look at this is and tell me what you see over here so if you if you if you if you zoom in further or or if you or if you wear your sunglasses not sunglass if you wear your goggles with minus 2.5 power you will see that your diagonal matrix uh diagonal diagonals principal diagonals scalers are all equal okay so that's what make it as a scalar mates okay so what is scalar Matrix a scalar Matrix is say sorry not a scalar a matrix is said to be an scalar Matrix if and only if if it is principal if all the elements in the principal diagonal are non are zero and principal diagonal elements are should be equals to each other okay so that that is called the scalar matrices so if all the elements in the diagonal matrix okay so all the elements in the diagonal matrix and and what are diagonal matrix diagonal matrices are the matrices where the elements except the main diagonal are zero so if all the elements in the diagonal matrix are uh EX in all the all the matrices in the diagonal matrices uh are of the of of the D is is equal means the principal principal diagonal is equal then that is called the scalar Matrix so that is a scal matrix so please see the notes in description for the F the definition whatever I'm telling so you could not write it out please see the description for the notes of whatever I'm telling okay so so so so one of the so this is your first example so let's say second example second example otk 5 0 0 0 < TK 5 0 0 0un five what is this this is a scalar Matrix now now what what what what do I tell to you is to multiply with some multiply it's with with with the some Matrix okay so multi multiply with the same Matrix multiply with the same Matrix M multiply some The Matrix and then you will getting some other result some other result but I want to tell is to have a matrix like this uh where your all the diagonals are one all the diagonals are one that is your so now multiply with any Matrix just to just to make sure that is a matrix M multiplication is defined multiply with any Matrix or a vector any Matrix or or a vector you will be getting you will be getting your your your Matrix so this is this is this this this is your scaler Matrix so let's say s as as as of now and this is your any Matrix or vector v so when you multiply s * V answer will be V means exact so is it is by multiplying by one you will get exactly so please see please do and see the experiment so when you it this when you multiply this Matrix with some other Matrix or vector you will be getting it is just like multiplying this Vector this is this is one so whenever you multiply s * V means this these types of Matrix where your principal principal diagonal is one all are one then you multiply with some Matrix or vector then that then that will yield or or result to this Vector original Vector to which you multiply that scalar Matrix to okay so that is so so so scientist have seen this y result and named this as a identity Matrix name this as identity Matrix or a unit Matrix or a unit Matrix okay so when you when you multiply this identity Matrix with any Matrix that is simply by multiplying one and you will be getting a result which is V okay so you'll be getting the same result so you have you may consider this Matrix with one and if you multiply any even 10 you will be getting your 10 as output so it is same as that identity Matrix oh my gosh that that the one who's is just flying the of pollution I am really not liking that no problem again so here over here your identity Matrix are just like a m multiplication by one so please pre to this is a wi property which we have given a new name is the Matrix or the scaler Matrix here in your principal diagonals are all one then that's uh nothing but uh identity Matrix okay let's let's go on next page the next page so let's talk about some last matri with something called a triangular Matrix triangular triangular Matrix so the Triangular Matrix are of two types so a square Matrix I'm just try to Matrix so a square Matrix is said to be a triangular Matrix if the elements if the elements if the elements Ave oh my gosh my hand ratting Ave or below the principal diagonal below the principal diagonal principal diagonal are zero okay so for example uh you have the diagonal 3 4 6 1 2 3 and z z0 okay okay so this is your oh my gosh what do I made over here 3 1 2 0 4 3 0 0 6 okay so it is telling the Triangular this this is a triangular Matrix because all the elements if the elements above means Above This is this this is your principal diagonal this is your principal diagonal okay so whatever Ave if either above or below either above or below yeah here is your or okay so either above or below either above or below either above or below um to the main principal diagonal are zero then that's called a triangular Matrix so here above is non Zer but below is zero so that's how we call it as a triangular Matrix because it forms a triangle so that's why it's called a triangular Matrix and this is called the upper triangular and here here it forms the triangle so here it forms a triangular part okay so that is the upper triangle so this this where your zeros are below the main principal diagonal so that is called the upper upper triangular Matrix upper triangular Matrix and for example you have 1 0 0 2 3 0 4 5 2 and over here this is your main diagonal okay okay and above you have zero and below so that that is the uh that is the uh lower triangular Matrix that is a lower triangular because it forms a triangle triangle low and below below of the main diagonal okay so that is the lower lower triangle Matrix and upper triangular Matrix cool so I hope that you understood so just just to re recapitulate the Triangular Matrix is said to be a triangular Matrix if the elements above that principal diagonal or below the principal diagonal are zero the the the the the the elements uh the or or the what do you say if the zeros are below the principal diagonal of the Triangular Matrix then that is called the upper triangular Matrix because it forms the triangle upper of the principal diagonal and if the in in the in the Triangular Matrix to the of your principal diagonal of if your zeros are above your principal diagonal then that's nothing called as a triang a lower triangular Matrix that is of two types cool the last thing which I'm to discuss is about symmetric Matrix okay so is about symmetric matrix it's about what do you say repeat me with me symmetric Matrix symmetric who knows so you have this so you have a and when you do this so it should be foldable so that is symmetric so this this paper is symmetric okay so the same way the the the M matri can be symmetric as well the M matrices can be symmetric as well so what is symmetric Matrix so so the definition of a symmetric Matrix definition of a symmetric Matrix if your a transpose is equals to the a a is if your a transpose is equals to the a so that's where we call that as a as a as a triangle or or or a symmetric Matrix okay so it's it's it's it's called a symmetric Matrix if your a transpose is equals to A itself okay so so for example so for example you I'm just going to take you you can think of any example this is your task but I'm just just going to take a small example of uh 2 4 69 okay so 2 469 so when you add the transpose so this is your 2x2 matrix and then if you do the transpose you'll be nothing 2649 2x two 2x two okay so that is the 2x two so over here here you follow the equality of a matrix so the you if you remember the equality of a matrix if you remember the quality of a matrix of of the matrices so if if a matrix a is one equals to Matrix B if its corresponding elements if it's corresponding elements this to this this to this this to this this to this are equal and they are of same order and they are of same size okay so they are of same size but this is equals to this okay four is not equals to 6 so here this is not a symmetric Matrix okay so this is not a symmetric Matrix so your all symmetric Matrix should be should be square Matrix to be symmetric okay but not every Square Matrix can be symmetric but but you for for being symmetric your your Matrix should be squar Matrix for for being symmetric but it is but it's not guaranteed that your every Square Matrix will be symmetric but for being metric it is you have to have a square Matrix for example you have 2 2 2 2 apply the transpose on this what it would be 2 2 2 two 2 by two 2 by two this is this is correct this is correct corresponding are also correct the size is also correct that is the symmetric Matrix that is the symmetric Matrix and I hope that you understood about the concept behind symmetric Matrix so this is all so that was we had a talk on these stuff so I hope that you like this video and I also talked a lot and sorry for the crackers please find that guy and beat him as much as you can who's fing up the crackers outside so sorry I I I included Hindi but no problem okay please feel free to sco that guy not beat him because Dali is Festival of having fun but yeah please SC that because they disturb you in studying no problem uh so let's so I I I hope that you understood and please feel free to do your home homework assignments so here is the homework assignment uh the discussion for the solutions of the program programming assignment or sorry homework assignment is being released soon in the form of video so you can assist that but I will wait for two two or 3 days and then I will release one video on uh solving these homework assignments please feel free to do this and please feel and I'm not giving these notes because these notes are already available in the description down box below in the form of some uh good good hand handwriting in the description down box below please please feel free to assess thanks for seeing this video I'll be catching up in the next video till then byebye have a great day byebye hey everyone so let's get started with a new lecture on lecture number seven which is on determinant and this is one of the one of the again I would say important concept to study because in principal comat analysis or whether you uh it it it it comes a lot in your machine Learning Journey as well as well as in deep Learning Journey because it tells you how to solve or solving the linear equations or or or or if if I talk about in terms of linear transformation it just tells you how the how the how the change in area or a volume occurs okay and and determinant is nothing when you it's nothing but you just TR you just give some Matrix and then you get one number so we'll be talking about that in detail in this session uh I I think you'll you'll get a lot from this session and and you you can make your own notes or the notes is in description un boox below either it would be updated soon but yeah uh I it is it is already been made it's just sent for processing and that it will be into your description if you like this video please be sure to subscribe this channel as well as like this video and comment because YouTube algorithm knows okay this is a good video to recommend because many many other the people say uh your channel is underrated so I want you I want this channel to be rated Channel because I work a lot on this channel Okay cool so let's get start with solving uh what is determinant so we'll we'll get onto the geometric meaning soon but uh in in determinant what you do if you know about a square Matrix if you know about a square Matrix which which we talked about and and I have told that is very important Square Matrix are very important is used extensively in linear algebra to to use this term terminology so Square Matrix is nothing where your where your number of a rows is equals to the number of a columns for example uh your Matrix a is is maybe it can be 2 2 2 two okay so this is a 2X 2 where n = 2 and M = 2 so n * n Matrix where your Square Matrix is equals to where your number of rows is equals to the number of a columns okay so that is the so this is so what what you do you take your Square Matrix and determinant takes one square Matrix where the number of rows is equals to the number of colums you write determinant of uh an A and A A should be the square Matrix a should be the square Matrix and then you get one scalar or or or a number as an output when you apply the determinant function or or or when you take out the determinant of that Matrix okay so now how this is useful we will see how do we take out the scalar a just in a second numerically but but uh but when you um how how the determinant is useful this is this is one of the most important concept to know so the determinant is useful in in solving and solving linear equation and linear equation is used very very extensively solving linear equation or maybe it can be useful in in in in in in knowing okay in knowing how linear transformation and knowing how linear how linear transformation transformation change their area or the volume okay change their area transformation change their area change their area over volume or volume okay not over it's or volume and it is also and it is also useful uh in other stuffs like uh when solving some some computationally it it it it it does reduces some computer not exactly mean uh doing efficiently not exactly I would say efficiently I would say very precisely so solving the particular linear equation and is used a lot in that so that's why we take out the determinant of a matrix and that when you take out the determinant of a matrix you simply give a squar matrix root to that determinant and then after when you take out the determinant you will get one scaler okay so this is what the this is this is this is what we use and and if you if you talk about um in machine machine learning use case so in machine learning if if you know about machine learning in machine learning you have something called as dimensionality reduction method and in and in that you take out the determinant of that covariance Matrix so covariance Matrix okay so when you take out the determinant of that covariance Matrix and then you and then and and and and then go further into solving the particular problem okay so not exactly covariance yeah so you take out the termin and then you go further into uh into other stuffs like uh uh the igen vectors and igen values and they are extensively used the determinant are extensively used in the igen vectors and igen values in principal component analysis okay so I hope that this is clear why we use determinant and and and what's the determinant is now now we need to care about how do we take out the scalar value because we give a function because we just give a a square Matrix into that determinant and then we will we are going we are we are just getting a scaler as an output so how do we even do that uh so for for doing that assume that you have a matrix a you have a matrix a which is nothing but 2x two so I'm just going to write um a b c and d okay so you have a matrix a b c d which is a 2X 2 Matrix so when you take out the determinant of that Matrix a which is nothing but which is nothing but so a means you take out the product of the diagonals you take out the product of the diagonals a minus BC a D minus BC so for example you have a matrix uh 2 3 4 6 and then you want to take out the Matrix the determinant of that Matrix 2x2 matrix which is nothing but 2 * 6 2 * 6 3 3 3 * 4 3 * 4 which is nothing 6 6 2 12 3 42 that will be nothing but zero zero is the answer or determinant of this Matrix okay so the terminant of a matrix can be zero we have we don't have any conditions but yeah the determinant of this Matrix is zero okay so this is how you take out the determinant of a matrix geometrically speaking okay so one thing that I want to highlight over here let's say for for example uh what does it mean geometrically what does it mean geometrically so so let's uh let me make one more page so that I could explain you what does it mean geometrically speaking what does it mean geometrically speaking either I could just go on some website to mean to mean what is actually trying to tell so let's go on one website let's go on one website which I want to show you all is this one okay so assume that over here of over here you have let me choose my black color okay here it is so you have um a matrix a matrix a b c d okay you want to take out the determinant of this so this this is this is what you take out so for taking out the determinant you just write either in this A B C D giving a pipelines like this okay or or you write determinant of this uh a a matrix and this a matrix is either uh a b c d like this okay so this is the notation for sooning that you want to take out the determinant of this Matrix okay that pipeline that big big pipeline okay pipe uh line okay now over here your a is 1 your B is zero your C is zero and your D is one okay you want to take out the determinant of this you want to take out the determinant of this you want to take out the determinant of this so how do you take out so what does it mean geometrically speaking so geometrically what it's trying to tell is when you plot this Matrix over here first of all you take this and then you go over here so this is nothing but the determinant of a 2X two Matrix is the area of a parallelogram with the column vectors AC and BD okay so this is the the the determinant is nothing but the area of this parallelogram of this parallelogram where the column vectors are AC and BD okay so when you when you plot the 2x2 matrix which which looks like this and and and this the the the determinant which means jum Al speaking is nothing but area of that parallelogram which formed by joining everything and then and that area of that parallelogram is nothing but determinant of that Matrix okay this is what does it mean geometrically speaking uh I would ask you to watch one video on three blue one brown to see how how is shown geometrically but yeah uh the the det terminal is nothing but the area of that parallelogram whatever forms so for example you your par so let me reduce the a a bit and then let me do something with this I don't know well how it is working yeah so let me do something like this and let me increase the area okay let me increase the B okay here it is so when you have the column Vector when you have a column Vector at 0.86 and zero okay and then you have another column vector which is 0.52 and the the parallelogram is formed is nothing but your favorite the determinant okay so this is what the determinant means and you can play with it by just going to demonstration wallframe and this with this website so let's go on the 3D view so how does it look 3D so 3D is nothing but area area of that parallel Zoid okay so if you just see over here the area of the paraloid is is nothing but a determinant we'll see how to solve how how to solve this deter this determinant one okay we'll see how to solve um three for the how to take out the determinant of a 3X3 Matrix and we will also see how to take out the determinant of a n byn Matrix okay so it's a it's a bit hectic task but we will try to do it so this is this is what the geometrically means and for 2D the area of a parallelogram and for 3D area of a parallel Zoid okay which you can see from the diagrams which are shown over here so if you just if if I could zoom in I can't zoom in but yeah I can just show you this is this this is what you have your uh 3x3 Matrix and then you this is the paraloid which is formed and then when you try to take out the determinant of this is nothing but the area of this parallel Zoid okay so this is what it means and the determinant geometrically is nothing but the area of a parallelogram or parallel joid in 3D dimension okay so this is this is what you need in in a geometric intuition just just just to make sure that what the geometrical it it means okay so now let's see now one of one of the important thing which I want to show you up is is is we have seen we have seen how do we take out the determinant of a 2X two Matrix so the determinant so here is your a here's is your here is your a and you have and then you want to take out the determinant of this A B C D and I'm just writing pipe to denote okay this is a determinant so when you take when you try to take out the determinant of this so it's nothing but equals to uh uh a a minus oh my gosh it's a D minus BC that's uh then when when you take up that's a uh simple scalar which is e not exactly that not 3+ 3.71 1 it's e okay so let's let's give it any scaler which is e okay so this is this is what it means in 2x2 matrix I'm talking specifically 2x2 matrix now now let's talk about how do we take out the determinant of uh 3x3 Matrix so determinant determinant determinant of 3x3 Matrix 3x3 Matrix so how do we even approach we taking out so you have want to take out the determinant of a b c d e f g i okay so G h i is this is your Matrix this is the determinant of this Matrix okay so how do you take out how how do take a determinant of this Matrix and of course your it should be a one scalar okay it should be one scaler or a number or number okay so how do we take out the determinant so can't we do a * a * e * I and then it will not work this is this is not you can you you can just guess how do we do it just try and commment and maybe I can just see and be a bit funny in job so please be sure to write it and I will try to see what you write it okay so so let's start approaching how do we even approach this problem so what we do we simply so so what we do just just make sure that first of all we go to the a11 okay so me first element in that Matrix and then what we do we simply leave this uh column and this row and write a minor Matrix or a submatrix of that of of that uh big Matrix or you can say that we take out the minor of this Matrix how do we take out the minor of this Matrix you simply when for for example you choose this number okay so what you do you you leave this column and you leave this row and then you write uh and then what you do you take out the minor and then you take out the determiner determinant of that by multiplying by a okay so the first element is this and then you have e f h i we left this column and this row and then we write e f hi okay we want to take out the determinant of EF HR okay now what you do now what you do here is your plus sign now it will be a minus sign over here okay you go to the B you leave this column and you leave this row okay which is nothing but b and d f g i DFG because we left this column this row and this column just d f g i okay and then here is your minus then here will be plus plus uh you write C now we left this column this this this column and the first row which is which will be left the determinant of D GH okay and then we have convert now these are called a minor or a submatrix submatrix or the minor of our Matrix a these These are called the min minor these are called nothing but the minor these are nothing but called the minor minor of our Matrix of our Matrix a okay so when you try to now it is very easy a * a * uh EI now you can just apply your 2 x two a EI and FH EI minus FH okay minus b d i FH d i minus FH okay plus C and then you have DH EG okay DH minus EG okay and then you'll be left with some scalar and then you can simply do do this thing and then you simply multiply with this and then you do do some calculation and then you'll be getting your output as maybe some some scalar some scalar value okay so let's see one of one of the one of the one of the problem or or the stuff to to see how how it looks like Okay so let's let's assume that you have a a matrix or 3x3 Matrix so here's a question for you okay maybe you can try try to approach it uh the you want to take over the determinant of I'm writing this pipe that denotes that you want to take out the determinant of that uh for example 0 1 2 uh 1 2 0 uh let's let write 1 1 0 okay just a random random I'll be walking you through it so take out the determinant of this this is a 3X3 Matrix try to take out the determinant of this so how do we take out so first of all we go through the first element and then what we do we take out the minor of this Matrix so the minor so we leave this column and this row so we'll be left with zero and then we and then we write out minor and then we take out the determinant of our sub Matrix okay plus now no no no it will be not plus over here it will be minus because here is our plus minus okay one you leave this column and this row which will 1 0 1 0 okay so 1 1 0 1 0 okay and then you write + 2 and then you have uh you leave one to one one okay you leave this column and this row okay you leave this column and this row you'll be left with one 2 1 1 okay and then you do the sum and then you do the sum so and then you take and then what you do you try to take out zero 2 * 0 which is 0 0 okay Min uh 1 * 1 * 0 of course 0 and 1 * 0 0 okay plus two uh 2 okay 1 * 1 1 2 * 1 2 okay then you'll be left with of course zero then it will be done then done it will be also 1 * Z which is nothing but zero okay it'll be left it 2 * 2 2 * 2 that that will be 4 okay which will which is is your determinant of this Matrix so Min 4 is your determinant of this Matrix which you are seeing over here so sorry here is 1 2 it's not it's it's simply min1 so 2 * 2 is the determinant of this Matrix so I'll be so here you got the determinant of this Matrix which is nothing but min2 okay so this is this is how you take out the determinant of a 3X3 Matrix as well so there are there are some problem for you to work on so I'm just just going to write it out so there's one problem which which which you can approach okay so you want to take out the determinant of uh 371 4 please answer the HW please answer in the comment box it's just a quiz which you will see in your attendance as well okay so this is what the determinant of that Matrix of the 2x2 matrix or 3x3 Matrix we'll try to solve the determinant of a 3X3 Matrix using lianes formula or the rule of surus okay so which is very good formula to work on so we'll see that but before that I want to highlight some of the properties some of the properties of that properties properties of determinant Matrix of determinant of a matrix determinant of a matrix the first first one is the first one is the first one is for example you want to take out the determinant of this Matrix for example you to take out the determinant of 1 0 uh 0 1 okay so try try try to take out the determinant of this 1 * 1 which is 1 uh and then and then minus 0 okay what what it will it with one and can you identify this is an identity Matrix even if you have uh three three identity Matrix then that will be nothing but that will be nothing but one so whenever you have identity Matrix whenever you have if if if it is if it is identity Matrix if it is ENT identity Matrix identity Matrix then then then the then the then the determinant of that identity Matrix will be one okay this is this is one of the property second property if the if the rows are the same okay so for example if the rows are the same are the same for for example a a b b okay a a b b then a minus ba will be nothing but zero okay so this is another property third property is you have a scaler multiply it with some uh a and you have another scale c and b d okay so what it will be it it just makes sense r a D minus r CD or r r CB okay you can write write it down like this and then it's it's nothing it's nothing you just you just take that out of out of okay you just uh take take that as a common r a D minus BC okay so we can write this as a we can write this we can write this as a r * a b c d either we can write it now so we proved it so it is just equivalent you can write this so for it will be easily for us to solve okay so it is so it is R times as either it is same as over here so we a D minus BC so it's just equivalent to that so this is another property which you see a lot in while taking of the determinant of a matrix okay so this is these are the some of some of the properties which I want to highlight in front of you so now let's go on to the another stuff is how do we take out the determinant how do we even bother taking out the determinant determinant determinant of 3x3 Matrix so you can just say okay I'm just going to just going to take out the minor of the sub Matrix of the Matrix and then I will do that so here's another another trick which is called the rule of surus I think it's it's it's not a I would say uh okay it's a good technique but okay you can try it out but eventually I like that my Approach but yeah it is very very straightforward approach which I'm going to tell over here okay so assume that you have a matrix M that you have a matrix M Okay so a11 1 a12 a13 okay a21 a22 a23 a23 a31 a32 a33 okay so you have this 3x3 Matrix now when you wanted to take out the determinant determinant of this Matrix M so how do we even bother doing that so for for for for so you can use the rule of suus rule of suus I think that funny name he has but yeah again I'm no no want to comment on on his name he's a again a great people okay so not I'm not even a one 1% of these people so these are amazing people who give a lot to the world so I think about I'm no one to say about but yeah amazing name so what you do you take out the determinant so you want to take out the determinant of a11 a12 a13 okay so this Matrix I'm just writing this Matrix a21 a22 a23 okay a31 a32 a33 okay and then what you do you take out the first two column and write it in another format like this a11 a12 A2 1 this is a trick for solving a 3X3 Matrix a22 and a 31 okay so a31 and a32 so this is a22 okay it's say a21 okay so this is what you now you write this now what you do now what you do so what you do you you simply take out the product you simply take out the product like this the first diagonal okay so this is the diagonal so what you do a11 a 22 a33 okay a11 a22 a33 plus plus a12 a22 a23 okay A2 3 and a31 so what you do you take out the product of these three you take out the product of these three so A1 2 a uh uh 23 okay a 23 uh and a 31 okay now what you do you simply uh do this simply multiply the next next diagonally okay so plus plus a13 a21 okay I'm I'm I'm I'm doing a bit messy so let me do a31 uh if I'm not wrong a13 a a a13 a21 and A3 2 okay A a A1 3 A2 1 a32 now you are done with this now what you do now what you do you now go from bottom to top here you are going from top to bottom now you'll go from bottom to top by changing the sign now okay now you go from bottom to top so here's how you do here's how you go further okay so so the way you go is you have a31 so from here so from here a 3 1 okay and then a22 and then you go to a a13 so now you start going at this side like like this okay so a31 I'm just going to write a31 a22 a22 and then a13 a13 okay and then what you do and then plus no uh you you minus because you change you go from bottom to top so here you minus it now now you go at this one now you do this and then a32 okay this one this one and this one a32 * a23 yeah if I'm it's a it's a a23 if I'm not wrong yeah a23 and a a11 a11 okay now minus now this is done now you go at last one which is this one a33 a21 a12 okay and here's how you take out the determinant of a matrix using suus rule okay or a rule of suus okay so and then you'll be getting after after doing this all those stuffs you can just cancel it out something if it is so you just you just do do the computation then here's your Matrix and this is just a scalar number or other stuffs so here's the rule of suru so here's how you do you do simply you do you do write the first two column uh at at the side so that it could be easily so uh so what you do you simply take of the product from top to bottom for the first three and then you take out the bottom to top for the second three starting from the last okay so here's here's here's what the full the rule of sarus means here here's how you take out the determinant of that Matrix like this okay so now I'm going to talk about is uh you can see the Wikipedia Pages for a libanese rule because they write a very very kind of libanese stuff so you can just go there and see more see more about this rule okay so the next thing which I'm going to talk about is the next thing which I'm going to talk about is how do we take out the determinant how do we take out even B of taking out the determinant of n by n Matrix the determinant of n by n Matrix so how do we even take out that and how do we even bother taking out that okay so here's so I'm just going to write the N by n Matrix as I'm just going to Rite the N by n Matrix or let's start with a particular example let's start with a particular example so it would to totally make sense okay so let's let's start with a particular example and then at last we'll just write a definition and then we'll end this video okay the example is bit long so I'm just going to maintain my handwriting so the example is you want to take out the determinant you want to take out the determinant of a 4x4 Matrix 1 2 3 oh my gosh three 4 okay 6 6 6 9 2 1 and then you have a 4 9 2 1 and then you have a 0 1 1 one okay so here's here's your determinant of this Matrix so to take out the determinant of this Matrix so how do we even approach taking out the determinant of this Matrix so how do we take out the determinant of this so for taking out the determinant of this so for taking out the determinant of this for for taking out the determinant of this you take out you take out you first of all take a the minor or the submatrix of this okay so you you go to the First Column first element and then you leave this column and this row and then write the sub Matrix so you just one and then you take out the determinant of 9 2 1 9 21 1 1 1 okay this is plus sign so it will be minus sign now you go at this uh take take out the sub Matrix leaving this row this column and this row so it would be two first of all you take product it so you multiply with that 2 2 * uh the determinant of 6 2 1 6 2 1 42 1 and 011 okay and then you uh change the Sign Plus and then go through with three and then you leave this column and this row so it will be nothing but uh three and then you have 621 I also just write okay 66 6 91 I I just leave it so I'm three 691 691 uh 4 4 91 4 91 and 01 1 okay 01 1 now the last one is there four okay so there is four and then you take out the terminant of leaving all the all the uh column one and then row 692 692 492 and uh okay I think it's wrong 492 and 0 1 1 okay so these are the sub Matrix of that Matrix let's name it as an n M okay so this is a matrix M and then you have to take a determinat of that Matrix M so here's the 4 4x4 now you do this now you have this now what you do now here you convert it to 3x3 determinant now what you do you convert that to a 2x2 here's how you do so you you don't want to use a suus rule because I I eventually don't like that rule it's very hectic rule sometimes it maybe cause you error but no problem in that so here's how you do it so first of all what you do so first of all what you do you you simply uh multiply uh one okay you simply go ahead and take take your uh one as a so if you can see I just want to take that one as an uh uh this one and then what I and then I go and approaching this so here is your nine so first first of all go at this element take out nine you want to take out the sub Matrix of this Matrix so nine and then you take the termin of 2 1 1 1 so what how this came 2 1 uh you leave this this row and this column 21 1 1 okay now you simply change the sign minus okay you make sure that t you're doing only doing for this you're only doing for this we'll come to this later on but we are only doing for for this a21 okay minus now now we go to this two now we go this two we leave this column and this row which is 91 1 1 okay so which is a what happened yeah so which is nothing but uh what do you say uh two because here is our two leaving this row this this this column and this row 9111 okay uh did the determinant of 91 1 1 okay and then what you do plus now you change the sign and then you go at last 1 leaving this 9 to11 okay so the one and the 921 1 okay so you take out that okay now this was plus now you make it minus okay now here is your two so I will take that outside I will take take that outside okay and then I will just go ahead into solving this so you take this take this as a now you take out the minor of this Matrix or the sub Matrix of this Matrix so here's how you do it so you simply add it minus so here is minus 6 uh 21 1 1 so here here's how you go with this you ignore this column and this row 211 1 now you go to this you ignore this 41 0 41 0 1 and then you go over here ignore this 42 01 okay so this is how I'm I'm I'm going to write minus 2 okay because you go over here 2 over minus 2 CH changing the sign take out the determinant of 4 1 0 1 4 1 01 okay and then you simply plus um now you change the sign you go one go to go to one 42 0 1 42 0 1 uh + 1 uh 4 2 0 1 okay and then what you do and oh my gosh yeah so then what do you do now you now you converted that 3x3 Matrix for this one and for this one now you go to this one okay by changing the sign plus plus and then you go and then you write separate three now you write separate three and then you take out the first one six okay so you leave this SC column and this row which is nothing but uh six and then 9111 which is the sum Matrix of that Matrix Min 9 because this plus 9 and how how how came you go with this column leaving this column and leaving this row 41 01 which is nothing but 4101 okay plus changing the sign 149 01 how this 4901 came is you have this you leave this and this you leave this column and this the row which is 4901 okay so this is how you came it and then and then you're done okay now what do you do you you do for the last one you do for the last one this because you you done for this you're done for this you're done for this now you converted that to a 2x2 MRI which is easily deter which which we can easily take out the determinant now you go to this okay so here's how you do it so Min 4 okay and then what do you do and then what do you do you leave this column and this row taking out the first element so six take the determinant of I was I think it's where it was 9 9211 9211 9211 minus minus 9 okay so over here it was leaving this the SE going to this and leaving this column and this row which is 4201 I I I think about it yeah that's 4201 4201 and then you change the sign plus 2 49 I think it's it's it's more about you leave you go over here 4901 okay that is 4901 okay now you are done now this is what you have written so you converted the first Matrix the first Matrix this one this one and this one as well uh into a minor Matrix which is 2x2 determinant so you can easily take out and then do the product and then you take out okay so let's do over here if if I have a chance to do over here but no problem I will do over here okay so here's how you do it here's how you do it so for doing it first of all you have the one available which is over here you have the one available which is over here what do you do you simply 9 16 + 7 how how how we came so you have the particularly nine times because of course you want to always want to multiply it out okay so I think about this is you have uh if if you go over here 2 * 1 okay and 1 * 1 so 2 2 2 * 1 how much 2 * 1 how much it would be uh 1 1 I would say uh 2 1 which is 1 so it will be 9 okay minus minus over here uh 9 9 * 1 which is 9 1 which is 8 16 16 done and then you have 9 * 1 and then minus 2 * 1 so 9 2 which is 7 okay so here's how it came okay and then you then this the left minus two now you go on second one two over here so when you when you take a two * 1 how much 2 * 1 how much 2 * 1 2 1 okay that is 6 over here here so we write uh 6 8 + 4 okay so here's how you do so it is 6us 4 * 1 of course 4 * 2 it's 0 * 1 of course 0 so 4 * 1 4 * 2 which is 8 which which you have written over here okay then you go over here 4 * 1 how much 4 * 1 4 and then you four so here here is a plus 4 now now you go to the next + three because you go over here now 9 * 1 how much 9 * 1 how much uh 9 * 1 9 of course 1 uh which is nothing but 8 8 * 6 48 so you have 48 36 + 4 okay so here's our 48 9 uh so 4 * 1 4 so 4 9 49 36 because this 2 * 0 is 0 then you go over here then you have this 9 9 9 * 0 is of course 0 4 * 1 so 4 2 are 8 eight so over here uh I think I'm wrong over here um you have this 4 * 1 4 91 0 0 so 4 uh it's it's it's it's four okay so it's four it's it it it it it should be eight okay it should be 8 which is nothing but what you do you 4 * 1 4 and then you simply multiply with two which is nothing but 8 okay now you simply 4 4 uh 28 30 6 + 88 so how you take out 9 * 1 how much 9 2 7 7 7 6 7 76 how much uh oh oops it's it's uh it should be 9 * 1 2 987 76 42 okay so which will be nothing but 42 what the hell i' written over here so I have to just couple it out so I have to just return it it will be nothing but 42 okay minus minus minus uh minus 4 * 1 of course 4 9 are 36 plus 2 4 4 1 are 4 4 2 8 okay so here's how you do it now you simply multiply with this and then first of all do the calculation do the calculation then you'll be getting one a scaler as your output so please feel free to put your answer in the description box below I know the answer but yeah I want to leave it to you to do the rest of the calculation I have done a lot so here's how you take a the determinant of n byn Matrix and how you do it and how you do it it's very very easy you just uh keep converting that to a lower or a sub Matrix and then you and then after that you are done okay so here's how you do it so you you define one you define one sub Matrix AIG J you define one sub Matrix AIG J which is nothing but the Matrix the n n minus 1 * n1 Matrix n1 n1 Matrix if you ignore ignore the I row and I column if you ignore if you ignore the I row which which you are doing I row and J column which which you were doing okay that is your new Matrix which which we were forming that is a recursive this is a recursive you can write a Python program for write a recursive solution for this okay so you were writing a one one and then you were adding the determinant of that subm Matrix and then you are doing so and so on so on that is a recursive solution so you writing the recursive recursive stuff so we we we already written a lot so I hope that you understood for formal definition which you can see yeah we have gone through one of one of the example which is very very much important for us to know okay so I hope that you will uh get a lot from this video and determine it I hope that concept is clear with my examples and I also hope that you enjoyed this video I think I have to wrap up with wrap up with this video I'll be catching up your next video till then byebye have a have a great day meet you in the next lecture okay everyone let's get started with another lecture I know it's bit L late lecture but I apologize for that I'll be I'll I'll be making making sure that I'll be providing you around three to four videos this week so I already provided two videos now I think about two of three videos will provided more this week till your next uh assignment or homework assignment and please make sure that your homework assignment is released if we find any student who are not active we will remove them from our LMS because this is an opportunity which are given for free for others to learn because if the people do not take this opportunity we are going to drop that student so uh we we we highly recommend to to to to be active on LMS please do your assignments please attend your attendance and every stuff okay so please please go there and Mark your attendance and as well as uh complete your assignments even if you complete around out of 25 questions you you have to complete around 20 questions you can complete 20 questions write right in Notebook and then give it to us okay so you your programming assignment sorry the homework assignment will be will be evaluated and then that will be uh till the end end of the course and if we do not find you active in the course we will drop you out okay so this is one of those announcement that our team has told me to give me to give it to give it to you all through Me Okay cool so so what's the mod of this lecture the M of this lecture to talk about the coactor the minor and educate or the adjoint and invoce of a matrix so these are very very correlated these are very very correlated uh for for taking all the coactor you need mind and for taking out the minor you need determinant and for taking out the aducate you need coactor and taking out the inverse you need ugate okay so again I'm explaining for for for taking out the coactor of a matrix for taking out the coactor of a matrix you need minor and for taking of the minor you need determinant and and and and after after you take out and for taking out the adjugate for taking out the adjugate for taking out the adjugate for taking out Agate you need coactor and then for taking out the inverse of a matrix you need aducate okay so these are very very correlated and they are heavily used for many this inverse of a matrix because they are so correlated so I thought okay let's let's start with this video so that everyone knows about coactor how the N inverse of a matrix is calculated because it is extensively used in the industry okay uh mainly in linear algebra there's not too much use in machine learning some sometimes us machine learning but it's very very good to know about these stuffs okay so first of all how do you be now let's let's let's go ahead and talking about the first two stuff which is which is a minor of a matrix or the coactor of a matrix so let's start with a minor let's start with a minor minor of a matrix so so so a minor of a matrix a as as if if you remember the minor the a minor of a of of a Matrix a a minor of a matrix a matrix a is the determinant of the small same some some smaller um Square Matrix um a minor of a matrix a is the determinant is the determinant is the determinant of some of some smaller of some smaller squar Matrix as you remember remember that what we do what we do if we were removing the column and the row for that for that point or the element and then we were we were obtaining a sum Matrix in the determinant and that's actually when you when you take out the determinant of of that some Sub sub Matrix that's actually the minor we we will see see one example just just in a second for example for example let's take an example that you have the following that you have the following uh Matrix okay you want to take out the determinant of this Matrix or the minor of this Matrix you want to take out the minor of this Matrix so for example you told okay you want to take the minor of Matrix M for I row and J column okay that so you take out so you for example you choose okay you want to remove the second row uh and the third column okay so you are saying 2 3 so you to you want to take out the minor of a matrix given I = 2 and J = to 3 so what what it will do it will it will leave second row and it will leave the third column okay so the minor of this Matrix a will be left with the the the sub Matrix will be left with 14 1 9 as you all are knowing okay so now when you take out the determinant of this Matrix so 1 minus uh this is first of all for taking on the determinant of a 2x2 matrix what we do we simply what we do we simply uh multiply the DI diagonals and then sub subtract it so 1 uh my time uh 9 okay minus uh of course uh sorry this minus and minus 4 okay so that will be left with 9 + 4 which is nothing but 13 so 13 is a minor of a Matrix given I = 2 and J = 3 so what does it mean we leave the second row and third column or we delete the second row and third column to obtain the sub Matrix so that is the minor of that Matrix okay so again explaining what we do we simply remove just one row and one column and we take what row you want to remove and what column you want to remove by the user I and J you you remove one row and one column from the square Matrix and make sure that is a square Matrix what is the square Matrix the square Matrix is the one where the number of rows the number of rows matches with the number number of columns okay so the number of a rows matches with the number of a columns and over here when you take out the minor of this Matrix a given you remove one row and one column so you rem the remove the second row and the third column for example if you want to take one one so the minor of this will be you have you want to remove the first row and First Column the minor will be determinant of that uh 3 0 so sorry it will be it will be I think 0 5 91 so take the determinant of this so 0 0 * 11 0 9 * 5 45 what it will be it will be 45 or 45 okay so that will 45 around according to this okay so that's that will minus 45 so that's how what this minor tells you minor tells you okay you want to take out you want to remove that column I you want to remove that I row and J column and then write write down the Matrix and then take out the determinant of that submatrix and whatever the determinant will be that will be your minor of that Matrix okay so this is this is what it's trying to tell you so over here oh my God what is this where is where is my pen so this is what it'sing trying to tell you over here okay so what does minor means minor of a the a minor a is the determinant of some smaller Matrix some a smaller Matrix okay so a minor a matrix a is the determinant of some smaller Matrix for for example which you're seeing over here and then you so how do you take out you remove one row and one column and ride the rest of the Matrix element into a new Matrix and then you take out the determinant of that Matrix and the whatever the determinant a scalar value that scalar value will be uh the minor of that Matrix okay so this is how you calculate the minor of the Matrix so so so so so using minor of a matrix you can calculate the co coactor of a matrix using minor of a matrix you want to calculate the coactor of a matrix so why do we you why do we need to calculate the minor for Matrix to calculate the coactor you we need uh we need to calculate the minor so what does it mean so why do we even care about coactor why do we need coactor So Co coactor is required for coactor is required for computing determinants Computing Computing high level determinant or larger determinants okay Computing larger determinants or determinants and taking out and in taking out in taking out the inverse of a matrix indirectly inverse of Matrix indirectly as it is not used directly over there you want to take out the adjugate of that for taking out the inverse but adjugate uses adjugate us a CO coactor and coactor is being indirectly contributing to taking out the inverse of a matrix we'll see the inverse of Matrix just we will visit after some slides okay so this is this is what it means to be minor so let's talk about the coactor of a matrix let's talk about the coactor of a matrix so what is the coactor coactor is calculated first of all we need to calculate the the the minor so for example you have the following uh Matrix you have the following Matrix you have the following Matrix 147 305 1 911 okay so this is this is your this is your um this is this is your 3x3 Square Matrix you take out the minor of this Matrix you take out the minor of this Matrix given I to be 2 and J to be 3 okay so you want to take out the determinant of the sub Matrix of the sub Matrix of the sub Matrix so for example I'm just taking one example given I = 2 and G = 3 so what you do you leave the second row and third column the second row and third column so left with 1 4 1 9 so this is and then when when you take out the determinant determinant of M2 3 that will be what 9 9 * 1 9 um 4 that will be nothing but 13 and as we shown 9 first of all the product of the diagonals and subtract it minus 4 so that will be what 13 okay so that is the minor of that Matrix now when you take out the minor of the Matrix how to calculate the coactor of a matrix so for calculating the coactor of a matrix I and j i and J and make sure that I I I matches with the minor minor of that and J matches with the minor of uh or uh whatever the uh J over here so these these two should match equals to 1 the power of I + J * the minor I and J okay so this is how you calculate so for example for this example let's calculate the coactor so how do how how do we calculate the coactor so the here I is 2 3 J is 3 is which which is nothing but equals to 1 1 2 + 3 * 13 okay so whatever the value will be over over here we don't care of that it will be minus one because it's five mean min1 to ^ 5 what it will be 1 of course because if it if it is 6 then it will be 1 so it is 1 * 13 so the output will be the the answer will be Min 3 will be the coactor of this Matrix given I to be two and J to be three okay of that minor okay of that of the two three ENT three okay so what how you write the coactor the coactor of 23 entry where two is the row and J is the uh two is the row and three is the column entry is min 3 okay so this is how you C calculate the the coactor of a particular Matrix okay so let's see one more example to make intuitive sense to you so that it would not left in sense oh my God what is happening with with some example so let's take an example that you have 2 4 6 21 2 1 one1 so this is your Matrix so you select okay you are selecting the third row you're selecting the third row you to take out first of all minor so going to take out the third row and the first column okay so third row and the First Column okay so you to take out the minor of that so first of all you leave the third row and the First Column so the minor will be the minor will be the deter the The subm Matrix will be at what uh 4 61 2 and when you try to take out the determinant of this what it will be 4 * 2 6 * 1 which is nothing but 8 6 which is nothing but 2 okay so the minor of 3A 1 entry is nothing but equals to 2 okay so after after you calculate the minor if you calculate the minor you wanted to calculate the the coactor because you want to calculate the coactor so for calculating the coactor you need a minor so you taken out the minor now when you calculate the coactor of 2x3 entry of the two two sorry it's 3x 1 now it's 3x 1 3x1 entry which will be what uh which should what so c i j so formula is c i the coactor of three I and J entry is nothing but 1 to the power of I + j i + J times the minor Matrix I and G so in this example 2 3 = 1 2 + 3 * 2 * 2 so what it will be it will 1 to the^ of 5 * 2 okay so that will 1 time 2 which will nothing but minus 2 is your coactor of that Matrix okay so the coactor of that Matrix for that ENT 3 3 3A 1 is 2 so this is how you calculate the coactor of a matrix so I'm just just going to ride the steps for you to calculate the coactor of a matrix so first of all you take out you take out you take out the minor you take out the minor take out the minor m i j how you take out the minor so first of all you take out the sub Matrix so you remove the one row I throw I'll just remove I just going to write remove I row remove I row and J column okay and then whatever the sub Matrix would be left and then sub Matrix sub Matrix and whatever the sub Matrix take take out the determinant of that sub Matrix okay that will be a minor after you take out now you can simply calculate the co factor which will be nothing but C J which is nothing but 1 the power of y + J * m j okay so this is how you calculate the coactor of a matrix c i j for that I entry okay so I hope that you understood what's the coactor and what's the com Miner of that so some some of the applications so some of the application so here over here what you're trying to actually do is to uh so we can write it's basically this Co coactors are basically used in prominently in lapl formulas for for the expansion of the larger determinants okay as as we have already seen so the formula of determinant of a which is nothing but I = to 1 all the way around to the n a i j a i j 1 I plus j m i j okay so this is for taking of the determinant as as I told you one of the most best application of uh of the coactors it is used in is a laplus formula for taking out the determinant of larger determinant so this is the formula for taking out the determinant of a by using the coactor so I = to 1 all the d m a i j times uh uh times of course minus one this is the coactor of your Matrix and this is a minor of that okay for that to I I and J entry now so we had seen the co coactor we have seen the coactor and we have also seen the minor and we have talked a lot about determinant and we talked a lot about determinant now let's talk about now let's talk about uh the Agate of a matrix so the adjugate of a matrix or some sometimes call it as a adjoint of a matrix so adjugate Matrix okay so we have to take out the aggate of a matrix so let's write it out so when how we take the adjugate for Matrix so first of all what is the adjugate of for Matrix so the adjugate of a matrix or the or sometimes there are lots of names sometimes we call it as the adjugate sometimes we call it is a classical adjoint classical adjoint and a lot more okay so this is a classical adjoint we also call it as that so how do we take out the adjugate of a matrix is nothing but the transp of its Co transpose transpose of its coactor Matrix coactor Matrix so Agate of a matrix nothing but the transpose of its coactor Matrix okay so here's how you define it so the aggate aggate of a matrix a is nothing but transpose of that coactor Matrix okay so this is a coactor coactor matrix which you taken out for every for every I and J in your Matrix okay so Agate is what is the transpose of that coactor Matrix so here are some properties so over here the adjugate adjugate of a is nothing but C transpose and it is nothing but uh minus one of course I'm writing the formula I + j i + J time M this is this is the formula for Cal calculating okay and and I and J should go from for all the elements so I and J okay so this is the I and J and this is how you take out the aggate of a matrix this is the definition of the aggate of a matrix okay one of the property is a times the inverse of the Matrix It it means you have a matrix a and you have a matrix inverse of that so the output will be of always the identity Matrix when you multiply the a matrix and the inverse of that Matrix so what is inverse of a matrix so here's how we deal with it so inverse of Matrix of inverse of a matrix is nothing but the AI how you C calculate it if you know about 1 / a this is this this is what we write but here's how we do that so 1 over the determinant of a one over the determinant of a times the Agate of a times the Agate of a and how do we calculate the Agate of a we calculate the aggate of a by taking the transpose of our coactor Matrix and you all know the for taking out the coactor Matrix we have this equation 1 the^ I + J * m sub subscript I and J okay so this is how you calculate the uh inverse of a matrix you calculate the 1 over the determinant of a times the adjugate of that a adjugate of that Matrix a this is how you calculate the inverse of a matrix it's not a big deal it's just a small stuff which you are seeing over here okay so so we had talk so we have we have a talk about inverse of Matrix so I'm just going to write it out in one detail about what we had a talk on this now and one one more thing over here if your the determinant of a the determinant of a is equals to zero then your Matrix The Matrix is not invertible if your determinant of that a is zero then your Matrix then your Matrix a is not invertable then it will be nondefined okay so let's uh let me write it out what we had studied we have our coactor we have our coactor of a matrix coactor of a matrix is nothing but uh minus 1 I + J to the power of time m i j okay and then you take out the the the adjugate of a matrix the adjugate of a matrix a is nothing but what the the coact the transpose of our coactor Matrix and for taking all the inverse of that for that Matrix for for for for Matrix a we have 1 over the determinant of a times times your uh Agate Agate of a and if your if your in uh the determinant of a is zero if determinant is zero then then your your Matrix is not invertible your Matrix is not invertible is not invertible okay so this is this is this is what the whatever we have studied in this video and I hope that you are able to understand so in the next session we started started talking about uh the systems of equations and and and and and we also talk about uh and then we will talk about igen vectors and igen values we'll also talk about Rank and rank of a matrix and choice of a matrix so I think we should end this video I'll be catching up your next video till then byebye have a great day hey everyone welcome to this next next lecture on trace of a matrix so in this video I'm going to talk about trace of a matrix okay uh Trace will will will will I I I will talk about how do we calculate the trace of a matrix and this video is not only about Trace we'll we'll talk about something called as hardart product which is one of the most important stuff we'll talk about its properties we'll talk about a cyclic property of a trace as well we'll talk about some more properties of a dress trace and then we'll talk about what are some exceptions in Trace and then we'll talk about our uh ner product I don't know how to pronounce it I think think a k is U silent over here so I think Ron roner products we'll talk about that and how with one with one example okay so this is the agenda for this video and the notes for this video is in description box so I hope that you will be able to go in the description box and see there uh the the notes of this video and maybe if and if if you're wondering whom to whom I'm writing on it's the updated Microsoft whiteboard and and I and I simply think that's that this is amazing this is going to beat every whiteboard available in the market uh so this is just an information from my side uh of the stuff so let's get started talking about a trace of a matrix but before that I want to I I want to give you some some class announcement the first announcement is we are removing around five students from the course by personally emailing them first of all understanding their what they're facing and if we think okay we can remove if we don't get a response from that student we are going to just remove them from the LMS okay so new seats are being available so you can go ahead and and draw for that LMS for absolutely free it's absolutely free so you can go ahead and assignments are also being released okay so if you're not able to do the assignments you are most likely uh not going to get uh you are not getting the grades and you'll not most likely not able to pass the course okay so so let's talk about trace of a matrix so so so these are some of the class announcements so let's get get ahead and talking about a trace of a matrix so so for for taking out the trace of a matrix it should be a square Matrix so for example let's say you to calculate the trace want to C calculate the trace trace of a square Matrix so you want to calculate the square of you want to calculate the trace of a square Matrix a okay and usually write that and and usually write that TR R and so this is the this is the formal notation for denoting that we are taking out the trace of the Matrix a so this is read as a uh taking out the trace this this this one is nothing but your Trace there's nothing but your Trace okay so so you're actually taking out the trace of a matrix a cool so I think that this is this is good to go so the trace of a matrix a is is defined by T TR and then in bracket you write a okay so so how do what's so how do we calculate the trace of a matrix so how do we even bother calculating the trace how do we even bother calculating the trace of a matrix for calculating the trace of a matrix we do sum of elements sum of elements sum of elements sum of elements sum of elements on the main diagonal of the Matrix a on the main diagonal of the Matrix a of the Matrix a or you can say of a okay and a is a matrix or a square Matrix so so the the how do we calculate the trace of Matrix the trace of a mat is calculated by the sum of elements on the main diagonal of the A and B say for example say for example you have a matrix a you have a matrix a you have a matrix a so let's assume that the M Matrix is 3x3 Matrix so let's assume the Matrix is 3x3 Matrix so just I'm going to take the maybe this color this shoots okay so you have uh so let's write it out a11 a12 a13 so let me just draw it over here as well okay so we have that and then let's draw A2 1 a22 a23 and let's pick this green color a maybe 31 a32 and a33 so you have this Matrix so you have this Matrix a so you have this Matrix a and you want to calculate the trace of this Matrix so for calculating for calculating the trace of a matrix a what you will do you will just um sum the elements of the main diagonal so a11 + a22 + a33 okay so the main diagonal is this this one and this one then this one okay so and then you'll be getting your scaler as an output it can be C uh whatever the number is okay so this is how you calculate the trace of a particular Matrix and and formally I can Define this I can Define this I I can Define this as uh I can Define this as a oh my God I think sumission is not written correctly I = to 1 all the way down to the three means in this case we are we want for a 3X3 Matrix so I = to 1 all the way to the three all the way to the 3 a i i okay so if we go on first of all a i = to 1 then that will be a11 + a22 + a33 okay so so this is how this is what the formal notation for uh uh for submission notation or the for Loop for particular for taking of the trace of a matrix okay so so let's take one example to perform the to perform the necessary accents accents so let's say let's say for particularly you have a data you have the particular Matrix you have particular Matrix a so just drawing the same Matrix and let's draw uh let's take one3 and let's take this yellow and let's write 11 5 2 let's take U uh green and let's write 62 5 and then let's draw a matrix so you have this Matrix now you want to calculate the trace of this Matrix the trace of a matrix is nothing but you want to calculate the trace of the Matrix a the trace of a matrix a is nothing but uh is nothing but it will go from I = to 1 all the way around to 3 a i * a I I think it's a a i * I okay uh this is what you and then sumission will will will this is the submission so it will it will add it up so 1 + 5 + 5 which will be nothing but 1 and 1 is the trace of a particular Matrix okay so this is the the one is a trace of the particular Matrix and I hope that you are able to make sense out of it and why do we bother studying Trace because because when you when when you go further me solving some some linear equations or or or systems of equations and and this is this is this is mostly used and in other formulas U mainly not in specifically linear algebra mainly some other formulas they are these straight race of magics helps the computation to be easier or help the too too much anotations as well as it has some cool properties okay so this is very very helpful not in only the con not in only the context of deep learning or machine learning it is most in the concept of context of maths and and and Mathematics and and and you you get in linear algebra and you get in other maths field or discrete M applications okay so this is what the trace of a matrix so we have a show you one example so I hope that you able to make sense out of it cool so let's see some some of the properties some of the properties some of the properties of the trace of a matrix so so some some of the properties of a trace of a matrix I'm just going to write in Black back so the properties properties so the first property which want to highlight the first property which I want to highlight is the trace of the Matrix a plus b can be written as the trace of the individual Matrix a plus trace of a matrix B so so I can write in this particular format it now the second so you can you can just think think think about it in a bit means let's let me just show you if if I can and I will just ask you to do experiment with it but I will just take an example to prove it example okay so let's say let's assume that that you're given a matrix a you're given a matrix a which is 2 2 2 2 and you're given a matrix B and and and you're given a matrix B 333 3 okay and you want to calculate the trace trace of a matrix A+ B okay A + B so what you can do first of all you can C calculate the trace of a matrix a you can calculate the trace of Matrix a so the trace of a matrix a is nothing but 2 + 2 okay which is four okay and the trace of a matrix B which is nothing but 3 + 3 6 and then and then trace of a plus trace of B which is nothing but 4 + 6 but 10 okay so so this is this is how what you you can take it out or in other words now if you first of all now this is the 10 we have proved we have taken out the uh this side rhs side let's see the LH side so in LHS so let's say let's say for a particular example for a particularly for for for example let's say let's let's take these one Matrix and then try to add it first so first of all We'll add it so let's add this Matrix A and B so 2 2 + 3 which is 5 then 2 + 3 which is five five five so we got 2x two Matrix when adding these two Matrix Two element wise addition so you get a matrix a plus B A + B which is this one now if you calculate the the the the the the trace of this particular Matrix a plus b so the trace is the sum of the elements in in the main diagonal so 5 + 5 is what 10 and we had proved therefore LHS is equals to rhs and hence proved okay so this property is proved proved like this okay so this is how you can prove the properties if you want and this is very very useful if you if if you want to get the clarity in your particular Matrix okay so another property which I want to show show showcase to you all is another property which is the trace of a matrix when it when it is Multiplied with some scalar C with some scalar C okay so so what is the trace of this Matrix so a is a matrix and C is some scalar C is some scalar so that is equ equivalent equals to C trace of a okay so first of all you take out the trace of a and then multiply with that c okay and that actually C what it does it just stretches it it simply means it stretches your Matrix okay and if if you talk about a geometric view okay so it's exactly what it's trying to do it's you you can hence prove it as well say for example you want to you have let's say for for for a particular example let's say you have a matrix a which is 2 2 2 2 okay and you have the scaler C which is two okay which is two so this is and then you want to take out the trace of CA so first of all you can take out the trace so the trace of a is so first of all let's take out the trace of a the trace of a is four the trace of a is four 2 + 2 4 and then when you when you multiply the trace of the two times the trace of a which is 4 * 2 which is nothing but eight is a particular answer of that question okay so eight is the particular answer for that question and it makes sense you can this is this is the this is the this is the your uh rhs proved and sorry yeah rhs proved you can prove it the same so when you take out the trace of the mrix which is the mrix is eight sorry so sorry it's four plus oh my God 4 4 4 4 and then we take out the trace of this Matrix which is 4 + 4 8 so and hence proved so r and E equals to LHS okay so these are the properties which I'm not going to prove all of the properties I've just showed you how I'm how how I proceed pro pro proving this stuff okay so another another property another property another property is a trace of a matrix a is equals to trace of a transpose of that Matrix it gives you a Clarity whether we transpose it that the main diagonal will be the same and the trace will be also the same okay so I I I need to prove it to Showcase to you all to see the interesting property of this the interesting property of this let's say for for for example you have a 2222 my favorite Matrix so so it is just Square Matrix because for particular Trace you need to have an Square Matrix and yeah it it it would work well okay so you you have a square Matrix 2x two okay so when you do the transpose of this Matrix when you not exactly you don't need a square Matrix to be done transpose you just need to D some some of the elements of the main di diagonal you don't need to do the uh you need you need not to have only the square m I'm just taking an example to make it convenient for you so so first of all you take out the trace of this so let's first of all take out the trace of this Matrix the first uh which is four trace of this will be four because the main diagonal 2+ 2 is four okay when you transpose it when you transpose It 2 2 2 two okay 2 two okay so this is this this is how it looks and and when you when you when when you go ahead and then uh add it it is also four okay the transpose does not matter and of course I have taken very very easy easy examples and exactly and Hance proved okay so whether you do the transpose the diagonals will remain same now next next property is uh the trace of a product so so so let's let's let's talk about an another greatest stuff which is a trace of a product trace of a product and the trace of product is the trace of a transpose B okay is equals to a trace of ab transpose which is also equals to trace of B transpose a which is also equals to trace of B A transpose okay so these are equivalent equal whatever we have written these all are equivalent equal whatever I have written over here and is nothing but uh this is we are we are we are multiplying the two mates the trace of the product okay so I hope that you're able to make sense out of it it's not a big deal for you okay so this is this this is just the basic properties which I'm highlighting okay so we had seen some some of the properties and and I want to talk about some more properties which are which are more useful means means we are also going to gather some information about uh a b other kind of products okay that we are going to to deal with Okay so let's let's let's talk about the the the hardart product okay and hardart product is is one of the most important product which you will see so let's talk about hardart product and it's very very important as well because if anybody go on Wikipedia and see some properties what is hardam product and what is um raw Necker product we will see that but before that I want to highlight one more property of a trace one more property of a trace the the trace the cyclic property which I don't which which which I can't forget means I I can't forget it if I forget it no one is going to to leave me so the the the I'm just highlight the cyclic cyclic property cyclic property of Trace okay and then and then we'll talk about two two kind of product which is hardat product and roniker product okay so we'll talk about that two kind of product in detail okay so the cyclic property says that let's say let's say for example going to calculate the trace of a matrix a b c d okay A B C D is just a multi M multiplication of a four Matrix so it is nothing but equals to you can just you can just take the you can just b a c d which nothing but equals a trace of CB uh I think it's c d a c d AB which is nothing but trace of d a b c okay so first of all B Gone to the um B B Gone first then C gone first then D gone first okay that's a cyclic property it's it goes in cycle okay but but but arbitrary permutations are not allowed but arbitary but these are not allowed I I think they done wrong over here it should be something like U first of all it was B and then it should be uh c b a d I think so like this yeah I hope so it should be like this and then when you go ahead um yeah so it should be something like this and then you keep on rotating after to recheck the thing but it but it keeps on so the trace of the cyclic property says over here so b c da a then you have a c d AB so first of all B Gone first and then we have CD and a a going last okay and then this is a cyclic per mut ations that Trace is an invariant under the cyclic permutations and the permutations you all know you can check this out this is the property this this property is known as cyclic permutation and one more thing I want to highlight over here that no arbitrary permutations are allowed you cannot do something like this okay so you have to have the symmetric matrices are considered it means if the product of three matrices symmetric me are considered then any permutation is allowed so for example if it is symmetric Matrix and for being a symmetric Matrix it should be equal to its transpose the the the the matrix product should should should be equals to transpose and the trace of a matrix should be equals to transpose of that matx trace of the transpose of that Matrix then it's called the symmetric Matrix and and then any permutations is allowed okay any permutations is allowed except this this is the only case where the any permutations allowed otherwise we don't allow any permutations are allowed in cyclic property okay so this is this is Clic property which you have to remember okay I may have written it wrong but I hope that you will correct it out by the Wikipedia page so this is this this this this was the cyclic property which I want to highlight and I hope that you are able to uh understand it a much better way so let's talk about um let's let's talk about hardart product so let's talk about hardart product which are B because we haven't we hadn't have a chance to talk on this hard demand hard demand product as as as as it seems to be a bit useful for me because it is also used in various Quantum Computing as well as machine learning as well as deep learning so let's assume let's assume that you want to take out the dot sorry I'm I'm saying dot product it should be hamat product hamat product when it multiplies with the two matrices it just do the element wise product okay and the and the Matrix and just just to the element wise product and gives another Matrix of this of of of the same Dimension Okay so so let's say for for example we given a matrix a multiply The Matrix B okay and this is the sign for the har product is just a small O Okay so so so let's say you have a matrix a we have a matrix a a11 a12 a13 A2 1 a22 a23 a31 um a32 a33 so so you have this Matrix a you have this Matrix a and you have Matrix B and you have another Matrix B and another Matrix B is maybe b11 B12 B13 B B21 B22 b23 b31 b32 b33 okay you have the two matrices and when you take out the dot sorry hardat hardat product hardat product between these two Matrix which will be nothing but the product wise multiplication so a11 b11 a12 B12 a13 B13 then a21 B21 a22 B22 a23 b23 okay a31 B2 b31 um um it's it should be a32 b32 and then a33 b33 okay so this is your Matrix uh the heart of our product which is Tim element wise product okay so I hope that you are able to get means element wise product it's not a big deal it's very very easy to understand okay so some s some of the properties of this some of the properties which I want to highlight properties properties which I want to highlight some of the properties of this particular uh product is is you can write it out in this format which is uh which is equals to this sorry B * A B B BB do B Circle A and then a and then b c which is nothing but equals to A B do c I hope that you all remember the properties name okay another is a uh b + C which is nothing but equals to A B + a c okay so these are some some of the properties which are highlighting over here A C nothing but equals to uh okay you can write it out something like this a z which is not nothing but equals to 0 time with 0 a which is nothing but equals to zero okay so this is these are some of the properties of a hardar product which you which I want you to think about it and and solve it on your own and prove it and and then prove these properties if you want okay and just like I've Tak taken some examples and proved it so let's talk about another so one so so let's so I'm just just going to show you what are the property of the trace of a trace of a uh trace of a hardat product the trace of the hardat product where is the where is that trace of a hardart product I I'm not seeing where it at but yeah it's it's very it's one of the important stuff but yeah let's go ahead and talking about um um and droner product I don't know how to pronounce it I'm pronouncing it good or bad way but I want you to think about this means uh you you wanted to the something called as roniker product roniker roniker product so I think we have to talk on this so roniker product let's let's talk let's talk about this Ron roniker product so you have a matrix a you want to calc you want to do the Rona product A and B between A and B okay so let's say and we we this is the roniker product sign for showcasing okay this a r roniker product product and this is how it looks 1 2 3 4 and then uh like this 0 5 6 7 okay and then you and this is how the raw product works so what you do you make a big Matrix means a big Matrix like this and you take this first element and multiply with all as a scaler and multiply The Matrix on Under The Matrix B so something like this 0 5 6 7 okay and then you and then you go on as a two as a scal in the second element you have 0 5 6 7 okay third element you three 0 5 6 7 okay uh 4 0 5 6 7 okay this is how it should work and and and and then what you do and then what you do you simply uh and and then you follow your whole procedure the whole procedure is uh which is nothing but one 1 * 0 then then 1 * 5 1 * 5 then we have 1 * 6 1 * 6 1 * 7 for for for this one I'm I'm doing like this okay and then you keep on doing this 3 * 0 3 * 5 3 * 6 3 * 7 I'm doing doing for this and then let's do for the same 2 * 0 then 2 * * 5 2 * 6 2 * 7 4 * 0 4 * 5 4 * 6 4 * 7 okay and then when you when you do this stuff you'll be left with you'll be left with 0 5 0 10 uh 6 7 12 14 0 5 15 actually 0 20 and in 18 21 24 28 and this is what you get as a 4x4 Matrix this is this is nothing but called the roniker product and one of the property and trace this is the the trace of uh the trace of this Ron product is can be written like this can be written like this can be written like this uh trace of trace of a and then times the trace of B okay okay so you can write it something like this but but but one thing which I want to highlight over here you cannot you cannot uh do something like this in a regular case in your in in any your if I could show it to you if if it could have a chance to show show it to you so let me just show it on a Wikipedia page I think that exactly not equals to H so the trace if if if you see the trace trace of a matrix product okay the trace of matrix product it can cannot be written like a * b as a matrix product usual matrix product which is Trace of a which is which is which is completely wrong it it cannot be written but there's a case which is Ronica product which we can write it something like this but in magx product we are not allowed to do that okay so so this was the bit about this uh Ronica product and I hope that you understood the hard demand product and the trace of a matrix so I hope that that we are done with the Core Concepts of linear algebra from the next session we'll be starting talking about systems of equations solving systems of equations lud de composition gion mixtures and then we are done with this uh chapter and I hope and and I and I really appreciate your patience throughout this course and then and and I I guarantee that you will learn calculus and the easiest way that I can and and I also hope that I will providing so much Valu to you all uh even I'm I I think uh it it it motivates me like if if I see the watch hours and it's bit increasing and it motivates me a lot okay uh peoples are watching these videos so please keep watching please share this course it's very very important for me so that it could reach to lots of viewers and I know this course will be boom in upcoming future and many people are going to take benefit from this and some of the comments are say said that you're that please don't stop uploading the videos this course will be boom on future if I just complete the course and then I show it to the viewers hey see the course is completed complete this you are it is more than any premium course you're you're getting for absolutely free you're getting the assignments you're getting everything for free so I think that it is so so much of uh the features which are available for free the people do not give when they when you when you pay for that okay so I hope that's that's it for this video I'll be catching up in next video till then byebye have a great day so let's get started talking about systems of equations as this is the last video on linear albra series and I hope that you are able to understand everything in linear algebra as well as some of some of the videos of linear algebra is already released before around nine nine videos and I hope that you are able to make sense out of it uh so we had a talk on everything which is required for deep learning for further deep learning is we have already talked about that and one concept which I haven't talked is igen vectors and igen values I'll I'm going to talk about I have already talked about this in my PCA videos so as I haven't seen much of use in deep learning but yeah surely you can go to my pcab video or principal component analysis video in ml1 and you can see there about igen vectors and igen values if you're interested in learning that so this is the last video on systems of linear equations so I'm just going to write linear as it does not make sense so linear equations so we'll try to solve we'll first of all see what the systems of linear equation means and we will see also how to solve this um this linear equations and every stuff okay so what are linear equation so as the as first of all let's let's start with the what is a linear equation a linear equation is it's an equation for a line so so as you have seen in linear regression so your this is the this is this will this will be your linear equation whatever the hypothesis is maybe the hypothesis h of xal to Theta 0 + Theta 1 * X X1 okay so this this this this equation is your linear is your linear equation the reason why I'm saying is a linear equation because over here it does not have any powers it it has a power of a one and and it is a straight line or or or or a line okay so so some of the examples of linear equations some of the examples of linear linear equation so I'm just going to give some some examples so maybe y = to 3.5 0.5x okay another example may be y = 0.57 x okay but they they both mean the same they both is actually equivalent whatever you write with in that form or you write in that form and you can also write this out in y+ 0.5x = 3.5 you have written that into another mode you can also write y + 0.5x 3.5 = 0 you have written that into a new mode or you have written this this into new mode so they are equivalently the same linear equation equivalently they are same linear equation same linear equation they are not different linear equation as you can see over here uh so let's let me just show you so first of all let's see this one okay y = 3.5 0.5 * X and if if you compare y = 0.5 and when you do the manipulation of algebraic manipulation you will get this and you can check that exactly if we will L to that okay uh which you can see 0.5 * 7 0.5 * 6 exactly what what what what what that second equation is telling and then you just you you you have just converted this 0 Plus 0.5x on the on on on the left on the left hand side okay and making that equ equals 3.5 you just manipulated this is a manipulation and they mean the same okay so this is these are the linear equations which I want to show it to you so so we had a talk on linear equation that is an equation for a line okay so it's an equation it's an equation of a line or a for a line whatever okay so what is systems of linear equation so systems of linear equation is when we have two or more linear regession so so sorry it's linear equation they are working together okay so so as as from from from from history we have seen particular statement is called something and a group of particular statements are called something okay so in the same way for example if if you have seen my linear combination videos so we have we had told the set of all the linear combination I think yeah the linear combination is called span and only one that is is called a span okay so the set of they are working together so in the same way um we have the systems of equations are the set of or when we have two or more linear equations working together okay so system of equation the definition of a systems of equation is when we have two or more 2 plus 2 plus linear equation 2 plus linear equation 2 plus linear equation when we have 2 plus L linear equation um when we have two plus linear equation uh they are working together they are they are working together then that's called system of equation working together together they are nothing but called they are called system of linear equation okay so so systems of linear equation means there are two or more linear equations working together that's nothing but the systems of equations so for example so let's say for for for example U 2x + y = 5 x + y = 2 that is you have the set system of linear equation and you need to find the value the value of X and Y by solving this system of equation we'll see how to solve system of equation using substitution elimination and Al algebraic manipulation we'll try to see how to solve how to find X and Y so they both are working together they they both are they both this is a a system of linear equation these both equations are linear equation and and and and using the system of L or we need to solve this uh system of equation by finding the value of X and Y okay so so so let's so let's see how do we proceed further in solving the systems of linear equation so I'm just going to see the recordings is being recorded yeah correct it is being recorded let's let's go ahead and solving the linear or so sorry it's systems why I'm saying the linear and linear regession uh just want to share one incident I was giving giving a speech and there was a kind of St stuff deep meaning okay so the I was having a quot and then I was telling the the beautiful line is is the title of this and and the deep meaning so I was so I was in a stage and and and and told uh the deep learning of this Cote so I was like so seriously I told the Deep learning but no problem again I corrected it but yeah it was a funny no one was knowing about deep learning in my school that uh at that point okay so solving so so so we need to solve let's let's take one example let's take one example to solve one linear equation to to to to solve a linear equation so let's go ahead let's let's go ahead uh to to to solve the linear equation so let's say solving you need to solve this x + y = 6 3x + Y which is nothing but equals to what uh 2 okay so you need to find the value you need to find the value of X and Y so how you're going to proceed further what we can do is simply merge them together merge them into one question into one uh one one equation by making the LHS to the LHS side and rhs to rhs side okay so x + y 3x + y okay so what I'm going to do is have over here we subtract it so let's sub subtract it out okay 6 2 so we are subtracting the linear the the equations okay so from the the second equation from the first equation sub subtracting the second equation from the first equation and and then we are done so we are sub subtracting with this now we if we x + y + 3x y = 4 and then you proceed further is 4X and then it is cut okay 4X = 4 and x = 1 okay so when you when you say that you you you got one what you can do so we now know the value of x you now know the value of x so after knowing the value of x you can put them together 1 + y = 6 when you put X x = 1 x = 1 1 + y = 6 and 3 * 1 + Y = 2 and Y = to I think 5 and maybe y = to 5 okay so uh so y = 5 of course you you can you you you you check with both the equations and both the equations yields the same y when when when you put X X's okay so so you can solve any of these uh equation and maybe the first equation or the second equation and then take y I've just done to to to show you the the check that okay the second equation means the same what exactly the first equation means okay so the value of of X and Y will be x = 1 and y = 5 is the solution to the system of equation okay so when you when you so you find the value so the question was to find the value of x and y and you are done with finding the X and Y values and and it is nothing but a beauty of algebra and and I seriously like algebra in these cases and and we'll see some of the some of these geometric examples that how it is working and and and and geometry geometrical interface of the systems of equations okay so so so like I think that we are able to make sense out of it and I also hope that you are able to understand it now we had seen the numerical understanding now let's try to Simply understand the geometrical aspect of this okay the geometrical aspect of this let's see let's say you have an X so sorry you have an X and Y AIS so sorry this is X and this is y AIS okay so let let let me to not write this out okay but it make more sense in in in in context of linear algebra so let's write 2 4 6 8 10 12 okay so let's go ahead with solving the same thing 2 4 6 8 10 12 okay now let's plot both of these equation let's plot both of these x + y = 6 and 3x + Y = 2 and graphing these is not a big deal if you to graph if you to graph the equations the equations graphing the equations I would like you we we'll cover that in a precalculus but I would like you to have some context understanding of how we graph the equation and the way we graph the way I used to just just just in this example let's assume that you want to grab the function you want to grab the function maybe F ofx = to x² how how how you going to graph it so you can just put the values of different different x's and point and keep keep mark on the point and and then and then and then after certain certain X's value just just join that point or not in the other words let's say for for example you do the same you you try the different different values of X you try the different different values of Y and keep pointing over there so you then you are able to graph the equations and if if if you still not if still confused I would like you to send to one video which will the link in description like graphing the equations which is not a big deal they just form a table and they just try different different X's values and then they get the Y values and then to try the yv value and then they get the x value okay and they keep on doing it until un they found some pattern in it and and it's not a big deal to found a pattern to to to have maybe three to four uh input values of x's and Y then you'll be getting your the the graph of that equation okay so I think uh let's plot this X and Y so the plot of this X and Y table will be nothing but uh will be nothing but what uh six and8 I'm just going to have a good uh so sorry I'm not able to plot clearly let me just touch this it's starting it is touching actually eight okay but it's looking very bad actually so let me try Okay so let's assume that it touches 8 okay so this is8 okay and this is six and this is an equation for your x + y = 8 let's try to plot uh maybe this one um this this particular ter stuff 3 minus 3x + Y = 2 okay so how you going to plot it so the so the plot of this would look something like this so looks something like this so when you go ahead and touch this so this is your the the graph of 3x + Y = 2 this this is a graph of that equation and when you see over here so now you have these two equations now if you if you if if you go closer and closer to this uh if if you go a little bit closer to this you'll you'll be noticing that okay I think I done a little bit wrong over here here I've done little bit wrong over here of course and I have done little bit wrong over here I should give two over here rather than giving two over there and one over here okay just just but in if if you if you draw a graph formally on the graph paper you'll be getting exact stuff but I'm just assuming okay some something like this now the the intersection the intersection which you're seeing over here the intersection the intersection which you're seeing over here is actually Your solution of x or or or the values okay or the values or the values of X and Y or the or or you find the solution to both of the you you already solved using graph of the value of X and Y how where where the points intersect so I'm just going to write it out let's remove it first of all so the point intersect so it is nothing but five okay at Y and there nothing but one at X so X = to 1 and y = 5 so you get the answer from here as well by geometry purpose the point of intersection the point of intersection is where where the lines intersect is actually the solution to that linear to that system of equation okay so when you when you can plot it uh maybe three linear equation and it will be in in in if if if you three linear equation with with the two variables okay so maybe it may be on uh uh on a a threedimensional plane and where the plane intersect exactly that's a solution of x y and z if if there are three values X Y and Z that's not a problem of a two two dimensional variable that is for of a problem with threedimensional variable where you have where you you plot the plane you have a plane something like this of x value y value and Z value and then you have this is this is one of the linear equation maybe you have another L linear equation and maybe you have another linear the point of intersection maybe this one is actually Your solution to that X and Y and Z okay so we'll see one geometric purpose later on uh but this is how the the 2D 2D geometry in 2D plane this is if you want to find the value of X and Y the point of intersection of the the the linear equations is actually the solution to the values of we able to find we we want to find it okay so I I hope that you're able to make sense out of it and it's not a big deal to understand it okay so I would like to go further I would like to go further into we had a talk on this is the two variables which is two 2D ples stuff so now let's go ahead now let's go ahead now now let's go ahead and talking about what that linear equation when we call a particular equation as a linear equation and when we call the particular equation as a nonlinear equation so who can tell me that 2x + y Z = 4 is it a linear equation yes or no I think this is a linear equation but is this a linear equation but is this a linear equation so sorry I think uh I have done a wrong example but no problem 2x + Y 2 Z = to 4 is this a linear equation yes or no it's no because here the power is through as a quadratic equation okay so this is not a linear equation over here but this is a linear equation okay so I'm just going to get started with with talking about variables which we are dealing up okay so variables which you're dealing it up so if if you see this example if you see this example of this x + y = 6 and 3x + Y = 2 and then you add minus over here so over here here we the the the the system equation is a two Dimension system equation is a twood dimension two Dimension uh variables okay why because you have only two variables okay X and Y but what if if I add x + y = to or plus maybe Z = 6 and 3x + y + z = two so you able to find x y and what about Z so this is a threedimensional problem through the system equation is a threedimensional the system of equation is a threedimensional stuff and uh okay so so this is how we are able to make sense out of it as two Dimension and threedimensional variables okay so let's get started solving up our problem so we have this two Dimension and three dimension Okay so I hope that you're able to understand what I'm trying to convey over here but in let's let me show you some other stuff so here we are seeing only two two system two two linear equation in the system equation your this just identify 3x + Y = 2 and maybe 2x + 2 y = um 16 okay so just let me know what uh is this a two two two dimension or three dimension it is a two Dimension because there are only two unique variables which you need to find okay but what if I changed 2 Z and maybe 2 Z I just change it and 2 Z + 2 y it's a threedimensional problem then okay so it's a toally based upon the unique variables you have in your problem statement so here we have more variables you you you you in a system of equation you have more variables and it's AR one okay so I hope that you're able to make sense out of it and and I also hope that you are you are able to understand it okay so let's go so so I hope that uh it's just not a big deal for you at least and uh uh please recapture it if if if if you're not even com uh comfortable please rewatch the video again I would ask you okay so we had seen that maybe the the line of intersection is called the solution to the process equation but there are three types of possible solution cases so the first type is no solution second type is one solution third type is infinitely many solutions so for the system of equation you can have either you can have either no solution you can have either no solution you can have either one solution and you can have either infinitely infinitely many solution many solution okay so you are have you can have one solution no solution exactly no solution for that system equation you can have one solution for that equation and then you can have infinitely many equation many solutions for that okay so if there if when there is a no solution for that equations that's called inconsistent or if there is a one or infinitely many solutions that called consistent that's called consistent okay so let's I will just go through the note again but let's see what that geometric mean no solution one solution infinitely many solutions okay so so let's here is our graph here is our graph here is graph so over here let's say for for the second example this is your one so this is a this is maybe two two two variable Stu and two dimensional Stu so you have a two linear linear equation in that system of equation and you have the first equation and you have the second equation and what you can see over here they do not intersect they do not intersect they're parallel to each other so that's why they have the no solution they have the no solution okay so if if there's a point so this is an example of no solution another example is if you have this one and the and you have the another equation something like this the point of intersection the point of intersection which you see over here is this is this this this gra an example of one solution because there is one intersection at that point okay the infinitely Min solution graph will would look like something like this if you have if you have something like X and Y graph X and Y graph and you have the on the you have the first equation and the second equation is is on the same line of that first equation uh then that's called then there where we we will be having the infinitely many solution to that linear equation Okay cool so I hope that you are able to make sense out of it and it's not a big deal to understand it okay so so these are three types of solutions and and and when we call this when there is a no solution we call that as a inconsistent we we call this as a inconsistent and these two are called the consistent these two are called the consistent okay so I hope this is a two these are diagrams of two equations in a variable and in two variables uh not a big deal to understand it cool so you this now now we are done with it and I think I spoke in just just before no problem again so solving system of equation so now let's let's let's start solving system of equation we had solve on system equation using regular rbra but basically real world you not get a system equation in very very easy mode you have to make you have to understand it and I and I will ask you to solve this system equation just to make sure that you're able to understand everything so let's start with solving uh system of equations so uh uh solving system equation so let's go ahead uh 3x + 2 y = 19 so let's take one let's take one example let's solve this algebraically we'll solve this algebraically okay man manipulation we'll do a lot of manipulation in this so let's take one example and the example States 3x + 2 y 3x + 2 y = 19 and x + y = 8 okay so over here you have this and and what we specifically do we make make that to um I I would say make that y or whatever the variable we to find into one side and other other other stuff in the in the left uh opposite side of that which is in rhs so what I'm going to do is 3x + 2 y = 19 y = 8 x so I so y = 8 x so now my trick will be I'll replace the Y over here with 8 x okay replace y with 8 x with 8 x so 3x + 2 8 x + = 19 and you have y = of course 8 x okay 8 x now what I will do I will expand this I will expand this okay so after you expand this 3x plus just write expand okay 3x + 16 16 2x = 19 okay so now you have this y = 8 x okay so you have expanded it now what you will do you will try to solve this okay you'll try to um try to solve this this one so 3x 2x which is of course X and we have us left with 16 so which is nothing but x + 16 = 19 and Y = 8 x so x = 19 6 and Y = to 8X and this will be yield yielding to your favorite uh uh 16 okay it's 16 no yeah 16 which is with three and then we we got the value of three we got the value of three now you put the value of three over here so so over here 8 3 which is nothing but 5 so you found x = 3 and Y = 5 as a solution to this linear equation of the system of equation I hope that this is very very easy not very hard to understand this we are sub this is the method called substit tion solving by substitution okay so we sub substitute the values the so what I did my technique was first of all make X on the one side all the all the variables on one side and other all the things on the opposite side of that variable which is the rhs in this case um and then try try to take out and try to do the algebraic manipulation and then you're done you just find one variable and other variable is in front of you okay so now we have seen these two variables now let's try to solve let solving the system ification of three equations in three variables so we'll be having the three equations in three variables okay so now let's see that how how we are going to proceed Sol further solving that okay so let's let me just make that this this this point and let's see let's let's go further so let's say x + z = to 6 okay X+ Z = 6 Z 3 y okay Z 3 y y = 7 and 2x + y + 3 Z = 50 I will try to be as much neat as possible to make sure that everything is going very very fine okay so what I will do what in my hand is to do is to I I'm seeing this x I can make this x equal to 6 Z okay I can I can do something like that okay so what I'm going to do is I can I can just make that X = to X = to 6 Z so let's go further x = 6 Z okay x = 6 Z now we have 3 y 3 y + z okay 3 plus Z because I'm I I or in for so let's let's assume let's try for for or what I'm going to do is to give you give you a good idea about how to be clean so what what I will do I'll I'll I'll I'll make a separate PES for for all of them so this is for X Y plus Z because we we don't have y in this case so we just leave this space for it which is six okay Z which is z okay so what I'm going to write z + 3 y okay minus 3 y = 7 and we have 2X + Y which is for this plus 3 Z = 15 this is called the neat and then you what you go further you go further then what you do you you first of all first of all x equals to Alo sorry I don't have to first of all you have to go further okay X then then you leave all the space for Y and Z okay equals to 6 Z okay 6 Z okay so that the equation left alone the the the variable left alone and the and our LHS side okay you now you write the same thing again 3 y + z = 7 and 2x x + y + 3 Z = 15 okay now what I'm going to do is to substitute the values of X over here now I'm going to do is to substitute the values of X over here so after substituting the so let's sub substitute the values of X over here which will be nothing but uh X then we leave this space equals to 6 Z 3 y 3 y + z = 7 and 2 6 Z + y + 3 Z which is nothing but 15 okay now you sub substitute the values of X and if we try to solve it if if you try to solve it uh if if you go ahead and try to solve this we be getting this um if you go ahead and try to solve this uh let's go ahead and solving this uh so uh over here if if if I just just solve it which is nothing but y + z = 3 okay just I'm solving this the last one which is the last equation I'm I'll be getting y + z which you can check it out okay so if we are solving this 2x + y + 3 Z = 15 you're getting 6 Z okay now now we are left with so now we left with x = 6 Z okay 3 y + z = to as usual now we write y + z = 3 okay now because this is the which we have solved okay now we repeat the process again now over here I can just make Z = to y y 3 yes or no yes or no 3 y + z = 7 and z = 3 y I can do something like this to make the variable alone so that we can sub substitute it now if you go ahead and substitute it so if you go ahead and put put put the values of Y so x = 6 z u maybe maybe 3 y + sorry Z values so Z what what we were having 3 y isn't it we were having or not exactly we're having the Y cut I think 3 y okay = to 7 = to 7 we go ahead which is but Z = to 3 minus uh uh what do you say you go further okay so you are left with 4 y 4 y + 3 okay so you'll be uh and and Z = to 3 Y which which which you are seeing over here okay now we have this now we have now we have substituted the values now we'll try to solve it so when we solve it when we solving when we solving 3 y + 3 y = 7 when you simplifies 2 4 y = 4 okay or Y = to 1 okay when when you try to solve this linear equation and it's not not a big deal to solve what you going do you can just add you just say okay uh this is uh 4 y + 3 which is 4 y = 7 3 and left with 4 and when you try to and and and and and then you will be left with minus one okay so so this is this is what you get y = to minus1 okay now you you got the value of one value which is x = 6 z y = to 1 and z = 3 y 3 y okay 3 Y which you're having now we go the values of Y we can substitute the values in z x = 6 z y = 1 and z = 3 1 okay nothing but 4 now we got the values of Z so x = 6 4 which is 2 okay so we are done with x = 2 y = 1 and Z = 4 which is is our solution solution to our system of liation in a higher Dimension or in three variables okay so this is a process called sub solving that by substitution and it works nicely okay it works very very nice to every most of the cases but what it's a very long process okay it's a very very long process but I would recommend you to have a hands on on this if you're not able to solve uh the system equation using regular algebra okay so we have Sol using this kind of stuff now let's try to solve the system of equation by elimination so I'm just going to write solving by elimination elimination okay so how are we going bother solving it example 3x + 2 y = 19 and x + y = 8 okay so this is your this is going we are going to solve it okay so what do elimination means we are going to either multiply add or subtract the the the equations from each other so we'll see how to do that so let's say so over here what you so we we are going to multiply the equation so we are going to multiply so you can see that over 2 Y is over here so here is also y so we are going to multiply the second equation with the two the second second second equation with the two so we are going to multiply the second equation by two 3x + 2 y = 19 and 2x + 2 y = 8 okay so when you go further you you you have this and and what you do and what you do you simply uh have the particular now you subtract the second equation from the first equation you subtract this equation from the first equation okay now now you do the sub subtraction over here subtraction over here so actually you're are eliminating the variables from the first one so 3 3x + 2 y 2x + 2 y which but 3x + 2 y 2x 2 y so it get cut down so we will be left with X = to what 3 okay X = because when you when you do this uh 19 minus uh what are you saying uh uh it's I think it's 19 or it's 16 yeah so so this this this will be also it I don't know why I haven't multiply the both both side by two now we have to multiply both side by two so 6 19 16 will be 3 okay so 9 19 6 6 16 will be 3 so now we got the values of X so X = to x = 3 and when you do this 2x + 2 y = 16 put the values of 3 2 * 3 + 2 y = 16 the Y value would be 5 and you found x = 3 and Y = 5 this is called the solving by elimination you first of all you multiply the number by two for the second equation and then you subtracted the second equation from the first equation and you're done with solving your linear equation or system of linear equation okay so so this elimination is little bit faster but it needs a neatness it needs you to have good logic and it needs to have a good strategy but um you can solve whatever you like uh in the system of equation you can you can make use of any any of them maybe system of equation using elimination Al manipulation May or maybe substitution it totally makes sense to you okay so thanks for seeing this video I hope that you're able to make sense out of it this this this was the last lecture on lar algebra I'm very very excited to to start with uh calculus okay I'm going to teach the first time Cal calculus and whatever I know about calculus I'm just going to put put that in front of you so that it could recapt youate whatever I had studied as well okay so and it makes sense okay I'm able to teach then I'm able to understand that as well cool so I'll be catching up in the next video till then byebye have a great day hey everyone so let's get started with a new lecture on lecture number seven which is on determinant and this is one of the one of the again I would say important concept to study because in principal compon analysis or whether you uh it it it it comes a lot in your machine Learning Journey as well as well as in deep Learning Journey because it tells you how to solve or solving the linear equations or or or or if I if I talk about in terms of linear transformation it just tells tells you how the how the how the change in area or a volume occurs okay and and determinant is nothing when you it's nothing but you just TR you just give some Matrix and then you get one number so we'll be talking about that in detail in this session uh I I think you you'll get a lot from this session and and you you can make your own notes or the notes is in description un box below either it would be updated soon but yeah uh I it is it is already been made it's just sent for processing and that it will be into your description if you like this video please be sure to subscribe this channel as well as like this video and comment because YouTube algorithm knows okay this is a good video to recommend because many many other the people say uh your channel is underrated so I want you I want this channel to be a rated Channel because I work a lot on this channel Okay cool so let's get started with solving uh what is determinant so we'll we'll get onto geometric meaning soon but uh in in in determinant what you do if you know about a square Matrix if you know about a square Matrix which which we talked about and and I have told that is very important Square Matrix are very important is used extensively in linear algebra to use this term terminology so Square Matrix is nothing where your where your number of a rows is equals to the number of a columns for example uh your Matrix a is is maybe it can be 2 2 22 okay so this is a 2X 2 where n = 2 and M = 2 so n * n Matrix where your Square Matrix is equals 2 where your number of rows is equals to the number of columns okay so that is the so this is so what you do you take your Square Matrix and determinant takes one square Matrix where the number of rows is equals to the number of columns you write determinant of uh an A and A A should be the square Matrix a should be the square Matrix and then you get get one scalar or or or a number as an output when you apply the determinant function or or or when you take out the determinant of that Matrix okay so now how this is useful we will see how do we take out the scalar a just in a second numerically but but U but when you um how how the determinant is useful this is this is one of the most important concept to know so the determinant is useful in in solving and solve linear equation in linear equation it's used very very extensively solving linear equation or maybe it can be useful in and in in in in knowing okay in knowing how linear transformation and knowing how linear how linear transformation transformation change their area or the volume okay change their area transformation change their area change their area over volume or volume okay not over it's or volume and it is also and it is also useful uh in other stuffs like uh when solving some some computationally it it it it it does reduces some comput not exactly me doing efficiently not exactly I would say efficiently I would say very precisely so solving the particular linear equation and is used a lot in that so that's why we take out the determinant of a matrix and that when you take out the determinant of a matrix you simply give a squar matrix root to the determinant and then after when you take out the determinant you will get one scaler okay so this is what the this is this is this is what we use and and if if you talk about um in machine machine learning use case so in machine learning if if you know about machine learning in machine learning you have something called as dimensionality reduction method and and in that you take out the determinant of that covariance Matrix so covariance Matrix okay so when you take out the determiner of that covariance Matrix and then you and then and and and and then go further into solving the particular problem okay so not exactly covariance yeah so you take out the termin and then you go further into uh into other stuffs like uh uh the igen vectors and igen values and they are extensively used the determinant are extensively used in the igen vectors and igen values in principal component analysis okay so I hope that this is clear why we use determinant and and and what's the determinant is now now we need to care about how do we take out the scalar value because we give a function because we just give a a square Matrix into that determinant and then we will we are going we are we are just getting a scaler as an output so how do we even do that uh so for for doing that assume that you have a matrix a you have a matrix a which is nothing but 2x two so I'm just going to write um a a b c and d okay so you have a matrix a b c d which is a 2X 2 Matrix so when you take out the determinant of that Matrix a which is nothing but which is nothing but so a d means you take out the product of the diagonals you take out the product of the diagonals a D minus BC a D minus BC so for example you have a matrix uh 2 3 4 6 and and then you want to take out the Matrix the determinant of that Matrix 2x2 matrix which is nothing but 2 * 6 2 * 6 3 3 3 * 4 3 * 4 which is nothing 6 6 2 12 3 4 12 that will be nothing but zero zero is the answer or determinant of this Matrix okay so determinant of a matrix can be zero we have we don't have any conditions but yeah the determinant of this Matrix is zero okay so this is how you take out the determinant of how Matrix geometrically speaking okay so one thing that I want to highlight over here let's say for for example uh what does it mean geometrically what does it mean geometrically so so let's uh let me make one more page so that I could explain you what does it mean geometrically speaking what does it mean geometrically speaking either I could just go on some website to mean to mean what is actually trying to tell so let's go on one website let's go on one website which I want to show you all is this one okay so assume that over here of over here you have let me choose my black color okay here it is so you have um a matrix a matrix a b c d okay you want to take a determinant of this so this this is this is what you take out so for taking out the determinant you just write either in this A B C D giving a pipelines like this okay or or you write determinant of this uh a a matrix and this a matrix is either uh a b c d like this okay so this is the notation for swing that you want to take out the determinant of this Matrix okay that pipeline that big big pipeline okay pipe uh line okay now over here your a is 1 your B is zero your C is zero and your D is 1 okay you want to take out the determinant of this you want to take out the ter determinant of this you want to take out the determinant of this so how do you take out so what does it mean geometrically speaking so geometrically what it's trying to tell is when you plot this Matrix over here first of all you take this and then you go over here so this is nothing but the determinant of a 2x2 matrix is the area of a parallelogram with the column vectors AC and BD okay so this is the the determinant is nothing but the area of this parallelogram of this parallelogram where the column vectors are AC and BD okay so when you when you plot the 2x2 matrix which is which looks like this and and and this the the the determinant which means geometrically speaking is nothing but area of that parallelogram which formed by joining everything and then and that area of that parallelogram is nothing but determinant of that Matrix okay this is what does it mean geometrically speaking uh I would ask you to watch one video on three blue one brown to see how how he shown geometrically but yeah uh the the det terminal is nothing but the area of that parallelogram whatever forms so for example your par so let me reduce the a a bit and then let me do something with this I don't know what how it is working yeah so let me do something like this and let me increase the area okay let me increase the B okay here it is so when you have the column Vector when you have a column Vector as 0.86 and Z okay and then you have another column Vector which is 0.52 and the the parallel gram is formed is nothing but your favorite the determinant okay so this is what the determinant means and you can play with it by just going to demonstration W frame and this with this website so let's go on the 3D view so how does it look 3D so 3D is nothing but area area of that parallel Zoid okay so if you just see over here the area of the paraloid is is nothing but a determinant we'll see how to solve how how to solve this deter this determinant one okay we'll see how to solve um three for the how to take out the determinant of a 3X3 Matrix and we'll also see how to take out the determinant of uh n by n Matrix okay so it's a it's a bit hectic task but we will try to do it so this is this is what the geometrically means and for 2D the area of a parallelogram and for 3D area of a parallel Zoid okay which you can see from the diagrams which are shown over here so if you just if if I could zoom like I can't zoom in but yeah I can just show you this is this this is what you have your uh 3x3 Matrix and then you this is the parallel Zoid which is formed and then when you try to take out the determinant of this is nothing but the area of this paraloid okay so this is what it means and the determinant geometrically is nothing but the area of a parallelogram or paraloid in 3D dimension okay so this is this is what you need in in a geometric intuition just just just to make sure that what the geometrical it it means okay so now let's see now one of one of the important thing which I want to show you up is is is we have seen we have seen how do we take out the determinant of a 2x2 matrix so the determinant so here's your a here is your here's is your a and you have and then you want to take out the determinant of this A B C D and I'm just writing pipe to denote okay this is a determinant so when you take when you try to take out the determinant of this so it's nothing but equals to uh uh a a minus oh my gosh it's a minus BC that's uh then when when you take up that's a uh simple scalar which is e not exactly that not 3+ 3.71 1 it's e okay so let's let's give it any scaler which is e okay so this is this is what it means in 2x2 matrix I'm talking a specifically 2x2 matrix now now let's talk about how do we take out the determinant of uh 3x3 Matrix so determinant determinant determinant of 3x3 Matrix 3x3 Matrix matx so how do we even approach we taking out so you have want to take out the determinant of a b c d e f g h i okay so GH I is this is your Matrix this is the determinant of this Matrix okay so how do you take out how how do you take out the determinant of this Matrix and of course your it should be a one scaler okay it should be one scaler or a number or number okay so how do we take out the determinant so can't we do a * a * e * I and then it will not work this is this is not you can you you can just guess how do we do it just try and comment maybe I can just see and be a bit funny in job so please be sure to write it and I will try to see what you write it okay so so let's start approaching how do we even approach this problem so what we do we simply so so what we do just just make sure that first of all we go to the a11 okay so me first element in that Matrix and then what we do we simply leave this uh column and this row and write a minor Matrix or a submatrix of that of of that uh big Matrix or you can say that we take out the minor of this Matrix how do we take out the minor of this Matrix you simply when for for example you choose this number okay so what you do you you leave this call column and you leave this row and then you write and then what you do you take out the minor and then you take out the determinant the determinant of that by multiplying by a okay so the first element is this and then you have e f h i we left this column and this row and then we write EF hii okay we want to take out the determinant of EF hii okay now what you do now what you do here is your plus sign now it will be a minus sign over here okay you go to the B you leave this column and you leave this row okay which is nothing but B and D FG I DF GI because we left this column this row and this column just d f g i okay and then here is your minus then here will be plus plus uh you write C now we left this column this this this column and the first row which is which will be left the determinant of d e g h okay and then we have convert now these are called the minor or a submatrix submatrix or the minor of our Matrix a these These are called the minor these are called nothing but the minor these are nothing but called the minor minor of our Matrix of our Matrix a okay so when you try to now it is very easy a * a * uh EI now you can just apply your 2 x two a EI and FH EI minus FH okay minus b d FH d i minus FH okay plus C and then you have DH EG okay DH minus EG okay and then you'll be left with some scalar and then you can simply do do this thing and then you simply multiply with this and then you do do some calculation and then you'll be getting your output at has maybe some some scalar some scalar value okay so let's see one of one of the one of the one of the problem or or the stuff to to see how how it looks like Okay so let's let's assume that you have a a matrix or 3x3 Matrix so here's a question for you okay maybe you can try try to approach it uh the you want to take the determinant of I'm writing this pipe that denotes that you want to take out the determinant of that uh for example 0 1 1 2 uh 1 2 0 uh let's let's write 1 1 Z okay just a random random I'll be walking you through it so take out the determinant of this this is a 3X3 Matrix try to take out the determinant of this so how do you take out so first of all we go to the first element and then what we do we take out the minor of this Matrix so the minor so we leave this column and this row so we'll be left with zero and then we and then we write out minor and then we take out the determinant of our sub Matrix okay plus now no no no it will be not plus over here it will be minus because here is our plus minus okay one you leave this column and this row which is 1 0 1 0 okay so 1 1 0 1 0 okay and then you write plus 2 and then you have uh you leave one 2 1 1 okay you leave this column and this row okay you leave this column and this row you'll be left with 1 2 1 one okay and then you do the sum and then you do the sum so and then you take and then what you do you try to take out zero 2 * 0 which is 0 0 okay uh 1 * 1 * 0 of course 0 and 1 * 0 0 okay plus 2 uh 2 okay 1 * 1 1 2 * 1 two okay then you'll be left with of course zero then it will be done then it done it will be also 1 * 0 which is nothing but Z okay we'll be leftt with 2 * 2 2 * 2 that that will be 4 okay which will which is your determinant of this Matrix so 4 is your determinant of this Matrix which you are seeing over here so sorry here is 1 2 it's not it's it's simply 1 so 2 * 2 is the determinant of this Matrix so I'll be so here you got the determinant of this Matrix which is nothing but min2 okay so this is this is how you take out the determinant of a 3X3 Matrix as well so there are there are some problem for you to work on so I'm just just going to write it out so there's one problem which which which you can approach okay so you want to take out the determinant of uh 371 4 please answer the HW please answer in the comment box it's just a quiz which you will see in your attendance as well okay so this is what the determinant of that Matrix of the 2x2 matrix or 3x3 Matrix we'll try to solve the determinant of a 3X3 Matrix using lianes formula or the rule of surus okay so it's is very good formula to work on so we'll see that but before that I want to highlight some of the properties some of the properties of that properties properties of determinant Matrix of determinant of a matrix determinant of a matrix the first first one is the first one is the first one is for example you want to take over the determinant of this Matrix for example you want to take out the determinant of 1 z uh 0 1 okay so try try try to take out the determinant of this 1 * one which is one uh and then and then minus Z okay what what it will it is one and can you identify this is an identity Matrix even if you have uh 3x3 identity Matrix then that will be nothing but that will be nothing but one so whenever you have identity Matrix whenever you have if if if it is if it is identity Matrix if it is identity Matrix identity Matrix then then then the then the then the determinant of that identity Matrix will be one okay this is this is one of the property second property if the if the rules are the same okay so for for example if the rows are the same are the same for for example a a b b okay a a b b then AB minus ba a will be nothing but zero okay so this is another property third property is you have a scaler multiplied with some uh a and you have another scal c and b d okay so what it will be it it just makes sense r a D minus R CD or r r CB okay you can write write it down like this and then it's it's not it's nothing you just you just take that out of out of okay you just uh take take that as a common r a D minus BC okay so we can write this as a we can write this we can write this as a r * a b c d either we can write it now so we proved it so it is just equivalent you can write this so for it will be easily for us to solve okay so it is so it is R times as either it is same as over here so we a D minus BC so it's just equivalent to that so this is another property which you see a lot in while taking out the determinant of a matrix okay so this is these are the some of some of the properties which I want to highlight in front of you so now let's go on to the another stuff is how do we take out the deter DET minant how do we even bother taking of the determinant determinant determinant of 3x3 Matrix so you can just say okay I'm just going to just going to take out the minor of the sub Matrix of the Matrix and then I will do that so here's another another trick which is called the rule of suus I think it's it's just not a I would say uh okay it's a good technique but okay you can try it out but eventually I like that my approach but yeah it is very very straightforward approach which I'm going to tell over here okay so assume that you have a matrix M and that you have a matrix M okay so a11 a12 a13 okay a21 a22 a23 a23 a31 a32 a33 okay so you have this 3x3 Matrix now when you wanted to take out the determinant determinant of this Matrix M so how do we even bother doing that so for for for for so you can use the rule of suus rule of suus I think the funny name he has but yeah again I'm no no one to comment on on his name he's a again a great people okay so not I'm not even a one 1% of these people so these are amazing people who give a lot to the world so I think about I'm no one to say about but yeah amazing name so what you do you take out the determinant so you want to take out the determinant of a11 a12 a13 okay so this Matrix I'm just writing this Matrix a21 a22 a23 okay a31 a32 a33 okay and then what you do you take out the first two column and write it in another format like this a11 a12 A2 1 this is a trick for solving a 3X3 Matrix a22 and a 31 okay so a31 and a32 so this is a22 okay it say a21 okay so this is what you now you write this now what you do now what you do so what you do you you simply take out the product you simply take out the product like this the first diagonal okay so this is the diagonal so what you do a11 8 22 a33 okay a11 a22 a33 plus plus a12 a22 A2 3 okay A2 3 and a31 so what you do you take out the product of these three you take the product of these three so a12 a uh uh 2 3 okay A 2 3 uh and a 31 okay now what you do you simply uh do this simply multiply the next next diagonally okay so plus plus a13 a a 2 1 okay I'm I'm I'm I'm doing a bit messy so let me do a31 uh if I'm not wrong a13 a a a a13 a21 and a32 okay A a a13 a21 a32 now you are done with this now what you do now what you do you now go from bottom to top here you are going from top to bottom now you'll go from bottom to top by changing the sign now okay now you go from bottom to top so here's how you do here's how you go further okay so so the way you go is you have a31 so from here so from here a31 okay and then a22 and then you go to a a13 so now you start going at this side like like this okay so a31 I'm just going to write a31 a22 a22 and then a13 3 a13 okay and then what you do and then plus no uh you you minus because you change you go from bottom to top so here you minus it now now you go at this one now you do this and then a32 okay this one this one and this one a32 * a23 yeah if I'm it's a it's a a23 if I'm not wrong yeah a23 and a a11 a11 okay now minus now this is done now you go at last one which is this one a33 a21 a12 okay and here's how you take out the determinant of a matrix using suus rule okay or a rule of suus okay so and then you'll be getting after after doing this all those stuffs you can just cancel it out something if it is so you just you just come do do the computation then here's your Matrix and this just a scaler number or other stuffs so here's the rule of suru so here's how you do you do simply you do you do write the first two column uh at at the side so that it could be easily so uh so what you do you simply take of the product from top to bottom for the first three and then you take out the bottom to top for the second three starting from the last okay so here's here's here's what the full the rule of suus means here here's how you take out the determinant of that Matrix like this okay so now I'm going to talk talk about is uh you can see the Wikipedia Pages for a libanese rule because they write a very very kind of libanese stuff so you can just go there and see more see more about this rule okay so the next thing which I'm going to talk about is the next thing which I'm going to talk about is how do we take out the determinant how do we take out mean bother of taking out the determinant of n by n Matrix the determinant of n by n Matrix so how do we even take out that and how do even bother taking out that okay so here's so I'm just going to write the N by n Matrix I I'm just going to write the N byn Matrix or let's start with a particular example let's start with a particular example so it would to totally makes sense okay so let's let's start with a particular example and then at at last we'll just write a definition and then we'll end this video okay the example is bit long so I'm just going to maintain my handwriting so the example is and you want to take out the determinant you want to take out the determinant of a 4x4 Matrix 1 2 3 oh my gosh 3 4 okay 6 6 9 2 1 and then we have a 4 9 2 1 and then you have a 0 1 1 1 okay so here's here's your determinant of this Matrix so to take out the determinant of this Matrix so how do we even approach taking out the determinant of this Matrix so how do we take out the determinant of this so for taking out the determinant of this so for taking out the determinant of this for for taking out the determinant of this you take out you take out you first of all take out the minor or the submatrix of this okay so you you go to the First Column first element and then you leave this column and this row and then write the sub Matrix so you just one and then you take out the determinant of 9 2 1 9 2 1 1 1 1 okay this is plus sign so it will be minus sign now you go at this take take of the sub Matrix leaving this row this column and this row so it would be two first of all you take product it so you multiply with that two two times uh the determinant of 6 2 1 6 2 1 4 2 1 and 01 1 okay and then you uh change the Sign Plus and then go through with three and then you leave this column and this so it will be nothing but uh three and then you have 621 I also just write okay 66691 I I just leave it so I'm three 691 691 uh 491 491 and 01 1 okay 0 1 1 now the last one is there four okay so there is four and then you take out the terminant of leaving all the all the uh column one and then row 692 2 692 492 and uh okay I think it's wrong 492 and 01 1 okay these are the sub Matrix of that Matrix let's name it as a m okay so this is a matrix M and then you have to take a determinat of that Matrix M so here's the 4 4x4 now you do this now you have this now what you do now here you convert it to 3x3 determinant now what you do you convert that to a 2X two here's how you do so you you don't want to use a s rule because I I eventually don't like that rule it's very hectic rule sometimes it maybe cause you error but no problem in that so here's how you do it so first of all what you do so first of all what you do you simply uh multiply uh one okay you simply go ahead and take take your uh one as a so if you can see I just want to take that one as an uh uh this one and then what I and then I go and approaching this so here is your nine so first first of all go at this element take out nine we want to take out the sub Matrix of this Matrix so 9 and then you take out the determinant of 2 1 1 1 so what how this came 2 1 uh you leave this this row and this column 2 1 1 1 okay now you simply change the sign minus okay you make sure that that you're doing only doing for this you're only doing for this we'll come to this later on but we are only doing for for this a21 okay minus now now we go to this two now we go this two we leave this column and this row which is 911 1 okay so which is aray what happened yeah so which is nothing but uh what do you say uh two because here is our two leaving this row this this this column and this row 9111 okay uh the determinant of 91 1 1 okay and then what you do plus now you change the sign and then you go at last one leaving this 9 21 1 okay so the 1 and the 9211 okay so you take out that okay now this was plus now you make it minus okay now here is your two so I will take that outside I will take take that outside okay and then I will just go ahead into solving this so you take this take this as a now you take out the minor of this Matrix or the sub Matrix of this Matrix so here's how you do it so you simply add it minus so here is minus is 6 uh 21 1 1 so here here's how you go with this you ignore this column and this row 211 1 now you go to this you ignore this 41 0 41 01 and then you go over here ignore this 42 01 okay so this is how I'm I'm I'm going to write minus 2 okay because you go over here two over minus 2 CH changing the sign take out the determinant of 41 0 1 4 1 0 1 okay and then you simply plus u now you change the sign you go one go to go to 1 42 0 1 42 0 1 uh + 1 uh 4 2 0 1 okay and then what do you do and oh my gosh yeah so then what do you do now you now you converted that 3x3 Matrix for this one and for this one now you go to this one okay by changing the sign plus plus and then you go and then you write separate three now you write separate three and then you take out the first one six okay so you leave this column and this row which is nothing but six and then 9111 which is the sub Matrix of that Matrix 9 because this plus 9 and how how how 9 came you go with this column leaving this column and leaving this row 41 01 which is nothing but 41 01 okay plus changing the sign 1 4901 how this 4901 came is you have this you leave this and this you leave this column and this the row which is 4901 okay so this is how you came it and then and then you're done okay now what do you do you you do for the last one you do the for the last one this because you you done for this you're done for this you're done for this now you converted that to a 2X 2 m which is easily deter which which we can easily take out the determinant now you go to this okay so here's how you do it so 4 okay and then what do you do and then what do you do you leave this column and this row taking know the first element so six the determinant of I was I think it's it was 9 9211 9211 9211 minus minus 9 okay so over here it was living this the SE going to this and leaving this column and this row which is 4201 I I I think about it yeah that's 4201 4201 and then you change the sign plus 2 49 I think it's it's it's more about you leave you go over here 4901 okay that is 4901 okay now you're are done now this is what you have written so you converted the first Matrix the first Matrix this one this one and this one as well uh into a minor Matrix which is 2x2 determinant so you can easy take out and then do the product and then you take out okay so let's do over here if if if I have a chance to do over here but no work problem I will do over here okay so here's how you do it here's how you do it so for doing it first of all you have the one available which is over here you have the one available which is over here what do you do you simply 9 16 + 7 how how how we came so you have the particularly 9 times because of course you want to always want to uh multiply it out okay so I think about this is you have uh if if you go over here 2 * 1 okay and 1 * 1 so 2 2 2 * 1 how much 2 * 1 how much it would be uh 1 1 I would say uh 2 1 which is 1 so it will be 9 okay minus minus over here uh 9 9 * 1 which is 9 1 which is 8 16 16 done and then you have 9 * 1 and then minus 2 * 1 so 9 2 which is 7 okay so here's how it came okay and then you then this the left minus 2 now you go on second one two over here so when you when you take a 2 * 1 how much 2 * 1 how much 2 * 1 2 1 okay that is 6 over here so we write uh 6 8 + 4 okay so here's how you do so it is 6us 4 * 1 of course 4 * 2 it's 0 * 1 of course zero so 4 * 1 4 * 2 which is 8 which which you have written over here okay then you go over here 4 * 1 how much 4 * 1 4 and then you four so here here is a plus 4 now now you go the next + three because you go over here now 9 * 1 how much 9 * 1 how much uh 9 * 1 9 of course 1 uh which is nothing but 8 8 * 6 48 so you have 48 36 + 4 okay so here's our 48 9 uh so 4 * 1 4 so 4 9 4 9 36 because this 2 * 0 is 0 then you go over here then you have this 9 9 9 * 0 is of course 0 4 * 1 so 4 2 8 so over here uh I think I'm wrong over here um you have this 4 * 1 4 910 0 so four uh it's it's it's it's four okay so it's four it's it it it it it should be eight okay it should be eight which is nothing but what you do you 4 * 1 4 and then you simply multiply with two which is nothing but 8 okay now you simply minus 4 4 uh 28 36 + 8 so how you take out 9 * 1 how much 9 2 7 7 7 6 7 7 6 how much uh oops it's it's uh it should be 9 * 1 2 9 8 7 7 6 14 42 okay so which will be nothing but 42 what the hell i' written over here so I have to just couple it out so I have to just return it it will be nothing but 42 okay minus minus minus uh minus 4 * 1 of course 4 9 are 36 plus 2 4 4 1's 4 4 2 are 8 okay so here's how you do it now you simply multiply with this and then first of all do the calculation do the the calculation then you'll be getting one a scaler as your output so please feel free to put your answer in the description box below I know the answer but yeah I want to leave it to you to do the rest of the calculation because I have done a lot so here's how you take out the determinant of n byn Matrix and how you do it and how you do it's very very easy you just uh keep converting that to a lower or a sub Matrix and then you and then after that you are done okay so here's how you do it so you you define one you define one submatrix a J you define one sub Matrix a i j which is nothing but the Matrix the n n 1 * n one Matrix n minus1 n minus1 Matrix if you ignore the I row and I column if you ignore if you ignore the I row which which you were doing I row and J column which which you were doing okay that is your new Matrix which we which we were forming that is a recursive this is a recursive you can write a Python program for write a recursive solution for this okay so you were writing A1 one and then you were adding the determinant of that submatrix and then you are doing so and so on so on that is a recursive solution so you are writing the recursive recursive stuff so we we we already written a lot so I hope that you understood for formal definition which you can see yeah we have gone through one of one of the example which is very very much important for us to know okay so I hope that you will uh get a lot from this video and determine it I hope that concept is clear with my examples and I also hope that you enjoyed this video I think I have to wrap up with wrap up with this video I'll be catching up your next video till then byebye have a great day meet you in the next lecture hey everyone welcome to this first lecture on single variable calculus from this video I know it's bit 6 days till the video is not being uploaded it's because uh I was I was having some examination that I will that I Was preparing for and I Was preparing for the content for single variable calculus so in this series of lecture we'll be talking about single variable Cal calculus it's U I would say will will come to calculus but uh we had a talk on on linear algebra and some of the videos like I vector and I values to be added okay so that is to be added and that is sent into that is we are making some good examples so that everyone could be could could get some uh fam familiarity with the igen vectors and I values so we always want to deliver you the quality content not the in a fast way or whatever the cont so that everyone could understand igen vectors and igen values that is left and soon it will be added so over here now we'll be starting off with single variable calculus I don't know what happened just in front of my screen but that's a my SQL update no problem just just just for those who wants to know so we'll be starting with the lecture number one uh which is a single variable calculus and this VAR I'll be talking about uh I'll giving you an introduction to calculus and what are the content which you're going to cover okay and what is the next series of videos in this ml2 okay and from now on the video lectures will be around 3 to four videos per week now my everything has got over I'll be focusing on the completing this series as soon as possible cool so uh so in this video we'll talking about that uh friendly introduction to calculus I have prepared my own lecture notes so that I could not miss any topics the first thing which I talk about is giving you what is calculus many people think there is some misconceptions about that I will I will say you uh I will I will just I will just give you some examples a geometric examples of what calculus is and what calculus is not okay uh what are the problems that can be solved using calculus what are the problems that cannot be solved using Cal that that does not require calculus okay we'll talk about two big ideas in calculus such as differentiation and integration now you may think here you you're going to start with differentiation integration don't worry my friend it's very very very I will say I will just give you an I I would say a ta a trailer means 0.1% what is going to come in differentiation and what is going to come in integration okay the geometric view only okay so then then we'll end this lecture talking talking about this lecture now what will be the content which will be in this lect uh single variable calculus course so first of all I don't want anyone to be missed for example many uh high school students watch watch this video so we are going to start with the precalculus we are going to start with a precalculus so I hope that everyone will be comfortable with the precalculus I'll be not covering logarithms I'll be not covering basic algebra because I require you to have a knowledge till class 10th math and uh I hope so you'll be having that like logarithms like uh I'll be talking about trigonometry as well and don't worry about that so I want logarithms and basic algebra like factoring GC F and a lot more so these are the algebra 1 and Algebra 2 which are required like exponential functions as well so uh in precalculus we'll be talking about the two two main Concepts which will be not two main Concepts I'm talking about functions talking about functions mainly the functions functions and we're talking about uh the second one is uh we'll be after after talking about functions we'll be talking about trigonometry Trigon metry okay so just review these two topics from a scratch so that everyone could be familiar it with what's going on and the and and in the further lecture so we'll be covering precalculus in two videos okay so we'll be talking about calculus then we'll going then then we'll talk about limits okay and after talking about limits we'll talk about differentiation solve taking out the derivative some of the power rule power rule then the there are lot lot lot of the rules which which we which are going to learn for taking out the derivative we'll talk about integration solving taking taking on integral for a function and then in infinite series okay so these are the things which will be taught uh in this single variable calculus Series so let's get started with this video so basically in this video we'll Define what is calculus anyone could Define me what is calculus just go in Des description box and tell me what what is calculus what is calculus so anyone could give it a try so calculus is is is is is is you you may think it's a different subject it's not a different subject it's not a something oh my God what is this a rocket science it's a it's a very Advanced version for your algebra and geometric problem okay so calculus I think is a Zach Newton and other the great great physicist mathematicians invented it for solving the some of the great problems so calculus is nothing but Advanced version of your regular algebra Advanced version Advanced version of your regular algebra which you see regular regular algebra and geometry and geometry which you see in real world okay so we'll we'll see some examples so what do you mean with this we'll I will give you a formal definition of calculus when we go further in the course the reason why I'm don't want to give you the formal definition to so that you canot confuse you could not confuse with a definition because I want to be very very clear in the first lecture so I'm going to I want to take some example of it okay so let's take let's take an example let's take one one example let's take one example so example can be example can be let's say that you want to find that you want to find the slope of this line slope of this line so slope of this line can be fin over uh like like this so you run so this is called run and this called rise okay rise okay the slope can be found using a reg regular math of the straight line by the slope can be can be regarded as a rise over run rise over run rise over run okay or Y2 y1 / X2 X1 okay so it tells uh it it just tells how much the Y changes when X changes okay that's how we this uh this is this is telling which will come to that we'll talk about slope briefly in our future videos but over here you can calculate the slope of this line by simply your regular math problem your reg regular math problem isn't it you're using a regular regular mathematics okay mathematics but you told but you're told to find maybe you you select this point and want to find the slope at this point and at every point in this for example over here the slope will be same for this line so over here if you to find the slope at this point you can take another point and then take out the slope for example it goes one uh one at the rise and goes up at the top so that will be slope for every point the slope will be of same okay so so this is a this is this is you can calculate so for every point in that line the slope will be the same now coming to the another this is this is your first first figure this is your first figure number one okay so this you can calculate the slope of this line using your regular math which you can see over here now I if I if I just tell you if I just give you a a line so let me just uh oh my God where is this okay so this is your this is your thing and and you have me just draw a little bit big line uh something like this you want to calculate you want to calculate the slope of this curve line I'm to calculate the slope of this curve line you cannot use you cannot use slope over here slope over here will be not used your regular math your regular math is can cannot be used because every time the slope is changing every time the slope is changing every time the slope will is changing so so you cannot use your regular mathematics over here okay you may think I will just take out the slope and then take out the average but what if I tell you take out the exact slope okay so that it could be same at every Point how do we do that how do we even do that so for example if I try do it over here okay I try to I try to take take out the slope at this point you may think okay I'm going that side but it's but isn't this changing if I go over here here this the the the the slope is changing the slope is changing so what if I to say you to calculate the slope of this line you'll be not able to using reg you'll be not able to calculate using regular algebra okay so it is solved so mathematicians has comes up comes C up with Calculus they have came with Calculus so calculus using calculus you can take out that slope on on on on any particular point in that curve okay so using calculus you can calculate the slope of uh what slope of a maybe curve okay so using calculus there's topical differentiation which will come to that so using you can calculate the slope of a curve okay so that's that's what the one of the calculus problem is okay so uh you can see that I differentiated the regular math problem with a calculus problem this is a calculus problem this is a regular math problem now let's see you have a one you have a one Tower okay so assume I'm taking another example I'm taking another example okay I'm taking another example over here let's let's say let's for for for the sake of an example let's say that you have a tower over here so assume this is a tower of yours okay so this is a tower I'm adding T1 which Tower number one and this is your Tower number two okay Tower number two now you need to calculate now this is your straight line okay this is your straight line cool so you can calculate the length of this using your regular math okay using your regular mathematics problem the length of this can be calculated using a regular math problem but what if I give you there's one Tower there is one Tower and there's another Tower and the wire is something like this the wire is something like this and then and you're given given this stuff C calculate the length you're given the specific stuff and you calculate the length how are you going to calculate it you cannot calculate using regular mathematics whatever you have in your toolbox so there the calculus comes there the calculus comes for calculating the the the slope of a curvy line okay so this is there's the calculus plays an important role so let's example you want to calculate the slope of of of course over here the slope will be zero but you told to calculate the slope over of this it will be you'll be not able to calculate using a regular problem here you need calculus okay so these are some of the instances where the calculus are being used extensively in real world examples okay so there are two big ideas in calculus which I want to highlight there are two big ideas in calculus which I want to highlight the first the ideas in calculus let let me write what are the ideas in calculus the ideas in calculus the first is differentiation different differentiation second is integration integration okay so there are two two big problem which are differentiation and integration so so I will just go go over it very quick way to make you understand about this what does these term means so let's talk about differentiation let's talk about what does it mean differentiation and of course there will be long long Le lectures coming on this briefly talking about this a lot with a lot more examples Okay so uh differentiation is a process for finding the derivative of a curve derivative of a curve so it's the process it's the process for finding for finding the derivative the the derivative of a curve of a curve okay so differentiation is the process of finding the derivative of curve but what is a derivative what is a derivative derivative in calculus derivative in calculus is just a fancier version for saying slope derivative is nothing but is just a fancier version is just a fancier version fancier version for slope okay so in calculus we we we call D we call slope as a derivative okay derivative for the curve okay so you find the derivative of a curve and derivative is nothing but a slope of a curve okay so derivative in in a nutshell a derivative is nothing but derivative is nothing but I is equals to slope and is as well as it is a rate it is a rate of instantial instanes change okay so we talk about that but you can think of it as a derivative as a rate so what is rate over here so let's take an example you want to calculate miles per hour miles per hour okay how much this miles changes when hour means it means what it if you go 1 hour then the miles is bigger like that miles per hour taken or a profit per item these are the rates okay profit per item so these are the derivative is that okay so derivative is just a fancier version for a slope because in slope we take out we can we can't take out the slope of a curve line but using the derivative you can calculate the slope of a curve line okay so uh this is this this is what I want to tell is over here you have uh this problem and you have this problem this problem so this is the ra this is a run you run X x uh X on in X direction and you go uh and then then you rise okay so the slope is nothing but rise over run so it just tells how much the how much the Y changes when X changes okay so this is what the slope is and the derivative is nothing but the slope of a curve okay so what's the slope of a curve what's the slope of a curve what's the slope of a curve what is the slope of that the slope of a curve is the uh let's let's let's take one example let's take one example I'm just I just believe in taking an example okay so we have an example something like this you have a X and Y plane and you have a X and Y plane something like this okay so you have something like this oh my God what is this okay so this is this is your curvy line you take out the slope okay so you select any two point A and B okay you select any two point A and B and join as made a secant line over here so we'll talk about this later on so you joined it okay now what you do now over here the slope or the steepness of this curve the slope the slope or the steepness steepness of the particular curve is changing is changing every is constantly changing between your point A and B okay so if you go over here the slope and steepness is constantly is very steep over here but it is so over here is the slope or the steepness is constantly changing for this curve between your two points which is a and b okay so let's take an example that you want to calculate the SL slope at the at at the at the exact point exact slope at the point C so how you're going to calculate so the geometric view which which I want to tell what you do in basic differentiation you zoom in as infinitely you zoom in infinitely far zoom in infinitely far in that at at that point so for for example you you zoom in infinitely far I'm telling you the geometric view telling you the geometric view so what what you do you zoom in so when you zoom zoom in infinitely far this curvy line becomes your formal straight line okay so when you zoom at this reason you zoom in extremely far infinitely far although you cannot get too much infinite but just assume as a geometric you zoom in a lot there is something called limit property which which we'll talk about but when you zoom in too much what it so it would this curve line will become a straight line okay so when when you zoom it so this curve line will become a straight line so let's take an example that be zoomed in too much too much and and now over here this curvy line becomes a straight line now here's a point C now this is a regular calculus problem so sorry regular math problem you can just uh go over rise okay rise over run okay now you'll be calculating the slope at that exact point okay so what you exactly doing is zooming zooming infinitely far infinitely far okay Zoom infinitely far that that that curve okay uh at for at that point at that point C so the curve becomes curve becomes straight curve becomes straight at that point okay and then you can solve using the regular math problem which is rise over run okay it's not a big deal to understand it just geometric View but we will again revisit differentiation these topics again in in our later videos okay so that is differentiation which is finding the derivative or the slope of a curve at any point C okay so now so we have seen differentiation now now let's see integration the definition of integration so we'll talk about integration means it is not if you're getting confused bear with me these concepts are too too much uh I'll explain in too much easy way so you don't need to uh to to worry about these but if you're being worried don't worry I'm just giving you a geometric view we'll again revisit these concept times and times so let's say for an example that your it's is the area under the curve it's the area under the curve actually okay so I'll just give you what is happening integration uh so this is your favorite uh X and plane and this is your oh my God so this is your thing and then you have a line something this and you're told to calculate the area of the Shaded region area of the Shaded so this is a rectangle this is this is a rectangle you can just calculate the area of this sh line so sorry what you can do actually do so say say for example this is your y5 and you want to calculate the area of this C line okay length in the breadth okay not a big deal to to talk about because maybe this is this very easy to understand it isn't it so so over here we are we can this is reg regular math problem this is a regular math problem regular math problem regular math problem but what if if if you get something like this what if if if if you get something like this so you have this and you have this and let's say for example that you have the curve like this and you are told to calculate the area of the Shaded portion over here it's it does not make any sense that how we going to calculate the area of this C line because not anything we cannot use our regular math over here so here's what we Cal integration is nothing but area under the curve area under the curve okay area under the curve and differentiation nothing but the SL derivative or the slope of the curve slope of the curve okay so different in integration helps you to find the area under the curve okay by adding the we we do is it is nothing but addition okay it's not a big deal we understand it much better way so you write a differentiation for a function we we'll talk talk about I'm not going to introduce it as of now so this is your integration which is the area under the curve and that is your difference differentiation the first topic will be differentiation we're talking about and then we'll go on integration okay so I hope that's not a big deal and I also hope that you understood this now this is this was the first lecture if you have understood a little bit about calculus and I hope that you understood a little bit about this so please give a thumbs up to this video and I hope that you liked this video I'll be catching up your next video in talking about precalculus about functions and then trigonometry and then talking about differentiation and I hope that you enjoyed this tutorial I'll be catching up in the next video till then byebye have a great day hey everyone welcome to this second lecture on single variable calculus uh so in this video we'll be talking about precalculus basically we'll be completing our pre precalculus uh and the in two videos as I think that I should review functions and I should review trigonometry so that everyone who has lost touch in this uh they can review it and the one who is who has at least seen these functions in trigonometry before they can uh just refresh up it is not a full full videos on functions and tri trigonometry I'll recommend watching some of lectures on trigonometry and functions if you want to learn actually trigonometry and functions and solving it but basically it will Pro provide you everything you need for calculus mainly the what you need for functions and you will whatever the trigonometry you need for for for taking of the trig values about uh we we'll talk about sakova we'll talk about one one more thing which is uh uh the special right triangles we'll see some of the tricks for solving the for for for solving it uh we'll also see the unit circle where we'll be seeing the radiance degrees and every stuff will give you the graph of cosine and uh uh cosine and S we'll try to give you the graph of that so I hope that you will enjoy the these two set of videos on precalculus if you're completely new to math and your class I think class 10 then I think that you're good to go just review the lecture of this if you are a little bit go ahead but means you can if if you're in college or or other set of classes I would say uh these these will be good refresher for you cool so we'll revie we'll be reviewing our function so what is the function if if if you can go ahead and write in the description box uh basically the functions is tells you the relationship it's a relationship between your two things in which one depends on other for the for for for for doing some processing okay so basically I think about the functions it's it's a relationship it's a relationship Rel relation it's a relationship just let me write relation relationship between two things between two things in which and between two things in which one depends on other in which one depends on other in which one depends on other it may it it may happen that you're that you're not able to get this what the definition is so let me write a function which takes any value X and Returns the square of that X if you are into programming and I hope that you are in so uh it's it's it's okay that you are not in so you may have seen functions before and and I really hope that uh in in in your programming you just Define the function so what the function does it takes some arguments okay so over here it takes some input values okay and the function do something and Returns the output okay so what is trying to do what is doing is taking the value in input value input value and returning the and doing the square of this so what is doing in the box so we are giving the giving x to the function which is f it is doing the square of this it's doing the square of this and giving your output y Okay so for example the function f let's say we give two to this function it will return it will it will take out the four and then it will give y as a four okay so basically it is the function f is doing some processing and giving some output okay the same way you think about the functions it's it's um it's it's it's kind of a processing what it is doing for example in this F ofx = to x² so it is taking the input value and then squaring them up the function can be let's take an example it takes uh maybe a set okay a set I would say giant X and Joint X is nothing but x equals to the X1 X2 and X3 okay and and and it doing what what it does this function tries to multiply with some Theta okay for example it multiply with some constant to 2 * X1 + 2 * X2 + 2 * X3 so it take the set of input values okay so I hope that that function is making sense what the function actually is so it takes one input value and do do the square of it and give the output value so Y is consider over your output value and X is considered as input value Okay cool so so so let's so let's let's go ahead um basically uh input value is the one which we input anything for example in this case we input two into that and then it does some processing as I said and Returns the square of that or gives the output value cool so I hope that that you that you're making that you made sense out of it so now let's talk about some of the terminology which I want to introduce to you first of all domain of a function the domain of a function so set of all the inputs the set of all the inputs of a function set of all the inputs of a function f let's take F function f is called the domain and what is the range what is the range range is set of all the outputs set of all the outputs set of all the outputs of a function is the range of a function okay so so say for say for an example that that you have a function that you have a function f that takes the value first of all that do the square of that do square of that so you give one and you give min2 over here you return 1 and four okay the domain is 1A 2 and uh range is 1A 4 okay it may happen that you may enter the third two and it will give four so it may it it it cannot be it it can be the same thing four four it can be the same thing okay so these are the certain terminology which you will see a lot in the uh up upcoming videos okay so I want to introduce you two things which is independent independent variables so all the input values are independent variable or values okay so basically so basically all your input values input Val values input values are the independent independent variables independent variables okay all the input values are the independent variables and all the and and the output values are called the dependent variable output values output values it it makes sense are the I I just want to include this one this one this one this one you can just write it out okay are the dependent variables so so it makes sense that for example we give the function f maybe X okay and X is not dependent on anything to be relied because X we have to give it is independent it is not dependent on anyone but this Y is dependent on these X on the input value so that's why we say output value is dependent variable and input values are independent variables okay these are two things so let's take an example I'll take I'll take one small example let's say let's say you have a function you have a function uh F ofx okay x² and you have another function G of X okay which is 5x 8 okay so you have two functions f ofx g of x 8 now now there is a chain of function so let's say F of G of3 if someone ask you to evaluate this function so how will you do so this is these functions are called as composite function composite functions these type of functions are called the composite functions Okay so what we do first of all as as you already might have been guessed okay I'm going to just evaluate G of3 and whatever the output G of3 will give I will give the input to the f of x okay so what how this work workflow will do first of all we'll evaluate the G of 3 okay so 5x 8 we give 3 to the input and we get output as a 7 now we give this seven as a input to to our F x² now that is uh F and then we get the output 49 49 okay and 49 is our uh output value okay so 49 is the answer or or or the result when we apply the G of3 with the output uh uh f f on the output of the G of3 okay so these the these functions are called composite function okay and I hope that you you will see a lot when when when we started change rule of differentiation and it's very very used there you will you'll make use of composite function you make use of the terminology of composite function cool so uh so maybe if you just you can you can just go ahead we have a line so let's let's let's talk about uh slope okay it's always better to talk talk about slope okay so uh let's go ahead talk about the slope say for an example you have the line you have the line okay so I I just draw a very bad line so let me just pick up this and let me just I don't know how to do it leave it so you let's let's take an example that you have a line okay that you have something like this and you have a line and you're told to find the slope of this straight line and you can do with regular math it is nothing but the slope of this line will be rise over run okay so so you can take any two values any to values you Y2 y1 / X2 X1 so how much y changes when X changes okay so it is just telling how much y changes when X changes okay so this is nothing but the slope okay slope is not a big deal to understand it so I hope that it's that it makes sense out of it now let's try to do one thing let's try to do one thing is Let's uh let's let's plot one line so graphing of a function how we do the graphing of a function let's let's let's talk about that a little bit so graph of a function graph of a function so let's take a let's let's say you to you have a function y and you write a function yal 3x + 5 you can also write the function something like this let's take an example you want to make a graph of this function so how are how are we going to do that so basically what I'm going to do let me just remove these straight line I'm just going to draw every everything over here so let's let's take let's take an example 2 4 6 8 10 12 14 uh let's let's do 14 14 uh 16 18 and 18 and 20 okay you have you have 2 4 6 6 oh my God this is 8 10 12 14 16 18 18 and 20 Okay so so how do we even plot our function y = 3x + 5 so we make a table we make a table so let's make a table let's make a table some some something like this let's make a table okay some something like this and you give X and Y okay so Yi you put the values of X so for example you choose x = 0 so when you evalue 3 * 0 means the output will be five okay so the so the first point you got 0a 5 so you put the point on that okay so on y value we have some over here okay now you put 1 and when you 3 * 1 3 + 5 which is 8 okay so 1A 8 is another another point so one and 8 okay one and 8 so maybe you go ahead my diagram is not good so you you will you will keep doing that and and just is uh just to draw a s straight line over there okay just just just draw a straight line over there uh just joining the points and you'll be getting your graph of a function I know it's I think because of my X and Y plane it is failing to draw but you can just take a graph paper and work on that okay so this so we had a talk on slope and we'll revisit the slope in times and times when we talk about differentiation so don't worry if if if you don't understand it but I but I can just hope that you understand a little bit so a straight line is if if you know about slope intercept form slope intercept for okay so over here you have y = mx + b is an equation for a straight line okay uh straight straight line okay where m is the slope m is the slope m is the slope if you all have already been seen and B is the y intercept B is the Y intercept okay so what is the inter Y intercept and x intercept if your line crosses some from here so the Y intercept of this will be four because it intercepts the the the Y AIS at the point 4 okay so that's the that's that's called Y intercept and slope is nothing but rise over run okay which is Y2 y1 / X2 X1 cool so these these are some of the talk on functions and I hope that that you are able to get the sense out of it now let's do one thing let's try let's let's let's try to talk about these the two two kind of functions which you will see a lot in your different in your Calculus journey is parabolic function and absolute value function okay so let's let's talk about that main the graph so U so let's take F ofx = x² this is is an equation for your Parabola okay so maybe let me let me take my black pen I think that that works okay okay okay so now when you when you try to plot it when just just just make a table X and y1 and try to put put the values and get the values so you put the values of X you'll get the value of y put the random Val of X put the Rand get the get the value of y and keep keep putting on the over here so you will get the parabola something like this let me touch it I think it's just not a it's it's not a good good Parabola but yeah okay so this this this is the diagram of your f ofx equals to or a graph of f ofx = to x² okay so you you may you'll think that this function is a continuous function we talk talk about that I I I just don't want to introduce you over here okay so uh this function is a continuous function we we see we'll see how to uh this it is also differentiable so we will talk about this so so that's why I'm in introducing to the graph of these plots so that it would be easy to understand that at at that point so this is your don't worry if you don't understand what is continuous and what is differentiable just I've told you we'll talk about in detail in our later videos okay so this is a function for your F ofx this this is a graph of your F ofx = to x² okay so I just want to draw another make a graph of another function f ofx equals to absolute value of x so absolute value of x so the the the so the the graph of the function will look like straight line let me join it over here join it over here okay so this is your graph of the function okay this is your graph of the function f ofx this is this this is a graph of function a g of X let's name a g of X because it will be confusing G of X Okay g of X where this this is your graph of function okay you can put the values you will get the exact graph of this okay but one thing which I want to tell you that this is a continuous function this is but this is nondifferentiable you may think hey why you telling this now you can tell me later on so just for your information I'm just telling so that why we are introducing these kind of graphs and in front of you so first of all I told you one property that the which is continuous and which is differentiable if you don't understand ignore it the second the second conclusion which you can make out of it the second Insight which you can get of this is both are symmetric both both function fun are symmetric both functions are symmetric with respect to two with respect to Y AIS okay so if you know symmetrical okay this makes them even function these are being symmetric this these are the these these functions are called the even functions okay another thing is the the polinomial function like this or let function like this F of f of f ofx okay = to 9 x^ 4 4x² + 3 so this function is also the even function can you guess why because the power the powers all the powers all powers are even okay all the powers are even okay so so that's why it is a even function so so so so that's why it is an even function if the powers are odd okay then that will be a odd function okay so I hope that you that that you understood either it's not important to know what is even function what is odd function but just for a general purpose I I told you cool so we had a talk on functions now let me see how much the time is being there I think 20 minutes we can go ahead talk about trigonometry now so we had a we had a brief talk on functions and I hope that you had got a very good sense on that so now what I will do I will just start off with uh with the basics of trometry uh either we can get started in the next video I think yeah so let's so I think it the I will just pre prefer in the next video for trigonometry because because there there's a lot to talk I can't continue with this video so I'll be catching up your next video in trigonometry because this is a two pages so I need to and I need to make around your 40 minutes to talk about trigonometry because trigonometry is a big topic to understand so we after after trigonometry we'll talk about limits we will talk about there are a two three videos coming on limits first of all what is limits the evaluating limits squeeze theorem so we'll talk about that mean the sandwich theorem so we'll talk about that so I hope that you had understood this very properly I'll be catching up your next video till then byebye have a great day so now we'll start with the trigonometry I think we'll just review trigonometry in such a way so that you could be from comfortable with upcoming calculus videos and this is not a math Channel I don't know why I'm feeling like I'm teaching mathematics it's it is a part of our machine learning course sorry deep learning course which I'm teaching so that's why I want everyone to go from very scratch to such an advanced level Because deep learning is a b speed so so that's why you have to first of all make your fundamental strong okay so we'll we'll be getting it started with the trigonometry okay we'll just review uh some of the trick functions we'll also review the unit circle maybe some of you have far good in it or I don't know about that I will also review how to graph sign and cosine okay so basically what is trigonometry first of all maybe you can just uh it's it's it's a study of triangles or maybe the right triangles which you see so mainly the trigonometry is the study of right triangle and there are total of three main trigonometric functions so there are total of three main Tri Tri trick functions I'm just going to write trig functions so they are total of three main trick functions the first one is the F the first one is sign okay s second one is cosine the third one is tangent okay so these are the three uh main trigonometri functions and there there there there are some more which which are called cosecant secant and cotangent so these three and the reciprocals they they reciprocals they reciprocals are also there some some important trick functions so they reciprocals the reciprocals are also the very important trick function such as uh cosecant Co coant secant second one is secant and third one is cotangent okay so we will talk about these in detail in in our whole session we'll talk about these six Str trick functions as these three are the reciprocal of this so we'll will study everything today uh these three six functions our our whole lecture will go around these St functions okay so I want to introduce to you something called a some some I would say um uh u i it's I I would say a good weapon for you okay a weapon that helps you helps you to solve uh trick trick trick functions very easily and very very very very very important uh the the sign to remember the what is a sign of the particular angle so that is nothing but cira so TOA so maybe some of you some of you have seen this and some of you have not so this so SOA is very very important in your trigonometry Journey it's very again I'm saying very very important many many people has different different stuff but very very easy to understand and very very easy to uh it it it helps you to remember the definition of your s cosine and tangent so using CA you can remember the the the definition of what that sign means what the cosine means and what the tangent means and it is very very useful and very very important about this okay many people say different different Rhymes to to to identify the definition of s cosine and tangent but I think this is the best and one thing which is easily remember rememberable to anyone okay so what I'm going to do is to I'm going to make a a right triangle okay so but before that I I I just introduce you in that right triangle what does it mean so first of all let me make the pen a little bit lower yeah so so let's take let's let's say let's say for an example that you have this one and you have this one okay I I just don't know how to draw a good line and and this one is and this is your right triangle let me okay so basically this this is called the hypotenuse so let me just give a name so this this is called the hypotenuse hypotenuse which is given Edge okay and hypotenuse is the largest side in your triangle okay this is uh this this this is your angle let's say x and uh and this is this is called the adjacent adjacent side adjacent side to that angle X okay adjacent side to that angle X as it's the right triangle and this is called opposite side to that angle opposite side opposite side to that angle okay so basically what I'm saying that this is a hypotenuse H okay um and we have an angle X where this uh let's let's give some name ABC okay and BC is adj side to this angle X and AC is an opposite to the angle X okay so which is opposite of the angle which which is a side which is opposite to angle X so now what I'm going to do is to take out is just to give you the definition of s of x s of x cosine of x and tangent of X okay so what I'm going to do is to using the definition of Circ K so what I'm going to do so to TOA so so s of theta and Theta is an angle Theta is an angle over here it will be X we we'll solve it but before that over here which you can see s of theta okay cosine of theta and tangent of theta tangent of theta so let's go with the definition of so so so let's try to Define s of theta so when you define the S of theta so so opposite over hypotenuse so s is s of theta is equals to the opposite side over the hypotenuse so opposite opposite opposite over hypotenuse so that's a definition for your sign of an angle the sign of an angle is nothing but the opposite over hypotenuse what's what is a cosine what is the cosine of an angle cosine of an angle is adjacent over hypotenuse adjacent adjacent over hypot tenous okay or in other words a over H as we given the name A and H okay so uh this is a sign this is a cosine and the the the the for for taking of the sign of an angle the definition for sign of an angle is nothing but the adjacent over hypotenuse if you want to calculate the tangent tangent of an angle which is nothing but uh which is which is nothing but opposite over adjacent opposite opposite over adjacent opposite over adjacent which is O and H okay so with the with the definition opposite over adjacent so using this rhyme SOA you able to uh to to to Define these three trick functions okay so now let's use this CA to take out the trig values okay so but before that let's give let's say the adjacent side over here the adjacent side uh let's let's assume adjacent side is four whatever the centimeters or meters let's let's assume centimeters the hyp the the the AC which is which is opposite side to that angle or the height so it will be three and may you can take out the hypotenuse how you can take out the hypotenuse this is very very easy using Pythagorean theorem Pythagorean theorem tells a² + b² = c² a sare is your BC b square will be your AC equals to c² so when when you go ahead when you go ahead 3² so sorry 4² + 3² = to what c² okay 4² + 4² 16 + 9 = to what c² 616 25 = c² and when you when you when you just remove this so it will be < tk25 = C which will be C = 5 so the hypotenuse will be five okay so you given the sides of an of of a right triangle now what you need to do you need to take out the S of the x s of x s of X so how are you going to do take out the S of X but taking out the S of x the sign the sign definition is so K so sign is opposite over hypotenuse so opposite over here is three and hypotenuse over here is five is your s of that s of s of the x s of X is nothing but the 3 over 5 so what is cosine of x so what is cosine of x so what is cosine of x cosine of x is C so so C A so adjacent over hypotenuse so adjacent side over here is a thing BC and this is 4 ided H which is 5 so cosine of x is 4X 5 what about tangent of X so tangent of X is nothing but opposite over adjacent and opposite to that angle X is three and adjacent to that angle is four okay so which is which is nothing but 3 over 4 is the tangent of X okay so these three s cosine and tangent we are taking out and this giv you definition what is a sign what is a cosine and what is a tangent s is nothing but the opposite over hypotenuse cosine is nothing but adjacent over hypotenuse tangent is nothing but opposite over adjacent how you remember it using the SOA definition and I think this is this is pretty much easy okay so we had used this s we have used thisa to identify this s of the particular x cosine of the X and tangent of X okay so we have seen this uh s cosine and tangent so we have seen the definition of these three now what about the reciprocals of it now what about the reciprocals of this so the same way the other three functions are the reciprocal of s cosine and tangent so let's let's let's let's talk about that so other trig functions other trig functions other trig functions are the reciprocals are the reciprocals of these existing these s of x cosine of theta and tan tangent of theta so let's give the Theta name Theta angle okay so so uh let's let's let's talk about the first one which is the cosecant okay cosecant cosecant cosecant so what is this cosecant is a reciprocal cosecant is the reciprocal cosecant is the reciprocal reciprocal of s cosecant is a reciprocal of sign we'll see what the reciprocal means just in a second second one we have which is secant and we denote this as SC SEC okay set so secant is nothing but is the reciprocal reciprocal reciprocal of your cosine of your cosine and the the the the last one which is the over here is cotangent cotangent which which we didn't denote is a cot okay is the reciprocal of your tangent is the reciprocal of tangent and how do you define cosecant cosecant is SC CC CS C okay secant SEC C and what about cotangent Co T okay so in sign we write s n cosine cos tangent t Okay the these are sh form given to them so now what you mean by reciprocal so let's take out the let's let's take the definition of cant cosecant of theta for for for for for any angle okay which is nothing but the reciprocal of s sin Theta so 1 / sin Theta so reciprocal of the S of that angle sin Theta okay so it will be one over s let's let's remember our favorite definition from one and only so so CA SOA so sign is opposite over hypotenuse s is opposite over hypotenuse s is nothing but opposite over hypotenuse it goes up of it will be H over o h over o which is nothing but your cosecant so definition of a cosecant of a Theta uh is nothing but a hypotenuse over uh over opposite of that angle okay uh the next one is the next one is secant of theta secant of theta is the reciprocal of cosine which will be 1 / cine of theta so it will be nothing but so what is the cosine adjacent over hypotenuse 1 over adjacent over hypotenuse it goes above so it nothing but h of a h over a which is hypotenuse over adjacent okay so the the definition of secant of the Theta is nothing but the hypotenuse over adjacent the last one over here is cotangent so what's the time so the last over the last one is over here is cotangent cotangent which is cot of theta is is the reciprocal of a tangent 1/ tan of theta So Tan of theta is nothing but opposite over adjacent so one over uh opposite is over over here o by a okay so that is so it goes above 1 over so sorry a over o which adjacent over opposite angle okay so opposite to that angle Theta so cotangent the definition of a cotangent is adjacent over opposite of that Theta okay so we have a g given you definition of CA s cosine and tangent and we have also given you the the definition of cosecant secant and cotangent of theta okay so we have also we have given you everything about this now I hope that you had got a good idea about what is these angles tells you but before that what I'm going to do what I'm going to do is to solve for the triangle take out we have to have taken out the sign of that triangle which we have built up S of this was 3 over 5 cine 4 over 5 tangent 3 over 4 so what will be the cosecant of these uh of of of this uh triangle okay so let's let's take out the cosecant the cosecant of X of the angle X which will be 1 over the S of theta okay so which is nothing but again when you when you go ahead so so let's let's not write it again let's let's use our formal definition so cosine cosecant of theta is hypotenuse over adjacent hypotenuse was F five and adjacent was four so F 5 over 4 is the answer of this so sorry it's 5 over3 okay because adjacent because uh over over here your uh adjacent opposite angle so this is this this is uh opposite okay I don't know where it is yeah so it is opposite so 5 over 3 okay which is the reciprocal of your sign if if you told to take out the cotangent or the secant first of all let's L secant of X which will be nothing but secant of X which will be nothing but let's let's let's say for for for take example secant of X is hypotenuse over adjacent hypotenuse was five adjacent was four okay so that is just the reciprocal of your cosine what is the tangent of X what is the tangent of X so tangent of X is adjacent over opposite okay so adjacent so adjacent will be uh four and uh opposite is three four and three okay so we have taken out for for for for this triangle we taken out the cosecant secant and who told tangent it's cotangent okay so mainly we would add C okay so um so these are the things which I which I want to remember and I hope that you remember it as well okay now I hope that that you have got a better idea about what is this SOA means and the form form formal definition of this uh CA and these six definitions I want to introduce you to to to two special right triangles it is very very important to know okay so I'm I'm just going to introduce to you about two important uh two special that helps you to remember these stct values because these will very handy in your uh calculus Journey so I'm just going to introduce to that so there are I'm just going to write two special right triangles two special right triangles right triangles so the first one is the first one is 45° 45° 90° triangle 90° triangle this is a cute angle okay so over here when you when you when you try to make a make a that so let's make a right there is one angle which is of 90° and other two angle are 45° okay so I'm just going to write 45° and 45° okay so this is the following and you have let's say for you you you'll be getting these base so base will be one it will be also one and the hypotenuse will be 1.41 which is < tk2 okay and the hypotenuse will be < tk2 because when when you take the hypotenuse how you'll do 1 + 1 1 s + 1 s = c² when you when you do this 2 = to c² when your < tk2 okay that is your hypotenuse now now let's apply Saka and their reciprocals to take out the sign of the 45° okay so let's apply the ca over here to take out the sign of 45 Dee okay of this angle let's let's apply that uh let's let's let's go ahead uh yeah so s of 45° will be first of all SOA let's let's remember our definition so TOA so opposite over hypotenuse so opposite 1 over hypotenuse < tk2 okay so which will which will be nothing but when you rationalize it when you rationalize it it will be nothing but < tk2 by 2 I hope that you how you you know how to rationalize you simply multiply something this I think that's some of you do not know about it so < tk2 * < tk2 < tk2 will beunk 2 by two that's what you get okay so that so you you get this and then when you when you go ahead that it is approximately equals to 0.71 you can calculate using your calculator okay so that is your s of your 45° what is the cosine of 45° cosine cosine of 45° cosine of 45° so adjacent over hypotenuse so adjacent is one and hypoten puts two okay so adjacent is 1 and < tk2 1 / < tk2 which will be again < tk2 / 2 by rationalizing approximately equals to 0.71 that is a cosine of 45° now what is the in in in this in the part for this triangle what is the tangent of 45° 1 / 1 how do you say opposite over adjacent which will be around 1 so 1 is the tangent of your 45° for this triangle so what about the reciprocals of it so what about the reciprocals of it so the reciprocals of it will be first of all secant first of all let's let's let's talk about uh co co cosecant cosecant of 45° which will be uh the the the reciprocal of it so hypotenuse over uh opposite angle so hypotenuse is < tk2 < tk2 by 1 which is nothing but approximately equals to 1. 4 1 okay what is the secant of 45° so secant will be h/ a h/ a hypotenuse hypotenuse is < tk2 over 1 which will be also approximately 1.41 what is a cotangent what is cotangent so what is a cotangent is will be 1/ 1 because adjacent over hypotenuse which will be one okay so these are the reciprocal the trig values so so we got the trig values of you can see over here that using this special these these special right triangle will be so so much in your journey so that's why I'm introducing to you this one okay now let's go ahead let's let's talk about another now you got to know these stct values let's talk about another uh special Tri triangle which which is nothing but um 30 60 90° triangle 90° diory angle and of course this is a acute angle okay so when you when you have this uh let's let's let's print it out yeah so over here you have this and let's say let's say for for sake of an example your uh uh your uh 30° 60° 90° okay adjacent side of 30° is < tk3 which is approximately equals to 1.73 and it is one the the the the the the height or AC is sorry the height will be one and the hypotenuse is two because this is all because mainly people what they do they put that into the base and that is wrong because the hypotenuse is also always the longest side okay now let's do one thing let's apply the ca so K TOA on 30° okay for the 30° angle for the 30° angle okay so go ahead apply the ca for the 30° angle then go ahead and apply the Circa and the reciprocals as well and the reciprocals are well for the 60° angle and you are good to go and you are and you'll be getting your trick values and that that that will be yielding to around so much of trig values in no time which you got it okay so I want you to do these two things taking out and write the answer in description box uh sorry I'm saying in comment Box about the the the the the all the all the trig value and the reciprocals for the 30° and all the all the all the tri function with the reciprocals for 660 de okay cool so we had done lots of practice okay but you may think yeah you can't we do for greater angle because all these are cute angle can't we go ahead talk about the uh the the the large angles like maybe 270° okay so maybe maybe bit more than that something like cosine of pi/ 3 cosine of maybe 3 Pi or sine of 3 pi/ 3 sine of 7 High over six uh maybe anything anything can be happened okay so how you go ahead and do that how you go ahead and do that so you can just uh maybe what is the sign of 2 210° what is this cosine of 120° there a lot more things so for that for that we have something called as unit circle you have we have something called as unit circle which which is very very very very important and it may happen some of you may think he you I cannot remember unit circle because many many of you has an enemy with a unit circle in your I think class 9th and and class 10th I think most mostly in class 10th uh so so don't worry about it very very trick is available online about remembering it and it's very it's you don't need to remember it it makes sense as well sometimes okay if if you think about geometrically don't think about remembering everything you can just make sense of it because it's it's it's it's it's kind of U very very important in your Calculus Journey because these are the very very frequent radians which you get or degrees which you get in your whole calculus Journey okay so what I'm going to do is to introduce to you a unit circle I'm not going to give you a trick for remembering the unit circle but I will leave a link in the video description about the trick for remembering this but as always Google is up for you you don't have to worry about it okay cool so um let's go ahead let's let me show you uh let me show you the unit circle let me show you the unit circle where is my unit circle here here we go so just going to take in between make it a big okay so this is your unit circle this is your unit circle I'm just going to make it a little bit big yeah so this is this this is your unit circle and very very uh uh scary or disastrous unit circle and and it's very very important as well so uh I'll just introduce you so that every everyone is familiar here you have three things the first thing is coordinates second thing is you have the uh the radians okay of the coordinates and then you have the degrees angles angles in radians and angles in degrees okay so you have the coordinate so we talk talk talk about that coordinates you have angles in radians in radians and you have angles in degrees in degrees okay so first of all let's let's let let's talk about this one uh let's let's talk about this one so this these go first of all over here you have y AIS and xaxis so uh the the the radi with this origin to this point the the radius of the circle is r = 1 R = to 1 so the coordinate at this point will be 1 comma 0 will be 1A 0 why 1 comma 0 1 on xais and it's 0 XIs 0 okay so 1 comma 0 it is the same 0 0a 1 on x axis is z so radius is areal to 1 everywhere so it will be 0a 1 so this is y axis this is one this is xais this is 0 comma minus1 so these are coordinates the same way these are also coordinates this for xaxis and this is for y axis this is for xaxis this is for y AIS okay and you may think how you have come up with these kind of uh coordinates how you come up with this it's it's basically uh more about geometric understanding you can go ahead see if if you go in much more detail as a bit out of the bound of this video because we just reviewing it so over here which you're seeing over here X and Y coordinates so these these are all the things which you're seeing outside the circle are the coordinates inside which you are seeing this Pi what whatever the fraction which you're seeing uh is the radians is the radian okay so over here you have 2 pi you have 2 pi and then pi over 6 pi over 4 pi over 3 for for that coordinate so there are three over here and Pi / 2 then go ahead we have these all the things are the are the for the for for where the radian is 4 Pi or 3 the coordinates are this 5 5 pi over 4 the coordinates are this okay so these are the things the next thing is you have the degrees you have the degrees you have the radian you have the degrees 120° 135° 90° 6 60° maybe you all remember using a pro protector okay it is very very uh familiar to you so I hope that's not a big deal now but there's one thing which I want to tell you is how do you remember these things so first of all what you do you have the three three points over here you give two two two two all the denominator will be given two okay and now uh 1 2 3 1 2 three okay you you do the square root every numerator if you put it does not require it < tk3 < tk2 < tk2 < tk2 and of course it does not require so you get this so these these some kind of tricks for remembering it it's very very useful in this okay so it's it's very very useful as well okay uh so you you remember these coordinates these Pi is the 1/3 Pi / 6 is 1/3 of Pi / 2 so you need to only remember some of the coordinates and some of the radians only that and using that you are getting uh using that you can get more radi or whatever okay so these are there are some tricks which you which you need to remember uh maybe you can search online otherwise the link is in the description Box about the trick for remembering this these things okay so you have the radians you have the degrees okay now what so every coordinate X and so every coordinate is a pair of X and Y okay x coordinate and y coordinate but it is indicating this is this cosine of theta and S of theta so X indicates the cosine of that maybe the radian or or or an angle and S maybe this Theta can be the radiant or that uh or that angle okay so let's let's say for for the S sake of an example let's take an example you told you want to find out the cosine of Pi / 3 of Pi / 3 how are you going to find it so you search 5 over3 over here what is the x coordinate is what is the x coordinate because x coordinate indicates the cosine of theta which is 1 / 2 what is the S of < / 3 so y coordinate is root < tk3 / 2 okay so these are thing these are the trig values okay which is which is very very useful maybe in your examination or in calculus you can take out anything with this say for an example you're told to find cosine of pi/ 6be cosine of pi/ 6 so over Pi / 6 is will will be the the x value is < tk3 < tk3 / 2 let's take an example you told s of 3 piun / 6 uh 3 3 piun over 4 so what it will be it will be nothing but minus sorry < tk2 /2 because that indicates the y coordinate so coordinates indicates the pair of the cosine and the sign of that angle or the radian okay so some of the interesting thing which I'm to show you to you is what is the tangent of 3 piun / 4 what is the tangent of this 3i 4 so tangent you all know tangent is equals to S of that 3 piun 4 / the cosine of 3i 4 okay so s of theta divid by the cosine of theta so it will be the S of theta 4 will be < tk2 / 2 okay < tk2 / 2 because that's Co sign is which which is min2 which which you can see over here so the the the the denominator cancel which will be minus 1 the tangent of the 3 Pi 4 will be minus one so this all about manipulations more all all about other things which you need to which you need to just uh apply some logic and you will getting getting your trig value so this gives you lots of trig values okay now what I'm going to do now what I'm going to do now what I'm going to do is um is to do one thing uh first of all uh what is what is the cosine what is the cosine what is the cosine of 3 pi over here we we only still have 2 pi okay but what is 3 Pi so it it here the radian is 2 2 2 pi so what is the cosine of 3 Pi so how how is construct at 1 Pi okay then 2 pi then 3 pi over here it will come over here the 3 Pi the cosine is always referred to the minus one so the answer will be minus one how first of all here is your Pi okay you rotate there is two first of all you go over here you rotate half circle Pi then 2 pi then 3 pi over here so 3 Pi will becoming minus so what is the S of 3 Pi which is zero because the y coordinate is zero so it is not matter whatever you you can have it does not matter okay now there is one last thing which I want to tell which I want to tell is there is one last thing which I want to tell is what is the S of piun / 4 what is the S of piun / 4 which will be nothing so over Pi but this is pi but there is minus so you here it is in second one so you what you do you start going you start going into the negative Direction okay so leaving one you go to two Okay because here is here the second coordinate you go over here 2 one and that is that is so sign of my piun 5 will be sine of 7 piun over 5 4 okay so that is nothing but two okay so uh root so sorry it's minus 2 2 over 2 okay so this is how you go in the negative direction if it is over here then you go from here so this is how everything is working you using the unit circle and I hope that you understood very very intuitively and I hope that's very not a not a big deal to understand these things so this is a whole thing and and and and basically you will see whole calculus and revolving around this okay most of the calculus problems TR TR calculus problems cool so I just want to talk about the last thing which is very very useful over here is how do you graph s cosine and tangent maybe you can search online because but I I just show you the graph of s of yal s of X looks like so here is your thing so it it it will look something like this it will look something like this it will look in cyclic form okay in cyclic form it it will look in cyclic Forum something like this okay so it looks in cyclic form but the same way your your your cosine will be will be different will be different because over here it it it is some some something y s of X something like this but what is the cosine cosine will be let let let let little bit different a little bit different it will be okay it will be okay so it will is cosine y = cosine of x will be something like this and and and this these are the graphs which you will see later a lot when when when when I will teach I will take these kind of graphs about I'll go in different differentiations very very important okay so I hope that you understood the trigonometry whatever I taught and um it's just a review there there a lot to learn in trigonometry there a lot to practice in trigonometry like inverse strict functions and ASM tootes we have lot more things which you can explore please please please go ahead see some tutorials if you're going to go ahead deeply in trigonometry these are things which I need to revise before going to the calculus now we are ready now we are ready to go in calculus from the next very we'll be talking about limits and we completing I think limits in three to four videos I think only three videos will required for limits short short videos we completing limits and then we are good to go and then we start with differentiation okay so and then we will go ahead talking about solving different take take Taking out the derivative like quotient rule chain Rule and a lot more and then we'll go ahead uh there's also power rule which I can't forget about that so there's um so about different op after differentiation I think we'll go ahead with integeration okay so I hope that you understood I'll be catching up the next video till then byebye have a great day hey everyone welcome to this lecture from this lecture we'll be actually starting off with uh limits and and limits is one of the most important topic which I cannot leave we will not too much talk about limits we'll not do that much kind of examples but yeah I will give you a a brief about limits and what the limits are and there there are lot more lot of the things which we'll talk about as well as we'll talk about uh uh how to evaluate the limits using various various techniques which we'll study in the next video basically in this video I'll just give you what exactly the limits is okay so we'll we we we see lot lot of examples to understand uh why this is called the microscope of maths so it's this very very nice uh nice things which have invented so far uh in the history of uh math and I think that differentiation the definition the formal definition of differentiation will'll Define using the limits property okay so now let's get started with one of one of the example which is in front of you which is that maybe you are familiar with this plot it is the the parabola plot if you know because we had a talk on this and how you plot you just plug in the x value just put the point on the X x coordinate and the ycoordinate and then you join that the points so this is what you get and this is not a best Parabola diagram in the history of math uh but yeah this is the basic uh basic stuff which you seeing over here now what I'm going to what I'm going to do is uh uh make a pie wise function but before that what I'm going to do is to just just uh talk about the this function and then we'll make a PE wise function but before that what I want what I want is to find the value I I I I want to find F of two F of two F of two so what it will be so we give to the X and this will be nothing but four assume that this is a four okay so just want to make it some over here so it is a four okay so this is nothing but four but what do you I say you have a function G of X you have a function G of X you have a function G of X you have a function G of X where you uh first of all uh what it X squ for every values except xal to 2 except x = 2 there is x² okay and another is when when when uh the input value is two then the output will be one when X = to 2 then the Y value will be be one uh in the first is telling x² in every input values except two and one for for the input value equals to two so that is these functions are nothing but called the pie wise function pie wise function uh which you which you might have observed already and I hope that you had already so now if I want to plot it over here this plot G of x if I try to plot it the G of X so what it the what the oh my God yeah so uh what if I if I want to plot it so for plotting it let me just remove this one because I oh my God I don't want to do this uh I don't know how to select the good uh the Eraser let's use very simple eraser let's first of all remove this and there is a discontinuity okay so if fals to two if fals to 2 then if input value equal to two we just saying that it is it should it should be one okay so this is your function of your G of X this is your function of your G of X where we are saying it this is a function this is a graph of x² this is a graph for X squ but we had told there is one discontinuity which we'll talk about today about discontinuity but there is one discontinuity in this function and you're saying if at xal to 2 make that to two and this x² does not work for x x is equals to 2 okay okay so this is a function this is a graph of your function G of X okay uh this this pie wise function this is how it looks like now coming to the next part is what is I'm just asking one thing what is the limit what is the limit what is the limit of your function G of X of your function G of X when when X approaches to when X approaches two not exactly two when X approaches two from the right hand side and the left hand side okay so it it may be confusing to you what exactly I'm saying what exactly I'm saying what is the limit of G of X when X approaches 2 from the right hand side and from the left hand side so let's start with the from the from the left hand side so let's say the let's say the input values the input so let's start from the from this value so it gets closer and closer to two okay so it approaches Clos and Clos it so we simply write limit of G of X when X approaches to so this is this is your limit uh notation to write it out so basically we are telling uh here we are telling what is the limit of when X approaches two from the left side okay so when X approaches two from the left side it seems to be approaching four it seems to be approaching four we are not taking exactly F of two because that is undefined at that point the function x² is undefined but basically there is discontinuity and we are we are getting closer and closer to two from the left side for for for example we are taking the value 1.9 1.999 1.999 1.999 N9 we are not getting exactly to two but we taking these values and taking the square of it okay so it seems to be approaching fold how I'm perceiving that so let's do one thing let's try to give the let's try to do from the left hand side first of all so we have an x value and and we have a g of X okay we have a g of X so you give 1.9 to XX when you square it up you get 3.61 okay and because it is defin else everywhere except X exactly equals to two so at 1.99 it will be 39601 that is a square of it okay so we give 1.999 so that is 3.99 601 okay we are not taking exactly it's technically do not can get exactly two four but it if you you use the calculator 1 1999999 it will just take out the square it will just round of that but actually this technical not true okay so over here you you're are getting you when when you're are approaching two when you're are approaching two when you are approaching xal 2 from the left hand side it seems to be approaching four your function G of X seems to be approaching four let's take an example of this so when you're approaching two from this side when you're approaching two from the left side it seems to be approaching four okay it's not exactly taking as a two as an input we saying if the the the the limit of a g of X tells you when X approaches 2 from the left hand side and when from from the left hand side so over here when the limit uh of G of X when X approaches 2 is approaching okay limit of of G of X when x x approaches 2 is approaching four the fun is approaching four so it is approaching four it is approaching four it is approaching four so when you when you get Clos and closer to two from the from from from the left hand side it seems the function G of X is approaching Clos and Clos it's it's it's approaching four it's not exactly four but it's approaching four okay now let's see the same way going from the right hand side so let's go with the right hand side so when we try X and G of X we give 2.1 4.41 2.01 uh 4.41 so from the right hand side as well from this side as well from this side as well from this side as well it seems from this side as well we are approaching to from this side this seems like it is approaching so it seems like it is also approaching four it is also approaching four so the limit from the right hand side limit of f ofx f ofx = to 2 of G of x from the right hand side is equals to 4 and the limit limit of x approaches 2 from the left hand side is also four so the limit of G of X when X approaches 4 2 is exactly equals to 4 and this is how you take out the limits of a function okay and this is damn easy we have we had to Made made use of table or Forum using calculator and so sorry and then we are done okay this is what limits are limits are nothing uh it's it's it's it's a function limit of a function limit of a function if it exist because limit cannot exist as well I will tell you the reason lat later on so limit cannot exist as well for some x value C and we denote so we're just going to write the formal let's write let's make a new page yeah so I'm just going to write the for formal definition the formal definition says that limit not no it is not a formal definition but um this is an informal definition but just now for the definition okay the limit of a function limit of a function limit of a function if it exists a of course if it exists if it exists limit of function if it exists for some x value for some x value C for some x value C okay for some x value C to the height of a function to the height of a function to the height of a function the height of a function gets closer and closer gets closer and closer as we saw that is gets closer and closer closer and closer to uh as X gets Clos and closer gets Clos and closer to to the to see gets closer and closer to see from the left side from the left and the right side from the left and the right side okay so for example this is your function this is this is your function assume that this is your function and this is there is a discontin it over here and you're telling that okay what is the what is the value of x so for example it's something like this okay and you're telling that's two so what is g of X when the what is the limit of what is the limit what is the limit of x approaches to of your function G of X okay so when X approaches to from the negative side sorry the left side and the positive side from the from the from the right side it seems to be approaching from the first of all from here and then it seems to be approaching for exactly it is four okay so it's check the gets the x value gets Clos and closer from the left and the right side and then you decide and then if the both are equal then you say okay that's the limit which exactly equals to four okay so now we had seen the one example and I hope you had got a very good idea about limits and we'll I will just give you the formal definition of a limits because it's very important for you as well to understand what exactly a limit is okay so so what I'm going to do now is to take another example so that you could get a more uh more more good definition for you at least uh we we we'll see that okay so we'll just give you the good good definition of the limits and it's very very important as well uh mainly if you uh for for for for for forgetting more about what exactly the limits is okay cool so uh what I'm going to do is take another another function take another function and the function is uh the function is the function is uh F ofx = 3x + 1 so what I'm going to do is to take a y i just to take a function three y = 3x + 1 y = to 3x + 1 so this is your function uh F ofx this is your function f ofx okay and you will identify the need of the limits from this function and you you will get to know the need what's exactly the need of limits from this function so let's get stress so let's what what do I ask you to do take your graph paper try to plot this function by putting X values and try to put the coordinates on the your graph paper and then you are done okay so what I'm going to do is to make the make a quick quick uh diagram of this function I don't know it it is it is a bit hard to make but no problem I'll try to make it as much as I can so just want to is it is uh just wait for a second I'm just checking the diagram yeah so what I'm going to do is to make an X and Y plane so I'll just put this make let's make in blue because it works okay so this is your X sorry y cord y plane y AIS and this is your xaxis okay what I'm going to do now is to just plot it now is two is approach a 7even so one two oh my God what is this oh I I I I got to know about this now one two uh let's let's let's make it a little bit more we two 3 4 5 1 2 3 4 5 6 7 okay so this is your uh let's let's make it inal way now when I'm going to try to put the value of one so let's put the value of one over here that is four and it is so that is four okay put the value of two that is that is nothing but uh seven I think so yeah that is seven okay so when I when I try to just join the points I'm going I try to just join the points I'm just trying to fully join the points okay so that is this is what I get when joining it okay so it is not a best function in the history of math but yeah that's what I can draw in just now with quick graph so this this this is the function y = 3x + 1 so this is this this is a function y = 3x + 1 coming to that now this is a function now what I want to know is limit limit limit of your function let's say f ofx let's give the name of this function f ofx limit of function limit of a function f ofx when X approaches when X approaches 2 what what what it will be you can simply it it is not it is continuous it is we we have this this is not a pewi function it is continuous and over here we don't have any discontinuity we don't have any whole over here okay it is just a point just just for Dra drawing the diagrams but but over here your uh this function is continuous and if you go when when when when when when we approach from the negative side as of the positive side and even when we get when we get x = 2 even when we get x = 2 so you'll be getting uh y = to 7 and that is the fully valid according to your function that is defined that is defined so the limit of your F ofx when X approaches to from the both the side is seven when X approaches to from the both the side from the from from this side and from that side even it gets two it will be defined because your function is not set it that okay your Y is 3x + 1 is not equal to 2 so it is not something like this it's not something like this it is defined at at X = to 2 so the limit of your function you can simply put the value of x and you'll be getting your limit value over here so you can simply put the value over here and then you'll getting your uh the limits even when when you say it it goes from the left side and the right side and it seems to be approaching seven okay coming to that now we have seen this now what I'm going to do is a little bit twist it so that so that you could get uh at least the idea of why limits are too much useful in this era so what I'm going to do what I'm going to do is um is uh say say for say for an example say for say for an example uh uh I'm just going to take a take a take this and then I'm just make a hole over here okay so just make a hole over here oh my God this is what I made the hole okay so now now the function is defined this function y is defined everywhere except X = to 2 and when it's xal to 2 it is one it is one okay so so so so what is so what is the limit of f of x when X approaches 2 it's seven It's s of course it's seven but you you will see the but you'll see the the main idea that if your function has discontinuity it will tell you that if we get closer and closer to two from both the side from the left side and the right side say say say for say for an example you have X so you put 1.5 so you put it you go from left side that is you have uh y function so that is one when you put one you'll get four when you put 1.5 you get 5 5.5 when when you put 1.9 you get 6.7 you get 1.99 you get 6.97 you get 1.999 you get 6.99 97 so this is this is getting closer and closer to seven if if you get closer and closer to from the from the left hand side it is getting Clos and closer to seven coming to that from the negative side coming to that from the sorry from the right right right hand side so that is that is that is nothing but 2.01 that is 7.3 2.01 that is 7.03 2.1 7.3 so this is also seems to be approaching 7 from the from from the right hand side so the limit is seven okay so this is how you you you you take out the limits and I hope that it's completely making sense at least to you okay coming to that later on now now what I'm going to do what I'm going to do is uh is to just go ahead give you the the the the topic which is onesided limits okay so you all have seen the onesided limits but I this it's my job to make you familiar with these stuff okay so I'm just going to take this one this diagram I'm just going to take only this diagram just going to take only this diagram okay now uh just let me just make it in the new page so that I could make you understand a better way okay so when X approaches to from this side and then that side okay let's make a new function let's make a new function let's make a new function don't ask me what's the name of the function just just let's draw a random function so that just just we can understood visually let's call that function P of X okay let's call that function P of X of course this is a peie wise function this is a pie wise function um it will be like this x² for and I will just tell you later on okay coming coming to that so let's make uh let's let's make a function this one uh let's make a function let me draw a DOT line at least a line uh something like this and then something like this I want it a little bit big so that everyone could be able to see it now uh just going to take this now what I'm going to do one uh it's it will be something like this okay so I just let's do it and this is from this side okay so this assume that this is your function uh this is your function it's just not a big big big function which you have ever seen and your eror okay let me make a little bit so that everything is yeah okay so you have the okay so you want to you have a piecewise function have peie wise function so assume that this is a p of X this is a p of X which is a which is a piecewise function which you ever seen in your life uh again just just just assume that that is a function and and over here and and over here uh over here uh you have limit what is the limmit of X approaches uh 2 okay so what is the limit of x approaches 2 from the negative side of your function f of e of X so when you when you get closer and closer to two from the negative side means from the left side it gets Clos and closer to five that gets Clos and closer to five it gets Clos and closer to five that is nothing but five okay so when you get Clos and closer to two from the negative side that's got Clos and closer to five and when you get closer closer to seven then when you get closer limit of P of x from the right hand side from the right hand side you get it is getting closer and closer to two that is nothing but two so over here you you you're taking the limit from the from the left hand side and taking the limit from the right hand side and these both uh right right hand limit and lefthanded limit are not equal are not equal are not equal okay are not equal and so so that's why uh this limit does not exist this limit does not exist why because the limit because the limit from X approaches 2 from the negative side of a function P of X is not equals to the limit of your P of X when X approaches 2 from the positive side it's not equals to which which you can clearly over here which you can clearly see over here that this the X approaches to from the left hand side and X approaches to from the right hand side is not equal but in previous cases which you have seen they both were equal so there the limit exists but here the limit does not exist okay so this is what the whole idea of the onesided limit when someone ask you to evaluate something like this get to get the limit from the negative side you're just going to go go uh get Clos and closer make a table format make a TBL format and then go ahead but we'll see how to evaluate the limits in our next section of of of of a function so don't worry about that okay I hope that everything is clear and now what I'm going to do is uh have have a small understanding of uh of of of a function again a pie wise function this is a peie wise function so let's let's let's take another pie VI punch so what I'm going to do uh it's the it will tell you the idea of infinity which will talk about we will talk about this in our next video a little bit more way I just going to go to give you the intuition about this okay so this is your this is your something like this okay assume that this is 1 2 3 4 5 6 okay um this is also 1 2 3 4 5 and this is also 1 1 2 3 4 5 5 1 2 3 4 okay now what I'm going to do is to just make uh is to just make us or here okay to make something like this make something like this and when we say when we say that when X approaches when the limit when the limit of when the When when when when the limit of f ofx let's say the function f ofx when X approaches negative uh from the from from the right right hand side from the right hand side even even from the left let's say from the left hand side from the left hand side when the limit get close and close to left hand side so it says that it's it's getting to Infinity it's getting to Infinity okay because you have a vertical asymptotes over here vertical asymptotes okay so it's getting to infinite so we say that that is a Infinity that is the infinity okay so this is a general idea when a limit can be in okay so don't worry about this will talk about vertical ASM tootes because this is a vertical ASM toote so we say that when when when when when the X approach is three it gets the limit of function gets gets to the infinity Okay cool so what I'm going to do now is talk about the last things of the topic which which which which we are left on is about continuity I think so yeah we'll talk about continuity but before that I want to give you a formal definition of a limit so that you could be under you could just write some somewhere so that everyone is familiar with it so the formal definition of a limit the formal definition of a limit the formal definition of a limit let F be the function let F be the function okay so the let let F be a function let F be a function let F be a function and C be any real number and C be any real number any real number okay limit limit of x approaches C of your function C is then C is the arrow number mainly we call it an arrow number which we which we have to approach exist this limit exists exists if and only if if and only if three conditions are made first condition limit of f ofx when X approaches C from the negative side exists exists second limit from X approaches see from the positive side exists and and third one is limit of x approaches C from the negative side of f ofx equals the limit of x approaches C of function f from the positive side so they should be both equal okay so this is so these are the three conditions where you all have seen in a real life examples which I just showed you about this example or maybe or this example Maybe Okay cool so now let's talk about the last thing which is nothing but continuity which is nothing but Contin nity so what I'm going to do is just is just spend some minutes talking on this uh talking on this uh so we'll talk about continuity so let me just give a definition continuity okay continuity a a continuous function basically the definition States a continuous function uh cont newest function is simply is simply a function with no gaps with no gaps or holes in between holes okay so a function which you can draw without without tick for example I can draw something like this so with it has no gaps okay or end holes in between okay so this is a this this is a this is a continuous function okay so we'll see some of the examples where where the functions are continuous and where the functions are not continuous so let's see some of the examples where the functions are continuous where the functions are continuous so just going to make it something this oh my God it's not correct so let's assume oh my God what is this what is this I think that I'm losing my mind I think so yeah so over here this this this this is a function this is function what I let's let's say p of X let's say p of X and this is continuous because you are drawing without taking out your hand and since one of one of the main thing about continuous function if you are making it making it draw without taking your pencil off the paper then it's continuous that's that's a that's another cool definition which is provided in some of the book okay so this this is some of that this is what you this is a continuous function let's draw let's draw uh something like this something like this it is also the continuous function so this is also the continuous function of the absolute absolute value of x okay so this is also continuous function but what are not continuous functions so let's take an example let's take an example of this function of this function the function states you have uh maybe something like this you have something like oh my God you have something you have something like this and let's do one thing let's just make a hole in between okay let's just make a hole and this is and this is not a continuous function okay another stuff is I will tell you the the good definition another another can be another can be uh let's take example of this okay this is uh I'm going to make a piecewise function I'm going to just make a pie wise function and this function is also not continuous function okay this this this function is also not a continuous function let draw vertical ASM tootes so this is also not a uh the the the the function which is continuous okay because we are you're taking off your hand and another stuff which I'm going to talk about is another pie wise function another pie wise function which is this one okay make whole there and let's make there's a hole over here so this is also not a continuous function okay so uh so when Whenever there there is some kind of piece the constraints it's it's it's difficult so uh basically you you're seeing the two functions so let me draw another function another same function which you all had already seen so that I could take one example of this uh something like this one and something like this one okay so these are the two functions which are not continuous so these two functions with the gaps are not not continuous everywhere these functions are not not I not say but the more precisely I would say the these two functions with the gaps are not continuous everywhere these two functions are continuous everywhere but these two functions are not continuous everywhere but sometimes a function is continuous everywhere it's defined okay such a function is described as a being continuous over its entire domain so if the function is continuous that that means that the function is continuous over its entire domain okay which means that it it's it's it's it's gaps or gaps occur at X values where the function is undefined okay so which you're seeing the function P of X is continuous over the entire domain is continuous over the entire domain which you're seeing over here it's continuous over the entire domain it has it don't have Gap in between but over here G of X on the other hand it's not continuous over its entire domain over its entire domain okay so G of X is not continuous over its entire domain maybe let's say for say for example you have this diagram so this this diagram so this function y is continuous over it in in entire domain except at Value except at xal to 2 because at xal 2 it has a whole so the function y is not continuous everywhere except x = 2 okay so this is how you say if if the function is a continuous or not maybe you say the it's you you say say that the function is continuous over its entire domain but basically as a more precise would say that okay the function is continuous everywhere except at this point okay so this was all about this uh continuity and I hope that you got to know what limits it's it's it's it's a good definition to to to to just take in your mind and and I hope that you will consider uh this uh in your own and I also hope that this limits got in your mind in the next section we'll talk about the evaluating limits and then we'll get on differentiation my favorite topic and then we'll talk about integration calcus over okay and then we'll go to probability Theory because it's probability theory is also very very important uh in this era and let me know that I'm that I was reading a book uh not what you want gift in a Christmas because I'm thinking that I should make a very very very comprehensive data science onee plan master plan or road map to complete and in in depth to get in Fang what do you say I'm not in Fang but I think many many of my students got into Fang uh so I think I'll be I'll be eligible I'll be help taking help from a lot of people to make that road map available okay so I think that if if you want that please comment it down below I'll be very happy to give you as a Christmas gift to make a full data science plan data scientist plan which goes from very scratch mass and this go go step by step with book recommendations with every stuff let me know in the comment box below I'll be catching up your next video till then byebye have a great day hey everyone welcome to this video um basically in this video we'll talk about how do we evaluate the limits because in the previous video I've just given you an introduction to limits we haven't solved as I've just shown you the numerically how uh sorry geograph maybe graphically how do we even uh go ahead and take out the limits with only few examp examples in this video what I what I will do is I will try to show you some of the methods for how we evaluate the limits we'll talk about substitution main the plugging one and then we'll talk about how do we evaluate limits using calculator and even if does not work there is algebra which is always there for you in maybe factoring evalu EV evaluation of a limits using factoring and rationalizing and conjugate and Sarah will talk about that today okay and I will just give you a a brief about squeeze theorem so that you could be you could be familiar with what is squeeze theorem is okay just a sandwich theorem cool and uh the frequency of the video will be bit low these days the reason why um uh cs001 is preparation is going on and there a lot of works on is on my head so it's bit slow but yeah I it's just like three videos per week is coming as men mention as promised but previously there was five videos Six videos were coming but I think it's my apology that the I'm not going to upload uh more than three videos per week okay and and the homework set says updated sorry the homework set will be updated on your LMS uh please go there and try to solve it I'll just uh have our T to to to to to grade your uh assignments Okay cool so uh plugging and using the calculator so let's talk about plugging let's let's just talk about plugging so limit of x approaches three okay and of a function of of a function x² 10 okay so what is telling this is your function f ofx so function f ofx is nothing but x² 10 okay so what is the limit when X approaches 3 okay so maybe just when when when you plot this fun function and when when you when you go when you approach X from the left hand side and when you approach X from the right hand side it seems to be approaching minus one okay but but it's not possible for every time for you to draw a graph and then go ahead so what you do you first of all try the substitution you first of all try the substitution so over here it seems to be approaching three and it is a it seems like a continuous function okay and it is a continuous function so over here when you what you do you put three into that X you put the three input to the F ofx so what do you do you simply put 3 over here okay so 3 S 10 which is equal to 1 so the limit of x approaches 3 of of this function is equals to minus1 it says that it's the the the function when X approaches 3 from the left hand side and the right hand side seems to be approaching minus1 okay or is approaching minus1 so what you do first of all is to try direct substitution you just give give the value of x to the function which is over three over here and then you take out the answer of it okay so this is called substitution method or plugging and it only works with a function which is continuous it only works with a function only works when your function is continuous otherwise it it works very well in most of the cases okay but but do don't you think that these this is just like a function no this is this is not like a function it is just a method which we use everywhere I will tell you how it is being used everywhere but every time it is not possible that this case happen let's take another example let's say an example that the you want to take the limit of the function which is 10 / x 5 when X approaches 5 when you try this plugging method over here when you try this plugging method over here what what will happen what will happen happen it it will simply this is this this is a function to 10 5 5 so you put x 5 that will be 10 /0 that is indeterminate form we say that is indeterminate form and this is undefined and the limit does not exist but the limit do exist in this case okay may maybe in some time we'll we see the tools that will say the limit that will that that will help help us to evaluate these kind of limits but over here this is undefined so that's why the substitution does not work everywhere does not work everywhere because it is giving you the indeterminant form if it is even a continuous Okay cool so now what we now this is the first method which you have seen let's see the second method which is of using the calculator so using calculator let's let's say for for the sake of example I'll take another example limit of X approaches the limit of x approaches 5 of the function X x² 25 / x 5 equals to what okay so this is this this is the thing so what I will do I'll make use of calculator I'll make use of calculator what you can do first of all is to put the values of five over here put the values of five so maybe 5 S 25 5 5 so 5 2 25 25 over 5 5 that will be 0/ 0 and when you divide something by 0 that is undefined that is undefined so the plugging method is not working over here so what method would work work over here so what you do you you take your calculator okay you start approaching you start putting the values of x from the left hand side and you start putting the values on the right hand side and see and make a table of it and see to whom it is approaching okay so say for an example this this is this this is your X this is your X this is your X and this is your y this is your X and this is your y so X maybe let's say 4999 uh 8 okay so 4998 8 that the when when you put this 4.9 and 8 when you when you go from the left hand side when you put this in function 4.9 and 8 that will be 99.998 okay now you put 4.99 9 okay that will be 99.999 okay and when you when you put five it gives it is undefined okay now you have seen from the left hand side it seems to be approaching what why is approaching what it seems to be approaching 10 so the limit of x approaches 5 from the neg from the left hand side of this function x 5 is equals to what 10 it seems to be approaching 10 from the left hand side okay but the but the definition of the limit what we have seen the limit I'll just draw it the limit the limit of x approaches a from the negative side of the function f of x should should be equals to limit of x approaches a from the positive side to be the limit called as so that the limit X approaches a is equals to whatever okay so if this is 10 this should be also 10 10 so that it could be called as a so that the limit from the both both both sided limit should be same okay so over here when we put five when when we put 5.01 5.1 okay so when when we go from the right hand side when we go from the right hand side it it is seems to approaching also 10 to 10.1 so when we put 5.2 from the right hand side I'm telling 10.2 so 5.2 it seems to be approaching 10.2 okay so basically the limit of x approaches five from the positive side of this function f ofx let's let's assume this function f ofx is also 10 is also 10 so as as for the definition of a limit the limit of a function f ofx when X approaches 5 from both the sides it seems to be approaching of the function f ofx it seems to be approaching 10 so the using the pluging our limit was undefined but using the calculator the limit we Define the limit okay the limit do exist okay so this this is this this is the second method using calculator but every time calculator does not works okay maybe uh the the advance calculator may may work but basically your computer calculator mobile calculator is not work May maybe some of the cases so that is using the calculator now let's see another thing another uh method for solving of it is using algebra but I I do want to see the timing of it so what's the timing is 9 minutes okay I just want to complete it very fast way so that I could not take mod of your time cool so what I'm going to do is to solve limit I just to solve limit solve limit using your basic algebra okay uh first of all what we'll do we'll try factoring we'll try factoring okay and then we'll do the rationalizing or conjugation okay so what's the limit what's the limit when X approaches five when X approaches 5 of the function x² 25 of x 5 that's the same function you know that the it should be 10 10 it should be 10 x 5 we have we have seen that now we'll we'll make use of factoring to uh evaluate this limit so so what so basically the limit what it tells when X approaches five when when in this function when X approaches five from the both side what it is approaching okay okay so that's what it is the Lim the the limit tells what happens when X approaches five from the right hand side and the left hand side and what will be the Y value of it okay so the first thing which you'll try is plugging the first thing always you have to try is plugging okay if now the plugging will be the indeterminate form or undefined okay so plugging is undefined plugging is undefined over here so first of all every time you you have to try the pluging first second what you have to do is to factor x² 25 x² 25 so it is basically x² 5² so a² B squ so what it will be so a squ b square will be uh A b + a a minus B and then a + b okay so that's the that that you have already studied so what I'm what I'm going to do the limit of a function X approaches 5 x² 25 / x 5 will be what the limit of x approaches 5 and that we have factored it out okay that is x 5 and x + 5 and in the denominator we have x 5 isn't it isn't it so what so what we will do we'll cancel out these two so what will what we have left with X limit of x + 5 now what you do now you put your x value over here now you use sub substitution limit of x approaches 5 of your function 5 + 5 so that will be 10 so limit of x approaches 5 is nothing but 10 so what you have done you factored it you do some algebra man manipulation and then you at last you plug in the now you left with something now you plug in and then you now you plug in or use the substitution method and then you are done with the the limit of this function will be 10 that exactly what you have seen before okay I hope that this is this is pretty much clear to you what I'm going to do just recap recapture Rec capsulate once you again is basically what we have done is to first try the plugging method first try the tried the plugging method second what we have done is to factor x² 25 and 25 is perfect square of 5 okay so x² 5 S okay and then using the a a b and a + b okay we can write something like this so that it could be cut in like this okay so the just and then we'll be left with this and you can plug in the values of X and then you are done with this okay that's that's that's that's pretty much easy this way for evaluation of the limits is what I'm going to do now is to take another example to Showcase you the rationalization stuff and uh so that it would be very easier for you at least so another example is what is the limit when X approaches 4 of this function fun otk x 2 by x 4 okay so this is your basically the the the the you have to EV evaluate the limit it's just simply telling when X approaches 4 from the both side what it is approaching on the Y AIS okay so first of all what what I have told to you what I have told to you is to try out is to try out uh a plugging method plugging so let's try out so so it will be nothing but 4 < TK 2 okay 4 4 whatever above comes 4 2 that is undefined that is undefined okay so plugging does not working at a first second thing what I've told to do the second thing what I've told to do is to multi uh now we have to think of something like this so limit of x approaches 4 x 2 X 4 what we can do so that uh this x 4 cuts off okay because this is what is causing the problem at the denominator so if if you know about the conjugate the please see the definition of conjugate simply changes the sign of it okay please see the conjugate over the Internet it's very one one minute definition you multiply with the conjugate of x x 2 you multiply the conjugate of x 2 so times x + 2 the conjugate of x 2 x + 2 x + + 2 okay now what now what you will do so you are left with x otk x 2 otk x + 2 so a b and a + b that will be what a s b s so otk x² b² okay and this will be left with x 4 and this otk x + 2 otk x + 2 now when you when you do this x 4 above will be x 4 x 4 < TK x + 2 otk x + 2 okay I think I'm correct so this is cutting out so the the left will be root x + 2 root x + 2 now this is your now what you do you put the value of uh four over here okay so 1 / < TK4 + 2 so that will be nothing but 1 / 2 + 2 that's 1X 4 is the limit the limit when X approaches 4 of this function of this function x 2 x 4 is nothing but equals to 1 1X 4 that is your answer okay so you have tried plugging mainly the substitution the second thing which you have done is to um this the second thing which you have done is simply uh uh factoring main not not exactly factoring multiply the conjugate so that the so that what is causing the problem will will be eliminated and then you put put in the value then again you substitution to take out 1x4 is the answer of this EV limit okay I hope it's pretty much clear to you at least now what I'm going to do is to talk about nothing but a squeeze theorem I think that I'm very bad at this means a drawing squeeze theorems but I'll fully fully try to just help you understand what this exuse theorem tell you I'm just going to not spend so much time on it but yeah it's it's good theorem so basically this this is also called a sand theorem sand Wich theorem okay so say you have a function f g and H so let's draw a function FG and H so let's draw a function f g oh my God this is this is not f and g Okay so this is your function so let's draw some something like this oh what the hell this is just want to take simply this this one okay so this is your thing and what I'm going to do is to add wait for a second okay and this is your another function okay so this is your I think I think that this is your F and this is your G and this is your H okay so I hope that this is a squeeze theorem something like this so I I can just explain you this so you sech search online for the exact picture so that the so that it would be better for you at least so you have a function you have three functions f g and H where G is sandwiched below your function f and H okay so basically this G is stand pitched below between your function f and H and you can see and you can see the when this let's let's let's assume this is one this is two okay and this is also one 2 and this is three okay so what is the limit of x x approaches 2 of a function f of x of a function f ofx okay what is the when when when it goes from this side and this side it seems to be approaching three it seems to be approaching three okay okay so this seems to be approaching three but it seems to be approaching three what is the limit of H of X when x x x approaches 2 it it is also three because when you because H is lower than the your F okay but when when we see see when when when when we go from right hand side and left left hand side it seems to be also approaching three so the limit of x approaches 2 of a function f ofx is equals to the Limit of X approaches to of your h of X is equal to the Limit and if if they both are equal then the that is also the limit when X approaches 2 of your G of X is also equals to 3 so these three will be equals to three okay so this is what the scuse theorem tells you the rigorous proof of this theorem can be seen on the internet if if you want to dive in okay so the basically what it's telling the limits of these three theorems will be the same okay don't don't worry about this it's it's it's it's kind of uh not a big deal just a basic example to help you understand when X approaches to from the left hand side and both right right hand side in all the three functions cool so we have if you haven't understood uh understood squeeze theorem don't try to understand it's not even on your deep deep learning syllabus okay so we have seen this uh very precisely and I also hope that you understood it as well uh in the next video we'll start off with the differentiation I will try to complete differentiation as much as I can I'll will try to there is three to four videos on differentiation I just want to talk in in a very cool way so that everyone could understand what the differentiation is and it's it's nothing but the change mathematics of change when one changes just a fancy slope we'll talk about that in detail I hope you will understand it I'll be catching up your next video till then byebye have a good day hey everyone welcome to this lecture uh in this lecture we'll talk about differentiation we I think we'll just uh get get get some idea we'll reach till the formal definition of derivative we we'll try to Define derivative with which is uh using the different coecient uh definition so we'll try to Define derivative we'll try to take out the derivative of a function which you which you can think of something like 1/ 4x2 we we will derive these kind of function f ofx = to or we'll derive the function like f ofx = x² you will get the tools after this video where you will be able to derive these kind of uh the the functions which are not too much uh funky functions something like this okay so so it is important as per the AI and ml Ai and ml uh if you are just want to get an idea about how differentiation works and how do we take out the derivative or you to do your back propagation because in deep learning we are going to do everything from a scratch maybe deriving the back propagation U um using uh derivatives and we we'll try to derive the we'll try to take out the derivative of the function when doing the back propagation and then we'll do the lot more stuffs from very scratch okay so so that's why I want you all of you to just take a very good attention at this in the next couple of uh very videos as well as because in this video I'll give you a geometric intuition as well as the intuition of the definition of differentiation the next video we'll see the differentiation rules like quotient rule power rule chain Rule and a lot more we'll also see the vector Cal calculus after we complete differentiation and integration because uh I'm just going to cover up integration as well it's the only reason because in probability and Theory you probability Theory and statistics you in probability density function CDF thetic require you to have a knowledge of integration and as well as some some of the deep learning research papers it is not too much found integration in deep learning but yeah it is uh in behind of the the con concepts of PDF CDF which you usually do okay so we had a lot more talk now let's get started with uh with with the defining with journey of defining differentiation and I hope that you will be able to understand but before that what I want you to do is just recall the slope and then using the slope I just if you if if you have seen my previous videos I told you differentiation uh is is is the process of taking on the derivatives and derivatives are nothing but the slope of a curve okay or slope of a function so let me just take one example let me take one example example States oh my God yeah example States example states that you have uh for example example you have this line okay so let me just draw the line you have this straight linear um straight line okay uh this is this this is on your graph paper where it where it goes on xaxis one unit and it goes above 1 and half unit okay and it does it is the linear so it is same at everywhere so one 1 / two etc etc so you pick any two point you pick any two point and you see okay it is running towards uh it it is running one unit and is going above Rising one 1 and A2 units okay so it is uh running one unit and Rising 1 and a half unit so slope formula is nothing but the rise overrun rise over run okay or Y2 y1 and X2 X1 we are seeing that is running one unit and is going Rising it is running one unit and it's rising 1 and/ half unit okay so it is Rising 1 and/ half unit over 1 okay so the final slope the final slope which you will get which will be 1/ half okay that is the slope of this function let's give this function name as G of X okay so the the slope of this function is g 1/ 2 and simply means how much y changes how much y changes when X changes you can think something like this as X is changing one unit X is going one unit and Y is move U rising up 1 and half unit okay when X changes okay so that's that t you can think of slope or the steepness of your line that's also the that's that's also you can understand by the slope okay the steepness of your line okay so uh this is your slope now coming to the calculus term what is the derivative what is the derivative of this function G ofx what is the derivative of this function G of X with respect to x with respect to X that will be nothing but 1 / 2 that that will be nothing but 1 / two why it is one 1 / two is over you because the derivative as as as I told derivative is nothing but the slope nothing but the slope that how much how much this G of X or Y changes how much this y changes when X changes how much this y changes when X changes okay so that is nothing but a slope but the fancy term in calculus we we we give which is derivative of course there's a lot more difference between the your regular slope and the derivative which we'll see later on but as of now what you can see that the derivative of this function G of X is nothing but 1/ 2 2 is nothing but 1/ two and how this 1/ two came is we are seeing that okay it is uh it is a linear line so derivative is nothing but a slope but the slope is rise over run and we are going one one at the this at running towards one and Rising 1 and half okay so the derivative of this function G of X with respect to X how much X Change or how much y changes or it is just equivalent to y 2 y1 over X2 X1 you can think of like that because this is a slow formula okay so that is uh that is the derivative of this function is nothing but 1/ two and this derivative is nothing but telling exactly the same how much this function or G of Y changes how much this y changes when X changes a little bit okay so you can think of like that okay so now I I'll take another example so you are more comfortable with okay so you have a l line you have a line let let me just draw a straight line something like this okay you you're moving towards you are running one one unit let's assume you running one unit okay and you're running one unit and you're Rising three units you're Rising three units okay so you're running to one one unit you're running one unit and you're rising and you're Rising Three three units Rising three units so what is the slope of this what is the slope of this um function so the slope of this graph or the function is uh maybe 3 over 1 3 over 1 which will be nothing but three okay what is the slope slope is three okay what is the derivative what is the derivative and derivative of this linear we we don't require derivative over here but what is the derivative so derivative Dy by DX Dy by DX which is which is just tells how much y changing when X is changing X is changing one it is going rise it is going one and it it it it is Rising one then Y is rising three okay so that is how much y changes when X changes okay so that that will be nothing but uh uh 3 over 1 okay 3 over 1 y changes 3 when when X goes 1 then y goes up three when X goes x x run one then y run Rises three okay so that the derivative will be also three so we write this is this is a formal this is a formal way we write Dy by DX Dy by DX okay so derivative of this function y with respect to X derivative of y with respect to that point x okay with respect to X so for example if you want want to take out derivative of this point derivative of this point so you'll get the same thing you're going one at this side and you're moving up okay so I'm I'm not taking the exact stuff but the but in the the function you'll be going so this is uh this is a point okay so that will be three okay so the slope of the slope of the linear lines will be always constant so any point you go on X for example if I go any point on this the slope will be same it goes the slope will be same of course the slope will be same the derivative at this point for say X1 the derivative of y with respect to X1 will be also maybe it goes one unit and 1 one that will be one okay so it is it is writing Dy by DX which is the derivative of this function y we we we we can we can name the function but you know the function for example we can remove this F ofx we can just write y okay so the derivative of this function with respect to X okay and X can be Point okay over here okay so this is so this is a formal way of representing Dy by DX another way to represent U derivative uh it it is read as Dy by Dy DX okay Dy DX which is nothing but uh uh uh derivative of the function with respect to that X okay another way we we can write in various ways we can write the derivative of function in various ways let me make you familiar with the ways as well okay so uh so we can write let's let's assume we have a sum function f ofx okay which is let's assume uh any function okay any function let's let's assume F ofx so when you want to take out the derivative derivative of the function f ofx with respect to X you you can just write derivative Dy DX d y DX so sorry Dy DX okay the derivative of function ex it is equivalently equals to this it is we we can also write F Prime X or fx that exactly that tells you the derivative of this function derivative of the function f with respect to X it is ALS we can also write this as a Y dash because Y is a function and we say what is the derivative of the function y with respect to X or we can write f F like like this or we can write y this there are lot more techniques we can write d x f something like this so they all are equivalent but we'll follow the formal notation which is this one okay Dy by DX which is nothing but how much y changes when X changes and that is nothing but the slope that is nothing but a slope but don't worry I'll give you the formal definition of a limit in in just a second when be try to Define differentiation with the help of a rate okay so we will try we'll come on that don't worry okay so I'll just give you the formal definition of a limit so that you could uh you could just Define limit what it is but as of now how much y changes when X changes okay so there so there are tons of not exactly tons of ways there are so many of ways for writing the derivative notation okay as you know the peoples are very smart on the earth they they just invent these kind of stuff I don't know why they haven't stick with that Dy by DX because I like that notation I don't know what the researcher have thought of maybe ISAC Newton has thought of this one and then a lot of researchers that thought this one and they all fight it together to get the work done but I don't know what they have done I have to go at the past and then ask them okay cool so we have seen the derivative of a line and I hope that you understood it as well so uh one thing which I Let's uh do we want to go ahead yeah let's go ahead let's let's let's talk about one similar example so that everything u i I don't think we should go ahead and uh see one more simple example because we have already seen it now we have seen the derivative of a line now we have seen the derivative of a line which is nothing but a slope of the line okay so you may think hey I Ed Dera is that simple no it's not that simple we'll we'll see uh we'll see but yeah it it it it it is not it is doable if you uh keep your good mind concentrated over here okay cool so one of the example which I want to highlight is from calculus for dummy's book okay example is from calculus for dumy book you can check out this book it's amazing book which I ever seen on calculus for beginners is is what I use for teaching as a reference uh there there there's an example where there there are two students there are two students let's Assume My Name aush let's assume uh let's assume there are two students aush and let's assume there second student which is Risha okay which is Risha uh maybe R is my best friend over the school but these are the two uh students these are two friends okay whiches around I think they are they are they are um I I don't know the the name of this seesaw yeah that is seesaw when when one goes down then up for example this one okay when um one is sitting above on the bench one goes down and when uh this goes down this goes up okay let see so I I don't know how what what what the name of the game is but that is the game okay so here it is telling that the IOU this aush aush is the the weight of aush is twice as as much as Laurel okay as sorry as much as Risha okay so iush weight is a twice as much as rishab okay so the rishab age is 20 sorry weight is 20 then aush weight is 14 okay so if the rer age is X then iush weight is 2x okay that is twice of Russia now they are they are on they are on seesaw they are on seesaw and this is something like like this this is a ground this is a ground and uh uh rishab is sitting here and aush is sitting here okay and a a is sitting here and rishab this is rishab and this is aush and of course I just changed the name so that uh uh it it it is not uh too much so so so that it would be understandable uh to to you all because I find those names very hard to pronounce and you can more connect with the Indian names if you're an Indian okay so there are two students rishab and Laurel where aush weits is twice as much as rishab now rishab has to has to sit twice as much closer so they have to sit as much closer to uh rishia okay for them to balance up okay because it is to much heavy is very hard to balance okay uh and for every inch for every inch aush goes down for every inch aush goes down rishab goes up by rishab goes up by 2 in okay so when uh when the aush goes down by 1 in okay then rishab goes up by 2 in okay so if the aush goes down by 10 in the Risha will go over by 20 in okay so aush weights of course higher so that's so so just listen my thing is when aush goes down by 10 Ines then rishab goes up by 20 in when a goes down by 1 in then rishab goes up by 2 in down up down up something like this okay so when aush when aush goes down by down by 1 in then the rishab goes of above by 2 in so it is so rishab mov moves twice as much as a so Ria moves twice as much as a us okay so then you got this is this that's a derivative you got the derivative so so we'll see it you got the derivative and you may recall this is nothing but your favorite rate okay we'll see it so uh rishab moves twice as much as hardi uh twice as much as aush I'm just taking the book books example because I have written my notes over there uh that the the name of the hard over there but uh basically uh rishia moves twice as much as a reserve moves twice as much as a so uh Dr okay so I didn't denote Ria with r is equals to the D 2 D A okay so the r goes R moves twice up as um uh aush okay so with the calculus symol you can write it something like this and when you uh when when you divide both side by da or you move it over here Dr by da is equal to 2 and that's nothing but your favorite derivative which you got that's nothing but the favorite derivative which you got and over here this derivative this this your your your your your basically this what what what you're seeing is the derivative of R okay so the derivative of your R okay derivative of rer r with respect to ause derivative of rer r with respect to ause so Dr can be thought of as a change in uh r position as dhda can be thought of as a change in a position okay so if hardi goes down is if aush goes down by 1 in then rishab goes up by 2 in so Dr can be thought as change in rishop position and D can be thought of as a change in a position okay so that this is this is what you got when you the calculation this is what you got as uh this is what you call it as a derivative and this that D DN by DH it's just telling derivative of r with respect to a okay derivative of rishab with respect to aush so what does it mean that rishab is moving two times as much as aush rishab rishab moves two times as much as aush okay that's the that's exactly what you're telling that this is uh this is dy by DX which is derivative of r with respect to a is nothing but telling the rishab moves two times as much as Hardy aush okay so that's that's how you got the derivative you can take a look this is this is the derivative which we taken out from the from the uh Ria point of view okay because R was moving up but over here but over here uh you you can take out the derivative from the aush point of view from the aush point of view okay so so the so the da a the derivative da can be thought of as a change in a i position is equals to 1 / to DH when aush it is just telling it is just telling uh aush moves half as much as uh this guy Rish Okay so aush moves half as much as uh risham okay so da equal to Dr R Dr so when when do the calculation da by Dr is equal to2 and that's your derivative which you got which which you got and that is nothing but the derivative of aush with respect to rishab and it simply means that a moves 1 and2 inch for every inch Laurel uh that rishia moves okay so so so basically what is doing is uh it is the derivative saying that uh aush is moving 1 and half when I aush is moving moves 1 and2 in for every inch Ria okay so how much as as I told how the change in position so how much a changes when R changes okay okay so a um when a a a is changing 1 and half when R is changing so when aayush moves 1 and/ 12 in when uh rishab moves 1 in okay that's that's pretty much clear I I I hope so uh it is if if you're getting confused please recall the video again so that you could be easily understandable it is very very easy to understand again I'm recalling that uh this is d a by Dr da by Dr is is the derivative from the aush point of view so it is just sing how much iuse changes when R changes when rup changes and it's how much rup changes when iuse changes okay so this these are two from two point of views so it is just in this one how much how much I use changes how much I use changes how much I use changes how much I use changes when how much I use changes oh my God how much Rish up changes when iuse changes and how much iuse changes how much iuse changes when Rish up changes okay so this is from different point of view and we taken out the derivative from the same okay so I hope that everything is clear I'm not going to talk about too much on that because we have already taken a lot of time on it and I hope that is very very understandable to you as well coming to different thing I I I think I'll just I'll just give you a proper definition of uh not I'll not able to give you the proper definition because it is already let me the timing that this one HS up so just see the timing it's 24 okay I can continue it I think I can continue it yeah so uh let's talk about let me give you the formal definition let me give you the formal definition of uh just just just just a English definition the English definition which you which the example you saw this example you saw is the derivative so as I already told you thousand times a derivative a derivative is simply is simply a measure a measure of how much how much one thing changes compared to another compared to another okay so d a by Dr saying how much a use changes compared to Russia okay that's exactly called the derivative cool so another we can another we we can think of Let's uh uh uh another another example can be uh when when a person driving at a constant speed of 60 M hour for for example there there is a car I don't know how to draw a car oh I I got to know about the car okay so this is a car this this is a car and this is going with a constant speed of 60 M hour 60 m per hour okay 6 6 60 M hour and it's driving at a 60 M hour so uh what is the derivative derivative of p with the D DP by DT so is telling how much how much how much position changes when time changes if there's 2 hour then where's the car is okay so that we we can think of it as a derivative as well okay so we had said it we had talked a lot about linear only and I hope that you understood that understood it as well okay so we have only talked about linear over here it is going to the constant speed it is just going at a constant speed and we have we have talked about only the straight lines we we are not talk about the the the the the derivative of a curve okay so the derivative of a curve where the slopes are constantly changing at every point where the slopes are constantly where the slopes are constantly changes so this is a parabola where the slope are constantly changing at each and every point so let's say you want to take out the slope at this point C how you going to take out let's say you want to take out a point F how how you going to take out say you H how you going to take out so there are so we so we'll see today about this okay so uh what I'm going to do what I'm going to do is just just tell you what's the derivative okay just going to tell you what's the derivative but how I take out how I take out I will talk about in the next videoi or in the in in the next video where we'll learn about the difference coecient or I'll try to cover the different coecient in this video only okay let's let's let's let's try to cover the different coecient in the next in this video only say you have a function f ofx = to 14x squ so the diagram for this will be like uh will be like uh something like this I I'm just going to make it something like this so that's a um a graph of this function that's a graph of this function that's a graph of the function I hope so that's a graph of function so you have an X you have an Y and the derivative of d by DX so derivative so say for say say for an example say for an example you want to take out the derivative of this point and this x is 2 and Y is what Y is what uh let's assume uh or X is one so let's assume X is 1 and y is0 0.25 okay so that is derivative 0.25 D D1 okay so what it will be what it will be it will be I'll just take uh what is what is the slope at this point uh that is we we can use the derivative to take out the slope at at at at that point uh you you I already explained you how we will we'll see how it how how how it does but later on but over here the derivative of this function is nothing but 1 / 2x you can plug in the values of X you can plug in the values of X say for an example that I plugged in uh I plugged in 1/ 2 1 / 2 * or x/ 2 * uh I plug in two okay so it will be one and the derivative and the derivative at this point one at this point one and it will be one it will be what it will be one the slope at this point the slope at this point the slope at this point D the slope at this point will be one okay you have the derivative and you can put any point you can put in any x value you will get the slope at that point okay because we make use of derivative to take over the slope at at exactly that point okay so you can make use of you can make use of 1x 2x we'll come to that how we evaluated 1X 2X and the later videos but in differentiation rules thought I will cover in this video only uh so you can this is how you take out the Dera we have we have saw using the derivative you can put in any value of x after taking out the derivative of function which is how much y changes when X changes okay so which is one 1 1/ 2X and X which the value which you have to input in to get the slope at that point or to get the derivative at that point or to get the rate at that point okay or you you all know okay so we had this we we we'll see how do we how do we got 1/ 2x but before that let's talk about the difference coent let's let's talk about the difference coecient because it is the most important concept which one need to know okay because most of the most of the things in calculus is based on it's just because it is it is needed because uh I have think I I I think uh if it it just tells you how it gets infinitely closer to make the line from curve to a straight line okay so we so we'll see today one okay let me find uh the copy which I want so that I can at least go ahead and I'll have help you out okay because I usually make notes before teaching in video because I can just hope that I don't make any uh mistakes in the videos see say for say for an example you have a graph something like this okay you have a graph something like this okay let me just uh draw this one graph at this point yeah that's good okay and you pick two points and you pick two points let's say this one X and this one okay so you pick the two points and you assume that this is a point x there on the x coordinate is X and there's a h distance between this point so this is x + H so this is H so for example this was 2 and the distance from this to this is uh h = 2 then over here it will be four okay so you can assume like this so H so H depends on H okay so uh the distance is H okay the distance is H so this is a point this the x coordinate is is x and y coordinate so and another point so this is X1 one coordinate and this is the second coordinate x coordinate okay so what is the coordinates of this point it will be X which is on X and this is your f of x function okay so this is f ofx f of x okay and what is the coordinate of this point the coordinate of this point will be X+ H is your X is the point is xais and that will be nothing but f of x + h f of x + H because we want this is also the distance of H okay so f of x plus h uh which you're seeing over here okay now we we got the we got the coordinate of this we got the coordinate of this so the coordinate of XA f of x and there H distance where this there on X X Plus H okay and this one is X the the coordinate of the xaxis and this is of Y AIS okay so I hope so it is making sense try if if it is if it is getting confused try to think on yourself is if you if you move this X Plus H and if you if you try to put put in that function f ofx and we can add some value H so that's it that's that's that's pretty much the common sense uh this is a very common sense to understand X+ H okay now coming to this now coming to this what we can do we can draw a secant line we can draw the secant line so let me draw a secant line something like this let me draw a secant line something like this a secant line the definition of a secant line is a line which intersects two points two points on a which which intersect two points on a graph which intersects two points on a graph that's a secant line or a more formal definition of a secant line let me just have you the more formal definition of a secant line a secant line is a line with that intersects a curve at two points okay to intersect a curve at two points uh this is where we draw the seant line and the secant line is something this now now what you can do if you take if you take this point if you take this point if if you take this point oh my God I think I have to choose the pen yeah if you take this point okay you make it closer to this point okay so when you slide this point with your secant line you slide this point to over here with your second line okay so let's do do do the thing now you you'll be getting just make sure that you're following me just make sure you will be having something like oh my God the SEC L do does not work correctly over here let me make something touching over there okay now what you do you you now this this point has come to over here now what you do you you take this point you slide a little bit with the SEC line you slide a little bit om mg uh you slide this a little bit okay now let me just draw it okay you you slide with the secant Point as well you slide with the secant line as well okay you you now what you do you take this point again you slide it again you slide it again you slide it okay now let's slide it again uh it will be make sure that it intersect the both the point okay now again take this red one again take this red one slide a little little bit over here and let's continue doing that okay that will be intersecting at the two points okay at some point at some point it will be so let's let's draw the graph again again so what you're actually doing you are making this you are making this H you're making this H to be to to approach to to approach zero okay you're making this H we can make use of limit we can make as as we want to go uh closer and closer to not exactly X but we but what we can do we can make this H approach is zero when X when h approaches zero when H approaches zero it will be F ofx so oh my God uh when f of x okay f of x and this f of x plus h when this H becomes H approaches zero then then that will be so let me just make you familiar let me complete that thing okay so we will come to this will come to this okay so this was yours and this was your two points this was your two points now when you do this when you do this you will be left with something like this a secant line from us from sorry a tangent line a tangent or over here from the secant when you when when when when you take your H approaches zero when you when you just make your H when you may just make your P um make use of limit make use of limit when H approaches zero when it approaches zero okay so this point will go over here here here here here so at some point will become a tangent it will become a tangent and the derivative of any function of a function is the is is is the slope okay of a tangent the slope of the secant would be if if I draw a secant line the slope would be we go at this point so we go something this so rise of run so it is very easy so secant line becames the tangent line becames the tangent line and the tangent the slope of the tangent line is nothing but the slope uh the derivative the derivative the slope of this tangent line is nothing but the derivative so what you do so the so the slope of the secant line so let's let's start writing the formal definition let's start writing the for formal definition I think uh it would be very easy for me at least to draw it again okay so everyone is on same Pace OMG let me mix little bit up yeah so this is your one point and this is your second point Point okay let's draw a secant line over here okay and uh so what is what what will be the slope what will be the slope of this of this of the secant line so we have we were having our x coordinate okay and then we were having x + H and this was a distance of H okay and this was uh X comma f of x and this was nothing but X XA f of x + H okay so this is what you have so what so what would be the slope the slope of this would be Y2 y1 X2 X1 okay so f of x + H f of x ided by x + H x okay so this plus minus this cuts down okay so you'll be left with f of x + H f of x / H okay so uh now uh now you got the you got the slope of the secant line that is nothing but called the difference coecient difference coent okay quotient okay why I'm pronouncing it wrong so that is the slope this is the slope of your secant line so when you when you make your H approaches zero when you you make your hedge approaches zero so this will become a tangent line so it will go slide over here you slide it over here you slide over here so it will be something like this and then it will something like this and it some it it will somewhat become like this it will it will only touch uh okay it will become something like this this is the tangent line This is a tangent line so what how you can do this you can make use of limits to make your H approach zero because if the H gets if the f of x so it make in in other words you can you're sliding this point to this point and that will be equivalent the coordinate will be equivalent so you just want H H to be zero so H approaches zero not not exactly zero technically you can you can't get exactly zero f of x plus h f of x plus s f of x / H okay and that's the the derivative of your function with respect to X that's the derivative that's the definition of a derivative with respect to X okay so the seant line becomes the tangent line when you approach H to the zero so I hope that this this this this makes a complete complete sense okay so it just tells how much the function is changing when X is changing it it what it does so what it does again I'm again I'm telling it slides you can see the slides over here it started to become the tangent line so it started making it h h approaching zero okay you made use of limit to Define uh this uh this this this a derivative and the formal definition of a derivative let me just Define it for you let me just Define it for you let me just Define it for you um okay uh I think I have to find that definition of it yeah so the definition so the definition the definition is derivative of f ofx with respect to X is equals to limit when H approaches zero f of x + hus f ofx ided h okay that's the formal definition and what it does what it does this slope or this simply the shrinking we are shrinking rise over run we are shrinking the rise over run okay we we are making shrinking we are making of limit property we shrinking over here sliding this uh this this this coordinate this coordinate okay so we had a talk a lot and I hope that you are uh enjoying it as well even I am enjoying it okay but one thing the just one question which I want to solve is take out the derivative of the function f ofx which is 1 / 4x² which is 1 over 4X s we are going to take out the derivative now okay which you have seen we have taken the derivative okay one one 1/ 2X I will just show you how I taken out so this this is your function now let's go ahead now let's put in let's we have a definition now we can limit of H approaches zero limit of H approaches zero we can put this uh X this x is the coordinate which which he wants so we just going to give X and we can take this 1 over 4 as a coent okay because that that only wants 1 / 4 okay x + H and we don't have to leave a square because this is the one X we want okay minus your whole function 14 x² okay 14 x² cool divided by H divided by h okay so this is your now we are going to evaluate this limit so the limit of H appro H approaches zero 1 / 4x² + 2 x h / 4 + h² A + B whole Square you know 1/ 4² 1 / 4 x² so this one cuts out this one this one cuts out out this one so you are left with you are left with limit of edge approaches Z 2x + H over 4 plus uh maybe uh I I yeah I can write something H Square okay you can write the four over here as well you can write this four over here as well okay because when you when you when you multiply this oh my God why have left this when when you multiply 1 over4 with every member of this so that will be nothing but uh let me be little bit transparent let me be a little bit transparent let me be a little bit transparent then I think that I've done wrong a little bit I don't have to do wrong over here yeah let me be a little bit transparent so oh my God sorry for delays but 1 / 4 just expand in x² + 2x H + h² 1 / 4x² now you simply limit of H approaches Z 1 / 4x² + 2 x h by 4 + h² by 4 1 / 4x² this cuts out with this limit of H appro H approaches 0 1 and now it cuts down so 2x H 4 + h² 4 okay let's uh let's let's keep keep keep on working on it so that let's write the same thing again H approaches zero 2x H by 4 + h² by 4 by H I think I forgot in everything H we don't have to forget H okay by H so H is there don't forget okay now what I will do I will try to add it when H approaches 0 4 okay so that will be nothing but 2 x h + h² okay the limit of h h approach is zero we take common H 2x + H uh by 4 by H and this cuts out this and this cuts out okay so limit now it's very easy 2x + H by 4 now you can do the substitution you can do the substitution limit uh now we don't have to write limit 2x + 0 by 4 and that will be nothing but 2X by 4 and that will nothing but X by 2 or 1 / 2 x okay this was that much easy to calculate the derivative of a function okay using our formal definition of a limit and we showed you the geometric interpretation of the differentiation I and I hope you really enjoyed it try to take out the derivative of x² so just just just for your convenience the limit it it will be x + h² x² / H okay divid by H so let me see if it is exactly equals the same yeah it is divided by H okay so this now try to take out now this take out the derivative of a function f ofx which is x² and using the limit formal definition okay so I hope that this is pretty much clear to you at least uh I hope so it it is very much clear although you get a very very complex function complex function it is not a we we we we can't use our uh we have a different differentiation rules which will help us to do take out the derivative very quickly which we'll talk about in the next video till then byebye have a great day you have done a great job today meet you in the next video to this uh video uh in this lecture basically we'll talk about differentiation rules in our previous video we talked about uh differentiation which is approximately 40 minutes of video so sorry for that much long the only reason is uh I just completed the whole differentiation definition because in the previous video we given you the geometric intuition of differentiation and in this video we'll try we'll we'll see some of the rules for taking out the derivative of a function of even a complex functions we'll try to take out in the in the in this video and the next couple of videos so try to see that and then we'll see a local Minima and Maxima we'll try to see that uh and then future varibles and then we'll go on integration we'll complete the integration the same way as we completed differentiation however we'll not focus on that much on integration because it is not being used too much but but we'll surely take a look because sometimes it comes integration comes over the research paper then we'll go to the probabil probability Theory and a statistics and then we'll start with deep deep learning and you may be thinking hey why we are learning these much things and just I let let me tell you what happens if the beginners get very confused oh my God what is happening behind them behind the algorithms when they study deep learning so when we are going to start with deep learning then we are going to go very fast way okay um it's because you'll be understanding each and everything each and everything whatever I'm going to write it out and if you don't see these videos if you don't know what is calculus if you don't know what is uh uh what is differentiation integration you been not getting the actual point of view of deep learning and you'll be not understanding deep learning so that'sa we are doing all those things and it's very very useful to learn these as well for your professional career because it will maybe if if you want to go in research it will very uh you'll be able to understand hardest research papers in this era okay so let's get started with the uh differentiation rules I'm not going to recap the previous video but I want you to see the previous video uh which which which you have already had a talk on that but we have we had formulated a definition we have for formulated a definition of differentiation so let me just give you what what definition we have formulated if you want to take out the derivative if you want to take out the derivative Dy by DX and Y is a function okay so we we are solving for y so we if you to take out the derivative Dy by DX we were have we were having a limit definition okay this a using the difference coent when H approaches zero limit sorry f of x + H minus F ofx by H okay and this is this is the this is and You by solving this by using the this we are we are able to get it but when you have a too much complex functions it would very tedious and almost impossible for you to achieve using this okay so that's how we have differentiation rules which will help us to uh take out the derivative of the functions okay so let's get started so let's get at least get started with the today's video uh the the first rule which I'm going to talk about is the first rule which I'm going to talk about is uh the the the constant rule okay so every everyone should should have to should should be familiar with it it's a constant rule the first rule which I'm going to talk about about is the constant the constant rule so what this rule tells if you have a function let's say F ofx equal to 5 okay f ofx equals to 5 and and this and the derivative will be zero the derivative will be zero and the slope will be also zero because derivative is nothing but a slope and over here the it the the derivative the change the it is nothing is changing so derivative will be zero so the derivative the derivative of this function so basically we'll write y = 5 so derivative of f ofx with respect to X so we write f ofx is equals to Z okay for this function the derivative for this function f ofx is with respect to X is equals to zero nothing is changing okay nothing is changing uh just I'm to introduce to you the note notations just I want to introduce to to the notations we can write this in a short form as well F Prime x equals to Z so this is this this not notation this notation d uh F ofx uh by DX D of Dy by DX is equivalently equals to this equivalently equals to this okay so it is just telling fime X just a short form which will use interchangeably we we we'll use this uh consistently both the formats so that everything is crystal clear so we'll use both the things uh very frequently at the same time okay so that it saves the time and I like this notation much better but for the definitions of the con of the rules we'll use this notation so that everything is clear okay so we'll use that these two notations very frequently over this video so let's take some more examples so this was the one of one of the example the another example which I want to talk about is G of x = to 7 G of x = to 7 so what is the derivative what is the derivative of this function G of X of this function G of X with respect to X which is also equals to Z or F G Prime X is equals to Z okay so this is the constant rule which we had a talk on okay now let's go ahead now let's go ahead now let's go ahead let me just uh finish this uh this stylist now let's go ahead let's talk about the functions like let's take an example uh you want to you want to take out the derivative F ofx = to X the power 5 x to the power 5 you can use this limit definition to to do this but but there is a very quick way to take out the derivative of this function okay how how much X is changing when uh Y is changing changing okay so uh you see the definition in in my previous video because you'll be getting more bro broader view what this derivative is trying to do okay so we we we can use a rule called power rule okay there is this is a very very extensively used in other rules as well so please make sure that that you understand each and everything so f of x = to x to the power 5 okay so so let's take an example you take out the derivative of this function f ofx of this function f ofx with respect to X so how how will you do it so derivative of this function f ofx with respect to X which will be nothing but what you do you take this power you take this power and bring in front of the bring as a coefficient of x so you will take you'll take this power okay bring that in the front of the X okay and reduce that power uh by 1 okay so 5 1 so it will be nothing but 5 x ^ 4 okay 5 x X to the^ 4 so there are two things which you have done there are two things which you have done the first thing which you have done is to brought the power brought the power brought the power to the to the just as a coefficient of that X okay and reduce used the the the the power at that x value at that x value by one by one okay let's see some some more examples of it so that it would more make sense at least to you okay so let's take an example that you have a function again let's use the function name of f ofx which is equals to x² which is equals to x² okay so how you're going to take out the derivative of this function the derivative of the function derivative of the function so how you will take out so what we do we take this two bring in front of x 2 x 2 1 so it will be left with 2X and this is one so we we we can neglect it but this is your actual derivative this is your derivative of your uh x² okay so uh this is the D derivative of this function f ofx okay if if you use this limit definition it would take around 2 to 3 minutes or maybe 5 minutes for you at least to take out two to reach till 2x but in two steps or two seconds or even one seconds we we completed it okay so so so that's why these rules are very very important as well let's talk about one more example you have another example x^ 2 x the^ 2 so what will be the derivative ative of this function so the derivative of the function the derivative of this function which is D Dy by DX which is nothing but equals to you bring this minus 2 in front of it you bring this minus two in front of it okay uh now what do you do uh x the^ 2 2 1 so it will be nothing but 2 x 3 and this is the derivative of this function this is the derivative of this function okay bringing the power in the front of the X and then uh reducing That Power by one okay so that is called the the the the power rule okay the another uh rule which which is which is related to power rule which is nothing but the constant multiple rule the constant the constant multiple multiple rule okay the constant multiple rule so let's take an example that you have f of x okay you have you have a function you have a function you have a function let's name it a y because I I have to write f of x times and times so let's use y equal to 4X to the^ CU okay the X sorry 4X CU and you want to take out the derivative you want to take out the derivative of y Prime or Dy by DX the derivative of the function with respect to X okay so what you do what you do you simply take this scalar okay that multiple four times the d uh uh maybe uh the derivative of x CU okay derivative of x Cube okay so what you will do Dy by DX of uh this x Cube or wait for a second let me just make it more transparent at least so that it will be very very useful for you at least Dy DX xq okay so four * the derivative of x CU will be the derivative of x CU will be what you can use the power rule bring the three in front of it and reduce the power by two 3x² 3x2 it will be nothing but 12 X2 is the derivative is the derivative of the function y okay so Dy by DX which would be nothing but 12 x² let's take another let's take another example let's take another example Y is equals to uh 2x² okay what you what you do you take out the derivative of this and after you taken our derivative and then multiply with two okay so the derivative is equals to uh two * the derivative X squ will be what bring two in the front sub subtract which is 2x which is 4X is the derivative of this function okay so that's called the constant multiple rule are are you getting what I'm trying to say yeah so uh this is the two example let's see one last example so that it's it make completely sense to you uh 4X ^ 3 okay 4X to the power oh my my god I've already taken it uh 5 x to the power maybe 4 okay so so how do you take out the derivative of this so what you do five * the derivative of X4 will be bring three in the front sorry bring four in the front then subtract X subtract 4 1 which is 3 which is 20x cu okay so this is the derivative of this function the derivative of the function will be 20 x Cub okay so this is this this is called the constant multiple rule another rule which which are which which we are going to see which is called the sum rule okay which is which is again the useful rule uh is very fairly simple rule okay so let's see the sum rule so the sum rule states the sum rule states um let's say you have a function you have a function f ofx which is equals to x ^ 6 + x ^ 5 + x ^ 3 + x ^ 2 + x + 10 what is the derivative what is the derivative of this function or what is the derivative of this function what is the derivative of function so the derivative of the function will be so what is the derivative function so what you do you take out the derivative of every terms okay take out the derivative of every terms okay so what is the derivative of x CU sorry x^ 6 so we we can use the power rule so what is the derivative which will be bring 6 in the front Okay 6X to the power 5 plus bring five in the front 5 x 4 plus beinging three in the front 3x² plus bring two in the front 2x 1 plus it will be what it will be 1 okay so because um this is 1 1 which will be what uh zero okay so x x to the power Z which will be equals to one so one and this is called this this was the the the constant rule okay so so this the this what is the derivative of 10 which will be zero because the the the there is nothing is changing over there in that for that function okay now this is your actual derivative so we can simplify it 5x ^ 4 + 3x 2 + 2x and this is the derivative of this function okay so this is called the sum rule okay uh the same with diff uh the difference rule works okay so instead of plus there will be minuses okay instead of plus there there will be minuses the one example which I want you to work on is uh G of X which is equals to 2X x ^ 5 + 6 x ^ 8 + 10 x the power 1 okay try to work in it and take out the derivative if the function is differentiable take out the derivative of it okay maybe it it is differentiable maybe make it plus okay so you want to take the derivative of this function G of X Okay cool so uh try try to do this just pause this video and try to do this if you can go ahead otherwise let me try to do this for you so so um so let's do this so 2 * uh it is 4 uh X so sorry I just m it's it's my habit I don't know why 5 x ^ 4 + 6 * uh 8 x ^ 7 plus uh May over here it would be 10 * 1 okay okay 10 * 1 and over here the left will be the left will be uh 10 X4 + 68 48 X7 + 10 okay so this is the derivative of this function okay so try to work on several examples the problem set which will be released through your LMS okay you you can see from there uh the soon the the LMS will be updated with the prior information the certificates of the the chapter number one and the chapter number two will be given to you okay please see the elements for the same and the email if you have enroll elements because there there are only around 100 students which have enrolled I want more of the people to enroll at least 400 okay another uh now we have seen this the constant rule power rule multiple sum Rule and difference Rule now what I want you to do is to remember some the how do we differentiate trig values and it would very tedious start for me to at least showcase so what what I want I have I have seen a lot of people to me memorize this because this is very very handy okay so we are going to talk about differentiating differentiating just just don't memorize it you don't have to see how it came and how we derived it okay this is um most of the people just remember this means who who whoever is is uh good at this okay uh just you can uh what is the derivative of sinine of X with respect to X which is nothing but cosine of x okay the derivative of s of X with respect to X is cosine of x derivative of tangent of X with respect to X which is nothing but secant SEC SEC squ X okay uh another is uh derivative of SEC x with respect to X which is nothing but SEC X Tan x okay another is derivative of cosine of x with respect to x minus sin of x minus sin of X and another is derivative of cotangent of X with respect to X which is nothing but equals to minus cose Square X okay and the last one is derivative of cosecant of X with respect to derivative with respect to X which is nothing but minus the S cosecant x times the cent of X okay so the these are the six trig values which I want you to remember okay because it will be very very useful when we talk when when we talk for further rules and very very handy as well okay you can always view means if if you do the lot of practices you will it will be automatically memorized in your mind because I haven't seen the lecture notes for writing these even what whatever I'm teaching I'm not seeing my lecture notes because I practice a lot of it I remember everything okay so uh try to just practice it out it will very easy for you to at least understand it these are six streak values which is very very Handful in your Calculus Journey till now okay and this is taken from one of the most most famous book on calculus are calculus for dummies okay so now what I'm going to now what I'm going to do is we have seen the some of the diff how do some of the different some of the derivatives of the some of the trick values which is six Tri values uh there you can search for online if you want to see the steps how they have come up with and if you want me to do just feel free to comment it below maybe I can make a next video on it but again this is a toally optional one okay okay so now what I'm going to do is uh talk about the last thing differentiating exponential and logarithmic functions okay at least this is very very important as well how do we differentiate a logarithmic function and how to differentiate uh how to differentiate exponential functions and logarithmic functions and then we'll see uh in the next video we'll try to see uh the product rule and the quotient Rule and in the next and in and then in the next video we'll try to see in the next to next video we'll try to see the chain rule of differentiation we'll try to see how to use different different like products rule in chain rule how it is very very useful in that then we'll see the diff implicit differentiation we'll see the logarithmic differentiation which is very which is very very useful in in your Calculus Journey at least okay let's get started with uh exponential functions okay exponential functions let's get started with that uh exp differentiating exponential exponential uh functions exponential functions let's start with it uh so what is the derivative what is the derivative of e ^ x by sorry with respect to with respect to X which is itself okay so that the derivative of this e to the^ X is itself the derivative is is its own function okay so e to a to the power x okay if you want to see how it came I would just link some video some resources which I really really like to because if I again go ahead and teach you it will very very uh boring um and also it is out out of the bound so what I suggest you to see the link in the video description okay so the the derivative of any exponential function means the e e to the power x is equals to the itself okay but what if we have a function f ofx which is equals to 5 E power x 5 e the power x so what is the derivative what is the derivative of function what is the derivative of this function what is the derivative of this function what is the derivative of the function so the derivative of this function will be what you can do what you can do you can simply you can use the constant multiple rule over here okay you can use the constant multi multiple rule so here's how here's how I'm going to do it so Dy d by DX of 5 e x so what I'm going to do is to take that five outside to it 5 * d by DX e to the power x okay so which will be nothing but 5 * uh which would be uh which will be nothing but five times and it the the derivative of the E to ^ x is itself e to the^ X so that will be nothing but 5 e x and which yields the same thing okay so the derivative of any exponential function most of them which have ever seen it's its Alpha function okay so I hope that pretty much everything is clear and here we use the constant uh constant multiple rule multiple root okay uh to to to to take that five outside the derivative and then multiply with the derivative of e^ x cool so we have seen some exponential functions you can try out 6X 10 x whatever you you want to try try it man okay so we have seen exponential function now let's see uh now let's see another thing which is a logarithmic function which is Game Changer over here and I if you don't know about logarithms I'll link a video I link a I link a simple uh uh Nancy p video which I really like her videos because uh she's she she is an MIT graduate and she teaches very well these things she teaches very well and uh now she stopped making the videos but uh his her videos on calculus I know the it is it is bit a half incomplete but she she taught these things very well like logarithms some the rules like chain rule I even watched her video amazing videos by her so you can check out the channel I'll just give a link in the description okay so uh another thing which I'm going to talk about is lo logarithmic functions how do you differentiate the logarithmic functions okay so let's take an example you to differentiate the function uh which is f of X which is nothing but natural logarithm of X okay so how do you take out the derivative of this function which is natural logarithm of X okay so which is nothing but log base ex isn't it log base e so which will be nothing but um which which which which will be nothing but 1 /x so the derivative of the natural logarithm of X which is nothing but 1 /x okay uh we will see when the when your base is not when when when your base is something because what we do we tend to me memorize some of the differ derivatives okay and then we'll solve further things using that whatever we had memorized and it's not a big deal to remember four to five derivatives okay so this is your derivative of natural logarithm of divided with respect to X which will be nothing but One /x one/ X so if your if if the log base if the log base B is a number is a number other than e other than e if it is other than e you can tweak this derivative a little bit okay so let's take let's take let's for for for the sake of an example you have you have a function f of x make it f ofx equals to uh oh my God my hand is painting now so F ofx which is nothing but equals to uh what say uh what say uh log base 2x okay uh log base 2X and uh how we do it so what we do what we do we simply if you take the derivative of this of this function which is nothing but 1 /x okay which is your natural logarithm by okay ln2 natural logarithm of two okay so natural logarithm of two okay so when you do this 1 / X natural logarithm of 2 this is how you do it for if the log Bas is different let's take let's take another example if you want to take out the derivative of a function which is log base 10 x you you you also write as log X which is by default the the base is 10 okay so I'm going to take out the derivative of this Dy by DX X of this function log base 10 x which will be nothing but equals to first of all 1 /x you all agree 1 1 /x divided by natural logarithm of 10 and uh when you do this 1 /x Ln 10 okay and that is the derivative of this function so this is how you take out the the the the derivative of the logarithmic functions and I hope this is pretty pretty pretty much clear to you okay okay what if we try to cover this in this video our product Rule and quent Rule just wait for a second I have to see uh the timing which we have covered we can do yeah um yeah let's cover the product rule let's cover the quo rule okay so uh no no no let's let's get on to the next video to cover these two the product rule and the question rule uh it it would be better for us at least so that the video duration should be short okay so we have seen a lot in this video I'll be catching up in next uh so now let's get started with uh product rule because in the previous video we had a talk on this uh various basic differentiation rules Which is far more very very easy to understand and uh from this video the things will get started a little bit difficult but as a sum rule as the as the difference rule the same will be the product rule but the product rule is bit important and quent Rule is also bit important for solving the derivatives questions and as well as uh in a when and the the reason why I'm teaching these because this is this product rule and question rule is important in your chain Rule and implicit differentiation and chain rule is the the far most important thing which you have to cover uh for deep learning and then so so so so that's why I don't want to leave this product rule and the quti rule otherwise I would have definitely skipped but these two important rules which I can't forget the reason why you all know is uh these are my favorites uh because it is e easy to teach okay so assume that's what I can say to you that's what I can say to you assume that you have two functions oh my God my hand is painting again I don't know what happened to my hand and what do you think I should uh take some break or what no let's not take break let's continue working on otherwise tomorrow I will die and uh no one knows what will happen uh so you have a two function f of x and G of X which are differentiable okay which are differentiable means it is we can take out the derivative of this we'll see when the function is differentiable and when the function is not in our later videos or you can search online for the same but say you have function which is differentiable and and now if you take now if the function are in this format so you have H ofx which is f f of x time G of X okay so you have like a product of kind of thing for example you have a function y x Cub time sin of x s of X so how how how you going to take out so this is your f of x this is your f of x and this is your G of X okay so how do you take out the derivative of this so derivative the derivative of this kind of function Dy by DX of a function f ofx g of X which will be nothing which will be equals to F ofx times okay the derivative the derivative of G of X of G of X okay of G of X Plus G of X time the derivative of f ofx of f ofx okay so so this this is how you do it first of all um you you you leave the first thing and then you multiply with the derivative of the second function then you plus it then the you leave the second thing you multiply the first one okay it get you can write in this way because just to make sure that you will be not be confused I can write in different different ways I can write in different different ways is first of all I can take this derivative and then this one okay so for example d d by DX f of x okay uh times G of X leaving the second function alone plus then leaving the first function alone times taking of the second function changing the position which does not matter at all okay because you will see it that I will do it because that's my way of doing this everything interchangeably coming to the next notation we can write this out let's assume let's assume if let assume let assume u b f ofx and uh V I think V yeah let's assume V be G ofx let's let's assume V be G ofx so you can also do this but you you'll just replace u u f f of x with u and G of X with v okay another notation which which which I'm going to write it out which is very very uh important F ofx times G Prime X the so this we can write the derivative in this way so this this can be written this way plus G of x * F Prime X okay so this is the quotient rule U which we which is the definition of a quotient Rule now let's see some of the examples so that this is pretty pretty pretty much clear to you every every every one of you so y = x Cub * sin of X sin of X okay so what is dy by DX it will be nothing but so you take this x Cube so so X CU * d by DX sin of X okay plus uh you leave the you now now what do you do you leave the second one as it is times you take out the derivative of the first function first okay first f of x which is X the derivative of x CU which will be something like this coming to now now uh X CU times the derivative of s of X remember remember the derivative of s of X which is what equals to cosine of x cosine of x plus now you leave the S of X as it is times the derivative of x Cub so you bring three in the front of it x² okay now it will pretty much everything is clear everything will be clear which will be nothing but X Cub cosine X Plus sin of x uh okay so you can do something like this maybe bit more cleaner 3x² sin of X okay so this is the derivative this this is the derivative of your function okay so let me just make it a little bit more transparent so that everyone is AAL to so this is a derivative and this is the product rule from which we have achieved let's take another simple example so that uh it would very very very much clear to everyone uh 6 x² + 7 x CU so what is the derivative of this function Dy by DX so first of all you take out the first one and leave the second one so 6x^2 Prime okay so this Prime I'm saying this the derivative of this function 6 S Plus okay let's let's multiply we have to multiply 7 x Cub plus now you take the second second one prime uh times you leave out the first one and then when you when you do this uh you just simp 6 * 2x² which is nothing but uh 2x which is 12x uh * 7 X3 7 X3 okay * 7 X3 uh now you simply you can simplify further it and then you can do it and now you take out the Dera derivative of this and then you can simplify it further on which is very very easy for you at least okay uh try to do with and answer answer me in the comment box coming to the this this was a product rule now let's talk about another rule which is the I rule which is the quotient rule where you may you may have already been guessed your functions are being divided okay so let's do this let's let's let's let's do this so let's say you have uh you want to take out the derivative of a function like y = to sin of x / X to power 4 so how you how you're going to take up so we have something called as the uh uh quotient rule the quotient uh rule which which you can use to take out the derivative of these kind of function uh d by DX uh let me write the formal definition first because I do believe in formal definition so let's write a formal definition and then we'll come up with then then we'll Sol solve this example okay so what you will do uh so the derivative of this the quent rule state some something like this G of x time F Prime x f Prime x minus you leave the now you leave the f of x now you simply multiply with uh G Prime X okay and then divide it with GX s GX s okay leave G of X multiply with the derivative of f ofx minus f of x leave f of x and then multiply the derivative of G of X and then multiply with G of x² okay sorry divide by G ofx Square okay and this is the your quotient rule we can write it in this way format as well G of x * the derivative of um f ofx okay minus F ofx time Dy by d uh GX okay so you and then divided by G x² okay now you now you now using this you can take out the the the the the the the the the the derivative okay uh of these kind of functions so now now let's do one of one of the example now let's do one of one of the example let's do one of one of the example uh which is d by DX okay you going to take out of sin of X over X x the^ 4 okay so how you will do it how will you do it so uh first of all this is your F ofx and this is your G of X which is first of all you take out F ofx sin of X derivative of this times leave x ^ 4 minus uh s of X leave that times take out the derivative of this okay divided by x^ 4² great okay uh now what do you do the co the that the derivative that you all remember cosine of x time uh x ^ 4 sin of X so times the it is nothing but uh 4X ^ 3 okay and divided by x ^ 8 you keep doing this now let's simplify it bit a little little bit x to the power 4 cine of xus uh 4 x CU sin of x / x ^ 8 okay now you just keep on doing this H keep take as a factor x^ 3 okay and then x cosine of x for this minus uh 4 sin of X okay and take that as X to the^ 8 now you can simply use the EXP exponents you can simply uh use uh you can simply minus it out okay you can simply minus it out so it will be left with X cine of x 4 sin of X okay uh when you X which is will be which will be x^ 5 okay this is X and this is your final derivative after after you simplify everything this is your derivative either you can go with this but I suggest some simplify as much as you can so at least it is doable just just you can put in the values of X and then you are done okay so we are we are done with this quent rule as well as we are we are done with this period rule okay I hope that this is pretty much clear to everyone if you have any problem any doubt you can ask in our Discord server uh or you can see the student manual if if you don't know how to enroll in LMS just to update uh let me write in enroll in LMS so just enroll enroll in LMS everything is Free Your da support is free everything is free so you can go there enroll there and I hope that you will take this opportunity to uh learn deep learning from a scratch and learn as as compr as as comprehensive as you can okay so thanks for seeing this video I'll be catching up your next video talking about the chain Rule and implicit differentiation till then byebye have a great thing hey everyone in this lecture we are going to talk about chain rule of differentiation we'll try to know about more about it and it is very very very very very used in deep learning or whether we learn back propagation we'll we'll be we'll be using this this rule which is a chain rule to take out the derivative when we back propagate okay so I ask you to pay a special attention at this rule so basically so this rule tells if you have if you want to take the derivative of a function okay so let's assume Dy by DX it's nothing but the derivative the derivative derivative of inner function leaving the outside function and the derivative of the inside function okay so derivative of the outside function leaving the inside function time times the derivative of inside function but but it I know it does not make any sense to you so let's talk about uh uh wait wait for a second let me just delete it out so let's let's let's let's take one example and then we'll formulate this definition then we'll formulate this definition of chain R so the example States the example States let's say you have uh y = 3x + 1 to the^ 7 okay so this is your function this is your function which you want to take out the derivative so you can actually use a power rule and then you can use a lot of rules available but um it it will be very uh hectic for you to do it so we have a chain rule of differentiation which will help you to do this so what is the derivative of this function so Dy by DX or Dy by DX so using the chain rule what what we do first of all let's use the power rule okay so let's use the uh let's use the power rule to just make that seven into the front of 7 so what we are doing is taking out the derivative of the outside of function so the derivative of outside of a function okay we we are not touching inner one this is our inner one so we are taking the derivative of the outer one okay so outer one is some value okay seven so what we will do derivative of this will be we bring seven into the front of it whatever will be and this will be 6 7 1 using the power rule okay so leaving the inside function as it is leaving the inside function as it is and then using the power rule we have bring the seven over here and subtract one from there and this is the derivative of the outside function derivative derivative of outside function okay derivative of outside function okay and out outside function was uh we have some value and just to the power 7 okay that's the derivative now the time the derivative of inside function times the derivative of inside functions so what is the derivative of over here 3x the derivative of 3x will be what will be 3 plus we'll use a sum Rule and derivative of constant is simply zero so that will be 3 okay so the derivative will be U 7 * 3 21 3x + 1 to the^ 6 and this is the D derivative of your function which is this 3x + 1 the^ 7 again I'm recapitulating so that it could make more sense to you okay uh let's take an example another example let's say you have G of X which is nothing but um let's say 2x plus maybe 4 okay and we are squaring this up we are squaring this up so um so so now let's try to solve it so first of all what we what we will do we'll take out the derivative of the outside of function the derivative outside of function which will be you bring two in the front of it two leave this as it is subtract one from there add one that's fair enough times we have taken our derivative now we times 2x + 4 constant this is this is a constant so we this is a zero the derivative of this will be zero and this will be two okay time 2 so it will be 4 2x + 4 is the derivative of this function G of X okay so this is what the chain rule says now let's take another now let's take another example so that it could make more and more sense to you otherwise it would be very U hectic for you at least so let me take let me just remove it out let me take another example um so another another example is uh let's say you have f ofx X okay which is equals to sin 3 okay uh 5 x² 4x so what is the derivative of this function so the derivative of this function we can write in this way so the derivative of the function will be sin 5x^2 4x we can write in this way as well okay so we can write in this way okay because you all know that trigonometry is not just on this uh so it will be three over here now we can go ahead and taking out the outer derivative we can take out we can go ahead and take out the U out outside of this function so outside of the function will be so outside of a function will be uh this will be three we bring three in the front of it we bring three in the front of it s f of x² 4X the same inside we leave inside one okay subtract 3 from two as a power rule states times the derivative of inside of a function derivative of insert inside of a function so the derivative of of inside of function sin 5x² 4x okay take out the derivative of inside of a function okay so I hope that this is pretty much clear as of now now you can go ahead and take out the derivative of this inside of a function and you will be good to go okay and you will be good to go you just take out the derivative and this is your homework you all know how to take out so just try to take out and please give me in the comment box okay now another example you can just take out the derivative as s um is cosine you can actually use the product rule which you all know so go ahead and try it out coming to coming to the next example is let's say you have uh let's say you have um let's let me take another example you have a k of X or G of X let's say you have a function G of X where you have a function sine x² 3x so what you will do first for first thing is take out the derivative of outside of a function so the outside of function so the that is nothing but there is a sign of something okay so you then when when we take out the derivative outside of function so what is the derivative of a sign we have studied the cosine okay and leaving the inside as it is times the derivative of inside of a function okay so the x² the derivative x² is 2x 3 okay so the derivative so the derivative will be what the derivative will be cosine of x² 3x x * 2x 3 is the derivative uh G derivative of a function G of X okay so I hope that chain rule is giving you some of the definition or some of the uh some of the way to think about it how this and this works as you as you see these are composite functions okay so so that's why CH this chain rule works you can see online why this chain chain rule works because it is important to know about that another example which I want to put in front of you is here I I want you to work in this in this example you have H of X which is equal to X2 + 5x 5x 6 to the^ 9 so what you do you bring 9 into so first of all you take out the derivative outer of a function that will be 8 x^2 + 5x 6 to the power uh sorry this is 9 this is 8 okay uh now times the derivative of inside of a function so the derivative of inside of a function be 2x + 5 okay that is 2X and five and this constant is zero okay so 9 X2 + 5x 6 ^ 8 and 2x + 5 is the derivative of H ofx okay so now I hope that is pretty much clear so let's write write the formal definition let's write the formal definition let's write the formal definition of chain R so let's say you have a function if you have a function okay which is f g of X which is just like composite function okay and it is a comp composite function then then the derivative of y of of a function will be uh the derivative of will will be first of all we take out the derivative out Outer side okay okay I'm noting this is f Prime Times the derivative times the derivative of the inside of a function G Prime X okay so we are taking the derivative of outside of a function leaving the inside as it is multiplied by the derivative of inside of a function okay so over here this is of derivative derivative of outside leaving the inside and this is the derivative of inside of function okay inside of a function so we can we can we can write on different notation so let's WR let's write it out in different notation so the different notation will be let's say if if uh Y is equals to the F of U okay and U is equal to G of X so basically it is just saying F of of G of X okay so U is equals to this now we can write that out into the other formal notation which you mostly see which is not nothing but just wait wait wait for a second let me just drag it over here the derivative of function this Dy by DX will be Dy by du okay so so first of all take taking out the Dera of a function okay times du by DX okay so first of all taking out the outsider then taking out The Insider okay so this is what the formal definition States so I hope that that this is pretty pretty much clear with a lot of examples which you did now coming to the uh chain rule can be used with different different rules okay chain rule with product rule quent rule so that's why chain rule makes it easy to for for for for you to work on so let's let's go let's go ahead okay let's go ahead and and do one uh example which is example uh 4x² okay s of xq so in this example we'll make use a product rule product rule and chain rule to take out the derivative to chain rule take out the D derivative so just have to remind about the product rule if you to take out the derivative of the two functions which is being multiplied this one and this one okay when when when two functions being multiplied okay so which is f ofx f ofx time G of X so that will be the derivative will be first of all we take we we leave the first function as it is times the derivative of the second function which which is G of X plus the derivative of the first function the derivative of the first function times the leaving the second function as it is so this is the product rule which we have started now coming to this what if we let's let's name this function as F ofx now we want to take out the derivative of it so the derivative of it will be 5 Prime X which will be nothing but U first of all we'll by by going we can we can have this as a first and we can have this as a second so it does not it matter order does not matter first of all let's take out the derivative of the F ofx so let's assume that this is the G of X and this is your f of x okay so let's let's let's take out the 4X s okay so the derivative uh 4X s okay take out times leaving the leaving the other function as it is leaving the other function as it is okay plus taking all the derivative taking all the derivative so multiplying F ofx first of all 4x2 times uh the derivative s of X Cub okay derivative of the SEC second function okay uh second function now now let's let's take out the derivative so after we take out the derivative which will be nothing but 8 x sin xq so when we multiply so that derivative will be 8X and when we multiply with this so 8X sin x Cub plus now over here which which will get as uh the derivative of s of something is cosine of something but before that over here which you're seeing there is some chance of chain rule there is a some chance of chain rule which in this case which are seeing we'll use the chain rule in this case because we have outer function and we have an inner function and we're a bit confused because we are not seeing any power we we can't do easily with the power rule on anything okay so we'll leave 4X squ times what is the derivative of outside of function so we have a sign of something we have a sign of something so this is outside of function so what is the D derivative of outside of function which would be cosine leaving the inside function times the in the the derivative of inside function the X cube is 3x okay and we and using the chain rule we got the derivative now you're good to go now the derivative is which of this function 8X let me just use a different color so which will be 8X sin x Cub okay + 12 x to the^ 4 cosine of x when you simplify it you will be getting this x to the power 3 okay and this is your derivative of a function so use product rule and then in one of one of the functions or one of the part we use the chain rule to differentiate nice so we are we we are good to go with u chain rule of different differentiation and I hope that you uh that you got got to know about it much better and I hope you will be uh remembering these stuffs now let's talk about logarithmic differentiation the last thing which I'm talk about is logarithmic differentiation using logarithms you will be easily able to take out the uh to differentiate okay and and these are used to quickly take out the derivatives okay so the last thing which will talk about is logarithmic logarithmic logarithmic differentation okay so we want to take out the logarithmic differentiation now coming to this you have a function f ofx which will be equals to uh let's this this is this is the question we have to take out so X Cub 5 3x^ 4 + 10 4 x 2 1 2x ^ 5 5 x 2 10 we want to take out the derivative of this function and you may be thinking here you oh my God what the hell this is and you'll be also in oh like oh my God how how I'm going to approach this problem so let me tell you this is very very easy problem but uh we will use something called logarithms to solve this so what we are going to do now is to take out the logarithm we just take out the logarithm on both the side okay so take out the log logarithm logarithm of f ofx equals to logarithm just the same thing okay so let me just um snap it out how I'm going to snap it out no no no wait wait wait let me just do it for me at least so that I could not add to the current page over here okay so you take out the logarithm so you take out the logarithm both the sides so oh my God I think it's I have done wrong yeah so now you take out the logarithm of above the side now coming to this now coming to this now what you do you know the property of a logarithm if if you have a lot of fun um in this you you you know all the property of logarithm uh which will be logarithm of X Cube to the individual U terms inside it and to individual uh these things okay so times uh * logarithm 3x ^ 4 + 10 * logarithm 4X 2 1 * logarithm 2x 5 5x 10 okay now now when we uh when you you all know the when how when we take out the uh the the when we take out the derivative of a logarithm and you all have studied because I've already talked about this it it is nothing but when when you take out it it will be nothing but uh 1 by F ofx times F Prime X okay so we we can write it out F Prime X over f of x at this side and all and in this side what you do you simply one over 1 / x ^ 3 5 * * the derivative X x3 5 derivative so it will be nothing but 3x 2 3x 2 by x3 5 x3 5 okay now times do the same thing with this with when then we'll get 12 x CU 12 x Cub by 3x 4 3x^ 4 + 10 * uh 8X so it will be 8X by 4x^2 1 so you can recheck how how we got it it's simply 1 / 4X 2 1 * 4X 2 1 derivative so 8 there will be 8X and this is zero so that is 8x by so times uh the last one which will be 10 x ^ 4 10 x and we can write it out below things 2x the power 5 5 + uh sorry 10 okay so this is what you got when you take out the when you just take out the derivative of the natural logarithm okay basically uh you when you when you when when when you take out the derivative of a natural logarithm you will do something like this okay and it should be plus when you when you go ahead uh when you take out the natural logorithm of uh of the this this is a property you it will be becoming plus okay will becoming plus now then you differentiate it and then you get it now at last now at last let me just go ahead or let me just keep working on it now you will get F Prime X which is equals to the step number four which is equals to what you will do what you will do uh you will use something called as uh we we'll simply multiply with the logarithm and the actual thing this one okay and this one Whatever the differentiate we got it okay so that will be nothing but first of all we write whatever we got after taking the derivative of our logarithm six this one + 12 x Cub / 3x^ 4 + 10 + 8 x by 14 x 2 1 + 10 x^ 4 10 x / 2x^ 5 5 x^ 2 10 times big times the question x x ^ 3 5 3x^ 4 + 10 4 x^ 2 1 2X to^ 5 fx^ 2 10 and this is the your derivative of your large functions function which you saw over here and you may think yeah use this is this this is also a long process I agree this is a long process but if you go and solve with other process I assure you you will be getting you can use product rule to solve it but it will be very this is the very easy to solve this particular Problem by logarithmic difference iation so we talked about chain Rule and the most important thing was chain rule if if you haven't understood the logarithmic you can safely ignore this okay so I hope that you got the problem and I'll be catching up the next video with the introduction to integration and then we'll start off with probability and statistics thanks for watching this video I'll be catching up in next video till then byebye hey everyone from this lecture we are going to start off with deep learning we'll talk about we'll start off our journey with actual deep learning which you all are uh w from lots of time and I just want to make a disclaimer is I assume you that you have already covered the previous videos and some videos of probability uh which is not yet uploaded which will be uploaded in coming days but I assure that whatever the videos is uploaded like mathematical prerequisite please be sure that you complete those lectures first you can was in watch that in 2x lectures because all the things which you will study will heavily depend on the previous one okay so so please make sure that you have a better understanding of mathematical intuitions which I already taught if you faced any problem just join our Discord server we'll get or maybe we can get on a live with some Tas you can just discuss that and make your doubt clear and you can simply ask at M our Discord server which will be in the description box uh the link will be in the description box okay so uh what is deep learning so we'll try to answer in this lecture um so first of all I'll try to answer what is machine learning machine learning is an artificial intelligence domain where we extract patterns from the data and analyze the data and make intelligent predictions on the new data according to the pattern which we has already learned or our machine has already learned okay so we have a function f that that takes some input values and that map that input values to an output variable y okay so I'm talking about in the context of supervised learning so basically so basically you have a function f that that takes the input value X and that Maps the input value to Y so you want to construct a function so what so you learn a function f that that ex that extract parents from the data that extract parents from the data or loan learn from the data and analyze the data and make intelligent predictions so we can give X to this input value it will give us y variable for for for for for getting the desired y variable we do need a a very good function which actually does that specific job so exactly what machine learning tries to do is to make a function f that Maps the input value x to the output value y if you haven't already familiar with machine learning I'll ask you to take an introduction video or introdu int int introductory course of machine learning maybe you can go to ml1 or you can go to some other machine learning course but I highly S Suggest mll1 is the best course for you to consider at this point cool so um so you you got to know about the definition but there are different machine learning algorithms so you may ask that how you how we are going to extract patterns from the data and how we analyze the data so that is the first question which may come in your mind how we extract the patterns from the data and how we make intelligent predictions or how we do how do we analyze the data okay so so for making intelligent predictions first of all you need to extract patterns from the data so how are you going going to extract patterns from the data which we'll see uh in a review of machine learning in the course but there are different set of algorithms which will help you to extract patterns from the data or analyze the data some of the examples are logistic regression logistic regression logistic regression we have linear regression we have linear regression and I'm preparing I think a four to five hours of lecture four to five hours of lecture on linear regression is the mainly video titled as multivariate analysis you can go on New Era YouTube channel you can go on newa YouTube channel to maybe it will be uploaded till the end so maybe you can just go there you'll be seeing a title multivariate and regression analysis I have taught linear version in great detail there cool so uh so back to our topic so there are different set of algorithms which will help you to extract patterns from the data say for example legis ression and logistic regression is a classification algorithm classification algorithm we can use for classification tasks classification tasks and linear regression is a regression is a regression algorithm which will help you to perform regression tasks and many people just think about linear version is very simple algorithm uh it does not perform well but but but you but just go in statistics uh term and then you will see the power of linear regression mainly people forget to write to use Lear regression in a right way so you can watch the multivariate regression analysis which will be uploaded soon so um n base which is another yet powerful classification learning algorithm which can be used to predict whether an email is a spam or ham so using nbase you can construct a function f that takes an email that takes a email and classify that as a Spam or not non spam or non spam and let's denote spam with zero and let's denote non spam with one okay so you want to learn a function f that takes the input value X and that Maps either zero and one or or in other words we can say y be the member of zero and one okay so there is n base cool so the performance of these simple algorithms heavily depends on the representation of the data which you have okay you should have a good data to for your machine learning algorithm to form to perform well if you have a bad data your machine learning algorithm will not perform well but this ex this extract or this this this paragraph is taken from book written by Deep learning uh by Ian Goodfellow um I I only know the one one one auor name and others are I think U um I I don't know exact name but but y yosua Benjo so so you can just go there and see the book by Yan Goodfellow so this is an extract from that book and what is it indicates the performance of these simple algorithms depends heavily on the representation of the data which you have the representation of the data which you have or which you're given say for an example you're using linear regression to predict the house prices okay so so basically what exactly is trying to tell uh you you're using using Lear ression um to predict the house of the prizes so on time of prediction say uh so you train an algorithm you train an algorithm which takes size and as an input okay and uh and number of a fans of a house number of a fans of a house and then using these two features it predict your y variable y variable okay so this is how you train a function f that takes size and number of fans and then give you the pricee of the house so basically basically it is saying that you are using linear R to predict the house prices so now you trained it using these two features now when the time of prediction came user have to provide one size and the number of a fans okay so in let's take a bedroom ra rather than fans so number of bedrooms to make predictions okay but when you give number of a fans and then ask your model to predict the price your model will not be able to predict do you do you do you know the reason why it's very simple because you have trained your model on the size on two feature on based on two features and the number of a bedrooms and then you getting price what if if you give only the fans you'll be not able to predict it isn't it so that's the major problem of representation that that that that these performance of these machine learning algorithms depends heavily on the representation of the data which you have given and these are features so size is also a feature number of a fans is also a feature number of a bedrooms is also a feature so I hope that this is clear we'll we'll come to that we'll we are coming to definition of uh uh what machine learning sorry deep learning cool so the problem of feature representation so as I've taken one example to start the to start with a problem of feature representation or feature uh uh uh learning so we will talk about that AI task can be solved if we have right set of features and make a mapping from feature to desired output so all the AI tasks which is available today okay so say say say for an example that you wanted to predict the price of the house okay want to predict the price of the house you want to predict the price of the house so so so for for predict in this you should have the right set of features for this to get to particular uh answer so you want to learn a function f okay that correctly maps from some feature X1 X2 all the way around to the xn given these n features it predicts your y variable and these n features should be right set of features should be right set of feat if you have bad set of features where our AI model will not not able to perform very well okay so we do want the right sort of features so that uh we can train our model on these rights of features and then get the desired output one of example which I want to represent to the real world example say for example that you're learning some science concept where you have feature of the particular thing so uh say for an example I'll take a simple example so that uh it would be very easy um let's take a example in in real world concept um car okay so a car and what are the features of it what what what are the features of it so the features of it can be it should have four wheels it should have four wheels um it should be not too much big it it we have we have steering we have a steering we have seat belts you have seat belts so these are some of the features we used to identify cars okay and they they they come in different different color so there are a set of features we need a right set of features to uh to understand that is a car and how do we learn it uh how do we learn it say for an example that uh these seats and then fourwheel steering these are the right set of features that we that we used to identify whether that's a car or not okay so that's how a baby learns it identifies some set of Fe features okay uh my my my my father is telling that okay it is the steering So based on that I will identify okay that's a car because I've identified some of the features of that because I've identified some of the features of that uh one of one of the main main thing which I want to highlight is identifying the the brand of a car okay brand of a car identifying the brand of car that's that's a very very that's that that I face in real world is for every car we have identified feature okay say when I when I when when I see a car I'll take a look at logo of that in in front of the car so in front of that there is a logo and if it is logo in something like this then it's Audi okay then it's AA then it's AA because of this logo I'm able to identify what's the because of this feature mainly the logo we let's this because of this feat feature I'm able to identify okay that's a car so this is the right or unique set of feature that this car have so so for example so when you can train your model okay so you need right set of features okay um so so your model is able to identify that I hope that this this give you pretty much lot of sense to you at least okay say for example you want to detect the cat in in an image so you want to build a model that given a image eye that will detect whether that is a cat or noncat okay so a cat can have can have different set of features so you can hand design right set of features by yourself like you can design you can just the the values are in pixel format the values are are in pixel format okay the the picture so you can take the only the pixel which are of ears you can take only the pixel which are of ears so you can design the right sort of features like ears nose and which are very consuming time consuming task because for because you need to be very good at the the the at the background of that domain or or or or or you should have a good domain background for identifying the right sort of features because in this example it's very easy car image but what if uh in real world you don't have a problem like this you do have a problem like this but but like weave detection um like in weather you you should have a great background inside that so you should write you should design right set of features and that will be very timec consuming task and getting the right set of features for your model is very very challenging in today's era for many tasks around us okay say for an example um like uh wave detection or or whatever um that we should we we don't know uh what are the right sort of features we we think okay every every feature is the right right set of feature but getting the right set of features in today's era for many task is also very challenging okay so so what so so to in using machine learning using machine learning what we are able to do what we are able to do we are hand designing the rights or features we are hand designing the rights or features so we get an input we get an input we get an input and then we hand designed right s of features so this is a car so we we taken out the pixel of maybe wheels for that image and then we we taken our right s of features like Wheels steering logo okay so there are some sort of features we hand designed by ourself by programming and whatever and then we train a machine learning algorithm on these pixels or whatever on this whatever our features which we' have extracted let X1 X2 all the way around to the xn okay we train a Model F let's let's put in a giant X okay and then we give this set X and then we train our F maybe it can be uh classification algorithms like legis regression it takes the value of x and then classify that either a car or a not car okay so in machine learning what you're doing is you're hand designing the right set of features by yourself because when you see your machine learning data data which you have you're given the in several input values several input values 1 2 3 4 5 okay and you are given the the target label and these these Fe features are hand designed these features are hand designed okay so this is how uh this is what today's uh today's machine learning is able to do is it also require feature extraction it also required to extract features from the data by human human human human will do it human will Design right of features so this is what the problem which we have is the is hand designing the rights s of features which are very challenging and is very time consuming task for Designing the right right set of features so so what is the solution to the pro problem the one solution to this problem is making machine learning not only learn the mapping from features to Target labels also learn the representation to y okay so basically we are asking our computers to not only learn this classification stuff not only make a model given the set of features given the set of features also learn features by itself okay so given a car given a car learn feature EXT extract feature automatically and make a model on the feature which you extracted Okay so say for example uh in machine learning you are hand designing set of features and then you're giving giving to the model whoever the right set of features is but in deep learning what what what exactly you were doing is given a car an image to your to to your system what it does first of all it extract features that's called feature extraction or feature learning or representation learning it extract right set of features and extract right set of features let's say Wheels let's say anything okay and based on extracted features it builds a classification model or whatever learning algorithm and then is able to classify so so there's a huge amount of time which is preserved and this actually perform very well in today's ERA with stateoftheart models which are doing very perfectly so what I again I'm going to repeat that one solution is to not only learn mappings from X to Y but also learn X's as well also learn the features of it as well okay of course you're going to going to give you give the input which is the car but but but in but for if we have to identify that problem that can be solved using deep learning or that problem that that can be solved using machine learning you have to identify that okay the model takes the raw data as input which is the image and perform feature extraction by learning the feature representation so it ex automatically extract the features and learn the parameters to perform the necessary task or to build a model f that maps from features the Learned features to Output but one thing which you will ask question that how do we go on performing feature extraction so how it performs and what is what these uh three three things means don't worry about it just just I will will briefly talk about in this future detail don't worry about anything just understand what exactly deep learning trying to solve okay so I think it's very very very very much clear here I just want to move forward cool so what is the definition of machine learning so this is a definition by the book again I'm saying this is by Ian goodfella yosua benju book and deep learning methods aim at learning feature hierarchies with features from higher level of features form by composition of lower level features and automatically learning features at multiple levels of distraction allowing a system to learn complex function mappings from the input to the output directly from the data without depending completely on human crafted features and learning deep architectures for AI and that and and I personally know that you are very confused with this statement so let's get ahead and make you understand that what the exactly definition trying to tell maybe you know about hierarchies okay the hierarch means like we have this hierarchy of a feature so you have different different feature different different levels so basically this is the this is in this level you are extracting some level of features some lbel of features you are extracting so that is visible layer that is the input pixel so you give this pixel this pixel this pixel this pixel this pixel so these are input level fixes which is given to your model which is the raw in raw raw input raw raw input and then the then it is passed don't worry about what is this what is this what this Arrow just assume whatever just one you understand what exactly I'm telling first the input which we give our which we give to our model or whatever algorithm is the pixel value is the pixel value is the pixel value okay um is the pixel value which which we given in which is visible to us now now the we we give to the second level we second layer which you usually call as a hidden layer but don't worry about it just just don't just just don't worry worry about it then we give to the next level which extract some patterns some feature like this some feature like this okay then we go then then we give to the next feature whatever the information contained whatever the information is G given to the next feature and then we learn some sort of features again then we extract extract from this image some set of features then again next next l level we extract some set of features we extract some set of features and then based on these learned features you're getting whether that person is a car with person or animal okay uh so basically what exactly you are doing is extracting features till this level you're extracting features and at last you're making a model here and then making prediction whether whether that is a car person or animal don't worry about it what exactly um what what exactly is trying to what what exactly these Arrow represent and how how are we making classification model just don't worry worry about that the only thing to worry about that you are understanding the right thing here the right thing is that you are learning features at different different levels and you are learning feature hierarchies with features from higher levels of the hierarchy so here you have you have some set of features learned and then the second and the third so have multiple levels where you're are learning different different features and because of this you're able to make complex functions we'll talk complex mapping from the pixels to the car person or animal okay you're here no human Loop is needed it is automatically creating it is automatically extracting his her uh glasses or whatever it is auto automatically no involvement no human crafted features at level one it extracted some sort of features at at level two extracted some some set of features at level one it extract edges okay mainly this edges edges level two extracted Corners mainly this one and Contour level three it extracted object Parts like this okay level level three so it is learning complex features now your model is able to make complex function of comp complex function f that takes the input image and then then powerfully making or making a very good prediction comparable to human U score or accuracy so I hope that that this is very clear on the definition of deep learning and and general idea what the what exactly deep learning trying to solve is learning feature hierarchies okay with features feature hierarchy from higher levels of the hierarchy formed by the composition of lower level of features so you're not involving any any human Loop just you're learning feature learning exactly what the Deep learning is trying to solve cool so um we we we we'll again precisely Define uh you will learn when when you will learn neural networks then you will understand what exactly de printing is but I hope so that that that that give you a better sense over here coming to the different applications there are thousands of applications which can be solved which are which are in production today which are using deep learning to solve the real world problem the first one is um op classification problem given an image classify that whether that image is of cat or a noncat so how does it helpful and maybe and when you go to the company you just show your face and that allows gate opens and then you go inside that's face recognition where it identifies whether you are that person or not okay uh classification plus localization to localize that where that object is for if for example it can be used in cell driving car which you're seeing in front front of you it it is able to localize the stuff uh so that it would make their own decision to where to go further and then we have art generation using from text so given a a beautiful woman it will generate the image of beautiful woman it can be possible I'll show you one demo today and then we have chat Bots uh chat Bots like AI coder uh AI Q&A system using gpt3 and then uh lots of things uh search recommendation system like Google is using San Francisco whatever is there um so I think these are some of the examples another examples are speech recognition task you can just make use of Alexa how are you and then it will give you the answer music generation using deep learning you can actually generate the music using deep learning and then brain tumor detection it is used also used in medical industry so these are some sort of applications which I highlighted for you at least to get to know much uh in in in much more detail so I hope that this is very clear now and now what I'm going to do now is to show you some of the cool application which I built as a project by myself so I hope that that will give you more sense to you so I'm just going to show it to you um the first one which I want to show to you is the chatbot which we had developed at Anton so let me just uh let me just make it little bit oh wait for a second I'll just make it 1080p so that it would be more precise for you to at least see that so you can see over here uh and chat which is which is able a Discord chatbot which is able to chat with me uh like uh which you can see no problem let's talk about something else and then I seriously haven't heard about this song we did it and this is an chat which you can of course opt for it you can just make you make that in your own Discord server if you have just email us we will uh my company has launched this product which is anat which uses gpt3 so this is one of one of the example of deep learning the another example is I just show you another example we have ancer which actually given program for taking the factorial it gives a Python program for that which you're seeing in front of you that it it it is able to solve any kind of programming question which you presenting in front of your screen and I I hope this is anodo which is again you can email us to get the access of it now coming to the next part is n Q&A q& is a system which you can see over here that we have n q you can just ask what is a circle and whatever it is able to answer your question and that is we even answering uh in machine learning tasks and I hope that this this is what the C assist says system we have developed and it is available for uh which you can email at Anon will be happily will'll be happily giving you in your own Discord server to make your uh server produ productive coming to the next project is Art generation using deep learning which is generated adversarial networks which we will do in this course uh using Gans and which you can see that how this is generating the image and this is the image which is generated by an this is on my own YouTube channel this is a image which is generated by uh peoples okay coming to this we have another another art which is generated which you can see over here uh using text to image and I really hope that it made a lot of sense to you you can just go at my YouTube channel and uh just sub subscribe this YouTube channel if you want and then uh go to playlist go to M2 and also also what I what I want to highlight is uh you can just uh have you can just enroll in LMS you can just go there and enroll in LMS by going to this Doc and uh then going to uh reading all the course and then assignments and a lot of lots of stuffs you can go there and uh enroll in your LMS which which I written over there you can enroll in your Neo LMS okay so you have so I hope that this is pretty much clear and I also hope that you have enjoyed this video If you haven't uh please leave a comment at how I can improve this uh these lectures uh otherwise uh I hope that this video give g g given a lot of intuition of behind deep learning I'll be catching up in next video till then byebye have a great day everyone welcome to this lecture we'll be finally starting off with introduction to neural networks uh so let's get started with this lecture um so uh first first of all we we will talk about biological neural network as it is very important um that how our neurons in our brain work so I'll try to relate the biological neural network with our neural networks specifically we'll talk about perceptron so in this particular lecture here's the outline of this lecture we'll start off with the biological neural network we will will get into the the the that how we can relate this to uh something called as perceptron on and then we'll go ahead talk about different things kind um activation functions and whole outline can be found on a course website as we had detailed uh sections and subsections provided there cool so uh let's start with biological neural network so here in front of you you're seeing is a neuron in a human brain so basically human nervous system contains which is something called as cells and you know cells are the basic unit of a life you have already studied in class so so so human nervous system contains cells called neurons and the neurons are connected to one another with the use of exons and the dendrites and the connecting regions between exons and dendrites are referred as synapsis so what exactly it is telling that you have a several neurons let's assume this as a specific neuron so you have a neuron and this is connected with another neuron another neuron okay with the help of Exon and dendrites and dendrites and these are the the reasons which connects the exons and the dentrites are called synapses but you may be thinking hey uh you are not in Biology class then why why you all are teaching this so I'll try to relate this with the particular stuff like this the the the keywords the dentes are the input terminal which takes the some input from other new neuron say say for an example you have a neuron over here so this is your particular neuron and this gives some input to the another neuron so they are connected to each other so this is a neuron which gives which which which gives an output which is connected to another neuron and this the output is taken the output of another neuron for for for for this particular neuron it it act as a input input terminal where takes the output of the previous neuron okay and so that's why we have a dendrite which is nothing called the input terminal okay the next thing is the Exxon which is the output wire which is the output wire so Exon terminal is an output wire so this so whatever it outputs the neurons whatever it outputs so what dite received from the neuron denr is called the input terminal and whatever it is outputed is from the Exon terminal because it's the it's the Exxon which is the output wire and which output something and Exon terminal are the output terminals which output something let's say let's say output something let's say this and this is again transferred and taken input from using the dendrite so again I'll Recaps youate this stuff as Dent rites are the input terminals the Exon is the output V and the Exon terminals are the output Terminals and this is a particular structure of a neuron this is a particular structure of a neuron so I hope that this this this gives you a better sense of um moment cool so we will not um want talk about this biological neuron we'll go ahead and talk about we'll try to relate this with artificial neural networks okay so so let's take an example uh you have a neuron which gets an input say for an example you're getting X1 you are getting X2 X3 X4 which is an input received in dendrites so you have a dendrite which is a dendrite terminal which is the input terminal so let's say you get four um inputs don't see this diagram as of now just only see this diagram and listen to what I'm saying so the information which then right receives is called X1 X2 X3 X4 okay so uh for for for for for this example you have X1 X2 X3 X4 which are the input which is received in D rights and the information the information X1 X2 X3 and X4 are weighted by some weights and W1 W2 W W3 and W4 and it determines the effect of your input so uh say for example X1 how much this effect of an input in this neuron on okay so we'll take a specific example say say for an example you saw something okay so you you have a human eye so just and you saw something like um like a dog like a dog okay so you saw different different thing like its eyes it's eyes let's let's assume this eyes is X1 its ears X2 it's tail X3 and its legs X4 so all these in your mind all these contain some weights let's say example that you saw that you are quite familiar with the mouth or the eyes of the dog to be similar so let's take W1 X1 okay so this input how much weight it contains how much effect to so because you want to identify that dog so that's why you want to identify how your your your maybe mind knows how much effect your eyes there okay so eyes of a dog how much effect does that ear of a dog effects uh on for for for for you so that you are a successfully able to classify that as a dog okay so so most important thing say for example it's its tail may be having the the biggest weight because by seeing the tail you're able to identify whether it is a Dober man or anything so tail would be the containing the highest weight so the whole whole whole phen or whole thing of weight is that that the W1 W2 W3 it contains the information is weighted we give some weights to every information whatever we get in the D right so that we'll be able to identify the effect of each input in your dendrite okay so basically in in an in an overview it determines the effects of the input so W1 X1 so what we do we simply multiply with the input so all X X1 has has has its respective weight say for example X1 X2 and X4 so we have four features we have four features and let's say that X1 is more important in I in doing that task so X1 is weighted more W1 W3 W4 and W5 let's say X1 is important so its weight will be high because it is weighted and this X1 has the the most important effect of the input okay so we'll come to that weight or uh a ton of time the whole deep deep learning is based on that getting good weight so we'll talk about that okay just assume that you have any weights we don't we still don't know how do we get the actual weights we still don't know about the formal definition I'm just defining it informally so the weighted information now what you do you multiply the weights with the inputs so you can determine the the effect of the input uh using that weights okay so the weighted information are aggregated in the nucleus so basically this is a nucleus which is nothing but the PowerHouse okay so it's aggregated in the nucleus as a weighted sum as a weighted sum as a weighted weighted sum as a weighted sum so what you specifically do you simply um multiply the weights with the respective inputs and add it up okay um so W1 X1 plus W2 X2 + W3 X3 + W3 * X3 + W4 X4 okay simply add it that's it that's what what what what you do you simply aggregate in it in a sum variable or a nucleus let's call it as a z okay that's a nucleus that's a nucleus where you aggregate all the information at one point plus you add some biom okay let's let's let's add some bium let's add some bium and don't do uh that is a bias which we will have a detailed talk uh in this uh section please don't worry about that we'll have a detailed talk on that just you can ignore this or assume some constant like 0.1 okay don't worry about that what W1 how how how we'll choose W1 we'll see in the whole section ction then what then what we do so here we came to a nucleus and nucleus perform one action to it so this now nucleus now this is down here you apply the the the what do you say the nonlinear function the nonlinear function so on Z so you so you on Z you applied some kind of uh some kind of function don't worry what that function do okay just just just assume that we apply some kind of function may maybe you have already seen something called as sigmoid function I'm just taking an example of a Sig word function there's a lot of functions which which we apply which we'll formally Define in this section don't worry about that the only thing which you need to worry is to understand the whole process of uh neural networks and I'm just trying to for informally Define the neural networks with the help of your neuron so so where we are we have set of inputs which we got from a d right then carrying these input carry carries the the the weights or the or the or the information is carried by the weight okay weighted by the weights which is W1 all the way to W4 why all the W4 because we have four inputs which we got okay it determines the effect of each input by taking or or the product between their respective um inputs and then what we do and then we reach to the nucleus where all the information is aggregated by taking a sum where we add one bias term we'll talk about it l later on what exactly that bias term do okay and then and then after after a aggregation now some processing applies like nonlinear function which is a sigma function in this case maybe if you know about it if if you know about legis ression then you might be knowing that and then it is further sent and then it is further sent for further processing to Exon y okay so it is further sent to another now we got our output which is some non non on some function on Z and then we get our output y okay and then it is sent to as a input to another neuron as an input to another neuron or we get a final output or we reach to the destination what we wanted to reach so what does it mean it reaches to destination so let's take an example you saw something you saw a dog okay you saw a dog and here the the information uh let's say you want to identify whether whether that dog is a is a German shepher or a doberman okay Doberman pure so specifically what you will do you all know that a German shefer has a long long long hair and kind of wolfy um nature kind of stuff and Dober man is very uh thin and have a and don't don't don't have a long tail as well as they are very um they very strength and kind of stuff you have a specific mind in your uh your specific picture in your mind so when you see Doberman or when when you see a dog you need to and that dog is either German shepher or dman pin okay so here is a dog that dog is either German Shepherd so how how your mind will work and I'm just taking an example of it so what happens is you see his hair you see his tail so all the information get into your into your eyes and through eyes you get into into your mind through eyes it gets into your mind and all the things like hair Dober Manel these are your input these are your input hair tail ear eyes these are your input and over here the that's a hair is carried by some weights carried by some weights all the weights so that we can understand the effect of our inputs so say for an example that uh the your hair has the the the weight of a hair because in your mind in in at least in my mind I I'll I'll I'll be having more influence of hairs so w one here will be very large okay so I'll be able to identify that and then what and then what happens after after we aggregate the information we simply aggregate this information in a nucleus so every feature is very important so you aggate the information as a nucleus and then you apply a nonlinearity or some some kind of function don't worry about what is non nonlinear Etc what what this function does just simply we apply some kind of function or some kind of processing and then we reach to the T destination whether that dog is a doberman PTI or German Shepherd okay so or or maybe that output whatever whatever output we get after applying that function it it will be sent to another neuron so that we so maybe if required I don't know about much more about brain cool but is this exactly happens in our maybe um um a specific neuron it's it's kind of no absolutely no is just an inspiration from a neuron it's not like that how these kind of exact maths is being calculated it's not that it's just an inspiration so that like his scientists previously just take an inspiration of it and made a mathematical Morel out of it okay so do not relate it to exactly how neuron works you can see other videos on how neuron and how brain works but but specifically this is taken for inspiration for this kind of uh statements that I've described up Okay cool so I hope that this gives you a better sense about how everything works let's go ahead um over here the pictorial representation of a workflow so exactly this is the artificial neural networks so this is in mathematical model this is whatever you're seeing is not a real neural network or or or a brain is just an artificial neural networks where we have we will talk about what is neural what is networks later on but this is a pictorial representation of what our workflow States so just recapitulate you you have a set of inputs you have a set of inputs X1 X2 X3 all the way around to the X4 okay and all these inputs are carried by or all all the information is carried by the weights which we denote with the W1 W2 W3 W4 and a biased term okay and um and these weights determine the effect of your input and this is a nucleus this is a nucleus where all the information is aggregated by taking out the sum of and this is this is the summation notation uh W1 X1 + W2 X2 + W3 X3 + w4x 4 and then we had the bias term and then in that and then let's assume that this is the nucleus and then we apply and in nucleus we apply some kind of a function on it so let's say Sigma on Z okay and then we get some output Y and then it it it is either your destination it is either your destination which you want to achieve or or it is or it is sent to another another neuron the same neuron like this where it have where it again multiply without which which will'll see later on okay cool so I hope that this gives you a very specific sense about artificial neural networks and I hope that uh you'll you'll you are able to understand how how exactly it is working so now what I will do I'll just just make a remark that neural networks whatever artificial neural network which you see is called exactly this is what artificial neural network is okay so neural network basic units is inspired from machine learning and machine learning is obviously spy from a brain and stuff so so here which you're seeing if if I know this the course prerequisite is machine learning fundamentals I either recommend in my mll1 course or anything but you're exactly seeing that this logistic regression or or or whatever we have studied is exactly logistic ression if you see okay so basically uh this is the one unit so this is what you what you're seeing this is a logistic regression what do you do you simply multiply with the given weights and the inputs and then we agre create it and then we and then we apply a nonlinearity or the sigmo function which you usually know 1 / 1 + e to the^ minus g z and then you will get some output let's say a and then if a is greater than 0.5 you identify okay that that value um uh let's uh one or if it is or else if it is smaller than or equals to 0.5 then zero okay then zero so this is this is usually used for classification problems and why do we apply this sigmod function we'll talk about in detail in this deep learning we'll talk about this Sigma function in very detail but what this sigment function tells you um so what it does it you you get your output you get your output in a range in a continuous manner okay so it simply squeezes that output into bit between 0 to one between 0 to one now this was your basic unit which you already seen in machine learning what do you do you put take that basic points and you put several units and stack them up okay and take that stacked layer and make several layers okay so so you this is a particular unit which is exactly what exactly computation is doing is simply multiplying with different different weights and then applying processing Etc and putting up different different basic units and then at last with that kind of stack or basic units are able to generate predictions so this is the Deep neural so we will talk about that later on but the basic idea that this slides want to give you that neuron networks are inspired from basic units of machine learning or puts up puts up lots of basic unit together and then get your output but don't worry what this exactly diagram States forget about it about it if you don't understand okay please rewatch the video if you don't understand otherwise uh you can simply ignore what what exactly each neuron is doing will will cover that in detail in a multi neural network uh or perceptron section cool so the perceptron now what we'll do is formally Define a perceptron so that it would very helpful for you at least so let's take an example so now we will formally Define the perceptron so um here you can see the simplest neural network is referred as the perceptron as the perceptron where uh where we have the basic which is the simplest neural network which we which we refer as a perceptron so what we are given we are given the information from X1 to X dimensional okay so I'll take an example I'll take a simple example because I just want to may have a conversation with you so that at least you can understand everything and please make sure that you watch in kind of a 2X manner it's okay for you I do I I don't care about that so uh let's take an example of a diabet or maybe huh yeah so diabetes predictions system diabetes predictions I'll just take a different pen so that at least it gives me good a feeling so uh what's your favorite color I don't know it's blue so diabetes prediction system diabetes prediction system so in machine learning you're given set of features and you're told to take that set of features and map to or make a fun F that takes a particular set of features and maps to an output variable y that's it that's that's exactly what in machine learning you're trying to do so these so let's say your X1 denote U maybe some kind of a um let's say the BP okay and X2 denotes BMI okay X3 denotes your age X4 denotes your maybe um uh symptoms which have a certain SE or the height okay X4 Den notes your Heights so these are your information these are your information okay and these information are carried by the weights are are these information are weighted by weights that how much this how much this have effect or or or or how much um uh how much how how how much our input effects okay so or how much our information carries information okay W3 and W4 so w 1 W3 W4 okay so you have a respective weights which tells you how much it affects okay how much how much your information have weights or how much how much weightage or how much information it has Okay cool so what I will do I'll just have my X and uh this is X1 X2 all the way around to the XD okay and that is transpose so that it's become it's a column Vector I think yeah it's a column Vector it should when when you do the transfers it becomes the row Vector that is a x which is the input value and output value output value Y is either zero or one I'm taking an example of a classification case of a classification case so you are your output is either zero or one cool so specifically over here you have a weights you have a weights um which is carried by the weights your information where what is learning so where learning occurs how you learn the particular system how you make a diabetes prediction system so how you learn it so learning occurs by changing the weights and the goal of changing the weights is to modify the computer function to make the predictions more correct in future iterations so what is the learning tells you how do we how do we learn it okay so the whole learning stuff is getting the right set of weights or identifying how much X1 contains or or identifying the right set of Weights so that we'll be able to identify which input have more effect okay which input have have more effect if you don't understand from this point that how learning occurs don't worry about it we'll talk about in detail what exactly we call as a the the learning problem okay sure so um what exactly how what what is learning and in high level overview what we do the learning occurs by changing the weights W1 W2 W3 and W4 so we change the weights until and unless our prediction uh be more correct in our future iterations okay and then uh this and then you you strive to find the the best weights the best weights by choosing algorith like gradient descent algorithm or stochastic gradient descent and there are lots of optimization algorithm which are out there cool so now after now what you do you you simply multiply or or or or multiply the or take out the product of the inputs and the weights and then you aggregate the weighted information okay the whatever the information which you contain whatever the information which you contain you simply multiply with the inputs just order to X so um simply aggregate the information XI and wi so um W1 X1 so we identify so we are able to uh say okay in a nucleus you'll be having the weighted information or the aggregated information so that we are just adding it up and then we are adding the bias STM and then we apply some kind of activation function which is some nonlinearity okay which is some kind of function here here it is a sigma function before sending it to the destination y okay so now we are we are ignoring too much about bias STM we are ignoring bias term and then we are ignoring nonlinearity or activation function okay let's talk about that and then we'll end this video cool so over here the perceptron with the bias term so what exactly do what exactly bias term help you to do say for example take a simp simple example y = mx + b y = to mx + b so you all know about it very very very carefully so you all know know know about this specific term called y = mx + b where you have this where let me just erase it out so that it would be much better because I don't know why I'm not able to draw very good kind of stuff oh my God no problem so you have this and then you you have this Okay cool so this is the the equation for this straight line Y = to mx + b okay and M here is the coefficient or yeah coefficient of x coefficient of x and B here is your Y intercept you B here is Y intercept or we can say m is slope of this particular line okay so what if just I'll I'll I'll not go into y MX plus b because you already know because it scores expects you to go go at Algebra 1 and Al Algebra 2 so um what is B tells you if we B if we make that b to be equals to zero what will happen if we make that b equals to Z what will happen so over here your y your y will be zero okay your y will be zero and always pass through the origin which is 0 and Z where X is z and y is z and Depends and your straight line or your or your or your or your line will depend only on one parameter so y = to MX where if you have b equals to Z then then we don't need to write it so over here it only depends your slope okay it only depend you can either make this way or either make this way but the only parameter which it which which it it will depend is M okay is M now over here you're only able to make a function you're only able to make a function you're only able to make a function which just Maps which which is which is non complex function which passes only through origin and just only depends on one parameter but when we add B there when we add B there y = mx plus let's say 2 so over here let's assume two so you you able to make more complex you're able to make more complex function and shift the graph okay say for example it it's if we add B if we have zero then it does not shift the graph when we had the bias stor it shift from here to here so what it does it shifts the graph and hence it is able to represent more complex situations which it was not able to um make it before so from this y = mx plus C example it is simply saying it is able to represent the more complex example or shift the graph a little bit up the same way it will work in your neural network bias allows you to shift the activation function by adding a constant to it that is the given bias to the input you can think of it as a linear constant which we learn as a weight okay which we need to find a good bias okay we we we of course we don't just just just we do do not only need a simply add a bias we do need to find a very good bias which we'll talk about L later on that how do we get the W 1 W2 or how do we get B1 and Etc so and make sure that W1 W2 W3 uh W1 W2 these are the weights these are the weights or we sometimes call the parameters and you I I I have already discussed these weights are are the weights for your inputs for your inputs or every input has it certain weights okay so specifically in this case your bias storm help you to shift the graph of your activation function so if you have seen your logistic regression if youve seen your logist logistic regression the graph of this the graph of logistic regression is s shaped s shaped okay s shape like like this so when bias is zero it the the origin is over here and bias is zero now when we say bias one then it is able to shift the graph and hence it is able to represent more complex situation and when we do plus one then it is able to represent much more complex situation so basically bias term shifts the graph a little bit or a linear as a linearly and then it is it is able to represent more complex situation so that's why bior is absolutely necessary in neural networks it's not kind of it it will not work without biom but it's very very necessary part of neuron networks cool cool so uh over here which you're seeing is neural network which is let's say you want to build a house price predictor because we have all we we we are only seeing out the examples of maybe kind of stuff like um we are only seeing examples of maybe kind of a classification problem but what if you if you get a regression problem where we want to predict the house prices so let's say we are given the information X1 X2 so these information is carried by the W1 W2 W3 and for a bi and okay so so then we apply a linear activation function we don't apply any any kind of nonlinearity we don't apply any nonlinearity we don't apply any nonlinearity you don't apply that you simply apply the linear activation function which is just the identity function okay we just it's it's a function when you give your Z which Z is aggregated information of nucleus which just gives Z the input okay which is a linear activation function okay and then you and then you reach the output and then we have your familiar m e meanus square error okay and then you take the partial derivative of it but don't worry about it we'll we'll talk about talk about gradient descent in Greater detail okay don't worry ignore it just I I have just written it out so that how training occurs you'll get to know but just ignore this cool so the last thing which I'll discuss in this video is intuition behind activation function why do we need this n nonlinearity which you're seeing that why do we need a sigma function and why do we need activation function after after we aggregate the information why do we even need that next step which is nonlinearity why do we even need to think about that so don't worry about what the Picture Tells don't worry about what the Picture Tells worry about some uh a story okay so if you smell something delicious delicious okay I'm pronouncing it correct so if you smell something delicious think of your favorite food my favorite is let's say an example of pizza okay take any example your favorite food so if we smell something delicious which is your favorite food in your neurons your sum neurons which which learn to identify that favorite food will get activated and will help you to get sense or tast it so your so you have several neurons you have millions of neurons and some neurons will get activated when you smell it okay to uh when when when when you smell some when you smell your delicious food your some neurons will get get activated and then it will give the signals to your mind to to just get a sense of something or taste something okay and if you s smell something which is not good the same neurons do not get activated okay now this is kind of a critical in this case it's very very kind of inspiration from brain like say for example you have a neuron 1 you have a neuron 2 you have a neuron three you have a neuron 4 you have a neuron 5 neuron 6 neuron 7 neurons eight okay so several neurons you smell something delicious you smell something delicious so what will happen so what will happen maybe the first neuron get activated the first neuron get activated this neuron get activated and this neuron get got activated these three neurons got activated and then it helps and then it it it it tells your hand or tells your mind to just uh taste something or kind of that but but but now now what will happen I'll just have this now the same neurons which we are having the same neurons which which we are having now when you Sim something which is not delicious the same neurons will not get activated other neurons which will get activated which is not the same which which is used for kind of so it will not get activated the same will will not get activated but other neurons will get activated that will help you to leave that food so in general same happens with your neural network that can happen as one activated and zero nonactivated okay so we can say if the value closer to the value to zero the Lesser it is activated so in this example in this in this example in this example um say for an example you have X1 X2 X3 and X4 now these are your inputs now over here this this neuron got activated this this neuron got most and most activated because it for for for this task these two got more activated these two got more activated as compared to this these two are completely zero these two are completely zero and these two are completely one these two are completely one and maybe this is kind of maybe 0 um 75 okay more one okay so um this is how the interation of activation function which activates you which activates a particular neuron so that it is able to do one task this is a this this is kind of a relation to your uh brain kind of stuff uh so uh using linear activation function so why our why our um activation function should be linear why do we need nonlinear so here your data is linearly separable so we do not need any nonlinear activation function we are happy with because here your data is easily separable by a straight line so it is linearly separable but in real world your data is not nonlinearly separable so that's why you have your favorite nonlinear activation functions one of the example of a nonlinear activation function is sigmoid function okay which is 1 / 1 + e^ minus Z and all null linear activation functions are differentiable when you take out the derivative of this you take out the derivative with respect to Z is nothing but time 1 C okay but don't worry about it we'll see the derivations later on so over here your data you cannot fit a straight line to this or fit a straight line like like this to to separate it out so so so for that you need a this you need a or you need a line or a circle which separates it out so so it separate the green and this blue one which is a non linear which which exactly nonlinear activation function achieves is is using to find a nonlinear decision boundary okay so here your data is nonlinear it helps you to achieve the nonlinear activation function to help you to build a nonlinear decision boundary okay so I hope that this gives you a better sense of it so I hope um um so I'll just start off with the last of uh I'm saying from a lot of time so so basically using nonlinear activation function so you have a set of uh inputs X1 and carried by the weights and then you aggregate the nucleus and whatever get net J and then what you do you apply to a non a nonlinear activation function because your data is non non non L linear okay so provide that into a nonlinearity okay and then and then it gives your output and then using a threshold like Z if it is greater than 0.5 you'll just say Okay this the person has a what's say the person has U diabetes so if if it a classification problem but what if it if it is a regression problem we use a linear activation function okay just uh pass that uh the output or or or or the net J rather than applying activation function okay and then and then we get an output but you may be thinking you may be having some questions around it hey hey hey I use you told in can we have a nonlinear data in regression problem yes absolutely we can have but but you will soon realize in neural networks you don't have only one neuron you have a several neuron and and at last you have one output layer and in that output layer uh where there you don't apply any activation function but other neurons you do apply activation function but in rest but in output neuron you don't apply neuron Network sorry activation function and then you simply apply a linear and then you get your output for regression problem but don't worry about it we'll discuss that in very detail so I hope that this is very clear on activation functions and I hope that you understood it very well now we'll talk about the training how do we how do we make it learn or how do we make it learn a real world neural network or how how do we make it how do we train this neural network so that it would be able to cor correctly classify uh the particular neuron and what exactly learning means and what is learning problem so let's talk about that in the next lecture hey everyone welcome to this lecture so in the previous lecture we had a talk on introduction to neural networks we had defined artificial biological neural network we also talk artificial um neural network in inspired by biological neural network we had also told you about um what are weights and Etc we had also given an intuition behind what are activation functions and why why do we need it we talked about linear and nonlinear activation function so now we had seen that how we we we we go ahead and make prediction like with the information carried so what eventually we do so we'll just just do the quick recap of it so basically basically what exactly we do is this is what the perceptron looks like so you have the input feature X1 X2 X3 okay and X4 so these are the four input features and each feature is carried by the weights and these weights like W1 W2 W3 W4 and we have an bias term please see the previous video to know why do we require bi so these are some of the weights so these all the and we have x0 which is always set to one okay so basically an x0 is being multiplied with this so X1 be multiplied with its weight and it identifies the effect of our input so X1 + W1 + X2 + W2 all the way down to the X4 + W4 and these information are carried into a nucleus if you talk about in biological way or is we we do the some of it and then we apply some kind of processing on it which usually called as activation function whether to activate the activate this particular neuron or not okay and if if it is gives zero then then we say okay or or maybe if let's say you are working on some classification problem it g 0.4 so it if it is smaller than our threshold if it's smaller than our threshold H let's say epsilon then we say Okay um say that returns zero and maybe zero can be the person has a diabetes and if it is greater than or equals to maybe greater than or equals to Epsilon then you can say return one and that one can be the person does not have ades so it it is totally dependent on your case so that's just that was a particular neuron where we talked about that how the forward thing work okay so how we do the forward propagation how we do the this is called a forward propagation this is called the for forward propagation where we are prop propagating forward to make prediction okay so we we where we are forward where we are doing for propagating forward to make prediction or get our particular variable Y what exactly we are doing is multiply with these input feature with the weights and do the weighted sum of it and then apply some n activation function and then we get our output okay and now who will tell us that we we are getting the good output we are getting the good output and how do we how do we get these weights how do we get this W1 W2 W3 W4 and B because these are the input feature which we'll get from the user these are the input feature but how we will identify these weights how we identify these weights because it is playing a crucial role over here when when being multiplied so we need to identify what is the effect of our input okay because uh we we need to know how do we get these weights so let's get started talking about this so now let's get started what exactly do we mean by learning this perceptron so so how we can make this perceptron learn to make good prediction or can be using in in in or or okay so what we'll do now is to formalize our learning problem so what exactly does it mean is you have your input feature and you have your input and this is a giant X so we'll say x is a set or giant set which contains the input features and please note I'm not adding the design Matrix if you wanted to know what exactly we will what what is design Matrix I would recommend you to watch my machine learning fundamentals or ml1 videos like first video which was multivariable or multivar uh like multivariable um linear regression it would be very nice for you to know about how we structure our inputs uh so that you could get to know that exactly how the input is structured cool so you have X1 X2 X3 and X4 okay so these are the input features an input feature can be n features X1 all the way around to the xn okay so we have n features in our input set X cool now given these input feature given by the user so this this this will be given by the user this will be given by the user and we need to and we need to and then we'll be having our output if this is a case of supervised learning problem if this is this this is a case of supervised learning problem then we'll be having our label or we can say then we'll be having our supervisor which is Target variable Y which will tell us is which will tell us that how we which will help us our to our model to learn to okay so I hope that you know supervised learning so if it is a case of supervised learning problem then you're giving the given the input set feature X and then you given output variable Y and there's a ground Ru that that is a ground Ruth which we know because these are the these x and x X1 y1 X2 Y2 these are your training examples which is given to you now we need to learn a function f which takes the input value X and we want our function to map to Target variable y okay so to map a Target variable y so you want to learn a function f that takes these input feature X and Maps this Maps this to a Target variable y hat and this y hat this y hat should be equals to why don't worry about other cases like overfitting Etc worry about that what exactly we need to learn we need to learn a function X we need to learn a function f that Maps your input variable to some Target variable okay and then um so and this target variable should be equals to your actual Target variable while training and then you can use this learn function to predict on new new examples where you don't have these your ground Thro okay so I hope that you're getting this this this is what machine learning tries to do it tries to find a function f that Maps your input variable to some output variable and and now so here's some diagram of it so you have unknown function you have not learned any kind of function which is f which Maps your input variable to Y and now what you do you have your training example with that training example you give that training example to the learning algorithm let's say in this case neural network or we can say linear regression or we can say logistic regression or we can say support Vector machine so so you give to the support Vector machine or whatever and then it will output and then it will output a learn function G learn function G which Maps these input variables to our output variable and this course comes with the machine learning fundamentals prerequisite so I hope that you know about these algorithms previously okay cool very nice now let's go further so this was the formal formalization of our learning problem so what exactly is learning so so how our perceptron or any algorithm learns so learning happens by changing the values of our weights so what exactly we do what I'm going to do is X1 and X2 okay and I'm neglecting the bias term as of now okay so neglecting the bias term as of now you have X2 and X1 we give to a neural network which is a perceptron what it does and each information is carried by the weights carried by the weights and we say X1 W1 + X2 W2 and then you apply the procing or the nonlinearity on this Z and Z is this one okay so so so you may be thinking okay you you will you are getting X1 and X2 but who will give you W1 and W2 whole learning depends on getting these good W1 and W2 please listen me carefully whole learning means in all the learning what exactly you need to do is find good find fine good weights F good weights and some or parameters parameters is something if someone if someone is telling you that that this neural network is learning eventually what is doing is getting good weights or getting the good set of Weights that's getting the good set of Weights that that for the particular problem so let's say in starting when we start in starting what your perceptron will do the perceptron will set your W1 to be zero and W2 be0 okay in starting we'll set all the all our weights to zero okay now it will output some y okay that that will be also zero because when you simply multiply with 0 it will be eventually zero um so what what exactly it is doing is it change the value of Weights in every iteration so now you when you initialized your weights let's say W1 to be Z and W to be Zer and we'll see initialization techniques later on but let's say for this example we had initialized our weights now now we now we'll start training it eventually what this training means is getting the good WR rights or the getting the good set of weights or right set of Weights like W1 and W2 so in first iteration an iteration number we have to check we have to give as a hyper hyper parameter let's say that we want to do for th000 iterations okay so so what essentially it will do it will change the value of weights from 0 to maybe 0.2 and W2 to be 0.3 okay that will change the value of weights and check okay because you will get to know that we have something called as loss function and this loss function in this case it's if we apply the nonlinearity which is a logistic loss then then it is a log logistic regression or log loss which we'll use over here so basically we want uh so now after updating the weights we'll check if the loss is decreasing or the error is decreasing by changing those weights if it is decreasing then we update these weights from 0 to 0.2 and 0.3 that's first iteration is done we will do the second iteration and in second iteration what we will we'll change those weights like 0.4 and W2 by 0.5 and I'm doing this completely because some people will ask how are you writing these These are completely random okay you will get to know in late later on that eventually when we do the back propagation I'll do a step by step one example to show you how to show you every cases but over here I'm just sticking as a random okay now over here you up in the second this is a second iteration this is a second iteration this is a second second ration where W1 is this and W2 is this where it changed the weights or tweaked the weights from 0.2 to 0.4 and from for W2 to from 0.3 to 0.5 now we check if the loss function loss function now we check the L loss function is decreasing if it is decreasing then we update from 0.2 to 0.4 and 0.5 okay So eventually what we are doing is changing the values of weights until and unless we get our good or or or or our loss function is equals to zero or our error is zero so in brief we'll use our batch gradient descent algorithm maybe you already know about batch gradient descent algorithm to minimize our loss functions to minimize our loss function So eventually our goal our goal what is our goal to minimize to minimize our error our error with respect to for with respect to um yeah so we need to minimize the uh error um we need to minimize our error that's our end goal so we'll use gr gradient desent algorithm to find good weights don't worry you don't have to do by your hand will you make use of the algorithm which is gradient descent algorithm to find the global Minima of our function J of theta and in the case of regression problem your J of theta is 1 / 2 m i = 1 all the way down to the m s h of x y n² so that is a mean square error and the and what you do you have a function and you need to find the global Minima in this function okay and when you when you find the global Minima in this function that will be here okay and we will we'll cover this so we'll we need to find the until and unless our loss is equals to zero or it it reach to Global Minima in our function J of theta cool so I hope that this is pretty much clear about what exactly learning means learning simply means is changing the values of our weights in every iteration and checking if the all f is decreasing if it is then update those values to the new weights from the old weights to the new weights cool and uh in brief what we do is use bash gradi algorithm in this example but there are lots of optimization algorithm that that that covers the limitation of these gradient descent which which will help us to find the global Minima of our function or to converge or to get the good values okay so in anation of gradient descent what exactly is doing don't worry we'll cover gradient descent we have already covered actually gradient descent in our machine learning course if you want to go there you can go there and watch that what exactly does it mean but don't worry if you don't want to watch that we'll cover gradient descent again to to to let you know how exactly the working uh means how exactly the geometric purpose of gradient desent works cool so let's go ahead let's go ahead talking about the gradient descent so that you could understand if you haven't understand don't worry about it you will you will understand it later on cool so we'll use our standard gradient descent algorithm to train our perceptron means what do we mean by training we mean by training is getting those good weights W1 and W2 okay and and of course we do need a bi as well we do need a bias as well so we need a bi so we need to get W1 good we need to get a good W1 W2 and the B we need to get these three parameters or weights uh which are good for your problem so here how it works so in every iteration okay in every iteration it changes the value of Weights okay of her parameters and check how well your model is performing with the current weight if it is performing well it simply update the weights with the current value it keeps on doing this until unless you convert first to your Global Minima okay so over here over here let's say over here let's say you have your loss which is very high loss very high error very high error very high error which is J of theta let's say um 500 okay that is your error which is pretty big now over here when the when when your loss was 500 your weights were Theta 0 oh my God W1 to be Z and w 2 to be zero and bias to be also zero so these are all our zeros when you're for when your all thetas were or sorry when your all weights are zero then you your loss was very high okay now when you update these laws when you update these laws now what do you do using gradient sent what exactly it's doing it's it's it's changing the weights of this it's changing the weights of this of all of these like now it changes the weight to W1 to be 1.2 and W to be 0.4 and B to be 0.1 so it changed the weights now checked if the loss function is decreasing so you have a less loss and now when we updated it loss function seems to decreased loss function seems to decreased it CES to 400 now we update our weights to be not this to be this okay now again what we do in next iteration it updates these weights to be the new weights and checks if the loss one decreasing and over here when updating those weights again tweaking this means uh let's say 4.1 so in this over here it by tweaking these weights we are getting the loss function loss function to be 200 which is eventually very low okay so keep on doing this until unless you reach to be here because here your loss function is zero and you get good set of parameters W1 W2 W3 all the W1 or in this for example W1 W2 and B so when you reach at this where your loss is zero you have a good parameters and this is come some this this is a parabola and something like that because it should look like Parabola um just for showcasing you all so I hope that what what does it mean if you want to know this in depth I have a video on my ml1 ml1 course please go there and watch that and on my YouTube channel um New Era so this was a geometric purpose of it this this was a geometric purpose of it now let's get ahead now let's get ahead to talk about um like the the the formulization um like the mathematical part of it like what what is strategy do we use to update the weights or change tweak the weights and Etc so we have already studied the dead derivatives it is just a fancy slope so what do the slope means how much y changes when X changes so what what do we need to know in this case what do we need to know in the case of here we need to know how much how much loss is changing how much loss is changing when we change W1 okay the same question again how much loss is changing when we change W2 how much loss is changing when we change to W or B okay for this example so so so it will tell us how much loss is changing cool so I hope that this gives you pretty much sense about now this is exactly slope and that is a slope and in calculus term if you want to take out the slope of a of a nonlinear or a curve if you want to take a slope of a curve we call that as a derivatives which you have already studied if you don't know about derivatives something will pop up or you can just go on New Era YouTube channel New Era YouTube channel there is a playlist called single variable calculus single variable calculus okay go there and complete the all set of videos then you'll be knowing the geometric purpose of the derivatives is just a fancy slope is just tells how much that loss changes when that weight changes okay how much that loss changes when that weight changes so how much cost function is changing when feature weights changes so we have a lot over here and this example we have taken the log loss we have taken the log loss because we are dealing with the classification problem in this case let's be honest we are dealing with the classification problem in this case cool so over here you have 1 / M where m is the number of examples it is looping through I = to 1 all the way the m y I log of H of x i + 1 y I log of 1 s h of x i if you don't know about this log loss I again go recommend to complete mll1 course which is machine learning fundamental course now now what Z means Theta transpose X and H of X means um sigmoid of X and sigmoid is nothing but 1 / 1 + e^ minus Z and E has some value which you all know now we have a loss what our goal is we need to optimize our our we need to minimize our loss function and find the the good weights we need to find the good weights it should not be here it should be here we need to find the good weights good set of weight and that minimizes this loss function we need to find good set of Weights W1 W2 all the w n that minimizes the loss function J of Z okay so how do we solve this op optimization problem because you all know about this that um you maybe if you have already not studied calculus I'd again recommend you to do my calculus course because in this this course you will get to means it's to because I don't I don't ignore calculus in this course please please please go there and watch my single variable calculus videos and then it will it will make pretty much every sense to you now so now you need to solve this optimization problem so what exactly we do is the first step is to initialize all weights to be zero initialize W1 to be zero W2 to be zero all the way around to the w i to be zero with the bias term also equals to zero okay now you keep on doing this you keep on and now you keep on doing this step until and unless it converged or until unless it is great it is greater than or equals to that iteration the number of iterations you want to do or until unless it finds the global Minima and your loss function or until and unless your your JF s minimized okay so you have your gradient so this is your gradient which is which is which you already studied in that course of single variable calculus and this is maybe you will see in Vector calculus this is just a notational argument to write the derivatives so so what exactly we'll do for vectorization we'll put that all in in a column Vector so this is a column Vector it'll make that as a row Vector now so we so that is we need to that is the partial derivative of your loss function J with respect to W so that is the that is the vector of gradients uh gradient Vector now this Vector contains the partial derivative of J with respect to W1 why are we taking the partial derivative of J with respect to W1 if you don't know about the part difference between the partial derivative and the derivative it 90% means the same u means in it's it's it's kind of a don't worry if you don't know about the difference between partial derivative and derivative for this if you don't know about the difference please understand as a say okay so it's just saying how much the loss function is changing when we are changing this W1 okay when we are changing this W1 So eventually you're taking out the derivative of a loss function with respect to W1 we taking out the derivative of a loss function with respect to W1 okay uh now now when we take the derivative so let's say W1 equals to W1 which was old so I'll just write W1 old the old which in this case will be zero if it is the first iteration minus the alha Alpha which which which which I'll come to that let's assume that is 0 0.1 I will come to this Alpha in just a second and then you write partial der um partial der of with respect to W1 you said doj with by do by do W1 okay so this is what it is doing it simply it's simply simply what taking of the partial how much the loss function changes when W1 changes and multiply with the alpha okay and then subtract this particular whole operations with this old one okay and then update that W one to be the new whatever you get by doing this operation and you do this for every example and this keep changing the W new and W old will keep changing okay uh for example this is W1 is over now it will do for W2 all the way around to the W J that is a first sttion okay that is a frustration in second iteration it will do W1 W2 all the way under WJ okay for the second iteration for third iteration it will do the same okay so uh so this is what does it mean what do I mean with this so you take out the partial derivative of J with the respect to L one if you don't understand till now don't worry about it I'll again talk about keep on talking about this but just I just I I I can just hope that you know about this particular thing what exactly we are doing because the you already have studied in your machine learning course so I just don't want to focus more on this so the learning rate GS and general know some additional control over how large the step should be make so if the learning rate is too large you can't you can overstep the minimum and even diverge so so you you all know that we are that we are doing this and we are here so if we have a now we need to identify which rate we need to go to the minimum which rate we need to go to go to this local minimum but this rate is set by the Learning rate Alpha learn learn learning rate alpha or we or you will see sometimes this notation okay so you will uh you want to uh know the learning rate or the rate by which you can control how large your iteration or steps should be um for your change so if the learning rate is too large you you can either diverse so let's say you have this uh you have this loss function and this you you need to go here now learn learning rate is around one what if what what you will keep on doing is go there go there go there it will just do like this it will never convert in local minimum it will just keep on diverging in The Jig jaag manner okay and if you have a small you will I I think uh you'll never converge okay so you can go there um https developers.google.com machine learning classc filtergraph this gives you a geometri or grab view of the learning rate so so over here we are we have on solving this optimization problem so again I'll repeat what exactly we are doing or where we are we are initializing the weights to a zero and we are repeating this step until an convergence so what exactly is doing it is simply M it is what is exactly doing it's first of all taking the partial derivative of of of what do you say of J with respect to W and that is W is old okay not the current on means what w is obviously whatever the W you have so you take out the partial Dera of clause function with respect to W1 and then what you do is what exactly is telling how much the loss changes when W1 changes and then we get to know about that and then we multiply with the learn with the alpha which is a learning rate which gives you additional control over how large the step should be and then you're subtracting from the old weight whatever you get that whatever you get from this operation which is this one and what which is this one and then you get your new weight cool I hope that this this gives you a pretty much Clear sense about it but the the next step is update rule so we are updating our old one with a new one and you may think hey a why are we subtracting it so one way to understand it is the way I understand it is we are subtracting why are we sub subtracting this operation from the W1 is because if you need to reach Global Minima when you if you need to reach the global Minima so let's take an example of this so you want to move down not up you want to not go above you want to go go so sorry you want to go down right so you are subtracting it to go down okay not you want if you add it it will go above it will it will go above okay so I hope that this this gives you pretty much sense sense sense about it so why we are Sub Sub sub subtracting it is the one reason to go down it's kind of a one way to understand there are several ways when you when you would do the partial derivative by your own hand you'll understand in more detail uh you'll get in problem sets so we are updating our old old weights with the new weight and instead of addition we are subtracting is the only reason because we need to reach our Global Minima over here you want to minimize your cost function so you need to reach to Global Minima so we need to subtract to go down so why gradi isent use derivatives so you may be thinking why are needing this kind of a partial derivative or derivative why do we even need it so what exactly is doing let's take an example that you are at this you are at this point and this is this this is this is your function of your loss or let's say this of course this is a parabola and let's assume that this is a function of J of Thea where your loss is very high at this point your loss is very high at this point but you need to reach over here but you need to reach over here but you need need to reach over here so when you take out the so what what it does it draws a tangent line on this it draws a tangent line on this okay T tangent line on this point when you take out the partial derivative of J with respect to W1 it takes out the in geometric view I'm saying it is a tangent line at this so what is this telling what it is telling if we draw a tangent line at that so let me just say if we draw a tangent line at the green point we know that if you're moving forwards okay okay so if we draw a tangent line or how does tangent line is drawn at that point it's taking out the derivative of your loss function or whatever that function is so if you take out if you draw a tangent line at that green point if we say if we moving upwards we are we are seeing that we are that we are going away from our local Minima sorry Global Minima or the Minima of the function where we need to reach where our loss function is zero that that we exactly want and when your loss function is zero you know that you have a good weight so if you draw a tangent line at the green point we know that if we are moving upwards we moving away from the Minima and if we if we are if we go down we are going close to our Minima okay so a tangent gives us a sense of the steepness of our slope of a function okay another thing it tells another thing which is a very crucial this derivatives tells another thing which this which is very CR crucial this derivative STS is the first is the direction to move Theta in or the or the parameters in so over here over here if you see that we are moving upwards we are going away from the Minima but if we go downwards we are moving or we are getting closer to Minima so it will tell you okay we need to go down ra rather than going upwards we need to go downwards okay the first thing it tells is to move s in the second is how big a step to take okay that how big a step how big step to take if the slope is large we need to take a large step because we are far away from the minimum and if the slope is small we need to take a smaller step because there the slope is smaller okay and for this illustration What do I recommend you to do maybe you if if you go to this website or the link when you put it it first of all it takes a larger steps but when when it start reaching to the Minima it start taking a small small steps because there your slope is small okay so it it tells you how big the step to take so these are the two things which this derivatives tells and what exactly we do need okay so I hope that this the calculus is again the very good thing which you need to know are again Toom to know about the geometry purposes by going on my YouTube channel Numa it would very helpful for you cool so now over here you have below is a perceptron which you all see which you which we haven't se which we have already seen it now what we will do is see how we will try train this perceptron to perform well and what do learning means or what does training means is getting good set of Weights W1 W2 all the way around to the W4 with the bias term so this is a perceptron which you're seeing over here and now I hope that uh you know I hope that you got to know about uh the perceptron and everything out here in the next video what I'll try to do is to make you train everything give you equations that how we will do and do we'll do one work example as well as we'll work on some activation functions for taking of the Deb we'll we'll do the lots of derivative steps in our next video till then byebye have a great day so in the previous lecture we had a talk on um the introduction to neural networks and I hope that you really uh like that lecture and understood every concept because most of the concept later on will be dependent on the previous one so basically um now we'll start talking about the learning problem and you don't need to worry about if you don't understand it it's just for giving you an intro if you know about machine learning you just know you know about grade in descent how gr grade in descent works then it will be pretty much clear to to understand this section if you don't know about it I will ask you to watch my calculus videos to understand it better and if you don't understand even if you know calculus I'll ask you to wait for the next lecture because we'll be having we'll be doing a stepbystep example uh using numeric example to help you out cool so so what is so over here what I'm going to do is to formulate the learning problem so basically in this we are formulating the learning problems so here you're given the input variable X and then you have input variable Y and then you want to make a function f which takes this big or or the big X or set X and Maps it to Output VAR varable and we want our function to map our input to Output variable so you you all know in machine learning what we do we take a set of inputs let's say you want to you you wanted to build a diabetes prediction system so you take uh let's say the age of a person the height of a person the BMI and Etc whatever Foods they eat and you take the inputs and then you make a function f and then using that and then it learns to predict a given those input features or those input values or those information to map it to Output variable whether the person has a diabetes or not okay so you want to learn a function f and your data if you if you I I assume that you already know machine learning and and a bit of machine learning the machine learning fundamentals so basically in Mach what what what what you do you you you have a you have data so X1 and y1 which is the one training example X2 and Y2 which is second training example X X3 and Y3 which is third training example and x and YN but over here you have for example input and the target variable input and the target variable okay so this this is your data now you want to learn uh F which takes that input variable X and then maps to Output variable y so so you so when you pass it through this algorithm which is NN and you pass through this algorithm you pass F to this algorithm you will get G which is trained function or which is learned function which is uh which is what what do you say which is very good function to Maps your input variable x to the output variable y so that's a case about learning formulation so I hope that you already know about nonlinearity I won I don't want to jump into this so what is learning so learning happens by changing the values of our Ates and in every iteration of it we should decrease in brief we'll use our bat grent descent algorithm to minimize our cost function so we had already had a talk on this we all we we also talked on our gradient descent algorithm we had also also seen our this and now we also also seen the learning rate we have also seen the update rule we we have also seen the Y gcent users derivative now what we will do is um jump on the training of perception so you have a perceptron where you have a set of inputs you all know what what exactly perceptron does it takes set of inputs with a biased term with a biased term and then pass it to nucleus or a neuron which we say in neuron it do two things first of all aggregate the information and take the weighted sum exactly what it is doing there and the second half it applies the processing in it which is 1 / 1 + e^ minus Z which is an active ation function whether to activate this neuron or not and then we get our output by hat and then we check now we got a y hat which is a model prediction now we check whether this y hat is equals to that Y which is a ground through and if it is uh we we take a loss uh using the log loss which is the negative log log likelihood which you're seeing over here okay so now what we have planned to do is to use grid algorithms so we have already seen what what exactly learning means learning means changing the values of weights until and unless we get a good model until and unless um our loss is minimized so basically W1 W3 all the around of the B are the parameters or the weights which we need to find good which we need to find perfect weights which works very well so basically in whole deep learning era what do we need to do is to find the set of weights which is W1 W2 W3 W4 and all the way around to the B um and B to get if we have good weights we'll be we'll be able to get good output and if you have bad weights we'll be able to get the bad output so you may be thinking hey you how we are going to get this weights if uh so so basically we initialize the weights so before training our neuron or before before training our neuron or before learning these weights what exactly we do what what exactly is we do we initialize all our weights so basically we initialize W1 to be zero W2 to be0 W3 to be0 W4 to be0 and B to be0 okay and then we start training it because now we have the weights now you now your model will performing very bad because everything is zero so you'll get your final output to be zero okay and that is very bad right so so what you do you take out the derivative because you need to find the local sorry Global Minima but in this case it will be able to find the local Minima so you need to find the Minima of that function uh of that function loss okay of of of of the loss so what you need to do you need to take out the derivative of L with respect to W1 so basically what is saying how much the loss changes or J of theta changes when W1 changes when you weight changes okay so basically it's just it's just a pretty much easy version like how much how much your loss or how much your error changes when you change W1 a little bit if it decreases if the if the loss changes when one when W1 is 0.2 then you update that way W1 okay so that's why we take out the derivative because it tells lot of things to us which direction to move Theta in and uh yeah so and and and it all tells us the slope andc etc etc okay so basically so that's why we take a look at we in the previous video we have seen that why grad desent use derivative please see that so over here we get our output now what we need to do is to take out the derivative of L with respect to W1 okay that tells how much l changes when W1 changes a little bit so let's let's go ahead and so over here you need to take a losses there and then you and there is a path a full path okay so basically this is uh here we'll use the multivariable chain rule of calculus so for taking out the D do L by do W1 which is partial derivative of L with respect to W1 what do you do first of all partial derivative of L with respect to sigo of Z okay the sigo of Z because we can't directly go to we we can't directly take out the derivative of L with respect to W1 we have to go through the path so over here we'll use the chain rule of differentiation multivariable chain rule of differentiation what exactly we are doing this computational graph is derivative of L with respect to that Sigmar function which is um Sigma of Z okay and the sigment of Z is 1/ 1 + e e the^ minus Z okay so you take out the derivative of L with respect to Y hat because that's a y hat not that not the it is basically this basically this um this particular sige of Z is nothing but your prediction what you're getting as an output right so you're taking the derivative of L with respect to Y hat equivalent it does not matter and then you take the derivative of this um Sigma function with respect to this one or or or you can say with respect to this one and with respect to this one but it does not need need to be because this is your one neuron this is your one neuron which is okay you take out the derivative and then you can simply go to w one okay without even going here just just have marked a line to make you understand but this whole process takes in one one line Okay cool so uh so here we have you so we'll simply Dera of L with respect to this neuron and then using this the derivative of this neuron with respect to W1 okay cool and then for taking out the derivative of um now over here you the derivative of sigar function with respect to W1 which which are over here so now let's go ahead and take out the the mathematically about let's solve this particular problem so we'll be getting our D derivative okay so let's solve it so let's get ahead so we want to take out a derivative of L with respect to W1 the first parameter so we need to choose because we need to find W1 W2 W3 and W4 okay these four parameters to be good parameter okay and then we'll getting our good output so basically what you do derivative L using the chain rule of calculus okay so so let's take out the first of all let's take out the derivative the derivative of loss with respect to Y hat okay with respect to Y hat or prediction okay so basically your log loss is nothing but minus I'm writing the negative log likelihood y log of H of X which is your prediction or we can say the sigma of X which is a prediction plus 1 y log of 1 minus sigmoid of Z okay so basically you have this and then when you take out the derivative of it when take out the derivative of L with respect to uh this Z so Sig of Z so basically what you'll do so just for your information the derivative of of log X with respect to x with respect to X is nothing but 1 / X so that's your derivative 1 /x so you'll you you'll be left with y Sigma of Z + 1 y 1 Sig of Z when you take out the derivative of this if you don't know calculus don't worry about it um you can just think about okay when we take out the D derivative you'll get this calculation or you can learn learn calculus or see on some YouTube videos to understand how it came but basically is very very easy to understand first of all the derivative this is a constant this is uh this is a very varable uh this is uh your your um so when you take out the what do you say 1 over uh this that you'll be left with the derivative of log X so that will be this and plus 1 + 1 Y and then you simply add 1 by 1 Z okay so that's it that that exactly how the how we take all the derivatives now let's go further and uh and now now we now we have had found we had found this one which is this one we have we we done with this one now we need to find the this one so basically we're taking out the derivative of Sigma of Z with respect to W1 so Sigma of Z Sigma of Z which is the function 1 / 1 + e^ minus Z so that's your function which is a sigo function so you need to take out the derivative of that with respect to this Z with respect to Z because we can't directly go to W1 but with respect to Z and then and then and then we'll be having this this one so from here to here and using this Z we'll get our W one okay so basically how you take out so 1 + 1 1 + e^ minus Z to the to the^ minus 1 because we had converted to this fractional form to aine form so you can t take take take a look like this and then you use the power rule of differentiation so what you did is to transfer this over here transfer this over here so let me just how I come up come come up with this you can simply feel free to um ask me over comments or see any online video because I assume that you already know these uh what do you say Sigma function or or or the derivatives uh calculus don't worry we'll derive this in our next lecture now you have taken out all the now we have now we have taken out all the derivative of L with respect to we can simply multiply with this derivative of Z is this and derivative of Sigma Z with respect to is this one and how this X1 came how how this x X1 came so because the derivative of Z with respect to W1 and Z was nothing but W1 * X1 * X1 okay uh we just assume that W1 * X1 over here over when you take out so over here we need so you'll be left with X +0 okay so you you're left with W1 uh sorry X1 X now let's go further we so that's why we got X1 and then you got the derivatives of respect to one but if you have in a rest don't worry about it pretty much easy we'll again re re revisit the same thing but we'll do the all the calculations by ourself so that you get a very good understanding of it but don't worry if if you haven't understood is just for those who knows calculus for those for those who knows calculus who knows calculus okay to to take out an Al who who are who are good in mathematics so we have t so now we have seen our so now we'll see some of the activation functions so now we'll see some of the activation functions and then take out the derivative of those activation function okay so this first activation function which you have already seen is the logistic function the main main reason why we use Sigma function is because it exist it it it makes that the output of Z into a range of 0 to 1 okay so when you take out the derivatives which you're seeing in front of you we had already taken out by derivative of Z with respect to uh Sigma of Z with respect to Z okay cool uh let's go further so we have another activation function which is the tan activation function the hyperbolic tangent activation function is often referred as a Tage activation function it is very similar to activation function it's just similar to activation function but rather than making that Z to in the range of 0 to one it makes in the range of minus 1 to 1 it range in the range it it makes in the range of minus one to 1 rather than making it to the 0 to one so that's why we Define as a tan activation function what is the function formula the formula for that e^ x e ^ x / e^ x + e^ x so you just instead of Z over here it's X so you can just put the x value or input value to convert into range of Z sorry minus one to 1 when you take up the Dera it's a bit hard and I don't want you to get into this because it's kind of you just need need need to know about this particular stuff you don't need to you you need to know about the derivative but if you are seeing over here the Der ative of that e^ minus Z is nothing but 1 t h squ okay so all the derivatives which be here we are using the chain rule differentiation exponential uh derivative Etc to get it to 1 minus t z ² which is the derivative so why why I'm telling you the derivative because we'll use it in our later CL later lectures so that's why if if you're not not getting it why we are why we are using it please be sure to uh please be sure to complete the whole class class and then you'll be understanding why do we need to use these so then the next activation function is widely used activation function Rel activation function which is a rectified linear unit the main advantage of this reu activation function over another activation function it does not activate all the neurons at at the same time so basically if if what it does it takes the max of zero and Z okay assume that your Z your input value Z is 1 so when you take the max of 0 and 1 what it will be answer will be zero so so that particular neuron is not activated because in neuron we have a particular Z and then you have some kind of activation function so Z is let's say one and when you apply this Max then the neuron is not activated okay at the same time because it help it really helps uh and and and and the special property of all the activation function reu activation function whether whether it be Tage activation function or whether it be what do you say Sig mode activation function all these um functions are nonlinear in nature and is differentiable so all are differentiable so that's why we are able to take out the derivative but what do you think about the derivative of this so that so we have the equation Max of 0 comma Z so the derivative of activation function is one if x is greater than zero and zero if x is smaller than zero okay so so so the the derivative is this uh which we can represent through this diagram cool so we'll discuss about it advantages and disadvantages later in the course and we continuously revisiting these activation functions a lot to help us better understand and we'll be introducing later activation sorry extensions of some activation functions to overcome their advantages so if you don't know about any of these things and if you didn't got it really don't worry directly move to the next lecture you'll be understanding everything because there I have gone very slow in understanding step bystep gradient an example so here's an recap so exactly perception learns is by changing the ways and here the path you follow from going to L to the W1 by first of all the Der partial derivative of L with respect to that Sigma of Z and then partial derivative of Sigma is Sigma of Z going to Sigma of Z and then partial Dera of s of going to W1 okay and this is the same for every particular what do you say um the every particular feature over here okay so I hope that's that's that's pretty much clear to you and I hope that you are able to understand everything out here in the next lecture we'll start off with multier perceptor and I hope you'll enjoy that let's go on next video hey everyone welcome to this lecture on multilayer neural network in our course mlo2 and I hope that you are really liking this course so let's get started with uh multilayer uh neural Network so what is multilayer neural network so in in perceptron which we have seen we have a particular unit I would say we have particular unit like this and and and in multilayer percepton we include multi uh lots of perceptron and stack them together okay so let's take one example so taking one example which you're seeing that we have a particular so so which which we have seen in previous videos we have several inputs several inputs and we give to a particular Neutron and then we get our output y okay so what we will do what we will do is have mulp on perceptron like this say for example we have information X1 X2 and X3 we give to the to this particular neuron and then the output the output from this neuron out output from this neuron is given to another neuron and then we get our output right so this is a multilayer perceptron this is a multilayer perceptron where we have a multiple perceptron or or more than one computational lab okay in perceptron you have you were having an input layer and an output layer right so you have a input layer which is X1 all the way down to the X4 and then you were you you were having the out output like this right so yeah so you're having the neuron and then you're getting output so from this particular neuron you are getting the output so this was called as an output layer right output layer and because we here we are having the because from this neuron we are getting the output so that's why we call this as a output layer where all computation was happening in the only in output layer right so all the computations like the aggregation of the information like this I = to 1 all the way around to the J XJ and WJ and then we have apply the nonlinear activation function over here we are applying the sigmod activation function like this and then we are and then we were getting our output right that is that all the all the all the computation was happening in this neuron now over here in in multier perceptron we our input is passed through several layers so we have our input so we have our input X1 X2 and X3 it is passed to one neuron one neuron and then the output from this neuron the out put after doing the computation and computation what it does first of all the aggregation of I = to 1 all the around J XJ and WJ and then the preprocessing okay or the activation function so this processing is same okay so we app do the all the computation and then the output from this is passed to another neuron right and then it performs aggregation and the processing then passed to another neuron that we have to specify now you may ask me ask me a question here use and how many number of layers which we have so over here in this example and then we get our output so here in this example we have total of three layers you have total of three layers um which is called the uh these two are called The Hidden layer and then we have them then then we have an output lay so let's discuss about the terminologies which we will eventually use a lot in this say for an example you you have this example and then you have an input layer you have input layer and then you have a weight for for with respect to every input and then we have one bias right and then we give to the and then we give to the one neuron and then the output from this neuron is carried by some weights with the with the information from the previous neuron so this this weights is need to be learned because because over here we need to learn these weights as taught in the previous video we need to learn these weights so basically the information from the from this neuron is carried by some weights which we denote by w we we talk about what this 21 means later on but over here the E information is carried by the weights right and then and then the it is passed through in over here now what what will the computation the computation in this this neuron will be w21 times times uh the h11 okay the information which we got from here right and plus the bias term plus the bias term okay and then we get our output then then we get our output which is the which is our y so over here we have a total of two uh layer neural two two layer so we in this particular example we have two layer Network and here we have one hidden layer we have one hidden layer the reason why we call this because we are not see the user is not seeing this right what the the hidden layers that's why KOB we call this as a hidden layer but we are seeing the output so that's why this output layer this is called output layer we do not count our input layer because eventually we are not doing any computation in input layer but in in in Hidden layer and output layer we are doing computation right so that is our favorite output layer and hidden layer so again I'm again I'm repeating the through several layers which is not visible to the user that's what we call that call it as a hidden layer right so that was pretty much easy to understand it in much better way now let's talk about uh we will talk about these termin ologies to or notational arguments what exactly this 14 and 15 means and what this just relates to what this relates to and what this relates to and all the stuff but over here this was an introductory kind of a slide for making you understand about multilayer perceptron like how we just extend the idea of perceptron to multilayer perceptron right so let's go on the next slide to to to understand much better better way let's go over here so let's take a let's let's take one example over here but before that I want to make you familiar with ter logies so let me just show it to you so here it is so over here you have an input layer then you have one hidden layer the layers which is not visible of course the and this is called the output layer the L which which is the output layer right so information is carried by some weights so information is carried by the weights W W1 W2 W1 W3 and all the way did bias and then we have four input layer and then we have an layer and then we have an output layer right so so the the notation which you're following to be very much consistent is we have a w to denote a weight and then we seeing lay number lay number and weight number okay so this this this this weight this weight is of which lay it's for layer number one so we write layer number one and what is the what is the number what is the weight number is the first weight right so we write as a land number and the uh weight number so that we have lay number one because it's going in layer number one and then we have a second second weight first layer third weight first layer fifth weight right so over here we'll change the argument but for being precise I'm doing like five we have fifth uh weight which we need to learn but a but as we go further we'll slightly change our notations to help you much more better on more concrete or industri stand wise right so just for information you can assume that a 15 okay and this is layer number this is layer number which is going for layer number two and this is the weight number there is only one weight since since there is only one weight so we have to one right and over here you have an hidden layer so we denote by at which denotes the hidden layer and then this is your unit number this is your unit number and this is your layer number okay so this is a first hidden layer so we denote by one and this is a one there is one perceptron layer we will see that we will having a several perceptron like this and each each denotes a unit right so over here we have the first unit right so we have the first unit okay and then over here we have an output layer which is denote by o and then we have and then this is this is this is nothing but your layer number or output number you can understand in this way so sorry that yeah that is an output number or we can think of in different way that that is an output number and this is your layer number okay but we can slightly change it to our formation is like this I think uh we can slightly do the changes like this where this denotes the unit number where this denotes I think there's a typo it should be one over here and there it should be two over here okay that denotes the unit number and that denotes the layer number to be consistent over here okay I hope that that's pretty much clear about the notations so let's go on our example which we have seen previously so let's go on examples so here we have a very good example to understand a much better way so diabetes prediction system given age height and BMI okay so you have three information or three input value and there is one bias term where we always set x0 = to 1 okay and then here we take an example then let's take an example AG is 4.5 understand this way H can be 4.5 years old and then height is 5 cm or and BMI is six and then x0 is obviously one by the convention so we taken a default value for this example though no one need to understand how this example came it's just a random example which I've taken now I have given the random weights don't worry how these weights come we'll learn how to get good weights just for just a random stuff right just to make sure that is you're clear about the process which is going on so over here over here you have weight 1 one which is 0 0.1 we had just defaulted this okay so we have w11 weight 1 weight 2 weight 3 weight four and then we have one bias term like this okay which is randomly initialized now we go to the first hidden layer in the first hidden layer we have one Z and then we have an H so what do Z does Z Aggregates the information right so it just multiplies the in the weights with the input values so over here if you multiply 0.1 times your uh your input feature 4.5 plus the 0.2 * 5 0.3 * 6 0.4 * 1 okay so that is 0.4 so sorry 0.4 times uh I think I've done did wrong over here I think this should be removed oh my God this should be removed uh please ignore this and then we have an bium please ignore this okay uh and then we have an h11 which is over here 1 1 by 1 1 + e^ minus Z because here we are applying the sigma activation function which squeezes your output into the given range right so over here we have 0.9 9 okay so you get your uh the output from the first hidden layer and this is your output from the first hidden layer okay and then we give to the let me just uh do this little bit concrete it should be 0 2 and 1 the output layer now you simply have initialize a random bait 0.3 times the information from the previous layer and then we add the bias term and the bias term which you have taken over here is 0.2 as a randomly as a randomly the bias term is 0.2 and then we get our output and then we apply the activation function which is 0.62 and then we get our output now if this is a diabetic prediction system we can have a rule which is we can the our prediction is zero the person is not having a diabetes if the predi if the probability is smaller than 0.5 okay and over here it is greater than 0.5 so it is nothing but one the person is having a diabetes with these information okay however don't just think this is wrong right uh means this is just I've taken one example a very random example a very abstract example a very imaginary example okay don't worry this is for actual case this is just to show you how we are going forward in our network with multier perception so how we are going how we are doing how how we are going forward in our Network so we call this as a forward forward propagation we call this as a forward propagation which we call because we are we are propagating forward in our multilayer perceptron right so that is our uh that that is our just an example to help you can to help you better understand these things cool so we have talked about rotations so now we can do for multiclass classific prediction as well with with lots of hidden layers in between like this okay so over here so I'll just make you understand much more detail so over here you have a example of multiclass classification prediction you're given the color size and the and the size of the bird so you're given the color of a bird and then you're given the size of the bird you need to predict you need to predict you and and you're given the sound of a bird right so so so you're given the color of a bird size of a bird and sound of a bird you need to predict uh whether that bird is a sparrow whether that bird Sparrow or parrot okay given these three information you need to predict whether that bird is a sparrow or parrot okay so you're given these three information every information is carried by those respective weights with with one bias St right so so over here the number of Weights which you will get and and so you have a one you have of of over here over here you have one hidden layer you have second hidden layer you have third hidden layer okay and then we can increase and then we can increase lots of hidden layers that's that's that's what we have to choose now you may ask one question H is there any way we can have we can def we can have the number of layers defined like how are how how are we going to choose the number of layers which we want right the number of hidden layers which we want so this is a total very active area of research that there is there is no fixed number of hidden layers which we can use to get optimal results but it is just activate your research we just tune our we just check with two layers it works or not we just tune our hyperparameters like this to get our output right to do to analyze which number of head layers are working well right so here you have the first here and there you simply do the information aggregation and the pro processing step right so act activation step so over here you have a total of so the the the so the the size of an input layer the size of the the size of a input layer is n n n * 3 the the the number of weights at uh at this hidden layer is 4 * 1 because there are four weights times the the the there is only one uh unit because further we'll see we'll be having several units so that's why that is your four * 1 which is the number of Weights okay and the information is carried by the the the output from the edge11 is uh at subscript one to the power superscript one is carried by the weight w subscript 2 one and over here you have un biased term as well so you have a 2 * 1 so over here you have w31 and then it is carried by and then the output from this Le is carried by some weights with one bias term like this now over here we need two outputs first of all for Sparrow and second for parrot okay so every so every so we we we every every uh o output is carried by some weights or the information is carried by different different weights for different different units right and then we get our particular output the maximum so we say let's assume that that this is for a sparrow and this is for parot and this is for 3 * 2 over here we have three weights for the for the sparrow for the for the parot and the bias okay and the information scried by the the the information the weights for the the the information got or the output got from this hidden layer is carried by three three weights the first weight is for the sparrow second is for the parrot third is the bias term okay and then we have a to Total two units over here right so there are a total of six weights there total of six weights over here okay so I think there there there there's a typo have total of three weights over here but but we eventually don't count it right so over here so over here you take out the maximum of Pi right so you take out the maximum of of the probability of 012 so so let's let's let's assume we get 0.7 and this is 0.4 so what is the maximum 0.7 so we classify given these three information our uh uh the the bird is a sparrow okay so that is your with multiple uh hidden layers as well as with multiple output so now we'll see one hidden layer neural network now what we will do is to to stack different perceptron in a particular layer for getting our output right so over here assume that you have two inputs so and just make you familiar with it so you have two inputs X1 and X2 okay and then you have a the one unit second unit third unit and fourth unit okay so that is your first neuron second neuron third neuron and fourth neuron and then we are having the output layer so the this is a one her and layer neuron l so over here let's go with the so so now your information X2 is scattered by weights like w21 for the first neuron for the first neuron in layer number one it's scattered by the weights right and these weights are need to be learned right weights are the thing which we need to learn right which which we use optimization algorithms to learn these which we which we'll do in our couple of next videos to understand how we learn these weits okay so X2 information X2 is carried by the W2 carried by different different weights for different different neuron say for example in this the W2 is the the the weight for H1 by this X2 is carried by this the for the X2 the information is carried by this weight for this particular neuron and the information of this weight the information of this is carried by this weight for this neuron and for this okay and then we get our output like this and then uh the out outut from this is carried by this the output from this is carried by this way the output from this is carried by this way the output from this is carried by this way and then we do our formal uh in in every step we do our formal uh what say Pro multiplication or aggregation and activation stuff right so in every neuron this is this is what is happening okay these two these two steps which is happening in a particular neuron and assuming currently I'm neglecting so I'm I'm and over here for Simplicity for Simplicity neglecting neglecting a biasm neglecting bias okay so I'm currently neglecting biasm over here so that is for the second now let's let's go further to understand this this this way so for this for the first we have the first information scattered by this way for this particular neuron and then for f for for this we have this particular particular neuron and for this this information scattered by this weight for this particular neuron and for this information scattered by this weight for this particular neuron okay so you may have and then we do the formal process to get our output so over here if you combine those things this is how it looks like this this is how it look like so let me just show it to you so you have W1 1 and 1 w 1 2 superscript 1 W2 so sorry so sorry W13 right 1 and w14 1 okay so this is this indicates the layer number this indicates the L number this indicates from where it is coming right so from which from where it is coming the unit one the input input unit one or input unit 2 so it is coming from input unit one that that indicates the input unit okay input unit input unit right and uh uh this is the weight number the weight index so this is the first weight right so over here weight index so the same goes with the the the the the input number so let me just change the color so that it makes sense and W2 is is your weight index and this is your land number same goes with this same goes with this this and then goes with this okay so this is how the notation is working for this particular example we have w21 and then we have w22 w23 and w24 right so you have a w21 so over here this is the input unit 2 this is the because X2 and this is the the the the the the weight index and this is your land number right so this is how we denote the weights over here and if you see this example this has changed the the this one this one over here w11 to this indicates your uh the the the hidden unit right hidden unit and this indicates your weight index and this indicates your layer number so that is your notation arguments now in every particular um uh what is happening in every in every uh this neuron what is happening so I've done a very good uh very good analysis over here so I'll just tell you that what exactly is happening in every neuron or the unit unit hidden units okay so first of all I have given different different names so for so for aggregation steps aggregation steps aggregation steps I'm using Z okay and for post active post the the post activation I'm using H as our final output right so so over here so let's assume for this let's assume for this what is what is happening over here so basically this is this this indicates the the hidden unit the hidden unit and this indicates the layer number the layer number okay so for the first unit and in the first hidden layer we are multiplying the weights of the the first w11 this weight okay and then we multiplying for the first information and the second information right so we are not just uh because uh the first information and the second information is carried by different different weights and then given to this neuron okay because we have several neurons so for the the the two neurons is given to this the two input values is given to this neuron right okay and then we add the bias over here and then this is what the aggregation step means and then we apply the re activation function value activation function on the on on on the output which we get and then over here what what is happening in this it we are simply multiplying the weight from the for the the information X1 is carried by the weights with to the H the hidden unit number two same goes with the information number two is carried by some weights to the to the second second hidden unit okay and then we add the bias and then we get our output same goes with j3 j3 is our this this unit right so over here this is your pre preactivation preactivation preactivation in preactivation the information is aggregated okay with the respective weights and then applying the r for Z4 we are for this one we are doing the pre aggregation step and then applying value okay and then we have and then we get our output which is simply which simply multiplying the multiplying the weight with the output which you get from the particular unit this is also the out this is the weight which is carried by the information by the edge2 this is the weight the this one is scattered by the weight the inform the the the the information is scattered by this weight the information of this scattered by this weight and this is the B and then we get our output and then we apply some kind of activation function over here like reu or sigmoid or tan whatever we apply over here and then we get our output right so I hope that makes sense let's go further so if we can write in vectorial format to have it much more better way so I'll just see so we'll cover till uh different Laya so let's cover over here and then we'll uh go from the next video Let's cover the vectorial format and then we'll uh cover the rest in the next videos so we can write in this way we can write in vectorial format so we can have our big Z we can have a we can have a uh a matrix or or a vector which is z okay and we can store all our weights in a matrix and in know for this particular example we can store this uh our our weights in a particular Matrix so we store this we store for the first uh we store for the uh first information we store this weights and for the second for this for for the weights for this information and the weights for this information as stored like this okay where we have for this for this which are for first first information weights these are second information weights or the second put weights okay I store them into a particular weight which is weight Matrix one okay for this indicates the L number now we have now we make for the second which is which is St as a as as as a column Vector is 112 which indicates which which you can see over here which is weight number two and this weight number two contains the weights for the particular for for every um or or or you would say like this okay and we can write in this way we can write in this way uh in the vectorial format and then we can simply uh take out Z okay so what you can do you can uh simply multiply the weights with the with with the with the column Vector which is X1 and X2 we can put that into a vector as well and when you apply a matrix vector product with with a bias term so we'll we we'll add the bias term in every neuron the bias term is like this so when you add this when you add this so you'll you'll be getting you'll be getting your when you do the Matrix Vector product and then add the BM then add the B term you'll get a uh you'll get a vector is 1 2 3 4 for this particular example and then you apply the Sig mode function and then you have a big H1 and then you apply the activation function and then you apply the activation function like this uh like this and then you and then you'll be getting your output Vector Big H one where you'll be having these things so this is more efficient or more computationally efficient over here and then what you do and then you do the same for12 where you apply the Sig word function every element Sig word function on these on on on the particular vector vector which you'll get from here okay so that's what we have written in a vectorial format so so there's no any kind of a theoretical concept which needs to be explained over here everything is very very clear in terms of writing these things out here main part will be your back propagation stuff which needs a little little bit of more explanation but these examples are pretty pretty much easy to understand I hope that this makes to sense to you I'll be catching up in next video till then bye have a great day so uh welcome to this lecture on uh on on neural networks so in this lecture what we will do is maybe we'll talk start talking about um chain rule of calculus um and try to try to start off with that propagation but before that I'll just take some examples or worked examples of of multier perceptron just to be very clear in uh in calculating all those things and maybe we'll talk about different applying different application uh sorry act activation functions on on on your in in neural networks and how things work and F prop so maybe we'll revise it and then we'll go on computational graph which is of chain rule of calculus and then we'll try to see through the through the computational graphs like how do we calculate the how do we about great great info about chain Rule and then we will go ahead and and and end this video on starting introduction to to back propagation cool so let's get started so till till previous videos we talked till uh nine slides so I'll just want to make you familiar with it right so we talk till n9th class uh sorry ninth slides so what we will do we'll just Recaps youate it so that it would be better for you so we have a z variable we have a variable Z and then we have a variable X and then we have a biased term B right and and then if these these are our weights these are our weights this is the input feature this is Matrix Vector multiplication plus the biased term and then uh and then you get your and the biased term is the vector then you get your uh pred uh a vector which is where we apply the the the the post post activation sorry sorry the activation functions on each Z right so when you when you take out the dot product between uh your weights and and input value use X or the information then and then you apply the preprocessing stuff like this sigmoid in this case and then you get your output which is a vector uh a vector which you will get uh in over here and then this Vector is Multiplied with uh another uh weights Vector weights Vector this Vector H1 is Multiplied with another weights Vector plus the bium so basically we're taking the dot product between these two uh vectors maybe yeah so we are taking uh we are taking the dot product between these two vectors and then uh we we were getting this 012 okay uh so this was our basic uh basic revision of you of our previous lecture and I urge you to to basically have a good understanding of these things by watching our previous lecture because we had discussed a lot in that cool so now let's start seeing the worked example of one layer neural network so basically the the current neural network which we have is one lay one layer neural network one layer neural network Network so basically we have 1 two um three and four neurons four neurons right we have four neurons and then we have and then we have uh one particular one particular output neuron right so we have output neuron and over here we have two input features and x0 is always equals to one so so we don't need to worry about that all right and and and for assumption for Simplicity we have taken our bias term bias term all equals to zero for all uh neurons in this case so basically we have a weights we have weights like 0 0.1 so we have um so we have the first weight in the F from so W uh from the first to the first neuron so we have 1 one to be 0.1 for the first layer for sure so 0.1 then for 0.2 for the first information so the first for the first information X1 is carried by these weights into the four neurons for the first neuron for the second for the third for the fourth and then X2 for the first for the second for the third for the fourth so you have a weight Vector we we call this as a weight Vector we call this as a we call this as a weight Vector right and this is your input Vector which you're seeing which is 21 right so so the in we have taken a very dummy example to Showcase this is two and this is one and the and the weights for the second layer is 0.91 1.1 and one2 that is that are just random and just for the sake of example of a forward propagation like how do we multiply and do all those stuff right so first of all we we when we reach when we do calculation till here we get uh the vector uh for this we have 0.7 for this we have 1 uh after doing all the processing and the processing which is over here in every neuron is the first one is your I uh the the aggregation wi I * XI and then you apply the the the processing currently we're not applying the processing over here but the the first one is the is the weighted average or or the or what do would say the dot perk between your input features and the and the weight values right and then you have done the first part of it the second part is applying applying the the activation function so in this case we for this for for particular getting edge1 one then we apply the activation function on Z which we get like Z1 Z2 Z3 and Z4 you apply that and then you get a final Vector which is the output from this particular hidden layer so this hidden layer is this H H1 okay the first hidden layer outputs this and then this is Multiplied with with weights over here um we have another Vector weight and of H1 * times the the the weight for the second layer we take out the dot per between both of both both of them and then and then uh we get our final output okay so this was your applying the sigmoid activation function where it squeezes the output in the range of 0 to 1 so this one is squeezed into 0.73 1.6 into 0.832 1.3 into 0.78 5 Okay so this this was your basic example of applying sigmo function let's go ahead and see uh the the the next neuron so for the for the we have we we are done with the H1 so we are done with H1 now we do for 01 um for for for this so basically what I can do uh that indicates it's it's the second layer and this is the first unit right and uh this is what it does and now if if you see this is this is your uh output this is your uh the weights this is your weights W2 so this is your weights for the for the second layer and this is your your H1 which you got from the previous layer so information from the previous layer so this information for the previous layer is Multiplied with the given weights and then you get the particular output and then over here first of all you did the uh what do you say weighted average Now by taking the dot product between those those two vectors now what you do you apply the sigmoid function you apply the sigma function and on 2.5 it gives you a range of 0.93 right and then you get your 0 93 as an output so that's a one head and layer neural network right so where we are using the sigmoid activation function now let's go ahead and talk about Ru activation function the same the same example carries out so we have a 4x2 Matrix Matrix where it contains I think um a 4x2 Matrix of weight Matrix we have 2x1 input Matrix and we have four 4x1 bias bias uh sorry not Matrix 2x1 vector and 4 4x1 uh uh 4 * 1 uh bias vector and then we are getting the output and then we have an H1 which is what it does it over here we instead of uh applying uh the sigmo activation function we are applying reu activation function so basically what you mean and relu what it does it squeezes your output between one and zero right so so B basically not one and Zer it just takes out the max it just take out the max of zero and uh and zero I think yeah so it takes the max of zero and Z so whoever is bigger it just gives that as an output okay so 0.7 is bigger than zero 1 is bigger than Z so if there is minus one and your and and and let's say uh let's say 0 and minus one so so your Z is minus one then the output will be uh Z so there will be zero right so reu just what it does is the equation is Max of 0 comma Z and and whoever is bigger it just uh information for the next headden lay it is widely used Rel activation function and we'll see the advantages and disadvantages later on uh here we apply the tan activation function the tan activation function what it does over here which you can see um it's uh oh my God I think there's a typo over here we are applying the tan activation function uh tan activation function over here and this is the formula for it so we we urge you to watch the previous lectures if you haven't seen about these these activation functions in detail so we had a talk on on on a one layer hidden hidden neural network now here we see see an example of two hidden neural network two layer hidden neural network where we have for the for the first hidden layer for the first hidden layer our weight Matrix look like this our weight Matrix look like this we can also write in this format W1 right and then we can write in this format transpose we can write uh in this format so for the first uh weights right so we can simply write this as a this this row Vector into our column Vector right so sorry row Vector this column Vector into a row vector and then we can either transpose over here but but but for Simplicity let's let's stick with our example so basically we have W1 and then we have another this is a weight Matrix right and over here this this is a weight Matrix for for the first layer the weight Matrix for the second layer looks like this where for this you have the particular uh column Vector for the second uh hiden unit you have and you have this red Vector for this which you can see in detail so we have this uh weight Matrix for the second layer and then we have a third uh third weight Matrix or the or the column Matrix for the third layer right so basically for the output neuron okay so you can see it out just pause this video if you want to go ahead and see it out how it just works so we have different layer of neural networks so basically here we have a two layer neural network we have I think uh in in previous previous example this is three layered neural network uh but in if we include this particular output neuron so this is three layer neural network this is three layer neural network Okay cool so over here we have several kind of different layers neural network and and every uh and these are all carried by the weights and our primary goal is to optimize these weights to get good Theta okay or the primary or the weights over here so we can have L layer neural networks like this and we will formally introduce you to the Larn neural network maybe at the end of this video U maybe at the end of the back propagation when we'll formally give you the tools or the definition of neural networks both forward propagation and backward propagation for L layer neural network and when we'll Implement our own neural networks right so that's why I think we can script this L neur neural network right now so let's get ahead so now we'll talk about the chain rule of calculus so the chain rule of calculus so first of all we will'll start off with the derivatives derivatives of the computation graphs and over here let us assume that you want to take out the derivative of P the partial derivative the partial derivative of p with respect to X1 right so the partial derivative of p with respect to X1 okay the partial Dera of p with respect to X1 so what it will be over here we can't directly take out the partial derivative of p with respect to X1 we need to go with the path and this is where the chain rule comes in right so the chain rule comes in first of all you take the partial derivative of p with respect to Z with respect to Z1 times the partial derivative of of Z1 with respect to X1 then you will get to this so basically first of all you you you make a relation with this by taking the partial derivative of p with respect to Z1 and then times right so that is the CH of calcul multi multiv ch ch R of calculus times U uh the partial derivative of Z1 with respect to this particular X1 all right so for for reaching from here to here you take you you you need to follow the path but there is one more way we can reach to this X1 okay so that's why we add a plus sign here the partial derivative of p with respect to Z2 times the partial derivative of Z2 with respect to X one so there's one more way so there's one One path to go here and there is another path to go here right so basically and then we'll and then we'll be having our partial derivative of p with respect to partial derivative of X1 the first path is this path and the second path is going by this path right so basically you you over here this is the come this is the parti the derivative of a chain rule of Al so basically again I'm repeating the partial derivative of this particular p don't worry about these things what they are just assume that all are differentiable and and we are able to calculate the partial derivative or the derivative the partial derivative is quite similar to derivative because the difference between the partial and partial derivative and and derivative is just uh you you can see my Matrix calculus course for this but basically the difference between them is um the difference uh it's it's it's it's more uh partial derivative is involved in vectors right so that's why we we add the partial derivative over the partial derivative of this p P right with respect to X1 so it is it is asking how much this P changes when X1 changes so this this is basically change saying how much how much P changes how much P changes when X1 changes so that's what the derivative is D derivative is a slope right so change in y over change in X right so for for for understanding the change in y change in P over change in X you need to follow the root to to understand the change in X when you change P right so when you change X1 how much P changes okay or how much P changes when X1 changes so basically for taking the for taking out the change you for uh for for for for the for for this with respect to uh for for this with respect to this then you need to follow two parts the first part is the partial der of p with respect to this Z1 and then multiply the partial D of Z1 with respect to X1 this tells how how much for in this tells the how much P changes when Z1 changes and how much Z1 changes when X1 changes so inly it is telling how much P changes when X1 changes right but there is one more path which is the partial of p with respect to Z2 and then multiply it by the partial derivative of Z2 with respect to X1 this is telling how much P changes when Z2 changes and how much Z2 changes when X1 changes okay and then we get our final partial derivative of p with respect to X1 now coming to the next the coming to the next part the next part State the partial derivative of p with respect to X2 the partial der of p with respect to Z2 right uh and so basically if if you want to calculate the partial der of P me how much P changes when X2 changes so there are a total of two paths the first path which we can go is by this and the second part which we can go is by this right the partial der of p with respect to Z2 and then by following this path the partial der of Z2 with respect to X2 right uh with respect to X2 and then you get your how much P changes when X2 changes for the first path for the second path the partial derivative of p with respect to Z1 and partial derivative of Z1 with respect to X2 right so how much P changes when Z1 changes and how much Z1 changes when X2 changes and then you'll be getting a partial der of p with respect to X1 and partial derivative of p with respect to X2 so it's basically if you have seen a great recent thing it we we are what we doing what we were doing we're simply taking the partial D of g z with respect to with respect to Theta or W1 so it just tells how much J changes or loss changes when W1 changes so I'm just teaching you the concept so that you could understand the back propagation in much easier way when when we study about back propagation later on right so that's that's the first thing about the derivatives of the computation graph uh when when we talk about the chain Rule now let's get ahead I hope that this this this makes sense to you and this is now let's let's keep talking about the uh the Deep computational graph if you have a deep computational graphs how things work right so we had a talk on forward propagation all these things which which we talk on forward propagation but now we'll start talking about the backward propagation how we do the how we back propagate okay so the first thing we want to talk about is chain rule in deep computational graphs so over here you have this this H1 this this H1 a takes information it's h h H1 is is is is is is the function of X1 and X2 and this h12 is a function of X1 and X2 right and this h21 is a function of h11 and h12 and this H22 is a function of h11 and h12 and P is a function of h21 and H22 so it takes these two values to compute their output right so that's what the that's what these these indicates over here so now so now I want to talk about is what is the the partial derivative of p with respect to the partial derivative of p with respect to X1 so first of all the partial derivative of p with respect to h21 so first of all we go this way times the partial derivative of h21 with respect to H1 U sorry it's X1 yeah so the so that's X1 so basically we we do this way right so we this all for sure the path but using this we are able to reach X1 right and the partial der of p with respect to H22 right and the partial der of H22 with respect to X2 right but over here if you see we can calculate but there's when calculating h21 h21 to we have one one object over here there there there's one blockage so first of all what you do partial Dera of h21 with respect to with respect to partial derivative of of what do you say h11 h11 times partial der of h11 with respect to partial with respect to X1 right this is how you calculate it this is how you will calculate it okay just for Simplicity let's let me showas you to you how we Cal how we calculate the partial der of p with respect to X1 is partial der h21 with respect to with the partial D of p with respect to h21 first of all we get two here and then with this and then with this we calculate the partial der of h21 with respect to X1 for the we have another path partial der of p with respect to H22 times the partial derivative of H22 with respect to X1 right so there's two path but in in in in in the second path h21 with respect the partial derivative of S21 with respect to X1 and partial D s22 with respect to X1 has a block in between right so so basically for calculating the partial derivative of S21 with respect to X1 what you will do you will calculate the partial derivative of h21 the partial derivative of h21 times the partial D with respect to uh part with respect to h11 times the partial derivative of h11 with respect to X1 so the the blockage clears out so the blockage so the blockage clears out right plus there is one more way we can get to this X1 so basically the partial derivative of h21 with respect to h12 and partial with and and and partial derivative of h12 with respect to X1 and then we calculate this particular partial derivative of h21 with respect to X1 so there's two path over here which we can get to uh that how much h21 changes when X1 changes over change in h21 over change in X1 right so this is how we calculate for X1 right and then we'll do the same for this particular because there's some blockage in between right so let's let's do for that as well so basically when we do the partial derivative of H22 the partial derivative of H22 with respect to X I think X1 okay so we are calculating for X1 so for X1 it is nothing but the partial der H22 with respect to h11 so there's a blockage in between right so there's the blockage in between and then the partial derivative of of what do you say okay so over here I think uh I I did a little bit wrong over here I think so yeah so basically over here is B basically telling you have another path which we can go in this way so basically if if you see over here it starts Cal calculating but over here if if you see the partial derivative of H22 with respect to h11 and the partial and times the partial derivative of h11 with respect to X1 it should be X1 over here right and then it goes with the same with with this for s22 I think the the the diagram is bit wrong I'll just put the picture right so it understand much much well you can simply ignore this you can simply ignore this this is kind of um misleading diagram so for calculating the partial der s22 with respect to X1 so first of all the partial derivative of s22 with respect to h11 right um H h11 h11 right and then times the partial D h11 with respect to X1 right plus the partial derivative of H22 with respect to H H22 with respect to h12 right so we we have another another path which is like this times the partial der of h12 with respect to X1 so we calculated this as well and then we were having two two parts this path and this path and then we eventually will get our output as our final output right so this this was little bit misleading this was also little bit misleading but I will change change it um so basically this is the two paths which you calculate right so that's uh that's a particular thing which I talk about uh and and then same go and then we can write in this format and then like which which you're seeing over here and then we can calculate our partial of p with respect to how much P changes when X1 changes so that's a that's a that's a lot of things which is over here I hope that you underst to this uh deep computational graphs so in the next video what I will do I I'll I'll go through I I'll make you go through the the iteration of back propagation so we we'll solve an example of an iteration of back propagation out here to understand much very well like how everything works and how everything does not works all right so we'll so we'll do in our next video of an iteration of back propagation and we'll try to formally Define the back propagation in deta so thanks for watching this video I'll be catching you next so everyone in our previous lecture uh we had a talk on propagation we had talked about comparation graphs we had talked about how do we back propagate in computational graph and I and I hope that given you a so much sense about back propagation and back propagation is not an algorithm it's uh it's it's a part of gradient descent which we do which you'll come to that later on but basically today what I'm going to do is to do an duration of back propagation uh mathematically by solving a a neural network where I where I'll be doing one iteration of back propagation and show you the updated weights uh which which optimizes the loss a little bit okay so I'll be doing only one iteration but in but in but in but in practice we usually have the parameters of how many iteration which you're which you're going to do which will talk about later on in our hyperparameter optimization sessions so basically the back propagation which I'm going to talk about is just uh is taken from a Blog which I link in description box below so the explanation of this written is also available in the form of blog which I link to the description box below I would like to give give a big shout out to that guy and I'll try to explain it much more detailed way so that you could also understand by watching this video so so basically this this is the basic uh stuff which is in front of you which is a basic a twed neural network where where we are having uh one hidden layer and one output layer with two outputs or two outputs from your neural network so basically let me take my pen so basically you have several weights uh which is carry your information is CED by several weights so basically this uh X X1 is CED by this W uh 1 one or w11 okay so basically what I what I'm going to do is to vectorize this neural network and write this into the form of linear uh algebraic format or I would say majores format or vectors so basically I'm going to what what I'm what what I'm going to do is to store our input so basically the input which which it which it will go is just 0.05 and 0.10 and they're just I I've just taken a sake sake sake sake of an example this is this is nothing much more to worry about so basically this is your inputs X1 and X2 0 0.05 and 0.10 that is your input to your model and uh that's your that's that's our column Vector which is the X and I should denote with the small X rather than big X so basically small X and you have a weight Matrix for the first hidden layer the weight Matrix for the first hidden layer so for for for the layer this is a layer so so basically you have 0.15 and 0.20 right so 0 0.15 is a weight uh is is a weight for X1 and 0.20 is a weight for x uh of course uh X1 going to uh if you see X2 okay okay so X 0.15 is X1 0.20 is for X2 so basically your information is scattered X2 X1 is scattered by 0.15 uh from the first information to the first hidden layer or the neuron and your second uh way and second information is carried by some weight to the first hidden lay so basically that is 0.20 okay now we have the another neuron as as as I said we stack the neurons or the basic units right so we stack the so so basically this h21 basically this is a hidden layer and we have two neutrons in it and this H this X1 is CED by weights and being aggregated at h21 which is the second hidden layer second hidden neuron in the first hidden layer and then this uh and then X the S2 then X2 information is also C by some ways for particularly this neuron so 0.25 and 0.30 which is weights for this for the first layer weights for the second layer weights for the second layer is W2 is equals to uh 0 0.40 which is going uh just is carried this h11 H1 uh H superscript one sub subscript one is carried by some weight 0.40 and for and then this this this this this information is also carried by 0 050 for the second neuron and this the second H2 the second second neuron also gives out some information which is carried by some weights which goes in the which which which goes in the second out the first output neuron and this and the same information is Cared by another another weights for the second neuron okay so this is this is the basic neural network which you have and you have a bias term and you have a bias term which is first of all for B over here where for this you have 0.35 and for this you have 0 0.35 for this you have 0.60 for this you have also 0.60 pretty much it okay so now what I'm going to do is to do a forward propagation so basically that's that's that's what I'm what I'm going to do is to do a simple forward propagation and basically uh uh what what I'm going to do for propagation is get some predicted value o o sub superscript 2 subscript one and o superscript 2 and O sub subscript 2 so that's for what I'm going to to get so let's go so here let's let's go in our first uh hidden lay and in the first unit or neuron so when when you go there as as as I already say to you a neuron is Con a neuron in a hidden lay consists of two things first it gets aggregated in as uh in a nucleus which we call this as a z and then we have something called is post post uh sorry AC activation function which activates this neuron which decides whether to activate this neuron for the particular task or not okay so so basically if this is zero then the neuron is not activated but if this is something then a neuron is activated and that contributes some information that can go into the second layer of network so basically if you're seeing that z z superscript one sub subscript one is can be calculated by using something like w transpose X plus b and basically your W if you if you think for for but for this W was 0.15 and 0.2 right so this this this was your uh for the first the first information carried by two ways into two two different neuron right but but basically uh but basically over here uh which which you're seeing over here which which which we have this this over here this is carried by two weight 0.15 and 0.2 right uh 0 0 0.15 0.2 from two two different inputs and then we add a bu term which is 0.35 and multiply by 1 because x0 is always equals to one and then you get your output so basically this is your weights this this is your input X1 this is your W 21 okay for the first and this is w11 okay and this is your bias term right so this is this is basically your W transpose x + B which is your hypothesis and then this this this is aggregated and then what you do you simply apply an activation function here we are applying a sigmoid activation function sigmoid activation function but we'll see that this sigmoid activation function has a really big fall of Vanishing gradient isent problem so which will talk about it that later on but for Simplicity let's go with sigmoid so when you apply the Sig sigmoid to this output of Z1 the it it it is it say 0.59 it means this neuron is activated uh right and then you get your final output for this is nothing but 0.59 blah blah blah okay so that's your out that's your output from this for for for this you have again the Z1 and A1 and and this is this this in this newon X1 is carried by some weights and X2 is carried by some weights and then we aggregate that and then we add the bias term which is 0.35 and then we get our output and then we apply an activation function which is Sigma activation function and then you get your output right so that that that that is for the first H h11 and h12 now let's let's go ahead and talk about the the the output neurons right so that's that's a production so basically uh if you're seeing over here Z2 if so basically if you're going over here so this is a second layer of course and the first neuron right so basically when you when you calculate that this this output output neuron is carried by two information from the previous layer which is uh this information and this information so this information is carried by some bits and this information is carried by some bits and please note that these informations or the weight value are random as of now okay your your algorithm main goal of your algorithm to learn these weights okay uh that's that's that's that's what which is super important and this a12 is then you apply an activation function on top of it and then we get our o o o21 as an output okay same we do with o22 for which which we get an output as like this so now so now we have we have got our output now what we want to do we want to calculate the error as well like with these weights with these particular weights how well our models performing or how is the loss function or how is the cost function or or what's the what's the error is or how well are models performing right so basically uh let us assume that a ground Thro is for that a ground Thro is 0.01 and o22 for o22 we have 0 0.99 but our model given 0.75 for the for the first one and and 0.1 uh 0.77 for the second output neuron which is your model model output so what you what your model will do uh so basically we can calculate the error by by Sub Sub sub subtracting uh 0.75 then this one and then 0.77 with this one okay so basically you know how to take out the loss which is a mean square error what what whatever you can use over here and then you can uh and then we and then we make use of mean squ error to C calculate the error which is .20 29837 blah blah okay so that's what we are done with for propagation where where we got the error J with all of these parameters now we need to optimize these uh this this J so basically what I told you in our previous lectures or our previous grent lectures is we take the the the partial derivative of of of our C function J with respect to our parameters whoever over there and what we do we simply adjust these weights and check if the loss function is decreasing if the loss function is decreasing we update those weights right so that's that's what we do uh when when when we talk about uh derivative so derivative tells you two things how much weight to change and in which direction your your your your your weight will go in so please note that you was the lecture of gradi and descent so that you have understood in much more uh good way so what I'm going to do is to take out the partial first of all we need to update this weight W1 w211 so what I'm going to do is take of the partial derivative of J cost function with respect to w21 which which tells us how much loss changes how much loss changes or cost changes when that w21 that that W changes or that parameters Chang or that weight changes okay so so how we can calculate that so that's quite easy to calculate so if you want to take out the partial derivative of cost function with respect to your W12 so you have some blockage in that so first of all you need to calculate the calculate the the the the the the partial derivative of J with respect to a12 so the activation function of this so if you're seeing that you to calculate the first of all you have to go over here multiplied by as your as we invoke the chain rules so basically this a12 so first of all you take out the partial de derivative of J because over here over here if you if you want to go back then over here you have two things Z and a okay and Z this this is nothing but A2 like this okay so that's what we need to do so that's what we need to do is is is just take out the partial derivative of J with respect to a12 after that now we need to C because we still haven't reached there we still haven't reached there to our W12 so basically we calculated the partial derivative of A1 this one this uh this this one with respect to this okay because we need to calculate the partial der of that so we calculate that and then using Z1 and then using Z1 we can go to this parameter to know how this is changing okay so basically let's let's so basically here's the calculation which is involved so here's our cost function where where I have for Simplicity I have written this of course and then you take out the partial derivative of J with respect to a12 so basically what I what I'm doing over here so basically what what I'm doing over here is to using the the chain rule of calculus and the power rule ofal calculus to perform this calculation so basically what what I'm doing is is performing uh performing the first of all the the partial derivative of the inner function of the inner function inner function and the partial derivative or The Taking of the derivative not partial derivative the derivative of inner function leaving the outside function as it is sorry so sorry partial derivative outer function leaving the inner function as it is and and then taking out the times the partial the derivative of inner function so first of all when we take the the derivative of outer function so basically here is two so using the power rule we take it over here right and subtract Min 1 from this right so when when we 2 2 * 1 by 2 that is cuts down so we are left with uh y h of X now that that is our the derivative of outer variable now outer the outer function somehow because over here we have something but there is something which is one / two something something and this is two so the derivative of outer function which where we take two over here multiply with it as I said as you have listened me that I told in gradient when when when when do in gradient send it canceled out so that's why we do that and then we leave this as it is times your your the derivative of inner in inner function okay so when when you take out the derivative of inner function when when you take out the derivative of inner function this why this this this this y have uh IID say uh i' say if you to take out with a12 so this so This eventually becomes 1 1 + 0 and 0 is nothing but I would say uh the the the reason why we got zero because the the derivative of any uh inner in inner uh constant is zero and here we are using the sum rule because we are applying the derivative of n on every function and then the reason why we have minus one because uh when you multiply this this this minus one with this so you so it'll be left with this final formula which is a partial derivative of J with respect to a12 so that's that's your that's your the the partial derivative which you got okay now this just tells us how much cost changes when that activation function or a to1 changes okay that's what what you got over here now you can plug in the values to get that value right so when you plug in the values so basically put put the minus sign as it is this this is a ground Ruth and this is a model predicted which you get which is 0.74 right so that's you you got the value of this one now you go the same for the derivative of A1 2 with respect to Z1 so basically this is your as usual sigmo function and we have already derived this in our intro to NN chapter so when you take out the derivative of your activation function this something looks like like this and then when you take out the and then you put in the values of sigmoid of Z1 so basically your Z1 was what what what what was your Z1 we have just calculated priorly when doing for propagation so it it was this times minus 1 1 minus this and then you get your final output which is 0.186 which you got the value of this as well now the last one which you're left with is z12 where we are simply the the the the the the z12 is this so we going to take out the partial Dera of z12 with respect to this variable sorry this parameter so basically when you calculate that when you calculate that you are one left with you're one left with uh this this particular value which is uh H1 one okay that's that's that's that's that's what you're left with let let me just make you sure that what exactly your left with here so when you when you go back here so the when then you take out the partial derivative of z12 with respect to w11 then you left is f 5 93 because uh that that uh because that's that's a constant right and and you have XI which is left so when when you do the calculation you'll be getting this 0.59 which is quite well to understand okay so that's a that's the first that's the first parameter updation now what I what I'm going to do is to just change the little bit of calculation so that that you are you up to the standards of the calculation which are going on so Delta rule the Delta rule is when you take out the partial derivative of J with respect to W1 as how much cost changes when that changes right so that is which we have just taken out which we have just taken out as you're seeing over here we are just just taken out we have this so we can fill in the formulas W12 that is a ground Thro minus your actual value sorry sorry yeah mod predicted value and we have minus over just we add little bit of notations times this one which is uh which is partial der Z1 with two and then Etc which is the which is the partial derivative of your segment function which you got okay this this formula and this formula and then in this when you take out the partial derivative of Z1 with respect to whatever with respect to your parameter you have the output as a uh a12 so basically when you when go there uh uh this a12 which is a11 so basically that uh that particular value so yeah so basically you're you're left with a11 which is over here okay so basically you left with a11 and then you using that a11 you you get that W12 so basically using that A1 because this h11 have the a11 of course you you h11 is an output of your z11 and and a11 right so your a11 is the final output of course so basically you have this a11 over there if you're confused a little little bit on that so let me just make sure that you're that that that you're that you're understanding what I'm saying so over here I think this there is a slightly change it should be 7 six whatever but but basically we are we are going here and this is where we are we we are using uh this is from this is where we have this uh h11 basically where we're going backwards right so with here we have Z as w11 uh W2 * whatever uh the the output from a11 right so this is your constant of this so that is your a11 is which is an output when if you studied about calculus then then you might be familiar with this so that's your partial derivative of Z1 so sorry U yeah so so basically uh that that that that was a part derivative of z11 with Z with respect to your parameter W and please be sure that I'm making lots of Errors over here because I think that it's it's very tough to at least pronounce their name but no problem in that but now we can write this into Delta notation and Delta notation here we can do we can take this uh and put that into a Delta 012 which is the which for that variable right and then multiply it by a11 and that's your partial deriva of J with respect to w211 okay so that's that's a Delta rule which you also see in real world so now we can just go ahead and and and and do all the calculations so we had taken out all all all of these in over here now what we can do we can we can multiply with that and then we get a final output and now what we can do we can update our uh weight because that because now we need to update our previous weight right so that's the that's the first update which we going to do let let us assume we have taken a learning rate which is 0.5 which is fairly a large learning rate but previously our weight was 0.4 but minus uh which 0 0.5 times the derivative okay and then you get the new weight okay previously 0.4 now it was now it is 0.35 which optimizes the error now what I'm going to do now what I'm going to do is um is just have something which is partial derivative of J with respect to w21 and basically over here what we are doing is take out first of all go back and then first of all take out a21 because over here you have something like this yes right so so basically you need to go back and this this is for a21 right so basically this is uh this is for uh second uh second weight going into first neuron as far as I know right so basically you have this a12 which is the second uh new second activation function so basically you take out a partial deriva of J with respect to Second activation functions you can do the calculation Now by your own and then using that you go to over here and using Z you take out the partial derivative of Z with respect to w21 which which tells how much G changes when this parameter changes and when you do that you'll get this 0.822 and when you when you when you update your parameter by the old one by minus 0.5 which is the learning rate you get the 0.40 which is uh pre previous one was 0.45 now was 0.40 right you do the same for the other two for the second for the second layer neural network for the second layer uh out for for for the output layer weights so you can do in this way the same way the same will follow up right and and there is something called a memorization there is something called memorization which I just just want to tell is when you take out say say for an example you take out the partial derivative of J A1 to and and your previous iteration you will will come to that the instance where you'll see the partial derivative already taken which which can be used in next iteration so we just make use of that rather than read read read redoing the partial uh the partial derivative of that so so that's what I we just make use of that of the of the one res all cre but but there will be a separate video coming up coming up on this so we had now updated our all uh parameters which is all the parameters of this till now now we need to update the parameters of this because we are back propagating back propagating over here so now we're updating the values of the parameters of the first hidden layer so basically we have to calculate the partial derivative of J with respect to w11 uh with for the first uh parameter so basically what I'm going to do is partial derivative of J with respect to a11 right first of all we need to go there times the partial derivative of J with respect a11 with respect to Z1 because we thebr we also go to Z1 and then using Z1 we go to W1 okay so as you know we first go here we first go here we first go here the partial derivative of J with respect to the G with respect to uh A1 a11 and then and then using this we go over here uh you take out the partial derivative of this with respect to Z uh 1 one right and then using this we take out the partial derivative of Z with respect to this and this this this this tells us if and using the chain rule as I told this is a chain Rule and there is a some notion called intermediate variables and and all those stuff which I which I'll come to that later on but basically this is the basic idea if something is causing blockage that's that's the chain rule which if you have already known about that so you take up when when when you do the calculation you'll get your partial Del of J like how much cost changes when w11 changes one superscript one and Sub sub subscript one one changes so now if you if you go over here if if you go over here uh for calculating the partial derivative of J with respect to a11 a11 so there a one blockage which is causing over there so we need to calculate the partial derivative of e eo1 because that's that's our output with respect to a11 right plus the the the partial derivative of e O2 with respect to A1 okay because as we know as we go over here and from this side as well as I told in your previous section uh in in in our previous lecture so that's that's the path because there are two paths which which we can go further so basically the part should derivative of Z with a11 so here's here's your two paths the first path for for going to a11 and this is the second path for for for for going to the Z1 like this and like this right as I told so first let's take out this partial derivative E1 with respect to a11 so when you when you take out the partial dtive E1 that is your a that that is nothing but uh a one 2 that's that's that's what it is right that's that's the output of it right uh as far as I know that's that's a soorry so sorry uh uh just just wait for a second let me confirm it if I'm correct over here maybe I should uh yeah I guess that I'm correct 0.75 yeah I'm correct I think so basically this is this is not this is not an error I think you can ignore this this is an output output of the of the of the out this is basically an output not an error please ignore this as of now this is an output not an error okay so basically this is an output not an error between the ground throw this just an output which is a21 a12 okay so and this is a22 okay so that's that's activation for which you get from output now basically when so basically you have to go from here to here so basically you are here so you you take the partial derivative of this with respect to this and then using this you go over here that's what we need to do right so you do the same and then for taking of the partial derivative of eo1 with respect to z12 right so z z z12 we need to first of all take out the partial derivative of a11 with respect to a12 times the partial derivative of A1 to divided by so sorry with with respect to z12 so basically this is quite confusing as of now I know but basically uh what we are doing we have two different paths to go above okay we have two different paths to go above sit down and see where it is going okay sit down and see where it is going and then you'll understand that we have a two paths where it going from this side uh from from from from from this side and from this side and you'll be seeing that we have taken from the this side this is partial derivative E1 with respect to a11 and this is the and and and when you take out the partial derivative for from this side as well okay from this side as well right so so so basically what what you can do is uh have this particular which you're seeing which is your uh which you can calculate that and then you got your final so basically you can plug in the values of that you can plug in the values of that because we need two these two for calculating the Z how much a changes when this changes plug in the values and and then we get our values and then we simply plus that because because that's the two path to go at that a11 okay so after that we done with this now we Cal so basically we we done with calculating the partial J with respect to a11 partial Dera of J a11 because it involves lots lots of calculations not only from this side it will go from this side as well if there's a two paths for that and that's why back back propagation is one of the hardest stuff in deep learning but it but but but it comes over uh learning all the stuff I suggest you to maybe read a Blog with it as well as watch the video that would make more sense uh so basically now we done with that so we take out the partial derivative of a11 with respect to z11 because without that we can't go so basically you all you the partial derivative of your Sigma function is always you know and then you have a z when you take out that which gives X1 which is output now you can simply plug in the values which is 0.036 time 0.24 which is another derivative then times 0.05 and then you get your output as a final output okay so that's the derivative of how much J changes when w11 changes and now what you going to do now what you going to do is just is just update your values 1 one is equals to W is new one this is the old one right this is the old one minus you're learning at Alpha and the D derivative of J with respect to 1 one okay and this is your out put which is 0.04 and then you can calculate for 1 one same you can do with W uh W uh W one two for the first layer but you need to identify the paths right the number of paths and then do it do it in that way okay so that's what the the iteration of back propagation means so we did a one one iteration of back propagation and I hope that this this this was a really nice session uh basically I just uh basically uh this was a a really really nice session on back back propagation uh if you like this lecture let me know and if if you have any questions or any doubt