Learn all the basics of structured query language in this comprehensive SQL course. You will build out real database tables and practice querying them in flexible ways as a backend web developer would in the production setting. Lane Wagner created this course. Lane is an experienced software engineer and creator of Boot.dev. So let's get started. As a web developer, you might think that you need to know JavaScript and Python and Go and TypeScript, but I'm actually here to tell you that what you really need to know is SQL or SQL. See, no matter what programming language you end up using daytoday as a developer, it's very likely that you'll actually be using SQL alongside that programming language in your web projects. Stick around and in just a few more minutes I'll explain why SQL can actually be a game changer for your career. I'm Lane, the founder of Boot.dev and the host of the backend banter podcast. I've been writing SQL for about 10 years now. I've spent over a year designing this course and updating the material, and I've actually already taught thousands of students with this stuff. And all of their feedback has actually gone back into the course improving it over time. So what you're about to watch is actually some really battletested material. During this course, we'll be learning all the foundational SQL skills that you need, but we'll be focused on the stuff that's most important for web development. The best part is that we'll be handson keyboard, filling out a realworld database layer for an actual web application. It's actually a PayPal clone that I'm calling Cashpal. This next part is very important. Do not, please do not binge watch this video. Look, tutorial hell is a real place. It's a place you're going to find yourself if you don't write your own code. So please, code with me. So, head over to boot.dev right now, grab a free account, and that's where you can actually follow along with every exercise right in your browser. Alternatively, if you don't want to create a boot.dev account, I've also linked all of the raw text files down in the description below. There's a GitHub link. Now, be aware, this SQL course is actually just one part of a full backend developer career path over on boot.dev. If you're interested in going from zero to hireable as a backend developer, definitely go check that out as well. If you get stuck during this course, don't worry about it. We've got three resources that you can check out. The first is the boot.dev discord, the second is the free code camp discord, and the third is the free code camp forum. All of those places are great resources for getting help. They'll be linked down in the description below. Lastly, if you want to connect with me personally, there's three places. You can find me on Twitter or X at wagslane. You can go sign up on boot.dev and I'll be in your email. Or I'm also the host of the backend banter podcast, which you can find in any major podcast player or just here on YouTube. With that out of the way, let's talk about SQL. As a backend engineer, one day I'm sitting in my office at work and my boss is staring kind of longingly out the window and I walk over and he says, look at that guy. Look at that guy shoveling manure. That's what I do. That's what I do day to day as a developer. And I mean, he was right. As developers, we just kind of take data from one place and shovel it into another place. We're just kind of moving crap around. And the best tool that we have for moving crap around is SQL or SQL. Say you're a developer working at YouTube. Your job is to shovel data from creator's devices, right? So a video, a title, a description, a thumbnail, shovel that up into the cloud and store it in some database. And then your job is to shovel that data back down to user's devices where they can watch the videos and see the thumbnails, SQL or structured query language, often also called SQL. I like to call it SQL. It's a little easier to say a few syllables. This is the language that we use to communicate with most databases. The vast majority of databases use SQL as a query language, a protocol that we use to communicate and get data in and out of database servers, things like MySQL, PostgreSQL or SQL Lite. A database is just a piece of software that makes it easy to store large amounts of data in your computer's file system. You could kind of think about it as just a really advanced Microsoft Excel or an advanced Google sheets. When you work with Google sheets or Excel, you're probably moving data around fairly manually, right? You're pointing and clicking, dragging and dropping. When you work with SQL and with a database, you automate all of that, right? So you write code that automates the creates, the reads, the updates and the deletes within the database. That's why SQL is so cool. And that's why as backend developers, SQL is critically important. Let's hop right into the first lesson and we'll start writing some SQL. So here on the right, I have my kind of starter SQL code for the lesson. On the left, I've got my instructions. And then down here at the bottom, I have the ability to run and submit the code. Now it's important to note that all throughout this course, we're going to be writing SQL that's executed against the cash pal database. And cash pal is really just a toy web application. That's sort of a clone of PayPal. PayPal is an application for sending money online and cash pal is basically the same thing in toy form, right? So you can imagine that the data that's stored in cash pal's database is things like users, right? Who are the people that use cash pal and then transactions, right? Every time one user sends money to another user, we need to store that information in our database. So let's jump right into the assignment. It says, I have provided a simple SQL statement for you that retrieves some records from a table. However, there isn't a people table. The table in our database is called users fix the bug by changing people to users within the select statement. So here we've got select star from people. Um, and it looks like there was just, you know, a mistake made. So we're going to swap that out for select star from users. In fact, let me really quickly run it in its old state and just see what happens. SQL logic error, no such table people. Okay, cool. And then let's change it to users. Run that code perfect. And I just want to call attention to the fact that the output of our little SQL statement here isn't console output, like you might get in a programming language like Python or go. Instead, we actually get a result set that's kind of formulated as a table of rows and columns. So now let's kind of break down the anatomy of the select statement that we modified in the first exercise. It's important to note that select statements are probably the most common type of statement that you'll write in SQL because select statements are the equivalent of a read operation, right? It's how we get data out of the database. Let's take a look at this first example, right? Select ID from users. In this case, we're selecting the ID column from the users table and all SQL statements and in a semicolon. So we're saying, give me all of the IDs from the users table. It's also worth pointing out that keywords in SQL are case insensitive. Generally speaking, SQL is case insensitive. So this select statement is all caps, which is typically the convention. The convention would normally also be for this from keyword to be all caps. But I just wanted to demonstrate that it doesn't actually matter. It will work either way. So we've talked about how to select a single field or a single column, right? Select ID from users. Selecting multiple fields is also pretty easy. You just separate field names with a comma, right? So if we want all of the IDs and the names from the users table, then we would select ID, comma, name from users. Now in the last assignment, we actually just selected all fields. We didn't name explicitly which fields from the table we wanted to get back. We said, just give me all of the columns that exist on the table, right? And when you want to do that, you just use the star operator or the wildcard operator instead of explicitly naming every single field and separating with commas. So moving on to the assignment, it says the state of our cache pal users table is as follows, gives us this nice little table. So keep in mind, this is the data that's actually in the database, right? And when we write a select statement, we're generally trying to select some subset of that data. We generally don't want all of the data in the database to come back from our query. We're just trying to get at something specific, right? So the assignment goes on, it says, it's very common to write queries that only return specific portions of data from a table. Our HR team has requested a report asking for all of the names and balances of all of our users. Write a query that retrieves all of the names and balances from the users table. So let's go ahead and do that. Start with a select keyword. And we're not going to do star because we just want name and balance. We just want the name and the balance columns, right? And I will capitalize to kind of adhere to conventions from the users table. Go ahead and run that. So you can see all we got back was names and balances. If we wanted, for example, the age as well, then we could add age here, right? We'd get an additional column back in our result set, but we don't need age, right? The assignment didn't ask for that. So we'll go ahead and submit that. So many databases use SQL. SQL is just a query language, right? And lots of different database technologies out there use SQL or allow us to write SQL in order to interface with the database, right? So Postgres is a really popular one. It's one that I use in production all the time. SQLite is really popular. It's the one that we are using in this course, actually. SQLite is what boot dev is running on the back end to power this whole interactive experience. But really, that's all you need to know is that SQL is a common language. So when you learn SQL, you'll be able to use basically any database that supports SQL. Though it is worth mentioning that while SQL is a common language, sometimes databases support different dialects of SQL. So you will see minor differences, right? Maybe SQLite only supports certain data types, whereas Postgres supports other data types. So there are little nuances, but generally speaking, when you pick up SQL as a skill, it will make it so that you're able to use all of these databases, even if you do have to look up little things that are different from time to time. So let's jump into this assignment. It says one way in which SQLite is a bit different is that it stores Boolean values as integers, right? The integers zero and one. So it's very kind of raw binary in that way. Select all the IDs, names, and is admin flags from the users table. Okay. Pretty straightforward. So select ID, name, is admin from users, go ahead and run that. Looks good to me. You may have heard that SQL isn't web scale. Why didn't you use MongoDB? MongoDB is a web scale database. Just by not using structured query language, you can make your database scale to billions and billions of users, anyways, that's not how it works. Let's talk about the real differences between SQL and no SQL. Let's look at a few of the more popular examples in both categories. So on the SQL side, we've got Postgres, QL, one of my personal favorites, for sure. You've probably heard of MySQL, SQLite. We've got SQL Server, SQL Server, that's Microsoft's. You've probably heard of Oracle, and also thrown a mention of Cockroach, CockroachDB. Okay. So these are just a few examples. There's literally hundreds of SQL databases out there, but these are ones that you may have heard of. No SQL databases, got Mongo, MongoDB. You probably heard of Redis. You may have heard of Elastic, Elasticsearch. Firebase, Firebase is pretty popular. And we'll also mention Dynamo, DynamoDB, that's Amazons. So these are just some examples of databases that fall into the SQL and the NoSQL categories. Now the first thing you need to understand about the difference between SQL and NoSQL databases is that the SQL databases tends to be much more similar. I mean, they're in a group because they're all SQL databases. So right out of the gate, they have something in common. Whereas the NoSQL databases, all they have in common is the fact that they don't use SQL, right? They don't all use the same query language, right? All SQL databases use structured query language. They have a common language that we use to interface with the databases. No SQL databases do not all use the same query language. They just don't use SQL. Now SQL databases also tend to be, they tend to be kind of general, general purpose. Now that's not always true, right? At the end of the day, a SQL database is just any database that supports SQL, right? So you could have a specialized database, but it just so happens that the most popular SQL databases tend to sort of be general purpose, which means they're often a great starting point for most web applications or websites. And right out of the gate, I'm going to go ahead and call out an exception here in that Cockroach DB is kind of an outlier among these databases in that it's a very distributed database kind of built for scale, right? So you add some complexity to the database, you get some scaling benefits. Same with SQLite. SQLite is kind of purpose built for very small applications where you embed your database like directly within your application. So those two, I'm going to kind of just flag as a little different, not quite as general purpose. Now, no SQL databases on the other hand, tend to be specialized, specialized, right? So usually no SQL databases are built for a very specific purpose, right? And again, I'd flag an exception MongoDB tends to be a little bit more of a general purpose database. For example, Redis is often just used for caching or kind of in memory, key value stores, right? So it's very specifically built for one use case. A lot of times, web apps will use Redis and a SQL database. Elasticsearch, as you could probably tell, is very often used for search and used for aggregations. So if you have, for example, a giant search component on your site, right, like the eBay search bar, for example, you might use Elasticsearch to make those searches efficient. Firebase is Google's product. It's kind of specifically good at real time, real time, and mobile, like mobile apps, right? And then DynamoDB is probably actually similar to Mongo. It's a little bit more general purpose, but it's AWS's kind of specific product for data at scale. Now I've done a lot of hand waving here, but the thing that I really want you to take away from this is that at the end of the day, an SQL database is just any database that can be interacted with using the programming language, structured query language, SQL, right? And any no SQL database is a database that just doesn't have that, right? It probably has its own kind of proprietary or specific query language that you'll use to interact with it. Just like any technology decision, when you're deciding which database to use for your project, you really need to kind of weigh the pros and cons of the database against your specific use case. That said, for most simple web applications or websites, something like Postgres is going to do really well, right? It's a general purpose database that can handle scale at a decent level as your application scales up and you understand more your specific needs, right? Maybe you need caching, maybe you need search. You can look at introducing other database technologies to your stack. So as we spoke about earlier, the big difference between SQL and no SQL databases is just whether or not the databases support the use of SQL, right? And that's what this assignment is talking about. And it really, I want to reiterate the fact that no SQL databases don't have all that much in common, right? For example, there's a bunch of no SQL document databases and those tends to have more in common with each other, right? MongoDB and DynamoDB, for example, are both kind of document stores and they're more similar than just like the whole group of all no SQL databases, right? Key value stores like Redis and Memcached are quite similar, but they're not similar to again, other no SQL databases like Mongo. They're kind of in a class of their own, if that makes sense. So the question for this assignment is each no SQL database tends to use blank query languages. And the answers are the same or different. And I'm going to say different because they're kind of all over the place. The next question on SQL versus no SQL is blank compatible databases tends to be more similar in their functionality than blank databases. So no SQL and SQL or SQL no skill. Well, let's see what makes sense here. SQL compatible databases tend to be more similar in their functionality than no SQL databases. So it's going to be that second one. Next question is which type of database always uses table structures, right? So SQL organizes data into tables, right? When we were writing our SQL queries earlier, we were doing select star from users, right? The user's table stores data, SQL assumes the existence of tables that we can select data from, right? No SQL databases don't always use that terminology. Don't even always use that way of grouping data, right? So it's just SQL that always uses table structures. I really quickly want to just compare a few of the popular SQL databases that are out there. You may have heard of Postgres, MySQL, Microsoft SQL Server, SQLite, and there are a ton of others. In fact, if you want to follow this link here, you can go look at really all of the, at least relatively wellknown SQL databases that exist, and there's more than a hundred. So let's quickly just compare SQLite and Postgres. So we're using SQLite in this course, but I do use Postgres in later web development courses on boot dev. I think they're both great databases. SQLite is sort of built for the embedded use case. So it's really great when like resources are constrained, maybe you need a database on like a mobile device, or if you're deploying say to the edge, right? Maybe if you're running a database, um, say hundreds of copies of your database on different edge servers distributed geographically around the world, SQL, SQLite can be really good for that. It's really good at being embedded within your application. So there are great use cases in production, even for SQLite, Postgres on the other hand is more of a monolith, uh, Postgres acts as a server itself and will typically be used for more traditional web applications that need to serve more users or at least operate at a larger scale. Right? So if you're storing massive amounts of data in your database, Postgres will be a better option most likely than SQLite. Postgres also just has many more features than SQLite, right? So if you're storing lots of data in a database and you need to do lots of complex things, Postgres is going to serve your needs a little bit better. And one of those features is kind of exhaustive type checking. So SQLite is pretty loosey goosey with types, right? You can specify types on your columns, but at the end of the day, SQLite will kind of just let you put whatever you want anywhere, whereas Postgres will enforce kind of more strict static type checking. To show you what I mean, let's jump down into the assignment. So it says, let's look at how SQLite does not enforce type checking. This within the create table statement, name is defined as a text field, right? Okay. So we've got this first statement, create table users. It's got an ID field that's an integer, a name field that is text, and an age field that is an integer. Next it's inserting two records into that table. ID name age values one John Doe and 21, right? So ID one name John Doe age 21. And then also inserting a second record into the table where ID is two, name is Montgomery Burns and age is 33. And then finally there is a select star from users table that runs. So let's go ahead and just run that code so you can see, see the output, right? Got this users table, got some data in there. So it says run the code and take a look at the results. We did that on line three, change the text string Montgomery Burns to the integer one and run the code. So this is what's kind of interesting, right? We're no longer putting text in the name field. We're putting an integer there, but it still works, right? SQLite just like doesn't care. Whereas Postgres would have actually thrown an error at us in this instance. This is notice how even though we define name as text, SQLite allowed us to use an integer like Python and JavaScript, SQLite has a loose type system. You can store anything anywhere. So to pass the assignment, submit the code in the altered state where the record with ID two has a name of one. Okay, cool. We'll just submit like this. So by now we're familiar with the idea of a table in a database, right? The table has columns and every new entry in the table is a row in the table, right? Each row, of course, having multiple cells, each with a value for the associated column, right? A table, a user's table might have ID, name, date of birth as columns, and then every new user would get their own row in the table. Well, now let's look at the SQL statement that we can use to create new tables. Okay, so we've got the create table statement. So create table and then the name of the table. So in this example, we're creating an employees table, and then we're specifying a few different columns that we want to create, right? An ID column that's of type integer, a name column of type text, an age column of type integer, and finally is manager, which is a Boolean and salary, which is an integer. This is kind of annoying to specify the create table statement horizontally like this. So there's a little more well organized syntax that we can use like this, where we kind of split it up onto new lines with some nice indentation to make it a little bit easier to read, right? But the takeaway here is that name of the table comes right after the create table statement. Then we've got an open and a closed parentheses, and inside we specify all the fields and their types. So let's jump down into the assignment and write some SQL. So the assignment says, let's begin building a table for the cache pal database, create the people table with the following fields. All right, so create table, going to be called people, open parentheses, the names of all the fields, we've got ID, which is an integer, then a comma to separate between the columns. You'll notice that I'm using the term column and field kind of interchangeably. In SQL world, column is definitely the more correct term. The reason you'll hear developers kind of, I don't know, slip up or use the terms field and column interchangeably is because once you convert a row in a database into a struct or an object, then within the programming language, you'd call that a field on an object. So for example, a person object might have an ID field. All right, moving on, we've got handle, which is text, name, which is text, age, which is an integer, balance, also an integer, integer, and finally is admin, is a Boolean. Then we end all of our SQL statements with a semicolon. Great. I'm going to go ahead and run that. And just so you're aware, this next SQL statement that's running after the create table statement just kind of dumps the information about the people table. So that's why we were able to get kind of this nice little description of the table that we just created, all the different columns we created and their types. That looks correct to me. I'm going to go ahead and submit it. Now it's extremely rare to work on a web application that only has one table. Most web applications are going to have many tables. They certainly have a table per entity. So for example, in a social media application, you might have a table for your users, a table for their posts, maybe a separate table for all of the comments on those posts, and then maybe even a separate table keeping track of all the likes on the posts, right? Well in our case, we're building a cash pal, which is a PayPal like clone. So we'll probably need another table called transactions. This is where we'll keep track of all of the payments between users. So create the transactions table with the following fields. So create table transactions, fields ID, integer, recipient ID, integer, sender ID, integer, note, text, and finally amount, integer, perfect, right? This makes sense. Every transaction is going to get a unique ID to identify that transaction. We'll also need to keep track of the recipient and the sender in every transaction, an optional note and how much money is being sent. Cool. Let's go ahead and run that. And that's looking correct to me. Now rather than creating a new table, let's talk about changing an existing tables. This would typically be kind of dangerous, right? If you have code that depends on a specific name of a database table, then it can be tricky to kind of swap the name out live. But if you're working with a toy database or maybe you haven't pushed to production yet, this is usually a pretty simple thing to get done. We have an alter table statement that allows us to do it. So for example, if we would just want to rename a table, then we can alter table employees, rename it to the contractors table, right? We can also rename columns by doing alter table name of the table and then rename column salary to invoice, for example, right? So the same alter table keywords are used for both altering the name of the table and the name of individual columns. And then if we're not actually renaming, but instead we're adding or deleting columns, we actually still use that same alter table keyword at the start of the SQL query. So alter table contractors, in this case, add column, and then the name of the column and its type, or just alter table contractors drop column and then the name of the column. So this alter table statement really gets a lot done for us. It's the latter half of the statement that really kind of describes what's going on. So dropping down into the assignment here, it says, we need to make some changes to the people table. At the moment, we have these five columns shown as rows so we can display data types. Okay, so these are our columns, ID, handle, name, age, balance, is admin. Rename the table to users, rename the handle column to username and add the password, text column. Okay, so we're actually gonna be writing a few different SQL commands here. And just to start, I'm gonna go ahead and run the code in its current state and it looks like the users table doesn't exist, which if we take a look at the setup code, we can see that this is kind of what's being run before our code runs. So this makes sense, right? The people table is being created and when we kind of dump the information on the users table, it's not there. Okay, so first thing we need to do is rename the table to users. So we'll do alter, able people and then I'm gonna double check our syntax up here. Rename to, rename to users and just so that you're aware, users is a very conventional name for the users of an application. You typically would not name all of the people that are using your tool in your database. You typically would not name that table people. In fact, I explicitly named the table people so that we could in this exercise change it to users because that's the much more kind of standard thing to do. So alter table people, rename to users, I'm gonna go ahead and run that. Cool, now we're getting closer to the right answer, right? We're at least getting this output that describes the users table. But there's a couple more instructions. Rename the handle column to username. Okay, so after this, we'll do alter table, now called users, right? Alter table users, rename handle to usernames. It's going to be rename column handle to username, okay? This one I've seen both ways. I wouldn't say there's necessarily a right or a wrong answer around handle or username, right? Twitter calls them handles. Most applications probably call them usernames, but it's not too important. And I would argue the more social your app is, the more likely you're probably going to call them handles. Okay, cool, let's run that. Now we can see that we've swapped that handle out for the username fields. That's looking good. And then add the password column and it should be of type text. So again, alter table users, add column, password type text. And let's run that. Cool, this is looking good to me. I'm going to go ahead and submit it. Good database migrations are kind of like unit tests in the sense that a lot of people don't actually do them very well, but like to walk around talking about how great they are. I am an aggressive unit tester. So if you're wondering what the hell I'm talking about, this video is for you. Let's talk about database migrations. Let's jump right into an example. Let's say that we have a users table in our database and you, the users table has a few fields might have an ID. Say users have a username, maybe a password anyways, let's say that we've deployed this application to production. So we actually have users, this table is being used in production by our web application. But what happens is now we want to add a new feature and the new feature requires a new field in the database. Turns out now we need to add a new field, call it birthday. The act of adding that field of adding a new column to the table. That is a database migration. Now this type of migration where we've added, add a new column or add a new table, it tends to be fairly safe, tends to be fairly safe. And the reason for that is the application that's been connected to this database and running queries, it didn't care about this birthday field before. It was never say, you know, querying, give me all of the users whose birthdays are before the state. It wasn't making those queries by adding a new field. It's very unlikely that we'll break anything by adding a new table to a database that's being used. Very unlikely you'll break anything because the current code simply doesn't care about that database table because it just didn't exist in the last version. On the other hand, let's say we do a migration where we remove passwords from the users table. Maybe we're no longer storing user passwords because we only support signed one with Google, something like that. These types of migrations, right, removals of data, remove, I'll just do RM, they're very dangerous. They tend to be very dangerous. So let's talk through some rules of thumb about how you'd approach migrations depending on if your migration is adding a resource like a column or a table, deleting a column or a table, or updating because this is going to change a lot, right? So let's assume that we're adding, we're adding a new column or a new table. This tends to be safe and so what you can do first to keep things simple is first you run the migration on the database. So you update the database, step number one, right? And by updating the database, you haven't broken what's currently running because you're just adding new stuff, right, again, generally speaking. Okay, number two, you'll update your code, right? Now you can deploy the new version of the application that actually uses those new fields or tables. Now let's assume that you're deleting a column or a table. The first thing you're actually going to do in this case is update the code, right? So presumably you're deleting a column or a table from a database because you no longer need it in your application logic, right? For whatever reason, you don't care about users' birthdays anymore so we're just going to go ahead and delete it. Well, first you need to update the code. Stop querying that resource, right? Stop querying that column or that table. Once the code has been updated, now you can safely update the database without breaking anything. Now let's talk about the thing that is by far the hardest. This is updating. Now generally speaking, you should try just to not update. And what I mean is changing the name of a table is generally speaking just a really bad idea, changing the name of a column really bad. Try to get those things right the first time. But if you do have to change it, just know that it's going to be more work and you need to be extra careful. Because keep in mind, when we're adding stuff, we can safely update the database beforehand. When we're deleting stuff, we can safely update the database after the fact. When we're updating stuff, there's really no safe way. I mean, think about it for just a second. You've got an old version of code that expects an old database name and a new version of code that expects a new database name. Really your only option is to make sure that you update both the database table name and the code at exactly the same moment in time. And it's really hard to make sure that happens. You're going to have probably milliseconds or seconds of downtime. So because this is a harder problem, there's not just a simple one to solution. I'm going to just give a few ideas of how you can approach updating the database. Approach number one is scheduled downtime. Downtime. This means you literally just turn off your application. You're like, look, customers, I'm sorry, you cannot access the application for the next 30 minutes. We're doing a big update to our database. I don't recommend that that kind of sucks, right? People want access to your web application. So this is like what you would do if you really feel like you don't have any other options. It's simple, but it does affect your customers. Number two is kind of what I described at the start, which is just a same, same time deploy, right? So we're just going to deploy the update and we're going to deploy the code at the same time. We understand that there will be kind of a bug there for a few seconds. But if you've determined that say you don't have any active users at the moment or a few seconds of issues, aren't really a problem and it's not worth doing anything more complex. I mean, I've seen companies do this. I wouldn't say it's a good idea, but it does get the job done. The best approach or the most robust approach is probably to copy, to copy the database or the database table, right? So we create a new copy of the table with all the exact same data. We can update the new copy's name to be the new table, right? And now we can safely deploy the new code that references the new table. There is a possibility of, you know, in the interim of you've done the copy and now you've deployed the new code that new records will be added to the old table that you would also need to copy, but that can also be handled, right? You can write a fairly robust migration script that copies data to the new table, deploys the code, makes sure it moves over any records that were added in the interim, that sort of thing. So copying tends to be very robust. It takes a little more work, right? You're writing a more, a more complex migration scripts to make sure that everything goes off without a hitch. Now, I know I just said that copying was the best approach and I may have misspoke there. There actually is a better approach that I'm aware of. I'm going to call it aliasing. The thing is sometimes aliasing is not possible. So there are certain databases that support an aliasing feature and some that don't. So it kind of just depends if this is available to you. But the whole idea behind aliasing is that you can give the table a second name. So your database table effectively has two names it can be referenced by. So what that means is your old code references the old name. You alias the table with a second name, so that can be referenced by two different names. The new code uses the new name, right, and then once you've safely deployed the new code, you can drop the old name from the table. That would actually be the best, the safest and the simplest approach, but it kind of depends on your database technology and what's available to you. These are just four options. These are the four that I've tended to use the most. Hopefully they help. And then I just want to reiterate that you shouldn't be updating names very often, right? Pick good table names, pick good column names, try to do ads and deletes and avoid a bug. Now, the last thing we need to talk about with database migrations are up, up and down migrations. Right? So we talked about the different types of migrations in the sense that you can add something, delete it, or update it. But realistically, any migration that brings us forward in time, we call an up migration, right? Our first up migration might create a table, right? And then our second migration might delete, I should say our second up migration might delete a column from that table, right? Our third up migration might create a new table, create another table. Now let's say our fourth up migration renames a column. And then maybe our last migration deletes, deletes a table. Okay, those are all up migrations. And in theory, the latest running or the current running version of our application, we'll just use the latest version of the up migrations. In other words, it will have run every single up migration in order to arrive at kind of the final state of the database, the one that's running in production. Now a down migration, a down migration is really just used to roll back changes in the case of emergency or in the case that something goes wrong. So you don't plan to use your down migrations. You just kind of have them as a backup. And frankly, this is why at the very beginning of the video, I talked about how people talk about great migrations, but oftentimes they don't employ them. Not every company has great plans for down migrations, just to speak frankly, it's more robust to have a great down migration so that you can roll up your database and roll down your database, bring it forward and backward in time. But it's a lot of work, right? So you won't necessarily always see teams that have fantastic down migrations, but let's just talk about what they'd look like. So a down migration is very simply just the opposite of its kind of related up migration. So when you add a new table, you might also log a down migration that deletes that same table. So delete table, here we'd have add column, right? We're just doing the inverse of the equivalent up migration. The third down migration would delete a table again, delete table. The fourth would rename the column back to whatever it was, right? It would invert this up migration. And then finally here, we would have an add table command. And that's a five. Why did I write six? There we go. Okay. So the theory is I can go all the way up to the latest version by running these up migrations in order. And if I need to go back a version, I can just run the equivalent down migration, right? So I get up to the latest and then I say, oh crap, I need to roll back to the last version of my database. I can just run this down migration number five to readd that table that I just deleted. So as we just talked about, database migrations can be pretty dangerous. They tend to be some of the more dangerous things that you do when working with databases. Like with all web development, the closer you get to the data, the more careful you have to be, right? Bugs that you push to production are generally pretty easy to revert and get the right code pushed out to users and get the bug fixed. When you mess up data, sometimes it can be harder to revert those changes. So you always have to be more careful when you're working with kind of the persisted data that sticks around in your database because sometimes just changing the code back to what it was won't necessarily revert the state of the file system in the database. This is a pretty solid meme regarding production databases. I've definitely been the dog in this situation. You don't want to be the dev that alters the production database and brings the site down. It's actually, it's not fine. Moving on. The question associated with this first lesson about database migration says, which of the following statements about migrations is false? So first one is you can be fast and loose when writing migrations. A bad migration is easy to fix. That is false. I'm going to read the rest of them just to make sure nothing else is even worse. Well written migrations are reversible. That's generally true, right? You can go up and you can go down. That doesn't necessarily mean you always want to be doing that, but they are reversible. A good migration takes into account any systems that rely on the existing schema. That is true. You need to make sure you don't have any active code that's relying on an old version of the database. Migrations are incremental changes made to a database. That is true. Okay, cool. So it is this one. You should not be fast and loose with migrations. They are not easy to fix if you get them wrong. The next question is will database migrations often be coupled with application code updates? And that is generally speaking true, right? You want to roll the database forward to a new version along with the new code that uses that new schema. The next question says why are good migrations written in a reversible manner? And the answers are they are not so that if something goes wrong, the changes can be rolled back or because you should always roll back changes before applying new ones. Well they are. Good migrations are written in a reversible manner, so it's not the first one. You don't always need to roll back changes before applying new ones. That's not how migrations work. Usually you'll add one new incremental migration and just roll that one forward. The middle one, so that if something goes wrong, the changes can be rolled back, that is the real reason. It's important to understand though that just by rolling back the schema changes doesn't necessarily mean you've fixed the data. So it just kind of depends on what quote unquote went wrong, but at least when you have good down migrations, you can bring the schema back to where it's supposed to be. So it's going to be that middle one. So we've talked about this a little bit before, but when you're writing reversible migrations, the term up and down migrations really are used to refer to kind of the chronology. So you'll put every new change to the database schema in subsequent up migrations, right? So your first up migration might create a new table, the next one might add a column, et cetera, et cetera. And every down migration has one associated up migration. Okay. Our assignment here where we'll be practicing with some migrations is to add additional columns to the transactions table. We want to know whether or not the transaction was successfully completed between two users. We also want to know, or we also want our database to track the type of transactions. So our transactions table looks like this at the moment, okay? Complete the up migration, complete the following up migration. Add the Boolean was successful column to the transactions table, and then add the text transaction type column to the transactions table. Okay, cool. So we'll be adding two columns, alter table transactions. Add column was successful Boolean, and alter table transactions. Add column transaction type, cool. Let's go ahead and take a look at that was successful Boolean transaction type text looks good to me. Let's talk about some data types. So as I've mentioned before, we're actually using SQL lite in this course. And the data types that are available to you kind of do depend on the specific database engine that you use it, right? So we're using SQL lite. And so you'll see types like null, which means nothing's there. And actually that is pretty ubiquitous. Basically every SQL database I've ever worked with supports null values. You've got integer types, which are, you know, all numbers that can also be negative, right? So negative one, negative two, zero, one, two, three, four, etc, signed integers, reels, this is your equivalent of like a floating point value or a double, depending on what programming language you're coming from, but basically numbers with a fractional part. You've got text fields, and then blobs, which are basically just like big blobs of binary data. And then the other thing to keep in mind when working with SQL lite is just that Boolean values false and true. You can use the kind of keywords false and true in your SQL, but when you get the data back, it will be represented as ones and zeros. I think the only other thing really worth pointing out at this point is that the text field is supported by most other large databases, think, you know, Postgres, MySQL, but they also have an additional type of text field called a varchar. And you would typically use a varchar if you know exactly how long your text field is going to be. Like say, you know, it's going to be 36 characters long. Like maybe you're storing, I don't know, password hashes or emails, and you know that there's a maximum length of emails. And the reason you would do that usually is for performance reasons. If you can tell the database, hey, this field is never going to store data larger than 36 characters, then the database can make certain optimizations to keep the database kind of fast in the file system, right? Keep your queries a little more performant. But SQL lite just doesn't deal with that, right? It's a little more loosey goosey with how it deals with data. And in case you're wondering why it's called a varchar, that's kind of shorthand for character varying, right? So varying amount of characters. But again, you would actually specify exactly how many characters when you use that type of column. So again, in this course, we'll just keep it simple, use the text type. So the question is, how is a true Boolean value stored and presented in SQL lite? And we've got the string true, the string false, one or zero. True is the Boolean value one. Next question presented as a statement says all SQL databases support the same data types that is false. Next question, what type would you use to store a user's email? Well, of these types, we've got integers, reels, texts, blobs, I guess technically you could like convert the email address to a binary number stored as a blob, or frankly even maybe an integer real if there's enough, if there's enough data there. But realistically, come on, you should be storing it as a text field if you're using SQL lite. Again, if you're using MySQL or Postgres, you might use like a varchar 36 or something like that. It's really important to understand null values in SQL because it's not necessarily the most intuitive thing you've probably ever encountered. So a null value indicates the absence of a value. So for example, if you have a column called username, and a row in that table has a cell that is the empty string, then technically that is a username of string length zero. And that's different than if you actually explicitly set the value of that cell to null, which is used to indicate that there's nothing there. So generally speaking, you want to prefer to use nulls rather than like empty strings or zeros or false in the case of a boolean value when you're trying to represent the fact that there's nothing here. It's probably worth mentioning that the idea of null in SQL is very similar to the idea of none if you're coming from the Python world or null if you're coming from the JavaScript world or mill if you're coming from the Go programming language. And one of the neat things we can do in SQL is actually set constraints on our database schema and say, we never want a specific column to be allowed to house nulls, right? So that protects us and says we'll never accidentally insert, for example, a user into a database without making sure that they have an email. Okay, enough about nulls and constraints, let's jump into the assignment. Because we didn't force any constraints on our tables when we created them earlier and it has allowed for null entries to make their way into our table. Let's take a look at our transactions table and see what those null values look like. Write a query to select all of the fields on all of the records of the transactions table. So select star, that's all of the columns or all of the fields, right? From transactions, let's go ahead and run that. And we can see, notice that there's a bunch of data just seemingly missing, right? That's because those cells have the null value in them and it looks like that's all we have to do for this assignment. So I'm going to go ahead and submit it. So we talked a little bit about constraints in the last lesson, but now we're going to actually use them and essentially a constraint is just a rule that enforces something about our schema, right? So again, for example, if we have a user's table and we want to make sure that we never accidentally insert a user into that table without ensuring that they have a valid email address, we could add a not null constraint on the email column. Now how do we actually define a constraint? So the constraint just comes after the type in, for example, a create table statement. So ID is the name of the column and then we have integer, the type, and then the constraint, right? So for the ID, there's a primary key constraint, which we'll talk more about later. We've got a unique constraint on the name. Again, we'll talk about that one later. And then here you'll see the not null constraint that we're putting on the title. Okay, let's jump into the assignment. It says, thankfully all of the tables we've created for cache palette to this point have been for testing purposes. Now that we have a better understanding of constraints, let's rebuild our database with the proper constraints and tables, create the user's table with the following fields and constraints. So we're going to need a create table statement table is going to be called users first field is ID. It's an integer type and the constraint is going to be primary key really quickly. Let's just talk about what the primary key constraint means. So a the primary key constraint means that ID is going to need to be unique for every new row. So if I add a user with ID one, and then I try to add another user with ID one, then the database should error and get mad at me, right, because they're not unique. So that's the first thing. The second thing that the primary key constraint does is that you can only use the primary key once on any given table, right? That's why we're calling it a primary key. So you'll most often see primary keys on some sort of ID column. One last thing worth mentioning that the primary key constraint does is that it is also it doubles as a not null constraint. So you can almost kind of think of a primary key constraint as both a unique constraint and a not null constraint. So we want to make sure that an ID is present on every single user record in this case. Moving on, we've got a name field, it's going to be text and it's just going to have a not null constraint. Right? So keep in mind, that means the name field can be the same on different rows, right? We can have two users with the same name, not a problem. We just can't have it missing, right? In this case. Okay. Next we've got age. It's an integer, integer, see if I can spell. It's also going to be not null. We want to make sure we've logged an age for everyone. Next we've got a country code. We want to know what country our users are living in. That'll be an integer. Oh, no. Excuse me. It's an age and it will be not null. Next we've got a username, also text. In this case it's going to be unique. Now the primary difference between unique and primary key is that A, you can use unique, you can use a unique constraint on multiple columns, so you won't just have one unique column. And also unique columns can typically be nulled. So that's not necessarily a problem. All right, I should capitalize this. Use proper conventions, so unique. Next we'll need a password, text, not null, and is admin going to be a boolean with no constraints on that one. Finished up with a semicolon. Let's go ahead and run that, see what we get. Sequelogic error near closing parenthesis. Ah, I have a trailing comma here that I do not need, run it again. Cool. So we can see the names of all the columns, we can see the types, and we've got, you can see the constraint here of whether it's not null, you can see the primary key there. This is looking good to me, I'm going to go ahead and submit it. So I already kind of did a spoiler of this exercise, but I'll go ahead and just kind of give you the rigmarole again. A primary key is a constraint that is effectively adds a not null, right, so you can't have null primary keys, you can't have duplicates, so they're effectively unique, and you can only have one primary key on a table. And most of the time, you'll see this a lot, especially in backend web development, most of the time you'll have an ID column on a database, and that column will be the primary key. Sometimes you might be tempted as a web developer to make a column like email the primary key, right, thinking to yourself, well, we don't allow any two users in our database to use the same email, so we might as well just make it the primary key and kind of use it as an ID. I would definitely recommend against this. It's definitely best practice to have a specific column called ID that is used as the identifier for that row in the database. And the main reason for this is sometimes business logic changes, right, maybe in the future you will allow users to have the same email address, and if you've been using that email address as a unique identifier all over the place in your code base or in your systems, it's really hard to undo that change. So just coming right out of the gate with, you know, we're going to put a unique identifier on every single row, and that's never going to change, that can save you a lot of hassle in the future. So let's hop down into the assignment. It says run the code and notice there's a bug, okay, let's run it. Constraint failed. Unique constraint failed. Users dot ID. All right, there's a violation of a primary key constraint on the ID column. Fix the data that's being inserted. When working with integers IDs, it's best practice to increment the ID by one for each successive insert. Follow this convention when fixing the bug. Okay, so if I look at this code, I can see there's two inserts happening, and it looks like the first insert is inserting a value of zero for the ID, and the next one is also using a value of zero. So to fix this bug, I should be able to just change this to a one. Cool. Now we've got two rows in our database. First one with ID zero, second with ID one, going to submit that. Next we've got foreign keys, right? So we just talked about primary keys, which are an ID on an individual table that kind of identifies every row in that table. A foreign key is just a key in a table that references the ID of another table. So it's really what makes databases relational, right? This is how we relate data in one table to data in another table. Now you don't technically need to add a foreign key constraint on a field in a table to make it a foreign key, right? Remember a foreign key kind of just references an ID in another table, right? So if I have a user's table and there's a user in there with ID four, and then I have my transactions table and it has a column called, you know, user underscore ID with an ID four, then it's, you could argue it's, it's referencing that other table, right? Just kind of inherently, however, there is an explicit foreign key constraint that we can add to fields. You can see that syntax right here. And the reason you would use that constraint is to ensure that when you're referencing a specific foreign key or I guess in your table, it's a foreign key in the table that you're referencing, it's, it's that primary key. But what it does is it ensures that that key actually exists in the other table, right? So when I create a transaction, say with user ID four, right? So my foreign key is a primary key of my user. So this transaction is for user number four, that foreign key constraint will make sure that in the user's table, there actually is a user with ID four. And if there isn't, then it will throw an error, right? So it's a way to make sure that my relationships actually exist in my database. This is one of those things that's kind of hard to understand in the abstract. So let's take a look at this example. So let's say we have a department's table. And each department has an ID, which is its primary key, right? So something identifying each individual department, and then it's got a name for the department. Great. And then let's say we have another table employees. Each employee also has its own ID, right? So keep in mind, we've got a primary key for both tables. Now employees, of course, can belong to departments. So we're going to store a department ID on the employee's table, right? This will tell us which department the employee is in. This is referencing the other table. Now, this is a foreign key, right? Because it's referencing the primary key of another table, but we're also going to add a constraint called foreign key departments in this case, right? We just name our constraint, technically, whatever we want, but it's nice to be descriptive. So foreign key departments. It's going to be a foreign key on our department ID field, referencing the department's table and the ID column from that table, right? So by adding this constraint, if we try to create a new employee in a department that doesn't exist, the constraint will come into effect and give us an error. Let's hop down into the assignment. It says our users table stores the country our users are from in a country code field. So we've got country code on the users table. We need some additional data about countries, like their name, but we don't want to bloat our users table with all of that country data. That makes sense, right? We want to keep country data kind of in its own table. The locations team at Cashpal has created a countries table, and we can link a user to their country by setting a foreign key in the users table. Take a look at the code. There's an issue with the insert statements again. Fix up the data so no foreign key constraints are violated. You'll need to reference the setup code below. Okay, so I'm going to take a look at this setup code. Looks like we're creating a users table with that country code, and then it looks like some data is being inserted into the countries table. Oh, and here's the create table statement for the countries table. So it's just got a code and a name. Okay, and then we'll have United States that's in the countries table, and we also have India codes US and IN. So let's go ahead and run the code in its current state to see what happens. Constraint failed. Foreign key constraint failed. Okay, so this first user is going to reference US. That should work, right? We have an ID of US here. That's fine, but here, ah, so we're inserting again into the users table, but here it looks like this was mistyped, right? It's supposed to reference IN as the country code for India, but it's got IND. So just removing that D should fix this up. There we go. So I've used this word schema a few times so far in this course, and I really just want to talk about what it means. Basically a database schema is just the shape that you're using to define your data, right? So for example, the number of tables in your database is part of your schema. The names of those tables is part of the schema. The names and data types of all of the columns in your tables, that's all part of your schema. So really a schema just tells you how is data organized within this database. Now it's important to point out there is no perfect database schema for your app. There's lots of different ways that you could model the data that makes your application run. You could pick one and there are a few rules of thumb for picking a good one, which of course we'll talk about in just a second. So get your database schema as best you can to model what's going on in your application. And honestly, my rule of thumb is try to keep it as simple as you possibly can while accurately modeling relationships. If you keep it simple, it's always easy to add complexity that adds functionality later. Whereas if you add a bunch of complexity up front, oftentimes it can be harder to strip back that complexity into simplicity down the road. So to start getting specific, we can use cash pal as an example. It says one very important decision that needs to be made is to decide which table will store a user's balance. As you can imagine, ensuring our data is accurate when dealing with money is super important. We want to be able to keep track of a user's balance, see the historic balance at any point in the past, and see a log of which transactions changed the balance over time, right? So to be able to essentially audit the balance as it changes, right? People are curious as to all of the transactions they've had in the past. So we need to make sure that we don't like overwrite that data or lose that data. There are many ways to approach this problem. For our first attempt, let's try the simplest schema that fulfills our project's needs. Again, we're always going to try to opt for simplicity first. So jumping into the assignment, it says the architecture team at cash palace decided on a single transactions table. The transactions table stores individual transactions, and we can keep track of the current balance on each transaction record. If we want the current balance, we just look at the most recent transaction. So create the transactions table with the following fields and constraints. All right, create, table, transactions, going to be an ID, integer, primary key, sender ID, integer, recipient ID, integer, memo, text, not null, mount, integer, not null. And finally, the balance, integer, not null. Now you might be wondering, I don't think I've addressed this yet, why we're using integers here for amount and balance instead of reals, which are like floating point numbers. And the reason is in financial applications, it's actually very common to store money as an integer and just store it in the units of like the smaller units. So for example, rather than storing our money in dollars and storing like $5.67, we store it as pennies. So when you have $5, we just store 500, right? You have 500 pennies. And the reason for that is floating point arithmetic has like rounding issues in computation, whereas integers don't have those issues. So if we just use integers, keep it simple, then we don't have any of those potential data integrity issues that you get with floating point numbers. I'm not going to go super into detail on all the issues you can get with floating point numbers. You can definitely go look that up. Let's know that that's why you'll see integers very often used in financial applications. Okay, now that we've written our create table statement, let me go ahead and run that. See if we get what we expect. This looks good to me, I'm going to go ahead and submit. So we've been using the term relational quite a bit throughout this course, but we haven't really talked about what it means. A relational database is just a type of database that stores data that can be related to other pieces of data, right? So in the case of Twitter, a user is related to their tweets, right? And relational databases are just databases that keep that in mind, right? They make it really easy to relate different entities between tables. So some properties of relational databases are data is typically represented in tables, right? That's how we've been doing it throughout this course so far. Each table has columns or fields that hold attributes related to that record, right? So in this image, for example, we've got a students table, and then there's two columns, the ID column and the name column or the ID field and the name field. Column is the more accurate database term, but you'll hear field used just because fields are often used in kind of more traditional programming, which is like Python or Go or JavaScript. Each row or entry in the table is called a record, right? So this first record in the student courses table, for example, has student ID one and course ID one, and then typically each record has a unique ID called the primary key. Now that's not always the case. That's why I say typically, so maybe nine times out of 10, you'll have an ID column on a table so that it's really easy to identify each unique record in the table. So let's answer this question. It says, how many courses is Sam enrolled in? So we've got our relational database here, and we can see that Sam is ID number one in the students table, right? So we're trying to figure out how many courses he's enrolled in. Well, let's look up the student courses table. We can see that student ID one, which is Sam, right? Because we have that relationship over here. We can see he's enrolled in three different courses, right? We have three rows in the student courses table. He's enrolled in course one, two, and three. So the answer is going to be three there. The next question is, how many students are in the MongoDB course? Okay, so this time I'm going to start at the courses table, look up the MongoDB course. I can see it here. It's got an ID of three. So looking at the student courses table, I can see there's three rows that reference the MongoDB course, right, with ID three. And I see students one, two, and three. So all three students are in the MongoDB course. So going to be three again. So we know what a relational database looks like, right? With tables and keys that kind of point to each other and reference each other to build relationships. The question is, what's a nonrelational database? And I mean, most simply put, a nonrelational database is just a database that doesn't support those kinds of complex relationships between data. And typically, when we're talking about like no SQL nonrelational databases, we're talking about databases that nest data. So rather than using keys to reference other data and keeping everything kind of nice and tight and normalized, which is a concept that we'll talk about more later, they just kind of lazily nest the data within itself, which does have benefits. So I'm not trying to say that nonrelational databases are always a bad thing, but it's important to understand some of the tradeoffs. So to oversimplify it, you can kind of think of a nonrelational database or most nonrelational databases as just giant blobs of JSON data, right? JavaScript's object notation. For example, if a user can have multiple courses, you might just add all of the courses to the user record. So for example, in this database, we've got one kind of top level JSON object, and then we have this key users, which holds an array or a list, a list of things, right? And in this case, we've got one user with ID zero, the name is Elon, and then we've got a nested list or nested array of courses. So we're actually storing each course on top of each user record, which means if we were to add another user to this array, right, like we add Bob, for example, and we want to put Bob in the biology class, we would actually need to store a copy of the biology class's information under the Bob record, right? So now instead of having one course and one user and having them reference each other, we have to have a user and their copy of the course, right? So it kind of, in some instances, creates data redundancy in the system. So here's a visual example, right? We've got in the relational database, we have a posts table and a comments table. And the posts will reference the comments or actually the comments will reference the original post. So every time you have a new comment added to the system, it will just reference the original post. Whereas in a non relational database, what you'd actually do is just have one posts table or whatever the database happens to call the kind of equivalent idea of a table and you just nest all of the individual comments within each post. So in this case, it probably is fine, right? Because a comment can't really be a comment on two posts, most likely. But it does get to be more of a problem when you do have those many to many relationships that relational databases make really easy. So the question says, relational databases typically blank duplicate data, while non relational databases often blank duplicate data. So do duplicate data or do not duplicate data. And typically relational databases are very good about not duplicating data. So they do not duplicate data. Whereas non relational databases or no SQL databases kind of are okay with duplicating some data, again, usually with some sort of trade off and we'll talk about some of those trade offs later. The next question is non relational databases connect similar entities by using blank got nested data, keys, lover and concurrency. And the answer is nested data. And I will point out that this question should probably be a little more loose and say typically connect similar entities by using nested data because there are no SQL databases that do allow for more complex. Well I should say there there are other alternatives aside from just nesting data. In fact, some non relational databases are so simple that you couldn't even nest data in them if you wanted to write maybe they're just very simple key value stores. So just kind of keep that in mind. Let's talk about CRUD or C R U D which stands for create, read, update and delete. These four operations really are the bread and butter of all things data, all things databases, right? And HTTP and CRUD map very well to one another. So your typical backend web server in like a very standard web application will often be referred to as a CRUD server because it very simply maps HTTP requests to database operations. So for example, an HTTP POST request will very often create a new record in a database. Whereas an HTTP GET request will perform a database read, an HTTP PUT will update something and an HTTP delete will delete something. So in the simplest web applications, again, your server is really just reading an HTTP request and kind of deciding what it needs to do to the database. Just need to create, read, update or delete. So moving on to the assignment, it says we've created a table for you called CRUD. It's a toy table that we're using for interview practice at cashpal. Determine which SQL command can be used for a read operation and use it to read all of the fields in all of the records in the CRUD table. Cool. So this is just going to be a select star from CRUD. Let's run that. Cool. And you can see here, it looks like the table is filled with those mappings of HTTP methods to in this case, actually database keywords. So read, select. Yeah, makes sense. I'm going to go ahead and submit that. We've done a lot of selecting so far and we've done a lot with schemas, but now it's time to look at how we can insert data into a database. So there is in fact an insert statement and it looks like this. So insert into table name followed by a list of fields and then the values that we want to insert into those fields or insert into those columns. The assignment says, let's start manually adding some of the records to our users table. Take a look at the create table statement in the setup code below for the users table structure and use that information to insert the following records into the table. Okay. So we're going to be inserting record one and record two. Let's take a look at that schema here. So we've got this create table users. Okay. We can see what columns are available to us. It looks like we need to write our insert statements here. So insert into users. Then we need to do the names of the columns we want to insert into, I'll actually put this on a new line. So it's going to be ID, name, age, country, code, username, password, and is admin. And it's going to be values and then all the actual values we want to add, so values. And one, David 34, us, David dev, the username, insert practice is the password and is admin is false. And we ended up all with a semicolon. Oh, okay. So just to be clear, order matters here, right? So the first key I'm passing into this insert statement is the ID column, which means the first value needs to be the ID value. Make sense? Cool. And we have one more record to insert. The good news is all of column names are the same. Now we just need to change them with values. So it's going to be ID two, name, Samantha, age 29. Looks like she's in Brazil, username, Sammy 93, password, adding records, and is admin is still false. Cool. Go ahead and run that. Seems to have worked. I'm going to go ahead and submit. Let's talk about how data flows through your typical web application. So take a look at this diagram here. We've got the front end of our web application. In this case, looks like it's a mobile device or a mobile app. We have the backend web server, which is what we as backend developers are primarily responsible for coding up. And then we've got the database, right? Maybe SQL light postgres, my SQL, whatever. And the way that these three things typically communicate with each other is that the front end communicates with the backend over HTTP. So HTTP get requests, post requests, but delete, whatever, right? And the backend server commit communicates with the database itself using SQL. By the way, I want to point out if you've gotten this far in the course and you're hearing me say HTTP post, get, put, whatever, and you're not understanding what I'm talking about, I do have an HTTP course that I'd recommend you take before this course. So you might want to pause your progress on this course, go look up my HTTP course, check that out, and then come back. So just so you're aware, I'm kind of assuming that you understand at least the basics of HTTP requests as they relate to web development. Cool. So the front end processes some data from user input, maybe a form is submitted, right? Maybe a button is clicked, whatever. Front end sends that data to the backend via an HTTP request. And then the HTTP request is kind of converted into a SQL statement and the backend server sends that to the database, right? So let's take the example of a new user is registering. So the new user enters an email, a password, clicks a button. The front end sends a post request to the database with the new username and password. The excuse me, let me, let me rewind that just a second. The front end sends a post request to the web server, an HTTP post request to the web server with a username and password. The server takes that username and password from the post request, converts it into an SQL statement and executes the SQL statement against the database, right? Probably inserting a user record. If that operation succeeds, then the HTTP post request will be responded to by the web server and the front end will get a happy 200 okay response code. So the question here is a front end typically communicates with the database directly to add new records. And then the answers are false and true. No, it is unusual for a front end to interact directly with a backend database. There are exceptions here. It can be the case that the front end application is actually running a database locally, right? For example, SQL light is very often used as kind of an embedded database. But that doesn't work if your application wants to store data on the cloud, for example, right? That would be like a local only application that would do something like that. So in your typical kind of web application architecture where data is stored on the cloud and kind of travels across devices, the front end won't often, will not often communicate directly to a database. So this is false. The next question is the create in CRUD maps to which SQL statement and HTTP method. And it's going to be, well, in SQL, it's an insert, right? That will create a record. And in HTTP, that would typically be a post. Let's talk about the auto increment keyword. So the auto increment keyword in SQL is a feature supported by most SQL databases that effectively allows you to automatically increment the values in a given column. So for example, this is most common with an ID column. So you have an ID column that is integer primary keys, right? So every new, say user in your database, you want them to have a new ID and you want to increment by one every time. So let's just say that you've got this user's table, it's got its ID column, and you've got four records in the database and they have IDs one, two, three, and four. What the auto increment keyword allows you to do is when you insert that fifth record, you actually don't have to specify in your SQL statement that its ID is going to be five. You can just say, hey, please auto increment this column, and the database will automatically check and say, oh, I'm already using IDs, you know, one through four. So this new record is going to have ID five. That's useful because it means when you insert a new record, you don't first have to do a database read to check which IDs are available or which ID you should use next. Now quickly, before we jump into the assignment, I do want to call out that while this paradigm of using an integer ID that auto increments is fairly common, you'll also see a lot of UUIDs out there in the world. And to summarize, a UUID is basically a randomly generated ID, right? So instead of every record having an ID that just increments by one number, you'll be generating a very large random number as your ID for every record. And again, the nice thing about that is you don't have to do a read before you do an insert because you can just kind of generate a huge number randomly and be fairly confident that and when I say fairly, I mean extremely, like it's essentially mathematically, it's nearly impossible to have duplicate UUIDs because there's just so many possible combinations. But that is something you'll see out in the wild. We won't be doing them here. If you want to go Google UUIDs, please do so. They're very interesting. Those are kind of the two main ways that I've seen primary key IDs handled in production databases. So jumping into the assignment, it says, let's add some more records, but allow the database to automatically increment the ID field, add the following records to the database. Okay. Straightforward. And the interesting thing to note here is that it says SQL lite or in SQL lite, an integer ID field. So if its name is ID and it has a primary key constraint, it will automatically auto increment by default. So in some databases, you actually do need to like specify auto increment in the table creation, but you can see down here in the setup code, there's actually no auto increment keyword added to the ID column. SQL lite is just doing it by default. So go ahead and get these records inserted. This is the state of the database at the moment. Right? You can see in the setup code, it's inserting a bunch of users ahead of time. We need to write our own insert statement. So insert into users and we've got name, age, country code, username, password is admin. Again, we don't need to use the ID column because it will be done automatically for us. So let's use lance 20 us, there's a username, there's a password and then is admin is false. Need another one of these. This time we've got Tiffany 28, she's in the US username, auto increments, keeping, keep in mind auto increment is just, just happens to be Tiffany's password. And she is an admin and go ahead and run that well, and you can see that it automatically used ID seven and eight. This looks good to me. Now at this point in the course, you might be wondering, gee, this seems really inconvenient. Every time I need to insert something into my web applications database, I have to go manually write some SQL to do it. Uh, no, that's, that's not how it works at all. When you're sort of just poking around through your applications database, maybe trying to figure out what the schema looks like, maybe just doing some research, trying to figure out, you know, how many users your applications has at that point, you will just kind of be manually doing SQL queries, right? You might have some SQL client like PG admin. If you're using Postgres or SQL workbench, you'll probably just be writing manual SQL queries connected to your database. When you're actually writing backend servers, you probably will not be writing one off SQL statements. Instead, what you'll be doing is writing SQL, but using kind of dynamic interpolation to inject values into the SQL. Let me, let me show you what I mean. So here's some go code, for example, that you, I don't want to say that you'd see this in production because there's actually safer ways to do this, but I think it gets the idea across. Here we've got an SQL statement, right? Insert into users, name, age, country code, values, and then you'll see we've got these dynamic placeholders percent S, percent B, percent S. In go, these placeholders will get replaced by whatever these values are that come afterwards. So the user's name, the user's age, and the user's country code. So this is more like what you would see in a production application, right? You've got some SQL, but it's being dynamically generated either by your programming language or by your programming framework. And I also just want to overstate that you probably won't see something quite this simple, right? In go, you probably won't just see fmt.sprintf. If you're coming from the JavaScript world, you probably won't just see a template literal with values injected. And the primary reason for that is because there's this whole area of security concerns called SQL injection, where basically, depending on what those dynamic values are, people can actually kind of hack your query and cause your query to do things that you didn't intend. The good news is that basically every library, any good library that allows you to connect to a production database should handle SQL injection for you. For example, in go, the standard library's database SQL package handles this for you. So you will see something that looks like this, but there's probably a specific method or function that you'll be calling that handles potential SQL injection for you. So the important thing to take away from all of this is just that your SQL statements will likely be generated dynamically in your programming language. So question here. Every time someone creates an account on boot.dev, Alan or Lane has to manually add them to the database by hand by writing a SQL query. That is false, right? We've automated this whole process in our backend server. Next question is within backend systems, SQL queries are typically blank, generated by code or written by hand. So I mean, to be fair, like this template is typically written by hand, but then the kind of end query that's running against the database is generated by code. So I'm going to go with generated by code on this one. It's often useful to get the count of the records in a table rather than just getting all of the records in a table. So we can use a select statement to get a count of the records. This can be useful when we want to know how many there are, right? So here's an example is SQL light, select count, which is actually a function of star from employees. This can actually be kind of weird the first time you read it, right? Why am I selecting a count of star or a count of wildcard? Well, in reality, the count function takes field names, right? So you can count on individual fields or individual columns, but if you just want to know the total number of rows, then you can just use a wildcard to say, I don't really care about which column I'm counting. So the assignment says, here's the current state of our users table. Cool. So we've got eight different users, a bunch of fields, whatever. It says our base, our business strategy team at cashpal wants to know how many users of the app we have. We can't use the ID number to calculate the count because user accounts can be deleted, right? So maybe one day John is deleted. We can't just look at the current ID because Tiffany would still have ID 8, even if we deleted John, right? We'd just be missing kind of a record for ID 3. So we need to use account statement to retrieve the number of records in the users table. Let's go ahead and write that. So select out star. And again, star is referring to column names, but I don't care. I'm just trying to get the total number of rows. I don't care, you know, whether a name is present or a name is not present, I just want total number of rows. So we'll use the wildcard. Let's let count star from users. From that, count star 8. So earlier we talked about how a create operation flows through the architecture of a web application. But now let's talk about a read. So again, we've got our front end, our backend server, and our database here in the diagram. In fact, let me grow this just a little bit. The first thing that happens when we want to do a read is that the mobile application will send probably an HTTP GET request to the server, right? By convention, that's a pretty common way to do it. At that point, the backend server will fire off a select statement to the database, right? What it gets back from the database are a essentially a table of rows, right? And it will parse that table of rows and do some sort of conversion into something that it can send back in the HTTP response. Very often it will be a JSON object. So that's that's pretty standard operating procedure. This is not how it has to work. This is not the only way web applications are built. But it is a very common convention, especially for restful APIs. So the question here is the HTTP method that generally corresponds with a SQL select statement is an HTTP blank. We've got patch, update, get input, and it's going to be a GET. Next question is which happens first, a select statement is executed, a GET request is made, or a JSON response is sent. And in this case, it's going to be a GET request is made. That's the very first thing that happens, right? We can't execute a select statement until the front end makes a GET request can't send a response till we get the request in the first place. Let's talk about the where clause. So you'll see the where clause all the time. In fact, it's actually pretty unusual to make a select statements in SQL without using a where clause because the where clause allows us to filter down the data. And unless your database only has like eight rows in it, which would be pretty crazy for a production database, you'll probably want to filter down your result set. So what does that actually look like in syntax? Well, here's an example. Select name from users where power level is over 9000, or I should say, greater than or equal to 9000. So this will return all of the rows from the users table, sorry, it will return the name column or the values in the name column from the users table, where the power level, which is a different column, right, not the name column, but the power level column is greater than or equal to 9000. So the assignment says we need to know the username of all of the users in our users table that have admin privileges, retrieve them. Let's start with something simple. Let's do select star from users. I'm going to go ahead and run this. And this will just allow us to see our full, our full data set, right? So this is just everything in the users table. Now, we want to filter down to just the rows, just the rows where the user has admin privileges or there is admin flag assets too. So I'm going to go ahead and say select star from users, where is admin is true. Go ahead and run that. It looks like we've properly filtered down the result set. The last thing is it says we just want the username. So I'm going to change this star username, I would expect just to get Alias and Tifaroon. Cool, let's submit it. We already know what a null value is, but now let's talk about how we can filter down to either just the null values or maybe ignore the null values, right? So there's actually two special ways to deal with null values in SQL. You've got the is null syntax and the is not null syntax. So for example, select name from users where first name is null, right? Or is not null in the other example. The assignment says the way we store transactions at cache pal is interesting. We store a user ID field on the transactions table. That user is the owner of the transaction and a user ID is never null. Whenever the owner of the transaction receives money, the sender ID will not be null. So let's think about that for a second. So you've got a transaction with a user ID. So that user owns this transaction. If they are the receiver of money, the sender ID will not be null because it will include the ID of the sender, right? So when the sender ID is not null, we can see who sent the kind of owner of the transaction the money. And then the opposite of that was also true. If the owner of the transaction is the sender, then the recipient ID will not be null because that ID will point to the receiver of the money. Start to make sense? All right. So select all of the rows from the transactions table where the owner of the transactions is receiving money. Okay. And I'm just going to look at the setup code. So transactions, we've got an ID for the transaction, user ID, recipient ID, sender ID, and amount. Okay. So select star, right? So select all of the rows from the transactions table where the owner of the transaction is receiving money. So select star from transactions where if they're receiving money, there needs to be a sender, right? So where sender ID is not null. Run that. Cool. And as we'd expect, the recipient ID on these is null because the user is the recipient. So let's go ahead and submit that. Let's talk about deleting now. So when a user deletes their account on Twitter or deletes a comment on a YouTube video, that data actually needs to be removed from those respective databases, right? So when you delete your tweet, we need to actually go purge it from the database, right? The Twitter database. In SQL, there is a delete statement. Looks like this. So delete from table name, and then optionally, you can say where something equals something or you know, where something is greater than or less than or whatever, right? But the point is delete from table name is kind of the different thing. A couple of things I want to point out here, if you just do delete from employees, that will delete everything in the employees database, right? So for example, if I just do delete from users here, everything's gone, right? That's like super dangerous. So when you're working with a production database, be very, very careful with your delete statements. You do not want to delete the data when you're not intentionally trying to delete the data. The difference between delete from users and delete from users where ID equals three is a huge difference. This will delete one user, whereas if I remove that where clause, that just says delete all users. In fact, a rule of thumb that I just personally have is anytime I'm going to run a delete statement against a production database, I always run it as a select statement first, just to make sure that I got my where clause right, right? Just to make sure, and I can kind of see everything that's going to be deleted by running a select first. So again, when you're working with production data, run a select, see all of the stuff that you're going to delete, and then just change it into a delete statement and run that. Okay, the assignment says, Samantha, one of our cache pal users has opted to delete her account and stop using our app, which of course makes us sad. Anyways, we need to remove her record from the database. So delete Samantha's record from the user table. This is what our users table looks like at the moment. So it looks like Samantha has ID two. Now something to point out here. It just so happens that we could write, we could write this SQL query, delete from users where name equals some man thought, okay, we could run this. In fact, let me run it and it works, right? Samantha's gone. There's a devious little problem with this, right? It's very likely that if our app is popular, that there's many Samantha's in the database. So this is actually a really bad query to run. You could potentially delete 20 different user records, all of whom are named Samantha. So generally speaking, if you know you just want to delete one record, use the primary key. So we're going to do where ID equals two. This is much, much safer. We're guaranteed to only delete the row we care about. So I'm going to go ahead and submit it in this form. The wisest senior developers are the first to admit that their code base is a flaming pile of bug ridden garbage that has somehow survived in production as long as it has. So because you and your team are always just one bad commit away from wiping out all of your customer's data, don't you think it would be smart to back up your production databases? So let's talk about how you would actually set up database backups or how they work is probably a more accurate way to put it. So here we've got our production database, right? And every day new data is being added to the production database. And so naturally we're concerned, right? We want to make sure that even if something catastrophic happens, if this database gets deleted, if some bad code gets pushed that wipes out all of the rows in the database, right, that we have a way to restore the database. So one very common strategy is just kind of snapshot the database, let's say daily. A lot of companies I've worked at kind of just do daily snapshots. So for example, every day at midnight, an automated task runs, right, there's some code running on the server that copies all of the data out of the production database and into a snapshot for the day. So we'd say prod database copy, you know, May 1st, 2023, something like that. And that data is going to live in cold storage somewhere. It's going to be very cheap. We're going to shove it into a flat file system. We don't need to be able to access this data kind of live from our application, right? So kind of technically speaking, this might live in something like an Amazon S3 bucket or a Google cloud storage, cloud storage bucket, right, so very cheap storage, the idea being if something goes wrong, we can always kind of restore from this backup back into our prod database, right? It's not being used live, it's just it's just a backup. And then of course, the next day we would take, let me change colors back. The next day we would take a new snapshot and name it prod database copy, May 2nd, 2023, right? You get the idea. We're taking snapshots daily. And then usually what would happen is we'd only keep the snapshots for a certain amount of time, right? We might take a snapshot every day, but only keep them around for a month. So once we have a month's worth of snapshots, we start deleting the old snapshots, just so we don't need to store all of that data forever, because that could start to get expensive. Now you may have already noticed there's a problem here, right? If we're just taking a snapshot every day, that means that we take our snapshot, more data is added to the database, and then something bad happens. If we restore from that last snapshot, we're actually going to lose whatever happened in the last, you know, five or six hours since that snapshot was taken. So like the simple way to solve this or to mitigate this would be to, instead of doing daily snapshots, you could do hourly snapshots, right? You still have the same problem, but now you have it at a smaller scale. You'll never lose more than say 59 minutes worth of data. Now it's worth pointing out that for most small companies, this snapshot at a, you know, hourly or kind of daily rate, um, is fine, right? You hopefully don't lose your production database anyways, but if you do, you're only going to lose a couple hours of data. It's probably not mission critical. Your business probably won't go out of business, right? And this is a very simple thing to set up, right? Most cloud providers of databases, things like Amazon RDS or Google Cloud SQL have literally just a button you can click to set up automated snapshots. So if you're working at a small company or on a small project, snapshots are probably the way to go. Let's talk about kind of a more robust option. Say you can't afford to lose any data. What you might do in that case is, I mean, you'd still have your, your prod. Let me, let me make this a little bit bigger. You'd still have your prod database, but now instead of taking hourly or daily snapshots, what you might do is anytime a change is enacted on the prod database, you might set up a system where that change is copied to some, to some append only log, append only log, right? So for example, if you create a record here, you would also in the append only log, log the fact that you created the record. Similarly, if you then delete a record, keep in mind, when you delete a record in the prod database, it's just gone, poof, right? But in the append only log, you would just log that you deleted a record. So log that record was deleted. The difference is in the append only log, right, we still have, we still have the log of the record being created. So we could kind of go back and replay that record creation event if we need to. So this kind of a system is frankly a bit more complex to set up, a bit more expensive to set up, but can give us a little more granularity and robustness in the sense that we won't ever lose any real time data. And I quickly just want to reiterate the fact that for most companies, especially smaller companies, the snapshot update works just fine, and you only kind of venture into this more complex set up if you really needed to. So we already touched on this briefly, but deleting data can be really, really dangerous, right? If you delete stuff that you didn't want to delete, you'll be sad, right? Especially you don't have any sort of backup strategy, you know, set up. So we've already talked a little bit about some of the different backup strategies. Just know that there's really two high level things that you want to think about. The first is, one, make sure that you have a backup strategy for any production database, right? Make sure that you're at least taking snapshots at regular intervals, right? So that, you know, if something goes catastrophically wrong today, you can at least restore the database to what it was yesterday. Yes, some people will lose their data, and that really sucks, but it's not as bad as losing all of the data in the application for all time. So definitely have some sort of backup strategy. Number two is sometimes you will want to do soft deletes. And a soft delete is just where instead of taking a snapshot of the entire database, you just never delete stuff from the database. You never run a SQL delete statement, and instead you just mark records as deleted, right? You have like a deleted at column on your database table, right? And when something is deleted, you'd like set that timestamp to the time that it was deleted at. And then later when you select data out in your application logic, you just like ignore stuff that's been marked as deleted. So this makes it so you never actually delete anything. Applications do this. The only time you really need to be wary of doing this, I mean, there's actually two things. The first is it adds a lot of complexity to your application, because now you have to actually like be filtering based on this deleted at flag. So it actually is more work to do it this way. The other problem is you potentially have like GDPR or privacy concerns, right? Because now when your users delete their accounts, their data is not actually being deleted from your database, which again, like from kind of an ethical privacy standpoint might not be what you want. So just some things to keep in mind. Okay, the question says, you should have or you should blank have automated backups being taken of a production database, answers are sometimes never almost never or almost always, it's going to be almost always like please, please have backups. Next question says, a soft delete is where you blank, delete some data, but it's not actually removed from the database for 30 days, delete data from a snapshot, mark a row as deleted instead of actually removing the data, or delete some data by asking your database in a very nice soothing voice, usually with a please. It's going to be marking a row as deleted. Soft delete, mark it as deleted, don't actually remove the data. One last thing I forgot to say about soft deletes is just like it can potentially be expensive in the sense that like, if you have a very large database table and say like 90% of the data is deleted, if you're keeping it around and just having it marked as deleted, your queries might start to get slow, even though you've deleted a lot of data. So you know, soft deleting will never like make your database faster due to like decreasing the amount of data in it. So just of course, just another thing to keep in mind. Let's talk about updating data. So we've talked about creating new rows in a database, talk about reading them, we've talked about deleting them. Now we're going to talk about updating existing rows, right? So maybe we just want to swap out one specific field or one specific column on an existing database row. In SQL, we do this with the update statement. So the update statement looks like this, update employees. So literally just update and then the name of the table, set, and then a comma separated list of column names and their new values, and then an optional where clause, right? So in this case, update employees, set job title to backend engineer, salary to 150,000, where ID equals 251, right? So we're updating one employee. We're giving them a new title, a new salary. Great. Okay. Let's jump into it with the assignment says we need to update Lane's record in our user table. He founded cache pal, but he's not even recognized as an admin update Lane's record within the users table so that the is admin field is set to true. Here's the current state of the users table. Okay. So it looks like Lane has ID nine. And currently he is not an admin. So update users set what's called is admin true where ID equals nine. Now again, important to point out here, I could say where name equals Lane, but if we have other lanes in the database that we don't want to be admins, then that's going to capture them as well. Right? So, you know, be as specific as you can be with your where clauses so that you don't run into any of those sorts of issues. Let's go ahead and run that. And you can see that the record is updated. So I'll go ahead and submit it. I want to briefly touch on the idea of an ORM object relational mapping. If you're not new to web development, you'll almost certainly have heard of ORMs or maybe even used one before, basically the, an ORM is just a library that makes it much easier to interact with a database. And even more specifically, the whole idea of object relational mapping is to map kind of our inmemory representation of some object or some struct or some record, map it to the database schema that we're using, typically the table, right? So for example, we might have in Golang a struct called user, and a user has an ID, which is an integer, a name, which is a string, and is admin, which is a Boolean, right? And this is Golang code, right? If we're using an ORM, then what we might be able to do is just create an instance of a user, right? ID 10, name, lane, is admin false, and use some sort of method or function like database.create, give it the user, and it will just kind of automatically generate the SQL that will run that insert statement, right? So generate an insert statement and execute it against the database. This is really convenient, right, because it means we don't have to worry about writing all of the raw SQL, we can kind of automatically map objects in our programming language to rows in our databases. There are good and bad things about ORMs. I would argue that generally speaking, you'll want to use an ORM, as long as the ORM makes it easy to also write straight SQL, right? So you still get this escape hatch where you can do very specific and very, I don't want to say complex, but more advanced things with your SQL, right? Sometimes very simple functions like create, update, delete, will get you really far, but later you'll need to write more complex queries, right? Things that we'll cover later in this course. And if your ORM is limiting you from using the full flexibility or the full power of SQL as a language, then that can be a disadvantage. So to like sum up and give you a rule of thumb, an ORM typically trades simplicity for control. And again, in production, what that often means is you will use an ORM for most stuff, and then occasionally you'll need to write some raw SQL when you're trying to do something very, very specific. Cool. The question here is, when using an ORM, you blank, call methods and functions made available via the ORMs API, or you write a lot of raw SQL. And the answer is you call methods and functions made available from the ORMs API. Next question says, one advantage of an ORM is that it blank, gives you more control over your database, is easier to debug at a low level, makes your code less verbose, or ensures faster queries. This isn't actually, this is actually interesting. The answer is that it makes your code less verbose, right? You don't have to write nearly as much code when you're using an ORM, you just call some function or some method that's been rebuilt for you by the library. So it does make your code less verbose. However, I do want to point out that it does not give you more control over your database. In some cases, it actually takes control away. It's also not easier to debug at a low level, because if you want to figure out what SQL is being run against your database from this method, you're going to have to do some digging, right? So you're just looking at your code and, you know, fixing your SQL. Also ensures faster queries, again, not necessarily the case, sometimes, especially when your ORM code starts to get a little hairy, it can really generate inefficient SQL, which again can be hard to debug. So there's trade offs with ORMs, I'm definitely not going to say they're bad or they're good, use as intended. So should you use an ORM? Almost always, it depends on the project slash team, almost never, always. I'm going to go with it depends on the project slash team. There are instances where an ORM makes a ton of sense and there are instances where it doesn't. Moving on, let's talk about aliases. So there is an AS keyword, AS AS, in SQL that allows us to essentially rename different words in our SQL queries, and we would typically do this to make the query a little bit more concise, easier to type, less verbose. And it's important to understand that these aliases, they only last for the duration of the query. So really the convenience they provide is just for kind of within the SQL itself. It doesn't persist, it doesn't get saved to the database or anything like that. It's really just to make writing the query itself a little simpler. Let me show you an example. So let's pretend that we have two columns, employee ID and employee name on an employee's table. Now, first of all, I would argue that this naming scheme isn't very good. I would have preferred to just see an ID column and a name column, because remember these columns are on the ID's table, so it's pretty obvious that it's an employee ID and an employee name. So you kind of have some redundancy here in the column names. But either way, let's just assume that this is the schema we're working with. What we can do is alias the employee ID column as just ID and the employee name column as just name. That does two things. It means that later in the query, we can refer to those columns as just ID and name, right? So it makes writing the SQL a little simpler. It also means that when the data comes back from the database, like the literal rows that we get back from the database, the keys for those columns will now be ID and name instead of employee ID and employee name. So kind of useful from a structuring the return data standpoint as well. So let's see what this looks like in an actual assignment. Let's write some code. It says, a user has asked us to find all the transactions on their account from their grandma. We thought it would be fun to rename the note field to birthday message because we noticed all the transactions from grandma just happened to be birthday messages. Return the amount and the note field, renamed to birthday message from the transactions table where the sender ID is 10, which is grandma. Okay, I'm going to show the database setup codes so we can see what we're working with here. All right, so return the amount and the note field. So select amount note from transactions where sender ID equals 10. Now if I just run this as is, this is what I get, right? The key for this column is amount. The key for this column is note, and then we've got the amounts and we've got the notes. But we've been asked to rename the note field to birthday message. So we'll do note as birthday message. Now the only difference here, again, well, I should say there's two differences. This now means that later in the query, we can refer to the note column as birthday message, but we're not going to do that because we don't care in this query, right? We don't need to use, we don't need to like write a where clause using the note column. So we don't have to worry about that. But what it should do is also change that key in the return data, right? So now when we parse these SQL rows in our application, we'll parse this column as birthday message. Cool. I'm going to go ahead and submit that. Let's talk about functions in SQL. So remember that SQL is a language and like most programming language, it supports functions. So in SQL, functions look very similar to functions that you've used in other programming languages. And when you call them, you use parentheses and you pass in some number of arguments, right? So in this case, we've got the IIF function, open parentheses to start passing in parameters, and then we're passing in 123 parameters. And then we're closing the function call. Now you might be wondering what the IIF function does. Well, the IIF function is essentially a ternary, if you're familiar with ternaries from JavaScript. And basically what it says is, first, give me a condition. If the condition is true, I will return the first value you give me. But if the if the condition is false, I'll return the second value, right? And actually, if you look closely, there's actually a slight bug here, because if these two values are the same, then it will return the string car B is bigger. So this would probably say car B is greater than or equal to something like that. Anyways, irrelevance. The point is, you get how this works, right? Conditions true, we return the first thing conditions false, we return the second thing. So IIF can be really useful if we're trying to like compute something based on some conditional. So when would I use this kind of a function? Well, let's take a look at the example. Let's say we have a product table, and we want to return kind of how many we have of each product, right? So say we've got, I don't know, 10 apples and 30 bananas in stock, right? We want to return the the sheer amount that we have. But we also want to return a little text string that that's a little more descriptive, right, that can be computed from the quantity itself. So in this case, we're saying if the quantity is less than 10, we're also going to return the string or we're also going to put in the return row, the string order more. Otherwise, if we have at least 10, we're going to put the string in stock in the row. And you can see why this would be really useful, right? Now you can give your employee this report, and it will just clearly state on every row, right? 9, order more, right, bananas, 11, in stock. Now they can just take a look at the order more or the in stock column to see whether or not they should order more of whatever it is, right? We can do interesting kind of computed columns in our return data by using a function like this. And you can see we're actually coupling this with an as clause so that when the data comes back, it has a nice kind of column name to it. So the assignment for this lesson says we need to look through cachepals transaction data and determine whether or not any of the transactions need to be audited. Return all the data from the transactions table and add an extra column at the end called audit. Okay. So let's just start with that. So select star from, do that right, from transactions and add an extra column name at the end called audit. I'm going to run this query, I'll just get the whole transaction stable. Okay. Now this audit column, it says if a rows was successful field is true, the audit field should say no transaction, no action required. However, if was successful is false, the audit field should say perform an audit. Okay. So in addition to the wildcard, in addition to everything else, we're also going to return a new column. We're calling it audit. And in order to calculate the audit field, we're going to use this IIF, it's IIF, not IFF, right? Okay. IIF. And the condition is going to be if was successful equals true, right? Or actually, I think because this evaluates to a Boolean, we can just say if was successful. So if was successful is true, then the first thing we pass in as a parameter, technically the second parameter, right? The first thing after the condition will be what's returned. So we'll do no action required. Otherwise, we'll say perform an audit. And then we want this new column to be called audit. So select star and audit, and the way we'll calculate audit is using this function. So in theory, we should have one row down here at the bottom, right? This magic the gathering draft row, it should be the only one where an audit needs to be performed. So let's run that again. Take a look at our results set. Yep. No action required on all of those performing audit on the last one. This looks good to me. Another useful clause is the between clause, right? So this essentially lets us to check whether a value is between two other values, right? So in this example, select employee name and salary from the employees table, where the salary is between 30,000 and 60,000, right? So we'll go get all the rows from the database, where the salary field has a value between 30 and 60,000. It's also worth pointing out that we can just throw a not before the between, and that will give us everything that's not between the two numbers, right? So if we don't want everything between 20 and 100, then we can do a not between. Oh, the assignment says we need to figure out or we need to see how many young adults are using cashpal. Query our users table to find all the name and age fields of users between the ages of 13 and 18. Seems straightforward enough. So select. One page from capitalized from users where age between age between 18 and 30. Cool. Let's run that. This is looking good. Let me see what the full, I'm actually curious now, what does the full table look like? Run without between. Yeah. Okay. So we're like excluding Ram here, excluding David. Cool. Okay. That looks right to me. Let's submit it. Distinct is another super useful keyword that does kind of what you'd expect. It allows us to select rows where a distinct value is present. So for example, select distinct previous company from employees. This will only return one row per unique value, right? So let's say that I have 10 employees and between the 10 employees, maybe there's three that worked at Google for that worked at Microsoft and another three that worked at Apple. When I run this query, I only expect to get three values back, Apple, Google, Microsoft. So jumping into the assignment, it says cash bill executives want to know how many countries we have customers in. We store country code data as a column on the users table, run a distinct query to get all the unique country codes from the user's table. So simple enough, select country, I'm going to run it kind of the normal way first so we can see the difference from, let me capitalize that, from users. Select country code from users. If I just run this, I'll get one country code per row in the database. You can see tons of stuff here, but this isn't what the executive is asking for, right? They don't want a single row for every user in the database. Maybe we have 100,000 users, right? They just want to know how many countries total, right, exist across all of our users. So we can use distinct, distinct. Run that again. Oh, had to refresh my page, had a network issue. Okay, so it's like this to cover code now, yeah, now we get it kind of whittled down to each unique country code. I'm going to go ahead and submit that. Well, let's talk about logical operators. You're probably already familiar with logical operators if you've done any sort of programming in like Python or JavaScript or whatever. It's really simple in SQL. The logical operators are just the key words and and or, spoiler alert, we'll talk about or in just a second. Cool, so when we're writing, for example, a where clause, we can add more than one condition by anding that condition with another condition. So for example, here we're selecting product name, quantity, shipment status, right, those three columns from the products table where both of these things are true. The shipment status is pending and the quantity is between zero and ten, right? This again should be a pretty familiar concept if you've done any sort of programming before. And then the only thing I really want to call attention to in SQL is that when you're doing a quality in SQL, all these inequality operators are what you'd expect, right? Less than, greater than, less than or equal to, greater than or equal to. But the equal operator, when you're checking for equality, is just a single equals. It's not double equals or triple equals like it is in some other languages. And that's just because it's not taken up for assignment. So like it's not taken up as the assignment operator. So it's just the equal sign. Cool. Like you could see here, right? Shipment status equals pending, not equals, equals pending. Okay, with all that preamble, let's get to the assignment. It says the legal restrictions in Canada have changed the way that we handle Canadian minors. So minors are people under the age of 18, right, essentially kids. The way that we handle their transactions has to be more strict, right, for legal reasons. We need to find all those users so that we can find how many of our users are going to be affected by these changes. So write a query that retrieves all of the fields from the users table, where the users are from Canada and are under the age of 18. We can take a look at the table here. Okay, select star from users, where country code equals Canada, and age says under the age of 18, so less than 18. This looks good to me. Now we're going to work with the or operator. So it works very similarly to the and operator, but instead of both conditions on either side of the or keyword needing to evaluate to true, only one does, right? And to be clear, it's okay if both do. So at least one side needs to evaluate to true. At least one condition needs to evaluate to true. And it's also worth pointing out that the order of operations can be manipulated with parentheses. So in this case, we're saying we're going to evaluate this and that first. And then the result of that is going to be ordered with the other, right? So we can use parentheses, just like in math, to adjust the order of operations. Okay, assignment says the laws have changed again. Now we need to see how many affected users meet this criteria. Users who are from the United States or Canada and are under 18. Write a query that retrieves the count of every user that matches the conditions. Okay, so select count star from users. Let's just run that. So in total, there's 11 users in our table. Next we need to filter this down and say where country code equals US or country code equals Canada. Okay, with that filtering, we're down to eight. Now I'm going to pop this in parentheses and say and because we're requiring that all the users must be under 18 and age is less than 18. Let's run that perfect. Next we've got the in clause. This one's pretty cool. And it's not always, in my opinion, super intuitive how it works. So we'll definitely go over it. But basically, the in operator returns true or false. If the first operand matches any of the values in the second operand. So it's kind of a shorthand for like multiple or conditions. So take a look at this, we've got this first query, select product name and shipment status from the products table, where shipment status is in this kind of list of options. So as long as shipment status is one of these shipping, preparing or out of stock, it will return true, which means we'll return the row, right? Whereas here, we've got select product name, shipment status from products, where shipment status is shipped or shipment status is preparing or shipment status is out of stock. These are identical queries, they do the exact same thing. This is just kind of a more convenient way to write it. And later, we'll see how this allows us to kind of use the in operator with dynamic data. So we don't have to like explicitly spell out all of the different options, right? Maybe we're comparing against other data that's somewhere else in the database, cool. So let's jump into the assignment. It says, we want to know which of our users are from North America, right? A select statement that returns the name, age and country code fields for every user within US, Canada or Mexico. So select, and this isn't a count, right? We want to know which of our users, let's see, okay. So select name, age, country, code, from users, where, let's see, age, not age, where country code in US, Canada, Mexico. Looks good to me. I'm just gonna send it on this one. Next we've got the like operator. I love the like operator. It's kind of the first operator that we've used that allows for like fuzzy matching, right? Or kind of wild card matching. So the first thing to understand is that the like keyword is going to allow us to look stuff up in the database by like partial matches, right? So we'll get to that. It'll make more sense with an example. First let me explain this kind of percent operator. So this percent sign operator will match to zero or more characters, and we can use this operator within the query string that's supplied to the like clause to find more than just exact matches depending on where we place it. So for example, select star from products where product name is like this string, banana percent. And what we're saying is any product names that just start with the string banana, we want to match, right? Because this this percent sign effectively says anything else can be here, right? Zero or more characters can be in this spot in the string. So similarly, if we want every product name that ends in banana, we just put the percent at the beginning, right? And then if we just want to do a contains, right, does the string banana show up anywhere in the product name, then we can just slap a percent sign on both sides of the string. So the assignment says our HR team is dealing with a ticket from one of our users, but they're having a trouble pulling up their record in the database. They're pretty sure the user's name starts with a L write a query that returns all the fields for records where the user's name starts with a L. Okay. So select star from users where the name is like they starts. So starts with a L. So it needs to be a L and then percent cool. Going to just send it, right, we got Alan, Albert, Alvin, Alphonse. Looks good to me. So still working with the like clause, we're going, we're going to take a look at another operator basically. So the, the percent operator or the percent sign, like I said, matches zero or more characters. Whereas the underscore operator matches exactly one character, right? So for example, here we're saying, uh, you know, give me all products where the product name is a four letter word that ends in oot, right? So it'll match boot, root foot here. I don't know if you can tell, but there's actually two underscores, but now this is going to match things like shoot and group, but importantly, it will not match things like boot, root foot, right, explicitly going to have five characters. Okay. HR has been able to narrow down their query even further. They want a report of all users whose names start with a L and are exactly five characters long. Okay. So let's do select star from users where name, like underscore, underscore, underscore, but an Al at the beginning. So it starts with Al one, two, three underscores run that Alan and Alvin perfect. And just to show you what would have happened if we did this, we would match some more stuff. We'd get Alfonso and Albert. So that's looking right to me. First quiz question dealing with wildcards and the like, the like clause says, which describes the values that match example one? Okay. So this is example one or underscore wildcard. Let's see values that start with or yup and have three characters exactly. No, because we've got this wildcard here that could be zero or more characters values that end in or no, that's not it. Values that end in or no, that's not it. Values that start with or and are at least three characters in length. Yeah, that's accurate, right? We need three characters. We could have some more. Next question, which would not match example two? So we've got two underscores here, bling that matches sling that matches thing that matches singing does not match too many characters, right? This, this only has room for five characters. New keyword, we've got the limit keyword. Now this one, this might be one of the keywords that I use the absolute most in SQL apart from like the obvious things like select and where limit is super, super common, both when you're writing application code, as well as when you're just kind of making one off queries to a database, because it's very often the case that when you're working on a production scale database, a table doesn't just have six or seven or 10 rows like what we've been dealing with in our little sandbox environment, right? We could have a thousand rows, we could have a million rows, we could have 100 million rows in the database. And if you try to just select all of those rows, something's going to crash, right? That's a lot of data to pull out of a database all at once. So that's where the limit keyword becomes really, really useful. Here's what it looks like. So after any select statement, we can end it with this limit, this limit section here we're saying, just give me 50, do not give me more than 50 rows, right? Give me up to 50. So if my query was only going to return three rows anyways, the limit keyword effectively would do nothing here. But if like, you know, 7000 products match this query, we're going to stop the database and say, just give me the first 50, give me the first 50. Okay. Moving on to the assignment says a lot of our users have been using catch pal to pay other users for lunch. Let's take a look at a sample of that data. Write a query that returns all rows and fields from the transactions table. Any record where the note field has the word lunch in it, okay. And the query should return at most five records. So select, it says all rows and fields, yeah, select star from transactions, where note like just has the word lunch. So we'll do wildcards on other sides of lunch. Okay. And let's just go ahead and run that really quick to see how many there are. Looks like we've got a lot, 14. And now we'll limit it down to just the first five. Again, cool. Just five, just five results now. I want to just point out, you'll probably do this a lot when you're like manually working with a database and just trying to like figure out what the data sort of looks like. Right? So you've got a database, we got a table in it. It has a hundred thousand records. You don't need to see every single record to get a feel for like what all the columns are and what kind of data is actually in those columns. You'd typically just kind of like connect to the database, run a simple query like this, maybe limit it to 10 or 20 or 30 rows that you can fairly easily scan through. That's something I find myself doing a lot as a backend developer. Cool. I'm going to go ahead and submit that. So this question here says, limit five will always return five records and the answers are true and false. And the reason this is false, I'll just go ahead and click that now. The reason this is false is because if the query were only going to return zero or one or two records anyways, then limit five isn't going to add records, right? It's just saying, don't give me more than five. So it's actually possible for a query with limit five on the end to return fewer than five records. Next question says, why might you use a limit clause? First answer, I wouldn't. System performance is an ops person's problem. I like that answer, but it's wrong. Next one is to get as much data as possible. Nope, that can't be it, right? We're trying to limit the data, the amount of data because I'm a machine learning engineer and don't care about efficiency. Again, kind of funny, not accurate. Last one to avoid selecting a huge amount of data and causing strain on the system. It's going to be that last one. Next is the order by clause. And this one usually goes hand in hand with the limit clause. It's very often that you'll use both of these in a query and it's because the order by clause allows us to sort the data, right? And then the limit clause caps the amount of data, right? So if we order it the way we want it and then we just get like the first five, that's potentially pretty useful, right? Like give me, for example, like maybe you're building a leaderboard, a leaderboard, right? Like the one we have on boot dev. And I want to like get all of the users, but first I want to sort them by like how many exercises they've completed, right? And then just give me the top 10. Like that's a very common type of query that you're going to make in a database. So let's take a look at an example. So here we've got, you know, select name, price, quantity from products, order by price. Okay. So this is going to sort by the price field. Now by default, it's going to sort in ascending order, right? In other words, it's going to put the lowest values at the top and go down from there, right? Whereas, or sorry, it's going to put the lowest values at the top and then increase in value as you go down row by row, that's ascending order, right? If you want descending order, you have to explicitly specify it, right? So order by quantity descending, right? And that would, again, that would give us the highest values at the top. And then the values would drop as we go down. Okay. So the assignment says, write a query that lists all of the records in the transactions table where amount is between 10 to $80 and the results are sorted by amount in descending order. Okay. So first let's just write the select statement. So select star from transactions where amount between 10 and 80. Okay. Let's just run that. Take a look. So we've got our data correct, but it's not ordered the way we want, right? The amounts are kind of all, all out of order. So we'll add order by, what was it amount, order by amount, if I run this. So now we've got the smallest amount at the top and it's ascending as we go down, but it says we want it in descending order, so we want the biggest amount at the top. So we'll just add a descending keyword there. Run that. Cool. Now we've got the biggest amounts at the top and we go down from there. All right. We've got a quiz, got a little database table here and says example one is sorted in blank order. And I'm going to go ahead and assume it's talking about the age column, much more obvious how to sort by age than sort by name. It's sorted in descending order, right? We start with the biggest number, we go down from there. Next quiz question says, which query would potentially return the data in example one? Okay. Same table. The select star from people order by age. That would not give us this data because it doesn't specify an order, so it would do ascending. That wouldn't do it. Select star from people order by age descending. That could definitely be it. Select star from people order by age ascending, again, no, and select star from people order by descending age. That one's just incorrect. So it's going to be order by age descending. All right. Now we're going to use both of these keywords kind of in tandem. Like I said earlier, this is pretty common. Assignment says, an HR employee got into the Git repository where we store all of the queries that we run and tried to update one himself. Fix the bug in the SQL query. Okay. So select star from transactions where amount between 10 and 80 limit for order by amount descending. Let's try to run that SQL logic error, right? The problem here, so this wasn't actually a problem. It just bothered me. The descending is in lowercase and I like my conventional SQL where everything's capitalized. The problem here is that these are out of order. You need to order by first. First we sort, then we truncate is like the way I like to think about it. First you sort the data set and then you limit it down to just the bit that you want. Let's run that. Aggregations are one of my favorite parts about working with databases. Now aggregation sounds like a big, scary word, but it's actually a pretty simple concept. An aggregation is just when we take a large amount of raw data and aggregate it down into a single value. Now there's something interesting that I want to point out when it comes to architecting your database. Generally speaking, I think it's a really good idea to store database or store data in your database in sort of a raw format. And the reason for that is if you preaggregate your data, right? If you precompute a result and then store it in your database and say kind of discard the original raw data, you can never get back at that original kind of raw form of the data. So generally speaking, it's a good idea to store data in your database in sort of a raw format, and then you can just run aggregation queries on the fly when you need the calculated data. And I know I'm talking in vagaries, but we're going to hop into it in just a second so you can really see what I mean. So without realizing it, you've probably, well, you actually have already written an aggregation in SQL. The count function is a very simple aggregation, right? It takes as input many rows from the database and returns a single value, right? The count of how many rows there are. So to sort of reiterate why this matters, right? Why we would store data in a raw format and just run, for example, a count query when we want to know the count of rows is if we just store the count of rows, thinking, well, maybe I don't actually need all these transactions, I can just store the count of transactions because at the moment, all I'm doing is showing on the page how many transactions they are. The problem is if later down the line, we need to show something like when the transactions happened, right? So we need all the dates on every individual transaction. If all we were doing was storing the results of the aggregation, the count itself, we wouldn't be able to go backwards. So again, I just want to reiterate, store data in a raw format, right? As raw as you can, as raw as makes sense. And run aggregations like count queries when you need that data. So let's hop into the assignment. It says the front end team is building a dashboard page in cache pal. We need to be able to provide them the number of successful transactions for a given user, return the number of transactions where the user ID is six and was successful is true. Okay, so select, count, star. Now remember, when we're using the count function, this wildcard refers to the fields, right? So we're just saying we don't care which field we count, we just care about the number of total rows. So just keep that in mind. All right, select the count of star, ROM, transaction, transactions, where, let's see, user ID equals six and was successful is true. Cool. Let's try running that. We got three, let's take a look at the setup code just so we can see. Okay, yeah, it looks like a lot of stuff was inserted into the database. So we, we, it looks like we're filtering it down to an appropriate amount. I'm going to go ahead and just submit that. Moving on, we've got another aggregation. This is one that we have not used yet. So the sum function or the sum aggregation does what you'd expect. It sums a group of values. Now with the sum aggregation, it wouldn't make sense to use all of the fields in a database, right? We're not counting rows. Now, what we're trying to do is sum all of the values in an individual column. So here, we're going to pass in the salary field as the parameter to the sum aggregation in order to get a total. So let's jump into the assignment says we need to be able to calculate the current balance for a given user, because we don't yet store the running balance on each individual transaction record. Write a query that returns the sum aggregation of the amounts for all of Bob's transactions. So first, let's just go ahead and do select star from transactions, transactions, where user ID equals nine, right for Bob. Let's just take a look at this data. Okay, so it looks like there's three transactions, and we've got three amounts, 1050, 50, and negative 2489. Now to get his balance, all we have to do is sum the amount field for the amount column, right? Go ahead and run that. Cool. That looks about right based on what I remember from Bob's transactions. We've got another aggregation to practice with. This is the max aggregation, again, pretty obvious what it does, it just returns the largest value from a set of values. So for example, select max price from products should return the product the max price or specifically the value of the max price. So let's jump in to the assignment again, pretty straightforward, how's this work. So I want to just get right to an example. It says use a max aggregation to find the largest amount of money received by Jill, user ID four, return her user ID and that amount. Okay, so first I want to just find the transactions from Jill, so select star from transactions, where user D equals four. Okay, run that, get a feel for what Jill's transactions look like. Okay, and we're looking for the max and the largest amount of money, return her user ID and that amount. Okay, so it looks like the max is 50, so we're going to expect that. So I want to do select max amount and I can just comma separate, right, because I want to select multiple things, select max amount and user ID from transactions. Run that, yep, 50, there it is, perfect. We did max time to do min, min function works the exact same way except it returns the lowest value, smallest value, okay, assignment says use a min aggregation to find the age of our youngest cache pal user in the United States in the users table, okay, the users table has these fields available to it, ID, name, age, country code, user name, okay, and we want just the age, okay. So select min age from, oh, this is from the users table, from users, where country code equals US, run that, that looks right to me. Now let's talk about the group by clause. So the group by clause is not an aggregation function like min or max, but instead it gives us a more powerful way to interact with aggregation functions, let me show you what I mean. So the group by clause essentially allows us to create multiple summary rows, in other words to kind of run the aggregation multiple times resulting in multiple results. So for example, look at this query, we've got select album ID and the count of song IDs, so give me the album and the number of songs in the songs table grouped by the album ID, right, this is a really useful query, we've got a huge list of songs, they all have album IDs on those records, we can group all the rows for each album ID together and count the number of songs, right, super useful query, a way to see how many songs are in each album. Let's use it in the assignment, says let's get the balance of every user now, all in a single query. Use a combination of the sum aggregation and the group by clause to return a single row for each user. The row for each user should contain the user ID and their balance, which is a sum of their amounts called balance, so we want to make sure we alias that column so that it's called balance, okay, so select user ID, sum amount, from, this is transactions, where, wait, is there a where here, no, group by, user ID, use a combination of the sum, single row for each user, okay, that looks right, the row should contain the user ID and their balance, okay, cool, oh, we just need to alias it, so let me run it like this, and you can see by default, SQL just kind of gives us some amount as the name of this column, which is kind of nasty, we're gonna do instead as a balance, like that, cool, and submit that. Next we've got the average aggregation, again, it does exactly what you'd imagine, these are kind of very common statistics ideas, right, we're gonna find the average of a bunch of values, it is important to note that it does ignore null values, so it's only going to average kind of the values that exist, cool, let's use it in the assignment, it says our marketing team is trying to determine the best marketing channels to advertise through, but they need more information about our current users, they wish to know the average age of users in the United States, return a single value representing the average age of all users where the country code is US, so, select average age from users where country code equals US, let's just send it, we got it, let's talk about the having clause, and I actually want you to almost pause the video, well, not pause the, well, okay, pause the video after I explain this concept, because it's one of those concepts that when I first learned about databases really eluded me, I had a really hard time understanding the difference between the having clause and the where clause, so let me try to break it down for you. The having clause is just like the where clause, it works the same way, it's used to filter rows down, the difference is that having operates on rows after an aggregation has taken place due to the group by clause, whereas the where clause operates on the rows before the aggregation happens. Does that make sense? So if you think about the order in which the query is executed, first the where clause is going to filter the total result set down to some smaller set. Then the group by clause is going to kind of break that smaller set into individual groups that you can then aggregate, right, like maybe you can get the count of all songs in the album, right, you've got five albums, you've got five subgroups. The having clause allows you to filter again after that group by using the results of the group by in the having clause. So to be clear, the having clause is definitely not as commonly used as the where clause, right, because it's only really going to be used in tandem with an aggregation. Let's take a look at this example. So here we have select album ID, count of ID as count from songs, group by album ID. So we've seen this before, right, this should return the album ID and the number of songs in the album. The difference now is that we've added a having count is greater than five clause. So what this will do is it will take that end result, right, of album ID and count, let's say that there were 10 albums, each with their own kind of song count associated with them. On that small resulting set of the 10 albums with their counts, we're going to filter one last time where we remove all of the rows or all of the albums, essentially, that don't have at least five songs in them. As usual, hopefully, this makes more sense after the assignment. Let's jump right into it says a new page in the cashpal app allows users to see how much money they've spent on a specific kind of transaction and alerts them if that amount is fairly large. Let's write a query that returns the total amount spent by each user on lunch when that balance is greater than 20. Okay, so this is actually gonna be a pretty complex query, which is which is great, good for practice, right? Again, if you're following along on boot dev, I highly recommend you pause the video and try to solve this on your own. So it says your query should return a sender ID, the person spending the money and a balance. The balance is the sum of all amounts spent. So first, let's just let's just start by getting a look into this table. We're working with the transactions table, I believe, let me in fact, let me go ahead and take a look at the setup code. Yeah, it's just a bunch of transactions. So to start, let's just select star from transactions. Take a look at some of this data. Okay, now we can kind of start to understand what we're working with. So we want a query that returns the total amount spent by each user. So it's gonna look something like this, let's select some amount from transactions. Group by user ID. And I should probably include the user ID there. Is that something we want? Return a sender ID, the person spending the money and a balance, the balance is the sum of all the amounts spent. It's gonna be some amount as balance than that. So now we can see the user IDs and their balances. Total amount spent by each user on lunch when that balance is greater than 20. Okay, so we also need a having balance greater than 20. So we'll filter out any rows that don't have that. It's now really starting to get down into the weeds here. It says the query should return a sender ID, the person spending the money. Okay, so we don't actually want the user ID, we want the sender ID. Which means I think we should be grouping by the sender ID as well. Don't return any rows that have a null sender ID. Yeah, so we want to group by the sender ID. The note must contain the word lunch to be part of the aggregation. So that's actually a where clause, right? So where note like, we know how to do this, right, like percent lunch percent, right? That'll match a zero or more characters to run that. Okay, now we're really getting somewhere, got three sender IDs, we got some balances. Order the results by the balance in ascending order. Order by balance, ascending. Okay, we did we check all these boxes, returning the sender ID and a balance, good. The balance is the sum of the amounts, good. Don't return any rows that have a null sender ID, there's no nulls there. Group by sender ID, yep, the note must contain lunch, we got that. The aggregated get balance must be greater than 20, we got that. Order the results by balance and ascending order. We should be good to go. I know I already went over this, but I really just want to reiterate it again because this can be really confusing. The difference between the having and where clauses, because they are very similar, they're both used to filter down results set, is that the where condition is applied to all the rows before the rows are grouped into aggregate rows, right? Whereas the having condition is applied to the grouped rows, right? The results of the aggregations. So with that in mind, let's look at the question. It says, in the example, should you use a where clause or a having clause to filter down to a specific class ID? So here's the example. Select class ID, count ID as count from students, where blank, group by class ID, having blank. So if we want to filter down to a specific class ID, we should actually do that in the where clause because we have access to that information before doing the group by, right? Having is typically used to filter based on the result sets, so we would do that after the aggregation. So in this case, we'll use the where. Next question says, in the example, should you use a where or a having clause to filter down classes of a particular size? Okay, interesting. So this is the count, right, the size is the count of students in a class. We can't do that before the group by clause because we haven't yet figured out the count inside each class, right? We have to do the aggregation on each class ID to figure out how many rows, right? How many student rows there are for each individual class. So it has to actually be the having clause in this case. Let's talk about rounding numbers. Not every function that's built into SQL is an aggregation, right? The round function is not an aggregation. It takes just a single value as input. Well, technically it takes two values, right? It takes the value to be rounded and the precision that we want to round the value to, but it is really common to use the round function when you're dealing with the results of an aggregation. By default, if we do not pass in a value for the precision parameter, by default, SQL will just round it to the nearest whole number, at least SQL lite will. Okay, so the assignment says fix the query so that it returns a whole number. That just means a number without a fractional part, right? And rename the result column to round age. Okay, so first, let's just run this as is. We get this really nasty decimal point here. We're going to change this to round to a whole number. I would expect this to round up to 28, right? Yep, 28, that looks good. And then it says to rename this field. This is a nasty, nasty column name, right? Round average age. Disgusting. Let's alias it as round age. Perfect. Fair warning, the queries we write in this chapter will start to get a little bit harder. We're moving into sub queries. So make sure that you understand regular queries, at least all the concepts we've covered so far fairly well before moving on to this chapter. Let's take a look at an example. So in this query, we've got select ID, song name, artist ID from the songs table, where the artist ID is in. Now remember, we've seen the in keyword before, we kind of used it to select, or to query for when a value is in a list or a set of values. But now, instead of saying, for example, artist ID in, you know, one, two or three, right, a list of explicit IDs, we're going to perform a sub query inside of these parentheses. And we're saying we want the artist ID to be in the result set of this sub query, right? So this query will run first, and the results will be used here in the in clause. Hopefully that makes sense. It should make some more sense when we get to writing some code here in a second. And I do want to point out that actually the only syntax specific to sub queries are these parentheses that surround the sub query itself, right, we're, we're quite literally just writing a normal query, and using the result set here in this in statement. So jumping down into the assignment, it says one of cash bow's customer service representatives needs us to pull all the transactions for a specific user. The trouble is, they only know the user's name, not the user's ID. So keep in mind, we could solve this problem by like running a query to get the user by their name, copying the ID, and then manually running a second query, what using a sub query is going to allow us to do is do it all at once all in one SQL query. So we've been tasked with using a sub query to get all of David's transactions. Okay, so we want to select star from transactions, where user ID equals now remember we weren't provided with a user ID, so we actually can't explicitly set it here. So we need to use sub query where user ID equals select ID from users, where they go to another line, where name equals David. Okay, we can just double check does this match our syntax from before? Looks good. Okay, so to be clear, we've got two different tables we're interacting with a transactions table and a user's table. And we are saying we want to get all the transactions or the user whose ID is whatever the results of this query is, which is select ID from users where David equals where name equals David. Okay, let's go ahead and run that. That looks good to me. It looks like it's grabbing all the records for user ID one, let's just check the setup code really quick and make sure that David is number one, it looks like he is because we're using an auto increments, primary key ID, so David should be ID number one. Cool, I'm going to submit. Now I just want to point out the difference between the query we wrote in the example here. Like I said before, the in syntax is not required for sub queries. The difference is that in this query, we expect multiple rows or multiple values to be returned. So we need to do an in clause, whereas here, we expected just a single user to be returned. And in fact, if we wanted to ensure that we could add a limit one, right, just in case there are multiple David's. Next we've got a little quiz. So it says a sub query, a creates a temporary table, B allows you to query the result set of a nested query, or C is a technique for speeding up your database. Now it doesn't create a temporary table, a sub query only exists at execution time. So no data is actually stored in the database, like the result set of your sub query is not stored in a new table in the database or a temporary table in the database. That's not what's happening. It's just a way to express a subset or a result set within your query. It only exists at execution time. And it's not a technique for speeding up your database. It's not any sort of like performance optimization, at least not inherently. So the answer is it allows you to query the result set of a nested query. Now this quiz question says the example will return blank rows. Okay, let's take a look at this. We've got select ID, song name, artist ID from songs, where artist ID in this. Hmm. Okay, this is actually the same example from the previous lesson. How many rows will this return? Well, we can expect that this sub query will return multiple rows because it's just querying for names like Rick. So anyone with a first name, last name, combo that starts with Rick is going to be returned here, right? And then the outer query is selecting ID, song name, artist ID from the songs table. So it's potentially selecting many songs where the artist is in this smaller list of artists. So I mean, we're already working with multiple artists. So it stands to reason that we have to be working with multiple songs. So potentially many is what I'm going to go with here. It's important to remember that SQL is technically a full programming language. Now, like I said, at the beginning of the course, we don't typically use SQL to build out full applications from scratch, right? It is a domain specific language in the sense that it's intended to be a query language, a language used to interact with databases, but it is a programming language, right? It has functions. It has ways to do these sorts of things. One example of this is that you can actually select information using SQL without having any backing database or table. So for example, this query select five plus 10 as sum. I mean, all that does, in fact, I'll just run it here. All that does is return a sum column with the result 15, right? But you'll notice I didn't even reference any tables in order to do that. Let's jump into the assignment that kind of demonstrates this. So the finance department has found that people who have lived longer than 40 years need to start thinking about retirement, write a query that returns all of the users who are more than 40 years old. Unfortunately, this tapered awkwardly stores age in days in the age in days field, use a sub query to convert years to days and filter on that. Assume every year has 365 days. Okay, so write a query that returns all the users who are more than 40 years old, select star from users, where, let's say age, this age is greater than something like this. And then we'll do a sub query there. Now we have an age in days field, where age is greater than, we can do age in days, sorry, we want to reference age in days, because that's, that's the actual column that's on the database. Right? Yeah, okay. Oops. So age in days is greater than. Now remember, we can't just do 40 here, we can't just do that, because that's years. So we need to convert to days. So we can do 40 times 365, right? We'll convert our years into days. Cool. Let's run that and see what we get. See these age in days, values are actually quite large. That looks good to me. Another quiz, SQL can only operate on data stored in tables. That is false, as we just saw. Architecting a database can be really tricky. But the most important thing to get right is that you've modeled your one to one relationships, your one to many and your many to many relationships accurately. If you do that, everything else will start to fall into place. Let's talk about. There are really three different types of relationships that we can have between entities in our database, right? We've got one to one, one to many, and many to many. And to draw that out, look something like this. If I have one of entity number one, it relates to one thing of entity number two. Another thing of entity number one, it relates to exactly one other thing of entity number two, you get the idea. One to many would look more like this. We have some things of type number one or of entity number one, and they might relate to three different types of entity number two. The second one might relate to two. This third one might just relate to one. It's really one to zero to many. You might even have one that doesn't relate to anything there. Okay, cool. And then a many to many relationship is exactly what it sounds like. We'll have all these different instances of thing number one, some instances of thing number two, and we can have kind of multiple relationships going on at the same time. Now let's start simple. Let's say we have in our database, a users table. Actually let's go with students, a students table, be a little bit more specific. And in the students table, we have two fields. A student has an ID, and a student has a name. Let's say we are thinking about adding a new entity to our database, and this entity is a GPA, right, a grade point average, and we're trying to decide how we're going to relate a GPA to a student. Well, once we decide that it's a one to one relationship, meaning a GPA and a student are tightly coupled to one another, right, a student has one and only one GPA, and that GPA is related to one and only one student, right. If that's the case, then it's pretty simple. We just add a new field, right, we just add a new field called GPA. Generally speaking, with a one to one relationship, it's easiest to model that as just another field on a database table. There is one other option though. What we could do, and I would argue this is typically a little less common because it's a little more complex, but I've seen it around, is that we'd create a new table, and we might call it something like, I don't know, student credentials, or maybe student scores. In this second table, we would have essentially the same ID, and the reason we'd have the same ID is to make sure that this relationship remains one to one. At the end of the day, we want to make sure that both of these tables have the exact same number of records, so that one record in one table will relate to exactly one record in the other table. We would typically do this for organizational or performance reasons, right. It's that we want to take this field here, the GPA field, and move it into a new table and kind of keep it separated physically and logically from the students table, right. It would give us some flexibility. Maybe we have some other data in here, like a test score that we'd want to add as another field on this table. So one to one relationships, generally speaking, it's just a field on the same database table, but it might be a kind of one to one mapping of primary keys between two tables. Now let's talk about one to many. Now one to many tends to be the most common type of relationship that you'll see in web development, right. Imagine a user and their tweets, right. You have one user and that one user can have zero to many different tweets that they've authored. Let's go ahead and model this out. So let's say that users have an ID and a name, seems pretty straight forward, and then tweets will need an ID, some text, and now is the tricky part. We actually need to model the relationship between tweets and users. So keep in mind, a user can have zero or many tweets. And this is the case, the easiest thing to do is to put a foreign key ID on the entity that is the many. So in this case, the tweets should reference the users. So tweets need a user ID. If you think about it, it starts to make sense, right? In fact, let's just jump right into some examples. Let's say that we have a user number one, name Lane, and user number two, ID two, name Alan. And then a new tweet is created ID one says hello. And let's say Lane tweeted it. So it will be user ID one, right, it references Lane over here in the users table. The next tweet will of course be ID two, because we need all of the IDs in the tweets table to be unique, right? They're the primary key. But the user ID on this one, it's hey, might be user ID two, right? So Alan tweeted this tweet. Now when we add a third tweet, yo, let's say Lane tweeted this one again, we could just reference Lane again, right? So we can have many tweets, right, in this case, tweet number one and tweet number three that are related to one user, right? User number one, which is Lane in this case. So one to many relationships, foreign key on the table of the many. Now let's talk about many to many. This is the arguably the most, the most complex relationship type, many to many users and tweets don't really make sense. So let's call, let's change out the tweets table for something else. Let's do groups. So let's say that users can organize themselves within groups. And if you think about it, this starts to make sense, right? A user should probably be able to be a part of many different groups, but a group naturally can have many different users in it. So we've got a many to many relationship. Okay, let me move these apart just a little bit. Now, a group, a group is going to have slightly different data. A group should probably have a name, I guess that makes sense. But just to keep it a little unique, let's say that a group also has a size, like a max, a max size, okay. And let's add a couple of groups. So we can still use Lane and Allen, but we'll create a new group, all the Gophers, and it has a max size of 20. Then we'll create another group. Pythonistas, max size of 30. Okay, got a couple groups. And actually, just so that they're different. Let's add a third group. Now let's add a third user, that'll be good. So this will be user number three, name of John. Okay, now, how do we model a many to many relationship? The problem is we can't use a foreign key. Because if we just add a foreign key to the group, we'd be stuck with a one to many relationship, we'd have no way to relate multiple users to multiple groups, we'd only be doing multiple groups to one user. So the approach, typically here, is to create a new table. So we actually have to add a third table here in the middle. And this is typically called a joining table. And really, its only purpose is to model the relationship between users and groups. And oftentimes, you'll see the table just called, for example, user groups, right. Very obviously, just kind of mapping the difference or mapping the relationship between users, users groups, right, users and groups. Okay, what would what would actually be in this table? Well, typically, there's just two things in this table. There is a user ID. And there is a group ID. All right, so just two foreign keys, make up this table. And typically, you'd put a constraint on this table, and say, we're not going to allow two rows in this table to be identical, let me show you what I mean. So let's say that Lane joins the Gophers group. When he does that, the way we're going to indicate that he's joined is by adding a new row to the joining table that says user ID one group ID one, let me add some some spacing there. So user ID one group ID one. Now let's say that Lane also joins the Pythonistas group. So we do user ID one group ID two. Now what I was talking about constraints earlier, what I mean is we wouldn't have a we wouldn't allow a second row to be added here that's identical to this other row, because it's fully redundant. It's telling us the exact same thing, right, that Lane has already joined the Pythonistas group. So we wouldn't do that. So Alan, Alan joins Pythonistas as well. So Alan's in the Pythonistas group, right? And maybe John, maybe John joins the Gophers group. Okay, so notice the many to many relationship here, right? Lane has now joined both groups, Gophers and Pythonistas. But the Gophers group also has two different users, right? It has Lane and it has John. So by using a joining table, we're able to accurately model a many to many relationship. So like we just talked about, there's essentially three different relationship types we need to concern ourselves with one to many one to one and many to many. The question here is, which is an example of a one to one relationship? A university's professors, so the relationship of university to professors, that's not one to one, there's one university has many professors potentially. And I mean, I guess you could even have like, you know, professors that work at multiple schools at the same time, maybe they're part time, right, so you get a little complicated. A father's children, again, not one to one can have multiple children. A transactions note, that's potentially one to one, right? I mean, it doesn't necessarily have to be but it could be you could definitely constrain your app and say every transaction can have just one note on it. Or a user's transactions. That doesn't make any sense. A user should be able to have many transactions. So I think the most correct thing here by far is a transactions note. Next question is, how would you model the relationship between a class and its name? Okay, so let's take a class like CS50, right, Harvard's famous CS50 class. It can only have one name. I don't see a world in which you would want multiple names for an individual class. This seems like a field on a row sort of situation, so I'm going to say one to one. Let's take a look at this example of a one to many relationship, or a couple examples here. A customer's table and an order's table, right? Each customer should have zero, one, or many orders. And this is important to understand. When we say one to many, what we really mean is one to potentially many, right? Zero to many. It's okay to have a customer and they haven't placed any orders yet. That should be a valid state of the database. A user's table and a transactions table, right? Again, a user should be able to have multiple transactions. Let's jump down to the assignment. It says, it turns out that when we originally designed the cache pal database schema, we assumed that users would only have a single country that they lived in. With digital nomads becoming a thing, it turns out many users actually have dual citizenship. So instead of a single user's table, where each user has a single country code, do the following. Remove the country code field from the user's table and create a new table called countries with four fields, ID, country code name, user ID, foreign key to the user's table. Okay. That makes sense, right? So with our current database schema, all we can do is give each individual user, right? Each individual user row can only have one country code because it's just a field on the row or a column on the row. That's a problem. So we're going to remove the country code from the user's table and create a new table. So create table, and we're going to call it countries. And it should have four fields or four columns, ID, integer, primary key, I'm going to guess, country code, text, name, text, user ID, integer, but it's not enough just to add the column user ID, we're going to actually constrain it with a foreign key. So foreign, foreign's always hard for me to spell foreign key on the user ID column, references, user's table, ID column, okay? This looks better to me. And I hope as you're looking at this query, it's making sense why this works, right? We can now add multiple rows to the country's table that reference the same user, right? So say you have your user record lane, right with ID one, I can now go into the country's table and add two records, I can add maybe United States and Canada, and have them both reference lane. So this is a way for us to model the relationship between one user and their multiple dual citizenship. Next, we've got manytomany relationships, and frankly, these ones are kind of the biggest pain in the butt because it just takes a little bit more work to model this in your database. I mean, to be fair, onetoone is the easiest, onetomany is kind of middle of the road, and manytomany is hardest. And when I say hard, I don't mean it's like super complex and hard to learn, I just mean there's just a little bit more legwork to do. So typically the way that we model a manytomany relationship in an SQL database is by using a joining table, right? So a joining table is a special table that doesn't really have any metadata on it, right? So when I say metadata, I mean like all this extra crap, right? So you've got the user's ID, and that's its primary key, but all this other crap, we can just kind of call that metadata. It's data about the user, right? But it's not the identifier of the user. So essentially you could break almost every database schema up into the primary key and then the metadata. So what I'm saying is a joining table is really just a table with only identifiers and no extra metadata. And that's because its only job is to model relationships, which is what IDs do a great job of. Now, I'll show you an example of a manytomany table in just a minute when we get into this exercise, but I also just want to point out that one thing that makes our joining tables better is when we use a unique constraint across two fields. So for example, here in this example, we have a product suppliers table, and all it has on the whole table is two IDs, product ID and supplier ID, right? So imagine a products table and a suppliers table, and we're trying to model a manytomany relationship between the products and the suppliers. This joining table has rows in the table with just two values, the product ID and the supplier ID, and all this does is say I have a relationship between product one and supplier three, or product one and supplier one, or supplier one and product four, right? I can now model this manytomany relationship because I have a joining table, and this unique constraint just makes sure that I never try to model the exact same relationship twice, right? When I'm doing a manytomany relationship and drawing lines between the two different types of entities, I don't need the exact same line drawn twice, right? So you may have already guessed it, but what a row in this database means is that I've drawn a line between a product and a supplier. So say we have our product table and our suppliers table, and at present, no products are associated with suppliers. In other words, we're essentially saying that the suppliers don't carry any of the products yet, but the minute a supplier decides to carry a product, right, and supply that product, we would add a row in the database with that product ID and that supplier ID, right? And so if we need to check, hey, does this supplier offer this product, then we can just go into our joining table and look up, you know, all the products, where the supplier ID equals X, right? And we could do it the other way around. That's the interesting thing about a joining table, it allows you to do it both ways. So jumping into the assignment, it says we have another issue with our current usertocountry relationship. In the current schema, a user can have many countries associated with it, but there are duplicate records. If two users are associated with the United States, we are creating two countries' records. It would be better if each country only had a single record. That way, when a country changes its metadata, for example, maybe it renames itself, right, instead of United States of America, maybe we wanted it to be the United States of America, we only have to update one record, right? In the old schema, we were storing one country per user. So if we change the name of a country, we'd have to update every country record for every user. We don't want to do that. We don't want to duplicate data, right? So the assignment says, use a joining table to deduplicate country data. Remove the user ID field from the countries table, okay? So we will no longer have this foreign key here. Now the countries table is simply countries, right? Create a new table called users countries, all right? Create table, users countries. It should have two fields, country ID and user ID. Country ID, integer, user ID, integer. And we want to add this unique on both columns constraint. Country ID and user ID. Perfect. Let's run that. Uhoh. What did I mess up? What did I mess up here? There's an extra comma there on that. There we go. I was required to take a database normalization class during my CS degree and frankly it was boring. Look here's the deal. There's basically the academic definition of database normalization and there's how database normalization actually impacts the apps you write. Now in this video, I will give you kind of a high level overview of the academic definitions of first, second, third normal form. But really what I want you to take away from this video is how database normalization and how certain strategies can help you reduce data duplication in your databases and improve data integrity. Basically just making your web apps easier to work within and more maintainable. So we are talking about database normalization and basically what that means is you can have a database that's architected in a less or a more normalized way. And the more normalized the database is, the less data redundancy you'll have. So the less data duplication and the more data integrity you'll have. So the more correct the data will be. So generally speaking, normalization good and the reason for that is you're much less likely to introduce data related bugs into your application. So there are four tiers of database normalization. There's first, first normal form, second normal form, third normal form, and voice cod normal form. And after the guys who kind of came up with this system. Okay. So what does that mean? Well, basically the most important thing to understand is that as the levels go down, your database becomes more normalized and these names for second, third normal form and voice cod normal form, just map to some rules, right? So for example, first normal form might have one, two, three rules associated with it. That's not actually how it works. I'm trying to, trying to give an example. Second normal form adheres to, let's say two additional rules and, and all of the rules from first normal form. So five total rules for second normal form, right? Third normal form, let's say tax on one additional rule and it adheres to all of the rules from second and first normal form. Hopefully you get where I'm going with here. So third normal form has six total rules and let's say voice cod normal form tax on one additional rule, right? And then adheres to all of the previous rule sets. So as you normalize your database more and more, you'll be kind of moving down this kind of tier list of normalization. So we talked abstractly about the idea that all of these normal forms have rules. Now let's talk about the actual rules themselves. So first normal form has two rules. The first rule is every row must have a unique primary key and rule number two is that there can be no nested tables, okay? Two very simple rules. Let me show you what I mean. Here is, well, let's, let's draw out a little database for ourselves. Let's say that we have a table in the database and the first row, let's say this is a user's table. We've got first name, lane, last name, Wagner, and then age 17. If in the same table, I have the exact same row, Lane Wagner 17, then this table does not adhere to first normal form. First normal form requires that every row must have a unique primary key, which translated out of kind of academic database speak literally just means that you cannot have completely duplicate rows, right? So the simplest way to escape, to escape, you know, this, like being outside of any normal form at all would be to just add an ID column. Like if we just add IDs here and we give row number one ID one and row number two ID two, then tada, we're in first normal form. Now there is this second rule, right? There can be no nested tables. I've never actually ran into that in production. Most production databases don't even allow you to nest tables in the first place, so you don't have to worry about it too much. But it really just means you can't, you know, take an entire table and shove it into the cell of another table, um, which again, hopefully it just makes sense why you wouldn't want to do that. Um, but again, most databases don't let you do that anyways, moving on to second normal form. Second normal form actually just has one additional rule. So to be in second normal form, your database must adhere to first normal form and what additional rule? The additional rule is that all columns that are not part of the primary E must only be dependent on the entire primary E, not just a part of the primary key. That's kind of word soup. So let's look at an example. We've got our database, say we have three columns, we've got first name, and do last name and first initial. So first name, last name, and first initial. And then let's populate the database with some names. So we've got, say we've got two lanes, we've got a lane small, we've got a lane Brewer. And then let's say that we've got an Allen small, and then the first initial for all of these would be L, L, and A. Now this table adheres to first normal form because there's no duplicate rows and no nested tables. It does not, however, adhere to second normal form. And in order to understand why, we have to understand what we mean by primary key. So typically when you're working in a production database, the primary key in a practical sense will just be an ID column, and that ID column will always have a unique ID for every row in the table. That makes database normalization fairly easy, right? But when we're trying to understand database normalization in more of an academic sense, when we say primary key, what we mean is just kind of the smallest number of columns that we can use to uniquely identify a row. So in this case, first name can't be a primary key on its own because there's two lanes. First name can't be a primary key on its own because there's two smalls. And first initial can't be a primary key because there's two Ls. But if we say combine first and last name columns together, they are unique together, right? There's only one lane small combination. There's only one lane brewer combination, and there's only one Allen small. So our primary key is going to be the combination of first and last name columns. So with that definition in mind, let's read the rule again. All columns that are not part of the primary key, so in this case, first initial, must only be dependent on the entire primary key, not just a part of it, right? Here's the problem. First initial is entirely dependent on just the first name column. In other words, it's dependent on part of the primary key, not the entire primary key. One way to solve this problem would be to create a new table and to move, to move first initial, the first initial column down here into that second table. And then we would map first name to first initial. And now you'll see we actually have some redundancy down here. Notice that lane being mapped to L only needs to happen once, right? So we could actually remove a row. Cool. Now we have one table with unique data, and anytime we need a first initial, we can look up the first initial for a given name in a separate table. This reduces redundancy, right? We talked about how normalization reduces data duplication and data redundancy. We now have less data duplication. Moving on, we've got third normal form. So remember, the database in third normal form follows all the rules of first and second normal form, but also one additional rule. And that is that all the columns not in the primary key are dependent only on the primary key. Pendant. Let's bust out an example. I'll use the same examples last time. Let's say that we've got lane small, actually, let's do this. Let's do first name, do last name, we'll do first initial. The key difference is that this time we'll add at the start an ID column. And we'll even be good database citizens and give some unique IDs. So in this example, the primary key is literally just the ID column. And then let's add some data. So we've got, we need two lanes, lane, lane, do Allen again. And we'll do small, small, and we'll do Brewer in the middle. And then here, we've got L, L, and a, whoo, okay, now notice this table actually does adhere to second normal form technically, right? Because yes, first initial is completely dependent on first name, but first name is now not part of the primary key. So it does adhere to second normal form. I'd argue that it's a pretty stupid academic distinction. Really we have the same problem, we're duplicating data. So anyways, the way we fix it is essentially identical. We can take this table, create a new one, and strip it down to just the parts we care about. In this case, we don't need last name or ID, we would just map first names to first initials. And the way we're going to do that is by shrinking it down here. We don't need two lanes. We just need a lane and an Allen, and move this column as well, again, remove the redundancy. Cool. Now we have all the same data being represented. Why can't I move that? There we go. Anytime we need the first initial for a first name, we can look it up in this secondary table, right? We've reduced some redundancy, and we have a primary ID column. Again, the distinction between second and third normal forms in practice as a backend developer working on databases is fairly meaningless. The idea is basically the same. So voice cod normal form adds one additional rule, and that rule is that a column that is part of primary key may not be dependent on a column that is not part of the primary key. A fun historical fact is that voice cod normal form was actually created later, after the first second and third normal forms, only after realizing that there is a way for duplicate data to slip into tables, even when a table adheres to all the rules of third normal form, so this additional rule was added. Now in order for voice cod normal form to actually matter, the database actually has to be in kind of a weird and specific state. That's why it wasn't really added until later, when people actually found out that this is potentially a problem. Okay, so what do I mean? Let's take a look at this database we have here, with the four columns, release year, release date, sales, and name. The problem here is that we have multiple possible primary keys, or candidate primary keys. For example, we could just have the primary key be the name column, because all of these names are unique. Kiss me tender, bloody mary, I want to be them, he got me. They're all unique. Additionally, a possible primary key could actually be the combination of the release year column and the sales column. If you take a look, 2001, 100, 2001, 200, 2002, 100, 2002, 200, those are all actually unique combinations, so that could be a possible candidate key. Additionally, just the release date column could be its own possible candidate key. Again, the thing that sets up this problem for voice cod normal form is we have multiple possible primary keys. Now, let's say for the sake of example that we've chosen the combination of release year and sales, these two columns, release year and sales, as our primary key. Now, the problem is that release year, this column, is fully dependent on the release date column. We have a column in the primary key that is dependent on release date, which is a column that is not part of the primary key. We're breaking voice cod normal form. If you go back and read the text from second and third normal forms, you'll actually realize that this isn't strictly forbidden in those definitions of normal forms. We can fix this. The way we fix this is just by making release date not dependent on release year. We'll just do release date and we'll just store the month and the day in that column. If we were saying we might change this to say release month day or something like that, you get the idea. It's worth pointing out that the distinction between second, third, and voice cod normal forms is mostly an academic exercise. In your day to day job as a developer, you shouldn't be worried too much about the differences between all of the different normal forms. What you should be worried about is are you duplicating data? Is there a way I can restructure my tables so that when I update something in one place, I don't also need to update it in another. That will keep your database less duplicated and it will also keep it more correct because there's less of a chance of you forgetting to update multiple copies of the same data. To recap, really the whole purpose of database normalization is to get data integrity and to reduce data redundancy. One great example of data integrity is I like to think of a user's age and their birthday. If we store their age in a database, like age equals six, that data becomes incorrect with the passage of time. If we don't touch that data next year, it will just be wrong. It will just be out of date. That data does not have integrity. It becomes incorrect. That's a problem. Anytime it's easy for your data to become incorrect or it becomes incorrect with time, you don't have good data integrity. If instead you store the birthday, now that never gets old. We can always calculate an age from a birthday when we need it. Similarly, data redundancy, obviously we've talked about this, but we don't want multiple copies of the same data in a database. That can actually lead to data integrity problems because maybe we update it in one spot but forget to update it in another. Now we have incorrect, mismatching data. The question is, to improve data integrity, data should generally be stored in a blank form, precalculated or raw. Now if we precalculate the data, the problem is again, it can become out of date if the underlying raw data changes. So I would argue store the raw data makes it easier to update. You can always calculate the result later. The only time you ever really want to store precalculated data is for very specific performance reasons, right? And like all things with performance, it's not the first thing you should optimize. You really would only start to look into that if your queries were getting really slow and becoming a problem. Pick the best example of data redundancy. Each table has an ID field as its primary key. It's not redundant. A user's address is stored in two different tables. Yeah, that seems like a problem, right? Now when they update their address, we're going to have to update it in multiple places. By the way, this is like what governments do. I don't know if you've ever been through this where like you update your address with the DMV and like they update it, but then like it's not updated on your taxes. It's because like every government agency has their own database and so it's not all synced up. It's not all in sync. This is the whole problem of data redundancy, right? So you don't want that within your own system. I'm just going to read these other ones just in case. Two tables can both contain fields that store Booleans. Not a problem because as long as they're different columns that mean different things, that's not necessarily a problem. A country table and a user's table each contain a field called name. Again, not really a problem. And frankly, the more you work with production databases, the more you'll kind of find very common patterns amongst the names of columns. Almost every table will have an ID. Most tables will have a name column. Many tables will have a created at column, right, so that you can see when each individual row is created. There's some common patterns you'll see and that's definitely not a problem. So a user address stored in two different tables is the answer. The next question deals with the normal forms specifically. We can take a look at this diagram. I think it does a good job demonstrating, you know, if you're in a voice cod normal form, then you must also be in third normal form, second normal form, first normal form, right? Voice cod normal form is the most normalized database. First normal form is kind of the minimally normalized database, right? Okay. Which form has the most duplicate data? It's going to be first normal form. Least normalized. Next is which form encourages the most accurate and up to date information? It's going to be voice cod normal form, right? The most normalized. In the context of normalization, a primary key is made up of blank table columns. Now I want to reiterate this because it's really important to understand. In the context of normalization, a primary key is made up of one to many columns, okay? In the context of SQL databases, that's not always the case. It just depends on the database technology you're using, right? Some databases might only allow you to use one column for a primary key. Some might allow you to do unique on two columns and call that a primary key. So like the different technologies matter here. Just understand that when we're talking about database theory, yes, a primary key can be made up of, you know, combinations of multiple, multiple table columns. All right. We've got an assignment to go along with first normal form. It says, we hired an intern at Cashpal and her first task was to design a new company's table. This table will store our business client's data. Unfortunately she has committed the unforgivable sin. There's no primary key on this table. We could have entire duplicate rows, right? So this table does not even adhere to first normal form because we can just have completely duplicate rows. Big problem. Add an ID field. It should be an integer and have a primary key constraint on it. When you're done, the company's table will be in first normal form. Cool. This is easy. This is straightforward. ID, integer, primary key. Boom. Very rare that you won't see ID fields on tables in production. Now we've got an assignment for second normal form. It says, another developer on our team has created a joining table for the companies to use as many to many relationship. Unfortunately they did it a bit weird. They included meta information about companies on the joining table. A good joining table simply has the IDs of the entities in the relationship, right? We already talked about this. Metadata doesn't really belong in joining tables most of the time. It manages the relationship and nothing else. Any information about the entities themselves belong in their respective tables. Move the column that's out of place to its proper table. Be sure to add it as the last column to the table you add it to. Okay. So, it looks like our joining table is here. Users, companies. I would expect it to have, yeah, a user ID and a company ID. Yeah, revenue. This is a problem, right? This is a huge problem for several reasons, but just, I mean, just think about it for a second. Imagine that you have multiple records in this table for a single company, which you obviously will, right? Because one company can have many users associated with it. So, you'll have like seven different records. They could each potentially have their own revenue. That doesn't make sense, right? A company can just have one revenue number, not different revenue. It's all the same company, right? So, this needs to belong on that individual company's record. Next, we've got an assignment for third normal form. So, this rollout of business accounts is really causing some headaches for our development team. The company's table has been a disaster. Our database architect pointed out that the idea behind the size field is redundant. If a company has more than 100 employees, we consider it large. Otherwise, we consider it small. Remove the size column from the company's table and alter the select statement to calculate a size field in the result set that works the same way. Okay, so, let's see if this is making sense. So, we've got a company's table, a company has an ID, a company has a name, it has a number of employees, and it has a size. So, the problem here is that these two columns are essentially the same because we can always calculate a size, as we've defined size, right, small or large, from the number of employees. It's fully dependent, is what we would say in kind of a normalization theory. It is fully dependent on the number, the num employees column. So, let's get rid of that field. It's a dumb field. It's a stupid field. It's gone. Now, we need to alter the select statement because if I run it in its current form, there is no size column, but we still want the size column in the result set, right? Theoretically, we have someone looking at this report. We want them to be able to at a glance see if it's a small or a large company. So, we'll just add a little calculation here. We'll say select star and we'll also select IFF. Remember, we learned this, we learned this function a few chapters back. We're going to do a comparison on if num employees is greater than, what, 100, and is more than 100, then we'll consider it large. Otherwise, we'll consider it small. And we want this to be named size. We want the column in the result set to be named size. Let's run that. Oh, what did I screw up? IIF, not IFF. I was reading it and I was like, IFF, IIF, that is honestly really terrible name for a function. Very confusing. All right. IIF, we got it. Does this look correct? It's 10,000 large, 1,000 large, 4 small, 12 small. This looks good to me, right? We cleaned up our table definition, but we're still getting a good report for our stakeholders. All right, we've got a quiz about voice cod normal form. So cast your mind back to the explanation of voice cod normal form. Remember that it's kind of weird and doesn't frankly come up very often, at least in the sense that the distinction between third normal form and voice cod normal form. Okay. The question is, when can a table be in third normal form but not voice cod normal form? It has multiple possible primary key combinations and one of the columns in a possible primary key is dependent on a column outside of that primary key. That's sounding right. That's sounding right. Can Raymond F. Boyce and Edgar F. Cod decree it so from on high? Eh, close. Not quite. It has a primary key that depends on another column that's not a primary key. No, that's not BCNF. It has multiple possible primary keys. Yep, not that one. It's going to be this top one. This next question is just, which should you optimize for first, generally speaking, reducing duplicate data or speed? Now this is really just kind of a rule of thumb in software engineering. This isn't like a hard and fast fact. But in my opinion, and I hold this opinion fairly strongly, generally speaking, you should start with just reducing duplicate data because you're going to have fewer bugs in your application that way. You'll be able to move faster as a team. You'll be able to fix bugs, ship features, refactor code, right? Do all of the things that you normally have to do as a developer. You'll be able to do them better if you don't have to deal with duplicate data, right? If you have speed problems that can easily be solved or are best solved by introducing some duplicate data, that's okay. It's not like you can never, ever, ever have duplicate data, right? I mean, at the end of the day, caching just is duplicate data, right? It's not necessarily a problem, but cache invalidation is hard, right? So we kind of stay away from it as long as we can. This next question is when you don't need a composite key, and remember a composite key is just when you have like two unique columns together, right? So in the example of a joining table, we don't have an ID primary key column necessarily, right? We can just do a composite key on two different columns, right? So when you do not need a composite key, what should the name of your primary key's column be? I may have just given away ID is a very conventional name. This isn't, again, this isn't a hard and fast rule. It's not like your application is going to break if you name the column key or identifier or skeleton key, but like everyone uses ID, just freaking use it. Like, why don't be confusing, right? It's kind of like how everyone uses I in loops, right? Or I less than zero, like there's just a convention around some things in programming. And if you stick to them, it'll make your life a little bit easier. This question is which is more important for your career in backend development, memorizing the exact definitions of first, second, third, and Boyce Cod normal form, or internalizing simple rules of thumb regarding database normalization? The answer is internalizing the simple rules of thumb. That's going to make you a much better backend engineer, in my opinion, right? You do not need to know the exact definitions of these, of these normal forms. They are useful theoretical exercises for us to think about normalization, right? But these rules of thumb, right? Things like adding primary keys to all of our rows, avoiding duplicate data, not storing data that's completely dependent on other data, right? Having our schema simple, those things are what you're going to really use day to day and what you need to keep top of mind. Trying to hold the full academic definitions in your head is just going to be confusing. Finally, we've gotten to joins. Now joins are actually one of the most powerful features of relational databases. In fact, without joins, it almost wouldn't even make sense to worry about all these different complex relationships between tables. To put it as simply as I can, a join is just a way to query multiple tables in an SQL database at the same time. Now the first type of join that we're going to talk about is called an inner join. It's also kind of the simplest and the most common type of join. So by default, a join command is an inner join. So if you just use the join keyword in an SQL statement, you'll be doing an inner join. And an inner join returns all of the records in table A that have a matching record in table B. So we have two tables, right? And we'll get to the syntax of a join here in just a second, but understand that what we're talking about is we've got some number of rows in table A and we've got some number of rows in table B. Let's say we have 100 rows in each. When we write our join query, we're trying to get a single result set back, right? So if we got all of those rows back, we'd get 200 rows, right? Well an inner join is just saying, I don't want necessarily all of the rows. I want all of the rows that exist in both tables, right? And we typically link on some sort of ID. So you can see by this diagram, essentially what we're saying with an inner join is I just want the set of rows from both tables that exist in both tables, right? So let's say that in table A we have 100 records and 25 of them share some ID, some linking key with table B. It's only those rows that we're going to return in the result set. Let's take a look at an actual example. So here we've got some SQL, says select star from employees, right? So employees is in this case table A. Inner join departments, in this case departments is table B. And now we have this new keyword, the on keyword, which is used in tandem with a join. So this describes how we're going to join. It describes that key relationship. So inner join departments on employees dot department ID equals departments dot ID. So in this case, we're saying we want all of the rows where on the employees table, the department ID matches a row in the departments table with that same ID. Does that make sense? Think about it for just a second. Let's jump into the assignment and hopefully it will start to make sense as we go through some examples. So the assignment says our front end team is working on a profile page and would like to display a user's country name instead of just the country's two letter code. Let's start by writing a simple join between the user's table and country's table. We will expand on this query more in the next exercise. Okay, so write an inner join between users and countries. So it's going to, and then the next bullet point says return all fields from both tables. Okay, so select star from start with the user's table is table a so select star from users inner join between users and countries join on the country code field. So inner join the name of table B countries on running at my spacing, right? This is embarrassing. There we go on users dot country ID node be users dot country code. Let's take a look at the setup code so we know what we're working with. Okay, yes, the user's table has a country code. Users dot country code equals take a look at the country's table. Country's table dot also country code, okay, so we're saying give me all the rows from sorry all the fields from the user's table, inner join all of the fields and rows from the country's table where the country codes match on both tables. Okay, let's go ahead and run that. And I want to point out something that's interesting here. We'll see we have some duplicate column names. That's because when we do select star from users inner join countries, we're going to get every field from both tables. So first we're getting all of the fields from table a right ID name age country code username password is admin, and then all of the fields from table B, right kind of mashed together in the result set. So this feels right to me, I'm going to go ahead and submit that. Moving on, talk about name spacing on tables. So when we're working with multiple tables, we can specify which table a field exists on by using the dot, right, we use this in the last in the last example. So this kind of follows a similar pattern to different programming languages where you'll use this for like objects, right, like you might have a student object and if you want the field, you would do dot name. So SQL luckily uses a very similar syntax, right, we can do table name dot column name in order to access a column on a specific table. In fact, you'll get yelled at if you're trying to work with two different tables and you use the name of a column that's ambiguous. In other words, it exists on both tables, you kind of have to tell SQL like, you know, I'm using the name field on the students table, not the name field on the classes table. This will come up a lot when you're using common class names like ID, sorry, not common class names, common field names or common column names like ID or name. So this query returns the name field from the students table and the name field from the classes table. Yep. Makes sense. Moving on to the assignment, it says adjust the query to return the name and age fields from the users table, return the name field from the countries table and rename it to country name, sort by the country name as any order. All right, so let's fix the fix the select first. In fact, I'm going to run this so we can see the data that we're working with. Okay, we got we got a bunch of stuff there. So we're going to change this star, which is just all fields to be a little more explicit. So users dot name, users dot age. At this point, it's probably good for me to point out a convention here, you'll notice that it's kind of considered best practice to name tables in the plural sense. So we wouldn't have a user table, we should have a users table. That's just, it's just good convention, it kind of makes sense when you think about it, right? The users table holds many users. So you'll see that come up a lot. All right, users dot name, users dot age, return the name field from the countries table. So countries dot name as country name, and then sort by the country name in ascending order. So order by country name, sending. And remember, we can use this column name because we defined it up here. And that's who we get. Name age country name. This looks good to me. All right, so we talked about how the inner join is kind of the default join. In fact, you don't even have to write inner join in your SQL queries, you can just write join and it will perform an inner join. Left join, however, is a little bit different. Essentially, what left join says is it will return every record from table A, regardless of whether or not that record has a match in table B, right? So like, we're always getting every record from table A, regardless of the on clause in the join query. Right? However, table B, we'll still only get rows that do have a match in table A. Okay? All right. A small trick you can do to make writing the SQL query easier is to define an alias for each table. This is also just an important thing to understand. When you start working with a lot of SQL queries that start to get really long and really verbose, you'll see people alias table names, typically to make it shorter. So like aliasing the employees table as E, right? I don't think that's necessarily a good idea all of the time. The only time I recommend using an alias in order to shorten a name is if you're doing like a lot of manual queries and you're just trying to type faster, right? Like your bottleneck is your typing speed. When you're writing queries that are going to be used for a long time, like you're not just kind of running them one off against a database, like say you're saving them in your code base for your back end system to run, you probably don't want to alias your employees table to just be E. That only serves to make your code harder to read. Okay. Let's hop into the assignment. Hopefully this will help us understand left joins a little bit better. It says the cashpal team needs to report on all the transactions each user has made. Join the users and transactions table. Okay. So it looks like what we're going to want here is a result set that includes a row for every single user in cashpal, regardless of whether or not they have a transaction, right? Be sure to still return user records of users who have no transactions, right? So we want every single user record, right? And then we only care about the transactions that actually are associated with a user. If there's like orphan to transaction records, which means like they, they are not attached to a user in the users table. Like we can just discard them. We don't care about them. Okay. So let's jump right into it. Select says three fields, uh, users.name, name, uh, the user. Uh, the sum of transactions, dot amount, grab my comma as some count of transactions, dot ID as count. Now the reason I'm doing transactions, dot ID here and not just star is because I only want to count the transactions records, not all the user records, right? Okay. Uh, from users, left, join transactions. Now why am I doing it this way? Right? Why am I doing users, left, join transactions instead of transactions, left, join users? Well, the reason is because I want everything from the users table. So users needs to be table a, right? I want every user. I don't necessarily need all the transactions. I only need the transactions that are related to users on right users where we do our linking key. So users, dot ID equals transactions, transactions, dot user ID. Now we're using some aggregations here, right? Count and sum. So we need to tell SQL how we want to group our rows group by, um, users, dot ID. Let's run that really quickly and see what we get. Okay. First of all, does that look like the right amount of users? Let's take a look at our input data. Al, Alvin, Albert, yeah, this looks like, looks like we got all the users successfully. And you'll notice we have some missing data, right? We have, uh, null sums and zero counts. And that's good because that means everything's working, right? We have some users that don't have any transactions yet. So this is what we'd expect to see. Now there was one last constraint that we forgot to add up front, so let's go ahead and add that now. It says, be sure to order the data by the sum field and descending order. So order by some descending, run that cool, that looks a little more digestible, right? Bring everything sorted nicely and submit it. Now it makes sense that if we have a left join, there would also be a right join, but to be honest, right join is pretty dumb. Like there's really, there's really not a reason to use it. Um, in fact, SQL light doesn't even allow right joins, although some other s dialects of SQL or database technologies do allow you to use a right join. If you think about it, the whole idea behind a right join is kind of redundant. Instead of using a right join and ordering tables, A and B, where B is the table you want all the records from, you can just swap the order of the table names, right? And use a left join. So that's why I think left SQL light actually took kind of a good stance on this and said, look, we don't need right joins because just change the ordering of your tables and we'll just kind of force you to always make the first table, the one you get all of the rows from. I think it makes it easier to think about that way. So the question says we can retrieve the same records with a right join and a left join by grouping the table by a different field, giving up and drawing Venn diagrams, changing the field on the table, changing the field that the tables are joined on or flipping the position of the tables in the joint statement. It's going to be flipping the position of the tables. Now next we've got a full join and full join actually is different, but it kind of does what you expect. It just returns all the rows from both tables. Now something I want to point out that I don't think I've necessarily given enough attention to is that joins don't really operate on columns, right? They operate on rows. So when I was first learning SQL, I kind of got hung up on joins and I was a little confused thinking that like this Venn diagram represented all the fields in table A and all the fields in table B or all of the columns in table A and the columns of table B. That's not what's happening here. We're talking about the rows, right? So a full join will just return all of the rows from both tables. And like we've seen before, what it does when there's, uh, you know, what it does in relationship to the columns is just that it matches them all together, right? You'll get all of the columns from table A and then all of the columns from table B. Um, but you can control which columns you get back just like you normally would in the select statement. Right? It doesn't really have anything to do with the joins. So the question here is select the best scenario to use a full join when you need the matching results from two tables, when you need every single row from two tables, whether or not they're related. When you need all results from one table and matching results for another, or when you need all the results from a single table, um, it's going to be this one when you need every single row from two tables, whether or not they're related, uh, next we've got this little quiz. It says given the tables and the query, which join type produces the result. Okay. So we've got this users table here and a transactions table here and a result below. Okay. So which joint type produces the result? Well, the result does not have the same number of rows as either table, which means it has to be a subset, right? Can't be a left join can't be a full join because it only has three rows and the transactions table is the smaller table with four rows. So we're getting a subset, which means this has to be an inner join. All right, we got some different data now. And we're being asked the same question. So now let's see, we've got one, two, seven users and four transactions. And in the result set, it looks like we've just duplicated the user row once, which makes me think, let's see, makes me think that we've got, we could potentially have a left join going on here. And actually I should point this out because when we did our left join exercise, we did a group by, which means, uh, we kind of, you know, we got the exact same number of rows in our result set as table A. But if you don't do a group by and aggregate your table B rows, you can from a left join actually get more rows in your result set. Then we're on your left side, you're like your left hand table. That makes sense. Because you'll get one row per like related, uh, per relationship. So, um, select star from users, left join transactions on user ID equals transactions.userID. This is a left join. This is a left join because we don't have every transaction, right? If I check the transactions, we've got one, two, three transactions, transaction IDs, we're missing transaction ID four. So this is a left join. Now again, I just want to point this out really quickly. Here in the result set, we have two records for David and you might be wondering why. Because when we did our left join exercise earlier, this wasn't the case. The reason for that is because David is the only user here that has two transactions, right? So we get one row back for David and we get all that data and we get his, essentially his first transaction. In this case, the transaction with ID three, and then we get another row for David with his data for transaction one. And this is the default behavior when you run a join, right? You get all of the combinations of the relationships between the rows and the tables. The reason that we did not get multiple records for our users earlier was because we did a group by aggregation on our table B, which we could do here in order to smash those rows. So just be aware that's what's going on. All right, we got another quiz, new result set. Okay, this one's looking like it's actually based on the transactions table. And if we look at the query, we've got select star from users, blank transactions. So in this case, could be an inner join, but let's see, could it be an inner join? No, it's not an inner join because the last row in the result set does not have a user associated with it. It's not an inner join. It's definitely not a full join. This is a right join because transactions is table B down here in the query, right? So we get all the rows from table B and only the associated rows from table A. All right, time for some joining practice. Joins take some time to get used to, but the key to understand and using them effective is practice. That couldn't be more the truth. You just got to write a lot of SQL sometimes. Okay, multiple joins. To incorporate data from more than two tables, you can multiply multiple joins. Okay, so select star from employees, left join departments on employees.departmentid equals departments.id, inner join regions on departments.region.id equals regions.id. Cool, right? So we can potentially join lots of tables together. One thing I will point out, and I think we'll talk about this more in the next chapter, is that depending on how much data you're joining together, this can be a reason that queries get slow. So you know, just keep that in mind as you're architecting backend systems, if you're planning on using a lot of joins for queries that have to happen, say, maybe many times per second, you might start to get some slowness in your app. Okay, assignment says our front end team is finalizing the profile page for cashpal. We need to write a query that returns all the user data they need for an individual user's profile. The query needs the following fields. Okay, return only a single user record, specifically the one with ID equals six. Okay, how many tables are we working with here? We are working with looks like a user's table, a country's table, and a transactions table. Okay, so select, return only a single user record. So users.star, sounds like single user records, specifically the one with ID equals six, users.star from users. Now we don't want to do some joining. Now how do we want to do this joining? Oh, the query needs to return the following fields. Okay, sorry, I missed that. So we need to do users.id, we need to do users.name, users.age, users.username, user's country name or name to country names, it's actually going to be, that's going to be on the countries table. So countries.name is my guess as to how that's named, we could probably look here. Yeah, countries.name, okay. And then we also need the sum of the user's transaction amounts. So I misspelled users. So sum of transactions.amount as balance. Okay, so that's the data we're selecting. Now let's think about our joins. So we know we're going to be filtering this down just to a single user row. So we just want to make sure that we don't have any duplicate rows, right? We want just one row for the user. So thinking, when we join the countries table, I think we can just do a regular old join, which is, I mean, it's the same thing as an inner join, right? Inner join countries. What this means is if the user doesn't have a country, we won't return a row for them. So actually, I don't like that. We should probably do a left join here, because we want that user record either way. And if they don't have a country associated with them, we should probably just leave, like we should just be okay with this column being blank. So let's left join that. Left join countries on users.country code equals countries.country code. Okay, now transactions, we definitely want to left join on. Again, just in case, you know, there are no transactions. We want like a balance of zero, for example. So left join transactions on transactions.userid equals users.id. And because we're aggregating the transactions, we'll need to do a group by. So group by users.id. And that should get us pretty close. Let's run that. No such column users.identity. Oh, my autocomplete is killing me. There we go. Okay, so this is looking correct. We've got one row per user. I think the only thing we need to do now is filter down to a specific user. So we can just end this whole thing. Actually, we don't end because where goes before the group by. We just say where users.id equals six, six, right? Run that. Cool. Alan, Alias, we've got the country name. Ooh, do we need to rename country name? Yeah, that was close. I almost missed that. Countries.name as as country name. This is really common, right? Where you have two names, two column names that are identical, name and name. And so you want to change the name of one of them in your result set so that you get something that makes a little more sense. Cool. Submit it. We're on the home stretch now. We're in the last chapter where we're going to talk about performance. Now I've mentioned this before, but really performance with your database is actually one of the last things that you need to think about when you're designing how you're going to set up your database, right? Which database technology you use and how you're going to architect your schema performance is important. Don't get me wrong, but getting the data, right? Having the data, you know, reducing data duplication, increasing data integrity. Those things are generally speaking more important because it'll stop you from shooting yourself in the foot with bugs. Performance is something that you typically want to optimize for once you start having performance problems or once you know that performance problems are going to start happening in the near future, right? Maybe you're onboarding tons of new users every week. That's when you really should start be thinking, you should start thinking about performance for the first time. So at the heart of performance in SQL databases is the index, the index, SQL indexes. And an index is really just an inmemory structure held onto by the database that ensures that queries we run on our database are performant, which just means that they run quickly. If you have taken a data structures and algorithms course, and if you haven't, that's fine, actually have a data structures and algorithms course on boot dev that you can go check out. If you are not familiar with DSA, but if you are, a binary tree is one of the most popular data structures. And in fact, binary trees are what are typically used by SQL databases under the hood in order to create indexes. And without going too far into the weeds, a binary tree is really just a tool that we can use to efficiently find a value in a sorted list of values. So when you think about an ID column on a database, IDs are sortable, right? We can sort them into a list. And then by using a binary tree, we can perform a, essentially a binary search on that list and very efficiently find the value we're looking for, right? In other words, if we have a million rows in our database, and we do a lookup by ID on that database table, our database, if it's using an index, will not have to scan every row in the database to find the row we're looking for. Instead, it can use the index to very quickly use that binary tree that binary sort to find the key it's looking for, and then go directly to that row. So in big O notation, looking up using an index is a log N lookup, rather than an N time lookup. If that just went way over your head, go check out my data structures and algorithms course. But really, the only thing you need to know is that the index makes the lookup a lot faster. So let's check out the create index syntax. So in order to create an index on our database table, we just use the create index query, we create an index name, technically, we could call it anything, but probably a good idea to make it descriptive on a table and on a specific column in that table. It's fairly common to name an index after the column it's created on with a suffix of IDX. So for example, email IDX, if you want to index the email column. So I just want to point out like, why and when would you do this, right? Well, let's take the users table, for example. Right now, we have an index on the ID column, because by default, if you specify a primary key on a column, that column will be indexed automatically. But what if we are constantly looking up users in this database by their email and not by their ID, right, the ID is the primary key, but maybe like on the login page, for example, the users aren't supplying their IDs, they're just supplying their emails. So we need to do a query and look up the users by emails. Well, that query is going to be slow if we don't have an index on that column, right? It's not going to be slow if we only have like 1000 records or 10,000 records, but it's going to get very slow once we have 1 million records or 10 million records. So at that point, it gets really important, we need to think about how we index our columns. So the assignment says here, as it turns out, the front end frequently finds itself in a state where it knows a user's email, but not their ID, right? This actually is very common. Let's add an index to the email field called email IDX. Okay. So here, we're going to create an index. We're going to call it email IDX on the user's table, column name, email. Cool, let's run that. And you can see down here, I'm just doing, we're just doing a little select on the SQL light master to get to make sure that the index was created properly. All right, now it's important to talk about when we should index things because you may be thinking to yourself, well, if indexes just make everything fast, then let's just add indexes on every column in the database, right? That's actually not a good idea for several reasons. But really, one of the best reasons is that actually creating the index does have some overhead to it. So when you create an index on a column, what you're telling the database to do is to now keep an inmemory store of the data in that column, right? So rather than just storing it on disk, it's now going to bring it into memory. So indexes have a nonzero memory cost to create them, right? Even though they make queries faster when you run the queries, they can actually bloat like memory usage of the database as an example. There's other things too. For example, now when you insert a row into that table, the binary tree actually has to do an insert operation, which is a little slower than if it didn't have to do that. So if you've got hundreds or thousands of indexes on a very large database, you might start to see other kinds of performance problems. So as a general rule, I would argue it's best practice to not create indexes until you have a good use case for them, right? Until you need them to speed up an individual query. So the question here is, a binary tree index makes lookups, and this is in big O notation, order log n, order n log n, order n squared, or order n. And the answer is that it makes the lookups order log n, which is extremely fast. And again, I don't want to do like a crash course on data structures and algorithms in the middle of this SQL course, but if this is going over your head, please feel free to go check out my algorithms and data structures courses on boot.dev. Last question says, add indexes to blank, all columns, only foreign keys, columns that you frequently perform lookups on or only primary keys. And the answer is columns that you frequently perform lookups on, right? Once you understand that you're doing a lot of lookups on a column, and that those queries are starting to get slow, that's a good time to go add an index to that column. It's also worth pointing out, by the way, that when I say doing a lookup on a column, I'm talking about the where clause, I just want to be specific about that, right? Like in the example of the users table, it'd be like, select star from users where email equals X, that's a lookup on the email column. So the email column would need an index, right? An index on the ID column, in that case, does you no good. Last question says, indexes slow down blank, write speed or read speed. Now my assumption here is that when we say read speed, we mean lookup speed, right? And they definitely don't slow down lookups, they speed up lookups, but they can slow down writes, right? Now every time that you insert a row into a database, you need to update all of your in memory binary trees in order to keep them up to date, which again, makes sense if you understand how binary trees work. Because essentially you do some upfront work to make the lookups much faster down the line. Now we've talked about single column indexes, which are fairly straightforward. But there's also multi column indexes. And they're useful for exactly why you might think, right? It's when you need to do a lookup based on more than one column. Okay, so let's look at the syntax. We've got create index on blank, sorry, create user or create index, index name on users, and then all the columns in the index, right? So in this case, the first name column, the last name column and the age column. Okay, it's important to understand that a multi column index is sorted by the first column first, right? So the order of these columns or the order of these fields do matter for performance reasons. A lookup on only the first column in a multi column index gets almost all the performance improvements that it would get from its own single column index. Okay, so what do I mean by that, right? In the case of this index here, if I just did select star from users, where first name equals lane, that would be very fast, right? It would get basically all of the performance benefits from from this multi column index because I was just using the first name field. However, if I did a lookup based on just the last name or just the age, so for example, select star from users where last name equals Wagner, I would not get all that big a bump in performance improvements. Because first, the database needs to essentially guess at the first name, or do like a full table scan, right? So the order matters here, like first we care about the first name, then the last name, then the age. So the reason you would do this is if the query that you're running, your hot query that started to get slow, is a where on like all three of these things, right? So like select star from users where first name equals blank and last name equals blank and age equals blank, or whatever, right? So that's the reason behind why you would use a multi column index and just understand that you can essentially repurpose it as an index for the first column. So like you wouldn't need to go add a second index for just the first name, probably. And I just say I add that probably at the end, because technically SQL is just a query language and under the hood, every database acts a little bit differently. So it's always just something to keep in mind. Okay, so rule of thumb, unless you have specific reasons to do something special, only add multi column indexes if you're doing frequent lookups on a specific combination of columns. All right, let's jump into the assignment says we frequently need to look up all of the transactions between two specific users. There's a page on the website that allows a user to look up all the payments they've made to a friend by the friend's name, add an index on the user ID and recipient ID columns called user ID recipient ID IDX to speed up our app. Make sure the user ID is the first column in the index so that we can also use this index to speed up our queries that only care about the user ID. Okay, so create index, we wanted to name it user ID recipient ID IDX. And we're using that on keyword again, right, you'll you'll recognize the on keyword from joins, right, on which table the user's table, no, transactions tip, it's gonna be the transactions table. Yeah, transactions table right there on transactions. And then the field names, it says we want to make sure to use the user ID on first so that when we just query based on user ID, it's still fast, then the recipient ID. Perfect, let's run that. Looks good to me. All right, we had a whole chapter on normalization. Now let's talk about D normalization, right? So you'll remember that I mentioned during the normalization chapter, the generally speaking normalization is a good thing. And you want to normalize your databases, right? You want to reduce data duplication, improve data integrity, all those good things. Well, it turns out that sometimes all that normalization does come at a cost, right? When you get to certain levels of scale, all that normalization, all of those foreign keys, the linking relationships, the join queries, the sub queries, they can start to get slow, because your database technology is trying to do all of that heavy lifting for you all of the time, right? So sometimes, again, I really want to say sometimes you'll run into issues that really can only be solved well by actually denormalizing your database. And what that usually means is introducing duplicate data so that you can speed something up, right? So the question here is denormalizing a database can be used to slow down queries or speed up queries, and really, the answer is to speed up like that's the only reason you would ever like denormalize a database like I don't know why you do it to slow down the queries. The next question is, it's smart to start with a blank database and blanket as needed for speed. So I would argue it's smart to start with a normalized database and only denormalize it as needed for speed. We haven't really talked about this yet, but why does adding duplicate data speed up the database? Or why can it speed up the database? Well, the answer is that when you copy data, you frequently are putting it in a different format that makes it easier to get at makes it easier to access, right? So let's take the example of like an aggregation. Let's say we want to know how many transactions a user has, right? We can write a join query on the users and the transactions table and do a count on all the transactions and return the count of the transactions and voila, right? We have a count. That was a lot of steps just to get the count of transactions, right? If we just store the current number of transactions separately in, say, like a table called transactions count, now our query to get that transactions is like just one, a very simple query that can be performed very quickly as like a primary key lookup, right? Like select star from transactions count where user ID equals blank, right? That's a very fast query. There's no aggregation involved. We like essentially preaggregated by keeping that field up to date. Now again, you have a problem when you do this because it means now like what happens when you have 10 transactions in the transactions table, but your count says 11, right? You've introduced a potential problem or data integrity in your database. So this isn't something you initially want to do. However, when your app gets unbearably slow, because every time a user loads a specific page, you're doing some huge aggregation. It can make sense to denormalize, to precalculate, right? Just for the sake of speed. So start with normalize, denormalize as needed. A blank database is easier to keep bug free, denormalized, it's the same or normalized. I would argue a normalized database is much easier to keep bug free because it ensures that your data is more accurate. You couldn't have a SQL course without talking about SQL injection or SQL injection. This is like the most famous kind of security vulnerability that you can build into your apps if you're not careful. This is a fantastic comic by XKCD. Feel free to pause it and read it. It's hilarious. Go look it up online. Whatever. I love it. Okay. But let's talk about why the joke in this comic works. So let's pretend that we have this query. Insert into students name. So we're inserting into the students table the name column, values, and then a question mark. So we're going to insert some dynamic value into this table, right? So imagine we've got some backend server that has this query programmed into it, and it's going to insert a student's name maybe based on the form input on the website, right? So you can type in your name, click enter, and save a new student in the database. If we're allowing our users to inject any old string into our SQL query, then we can open ourselves up to some vulnerabilities. So in this example, if the user is effectively allowed to put whatever they want in this question mark here, under normal circumstances, we would expect them to just put their name, right? Lane, Allen, whatever. But if instead they put this disgusting little snippet of text, they can actually, you know, rewrite the query a little bit. So instead of this, now we have this filled out version with insert into students name, issues, Robert, semicolon. Now remember a semicolon in SQL terminates the statement. So whatever comes after it is now a new statement, right? So in this case, what this person did was they altered the SQL to now be two statements, the first one inserting a student named Robert, but the second, but the second statement just says drop table students, which means delete the table, right? So by allowing our users to put anything into our SQL queries, we can open ourselves up to this kind of an attack or someone just, someone just destroys your whole database table. So the answer to this, like the way you stop people from doing this is by sanitizing your inputs, which means you're basically detecting this kind of crap and not allowing it to happen. And you might be wondering, Oh no, that sounds like a big pain in the butt. I'm going to have to write some really sophisticated algorithms to stop SQL injection. No, in practice, you, you will not have to do that because those libraries exist, right? So for example, if you're writing go, the go standard library has a SQL package that allows you to like do variable interpolation, right, putting dynamic values into your SQL in a safe way that protects against SQL injection. And basically any database library worth its salt in any programming language is going to take care of that for you. Sure. It's worth looking up and making sure that your database technology does that for you, but you need to, your database library, your data's client does that for you. But just, just, just know that you don't need to be writing it from scratch. You should be finding a tool that does this for you. There's plenty of open source tools that do that. The most common mistakes that the developers make surrounding SQL injection, or I should say the most common mistake that developers make is rather than using a library's ability to do safe interpolation, developers will just use like normal string concatenation in whatever programming language they're using. So, so don't do that. Don't do like normal string concatenation where you have like your SQL and just like a raw string and you're just injecting values into it manually using whatever like the default language features are, right? In JavaScript, it would be template liberals in go, it would be like fmt.edsprintf. In Python, it would be fstrings. Like don't use those to put dynamic values into your database, right? Your database client should have a builtin way to do it that's SQL specific. So the question here says, SQL injection is best avoided by using a modern SQL package that handles the sanitization of user provided values. That is true. Next question says, what happened in the comic? All right, pause the video, read the comic. So, the answers are Robert's grades were all changed to A's, every student's database or every student's data in the school's database was deleted, Robert's data was deleted, or every teacher's data in the school database was deleted. Well, if we look at what actually got injected here, right, Robert drop table students, it's just dropping the students table. So all the students' data in that school's database was deleted.