welcome today's talk is the human nature of failure and resiliency by vm please give her a warm welcome hey hi oh my gosh the microphone is on um hey everyone i have a lot to cover so we're just going to dive right in who am i why am i here my name is vm brassuer but because we're all friends here you can call me vicky plus the virtual machine jokes have gotten old please don't think yours is original because it's not i'm the author of this uh which is as far as we can tell the very first book on how to contribute to free and open source software i am an author and community moderator for opensource.com the vice president of the open source initiative i'm an open source policy and strategy freelancer and i do training on how to do this sort of stuff right here but before i did all of this i used to lead software engineering departments and while i was doing that i started studying failure as a bit of a hobby i did a lot of research into failure this is a link to a bibliography of all that research currently there are 205 items in this bibliography it adds up to approximately 3 500 pages worth of preacher research into failure now this talk is going to take all of that and give you the greatest hits the things that are common across all those 3 500 pages of research into failure i'm going to give it to you today in approximately 40 minutes here they are here's a quick summary these are the themes that are common across all of that research and what i'm going to share with you today like i said there are thousands of pages here i'm not going to get into everything um i'm also not going to give you the secret serum that will prevent failure for you from here on out i'm just not going to do it because it's not possible i will however give you a list of questions of things you should consider when you want to start succeeding with failure i am only going to give you an overview again because dude 3 500 pages what the hell so um there will hopefully be time for questions if not now there is a break afterwards so catch me afterwards and we can talk about failure it's absolutely fascinating so another thing i need to mention as a limitation of this talk it does go into a lot of psychology and what i have found is most of the research almost all of the research is done in a western mindset using western psychology on western individuals and unrelated recent studies have shown that a lot of these psychological concepts that we in western cultures believe are solid truths don't actually hold true as well for europe for eastern asian african cultures so just be aware there is a bias here for western minds and finally do save questions for the end which is something i really don't have to say at pycon but i include this slide anyway so let's get into those common themes and we're going to start with complexity the world is complex this shouldn't come as a surprise to anyone people are complex hell the complexity hiding in something as simple as chocolate chip cookies is really quite mindblowing we as humans however we don't like complexity and that leads us to some very unfortunate tendencies for starters we have a tendency to ignore complexity completely la la la la la nothing to see here moving on everything around us is constantly changing constantly evolving yet research shows we prefer to operate as though we are in a static environment we will start a project we'll take a snapshot in our brain of how things are right then and then we'll operate within the snapshot while the rest of the world moves on without us as you can imagine this can lead to some problems research also shows that we dislike variation we like things to be just so and we like them to stay that way hence that snapshot we also prefer to operate in serial rather than parallel because that minimizes complexity and it allows us to focus our efforts on what we then consider to be the best option so we focus on the static now rather than the ever changing complexity of the future and the parallel projects so we can't know everything and we like to think we do but we really can't and because we're more comfortable with what we know we avoid everything we don't and this this is a problem um we don't actually know as much as we think we know we are each and every one of us a walking talking done in kruger film festival so we don't know uh we think we know more than we do and because of that we have a tendency to overlook a lot of things and these are the unknown unknowns and rather than just some silly thing a politician said once this is actually a real psychological concept it's a latent error latent errors are overlooked near misses latent errors look an awful lot like successes because they haven't failed yet and that's because latent errors have yet to meet their enabling condition a an enabling condition is that trigger that turns a latent error to the dark side of failure so uh there is a very good example i like to use for latent errors meeting their enabling conditions now i won't be able to see when you raise your hand but i'm going to ask you to raise your hands anyway how many of you out there remember the deep water horizon uh tragedy that happened a few years ago yeah the oil rig in the gulf of mexico went boom bad thing so what happened there was you had two latent errors really there was a lot going on but we're going to minimize things because again not going into detail we had two latent errors you had somebody performing a cementing procedure and that cementing procedure was filling a pipe with cement and while he was doing so he was doing it wrong normally that's fine that's perfectly fine he was doing it the way that they always do it and there was never a problem but he was doing it wrong and because of that gas was escaping from the pipe that's latent error number one incorrect cementing procedure latent error number two somebody was welding nearby usually not a problem you can have these things in close proximity all the time and it's an oil rig right someone's always cementing and someone is always welding not a problem okay so two latent errors and then we have our enabling condition something that does not happen very often especially not on the high seas and that is it was a windless day so thanks to that windless day that welding that spark caught the gas there was an explosion it killed 11 people 16 others were critically injured very very bad and we had the worst environmental disaster our country has ever seen because of latent errors meeting their enabling condition now it is possible to spot latent errors um you can look for them in your postmortems do you do postmortems you probably should as you're doing that as you're looking at your postmortem and you're looking at how things went ask the group so what went right we've been looking at what went wrong but what went right pretty much by chance those are probably your latent errors and things you should consider for your next project but here's the problem we're really bad at postmortems we just don't know how to do them so we focus on symptoms rather than causes when we do look for causes we look for just one we look for root cause i'm sorry folks gonna tear down your little house of cards here there is never just one root cause um we also have selection bias we prefer to look at the easy things the things we can actually answer very quickly because it makes us feel accomplished another form of selection bias that we have is that we only postmortem the things that went wrong rather than the things that went right as well if you post more than the things that went right you're more likely to spot those latent errors that never met their enabling conditions but we don't do that for us postmortems are things that you only do when goes wrong so what do we do how can we minimize these tendencies we have with just avoiding complexity well for starters do premortems before you even start your project do a premortem rather than a postmortem and start looking for things that might go wrong start looking for latent errors come up with contingency plans for all of them get skeptics in the room who will question all of your assumptions we'll talk a lot more about that in a moment and then make your plan in your premortem but then plan to change the plan because if you remember you take that snapshot right and we like to work inside the snapshot once in a while plan to pause bring your snapshot into modern times and take it again and once you take that new snapshot you might have to adjust your project accordingly now let's dive into assumptions man nearly every single piece of research in that bibliography has terrible things to say about assumptions um this is one of those lessons we never seem to learn for some reason we always assume and we always assume we're assuming and then we're okay with assuming we assume research has nothing nice to say about assumptions at all for starters assumptions are usually based on incorrect and invalid information we often base them on those snapshots we take in our brain and those snapshots again they're static whereas the world has moved on so our snapshots are wrong our assumptions are wrong we then use those assumptions as a basis for a set of heuristics which we apply to real world situations right now and that's not going to work how many of you have tried to estimate how long it's going to take to complete a project how many of you are actually right probably none of you if i could see your hands and you were you had them still up you would be liars every one of you um other really popular assumptions that we make in technology that we probably should stop doing user needs what is our user actually trying to accomplish we think we know but we really don't and yet we assume we move on and we develop things what business are we really in this is something startups never seem to answer and they keep failing because of it they don't know why they're in business assumptions usually are based upon a poor problem definition we are so bad at this i am a freelancer now i work with companies to help them with their open source strategy and compliance and all that sort of stuff and they come to me and they say vicky we want to do open source and i say great i want to help you do open source why do you want to do it what do you want to get out of it what problem are you looking to solve for your business and almost entirely except for one client i'm working with right now who is so amazing they don't have an answer they don't know why they want to do this and this is common we never really know why we're doing stuff we have a problem we're looking to solve but we haven't defined that problem and so we're basing our assumption on the problem that is not defined and so if we haven't defined our problem and we're basing our assumptions on an undefined problem we're basing our solutions on an undefined problem and we're naturally going to fail because we're doing the wrong thing it is absolutely impossible in technology to fail fast if you don't define success you must know what you're trying to accomplish because if you don't define success you can't define failure you can't fail fast if you don't know what failure even is now we in tech like to say that we don't have time for that holy crap no we are totally agile we are just iterative and it's great you know we're gonna just build and move fast and break stuff and it's amazing but the thing is we don't really we we have the time to do that but we don't have time to check the assumptions we have the time to do that and to build the wrong thing for the wrong person then scrap it because we don't check our assumptions it's terrible so you do have to question your assumptions as you are doing this entire process always question them and that's because psychologists have found over and over again that unquestioned assumptions become facts in the minds of the hearers we have all seen this in play when you're sitting there in a meeting and the person at the top of the desk at the top of the table there says so how long is it going to take to do this someone else at the table raises their hand they say we assume this will take two weeks but we need to confirm research shows that for almost everyone in that room especially the person at the head of the table they don't hear anything after two weeks it's it's just a psychological thing we don't hear and it needs to we need to confirm so this is really common in all cultures across uh all industries but we in technology seem to get bitten by it a lot so assumptions they're horrible they're terrible they are in fact the root of all evil they're not the next one is actually the root of all evil what do we do to minimize the impact well please define your problem please not only define your problem but communicate the definition of the problem because otherwise you will be sitting in that room with all those people and you'll ask them what are we trying to accomplish if each and every person in that room does not have the exact same answer then you still have assumptions that you need to fix and communication that you need to fix as well do premortems list and verify not only those latent errors don't just look for those but explicitly call out every single assumption that you are making be very obvious about it it's great to have assumptions they're shortcuts they allow us to move more quickly but be aware of your assumptions and once you have those write them down and you need to do this because you later need to go back and revisit them throughout the process just check in every once in a while on those assumptions because again you're working in your snapshot you need to update your snapshot to the now and when you're updating your snapshot to the now also go through all of your assumptions because some of them might no longer be assumptions now you might have knowledge rather than an assumption but you're not going to know that if you don't verify and this actually is the root of all evil businesses clubs projects any group of human beings every piece of research shows that human beings are the primary cause of failure surprising huh but we can't exactly get rid of them i highly recommend you do not get rid of human beings so that is not the solution here we are kind of a problematic species um we are fairly arrogant as the top of the food chain we like to think um ellen langer is a psychologist at harvard she was the first person to uh to publish a paper on this it's called illusion of control we as humans again arrogant we like to think we have a lot of control over things and we don't we over estimate the impact our actions can have and we overestimate even what we can just influence let alone control and because of that we ignore latent errors because we think we are in control again near misses remember deepwater horizon now if we look for latent errors if we're not actively ignoring them we can do something about latent errors we can stop that man from doing his cementing procedure incorrectly we can stop that man from doing the welding we can control these two things because we can see them and go that's not going to go well and we can control that but what we can never do is we can never make the wind blow we can never control enabling conditions and therefore we can never control fully any situation we're in we can think we can but we're wrong we just can't do it so how is your team organized your team your project your company how is it actually physically structured and organized you know what's your hierarchy and all that goodness because that organization can have a really dramatic effect on the its success rate and on its reaction to failures are you in silos are you in organizational silos who here knows what i mean by organizational silo hey not quite everyone um the other people are probably just doing twitter but um so organizational silos you've got this team here team c b and a and they're all working on their own little things very happily going along but they're not communicating nobody really knows what anyone else is doing and this is a problem it dilutes responsibility for failure let's say something goes wrong over here in team a there's a failure in team a and it could possibly affect teams b and c but there's no communication they don't tell them that so teams b and c are going to fail as well because nobody has shared information with them silos hamper communication they obscure information and they're a problem and they increase failures within an organization another problem is when your team is organized around processes and let's say you've got one team that's dedicated 100 to testing and this team is writing that team is designing and this team is you know deploying they're all around processes now what happens if the process is what's causing the failure what do you do then well studies show that we as human beings are less likely to change the process because it also might mean we have to change the organizational structure in some way and so we don't do it and we continue using broken processes because of it and that leads to a lot more failures now both with silos and with uh with these process organized things it does require a reorganoid to fix unfortunately and those are we probably all know reorgs are never fun but it will help reduce failures if you have multidisciplinary teams because you get a lot more communication across teams if you have people who cross procedural boundaries within a team and you get a lot more people who are asking questions and questioning assumptions so regardless of the structure of your team your group your project whatever it is regardless of their structure how does it react when something fails does it punish people for failures this is pretty common for people to be punished for failures if that happens it's actually a bigger problem than the failure itself because it increases the the impact of the failure that's because if people are afraid of being punished for failure they stop reporting failures and if people stop reporting failures it is impossible for you to learn from failures because that is the only way to prevent failures is to have failures and learn from them unshared failures are just the experience of an individual and that's it and i can stand right here on this kind of squeaky podium thing um i can stand right here and i can gain experience it just happens to me now if i want to learn from that experience it takes an extra step that's an activity that's something i have to manually do the experience comes at me for free whether i like it or not it's my choice whether i learn from it and for failure it's the same thing we can't learn from failures if we don't share them you don't have the information to share bigger problem or another problem with people being afraid of punishment for failure is that they stop innovating they stop trying new things and i'm not just talking like that silicon valley disrupting sort of innovation i'm not talking about that talking about the kind of innovation that actually matters the innovation of streamlining a workflow the innovation of trying a new library just small everyday innovations that add up to a great deal of improvement in your life we stop doing it because we're afraid we're going to get punished should it fail so that's a big problem i've had people say don't worry we don't have that problem i never hear about failures at all really did you just hear what i said people oh if you're not hearing about it doesn't mean it's not happening just means they're hidden and that's worse than not having failures at all another common problem with humans and also might i add my favorite cognitive bias i do as a matter of fact have a favorite cognitive bias um normalization of deviance uh diane vaughn is an american sociologist she studied the space shuttle challenger explosion and she is the first person to write about the normalization of deviance yey diane so normalization getting difficult to speak up here normalization of deviance is when you have a latent error lying right there in the open and rather than picking it up and putting it away you just step over it you just avoid it you know you just completely ignore la la la there is no latent error there right this is a big problem um an example i like to give of normalized deviance is when let's say you're a new programmer at a a company you're tailing log files as one is want to do and you're looking at log files and this error keeps popping up and you're like holy what is this error omg and you run to the senior developer and you're like hey what's this error and they say don't worry it happens all the time we just ignore it um a as somebody who used to run software engineering departments i'm going to tell you to get that out of the log because it's noise that's blocking my signal so okay that's problem number one but if it's an actual legitimate problem if that error in your log is legit then i'm sorry you are one race condition away from catastrophe that's a latent error that you are ignoring you have normalized that deviance so normalization of deviance we do it all the time we are very familiar with pressure and stress in technology um we have this unfortunate tendency across all of humanity but particularly in technology um also medical we do a lot of this we push ourselves too hard we try doing too much in too little time usually for no good purpose at all and this leads to a lot of problem the obvious problems are fatigue driven errors read the studies in the bibliography about the impact of this on your health care and you will this is real this is a real big problem but it also is a problem because but when we're fatigued when we're tired when we're stressed out we have a tendency research shows to rely more on untested assumptions we will make wild ass guesses and run with them and that's perfectly fine we think it's cool it's okay i'm totally stressed i've got to do i've just got to move on but it's a problem and it leads to a lot more failures so remember when i mentioned that we like to focus on just that one thing we're working in serial rather than parallel right we also have a really hard time not seeing that one thing through to the end uh which is a big problem if we haven't bothered to define what the end is frankly so we're just going to keep on going we're never going to stop because we don't know what done looks like and that's a big problem obviously but then we will have the sunk cost fallacy where people are like we've taken so much time and put in so much effort we should just see it through right okay maybe but usually that's not the case um we also have a problem with killing things before they fail when we've got project champions those people who are in the group and they've got this reality distortion field you know and they're just waving the flag we can do it we can do it and they just get this group think of everyone involved in the project who they get this deeply deeply held belief that yeah we can do it yeah we can succeed even when all evidence is to the contrary people have blind faith that yes we can do this when there's no proof that they actually can and so what you end up with is the shambling zombie project that never dies another reason we can't pull the plug is we aren't taught how to communicate we think we're being very nice by allowing something to continue rather than telling people i'm sorry we have to pull the plug on your project there are really good easy empathetic ways to tell people that we're pulling the plug on your project you're not being a jerk by doing that you can say it in a jerky way and then yeah you are a jerk but we don't teach people how to do this properly and so projects go on and on and on and finally they fail and everyone's upset so what do we do about this what do we do about i already mentioned we can't get rid of humans that's not one of the options organizational changes dealing with people anything dealing with people is hard i'm in management trust me it's hard they're hard to start they're even harder to finish so keep in mind this is these are going to be very difficult things but they're usually worthwhile for starters research shows again and again and again any sort of organizational initiative if it doesn't get support from the top this is where grassroots does not necessarily work you have to get support from the top or else your organizational change will not succeed ideally your support from the top on this failure stopping initiative should be the leaders discussing their own failures their leaders showing what they've learned from their failures and showing people it's okay and that starts to create something that we call an environment of psychological safety because people see it's okay to fail now again experience is automatic learning is not mistakes are also not automatic mistakes are only mistakes because somebody points at it and says yo that's a mistake before that it's just a learning opportunity it's just experience now learning it develops intuition it develops skills how many of you out there are senior technical staff okay i can actually see these hand a little bit so i lied earlier um you can put your hands down now i can guarantee you didn't become senior technical staff because of your age you became senior technical staff because dude you've seen some man okay and i mean you've experienced failure but you learned from it you developed intuition and skill and you're using those past failures to prevent future failures so that's really important we need the failures to do this but you can't do that if you're not in an environment where it's safe to make the failure studies finally are coming out all about psychological safety and you can find them in the bibliography and we are showing that psychologically safe teams are the ones that the most productive they are the most innovative they are the most cost effective so aside from taking care of your team being just the right thing to do in a humane way if that's not good enough for you oh honey please it is so good for your bottom line so there's lots of good reasons to create psychologically safe teams so as you're doing your premortems your postmortems as you're having all these discussions around your project bring in outside people and not just outside from other teams other development teams but i'm talking you know bring in customer service bring in users bring in marketing and finance bring in people who don't think the same way you do and have them in your premortem have them in your postmortem they're going to ask a lot of really interesting questions about things that you have been ignoring and glossing over these are project skeptics these are these are truth seekers and they are really valuable they help surface a lot of things that you otherwise wouldn't see and are latent errors or failures waiting to happen you can also make your projects just more survivable you know just if you're going to try stuff make it easier to try stuff first of all the easiest project to survive is when you don't even start so ask yourself do we really need to do this do we really need to reinvent the wheel again or can't we just use a library that someone else has used right so don't start them at all as manager i like this one build in checkpoints and milestones into every project and if you do funding for a project if you're in a big corporation that does that sort of funding thing um then only fund to a checkpoint otherwise just make this checkpoint a place where everyone in the entire organization knows this is a no go nogo situation if you're not actually moving us towards our goal at that checkpoint we will probably cancel you but that's okay and make sure everyone knows that's okay it's not a sign that you have failed in any way just means we're going to move on to something else it's fine and if you do have something that is potentially not very survivable if you have a project that is going to be a little more um complicated or involved spin it off get it away if you have a project that's going to explode honey get it away from the things that might be hit by the shrapnel you know because otherwise that you're going to have ripple effects from that potential failure should it actually fail all right so let's talk about some ways that you can work with failure experiments are controlled failure and they are amazing we literally as human beings would not be here without failure and that's because of evolution and life forms as in all other things no change is possible without some failure evolution itself is just a constant series of works for now solutions and maybe in a thousand years we'll have a better works for now solution it's just constant series of these so your experimentation should also be similarly uh continuous if you want your business and your project to evolve as you're doing your experiments you have something in mind we're testing for this we want it to look like this and this is your success right redefine that success don't have your success for your experiment be we got the outcome that we were hoping for have success for your experiment mean oh we learned something really good that we can use for future experiments so seek the truth first and traditional success second now experiments can be very risky remember the shrapnel right but that doesn't mean they all have to be risky think of experiments like your financial portfolio balance them with high risk and low risk because otherwise you're going to put your company your team your project all these things at jeopardy if everything is high risk also like investing do it for the long term right you don't just do that day trading and assume you're going to make millions of dollars because that's not the way trading works if you invest in the long term with your experiments you are experimenting multiple times you're not just trying once having it not get the outcome you want and then walking away done we tried it it's not going to work because that's that's not the way you can have successful experiments the nature of successful experiments um we we do like to say fail fast most of us don't really know what that entails but it does start with making things small and survivable again i talked about survivable with that nice little shrapnel metaphor but if we keep experiments small not only are they quicker to iterate upon but it also means that the outcomes are very very closely situated to the actions which means we can more easily determine cause and effect when you go into an experiment assume they're going to fail i just said assume i'm sorry we're not supposed to assume anything i will acknowledge that we are assuming here and i will confirm it later but expect that some of them will fail because if you don't then you're going to be very disappointed with your experiments and do have explicit success and failure criteria know what you're looking for and if you don't know that you can't know when you're not hitting that mark you can't know what failure looks like and to make everybody again more psychologically safe have an exit strategy one of the things that research finds is that people are unwilling to say that their experiment failed because they don't know what's going to happen to them personally at the end well my project failed so what am i going to get canned you you can come up with an exit strategy for these things you can make people feel more secure they know what's going to happen to them at the end and it's not bad but if you don't have an exit strategy people will be uncomfortable okay so introspection which is really not a great title for this slide but we're going to work with it you each and every one of you beautiful individuals in this this hall you want to get better from failure you want to learn from it the best way to do that is to actively start inspecting your failure environment so what sort of questions should you be asking what are you trying to accomplish if you can't answer that and if everyone in your team in your project can't answer that the same way you might have a problem step number one make sure you know what you're doing what's your user trying to accomplish if you're doing this for yourself whatever your project is that's one thing but if you're doing it for some external entity or person make sure you don't assume you know the answer to this question what are those assumptions list them out be very explicit about it because you want to check in on them to make sure they still hold true or not true or you still need more information have you looked for latent errors probably not because most people don't what does failure look like most people if you think of this at all you think of it in the success case but it's not always obvious it's not simply black and white that failure is the opposite of what you had defined as success so be very explicit what failure looks like and then be very clear with people what's going to happen should their experiment fail because then they will feel more safe even trying because there's that giant question mark hanging over their heads do you have a postmortem process do you have a premotor process figure that out in advance so everybody knows there is a preset expectation that you will be doing this how does your organization treat failure if it punishes failure you can try to change your organization but frankly between you me and the wall get out because there are some things that you just can't change on your own and if your organization is pointing fingers and blaming people and punishing for failure that's one of the things that's going to be very difficult for you to change as is an a culture that doesn't provide psychological safety if you're not in a psychologically safe environment if you don't feel you have the freedom and the support to experiment and to fail then you might need to find a job that will allow you to do that now the answers to all of these questions they're going to be different for each and every project each and every team each and every company right and so therefore the solutions are also going to be different for each and every project and team and company and that's why there is no silver bullet here that's why i can't just hand you this happy little serum that's going to make all failure go away forever it's actually really hard to do this properly you do have to think everything through so please just take the time ask these questions answer these questions and communicate your failures across the entire organization for those of us those of you who have been snapping pictures all this of all the slides you're going to be very disappointed to learn they're already available online so they're here at internet archive also here is a link to that bibliography i mentioned my contact information twitter handle at the top free note irc nick in the middle and my email address um and of course my book i will leave this up while we do q a so are there any questions but not comments disguised as questions please come on up to the microphone it looks like we have three and a half minutes maybe four minutes uh thank you for the talk thank you uh you're welcome er oops live demo a lot of these complexity analyses are always concerning about what happens when things go wrong with complexity and i feel like the other half of the coin is can complexity work for us like are there anything like latent successes and i think a lot of people would call this luck but i'm curious if anything in the research has talked about latent successes or how interacting variables might contribute to our success they they do talk a lot about variables um very few of them think of them or discuss them in context of latent successes because nobody's interested in that frankly we're all very interested in the failures because we love watching a train wreck it's just one of those things we do in humanity right we we love clicking through on those horrible click bait you know things that we see on buzzfeed so no that's it's actually a really good perspective though which is why um i recommend that in your postmortem you also look at the successes right because those are very telling as well they can tell you a lot about a what you did wrong but also they can help find the latent errors um next hi um for those of us who are not at the top or close to the top what tips if any of you have for trying to convince upwards to adopt things like this or how do we be more helpful towards leaders who do want to adopt things ideas like this you see this is really weird because i'm used to repeating the questions and i don't have to so uh so how do you manage up essentially yeah uh it depends i don't know the people you're working with and the answer to how do i manage up or how do i manage it all is one of ethical manipulation and in order to ethically manipulate you have to know which buttons to push and those buttons are different for everyone but it you do have to understand what they value right uh do they value certain things like you know success probably you know and and so you can couch things in a term in terms of things that will push their buttons that will help them understand this isn't just for us this is also going to help you and help show them how this is going to support everyone in the group but it can often help to um lead by example here and rather than going up first go lateral and work within your team and have your team be this shining example of collaboration and communication and you know premortems and postmortems and documentation oh for love a dog please doc everything um you know and that can help then become your pilot project and you can point to it it's very helpful to point to something and say look this is successful can you help me scale this up and they're more likely to listen to you at that point cool thank you you're welcome hello hi thanks um so you mentioned spin it off for a high risk project um that kind of felt like just basically delegating off like people who are going to die in an explosion to die what can you say a little more about that um so this often is done with companies as they are uh they want to do some sort of skunk works type thing and it's not going to work in their existing organization because it's going to make other people jealous that they're not working on the skunk works it might actually impact their work on other products you know and so they will spin it off into another company to another team into a lab and they will spin it off like that now while i do say explosion and shrapnel that does imply that i assume which we shouldn't do i assume it's going to fail and it might not so i'm not necessarily sending people off to their deaths because it could be a very successful situation and often spinning these projects out in that way gives people a lot more freedom than they would otherwise so they can experiment more and do things that they wouldn't otherwise be able to do in the typical structure of the group they were in so there it does give you a lot more freedom in that way and again have an exit strategy let people know what happens if this fails what happens if we can't make this experiment work right we're going to bring you all back in you're going to work on this we're going to move you to another lab so people know that they're not just going to get cut okay thank you welcome we are have 40 minutes or 40 seconds if there's any more questions otherwise great thank you all thank you